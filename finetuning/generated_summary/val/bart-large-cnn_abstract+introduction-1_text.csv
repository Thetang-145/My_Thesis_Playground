paper_id,summary
SP:7f4b788b00a2a10bcd60351c3e04c8f597101e96,"This paper proposes sqSGD (selective quantized stochastic gradient descent) for federated learning under local differential privacy constraints. The proposed algorithm is based on a novel privacy-preserving quantization scheme that uses a constant number of bits per dimension per client. The authors also improve the base algorithm in two ways: first, they apply a gradient subsampling strategy that offers simultaneously better training performance and smaller communication costs under a fixed privacy budget. Secondly, they utilize randomized rotation as a preprocessing step to reduce quantization error."
SP:632666b52c7c551d67fbbe70c06ed589c3a5e187,"This paper proposes a simple representation method for self-attention networks (SANs) that leverages prior knowledge related to language representation from the beginning of training. Specifically, the authors propose to use the prior word frequency knowledge for monolingual data and other prior translation lexicon knowledge for bilingual data, respectively, to enhance the language representation. The proposed method allows SANs to leverage prior knowledge in a universal way compatible with neural networks. Empirical results on two translation tasks demonstrate the effectiveness and universality of the proposed method."
SP:e3e728837f26acb9da283a42c219b6c3b3e131cb,This paper proposes a Bayesian Stackelberg Markov game-theoretic model for moving target defense (MTD) in which the attacker and the defender are playing a leader-follower game. The proposed model is based on Bayesian Bayesian Markov games (BSMGs) that model uncertainty over attacker types and the nuances of an MTD system. A Bayesian Q-learning (BSS-Q) approach is proposed to learn the optimal movement policy for BSMGs within a reasonable time. Experiments show that the proposed method converges to an SSE of a BSMG. 
SP:97911e02bf06b34d022e7548beb5169a1d825903,"This paper proposes a VAE ensemble framework for unsupervised disentangled representation learning. The framework is based on the assumption that entangled representations are unique in their own ways, and the disentanglement representations are “alike” (similar up to a signed permutation transformation). In the proposed ensemble, each model not only maintains its original objective, but also encodes to and decodes from other models through pair-wise linear transformations between the latent reprere sentations. Theoretical analysis shows that the success of the proposed framework is mainly due to the VAE im-plementation choices that encourage a PCA-like behavior locally on data samplers."
SP:59f9de3ebe4a04d2fc8778d8e3415bf85efb7822,This paper proposes a zero-shot approach to automated machine learning (AutoML) that predicts a high-quality model for a supervised learning task and dataset in real-time without fitting a single model. The method uses a transformer-based language embedding to represent datasets and algorithms using their free-text descriptions and a meta-feature extractor to represent the data. The graph neural network generalizes to new datasets and new sets of datasets. Performance is competitive with state-of-the-art AutoML systems while reducing running time from minutes to seconds.
SP:0f74dff929a4908405ebfa8e60fe1860eec6364f,"This paper studies the problem of compositional generalization in neural networks. The authors argue that gradient descent is one of the reasons that make compositionality learning hard during neural network optimization. They find that the optimization process imposes a bias toward non-compositional solutions. This is caused by gradient descent, trying to use all available and redundant information from input, violating the conditional independence property of compositionality. Based on this finding, the authors suggest that compositional learning approaches considering only model architecture design are unlikely to achieve complete compositionality, and suggest that standard approaches with architecture design alone do not address the compositionality problem."
SP:f99a1b2dbcb7a7b30dbfcfc60668e94b4ad53410,"This paper proposes a method for entity alignment based on knowledge graph embeddings. The proposed method, called NeoEA, aims to learn KG-invariant and principled entity representations, while preserving the original infrastructure of existing methods. The method is evaluated on a variety of entity alignment tasks, and the results show that the proposed method outperforms the baselines. "
SP:0e42de72d10040289283516ec1bd324788f7d371,"This paper proposes SACoD, a Sensor Algorithm Co-Design framework to develop more efficient CNN-powered PhlatCam. In particular, the mask coded in the Phlatcam sensor and the backend CNN model are jointly optimized in terms of both model parameters and architectures via differential neural architecture search. Extensive experiments including both simulation and physical measurement on manufactured masks show that the proposed framework achieves aggressive model compression and energy savings while maintaining or even boosting the task accuracy, when benchmarking over two SOTA designs with six datasets on four different tasks."
SP:493afcfa3fd64967785928ba3acecf3ffa6ce579,"This paper proposes a temporal matrix factorization model to learn the average developmental path and structured variations of individuals in the social network over their entire lives in two honey bee colonies. The authors use a unique dataset containing lifetime trajectories of all individuals over multiple generations in two generations in the two honey bees. The proposed method yields interpretable embeddings that are biologically plausible and consistent over time, which allows comparing individuals regardless of when or in which colony they lived. "
SP:08ae056f269c731b92b5a3d59e18f9ccfc0b703c,This paper proposes a data augmentation pipeline for image reconstruction tasks arising in medical imaging. The proposed pipeline is based on the idea of Data Augmentation (DA) for classification problems. The authors propose to use a few under-sampled linear measurements from the fastMRI dataset to augment the training data. They show that the proposed pipeline can achieve comparable performance to the state-of-the-art on the fast MRI dataset while using significantly fewer training data than the SOTA.
SP:3fdaae674a2b9d437a43d32778437dc7df9c1686,"This paper proposes a deep repulsive clustering (DRC) algorithm for order learning. DRC is based on the order-identity decomposition (ORID) network to divide the information of an object instance into an order-related feature and an identity feature. Then, object instances are grouped into clusters according to their identity features using a repulsive term. Moreover, DRC estimates the rank of a test instance, by comparing it with references within the same cluster. Experimental results on facial age estimation, aesthetic score regression, and historical color image classification show that the proposed algorithm can cluster ordered data effectively and yield excellent rank estimation performance."
SP:a5775441639529d61b7fee4b4298fd82a0c93bb5,"This paper proposes RAPID, a model-free exploration method for procedurally-generated environments. The method is motivated by how humans distinguish good exploration behaviors by looking into the entire episode. The proposed method considers each episode as a whole and gives an episodic exploration score from both per-episode and long-term views. Those highly-scored episodes are treated as good exploration behavior and are stored in a small ranking buffer. The agent then imitates the episodes in the buffer to reproduce the past good exploration behaviours. The experimental results show that the proposed method significantly outperforms the state-of-the-art intrinsic reward strategies in terms of sample efficiency."
SP:30024ac5aef153ae24c893a53bad93ead2526476,"This paper proposes Isometric Propagation Network (IPN), a method for zero-shot learning (ZSL) that aims to learn a mapping between the semantic space of class attributes and the visual space of images based on the seen classes and their data. Specifically, IPN learns to propagate the class representations on an auto-generated graph within each space and regularizes the two dynamic propagation procedures to be isometric in terms of the two graphs’ edge weights per step by minimizing a consistency loss between them. IPN achieves state-of-the-art performance on three popular ZSL benchmarks. "
SP:1d7c174f4f7a0eb26edceecc117f9af1528802e5,"This paper proposes HyperGrid Transformers, a new Transformer architecture that leverages task-conditioned hyper networks for controlling its feed-forward layers. Specifically, the authors propose a decomposable hypernetwork that learns grid-wise projections that help to specialize regions in weight matrices for different tasks. In order to construct the proposed hypernetwork, the proposed method learns the interactions and composition between a global (task-agnostic) state and a local task-specific state. The authors conduct an extensive set of experiments on GLUE/SuperGLUE. On the SuperGLUE test set, they match the performance of the state-of-the-art while being 16 times more parameter efficient."
SP:d957241c02163c1c5bc03a688aa4a2eb486fb9f1,"This paper proposes an algorithm to improve the overall performance of the task of “learning to steer” by analyzing the sensitivity of the learning algorithm with respect to varying quality in the image input for autonomous driving. Based on the sensitivity analysis, the proposed algorithm is able to enhance the learning outcomes up to 48%. A comparative study drawn between the approach and other related techniques, such as data augmentation and adversarial training, confirms the effectiveness of the algorithm."
SP:2df9ba21f72e041f80c7bc9ecfe89353f172b058,"This paper proposes Deep Constraint Completion and Correction (DC3), an algorithm to enforce the hard constraints of large optimization problems with hard constraints. Specifically, this method enforces feasibility via a differentiable procedure, which implicitly completes partial solutions to satisfy equality constraints and unrolls gradient-based corrections to satisfy inequality constraints. The proposed method achieves near-optimal objective values while preserving feasibility. In addition, DC3 can be used to optimize AC optimal power flows on the electrical grid."
SP:61a0163b21dc8f92dd699c1e154f53d30c80b2fe,This paper proposes a growing regularization method for deep neural network pruning. The proposed method is based on the L2 regularization with growing penalty factors. The authors show that the proposed method can improve the performance on CIFAR-10/100 and ImageNet datasets. They also propose a growing penalty scheme to exploit Hessian information for more accurate pruning without knowing the Hessian values.
SP:7b2bf0e36c926d1ed5ab9593a11e4ebce49df6ba,"This paper investigates the role of planning in model-based reinforcement learning (MBRL) algorithms. The authors study the performance of MuZero, a state-of-the-art MBRL algorithm with strong connections and overlapping components with many other MBRL algorithms. They find that planning is most useful in the learning process, both for policy updates and for providing a more useful data distribution. They also find that using shallow trees with simple Monte-Carlo rollouts is as performant as more complex methods, except in the most difficult reasoning tasks, and that planning alone is insufficient to drive strong generalization."
SP:96afc34acb196af0b37f66ca9c89ae22ee7b6521,"This paper proposes a method to perform implicit planning in deep reinforcement learning. The method is based on a combination of contrastive self-supervised learning, graph representation learning, and neural algorithmic reasoning. The authors show that the proposed method is able to match the performance of VIN-like models when the underlying MDP is discrete, fixed and known, and provide significant improvements to model-free baselines across three general MDP setups."
SP:b0fa24ad48e7e60d6899bd799adcd03473cadd6e,"This paper studies the learning of read-once DNFs, a subset of functions that are known to be efficiently learnable by neural networks. The authors show empirically that the learned neurons are aligned with the terms of the DNF, despite the fact that there are many zero-error networks that do not have this property. They show that the learning process has a clear inductive bias towards such logical formulas. They then show that this risk can be minimized by multiple networks: from ones that memorize data to ones that compactly represent the DNNs. Finally, the authors provide theoretical insights to explain why gradient descent “chooses” the compact representation."
SP:6e600bedbf995375fd41cc0b517ddefb918318af,"This paper proposes Graph Structured Reinforcement Learning (GSRL), which leverages graph structure in historical trajectories to slowly adjust exploration directions and rapidly update value function estimation with related experiences. GSRL constructs a dynamic graph on top of state transitions in the replay buffer based on historical trajectory and develops an attention strategy on the map to select an appropriate goal direction, which decomposes the task of reaching a distant goal state into a sequence of easier tasks. The authors also leverage graph structure to sample related trajectories for efficient value learning. Results show that GSRL can outperform the state-of-the-art algorithms in terms of sample efficiency on benchmarks with sparse reward functions."
SP:80c62de18a6a7433c9728fe0d731f733bb89e898,"This paper proposes Prioritized Level Replay (PLRE), a method for prioritizing training levels throughout training using a heuristic-based assessment of the learning potential of replaying each level during training. PLRE is motivated by the hypothesis that different levels provide different learning progress for an agent at specific times during training, and proposes a general framework for estimating the future learning potential given the current state of the agent’s policy. The authors show that temporal-difference (TD) errors, while previously used to selectively sample past transitions, also prove effective for scoring a level’S learning potential when the agent replays (that is, revisits) that level to generate entirely new episodes of experiences from it. "
SP:fd92d766a7721a411ff8c422bec18391d028fa78,"This paper proposes a model-agnostic approach to adapt auxiliary task gradients for asymmetrical task learning. The authors propose to decompose auxiliary updates into directions which help, damage or leave the primary task loss unchanged. This allows weighting the update directions differently depending on their impact on the problem of interest. The proposed method ATTITTUD leverages efficient automatic differentiation procedures and randomized singular value decomposition for scalability. The experimental results show that the proposed method outperforms strong baselines when leveraging out-of-distribution data."
SP:8eb8c34e56de137bfc32ea0fd8cd94e4bff5907d,"This paper presents a method for one-shot word-object learning in a simulated 3D world with a dual-coding external memory, where the agent is given a novel object and is instructed to put it on the bed. The agent is trained with a single introduction to the object via visual perception and language (“This is a dax”) and is able to manipulate the object as instructed. The authors show that the agent generalizes to novel exemplars within the same ShapeNet category and is effective in settings with unfamiliar numbers of objects. They further show how dual-code memory can be exploited as a signal for intrinsic motivation, stimulating the agent to seek names for objects that may be useful later. "
SP:9bd3d99bce743d356eb18692ef93365c78e5fcec,"This paper studies the problem of class imbalance in few-shot learning. In particular, the authors study the effect of dataset vs. support set imbalance, effect of different imbalance distributions (linear, step, random), and effect of rebalancing techniques. They extensively compare over 10 state-of-the-art few shot learning methods using backbones of different depths on multiple datasets. Their analysis reveals that the performances of their class-imbalance counterparts always drop, by up to 18.0% for optimization-based methods, although feature-transfer and metric-based algorithms generally suffer less. They also provide insights into the previously unaddressed CI problem in the (meta-)training dataset, showing that imbalance at the dataset level are less significant than the effects at the support set level."
SP:2a9cbbe3661d2f02f71472d0111f22a739412226,"This paper proposes a novel graph convolutional neural network (GCN) architecture based on the Polynomial Graph Convolutional (PGC) layer. The PGC layer is a non-linear combination of multiple graph convolutions (GC) layers, where each GC layer exploits neighbouring nodes at different topological distances, generating decoupled representations for each of them. The proposed PGCN is shown to be more expressive than the most common convolution operators and their linear stacking. Empirical results show that the proposed method achieves state-of-the-art performance on several commonly adopted graph classification benchmarks."
SP:b0a6873eb4bbf5cdc4a5dfa08782225ae91fc589,"This paper proposes Sim2SG, a method for sim-to-real transfer learning for scene graph generation. The authors decompose the domain gap into appearance, label and prediction discrepancies between the two domains, and propose pseudo statistic based self-learning and adversarial techniques to handle these discrepancies. The proposed method is validated on toy simulators and real-world data."
SP:ccc72f26d0637476d01671c147b5cb5d30fa8c2d,This paper proposes a model-free algorithm for continuous-action DRL for MuJoCo. The proposed algorithm REDQ is based on an ensemble of Q functions and in-target minimization across a random subset of the Q functions from the ensemble. The experiments show that REDQ achieves better performance than the state-of-the-art model-based algorithm on the MuJoco benchmark. REDQ can achieve this performance using fewer parameters and with less wall-clock run time. 
SP:c424d050996a7f383d2f12418dfdcea90d94ea65,"This paper proposes an extension of DSS and DATASET2VEC architectures to the case of probability distributions. The proposed architecture, called DIDA, inherits the NN properties of universal approximation, and its robustness with respect to Lipschitz-bounded transformations of the input distribution is established. Experiments on two tasks defined at the dataset level demonstrate the merits of the proposed model."
SP:3e5d5b61dceca85c444b3d0d06577229c3146664,"This paper proposes a spectral graph densification approach (GRASPEL) for graph learning from high-dimensional data. The proposed method is based on graph Laplacian-like matrices in graphical Lasso to learn ultra-sparse undirected graphs from potentially high dimensional input data. By interleaving the latest high-performance nearly-linear time spectral methods, the graph can be learned by identifying and including the most spectrally-critical edges into the graph. Compared with prior state-of-the-art graph learning approaches, the proposed method can substantially improve computing efficiency and solution quality of a variety of data mining and machine learning applications, such as manifold learning, spectral clustering (SC), and dimensionality reduction."
SP:7e6c73a642a8b3d64156c1d0ecf11f84e7222a22,"This paper proposes a novel unsupervised learning approach named goal-conditioned policy with intrinsic motivation (GPIM), which jointly learns both an abstract-level policy and a goal-conditional policy. The abstract level policy is conditioned on a latent variable to optimize a discriminator and discovers diverse states that are further rendered into perceptually-specific goals for the goal conditioned policy. Experiments on various robotic tasks demonstrate the effectiveness and efficiency of the proposed GPIM method."
SP:bdf293bf2118a927cbec6b96be03bfcad0243640,"This paper studies the problem of policy switching in deep reinforcement learning with low switching cost, i.e., a small number of policy switches during training. The authors propose an adaptive policy switching criterion based on the feature distance between the deployed Q-network and the underlying learning Q-networks. They show that this criterion substantially decreases the switching cost while maintaining a similar sample efficiency to the case without the low-switching-cost constraint. They also provide theoretical justification from a representation learning perspective."
SP:d06bef9ee5e9bdda1571478b6a8a7a2d3ab42f1b,This paper proposes a homotopy-stochastic gradient descent (H-SGD) algorithm for solving large-scale non-convex optimization problems. The proposed algorithm is a combination of SGD and SGD with homotopies. Theoretical analysis shows that the proposed algorithm enjoys a global linear rate of convergence to a neighborhood of a minimum while maintaining fast and inexpensive iterations. Experimental evaluations confirm the theoretical results and show that H-SGd can outperform standard SGD. 
SP:195d090d9df0bda33103edcbbaf300e43f4562be,"This paper proposes a Bayesian meta-learning method for estimating the 3D shape of objects from sparse point clouds. The proposed method is based on the Bayesian approach of Maeda et al. (Maeda et al., 2020) whose posterior estimate behaves asymptotically well with respect to the size of contextual dataset, and combine their method with Implicit Geometrical Regularization (IGR) (Gropp et al, 2020). The experimental results on ShapeNet and ICL-NUIM datasets demonstrate the effectiveness of the proposed method."
SP:ca637a2692cf2424d1ec5c7d2051c7881a5816f4,"This paper proposes a channel-wise activation suppressing (CAS) strategy to improve the robustness of deep neural networks (DNNs) against adversarial examples. The proposed method is motivated by the observation that the activation magnitudes of adversarial example are higher than that of natural examples, and that the channels are activated more uniformly than natural examples. This motivates the proposed CAS strategy to suppress redundant activation from being activated by adversarial perturbations via a Channel-wise Activation Suppressing strategy. Empirical results show that the proposed method can improve the adversarial robustness."
SP:a50e9aeb17340b141f7b88d522911a5c9229f7d3,"This paper presents a non-asymptotic analysis of overparametrized single-hidden layer linear networks with random initialization. The authors show that the squared loss converges exponentially at a rate that depends on the level of imbalance of the initialization. They show that large hidden layer width, together with (properly scaled) random initialization, implicitly constrains the dynamics of the network parameters to be close to a low-dimensional manifold. In turn, minimizing the loss over this manifold leads to solutions that correspond to the min-norm solution in the linear case. "
SP:7341f8e456c0b80a59595f1cc145b776add3db3f,This paper studies the eigenvalue decay of deep neural networks with ReLU activations. The authors show that deep networks have essentially the same approximation properties as their shallow two-layer counterpart. This highlights the limitations of the kernel framework for understanding the benefits of such deep architectures. The main theoretical result relies on characterizing such eigenvalues through differentiability properties of kernel function.
SP:3dd495394b880cf2fa055ee3fe218477625d2605,"This paper proposes a novel algorithm to address the overestimation problem in continuous control through deep reinforcement learning. Specifically, the authors propose to add a weight factor to adjust the influence of two independent critics, and use the combined value of weighted critics to update the policy. Then the updated policy is involved in the update of the weight factor, in which the authors provide theoretical and experimental guarantees for future policy improvement. The proposed algorithm is evaluated on a set of classical control tasks and is shown to be more computationally efficient and stable than several existing algorithms for control."
SP:a7f72a5f99f2e3e1a643e9bb83bf0416a859ec06,"This paper extends the inverse reinforcement learning (IRL) problem to a well-posed expectation optimization problem, where the goal is to recover the reward functions from expert demonstrations. The authors propose a Monte Carlo expectation-maximization (MCEM) method to estimate the parameter of the probability distribution as the first solution to the SIRL problem. The proposed method is able to generate alternative solutions to the IRL problem from a global viewpoint, and achieves a considerable performance on the objectworld."
SP:ee628e3ddc01de3f915b04834245c2250015e4d0,"This paper provides a unified theoretical analysis of self-training with deep networks for semi-supervised learning, unsupervised domain adaptation, and unsupervisory learning. The authors propose a simple but realistic assumption that a low-probability subset of the data must expand to a neighborhood with large probability relative to the subset. They also assume that neighborhoods of examples in different classes have minimal overlap. They prove that under these assumptions, the minimizers of population objectives based on self training and input consistency regularization will achieve high accuracy with respect to ground-truth labels."
SP:daa229d78712808420aad4c50604fc28fd2a4aba,"This paper proposes a hierarchical video prediction method for long-term video prediction. The proposed method is based on learning a sequence of semantic labels for each pixel in a video, and then predicting the motion and content change in this label space using a variational sequence model. Given the context frames and the predicted label maps, the proposed method generates the textures by translating the sequence of label maps to the RGB frames. The experimental results show that the proposed model is able to generate complex scene structures and motions over a very long time horizon. "
SP:e50b1931800daa7de577efd3edca523771227b3f,"This paper proposes a new method for graph neural networks (GNNs) that can handle undirected and directed graphs in a unified way. The key idea is to use a pair of affine transformations to characterize the process of message passing between graph nodes and assign an adjoint probability vector to them to form an IFS layer with probability. After embedding in the latent space, the node features are sent to IFS for iterating, and then obtain the high-level representation of graph nodes. The experimental results show that the proposed method is better than the related methods. "
SP:89d65999a0600ec4f81daf6232fb5897676b3ce3,"This paper proposes a method for graph generation from a geometric perspective by associating each node with a position in space and then connecting edges in-between based on a similarity function. The main contribution is dubbed as the geometric graph (GG) generative adversarial network (GAN), which is a Wasserstein GAN that addresses the above challenges. GG-GAN is permutation equivariant and easily scales to generate graphs of tens of thousands of nodes. It is competitive or surpasses the state-of-the-art methods that are either slower or that are non-equivariant."
SP:4f9388c18e44995fb1c6830256c520ff47a2e6ee,"This paper proposes an unsupervised method to mine noise-robust rules of the form X → Y, where X and Y are sets of neurons in different layers in a neural network. The proposed method is based on the Minimum Description Length principle, which identifies the best set of rules as the one that best compresses the activation data. Extensive evaluation shows that the proposed rules give clear insight in how networks perceive the world: they identify shared, class-specific traits, compositionality within the network, and locality in convolutional layers. "
SP:fc75d8d62ac5cc4cdde1b923ae54659a0dfba28b,"This paper studies the problem of fixed-dataset policy optimization in the worst-case setting. The main contribution of this paper is to provide a unified framework for the study of algorithms in this regime. This framework is based on the pessimism principle, which states that we should choose the policy which acts optimally in the worse possible world. The paper shows that pessimistic algorithms can achieve good performance even when the dataset is not informative of every policy, and derive families of algorithms which follow this principle. The theoretical findings are validated by experiments on a tabular gridworld, and deep learning experiments on four MinAtar environments."
SP:363661edd15a06a800b51abc1541a3191311ee0e,"This paper proposes a memory-efficient ALF Integrator (MALI) method for neural ODEs. The proposed method is based on the asynchronous leapfrog (ALF) solver, which has a constant memory cost w.r.t. number of solver steps in integration similar to the adjoint method, and guarantees accuracy in reverse-time trajectory (hence accuracy in gradient estimation). Extensive experiments on image classification, time series modeling, and continuous generative models demonstrate the effectiveness of the proposed method. "
SP:45b6d522ed9a2ecda2db0a3d45688ed3b0f32875,"This paper proposes a methodology to compare complex scene conditional generation models, and provides an in-depth analysis that assesses the ability of each model to fit the training distribution and hence perform well on seen conditionings, to generalize to unseen conditionings composed of seen object combinations, and to generalise to unseen conditions composed of unseen object combinations. The authors observe that recent methods are able to generate recognizable scenes given seen conditions, and exploit compositionality to generate unseen conditioning with seen objects combinations. However, all methods suffer from noticeable image quality degradation when asked to generate images from unseen conditions. Moreover, through the analysis, the authors identify the advantages of different pipeline components, and find that encouraging compositionality through instance-wise spatial conditioning normalizations increases robustness to both types of unseen conditionsings. "
SP:77bce8c5d383f6be82ebc694bf66fb1a408ad751,"Graph-Augmented Multi-Layer Perceptrons (GA-MLPs) are a variant of Graph Neural Networks (GNNs) that first augments node features with certain multi-hop operators on the graph and then applies learnable node-wise functions. The authors show that GA-MLP with suitable operators can distinguish almost all non-isomorphic graphs, just like the Weisfeiler-Lehman (WL) test and GNNs. However, by viewing them as node-level functions and examining the equivalence classes they induce on rooted graphs, the authors prove a separation in expressive power between GNN and GMLPs that grows exponentially in depth. In particular, unlike GNN, GA- MLPs are unable to count the number of attributed walks."
SP:5c0783e92017fc808ebd44a7d1aa7f6b92baacd8,"This paper proposes an actor-learner distillation (ALD) method to transfer learning progress from a large capacity learner model to a small capacity actor model in the actor-latency constrained settings. The proposed method leverages a continual form of policy distillation to compress, online, a larger “learner model” towards a tractable actor model. The method is applied to partially-observable environments, where transformer models have had large improvements over LSTMs recently, but at the cost of significantly higher computational complexity. The results show that the proposed method recovers the clear sample-efficiency gains of the transformer learner models while maintaining the fast inference and reduced total training time of the LSTM actor model, while still having experiment run-time comparable to the smaller LSTm."
SP:ccd59c3acb3d0886030451bbaea68fb83ef4dfa5,This paper proposes a Universal Representation Transformer (URT) layer for few-shot image classification. The URT layer is a meta-learning layer that dynamically re-weights and composes the most appropriate domain-specific representations. The experiments show that URT sets a new state-of-the-art result on Meta-Dataset. 
SP:beaa3dfef4bdf3d8fea64d4cf86911f45edd2873,"This paper proposes an unsupervised Progressive Learning (UPL) algorithm for learning representations from a stream of unlabeled data in which the number of object classes increases with time. To solve the UPL problem, the authors propose an architecture that involves an online clustering module, called Self-Taught Associative Memory (STAM), which learns based on a combination of online clusters, novelty detection, forgetting outliers, and storing only prototypical representations rather than specific examples. "
SP:f7a8e5a580524d54f4a0cd08bd3cb0a0a074528b,"This paper studies the generalization gap between decentralized and centralized training of deep learning models. The authors identify the changing consensus distance between devices as a key parameter to explain the gap between centralized and decentralized training. They show that when the consensus distance does not grow too large, the performance of centralized training can be reached and sometimes surpassed. They highlight the intimate interplay between network topology and learning rate at the different training phases and discuss the implications for communication efficient training schemes."
SP:08ab81a53ae0b51b214442f2f9d6edca0df9118c,"This paper proposes a siamese recurrent neural network (Siamese RNN) model for sequential multi-variate data. The proposed model is based on dynamical system theory, and is motivated by the analogy between synchronized trajectories produced by dynamical systems and the distance between similar sequences processed by a Siamese neural network. The model is able to simultaneously learn a similarity metric and the synchronization of unaligned sequences in a weakly supervised way. The experiments show that introducing such a coupling improves the performance of the proposed model. "
SP:e32bb6044bcb26cad3b0161db19170d726c40fae,"This paper studies the effect of codistillation (codistillation) on the performance of distributed SGD in distributed training. In particular, the authors propose to use a weak synchronization mechanism to encourage different models to learn the same function in parallel. This is different from the more commonly used fully-synchronous data-parallel stochastic gradient descent methods, where different model replicas average their gradients (or parameters) at every iteration and thus maintain identical parameters. The authors find that even at moderate batch sizes, models trained with codistillation can perform as well as models trained using synchronous data parallel methods, despite using a much weaker synchronization mechanism. "
SP:cd03bc0b12cf44e9d538d274de7dfe44acdb1e35,"This paper studies the generalization properties of SGD in deep learning. The authors show that SGD converges to a heavy-tailed stationary distribution with infinite variance in a simple linear regression problem with Gaussian data. They further characterize the behavior of the tails with respect to the algorithm parameters, the dimension, and the curvature. Finally, the authors conduct experiments on synthetic and fully connected neural networks."
SP:89f995142f8a2fcdc8c7b9f2e2cd1a4f75df3226,"This paper studies the effect of bandpass filtering on the performance of community detection networks (GCNs) in the low-frequency domain. In particular, the authors show that high-frequency components are less important for community detection. They also show that low-rank approximations of the graph Laplacian are more important than high-rank ones. The authors also provide several experiments to show the impact of high-frequencies on GCNs."
SP:7fc7e37c699a1bb738c65f0c6fa983203c6fd067,"This paper proposes a self-supervised method for learning graph structure and graph neural network parameters in a latent graph learning setting. The proposed method, SLAPS, is based on the idea of simultaneous learning of the graph adjacency and GNN parameters. The authors propose to learn the graph structure through self supervision and then apply a GNN to the inferred graph. The method is evaluated on several benchmarks and compared with several baselines. "
SP:8f8e1fa4cd025fc056a60c0b6ba9915e8617447f,This paper proposes a novel detection method for continual learning. The novelty detection method leverages network confusion caused by training incoming data as a new class. The proposed method is evaluated on a variety of image classification benchmarks. The results show that the proposed method outperforms existing methods. 
SP:1d242517748c52f2be8f0613316cda3a54d1d2f7,"This paper proposes a framework for learning to interpret natural language constraints for safe RL. To this end, the authors introduce a new multi-task benchmark that requires an agent to optimize reward while not violating constraints specified in free-form text. They then develop an agent with a modular architecture that can interpret and adhere to such textual constraints while learning new tasks. Their model consists of (1) a constraint interpreter that encodes textual constraints into spatial and temporal representations of forbidden states, and (2) a policy network that uses these representations to produce a policy achieving minimal constraint violations during training. They show that their method achieves higher rewards (up to 11x) and fewer constraint violations (by 1.8x) compared to existing approaches."
SP:bc9f37b4622868a92f9812d2ea901def79229d41,"This paper proposes a method for few-shot semantic edge detection, which aims to localize boundaries of novel categories using only a few labeled samples. The proposed method employs a semantic segmentation module in small-scale to compensate for lack of semantic information in edge labels. The predicted segmentation mask is used to generate an attention map to highlight the target object region, and make the decoder module concentrate on that region. The paper also proposes a new regularization method based on multi-split matching. Two new datasets, FSE-1000 and SBD-5, are constructed for the purpose of the proposed method."
SP:5e99fee48137d3d3d88017a02f7285ce35dce970,"This paper proposes Causal Screening, a method for generating causal explanations for graph neural networks (GNNs) from the perspective of cause-effect. The proposed method incrementally selects a graph feature (i.e., edge) with large causal attribution, which is formulated as the individual causal effect on the model outcome. The method is model-agnostic and can be used to generate faithful and concise explanations for any GNN model. Experiments on three graph classification datasets demonstrate the effectiveness of the proposed method."
SP:5b3d76b9e67bc39a813979b5d232a59f597d257d,"This paper proposes a new measure of network simplicity based on the smallest fraction of the network parameters that can be kept while pruning without adversely affecting its training loss. The authors show that this measure is highly predictive of a model’s generalization performance across a large set of convolutional networks trained on CIFAR-10. They also show the mutual information between the predictions of their new measure and strong existing measures based on models’ margin, flatness of minima and optimization speed."
SP:835d01ee91523fb29595cae8339dfe49de7d3a7c,This paper proposes a novel method for learning discrete representations for long-horizon planning. The method is based on the idea of learning a sequence of abstract states for a low-level model-predictive controller to follow. The proposed method is evaluated on a series of long-term video exploration tasks. The results show that the proposed method outperforms baselines in terms of planning performance. 
SP:2e31a542a7a60b1d425d95dd26e62374ba799cb8,"This paper proposes bit-level sparsity quantization (BSQ) to tackle the mixed-precision quantization from a new angle of inducing bit level sparsity. The authors consider each bit of quantized weights as an independent trainable variable and introduce a differentiable bit-sparsity regularizer to induce all-zero bits across a group of weight elements and realize the dynamic precision reduction. The method enables the exploration of the full mixed precision space with a single gradient-based optimization process, with only one hyperparameter to tradeoff the performance and compression. "
SP:9b8ae88357e03447c73c792ff5c173ddc3d365e7,"This paper studies the robustness of quantized neural networks against gradient-based adversarial attacks. The authors propose a temperature-scaled attack method to mitigate the gradient vanishing issue in quantized networks. The proposed method is based on the observation that gradient vanishing is due to poor forward-backward signal propagation in the trained network. To mitigate this issue, the authors introduce a simple temperature scaling approach to mitigate gradient vanishing while preserving the decision boundary. Experiments on CIFAR-10/100 datasets with multiple network architectures demonstrate the effectiveness of the proposed method. "
SP:16dddbe1432e4ffbf4b2a9180bf3c67495bd9e81,"This paper proposes ProtoryNet, a prototype-based RNN model that predicts the next sentence in a text sequence based on the most similar prototype for each sentence in the sequence. The proposed method is motivated by the prototype theory in modern linguistics. The authors propose to use the proximity of each sentence to the prototype as the input to the RNN backbone. The RNN is trained to predict the next word in a sentence based on its proximity to the closest prototype. The experimental results show that the proposed method performs better than the state-of-the-art.  "
SP:ac8a9afa6e87f9c36d080c2e7085c4e096af64ff,"This paper proposes a special case of hidden Markov models (HMMs) for disease progression modeling, where the true patient health state is not fully known. The proposed HMRNN can be combined with any other predictive neural networks that take patient covariate information as input. Theoretical equivalence of the proposed model is proved, and the proposed method is shown to have the same likelihood function as a corresponding discrete-observation HMM. Experiments are conducted on Alzheimer's disease dataset to demonstrate the effectiveness of the method."
SP:6355337707f1dd373813290e26e9c0a264b993f9,"This paper proposes a method for analyzing single-cell RNA-Seq data in the context of neuronal phenotypes. The proposed method is based on factorized linear discriminant analysis (FLDA), which aims to find a linear transformation of gene expressions that varies highly with only one phenotypic factor and minimally with the others. The authors further leverage a sparsity-based regularization algorithm to select a few genes important to a specific feature or feature combination. The method is applied to a Drosophila dataset of T4/T5 neurons, focusing on their dendritic and axonal phenotypes, and the analysis confirms results obtained by conventional methods but also points to new genes related to the phenotypes and an intriguing hierarchy of these cells."
SP:28e61a4f51f9f7283397d6336ea114375ae6a004,"This paper proposes a new method to generate saliency maps to explain the behavior of an image classifier. The proposed method is based on a variational approximation of the posterior distribution over the saliency map. The posterior distribution is defined as the distance between the classifier’s predictive probability of the image and that of a perturbed image. For the prior distribution, the authors make attributions of adjacent pixels have a positive correlation. The authors show that the approximate posterior is effective in explaining the classifiers’ behavior."
SP:01acd8b88768d86bcf21b8c20a930d706c5645a7,"This paper proposes a neural debiasing method for pretrained sentence encoders to reduce the social bias in sentence embeddings via a fair filter (FairFil) network. To learn the FairFil, the authors propose a contrastive learning framework that not only minimizes the correlation between filtered embedding and bias words but also preserves rich semantic information of the original sentences. On real-world datasets, the proposed method reduces the bias degree of pretrained text encoder while continuously showing desirable performance on downstream tasks. "
SP:f2f505d3f07ca3bb2f16f6f6f5d00fee98da6531,"This paper proposes a new method to certify models under l2 perturbations. The proposed method is based on randomized smoothing, which assigns different noise levels to different samples. Specifically, the authors propose a pretrain-to-finetune framework that first pretrains a model and then adjusts the noise levels for higher performance based on the model’s outputs. The experimental results show that the proposed method can achieve better accuracy-robustness trade-off in the transductive setting."
SP:692c7b9f6d982bbc5a22e566296a97e8a530b87c,"This paper proposes a probabilistic method for unsupervised recovery of corrupted data. Given a large ensemble of degraded samples, the proposed method recovers accurate posteriors of clean values, allowing the exploration of the manifold of possible reconstructed data and hence characterising the underlying uncertainty. In this setting, direct application of classical variational methods often gives rise to collapsed densities that do not adequately explore the solution space. Instead, this paper derives a novel reduced entropy condition approximate inference method that results in rich posteriors. The proposed method is tested in a data recovery task under the common setting of missing values and noise, demonstrating superior performance to existing variational approaches."
SP:4b7d050f57507166992034e5e264cccab3cb874f,"This paper proposes a method to incorporate multi-hop context information into the self-attention mechanism in graph neural networks (GNNs) to enable long-range interactions at every layer of the GNN. To compute attention between nodes that are not directly connected, the proposed method diffuses the attention scores across the network, which increases the “receptive field” for every layer. Experiments on node classification and knowledge graph completion benchmarks show that MAGNA achieves state-of-the-art results."
SP:36310d761deb19e71c8a57de19b48f857707d48b,"This paper proposes a new test to measure a text model’s multitask accuracy. The test covers 57 tasks including elementary mathematics, US history, computer science, law, and more. To attain high accuracy on this test, models must possess extensive world knowledge and problem solving ability. While most recent models have near random-chance accuracy, the very largest GPT-3 model improves over random chance by almost 20 percentage points on average. However, the best models still need substantial improvements before they can reach expert-level accuracy."
SP:7d7d34ba6e9fb36f2658cf4be44b137cdd73d34c,"This paper proposes GRAPPA, a pre-training approach for table semantic parsing that learns a compositional inductive bias in the joint representations of textual and tabular data. The authors construct synthetic question-SQL pairs over high-quality tables via a synchronous context-free grammar (SCFG) and pre-train the model on the synthetic data to inject important structural properties commonly found in table semantic parsers into the pre-trained language model. To maintain the model’s ability to represent real-world data, the authors also include masked language modeling (MLM) on several existing table-and-language datasets to regularize the pretraining process. The proposed method achieves new state-of-the-art results on four popular fully supervised and weakly supervised tasks."
SP:ebbb25902804b4f9f4985311c5debe2ef0ad7c7c,"This paper studies the MTL LS-SVM MTL method in the limit of large (p,n) and numerous (n,p) data. The authors show that the performance of MTL MTL converges to a deterministic limit involving simple (small-dimensional) statistics of the data. They also provide a simple method to correct the bias of the standard MTL LSTM algorithm."
SP:2be727b1333122fef3abfd2f7c576d2fc467893f,"This paper proposes a group equivariant conditional neural process (EquivCNP) which is a permutation-invariant and group-equivariant function with permutation invariance in a data set as in conventional conditional neural processes (CNPs), and it also has transformation equivariance in data space. The authors give a decomposition theorem for permutation and group equivariances, which leads them to construct EquivCNPs with an infinite-dimensional latent space to handle group symmetries. They show that the proposed method achieves comparable performance to conventional CNPs in a 1D regression task, and it is capable of zero-shot generalization for an image completion task by selecting an appropriate Lie group Equivariance."
SP:a54b0358a0a2900f76a2da7a0a99348805c8d66a,"This paper proposes a method for offline text generation based on off-policy learning from expert demonstrations. The proposed method is based on importance weighting, where the goal is to maximize quality given model-generated history. The authors propose to upweight confident tokens and downweight unconfident ones in the reference during training, avoiding optimization issues faced by prior offline RL approaches that rely on online data collection. The method is evaluated on summarization, question generation, and machine translation tasks."
SP:e77eca51db362909681965092186af2e502aaedc,"-based local supervised learning, where a network is split into gradient-isolated modules and trained with local supervision. This paper proposes an information propagation (InfoPro) loss, which encourages local modules to preserve as much useful information as possible, while progressively discard task-irrelevant information. Extensive empirical results validate that InfoPro is capable of achieving competitive performance with less than 40% memory footprint compared to E2E training, while allowing using higher-resolution or larger batch sizes under the same GPU memory constraint."
SP:21e44dddd20db1768de0dab869f8b0d3d5a598b7,"This paper proposes a novel method to improve the expressive power of graph neural networks (GNNs). The proposed method is based on the idea of diverse sampling, i.e., the representation of target node is finally obtained via aggregating the representations of diverse neighborhoods obtained using any GNN model. Experiments show that the proposed method can improve the performance of base GNN models."
SP:e9a8956f067a55b794508ac69f93b4b0290a664c,"This paper investigates the robustness of video models to bit-level network and file corruptions, which can arise from network transmission failures or hardware errors, and explore defenses against such corruptions. They find that corruption-agnostic defenses such as adversarial training have limited effectiveness, performing up to 11.3 accuracy points worse than a no-defense baseline. In response, they propose a corruption-aware baseline that exploits knowledge of bit- level corruptions to enforce model invariance."
SP:35f77a7dcce3f6e09db0db9d22207a6da1fdbe5c,"This paper proposes a new representation learning method for time-varying graphs that uses skip-gram embeddings to disentangle the role of nodes and time in the representation learning process. The proposed method is based on the skipgram embedding with negative sampling (HOSGNS) method. The method is evaluated on time-resolved face-to-face proximity data, where it is shown that the learned representations outperform state-of-the-art methods when used to solve downstream tasks such as network reconstruction and predicting the outcomes of a SIR spreading process."
SP:bac0a2d3478dd277cb1ceafedd7fff64e107a222,"This paper proposes a new skip-tree training task for self-supervised language modeling of mathematical formulas. The proposed task consists of three tasks: inferring types, inferring missing assumptions, and completing equalities. The paper shows that models trained on the proposed task show surprisingly strong mathematical reasoning abilities, and outperform models training on standard skip sequence tasks. "
SP:808f6d3af382876f5518e8e3a14ea73cc59c0a2b,"This paper studies the problem of imbalanced gradients, where the gradient of one term of the margin loss dominates and pushes the attack towards to a sub-optimal direction. To address this problem, the authors propose a Margin Decomposition (MD) attack that decomposes a margin loss into individual terms and then explores the attackability of these terms separately via a two-stage process. The authors conduct extensive evaluations on 12 state-of-the-art defense models and find that 6 of them suffer from imbalance gradients and their PGD robustness drops by more than 9% against our MD attacks."
SP:2180e15ad0bbecc98e043b41f6525d2a8061d304,"This paper proposes an incremental graph-to-sequence deep learning system to generate axiomatic proofs of equivalence between program pairs. The system is based on the OpenNMT-py framework. The paper shows that the proposed system achieves 93% average true positive coverage on 10,000 test cases while ensuring zero false positives by design. "
SP:19e32803278a7ad2be5343187468cd2e26335bc8,"This paper proposes a method to reduce the parameters of multimodal Transformers in the context of audio-visual video representation learning. The authors decompose the Transformer into modality-specific and modality shared parts so that the model learns the dynamics of each modality both individually and together, and propose a novel parameter sharing scheme based on low-rank approximation. They also propose a negative sampling approach based on an instance similarity measured on the CNN embedding space that our model learns together with the Transformers. They show that their approach reduces parameters of the Transformers up to 97% allowing us to train our model end-to-end from scratch."
SP:a5c22c090413ef4448db8e7f5b39332b3db6c73f,"This paper proposes an online contextualized few-shot learning (OC-FSL) setting to mimic naturalistic human learning. Three datasets are designed to mimic the visual experience of an agent wandering within a world. The proposed dataset RoamingOmniglot is based on handwritten characters from Omniglot, RoamingImageNet and RoamingRooms are based on images from ImageNet. The paper also proposes a new dataset based on indoor imagery that mimics the visual experiences of a wandering agent. "
SP:9c87f7778b8ee5d3e65fb1204b8067f12aac94e1,"This paper studies the problem of online learning of graph neural networks (GNNs) in the context of distribution shift and changing training data, when temporal graphs evolve over time. The authors systematically analyze these issues by incrementally training and evaluating GNNs in a sliding window over temporal graphs. They experiment with three representative GNN architectures and two scalable GNN techniques, on three new datasets. The results show that no more than 50% of the GNN’s receptive field is necessary to retain at least 95% accuracy compared to training over a full graph. In most cases, i.e., 14 out of 18 experiments, a temporal window of size 1 is sufficient to retain 90%."
SP:dce0bbc266a9ac746f0db5099836fa57a3055f4a,"This paper proposes a method to regularize the representation space of deep RL agents by comparing representation similarity across different pairs of states. The proposed method, called cross-state self-constraint (CSSC), is based on the implicit feedback between state and action from the agent’s experience. The method is tested on the ProcGen benchmark and shows significant improvement on generalization performance."
SP:3dda3d53fdc4bd8045db22cac740322e31e67bcf,"This paper studies the problem of adversarial attacks on GNNs in a restricted near-black-box setting, where a small set of nodes are perturbed with no access to model parameters and model predictions. The authors draw a connection between this type of attacks and an influence maximization problem on the graph, which allows them to propose a group of attack strategies. The proposed strategies significantly degrade the performance of three popular GNN models and outperform baseline adversarial attack strategies in the experiments."
SP:fca0583b19bd08f59fdb0e46f86a4b27495dd0df,"This paper studies the problem of learning causal structures in directed acyclic graphs (DAGs). The authors propose to exploit a low rank assumption regarding the (weighted) adjacency matrix of a DAG causal model to mitigate the sparseness of DAGs. They show how to adapt existing methods for causal structure learning to take advantage of this assumption and establish several useful results relating interpretable graphical conditions to the low-rank assumption. They also provide empirical evidence for the utility of their low rank adaptations, especially on relatively large and dense graphs. "
SP:f2c8172adcb82ed1c0e047ffed65412f3f1c1ac7,"This paper proposes an end-to-end method to jointly optimize automated data augmentation, neural architecture search, and hyper-parameter optimization in the AutoML pipeline. The proposed method, DiffAutoML, is based on a differentiable joint optimization solution, which allows to co-optimize the neural architectures, training hyper parameters, and training policies in an end to end fashion without the need of model retraining. Experiments show that the proposed method achieves state-of-the-art results on ImageNet compared with other end- to-end AutoML algorithms. "
SP:1ab30867e0bd8b6b65fad602cd80bada70b3f1ec,"This paper extends the Ensemble Distribution Distillation (EnD) framework to regression tasks by considering the Normal-Wishart distribution. The authors derive all measures of uncertainty, the reverse KL-divergence training objective, and the ensemble distribution distillation objective in closed form. Regression Prior Networks are then evaluated on synthetic data, selected UCI datasets and the NYUv2 and KITTI monocular depth estimation tasks, where they are shown to yield comparable or better performance to single-model and ensemble approaches."
SP:fe2aa4706defcac74e529d0cc3e1622d77451eca,This paper proposes a Bayesian online meta-learning framework to tackle the catastrophic forgetting and the sequential few-shot tasks problems. The framework incorporates MAML into a Bayes online learning algorithm with Laplace approximation or variational inference. The experimental evaluations demonstrate that the proposed framework can effectively prevent catastrophic forgetting.
SP:89d2765946e70455105a608d998c3b900969cb8d,This paper proposes a new graph neural network (GNN) architecture that can count subgraphs of size k. The proposed architecture is based on the local neighborhood pooling (LRP) method. The authors show that the proposed architecture can count k subgraph with a lower computational complexity than the existing k-GNN and LRP-based GNNs. They also provide an information-theoretic lower bound on the complexity of a general class of GNN with k-subgraphs.
SP:c43f5deb340555d78599a3496318514a826b1aae,"This paper studies the behavior of two-person zero-sum games in normal-form games, where the agents might have the motivation to coordinate and the number of agents can be arbitrary. In particular, the authors show that if agents employ one of the most well-known learning algorithms, Multiplicative Weights Update (MWU), then Lyapunov chaos occurs everywhere in the cumulative payoff space. The authors extend the volume-expansion argument of Cheung & Piliouras via the canonical game decomposition into zero-Sum and coordination components. The two components induce opposite volume-changing behaviors, so the overall behavior can be analyzed by comparing the strengths of the components against each other. "
SP:0cf756ba6b172f9b29e84945c093dfd89ae62803,"This paper proposes a new algorithm for adaptive deep learning algorithms based on the marginal regret bound minimization (MRLM) algorithm. The authors show that MRLM can converge faster than AMSGrad, Radam, and other existing adaptive algorithms in the long-term. In addition, the authors also show that the proposed algorithm can also converge faster in the short term.   "
SP:b6b594fc555bd12b33f156970f0665e2bf793484,"This paper proposes expected quadratic utility maximization (EQUM) as a new framework for policy gradient style reinforcement learning (RL) algorithms with mean-variance control. The proposed EQUM has several interpretations, such as reward-constrained variance minimization and regularization, as well as agent utility maximisation. In addition, the computation of the EQUM is easier than that of existing methods, which require double sampling. Empirical results demonstrate the effectiveness of the proposed algorithm in benchmark setting of RL and financial data."
SP:bf9d66f713b6502d274143c6273b2d071a0c045e,"This paper proposes a method for multi-task learning with auxiliary tasks based on implicit differentiation. The main idea is to learn a network that combines all losses into a single coherent objective function. This network can learn nonlinear interactions between tasks. Then, when no useful auxiliary task is known, the proposed method can learn a novel auxiliary task. The proposed method is evaluated on image segmentation and learning with attributes in the low-data regime."
SP:3070fd64f8eb4d7ece6521cb975fd1fe64d6329f,This paper proposes a new measure of uncertainty for neural machine translation based on long sequences of discrete random variables to detect out-of-distribution sentences. The proposed measure is based on dropout approximate inference on a Transformer model trained with dropout approximations. The method is applied to the task of German-English translation using WMT13 and Europarl. The results show that the proposed measure can detect when Dutch source sentences are given to the model instead of German.
SP:d5a1d9596b8329312533b3a0047c815f8e71a201,"This paper studies the problem of pruning neural networks at initialization. The authors compare SNIP, GraSP, and magnitude pruning methods to random pruning and randomly shuffling the weights within each layer or sampling new initial values preserves or improves accuracy. They show that random shuffling of weights in each layer can be replaced by a per-layer choice of the fraction of weights to prune. This suggests broader challenges with the underlying pruning heuristics, the desire to pruning at initialization, or both."
SP:1f6b266021da24bbf02b5a47f2b5eb23b4912166,"This paper proposes a new federated learning protocol that can defend against both a semi-honest server and Byzantine malicious clients. The proposed method uses a robust mean estimator called FilterL2, which is the first FL protocol providing dimension-free estimation error against Byzantine malicious client. The main challenge of the proposed method is the incompatibility between the server and secure aggregation. To address this, the clients are split into multiple shards, the local updates from the same shard are securely aggregated at the centralized server, and the robust estimator is run on the aggregated local update from different shards. "
SP:9f89ff90b203d86a569e3d5148546942f5bf2093,"This paper proposes a new benchmark suite of offline black-box model-based optimization (MBO) problems, where the goal is to find a design input that maximizes an unknown objective function using only previously collected data, for example from a set of previously conducted experiments. The benchmark suite includes diverse and realistic tasks derived from real-world problems in biology, material science, and robotics that present distinct challenges for offline MBO methods. The authors also present reference implementations of several existing offline Mbo methods and baselines. "
SP:073958946c266bf760d1ad66bd39bc28a24c8521,"This paper proposes a self-supervised ELBO formulation for multi-modal data. The proposed method, MoPoE-VAE, models the joint posterior approximation as a Mixture of Product-of-Experts (MVAE) and MMVAE (Mixture of Experts) as special cases. Experiments show that the proposed method is able to achieve better performance compared to the existing methods on a variety of tasks."
SP:98004554447b82b3d2eb9724ec551250eec7a595,"This paper proposes Prior-guided Bayesian Optimization (PrBO), a Bayesian optimization method for black-box functions that leverages the prior knowledge of the user to select which parts of the input space will yield the best performance, rather than BO’s standard priors over functions (which are much less intuitive for users). PrBO combines these priors with BO's standard probabilistic model to form a pseudo-posterior used to select the next points to evaluate next. The authors show that PrBO is around 12x faster than state-of-the-art methods without user priors and 10,000X faster than random search on a common suite of benchmarks. "
SP:e0e9cd5f39a60b5db1c4363ffdc2c593300ef43a,"This paper proposes to use binary neural networks to reduce the computational cost of deep generative models. To do so, the authors propose a new class of binary weight normalization techniques that can reduce the size and complexity of the models. The proposed method is evaluated on two state-of-the-art models, ResNet VAE and Flow++, and shows that the proposed method can achieve better performance and speed up the training process."
SP:7e9a83552c0ff001d3090a5a7162013b5dc6f47f,"This paper proposes a paradigm shift from perturbation-based adversarial robustness to model-based robust deep learning to address the out-of-distribution shift in the data distribution in a general context. The main idea is to obtain models of natural variation, which vary data over a range of natural conditions, and then use these models to improve the robustness of DL with respect to natural variation. The proposed method is evaluated on a variety of natural data distribution shifts in 12 different datasets. "
SP:011dab90d225550e77235cbec1615e583ae3297e,This paper studies the optimization of two-layer and three-layer CNNs with ReLU activations. The main contributions are:  1. The authors show that the global optimisation of a single-layer circular CNN with a single ReLU layer is equivalent to an `1 norm regularized convex program that encourages sparsity in the spectral domain.  2. They extend this result to multi-layer networks with two ReLU layers.  3. They show that pooling methods are convex regularizers.  
SP:98760a3b1a5058a485a5a1ed1b778c1d4fb2ff22,"This paper presents an approach to interpretable learning from demonstration using a probabilistic generative model, where the latent variables are explicitly aligned with high-level notions and concepts that are manifested in a set of demonstrations. The proposed method is evaluated in the context of two table-top robot manipulation tasks performed by a PR2 robot – that of dabbing liquids with a sponge (forcefully pressing a sponge and moving it along a surface) and pouring between different containers. The results show that such alignment is best achieved through the use of labels from the end user, in an appropriately restricted vocabulary, in contrast to the conventional approach of the designer picking a prior over the latent variable."
SP:e171d8c4eadf73852734c0fb8a74a69d80969e4b,"This paper proposes to use Variational Information Bottleneck (VIB) to suppress irrelevant features when fine-tuning on low-resource target tasks, and show that the proposed method successfully reduces overfitting. Moreover, the proposed VIB model finds sentence representations that are more robust to biases in natural language inference datasets, and thereby obtains better generalization to out-of-domain datasets. Empirical results show that VIB significantly improves transfer learning in low resource scenarios, surpassing prior work."
SP:a1ab99bee74a0a1310537beced0d89dc1e5ad7be,"This paper proposes a method to recover 3D shapes from a single 2D image using a pre-trained 2D GAN trained on RGB images only. The method is based on an iterative strategy that explores and exploits diverse viewpoint and lighting variations in the GAN image manifold. The results show that the proposed method recovers 3D shape with high precision for human faces, cars, buildings, etc. without requiring 2D keypoints or 3D annotations."
SP:eac0679dfee4dae78c1e515f8b325c9523b795dc," is a long-tail classification method that places more emphasis on the tail data. This paper proposes a new long-tailed classifier called RIDE, which reduces the model variance with multiple experts, reduces model bias with a distribution-aware diversity loss, and reduces the computational cost with a dynamic expert routing module. RIDE outperforms the state-of-the-art by 5% to 7% on CIFAR100-LT, ImageNet-LT and iNaturalist 2018 benchmarks."
SP:f4d0e821de6830722a3458fd40d8d6793a107827,"This paper studies the effect of different types of pruning criteria (layer-wise, layer-wise pruning, global pruning) on the importance scores of CNNs. The authors find that there are two blind spots: (1) Similarity: There are some strong similarities among several primary pruning metrics that are widely cited and compared. (2) Applicability: The filters’ importance scores measured by some criteria are too close to distinguish the network redundancy well. Based on these observations, the authors propose and verify an assumption that the well-trained convolutional filters in each layer approximately follow a Gaussian-alike distribution."
SP:eadb827653b2e1b608bb923d5549089cb2482d90,"This paper proposes GraphCodeBERT, a pre-trained model for programming language that considers the inherent structure of code. The paper proposes to use data flow in the pre-training stage, which is a semantic-level structure that encodes the relation of “wherethe-value-comes-from” between variables. The proposed method is based on Transformer. Two new structure-aware pretraining tasks are introduced for learning representation from source code and data flow. The experimental results show that the proposed method can achieve state-of-the-art performance on four downstream tasks."
SP:2c7a128e19cd2d39b0ca1b946b01604c3f7cead5,"This paper proposes a method to improve the accuracy of regression models that are trained using a skewed dataset. The method uses a semi-supervised learning framework with an adversarial network to force the distribution of the regression output to resemble the assumed true distribution. The proposed method is evaluated on four real-world datasets (pLogP, Diamond, House, Elevators) and shows that the proposed method can reduce the root mean squared error by up to 75 percent compared to regression models without adjusting the distribution."
SP:fee1e40275fa743aa6ad011ae742b3ea3fd137df,"This paper studies the problem of compositional generalization. The authors argue that the extraction ability does not transfer naturally, because the extraction network suffers from the divergence of distributions. To address this problem, the authors propose to use an auxiliary reconstruction network with regularized hidden representations as input, and optimize the representations during inference. The proposed approach significantly improves accuracy, showing more than a 20% absolute increase in various experiments compared with baselines."
SP:ffab573a977c819e86601de74690c29a39c264cd,"This paper proposes a poisoning method for deep policy-based deep RL agents. The authors propose a poisoning algorithm that works for policy gradient learners without any prior knowledge of the MDP. The proposed method, called Vulnerability-Aware Adversarial Critic Poison (VA2C-P), works for on-policy deep RL agent, closing the gap that no poisoning method exists for policy based RL agents, and uses a novel metric, stability radius in RL, that measures the vulnerability of RL algorithms. Experiments show that the proposed method successfully prevents agents from learning a good policy or teaches the agents to converge to a target policy, with a limited attacking budget."
SP:06ebd437ff2d1b5068f7a651716d3c1a60c2a001,"This paper proposes Dynamic Tensor Rematerialization (DTR), a greedy online algorithm for checkpointing that is extensible and general, is parameterized by eviction policy, and supports dynamic models. The authors prove that DTR can train an N-layer linear feedforward network on an $\Omega(\sqrt{N})$ memory budget with only O(N) tensor operations. DTR closely matches the performance of optimal static checkpointing in simulated experiments. "
SP:20efc610911443724b56f57f857060d0e0302243,"This paper proposes a new task to predict whether each token in the output sequence is hallucinated conditioned on the source input, and collects new manually annotated evaluation sets for this task. The authors also introduce a novel method for learning to model hallucination detection, based on pretrained language models fine tuned on synthetic data that includes automatically inserted hallucinations. Experiments on machine translation and abstract text summarization demonstrate the effectiveness of the proposed approach."
SP:3d0d026888cf87073df5bd74edd986f15351ff5a,"This paper proposes a method to find a distinct architecture for each class in conditional generative adversarial networks (cGANs). The search space contains regular and class-modulated convolutions, where the latter is designed to introduce class-specific information while avoiding the reduction of training data. The search algorithm follows a weight-sharing pipeline with mixed-architecture optimization so that the search cost does not grow with the number of classes. To learn the sampling policy, a Markov decision process is embedded into the search algorithm and a moving average is applied for better stability."
SP:8cdf6e8af07daaec6680c2bed6c1787a53580584,"This paper proposes a method for estimating the average causal effect from observational data based on unconfoundedness. The proposed method is based on the idea of orthogonality constraint, which is a regularization term to ensure that the outcomes are orthogonal to the treatment assignment. Theoretical guarantees are provided to show that the proposed method yields an asymptotically normal estimator of the causal effect. The method is evaluated on a variety of benchmark datasets for causal inference, and it is shown to outperform existing methods."
SP:77ec2512837df5c0a94000602dc2ef5c03fe41dd,"This paper investigates the role and expressive power of affine parameters in BatchNorm, a popular feature normalization technique for deep learning. Specifically, the authors investigate the performance achieved when training only these parameters and freezing all other weights at random initializations. They find that the performance of the BN is significantly higher than when training an equivalent number of randomly chosen parameters elsewhere in the network. They also show that the expressive power results from their particular position and bias."
SP:6683ceea773ff6d7fb613e503c583bb2979c7e89,"This paper proposes a test-time adaptation method based on test entropy minimization (tent1). Tent is based on the idea that test entropy is a measure of the confidence of the model, which is measured by the entropy of its predictions. Tent estimates normalization statistics and optimizes channel-wise affine transformations to update online on each batch. Tent reduces generalization error for image classification on corrupted ImageNet and CIFAR-10/100 and reaches a new state-of-the-art error on ImageNet-C. Tent handles source-free domain adaptation on digit recognition from SVHN to MNIST/MNIST-M/USPS, on semantic segmentation from GTA to Cityscapes, and on the VisDA-C benchmark. Tent is capable of online and source free adaptation for digit classification and semantic segmentations and can even rival methods that use source data."
SP:ed544ee661580592063aa17aee8924cc99919130,"This paper proposes to estimate uncertainty in RNNs via stochastic discrete state transitions over recurrent timesteps. The uncertainty of the model can be quantified by running a prediction several times, each time sampling from the recurrent state transition distribution, leading to potentially different results if the model is uncertain. The proposed method can be used to learn deterministic and probabilistic automata from data, learn well-calibrated models on real-world classification tasks, improve the performance of out-of-distribution detection, and control the explorationexploitation trade-off in reinforcement learning."
SP:a38c523196f68a90b5db45671f9dbd87981a024c,"This paper proposes a new method for privacy-preserving deep learning. The proposed method injects Gaussian noise into each residual mapping of ResNets. Theoretically, the authors prove that residual perturbation guarantees differential privacy (DP) and reduces the generalization gap for DL. Empirical results show that the proposed method outperforms DPSGD in both membership privacy protection and maintaining the DL models’ utility."
SP:9cbe32c1317889d6a3ec1b0798112d9b82cc7f67,"This paper proposes a new extension to BERT, called Length-Adaptive Transformer, to reduce the computational cost of BERT. To do so, the authors introduce a structural variant of dropout called LengthDrop, which stochastically determines the length of a sequence at each layer. They then use a multi-objective evolutionary search to find a length configuration that maximizes the accuracy and minimizes the computational complexity under any given computational budget. Finally, they extend the applicability of PoWER-BERT beyond sequence-level classification into token-based question-answering."
SP:e5b4098ea22a5da2b9659219dc24f885c493a011,"This paper proposes to improve the expressiveness of graph neural networks (GNNs) by exploring powerful aggregation-based GNNs. The authors reformulate aggregation with the corresponding aggregation coefficient matrix, and then systematically analyze the requirements of aggregation coefficients for building more powerful aggregators and even injective aggregators. Based on the theoretical analysis, the authors develop two GNN layers, ExpandingConv and CombConv, which achieve state-of-the-art performance on a variety of graph tasks."
SP:4dd6fb8e5a356af270d3b296ce3d50ae5753513c,This paper proposes a method for measuring disentanglement in a generative model by measuring the topological similarity of conditional submanifolds in the learned representation. The method is applied to both unsupervised and supervised variants of the generative models. Empirical results show that the proposed method performs similarly to existing methods. 
SP:ef1ee7b77e1c2fb3d76db27049a3bce42760d14e,"This paper proposes a method to make training data unlearnable for deep learning models. The proposed method is based on the idea of error-minimizing noise, which aims to reduce the error of one or more of the training example(s) close to zero to trick the model into believing there is “nothing” to learn from these examples(s). The noise is restricted to be imperceptible to human eyes, and thus does not affect normal data utility. The authors empirically verify the effectiveness of the proposed method in both sample-wise and class-wise forms and demonstrate its flexibility under extensive experimental settings and practicability in a case study of face recognition."
SP:4e8a835174f20df36d3d8d27fbcbbf2c68490032,"This paper proposes Nondeterministic MuZero (NDMZ), an extension of MuZero for nondeterministic, two-player, zero-sum games of perfect information. NDMZ formalizes chance as a player in the game and incorporates the chance player into the MuZero network architecture and tree search. Experiments are conducted on Nannon, a simplified variant of backgammon."
SP:73ae9c167dac3d92788a08891b0831f3e4997140,"This paper introduces Hindsight off-policy option learning (HO2), an efficient option learning algorithm that uses temporal and action abstraction in the option framework to improve data efficiency and accelerate learning by incorporating different abstractions. The proposed method uses a dynamic programming inference procedure through time and through the policy components for every time-step to train all components’ parameters independently of the data-generating behavior policy. Experimental results show that HO2 outperforms existing option learning methods and that both action and temporal abstraction provide strong benefits, particularly in more demanding simulated robot manipulation tasks from raw pixel inputs. "
SP:f79d9722256fb6b258bc1310bf1f6fb842303a0a,"This paper studies the problem of synthesizable molecule generation in the context of reinforcement learning. The authors formulate an objective function to maximize the expected maximum reward along a trajectory, propose a novel functional form of the Bellman equation, introduce the corresponding Bellman operators, and provide a proof of convergence. The proposed method achieves state-of-the-art results on the task of synthesisable molecule generation that mimics a real-world drug discovery pipeline."
SP:bd4b1781448def4327214c78f07538d285119ef9,"This paper proposes Contextual HyperNetwork (CHN), an auxiliary model that generates parameters for extending the base model to a new feature, by utilizing both existing data as well as any observations and/or metadata associated with the new feature. At prediction time, the CHN requires only a single forward pass through a neural network, yielding a significant speed-up when compared to re-training and fine-tuning approaches. The CHN is applied to augment a partial variational autoencoder (P-VAE), a deep generative model which can impute the values of missing features in sparsely-observed data. Empirical results on recommender systems, e-learning, and healthcare tasks demonstrate the effectiveness of the proposed method."
SP:8e4677cc6071a33397347679308165c10dca2aae,"This paper proposes a Bayesian deep learning method that first trains a point estimate, and then infers a full covariance Gaussian posterior approximation over a subnetwork. This enables expressive posterior approximations that would otherwise be intractable for the full model. A subnetwork selection procedure is proposed to maximally preserve posterior uncertainty. Empirical results show that the proposed method outperforms point-estimated networks and other Bayesian methods."
SP:be361952fe9de545f68b8a060f790d54c6755998,This paper proposes a model-based approach for jointly learning embeddings for states and actions in RL. The approach is based on a model of the environment and uses a generic architecture to learn a policy. The proposed approach can be applied in both discrete and continuous domains. Experiments show that the proposed approach outperforms the baselines in several domains. 
SP:ebb6bffcc4c2129e09ef5561c19df43c42ad18c0,"This paper proposes a viewmaker network for unsupervised representation learning. The viewmaker is a generative model that generates views by generating and then adding an `p-bounded perturbation to the input, and is trained adversarially with respect to the main encoder network. The proposed method achieves comparable transfer accuracy to the well-tuned SimCLR augmentations on CIFAR-10, and significantly outperforms the baseline on speech recordings and wearable sensor data. "
SP:ef7735be9423ad53059505c170e75201ca134573,"This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. Based on this taxonomy, the authors propose an integrated OOD detection approach that uses multiple attributes corresponding to different types of outliers. The proposed method is evaluated on CIFAR10, SVHN and MNIST as in-distribution and OOD data across different DNN architectures. The effectiveness of the proposed approach is demonstrated on several benchmarks."
SP:33920ec7ffefe3c1525cd5d4d53a851210d519da,"This paper presents a hierarchical VAE that can generate samples faster and more efficiently than the PixelCNN on several image benchmarks. The authors show that VAEs can represent autoregressive models, as well as faster, better models if they exist, when made sufficiently deep. They test if insufficient depth explains why VAEs have historically outperformed VAEs in log-likelihood. They scale a VAE to greater stochastic depth than previously explored and evaluate it on CIFAR-10, ImageNet, and FFHQ. They show that these very deep VAEs achieve higher likelihoods, use fewer parameters, generate samples thousands of times faster, and are more easily applied to high-resolution images."
SP:0a4e6c8017a1294fe2424799a0048d58eaf04cb3,"This paper proposes a new method for contrastive learning based on semi-hard negatives. The proposed method is based on a family of mutual information estimators that sample negatives conditionally – in a “ring” around each positive. The authors prove that these estimators are lower-bounds of the mutual information, with higher bias but lower variance than NCE. Experiments show that the proposed method outperforms NCE on four image classification tasks. "
SP:613a0e2d8cbe703f37c182553801be7537333f64,This paper proposes a data leakage attack to recover batch data from the shared aggregated gradients in federated learning. The proposed method is named as catastrophic data leakage in Federated Learning (CAFE). CAFE can recover large-batch data with high data recovery quality. Experimental results on vertical and horizontal FL settings have validated the effectiveness of CAFE in recovering private data. 
SP:ce229295081ff04b26f33829f2c3396b90897b5d,"This paper proposes a dynamic relational inference method for multi-agent trajectories. The proposed method is based on a deep generative model that can reason about dynamic relations. The model is trained on a simulated physics system with periodic and additive dynamics. It is then used to infer coordination and competition patterns from real-world basketball trajectories, where it is shown to outperform static relational inference methods."
SP:9f4b77d39f1deca28324fb637a0a77e89976baa8,"This paper proposes an inductive collaborative filtering framework that learns a hidden relational graph among users from the rating matrix. The relational graphs enable attentive message passing from users to users in the latent space and are updated in end-to-end manner. The key advantage of the proposed model is the capability to inductively compute user-specific representations using no feature, with good scalability and superior expressiveness compared to other feature-driven inductive models. The proposed model achieves state-of-the-art performance for inductive learning on several matrix completion benchmarks."
SP:9f9e9b0e37e59267d8516ab914bd619c53fbc9ec,"This paper proposes a multi-stage approach to learn disentangled representation learning for image reconstruction. First, a pre-trained model is used to learn the disentanglement of the latent factors. Then, a deep generative model is trained to model the missing correlated latent variables, adding detail information while maintaining conditioning on the previously learned disentangling factors. The proposed method is theoretically justified by the principal of D-separation and can be realized with a variety of model classes including likelihood-based models, variational autoencoders, implicit models such as generative adversarial networks, and tractable models like normalizing flows or mixtures of Gaussians. Empirical results show that the proposed method achieves better reconstruction quality than current state-of-the-art methods with equivalent disentangle performance."
SP:e398873e29b05176e1d52dc6f86a59a4f405e6fd,This paper studies the sufficiency of representation learning objectives based on mutual information maximization (MI) in the context of reinforcement learning. The paper provides a theoretical analysis of two popular MI-based representation learning methods and shows that they fail to learn representations that are sufficient for RL from a theoretical perspective. The authors also provide empirical evidence to support their theoretical findings. 
SP:881185782a9ec32fcbab14b42b78bf94edeba4b0,"This paper studies the convex semi-infinite dual of the two-layer vector-output ReLU neural network training problem. In particular, the authors show that the non-convex neural networks training problem is equivalent to a finite-dimensional convex copositive program. The authors show how neural networks implicitly attempt to solve copoitive programs via semi-nonnegative matrix factorization, and draw key insights from this formulation. They describe the first algorithms for provably finding the global minimum of the vector output neural network learning problem, which are polynomial in the number of samples for a fixed data rank, but exponential in the dimension. "
SP:8613b2fcfd076d3e28a9940bad0c490a6557c10c,"This paper proposes a method for learning disentangled, object-centric scene representations from vision and language. The method builds upon recent advances in unsupervised object segmentation, notably MONet and Slot Attention. The proposed method learns to associate the learned representations to concepts, i.e., words for object categories, properties, and spatial relationships, from language input. Experiments show that the integration of LORL consistently improves the performance of MONet on two datasets."
SP:5e73b99c9942dd85bf70a65ad3e3c6a45d69b66b,"This paper proposes EM-RBR (embedding and rule-based reasoning), a link prediction model for knowledge graph completion. The proposed model is a combination of embedding and reasoning based on rules. In particular, the embedding is based on rule embedding, where the rules are used to embed the relations in the knowledge graph. The reasoning is done by using the rules to find the most reasonable explanation for a given triplet to obtain higher prediction accuracy. Empirical results on FB15k, WN18, and a new dataset show the effectiveness of the proposed model. "
SP:19b74093512c4e5f8c504e96c590ac1eb7e2ce9b,"This paper proposes an architecture that combines declarative and procedural knowledge in the form of object files and schemata. The object files are active modules that maintain the state of a single object and invoke external external knowledge sources that prescribe state updates. The proposed model is a drop-in replacement for LSTMs, GRUs, and GRUs and achieves better generalization on environments that have multiple object tokens of the same type."
SP:42a3c0453ab136537b5944a577d63412f3c22560,"This paper proposes a new video-grounded language task for visual question answering (VQA) and video-based dialogues. The proposed method, VilNMN, first decomposes all language components to explicitly resolve any entity references and detect corresponding action-based inputs from the question. The detected entities and actions are used as parameters to instantiate neural module networks and extract visual cues from the video. Experiments show that the proposed method can achieve promising performance on the video QA and video dialogues tasks."
SP:126ce41b7f44975e5962f8bcb43f61bf2ed315c4,"This paper proposes two modifications to the Policy-Space Response Oracles (PSRO) framework, which is a general framework for learning policies in multiagent systems by interleaving empirical game analysis with deep reinforcement learning (Deep RL). The proposed modifications modify how PSRO adds new policies to the empirical game, based on learned responses to a single opponent policy. The first modification transfers knowledge from previous iterations of Deep RL, requiring training only against the opponent’s newest policy, and the second modification constructs a pure-strategy opponent by mixing existing strategy's action-value estimates, instead of their policies. The experiments show that the proposed modifications reduce the amount of simulation during training required by PSRO, while producing equivalent or better solutions to the game."
SP:33e0b6099b32a6a2c0f2c7a8caa57ba2935d8b00,"This paper presents a non-attentive version of Tacotron 2, which replaces the attention mechanism with an explicit duration predictor. The duration predictor enables both utterance-wide and per-phoneme control of duration at inference time. The proposed method uses a fine-grained variational auto-encoder to train the duration predictor in a semi-supervised or unsupervised manner, with results almost as good as supervised training."
SP:ab9532306d294f85db84b9419ce826f046a7d95e,"This paper proposes a method for bird’s eye view layout estimation from a pair of stereo images. The proposed method first generates a disparity feature volume using the features of the stereo images and then project it to the bird's eye view coordinates. Then, it applies inverse perspective mapping (IPM) to map the input images and their features to the birds eye view. Finally, it uses the projected feature volume to estimate the BEV semantic map. The method is evaluated on KITTI and CARLA datasets."
SP:3a151e18a5e623e9bf6e39a6065bfba1d5156fc1,"-based GNNs suffer from vanishing gradients, over-parameterization, and over-smoothing. This paper proposes a novel relation-aware GNN architecture based on the Graph Attention Network that uses gated skip connections to improve long-range modeling between nodes and uses a more scalable vector-based approach for parameterizing relations. The proposed method significantly outperforms several commonly used GNN variants when used in deeper configurations and stays competitive to existing architectures in a shallow setup."
SP:f9906d99f6ae5e32dda548bdccce9ae92d25b205,"This paper proposes a method to identify minimal regions in an input that are most relevant for a neural network’s prediction. The method uses gradient information (based on Integrated Gradients) to focus on a subset of neurons in the first layer, which allows the method to scale to large networks. After solving for the minimal masks, the method scores the mask regions to generate a relative ordering of the features within the mask. This produces a saliency map which explains “where a model is looking” when making a prediction."
SP:fc96fe4d0eeb0723bb7e4c9120c77981fc14731c,"This paper proposes a new method for 3D pose estimation based on deep neural networks and 3D generative representations of objects. The proposed method, called NeMo, learns a generative model of neural feature activations at each vertex on a dense 3D mesh and uses differentiable rendering to estimate the 3D object pose by minimizing the reconstruction error between NeMo and the feature representation of the target image. To avoid local optima in the reconstruction loss, the authors train the feature extractor to maximize the distance between the individual feature representations on the mesh using contrastive learning. Experiments show that NeMo is more robust to partial occlusion and unseen pose compared to standard deep networks, while retaining competitive performance on regular data."
SP:bde5b5b05d4a10634bd21a90cf0d8d22e2cda22d,"This paper proposes a non-inherent feature compatible learning (NIL) method for feature-compatible learning (FCL) without inheriting old classifier and training data. NIL requires only features extracted by old model’s backbone and new training data, and makes no assumption about the overlap between old and new data. The authors propose a unified framework for FCL, and extend it to handle the case where the old model is a black-box. Experiments on ImageNet ILSVRC 2012 and Places365 show the efficacy of the proposed approach."
SP:a9aa11e7ee77d9f6957266e4ad822c7dc0f82354,"This paper studies the effect of using gradient norm as a hyper-parameter search criterion for model selection in deep neural networks. The authors propose to use an accelerated approximation (AGN) of gradient norm that only computes the loss gradient in the Fully-Connected Layer (FC Layer) of DNNs with significantly reduced computation cost (200-20,000 times faster). The empirical results show that the use of approximated gradient norm can select the models with lower generalization error, but the efficiency is still low (marginal accuracy improvement but with high computation overhead). "
SP:13359456defb953dd2d19e1f879100ce392d6be6,"This paper proposes a method to retrieve entities by generating their unique names, left to right, token-by-token in an autoregressive fashion and conditioned on the context. The proposed method is able to capture the relations between context and entity name, effectively cross-encoding both. The method is evaluated on entity disambiguation, end-to-end entity linking and document retrieval tasks."
SP:9dfb808ce4c045c45436b35ceb03bc6fe6ed9745,"This paper considers the problem of routing users through a network with unknown congestion functions over an infinite time horizon. The routing requests are supplied adversarially. For each edge e in the selected path, the algorithm incurs a cost ce = fe(x t e) + η t e, where x t e is the flow on edge e at time t, fe is the congestion function, and η e is a noise sample drawn from an unknown distribution. The algorithm observes ce and can use this observation in future routing decisions. The proposed algorithm has space complexity $O(\sqrt{E|t})$ and time complexity O(|E| log t)$. "
SP:580ac3b74951bef5d5772e4471b01a805ff3dd68,"This paper proposes PMI-Masking, a principled masking strategy based on the concept of Pointwise Mutual Information (PMI), which jointly masks a token n-gram if it exhibits high collocation over the corpus. PMI motivates, unifies, and improves upon prior more heuristic approaches that attempt to address the drawback of random uniform token masking, such as whole-word, entity/phrase, and random-span masking. Experiments show the effectiveness of the proposed method."
SP:038cdd2df643edccb16dfd72e6eb123f6a6c0839,"This paper studies the effect of partially-conditioned amortised variational posterior in variational latent variable models (LVMs) on the performance of the learned generative model. In particular, the authors show that the ELBO objective forces partially conditioned models to approximate products of smoothing posteriors instead of the true posteriors, which results in suboptimal performance. The authors also show that this suboptimality can be mitigated by improving the variational family or inference network capacity. Empirical results on three real-world data sets demonstrate the effectiveness of the proposed method."
SP:f2574c0d6cdec78389fa1301d6a10976d1756279,"This paper studies the statistical properties of distributed kernel ridge regression together with random features (DKRR-RF), and derives optimal generalization bounds under the basic setting, which can substantially relax the restriction on the number of local machines in the existing state-of-art bounds. Specifically, the authors show that the simple combination of divide-and-conquer technique and random features can achieve the same statistical accuracy as the exact KRR in expectation requiring only O(|D|) memory and O(\sqrt{D}$) time. Then, the generalization bound in probability is derived to capture the learning performance for a single trail. Finally, an effective communication strategy is proposed to further improve the performance of DK RR-RF, and validate the theoretical bounds via numerical experiments."
SP:129872706a12d89f0886c2ad0fd4083d0632343c,This paper proposes a new RandomNAS-based approach called EPS (Evolving the Proxy Search Space) to address the problem of finding a proxy search space (PS) that is only a small subset of the global search space while keeping a good correlation for the top-performing architectures. The proposed method is evaluated on NASBench-201 and DARTS sub-search spaces for tasks such as image classification and NLP. The experiments show that the proposed method can achieve near-optimal NAS performance and surpass all existing state-of-the-art.
SP:27701f374d0b7e8b269d9133d6c3a10bca03b548,"This paper proposes PERIL, a method to combine imitation learning with meta-RL to enable an agent to quickly adapt to new tasks at test time. The proposed method is based on Probabilistic Embeddings for hybrid meta-Reinforcement and Imitation Learning (PERIL), which is a hybrid of imitation learning and meta reinforcement learning. The authors propose to use an auxiliary loss to train the embedding function to form a stronger relationship between the latent space and the true underlying state which defines the task. The experiments show that PERIL outperforms other Meta-RL and Meta-IL baselines and is capable of zero-shot learning."
SP:118758f563fa6e9e46d52a6f250005c06cf2f19f,"This paper studies the problem of learning over-parameterized convolutional neural networks (CNNs) with orthogonal patches in an image classification task. The authors propose a novel phenomenon of SGD in this setting, where the dot-product between the learned pattern detectors and their detected patterns are governed by the pattern statistics in the training set. They call this phenomenon Pattern Statistics Inductive Bias (PSI) and empirically verify it in a large number of instances. They prove that if a learning algorithm satisfies PSI then its sample complexity is O(d log(d)) where d is the filter dimension. In contrast, they show a VC dimension lower bound which is exponential in d. "
SP:a051b615da3a99562d2cd2dfbec5cd78af98d9b4,"This paper proposes a method to learn a representation of documents that reveals their underlying topic posterior information to linear models. The method is based on contrastive learning, which is an approach to representation learning that utilizes naturally occurring similar and dissimilar pairs of data points to find useful embeddings of data. The proposed method is applied to semi-supervised classification tasks with very few training examples. The authors show empirically that the proposed method can perform well in classification tasks. "
SP:8d011d4a77ced1f8cd849181d5293420f161ffd3,"This paper proposes a contrastive framework for multimodal multi-modal learning for generative models. The main idea is to train the model not just by the commonality between modalities, but also by the distinction between “related” and “unrelated’ data. The proposed method is evaluated on a variety of datasets for VAE and VAE-VAE-GAN models."
SP:3a0d3f1d63cd57b0613c40176e694435ed3eee50,"This paper proposes an energy-based prior to improve the generative performance of VAEs. The proposed prior is based on the product of a base prior distribution and a reweighting factor, which is designed to bring the base closer to the aggregate posterior. The reweight factor is trained by noise contrastive estimation and generalizes to hierarchical VAEs with many latent variable groups. Experiments on MNIST, CIFAR-10, CelebA 64, and CelebA HQ 256 datasets show that the proposed method improves the performance of state-of-the-art VAEs by a large margin."
SP:86b813ac0f5211a7c45884451f59f3ebaeeb4b83,"This paper studies the problem of regularized inverse reinforcement learning (IRL) with strongly convex regularizers to the learner's policy in order to avoid the expert's behavior being rationalized by arbitrary constant rewards, also known as degenerate solutions. The authors propose tractable solutions, and practical methods to obtain them, for regularized IRL. They show theoretical backing for their proposed IRL method’s applicability to both discrete and continuous controls, empirically validating their performance on a variety of tasks. "
SP:6f4a520cdc9901c2c87a7e887ce2535ad0b36f69,"This paper proposes conditional language-specific routing (CLSR) for multilingual neural machine translation (MNMT). CLSR employs hard binary gates conditioned on token representations to dynamically select LS or shared paths. By manipulating these gates, it can schedule LS capacity across sub-layers in MNMT subject to the guidance of translation signals and budget constraints. CLSR can easily scale up to massively multilingual settings. Experiments with Transformer on OPUS-100 and WMT datasets show that: 1) MNMT is sensitive to both the amount and the position of LS modeling: distributing 10%-30% LS computation to the top and/or bottom encoder/decoder layers delivers the best performance; and 2) one-to-many translation benefits more from CLSR compared to many to one translation."
SP:1e932b21e9557b1bbc1950c4e1701f5a3ecf50df,"This paper proposes a Wasserstein distributional normalization (WDN) algorithm to handle noisy labels for accurate classification. In this paper, the authors split the data into uncertain and certain samples based on small loss criteria and enhance this relation to exploit useful information, even from uncertain samples. To this end, they impose geometric constraints on the uncertain samples by normalizing them into the wasserstein ball centered on certain samples. Experimental results demonstrate that the proposed WDN algorithm outperforms other state-of-the-art methods on the Clothing1M and CIFAR-10/100 datasets."
SP:e0029422e28c250dfb8c62c29a15b375030069e8,"This paper proposes a method for quantifying the uncertainty of deep neural networks. The method is based on Platt scaling, which is an existing method that quantifies the network’s probability estimates, but does not provide a formal finite-sample coverage guarantee. The authors propose to regularize the small scores of unlikely classes by regularizing the small score after Platt scale. The proposed method is evaluated on Imagenet-V2 with ResNet-152 and other classifiers and outperforms existing approaches. "
SP:bf93641cbeaaa147ad0307de694e20adc23c290a,"This paper proposes a method to compute Wasserstein-2 barycenters, which is a geometric notion of the weighted average of probability measures based on optimal transport. The proposed method uses input convex neural networks and cycle-consistency regularization to avoid introducing bias. The authors provide theoretical analysis on error bounds and empirical evidence of the effectiveness of the proposed approach in low-dimensional qualitative scenarios and quantitative experiments."
SP:39aae6a094f7141bee6d4fa78be03fd20cf12b13,"This paper studies the multiple manifold problem, a binary classification task where a deep fully-connected neural network is trained to separate two low-dimensional submanifolds of the unit sphere. The authors prove that when the network depth L is large relative to certain geometric and statistical properties of the data, the network width n grows as a sufficiently large polynomial in L, and the number of i.i.d. samples from the manifolds is polynomially in L. The analysis demonstrates concrete benefits of depth and width in the context of a practically-motivated model problem: the depth acts as a fitting resource, with larger depths corresponding to smoother networks that can more readily separate the class manifolds, and width acts as statistical resource, enabling concentration of the randomly-initialized network and its gradients. "
SP:c5afd0a7485aa8dc732f6fa90d81a85a8bb51b3c,"This paper proposes a simple and scalable reinforcement learning algorithm that uses standard supervised learning methods as subroutines, while also being able to leverage off-policy data. The proposed method consists of two steps: one to regress onto target values for a value function, and another to regress on weighted target actions for the policy. The method is simple and general, can accommodate continuous and discrete actions, and can be implemented in just a few lines of code on top of standard supervised-learning methods. The experimental results show that the proposed method achieves competitive performance compared to several well-established state-of-the-art RL algorithms."
SP:54da307c1f9aac020ae7e3c439653765dbd8b3fe,"This paper proposes WaveQ, a method for deep quantization of neural networks with heterogeneous bitwidths. The method is based on a sinusoidal regularization term that maps the weights to the quantization levels and the bitwidth of each layer separately. The paper shows that WaveQ can find the quantized weights as well as learn the bit width of the layers by making the period of the sinusoid regularizer a trainable parameter and aligning its minima on the quantisation levels. WaveQ is shown to be able to find the weights and bit widths for a large variety of deep networks and achieves state-of-the-art performance."
SP:84ced6627d1dc3e78c9ffc726174e76db5f77795,"This paper proposes a novel data augmentation method for neural machine translation (NMT) by randomly replacing words or mixup with their aligned alternatives in another language when training NMT models. Since aligned word pairs appear in the same position during training, it is helpful to form bilingual embeddings which are proved useful to provide a performance boost (Liu et al., 2019). Experiments on both small and large scale datasets show that the proposed method significantly outperforms the baseline models."
SP:c1890bcafac6ac8fd5a3d2ff2dd1c37b71865a5a,"This paper proposes a real-time contribution measurement method for federated learning. The proposed method defines the impact of each agent. The authors comprehensively consider the current round and the previous round to obtain the contribution rate. To verify the effectiveness of the proposed method, the work conducts pseudo-distributed training and an experiment on the Penn Treebank dataset."
SP:b766979b4d3b15a039db4e5eebd8353521aea4bb,This paper studies the problem of learning Bayesian networks where a fraction of the samples are adversarially corrupted. The authors propose a nearly-linear time algorithm for this problem with a dimension-independent error guarantee. The algorithm and analysis are considerably simpler than those in previous work. 
SP:b3d507bd8fe8876f3a4f7696bc0483d0052484c8,"This paper proposes a method for long-horizon planning in model-based reinforcement learning. The method is based on the idea of collocation-based planning and adapts it to the image-based setting by leveraging probabilistic latent variable models, resulting in an algorithm that optimizes trajectories over latent variables. The proposed method is evaluated on visual control tasks with sparse rewards and long-term goals. "
SP:cfe57a61dc20207b64b7fff45f7cb33126dce558,"This paper studies the effect of curation on the posterior distribution of Bayesian neural networks (BNNs) for image classification. The authors propose a generative model describing curation and show that curation can be seen as a Bayesian explanation for the performance of BNNs. They show that the curation of CIFAR-10H is carefully curated, and that the likelihood of the curated dataset matches the tempered likelihoods used in past work. The curation implies that each label is almost certain to be correct, and if we destroy this pattern by adding noise to the labels, the cold posterior effect should disappear and eventually reverse."
SP:4ebd3874ecea94ed9d0ca7b2fb13bf246b556938,"This paper studies the speed-accuracy trade-off between autoregressive and non-autoregressive neural machine translation (NAR) models. The authors argue that NAR models suffer from suboptimal layer allocation, insufficient speed measurement, and lack of knowledge distillation. To address these issues, the authors propose a deep-shallow NAR model, where the encoder and decoder are of different depths, and the decoder is a single-layer model. They show that the accuracy gap between NAR and AR models is much wider than previously thought and NARs cannot capture target word order well without sufficiently deep decoders. "
SP:ce8cf444681a8e38408c6485029fe42b89a1f172,"This paper investigates epoch-wise double descent, i.e., the test error of a DNN also shows double descent as the number of training epochs increases. Specifically, this paper extends the bias-variance analysis to epoch-wide double descent and shows that the variance also contributes the most to the zero-one loss. Inspired by this result, the authors propose a novel metric, optimization variance (OV), to measure the diversity of model updates caused by the stochastic gradients of random training batches drawn in the same iteration. OV can be estimated using samples from the training set only but correlates well with the (unknown) test error. It can be used to predict the generalization ability of a deep neural network."
SP:8d8b738c676938952e62a6b2aea42e79518ece06,"This paper studies the adversarial robustness of model-agnostic meta-learning (MAML) in few-shot learning. The authors propose a robust regularization method for MAML to promote robustness-promoting regularization in the meta-updating stage. They show that robustifying the meta update stage is sufficient to make robustness adapted to the task-specific fine-tuning stage even if the latter uses a standard training protocol. Furthermore, they propose a general but easily-optimized robust-regularized meta- learning framework, which allows the use of unlabeled data augmentation, fast adversarial attack generation, and computationally-light fine tuning. "
SP:1fdce0afe8fd8c082f62f1a4b9823830d81860e8,"This paper studies the problem of tuning the step size for quadratic loss in a learning-to-learn setting. The authors show that computing the meta-gradient directly using backpropagation leads to numerical issues that look similar to gradient explosion/vanishing problems. They also characterize when it is necessary to compute meta-objective on a separate validation set instead of the original training set. Finally, they verify their results empirically and show that a similar phenomenon appears even for more complicated learned optimizers parametrized by neural networks."
SP:c8a9ab50888585b58369c4fb425be1170c96c14d,"This paper proposes a graph view-consistent learning network (GVCLN) for the semisupervised learning when the number of labeled samples is very small. The proposed method uses the neighborhood aggregation capability of GVCLN and use dual views to obtain different representations between two views. Two loss functions are designed besides a supervised loss. The supervised loss uses the known labeled set, while a view consistent loss is applied to the two views and a pseudo-label loss is designed by using the common high-confidence predictions. Experiments on several node classification tasks demonstrate the effectiveness of the proposed method. "
SP:9c8619d2c0df81c1222ba28cecbacc42408d0019,"This paper studies the problem of predicting the dynamics of systems when the underlying dynamics of the system is inferred from the data directly. In particular, the authors propose a method to learn the cyclic coordinates of a system using the Hamiltonian dynamics. These coordinates can be obtained via canonical transformations and can be searched for automatically with appropriate loss functions which naturally arise from the dynamics. The proposed method is tested on both synthetic and real-world data and is shown to be able to identify the conserved quantities in the system."
SP:d1e78b1759eef8fc16e5b7ad7f0e290e9dc5dea0,"This paper proposes a novel GNN-based model for graph representation learning with heterogeneous tabular features. The proposed model trains GBDT and GNN jointly to get the best of both worlds: GBDT deals with the heterogeneous features, while GNN accounts for the graph structure. The model benefits from end-to-end optimization by allowing new trees to fit the gradient updates of GNN. The experimental results show that the proposed model is more efficient than the state-of-the-art GNN models due to faster loss convergence."
SP:9f9dbff2fe7defd41b9ed1a6c9dcad07e932dea7,"This paper studies the role of the train-validation split in meta-learning in the linear centroid setting, where the number of tasks goes to infinity. The authors show that the splitting method converges to the optimal prior as expected, whereas the non-splitting method does not in general without structural assumptions on the data. They also show that if the data are generated from linear models (the realizable regime), both the splitting and non-Splitting methods converge to optimal prior. Finally, they show that in the agnostic regime, both the split-train and train-val methods converge."
SP:bb566eda95867f83a80664b2f685ad373147c87b,"This paper proposes a method to extract hard confident examples from the noisy training data. The method is based on the memorization effect of deep neural networks that they would first learn simple patterns, i.e., which are defined by these shared by multiple training examples. To extract hard examples that contain non-simple patterns and are entangled with the inaccurately labeled examples, this paper borrows the idea of momentum from physics and alternately update the confident examples and refine the classifier. The extracted confident examples in the previous round can be exploited to learn a better classifier and help identify better (and hard) confident examples. Empirical results on benchmark-simulated and real-world label-noise data illustrate the effectiveness of the proposed method."
SP:ca57b693e5eff372c872f42d66b18b8aa1d07c87,This paper studies the robustness of kNN and rNN algorithms to data poisoning attacks. The authors show that the intrinsic majority vote mechanism in kNN provides certified robustness guarantees against general data poisoning attack. The empirical evaluation results on MNIST and CIFAR10 show that kNN outperforms the state-of-the-art certified defense methods.
SP:6cfe70be8ac34d6f61009e7e583e537e9adeb648,"This paper studies the batch size selection problem for training graph neural network with SGD method. The authors propose a metric that combines both the variance of gradients and compute time for each mini-batch. They theoretically analyze how batch-size influence such a metric and propose the formula to evaluate some rough range of optimal batch size. The empirical results show that in contrast to conventional deep learning models, GNNs benefit from large batch sizes."
SP:30d97322709cd292a49f936c767099f11b0e2913,This paper proposes a new method to detect misclassification errors in neural network classifiers. The proposed method is based on a regression model based on Gaussian Processes (RIO) on top of the original NN classifier. The main idea is to calibrate the classifier’s inherent confidence indicators and estimate the uncertainty of the calibrated confidence scores using Gaussian processes. Empirical results on 125 UCI datasets demonstrate the effectiveness of the proposed method. 
SP:131b3da98f56d3af273171f496b217b90754a0a7,"This paper proposes a knowledge distillation-based approach to learn retriever models for downstream tasks. The approach leverages attention scores of a reader model, used to solve the task based on retrieved documents, to obtain synthetic labels for the retriever model. The proposed approach is evaluated on the open domain question answering task and achieves SOTA results."
SP:a516fff3cabc13cea1b8ed07dbf9eb1acb7dbb0e,"This paper studies the problem of learning a safe controller in a constrained Markov Decision Process (MDP). The authors propose to use formal language to specify the constraints of a constrained MDP by specifying them in formal languages as a step towards using safety methods from software engineering and controller synthesis. Constraint states are then used to augment the underlying MDP state and to learn a dense cost function, which can be used to quickly learn joint MDP/constraint dynamics. The authors evaluate the effect of these methods on training a variety of RL algorithms over several constraints specified in Safety Gym, MuJoCo, and Atari environments."
SP:e18cfc1502c4087422d3baf655c244d4f3924a76,"This paper proposes a new decision tree model, called Cascading Decision Trees, to improve the comprehensibility of classifications in binary classification. The main idea is to separate the notion of a decision path and an explanation path, and to build several smaller decision subtrees and cascade them in sequence. The cascading subtrees are designed to specifically target explanations for positive classifications. Empirical results show that the proposed cascading decision tree can reduce the explanation depth by more than 40.8% for positive classification. "
SP:0508336b2ec032b9b98a1039e94ea223f3987cec,"This paper studies the effect of increasing the number of parameters in a neural network on the performance of the network. The authors show that for models with a random, static sparsity pattern in the weight tensors, the network width is the determining factor for good performance. The number of weights is secondary, as long as the model achieves high training accuarcy. They analyze these models in the framework of Gaussian Process kernels."
SP:92e5a610ed13ada6d25d433b03ac06fa5eebd963,"This paper proposes a joint pre-training framework, JAKET, to model both the knowledge graph and language. The knowledge module and language module provide essential information to mutually assist each other: the knowledge module produces embeddings for entities in text while the language module generates context-aware initial embedding for entities and relations in the graph. Experimental results on several knowledge-aware NLP tasks show that the proposed framework achieves superior performance by effectively leveraging knowledge in language understanding."
SP:1db95a377f3d5ed129aa0511f840f647375e3528,"This paper proposes an unsupervised learning method for learning autoregressive orders in a data driven way without a domain-specific prior. The proposed method is based on a neural network that performs variational inference with the order of the sequence as a latent variable. The authors propose a practical algorithm for end-to-end optimization using policy gradients. Empirical results on image captioning, code generation, text summarization, and machine translation tasks show that the learned orders are competitive with or even better than fixed orders."
SP:1c310f02acda4aa14e4d043c8d6de8c94a8ecf44,This paper proposes a general doubly variance reduction scheme for sampling-based sampling methods for graph convolutional networks (GCNs) that can accelerate any sampling method under the memory budget. The main idea is to decompose the variance of sampling methods into node embedding approximation variance (zeroth-order variance) during forward propagation and layerwise-gradient variance (first-order variances) during backward propagation. The convergence rate of the proposed scheme is shown to be O(1/\sqrt{T}^2/\epsilon^{-1/2}^3/T}). The paper also provides theoretical convergence analysis for the proposed sampling method. 
SP:02e100a9ad4eedab8cba043d3726f022bc09a3af,"This paper proposes a method to perform image manipulation by training a conditional adversarial generator on the single target image. The proposed method is based on the idea that a primitive representation of the image (e.g. edges and segmentation) can be used to map the image to the image itself, which is then used to make image manipulation. The method is evaluated on a number of image manipulation tasks and is shown to be able to perform better than existing methods."
SP:4d7c1e30fa8eb3e7c67a4ec3bccc5d3ef713a773,"This paper proposes GLSEARCH, a graph neural network based model for MCS detection, which learns to search. The model uses a state-of-the-art branch and bound algorithm as the backbone search algorithm to extract subgraphs by selecting one node pair at a time. The proposed method replaces the node selection heuristics with a novel task-specific Deep Q-Network (DQN), which allows the search process to find larger common sub-graphs faster. Experiments on synthetic and real-world large graph pairs demonstrate the effectiveness of the proposed method."
SP:581c6d218e75b0df808bc2c83c8731a94e94a5b3,"This paper proposes an end-to-end trainable deep network architecture to convert a 3D point cloud into a wireframe model. The architecture gradually builds up the model: It starts by encoding the points into feature vectors, identifies a pool of candidate vertices, then prunes those candidates to a final set of corner vertices and refines their locations. Next, the corners are linked with an exhaustive set of candidate edges, which is again pruned to obtain the final wireframe. All steps are trainable, and errors can be backpropagated through the entire sequence. The experiments on a synthetic dataset and a new real-world dataset demonstrate the effectiveness of the proposed method."
SP:3e0fd62d9815d7de5e5139a1d6d2e80eea917154,"This paper studies the convergence of stochastic gradient methods in the setting where the noise level is unknown. The authors show that when the noise levels are known, the rate of convergence is polynomial in the number of steps. When the noise is unknown, they show that adaptive stepsizes are more effective than fixed stepsizes. They also show that a variant of RMSProp (Tieleman and Hinton, 2012) can achieve the idealized convergence rate. "
SP:71c4e6ab911962d730461eda0f2d72d810fc017c,"This paper proposes a method to augment neural machine translation (NMT) with prior word alignment information to provide hints or guidelines for the target sentence at running time. The proposed method is based on an enhancement learning model, which can learn how to directly replace specific source words with their target counterparts according to prior alignment information. This model is then inserted into a neural MT model and augments MT input with the additional target information from the learning model in an effective and more efficient way. The method achieves BLEU improvements (up to 1.1) over a strong baseline model on English-Korean, English-to-German and English-Romanian translation tasks."
SP:c26255a8ad441f11cfbe18fd6dad14773aca4a2b,"This paper proposes a new benchmark for reinforcement learning with different levels of hardness. The benchmark is based on a collection of toy environments that can be controlled by varying a number of parameters. These parameters include delayed rewards, rewardable sequences, sparsity of rewards, stochasticity, image representations, irrelevant features, time unit, and action range. The authors show that the proposed benchmark can be run in 30 seconds on a single laptop. "
SP:e8cbe62252aa671a6deaf12b97063063dfc6d1b0,"This paper proposes a quantile regularization method for regression calibration. The proposed method is based on quantile entropy estimation, which is an extension of quantile calibration (Kuleshov et al., 2018). The authors propose to use entropy estimation as a regularizer to regularize the quantile distribution of the regression model. The authors provide a detailed analysis of the side-effects of Isotonic Regression (IR) on the calibration of regression models. They also provide empirical results to demonstrate the effectiveness of the proposed method. "
SP:9c71ab8dcc433b59d9da3f0db377b74a369112bc,"This paper proposes a method to solve the problem of 6-DoF localisation and 3D dense reconstruction in spatial environments as approximate Bayesian inference in a deep state-space model. The proposed method leverages both learning and domain knowledge from multiple-view geometry and rigid-body dynamics. This results in an expressive predictive model of the world, often missing in current state-of-the-art visual SLAM solutions. The combination of variational inference, neural networks and a differentiable raycaster ensures that the model is amenable to end-to-end gradient-based optimisation. Empirical results on realistic aerial vehicle flight data demonstrate the performance of the proposed method."
SP:bacb279ab6d1997bf44b7b2af583f29679219c36,"This paper proposes EMMA (Entity Mapper with Multi-modal Attention), a model for leveraging textual descriptions to improve generalization of control policies to new scenarios. EMMA is end-to-end differentiable and can learn a latent grounding of entities and dynamics from text to observations using environment rewards as the only source of supervision. Empirical results show that EMMA achieves successful zeroshot generalization to unseen games with new dynamics, obtaining significantly higher rewards compared to multiple baselines."
SP:d90da59c651ae3e97af1cf85f3ab1f12cd56d149,This paper proposes a new method for training policy gradients in the actor-critic framework. The proposed method uses a new state-value function approximation that learns the value of the states (resp. state-action pairs) relative to their mean value rather than the absolute value as in conventional actor/critic methods. The method is evaluated on a variety of continuous control tasks and algorithms. 
SP:62d79bf04817bba3fdffb2c0c9209923a8428533,"This paper studies the effect of depth on the generalization performance of deep neural networks in the over-parameterized regime. To this end, the authors introduce local and global labels as abstract but simple classification rules. They show that depth is better for local labels, while depth is worse for global labels. They also compare the results of finite networks with those of the neural tangent kernel (NTK), which is equivalent to an infinitely wide network with a proper initialization and an infinitesimal learning rate. "
SP:9f8a9299ee67b9c707b241ce84cf41f4917ef735,"This paper studies few-shot learning via representation learning, where one uses T source tasks with n1 data per task to learn a representation in order to reduce the sample complexity of a target task for which there is only n2(n1) data. Specifically, the authors focus on the setting where there exists a good common representation between source and target, and their goal is to understand how much a sample size reduction is possible. First, they provide a risk bound of $O(\sqrt{dk n1T + k n2}$ for the linear representation class, where d is the ambient dimension and k is the dimension of the representation. Then, they extend this result to handle a general representation function class and obtain a similar result. Finally, they demonstrate the advantage of representation learning in both high-dimensional linear regression and neural networks, and show that representation learning can fully utilize all n1t samples from source tasks."
SP:e29ce50c1c28f9264613736b6c2d20afc4f312c1,"This paper proposes a new method to study the robustness of neural networks to perturbations to the semantic features of the input. The proposed method is based on a black-box approach to determine the features for which a network is robust or weak. The authors leverage these features to obtain provably robust neighborhoods defined using robust features and adversarial examples defined by perturbing weak features. They evaluate their approach with PCA features and show that their provably-robust neighborhoods are larger: on average by 1.5x and up to 4.5X, compared to the standard neighborhoods. They also demonstrate that their adversarial example are generated using at least 12.2x fewer queries and have at least 2.8x lower L2 distortion."
SP:e3fdb96a8c321a86b136e765abe796019d6f9c7a,"This paper proposes a multi-task learning algorithm for reinforcement learning. The main idea is to use the expectation-maximization algorithm to find clusters of related tasks and assign each task to the best performing policy. The proposed method is intuitive, simple to implement and orthogonal to other multi- task learning algorithms. The experimental results show that the proposed method outperforms the baselines on a variety of tasks."
SP:b3805eb7114391ed15d5806b1c3eb383bff44250,"This paper proposes a self-supervised representation learning method for non-stationary time series. The proposed method, called Temporal Neighborhood Coding (TNC), takes advantage of the local smoothness of a signal’s generative process to define neighborhoods in time with stationary properties. A debiased contrastive objective is used to ensure that in the encoding space, the distribution of signals from within a neighborhood is distinguishable from that of non-neighboring signals. The method is evaluated on clustering and classification tasks for multiple datasets."
SP:60b2ea4624997d6ccf862742fb9eb21b819d7eb1,"This paper proposes a method for learning modular networks for multi-task learning and transfer learning. The main idea is to learn a sequence of pre-trained modules that can be used for different tasks. This allows soft weight sharing between tasks with only a small increase in the number of parameters. The proposed method is evaluated on a variety of tasks, including multi-source domain adaptation, transfer learning, continual learning, and domain adaptation."
SP:cae669c631e11fe703bf6cb511404866b19f474a,"This paper studies the problem of posterior collapse in VAEs, where the learned latent space becomes uninformative. This is related to local optima of the objective function that are often introduced by a fixed hyperparameter resembling the data variance. This variance parameter regularizes the VAE and affects its smoothness, which is the magnitude of its gradient. An inappropriate choice of this parameter causes oversmoothness and leads to posterior collapse. This paper proposes AR-ELBO, which stands for adaptively regularized ELBO (Evidence Lower BOund). It controls the strength of regularization by adapting the variance parameter and thus avoids oversmoothing the model. Experiments on MNIST and CelebA datasets show the effectiveness of the proposed method."
SP:cb3c10afbdd8a49cdc23e3ea71ea46ab27253b85,This paper proposes an unsupervised deep generative model that combines a mixture model in the local or data-dependent space and a global Gaussian latent variable to capture global dependencies among observations. The authors show that the induced latent global space captures interpretable disentangled representations with no user-defined regularization in the evidence lower bound (as in beta-VAE and its generalization). The model performs domain alignment to find correlations and interpolate between different databases. 
SP:33792375012ff9dcffab598cc8fe5ebc71c98af4,"This paper proposes a self-supervised representation learning method that uses human interaction and attention cues to learn better representations compared to visualonly representations. The authors collect a dataset of human interactions capturing body part movements and gaze in their daily lives. The proposed method is evaluated on a variety of downstream tasks: scene classification (semantic), action recognition (temporal), depth estimation (geometric), dynamics prediction (physics), and walkable surface estimation (affordance)."
SP:6873a5e80e6142983c9bbd22931bfded7eed2f59,"This paper studies the problem of negative pretraining, where a pretrained model obtains a worse generalization performance than a model that is trained from scratch when either are trained on a target task. The authors propose three interventions to remove and fix this problem. First, they show that increasing the learning rate after pretraining can yield even better results than training directly on the target task, on the learning task-level, we intervene by increasing the discretization of data distribution changes from start to target task instead of “jumping” to a target tasks, and at the model-level we reset the network biases to larger values. The experiments are conducted on a variety of task changes and datasets. "
SP:5d27e5a301ed4f224fb2baecad77006a9fbb2189,"This paper studies the problem of finding safe spots in the vicinity of natural images that are robust to adversarial attacks. To this end, the authors propose a bi-level optimization algorithm that can find safe spots on over 90% of the correctly classified images for adversarially trained classifiers on CIFAR-10 and ImageNet datasets. They also propose a novel safe spot inducing model training scheme and propose a new out-of-distribution detection algorithm that achieves the state of the art results on near distribution outliers."
SP:1350ab543b6a5cf579827835fb27011751cc047f,"This paper proposes a point spatio-temporal (PST) convolution method for point cloud sequences. The proposed PST convolution first disentangles space and time in point cloud sequence. Then, a spatial convolution is employed to capture the local structure of points in the 3D space, and a temporal convolutions is used to model the dynamics of the spatial regions along the time dimension. Furthermore, PSTNet is incorporated into a deep network, namely PSTNet, to extract features in a hierarchical manner. Extensive experiments on widely-used 3D action recognition and 4D semantic segmentation datasets demonstrate the effectiveness of the proposed PSTNet."
SP:a808583e924f85ec847c6b2597bae5c3eeec0ca7,"This paper proposes AdaSpeech, an adaptive TTS system for high-quality and efficient customization of new voices. The authors propose several techniques to address the two challenges in custom voice: 1) to handle different acoustic conditions, they model the acoustic information in both utterance and phoneme level. 2) To better trade off the adaptation parameters and voice quality, they introduce conditional layer normalization in the mel-spectrogram decoder of AdaSpech, and fine-tune this part in addition to speaker embedding for adaptation."
SP:66f56cc202aed1382a342e13ecfe0c5af87f6fee,"This paper studies the gradient flow of training sparse neural networks. The authors show that the default choices of optimizers, activation functions and regularizers used for dense networks can disadvantage sparse networks. Based on these findings, the authors suggest that initialization is only one piece of the puzzle and a wider view of tailoring optimization to sparse networks yields promising results. "
SP:d9f17344cd266b16a70c37d891b2c64a6d454908,"This paper studies the relationship between label propagation (LPA) and graph convolutional neural networks (GCN) in the context of node classification. In particular, the authors analyze how the feature/label of one node is spread over its neighbors; and, how much the initial features/labels influence the final features of another node. Based on the theoretical analysis, they propose an end-to-end model that unifies GCN and LPA for node classification, where edge weights are learnable, and the LPA serves as regularization to assist the GCN in learning proper edge weights that lead to improved classification performance. Experiments on real-world graphs demonstrate the effectiveness of the proposed method."
SP:c5883e3a59e6575eff044251b38175a6ed024034,"This paper studies the generalization error of CNNs in the extended setting where the ground truth labels are generated by a function within another function space, which the authors call the generator space. The authors show that the R-Complexity of both the classifier and the generator function spaces depends on the size of the generator. They also propose a new entropy-like measure of complexity between function spaces (classifier and generator), called co-complexity, which leads to tighter bounds on the generalisation error in this setting. "
SP:9bb36be61f1d4db88d806092219eba39bf1b99db,"This paper proposes a novel post-training quantization method BRECQ, which pushes the limits of bitwidth in PTQ down to INT2 for the first time. The main idea is to reconstruct the basic building blocks in neural networks and reconstruct them one-by-one. The authors provide a good balance between cross-layer dependency and generalization error. The mixed precision technique is incorporated in their framework by approximating the inter-layer and intra-layer sensitivity. Experiments on various handcrafted and searched neural architectures are conducted for both image classification and object detection tasks."
SP:3035318ac36cad693a5e4ee7bed43db8df6fb492,"This paper studies the effect of dataset imbalance on the calibration of deep neural networks. The authors show that calibration varies significantly among classes, even when common strategies to mitigate class imbalance are employed. They also study the effects of label quality, showing how label noise dramatically increases calibration error. Finally, they show that poor calibration can come from small dataset sizes, which they motive via results on network expressivity."
SP:17d90f9d3f5891ac56f5ed6375a21d0c1517fd62,"This paper studies the problem of emergent communication in a multi-agent multi-joint RL setting, where the agents learn to communicate via actuating their joints in a 3D environment. The authors show that under realistic assumptions, a non-uniform distribution of intents and a commonknowledge energy cost, these agents can find protocols that generalize to novel partners. They also explore and analyze specific difficulties associated with finding these solutions in practice, and propose and evaluate initial training improvements to address these challenges."
SP:5ba686e2eef369fa49b10ba3f41f102740836859,"This paper proposes a method for estimating uncertainty estimates for sequential regression in deep recurrent networks (DNNs). The proposed method is based on meta-modeling, which is an extension of the meta-learning framework to DNNs. The method is able to generate both symmetric and asymmetric uncertainty estimates, and outperforms baselines on both drift and non-divergence scenarios. "
SP:0a58694abd6898a925b1d917ad2a68eefd0567e9,This paper proposes two unbalanced Gromov-Wasserstein formulations for the comparison of metric measure spaces. The first formulation is a positive and definite divergence based on a relaxation of the mass conservation constraint using a novel type of quadratically-homogeneous divergence. This divergence works hand in hand with the entropic regularization approach which is popular to solve large scale optimal transport problems. The second one is a distance between mm-spaces up to isometries based on the conic lifting. The authors show that the underlying nonconvex optimization problem can be tackled using a highly parallelizable and GPU-friendly iterative scheme.
SP:47dcefd5515e772f29e03219c01713e2403643ce,"This paper proposes a new method for saliency-based network pruning. The proposed method, called all-alive pruning (AAP), is based on the observation that dead connections do not contribute to model capacity, regardless of pruning methods. To this end, the authors propose a novel pruning method that produces the pruned networks with only trainable weights. The authors show that the proposed method can be applied to various saliency based pruning algorithms and model architectures. The experimental results show that AAP outperforms the existing methods at high compression ratios on three benchmark datasets."
SP:9eb7b946e00085b89844c485bcd94a392146d2b7,This paper proposes a method for controlled semantic image editing. The proposed method is based on a latent space transformation-based model that learns multiple attribute transformations simultaneously and integrates attribute regression into the training of transformation functions. A content loss and an adversarial loss are used to encourage the maintenance of image identity and photo-realism. Empirical results show that the proposed method achieves state-of-the-art performance for targeted image manipulation.
SP:d9d9d5ade0253be2733d8b035f755ebf82e7e18b,"This paper proposes a Gumbel-Softmax GAN model for discrete sequence generation. The proposed method uses a feature alignment regularization technique to improve the performance of the discriminator. Specifically, the proposed method aligns the mean statistics of the fake data distribution with that of the real data distribution in a finite-dimensional feature space. Experiments on synthetic and real-world datasets demonstrate the effectiveness of the proposed methods. "
SP:3ffa34b54779998f473f4e9a52287bcd0485cec8,"This paper proposes Spectral DQN, which decomposes the reward into frequencies such that the high frequencies only activate when large rewards are found. This allows the training loss to be balanced so that it gives more even weighting across small and large reward regions. In two domains with extreme reward progressivity, where standard value-based methods struggle significantly, the proposed method is able to make much farther progress. In a set of six standard Atari games that do not overtly favour the approach, it remains more than competitive."
SP:bff215c695b302ce31311f2dd105dace06307cfc,"This paper introduces a notion of usable information to study the representation learned by a deep network, and uses it to study how optimal representations for the task emerge during training. The authors show that the implicit regularization coming from training with Stochastic Gradient Descent with a high learning-rate and small batch size plays an important role in learning minimal sufficient representations for a given task. In particular, they find that semantically meaningful but ultimately irrelevant information is encoded in the early transient dynamics of training, before being later discarded. They also evaluate how perturbing the initial part of training impacts the learning dynamics and the resulting representations."
SP:c175ea892c831c2d0c38aded9b5e86d25b86545c,"This paper proposes a zeroth-order variance reduction algorithm for nonconvex-strongly-concave min-max optimization problems. The proposed algorithm, SREDA-Boost, is based on the SREDa algorithm proposed by Luo et al. (Luo et al., 2020), which was shown to achieve the optimal complexity dependence on the required accuracy level. The main contribution of this paper is to develop a new analysis framework to improve the convergence rate of SRedA. The authors also propose an improved algorithm, ZO-SREDA, which has less restrictive initialization requirement and an accuracy-independent stepsize. "
SP:c1617e79182c6d06c611ced9d892d7b2da5fd9eb,"This paper shows that increasing the number of object categories used during training can improve the generalization from seen to unseen classes from 45% to 89% and improve the state-of-the-art on COCO by 5.4% AP50 (from 22.0 to 27.5%) on the LVIS dataset. The authors verify that the effect is caused by the size of the categories and not the training samples, and that it holds for different models, backbones and datasets. This result suggests that the key to strong few-shot detection models may not lie in sophisticated metric learning approaches, but instead simply in scaling the number categories."
SP:a472784ddb36f88e6e468f282fbd7ad74f8f7d75,"This paper proposes a method for single-view implicit surface reconstruction from a single RGB image. The proposed method is based on a closed-form differentiable gradient sampler, which allows backpropagation of the loss on spatial gradients to the feature maps, thus allowing training on large-scale scenes without dense 3D supervision. Experiments on ScannetV2, ShapeNet and Pix3D show that the proposed method outperforms the state-of-the-art."
SP:b89ec0b50475bfb23399719ca36aa137b389fbf6,"This paper proposes a simple training strategy called “Pseudo-to-Real” for high-memory-footprint-required large models. The proposed method is compatible with large models with architecture of sequential layers. The authors demonstrate a practice of pretraining unprecedented 10-trillion-parameter model, an order of magnitude larger than the state-of-the-art, on solely 512 GPUs within 10 days. Besides, they also provide a technique, Granular CPU offloading, to manage CPU memory for training large model and maintain high GPU utilities."
SP:cd1e11b270f74d5dca9efd9fe1903c0a24bcba12,"This paper studies the problem of training energy-based models (EBMs) with shallow overparametrized neural network energies, both in the active (aka feature learning) and lazy regimes. In the active regime, this dual formulation leads to a training algorithm in which one updates concurrently the particles in the sample space and the neurons in the parameter space of the energy at a faster rate. The authors also consider a variant of this algorithm where the particles are sometimes restarted at random samples drawn from the data set, and show that performing these restarts at every iteration step corresponds to score matching training."
SP:4ff82f679a321ed61e02c50d5997c4e179441a0e,"This paper studies the lower bounds of differentially private ERM for general convex functions. For approximate-DP, the well-known upper bound of DP-ERM is O(\sqrt{p log(1/\delta) n), which is believed to be tight. However, the current lower bounds are off by some logarithmic terms, in particular for constrained case and unconstrained case. The authors achieve tight lower bounds for both cases by introducing a novel biased mean property for fingerprinting codes, and using a novel `2 loss function instead of linear functions. "
SP:c4b4914d64e76427435bee0da345fe33b1db7d27,"This paper proposes a scalable proximal gradient type algorithm for Wasserstein gradient flow. The key of the proposed method is a variational formulation of the objective function, which makes it possible to realize the JKO proximal map through a primal-dual optimization. The proposed method covers all the classical Wasserststein gradient flows including the heat equation and the porous medium equation. The performance and scalability of the algorithm are demonstrated on several numerical examples."
SP:01f652a6b323db3585376a3a8e975a73ec4fed0b,"This paper proposes a meta-feature alignment method for AutoML. The meta-features are learned via an Optimal Transport (OT) procedure, which aligns the meta features with the space of distributions on the hyper-parameter configurations. Experiments on the OpenML CC-18 benchmark show that the proposed method can improve the performance of AutoSkLearn and Probabilistic Matrix Factorization. "
SP:e789c71cef2094ff2bac51b523ca912f1f04c2c9,"This paper proposes a split-mix FL strategy for heterogeneous participants that, once training is done, provides in-situ customization of model sizes and robustness. Specifically, the proposed method learns a set of base sub-networks of different sizes and model robustness levels, which are aggregated on-demand according to inference requirements. The proposed method achieves customization with high efficiency in communication, storage, and inference. Extensive experiments demonstrate that the proposed SplitMix FL method is better than the existing heterogeneous-architecture FL methods."
SP:0fd50d89ffec376d136aa915c9c4e6ae281f5014,"This paper proposes an extragradient-type algorithm for nonconvex-nonconcave minimax minimax problems. The proposed algorithm is applicable to constrained and regularized problems, and involves an adaptive stepsize allowing for potentially larger stepsizes. The algorithm also converges globally even in settings where the underlying operator exhibits limit cycles. "
SP:af22742091277b726f67e7155b412dd35f29e804,"This paper studies neural contextual bandits, a general class of contextual bandits where each context-action pair is associated with a raw feature vector, but the specific reward generating function is unknown. The authors propose a novel learning algorithm that transforms the raw feature vectors using the last hidden layer of a deep ReLU neural network (deep representation learning), and uses an upper confidence bound (UCB) approach to explore in the last linear layer (shallow exploration). They prove that under standard assumptions, their proposed algorithm achieves $O(\sqrt{\sqrt{T})$ regret, where T is the learning time horizon."
SP:a9a2c21110e00f19882d27bef0063c422a15e576,"This paper proposes a shapley-inspired algorithm for training action space categorization and ranking for reinforcement learning. The algorithm is based on Shapley's algorithm for action space selection, which uses a Monte Carlo simulation to avoid unnecessary exploration. The proposed algorithm is shown to reduce the search space by 80% and categorizes the training action sets into dispensable and indispensable groups. It also ranks different training actions to facilitate high-performance yet cost-efficient RL model design."
SP:0e0adc42f6025034d341dc9c17b3f6251afebc2f,This paper proposes a method for quantifying the uncertainty of model predictions in the presence of covariate shifts in the data distribution. The proposed method is based on estimating importance weights that encode how the probabilities of the training examples change under the covariate shift. The authors show that the proposed method can be used to construct probably approximately correct (PAC) prediction sets that satisfy the PAC constraint. The method is tested on DomainNet and ImageNet datasets.
SP:0c522ffa2c90eb88296ad0c7999200a72b8755e2,"This paper studies the generalization performance of iterative semi-supervised learning (SSL) algorithms that iteratively generate pseudo-labels for a large amount of unlabelled data to progressively refine the model parameters. The authors show that when the class conditional variances are not too large, the upper bound on the generalisation error decreases monotonically with the number of iterations, but quickly saturates. The theoretical results are corroborated by extensive experiments on several benchmark datasets such as the MNIST and CIFAR datasets. "
SP:570149eb8fb97928f94312e40bdc48dfe9885848,"This paper proposes a model-free reinforcement learning method that can generate multi-step plans for future steps. The proposed method, called GPM, is trained by maximizing the value of the current state-action pair in the current time step. The authors show that GPM is more effective than existing methods in terms of exploration and exploration efficiency. Experiments are conducted on several benchmark environments to demonstrate the effectiveness of the proposed method."
SP:ce6a93847209a0926ed0be5190378a3f61db1935,"This paper presents a framework of multi-mode deep matrix and tensor factorization methods to explore and exploit the full nonlinearity of the data in matrices and tensors. The authors propose a new matrix factorization method called two-mode nonlinear DMF, which is a high-order generalization of the classical linear DMF. A new tensor decomposition method is also proposed. The experiments on synthetic data and real datasets show that the proposed methods have higher recovery accuracy than many baselines."
SP:931661154975d94fc5ba1bc89d7a7fdf643df8f2,"This paper proposes an interpretation technique to explain the behavior of structured output models, which learn mappings between an input vector to a set of output variables simultaneously. The authors focus on one of the outputs as the target and try to find the most important features utilized by the structured model to decide on the target in each locality of the input space. They introduce an energy-based training process for the interpreter function, which effectively considers the structural information incorporated into the model to be explained. The effectiveness of the proposed method is confirmed using simulated and real data sets."
SP:cf9b6963c32d8689f7203dd41b17461676d08739,"This paper proposes a method for risk-sensitive deep reinforcement learning based on the cumulative distribution function (CDF) of full episode outcomes, where the goal is to maximize a chosen function of the CDF. The authors propose a sampling-based method to estimate the policy gradient for a broad class of CDF-based objectives via sampling, and propose a variance reduction measure to facilitate effective on-policy learning. They show that the proposed method can be used to train agents with different “risk profiles” in penalty-based formulations of six OpenAI Safety Gym environments. "
SP:fa405481f36da10f8ca8d9d5c066458236806a12,"This paper proposes an active learning method for simulating large-scale, spatiotemporal, age-structured epidemic models. The proposed method is based on a neural process model and a deep learning surrogate model. The model is trained with a Bayesian active learning algorithm to learn a surrogate model that can be used to simulate the simulator dynamics. The authors show that the proposed method reduces sample complexity compared with random sampling in high-dimensional simulations."
SP:fdabafe7d5ca2239a241eba04e1f16cb1ac2316b,"This paper proposes a method to improve the performance of DP-SGD-based NLP models by fine-tuning pretrained models with DP optimization. The authors show that the performance drop can be mitigated with the use of large pre-trained models, hyperparameters that suit DP optimization, and fine tuning objectives aligned with the pretraining procedure. They also propose a memory saving technique that allows clipping in DP- SGD to run without instantiating per-example gradients for any linear layer in the model. They show that DP optimization fails at learning high-dimensional models (due to noise that scales with dimension) but not with dimension-dependent performance degradation."
SP:33008c957718d546ecb2d7b8800ef5b03700ace4,"This paper proposes a method to learn a conditional policy that first applies a sequence of transform actions to modify an agent’s skeletal structure and joint attributes, and then applies control actions under the new design. To handle a variable number of joints across designs, the authors use a graph-based policy where each graph node represents a joint and uses message passing with its neighbors to output joint-specific actions. Experiments show that the proposed method outperforms prior methods significantly in terms of convergence speed and final performance."
SP:46e8c6a9d7729e5112b3c9f8ff91d9557ea524c1,"This paper proposes a method to accelerate inference and training of coordinate-based MLPs for implicit neural representations by proposing a new split MLP architecture, CoordX. The initial layers are split to learn each dimension of the input coordinates separately. The intermediate features are then fused by the last layers to generate the learned signal at the corresponding coordinate point. This significantly reduces the amount of computation required and leads to large speedups in training and inference, while achieving similar accuracy as the baseline MLP."
SP:3ea7edab6ae65758b99615be07b7778188a6ff9f,"This paper proposes a method to infer object-centric representations of visual scenes without relying on annotations. The proposed method learns to decompose a scene into multiple objects, with each object having a structured representation that disentangles its shape, appearance and 3D pose. Each object representation defines a localized neural radiance field that is used to generate 2D views of the scene through a differentiable rendering process. The model is trained by minimizing a reconstruction loss between inputs and corresponding rendered scenes. Empirical results show that the proposed method can discover objects in a scene without supervision. "
SP:05c61145f3fc9486728aca19c4543065fe04e99c,"This paper proposes Deconfounded Subgraph Evaluation (DSE) to assess the causal effect of an explanatory subgraph on the model prediction. The authors argue that a distribution shift exists between the full graph and the subgraph, causing the out-of-distribution problem. To address the distribution shift, the authors introduce a surrogate variable of the sub-graphs and devise a generative model to generate plausible surrogates that conform to the data distribution. Empirical results demonstrate the effectiveness of DSE in terms of explanation fidelity."
SP:bb74fef9222f227343909f3936f1a8cd2322bbeb,"This paper investigates whether pretrained models are better active learners, capable of asking for example labels that disambiguate between the possible tasks a user may be trying to specify. To this end, the authors propose to use uncertainty sampling to train a pretrained model with data acquired through simple uncertainty sampling. The authors show that pretraining can enable large gains (up to 6x reduction in data points, +12% absolute gain for the same labeling budget) and show that this is an emergent property of pretraining."
SP:f5e9fc0b1b6a41e43ba4dd0cfd99d5ec7008eedf,This paper proposes a pre-trained graph edit model for automatically detecting and fixing bugs and code quality issues in Java programs. The proposed model uses a multi-head graph encoder and an autoregressive tree decoder to perform graph edit actions for automated program repair. A deleted sub-tree reconstruction strategy is used to enrich the model with implicit knowledge of program structures from unlabeled source code. The pre-training objective is made consistent with the bug fixing task to facilitate the downstream learning. The experimental results on the Patches in The Wild Java benchmark show that the proposed model significantly outperforms CodeBERT and BART.
SP:c7b724c671def2800694fcc2625fa48d98c7cfe6,-weighted Federated Adversarial Training (α-WFAT) is a new method to relax the inner-maximization of FAT. The proposed method is based on the assumption that the weights of the adversarial training data are weighted by the average of the weight of the local clients. The authors provide a theoretical analysis on the convergence of the proposed method. Empirical results on three benchmark datasets demonstrate the effectiveness of the method. 
SP:ff3c787512035e2af20778d53586752852196be9,"This paper proposes Mako, a new method for continual continual learning of lifelong machine learning (LML) that leverages data programming to leverage unlabeled data for semi-supervised learning with limited labeled data. The proposed method is built on top of supervised LML frameworks, leveraging data programming. Mako achieves similar performance, in terms of per-task accuracy and resistance to catastrophic forgetting, as compared to fully-labeled data. "
SP:447df6679b2880def833d4f444bf10e61cdf0e1c,"This paper proposes two methods to generate adversarial examples that can simultaneously be misclassified by the model and be detected as non-adversarial. The proposed method is based on orthogonalizing the gradients when running standard gradient-based attacks. The authors show that existing attacks that attempt to satisfy multiple simultaneous constraints often over-optimize against one constraint at the cost of satisfying another. To address this issue, the authors propose two methods: Selective Projected Gradient Descent (SPGD) and Orthogonal PDE (OPDE). The authors also show that the proposed method can evade four state-of-the-art and previously-unbroken defenses to adversarial example detection."
SP:5eef907024017849303477eed92f317438c87a69,"This paper presents a novel energy-based treatment for cooperative games, with a theoretical justification by the maximum entropy principle. By conducting mean-field variational inference, the authors recover classical game-theoretic valuation criteria through conducting one-step fixed point iteration for maximizing the ELBO objective. This observation also verifies the rationality of existing criteria, as they are all attempting to decouple the correlations among players. The authors define the valuation with the best conceivable decoupling error as the Variational Index. "
SP:1257373629c8584c001b69677ebd73e5f0c20d08,"This paper proposes a method to directly estimate epistemic uncertainty by learning to predict generalization error and subtracting an estimate of aleatoric uncertainty, i.e., intrinsic unpredictability. This estimator includes the effect of model bias (or misspecification) and is useful in interactive learning environments arising in active learning or reinforcement learning. The proposed method, Direct Epistemic Uncertainty Prediction (DEUP), is evaluated on downstream tasks including sequential model optimization and reinforcement learning tasks. "
SP:fd3c33c9237d0f1e33d896858a46c48da2216fe3,"This paper proposes block Givens coordinate descent algorithms to learn rotation matrix that are provably convergent on any convex objectives. The proposed method is based on product quantization (PQ) coupled with a space rotation, which is widely used in modern approximate nearest neighbor (ANN) search systems to significantly compress the disk storage for embeddings and speed up the inner product computation. Compared to the state-of-the-art SVD method, the proposed algorithms are much more parallelizable, reducing runtime by orders of magnitude on modern GPUs, and converge more stably according to experimental studies. "
SP:6ec2c8456ab95f7d028d00b591dab3eadc549eb8,"This paper proposes a two-stage neural framework to learn visual analogies from Raven’s Progressive Matrices, an abstract visual reasoning test of fluid intelligence. The framework uses a multi-task visual relationship encoder to extract constituent concepts from raw visual input in the source domain, and a neural module net-based analogy inference engine to reason compositionally about the inferred relation in the target domain. Experiments on five different generalization splits of the visual analogy dataset show that the proposed method achieves a high degree of accuracy."
SP:0e8c3a3dba649d496292b41228801feb8507d3b4,"This paper proposes SelfGenomeNet, a self-supervised representation learning method for nucleotide-level genomics data. The proposed method learns and parameterizes the latent space by leveraging the reverse-complement of genomic sequences. The network is trained with an unsupervised contrastive loss. Extensive experiments with different datasets show that the proposed method outperforms state-of-the-art deep learning methods. "
SP:2af5c866ed17f156b406153d3261baaa42cf95fb,"This paper proposes a steerable feed-forward learning-based approach that consists of spherical decision surfaces and operates on point clouds. The authors derive a 3D steerability constraint for hypersphere neurons, which are obtained by conformal embedding of Euclidean space and have recently been revisited in the context of learning representations of point sets. Exploiting the rotational equivariance, the authors show how their model parameters are fully steerable at inference time. The proposed spherical filter banks enable making equivariant and invariant class predictions for known point sets in unknown orientations."
SP:14330a1a1c33ec18de096ffb038ba06f04c7dccb,"This paper studies continual learning in the context of pre-trained language models (PLMs) and continual learning (CL) methods. The authors compare the performance of 5 PLMs and 4 CL methods on 3 continual learning benchmarks in 2 typical incremental settings. The results show that PLMs perform better than CL methods in the incremental setting, while CL methods perform worse in the continuous setting. The experiments also show that CL methods tend to perform worse on task-specific tasks than PLMs. "
SP:adb11a3bd1af2b68720f8f1b48639e31f65295fd,"This paper proposes a defense against directed deviation attacks in federated learning. The proposed defense is based on the intuition that certain patterns of gradient flips are indicative of an attack, and the intuition is remarkably stable across different learning algorithms, models, and datasets. The defense assigns reputation scores to the participating clients based on their behavior during the training phase and then takes a weighted contribution of the clients. The authors show that TESSERACT provides robustness against even a white-box version of the attack."
SP:2047e943d2337d4fc6b0a269f43c7dfbd8ed9141,"This paper proposes a neural net-based debiasing method for estimating linear functionals of high-dimensional regression functions. The proposed method is based on learning the Riesz representation of the linear functional using neural nets and random forests. The authors propose a multi-tasking Neural Net debiased method with stochastic gradient descent minimization of a combined neural net representation and regression loss, while sharing representation layers for the two functions. They also propose a Random Forest method which learns a locally linear representation for the linear functions. "
SP:96e1da163020441f9724985ae15674233e0cfe0d,"This paper studies the actor-critic algorithm for fully decentralized multi-agent reinforcement learning (MARL) problems with average reward. In this problem, a set of N agents work cooperatively to maximize the global average reward through interacting with their neighbors over a communication network. The authors consider a practical MARL setting where the rewards and actions of each agent are only known to itself, and the knowledge of joint actions of the agents is not assumed. They propose a mini-batch Markovian sampled fully decentralized actor-Critic algorithm and analyze its finite-time convergence and sample complexity. They show that the sample complexity of this algorithm is O(N/\varepsilon^{-2/3} \log(N)) and matches that of the state-of-the-art single-agent RL algorithms."
SP:8475e89f143c727e33147b652c2d0b3cdb420382," contrastive learning is a promising approach for large-scale self-supervised learning. However, the theoretical understanding of how it works is still unclear. In this paper, the authors propose a new guarantee on the downstream performance without resorting to the conditional independence assumption that is widely adopted in previous work but hardly holds in practice. The new theory hinges on the insight that different samples from the same class could be bridged together with aggressive data augmentations, thus simply aligning the positive samples (augmented views of the same sample) could make contrastive Learning cluster intra-class samples together. The authors also show that their theory aligns well with existing contrastive methods on both synthetic and real-world datasets."
SP:b491314336c503b276e34e410cf461cb81294890,This paper proposes a general speech restoration (GSR) task that attempts to remove multiple distortions simultaneously. The authors propose a generative framework to address the GSR task. VoiceFixer consists of an analysis stage and a synthesis stage to mimic the speech analysis and comprehension of the human auditory system. The proposed method achieves a 0.499 higher mean opinion score (MOS) than the speech denoising SSR model.
SP:c80a7392ec6147395a664734601fb389a1eb4470,"This paper proposes a method to model multivariate time series using a tensor network based on the idea of low-rank approximation to model the variable space. The tensor components are shared to ensure the translation invariance of the network. In order to improve the ability to model long-term sequences, the authors propose an N-order residual connection approach and couple it to the space-approximated tensor networks. Experimental results verify the effectiveness of the proposed method on four time series forecasting benchmark datasets."
SP:0a92939e6a1c88bfeb4fd1dea9ee7be4fd60d967,This paper proposes a variant of SCO algorithms with sparse moving averages for GNN training. The authors propose to store the moving averages of the aggregated features of all nodes in the graph in the most recent iterations of the Adam SGD algorithm. The proposed algorithm preserves the convergence rate of the original SCO algorithm when the buffer size satisfies certain conditions. The experiments validate the theoretical results and show that the proposed algorithm can outperform the traditional AdamSGD with a small memory overhead.
SP:72e0cac289dce803582053614ec9ee93e783c838,"This paper proposes Circulant MinHash (C-MinHash), a variant of MinHash that uses only two independent random permutations in a circulant manner to approximate the Jaccard (resemblance) similarity in massive binary (0/1) data. Theoretical results are provided to show that using two independent permutations leads to uniformly smaller variance than the classical MinHash. Experiments are conducted to show the effectiveness of the proposed method. "
SP:d254b38331b6b6f30de398bae09380cd5c951698,"This paper proposes a simple and efficient training scheme to achieve adversarial robustness against the union of lp-threat models. The proposed E-AT scheme is based on geometric considerations of the different Lp-balls and costs as much as normal adversarial training against a single lp threat model. Moreover, the authors show that using the proposed method one can fine-tune with just 3 epochs any lp robust model (for p \in {1, 2,\infty}) and achieve multiple norm robustness. In this way, they boost the state-of-the-art for multiple-norm robustness to more than 51% on CIFAR-10 and report up to their knowledge the first ImageNet models with multiple norm-robustness."
SP:4c2928f6772664d63c02c29f913b476e1c932983,"This paper proposes a safe multi-task learning model that does not allow for negative sharing. The proposed model consists of a public encoder shared by all the tasks, private encoders, gates, and private decoders. Specifically, each task has a private encoder, a gate, and a private decoder, where the gate is to learn how to combine the public decoder and the gate for the downstream decoder. To reduce the storage cost during the inference stage, a lite version of SMTL is proposed to allow the gate to choose either the public or the corresponding private encodes. Experiments on several benchmark datasets demonstrate the effectiveness of the proposed methods."
SP:c4cee0d44198559c417750ec4729d26b41061929,"This paper argues that energy-based sequence models backed by expressive parametric families can result in uncomputable and inapproximable partition functions, which makes model selection, and therefore learning model parameters, difficult and undecidable. Specifically, the authors show that there exist pathological EBM sequence models that have uncomputable partition functions which cannot be approximated well under stochastic estimates, and do not have asymptotic estimates that have any good guarantees. As alternatives, they consider sequence model families whose partition functions are computable (if they exist) but at the cost of reduced expressiveness. "
SP:f1eb66f24a14808d404f9ad9773ef4288efa060e,"This paper proposes a new family of Wasserstein distance metrics, called augmented sliced Wassersteins (ASWDs), which are constructed by mapping samples to higher-dimensional hypersurfaces parameterized by neural networks. The ASWDs are derived from the observation that (random) linear projections of samples residing on these hypersurface would translate to much more flexible nonlinear projections in the original sample space, so they can capture complex structures of the data distribution. The authors show that the ASWD can be optimized by gradient ascent efficiently and show that this can be obtained by an injective neural network architecture."
SP:ff2433f2de48d4ed8017e27bd6cf606845cdea9e,"This paper proposes a general framework for improving coordination and performance of multi-agent reinforcement learners (MARL). The framework, named Learnable Intrinsic-Reward Generation Selection algorithm (LIGS), introduces an adaptive learner, Generator, that observes the agents and learns to construct intrinsic rewards online that coordinate the agents’ joint exploration and joint behaviour. LIGS uses a novel combination of reinforcement learning (RL) and switching controls, which determines the best states to learn to add intrinsic rewards which leads to a highly efficient learning process. The authors demonstrate the effectiveness of the proposed method on tasks in Foraging and StarCraft II. "
SP:9eadc19f7f712c488cf50d091f372092f6352930,"This paper proposes a new multi-hop QA model, named DOCHOPPER, that uses a query q to attend to different parts of long, heirarchically structured documents to answer complex questions. At each step, the query q attends to information from a document, combines this information with q to produce the next query, and is able to “retrieve” either short passages or long sections of the document, thus emulating a multi-step process of “navigating” through a long document to answer a question. To enable this novel behavior, the proposed model combines a compact neural representation of q with a compact representation of a hierarchical part of the documents, which can potentially be quite large. The proposed model achieves state-of-the-art results on four different QA tasks."
SP:4e79b326bbda5d1509e88869dde9886764366d41,", this paper proposes a semi-supervised learning method to extract refined labels (e.g. vocal characteristics) from known initial labels. The method is validated on recordings from the MassEffect 3 video game. Experiments show that, using a subsidiary corpus, it is possible to bring out interesting voice characteristics without any a priori knowledge."
SP:9c399331a3b4a55d7e1ff9298f82a38b75b4f87d,"This paper proposes a multi-task learning framework for image processing tasks. The proposed method uses a task-agnostic Vision Transformer (ViT) to learn a disentangled representation of local and non-local features using a client-side head/tail and a server-side task-specific heads/tails. Each client learns a translation from its own task to a common representation, while the Transformer body learns global attention between the features embedded in the representation. The authors propose an alternating training strategy in which task specific learning for the heads and tails is run on the clients by fixing the ViT body, which alternates with taskagnostic learning on the server by freezing the heads/tails. The experimental results on various low-level and high-level computer vision tasks show that the proposed method synergistically improves the performance of each client."
SP:249a72ef4e9cf02221243428174bb749068af6b2,"This paper studies the problem of reward hacking, where RL agents exploit gaps in misspecified reward functions. To this end, the authors construct four RL environments with misspecification rewards and investigate the behavior of the agents as a function of model capacity, action space resolution, observation space noise, and training time. They find that more capable agents exploit reward misspecifications, achieving higher proxy reward and lower true reward than less capable agents. They also find instances of phase transitions: capability thresholds at which the agent’s behavior qualitatively shifts, leading to a sharp decrease in the true reward. To address this, they propose an anomaly detection task for aberrant policies and offer several baseline detectors."
SP:1c8d06fe0b2a79d5d0c0f317692c2ee869d1cc0c,"This paper proposes a f-divergence f-TVO that generalizes the TVO by replacing the KL divergence with arbitary differeitiable f divergence. The f divergence is derived from a deformed χ-geometry perspective, which is the deformed geodesic between the variational posterior distribution and the true posterior distribution. The proposed fTVO approximates dual function of model evidence f(p(x)) rather than the log model evidence log p(x) in TVO. Experiments on VAE and Bayesian neural network show that the proposed f -TVO performs better than cooresponding baseline f-VI. "
SP:d4ce49411198fe65b8f4c2d80af222e0732a4728,"This paper studies the interplay between individual elements of the deep reinforcement learning (DRL) toolbox in the continuous control setting. The authors show that the performance of policies trained using existing methods varies significantly across training runs, epochs of training, and evaluation runs; the critics’ initialization plays the major role in ensemble-based actor-critic exploration, while the training is mostly invariant to the actor’s initialization. A strategy based on posterior sampling explores better than the approximated UCB combined with the weighted Bellman backup; the weighted bellman backup alone cannot replace the clipped double Q-learning. The proposed method ED2 achieves state-of-the-art results on continuous control tasks from OpenAI Gym MuJoCo."
SP:21819b54433fa274657d9fe418f66407eee83eeb,"This paper studies the problem of finding a fair predictor for the Equalized Loss (EL) fairness notion, which requires the prediction error/loss to be equalized across different demographic groups. This is a non-convex optimization problem even if the loss function is convex. The authors propose two algorithms that can leverage convex programming tools and efficiently find the global optimum of this non-Convex problem. Experiments on real-world data show the effectiveness of the proposed algorithms."
SP:336c1b8a7f293a78dfab18e7b454b0ec39822293,"This paper proposes to re-examine systematic generalization of neural networks from the perspective of meaningful learning. To this end, the authors propose to augment a training dataset in either an inductive or deductive manner to expose semantic links to models. The experiments on SCAN and two real-world datasets on semantic parsing show that modern sequenceto-sequence models, including RNNs, CNNs, and Transformers, can successfully one-shot generalize to novel concepts and compositions through semantic linking. The authors further demonstrate that both prior knowledge and semantic linking play a key role in achieving systematic generalisation and that inductive learning generally works better than deductive learning."
SP:5d758b9125e716c92dde5cfcc8aad67adbd30ba0,"This paper proposes a method for 3D shape representation learning using multi-scale wavelet decomposition. It decomposes 3D shapes into sub-bands components at multiple scales and all scales form a decomposition tree in a principled manner rooted in multi-resolution wavelet analysis. The proposed AWT-Net firstly generates approximation or detail wavelet coefficients per point, classifying each point into high or low sub-band components, using lifting scheme at multiple scale recursively and hierarchically. Then, the proposed method exploits Transformers that regard the features from different but complementary components as two holistic representations, and fuse them with the original shape features with different attentions. Experimental results show that the proposed model achieves state-of-the-art or competitive performance on 3d shape classification and segmentation benchmarks."
SP:b89c04e2f8e94c7d0c3686edac835a86fab2d528,This paper proposes a method to combine the benefits of full and lightweight finetuning for NLP tasks. The authors propose a combination of lightweight and full-finetuning methods to achieve strong performance both in-distribution and OOD. They show that an ensemble of lightweight models achieves the best of both worlds: performance matching the better of full/lightweight models. They also show that a single model can achieve similar performance to a single full finetuned model.
SP:28fe2b3deb6a8f24f26d48240da38d280673b8f2,"This paper proposes Active Refinement of Weakly Supervised Models (WARM), a method to improve the performance of weakly supervised models via active learning. The method is based on Data Programming (DDP), a framework for learning from weak supervision. DDP generates probabilistic training labels from simple yet imperfect heuristics (or labelling functions) obtained a priori from domain experts. WARM directs domain experts’ attention on a few selected data points that, when annotated, would most improve the label model’s probababilistic accuracy. Gradient updates are then backpropagated to iteratively update the parameters of the individual expert labelling function in the weak supervision model. Experiments on multiple real-world medical classification datasets show that WARM can substantially improve the accuracy of probablistic labels used to train downstream classifiers with as few as 30 queries to experts."
SP:f663a1e64155f1d4c890a6fefae596f67ef3cb11,"This paper proposes a new algorithm called Common Gradient Descent (CGD) for training a classification model with group annotated training data. CGD is motivated by the observation that the empirical risk minimization (ERM) objective suffers from poor performance on minority groups and that group distributionally robust optimization (Group-DRO) objective is a better alternative. Inspired by ideas from the closely related problem of domain generalization, CGD explicitly encourages learning of features that are shared across various groups. Empirical evaluation on seven real-world datasets show that CGD achieves or matches or obtains improved performance over several existing algorithms for robustness that include: ERM, PGI (Ahmed et al., 2021), IRM (Arjovsky et al. 2019), and Group-DRo."
SP:faad5fe1eefbcc2e24638383d0bde7ad7975ff4e,"This paper proposes a bivariate explanation method to explain black-box models by capturing the most influential features for prediction per instance. The authors extend univariate explanation to a higher-order, which can capture feature interactions in black box models, represented as a directed graph. They apply their bivariate method on Shapley value explanations, and experimentally demonstrate the ability of directional explanations to discover feature interactions. "
SP:c8a4254e6fc2d2e7d1d41a76bb64f78f22a8639d,"This paper proposes a new method for learning probabilistic decision trees for fully-offline and partially-observable clinical decision environments. The proposed method, named Policy Extraction through Decision Trees (POETREE), is a novel framework for interpretable policy learning that is compatible with both fully-observed and partially observed clinical decision-making environments. In particular, the proposed method is able to learn a representation of patient history through recurrence, resulting in decision tree policies that adapt over time with patient information. Experiments on real and synthetic medical datasets demonstrate the effectiveness of the proposed algorithm. "
SP:5630707c9d0d9e21fce2efddef874e373bfed026,"This paper proposes a multi-agent reinforcement learning (MARL) algorithm for data augmentation, where each agent learns an augmentation policy for each patch based on its content together with the semantics of the whole image. The agents cooperate with each other to achieve the optimal augmentation effect of the entire image by sharing a team reward. Extensive experiments demonstrate that the proposed algorithm outperforms the state-of-the-art DA methods while requiring fewer computational resources."
SP:bb2a13a4d366140fc0c3e941c354cc674f6a904f,This paper proposes an adversarial distribution alignment method to reduce the difference between natural and adversarial distributions by considering spurious correlations. The authors construct a causal graph to model the generation process of adversarial examples to formalize the intuition of the adversarial attacks. Extensive experiments demonstrate the efficacy of the proposed method.
SP:9f09449a47464efb5458d0732df7664865558e6f,"This paper proposes a method for continual learning of convolutional neural networks by learning a low-rank filter subspace for each layer of the network over a small set of filter atoms. Then, for each task, a new filter atom is learned for each convolution layer. The proposed method can be applied to a wide range of optimization schemes, and the proposed method outperforms the state-of-the-art methods in both accuracy and scalability."
SP:b806dd540708b39c10d3c165ea7d394a02376805,"This paper studies the variance collapse phenomenon of Stein variational gradient descent (SVGD) and MMD descent on the maximum mean discrepancy (MMD) objective. The authors show that SVGD suffers from the curse of dimensionality in the proportional asymptotic limit, i.e., when the number of particles n and dimensions d diverge at the same rate. They show that the variance of SVGD can be accurately predicted in this limit, and derive the exact dimension-averaged variance for both SVGD and the MMD-descent under certain assumptions."
SP:3721f1b12d87e95f5aa4c977a1714d5c54cb70f7,"This paper studies the effect of adversarial training (AT) and adversarial examples on the robustness of a model. The authors show that the number of PGD steps needed to successfully attack a point is a good measure of the point's robustness. They also show that AT with strong smoothing effects suffers less from NL (without NL corrections) than standard training, which suggests that AT itself is an NL correction."
SP:2bcf42173d9d82fb3e517405deba4aa3d6f9d8d6,"This paper proposes a statistical method to measure the expected robustness of a neural network model. The proposed method, called Robustness Measurement and Assessment (RoMA), determines the probability that a random input perturbation might cause misclassification. The method allows us to provide formal guarantees regarding the expected frequency of errors that a trained model will encounter after deployment. The approach can be applied to large-scale, black-box neural networks, which is a significant advantage compared to recently proposed verification methods."
SP:6ba17dd4b31a39478abd995df894447675f2f974,"This paper proposes a hierarchical chunking model (HCM) that learns representations from non-i.i.d sequential data from the ground up by first discovering the minimal atomic sequential units as chunks. As learning progresses, a hierarchy of chunk representation is acquired by chunking previously learned representations into more complex representations guided by sequential dependence. The authors provide learning guarantees on an idealized version of HCM and demonstrate that HCM learns meaningful and interpretable representations in visual, temporal, visual-temporal domains and language data. Furthermore, the interpretability of the learned chunks enables flexible transfer between environments that share partial representational structure."
SP:625e3908502fd5be949bb915116ed7569ba84298,"This paper studies the problem of accelerating non-linear non-convex optimization problems by reparametrizing the optimization variables as the output of a graph convolutional network (GCN). The authors show that to obtain the maximum speed up, the neural network architecture needs to be a specially designed GCN. The aggregation function of the GCN is constructed from the gradients of the loss function and reduces to the Hessian in early stages of the optimization. The authors also show the utility of their method on two optimization problems: network synchronization and persistent homology optimization, and find an impressive speedup, with their method being 4 ∼ 80× faster."
SP:80346eeafb0a6d1d556c304a3f8753aff037469b,"This paper proposes SVMnet, an ensemble of support vector machines (SVMs) for non-parametric image classification. The proposed method is based on deep convolutional neural networks (DCNNs) for image classification, where the number of training samples is limited to a small number of images. The method is motivated by the fact that SVMs are faster to learn compared to DCNNs, and thus can be used for small training sets. The experimental results show that the proposed method can outperform DCNN-based methods when the size of training set is large."
SP:a18f4697f350a864866dac871f581b8fc67e8088,"This paper proposes a communication-efficient distributed GNN training technique named Learn Locally, Correct Globally (LLCG). To reduce the communication and memory overhead, each local machine in LLCG first trains a GNN on its local data by ignoring the dependency between nodes among different machines, then sends the locally trained model to the server for periodic model averaging. However, ignoring node dependency could result in significant performance degradation. To solve the performance degradation, the authors propose to apply Global Server Corrections on the server to refine the locally learned models. Extensive experiments on real-world datasets show that LLCG can significantly improve the efficiency without hurting the performance."
SP:6805f2245484fc91b5c13aa5f09e5478b810f97f,"This paper proposes a unified and end-to-end model approach for anytime pixel-level recognition. A cascade of “exits” is attached to the model to make multiple predictions and direct further computation. The authors redesign the exits to account for the depth and spatial resolution of the features for each exit. To reduce total computation, and make full use of prior predictions, the authors develop a novel spatially adaptive approach to avoid further computation on regions where early predictions are already sufficiently confident. Empirical results on semantic segmentation and human pose estimation show that the proposed approach enables anytime inference while also reducing the total FLOPs of its base models."
SP:1a75aaef7ba0d2de5804514f0de39d9c769f419b,"This paper proposes a new method for bootstrapping stochastic processes with neural networks. The proposed method, NeuBANP, learns to generate the bootstrap distribution of random functions by injecting multiple random weights into the encoder and the loss function. Experimental results on Bayesian optimization and contextual multi-armed bandit tasks show that the proposed method achieves the best performance in the sequential decision-making tasks. "
SP:34e1b51ff5d524490332aed51b9c411209c89a20,"This paper proposes a multi-modal and self-supervised pre-training method for large-scale regulatory genome data. The proposed method, called GeneBERT, takes the 1d sequence of genome data and a 2d matrix of (transcription factors × regions) as the input, where three pre-trained tasks are proposed to improve the robustness and generalizability of the model. Extensive experiments are conducted on the ATAC-seq dataset with 17 million genome sequences. "
SP:841b12443d0274e34b78940f220b17d36798899b,"This paper proposes IGEOOD, a new method for out-of-distribution (OOD) detection based on the Fisher-Rao distance between the underlying data distribution and the learned features of a deep neural network (DNN). The proposed method can be applied to any pre-trained neural network and works under different degrees of access to the ML model, does not require OOD samples or assumptions on the OOD data but can also benefit (if available) from OOD sample. The proposed model is able to combine confidence scores from the logits outputs and the features of the DNN. Empirically, the proposed method is shown to outperform competing SOTA OOD methods on a variety of network architectures and datasets."
SP:2fdca838ac3453e44cff395f1b760d839a5813bf,"This paper studies the fraction of linearly separable and group-invariant binary dichotomies that can be assigned to equivariant representations of objects subject to identity-preserving transformations that constitute a group, such as translations and rotations. The authors show that the fraction is determined by the dimension of the space that is fixed by the group action. They show how this relation extends to operations such as convolutions, element-wise nonlinearities, and global and local pooling. They also show that global pooling decreases the fraction, despite being a highly nonlinear operation. "
SP:47889067620e5ac2e304681769af9d1d930f6d2b,"This paper proposes a new method for explaining model mistakes in terms of high-level concepts that are easy for users to understand. The proposed method, called Concept Counterfactual Explanations (CCE), is based on two ideas: counterfactual explanations and concept activation vectors. The authors validate their approach on well-known pretrained models, showing that it explains the models’ mistakes meaningfully. In addition, for new models trained on data with spurious correlations, CCE accurately identifies the spurious correlation as the cause of model mistakes from a single misclassified test sample. "
SP:4aa5f00830fda36b6ca2f53d88c3a8a963058ec0,"This paper proposes a new kernel point convolution (KPConv) method to improve the efficiency and quality of KPConv. The proposed method employs a depthwise kernel to reduce resource consumption, and re-calibrates the contribution of kernel points towards each neighbor point via Neighbor-Kernel attention to improve representation power. In addition, the proposed method uses Inverted Residual Bottleneck (IRB) to craft a design space and employ a predictor-based Neural Architecture Search (NAS) approach to automate the design of efficient 3D networks based on the proposed module. Experimental results on 3D point cloud classification and segmentation benchmarks demonstrate the effectiveness of the proposed methods."
SP:bf7d2e765c435a943ec9257cfa43d070a64c2b67,"This paper investigates the relationship between data quality and adversarial robustness in adversarial training. The authors propose a method to measure the data quality based on the learning behaviors of the data during the training process. They find that low-quality data may not be useful and even detrimental to the robustness. They then design controlled experiments to investigate the interconnections between the quality of data and the problems of robust overfitting, robustness overestimation, and robustness-accuracy trade-off. The experiments show that when low quality data is removed from the training data, the problem of overfitting and overestimation can be largely alleviated, and the tradeoff of accuracy is less significant."
SP:99a36b28752bfc101877bfd0da436e6fb19c69d3,"This paper studies the number of neurons and training parameters that a neural network needs to approximate Korobov functions of bounded second mixed derivatives. The authors prove upper bounds on these quantities for shallow and deep neural networks, drastically lessening the curse of dimensionality. The bounds hold for general activation functions, including ReLU, and show that neural networks are near-optimal function approximators."
SP:a0112febb28e518e87142e7cbb7e3586d06cae0b,"This paper investigates the role of population size in the speaker-listener Lewis Game in the context of emergent communication. The authors show that the community size is not a structuring factor in language emergence by or in itself in the classic homogeneous Lewis setting. Instead, the relative difference of factors between speaker and listener is the most important factor in the emergent language properties, and the authors leverage this observation to control population heterogeneity without introducing confounding factors. "
SP:462112ea1a59ab8101ed9d908c5d838edeb844ca,"This paper studies the problem of learning high-order polynomial graph filters for heterophilic graphs. The authors propose to learn multiple adaptive polynomials acting on different subsets of the spectrum of the graph. Theoretical analysis and empirical results show that the proposed method is able to learn a better filter, thereby improving classification accuracy. "
SP:903545b1b340ec5c13070e0f25f550c444de4124,This paper proposes a method to solve the shortest distance embedding problem in graphs. The proposed method is based on the idea of betweenness centrality (BC)-based random walk followed by maximum likelihood optimization of node embeddings. The authors show that the proposed method preserves the exact shortest distance relation with respect to any calibrated node via steering optimization objective to reconstruct a global distance matrix. 
SP:13db440061fed785f05bb41d0767225403ecf7a1,"This paper proposes a new continual learning (CL) problem called Continual Knowledge Learning (CKL) to address the problem of knowledge forgetting in large language models (LMs). The authors propose a new benchmark and metric to quantify the retention of time-invariant world knowledge, the update of outdated knowledge, and the acquisition of new knowledge. The authors conduct extensive experiments to show that CKL exhibits unique challenges that are not addressed in previous CL setups, where parameter expansion is necessary to reliably retain and learn knowledge simultaneously. "
SP:639fd88482330389019fb5be7446a909b99a8609,"This paper proposes a stochastic algorithm for the criterion minimization problem of decision trees. The algorithm is based on the greedy algorithm of Breiman et al. (1984), where the goal is to find the best feature and threshold that minimizes a criterion. In this paper, the authors propose to use a non-deterministic algorithm to solve this problem. The proposed algorithm is shown to be faster than the original greedy algorithm by several orders of magnitude. The authors also show that the proposed algorithm minimizes an upper bound of the criterion. The experimental results on the MNIST dataset demonstrate the effectiveness of the algorithm."
SP:7f2640f18294519a5abb1daaa226800d2377a5e0,"This paper proposes a family of learning rate schedulers that can achieve minimax optimal convergence rates (up to a constant) for SGD on quadratic objectives when the eigenvalue distribution of the underlying Hessian matrix is skewed, which is common in practice. The authors show that the proposed eigencurve scheduler can achieve better convergence rates than step decay on CIFAR-10, especially when the number of epochs is small. Moreover, the theory inspires two simple learning rate schedules for practical applications that can approximate eigen-curve."
SP:8cfafcf0de6de33a8fd298593eeea82376b4697a,"This paper studies the problem of offline model-based reinforcement learning, where the goal is to learn a policy that maximizes the return of the agent in an offline setting. The authors propose to use a pessimistic MDP to penalize the agent when there is insufficient data to train the model, and to use the model uncertainty as a penalty to enforce the agent to learn the policy. The proposed method is based on Bayesian Optimization, and the authors compare the performance of the proposed method with a variety of uncertainty heuristics. They also investigate the effect of other hyperparameters, such as the number of models, rollout horizon, and number of agents, on the performance.  "
SP:3833662cf92249d83e65a1200f9e2890b5b23e95,"This paper proposes a method to improve the performance of off-policy MfRL algorithms by augmenting the scores computed by the critic network with learnable features from model-based RL (MbRL) components. The proposed method, called MaPER, is based on the idea that the TD-error of critic networks often overestimates Q-values, so it is often ineffective to learn to predict Q-value by sampled experiences based heavily on TD-errors. Motivated by this, the authors propose to use auxiliary features, which positively support TD-Error in calculating the scores for efficient sampling. The experimental results on various tasks demonstrate that MaPER can significantly improve performance of the state-of-the-art model-free and MbRL algorithms."
SP:0db83e057c21ac10fe91624876498d8456797492,"This paper proposes a human-in-the-loop reinforcement learning method called Human-AI Copilot Optimization (HACO) to allow the agent’s sufficient exploration in the risky environments while ensuring the training safety, the human expert can take over the control and demonstrate to the agent how to avoid probably dangerous situations or trivial behaviors. HACO extracts proxy state-action values from partial human demonstration and optimizes the agent to improve the proxy values while reducing the human interventions. The experiments show that the proposed method achieves a substantially high sample efficiency in the safe driving benchmark and achieves high safety and generalizability."
SP:7fda4f67daf3eb27cdfafe8f8a3f8d719da956c3,"This paper proposes Dual Meta Imitation Learning (DMIL), a hierarchical meta imitation learning method where the high-level network and sub-skills are iteratively meta-learned with model-agnostic meta-learning. DMIL uses the likelihood of state-action pairs from each sub-skill as the supervision for the high level network adaptation, and use the adapted highlevel network to determine different data set for each sub skill adaptation. Empirically, DMIL achieves state-of-the-art few-shot imitation learning performance on the meta-world benchmark and comparable results on the Kitchen environment."
SP:fb0efa670729796471a7a562b231172103bb8749,"This paper proposes a node embedding compression method for graph neural networks (GNNs) that uses bit vectors instead of float-points for node embeddings. The proposed method is based on the idea of hashing-based coding, where each node is represented with a bit vector instead of a float-point vector. The authors show that the proposed method can be trained together with GNNs and achieves superior performance compared to the alternatives. "
SP:15c243829ed3b2505ed1e122bd499089f8a862da,"This paper proposes to replace gradient descent with high-order ODE solvers (i.e., Runge-Kutta solvers) in the domain-adversarial training (DAD) setting. The authors derive asymptotic convergence guarantees for these solvers and show that they can be used as drop-in replacements for gradient descent in DAD. In addition, the authors show that the proposed solvers are more stable than standard optimizers and can achieve better transfer performance. "
SP:0ecbaf1770642b6ac5c9786ba2d18408310fc225,"This paper proposes iFlood, a new regularization method to prevent overfitting of machine learning models. The proposed method is based on the idea of individual Flooding (iFlood), which constrains the training loss on average to stay at a given level. However, the paper points out that the design of the loss function of Flooding can lead to a discrepancy between its objective and implementation, and cause the instability issue. To resolve these issues, this paper proposes to use instance-level constraints on training loss to encourage the trained models to better fit the under-fitted instances while suppressing the confidence on over-fitted ones. Experiments on both image classification and language understanding tasks confirm that models learned with iflood can stably converge to solutions with better generalization ability. "
SP:e6622975c9889cf6d3357ab439c2e268c4f4200e,"This paper proposes Value Function Spaces (VFS), a Hierarchical Reinforcement Learning (HRL) method for long-horizon tasks. The main idea is to use the value functions of low-level skills as action abstractions for the high-level policies. The proposed method is evaluated on a maze-solving and robotic manipulation task. The results show that the proposed method outperforms existing HRL methods on the tasks. "
SP:6adcd2a71ce70922c4cbe155d49f105964faee8f,"This paper proposes Top-n, a deterministic, non-exchangeable set creation mechanism that learns to select the most relevant points from a trainable reference set. The proposed method can replace i.i.d. generation in any VAE or GAN – it is easier to train and better captures complex dependencies in the data. Experiments on both set and graph generation tasks demonstrate the effectiveness of the proposed method."
SP:f1f1df92e3e7c6b3b9e326a78a708c0d5d990c83,"This paper studies the statistical limits of deep learning techniques for solving elliptic partial differential equations (PDEs) from random samples using the Deep Ritz Method (DRM) and Physics-Informed Neural Networks (PINNs). To simplify the problem, the authors focus on a prototype elliptic PDE: the Schrödinger equation on a hypercube with zero Dirichlet boundary condition, which is applied in quantummechanical systems. The authors establish upper and lower bounds for both methods, which improve upon concurrently developed upper bounds for this problem via a fast rate generalization bound. They also discover that the current deep Ritz method is sub-optimal and propose a modified version of it. Empirically, following recent work which has shown that the deep model accuracy will improve with growing training sets according to a power law, the paper shows similar-behavior of dimension dependent power law for deep PDE solvers."
SP:80614db60d27a48c3c1b1882844e298666b798d4,"This paper provides sufficient conditions for the correlation between robustness and generalization of ML models. Theoretical analysis is provided for several factors, such as the Jacobian norm of the last layer, data augmentation, and function class regularization. The results show that robustness induced by adversarial training is a by-product of such function-class regularization, and that DA can be viewed as regularization and therefore improve generalization. "
SP:4d49bcb069a76f108c0e2de50750827f45eb5676,This paper studies the problem of memorization in meta-learning. The authors propose a causal explanation for the memorization effect and propose two methods to mitigate it. The first method is based on the causal inference principle of front-door adjustment. The second method uses dropout to sample multiple versions of the meta-knowledge via dropout and group them into multiple bins. The experimental results show that the proposed method outperforms the baselines on four benchmark datasets.
SP:adfe205b335cf87bd4e470efd9f72bb639a4451c,"This paper proposes a novel reinforcement learning framework called ODITS, which allows the autonomous agent to adapt to arbitrary teammates in an online fashion. Instead of limiting teammates into a finite set of predefined types, ODITS automatically learns latent variables of teammates’ behaviors to infer how to cooperate with new teammates effectively. To overcome partial observability, an information-based regularizer is introduced to derive proxy representations of the learned variables from local observations. Extensive experimental results show that ODITS significantly outperforms various baselines in widely used ad hoc teamwork tasks."
SP:7b04b45c4dd237d69321d280dcdcbc89fb362015,"This paper proposes an online version of the Expectation-Maximization (EM) algorithm that uses a normalizing flow (NF) model to map the data space to a latent space. The proposed EMFlow algorithm is iterative, involving updating the parameters of online EM and NF alternatively. Extensive experimental results on high-dimensional multivariate and image datasets are presented to illustrate the superior performance of the EMFlow compared to a couple of recently available methods in terms of both predictive accuracy and convergence speed."
SP:a151ae8afae0a073b0df83a74fd084dfe3753a48,"This paper proposes deep linearly gated networks (DLGN) for deep neural networks (DNNs) with rectified linear units (ReLUs). The authors extend the recently developed dual view in which the computation is broken path-wise to show that learning in the gates is more crucial, and learning the weights given gates is characterised analytically via the neural path kernel (NPK) which depends on inputs and gates. The authors show that convolution with global pooling and skip connection provide respectively rotational invariance and ensemble structure to the NPK. The DLGN disentangles the computations into two ‘mathematically’ interpretable linearities (i) the primal linearity between the input and the preactivations in the gating network and (ii) the ‘dual’ linearity in the path space in the weights network characterised by the Neural Path kernel. The experiments on CIFAR-10/100 show that the DLGN recovers more than 83.5% of the performance of the DNNs."
SP:5676944f4983676b5ad843fdb190bf029ad647bb,"This paper proposes Dynamic Token Normalization (DTN), a new normalization method for vision transformers (ViTs) that can capture both long-range dependencies and local positional context. The proposed method is built on a unified formulation and can represent various existing normalization methods. Extensive experiments show that the proposed DTN can achieve better performance with minimal extra parameters and computational overhead."
SP:7a04efbf835c238bbdf70a8b8decee4ec2907a3a,"This paper proposes a method to measure the spectral bias of deep neural networks trained with SGD. The authors show that these networks exhibit spectral bias, and that interventions that improve generalization sometimes increase and sometimes decrease the frequencies of the learned function. They also explore the connections between function frequency and image frequency and find that spectral bias is sensitive to the low frequencies prevalent in natural images."
SP:9ef61f2064db8ac3b01b16694a744b274bdbbe83,"This paper studies mode-switching, non-monolithic exploration for RL. The authors investigate different modes to switch between, at what timescales it makes sense to switch, and what signals make for good switching triggers. They also propose practical algorithmic components that make the switching mechanism adaptive and robust, which enables flexibility without an accompanying hyper-parameter-tuning burden. Finally, they report a promising and detailed analysis on Atari, using two-mode exploration and switching at sub-episodic time-scales."
SP:c44d3749d8883fae7eb2a6378417fca28d25a4c9,"This paper proposes a new initialization scheme for the k-median problem in the general metric space (e.g., discrete space induced by graphs), based on the construction of metric embedding tree structure of the data. From the tree, the authors propose a novel and efficient search algorithm for good initial centers that can be used subsequently for the local search algorithm. The method, named the HST initialization, can also be easily extended to the setting of differential privacy (DP) to generate private initial centers. Theoretically, the initial centers from HST initialized can achieve lower error than those from another popular initialization method, k-Median++, in the non-DP setting. Moreover, with privacy constraint, the error of applying DP local search followed by our private initialization improves previous results, and approaches the known lower bound within a small factor."
SP:84c9eb6623e7950585d80a664dd51b3ecc356dea,"This paper proposes a new architecture for video prediction, named FitVid, which aims to address the problem of underfitting in video prediction models. The authors argue that the inefficient use of parameters in the current video models is the main reason for underfitting. To address this issue, the authors propose a novel architecture that is capable of fitting the common benchmarks so well that it begins to suffer from overfitting – while having similar parameter count as the current state-of-the-art models. They analyze the consequences of overfitting, and show that it can produce unexpected outcomes such as generating high quality output by repeating the training data, and how it can be mitigated using existing image augmentation techniques."
SP:6eb5ce1d85928a3af759d75016089c535941d0b0,"This paper studies the influence of data structure on test loss dynamics of stochastic gradient descent (SGD) in the setting of training on features with arbitrary covariance structure. To this end, the authors propose an exactly solveable model of SGD that predicts test loss when training on Gaussian features and arbitrary features. They show that the simpler Gaussian model can accurately predict test loss of nonlinear random-feature models and deep neural networks trained with SGD on real datasets such as MNIST and CIFAR-10. They also show that optimal batch size at a fixed compute budget is typically small and depends on the feature correlation structure. "
SP:a530dd966911e387a90e3cbf9f51c8cab6152723,"This paper studies the behavior of SGD in non-convex non-linear optimization problems. The authors show that SGD may converge to local maxima, SGD might escape saddle points arbitrarily slowly, and SGD can prefer sharp minima over flat ones. They also show that AMSGrad may not converge to the local minima.    The main contribution of this paper is to show that the learning rate needs to be chosen carefully to guarantee convergence."
SP:22d01913b78ef447b064c65a646fa301b861d3f7,"This paper proposes a method for hyperparameter optimization in meta-learning. The proposed method is based on the idea of knowledge distillation, where the second-order term is approximated by a single Jacobian-vector product (JVP) for each HO step and minimize the distance from the true second order term. The method is shown to be scalable to high-dimensional hyperparameters and the horizon length, and achieves good performance at convergence. "
SP:a64b26faef315c3ece590322291bab198932c604,"This paper proposes a new meta-learning method for few-shot image classification and cold-start recommendation tasks. The proposed method is based on clustering and task-aware learning, where the task-specific optimization process is carried out on the global meta-learner and the global base learner is optimized for the downstream clustering task. The method is evaluated on two real-world tasks and compared with several baselines. "
SP:f7a7c81ed2b6e9eb958b8b751deed8166622540c,This paper proposes an ensemble-based semi-supervised novelty detection method for OOD detection. The proposed method is based on a mixture of unlabeled ID and OOD samples to achieve good detection performance on near OOD data. It relies on regularization to promote diversity on the OOD and ID data while preserving agreement on ID data. Extensive experiments on standard image data sets and medical data sets demonstrate the effectiveness of the proposed method.
SP:a0ee0e08b4bb578836fd5e0781e8713f254569fb,"This paper proposes Latent Variable Sequential Sequential Set Transformers (LVSST), an encoder-decoder architecture for scene-consistent multi-agent trajectories. The encoder is a stack of interleaved temporal and social multi-head self-attention modules which alternately perform equivariant processing across the temporal and Social dimensions. The decoder can produce either the trajectory of one ego-agent or a distribution over the future trajectories for all agents in the scene. The proposed model achieves top results on the global nuScenes vehicle motion prediction leaderboard, and produces strong results on Argoverse vehicle prediction challenge."
SP:e253d49bbfadb76b2f7c4e7cdd1cc33d0cebc3e7,This paper presents a user study to evaluate how well users can identify the relevant set of attributes compared to the ground-truth. The authors propose a baseline explanation technique to explain image classification models. The baseline explanation is a combination of concept-based and counterfactual explanations. The results show that the baseline explanation outperforms the concept explanations. 
SP:6495caf14ebb8b9c3cbf50a5f05ec1eb600864fe,"This paper proposes a method to defend against backdoor data poisoning attacks by injecting malicious data into the training distribution. The authors propose an iterative training procedure to remove poisoned data from the training set. They first train an ensemble of weak learners to automatically discover distinct subpopulations in the training data and then leverage a boosting framework to exclude the poisoned data and recover the clean data. The proposed method is based on a novel bootstrapped measure of generalization, which provably separates the clean from the dirty data under mild assumptions. Empirically, the proposed method successfully defends against a state-of-the-art dirty label backdoor attack. "
SP:f0ad7cbc190113bb4612b7beca98d07aeff661fd,"-based multi-label text classification (MLTC) aims to assign a set of labels to each given document. This paper proposes to use latent label representations to model label correlations implicitly. Specifically, the proposed method concatenates latent labels (instead of actual labels) to the text tokens, inputs them to BERT, then maps the contextual encodings of these latent labels to actual labels cooperatively. The proposed method is conceptually simple but quite effective. It improves the state-of-the-art results on two benchmark datasets by a large margin."
SP:6e54083a06942f2c41e1796a9f911d3dd9bab0cc,"This paper studies the RKHS norm of convolutional kernel networks. The authors show that the norm of the kernel consists of additive models of interaction terms between patches, and that its norm encourages spatial similarities between these terms through pooling layers. They then provide generalization bounds which illustrate how pooling and patches yield improved sample complexity guarantees when the target function presents such regularities. "
SP:7bee8d65c68765cbfe38767743fec27981879d34,"The Neural Tangent Kernel (NTK) is the outer product of the Jacobians of a neural network (NN) Jacobian. The NTK can be computed analytically and is useful for understanding training and generalization of NN architectures. Unfortunately, the finite width NTK is notoriously expensive to compute, which severely limits its practical utility. This paper provides the first in-depth analysis of the compute and memory requirements for NTK computation in finite width networks. It further proposes two algorithms that change the exponent of the computed NTK, dramatically improving efficiency."
SP:1df605fc5fc828304f7b836724d8fd6c233ff80c,"This paper proposes a method for offline constrained reinforcement learning, where the goal is to learn a policy that maximizes the expected return while satisfying cost constraints. The authors propose a method that directly estimates the stationary distribution corrections of the optimal policy with respect to returns, while constraining the cost upper bound, with the goal of yielding a cost-conservative policy for actual constraint satisfaction. The proposed method, called COptiDICE, is motivated by recent advances in off-policy confidence interval estimation (Dai et al., 2020). The authors show that the proposed method outperforms several baselines in terms of constraint satisfaction and reward-maximization."
SP:5a10c13eb78d26a25dac74601419deb68c53cb75,This paper proposes a method for parallelizing Gated Recurrent Unit (GRU) training using a multigrid reduction in time (MGRIT) solver. The MGRIT solver partitions a sequence into multiple shorter sub-sequences and trains the subsequences on different processors in parallel. The key to achieving speedup is a hierarchical correction of the hidden state to accelerate end-to-end communication in both the forward and backward propagation phases of gradient descent. Experimental results on the HMDB51 dataset show that the proposed method achieves up to 6.5x speedup over a serial approach.
SP:fb935a5c44d7df6958d39ab1ef877956df08994e,"This paper proposes a method to learn a common embedding of fMRI data from multiple subjects in an experiment while retaining the ability to decode to individual raw fMRI signals. The authors assume that while noise varies significantly between individuals, true responses to stimuli will share common, low-dimensional features between subjects which are jointly discoverable. They show that their learned common space represents an extensible manifold (where new points not seen during training can be mapped), improves the classification accuracy of stimulus features of unseen timepoints, as well as improves cross-subject translation."
SP:95ed80753116005f1f7bae24c855d350f4af85a1,"This paper proposes a new benchmark for out-of-distribution detection for multi-class, multi-label, and multi label segmentation tasks. The benchmark is based on ImageNet-21K, which is a large-scale multiclass dataset with thousands of classes. The authors also introduce a new dataset of anomalous species. The results show that the proposed MaxLogit detector outperforms all baselines on the new benchmark. "
SP:abbab40e40ef09c8dccd16661af3c2a4461ebb1a,"This paper studies the structure of tournaments that arise out of d dimensional representations. The authors show that the tournament classes have forbidden configurations which must necessarily be union of flip classes, a novel way to partition the set of all tournaments. They further characterize rank 2 tournaments completely by showing that the associated forbidden flip class contains just 2 tournaments. This insight allows them to solve the minimum feedback arc set problem on this tournament class using the standard Quicksort procedure."
SP:d39765dcc8950d4fc1d43e4c167208736578882e,"This paper proposes a stochastic attention mechanism for neural processes (NPs) to capture appropriate context information. Specifically, the proposed method encourages the context embedding to be differentiated from a target dataset, allowing NPs to consider features in the target dataset and context embeddings independently. The proposed method is empirically shown to outperform conventional NPs in various domains through 1D regression, predator-prey model, and image completion."
SP:f6e7229b653a5a56a2993864cdb70809f5b6f9b4,"This paper proposes Proto-Trex, a method for interpretability and explainability of Transformer-based language models. The main idea is to use prototype networks directly incorporated into the model architecture to explain the reasoning process behind the network’s decisions. The proposed method is evaluated on a number of NLP tasks. The results show that the proposed method performs on par with several language models in terms of interpretability. "
SP:60ba9cb4c42cecde6379ec0279434dece822a2b1,"This paper proposes Trust Region Gradient Projection (TRGP) for continual learning to facilitate the forward knowledge transfer based on an efficient characterization of task correlation. TRGP selects the most related old tasks for the new task in a layer-wise and single-shot manner, using the norm of gradient projection onto the subspace spanned by task inputs. Then, a scaled weight projection is proposed to cleverly reuse the frozen weights of the selected old tasks in the trust region. Experiments show that TRGP achieves significant improvement over related state-of-the-art methods."
SP:25414fe1c6203f9b623c5317a4ffaba478085c4c,"This paper proposes a generalization bound for linear regression based on the length of the optimization trajectory after convergence of the gradient flow algorithm. The authors show that, with a proper initialization, gradient flow converges following a short path with an explicit length estimate, which induces a length-based bound for the generalization error. They show that short optimization paths after convergence indicate good generalization. The framework can be applied to generalization bounds on linear regression, kernel regression, and ReLU neural networks. "
SP:a9e5d81f7ba88f4052730f255cf48cb40ed80942,"This paper presents a frequency-based understanding of adversarial examples, which is motivated by the common misconception that adversarial example are high-frequency noise. The authors show that the majority of examples are not in high frequency nor in low-frequency components, but are simply dataset dependent. They highlight the glaring disparities between models trained on CIFAR-10 and ImageNet-derived datasets, and analyze many intriguing properties of training robust models with frequency constraints, and propose to explain the commonly observed accuracy-robustness trade-off."
SP:5d94dbfd10dc2ef86415853cc41f414a24962d4f,"This paper proposes a new metric to measure the heterophily of GNNs. The proposed metric is based on a similarity matrix that considers the influence of both graph structure and input features on the GNN. The authors show that not all cases of homophily are harmful for GNN with aggregation operation. Based on the proposed metrics, the authors propose a method to address the harmful cases. The method is called Adaptive Channel Mixing (ACM) that exploits aggregation, diversification and identity channels in each GNN layer to address harmful heterophilies. "
SP:fd4ab1cb777b541c22a923c1c86d82ac1d8384fd,"This paper proposes a deep reinforcement learning method for solving small-sized instances of traveling salesman problems (TSP). The proposed method is based on a graph neural network (GNN), a multi-layer perceptron (MLP), and an attention mechanism. The proposed model is trained on small random instances (up to 50 cities) and performs competitively on larger random or realistic TSPs. "
SP:8aa471b92e2671d471107c087164378f45fb204f,"This paper proposes a new method for federated learning with synthetic data. The idea is to train a local GAN to generate synthetic data, which are uploaded to the parameter server (PS) to construct a global shared synthetic dataset. The PS is responsible for generating and updating high-quality labels for the global dataset via pseudo labeling with a confident threshold before each global aggregation. A combination of the local private dataset and labeled synthetic dataset leads to nearly identical data distributions among clients, which improves the consistency among local models and benefits the global aggregation process. Extensive experiments demonstrate the effectiveness of the proposed method."
SP:7656b0bd5eb7e46359d8111e5534a07744f5d7ae,"This paper proposes a simple training method to improve the certified robustness of smoothed classifiers by controlling the sample-wise control of robustness over the training samples. To do so, the authors propose to use the “accuracy under Gaussian noise” as an easy-to-compute proxy of adversarial robustness for each input. They differentiate the training objective depending on this proxy to filter out samples that are unlikely to benefit from the worst-case (adversarial) objective. The experimental results show that the proposed method can significantly improve the previous state-of-the-art results."
SP:8fdfed1c38ae00a0063ab41f72fa26826f5f4570,"This paper proposes to remove padding tokens from the Wikipedia pre-training dataset to speed up the training of BERT. The authors show that at sequence length 512 padding tokens represent in excess of 50% of the Wikipedia dataset used for pretraining BERT (Bidirectional Encoder Representations from Transformers). By removing all padding tokens, they achieve a 2x speed-up in terms of sequences/sec. To exploit this characteristic of the dataset, the authors develop and contrast two packing algorithms. The shortest-pack-first histogram-packing (SPFHP) algorithm determines the packing order for Wikipedia dataset of over 16M sequences in 0.03 seconds. The non-negative least-squares histogram packing (NNLSHP) algorithms converges in 28.4 seconds but produces solutions which are more depth efficient, managing to get near optimal packing by combining a maximum of 3 sequences in one sample. Finally, they pretrain BERT-Large using the packed dataset, demonstrating no loss of convergence and the desired 2x speeds-up."
SP:460d4cc1a5c01e34abe37d9eb1b74dd3734b1d55,"This paper proposes an adaptive tree search algorithm that can find high-scoring outputs under translation models that make no assumptions about the form or structure of the search objective. This algorithm enables the exploration of new kinds of models that are unencumbered by constraints imposed to make decoding tractable, such as autoregressivity or conditional independence assumptions. When applied to autoregressive models, the proposed algorithm has different biases than beam search has, which enables a new analysis of the role of decoding bias in autoregression models. Empirically, the authors show that their adaptive tree-search algorithm finds outputs with substantially better model scores compared to beam search in autorgressive models. They also characterise the correlation of several translation model objectives with respect to BLEU. "
SP:ff7b9e6ff5303f8a4f0321d06d9d9573e4853c5f,"This paper proposes a method for learning to detect anomalies using an energy based model (EBM). The EBM uses Langevin Dynamics (LD) to generate incorrect samples based on an iterative optimization procedure, alleviating the intractable problem of modeling the world of anomalies. To avoid training an anomaly detector for every task, the proposed method uses an adaptive sparse coding layer to quickly update what is normal during inference time to avoid tedious data collection. Empirical results show that the proposed framework is able to efficiently adapt to a novel task with a few normal samples on both industrial inspection and video surveillance tasks."
SP:801a61d01d3b159f301013b182150a80fbfe8fa2,"This paper studies the problem of misinformation in question answering (QA) systems. The paper presents a large-scale dataset for this problem, CONTRAQA, which contains over 10K human-written and model-generated contradicting pairs of contexts. The authors show that QA models are vulnerable under contradicting contexts brought by misinformation. To defend against such threat, they build a misinformation-aware QA system as a counter-measure that integrates question answering and misinformation detection in a joint fashion."
SP:7effe51275b9b2e14b3e099533e410e09f5b7c5a,"This paper proposes Gromov-Wasserstein Imitation Learning (GWIL), a method for cross-domain imitation learning that uses the distance between the expert and imitation agents to align and compare states between the different spaces of the agents. The authors show that GWIL preserves optimality in the case of a single demonstration from another domain. They also provide a theoretical analysis of the case where GWIL does not preserve optimality. Finally, GWIL is evaluated in continuous control domains. "
SP:9ec000cd9c15e3c9988a41921c465b42e7d41877,"This paper proposes a new self-supervised learning method called Hierarchical Cross Contrastive Learning (HCCL) to further distill the information mismatched by the conventional contrastive loss. HCCL uses a hierarchical projection head to project the raw representations of the backbone into multiple latent spaces and then compares latent features across different levels and different views. By cross-level contrastive learning, the proposed method not only regulates invariant on multiple hidden levels but also crosses different levels, improving the generalization ability of the learned visual representations. Extensive experimental results show the effectiveness of the method on classification, detection, segmentation and few-shot learning tasks."
SP:943b0a3f94ba270bb7c0dc1e1f363e53bc5cf8ae,"This paper proposes a multi-agent deep reinforcement learning (RL) framework for learning dynamic general equilibrium (DGE) models of real-world economic systems with heterogeneous, interacting strategic agents of various agent types, such as consumers, firms, and governments. The authors propose to learn a spectrum of meta-game-Nash Nash equilibria for a meta game over agent types in economic simulations with many agents, through the use of structured learning curricula and efficient GPU-only simulation and training. The proposed method is more flexible and does not need unrealistic assumptions, e.g., market clearing, that are commonly used for analytical tractability. "
SP:f885c992df9c685f806a653398736432ba38bd80,This paper proposes a method to prevent model extraction attacks by requiring users to complete a proof-of-work before they can read the model’s predictions. This deters attackers by greatly increasing (even up to 100x) the computational effort needed to leverage query access for model extraction. The method requires no modification of the victim model and can be applied by machine learning practitioners to guard their publicly exposed models.
SP:39845a353e75e2f854c3dc649db3817d89ad9875,"This paper proposes a multi-resolution variant of the continuous normalizing flow (CNF) model for image generation and density estimation. The proposed method is based on the notion of conditional distribution over the additional information required to generate a fine image that is consistent with the coarse image. The authors introduce a transformation between resolutions that allows for no change in the log likelihood. They show that this approach yields comparable likelihood values for various image datasets, using orders of magnitude fewer parameters than the prior methods, in significantly less training time, using only one GPU."
SP:d09c2fad308249261a9742505e4ccaed2b3578b3,"This paper proposes a training-free method to detect noisy labels given good representations. The proposed method is based on the observation that good representations help define “neighbors” of each training instance, and closer instances are more likely to share the same clean label. Based on the neighborhood information, the authors propose two methods: the first one uses “local voting” via checking the noisy label consensuses of nearby representations, and the second one is a ranking-based approach that scores each instance and filters out a guaranteed number of instances that are likely to be corrupted, again using only representations. "
SP:ae81e2a23bf6042bf8b04ba41b957bb625268b7e,"This paper proposes a novel adversarial attack method for adversarial reinforcement learning. The proposed method is based on a collaboration between an actor and an RL-based learner. The actor is trained to find the optimal state perturbations for a given policy perturbation direction, and the director learns to propose the best policy perturbing directions. Theoretical analysis shows that the optimal policy in PAMDP induces an optimal state adversary. Empirical results show that the proposed method outperforms state-of-the-art attacking methods in various Atari and MuJoCo environments."
SP:f7b7dfafb03090a2c940ba738234a6c80bd5ad0e,This paper proposes a novel policy generation method for multi-objective reinforcement learning. The proposed method is based on a novel metric to measure the difference between policies. The novelty of a policy is defined as the difference in reward between a policy and a set of policies that are close to each other in terms of the cumulative reward. This metric is then used to evaluate the novelty of different policies in a constrained optimization setting. A novel policy seeking algorithm is proposed based on the interior point method commonly used in the constrained optimization literature. The experimental results show that the proposed method can generate diverse and well-performing policies compared to existing methods. 
SP:82b7860146bf3f772bdcd5b448d62136ff6d5177,"This paper proposes a method to deverberate speech from audio-visual observations. The proposed method is based on a multi-modal modeling approach and a novel reverb-visual matching loss. The method is evaluated on both simulated and real imagery for speech enhancement, speech recognition, and speaker identification, and achieves state-of-the-art performance."
SP:7abf578ef0d3b67d87437bdd1cff129f72c102c6,"This paper proposes a new position representation method, Attention with Linear Biases (ALiBi), to enable extrapolation at inference time for sequences that are longer than the ones seen during training. ALiBi does not add positional embeddings to the word embedding, but instead it biases query-key attention scores with a penalty that is proportional to their distance. The proposed method trains a 1.3 billion parameter model on input sequences of length 1024 that extrapolates to input sequences with length 2048, achieving the same perplexity as a sinusoidal position embedding model trained on inputs of length 2048 but training 11% faster and using 11% less memory."
SP:45ba2709aca444f50a133d71f33be9d2c1f887e8,"This paper studies the problem of multi-objective online convex optimization in the unconstrained max-min setting. The authors propose a new dynamic dynamic regret algorithm that is equivalent to the regret commonly used in the zero-order bandit setting and overcomes the problem that the latter is hard to optimize via first-order gradient-based methods. They also propose the Online Mirror Multiple Descent algorithm with two variants, which computes the composite gradient using either the vanilla min-norm solver or an L1-regularized solver. The regret bounds of both variants are derived. Extensive experiments demonstrate the effectiveness of the proposed algorithm and verify the theoretical advantage."
SP:d07fd26d0cb245e1fd1343472dd3c8300c39752a,"This paper proposes a generative replay method for continual learning, where the goal is to learn a classifier incrementally across a large number of training experiences. The proposed method is based on the idea of generating negative examples (or antagonists) to learn the new classes. The authors show that the generated negative examples can be used as negative examples to learn new classes, especially when the learning experiences are small and contain examples of just one or a few classes. "
SP:ec18e1450dd918b1ca95e301bc9262e072d77b52,"This paper proposes an inductive graph partitioning (IGP) framework to alleviate the NP-hardness of graph partition (GP) problems. IGP first conducts the offline training of a dual graph neural network on historical graph snapshots to capture properties of the system. The trained model is then generalized to newly generated graphs for fast high-quality online GP without additional optimization, where a better trade-off between quality and efficiency is achieved. The proposed IGP is also a generic framework that can capture the permutation invariant GP ground-truth of historical snapshots in offline training and tackle the online GP on graphs with non-fixed number of nodes and clusters. Experiments on a set of benchmarks demonstrate the effectiveness of IGP."
SP:ad28c185efd966eea1f44a6ff474900812b4705a,"This paper proposes a hierarchical generative model for graph generation that is multiresolution and equivariant with respect to node ordering. The proposed method is based on a hierarchical variational autoencoder (HVAE) model that uses a hierarchical clustering procedure to partition the graph into mutually exclusive clusters and coarsening into a lower resolution that eventually creates a hierarchy of latent distributions. Experiments are conducted on several graph generation tasks including graph generation, molecular generation, unsupervised molecular representation learning, link prediction on citation graphs, and graph-based image generation. "
SP:29e2e1daa6a32ef71ad225bd2fc27e33dece86c5,"This paper proposes a general framework for nonlinear ICA, in which the mixing function is assumed to be a volume-preserving transformation, and the conditions on the sources can be much looser. The authors provide an insightful proof of the identifiability of the proposed framework, and verify their theory by experiments on artificial data and synthesized images. They conduct experiment on both synthetic and real-world data to verify the theory."
SP:288ce587a277299765bdd4cea75a8c23e12de2b0,"This paper proposes a new graph convolutional network (GCN) architecture, called BankGCN, which extends the capabilities of most MPGCNs beyond single ‘low-pass’ features and simplifies spectral methods with a carefully designed sharing scheme between filters. It decomposes multi-channel signals on arbitrary graphs into subspaces and shares adaptive filters to represent information in each subspace. The filter bank representation is regularized to favour diversity in the frequency responses, in order to properly capture various spectral components in the graph signals. Experiments on several graph classification tasks demonstrate the effectiveness of the proposed method."
SP:3abcd0700eaf11d964c280d996a1dd4f34280b1c,"This paper proposes a new supervised pre-training method based on k-nearest-neighbor (kNN) classification to improve the transferability of the pre-trained model to downstream tasks. The proposed method is based on a kNN classifier to replace the linear or MLP predictor in the last layer of deep neural network, and a leave-one-out classification error is used as the loss function for optimization. Extensive empirical studies on multiple downstream tasks show that LOOK outperforms other state-of-the-art methods for supervised and self-supervised pretraining."
SP:2b3916ba24094c286117126e11032820f8c7c50a,This paper proposes a method to generate facial details from a single image that are consistent with any desired target expression. The proposed method is based on the idea of hallucinating facial geometric details consistent with the target expression and then adding them to a smooth proxy geometry. This proxy geometry is then used by a neural renderer to render novel images of any single image in any desired expression and view. 
SP:c7c50c44fdafb15b962e04d713cac309e57bc54b,"This paper proposes an unsupervised disentanglement of syntactic roles using a Transformer-based generative model with attention. The proposed model is based on an attention-driven variational autoencoder (ADVAE) architecture, which is inspired by Transformer VAEs. The authors show that the proposed model disentangles syntactic role better than standard sequence VAEs and Transformer models, and that it is capable of controlling realizations of syntactical roles separately during generation. "
SP:57ace99a05a76b7d7427619cb6881fc87d74160f,"This paper proposes a method for multi-agent reinforcement learning with sparse rewards and partial observability. In particular, the authors propose to reward agents for contributing to a more diversified team behavior by employing proper intrinsic motivation functions to learn meaningful coordination protocols. To this end, they propose a novel framework, where at each timestep, an agent simulates counterfactual rollouts of its policy and, through a sequence of computations, assesses the gap between other agents’ current behaviors and their targets. Actions that minimize the gap are considered highly influential and are rewarded. Empirical results show the effectiveness of the proposed method on a comprehensive set of challenging tasks."
SP:66784b2f0f08680057670dfea49a4ae88f7a2b38,"This paper proposes MEND, a post-hoc model editing method for large pre-trained language models. The main idea of MEND is to learn to transform the gradient obtained by standard fine-tuning, using a low-rank decomposition of the gradient to make the parameterization of this transformation tractable. MEND can be trained on a single GPU in less than a day even for 10 billion+ parameter models. Once trained, MEND enables rapid application of new edits to the pre-train model."
SP:ea9a6880083555a89f5ed22dca21ba2dc109c1a2,"-based physics-aware neural network (FINN) is proposed for learning spatiotemporal advection-diffusion processes. The proposed method combines the learning abilities of artificial neural networks with physical and structural knowledge from numerical simulation by modeling the constituents of partial differential equations (PDEs) in a compositional manner. Results on one and two-dimensional PDEs (Burger's, diffusion-sorption, Allen-Cahn, and diffusion-reaction) demonstrate the superior modeling accuracy and excellent out-of-distribution generalization ability."
SP:d369e2144544908fbcaaa53aab9555d71080ced8,"This paper presents an analysis of the brain representations of code generated by unsupervised machine learning (ML) models and representations of computer programs in the human brain. They analyze recordings from functional magnetic resonance imaging (fMRI) studies of people comprehending Python code. They discover brain representations that encode static and dynamic properties of code such as abstract syntax tree (AST)-related information and runtime information. They also map brain representations to representations of a suite of ML models that vary in their complexity. They find that the Multiple Demand system, a system of brain regions previously shown to respond to code, contains information about multiple specific code properties, as well as machine learned representation of code. "
SP:ab5a8934846776a7be7d0ac1973d41fd6aae89fc,"This paper presents Translatotron 2, a neural direct speech-to-speech translation model that can be trained end to end. The proposed model consists of a speech encoder, phoneme decoder, mel-spectrogram synthesizer, and an attention module that connects all the previous three components. Experimental results show that TranslatTron 2 outperforms the original TranslatOTron by a large margin in terms of translation quality and predicted speech naturalness, and drastically improves the robustness of the predicted speech by mitigating over-generation, such as babbling or long pause. The authors also propose a new method for retaining the source speaker’s voice in the translated speech."
SP:296102e60b842923c94f579f524fa1147328ee4b,"This paper studies the problem of few-shot attribute learning, where the task is to learn a representation of a semantic class from a set of attributes that were not previously labeled. The authors propose a method to learn the representation of the attributes from a small number of training examples, and then use this representation to train a classifier to predict the attributes of the test attributes. They show that supervised learning with training attributes does not generalize well to new test attributes, whereas self-supervised pre-training brings significant improvement. They also show that the predictability of test attributes provides an informative estimate of a model’s generalization ability. "
SP:0f69e20b9f97439d19e7a93144c8d877cedcd714,"This paper proposes REGS, a particle sampling method for sampling from unnormalized distributions. REGS is based on the Wasserstein gradient flow of relative entropy, which is defined as a sequence of simple nonlinear transforms iteratively pushing the initial samples from a reference distribution into the samples from an unnormalised target distribution. The authors propose a novel nonparametric approach to estimate the density ratios and simulate the ODE system with particle evolution. Extensive simulation studies on challenging multimodal 1D and 2D mixture distributions and Bayesian logistic regression on real datasets demonstrate that REGS outperforms the state-of-the-art sampling methods."
SP:a69b894166482ccd7a3a9db53e0f5a7e6ecff89a,"This paper proposes a method to classify larger, realistic images using quantum systems. The approach relies on a novel encoding mechanism that embeds images in quantum states while necessitating fewer qubits than prior work. The proposed method is able to classify images that are larger than previously possible, up to 16x16 for the MNIST dataset on a personal laptop, and obtains accuracy comparable to classical neural networks with the same number of learnable parameters. "
SP:acf3825e96d1b7c66cdc339fc5de77330b8e8e90,"-based federated learning is a popular method for face recognition. This paper proposes a differentially private local clustering (DPLC) mechanism to distill sanitized clusters from local class centers. A consensus-aware recognition loss encourages global consensuses among clients, which results in more discriminative features. Extensive experiments and ablation studies on a large-scale dataset have demonstrated the efficacy and practicability of the proposed method."
SP:408d9e1299ee05b89855df9742b608626692b40d,"This paper proposes a method for transfer learning from source domain to target domain. The proposed method, Head-to-Toe probing (HEAD2TOE), selects features from all layers of the source model to train a classification head for the target-domain. The method is evaluated on the Visual Task Adaptation Benchmark (VTAB) and compared with fine-tuning and linear probing. The results show that the proposed method can outperform fine-tuneing on OOD target domains."
SP:d6f11fb32851f97af287f962f83220d27a8bc76a,"This paper proposes an object-oriented text dynamics model (OOTD) to solve decision-making problems in text-based games. OOTD predicts a memory graph that dynamically remembers the history of object observations and filters object-irrelevant information. To improve the robustness of dynamics, the model identifies the objects influenced by input actions and predicts beliefs of object states with independently parameterized transition layers. The authors develop variational objectives to model the stochasticity of predicted dynamics. Empirical results show that the proposed model significantly outperforms model-free baselines."
SP:3e5ac4add9ab8a986fdf027b6e6a7d59698b3031,"This paper studies the problem of cost-sensitive hierarchical classification where a label taxonomy has a cost sensitive loss associated with it, which represents the cost of (wrong) predictions at different levels of the hierarchy. The authors propose a method that breaks the hierarchical learning problem into layer-by-layer learning-to-abstain sub-problems. They show that there is a bijective mapping between the original hierarchical loss and the set of layer-wise abstaining losses under symmetry assumptions. They employ the distributionally robust learning framework to solve the learning to abstain problems in each layer. "
SP:7997a1b59ef2fc0127c3fff02d191f5d655168f8,This paper proposes to learn a group of parameterized synperiodic filter banks to process sound waveforms that have limited time-frequency resolution capability. The proposed method is based on a Transformer-like backbone network with two parallel soft-stitched branches to learn semantic identity label and spatial location representation semi-independently. Experiments on both direction of arrival estimation task and the physical location estimation task shows that the proposed method outperforms existing methods by a large margin.
SP:8bc53935566be2b70403f4b46fe94686d5eae1a1,"This paper studies the problem of gradual domain adaptation, where the goal is to gradually shift the model towards the target distribution rather than learning domain invariant representations. The authors propose a method called GIFT (Gradual Interpolation of Features toward Target) that creates virtual samples from intermediate distributions by interpolating representations of examples from source and target domains. They show that under two assumptions: (i) access to intermediate distributions, and (ii) samples annotated with the amount of change from the source distribution, self-training can be successfully applied on gradually shifted samples to adapt the model toward the target domain. In the absence of these two assumptions, the authors observe that iterative self training falls short. To address this issue, they propose to use interpolation of features as intermediate examples to create a curriculum of samples which helps the model to adapt better to the target."
SP:862d6d76692aee384adc70fd845f0b89cfda93d3,"This paper proposes a method for multi-modal video-text retrieval based on video, video titles, and comments. The proposed method is based on an attention-based mechanism that allows the model to disregard text with irrelevant content. The experiments show that the proposed method can learn better, more contextualised, representations, while also achieving competitive results on standard video and text retrieval benchmarks."
SP:a35eb46f391e1a1e347e7243245ca69f4c0f129f,"This paper proposes DISDAIN, an exploration bonus for unsupervised skill learning, which aims to encourage the discriminator to visit states in which it is less confident about classifying the skill. The authors propose to train an ensemble of discriminators and reward the policy for their disagreement. The discriminator disagreement intrinsic reward is motivated by the epistemic uncertainty that comes from not having seen enough training examples, thus providing an intrinsic reward more tailored to the true objective compared to pseudocount-based methods (Burda et al., 2019). Experiments on tabular grid world and Atari suite demonstrate the effectiveness of the proposed method."
SP:4eafae76b923b75534cd28e6e04774ea69e3c2d1,"This paper proposes a spanning tree-based graph generation (STGG) framework based on formulating molecular graph generation as a construction of spanning tree and the residual edges. Based on the intermediate graph structure of the construction process, the proposed method can constrain its generation to molecular graphs that satisfy the chemical valence rules. The authors also newly design a Transformer architecture with tree based relative positional encodings for realizing the tree construction procedure. Experiments on QM9, ZINC250k, and MOSES benchmarks verify the effectiveness of the proposed framework in metrics such as validity, Fréchet ChemNet distance, and fragment similarity."
SP:3a19340d6af65e3f949dda839a6d233369891c46,"This paper proposes a spectral analysis of the Neural Tangent Kernel (NTK) of Polynomial Neural Networks (PNNs), which is a recently proposed parametrization of PNNs. Based on this analysis, the authors show that the NTK of the PNN is biased towards low-frequency functions, which results in a faster learning of low frequency components during training. The authors further show that this bias is due to the use of the recently proposed $\rho$-Net family, which is an extension of the previously proposed \rho-Net. The results are verified through extensive experiments. "
SP:ebed8b8a25cead3629832c2ba52caf0059971d3d,"This paper proposes a method to identify hidden subnetworks in sparse neural networks (NNs) that are not only ""hidden"" in the random networks but also ""disguised"" – hence can only be “unmasked” with certain transformations on weights. The method is based on a recent work (Ramanujan et al., 2020) that showed that there exist hidden subnetwork in randomly initialized NNs that have good performance without training the weights. However, such “hidden sub-networks” have mediocre performances and require an expensive edge-popup algorithm to search for them. In this work, the authors define an extended class of sub-nets in randomly-initialized NNs called “sub-nets” and propose a two-stage algorithm that plays a Peek-a-boo (PaB) game to identify the disguised subnetwork with a combination of two operations: (1) searching efficiently for a subnetwork at random initialization; (2) unmasking the disguise by learning to transform the resulting subnetwork’s remaining weights. Extensive experiments on several large-scale models (ResNet-18, ResNet-50, and WideRes-28), on CIFAR-10/100 datasets, demonstrate the competency of PaB over edge popup and other counterparts."
SP:fa9e46f1dc70dbe87ff53a6b8dd5419c14b40ef3,"This paper proposes a method to jointly clean the graph and denoise features of data. The proposed method is based on two operations: reconstruction and convolution. One operation reconstructs the graph with its intrinsic properties, including similarity of two adjacent nodes’ features, sparsity of real-world graphs and many slight noises having small eigenvalues in perturbed graphs. The other is the convolution operation for features to find the optimal solution adopting the Laplacian smoothness and the prior knowledge that nodes with many neighbors are difficult to attack. Experiments show that the proposed method can defend against different adversarial attacks."
SP:fcb14510ef8541f320ef1c3cab4c0c017e2e15b9,This paper proposes a method to learn texture mapping for a 3D surface and apply it to document image unwarping. The method is based on learning a continuous bijective mapping between 3D positions and 2D texture-space coordinates. The proposed method can be plugged into a differentiable rendering pipeline and trained using multi-view images and rendering loss. Experiments show that the method can reconstruct high-frequency textures for arbitrary document shapes in both synthetic and real scenarios. 
SP:28ac9848fb69d1c59fd751fbeee9a4ac799db897,"This paper proposes Adaptive Region Pooling (ARP), a novel downsampling method for fine-grained image classification and retrieval tasks. The proposed method is based on the idea of strided pooling and cropping operations, which allows the network to focus on a smaller but more critical region, and simultaneously increase the resolution of sub-sampled feature. ARP owns a trade-off mechanism that allows users to actively balance the scale of receptive field and the granularity of feature. Extensive experiments qualitatively and quantitatively validate the effectiveness and efficiency of the proposed pooling operation."
SP:8648453f5a7c5e9b99a8fdbaa340f4e2b4d048d0,This paper studies the problem of out-of-distribution (OOD) node-level prediction for graph-structured data. The authors formulate the OOD problem as a domain-invariant learning problem and propose Explore-to-Extrapolate Risk Minimization (Explore-TEM) to leverage invariant graph features for prediction. The key difference to existing invariant models is that they design multiple context explorers (specified as graph editers) that are adversarially trained to maximize the variance of risks from multiple virtual environments. Theoretical analysis is provided to prove the validity of the proposed method. Empirical results show that the proposed approach outperforms existing methods on several real-world datasets.
SP:870cd8794f7ff48fbed71c2abc9fb7dad51bd343,"This paper proposes InfoTS, a meta-learning method for time series data augmentation for contrastive learning. The proposed method is based on the idea of information-aware meta learning, where the meta-learner and the encoder are jointly optimized in an end-to-end manner to avoid sub-optimal solutions. A theoretical analysis leads to the criteria for selecting feasible data augmentations. Experiments on various datasets show that InfoTS can achieve competitive performance with up to 11.4% reduction in MSE on forecasting task and up to 2.8% relative improvement in accuracy on classification task."
SP:6bc677d060ba4ab09f6da61458680e7a7976644b,"This paper studies the universality of winning tickets in the Lottery Ticket Hypothesis (LTH). The authors propose a renormalization group theory framework to explain why winning tickets can be transferred across tasks. They show that iterative magnitude pruning, the method used for discovering winning tickets, is a Renormalization Group scheme. This opens the door to a wealth of existing numerical and theoretical tools, some of which they leverage here to examine winning ticket universality in large scale lottery ticket experiments, as well as sheds new light on the success iterative magnitudes pruning has found in machine learning."
SP:59ce2e6c3674157d6fa990316812d0823c1ec586,"This paper studies the performance gap between cross-attention (CA) and dual-encoder (DE) models in the context of information retrieval tasks. The authors show that DE models can capture a broader class of scores than CA models, which may be due to the latter overfitting to the training set. They also propose a distillation strategy that focuses on preserving the ordering amongst documents, and confirm its efficacy on benchmark neural re-ranking datasets."
SP:679e57a2027ff1855e5dc80bd3ec91f6489cc747,"This paper studies the importance sampling (IS) problem in the context of off-policy learning, where the goal is to estimate the performance of a target policy, given samples collected with a different behavioral policy. In this setting, IS is used as a what-if analysis tool, with the goal of estimating the variance of the estimator below the one achievable when sampling from the target distribution. The paper shows that variance minimization can be used as an inner loop to improve the performance. Theoretical results show that the minimum-variance behavioral distribution is guaranteed to yield a performance improvement, requiring the non-negativity of the reward only, and enforcing an implicit trust region. Based on these theoretical results, the paper proposes Policy Optimization via Optimal Policy Evaluation (PO2PE), a novel PO algorithm for parametric policy spaces. Empirical results demonstrate the effectiveness of the proposed algorithm. "
SP:b169c94c8fcc4f13cafdbafbe18eb26cb471ea0b,"This paper proposes a graph parallelism method for graph neural networks (GNNs) to model atomic simulations. The proposed method is based on Graph Parallelism (GP), a method to distribute input graphs across multiple GPUs to train very large GNNs with hundreds of millions or billions of parameters. The method is evaluated on the large-scale Open Catalyst 2020 (OC20) dataset, which consists of 134M training examples spanning a wide range of adsorbates and catalyst materials. The experimental results show that the proposed method scales up the number of parameters of DimeNet++ and GemNet models by over an order of magnitude."
SP:352c177d89b9460acee0c78364e6d9c153c6a93c,"This paper proposes Time Control (TC), a language model that implicitly plans via a latent stochastic process to generate text that is consistent with this latent plan. The authors propose to learn a representation that maps the dynamics of how text changes in a document to the dynamics in the latent space of interest, and then use this representation to generate the text by first implicitly generating a document plan via the latent process and then generating text consistent with the document plan. They show that the proposed method outperforms GPT2 on text infilling and discourse coherence tasks. "
SP:56a74403d4471cd95641dc669f5eac89a2c93144,"This paper proposes a method to learn object-centric representation from single 2D images by learning to predict future scenes in the presence of moving objects. The proposed method treats objects as latent causes whose function to an agent is to facilitate efficient prediction of the coherent motion of their parts in visual input. The model learns to explicitly infer objects’ locations in 3D environment in addition to segmenting objects. Further, the network learns a latent code space where objects with the same geometric shape and texture/color frequently group together. The method requires no supervision or pre-training of any part of the network."
SP:244f5d31ec93b7a4bfc4b257ee6cdd5cfdb18a38,"This paper proposes a VAE-based architecture for learning disentangled representation from real spatio-temporal data for mobility forecasting. Specifically, the proposed method learns a latent representation that separates the temporal dynamics of the data from the spatially varying component and generates effective reconstructions. The proposed method is able to achieve state-of-the-art performance across multiple spatio temporal datasets. "
SP:cf781d756cf0bed5f7cdeb94be49e6d4409eeda4,This paper proposes a new deep learning framework for probabilistic interpolation of irregularly sampled time series. The proposed method is based on a temporal VAE architecture with a heteroscedastic output layer. The experimental results show that the proposed method outperforms a range of baseline models and recent approaches. 
SP:80b8488b5a7c29014b0fefbc16698afac42250a0,"This paper proposes two proxies to measure the modularity of a neural network, i.e., importance and coherence, based on graph-based partitioning of the network's neurons. These proxies are based on the graph clustering of a graph representation of the neurons with edges determined either by network weights or correlations of activations. The authors show that these proxies reveal groups of neurons that are important and coherent, and that these partitions can reveal modularity."
SP:0d7cbb544bc39203c9c18b4fee56fc94cbe78375,"This paper investigates the lottery ticket hypothesis to discover lightweight speech recognition models that are robust to various noise existing in speech, transferable to fit the open-world personalization, and compatible with structured sparsity. The authors conducted extensive experiments on CTC, RNN-Transducer, and Transformer models, and verified the existence of highly sparse “winning tickets” that can match the full model performance across those backbones. They obtained winning tickets that have less than 20% of full model weights on all backbones, while the most lightweight one only keeps 4.4% weights. Those winning tickets generalize to structured Sparsity with no performance loss, and transfer exceptionally from large source datasets to various target datasets. In the presence of various levels of background noise, the winning tickets consistently achieve significantly better WERs than full models."
SP:cb9530f5517f1092513c200b3f32e55420fdd768,"This paper proposes to replace the widely used random weight initialization with a fully deterministic initialization scheme ZerO, which initializes residual networks with only zeros and ones. The authors augment the standard ResNet architectures with a few extra skip connections and Hadamard transforms to start the training from zero and ones entirely. This has many benefits such as improving reproducibility (by reducing the variance over different experimental runs) and allowing network training without batch normalization. The experiments show that ZerO achieves state-of-the-art performance over various image classification datasets, including ImageNet."
SP:16618b226e42a07095dcf9204ce4c0e3b2ed8bd8,"This paper proposes a minimax formulation for removing backdoors from a given poisoned model based on a small set of clean data. This formulation encompasses much of prior work on backdoor removal. The authors propose the Implicit Backdoor Adversarial Unlearning (I-BAU) algorithm to solve the minimax. Unlike previous work, the algorithm utilizes the implicit hypergradient to account for the interdependence between inner and outer optimization and uses it to update the poisoned model. They theoretically analyze its convergence and the generalizability of the robustness gained by solving minimax on clean data to unseen test data."
SP:7260bd50f600a481ec7710792b63f518218e0eaf,"This paper studies the convergence of permutation-based SGD for strongly convex functions with smooth second derivatives. The authors show that for 1-dimensional strongly-convex functions, there exist permutations that offer exponentially faster convergence compared to random permutations. However, for general strongly-convolutional functions, random permutation is optimal. For quadratic functions, the authors also show that easy-to-construct permutations lead to accelerated convergence. "
SP:39062dbbe9a30a7b47fa51179c15db34a3380a0b,"This paper proposes an automated normalizing flow (NF) architecture search method to find the optimal sequence of transformation layers from a given set of unique transformations with three folds. First, a mixed distribution is formulated to enable efficient architecture optimization originally on the discrete space without violating the invertibility of the resulting NF architecture. Second, the mixture NF is optimized with an approximate upper bound which has a more preferable global minimum. Third, a block-wise alternating optimization algorithm is proposed to ensure efficient NF architecture optimization of deep flow models."
SP:d2656ae0259accc5207234fc4206f6f7be9598d9,"This paper proposes to use Intrinsic Dimension (ID) of the dataset in representation space to measure expressiveness and cluster learnability of self-supervised learning (SSL) methods. Based on ID and CL, the proposed method is able to predict downstream classification performance better than the existing techniques based on contrastive losses or pretext tasks, while having no requirements on data augmentation, model architecture or human labels. The paper also proposes a modification to DeepCluster (Caron et al., 2018) to improve the learnable of the representations."
SP:4f5c00469e4425751db5efbc355085a5e8709def,"This paper proposes to use segmentation priors for black-box adversarial attacks to improve the imperceptibility of the adversarial perturbations in the salient region of the network. The proposed method is based on gradient-free black box attacks, where the attacker only has query access to the model output. The authors show that the proposed method can achieve better performance with little reduction in query efficiency and success rate. They further propose the Saliency Attack to further improve the performance by refining the perturbation in salient region."
SP:779821ed85084f8bf1b29d8822b312989b186ee9, SMILES-to-SMILES translation is a well-known method for chemical synthesis planning and reaction outcome prediction in organic chemistry. This paper proposes a novel graph-based model that combines the power of Transformer models for text generation with the permutation invariance of molecular graph encoders that mitigates the need for input data augmentation. The proposed Graph2SmILES can be used as a drop-in replacement for the Transformer in any task involving molecule(s)-to-molecule(s) transformations. Graph2SMILes achieves state-of-the-art performance on common benchmarks.
SP:ce3cde67564679a8d9a0539f1e12551390b91475,"This paper proposes a method for automatic disease diagnosis with reinforcement learning in task-oriented dialogues setting. Inspired by offline consultation process, this paper proposes to integrate a hierarchical policy of two levels into the dialogue policy learning. The high level policy consists of a master model that is responsible for triggering a low level model, while the low level policy is composed of several symptom checkers and a disease classifier. Experimental results on both self-constructed real-world and synthetic datasets demonstrate that the hierarchical framework achieves higher accuracy and symptom recall in disease diagnosis compared with existing systems."
SP:bd9cb543b5f199ab45e1bf8609c683f12ceb7659,"This paper proposes a self-supervised and personalized federated learning framework, named (SSFL), and a series of algorithms under this framework which work towards addressing the label deficiency at the edge. The authors first analyze the compatibility of various centralized self supervised learning methods in FL setting and demonstrate that SimSiam networks performs the best with the standard FedAvg algorithm. To address the data heterogeneous nature of the data at edge devices in this framework, the authors have innovated several algorithms including perFedAvg, Ditto, and local fine-tuning, among others. They further propose a novel personalized Federated Self-Supervised learning algorithm, Per-SSFL, which balances personalization and consensus by carefully regulating the distance between the local and global representations of data. Experiments on a synthetic non-I.I.D. dataset based on CIFAR-10 and GLD-23K demonstrate the effectiveness of the proposed algorithms."
SP:8ff52b027a3c2a464b2c2fedb768c092b0fc6ca5,"This paper aims to derive a general form of PDEs for the design of ResNet-like DNNs. To achieve this goal, the authors formulate DNN as an adjustment operator applied on the base classifier. Then based on several reasonable assumptions, they show that the adjustment operator for DNN is the solution operator of a PDE. The authors then show that several effective networks can be interpreted by their general form and design a training method motivated by PDE theory to train DNN models for better robustness and less chance of overfitting. Theoretically, they prove that the robustness of DNN trained with their method is certifiable and their training method reduces the generalization gap. "
SP:d44f0ebc2847695ecb4ed0bb3df61d6cd8cc6a40,"This paper studies the emergence of emergent languages in language games, where agents interact and develop an emergent language to solve a task. The authors focus on the factors which determine the expressivity of the language, which reflects the amount of information about input spaces those languages are capable of encoding. The expressivity is a trade-off between the complexity and unpredictability of the context that the language is used in. The paper also proposes a contrastive loss to alleviate the problem of message type collapse."
SP:892558b9f4fb53ed5ca2a7ee440b7d728b1886d6,"This paper proposes a new exploration strategy for reinforcement learning based on sample average uncertainty (SAU) based exploration strategies. The exploration strategy is based on SAU, which is an extension of SAU from the bandit setting to the sequential RL setting. The proposed exploration strategy, called $\delta_2$-exploration, is shown to outperform existing exploration strategies in both tabular and deep Q-learning settings."
SP:2f6e266b03939c96434834579999707d3268c5d6,"This paper proposes a video generation method that leverages the implicit neural representations (INRs) of video to model the dynamics of the video. Specifically, the authors propose a video generator and a motion discriminator for long-range video generation. The proposed method is evaluated on UCF-101 dataset and shows improved performance over existing methods. "
SP:878325384328c885ced7af0ebf31bbf79287c169,"This paper proposes three new methods for multi-label multi-winner voting in DPSGD: Binary, τ, and Powerset voting. Binary voting operates independently per label through composition, and powerset voting operates over the entire binary vector by viewing the possible outcomes as a power set. The paper theoretically analyzes the trade-off between binary voting and power set voting and shows that the former requires strong correlations between labels to outperform Binary voting, while the latter requires stronger correlations between power sets. The proposed methods are applied to DPSGD in the centralized setting and multi-site collaborative learning setting. The results show that the proposed methods outperform DPSGD."
SP:2488d3697a4ea732526b3ef11fbbd93e27d42e81,"This paper proposes a method to transfer the implicit step size schedule from a tuned optimizer to a new optimizer, preserving empirical performance. The proposed method is based on the idea of optimizer grafting, which allows for the transfer of the overall implicit step-size schedule from the tuned optimizers to the new optimizers. This provides a robust plug-and-play baseline for optimizer comparisons, leading to reductions to the computational cost of optimizing the optimizer hyperparameter search. "
SP:83b82c145f446c1a29e863362c6ceed018e93e2b,"This paper proposes an online RL algorithm called Learning Online with Guidance Offline (LOGO) that exploits offline demonstration data generated by a sub-optimal behavior policy for faster and efficient online RL in sparse reward settings. The proposed algorithm merges a policy improvement step with an additional policy guidance step by using the offline demonstrations. The key idea is that by obtaining guidance from not imitating the offline data, LOGO orients its policy in the manner of the sub-optimality policy, while yet being able to learn beyond and approach optimality. Theoretical analysis of the proposed algorithm is provided, and a lower bound on the performance improvement in each learning episode is also provided. Empirical results show that the proposed method outperforms state-of-the-art methods on a number of MuJoCo environments with sparse rewards and censored state."
SP:cf857736e3dc01325948488c791cbafc24b1c0fe,This paper proposes a two-stage Pareto framework for multi-task learning (MTL) solvers. The first stage uses a neural network to extract the weak Paresto front. The second stage is a low-cost filter that extracts the strong subset from the weak front. Experiments show that the proposed method is more efficient than the baselines. 
SP:0085e0bb1a265a3925540fbc4873aae60b8d01ce,"This paper studies the problem of knowledge distillation, i.e., learning a consolidated image feature representation from a collection of related task-specific teachers that transfer well on novel recognition tasks. The authors propose a multi-head, multi-task distillation method using an unlabeled proxy dataset and adding a generalist teacher is sufficient to consolidate representations from task specific teacher(s) and improve downstream performance, outperforming the teacher (or best of all teachers) as well as the strong baseline of ImageNet pre-trained features."
SP:ab0d024d4060235df45182dab584c36db16d8e31,"This paper proposes a generalization of conformal prediction to multiple learnable parameters by considering the constrained empirical risk minimization (ERM) problem of finding the most efficient prediction set subject to valid empirical coverage. Conformal prediction is a powerful technique for learning prediction sets with valid coverage, yet by default its conformalization step only learns a single parameter, and does not optimize the efficiency over more expressive function classes. This paper generalizes existing conformal predictions algorithms to multiple parameters and shows that it achieves approximate valid population coverage and near-optimal efficiency within class, whenever the function class is low-capacity in a certain sense. Experiments show that the proposed algorithm is able to learn valid prediction sets and improve the efficiency significantly over existing approaches."
SP:f6b88e1fa1a84d82302d960c6a596fc2ba320bf5,"This paper proposes a method to query object localization based on a small set of exemplary objects. The proposed method learns a transferable reward signal formulated using the exemplary set by ordinal metric learning. Experiments on a corrupted MNIST, CU-Birds, and COCO datasets demonstrate the effectiveness of the proposed method."
SP:0b23c5683b72dac05a7436cf3b49bd76263801d9,"This paper proposes QuadTree Attention, a method to reduce the computational complexity of transformers from quadratic to linear. The proposed method builds token pyramids and computes attention in a coarse-to-fine manner. At each level, the top K patches with the highest attention scores are selected, such that at the next level, attention is only evaluated within the relevant regions corresponding to these top K patch. The experimental results show that quadtree attention achieves state-of-the-art performance in various vision tasks."
SP:63bcbaf0c5644aaba863cf60fa10db763f382ee8,"This paper proposes a method for learning reusable temporally extended actions, or options, in reinforcement learning. Motivated by the recent success of mutual information (MI) based skill learning, the authors propose a method to learn termination conditions of options by maximizing MI between options and corresponding state transitions. The authors derive a scalable approximation of this MI maximization via gradient ascent, yielding the InfoMax Termination Critic (IMTC) algorithm. The experiments demonstrate that IMTC significantly improves the diversity of learned options without extrinsic rewards, combined with intrinsic rewards, in a reward-free RL setting. Moreover, they test the reusability of learned option by transferring options into various tasks."
SP:79da8f6cacc8386e02bab32154e7eaefbe2c683c,"This paper proposes a semantic topology-based open-world object detection method, where the object instances from the same category are assigned to their corresponding pre-defined node in the semantic topologies, including the ‘unknown’ category. This constraint builds up discriminative feature representations and consistent relationships among objects, thus enabling the detector to distinguish unknown objects out of the known categories, as well as making learned features of known objects undistorted when learning new categories incrementally. Extensive experiments demonstrate that the proposed method can outperform the current state-of-the-art open world object detectors by a large margin, e.g., the absolute open-set error is reduced from 7832 to 2546."
SP:97f618558f4add834e5930fd177f012a753247dc,"This paper proposes a novel algorithm to identify informative and diverse subsets of data that lead to deep learning models with similar performance as the ones trained with the original dataset. The authors propose a novel formulation of these constraints using matroids, an algebraic structure that generalizes linear independence in vector spaces, and present an efficient greedy algorithm with constant approximation guarantees. The proposed algorithm outperforms competing baselines on standard classification datasets such as CIFAR-10, Cifar-100, and ImageNet, as well as long-tailed datasets."
SP:e0432ff922708c6c6e59124d27c1386605930346,"This paper proposes a method for semantic segmentation that adapts the model parameters to the test sample before producing the final prediction. The proposed method is based on Instance-Adaptive Batch Normalization (IaBN), which modifies the normalization layers by combining the feature statistics acquired at training time with those of the test samples. A test-time training (TTT) approach Seg-TTT is also proposed to adapt the parameters of the model to a single test sample using a self-supervised loss. Experimental results show that the proposed method achieves a new state-of-the-art in semantic segmenting accuracy."
SP:427100edad574722a6525ca917e84f817ff60d7e,"This paper proposes a novel method for finding out-of-class samples in tabular data. The proposed method is based on learning mappings that maximize the mutual information between each sample and the part that is masked out. The mappings are learned by employing a contrastive loss, which considers only one sample at a time. Once learned, the method can score a test sample by measuring whether the learned mappings lead to a small loss using the masked parts of this sample. The experiments show that the proposed method leads by a sizable accuracy gap in comparison to the literature. "
SP:7782a99e3c41ff523c0c56bfbe399c855a77acf2,"This paper proposes a method to learn a low-dimensional embedding space that preserves the diagnostic attributes of represented disorders. To this end, the authors propose a conditional variational auto-encoder that incorporates dual utilisation of diagnostic information. The proposed method is evaluated on two neuropsychiatric neuroimaging datasets and shows promising results. "
SP:b3feb15b01e519e5b2e28b1c4a144056c493e2bc,"This paper proposes an end-to-end learning framework named QTN-VQC, by introducing a trainable quantum tensor network (QTN) for quantum embedding on a variational quantum circuit. The architecture of QTN is composed of a parametric tensor-train network (TTN) for feature extraction and a tensor product encoding (TPE) for embedding. The authors theoretically characterize the QTN by analyzing its representation power of input features, and show that QTN enables an end to end parametric model pipeline from the generation of quantum embeddings to the output measurement. The experiments on the MNIST dataset demonstrate the advantages of the proposed method over other quantum neural networks."
SP:c4b03a1b477ac94438d63beb29ef86d77acf1b1e,"This paper proposes DYNAMO, an algorithm that constructs low-dimensional manifolds where each point corresponds to a neural network model, and two points are nearby if the corresponding neural networks enact similar high-level computational processes. The algorithm takes as input a collection of pre-trained neural networks and outputs a meta-model that emulates the dynamics of the hidden states as well as the outputs of any model in the collection. The specific model to be emulated is determined by a model embedding vector that the meta-models takes as an input. The authors apply the algorithm to both RNNs and CNNs and find that it can enable novel applications such as clustering, model averaging, and semi-supervised learning. "
SP:29a42fdae15b9da955513f71e3100ebd0146a28a,"This paper proposes a method for constraint-based learned physical simulation, where a scalar constraint function is implemented as a trainable function approximator, and future predictions are computed as the solutions to a constraint satisfaction problem. The method uses a graph neural network as a constraint function and gradient descent as the constraint solver. The architecture can be trained by standard backpropagation. The authors test the model on a variety of challenging physical domains, including simulated ropes, bouncing balls, colliding irregular shapes and splashing fluids, and achieve better or comparable performance to top learned simulators."
SP:db07c2c0afdf27692dc504c9c54387c20211d469,"This paper proposes EDO-CS, a method for finding a set of policies with both high quality and diversity in reinforcement learning. The proposed method is based on the idea of clustering-based selection, where the policies are divided into several clusters based on their behaviors, and a high-quality policy is selected from each cluster for reproduction. Experiments on several continuous control tasks show that the proposed method achieves better performance than previous methods. "
SP:e51123a76713f1a1031d252e092985bd9b298fdf,"This paper studies the convergence of a multi-agent linear stochastic approximation algorithm driven by Markovian noise and general consensus-type interaction, in which each agent evolves according to its local stochastically approximation process which depends on the information from its neighbors. The interconnection structure among the agents is described by a time-varying directed graph. The paper derives finite-time bounds on the mean-square error, defined as the deviation of the output of the algorithm from the unique equilibrium point of the associated ordinary differential equation. The equilibrium point can be any unspecified convex combination of the local equilibria of all the agents in the absence of communication."
SP:f7f96d545a907887396393aba310974f4d3f75ff,"This paper proposes a Graph Mechanics Network (GMN) that is combinatorially efficient, equivariant and constraint-aware. The core of GMN is that it represents, by generalized coordinates, the forward kinematics information (positions and velocities) of a structural object. In this manner, the geometrical constraints are implicitly and naturally encoded in the forward Kinematics. Theoretically, the proposed GMN formulation is proved to be universally expressive under certain conditions. Extensive experiments show that GMN outperforms the state-of-the-art GNNs in terms of prediction accuracy, constraint satisfaction and data efficiency on the simulated systems consisting of particles, sticks and hinges, as well as two real-world datasets for molecular dynamics prediction and human motion capture."
SP:ee0b94238c3fde59cb8b67a687b77984fe7d3454,"This paper studies the problem of federated learning with partial model personalization. The authors propose two algorithms for training partially personalized models, where the shared and personal parameters are updated either simultaneously or alternately on each device, but only the shared parameters are communicated and aggregated at the server. They provide convergence analyses of both algorithms for minimizing smooth nonconvex functions, providing theoretical support of them for training deep learning models. The experiments on real-world image and text datasets demonstrate that the proposed algorithms can obtain most of the benefit of full model personalisation with a small fraction of personalized parameters."
SP:eb54e84275266d8909fcbfe1589da1c4396c3164,"This paper proposes CLTT, an unsupervised contrastive learning method for object representation learning. CLTT is based on viewing sequences that are generated procedurally in a manner similar to that of an infant interacting with objects in a toy environment. Instead of using arbitrary augmentation operations, CLTT generates viewing sequences by viewing successive views in such viewing sequences. This allows the authors to control the temporal structure of the viewing sequences, which allows them to ask the following questions: 1) can CLTT approach the performance of fully supervised learning? 2) if so, what are the required conditions on the temporal structures of the input? To answer these questions, the authors develop a new data set using a near-photorealistic training environment based on ThreeDWorld (TDW) and demonstrate that CLTT allows linear classification performance that approaches that of the fully supervised setting if subsequent views are sufficiently likely to stem from the same object. "
SP:2fb4af247b5022710b681037faca2420207a507a,"This paper proposes an extension of AlphaZero with Hindsight experience replay (HER) to solve goal-directed planning problems with sparse rewards. HER is a variant of MCTS where the goal is to reach a goal state in a deterministic transition model. The authors show that HER can be used in combination with the Monte Carlo Tree Search (MCTS) algorithm to improve the performance of the AlphaZero algorithm. The proposed algorithm is evaluated on a number of tasks in a variety of domains, including quantum computing and quantum compiling."
SP:e2d33c7331db7f52b84ad1018152564d91a9f126,This paper proposes Recursive Gradient Optimization (RGO) for continual learning. RGO is composed of an iteratively updated optimizer that modifies the gradient to minimize forgetting without data replay and a virtual Feature Encoding Layer (FEL) that represents different network structures with only task descriptors. Experiments demonstrate that RGO has significantly better performance on popular continual classification benchmarks when compared to the baselines and achieves new state-of-the-art performance on 20-split-CIFAR100 (82.22%) and 20- split-miniImageNet (72.63%) with higher average accuracy than single-task learning.
SP:511226b467019dcd85e9ebf8b9b56f8f1b3ef889,"This paper presents an empirical study of the properties and applications of aligned generative models for image-to-image translation and zero-shot image morphing. The paper first analyzes aligned models and provides answers to important questions regarding their nature. It shows that the child model’s latent spaces are semantically aligned with those of the parent, inheriting incredibly rich semantics, even for distant data domains such as human faces and churches. Second, equipped with this better understanding, the paper leverages aligned models to solve a diverse set of tasks, including image translation, zero shot vision tasks, and cross-domain morphing, and achieves state of the art results."
SP:0e13f831c211626195c118487f2fff36a6e293f6,"This paper proposes a semi-relaxed Gromov-wasserstein (SRGW) divergence between graphs based on optimal transport (OT) based on the GW distance. The authors argue that the original GW distance is detrimental for tasks such as graph dictionary or partition learning, and relax it by proposing a new GW divergence. The proposed SRGW is shown to be more efficient than exact GW solvers, and can be used for graph partitioning, clustering, and completion tasks."
SP:d6d144be11230070ae9395db70b7c7743540bad4,"This paper proposes a method to model systematic suboptimality of human behavior, i.e., when the deviation from optimal behavior is not independent, but instead consistent over time. This is achieved by predicting policies, which couple action choices over time, instead of trajectories. The authors introduce the Boltzmann policy distribution (BPD), which serves as a prior over human policies and adapts via Bayesian inference to capture systematic deviations by observing human actions during a single episode. The BPD is difficult to compute and represent because policies lie in a high-dimensional continuous space, but the authors leverage tools from generative and sequence models to enable efficient sampling and inference. "
SP:401ef5fe2022e926b0321258efac1f369f186ace,"This paper proposes a data-free post-training quantization method for deep neural networks (DNNs) that can be applied to inference-only devices with low computation and memory requirements. The authors decompose and approximate the Hessian-based optimization objective into three diagonal sub-items, which have different areas corresponding to three dimensions of weight tensor: element-wise, kernel-wise and output channel-wise. Then, the authors propose a novel optimization objective in the discrete domain, minimizing Constrained Absolute Sum of Error (or CASE in short), which does not need any dataset and is even not aware of network architecture. Finally, without fine-tuning and synthetic datasets, SQuant accelerates the quantization process to a sub-second level with > 30% accuracy improvement."
SP:fa4bc3f6ad3f2a0113a930fb49d68660d63910e8,"This paper proposes a method for time series segmentation based on neural networks. The proposed method is based on a bi-pass architecture with several structures that can process information in a multi-scale fashion. The authors show that the proposed method can find precise breakpoints, obviates sliding windows, handles long-term dependencies, and is insensitive to the label changing frequency. "
SP:8ad1b170f0392a132a3816c9cd28fb7332343e65,"This paper proposes a new explanation method for graph neural networks (GNNs) based on decomposing the information generation and aggregation mechanism of GNNs, which allows tracking the contributions of specific components of the input graph to the final prediction. Based on this, the authors further design a subgraph level interpretation algorithm to reveal complex interactions between graph nodes that are overlooked by previous methods. The authors conduct quantitative and qualitative experiments on synthetic and real-world datasets to demonstrate the effectiveness of the proposed method."
SP:b28a9d1ad4c539d07d53e39376cbd76024d7745c,"This paper proposes a new downsampling layer, called DiffStride, that learns strides jointly with the rest of the network. The idea is to learn the size of a cropping mask in the Fourier domain, that effectively performs resizing in a differentiable way. Experiments on audio and image classification show the generality and effectiveness of the proposed method."
SP:54cdc6fe43ed138231f26daf699119f2a16473d0,"This paper proposes a new collective robustness certificate for soft local models, where each output is dependent on the entire input but assigns different levels of importance to different input regions (e.g. based on their proximity in the image). The certificate is based on a novel randomized smoothing approach, where the random perturbation strength for different input region is proportional to their importance for the outputs. The resulting locally smoothed model yields strong collective guarantees while maintaining high prediction quality on both image segmentation and node classification tasks."
SP:aacc31e83886c4c997412a1e51090202075eda86,"This paper proposes an embedding-based normalizing flow (EMF) method for embedding differentiable probabilistic models into equivalent bijective transformations with domain-specific inductive biases. The EMF can be used to induce desirable properties such as multimodality, hierarchical coupling and continuity. The authors also introduce gated structured layers, which allow bypassing the parts of the models that fail to capture the statistics of the data. Empirical results show that EMF enables a high performance form of variational inference where the structure of the prior model is embedded in the variational architecture."
SP:825a254c0725008143b260ead840ae35f9f096d1,"This paper investigates the ability of pre-trained text-only language models (LMs) to generalize to non-linguistic concepts (e.g., directions, colours, etc.) given only a small number of examples. The authors show that the largest models (GPT-2 and GPT-3) are able to learn to ground concepts that it is explicitly taught, and generalise to several instances of unseen concepts as well. The results suggest that the large models can learn a sufficiently rich conceptual structure that could allow them to be grounded in a data-efficient way."
SP:702029739062693e3f96051cbb38f20c53f2a223,"This paper studies the effect of shaped rewards in emergent language experiments. In particular, the authors show that shaped rewards can explicitly bias the semantics of the learned language, significantly change the entropy of the language, and mask the potential effects of other environmental variables of interest. They also propose a mathematical model for understanding the role of experience buffer size in the entropy. "
SP:146ef14e569e10172a7dc602acd3fadf2c3bef8b,"This paper proposes an unsupervised cross-lingual learning method, called importance-weighted domain alignment (IWDA), that performs representation alignment, prior shift estimation, and correction. IWDA outperforms the more popular semi-supervised learning methods under large prior shifts, and can be additionally combined with them for further performance gains. The empirical results show that invariance of the feature representations strongly correlates with transfer performance. "
SP:461ed47339e08dafea90a7c015d2f20e534daeb7,"This paper proposes Bootstrapped Meta-Gradient (BMG), a meta-learning algorithm that first bootstraps a target from the meta-learner, then optimises the meta learner by minimising the distance to that target under a chosen (pseudo-)metric. The authors show that BMG can achieve state-of-the-art results for model-free agents on the Atari ALE benchmark and achieves both performance and efficiency gains in multi-task meta learning. Finally, they explore how bootstrapping opens up new possibilities and find that it can meta-learn efficient exploration in an ε-greedy Q-learning agent—without backpropagating through the update rule."
SP:49435d70bf8e16d5dbf34577cf8d3a5b21b1f25a,"This paper studies the generalization performance of MuZero, a model-based reinforcement learning agent. The authors evaluate MuZero on both procedural and task generalization. They identify three factors of procedural generalization -- planning, self-supervised representation learning, and procedural data diversity -- and show that combining these techniques achieves state-of-the-art performance and data efficiency on Procgen. However, these factors do not always provide the same benefits for task generalisation in Meta-World, indicating that transfer remains a challenge. "
SP:ba80e35d452d894181d51624183b60541c0f3704,"This paper proposes a graph decomposition network (GDN) for graph learning. The proposed method is based on a graph convolutional network (GCN) that is trained to learn a distribution of graphs in a supervised fashion, and performs link prediction or edge-weight regression tasks by adapting the loss function. GDNs are inductive and can generalize to larger-sized graphs after training. Experiments on synthetic and real datasets demonstrate the effectiveness of GDNs for the task of graph reconstruction. "
SP:91fd4189bf04aca4ccd1288ec8459e1edb29d378,"This paper proposes a two-player reward shaping framework for reinforcement learning. In this framework, a reward-shaping agent (Shaper) uses switching controls to determine which states to add shaping rewards and their optimal values while the other agent (controller) learns the optimal policy for the task using these shaped rewards. The authors prove that the learning algorithm learns to construct a shaping-reward function that is tailored to the task thus ensuring efficient convergence to high performance policies. The experimental results show that the proposed method outperforms existing reward shaping algorithms in sparse reward environments."
SP:20abe4d70152590c3c44fcb50c5d0293e25874ff,"This paper proposes a robust training and inference framework for vertical federated learning (VFL) to defend against backdoor attacks and inference-phase attacks. The proposed method is based on the Robust AutoEncoder (RAF) framework, which can recover the underlying uncorrupted features with provable guarantees and thus sanitizes the model against a vast range of backdoor attacks. Experiments on NUS-WIDE and CIFAR-10 datasets demonstrate the effectiveness of the proposed method. "
SP:3fbc5ebb4c598e849b3ecbb2886289e20bf1ea14,"This paper proposes to use contrastive learning to train unsupervised dense retrievers, and shows that it leads to strong retrieval performance on the BEIR benchmark. The authors also show that the proposed method can be used as a pre-training method before fine-tuning on the MS MARCO dataset, and achieves state-of-the-art results on the task. "
SP:ed4e2896dc882bd089f420f719da232d706097c5,"This paper studies the effect of fine-tuning and linear probing on in-distribution (ID) and OOD (OOD) accuracy of a two-layer linear network. The authors show that fine tuning results in lower OOD accuracy than linear probing, especially when the pretrained features are good and distribution shift is large. They theoretically analyze the trade-off between OOD and ID accuracy and show that linear probing achieves better OOD performance than fine tuning. They also show that LP-FT achieves better ID accuracy than finetuning. "
SP:96f4f90488c15167d85261a883cd70fc15e06bb9,"This paper studies the problem of learning to discover novel classes (L2DNC) from unlabeled data from seen and unseen classes. The paper proposes a meta-learning-based approach to solve the L2DNCL problem. The proposed approach is based on the assumption that high-level semantic features should be shared among the seen and the unseen classes, and can be naturally linked to meta learning that has exactly the same assumption as L2DMCL. The method is empirically shown to outperform several baselines on four benchmark datasets. "
SP:262a5aaa4e675b2aac6bd14d3aa007bf411ce550,"This paper proposes a method for model-based reinforcement learning in POMDPs, where the learning agent has access to both online and offline data. The offline data is obtained by observing another agent interacting with the environment. The proposed method is based on learning a latent-based causal transition model that explains both the interventional and observational regimes, and then inferring the standard POMD transition model via deconfounding using the recovered latent variable. The authors show that the proposed method achieves better generalization guarantees due to the offline data (in the asymptotic case), and empirically on a series of synthetic toy problems."
SP:bcb4e7e5c137edf04a9ea2fde014b0984c6ef89b,"This paper proposes an end-to-end retrieval-augmented model for open-ended text generation tasks. The proposed method uses a guide retriever that is allowed to use the target output and “in hindsight” retrieve relevant passages during training. The retriever is trained jointly with the standard retriever and the generator by maximizing the evidence lower bound (ELBo) in expectation over the posterior distribution Q of passages given the input and target output. Experiments on the Wizard of Wikipedia dataset show that the retriever finds passages with higher relevance in the top-10 (23% relative improvement), the generator’s responses are more grounded in the retrieved passage (19% relative improved) and the end- to-end system produces better overall output (6.4% relative performance)."
SP:bec15075409c71f98f3698bc35e34eeb4862d94f,"This paper proposes a graph neural network (GNN) for influence estimation and influence maximization problems. The GNN is trained on small simulated graphs and is then used to estimate the influence of a given node in a large graph. The authors show that the GNN can be used for both influence estimation (IE) and influence maximizing (IM) problems. In addition, the authors propose a variant of the cost-effective lazy forward optimization (CELF) algorithm with the proposed GNN.   "
SP:0c55b1f5e544e1e9510a12981107ae6c9f1eeb2e,"This paper proposes an active learning strategy for domain adaptation under the assumption of Lipschitz functions. The proposed method is based on the concept of discrepancy distance between source and target distributions, which restricts the maximization over the hypothesis class to a localized class of functions which are performing accurate labeling on the source domain. The authors derive generalization error bounds for such active learning strategies in terms of Rademacher average and localized discrepancy for general loss functions which satisfy a regularity condition. A practical Kmedoids algorithm that can address the case of large data set is inferred from the theoretical bounds. The numerical experiments show that the proposed algorithm is competitive against other state-of-the-art active learning techniques in the context of domain adaptation."
SP:f63c10ba7d6f5ef1c167faa8a221b3ab5cc06006, for Bayesian neural networks. This paper proposes a new variational approximation for singular neural networks based on desingularization. The authors show that the posterior distribution over the parameters of a singular model is asymptotically a mixture of standard forms. They show that a generalized gamma mean-field variational family can recover the leading order term of the model evidence. Affine coupling layers are employed to learn the unknown desedularization map. 
SP:9ba33d09bd68d8598e2aff428ecca5060922a4dc,"This paper proposes a generalization bound for domain generalization based on the Rademacher complexity of the model. Based on this bound, the authors conjecture that existing methods’ efficacy or lack thereof is a variant of the standard empirical risk-predictor complexity trade-off, and demonstrate that their performance variability can be explained in these terms. Algorithmically, this analysis suggests that domain generalisation should be achieved by simply performing regularised ERM with a leave-one-domain-out cross-validation objective."
SP:b1f622cbc827e880f98de9e99eca498584efe011,"This paper studies the problem of maximum n-times coverage, which is a generalization of the multi-set multi-cover problem, where each element must be covered at least n times. The authors define the problem in terms of the sum of the weights of elements that are covered n times, and define two variants of the problem. The first is to select k overlays to maximize the summed coverage of weighted elements, where k is the number of times each element is covered. The second is to choose the minimum set of overlays such that the sum is at least $\tau$. The authors also define the min-cost n-time coverage problem where the minimum overlays are selected such that $tau$ is larger than $\mathcal{O}(\sqrt{n}(k)$, where $k$ is the size of the population. "
SP:11ad277db038a77d5935e7504cc640e74bfc4efe,"This paper proposes an initialization method for spiking neural networks (SNNs) based on an asymptotic approximation of the response curve of the spiking neurons. The proposed method is based on the slant-asymptotically-estimated response curve, which approximates the actual neuron response distribution. The method is evaluated on MNIST and CIFAR-10 datasets and compared with other SNN initialization methods. "
SP:f7e8602b40b37f26277e3f44f60a11f879978986,"This paper proposes a method to deal with the periodic distribution shift in federated learning. The authors propose to model the distribution shift with a mixture of distributions that gradually changes between daytime and nighttime modes, and train a network with multiple light-weight branches specializing at different modes. Experiments on EMNIST, CIFAR and Stack Overflow show that the proposed method can mitigate the impact of distribution shift and significantly improve the final model performance."
SP:e38efcfcf63f0488b6e20a74a86b78aad1ead363,"This paper proposes a method for pruning deep neural networks (DNs) based on a recently developed spline interpretation of DNs. The authors show that a DN's spline mappings exhibit an early-bird phenomenon whereby the spline’s partition converges at early training stages, bridging the recently developed DN spline theory and lottery ticket hypothesis of deep networks. They leverage this insight to develop a principled and efficient pruning strategy that focuses on a tiny fraction of DN nodes whose corresponding spline partition regions actually contribute to the final decision boundary. Extensive experiments on four networks and three datasets validate the effectiveness of the proposed method."
SP:64ce86f8bd8572f699809c808aea8364fbbe4ef3,"This paper studies the problem of fair representation learning, where optimal predictors, on top of the data representation, are ensured to be invariant with respect to different subgroups. Specifically, the authors formulate the problem as a bi-level optimization, where the representation is learned in the outer-level, and invariant optimal group predictors are updated in the inner-level. To avoid the high computational and memory cost of differentiating in inner level optimization, this paper proposes the implicit path alignment algorithm, which only relies on the solution of inner optimization and the implicit differentiation rather than the exact optimization path. Empirical results on tabular, computer vision and NLP datasets demonstrate the effectiveness of the proposed method."
SP:9bd0a519881297066ee60ccf62ee27e4c109047d,"This paper studies the effect of different design choices in reinforcement learning via supervised learning (RvS) methods, such as policy architectures and how the conditioning variable is constructed, on the performance of RvS methods on a range of offline RL problems. The authors show that the most important design decisions boil down to carefully choosing model capacity and choosing which information to condition on (e.g., goals or rewards). The experiments show that more complex design choices such as the large sequence models and value-based weighting schemes used in prior work are often not necessary."
SP:af89e1cdd2b39df9982ca5cd9446ec66a4d317f2,"This paper proposes a method for learning maps of complex spaces based on already-seen spaces through program induction in a Hierarchical Bayesian framework. The model explicitly reasons about unseen spaces through a distribution of strong spatial priors. The authors propose a new behavioral Map Induction Task, and compare human performance with that of state-of-the-art existing models as well as our MapInduction framework. They show that their computational framework better predicts human exploration behavior than non-inductive models. "
SP:cccdcc95c4177b5531bad23b662060fdd0d88849,This paper proposes a differentiable nonparametric belief propagation (NBP) method to learn the probabilistic factors used for inference by a neural network-based algorithm. The authors propose to learn a set of marginal posterior samples using end-to-end training. The proposed method is evaluated on two simulated tracking tasks and on a real-world hand pose tracking tasks in challenging noisy environments. 
SP:76e858a6ef79a3bd861803395e25d7f65fd29a00,"This paper proposes a graph-based generative model that supports scaffolds as initial seed of the generative procedure, which is possible because it is not conditioned on the generation history. The experiments show that MoLeR performs comparably to state-of-the-art methods on unconstrained molecular optimization tasks, and outperforms them on scaffold-based tasks, while being an order of magnitude faster to train and sample from than existing approaches. "
SP:318b3c294a475960c13a4914b035fd3a2ea84661,"This paper studies the problem of imitation learning for deterministic deterministic experts. The authors propose a reduction to reinforcement learning with a stationary reward that recovers the expert reward and bounds the total variation distance between the expert and the imitation learner, showing a link to adversarial imitation learning. The proposed method is tested on continuous control tasks and is shown to be effective."
SP:fd1a9b4c5ee36159286f4a35fa93ed0c23120906,"This paper studies the effect of reweighting algorithms on the worst-group performance of machine learning models for fairness. In particular, this paper shows that under the over-parameterized setting, the ERM interpolator always converges to the same interpolator that fits all training samples, and consequently the worst group test performance will drop to same level as ERM in the long run. The paper also shows that adding regularization helps fix the issue, and that for regularization to work, it must be large enough to prevent the model from achieving small training error."
SP:318ace9202e42d1d278eb79fe1853138e1d00a06,"This paper proposes a new model of human-irrationality based on the Rational Inattention (RI) model to model the cost of cognitive information processing in multi-agent reinforcement learning (MARL). The proposed model, called RIRL, generalizes and is more flexible than prior work by allowing for multi-timestep dynamics and information channels with heterogeneous processing costs. The authors show that the proposed model yields a rich spectrum of new equilibrium behaviors that differ from those found under rational assumptions. For instance, some forms of a Principal's inattention can increase Agent welfare due to increased compensation, while other forms of inatt attention can decrease Agent welfare by encouraging extra work effort. "
SP:100c91da177504d89f1819f4fdce72ebcf848902,This paper proposes a new adversarial attack method for audio adversarial attacks based on phase-oriented energy dissipation. The authors leverage the spectrogram consistency of short-time Fourier transform (STFT) to adversarially transfer phase perturbations to adjacent frames of magnitude spectrogram and dissipate the energy patterns in spectrogram. They also propose a weighted loss function to improve the imperceptibility of PhaseFool. Experiments on the LibriSpeech dataset show that the proposed method can generate full-sentence imperceptible adversarial examples and achieve a 6.64x generation speed-up over the state-of-the-art. 
SP:713c57555a88d922516f42e7ff0ddd5bfbd90a24,"This paper proposes a generalized version of DirectPred (Tian et al., 2021) that sets the predictor directly, called DirectSet(alpha). The authors show that in a simple linear network, the proposed DirectCopy algorithm can learn a desirable projection matrix and reduce the sample complexity on downstream tasks. The authors also show that weight decay acts as an implicit threshold that discard features with high variance under augmentation, and keep the features with low variance. Inspired by their theory, the authors simplify DirectPred by removing the expensive eigen-decomposition step. "
SP:8433900e40c5c5df1f003dd1d4fb08c7aafd51f8,"This paper proposes a new method for learning long-term dependencies in sequential tasks. The proposed method, called Long Expressive Memory (LEM), is a gradient-based recurrent learning method that uses a time-discretized version of a multiscale ODE to solve the problem of exploding and vanishing gradients. Theoretical bounds are derived to show that LEM can mitigate the exploding gradients problem, which is a well-known challenge for gradient based recurrent sequential learning methods. Empirical results on image and time-series classification, dynamical systems prediction, keyword spotting and language modeling demonstrate the effectiveness of the proposed method."
SP:dbf896dd31627b27f0a902c716aff940e5ab7ac2,"This paper proposes a geometric deep learning architecture for small point clouds that is rotation and permutation-equivariant. The proposed architecture is composed of products of terms from the geometric algebra and reductions over those products using an attention mechanism. The geometric algebra provides valuable mathematical structure by which to combine vector, scalar, and other types of geometric inputs in a systematic way to account for rotation invariance or covariance, while attention yields a powerful way to impose permutation equivariance. The experimental results demonstrate the effectiveness of the proposed architecture."
SP:5a6099feb5da2c35f99d4d76c7e0ff3cd3e9c196,"This paper proposes a method to solve the real-time order fulfillment decision problem in the context of online retailing and supply chain management. The proposed method is based on a graph mapping solution framework, where a size-invariant graph model is developed to learn the hidden information on the heterogeneous graph. A novel graph attention mechanism is proposed to consider the high-dimensional edge features in the represented optimization problem. Experiments show that the proposed method substantially outperforms the baseline heuristic method in optimality."
SP:7f7f8245914ecc5b00570916bbcdb6c9b49d26de,"This paper proposes Trans-KnowAttn, a dialogue summarization model with out-of-context (CODC) inference and knowledge-attention modules. The CODC inference module leverages external knowledge from WordNet and a knowledge attention module aggregates the inferred knowledge into a neural summarisation model. To evaluate the inference capability of different methods, the authors propose a new evaluation metric based on CODD. Experiments show that the proposed method can provide statistically significant improvements on CIDEr and traditional automatic evaluation metrics. Human evaluation also demonstrates the superiority of the proposed model."
SP:e1591b266d6c329c6c07f4e5234253249ab1db8c,"This paper studies the problem of learning entity embeddings that can capture semantic dependencies between attributes. The authors consider the setting where the embedding of an entity is obtained by pooling its embedding with its associated attributes. They show that existing embedding models are unable to capture even basic Horn rules. However, they also show that some embedding strategies are capable of modeling both monotonic and non-monotonic attribute dependencies."
SP:794cca5205d667900ceb9a1332b6272320752ef4,"This paper studies the performance of transformer-based models on different reasoning tasks, including mathematical reasoning, commonsense reasoning, logical reasoning, and logical reasoning. The paper is well-written and well-motivated. The results are interesting and interesting. However, there are a few issues that need to be addressed. "
SP:3a16ffa27e7ef0684e6d0f3ee744787aef108a07,"This paper proposes a method for learning to generalize to more complex tasks in a compositional way. The authors propose a method to learn a meta-reasoning algorithm to decide which subproblems to execute by making analogies to previously seen problems. The proposed method is based on the compositional problem graph, which is a graph of tasks of different complexity in terms of problems with shared sub-problems. The paper shows that the proposed method can generalize better than existing methods that do not explicitly use compositional structure of tasks."
SP:7f91f3805bd643e3b796e885b00f88a77aa49d15,"This paper proposes Integral Pruning (IP), a method to reduce the computation cost of DNNs by pruning both weights and activations. The proposed method learns dynamic activation masks by attaching activation pruning to weight pruning after static weight masks are well trained. Through the learning on the different importance of neuron responses and connections, the generated network balances the sparsity between activations and weights and therefore further improves execution efficiency. The feasibility and effectiveness of IPnet are thoroughly evaluated through various network models with different activation functions and on different datasets. "
SP:d34277109f713f78abd3b911c7a38baf18c8c8c1,"This paper proposes a GAN-based method to generate knockoff features for feature selection. The proposed method is based on the Knockoff framework, which allows the generator to generate a set of ""knockoff"" features that satisfy the necessary swap condition. The paper also proposes a method for maximizing the power of the model using Mutual Information Neural Estimation (MINE) and investigate a regularization method to improve the stability of training. Experimental results show that the proposed method outperforms the original model in both Gaussian and non-Gaussian settings."
SP:7bf79b020c2cafaced61f2595ad17e8238c3dc5d,"This paper proposes a new method for sparse Winograd convolution based on spatial-Winograd pruning. The spatial-domain weights are pruned in a structured way, which efficiently transfers the sparsity from the spatial domain into the Winogrrad domain and avoids the need to retrain the network in the spatial-winograd domain. In the second part, the authors propose to use an importance factor matrix to adjust the gradients of the weights of the spatial domains. The proposed method achieves sparsity of 63%, 50% and 74% on CIFAR-10, Cifar-100, and ImageNet."
SP:35e050c84f55f30b5a958128fa5bdaa1cb3f7e90,"This paper proposes a method for unsupervised or semi-supervised clustering of data using a single adversarial objective. The proposed method is based on the Adversarially Learned Mixture Model (AMM), which is a generative model for both continuous and categorical latent variables. The AMM is the first adversarially optimized method to model the conditional dependence between inferred categorical and continuous latent variables in the latent space. Experiments on the MNIST and SVHN datasets show that the AMM allows for semantic separation of complex data when little or no labeled data is available. "
SP:c65ea3a1cc796e65465e8b4dc05ae103316e2cb3,"This paper proposes augment-REINFORCE-merge (ARM) estimator that is unbiased, exhibits low variance, and has low computational complexity. The estimator achieves adaptive variance reduction for Monte Carlo integration by merging two expectations via common random numbers. The variance-reduction mechanism of the ARM estimator can also be attributed to either antithetic sampling in an augmented space, or the use of an optimal anti-symmetric “self-control” baseline function together with the REinFORCE estimator in that augmented space. Experimental results show that the estimator provides state-of-the-art performance in auto-encoding variational inference and maximum likelihood estimation for discrete latent variable models."
SP:c54ee7a7d321a487257d2554c7e689967cf0ceaa,"This paper proposes a new probabilistic programming language called MXFusion, which includes a new type of re-usable building blocks, called probababilistic modules, which consists of a set of random variables with associated probablistic distributions and dedicated inference methods. The proposed method is based on the framework of variational inference, which means that the pre-specified inference methods of individual modules can be transparently used for inference of the whole probabilistics model. Experiments on real data demonstrate the power and convenience of the proposed method. "
SP:b65eb92fcbea57626721a156be6e6cbbad3c071c,"This paper proposes a method for pruning large neural networks while maintaining their performance. To achieve this, the authors propose a saliency criterion based on connection sensitivity that identifies structurally important connections in the network for the given task. This eliminates the need for both pretraining and the complex pruning schedule while making it robust to architecture variations. The method obtains extremely sparse networks with virtually the same accuracy as the reference network on the MNIST, CIFAR-10, and Tiny-ImageNet classification tasks."
SP:986b9781534ffec84619872cd269ad48d235f869,This paper studies the effect of beam search on the performance of neural sequence synthesis. The authors find that increasing the beam width leads to sequences that are disproportionately based on early and highly non-greedy decisions. They propose a fix that is based on constraining the discrepancies considered by the beam search and show that it can eliminate the performance degradation.
SP:b2a8f5c3a417390582f26981fe0c81c16d2bb07d,"This paper proposes Backplay, a method to improve sample efficiency in model-free reinforcement learning. Backplay uses a single demonstration to construct a curriculum for a given task. It starts the agent near the end of the demonstration and moves the starting point backwards during the course of training until we reach the initial state. The method is evaluated on a grid world and a four-player zero-sum game."
SP:426c98718b2dbad640380ec4ccb2b656958389bc,This paper proposes a multi-layer pruning method (MLPrune) that can automatically decide appropriate compression ratios for all layers of a neural network. The proposed method is based on a Kronecker-factored Approximate Curvature (K-FAC) method to estimate the Hessian approximation of the Fisher matrix. Theoretical analysis and empirical results show that the proposed method achieves state-of-the-art results on several benchmark datasets and model architectures.
SP:b97549a4c1f4b2407f97576fed46c25cbf669009,"This paper presents an analytic framework to visualize and understand GANs at the unit-, object-, and scene-level. The authors first identify a group of interpretable units that are closely related to object concepts using a segmentation-based network dissection method. Then, they quantify the causal effect of these units by measuring the ability of interventions to control objects in the output. They examine the contextual relationship between these units and their surroundings by inserting the discovered object concepts into new images. Finally, the authors provide open source interpretation tools to help researchers and practitioners better understand their GAN models."
SP:252c20661ef36f8c32f7412db315747925d3a3d0,"This paper studies the relationship between parameter and function distances between neural networks in a Hilbert space. The paper shows that the distance between parameters and functions can be measured in terms of the function L distance, which can be used as a proxy for the function in the function space. Then, the paper proposes a new learning rule that constrains the distance a network can travel through L-space in any one update. This learning rule is called HCGD, which penalizes each step of SGD to reduce the magnitude of the resulting step in L2-space. "
SP:f6cb7efaef82aff9849c8e157bfe5db5092a6271,"This paper proposes a deep neural network framework called Dynamics Modeling Network (DyMoN) to model biological data. DyMoN is trained as a deep generative Markov model whose next state is a probability distribution based on the current state of the data. The proposed method can be trained using probability distributions derived from the data in any way, such as trajectories derived via dimensionality reduction methods, and does not require longitudinal measurements. The method is well-suited to the idiosyncrasies of biological data, including noise, sparsity, and the lack of longitudinal measurements in many types of systems. "
SP:4828e4160b70ea11e364b48db24cb68cdf86edfc,"This paper proposes a graph Laplacian-based unsupervised learning method for image classification and image generation. The proposed method is based on the spectral clustering theory on the dimension reduced spaces, and the proposed framework can classify and also generate images as the human brains do.  The proposed framework builds an approximate linear connector network C analogous to the cerebral cortex, between the discriminator D and the generator G, to estimate the unknown number of classes. "
SP:d5f5f6a83f0290415ea94b3740a95360a8fa16e3,"This paper proposes a method for learning permutation-invariant representations of sets. The proposed method is based on a permutation optimisation module that learns how to permute a set end-to-end. The permuted set can then be further processed to learn a set representation that is permutation invariant. The method is evaluated on image mosaics, number sorting, and visual question answering tasks. "
SP:cf74c553bae2b1194beaba4df1545d35e66aa5b3,"This paper proposes Projective Subspace Networks (PSN), a method for learning non-linear embeddings from few-shot data. The method is based on the idea of projective subspace networks (PSNs), where samples of a given class are mapped to an affine subspace. The authors show that the PSN can be used for both supervised and semi-supervised learning, and that it is able to generalize well to unseen classes. "
SP:d7544bc4a0ae3237daa207e789a522363fb5170d,"This paper proposes CAML, a meta-learning method for fast adaptation that partitions the model parameters into two parts: context parameters that serve as additional input to the model and are adapted on individual tasks, and shared parameters that are meta-trained and shared across tasks. At test time, the context parameters are updated with one or several gradient steps on a task-specific loss that is backpropagated through the shared part of the network. Compared to approaches that adjust all parameters on a new task (e.g., MAML), CAML can be scaled up to larger networks without overfitting on a single task, is easier to implement, and saves memory writes during training and network communication at test time for distributed machine learning systems."
SP:8a5e86b6770a3c08f861fbf682296dc3a6c02204,"This paper proposes a framework where the user controls what characteristics of the data they want to share (utility) and what they would like to keep private (secret), without asking the utility provider to change its existing machine learning algorithms. The paper first analyzes the space of privacy-preserving representations and derive natural information-theoretic bounds on the utility-privacy trade-off when disclosing a sanitized version of the original data X. The paper then presents explicit learning architectures to learn privacy preserving representations that approach this bound in a data-driven fashion. Finally, the utility providers are willing to collaborate with the sanitization process."
SP:6b0e9a8f0c046a767dce8790489b3e90e12e2c46,"This paper proposes a progressive augmentation of GANs to improve training stability. The proposed method gradually increases the task difficulty of the discriminator by progressively augmenting its input space, thus enabling continuous learning of the generator. Experiments on MNIST, Fashion-MNIST, CIFAR-10, and CELEBA show the effectiveness of the proposed method."
SP:c210982ccdd134d4b293dbe144990398eefe1a86,"This paper proposes a rotation-equivariant convolutional neural network (CNN) model of primary visual cortex (V1) to identify common features independent of individual neurons’ orientation selectivity and phase invariance. The proposed model is trained on the responses of 6000 mouse V1 neurons to natural images recorded in V1 using two-photon imaging. The results show that the proposed model outperforms a regular CNN with the same number of feature maps and reveals a number of common features, which are shared by many neurons and are pooled sparsely to predict neural activity. "
SP:f17090812ace9c83d418b17bf165649232c223e3,"This paper proposes a new algorithm for distributed training of deep neural networks, called SIGNSGD. The algorithm is based on the idea of majority vote, where each worker sends only the sign of their gradient vector to a server, and the overall update is decided by a majority vote. This algorithm uses 32x less communication per iteration than full-precision distributed SGD. The authors prove that the algorithm converges in the large and mini-batch settings, establishing convergence for a parameter regime of ADAM as a byproduct. They also prove that unlike SGD, majority vote is robust when up to 50% of workers behave adversarially."
SP:0ceece0754a1fe9c46a978bb2854932905685fa4,This paper proposes a GAN-based method to generate realistic stock market data. The method is based on a conditional Wasserstein GAN to model the order stream as a stochastic process with finite history dependence of orders in a stock market. The proposed method is evaluated on both synthetic and real stock market datasets. 
SP:ba66503753b3c57781b435c55c47fc9f69450e65,"This paper proposes an unbiased reward estimator aided robust RL framework that enables RL agents to learn in noisy environments while observing only perturbed rewards. The core ideas of the proposed method include estimating a reward confusion matrix and defining a set of unbiased surrogate rewards. Extensive experiments on different DRL platforms show that policies based on the estimated surrogate reward can achieve higher expected rewards, and converge faster than existing baselines."
SP:0e62f75b81b696bf794932d0ceee60e9f665f1da,This paper studies the effect of network depth and width on halting time in gradient descent. The authors show that larger models take fewer training steps to converge. They also provide a simple theoretical analysis for a simplified problem of LNN and show that direct distance is expected to shrink as models get wider. 
SP:40e210d36298e2eafd06d9dc45312ea4fd586ade,"This paper proposes an online primal-dual framework for learning algorithms for online combinatorial optimization problems. The proposed method is based on the idea of adversarial training sets, which are distributions that encourage the learner to find algorithms that work well in the worst-case. The method is tested on the AdWords problem, the online knapsack problem, and the secretary problem. The results show that the proposed method can learn algorithms that are consistent with the optimal algorithms for these problems."
SP:b99732087f5a929ab248acdcd7a943bce8671510,"This paper re-examines several domain-specific components that modify the agent’s objective and environment interface, including domain knowledge and pretuned hyperparameters. The authors show that the performance deteriorates when all these fixed components are replaced with adaptive solutions from the literature. They also show that performance sometimes decreases with the adaptive components, as one might expect when comparing to components crafted for the domain, but sometimes adaptive components perform better. "
SP:47b0c8a984480eb353b36fd877d9775213fb1a5f,"This paper proposes a self-monitoring agent for Vision-and-Language Navigation (VLN) task. The proposed method consists of two components: a visual-textual co-grounding module to locate the instruction completed in the past, the instruction required for the next action, and the next moving direction from surrounding images, and a progress monitor to ensure the grounded instruction correctly reflects the navigation progress. Experiments show that the proposed method achieves state-of-the-art performance on both seen and unseen environments."
SP:7e70c97e9b7b182e974b071c93baafef8b11cf90,"This paper proposes two methods to improve the performance of neural program synthesis from input-output examples. The first method is execution-guided synthesis and the second one is synthesizer ensemble. The proposed methods are applied to the Karel dataset, which is the largest publicly available benchmark for the task. The results show that the proposed methods can boost the accuracy from around 77% to more than 90%. "
SP:dc7dfc1eec473800580dba309446871122be6040,"This paper studies the stability, convergence and acceleration properties of batch normalization (BN) from a theoretical perspective. In particular, the authors study the case of ordinary least squares (OLS) with BN. They show that BN has a scaling law, convergence for arbitrary learning rates for the weights, acceleration effects, as well as insensitivity to the choice of learning rates. They also demonstrate numerically that these findings are not specific to the OLS problem and hold qualitatively for more complex supervised learning problems."
SP:9984d73a1fcfce932cfcafb4d200f70b07723bf3,"This paper provides a theoretical analysis of data noising in Bayesian recurrent neural networks with a particular variational distribution. The authors show that each variant of data-noising is an instance of a variational recurrent neural network with a mixture of Gaussians whose weights depend on statistics derived from the corpus such as the unigram distribution. They use this insight to propose a more principled method to apply at prediction time and propose natural extensions to data noizing under the variational framework. In particular, they propose variational smoothing with tied input and output embedding matrices and an element-wise smoothing method. "
SP:f4a914d3df1a5a21a7365ba78279420f39210884,"This paper proposes a classifier-agnostic saliency map extraction method for image classification. The idea is to extract saliency maps that indicate parts of the image that any classifier could use, not just one given in advance. The proposed method is applied to medical image analysis, where it is shown that the proposed method can outperform existing weakly-supervised localization techniques."
SP:df038354c6a7638116a98d150aa4a8f5f2b0a2da,"This paper proposes a knowledge exchange method to move knowledge from multiple deep nets to a new deep net model, called the student. The student is independent of the teachers and can be trained on entirely different tasks with different output spaces. The proposed method is evaluated on a variety of supervised and reinforcement learning tasks, outperforming fine-tuning and other ‘knowledge exchange’ methods. "
SP:a72072879f7c61270d952f06d9ce995e8150632c,"This paper proposes a method for learning a dynamical system from high-dimensional heterogeneous data streams. The authors propose to perform a soft-clustering of the data and learn its dynamics to produce a compact dynamical model while still ensuring the original objectives of causal inference and accurate predictions. To do so, the authors propose an information theory inspired approach that incorporates stochastic calculus and seeks to determine a trade-off between the predictive accuracy and compactness of the mathematical representation. They provide theoretical guarantees concerning the convergence of the proposed learning algorithm. "
SP:2b03b7ea1264c2671d29e8fa5f3a828412ea7996,"This paper proposes a VAEAC model that is based on a variational autoencoder that can be conditioned on an arbitrary subset of observed features and then sample the remaining features in ""one shot"". The features may be both real-valued and categorical. Training of the model is performed by stochastic variational Bayes. The experimental evaluation on synthetic data, as well as feature imputation and image inpainting problems, shows the effectiveness of the proposed approach and diversity of the generated samples."
SP:f46f0cb43274fb20cba91ef7318305f668bc6928,"This paper proposes an approximation strategy to reduce the memory footprint of deep neural networks during training. During the forward pass, the authors replace activations with lower-precision approximations immediately after they have been used by subsequent layers, thus freeing up memory. The approximate activations are then used during the backward pass. This approach limits the accumulation of errors across the forward and backward pass, because the forward computation across the network still happens at full precision, and the approximation has a limited effect when computing gradients to a layer’s input. Experiments on CIFAR and ImageNet show that the proposed method has only a minor effect on training and validation performance, while affording significant savings in memory usage."
SP:6ad33c6fbdee78c13d9190601637e07d20fe024f,"This paper proposes a novel GAN-based method for face completion. The proposed method is based on a frequency-oriented attention mechanism, which trains a GAN progressively from low resolution to high resolution with conditional vectors encoding controllable attributes. A conditional version of the model is designed to control multiple attributes of the synthesized content. The method is able to complete images in a single forward pass, without any post-processing, and thus fast. "
SP:a300122021e93d695af85e158f2b402d21525bc8,"This paper proposes a statistical analysis to analyze the impact of reduced accumulation precision on deep learning training. It shows that a bad choice for accumulation precision results in loss of information that manifests itself as a reduction in variance in an ensemble of partial sums, and derives a set of equations that relate this variance to the length of accumulation and the minimum number of bits needed for accumulation. The analysis is applied to three benchmark networks: CIFAR-10 ResNet 32, ImageNet ResNet 18 and ImageNet AlexNet."
SP:3a1655a2efdf0246f459b6f82a2948aafc7438a9,"This paper establishes risk convergence and asymptotic weight matrix alignment when applied to deep linear networks on linearly separable data. In particular, the risk converges to 0, and the normalized weight matrix asymptotically equals its rank-1 approximation uiv i. The paper also shows that the linear function induced by the network — the product of its weight matrices — converges in the same direction as the maximum margin solution of the logistic loss."
SP:868dd531fe7886b0260295d25b75cc6d6d28f12d,"This paper proposes phredGAN, an extension of hredGAN to the multi-turn dialogue scenario. The proposed method is based on the persona-based sequence-to-sequence (Seq2Seq) neural network architecture. PhredGAN can capture attributes such as speaker identity, dialogue topic, speaker sentiments and so on. The authors also explore two approaches to accomplish the conditional discriminator: (1) PHRED, a system that passes the attribute representation as an additional input into a traditional adversarial discriminator, and (2) PHredGANd, a dual discriminator system that collaboratively predicts the attribute(s) that generated the input utterance. Experiments are conducted on the Ubuntu Dialogue Corpus and TV series transcripts from the Big Bang Theory and Friends."
SP:017b66d6262427cca551ef50006784498ffc741d,"This paper proposes a goal-driven collaborative task that combines language, vision, and action in a virtual environment as its core components. Specifically, the authors develop a Collaborative image-Drawing game between two agents, called CoDraw. The game involves two players: a Teller and a Drawer. The Teller sees an abstract scene containing multiple clip art pieces in a semantically meaningful configuration, while the Drawer tries to reconstruct the scene on an empty canvas. The two players communicate via two-way communication using natural language. The authors collect the CoDraw dataset of 10K dialogs consisting of 138K messages exchanged between human agents. They define protocols and metrics to evaluate the effectiveness of learned agents on this testbed, highlighting the need for a novel crosstalk condition."
SP:d5126851b9e75b49522d953ee2b253e3e6c836ba,"This paper proposes a new method for learning neural random fields (NRF) based on the idea of inclusive-divergence minimized auxiliary generator (IDG) for continuous data. In particular, the proposed method is based on using the gradient information of the model to estimate the parameters of the generator. The proposed method can be used for both unsupervised/supervised image generation and semi-supervised classification tasks. The method is evaluated on MNIST, SVHN and CIFAR-10 datasets. "
SP:0841febf2e95da495b41e12ded491ba5e9633538,"This paper studies the problem of training time attacks on graph neural networks for node classification that perturb the discrete graph structure. The main idea is to use meta-gradients to solve the bilevel problem underlying training-time attacks, essentially treating the graph as a hyperparameter to optimize. The experiments show that small graph perturbations consistently lead to a strong decrease in performance for graph convolutional networks, and even transfer to unsupervised embeddings."
SP:beb54248806f7a68beb60167c3dbbd45b34dad83,This paper proposes a new generative model based on the Cramer-Wold distance function. The distance function is based on a characteristic kernel called CramerWold kernel and has a simple closed-form in the case of normal prior. The authors show that the proposed method can be used to improve the performance of Wasserstein Autoencoders (SWAE) and WAE-MMD (WAE using maximum mean discrepancy based distance function).
SP:57538c4cac6a4510a0c79e6da3deffae4d6c3b91,"This paper proposes MahiNet, a hierarchical classifier for few-shot learning of many-class classification problems. The proposed method is based on a convolutional neural network (CNN) with a memory-augmented attention module and a multi-layer perceptron (MLP) to produce the probabilities over coarse and fine classes. The authors show that the proposed method outperforms several state-of-the-art models on MCFS classification tasks in both supervised learning and meta-learning scenarios. "
SP:ae9b6f7f2bd29ad1d24c4acbe1ecd345fcd6a081,"This paper proposes a neural speed reading model that can skip and jump text during inference. The model consists of a standard LSTM and two agents: one capable of skipping single words when reading, and one able to exploit punctuation structure (sub-sentence separators, sentence end symbols, or end of text markers) to jump ahead after reading a word. The experimental evaluation shows that the proposed model achieves the best overall floating point operations (FLOP) reduction (hence is faster), while keeping the same accuracy or even improving it compared to a vanilla LSTMs that reads the whole text."
SP:9be782b532e64c6aad140531a17fbba1dd3342cd," adversarial perturbations. This paper proposes a nonlinear radial basis convolutional feature transformation by learning the Mahalanobis distance function that maps the input convolutionsal features from the same class into tight clusters. In such a space, the clusters become compact and well-separated, which prevents small adversarial attacks from forcing a sample to cross the decision boundary. The proposed method is tested on three publicly available image classification and segmentation data-sets."
SP:b08dc82d5098474ddd68ab13003013ee6e7ba989,"This paper proposes a method for on-policy temporally consistent exploration for deep RL agents with sparse rewards. The proposed method is based on dropout, which is used to sample subnetworks from a global random variable for conditional distribution. Two factors, gradients’ alignment with the objective and KL constraint in policy space, are discussed to guarantee NADPEx policy’s stable improvement. Experiments are conducted on Mujoco tasks with sparse reward while naive exploration and parameter noise fail."
SP:304930c105cf036ab48e9653926a5f61879dfea6,"This paper proposes the nonlinearity coefficient (NLC) as a metric to measure the non-linearity of a neural network. The NLC is defined as the Frobenius norm of the Jacobian of the input data and the global variability of the network’s outputs. The authors show that the NLC can be used as a predictor of test error and that attaining a right-sized NLC leads to an optimal test error, at least in fully connected feedforward networks."
SP:17d8dc884e15131636a8c2490085ce42c05433c1,"This paper studies the phenomenon of bias amplification in classifiers, where a machine learning model learns to predict classes with a greater disparity than the underlying ground truth. The authors demonstrate that bias amplification can arise via an inductive bias in gradient descent methods that results in the overestimation of the importance of moderately-predictive “weak” features if insufficient training data is available. This overestimation gives rise to feature-wise bias amplification – a previously unreported form of bias that can be traced back to the features of a trained model. Through analysis and experiments, the authors show that while some bias cannot be mitigated without sacrificing accuracy, some bias can be mitigated through targeted feature selection. Two new feature selection algorithms are proposed to mitigate bias amplification."
SP:2b84207c0015dba126d4ef4a89ef9cc29656f2f8,"This paper studies the effect of over-parametrization on the generalization performance of neural networks. The authors show that the global minimizer of a weakly-regularized cross-entropy loss has the maximum normalized margin among all networks, and that increasing the overparameter improves the normalized margin and generalization error bounds for deep networks. In the case of two-layer networks, an infinite-width neural network enjoys the best generalization guarantees. "
SP:91459c66bb597751ffce8410e283ce3f094bdd5f,This paper proposes a GAN model that can control the location of arbitrary objects within an image by adding an object pathway to both the generator and the discriminator. The object pathway focuses solely on the individual objects and is iteratively applied at the locations specified by the bounding boxes. The global pathway focuses on the image background and the general image layout. The experiments show that through the use of the object pathway we can control object locations within images and can model complex scenes with multiple objects at various locations.
SP:fbfe2c90a70a6adf39fa4d4a3c28f6b5adbc6c06,"This paper proposes a new model-based reinforcement learning method called SOLAR. The main idea is to learn representations that make it easy to retrospectively infer simple dynamics given the data from the current policy, thus enabling local models to be used for policy learning in complex systems. The proposed method is evaluated on a suite of robotics tasks, including a manipulation task on a real Sawyer robotic arm directly from camera images."
SP:9a4c7d9df6685347e75e0ae72928225b7622a73c,"This paper proposes a method for learning policies in POMDPs from off-policy experience. The proposed method is based on structural causal models for counterfactual evaluation of arbitrary policies on individual off policy episodes. It leverages a model to explicitly consider alternative outcomes, allowing the algorithm to make better use of experience data. Empirical results show that the proposed method can improve the performance of model-based RL algorithms by making use of available logged data. "
SP:9371d08e2b3a821e40cc9d4757c22f6cdb731b6a,"This paper studies the relationship between adversarial robustness and the geometry of decision surfaces in the input space. The authors show that the geometry property of the decision surface in input space correlates well with the robustness of a neural network. Based on this observation, the authors propose a robustness indicator that can evaluate a network’s intrinsic robustness property without testing its accuracy under adversarial attacks. They further propose an adversarial training method that can enhance the network's robustness against various adversarial settings. "
SP:6f94f59bc936a11d95ded7309dc2458fee6d2595,This paper proposes an end-to-end DNN training framework that provides quantitative energy consumption guarantees via weighted sparse projection and input masking. The key idea is to formulate the training as an optimization problem in which the energy budget imposes a previously unconsidered optimization constraint. The proposed method trains DNNs that provide higher accuracies under the same or lower energy budgets. 
SP:7f07f3fa8a10b48bb380a7c84bc012ce3541122b,"This paper proposes a Bayesian policy optimization algorithm for learning policies that directly reason about model uncertainty while maximizing the expected long-term reward with respect to this belief distribution. The proposed method builds on recent policy optimization algorithms to learn a universal policy that navigates the exploration-exploitation trade-off to maximize the Bayesian value function. To address challenges from discretizing the continuous latent parameter space, the authors propose a new policy network architecture that encodes the belief distribution independently from the observable state. The method significantly outperforms algorithms that address model uncertainty without explicitly reasoning about belief distributions and is competitive with state-of-the-art POMDP algorithms."
SP:3823faee83bc07a989934af5495dafd003c27921,"This paper proposes a unified framework for building unsupervised representations of entities and their compositions, by viewing each entity as a histogram (or distribution) over its contexts. This enables them to take advantage of optimal transport and construct representations that effectively harness the geometry of the underlying space containing the contexts. The proposed method captures uncertainty via modelling the entities as distributions and simultaneously provides interpretability with the optimal transport map, hence giving a novel perspective for building rich and powerful feature representations. The key tools at the core of this framework are Wasserstein distances and barycenters, hence raising the question from the title. The experimental results show strong advantages gained through the proposed framework."
SP:9ce5b80147ea2c7d0711ec98e31f4bbb5eac534e,"This paper proposes a model-based reinforcement learning method for long-range planning in MuJoCo environments. The proposed method is based on a dynamics model that directly predicts distant states, based on current state and a long sequence of actions, and thus is able to yield more accurate state estimates. Experiments are conducted on two environments to compare the performance of the proposed method with the state-of-the-art model-free methods. "
SP:da14205470819495a3aad69d64de4033749d4d3e,"This paper proposes precision highway, an end-to-end high-precision information flow method to reduce the accumulated quantization error in neural network quantization. The proposed method is applied to both convolutional and recurrent neural networks and achieves 3-bit weight/activation quantization with no accuracy loss and 2-bit quantization without accuracy loss in ResNet-50 and LSTM for language modeling. "
SP:0355b54430b39b52df94014d78289dd6e1e81795,"This paper proposes a method for image restoration for denoising, deblurring, super-resolution, and inpainting problems. The proposed method is based on a GAN-based density estimation method. The authors propose a new optimization algorithm to solve the optimization problem in their method, which is a first-order iterative algorithm for constrained problems. "
SP:2feef921a0563d52fde1c074da754f73e6cabef8,"This paper proposes a novel method for knowledge distillation from few samples. The idea is to add a 1x1 conv-layer at the end of each block in the student-net, and align the block-level outputs between ""teacher"" and ""student"" by estimating the parameters of the added layer with limited samples.  The proposed method is shown to be efficient and effective to distill knowledge from teacher-net to student network constructing in different ways on various datasets and network structures. "
SP:ca491b166bd8bf1a7c71657471a2f58b7fd36609,"This paper proposes a new metric, H-score, to measure the transferability of representations learned from a source task to a target task in task transfer learning. The proposed metric is based on the notion of task relatedness, which is a measure of the similarity between source and target tasks. The authors show that the proposed metric can be used to select a suitable set of source tasks or to devise efficient transfer learning policies. Experiments on both synthetic and real image data demonstrate the effectiveness of the proposed transferability metric."
SP:c6884b04001bd0d43aa47e2d72ebbe2bbc89ab3d,"This paper proposes to add a planning phase in neural machine translation to control the global sentence structure ahead of translation. The proposed approach learns discrete structural representations to encode syntactic information of target sentences. During translation, it can either let beam search to choose the structural codes automatically or specify the codes manually. The word generation is conditioned on the selected discrete codes. Experiments show that the translation performance remains intact by learning the codes to capture pure structural variations."
SP:51810c5f8d40d9ec40469349f1612bf2eefe9aad,"This paper proposes to use a relativistic discriminator to make GANs more similar to integral probability metric (IPM) GAN. The discriminator estimates the probability that the given real data is more realistic than a randomly sampled fake data, on average. The authors show that this discriminator is necessary to make the GAN more stable and produce sensible predictions based on the a priori knowledge that half of the samples in the mini-batch are fake. Empirical results show that the proposed method is more stable than the non-relativistic counterparts."
SP:8df1599919dcb3329553e75ffb19059f192542ea,This paper proposes a method for continual learning that learns to build a model with two sets of parameters. The first set is shared by all tasks learned so far and the second set is dynamically generated to adapt the solver to suit each test example in order to classify it. Extensive experiments have been carried out to demonstrate the effectiveness of the proposed approach. 
SP:1342b6e11d1ccf04ee95b63d8b7a88b184dee43e,This paper proposes Relational Forward Models (RFM) for multi-agent learning. RFM is based on graph neural networks (GNs) to learn to predict the forward dynamics of a multi agent system. The authors show that RFM can outperform the state-of-the-art baselines on the task of learning to coordinate with multiple agents in a shared environment. They also show that embedding RFM modules inside agents results in faster learning systems compared to non-augmented baselines. 
SP:f2f01c7c4fb68c25d6e5ac56cbf79615ed1ee9ee,"-based inverse reinforcement learning (IRL) is a method to learn a reward function from expert demonstrations. In this paper, the authors propose a method that learns a prior that constrains the set of possible reward functions by learning a “prior” that is specifically optimized for the ability to infer expressive reward functions from limited numbers of demonstrations. The authors demonstrate that their method can efficiently recover rewards from images for novel tasks and provide intuition as to how their approach is analogous to learning a prior prior. "
SP:4c2f45c7fd0cac662a33be602985cf360b45fe4d,"This paper proposes a new framework for few-shot meta-learning based on Probabilistic Inference for Prediction (PIP). The proposed method, called VERSA, replaces optimization at test time with forward passes through inference networks, amortizing the cost of inference and relieving the need for second derivatives during training. The experimental results show that the proposed method can handle arbitrary numbers of shots and arbitrary number of classes at train and test time."
SP:44e0f63ffee15796ba6135463134084bb370627b,"This paper presents a novel deep learning architecture for classifying structured objects in ultrafine-grained datasets, where classes may not be clearly distinguishable by their appearance but rather by their context. They model sequences of images as linear-chain CRFs, and jointly learn the parameters from both local visual features and neighboring class information. The visual features are learned by convolutional layers, whereas the class-structure information is reparametrized by factorizing the CRF pairwise potential matrix, which forms a context-based semantic similarity space, learned alongside the visual similarities, and dramatically increases the learning capacity of contextual information. This new parametrization, however, forms a highly nonlinear objective function which is challenging to optimize. To overcome this, they develop a novel surrogate likelihood which allows for a local likelihood approximation of the original CRF with integrated batch-normalization. This model overcomes the difficulties of existing CRF methods to learn the contextual relationships thoroughly when there is a large number of classes and the data is sparse."
SP:18be2cb182761b64fa232c1b7d1899882e5bcf15,"This paper proposes a generative adversarial network (GAN) to generate high-fidelity and locally-coherent audio by modeling log magnitudes and instantaneous frequencies with sufficient frequency resolution in the spectral domain. The authors demonstrate that GANs are able to outperform strong WaveNet baselines on automated and human evaluation metrics, and efficiently generate audio several orders of magnitude faster than their autoregressive counterparts."
SP:0c0f078c208600f541a76ecaae49cf9a98588736,"This paper studies the problem of verifying the robustness of piecewise-linear neural networks to adversarial perturbations. The authors formulate verification of neural networks as a mixed integer program, and propose a novel presolve algorithm to speed up the verification process. The proposed method is able to verify the properties of convolutional and residual networks with over 100,000 ReLUs, which is several orders of magnitude more than networks previously verified by any complete verifier. "
SP:dc48dbfb8f4f25d3ceb7be607e8f2e0bc8f99f14,"This paper proposes to learn a default policy from data by restricting the amount of information the default policy receives, forcing it to learn reusable behaviours that help the policy learn faster. The proposed method is based on the KL regularized expected reward objective, which introduces an additional component, which is called a “default policy”, to learn from data. The authors show that the proposed method can improve the learning speed of the policy in both discrete and continuous action domains. "
SP:08a6a48b05e2c00d77a73413cbba52cda08e184c,"This paper proposes FLOWQA, a multi-turn model for conversational machine comprehension. The proposed model is based on FLOW, which is an alternating parallel processing mechanism that incorporates intermediate representations generated during the process of answering previous questions. The authors claim that FLOW integrates the latent semantics of the conversation history more deeply than previous approaches that concatenate previous questions/answers as input. The experimental results on CoQA and QuAC demonstrate the effectiveness of the proposed method. "
SP:fbb7bb8b4f75715f139c702750b28e7e87aa0e1f,"This paper presents a generative model for learning to predict future edits of Python code. The authors propose a two-headed attention-based model, where the two heads of the two-head attention network are used to capture the intent of previous edits and use it to generate subsequent edits. The proposed model is trained on a large-scale dataset of fine-grained edits from thousands of Python developers.   "
SP:dbb06f953788696f65013765f0a4e6967444fa0f,"This paper proposes a meta-classification method for multi-class classification that leverages pairwise similarity between examples, which is a weaker form of annotation. The proposed method optimizes a binary classifier for pair-wise similarity prediction and through this process learns a multi class classifier as a submodule. The authors formulate this approach, present a probabilistic graphical model for it, and derive a surprisingly simple loss function that can be used to learn neural network-based models. The method generalizes to the supervised, unsupervised cross-task, and semi-supervised settings."
SP:c5c84ea1945b79b70521e0b73f762ad643175020,"This paper studies the problem of visual question answering from the point of view of a neural network trained to answer visual question-answering tasks. The authors compare the performance of neural networks trained on the FiLM model to a set of human question answering tasks from psycholinguistics where the same question was investigated for humans. The results show that the neural networks learn to approximate the number system of the scene, and that the performance declines with more difficult scenes as predicted by Weber’s law. "
SP:0fb732fe65ef1081b046a6aa6e1972e40cfdc247,"This paper proposes a probabilistic extension of DistMult and ComplEx embedding models for link prediction in relational knowledge graphs. The authors argue that knowledge graphs should be treated within a Bayesian framework because even large knowledge graphs typically contain only few facts per entity, leading effectively to a small data problem where parameter uncertainty matters. The main benefit of the Bayesian approach is that it allows for efficient, gradient based optimization over hyperparameters, which would lead to divergences in a non-Bayesian treatment. "
SP:5ff0668b433a190d87d5833d8b2a8ca04daa299c,This paper proposes a new online learning algorithm for supervised dimension reduction. The proposed algorithm is based on the sliced inverse regression (SIR) algorithm. The algorithm is able to update the subspace of significant factors with intrinsic lower dimensionality fast and efficiently when new observations come in. The authors also refine the algorithm by using an overlapping technique and develop an incremental overlapping SIR algorithm. Empirical results show the effectiveness of the proposed algorithm.
SP:4d5b993c6be6e55bdf98eca9a3b23a1bab5d2499,"This paper proposes a multimodal discriminative-discriminative model that combines the idea of multi-modal generative learning with multimodality-specific learning. The proposed model is based on a two-stage model, where the discriminator and discriminator are modality specific. The discriminator is trained to generate a set of independent factors for each modality, and the generative model is trained with a combination of the two. Experiments show that the proposed model achieves state-of-the-art or competitive performance on six multidimensional datasets."
SP:cae76d3c3da91e50fe29cc3b6e204bb3e0793d7e,"This paper proposes a meta-learning approach for adaptive text-to-speech (TTS) with few data. During training, the authors learn a multi-speaker model using a shared conditional WaveNet core and independent learned embeddings for each speaker. The authors introduce and benchmark three strategies: (i) learning the speaker embedding while keeping the waveNet core fixed, (ii) fine-tuning the entire architecture with stochastic gradient descent, and (iii) predicting the embedding with a trained neural network encoder. The experiments show that these approaches are successful at adapting the multi-Speaker neural network to new speakers, obtaining state-of-the-art results in both sample naturalness and voice similarity with merely a few minutes of audio data from new speakers."
SP:e80d6118fc3b9ff3195fea2f6adac88e59d350c2,"This paper presents a connection between f-GANs and various depth functions through the lens of f-Learning. The authors show that the depth functions that lead to statistically optimal estimators can all be viewed as variational lower bounds of the total variation distance in the framework of f -Learning. This connection opens the door of computing robust estimators using tools developed for training GANs. In particular, the authors show in both theory and experiments that some appropriate structures of discriminator networks with hidden layers in gANs lead to statistical optimal location estimators for both Gaussian distribution and general elliptical distributions."
SP:861c5336fda684e5bdd8a05f0af10dd442bf5339,"This paper presents a method to represent a scene via a symbolic program for its objects, attributes, and their relations. The authors propose a model that infers such scene programs by exploiting a hierarchical, object-based scene representation. Experiments demonstrate that their model works well on synthetic data and transfers to real images with such compositional structure. "
SP:a8df2aa6870a05f8580117f433e07e70a5342930,"This paper proposes a Gaussian-gated LSTM RNN model for reducing the number of state updates in recurrent neural networks. The proposed method is based on the idea of timing gates, which controls when a neuron can be updated during training, enabling longer memory persistence and better error-gradient flow. The authors also propose a temporal curriculum learning schedule for the g-LSTM that helps speed up the convergence time of the equivalent LSTMs on long sequence tasks."
SP:e39bcc2ee6db054f0f1d8e8d04291a78488886ae,"This paper proposes a plug-and-play method for out-of-distribution (OOD) samples detection. The proposed method is based on a simple ensembling of first and second order deep feature statistics, which can be used to distinguish in- and out of distribution samples. The method is tested on CIFAR-100, TinyImageNet, and ImageNet. The results show that the proposed method outperforms the state of the art by a large margin in all standard benchmarking tasks."
SP:827f95cdefae78e38a9c4b5718fcf294606a1989,"This paper studies the problem of model recovery for one-hidden-layer fully-connected neural networks with sigmoid activations, where the goal is to recover the weight vectors of the neural network. The authors prove that under Gaussian inputs, the empirical risk function using cross entropy exhibits strong convexity and smoothness uniformly in a local neighborhood of the ground truth, as soon as the sample complexity is sufficiently large. This implies that if initialized in this neighborhood, which can be achieved via the tensor method, gradient descent converges linearly to a critical point that is provably close to the ground-truth without requiring a fresh set of samples at each iteration. "
SP:2b4a39b997934ccf0e6b5fcb4d1e62253592b05f,"This paper proposes feature boosting and suppression (FBS), a new method to predictively amplify salient convolutional channels and skip unimportant ones at run-time. FBS introduces small auxiliary connections to existing convolutionsal layers and preserves the full network structures and accelerates convolution by dynamically skipping unimportant input and output channels. Experiments show that FBS can provide 5x and 2x savings in compute on VGG-16 and ResNet-18, both with less than 0.6% top-5 accuracy loss."
SP:2b1813a3cc39d6e1eba546b456bf8d1f9cc8657c,"This paper studies the training objective of GANs from a mixed Nash equilibrium perspective. The authors propose a proximal proximal algorithm for the mixed Nash equilibria problem. The proposed algorithm is based on a two-player game, where the goal is to find a Nash equilibrium that maximizes the convergence rate of the two players in the game. The convergence rate is proved to be $O(\sqrt{T^{-1/2}/2})$, where $T$ is the number of players, and $\tilde{T}$ is a function of $x_i$ and $y_i$. The authors show that the proposed algorithm converges to the optimal Nash equilibrium $F(x,y)$ where $F$ is an infinite-dimensional game, and $Y$ is $f$-dimensional.  The authors also propose a sampling procedure to reduce their prox methods to simple sampling routines, leading to practically efficient algorithms. Finally, the authors provide experimental results to demonstrate the effectiveness of their algorithm."
SP:79ece684e3c4aca516b4ec41aa8fcb7d86449784,"This paper proposes a method for parameter-efficient transfer and multitask learning with deep neural networks. The basic idea is to learn a model patch a small set of parameters that will specialize to each task, instead of finetuning the last layer or the entire network. The authors show that learning a set of scales and biases is sufficient to convert a pretrained network to perform well on qualitatively different problems (e.g. converting a Single Shot MultiBox Detection (SSD) model into a 1000-class image classification model while reusing 98% of parameters of the SSD feature extractor). Similarly, they show that re-learning existing low-parameter layers (such as depth-wise convolutions) while keeping the rest of the network frozen also improves transfer-learning accuracy significantly."
SP:82b8270b33110e50b5914246f3ca75d3bdbffb6e,"This paper proposes a new normalization method, called mode normalization (MN), for multi-modal data. The proposed method first assigns samples in a mini-batch to different modes via a gating network, and then normalizes each sample with estimators for its corresponding mode (Figure 1). The proposed methods can be incorporated into other normalization techniques such as group normalization by learning which filters should be grouped together (Figure 2)."
SP:034c3bc2b2fe4991f56f168ea7b4b552c500b9ad,"This paper proposes a lottery ticket hypothesis that randomly-initialized, feed-forward networks contain subnetworks (winning tickets) that reach test accuracy comparable to the original network in a similar number of iterations. The authors show that random-initialized networks are easier to train than sparse networks that result from pruning because there are more possible sub-networks from which training might recover a winning ticket. The winning tickets have won the connections that make training particularly effective."
SP:08c662296c7cf346f027e462d29184275fd6a102,This paper proposes a self-supervised reinforcement learning method for Atari games. The method is based on an attentive dynamics model (ADM) that is trained to predict the actions taken by the agent. The ADM is then used as a part of the state representation for the actor-critic algorithm for count-based exploration. The proposed method achieves state-of-the-art results on a set of Atari games with sparse rewards.
SP:614f742a75039b1509343d53e0fb4a6d4088ab3e,"This paper proposes HyperGAN, a generative model that learns to generate all the parameters of a deep neural network. HyperGAN first transforms low dimensional noise into a latent space, which can be sampled from to obtain diverse, performant sets of parameters for a target architecture. The proposed method is trained with conventional maximum likelihood (classification/regression) on the parameters it generates, and an adversarial regularization keeps it from collapsing onto only one mode. Experiments show that HyperGAN can learn to generate parameters which solve the MNIST and CIFAR-10 datasets with competitive performance to fully supervised learning, while learning a rich distribution of effective parameters. "
SP:230b3e008e687e03a8b914084b93fc81609051c0,This paper proposes a differentiable estimator for the ELBO of the variational auto-encoder (VAE) based on importance sampling. The ELBO is used to train VAEs with binary or categorically valued latent representations. The proposed method is tested on two datasets with Bernoulli and Categorically distributed latent representations on two different tasks.
SP:153fe1172e689b345729c0c848cfb38bdae0e5f7,"This paper proposes a method to improve the adversarial robustness of a feed forward neural network by pre-training it on a mean field description of a Boltzmann machine. The method is evaluated on the MNIST dataset, where it is shown to be more robust to adversarial attacks. The authors also show that the performance of the method is correlated with the generative power of the underlying Boltzman machine."
SP:40ade446aa4a700cb1519b9115e8d6cdf33db4a4,This paper studies the effect of small changes in the size of the visible region of a minimal image on human and DNN recognition accuracy. The authors show that DNNs are more sensitive to small changes of the region size than humans. They also show that this phenomenon is independent of previous works that have reported lack of invariance to minor modifications in the object location in DNN. The results are interesting and interesting. 
SP:8ab0bb3eb38958d607fe6b6ebbd921b8abdf149d,"This paper proposes a new multi-agent reinforcement learning framework for the problem of ad-hoc worker teaming. In this setting, the manager is a self-interested agent, and the worker agents have their own minds (preferences, intentions, skills, etc.) and can not be dictated to perform tasks they do not want to do. To achieve optimal coordination among these agents, the authors train a super agent (i.e., the manager) to manage them by first inferring their minds based on both current and past observations and then initiating contracts to assign suitable tasks to workers and promise to reward them with corresponding bonuses so that they will agree to work together. The experimental results have validated the effectiveness of the approach in modeling worker agents’ minds online, and in achieving optimal adhoc teaming with good generalization and fast adaptation."
SP:50a5e5227932ff1196706f53fb82f1785da45e2a,"This paper proposes a new recurrent neural network (RNN) model for time series. The proposed model is based on the LSTM-based recurrent cell, which is able to handle multiple types of features, including sparse and dense features, time features, static features, and static static features. The experimental results show that the proposed model outperforms standard RNNs on time series classification tasks."
SP:f2c3dd2b485d6307847c759a5609b7ebe24b7058,"This paper presents a simple neural model that tries to answer the question whether a given formula has the given property, for example whether a propositional formula is always true. The proposed model is based on a feedforward neural network recursively built for the given formula in a top-down manner. The results of this network are then processed by two recurrent neural networks. Experimental results show that the model is insensitive to propositional atoms."
SP:845ae21e5758a8aabfa610c291fdcc5f61af7748,"This paper proposes a curriculum learning-based method for training deep neural networks. The proposed method is based on the idea that sampling random mini-batches from the entire dataset can improve the speed of learning and improve the final accuracy of the trained network. Specifically, they decompose the problem using the principles of curriculum learning: first, they sort the data by some difficulty measure; second, they sample mini-bats with a gradually increasing level of difficulty. They show that the proposed method improves learning speed and final performance for both small and competitive networks. "
SP:b33a6a1fe4bbae422ba001cbe656f31d07a62025,"This paper proposes a general PAC-Bayesian framework for generalizing over-parameterized neural networks from training data to test data. The main idea is to use the observation that stochastic gradient descent (SGD) finds solutions that lie in flat, wide minima in the training loss, where the output of the network is resilient to small random noise added to its parameters. This observation has been used to provide generalization guarantees for neural networks that are deterministic and uncompressed. In this paper, the authors show that if on training data, the interactions between the weight matrices satisfy certain conditions that imply a wide training loss minimum, then these conditions generalize to the interactions of the matrices on test data, thereby implying a wide test loss minimum. "
SP:d0533cb69d938d4128d17b1a6d8aeb8d1ca6e3fd,"This paper proposes a new training method for discrete latent variable models, inspired by the Expectation Maximization (EM) algorithm, to improve the performance of vector quantized autoencoders (VQ-VAE) on the CIFAR-10 dataset. In particular, the authors propose to use EM to train the discrete autoencoder with a sequence-level knowledge distillation, and then use it to train a non-autoregressive machine translation model. The authors show that the proposed method improves the performance on the larger English-French dataset. "
SP:60628f7db9cfcac3f0dbe6ce0b2a161310525ba0,"-based multi-view learning is an unsupervised self-supervised learning method that aims to learn sentence representations from multiple views of the same data. In this paper, the authors propose two models for learning sentence representations. One model uses a generative objective and the other one uses a discriminative one. In both models, the final representation is an ensemble of two views, in which, one view encodes the input sentence with a Recurrent Neural Network (RNN) and the second view is a simple linear model. The authors show that, after learning, the vectors produced by the models provide improved representations over their single-view learnt counterparts, and the combination of different views gives representational improvement over each view and demonstrates solid transferability on downstream tasks."
SP:f5da908b5f6c19a059d2447b9cda15af5e12dc55,"This paper proposes an online distributed optimization method called Anytime Minibatch (AMB) to mitigate the impact of stragglers. In AMB, all nodes are given a fixed time to compute the gradients of as many data samples as possible. Workers then get a fixed communication time to average their minibatch gradients via several rounds of consensus, which are then used to update primal variables via dual averaging. The paper provides a convergence analysis and analyze the wall time performance. The numerical results show that AMB is up to 1.5 times faster in Amazon EC2 when there is greater variability in compute node performance."
SP:f167ad4bb1e140f692ec71c8baf0a59bff7bbc6f,", the paper proposes to use intrinsic reward functions trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. The authors argue that such intrinsic rewards can circumvent the challenges associated with sparse and skewed rewards in reinforcement learning settings and can help improve sample efficiency. They test this in a simulated driving environment and show that it can increase the speed of learning and reduce the number of collisions during the learning stage."
SP:2db0ece25ebfb4d5e3aa8eb145964ce4be19409f,"This paper proposes a method to improve the performance of Neural Processes (NPs) by incorporating attention into NPs to allow each input location to attend to the relevant context points for the prediction. The proposed method is based on GPs, which is a family of conditional distributions for regression. The method is evaluated on 1D function regression and 2D image regression tasks. "
SP:26535b26a3178050d8aae56b7c9669c9d2408ac8,"This paper provides a theoretical analysis of credit assignment in gradient-based meta-RL. Based on this analysis, the authors propose a new meta-learning algorithm that overcomes both the issue of poor credit assignment and previous difficulties in estimating meta-policy gradients. By controlling the statistical distance of both pre-adaptation and adapted policies during meta policy search, the proposed algorithm endows efficient and stable meta learning. The experimental results show that ProMP outperforms previous Meta-RL algorithms in sample-efficiency, wall-clock time, and asymptotic performance."
SP:be5f2c827605914206f5645087b94a50f59f9214,"This paper presents NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability. The proposed method is able to solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. It generalizes to novel distributions and can solve problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs. It can also be used to help construct proofs for unsatisfiable problems."
SP:a99fddee87b684b2783ef3a21f8c15c19631953b,"This paper proposes a method for learning a policy for autonomous driving that is robust enough to drive a real vehicle. The authors propose to augment the imitation loss with additional losses that penalize undesirable events and encourage progress. They show that the proposed method can handle complex situations in simulation, and present ablation experiments that emphasize the importance of each of the proposed changes and show the model is responding to the appropriate causal factors. "
SP:f5be102f16ed9ac70a2e9e2580111226fb0d8b71,"This paper proposes a method to select a subset of training data to train a small proxy model to estimate the utility of individual training data points, and then select the most informative ones for training the large target model. The method is based on uncertainty sampling (Lewis & Gale, 1994) from active learning, where uncertainty can be measured by metrics such as entropy of the output probabilities. Extensive experiments show that the proposed method leads to a 1.6x and 1.8x speed-up on CIFAR10 and SVHN by selecting 60% and 50% subsets of the training data."
SP:4332dfe46b715595e9f1dd3f6a79b82a646b4c23,"This paper proposes a new method for planning in continuous control problems, where the goal is to learn a distribution over future trajectories. The authors propose to use SMC-based methods to estimate the density of the target distribution, which can then be used as a probabilistic inference problem. The proposed method is evaluated on Mujoco, where it is shown to be able to learn multimodal policies."
SP:d3e4e2c267fd9ae536ab1816d5c1ba8e8fec19be,"This paper studies the relationship between adversarial robustness and the input data distribution. The authors show that adversarial training is sensitive to the data distribution, and that the robustness of adversarial trained models can be affected by the distribution of the data. They also show that the clean accuracy and robust accuracy can be disentangled from each other, and the robust accuracy of adversarially trained models are more sensitive to data distribution than clean accuracy. Empirical results on MNIST and CIFAR-10 show that standard trained models achieve comparable clean accuracies on these datasets, but adversarial-trained models achieve significantly different robustness accuracies."
SP:a49fd0479a977c8fb45199210f9ff7dd2c0dabaf,"This paper proposes a new normalization technique called Equilibrium normalization (EquiNorm) for batch normalization. EquiNorm is an extension of BatchNorm that uses a transformation of layer weights instead of layer outputs to keep the contribution of positive and negative weights to the output in equilibrium. Experiments are conducted on CIFAR-10/100, SVHN, and ILSVRC 2012 ImageNet to validate the effectiveness of the proposed method."
SP:8188f15c8521099305aa8664e05f102ee6cea402,This paper proposes a method to detect mislabeled examples in training neural networks. The proposed method is based on the idea of implicit regularization of stochastic gradient descent with large learning rates. The authors propose to use the loss statistics to identify the mislabeling examples and discard them on the fly and continue training with the rest of the examples. Empirical results demonstrate the effectiveness of the proposed method on several datasets. 
SP:fbf023a772013e6eca62f92982aecf857c16a428,"This paper proposes a theoretical analysis of the pretraining and downstream tasks of latent variable generative models (HMMs). The generative model is either a Hidden Markov Model or an HMM augmented with a latent memory component, motivated by long-term dependencies in natural language. The authors show that under certain non-degeneracy conditions on the HMM, simple classification heads can solve the downstream task. They also show that prompt tuning obtains good downstream performance under certain conditions, while head tuning performs poorly."
SP:217c4205a99f9b37283137826c4be6ab9bfb4e8e,"This paper studies the problem of out-of-distribution generalization, i.e., transferability between source and target domains. The authors define transferability as the difference between the total variation and Wasserstein distance between the two domains. They show that transferability can be estimated with enough samples and give a new upper bound for the target error based on our transferability. Empirically, they evaluate the transferability of the feature embeddings learned by existing algorithms for domain generalization. They find that many algorithms are not quite learning transferable features, although few could still survive. In light of this, they propose a new algorithm for learning transferability features and test it over various benchmark datasets. "
SP:46f5874c8cbdb0832e92adcea85ca8a1b9ddc28a,"This paper studies the expressivity of reward as a way to capture tasks that we would want an agent to perform. The authors frame this study around three abstract notions of “task” that might be desirable: (1) a set of acceptable behaviors, (2) a partial ordering over behaviors, or (3) partial ordering of trajectories. The main results prove that while reward can express many of these tasks, there exist instances of each task type that no Markov reward function can capture. They then provide a polynomial-time algorithm that can construct a reward function that allows the agent to optimize tasks of each of these three types, and correctly determine when no such reward function exists. An empirical study corroborates and illustrates the theoretical findings."
SP:9d8b57d60a0e59f9d9a90605094e8ef895f1c7de,"This paper studies the problem of generalization in reinforcement learning. The authors show that the sequential structure of the RL problem necessitates new approaches to generalization beyond the well-studied techniques used in supervised learning. They show that generalization to unseen test conditions from a limited number of training conditions induces implicit partial observability, effectively turning even fully-observed MDPs into POMDPs. Based on this observation, the authors recast the generalization problem in RL as solving the induced partially observed Markov decision process, which they call the epistemic decision process (POMDP). They demonstrate the failure modes of algorithms that do not appropriately handle this partial observable, and suggest a simple ensemble-based technique for approximately solving the partially observed problem. Empirically, the proposed algorithm LEEP achieves significant gains in generalization over current methods on Procgen benchmark suite."
SP:10de45510320b7ddb7ffb18b33e67f7cad609418,"This paper proposes a framework for estimating higher-order derivatives of value functions in meta-reinforcement learning. The proposed method is based on off-policy evaluation, which allows for estimating the Hessian matrix of the value functions. The paper also proposes a new family of estimates, which can be easily implemented with auto-differentiation libraries, and lead to performance gains in practice. "
SP:54a60315416c6e304f59741490c335fb1e2ce95d,"This paper studies the problem of distributed learning with a central server. The authors propose a new algorithm, MCM, that performs bidirectional compression and achieves the same convergence rate as algorithms using only uplink (from the local workers to the central server) compression. To obtain this improvement, the authors design MCM such that the downlink compression only impacts local models, while the global model is preserved. MCM additionally combines model compression with a memory mechanism. Theoretical results on these algorithms are successively presented in Sections 3 and 4."
SP:6b19f16c429ffa7f613b57d082bde3794a8e29e0,"This paper introduces counterfactual invariance as a formalization of the requirement that changing irrelevant parts of the input data shouldn’t change model predictions. The authors connect counterfactually invariance to out-of-domain model performance, and provide practical schemes for learning (approximately) counterfactible invariant predictors (without access to counter-factual examples). It turns out that both the means and implications of counterfactuality depend fundamentally on the true underlying causal structure of the data. "
SP:6ff26839a14991597555ead4c82eb6ddb61e4dbc,"This paper proposes an adaptive pseudo-augmentation method for training GANs with limited data. The main idea is to augment the real data distribution with generated images, which deceives the discriminator adaptively and mitigates the problem of discriminator overfitting. Extensive experiments demonstrate the effectiveness of APA in improving synthesis quality in the low-data regime. The paper also provides a theoretical analysis to examine the convergence and rationality of the proposed method."
SP:0f3fcffb6dfbf344bd5ef73c3f6d3d84d2f13887,This paper proposes a point process causal inference framework for causal inference between pairs of event variables in multivariate recurrent event streams by extending Rubin’s framework for the average treatment effect (ATE) and propensity scores to multivariate point processes. Theoretical justification of the proposed method is provided. Empirical results on synthetic and real-world event datasets demonstrate the effectiveness of the method.
SP:5db39fbba518e24a22b99c8256491295048ec417," of residual connections in GNNs can amplify GNN's vulnerability against abnormal node features. This is undesirable because in real-world applications, node features in graphs could often be abnormal such as being naturally noisy or adversarially manipulated. To address this issue, the authors propose and derive a simple, efficient, interpretable, and adaptive message passing scheme, leading to a novel GNN with Adaptive residual, AirGNN1. Extensive experiments under various abnormal feature scenarios demonstrate the effectiveness of the proposed algorithm."
SP:66c5acd36a5fb74478d3f5ecaffc8479868dbe81,"This paper studies the problem of online sequential decision-making in a multi-armed bandit setting, where an agent must balance exploration and exploitation. The authors derive a set of Bayesian ‘optimistic’ policies which, in the stochastic multi-arm bandit case, includes the Thompson sampling policy. They provide a new analysis showing that any algorithm producing policies in the optimistic set enjoys Bayesian regret for a problem with A actions after T rounds. They extend the regret analysis for optimistic policies to bilinear saddle-point problems which include zero-sum matrix games and constrained bandits as special cases. In this case, they show that Thompson sampling can produce policies outside of the optimistic subset and suffer linear regret in some instances."
SP:c1b7b550b9f90bd5e9bf5218e22d1977ed1686a5,"This paper studies the convergence of a damped version of Finito, Prox-DFinito, for composite finite-sum minimization. In particular, the authors show that it converges to a sample-size-independent rate that matches that of uniform-iid-sampling with variance reduction. They also provide a theoretical analysis of the effect of random reshuffling, cyclic sampling, and shuffling-once on the convergence rate. "
SP:35c14ef59d9ed68f3f6e3a8cac95fdf3216a9d8f,"This paper studies the convergence of REPS in the setting of stochastic gradient descent. In particular, the authors show that REPS can be used to learn a policy that is near-optimal in terms of the gradient norm of the policy. The authors also show that the REPS algorithm can be applied to the setting where the policy is learned from the gradient of the MDP. Finally, they propose a method that uses a plug-in estimator to estimate the gradient norms of the REP gradients."
SP:3945d1fb07900d63b7706ca0bce5e451ebfe476b,"This paper proposes a method to disentangle the overall model vulnerability into the sensitivity to the rotation, the translation, the scale, and local 3D structures. Besides, the authors also propose metrics to evaluate the spatial smoothness of encoding 3d structures, and the representation complexity of the DNNs. The experiments show that adversarial training can improve the robustness to rotation and translation."
SP:81db7f494ca61d3586adb505bf5d2e6e9e2c2bd0,"This paper proposes an extension of RegretNet, a neural-network-based auction mechanism, to encode constraints using (potentially human-provided) exemplars of desirable allocations. The authors also introduce a new metric to evaluate an auction allocations’ adherence to such socially desirable constraints and demonstrate that their proposed method is competitive with current state-of-the-art neural network based auction designs. They validate their approach through human subject research."
SP:ee24606a968ab17b7827e7f3982af11636f6a2ee,"This paper studies the problem of user-level differential privacy in supervised learning. In this setting, each user has a training data set drawn from their own distribution Pi, and the goal is to learn to solve a linear regression problem with each user’s regression vector lying in a common, unknown low-dimensional subspace. The authors provide algorithms that exploit popular non-private approaches in this domain like the Almost-No-Inner-Loop (ANIL) method, and show that their algorithms satisfy nearly optimal estimation error guarantees. They also establish a general, information-theoretic upper bound via an exponential mechanism-based algorithm."
SP:3925fc528de17b8b2e93808f5440ea0503895b75,This paper proposes a new benchmark to test the performance of state-of-the-art VQA models against human-adversarial examples. The proposed AdVQA benchmark consists of a set of images where the model predicts the answer to a question and the human tries to find an image where the predicted answer is incorrect. The authors find that a wide range of state of the art models perform poorly when evaluated on these examples and conduct an extensive analysis.
SP:04f90c10f4ceca0dace727ad875265ce405fff9f,"This paper studies the role of heterogeneous cell types in the MEC of the entorhinal cortex (MEC). The authors first show that heterogeneous MEC cells are just as reliable in their response patterns as the more stereotypical cell types, suggesting that they have a coherent functional role. Next, they evaluate a spectrum of candidate models in terms of their ability to describe the response profiles of both stereotypical and heterogeneous cells. They find that recently developed task-optimized neural network models are substantially better than traditional grid cell-centric models at matching most MEC neuronal response profiles, including those of grid cells themselves, despite not being explicitly trained for this purpose. Finally, they extend models to encompass MEC cell responses as a function of reward as well as spatial position, introducing a simple modeling paradigm that performs reward-modulated foraging in the context of the path-integration task. "
SP:57f9812fa5e7d0c66d412beb035301684d760746,This paper studies the problem of pathological training dynamics of KL-regularized reinforcement learning with behavioral reference policies derived from expert demonstrations. The authors show that the pathology occurs for commonly chosen behavioral policy classes and demonstrate its impact on sample efficiency and online policy performance. The pathology can be remedied by using non-parametric behavioral reference policy. The proposed method outperforms state-of-the-art approaches on a variety of locomotion and dexterous hand manipulation tasks.
SP:cb38b58054581db865d8c2a4065f062724ca0a5e,"This paper studies the asymptotic decay of the test error of a teacher-student kernel regression method for kernel regression with neural tangent kernels, where the student kernel is a prior on the true function of the form described by Eq. (2), and the teacher kernel corresponds to the prior on a prior of the target function. The teacher kernel is defined as a convolutional neural network with a small filter size. The student kernel can be thought of as an overparametrized one-hidden-layer neural network. The paper shows that in the ridgeless case, the learning curve exponents of the teacher and student kernels depend on the size of the training set. In particular, if the teacher's filter size is smaller than that of the student's filter, the teacher will have a smaller test error than the student, and the student will have larger test error. In the ridged case, however, the student has a smaller filter size than the teacher, so the teacher has smaller test errors. "
SP:7e35e4e610e75c922f2b5219ce625e417f010eeb,This paper proposes a deterministic autoencoding framework for variational autoencoders (VAEs) that can be applied to multi-modal priors. The authors propose to use the distance metric used in the non-parametric Kolmogorov-Smirnov (KS) test for equality of probability distributions to regularize the training objective of the VAE. The proposed method is shown to improve the performance of VAEs on continuous and discrete data. 
SP:6232d8738592c9728feddec4462e61903a17d131,"This paper proposes a method for self-supervised adversarial detection based on disentangling class features and semantic features in an autoencoder. Specifically, the proposed method uses a discriminator network to discriminate between benign and adversarial examples. The proposed method is evaluated on CIFAR-10 and ImageNet datasets and compared with several other methods in the literature."
SP:e9d9ad4fb9dc3cb25f7282c0979a8ccb252f692a,"This paper presents a method to model the brain's representation of syntactic information in the context of a natural text. The authors propose a multi-dimensional embedding space for syntactic features that encode information about the syntactic structure of sentences. They show that the embeddings can explain additional variance in the brain activity of various parts of the language system, even after controlling for complexity metrics that capture processing load. They also show that regions well-predicted by syntactic feature are distributed in the language systems and are not distinguishable from those processing semantics."
SP:b4ad4632cd55a85b5403e936c4bd828e484473f7,"This paper proposes to use energy-based models (EBMs) to handle compositional generation over a set of attributes in the latent space of a pre-trained generative model such as StyleGAN. The authors propose a novel EBM formulation representing the joint distribution of data and attributes together, and they show how sampling from it is formulated as solving an ordinary differential equation (ODE). The proposed method is simple, fast to train, and efficient to sample. Experimental results show that the proposed method outperforms the state-of-the-art in both conditional sampling and sequential editing. "
SP:f5bf6d43bcc90a3bc5f2157fcc041f18224f95e0,"This paper proposes a federated linear contextual bandits model, where individual clients face different K-armed stochastic bandits coupled through common global parameters. By leveraging the geometric structure of the linear rewards, a collaborative algorithm called Fed-PE is proposed to cope with the heterogeneity across clients without exchanging local feature vectors or raw data. The proposed algorithm relies on a novel multi-client G-optimal design, and achieves near optimal regret for both disjoint and shared parameter cases with logarithmic communication costs. Experiments demonstrate the effectiveness of the proposed algorithms on both synthetic and real-world datasets."
SP:d3ff3012c614638c8d86322cfe461a9383f082ab,"This paper proposes a new offline model-based offline RL algorithm, COMBO, that trains a value function using both the offline dataset and data generated using rollouts under the model while also additionally regularizing the value function on out-of-support state-action tuples generated via model rollouts. Theoretically, the authors show that COMBO satisfies a policy improvement guarantee in the offline setting. Empirical results on the D4RL benchmark suite show the effectiveness of the proposed method."
SP:ca6f11ed297290e487890660d9a9a088aa106801,"This paper studies the evolution of features during deep learning training using a set of stochastic differential equations (SDEs) that each corresponds to a training sample. Each SDE contains a drift term that reflects the impact of backpropagation at an input on the features of all samples. The main finding uncovers a sharp phase transition phenomenon regarding the intra-class impact: if the SDEs are locally elastic in the sense that the impact is more significant on samples from the same class as the input, features of the training data become linearly separable, meaning vanishing training loss; otherwise, the features are not separable. Moreover, in the presence of local elasticity, the emergence of a simple geometric structure called the neural collapse of the features."
SP:a1cb0ca55bc919125f4dad5bcc6e0ad6c2527c1e,"This paper proposes a framework for learning to synthesize a program that describes the procedure to solve a task in a flexible and expressive manner, solely from reward signals. To alleviate the difficulty of learning to compose programs to induce the desired agent behavior from scratch, the authors propose to first learn a program embedding space that continuously parameterizes diverse behaviors in an unsupervised manner and then search over the learned program embeddings space to yield a program to maximize the return for a given task. The experimental results demonstrate that the proposed framework not only learns to reliably synthesize task-solving programs but also outperforms DRL and program synthesis baselines while producing interpretable and more generalizable policies. "
SP:4be92f235a78f030c4f09c920dc41eab0ba69aa8,"This paper studies the problem of physics-informed neural networks (PINNs) and shows that PINNs can fail to learn relevant physical phenomena for even slightly more complex problems. In particular, the paper shows that the soft regularization in PINNs, which involves PDE-based differential operators, can introduce a number of subtle problems, including making the problem more ill-conditioned. The paper also shows that these possible failure modes are not due to the lack of expressivity in the NN architecture, but that the PINN’s setup makes the loss landscape very hard to optimize. To address these failure modes, the authors propose two approaches to address these issues. The first approach is to use curriculum regularization, where the loss term starts from a simple PDE regularization and becomes progressively more complex as the NNs gets trained. The second approach is a sequence-to-sequence learning task, rather than learning to predict the entire space-time at once. "
SP:cfd501bca783590a78305f0592f537e8f20bce27,"This paper proposes Cycle Self-Training (CST), a principled self-training algorithm that explicitly enforces pseudo-labels to generalize across domains. CST cycles between a forward step and a reverse step until convergence. In the forward step, CST generates target pseudo-label with a source-trained classifier, and then updates the shared representations to make the target classifier perform well on the source data. The proposed method outperforms previous state-of-the-art methods in 21 out of 25 tasks for object recognition and sentiment classification."
SP:af51c83f2f16cbbd4eb087adb978d7dc1c2d7d76,"This paper proposes a single-stage structured pruning method called Discriminative Masking (DAM) to learn compact representations of features at every layer of a neural network. The key intuition behind DAM is to discriminatively prefer some of the neurons to be refined during the training process, while gradually masking out other neurons. The proposed method achieves SOTA performance on a variety of tasks, including dimensionality reduction, recommendation system, graph representation learning, and structured network pruning for image classification. "
SP:f831d25830efa88434b43e900241a5ad81119360,"This paper proposes a new architecture for self-attention networks, called Neural Interpreters, that can be applied to arbitrary set-valued inputs or representations. In particular, the proposed architecture is based on the idea of learning a sequence of functions that are end-to-end learned. The proposed architecture can flexibly compose computation along width and depth, and lends itself well to capacity extension after training. Empirical results on image classification and visual abstract reasoning on Raven Progressive Matrices show that the proposed model can generalize to new tasks in a sample-efficient manner."
SP:b78c78fd0b10a94466c049e97c59a56ea5455df6,"This paper proposes Behavior Transfer (BT), a method to transfer knowledge acquired during an unsupervised pre-training phase to a new task. The authors argue that standard fine-tuning strategies alone are not enough for efficient transfer in challenging domains. Instead, BT leverages pre-trained policies for exploration and that is complementary to transferring neural network weights. The experiments show that, when combined with large-scale pre- training in the absence of rewards, existing intrinsic motivation can lead to the emergence of complex behaviors, which can then be leveraged by BT to discover better solutions than without without pretraining."
SP:8f0eb77f64b185627b7a82005e0b9e368197c8cd,"This paper proposes PiRank, a new class of differentiable surrogates for ranking, which employ a continuous, temperature-controlled relaxation to the sorting operator based on NeuralSort. The authors show that PiRank exactly recovers the desired metrics in the limit of zero temperature and further propose a divide-and-conquer extension that scales favorably to large list sizes, both in theory and practice. Empirically, the authors demonstrate the role of larger list sizes during training and show that the proposed PiRank significantly improves over comparable approaches on publicly available learning-to-rank benchmarks."
SP:c4d1c99a2d53e90336c7e110738bc1eb8a38f3b4,"This paper proposes a reinforcement learning algorithm for estimating the ground-state energy of a variational quantum entmanent (VQE). The algorithm is based on a curriculum learning approach, where the goal is to find a VQE that maximizes the expressivity of the circuit while maintaining low depth. The algorithm uses a feedback-driven curriculum learning method to adapt the complexity of the learning problem to the current performance of the current learning algorithm and it incrementally improves the accuracy of the result while minimizing the circuit depth. Experimental results show that the proposed algorithm achieves state-of-the-art results in terms of circuit depth and accuracy."
SP:4fc9a0b34192e1b3587c8e2128851c6aebddd26b,"This paper studies the effect of arbitrary class distributions within the query sets of few-shot tasks at inference, removing the class-balance artefact. Specifically, the authors model the marginal probabilities of the classes as Dirichlet-distributed random variables, which yields a principled and realistic sampling within the simplex. Empirical results show that the proposed method outperforms state-of-the-art methods across several data sets, models and few shot settings."
SP:eb760d20f3820827c41358ff191d22f4fb78847e,"This paper proposes a patch-based patch-by-patch inference scheduling method to reduce the memory consumption of tiny neural networks. The proposed method is based on the observation that the first several blocks of a convolutional neural network have an order of magnitude larger memory usage than the rest of the network. To alleviate this issue, the authors propose to shift the receptive field and FLOPs to the later stage and reduce the computation overhead. The authors also propose to automate the process with neural architecture search to jointly optimize the neural architecture and inference scheduling, leading to MCUNetV2."
SP:b147639f58dd3197beb928c609d636e853c6bdd6,"This paper studies the problem of Bayesian automated mechanism design in unstructured dynamic environments, where a principal repeatedly interacts with an agent, and takes actions based on the strategic agent’s report of the current state of the world. The goal is to compute an optimal mechanism which maximizes the principal's utility in the face of the self-interested strategic agent. The authors give an efficient algorithm for computing optimal mechanisms, with or without payments, under different individual-rationality constraints, when the time horizon is constant. The algorithm is based on a sophisticated linear program formulation, which can be customized in various ways to accommodate richer constraints. "
SP:1c9c01a77aee3bf00e33bffd6be9ec49d2e5ba29,"This paper studies the problem of neural architecture search (NAS) for graph neural networks (GNNs) for different tasks. In particular, this paper focuses on the question of how NAS is able to select the desired GNN architectures. To this end, the authors conduct theoretical analysis and measurement study with experiments to discover that gradient-based NAS methods tend to select proper architectures based on the usefulness of different types of information with respect to the target task. The experiments also show that gradient based NAS also suffers from noises hidden in the graph, resulting in searching suboptimal GNNs. Based on these findings, the paper proposes a Graph differentiable Architecture Search model with Structure Optimization (GASSO), which allows differentiable search of the architecture with gradient descent and can discover graph neural architectures with better performance through employing graph structure learning as a denoising process in the search procedure. Extensive experiments on real-world graph datasets demonstrate the effectiveness of the proposed GASSO model."
SP:1ff7a4f6f2ef647b7a9d224f8250b46b7935359a,"This paper studies the problem of fair clustering, where a dataset is partitioned into clusters that consist of nearby points in a metric space. The authors consider two fairness objectives: the group utilitarian objective and the group egalitarian objective, as well as the group leximin objective. They derive lower bounds on the approximation of the utilitarian and egalitarian objectives and introduce algorithms with provable guarantees for them. They also derive impossibility results for other natural fairness objectives. "
SP:581faa3e1fd39ddefc2740985fa8f94cacdf2b64,"This paper studies the limitations of edge independent random graph models, in which each edge is added to the graph independently with some probability. The authors show that edge independent models are inherently limited in their ability to generate graphs with high triangle and other subgraph densities. They also provide a simple generative model that balances overlap and accuracy, performing comparably to more complex models in reconstructing many graph statistics."
SP:0d77c22df0830cb675b11ad883d014e3a1933c8e,"This paper investigates the effect of the choice of ReLU(0) in the output of a neural network on backpropagation and training performance. The paper shows that the effect disappears with double precision, while it is systematic at 16 bits. For vanilla SGD training, the choice ReLU($0) = 0 seems to be the most efficient, and the gain in test accuracy is more than 10 points (two runs). "
SP:73e6281bf556a6ae92bdcf8d68e6e8973bc8b56b,"This paper proposes a method for learning policies that use few bits of information in reinforcement learning. The proposed method, called robust predictable control (RPC), combines ideas from information bottlenecks, model-based RL, and bits-back coding into a simple and theoretically-justified algorithm. The method jointly optimizes a latent-space model and policy to be self-consistent, such that the policy avoids states where the model is inaccurate. The experimental results show that the proposed method achieves much tighter compression than prior methods, yielding up to 5x higher reward than a standard information bottleneck."
SP:dff08f0b290f3d138fd0299933052f3dc363b2d3,"This paper proposes a new Transformer architecture for graph representation learning. The proposed method uses a learned positional encoding (LPE) to learn the position of each node in a given graph. This LPE is then added to the node features of the graph and passed to a fully-connected Transformer. By leveraging the full spectrum of the Laplacian, the proposed method is theoretically powerful in distinguishing graphs, and can better detect similar sub-structures from their resonance. Empirical results show that the proposed model is competitive with or better than the state-of-the-art on several well-known graph benchmarks."
SP:f2bee0c4a6c558970538b422e5e36750447cd9bc,"This paper studies the problem of two-alternative elections where voters' preferences depend on a state variable that is not directly observable. Each voter receives a private signal that is correlated to the state variable. The authors propose a mechanism that elicits and aggregates the private signals from the voters, and outputs the alternative that is favored by the majority. In particular, voters truthfully reporting their signals forms a strong Bayes Nash equilibrium. "
SP:0823bd0dbb8045648e81a4c93e9782069cf2c605,"This paper studies the Hessian of deep linear neural networks, which is a fundamental object of study, closely tied to various problems in deep learning, including model design, optimization, and generalization. The authors develop theoretical tools to analyze the range of Hessian map, which provide us with a precise understanding of its rank deficiency and the structural reasons behind it. This yields exact formulas and tight upper bounds for Hessian rank for deep linear networks, allowing for an elegant interpretation in terms of rank deficiency. "
SP:24cdcb12fca34680d8b34bc61c51b9003368228a,"This paper proposes a new metric for quantifying linear disentanglement based disentangling (LSBD) based on linear symmetry-based disentangled representations. The proposed metric, DLSBD, is based on the notion of linear symmetries, which is defined as the sum of two linear terms, where one of them is a linear transformation and the other one is a non-linear transformation. This metric is then used to define LSBD. The paper also proposes LSBD-VAE, a semi-supervised method to learn LSBD representations, which can be used to evaluate LSBD methods. "
SP:374bfeb067fcea966c97e1721d65cd9d03d26ed3,"This paper proposes a new method for training deep state-space models (DSSMs) by combining variational inference with classic Bayesian filtering/smoothing to model dynamics more accurately than RNN-based DSSMs. The proposed method, called EKVAE, is based on the Kalman-VAE framework, which combines amortised variational estimation with variational smoothing. Empirical results show that the proposed method improves system identification and prediction accuracy on the image data of a moving pendulum and the reacher environment. "
SP:15ed638782cc0398df38ec49eed5c5ca9962d3b9,"This paper proposes a method to generate counterfactual explanations for a given query image. The proposed method is based on deep inversion, where a deep model is trained to generate images from the training distribution, and the goal is to generate explanations that contain discernible changes (for easy interpretability) while also being realistic (consistency to the data manifold). The authors show that existing methods are insufficient for producing meaningful explanations. They propose DISC (Deep Inversion for Synthesizing Counterfactuals) that improves upon the existing methods by using stronger image priors, incorporating a novel manifold consistency objective, and adopting a progressive optimization strategy. They also show that DISC is effective at learning classifier decision boundaries and robust to unknown test-time corruptions."
SP:e536acfe82bb5e41fa61929d44dad0b8f7c5ab19,"This paper proposes an algorithm for identifying regions of high inter-decision-maker disagreement (i.e., regions where the assignment of decision-maker has a large causal effect on the decision-making process) in a causal inference problem. The proposed algorithm is based on the idea of causal inference, where the goal is to find a region of high disagreement between decision-makers. The authors provide a generalization bound for the proposed algorithm. The algorithm is tested on a semi-synthetic experiment and real-world healthcare datasets. "
SP:8fa76926a21fb41c5c9fd357246c06a42ae26b9f,"This paper proposes a token-based method for image synthesis. The proposed method takes as input a sequence of latent tokens to predict the visual tokens for synthesizing an image. Specifically, the proposed method introduces two semantically different visual tokens, i.e., the learned constant content tokens and the style tokens from the latent space. The tokenGAN is able to control the image synthesis by assigning the styles to the content tokens by attention mechanism with a Transformer. Experiments on FFHQ and LSUN Church show the effectiveness of the proposed methods."
SP:fa34d40d07c0f154a69841b241a2743fe721f95c,"This paper shows that avoiding interpolation through ridge regularization can significantly improve generalization in both linear regression and classification settings. The authors provide asymptotic expressions for the robust risk for linear regression in Section 3 that explicitly explain robust overfitting. For classification with logistic regression, the authors also provide an explanation."
SP:09f080f47db81b513af26add851822c5c32bb94e,"This paper proposes a canonical point autoencoder (CPAE) that predicts dense correspondences between 3D shapes of the same category. The CPAE encodes an arbitrary ordered point cloud to a canonical primitive, e.g., a sphere, and decodes the primitive back to the original input instance shape. The primitive plays a key role to map all the unordered point clouds on the canonical surface and to be reconstructed in an ordered fashion. Once trained, points from different shape instances that are mapped to the same locations on the primitive surface are determined to be a pair of correspondence. Experimental results on 3D semantic keypoint transfer and part segmentation transfer show that the proposed method outperforms state-of-the-art correspondence learning methods."
SP:8f28988012f8dca74c90316f7feeda15d49af2c5,"This paper proposes a new method for domain generalization (DG) based on the empirical risk minimization (ERM) method. The authors show that the ERM method is suboptimal if the minima of the loss function are too sharp. To address this issue, the authors propose a new algorithm called Stochastic Weight Averaging Densely (SWAD) to find flatter minima. SWAD is based on a dense and overfit-aware stochastic weight sampling strategy. Experiments show that SWAD outperforms the existing DG methods on several benchmark datasets. "
SP:5068e491ee0ae7282cd98ef966b471389e2ab069,"This paper presents a large-scale study of performance predictors for neural architecture search (NAS) by analyzing 31 techniques ranging from learning curve extrapolation, to weight-sharing, to supervised learning, to zero-cost proxies. The authors test a number of correlation and rank-based performance measures in a variety of settings, as well as the ability of each technique to speed up predictor-based NAS frameworks. The results act as recommendations for the best predictors to use in different settings, and the authors show that certain families of predictors can be combined to achieve even better predictive power."
SP:c883fe9c7f4a5f950340ac79b6d7194278b1a1eb,"This paper studies the inherent privacy of releasing a single sample from a Dirichlet posterior distribution. The authors derive a simple privacy guarantee of the Dirichle posterior sampling, which allows them to analyze its utility in various settings. Specifically, the authors provide accuracy guarantees of the posterior sampling in Multinomial Dirichlets and private normalized histogram publishing. "
SP:aaea75b9c614f77e8025922780f9a8dd9c9d4aab,"This paper proposes a new algorithm to compute random walks efficiently and locally at the same time. The main contribution of this paper is to propose an efficient parallel algorithm for computing random walks that is both memory and round efficient, and yields an efficient local clustering algorithm. The experimental results show that the proposed algorithm is significantly more scalable than previous approaches."
SP:5739081ab7aaf71d389705c28f14a316fbb0a728,"This paper theoretically analyzes the typical learning performance of `1-regularized linear regression (`1-LinR) for Ising model selection using the replica method from statistical mechanics. For random regular graphs in the paramagnetic phase, an accurate estimate of the typical sample complexity is obtained. The paper also provides an efficient method to accurately predict the non-asymptotic behavior of the sample complexity for moderate M,N, such as precision and recall. "
SP:9d6202ab0010166f383d6d064aebe02ae97a1dfc,"This paper studies the fuzzy k-means problem, which is a generalization of the well-known kMeans problem. In this setting, the learner is allowed to interact with an oracle (domain expert) asking for the similarity between a certain set of chosen items. The authors prove that having a few similarity queries enables one to get a polynomial-time approximation algorithm to an otherwise conjecturally NP-hard problem. They also provide algorithms for fuzzy clustering in this setting that ask O(poly(k) log n) similarity queries and run with polynomially-complexity. "
SP:a8057c4708dceb4f934e449080043037a70fabf7,"This paper proposes a method for augmenting model-based RL by encouraging a learned model and value function to be jointly self-consistent. The proposed method is based on the idea that the value function should be consistent with the learned model. The authors evaluate the proposed method in tabular and function approximation settings, and find that it can improve policy evaluation and control. "
SP:cd01ab8f03cfb1bb067478ca82944d3a42826ca4,"This paper proposes a sampling method for few-shot learning based on the difficulty of the episodes. The proposed sampling method is algorithm-agnostic and can be used to improve the performance of existing methods. The method is evaluated on a variety of datasets, algorithms, network architectures, and protocols. "
SP:b31b1ee7067d4da70916986ba13e80bb14e2fdfe,"This paper studies the problem of logistic bandits where the number of outcomes that can be selected by the user is larger than two (e.g., ‘click’ vs ‘no click’). The authors use multinomial logit (MNL) to model the probability of each one of K+1 2 possible outcomes (+1 stands for the “not click” outcome), and the goal is to maximize the expected revenue. For this problem, the authors propose an upper confidence bound (UCB-based algorithm) that achieves regret $\tilde{O}(dK p T)$ with small dependency on problem-dependent constants that can otherwise be arbitrarily large and lead to loose regret bounds."
SP:0eaf058ed224464f6682cbbd80f716c89759f467,"This paper proposes a max-min entropy framework for reinforcement learning (RL) to overcome the limitation of the soft actor-critic (SAC) algorithm implementing the maximum entropy RL in model-free sample-based learning. The proposed algorithm aims to learn to visit states with low entropy and maximize the entropy of these low-entropy states to promote better exploration. For general Markov decision processes (MDPs), an efficient algorithm is constructed under the proposed max-max entropy framework based on disentanglement of exploration and exploitation. Numerical results show that the proposed algorithm yields drastic performance improvement over the current state-of-the-art RL algorithms."
SP:19107a648d3d23403a8693b065ee842833a0b893,"This paper studies the problem of learning continuous-time Markov chains of discrete sets of items (e.g., genetic mutations) in the context of cancer progression. The authors show that the learning task is generally underspecified in the usual setting of cross-sectional data, and propose to use a number of additional independent items to determine time order, and hence resolve underspecification. The proposed method scales exponentially in the number of items considered, thus limiting the analysis to around 20 items. To alleviate this issue, the authors propose an approximate likelihood maximization method that relies on a fast gradient approximation, which can scale to hundreds of items and is orders of magnitude faster than previous methods."
SP:68dfc737a8ea591da2c7fe048a5b8995c89e1fec,"This paper proposes UDoc, a new pretraining framework for document understanding. UDoc extends the Transformer to take multimodal embeddings as input. Each input element is composed of words and visual features from a semantic region of the input document image. An important feature of UDoc is that it learns a generic representation by making use of three self-supervised losses, encouraging the representation to model sentences, learn similarities, and align modalities. Extensive experiments and analyses validate the effectiveness of the proposed UDoc."
SP:de6c4c1a418d1ebadc294d77dda18612c163d9c0,"This paper studies data clustering problems with lp-norm objectives (e.g. k-median and k-means) in the context of individual fairness, where the goal is to find k centers such that the objective is minimized while respecting the individual fairness constraint that every point v has a center within a distance at most r(v), where r is v’s distance to its (n/k)th nearest point. The authors propose a local-search algorithm for this problem, which is based on linear programming (LP) techniques to obtain a worst-case guarantee on the objective which is much better than in MV20, and empirically, this objective is extremely close to the optimal. "
SP:feb4664dfd5066cff582f6b4f9b17c6169049ceb,This paper proposes a polynomial-time Gaussian sampling-based algorithm for the MAX-K-CUT and MAX-AGREE graph partitioning problems. The proposed algorithm is based on the idea of sampling from a Gaussian distribution over the vertices of the graph. The authors show that the proposed algorithm can achieve the best approximation ratio of the existing methods for the two problems. 
SP:cfd6cf88a823729c281059e179788248238a6ed7,"This paper proposes a motion-aware unit (MAU) to capture reliable inter-frame motion information by broadening the temporal receptive field of the predictive units. The MAU consists of two modules, the attention module and the fusion module. The attention module aims to learn an attention map based on the correlations between the current spatial state and the historical spatial states. Based on the learned attention map, the historical temporal states are aggregated to an augmented motion information (AMI). In this way, the predictive unit can perceive more temporal dynamics from a wider receptive field. The fusion module is utilized to further aggregate the augmented motion Information (AMI) and current appearance information (current spatial state) to the final predicted frame. Moreover, an information recalling scheme is employed into the encoders and decoders to help preserve the visual details of the predictions. The experimental results show that the proposed MAU can outperform other state-of-the-art methods on both video prediction and early action recognition tasks."
SP:07fa7cd4344d77a6e0f180d4f251cc8356b5202f,"This paper studies nonlinear function approximation with two-layer neural networks with polynomial and ReLU activation functions for deep RL with neural network approximation of the Q function. In particular, the authors show that the sample complexity scales linearly in the algebraic dimension of the neural network. They also provide sample-efficient algorithms in the generative model setting under completeness and Bellman completeness. In the online RL setting, they provide sample efficient algorithms for online RL with structured polynomials. "
SP:cac881243abde92a28c110f5bd84d115ed189bda,"This paper proposes a new benchmark to evaluate the generalization performance of deep metric learning (DML) methods under out-of-distribution (OOD) distribution shifts. Specifically, the authors construct train-test splits of increasing difficulty and present the ooDML benchmark to characterize generalization under OOD shifts in DML. Based on the new benchmark, they conduct a thorough empirical analysis of DML methods and find that while generalization tends to degrade with difficulty, some methods are better at retaining performance as the distribution shift increases. Finally, they propose few-shot DML as an efficient way to consistently improve generalization in response to unknown test shifts presented in the oOdML benchmark."
SP:bacff3685476855a32549d03095375649fd89df2,"This paper proposes METAOD, a data-driven approach to unsupervised outlier model selection (UOMS) based on meta-learning to automatically select a good outlier detection algorithm and its hyperparameter(s) (collectively called a model) on a new dataset. The proposed method is based on a large database of 300+ models from the literature. Extensive experiments show that the proposed method outperforms no model selection as well as other meta learning techniques that are tailored for UOMS. "
SP:bf1c45ef27953acab2195d54c8197d360c1e8190,"This paper proposes a differentiable surrogate objective framework for solving linear and semi-definite negative quadratic programming problems with soft linear and non-negative hard constraints. The paper provides theoretical bounds on the constraints’ multipliers and derives the closed-form solution with respect to predictive parameters and thus gradients for any variable in the problem. Empirical results on synthetic linear programming, portfolio optimization, and resource provisioning show that the proposed method outperforms two-stage and other predict+optimization approaches."
SP:41a9806ee6c0c84e046b7de79eb54dfe00de6995,"This paper proposes DropGNN, a graph neural network (GNN) framework that uses dropouts to improve the expressiveness of GNNs. In particular, dropouts are randomly dropped from the input graph, and the output of the GNN is combined with the dropout results. Theoretical results on the number of dropouts and the expressive power of dropout GNN are provided. Empirical results show that the proposed method performs better than other GNN methods on several graph benchmarks."
SP:090dc0471d54e237f423034b1e1c46a510202807,"This paper proposes a dual-stream network (DS-Net) to explore the representation capacity of local and global pattern features for image classification. Specifically, the authors propose an Intra-scale Propagation module to process two different resolutions in each block and an Inter-Scale Alignment module to perform information interaction across features at dual scales. The proposed DS-Net outperforms DeiT-Small by 2.4% in terms of top-1 accuracy on ImageNet-1k and achieves state-of-the-art performance over other Vision Transformers and ResNets."
SP:9dd460c3506a9a508b92baa63dff6b487e0eeca0,"This paper proposes a unified framework for learning visual concepts and physics models of objects and their interactions from videos and language. The visual perception module parses each video frame into object-centric trajectories and represents them as latent scene representations. The concept learner grounds visual concepts (e.g., color, shape, and material) based on the language, thus providing prior knowledge for the physics engine. The differentiable physics model is implemented as an impulse-based differentiable rigid-body simulator to infer physical properties, such as mass, restitution, and velocity, by fitting the simulated trajectories into the video observations."
SP:c511066c38f9793bacb4986c564eafa36e032f39,"This paper proposes SIMILAR (Submodular Information Measures based actIve LeARning), a unified active learning framework using recently proposed submodular information measures (SIM) as acquisition functions for active learning. The proposed method is able to deal with imbalance or rare classes, out-of-distribution data in unlabeled set, and redundancy. SimILAR significantly outperforms existing active learning algorithms by as much as 5%-18% in the case of rare classes and 5%+10% in out of distribution data on several image classification tasks."
SP:c141dc29b487ebfaa20ee50786886b0383d938bc,"This paper studies identity tests for ranking data that is generated from Mallows model both in the asymptotic and non-asymptotic settings. First, the authors consider the case when the central ranking is known, and devise two algorithms for testing the spread parameter of the Mallows models. The first one is obtained by constructing a Uniformly Most Powerful Unbiased (UMPU) test for the asymetric setting, and then converting it into a sample-optimal non-asymetrical identity test. The second one is derived from an optimal learning algorithm for the Mallow's model, and is both easy to compute and sample optimal for a wide range of parameters. The experiments show that the proposed tests scale gracefully with the number of items to be ranked."
SP:4c00bcc561832b581f479905b5e3310aeb3bdce2,"This paper proposes a method to learn a generalizable neural radiance field that can be used to generate a video of a human performance from sparse multi-view cameras. The proposed method is based on a parametric human body model for robust performance capture. Specifically, a temporal transformer aggregates tracked visual features based on the skeletal body motion over time, and a multiview transformer is proposed to perform cross-attention between the temporally-fused features and the pixel-aligned features at each time step to integrate observations on the fly from multiple views. Experiments on the ZJU-MoCap and AIST datasets show that the proposed method significantly outperforms recent generalizable NeRF methods on unseen identities and poses."
SP:5495d9168a8770eb2493e2d2bb6b68423e82b9e6,"This paper proposes a method to automatically search the search space of vision transformers. The proposed method is based on a weight-sharing supernet, which is used to evolve different search dimensions guided by their E-T Error computed using a weight sharing supernet. The authors also provide design guidelines of general vision transformer with extensive analysis according to the space searching process. The experiments on ImageNet verify the proposed automatic search space design method can improve the effectiveness of design space, thus boosting the performance of searched architectures. "
SP:c77b83c667a9b63fe15582336a77a34e96fd667b,"This paper studies the problem of learning linear threshold functions (LTFs) in the learning from label proportions (LLP) framework. In this setting, the learning is on a collection of bags of feature-vectors with only the proportion of labels available for each bag. First, the authors provide an algorithm that efficiently produces an LTF that satisfies at least (2/5)-fraction of the bags. If all the bags are non-monochromatic (i.e., bags of size two with differently labeled features), the algorithm satisfies (1/2)-fractions of them. For the special case of OR over the d-dimensional boolean vectors, the algorithm achieves an additional $\�(1/d) in accuracy for the two cases. The main result provides evidence that these algorithmic bounds cannot be significantly improved, even for learning monotone ORs using LTFs."
SP:2eb193c76355aac08003c9b377895202fd3bd297,"This paper presents a method to create surrogate benchmarks for neural architecture search that output the full training information for each architecture, rather than just the final validation accuracy. The method uses singular value decomposition and noise modeling to create the surrogate benchmarks. The paper also introduces a learning curve extrapolation framework to modify single-fidelity algorithms, and shows that it leads to improvements over the state-of-the-art algorithms."
SP:6ed1637ac697821931f685db0d476b9f7b56971a,"This paper proposes SimplEx, a user-centred method that provides example-based explanations with reference to a freely selected set of examples, called the corpus. SimplEx uses the corpus to improve the user’s understanding of the latent space with post-hoc explanations answering two questions: (1) which corpus examples explain the prediction issued for a given test example? (2) What features of these corpus examples are relevant for the model to relate them to the test examples? SimplEx provides an answer by reconstructing the test latent representation as a mixture of corpus latent representations. The authors also propose a novel approach, the Integrated Jacobian, that allows SimplEx to make explicit the contribution of each corpus feature in the mixture. Experiments on tasks ranging from mortality prediction to image classification show that the decompositions are robust and accurate."
SP:c8f82ec90f891d7394933483b7f926155ac363ef,"This paper proposes a Transformer-based visual embedding for VLP to better learn visual relation and further promote inter-modal alignment. Specifically, the authors propose a metric named Inter-Modality Flow (IMF) to measure the interaction between vision and language (i.e., Inter-modality Flow). They also design a novel masking optimization mechanism named Masked Feature Regression (MFR) to further promote the intermodality learning. The experimental results show that the proposed method outperforms the state-of-the-art VLP models, but also exhibits better performance on the IMF metric. "
SP:ecc173185ec28d0ef75c60df260ac4faba059f61,"This paper studies the problem of estimating the information leakage of an iterative randomized learning algorithm when the internal state of the algorithm is private. The authors study the dynamics of the Rényi differential privacy loss throughout the training process, and derive a provably tight bound on the divergence between the pair of probability distributions over parameters of models trained on neighboring datasets. They prove that the privacy loss converges exponentially fast, for smooth and strongly convex loss functions, which is a significant improvement over composition theorems. "
SP:acb1e0dc8d6ef5607e7d3ec9893b5364b9a6e831,"This paper proposes a new method for solving quadratic optimization problems using Reinforcement Learning (RL). The method is based on the idea of learning a policy to tune the parameters of the optimization problem to accelerate convergence to high-accuracy solutions. The proposed method, RLQP, is shown to outperform the state-of-the-art QP solvers by up to 3x and generalizes well to previously unseen problems."
SP:eb68e98d9baf9118381d25d4b2da030a6f78577f,This paper studies the effect of the principal components bias (PC-bias) on the learning rate of deep linear networks. The authors show that the convergence rate of the parameters of a deep linear network is exponentially faster along directions corresponding to the larger principal components of the data. They also show that this bias is more prominent at earlier stages of the learning process. They compare this bias to the spectral bias and show that both biases can be seen independently and affect the order of learning in different ways. 
SP:1598bad835a657e56af3261501c671897b7e9ffd,"This paper proposes a method to train clean models on backdoor-poisoned data. The authors frame the overall learning process as a dual-task of learning the clean and the backdoor portions of data. They identify two inherent characteristics of backdoor attacks as their weaknesses: 1) the models learn backdoored data much faster than learning with clean data, and the stronger the attack the faster the model converges on the backdoor data; 2) the backdoor task is tied to a specific class (the backdoor target class). Based on these two weaknesses, the authors propose a general learning scheme, Anti-Backdoor Learning (ABL), to automatically prevent backdoor attacks during training. ABL introduces a two-stage gradient ascent mechanism for standard training to 1) help isolate backdoor examples at an early training stage, 2) break the correlation between backdoor examples and the target class at a later training stage."
SP:6c0b7cb37e285cb9342f049d7b61af4565fe01fd,"This paper proposes a new method for 3D-aware image synthesis. The proposed method, called ShadeGAN, aims to address the shape-color ambiguity in existing 3D image synthesis methods with a shading-guided generative model that satisfies the proposed multi-lighting constraint. In this way, the proposed method is able to learn more accurate 3D shapes for better image synthesis, and achieves better performance on the 3D shape reconstruction task."
SP:4b3dad77d79507c512877867dfea6db87a78682d,"This paper proposes a quasi-Bayesian method for instrumental variable regression. The method is based on the recently developed kernelized IV models. The authors derive the quasi-posterior and analyze its theoretical properties, and present the approximate inference algorithm with time cost comparable to the corresponding point estimation methods. The algorithm can be further extended to work with neural network models. "
SP:fd0d72d0689f170f8157dc7f79deb01348e414b3,"This paper proposes a multilingual open-retrieval answer generation model that can answer questions across many languages, even for ones without language-specific annotated data or knowledge sources. The authors introduce a new dense passage retrieval algorithm that is trained to retrieve documents across languages for a question. They also propose an autoregressive generation model to generate answers directly in the target language without any translation or in-language retrieval modules as used in prior work. The experimental results show that CORA substantially outperforms the previous state-of-the-art on two open QA benchmarks across 26 languages, 9 of which are unseen during training."
SP:aa4d44b283ef4fea4335847c89fc7b5874169850,"This paper investigates the effect of ERM on the out-of-domain generalization of deep neural networks trained with ERM. The authors show that the domain adaptation theory of Ben-David et al. (2007) is not sufficient to explain the performance of ERMs. Instead, the authors propose to use other measures to explain ERM generalization. They show that Fisher information, predictive entropy, and maximum mean discrepancy are good predictors of the ERM performance. "
SP:340c5353a63884b49cfdc46ddb6153b28b2e894f,"This paper studies backdoor data poisoning attacks, where the attacker injects several watermarked, mislabeled training examples into a training set, and the model reliably errs on watermarked examples. The authors propose a theoretical framework to study backdoor attacks for classification problems, and analyze important statistical and computational issues surrounding these attacks. They identify a parameter called memorization capacity that captures the intrinsic vulnerability of a learning problem to a backdoor attack. They argue about the robustness of several natural learning problems to backdoor attacks, and show that some natural problem settings cannot yield successful backdoor attacks. "
SP:4c925cde6e5b9813946452fdd6b47816e2490f49,"This paper analyzes the effect of width and depth on the performance of deep neural networks. In particular, the authors focus on Deep Gaussian Processes (Deep GP), a class of nonparametric hierarchical models that subsumes neural nets. They show that depth accentuates a model’s non-Gaussianity, while width makes models increasingly Gaussian. They find a “sweet spot” that maximizes test performance before the limiting GP behavior prevents adaptability, occurring at width = 1 or width = 2 for non-parametric Deep GP. They also show that conventional neural networks trained with L2 regularization may need up to 500+ 1000 hidden units for sufficient capacity, but further width degrades performance."
SP:3f74dc3dc2cb444b3097aae1288dad5355e9a4d4,"This paper studies the problem of federated learning, where a group of clients periodically coordinate with a central server to train a statistical model. The authors propose FedLin, a general algorithm that aims to tackle some of the key challenges intrinsic to FL, namely objective heterogeneity, systems heterogeneity, and infrequent and imprecise communication. They show that existing FL algorithms suffer from a fundamental speed-accuracy conflict: they either guarantee linear convergence but to an incorrect point, or convergence to the global minimum but at a sub-linear rate, i.e., fast convergence comes at the expense of accuracy. In contrast, when the clients’ local loss functions are smooth and strongly convex, the authors show that FedLin guarantees linear convergence to global minimum, despite arbitrary objective and systems heterogeneity. They also establish matching upper and lower bounds on the convergence rate of FedLin that highlight the effects of infrequent, periodic communication. Finally, FedLin preserves linear convergence rates under aggressive gradient sparsification."
SP:29f44f2f7d0e9748eed6732ed19ca3335acb04e3,"This paper proposes a new method to approximate the Sliced-Wasserstein distance (SW) based on the concentration of measure phenomenon. The main idea is to assume that the one-dimensional projections of a high-dimensional random vector are approximately Gaussian. Based on this observation, the authors develop a simple deterministic approximation for SW that is both accurate and easy to use compared to the usual Monte Carlo approximation. The authors derive nonasymptotical guarantees for their approach, and show that the approximation error goes to zero as the dimension increases, under a weak dependence condition on the data distribution. "
SP:7d5ec55a01247b65e4a8f1973d448214585d6baa,"This paper investigates the relationship between the representations learned by language models, translation models, and language tagging tasks. The authors use an encoder-decoder transfer learning method from computer vision to investigate the structure among 100 different feature spaces extracted from hidden representations of various networks trained on language tasks. This method reveals a low-dimensional structure where language models and translation models smoothly interpolate between word embeddings, syntactic and semantic tasks, and future word embedding. They find that this representation embedding can predict how well each individual feature space maps to human brain responses to natural language stimuli recorded using fMRI. They also show that the principal dimension of this structure can be used to create a metric which highlights the brain's natural language processing hierarchy."
SP:698d6c344fe94ea4ec3ce54601f5976d82d00b85,"This paper proposes a method for few-shot conditional image generation. The method is based on a diffusion-based prior over the latent representations to improve generation and contrastive self-supervised learning to improve representation quality. D2C can adapt to novel generation tasks conditioned on labels or manipulation constraints, by learning from as few as 100 labeled examples. On conditional generation from new labels, the proposed method achieves superior performance over state-of-the-art VAEs and diffusion models."
SP:36d11071cbf989e1f02232d39f52a42e781a5b2b,"This paper studies the problem of self-supervised learning in the context of contrastive learning, where the goal is to learn representations by pushing positive pairs, or similar examples from the same class, closer together while keeping negative pairs far apart. The authors propose a novel concept of the augmentation graph on data. They propose a loss that performs spectral decomposition on the population augmentation graph and can be succinctly written as a contrastive loss on neural net representations. Minimizing this objective leads to features with provable accuracy guarantees under linear probe evaluation. Empirically, the proposed method can match or outperform several strong baselines on benchmark vision datasets."
SP:ae4bc7f2a00feb13e458ab17804c06709374ceee,"This paper studies the parameterized complexity of Bayesian Network Structure Learning (BNSL), a classical problem that has received significant attention in empirical but also purely theoretical studies. The authors show that a different kind of parameterization -- notably by the size of a feedback edge set -- yields the fixed-parameter tractability of BNSL w.r.t. virtually all well-studied graph parameters. They also analyze how the complexity depends on the representation of the input. Finally, they show how their results can be adapted to the closely related problem of Polytree Learning."
SP:3dc67f04c04466b0fe5aebb01c7578cd24caee0c,"This paper proposes a novel active learning algorithm in the streaming setting for binary classification tasks. The algorithm leverages weak labels to minimize the number of label requests, and trains a model to optimize a surrogate loss on a set of labeled and weak-labeled points. The theoretical analysis shows that the algorithm attains favorable generalization and label complexity bounds, while the empirical study on 18 real-world datasets demonstrate that the proposed algorithm outperforms standard baselines, including the Margin Algorithm."
SP:0e5812d8ed33d5b6d9d59dbb2312c7b1c9363f3d,"This paper proposes a novel measure of complexity called Kolmogorov growth (KG) to measure the complexity of a classifier’s function space, which is used to derive new generalization error bounds that only depend on the final choice of the classification function. Based on these bounds, the authors propose a new regularization method called N2N regularization, which constrains the network trajectory to remain in the low KG zone during training. The proposed method is shown to improve the generalization performance of deep neural networks."
SP:d5608d3317c2b246375eb14006b9e6a6026e0ab6,"This paper proposes VICReg (variance-invariance-covariance regularization) for self-supervised learning of image embeddings, which aims to prevent the encoders from producing constant or non-informative embedding vectors. The proposed method is based on two regularization terms: (1) a term that maintains the variance of each embedding dimension above a threshold, and (2) another term that decorrelates each pair of variables of the embedding vector. The authors show that the proposed method can avoid the collapse problem with two regularizations terms applied to both embedding dimensions separately, and achieves state-of-the-art performance on several downstream tasks."
SP:bc8a9fcf7de41f1a1b0c6d0fc3fdcac5c5f87613,"This paper proposes Information Directed Reward Learning (IDRL), a general active reward learning approach for learning a model of the reward function from expensive feedback with the goal of finding a good policy rather than reducing the model’s error. The proposed method is based on a Bayesian reward model and selects queries that maximize the information gain about the difference in return between plausibly optimal policies. The method achieves similar or better performance with significantly fewer queries by shifting the focus from reducing the reward approximation error to improving the policy induced by the reward model."
SP:d88f2bb3ed48deb04fae1b8f008ca69d8566819f,"This paper proposes a method to predict the parameters of a neural network in a single forward pass. The method is based on graph neural networks (GNNs) and is able to predict performant parameters in a fraction of a second, even on a CPU. The proposed method is evaluated on CIFAR-10 and ImageNet and achieves good results."
SP:8b233a2a5049ccda84e8840b97b800ffc5862e16,"This paper studies the distortion-perception (DP) function for the mean squared error (MSE) distortion and the Wasserstein-2 perception index. The authors show that the DP function is always quadratic, regardless of the underlying distribution. In the Gaussian setting, the authors also provide a closed form expression for such estimators. For general distributions, the estimators can be constructed from estimators at the two extremes of the tradeoff: the global MSE minimizer and a minimizer of the MSE under a perfect perceptual quality constraint."
SP:60ce257ca7c1dbbc88e4f36bad40f7eeb133368a,"This paper proposes a new cascaded GNN architecture for representation learning on textual graphs. The proposed architecture is based on the Transformer-GNN architecture, where layer-wise GNN components are nested alongside the transformer blocks of language models. The paper also proposes a progressive learning strategy, where the model is successively trained on manipulated data and original data to reinforce its capability of integrating information on graph. Extensive evaluations are conducted on three large-scale benchmark datasets, where GraphFormers outperform the SOTA baselines with comparable running efficiency."
SP:199a281592df47d71c57fdcbd24b40a0b0de9d76,"This paper studies the problem of user-level differential privacy (DP) under the assumption that a user contributes a total of $m$ samples to the learning process. The authors show that the privacy cost decreases as $O(1/\sqrt{m}$ as users provide more samples, while increasing the number of users decreases the privacy costs at a faster rate. They also provide lower bounds showing the minimax optimality of their algorithms for mean estimation and stochastic convex optimization. "
SP:ad5b98e656cac6eb931f80d852c397d117cf1609,"This paper proposes a self-consistent Gaussian Process (GPs) theory for deep neural networks (DNNs) trained with noisy gradient descent on a large training set. The main contribution of this paper is to derive a GPs theory for DNNs trained with finite-DNN and feature learning effects. The authors derive the GPs for a toy model of a two-layer linear convolutional neural network (CNN) and show that there is a sharp transition between a feature learning regime and a lazy learning regime in this model. In addition, the authors show that for a non-linear DNN and a fully connected network, there is also a transition between feature learning phase and lazy learning phase."
SP:231655b9fad6c76eb0ff1ba305ed421f5c293623,"This paper studies the problem of communication in the context of signaling games, where agents communicate over a noisy channel. The authors theoretically show that inductive biases on both the training framework and the data are needed to develop a compositional communication. Moreover, the authors prove that compositionality spontaneously arises in the signaling games. Finally, experimentally confirm that a range of noise levels, which depends on the model and data, indeed promotes compositionality."
SP:9d326254d77a188baf5bde39229c09b3966b5418,"This paper presents ResMLP, a multi-layer network architecture for image classification. The proposed model consists of two layers: a linear layer and a two-layer feed-forward network. The linear layer consists of a linear filter and a linear convolutional layer, and the feed forward layer is a feedforward layer. The two layers are connected by a linear connection between the two layers. The network is trained with heavy data augmentation and distillation. The authors also train the model in a self-supervised setting to remove the need for a labelled dataset. Finally, the model is adapted to machine translation tasks."
SP:6dabaca9a77620b7c4019bf5f9c2a88628fc691c,"This paper studies the problem of multi-class classification, where a stream of adversarially chosen queries arrive and must be assigned a label online. Unlike traditional bounds which seek to minimize the misclassification rate, this paper minimizes the total distance from each query to the region corresponding to its correct label. This notion of loss not only measures the rate of errors but also the degree of each error; choosing a wildly inaccurate label is punished more than selecting a label that is ""almost"" correct. "
SP:5c0114535065d5125349f00bafdbccc911461ede,"This paper proposes a method to transfer knowledge from oracle-based VQA methods to self-supervised ones. The authors propose a regularization term in the loss function to supervise the sequence of required reasoning operations. They provide a theoretical analysis based on PAC-learning, showing that such program prediction can lead to decreased sample complexity under mild hypotheses. They also demonstrate the effectiveness of this approach experimentally on the GQA dataset and show its complementarity to BERT-like pre-training."
SP:40fd96105e77063de4a07d4b36fe19385434c533,This paper proposes a new memory module for recurrent neural networks (RNNs) that can simulate a Universal Turing Machine (UTM) with bounded-precision RNNs with growing memory modules. The growing memory module is composed of neurons of fixed precision. The authors prove that a 54-neuron RNN with fixed precision can simulate UTM with time complexity linear in the simulated machine’s time and independent of the memory size. The result is extendable to various other stack-augmented RNN models. 
SP:3f33489b98ba6145fd4e334669493f15a63455f4,"This paper studies quantile regression with asymptotic bounds on the coverage of uncertainty estimation algorithms in learning quantiles. In particular, the authors prove that the quantile-regression algorithm suffers from an inherent under-coverage bias in a vanilla setting where we learn a realizable linear quantile function and there is more data than parameters. More quantitatively, for α > 0.5 and small d/n, the α-quantile learned by quantile regressors roughly achieves coverage α-1/2 + 1/2 - 1/n regardless of the noise distribution, where d is the input dimension and n is the number of training data. Experiments on simulated and real data verify the theory."
SP:ecb9c7c11dfb450d8e76504d42309b1888023d26,"This paper proposes a reinforcement learning-based method for memory allocation in class-incremental learning (CIL). In particular, the authors propose to use reinforcement learning to train a policy that allocates memory for old and new classes separately. The policy is trained on pseudo CIL tasks and then applied to target tasks. The proposed method is evaluated on three CIFAR-100, ImageNet, and ImageNet-Full benchmarks. "
SP:1137ed24393a24f24e9a36e1586e6924a55d627e,"This paper studies the problem of speeding up stochastic gradient descent (SGD) by parallelizing it across multiple workers. In this setting, the data is shared among N workers, and each worker takes SGD steps and coordinate with a central server. While it is possible to obtain a linear reduction in the variance of SGD by averaging all the gradients at every step, this requires a lot of communication between the workers and the server, which can dramatically reduce the gains from parallelism. The Local SGD method, proposed and analyzed in the earlier literature, suggests machines should make many local steps between such communications. This paper shows that this can achieve an error that scales as 1/(NT ) with a number of communications that is completely independent of T. In particular, it shows that $O(\sqrt{N})$ communications are sufficient. Empirical evidence suggests that this bound is close to tight. "
SP:8a78fee6173dc6639dfd9e33a10d0c8432a08512,This paper studies the Online Lazy Gradient Descent algorithm for strongly convex optimization. The algorithm is known to achieve O(\sqrt{N}log N) expected regret against adversarial opponents. This paper shows that the algorithm is universal in the sense that it also achieves $O(logN)$ expected regret. This improves upon the more complex metaalgorithm of Huang et al [20] that only gets O(N log N) and O(log N). 
SP:59e7ff1cdee42c9623615f6105c0e0f44e7b75a5,"This paper studies the Bures-Wasserstein (BW) geometry for Riemannian optimization on the symmetric positive definite (SPD) matrix manifold. The authors show that the BW metric has a linear dependence on SPD matrices in contrast to the quadratic dependence of the Affine-Invariant (AI) geometry. They also show that BW geometry has a non-negative curvature, which further improves convergence rates of algorithms over the non-positively curved AI geometry. Finally, the authors verify that several popular cost functions, which are known to be geodesic convex under the AI geometry, are also Geodesic Convex under BW geometry."
SP:1f835a54c74d396ae2e8620b01bed0ec53646f3a,"This paper introduces Dynaboard, an evaluation-as-a-service framework for hosting benchmarks and conducting holistic model comparison, integrated with the Dynabench platform. The platform evaluates NLP models directly instead of relying on self-reported metrics or predictions on a single dataset. Under this paradigm, models are submitted to be evaluated in the cloud, circumventing the issues of reproducibility, accessibility, and backwards compatibility that often hinder benchmarking in NLP. This allows users to interact with uploaded models in real time to assess their quality, and permits the collection of additional metrics such as memory use, throughput, and robustness, which – despite their importance to practitioners – have traditionally been absent from leaderboards."
SP:44dc6a69f5d65ca0b271177ac67d1beb12a154a0,"This paper proposes Neural Dubber, a multi-modal text-to-speech (TTS) model for automatic video dubbing (AVD) that synthesizes human speech synchronized with the given video from the text. The proposed model uses the lip movement in the video to control the prosody of the generated speech. An image-based speaker embedding (ISE) module is developed for the multi-speaker setting, which enables the model to generate speech with a reasonable timbre according to the speaker’s face. Experiments on the Lip2Wav single speaker dataset and LRS2 multi speaker dataset show that the proposed model can generate speech audios on par with state-of-the-art TTS models in terms of speech quality."
SP:24ea12428bd675459f0509aa7cee821fa236382e,"-based federated learning is a method to train a neural network on a large corpus of decentralized data while maintaining data privacy. In this paper, the authors propose to use the recently proposed Vision Transformer architecture with straightforward decomposable configuration to solve the problem of split learning without sacrificing performance. The results show that the proposed framework can achieve performance comparable to data-centralized training. "
SP:2065a8cb8b53140569b64fca1f00f7230f1ae2cc,"This paper proposes a differentiable point-to-mesh representation for 3D surface reconstruction. The proposed method is based on the Poisson Surface Reconstruction (PSR) method, which allows for efficient and differentiable representation of oriented point clouds. The paper shows that the proposed method can be used to bridge the explicit 3D point representation with the 3D mesh via the implicit indicator field, enabling end to end optimization of surface reconstruction metrics such as Chamfer distance."
SP:76b64e6b104818ed26e9331d134df0125d84291c,"This paper studies the problem of recovering the representation of an image R(x) from a corrupted version A(x), for some known forward operator A. The authors propose a supervised inversion method that uses a contrastive objective to obtain excellent representations for highly corrupted images. The proposed method achieves a higher accuracy than end-to-end supervised baselines when classifying images with various types of distortions, including blurring, additive noise, and random pixel masking."
SP:ca846ae9653fa843a6a64ce7361d44a0c31c5990,"This paper revisits the REINFORCE method for structural credit assignment in neural networks. The authors show that the standard on-policy approach, even with a variety of variance reduction approaches, learns suboptimal solutions. To address this issue, the authors propose an off-policy learning approach to improve the performance of the existing methods. "
SP:7aa09356b2c85d54933c0d0d89a3f8fe2e37b27b,"This paper proposes to use a self-supervised predictive loss function to model both the ventral and dorsal pathways of the visual cortex of mice. The authors show that the proposed method is able to model the dorsal and ventral pathways of mouse visual cortex with the same ANN architecture. They also show that their method can model both ventral (what) and dorsal (where) pathways, and that it can capture the functional specialization of both pathways. "
SP:fa11c4da16c01c6a3449f15b25a6e4e228ebbf4a,"This paper proposes TopicNet, a deep hierarchical topic model that can inject prior structural knowledge as an inductive bias to influence the learning. TopicNet represents each topic as a Gaussian-distributed embedding vector, projects the topics of all layers into a shared embedding space, and explores both the symmetric and asymmetric similarities between Gaussian embedding vectors to incorporate prior semantic hierarchies. The model parameters are optimized by minimizing the evidence lower bound and a regularization term via stochastic gradient descent. Experiments on widely used benchmarks show that TopicNet outperforms related deep topic models on discovering deeper interpretable topics and mining better document representations."
SP:b7ad495901eb2f73a8a26aa5c9325908451cfe09,"This paper proposes a pretraining method for object detection based on self-supervised pretraining. The proposed method is based on object-level contrastive learning, where object representations are introduced via selective search bounding boxes as object proposals. The pretraining network architecture incorporates the same dedicated modules used in the detection pipeline (e.g. FPN) and the pretraining is equipped with object detection properties such as object translation invariance and scale invariance. Experiments show that the proposed method achieves state-of-the-art transfer performance on COCO detection using a Mask R-CNN framework."
SP:b4dcb19fd97a906ed37e6af407260f0dedbbd402, routing problems (VRPs) are a class of combinatorial problems where the goal is to solve a large-scale vehicle routing problem. This paper proposes a learning-augmented local search framework to solve VRPs. The method iteratively improves the solution by identifying appropriate subproblems and delegating their improvement to a black box subsolver. The proposed method accelerates state-of-the-art VRP solvers by 10x to 100x while achieving competitive solution qualities for VRPs with sizes ranging from 500 to 3000.
SP:f5c80f76cb1e651fd808e7da4bfe6fdfd75b7155,"This paper proposes a method to actively forget the old knowledge that interferes with the learning of new tasks for continual learning. The method is inspired by the biological active forgetting and is based on the Bayesian continual learning framework. The authors propose a method called Active Forgetting with Synaptic Expansion-Convergence (AFEC) that dynamically expands parameters to learn each new task and then selectively combines them, which is formally consistent with the underlying mechanism of biologically active forgetting. Experimental results on CIFAR-10 regression tasks, visual classification tasks, and Atari reinforcement tasks show that AFEC improves the learning performance and achieves the state-of-the-art performance."
SP:a5945ec13e2f362df03b42511d44827ef081f4c3,"This paper studies the convergence of prior-guided ZO algorithms under a greedy descent framework with various gradient estimators. The authors provide a convergence guarantee for the prior guided random gradient-free (PRGF) algorithms. To further accelerate over greedy descent methods, the authors present a new accelerated random search (ARS) algorithm that incorporates prior information, together with a convergence analysis. The theoretical results are confirmed by experiments on several numerical benchmarks as well as adversarial attacks."
SP:ef18f4188426bc01be309633b486884b0e7a81a4,"This paper studies the lottery ticket hypothesis (LTH) which states that learning on a properly pruned neural network (the winning ticket) improves test accuracy over the original unpruned network. The paper characterizes the performance of training a pruned network by analyzing the geometric structure of the objective function and the sample complexity to achieve zero generalization error. It shows that the convex region near a desirable model with guaranteed generalization enlarges as the neural network model is pruned, indicating the structural importance of a winning ticket. The number of samples required for achieving zero generalisation error is proportional to the number of the non-pruned weights in the hidden layer. "
SP:3ef8660de61a1a73858934fcf8edfec104133ae7,"This paper proposes two new methods for private synthetic data generation for query release, where the goal is to construct a sanitized version of a sensitive dataset, subject to differential privacy, that approximately preserves the answers to a large collection of statistical queries. The first method, generative networks with the exponential mechanism (GEM), optimizes over generative models parameterized by neural networks, which capture a rich family of distributions while enabling fast gradient-based optimization. The second method, private entropy projection (PEP), can be viewed as an advanced variant of MWEM that adaptively reuses past query measurements to boost accuracy. The authors demonstrate that GEM and PEP outperform existing algorithms."
SP:d789e92c1e4f6a44de373210cd732198a6f809be,"This paper proposes MaskFormer, a simple mask classification model for semantic and instance-level segmentation tasks. MaskFormer predicts a set of binary masks, each associated with a single global class label prediction, for semantic segmentation and panoptic segmentation. The proposed method is able to solve both semantic-level and instance level tasks in a unified manner using the exact same model, loss, and training procedure. Empirical results show that MaskFormer outperforms per-pixel classification baselines when the number of classes is large."
SP:3aee15083ee1c0a75fedd67a50f9d729bf5ee411,"This paper extends the work of Daniely and Schacham (2020) to the overcomplete case, where the number of neurons is larger than the dimension (yet also sub-exponential in the dimension). They prove that a single step of gradient descent suffices. They also show this result for any subexponential width random neural network with smooth activation function. "
SP:220db9ed147bbe67de5d82778720a1549656e48d,"This paper proposes a score-based generative model (LSGM) based on the variational autoencoder (VAE) framework. LSGM is trained end-to-end in a scalable and stable manner. The proposed LSGM achieves state-of-the-art FID scores on CIFAR-10 and CelebA-HQ-256, and achieves SOTA results on the binarized OMNIGLOT dataset."
SP:d681e4e28c03f610acf6817a9e57db0c41c196b4,"This paper proposes a new explanation for the performance gap between neural networks and neural tangent kernels in image classification. The authors prove that for a simple data distribution with sparse signal amidst high-variance noise, a simple convolutional neural network trained using stochastic gradient descent simultaneously learns to threshold out the noise and find the signal. On the other hand, the corresponding neural Tangent kernel, with a fixed set of predetermined features, is unable to adapt to the signal in this manner. Empirical results on CIFAR-10 and MNIST show that as the background noise increases in intensity, a CNN’s performance stays relatively robust, whereas its corresponding Neural tangent kernel sees a notable drop in performance. "
SP:c347796244fcf9b5de19c68bcc5c811b7448217d,"This paper studies decentralized decentralized machine learning over a network where the training data is distributed across n agents, each of which can compute stochastic model updates on their local data. The agent’s common goal is to find a model that minimizes the average of all local loss functions. While gradient tracking (GT) algorithms can overcome a key challenge, namely accounting for differences between workers’ local data distributions, the known convergence rates for GT algorithms are not optimal with respect to their dependence on the mixing parameter p (related to the spectral gap of the connectivity matrix). This paper improves the dependency on p from O(p-2/3/2) to O( p-1/2/c-1) in the noiseless case and O(\p+1/\sqrt{c}/\epsilon}) in the general case. This improvement was possible due to a new proof technique which could be of independent interest. "
SP:24d637e8c3489bfe50b17bf684097776ad6ee485,"This paper studies the upper confidence bound (UCB) algorithm for the multi-armed bandit problem. UCB is one of the simplest optimism-based MAB algorithms that naturally adapts to the instance gap in the top two arms. This paper provides new results on the arm-sampling behavior of UCB, leading to several important insights. First, it is shown that the UCB algorithm is asymptotically deterministic, regardless of the problem complexity. Second, it also provides the first complete process-level characterization of the MAB problem under UCB in the conventional diffusion scaling. Finally, the paper also reveals profound distinctions between the behavior ofUCB and Thompson Sampling."
SP:43c8bcc93aa034965fa6d959d44b529ffc110cc7,"This paper studies the problem of cross-domain cold-start recommendation (CDCSR) in recommender systems. The authors propose DisAlign, a method to leverage both rating and auxiliary representations from the source domain to improve the recommendation performance of the target domain. Specifically, they first propose Stein path alignment for aligning the latent embedding distributions across domains, and then further propose its improved version, i.e., proxy Stein path, which can reduce the operation consumption and improve efficiency. Empirical studies on Douban and Amazon datasets demonstrate that the proposed method outperforms the state-of-the-art models."
SP:729c3e22a6f0170bdc8e1f511812dc9e9a4fd4a8,"This paper proposes a new architecture for vision transformers that replaces the self-attention layer with 3 operations: a discrete Fourier transform, an element-wise multiplication between frequency-domain features and learnable global filters, and a 2D inverse Fourier transforms. The proposed method is shown to be more efficient than existing vision transformer-style models and CNNs in efficiency, generalization ability and robustness. Experiments on ImageNet verify the effectiveness of the proposed method."
SP:e278079529d6da9e2ea26b47730dbc1256ffe2db,"This paper studies the problem of trustworthiness prediction on large-scale datasets, where the task is more challenging due to high-dimensional features, diverse visual concepts, and a large number of samples. The authors observe that the trustworthiness predictors trained with prior-art loss functions, i.e., the cross entropy loss, focal loss, and true class probability confidence loss, are prone to view both correct predictions and incorrect predictions to be trustworthy. To address this issue, the authors propose a novel steep slope loss to separate the correct predictions from the incorrect predictions by two slide-like curves that oppose each other. The proposed loss is evaluated with two representative deep learning models, Vision Transformer and ResNet, as trustworthiness predictions. Experiments on ImageNet show that the proposed loss effectively improves the generalizability of trustability predictors."
SP:c5704a709f318c6e9a5c716e5e7f250acccf46a8,"This paper studies adversarial robustness from the perspective of linear components, and finds that there exist some statistical properties for comprehensively robust models. Specifically, robust models show obvious hierarchical clustering effect on their linearized sub-networks, when removing or replacing all non-linear components (e.g., batch normalization, maximum pooling, or activation layers). Based on these observations, the authors propose a novel understanding of adversarially robustness and apply it on more tasks including domain adaption and robustness boosting. Experimental evaluations demonstrate the rationality and superiority of their proposed clustering strategy."
SP:590b67b1278267e966cf0b31456d981441e61bb1,"This paper proposes a new method for learning end-to-end reconstruction operators based on unpaired training data for ill-posed inverse problems. The proposed method combines the classical variational framework with iterative unrolling and essentially seeks to minimize a weighted combination of the expected distortion in the measurement space and the Wasserstein-1 distance between the distributions of the reconstruction and the ground-truth. More specifically, the regularizer in the variational setting is parametrized by a deep neural network and learned simultaneously with the unrolled reconstruction operator. The variational problem is then solved iteratively till convergence and takes significantly fewer iterations to converge as compared to variational methods."
SP:115d679338ab35829dbc594472d13cc02be5ed4c,"This paper proposes a contrastive loss to align the image and text representations BEfore Fusing (ALBEF) through cross-modal attention, which enables more grounded vision and language representation learning. Unlike most existing methods, ALBEF does not require bounding box annotations nor high-resolution images. To improve learning from noisy web data, the authors propose momentum distillation, a self-training method which learns from pseudo-targets produced by a momentum model. The proposed method achieves state-of-the-art performance on multiple downstream vision-language tasks."
SP:e5323a171f40c109722a7ea0aebdcd53c151b72d,"This paper studies offline policy evaluation (OPE) with Markov decision processes (MDPs), where the goal is to estimate the utility of given decisionmaking policies based on static datasets. The paper studies the behavior of a simple existing OPE method called the linear direct method (DM) under the unrealizability assumption. The authors obtain an asymptotically exact characterization of the OPE error in a doubly robust form, and establish the nonparametric consistency of the tile-coding estimators under quite mild assumptions."
SP:b45f6966fcc07f3a33f70a57e72507b16fc7bb24,"This paper studies the problem of non-smooth convex stochastic convex optimization with non-sub-Gaussian (heavy-tailed) noise. The authors derive the first high-probability convergence results with logarithmic dependence on the confidence level for convex problems with heavy-tailed noise. They show that for smooth objectives with Hölder-continuous gradients, the first (accelerated) method has optimal iteration and oracle complexity in all regimes, and the second one is optimal in the nonsmooth setting. "
SP:a22a893e25ce739dc757861741014764e78aa820," of long-term forecasting of time series. This paper proposes a novel Transformer-based architecture with an Auto-Correlation mechanism. The proposed architecture is based on a series decomposition architecture with a self-attention mechanism. In addition, the authors propose a series periodicity mechanism based on the stochastic process theory, which conducts the dependencies discovery and representation aggregation at the sub-series level. Experiments show that the proposed architecture outperforms the state-of-the-art in both efficiency and accuracy."
SP:eeb2c3348de291c5eacac5d9de7b6b84ca030ad5,"This paper presents a dataset of cryptic crossword clues as a challenging new benchmark for NLP systems that seek to process compositional language in more creative, human-like ways. The dataset is composed of two parts: a definition and a wordplay cipher requiring character-level manipulations. The authors show that three non-neural approaches and T5, a state-of-the-art neural language model, do not achieve good performance, and propose a curriculum approach, in which the model is first fine-tuned on related tasks such as unscrambling words. "
SP:7693974b70806d9b67920b8ddd2335afc4883319,"This paper studies the internal structure of ViTs and CNNs on image classification tasks. The authors find that ViTs have more uniform representations across all layers and that self-attention plays a key role in early aggregation of global information, and ViT residual connections propagate features from lower to higher layers. They also study the effect of dataset scale on intermediate features and transfer learning, and conclude with a discussion on connections to new architectures such as MLP-Mixer."
SP:dfd740399e48b946f02efdec823b8975a900f6a3,"This paper studies Thompson Sampling (TS) with approximation oracle in combinatorial multi-armed bandit (CMAB) problems. In particular, this paper studies the case where the oracle is a greedy oracle, which is a common oracle with theoretical guarantees to solve many (offline) combinatorially optimization problems. The authors provide a problem-dependent regret lower bound of order $O(\sqrt{T/2})$ to quantify the hardness of TS to solve CMAB problems with greedy oracles, where T is the time horizon and is some reward gap. They also provide an almost matching regret upper bound. "
SP:3ca7fdaba9793a61a1f9d264a551fe895e55dd99,"This paper studies the problem of federated learning in a hedonic game setting, where the goal is to find a federating coalition of players that maximizes the average error of the federating agents. The authors provide an efficient algorithm to calculate the optimal federating coalitions, and show that for some regions of parameter space, all federating arrangements are optimal. However, they show that this is not the case for all regions of the parameter space. Finally, they give the first constant-factor bound on the performance gap between stability and optimality, proving that the worst stable solution can be no higher than 9 times the total error of an optimal solution."
SP:17088db004fbf4902c5c3d53e387d1b68f4d69a5,"This paper proposes a self-supervised capsule architecture for 3D point clouds. The capsule decompositions of objects are computed through permutation-equivariant attention. The proposed method outperforms the state-of-the-art on 3d point cloud reconstruction, canonicalization, and unsupervised classification."
SP:34cc3466ff7786968f437007b6af7d9ffd4decc7,"This paper proposes a conformal method to compute prediction intervals for nonparametric regression that can automatically adapt to skewed data. The proposed method uses black-box machine learning algorithms to estimate the conditional distribution of the outcome using histograms, and translates their output into the shortest prediction intervals with approximate conditional coverage. The resulting prediction intervals provably have marginal coverage in finite samples, while asymptotically achieving conditional coverage and optimal length if the model is consistent. Numerical experiments with simulated and real data demonstrate improved performance compared to state-of-the-art alternatives."
SP:d39075aff611dd54574e7ee1a1aeacce83fdf532,This paper studies the effect of enforcing invariance in kernel ridge regression when the target is invariant to the action of a compact group. The authors derive a strictly non-zero generalization benefit of incorporating invariance into the objective function. They show that the generalization is governed by a notion of effective dimension that arises from the interplay between the kernel and the group. 
SP:97fac361b69ed5871a60dc40e51900747a453df9,"This paper proposes a decodable neural network (DecNN), which is a generative model that constrains neural network activations to “decode” back to inputs. The authors show that the decodability of DecNN enables a form of compositionality in neural networks, where one can recursively compose DecNN with itself to create an ensemble-like model with uncertainty. This uncertainty can be used for out-of-distribution detection, adversarial example detection, and calibration, while matching standard neural networks in accuracy."
SP:3f10ca1e7f8fef6cb0c5957ec2f0689fb9bed753,"This paper studies the rates of convergence of plug-in estimators of optimal transport maps via barycentric projections. The main contribution is a new stability estimate for barycenters that proceeds under minimal smoothness assumptions and can be used to analyze general plug in estimators. The authors show that under Sobolev type or Besov type smoothness, kernel smoothing or wavelet based estimators can speed up the rate of convergence and mitigate the curse of dimensionality suffered by the natural discrete/semi-discrete estimators and the Wasserstein distance between two probability distributions."
SP:573fbdbe5857c4aace1dfc27e25b8d65a18c9b96,"This paper proposes a distributed kernel-based meta-learning framework for dataset distillation using infinitely wide convolutional neural networks. The proposed method achieves state-of-the-art results on CIFAR-10, Fashion-MNIST, MNIST, and SVHN datasets. The authors also perform some preliminary analyses of their distilled datasets to shed light on how they differ from naturally occurring data."
SP:9837e0c68887cc1382aefd0ead01f72cde199e0d,"This paper proposes a novel semi-supervised learning method for detecting outliers in unlabeled data. The proposed method is based on one-vs-all (OVA) classifiers, where the OVA-classifier outputs the confidence score of a sample being an inlier, providing a threshold to detect outliers. The authors also propose an open-set soft-consistency regularization loss, which enhances the smoothness of the classifier with respect to input transformations and greatly improves outlier detection. The method achieves state-of-the-art performance on three datasets."
SP:eb86d33d5d47f1cfe2c66ca2c9f852229e32a32f,"This paper proposes Latent Explorer Achiever (LEXA), a method for unsupervised goal reaching in robotic manipulation and locomotion tasks. The proposed method is based on learning a world model from image inputs and using it to train an explorer and an achiever policy via imagined rollouts. Unlike prior methods that explore by reaching previously visited states, the explorer plans to discover unseen surprising states through foresight, which are then used as diverse targets for the achiever to practice. LEXA achieves state-of-the-art performance on a variety of robotic manipulation tasks."
SP:2db4aba9a370df67f786157f18cbaa4167c6a46d,"This paper proposes a low-rank factorized representation method to reduce the number of trainable parameters in a Transformer model. The proposed method decomposes a matrix into two smaller matrices, reshaping and reordering matrix dimensions prior to the decomposition, and is equivalent to a sum of Kronecker products with an efficient implementation. Theoretical results show that stacking multiple linear layers decomposed this way increases the expressiveness of the network, unlike stacking multiple low rank layers factorized in the standard way, which can only map into a subspace of dimensionality equal to the rank. Empirically, the proposed method can reduce the size of a simple encoder-decoder Transformer to as little as 4 million parameters."
SP:0ff862542ada5b664d615c26e7a4a95b6cbe540e,"This paper proposes a Transformer-based representation model for code summarization. In particular, the authors propose to encode both the pairwise path between tokens of source code and the path from the leaf node to the tree root for each token in the syntax tree in the Transformer framework. The proposed method is based on the idea of positional encoding. The authors show that the proposed method, TPTrans, outperforms the existing state-of-the-art baselines on code summarisation tasks in four languages."
SP:727bcd651b11b7d84dd2c2d535cc85402f9117d4,"This paper proposes a new Transformer-based GAN model for high-resolution image generation. The proposed HiT model is based on the idea of multi-axis blocked self-attention, which allows efficient mixing of local and global attention in low-resolution stages of the generative process. To further improve the performance of HiT, the authors introduce an additional self-modulation component based on cross attention to further reduce the computational complexity. The HiT achieves state-of-the-art FID scores of 30.83 and 2.95 on unconditional ImageNet 128/128 and FFHQ 256/256. "
SP:41a6753bc56eb16040600666a859294ae36cfa9c,"This paper studies the query complexity of learning geodesically convex halfspaces on graphs. Geodesic convexity is a generalization of Euclidean convexness and allows the definition of convex sets and halfspace on graphs, and the authors show that geodesic halfspace learning is linear in the treewidth and the minimum hull set size but only logarithmic in the diameter. They show tight lower bounds along well-established separation axioms and identify the Radon number as a central parameter of query complexity and the VC dimension. They provide evidence that ground-truth communities in real-world graphs are often convex and empirically compare their proposed approach with other active learning algorithms."
SP:e880db33ba8c305ef1808a02325e2d2b7da95e68,"This paper proposes a low-fidelity (LoFi) video encoder optimization method for temporal action localization (TAL) learning. The proposed method reduces the mini-batch composition in terms of temporal, spatial or spatio-temporal resolution so that jointly optimizing the video encoders and TAL head becomes operable under the same memory conditions of a mid-range hardware budget. Experiments show that the proposed LoFi optimization method yields new state-of-the-art performance when combined with existing TAL models."
SP:f79e91e469a70b219cd4a2116d5f389842f265ec,"This paper studies M-estimators with gradient-Lipschitz loss function regularized with convex penalty in linear models with Gaussian design matrix and arbitrary noise distribution. The authors provide general formulae for the derivatives of regularized M-ESTIMators where differentiation is taken with respect to both y and X. Using these derivatives, the authors characterize the distribution of the residual ri = yi−xi β̂ in the intermediate high-dimensional regime where dimension and sample size are of the same order. Motivated by the distributions of residuals, this paper proposes a novel adaptive criterion to select the tuning parameters of the regularized estimator. The criterion approximates the out-of-sample error up to an additive constant independent of the estimator, so minimizing the criterion provides a proxy for minimizing the out of sample error."
SP:be53bc4c064402489b644332ad9c17743502d73c,"This paper proposes a new beam-based summarization method based on attention-aware inference. Specifically, a global protocol is proposed based on the attention distribution to stipulate how a global optimal hypothesis should attend to the source. A global scoring mechanism is then developed to regulate beam search to generate summaries in a near-global optimal fashion. Extensive experiments on nine datasets show that the proposed global inference significantly improves state-of-the-art summarization models."
SP:4c7d14ab3304cfbf083815aa6e6d9c0e0a5fba6f,"This paper proposes a self-attention mechanism that is equivariant to the orientation of local coordinate systems (i.e., gauge equivariance). The proposed method is based on a multi-head attention mechanism that jointly incorporates both position-based and content-based information. To enhance expressive ability, the authors adopt regular field of cyclic groups as feature fields in intermediate layers, and propose a novel method to parallel transport the feature vectors in these fields. Extensive experiments show that the proposed method achieves state-of-the-art performance on two common recognition tasks."
SP:19cd64baeb7db11b5ec066e6f8ccb4bc576d3588,"This paper proposes a method for unsupervised learning of finite mixture models by combining expectation maximization and Metropolis-Hastings algorithm to evaluate only a small number of, stochastically sampled, components, thus substantially reducing the computational cost. The method is able to train both shallow and deep mixture models which involve complex, and possibly nonlinear, transformations. The performance of the proposed method is demonstrated in a variety of synthetic and real-data contexts."
SP:aae8847c5e52d14820967ab39770ab4ae16df59c,"This paper proposes a method for training deep neural networks with completely sparse forward and backward passes. The authors formulate the training process as a continuous minimization problem under global sparsity constraint. They separate the optimization process into two steps, corresponding to weight update and structure parameter update. For the former step, they use the conventional chain rule, which can be sparse via exploiting the sparse structure. The latter step, instead of using the chain rule based gradient estimators as in existing methods, they propose a variance reduced policy gradient estimator, which only requires two forward passes without backward propagation, thus achieving completely sparse training. Extensive experimental results on real-world datasets demonstrate the effectiveness of the proposed method."
SP:e0aa68ab03a3ef396b0dc4be4190b328d72cfab0,This paper proposes a novel family of importance samplers (IS) and Markov chain Monte Carlo (MCMC) based on non-equilibrium orbits (NEOs) for sampling from a complex distribution π and approximating its intractable normalizing constant Z are challenging problems. The proposed method is based on the idea of self-normalized IS estimators of expectations under the invertible map T and a sampling-importance resampling mechanism to sample from a proposal distribution ρ. The paper also provides theoretical results for both methods. 
SP:506dca4f64f837e32958c3c43a0c68f194a36bb3,"This paper proposes a new method for mini-batch set encoding. The proposed method is based on the idea of Mini-Batch Consistency (MBC) which is a generalization of permutation invariance and equivariance. The authors also propose a new attention mechanism that is amenable to mini batch processing of sets and can update set representations as data arrives. Experiments on image reconstruction, point cloud classification and dataset encoding demonstrate the effectiveness of the proposed method. "
SP:b2eafdb24fa081ae8b37525d70fb4bc2d54518dc,"This paper presents an algorithm for action exploration and equilibrium approximation in games with combinatorial action spaces. This algorithm simultaneously performs value iteration while learning a policy proposal network. A double oracle step is used to explore additional actions to add to the policy proposals. At each state, the target state value and policy for the model training are computed via an equilibrium search procedure. Using this algorithm, the authors train an agent, DORA, completely from scratch for a popular two-player variant of Diplomacy and show that it achieves superhuman performance. They also extend their methods to full-scale no-press Diplomacy."
SP:1ce1cef9988a07ccd2175a718b29ad23bc779429,"This paper proposes a multi-head attention method for multilingual and multi-domain sequence modeling. The proposed method is based on the observation that non-selective attention sharing is sub-optimal for achieving good generalization across all languages and domains. To address this issue, the proposed method proposes to learn shared and specialized attention heads for different languages and domain. The method is evaluated on several tasks including speech recognition, text-to-text and speech to text translation. The results show that the proposed attention sharing strategies consistently bring gains to sequence models built upon multi head attention."
SP:69c522cea4a150624bc709e1c12c0f65183c1b2a,"This paper studies the effect of covariate shift on the generalization performance of random feature regression under covariate shifts. The authors derive exact bounds for the test error, bias, and variance of the random feature model under the assumption that the conditional distribution of the labels given the covariates remains fixed. They also provide an exact linear relationship between the in-distribution and out of distribution generalization performances.  "
SP:ff1b7a7a6295e8f40f3b5df5f6950ca9d33603e0,"This paper studies the sensitivity of Thompson Sampling (TS) with misspecified prior in the context of Bayesian sequential decision-making (BDS) algorithms. The authors show that the expected reward of TS with a misspecification of the prior is at most $O(H^2/\epsilon^2)$, where H is the learning horizon and $H$ is the total-variation distance between the two priors. They show that this sensitivity is independent of the cardinality or structure of the action space, and is tight up to universal constants in the worst case. They also establish generic PAC guarantees for algorithms in the recently studied Bayesian meta-learning setting. "
SP:3477b64480ed638b1c4e1f8aa73fc2e77666c89a,"This paper studies the sample/query complexity of the Equivalence-Query-learning model, where the teacher provides counterexamples to hypotheses given by the learner. The authors prove an exponential separation between the sample and query complexity of this model and the standard PAC learning model. They also discuss how their result relates to adversarial robustness. "
SP:7520cc1203bb06bbe432e7cc679892e95258ed99,"This paper studies the problem of model selection for transfer learning from source data to target data. The authors propose several benchmarks for evaluating on this task. They find that existing model selection and transferability estimation methods perform poorly here and analyze why this is the case. They then introduce simple techniques to improve the performance and speed of these algorithms. Finally, they iterate on existing methods to create PARC, which outperforms all other methods on diverse model selection."
SP:dcdb9c88f61ac3caf3da8255a7953c753cf048d1,"This paper proposes a method for learning low-dimensional binary codes (LLC) for instances as well as classes. The proposed method is based on the idea of learning binary codes for instances and classes without requiring any side-information, such as annotated attributes or label meta-data. The learned codes are super-efficient while still ensuring nearly optimal classification accuracy for ResNet50 on ImageNet-1K. The method is applied to efficient image retrieval and OOD detection problems. "
SP:07def8c80d05f86402ce769313480b30cd99af43,"This paper proposes Generalized Depthwise-Separable (GDWS) convolution, which is an efficient, universal, post-training approximation of a standard 2D convolution. GDWS significantly improves the throughput of a pre-trained network on real-life hardware while preserving its robustness. The proposed method is scalable to large problem sizes and doesn’t require any additional training. "
SP:9e4d04b22ce4f986aabb747a42f40c827073e39e,"-based retrosynthesis prediction is a fundamental problem in organic synthesis, where the task is to identify precursor molecules that can be used to synthesize a target molecule. A key consideration in building neural models for this task is aligning model design with strategies adopted by chemists. Building on this viewpoint, this paper introduces a graph-based approach that capitalizes on the idea that the graph topology of precursor molecules is largely unaltered during a chemical reaction. The model first predicts the set of graph edits transforming the target into incomplete molecules called synthons. Next, the model learns to expand synthons into complete molecules by attaching relevant leaving groups. This decomposition simplifies the architecture, making its predictions more interpretable, and also amenable to manual correction. The proposed method achieves a top-1 accuracy of 53.7%, outperforming previous template-free and semi-template-based methods."
SP:772277d969c95924755113c86663fb0e009f24cc,"This paper proposes a Bayesian formulation of the deconditioning problem for statistical downscaling of low-resolution spatial fields with high-resolution information. The proposed method is based on the initial reproducing kernel Hilbert space formulation from Hsu and Ramos (Hsu et al., 2018) and extends it to a downscaled setup and devise efficient conditional mean embedding estimator for multiresolution data. The authors show that this solution can be viewed as a two-staged vector-valued kernel ridge regressor and show that it has a minimax optimal convergence rate under mild assumptions. Empirical results on synthetic and real-world atmospheric field data demonstrate the effectiveness of the proposed method."
SP:59cfeb59cecac51fecff8f8ceb0266fc6ac22a05,"This paper proposes a method to automatically search the critical component in DSNs, the feature-interaction layer. The authors propose a distilled search space to cover the desired architectures with fewer parameters. They then develop a progressive search algorithm for efficient search on the space and capture the order-priority property in sparse prediction tasks. Experiments on three real-world benchmark datasets show promising results of PROFIT in both accuracy and efficiency."
SP:23a2171eab71c4fd3754791ca2aac9be87411cdb,"This paper studies the problem of fine-tuning a pre-trained model on a target task with a small amount of labeled data. The authors provide a PAC-Bayes generalization bound that depends on the distance traveled in each layer and the noise stability of the model. Based on the analysis, the authors propose a regularized self-labeling method that uses layer-wise regularization to constrain the distance in the layers and self label correction and label reweighting to correct mislabeled data points and reweight less confident data points. Empirical results show that the proposed method outperforms baseline methods on several image and text classification tasks."
SP:f2a77f93bdc0401bbd6162a16fba25b9f90530e2,"This paper studies the multi-armed bandit best-arm identification problem, where the goal is to identify the arm that has the smallest CVaR, VaR, or weighted sum of CVaRs and mean. The main contribution is an optimal $\delta$-correct algorithm that acts on general arms, including heavy-tailed distributions, and matches the lower bound on the expected number of samples needed, asymptotically. The algorithm requires solving a non-convex optimization problem in the space of probability measures, that requires delicate analysis, and new non-asymptotic, anytime-valid, empirical-likelihood-based concentration inequalities. "
SP:765942c86da1594b33268df6d0d15c682bc7eaa6,"This paper proposes ViTAE, a new vision transformer architecture that uses spatial pyramid reduction to learn intrinsic inductive bias (IB) from convolutions. The proposed method is based on multiple convolutions with different dilation rates to learn the intrinsic scale invariance of convolutional layers. The authors also propose a convolution block in parallel to the multi-head self-attention module, whose features are fused and fed into the feed-forward network to learn local features and global dependencies collaboratively. Experiments on ImageNet as well as downstream tasks demonstrate the superiority of the proposed method. "
SP:5e3572a386f890c5864437985cf63b13844f338f,"This paper proposes Robust Informative Fine-Tuning (RIFT), a novel adversarial fine-tuning method from an information-theoretical perspective. In particular, RIFT encourages an objective model to retain the features learned from the pre-trained model throughout the entire fine-tuning process, whereas a conventional one only uses the weights for initialization. Experimental results show that RIFT consistently outperforms the state-of-the-art on two popular NLP tasks: sentiment analysis and natural language inference, under different attacks across various pre- trained language models."
SP:167a8b7e0173bffc5f08a9c2f378fe7bdf837da3,"This paper proposes a Stochastic Anderson Mixing (SAM) scheme to solve nonconvex stochastic optimization problems. The main idea is to use damped projection and adaptive regularization to the classical Anderson mixing (AM) scheme. The convergence of SAM is shown to be almost sure convergence to stationary points and the worst-case iteration complexity is improved by randomly choosing an iterate as the output. To further accelerate the convergence, the authors incorporate a variance reduction technique into the proposed SAM. The authors also propose a preconditioned mixing strategy for SAM which can achieve faster convergence or better generalization ability."
SP:fe9c80cc5615705ef844d59b56413779c8d54a06,"This paper proposes SNIPS, a method for sampling from the posterior distribution of linear inverse problems with additive white Gaussian noise. The method is based on Langevin dynamics and Newton’s method, and exploits a pre-trained minimum mean squared error (MMSE) Gaussian denoiser. The proposed approach relies on an intricate derivation of the posterior score function that includes a singular value decomposition (SVD) of the degradation operator, in order to obtain a tractable iterative algorithm for the desired sampling. Due to its stochasticity, the algorithm can produce multiple high perceptual quality samples for the same noisy observation. "
SP:b04caddcb2dc9e9b365a76fdbf3d3eb4efcdffd9,"This paper proposes a new framework for detecting drug traffickers on Instagram. The proposed method is based on a heterogeneous graph (HG) framework, which is used to jointly model multi-modal content and relational structured information on social media for illicit drug trafficker detection. A relation-based graph convolutional neural network is employed to learn node representations over the built HG, in which a graph structure refinement is introduced to compensate the sparse connection among entities in the HG for more robust node representation learning. A self-supervised module and a knowledge distillation module are further designed to exploit unlabeled data for improving the model. Extensive experiments on real-world data collected from Instagram demonstrate that the proposed method outperforms state-of-the-art methods."
SP:242da1384f48260d58a0e7949438611c05079197,This paper studies the question of whether the class of exactly representable functions strictly increases by adding more layers (with no restrictions on size) in a neural network with ReLU activations and a given architecture. The authors propose a counterbalance to the universal approximation theorems which suggest that a single hidden layer is sufficient for learning tasks. They also present upper bounds on the sizes of neural networks required to represent functions in these neural hypothesis classes.
SP:8d5741aedf3125e0e790a58ec3ce81a4e2ea4dcb,"This paper proposes a general framework of min-max optimization over multiple domains that can be leveraged to improve the design of different types of adversarial attacks. In particular, given a set of risk sources, minimizing the worst-case attack loss can be reformulated as a min-min problem by introducing domain weights that are maximized over the probability simplex of the domain set. The proposed method can be used to generate model ensemble attack, universal attack over multiple images, and robust attack over data transformations. Extensive experiments demonstrate that the proposed method leads to substantial attack improvement over the existing heuristic strategies and robustness improvement over state-of-the-art defense methods trained to be robust against multiple perturbation types. "
SP:9dcb74bfdbc4aa1e27f5d2adb6d2abf475e9324d,"This paper studies the problem of sparse tensor principal component analysis (SSTM), where the goal is to recover the k-sparse unit vector x \in R with i.i.d. Gaussian entries. The authors propose a family of algorithms that smoothly interpolates between a simple polynomial-time algorithm and the exponential-time exhaustive search algorithm. The algorithms recover the sparse vector for signal-tonoise ratio in time $\tilde{O}(k/t)$, capturing the state-of-the-art guarantees for the matrix settings. The results extend to the case of r sparse signals with disjoint supports, with guarantees that are independent of the number of spikes. "
SP:660137b0f84e47c06dc2bee1c95b299c67e4cb67,"-based multilayer-perceptrons (MLP) are known to struggle with learning functions of high-frequencies, and in particular cases with wide frequency bands. This paper proposes a spatially adaptive progressive encoding (SAPE) scheme for input signals of MLP networks, which enables them to better fit a wide range of frequencies without sacrificing training stability or requiring any domain specific preprocessing. SAPE gradually unmasks signal components with increasing frequencies as a function of time and space. The progressive exposure of frequencies is monitored by a feedback loop throughout the neural optimization process, allowing changes to propagate at different rates among local spatial portions of the signal space."
SP:b03063fa82d76db341076e5f282176f4c007a202,"This paper studies the problem of finding the quantal response equilibrium (QRE) of a two-player matrix game with entropy regularization. The authors propose an algorithm to find the QRE at a linear rate. The algorithm is motivated by the algorithmic role of entropy regularisation in single-agent reinforcement learning and game theory. The proposed algorithms can be implemented in a decentralized manner, where each player executes symmetric and multiplicative updates iteratively using its own payoff without observing the opponent’s actions directly. "
SP:862223b8bd4c275f96c7e41c92daaa2ca2906194,This paper proposes an implicit super-resolution network (ITSRN) method for low-resolution (LR) screen content images (SCIs) for continuous SR at arbitrary ratios. The proposed method uses an implicit transformer to infer pixel values at query coordinates from image features at key coordinates by the proposed implicit transformer and an implicit position encoding scheme is proposed to aggregate similar neighboring pixel values to the query one. Extensive experiments show that the proposed ITSRN significantly outperforms several competitive continuous and discrete SR methods for both compressed and uncompressed SCIs.
SP:3751625929b707ced417c3eb10064e4917866048,"This paper proposes a method for learning interventional distributions using sumproduct networks (SPNs) that are over-parameterized by gate functions, e.g., neural networks. The proposed method, iSPN, is motivated and illustrated by a structural causal model themed around personal health. The empirical evaluation against competing methods from both generative and causal modelling demonstrates that interventional SPNs indeed are both expressive and causally adequate."
SP:c857ff674ca05c1d949337cb885f056b82d981d6,"This paper proposes a method for generating low-dimensional temporal embeddings of fMRI data. The proposed method is based on the Markov factor analysis (DMFA) method, which is a generative model that employs Markov property in a chain of low dimensional temporal embedding together with spatial inductive assumptions, to capture temporal dynamics in functional magnetic resonance imaging (fMRI) data, and tackle their high spatial dimensionality, respectively. Experiments on synthetic and real fMRI datasets demonstrate the capacity of DMFA in revealing interpretable clusters and capturing nonlinear temporal dependencies in these high dimensional imaging data."
SP:855dcaa42868a29a14619d63221169495ed5dd54,"This paper proposes Moser Flows (MF), a new class of continuous normalizing flows (CNFs) for learning generative models for complex geometries described via manifolds, such as spheres, tori, and other implicit surfaces. The density is parameterized as the source (prior) density minus the divergence of a neural network (NN). The divergence is a local, linear differential operator, easy to approximate and calculate on manifolds. Unlike other CNFs, MF does not require invoking or backpropagating through an ODE solver during training. Theoretically, the authors prove that MF constitutes a universal density approximator under suitable assumptions. Empirically, they demonstrate for the first time the use of flow models for sampling from general curved surfaces and achieve significant improvements in density estimation, sample quality, and training complexity."
SP:545554de09d17df77d6169a5cc8f36022ecb355c,"This paper studies the problem of non-identifiability of unsupervised representation learning when the mixing process is non-linear. The authors propose an approach based on independent causal mechanisms, where each source is considered independently independent of the other sources. They show that this approach can be used to recover identifiability in the case where the mixing is nonlinear.  "
SP:7df49c554d6c9fca370f049279ef7324b6f79de9,"This paper proposes a method for approximate sampling from an unnormalized target distribution, where the goal is to obtain a tight lower bound on the log-likelihood of the target distribution. The proposed method is based on Annealed Importance Sampling (AIS) with Hamiltonian MCMC. The authors propose to use an AIS-like procedure with Uncorrected HamiltonianMCMC (UHA) to approximate the AIS. They show that UHA leads to tight and differentiable lower bounds on logZ. They also show empirically that their method yields better performances than other competing approaches, and that the ability to tune its parameters using reparameterization gradients may lead to large performance improvements."
SP:b0bf070e8d7eefdfc45f236e9ecb9edfb4816e0a,"This paper proposes an efficient and trainable local Lipschitz upper bound for certified robustness of deep neural networks by considering the interactions between activation functions (e.g. ReLU and MaxMin) and weight matrices. Specifically, when computing the induced norm of a weight matrix, the authors eliminate the corresponding rows and columns where the activation function is guaranteed to be a constant in the neighborhood of each given data point, which provides a provably tighter bound than the global bound of the neural network. The authors also propose to clip activation functions with a learnable upper threshold and a sparsity loss to assist the network to achieve an even tighter local bound. Experimental results show that the proposed method outperforms state-of-the-art methods in both clean and certified accuracy."
SP:f6314bfd897cb996de2eaabf0d3037f41da467f3,This paper proposes a method for conformal Bayesian predictive intervals with finite sample calibration guarantees. Conformal inference provides finite sample frequentist guarantees on predictive confidence intervals without the requirement of model fidelity. The proposed method is based on adding-one-in importance sampling to re-weighted posterior samples of model parameters. The authors demonstrate the utility on a range of examples including extensions to partially exchangeable settings such as hierarchical models. 
SP:1e86c162b8e8d652a0590b66aa5f7c363955cc5b,"This paper proposes a method to use denoisers for solving inverse problems. The proposed method is based on the idea of denoising potentials, which are the gradients of smooth scalar-valued deep neural networks, acting as potentials. The authors show that the proposed method converges to stationary points of an underlying objective function consisting of the learned potentials and can be integrated into existing inverse algorithms with backtracking step size, removing the need for enforcing the Lipschitz constant of the denoiser during training."
SP:da92e936f88b3842ca82c2914413b129ca35890f,"This paper proposes a method to generate music with human movements. The method works by extracting skeleton keypoints from a video and using a sequence of models to translate them to rhythmic sounds. In particular, the method first infers the music beat and the style pattern from body keypoints per each frame to produce the rhythm. Next, it implements a transformer-based model to generate the hits of drum instruments and implements a U-net based model to create the velocity and the offsets of the instruments."
SP:0f7ff312a242a553dc9ecf35b421e58fb2d50a26,This paper proposes a one-step algorithm for offline reinforcement learning that uses an on-policy Q estimate of the behavior policy to improve the performance of an actor-critic algorithm. The proposed algorithm is shown to outperform iterative algorithms on a large portion of the D4RL benchmark. The authors argue that the poor performance of iterative approaches is a result of the high variance inherent in doing off-policy evaluation and magnified by the repeated optimization of policies against those estimates. They hypothesize that the strong performance of the one step algorithm is due to a combination of favorable structure in the environment and behavior policy.
SP:0346eba4f587acbe3492d039066f1737360fd870,"This paper studies the problem of low-rank matrix recovery in nonsmooth matrix optimization. The authors show that the extragradient method, when initialized with a ""warm-start"" point, converges to an optimal solution with rate O(1/t) while requiring only two low rank SVDs per iteration. They also give a precise trade-off between the rank of the SVD and the radius of the ball in which we need to initialize the method. They support their theoretical results with empirical experiments on several nonsmoothing low rank matrix recovery tasks."
SP:d39f1d77d9919f897ccf82958b71be8798523923,"This paper proposes a method for estimating conditional average treatment effects (CATEs) for structured treatments (e.g., graphs, images, texts). Given a weak condition on the effect, the authors propose the generalized Robinson decomposition (SIN) which isolates the causal estimand (reducing regularization bias), allows one to plug in arbitrary models for learning, and possesses a quasi-oracle convergence guarantee under mild assumptions. In experiments with small-world and molecular graphs, the proposed method outperforms prior work in CATE estimation."
SP:eeb42a1e48857f976a647eb8d86d25c9012962d5,"This paper proposes a new method for causal effect identification based on a combination of graphical criteria and matrix equations. Specifically, the authors first characterize the relationships between certain graphically-driven formulae and matrix multiplications. Then, they extend the spectrum of proxy variable based identification conditions and propose novel intermediary criteria based on the pseudo-inverse of a matrix. Finally, they devise a new algorithm that accepts as input a collection of marginal, conditional, and interventional distributions, integrating enriched matrix-based criteria into a graphical identification approach."
SP:db15860d08418f6bc792c2ade2eade32840a12b8,"This paper studies the problem of unsupervised environment design (UED) in the context of zero-shot transfer learning. In particular, the authors propose to use Prioritized Level Replay (PLR) as a special case of UED. They show that PLR can generate novel and complex levels for effective training, and propose a new algorithm called Dual Curriculum Design (DCD) based on PLR. The authors also provide a theoretical analysis of the convergence of DCD to Nash equilibria. "
SP:9ed528da4b67f22678303cfd975aafe678db6411,"This paper studies the multi-armed bandit problem in the shuffle model with a distribution-dependent and distribution-independent regret bound of $O(\tilde{O}(\epsilon^{-1/\delta})$ where $T$ is the number of rounds, $a$ is a suboptimality gap of the arms, and $k$ the total number of arms. The authors provide an algorithm for the centralized model with $O(k^2/k)$ regret, which matches the regret of the best known algorithms for the central model and significantly outperforms the best-known algorithm in the local model. For the private binary summation problem, the optimal achievable errors in the central, local and shuffle model are $\Omega(\sqrt{m/\varepsilon})$ in the case of central model.    The authors also provide a regret bound for the private summation model, which approximates the sum of real values in [0, 1]. "
SP:de2523a5fdebda3573f1063447a7818bf3ed6333,"This paper proposes a new notion of calibration called threshold calibration, which is exactly the condition required to ensure that decision loss is predicted accurately for threshold decisions. Threshold calibration strikes a balance between average and distribution calibration; it is the necessary and sufficient condition to guarantee zero reliability gap for any threshold decision under any threshold loss function. To achieve this, the authors propose an efficient algorithm that takes an uncalibrated forecaster as input and provably outputs a threshold-calibrated Forecaster. Empirically, threshold calibration improves decision loss prediction without compromising on the quality of the decisions in two real-world settings: hospital scheduling decisions and resource allocation decisions."
SP:f55160db59c6f3e85f6e1ea0ec32c1a0982fbc48,"This paper proposes a method to construct centroid approximation for the distribution of maximum points of a random function (a.k.a. argmax distribution), which finds broad applications in machine learning. The method optimizes a set of centroid points to compactly approximate the arg max distribution with a simple objective function. Theoretically, the argmax centroid method can be shown to minimize a surrogate of Wasserstein distance between the ground-truth arg Max distribution and the centroids approximation under proper conditions. Empirical results demonstrate the applicability and effectiveness of the proposed method on a variety of real-world multitask learning applications, including few-shot image classification, personalized dialogue systems and multi-target domain adaptation."
SP:ef342e3c6a16e898a49b700a9fd4f0ea6a069dcc,"This paper studies the online multi-objective reinforcement learning (MORL) problem where the objectives are balanced using preferences. The authors consider the online setting where the agent receives a (adversarial) preference every episode and proposes policies to interact with the environment. They provide a model-based algorithm that achieves a nearly minimax optimal regret bound. The algorithm is provably efficient with a nearly optimal trajectory complexity with a sample complexity of $O(\sqrt{d, S}^2/2)$, where $d$ is the number of objectives, $S$ is number of states, $A$ of actions, $H$ the length of the horizon, and $K$ of episodes. "
SP:aa84981dd503ec34d9f06aa6e5f680e267f82b04,"This paper proposes a new method for generating explanations for dialogue response generation. The proposed method, LERG, is based on the mutual interaction of segments in input and output sentences. LERG views the sequence prediction as uncertainty estimation of a human response and then creates explanations by perturbing the input and calculating the certainty change over the human response. Experimental results show that LERG adheres to desired properties of explanation for text generation, including unbiased approximation, consistency, and cause identification. "
SP:965413b1726617006317bbbec55673dd5d21812a,"This paper proposes to combine error-compensation-based gradient compression with accelerated gradient compression methods to reduce the communication cost in distributed training of large-scale machine learning models. In particular, the authors propose and study the error compensated loopless Katyusha method, and establish an accelerated linear convergence rate under standard assumptions. They show that the proposed method converges with substantially fewer communication rounds than previous error compensated algorithms. "
SP:27c58dad7fa7743a8ff56fad863aa0dae823dccb,"This paper proposes a neuron-astrocyte liquid state machine (NALSM) that addresses the under-performance through self-organized near-critical dynamics. Similar to its biological counterpart, NALSM integrates neuronal activity and provides global feedback to spike-timing-dependent plasticity (STDP), which self-organizes NAL SM dynamics around a critical branching factor that is associated with the edge-of-chaos. Experiments on MNIST, N-MNIST, and Fashion MNIST demonstrate the effectiveness of the proposed method."
SP:64ccd697d3c11d7d8947ef1b06c61d94b6a2e575,"This paper studies the problem of graph topology imbalance in semi-supervised node classification. In particular, the authors propose a new metric called Totoro to measure the degree of graph graph topological imbalance and propose a model-agnostic method ReNode to address the topology-imbalance issue by re-weighting the influence of labeled nodes adaptively based on their relative positions to class boundaries. Empirical results demonstrate the effectiveness and generalizability of the proposed method. "
SP:ec12f0a05db75ac15ad22b34cdc2a0142bc2c72f,"This paper studies piece-wise constant signals corrupted by additive Gaussian noise over a d-dimensional lattice. The authors propose to estimate the partition of the lattice induced by the constancy regions of the unknown signal using the computationally-efficient dyadic classification and regression tree (DCART) methodology proposed by [14]. They prove that, under appropriate regularity conditions on the shape of the partition elements, a DCART-based procedure consistently estimates the underlying partition at a rate of order σ2k\sqrt{k} log(N)/k$, where k is the minimal number of rectangular sub-graphs obtained using recursive dyadic partitions supporting the signal partition, σ is the noise variance, $\kappa$ is the smallest magnitude of the signal difference among contiguous elements of the partitions, and N is the size of the structure. "
SP:3c65b3e69a024431cafdc1b4bfbccd432de69faf,"This paper proposes a method to reduce the spurious correlations caused by observed confounders in deep learning models. To do so, the authors propose to use counterfactual maximum likelihood estimation (CMLE) on the interventional distribution instead of the observational distribution. The authors derive two different upper bounds of the expected negative log-likelihood and propose two general algorithms, Implicit CMLE and Explicit CMLE, for causal predictions of deep learning model using observational data. The proposed method outperforms the regular MLE method in terms of out-of-domain generalization performance and reducing spurious correlations, while maintaining comparable performance on the regular evaluations."
SP:c5a59c8d6db0f5491721aaaef182609c360930d3,"This paper proposes a method to address the problem of conflicting gradients in multi-task learning, where gradients of different task objectives are not well aligned so that following the average gradient direction can be detrimental to specific tasks’ performance. The proposed method, called Conflict-Averse Gradient Descent (CAGrad), balances the objectives automatically and still provably converges to a minimum over the average loss. CAGrad is a special case of the regular gradient descent (GD) and the multiple gradient descent algorithm (MGDA) in the multi-objective optimization (MOO) literature as special cases."
SP:000cbfda2e26fdcfee50a628799a73b6886cfccc,"This paper studies the problem of few-shot learning in the context of language models and machine learning. The authors frame this problem as a teaching problem with strong priors, and study whether language models can identify simple algorithmic concepts from small witness sets. In particular, they explore how several GPT architectures, program induction systems, and humans perform in terms of the complexity of the concept and the number of additional examples, and how much their behaviour differs. "
SP:ba01895bf1aa07a0630b8c41fc0e91effb34b4cf,"This paper proposes a method to distill the robust and non-robust features in the feature space using Information Bottleneck. Specifically, the authors inject noise variation to each feature unit and evaluate the information flow in feature representation to dichotomize feature units either robust or not robust, based on the noise variation magnitude. They demonstrate that the distilled features are highly correlated with adversarial prediction, and they have human-perceptible semantic information by themselves. Furthermore, they present an attack mechanism intensifying the gradient of non-Robust features that is directly related to the model prediction."
SP:ed67b2664359799a11cebb9eaba6da74ff1dd977,"This paper studies the phenomenon of support vector proliferation in support vector machine (SVM) and minimum Euclidean norm least squares regression (MORL) models. The authors prove a super-linear lower bound on the dimension (in terms of sample size) required for support vectors proliferation in independent feature models, matching the upper bounds from previous works. They further identify a sharp phase transition in Gaussian feature models and bound the width of this transition, and give experimental support for its universality. Finally, they hypothesize that this phase transition occurs only in much higher-dimensional settings in the l1 variant of the SVM."
SP:99f226a63902863c429cb7baefab09626d13921e,"This paper studies the active pure exploration problem in Markov Decision Processes (MDPs), where the agent sequentially selects actions and, from the resulting system trajectory, aims to identify the best policy as fast as possible. The authors propose a problem-dependent lower bound on the average number of steps required before a correct answer can be given with probability at least 1-\delta. They also provide the first algorithm with instance-specific sample complexity in this setting. This algorithm addresses the general case of communicating MDPs; they also propose a variant with a reduced exploration rate and faster convergence."
SP:de4a0f5a464aa3311445cc25c4915cf0c4d975c3,"This paper proposes a geometry-based query embedding model for embedding entities and queries as Cartesian products of two-dimensional cones, where the intersection and union of cones naturally model the conjunction and disjunction operations. By further noticing that the closure of complement of cones remains cones, the authors design geometric complement operators in the embedding space for the negation operations. Experiments demonstrate that ConE significantly outperforms existing state-of-the-art methods."
SP:773b5b6d31e6899da395933eb7f9e25a6e50c406,"This paper considers the problem of optimal control of stochastic nonlinear systems with separable cost and constraints in the state and input variables. The authors propose a novel numerical scheme for implementation of the corresponding value iteration (VI) algorithm in the conjugate domain in the linear-time Legendre transform. Detailed analyses of the convergence, time complexity, and error of the proposed algorithm are provided. "
SP:7cd593ccba4830f3383a92ef6266224cc7699706,"This paper presents a method for learning multimodal representations from unlabeled data using convolution-free Transformer architectures. Specifically, the authors propose a VideoAudio-Text Transformer (VATT) that takes raw signals as inputs and extracts multimodals representations that are rich enough to benefit a variety of downstream tasks. The authors train VATT end-to-end from scratch and evaluate its performance by the downstream tasks of video action recognition, audio event classification, image classification, and text to video retrieval. VATT achieves the top-1 accuracy of 82.1% on Kinetics-400, 83.6% onKinetics-600, 72.7% on kinetics-700, and 41.3% on Moments in Time."
SP:97f533426dce73d27768dd7afc2ddf035cf21e61,This paper proposes a method to reduce the computational cost of self-attention in kernel machines by replacing the softmax structure with a Gaussian kernel to stabilize the model training and adapts the Nyström method to a non-positive semidefinite matrix to accelerate the computation. The proposed method Skyformer is evaluated on the Long Range Arena benchmark and achieves comparable or better performance than the full self attention while requiring fewer computation resources.
SP:a6f1094a4c9f38df38c9710b9dcd6299f430fae2,"This paper proposes a data-augmentation method for policy cloning in the setting of behavioral cloning, where the goal is to transfer the behavior of an expert policy to a student policy for high-degree of freedom (DoF) control problems. The proposed method combines image-based data augmentation to build invariance to image perturbations with an expert-aware offline data augmentation approach that induces appropriate feedback-sensitivity in a region around expert trajectories. The results show that the proposed method is able to transfer complex high-DoF behaviors from just a few trajectories to the student policy with high data efficiency. "
SP:3660d1d4a8e8f281880781ba32df7b678b705f9c,"This paper proposes a method to design ""robust"" objects, i.e., objects that are explicitly optimized to be confidently classified by deep neural networks. The method is based on the observation that deep networks are sensitive to input perturbations, and the authors propose to use this sensitivity to design “robust objects” to design robustness-based objects. The proposed method yields improved performance on standard benchmarks, a simulated robotics environment, and physical-world experiments. "
SP:4c12852373f5f113bd47dce3e2434c5e7d61a202,"This paper studies the problem of data augmentation in image-based off-policy RL and proposes a simple yet effective technique for stabilizing this class of algorithms under augmentation. The proposed method improves the sample efficiency and sample efficiency of ConvNets and Vision Transformer-based RL algorithms on a family of benchmarks based on DeepMind Control Suite, as well as in robotic manipulation tasks. Experiments on DMControl and Distracting Control Suite demonstrate the effectiveness of the proposed method. "
SP:f8ca9d92c45adc4512381035856b445029e3080a,"This paper studies the problem of federated learning, where multiple worker nodes (WNs) build a joint model by using local data. The authors consider a class of stochastic algorithms where the WNs perform a few local updates before communication. They show that when both the WN's and the server's directions are chosen based on a momentum estimator, the algorithm requires O(3/2) samples and O(1/3/1) communication rounds to compute a stationary solution. This is the first FL algorithm that achieves such near-optimal sample and communication complexities simultaneously. "
SP:bd3eecb81a17af010f2d3555434990855c1810f2,This paper studies the generalization properties of SGLD with isotropic noise. The authors show that the optimal noise covariance is the square root of the expected gradient covariance if both the prior and the posterior are jointly optimized. They also provide a new information-theoretical bound that enables such an optimization analysis. They then apply matrix analysis to derive the form of optimal noise.
SP:19fbd1a381598538662417a4a1885ba4ac04f5f8,"This paper proposes a new video compression method that can support multiple prediction modes. The proposed method is based on a motion compensation module that applies multiple 3D motion vector fields (i.e., voxel flows) for weighted trilinear warping in spatial-temporal space. The paper also proposes a flow prediction module to predict accurate motion trajectories with a unified polynomial function. The experimental results show that the proposed method achieves comparable R-D performance with the latest Versatile Video Coding (VVC) standard in terms of MS-SSIM."
SP:ba790fdcf2deef1a1b5e1961c7c4a28dd0218420,"This paper proposes a multitask generalization of Online Mirror 1 Descent (OMD) that operates by sharing updates between tasks. The authors prove that the regret of MT-OMD is of order \sqrt{1 + \sigma^2(N-1/T) + \tilde{O}(N - 1)^2/T^2$, where $N$ is the number of tasks and T is the time horizon. This improves upon the $O(1/N)$-NT bound obtained by running independent OMDs on each task. The paper also provides numerical experiments on several real-world datasets."
SP:75f80e4e7836a7575e60de7f055820c6c7065fcb,"This paper studies the underdamped Langevin diffusion (ULD) with strongly-convex potentials with finite summation of N smooth components, and proposes an efficient discretization method, which requires O(N + d 1 3N 2 3 /ε 2 3 ) gradient evaluations to achieve $\�-error$ for approximating d-dimensional ULD. The authors also prove a lower bound of gradient complexity as $O(\sqrt{d + d}/\epsilon^2/3)$, which indicates that their method is optimal in dependence of N, N, and d. In particular, they apply their method to sample the strongly-log-concave distribution and obtain gradient complexity better than all existing gradient based sampling algorithms. "
SP:22822f378c3fbc15b77eb736194b1ce7f0585072,"This paper proposes a method for continual learning in recurrent neural networks. The proposed method is based on a combination of weight regularization and projected gradient descent. In particular, the proposed method uses Bayesian weight regularisation to encourage good performance on all tasks at convergence and combines this with gradient projection using the prior precision, which prevents catastrophic forgetting during optimization. The method is shown to outperform existing methods in both feedforward and recurrent networks. "
SP:26de056be14962312c759be5d284ef235d660f9c,"This paper studies the problem of learning injective normalizing flows from low-dimensional data to high-dimensional space. The authors propose two methods to backpropagate through the volume term arising from the injective change-of-variable formula. The first method involves exact evaluation of this term and its gradient which incurs a higher memory cost; the second method uses conjugate gradients and Hutchinson’s trace estimator to obtain unbiased stochastic gradient estimates. The proposed methods perform end-to-end nonlinear manifold learning and density estimation for data projected onto this manifold. Empirical results show that the proposed methods outperform existing methods by more accurately learning manifolds and the corresponding distributions on them, and show promising results on OOD detection."
SP:395dae632dab83f3f61bdf67eabe4d351492798c,"This paper proposes Latent Equilibrium, a new framework for inference and learning in slow components of neural networks. The authors propose to leverage the ability of biological neurons to phase-advance their output with respect to their membrane potential. This principle enables quasi-instantaneous inference independent of network depth and avoids the need for phased plasticity or computationally expensive network relaxation phases. The proposed model can be interpreted as a biologically plausible approximation of error backpropagation in deep cortical networks with continuous-time, leaky neuronal dynamics and continuously active, local plasticity. The experimental results demonstrate the effectiveness of the proposed method."
SP:b937901e3230b14e36975fbab0658a52bdac4977,"This paper proposes a new graph neural network (GNN) architecture called Nested Graph Neural Networks (NGNNs) for graph classification. The proposed architecture is based on the Weisfeiler-Lehman (1-WL) algorithm, where the goal is to learn a node representation that encodes a rooted subtree around the center node. However, rooted subtrees are of limited expressiveness to represent a nontree graph. To address this issue, NGNNs proposes to extract a local subgraph around each node and apply a base GNN to each subgraph to learn the subgraph representation. Then, the whole-graph representation is obtained by pooling these subgraph representations. Theoretical analysis shows that NGNN is strictly more powerful than 1-wL and can discriminate almost all r-regular graphs. Experiments on synthetic and real-world graph classification/regression datasets demonstrate the effectiveness of NGNN."
SP:7b8284aa82022ce73802bfc57238b0d82031b226,"This paper proposes nested variational inference (NVI), a family of methods that learn proposals for nested importance samplers by minimizing an forward or reverse KL divergence at each level of nesting. NVI is applicable to many commonly-used importance sampling strategies and provides a mechanism for learning intermediate densities, which can serve as heuristics to guide the sampler. The authors apply NVI to sample from a multimodal distribution using a learned annealing path, learn heuristic to approximate the likelihood of future observations in a hidden Markov model, and to perform amortized inference in hierarchical deep generative models. The experiments show that NVI leads to improved sample quality in terms of log average weight and effective sample size."
SP:f3792f82b28727a7a198c6eac9511391d2045a5f,"This paper studies the problem of zeroth-order optimization of a Lipschitz function f defined on a compact subset X of R, with the additional constraint that algorithms must certify the accuracy of their recommendations. The optimal number of evaluations to find and certify an approximate maximizer of f at accuracy $\�$ is shown to be nearly proportional to the integral $\tilde{O}(\max(f)+ f(x) + \�)$. This result solves an open problem dating back to 1991. The upper bound relies on a packing bound by Bouttier et al. (2020) for the Piyavskii-Shubert algorithm that they link to the above integral. They also show that a certified version of the DOO algorithm matches these packing and integral bounds. "
SP:6e8134eeaf524db765a6186f3de74e936243f8d4,"This paper proposes a new method to attack uncertainty estimation of deep neural networks (DNNs) in a black-box setting where the attacker has no knowledge of the target network, and in a white-box scenario where the adversary has access to the target DNN. The proposed method attacks the network's capacity for uncertainty estimation by perturbing the parameters of the DNN to make it more confident of its incorrect predictions than about its correct ones. The authors demonstrate the effectiveness of the proposed method on three popular uncertainty estimation methods: vanilla softmax score, Deep Ensembles and MC-Dropout. They also show an attack on SelectiveNet, the selective classification architecture. "
SP:c5a5bf6e0bdebf5170c8fe3fedd2f3438e39cd21,"This paper studies the problem of community detection in dynamic networks. The authors propose a simple model for networks growing over time which they refer to as streaming stochastic block model (StSBM). Within this model, they prove that voting algorithms have fundamental limitations. They also develop a streaming belief-propagation (STREAMBP) approach, for which they prove optimality in certain regimes. They validate their theoretical findings on synthetic and real data. "
SP:b1163857a6b06047c3531ab762642fcbed6dd294,"This paper studies the regularization cost of linear neural networks as parameterization of linear predictors. The authors study the representation cost of certain sparse linear ConvNets and residual networks. They also study the reverse problem, identifying which regularizers (e.g., group quasi-norms, the k-support-norm, elastic net) can be the representation costs induced by simple l2 regularization, and designing the parameterizations that do so. "
SP:c9c7fc5288e24a54531b7063c028d307279fe2ef,"This paper proposes a non-parametric approach to reasoning in knowledge graphs (KGs) that is reminiscent of case-based reasoning in classical artificial intelligence (AI). The proposed method derives crisp logical rules for each query by finding multiple graph path patterns that connect similar source entities through the given relation. The method achieves state-of-the-art performance on NELL-995 and FB-122 datasets, outperforming all previous models, on the task of finding a target entity given a source entity and a binary relation. "
SP:f63e4ed39d577b50eab4f4b6d08ef912a69840ef,"This paper presents a Transformer-based entity linking model that combines large scale pretraining from Wikipedia links with large scale pre-training from entity linking datasets. The proposed model achieves the state-of-the-art results on CoNLL and TAC-KBP. The authors also provide a detailed analysis of the choice of negative entity candidates, Transformer architecture, and input perturbations for entity linking. "
SP:eaeee88e0717cda8d6f3d8ff83ebe594eba44f29,"This paper proposes an ensemble active learning method for large-scale training of deep neural networks (DNNs) with large labeled datasets. The authors propose to scale up ensemble Active Learning methods to perform acquisition at a large scale (10k to 500k samples at a time). They do this with ensembles of hundreds of models, obtained at a minimal computational cost by reusing intermediate training checkpoints. They observe that their approach obtains favorable subsets of training data, which can be used to train more accurate DNNs than training with the entire dataset."
SP:4a1cce61f12c68846c507130bd055b3444ac8101,This paper proposes a new routing algorithm for capsule networks. The routing algorithm is based on inverted dot-product attention. The proposed method is evaluated on CIFAR-10/100 and DiverseMultiMNIST datasets. The results show that the proposed method achieves comparable performance as the state-of-the-art convolutional neural networks (CNNs) but with much fewer parameters.
SP:99ca283c579152bc44b19c21392aeb7f6b76231b,"This paper proposes a new method for hyperparameter optimization in deep neural networks. The proposed method is based on the idea that hyperparameters control the level of correlated noise in training, which can be mapped to an effective temperature. To this end, the authors propose to use the parallel tempering technique of statistical physics to sample non-local paths instead of points in the hyper-parameter space. Empirical results on EMNIST and CIFAR-10 show that the proposed method can improve the performance of neural networks trained on dropout and learning rate optimization tasks."
SP:beba754d96cc441712a5413c41e98863c8abf605,This paper studies the effect of minimum risk training (MRT) and generative adversarial training (GAN) on the performance of machine translation (MT) models. The authors show that MRT does not optimize the expected reward and that other methods take infeasibly long time to converge. They also show that GANs and MRT do not work well when the pre-trained parameters are already close to yielding the correct translation. They conclude by discussing other RL practices in MT which should be avoided for practical and theoretical reasons.
SP:366b68d2490ea7569c74dc66ec0f83daa029ddd9,"This paper investigates the large-sample behavior of the Q-value estimates with closed-form characterizations of the asymptotic variances. The authors show that the closed form characterizations can be used to efficiently construct confidence regions for Q-values and optimal value functions, and to develop policies to minimize their estimation errors. This also leads to a policy exploration strategy that relies on estimating the relative discrepancies among the Q estimates. Numerical experiments show that this exploration strategy outperforms other benchmark approaches."
SP:d922459581c3295ff315fda6e59b9f7e9147f22d,"This paper proposes a collaborative generated hashing (CGH) method to improve the efficiency of the Top-k recommendation system by denoting users and items as binary codes. Specifically, CGH is designed to learn hash functions of user and items through the Minimum Description Length (MDL) principle to deal with various recommendation settings. CGH initiates a new marketing strategy through mining potential users by a generative step. Extensive experiments on two public datasets show the advantages for recommendations in various settings."
SP:c2a5551f229211c9aa4c43686b517fcde82bbccf,This paper proposes a method for addressing discrepancies in input and output spaces between source and target domains in pharmacogenomics. The authors propose to use adversarial domain adaptation and multi-task learning to address these discrepancies. The proposed method AITL is the first adversarial inductive transfer learning method to address both the input space and output space discrepancies. Experimental results show that the proposed method outperforms state-of-the-art pharmacogenomic and transfer learning baselines.
SP:a27f975266e990b2ab4a0ab8db1588e945d0300a,This paper proposes a mixture of model-based and model-free reinforcement learning (RL) algorithms that combine the strengths of both RL methods. The authors propose to use a special type of uncertainty quantification by a stochastic dynamics model in which the next state prediction is randomly drawn from the distribution predicted by the dynamics model. The influence of the ensemble of dynamics models on the policy update is controlled by adjusting the number of virtually performed rollouts in the next iteration according to the ratio of the real and virtual total reward. The proposed method is tested on a collection of benchmark tasks including simulated robotic locomotion.
SP:2aaddb6dda434b49487857d99c9d143e2f54d350,This paper proposes a method to detect adversarial examples using a class-conditional reconstruction of the input image. The method is based on the idea of reconstructing the image from the original image and then using the reconstructed image to train a classifier. The proposed method is shown to be more effective than other methods in detecting adversarial images. The authors also show that the proposed method outperforms CNNs and convolutional networks in terms of detection accuracy.
SP:da88bfbe3f59ce1a24522aa5e74c9472b079664a,"This paper studies the effect of initialization and the activation function on the NTK as the network depth becomes large. It shows that a special initialization known as the Edge of Chaos (Yang & Schoenholz, 2017) leads to better training dynamics and that a class of smooth activation functions discussed in (Hayou et al., 2019) also improves the training dynamics compared to ReLU-like activation functions (see also Clevert et al. (2016)). "
SP:dd59b897384c52c20d62be73fc33184c8c226f4b,"This paper proposes a self-supervised method to learn sentence representations with an injection of linguistic knowledge. The authors propose to learn to represent sentences by contrasting these diverse views of the same sentence. By contrasting different linguistic views, the authors aim at building embeddings which better capture semantic and are less sensitive to the sentence outward form. The model parameters are learned using a discriminating objective as proposed in Logeswaran & Lee."
SP:980babd58fc2ea5f40bb22b3a9a09737f14f3f18,"This paper presents a transfer learning method for sentiment classification in financial sentiment classification. The proposed method, FinBERT, is a language model based on BERT, which is applied to the FinancialPhraseBank dataset. The authors show that the proposed method outperforms the state-of-the-art methods by 14 percentage points on the FTSE100 dataset. "
SP:31c9c3a693922d5c3448e80ade920391dce261f9,"This paper proposes a method for singing voice generation without pre-assigned musical scores and lyrics. The authors propose three different methods to generate singing voice waveforms, which can be either unconditioned or weakly conditioned. They also propose a pipeline to tackle these new tasks, which involves the development of source separation and transcription models for data preparation, adversarial networks for audio generation, and customized metrics for evaluation. The proposed method is evaluated on a set of samples from a jazz music dataset."
SP:99d41c8285fd0270ff16e915ef03187a0a7005b0,This paper proposes a novel adversarial defense technique that leverages a latent high-order factorization of the network. The proposed method can be easily integrated with any arbitrary neural architecture and combined with techniques like adversarial training. Experiments on standard image classification benchmarks and audio classification tasks demonstrate the effectiveness of the proposed method.
SP:762729b64c1c1494de0f7410ea3662da61e93b6d, forecasting is an important problem in the context of time series forecasting. This paper proposes a novel clustering method for spatiotemporal time series data. The proposed method is based on graph attention networks (GATN) and graph transformer networks (GTN). The GATN is used for spatial clustering and the GTN for temporal clustering. Experiments show that the proposed method can achieve better performance than other baselines.
SP:81d7c60d0d12eb268d7edeebe86422991a1d4997,"This paper studies the algorithmic and statistical properties of the fitted Q iteration (FQI) algorithm with deep neural networks (DQN) in deep reinforcement learning. FQI is a simplified version of DQN that captures the tricks of experience replay and target network used in DQNs. Under mild assumptions on the action-value functions of the iterative policy sequence, the authors show that the algorithm converges to zero at a geometric rate. In particular, the statistical error characterizes the bias and variance that arise from approximating the action value function using deep neural network. The algorithmic error is defined as the difference between the expected return and the true value of the action function.   "
SP:a558ffa1706ef78893528c8c23e2295a79824d2f,This paper proposes a Transformer-based approach to represent the semantic composition of a sentence. The authors argue that the phrase composition plays an important role in the attention mechanism and propose a new attention architecture called PhraseTransformer. The proposed architecture uses hyper-nodes to represent candidate phrases in attention. The experimental results show the effectiveness of the proposed method. 
SP:622b0593972296a95b630a4ece1e959b60fec56c,"This paper presents a modular neural network architecture MAIN that learns algorithms given a set of input-output examples. MAIN consists of a neural controller that interacts with a variable-length input tape and learns to compose modules together with their corresponding argument choices. Unlike previous approaches, MAIN uses a general domain-agnostic mechanism for selection of modules and their arguments. It also uses a memoryless controller with a length-invariant self-attention based input tape encoding to allow for random access to tape locations."
SP:d668cc809e4f6b5f3330cf75cb5f71693a123c07,"This paper proposes a method to quantify the sensitivity of a deep neural network to quantization in floating point arithmetic. The method is based on Monte Carlo arithmetic, where the neural network parameters are quantized in a Monte Carlo fashion. The authors evaluate their method on the CIFAR-10 and ImageNet datasets and show that their method is able to gain the equivalent of bits of precision by simply choosing weight parameter sets that demonstrate a lower loss of significance."
SP:eda1d368aa3b4d806020c4c430a173d1ddd13d0d,"This paper studies the problem of ""objective mismatch"" in model-based reinforcement learning (MBRL). In particular, the authors point out that there is an objective mismatch between training the forward dynamics model w.r.t. the likelihood of the one-step ahead prediction, and the overall goal of improving performance on a downstream control task. The authors propose an initial method to mitigate the mismatch issue by reweighting the dynamics model training. "
SP:63c452f2b2cbfeea0b45831bd7dc1ac26883fd9f,"This paper proposes a new adversarial attack method that exploits both class-wise and layer-wise feature distributions of CNNs. The proposed method is based on the observation that adversarial examples are more likely to be transferrable to different tasks/datasets than standard adversarial attacks. To this end, the authors propose a method to exploit both layer- and task-wise features of a CNN. The method is tested on the ImageNet dataset and achieves state-of-the-art transferability results. "
SP:a7a2ded35804c381603a1196c7f7893fdf796c05,"This paper proposes a new method for comparing policies using Wasserstein distances (WDs) in a latent behavioral space. The proposed method is based on the dual formulation of the WD, which allows to learn score functions over trajectories that can be used to lead policy optimization towards (or away from) (un)desired behaviors. The dual formulation allows the authors to devise efficient algorithms that take stochastic gradient descent steps through WD regularizers. Two algorithms are proposed: Behavior-Guided Policy Gradient (PGG) and Behavior-guided Evolution Strategies (BGE), which are shown to outperform existing methods in a variety of environments."
SP:ef1c6403597c3a6083c1ad4256449325ac99416c,"This paper proposes a new learning-rate-based algorithm for interpolating data in deep learning. The proposed algorithm, ALI-G, uses the interpolation property to compute an adaptive learning rate in closed form at each iteration. The authors provide convergence results for the proposed algorithm in the stochastic convex setting. They also provide experiments on a variety of architectures and tasks. "
SP:6e24a1e0aff73db6ae8558f114b644965e287e36,"This paper studies the role of bottom-up, horizontal, and top-down connections in the learning of visual segmentation tasks. The authors propose a TD+H-CNN-based model with a combination of bottom up, horizontal and top down connections. They evaluate the performance of the model on two tasks: low-level Gestalt vs. high-level object cues for perceptual grouping. They show that a model with bottom up connections can learn to form perceptual groups better than a model that relies solely on horizontal connections. In addition, they also show that top-up connections can resolve straining on tasks with Gestalt cues."
SP:7a0db1e8804defc5c04e0f4dd345272c6df1ff77,"This paper proposes DeepHoyer, a set of sparsity-inducing regularizers that are both differentiable almost everywhere and scale-invariant. The proposed method is inspired by the Hoyer measure (the ratio between `1 and `2 norms) used in traditional compressed sensing problems. The experiments show that the proposed method can produce even sparser neural network models than previous works, under the same accuracy level. "
SP:5ec05ac5d72e8e0b39b15a0cd7b2f5a64e861024,"This paper proposes a variant of Adam for strongly convex functions that achieves a data-dependent O(log T) regret bound. The main idea is to maintain a faster decaying yet under controlled step size for exploiting strong convexity. The proposed SAdam reduces to SC-RMSprop, a recently proposed variant of RMSprop for strongly-convex functions, for which the authors provide the first-order logarithmic regret bound for this class of functions. Empirical results on optimization problems and training deep networks demonstrate the effectiveness of the proposed method."
SP:9f89501e6319280b4a14b674632a300805aa485c,"This paper proposes a lightweight and efficient BERT-based model, BlockBERT, which extends BERT by introducing sparse block structures into the attention matrix to reduce both memory consumption and training time, which also enables attention heads to capture either short or long-range contextual information. The experiments on several benchmark question answering datasets with various paragraph lengths show that the proposed model can use 18.7-36.1% less memory and reduces the training time by 12.0-25.1%, while having comparable and sometimes better prediction accuracy."
SP:0f04fc2e7966f4ba53909654fc0e8b90fc405f2a,"This paper studies the effect of pruning on the generalization performance of neural networks. The authors show that pruning leads to instability in the performance of the model, and that even small pruning of unimportant parameters can lead to instability. They propose a batch-normalized-parameter pruning algorithm to better control pruning stability. "
SP:dba3f5ec3af2a4a67ed4fc36b0f37fe556354177,This paper proposes NAS in embedding space (NASES) for neural architecture search (NAS) with reinforcement learning. The main idea is to use a pre-trained architecture decoder and a pretraining architecture simulator in the first stage of the NASES procedure. The proposed method is evaluated on image classification task on CIFAR-10. The results show that the proposed method can reduce the number of searching architectures to <100 in <12 GPU hours.
SP:e2e5bebccc76a51df3cb8b64572720da97174604,This paper proposes a homotopy training algorithm (HTA) to solve optimization problems arising from neural networks. The HTA starts with several decoupled systems with low dimensional structure and tracks the solution to the high dimensional coupled system. The decoupling systems are easy to solve due to the low dimensionality but can be connected to the original system via a continuous homotopic path guided by the HTA. The authors have proved the convergence of HTA for the non-convex case and existence of the solution path for the convex case. HTA has provided a better accuracy on several examples including VGG models on CIFAR-10.
SP:5d9517fa62cd97b94ff45f645e100a8ad631e281,"This paper introduces the 2-simplicial Transformer, an extension of the Transformer that includes a form of higher-dimensional attention generalising the dot-product attention. This attention is used to update entity representations with tensor products of value vectors. The authors show that this architecture is a useful inductive bias for logical reasoning in the context of deep reinforcement learning."
SP:f66721bf3eccf2e36444c2c41303e97745f10f0e,This paper proposes a method for estimating the pose of an object in an image from a fixed frame of reference. The proposed method is based on the CVAE framework of Kingma et al. (2014) and uses circular latent representations to estimate the corresponding 2D rotations of the object. The method is trained on unlabelled images and unlabeled labeled images. The results show that the proposed method outperforms the baselines in terms of the number of labelled images and the angle coverage. 
SP:87dc93d26ad5ad4a8dccde1780b5b127f391cfd6,"This paper proposes a curriculum learning method for multi-agent reinforcement learning that scales up the population of training agents in a stage-wise manner by progressively increasing the number of agents in each stage. The authors propose an evolutionary approach to fix an objective misalignment issue throughout the curriculum that agents successfully trained in an early stage with a small population are not necessarily the best candidates for adapting to later stages with scaled populations. The proposed method maintains multiple sets of agents at each stage, performs mix-and-match and fine-tuning over these sets and promotes the sets with the best adaptability to the next stage. Empirical results show that the proposed method outperforms baselines by a large margin."
SP:0ea5b3247ce031f25b98cf7d42bd4290020fbed2,"This paper presents a neural network architecture for graph neural networks (GNNs) that is trained on multi-scale image classification tasks. The proposed architecture is based on GNNs trained on the PGM dataset (Barrett et al. (2018)) and the RAVEN dataset (Zhang et al (2019)). The proposed model outperforms WReN, the previous state-of-the-art model, by a considerable margin. The authors also show that the proposed model is robust to variations in forms of object-level representations."
SP:9bcb840f867f1a7108aa22a7bb14c348fda52eb0,This paper proposes an adaptive noise MCMC algorithm that estimates and is able to sample from the posterior of a neural network. It dynamically adjusts the amount of momentum and noise applied to each parameter update in order to compensate for the use of stochastic gradients. The proposed method is evaluated on the Cifar10 benchmark and the large scale ImageNet benchmark. 
SP:8cf0614f0fbd3756453304703d00776cfc9a4b9f,"This paper proposes a method to identify winning tickets (small but critical subnetworks) in deep neural networks that can be identified at a very early training stage, which they term as Early-Bird (EB) tickets, via low-cost training schemes (e.g., early stopping and low-precision training) at large learning rates. They also propose a mask distance metric to identify EB tickets with a low computational overhead, without needing to know the true winning tickets that emerge after the full training. Finally, they leverage the existence of EB tickets and the proposed mask distance to develop efficient training methods, which are achieved by first identifying EB tickets via low cost schemes, and then continuing to train merely the EB tickets towards the target accuracy."
SP:8aeece75c839643a02d2b3b5f3aca7cb76cf1d35," regularization is proposed to improve the robustness of deep convolutional neural networks against adversarial examples. The proposed method is based on the Wasserstein distance regularization, which is applied to the bottleneck embedding layer of a deep neural network in a purely supervised learning setting without considering any reconstruction loss, although optimal transport theory or a discriminator loss has been applied to generative models in an unsupervised learning setting. Experimental results on several benchmark datasets show that the proposed method achieves state-of-the-art performance."
SP:efd68097f47dbfdd0208573071686a62240d1b12,"This paper proposes a neural, end-to-end model for jointly extracting entity recognition and relation extraction tasks. The proposed model does not rely on external NLP tools and integrates a large, pre-trained language model. The model is fast to train and achieves state-of-the-art performance on 5 datasets across 3 domains."
SP:8fd4f3f8615c0a7a76ec7bfe996d2ead803f7828,"This paper studies the problem of ordinal embedding, where the goal is to find a Euclidean representation for a set of items that is similar to the one given by the triplet comparisons. The authors propose a fast algorithm based on DNNs that constructs a representation for the items, using only the answers to the above-mentioned triplet comparison. The proposed algorithm is shown to be significantly faster than existing methods, and can scale to real-world large datasets."
SP:12e7f417a7ef1ccafccff5ffb3f8f11cd2c05b20,"This paper proposes a meta-learning framework to learn data values jointly with the target task predictor model. The proposed method uses a data value estimator (modeled by a deep neural network) to learn how likely each datum is used in training of the predictor model, and trains the model using a reinforcement signal of the reward obtained on a small validation set that reflects performance on the target tasks. Experiments show that the proposed method yields superior data value estimates compared to alternative methods across different types of datasets and in a diverse set of application scenarios. "
SP:e2c3374629cfd654b7b35e88507e65646d70470e,"This paper studies the statistical properties of the per-layer Jacobian of random fully connected ReLU networks through the study of the the per layer Jacobian in finite-depth and width networks. The authors compare three types of architectures: vanilla networks, ResNets, and DenseNets. They show that the variance of Jacobian squared norm is exponential in depth for ResNet and polynomial for DenseNet. They also show that for densely connected networks, the commonly used initialization of He et al. (2015) is enough to ensure the boundness of var(‖Jk|2) and var(|yl|2|) for arbitrarily deep networks. "
SP:4463645f1a9abfbf472935d9eb3342919aa4e0f4,", this paper proposes a method to speed up the execution of neural networks by learning to quickly adapt to a previously unseen design space for code optimization, both accelerating the search and improving the output performance. The proposed method, called CHAMELEON, leverages reinforcement learning whose solution takes fewer steps to converge, and develops an adaptive sampling algorithm that not only focuses on the costly samples (real hardware measurements) on representative points but also uses a domain-knowledge inspired logic to improve the samples itself. Experiments on real hardware demonstrate the effectiveness of the proposed method."
SP:df8483206bb88debeb24b04eb31e016368792a84,"This paper proposes a method to derive certified robustness for top-k predictions. The proposed method is based on randomized smoothing, which turns any classifier to a new classifier via adding noise to an input example. The authors derive a tight robustness in `2 norm for topk predictions when using Gaussian noise. They also empirically evaluate their method on CIFAR10 and ImageNet. "
SP:84a83ee258d5bc613b7d73045477018b8a56c56d,"This paper studies the relationship between the gradient signal to noise ratio (GSNR) of parameters during training process of deep neural networks (DNNs) and the generalization gap. The GSNR of a parameter is defined as the ratio between its gradient’s squared mean and variance, over the data distribution. Based on several approximations, the authors establish a quantitative relationship between model parameters’ GSNRs and the performance of DNNs. This relationship indicates that larger GSNRS of parameters leads to better generalization performance. "
SP:fb726f0fea2ed1a009b3aacf74ac149bcf988cdd,"This paper proposes QUERY2BOX, an embedding-based framework for reasoning over queries with logical disjunctions in massive and incomplete KGs. Queries are represented as boxes, where a set of points inside the box corresponds to the set of answer entities of the query. The authors show that conjunctions can be represented as intersections of boxes and also prove a negative result that handling disjunction would require embedding with dimension proportional to the number of KG entities. The proposed framework is able to handle queries with conjunctions, existential quantifiers, and disjunctive normal forms in a scalable manner. Experiments on three large KGs demonstrate the effectiveness of the proposed method."
SP:c8bbdbf038ddec801c931ae9399b8c16b08428bc,"This paper studies the convergence of SGD with a consistent gradient estimator, which is an unbiased estimator of the gradient of a convex loss function. The paper shows that consistent estimators converge to the same convergence rate as unbiased estimators, and that the convergence rate is the same for strongly convex, convex and non-convex objectives. The authors also provide a theoretical analysis of the convergence behavior of the consistent estimator. The results are verified on synthetic and real-world data."
SP:d53ee573b8083ecf891d4d560eb8a54c30c5cb3a,"This paper proposes to train a once-for-all (OFA) network that supports diverse architectural settings by decoupling training and search, to reduce the cost. It can quickly get a specialized sub-network by selecting from the OFA network without additional training. To efficiently train OFA networks, it also proposes a novel progressive shrinking algorithm, a generalized pruning method that reduces the model size across many more dimensions than pruning (depth, width, kernel size, and resolution). It can obtain a surprisingly large number of subnetworks (> 10) that can fit different hardware platforms and latency constraints while maintaining the same level of accuracy as training independently. On diverse edge devices, OFA consistently outperforms state-of-the-art (SOTA) NAS methods. OFA is the winning solution for the 3rd Low Power Computer Vision Challenge (LPCVC), DSP classification track and the 4th LPCVC."
SP:1be944b5f82d33ab1feb5639792a4c06b8f0c85a,"This paper proposes an extension of the Neural Module Network (NMN) architecture to the open-domain open-text question answering task. The proposed model is based on a combination of two modules that reason over a paragraph of text, performing symbolic reasoning (such as arithmetic, sorting, counting) over numbers and dates in a probabilistic and differentiable manner. The authors also propose an unsupervised auxiliary loss to help extract arguments associated with the events in text. Experiments are conducted on 21,800 questions from the recently proposed DROP dataset (Dua et al., 2019) that are heuristically chosen based on their first n-gram such that they are covered by our designed modules."
SP:319922e4a316a9b9e76504f806d30ea3bffa3f99,"This paper proposes a new method for network pruning based on connection sensitivity. The proposed method is based on the connection sensitivity as a form of gradient, which can be used to characterize initialization conditions to ensure reliable connection sensitivity measurements, which in turn yields effective pruning results. The authors also analyze the signal propagation properties of the resulting pruned networks and introduce a simple, data-free method to improve their trainability. Empirical results show that the proposed method leads to improved performance on several image classification tasks. "
SP:d5899cba36329d863513b91c2db57675086abc49,"This paper studies the choice of intra-layer topology in sparse neural networks. The authors propose a new initialization scheme for sparse networks that allows them to explore the space of very deep sparse networks. They evaluate several topologies and show that seemingly similar topologies can often have a large difference in attainable accuracy. They develop a data-free heuristic that can evaluate a topology independently from the dataset the network will be trained on. They then derive a set of requirements that make a good topology, and arrive at a single topology that satisfies all of them."
SP:b05a6a0f05dcc63a7e17233f20c49c465c46d194,"This paper proposes a novel initialization scheme for training recurrent neural networks (RNNs) on long sequence tasks. The authors derive a mean field theory of signal propagation in LSTMs and GRUs that enables them to calculate the time scales for signal propagation as well as the spectral properties of the state-to-state Jacobians. By optimizing these quantities in terms of the initialization hyperparameters, the authors derive the initialization scheme that eliminates or reduces training instabilities. The experiments demonstrate the efficacy of the proposed initialization scheme on multiple sequence tasks, on which it enables successful training while a standard initialization either fails completely or is orders of magnitude slower."
SP:7b65eb83b0d3149f788ab11b1ab9057b440ddd57,This paper proposes a post-classification post-training method for remote sensing image classification tasks. The proposed method is based on a siamese network to improve the discriminative power of convolutional neural networks on a pair of neighboring scene images. It exploits semantic coherence between this pair to enrich the feature vector of the image for which we want to predict a label. Empirical results show that this approach provides a viable alternative to existing methods.
SP:99c10e038939aa88fc112db10fe801b42360c8dc,"This paper proposes a method for self-supervised monocular depth estimation using semantic segmentation networks. The proposed method is based on pixel-adaptive convolutions and a two-stage training process to overcome a common semantic bias on dynamic objects via resampling. The method improves upon the state-of-the-art for monocular deep depth prediction over all pixels, fine-grained details, and per semantic categories."
SP:e98ec7fd9c27eabd7f5bf3429f984034c2d355a2,"This paper proposes a method to build linear classifiers that are certifiably robust to label-flipping attacks. The proposed method is based on randomized smoothing, a technique that has previously been used to guarantee test-time robustness to adversarial manipulation of the input to a classifier. In this paper, for each test point, the classifier makes a prediction and includes a certification that its prediction would be the same had some number of training labels been changed adversarially. The method is evaluated on several benchmark datasets common to the data poisoning literature."
SP:795cdeb7e4f7285f2c1ac9b9a0fbac3039201ed5,"This paper proposes to use differential privacy to improve outlier detection and novelty detection for anomaly detection and backdoor attack detection. Differential privacy has been proposed to avoid leaking any individual’s information, when aggregated analysis is performed on a given dataset. Theoretical analysis on how differential privacy helps with the detection is provided, and extensive experiments are conducted to validate the effectiveness of differential privacy in improving outliers detection, novelty detection, and backdoor attacks detection. "
SP:a5f0e531afd970144169823971d2d039bff752fb,"This paper studies the calibration of uncertainty prediction for regression tasks. The authors propose a histogram-based evaluation method inspired by reliability diagrams used in classification tasks. They show that the existing definition for calibration of a regression uncertainty (Kuleshov et al., 2018) has severe limitations in distinguishing informative from non-informative uncertainty predictions. They propose a new definition that escapes this caveat and an evaluation method using a simple histograms-based approach. They also propose a simple scaling-based calibration that preforms well in their experimental tests."
SP:c422afd1df1ac98e23235830585dd0d45513064c,"This paper proposes to combine Tensor Product Representations (TPRs) and BERT, a pre-trained bidirectional Transformer language model, for NLP tasks. The authors show that BERT is not able to learn and leverage TPRs, but HUBERT is able to do so. They also show that there is shared structure between different NLP datasets that HUBBER can leverage, but not BERT. "
SP:117b19c4163cb3d08eda6bc7af0d48ed815b519e,"This paper proposes a method for multi-agent reinforcement learning in a humanoid environment. The proposed method combines Hierarchical Reinforcement Learning (HRL) and Multi-Agent Reinforcement learning (MARL) with a goal-conditioned lower-level controller to learn low-level physical controllers for locomotion, navigation, and behaviour. The authors show that the proposed method is able to train heterogeneous heterogeneous policies for goal-directed collision avoidance in the environment."
SP:928640a19b0a0b1e1dc0d1b07cc99e1d51a4d817,"This paper proposes a graph embedding method to improve the performance of graph neural networks (GNNs). In particular, the authors propose to use a spatial representation of the graph to make the GNN aware of the differences between the nodes and also their locations in the graph. The spatial representation is obtained by a point-cloud-based graph embeddings method. The authors show that the proposed method achieves competitive or better results in comparison with the state-of-the-art methods. "
SP:465adf302cd8b7e6b449271a91d1d2fad844aa4d,This paper proposes a new method for frequency pooling in convolutional neural networks. The proposed method is based on discretizing the shift-equivalent prior of an image using the inverse Fourier transform (inverse Fourier Transform). The authors also propose to replace zero padding of convolutions with circular padding. Experiments on CIFAR-100 and a subset of ImageNet show that the proposed method can improve the accuracy and robustness w.r.t shifts of CNNs.
SP:77f0f3779f9bdeb75ea5744ab494942a4943117b,"This paper proposes a method to improve the generalization ability of deep RL agents by introducing a randomized (convolutional) neural network that randomly perturbs input observations. It enables trained agents to adapt to new domains by learning robust features invariant across varied and randomized environments. Furthermore, an inference method based on the Monte Carlo approximation is proposed to reduce the variance induced by this randomization. The experimental results demonstrate the superiority of the proposed method across 2D CoinRun, 3D DeepMind Lab exploration and 3D robotics control tasks."
SP:31772a9122ec998c7c829bc4813f6147cdc30145,"This paper proposes an explanation method for image similarity models, where a model’s output is a score measuring the similarity of two inputs rather than a classification. In this task, an explanation depends on both of the input images, so standard methods do not apply. The authors propose a method that pairs a saliency map identifying important image regions with an attribute that best explains the match. They find that their explanations provide additional information not typically captured by saliency maps alone, and can also improve performance on the classic task of attribute recognition."
SP:50f9dcac485552f2925839151da4dd8d82e35fcc,"This paper presents WaveFlow, a small-footprint generative flow for raw audio, which is trained with maximum likelihood without density distillation and auxiliary losses as used in Parallel WaveNet. WaveFlow can synthesize high-fidelity speech and obtain comparable likelihood as WaveNet, while only requiring a few sequential steps to generate very long waveforms. In particular, WaveFlow has 5.91M parameters and can generate 22.05kHz high-Fidelity speech 42.6x faster than real-time on a GPU without engineered inference kernels."
SP:963e85369978dddcd9e3130bc11453696066bbf3,This paper proposes a graph translation-generation-generative-adversarial-network (GT-GAN) model that transforms the input graphs into their target output graphs. GT-GAN consists of a graph translator equipped with innovative graph convolution and deconvolution layers to learn the translation mapping considering both global and local features. A new conditional graph discriminator is proposed to classify the target graphs by conditioning on input graphs while training. Extensive experiments on multiple synthetic and real-world datasets demonstrate the effectiveness and scalability of the proposed method.
SP:962caffd236630c4079bfc7292403c1cc6861c3b,"This paper proposes METAGROSS (Meta Gated Recursive Controller), a new neural sequence modeling unit. The proposed unit is characterized by recursive parameterization of its gating functions, i.e., gating mechanisms are controlled by instances of itself, which are repeatedly called in a recursive fashion. This can be interpreted as a form of meta-gating and recursively parameterizing a recurrent model. The experiments show that the proposed method achieves state-of-the-art performance (or close) on all tasks."
SP:d03aa0318f0d24a5b7c7817dfc7fba47ebec11cd,"This paper proposes a self-supervised speech recognition method that leverages a strong language model to provide learning signal given unlabeled speech. The proposed method, called Local Prior Matching (LPM), uses a language model for both text and speech to take advantage of the large amount of unpaired text-speech pairs. The paper shows that LPM reduces the word error rate (WER) by 54% and 73% relative to a fully supervised model on the same 360 hours with labels. By augmenting LPM with an additional 500 hours of noisy data, LPM further improves the WER on the noisy test set by 15% relative."
SP:e6af249608633f1776b608852a00946a5c09a357,"This paper studies the problem of fair and robust model training in the presence of data poisoning. The authors propose a generative adversarial network (GAN) framework called FR-GAN, which trains accurate models that are also fair, robust and robust to poisoning. They propose two discriminators: a fairness discriminator that predicts the sensitive attribute from classification results, and a robustness discriminator to distinguish examples and predictions from a clean validation set. They show that the proposed method can be used to maximize any of the prominent fairness measures: disparate impact, equalized odds, and equal opportunity. In addition, the parameters can be adjusted to maintain reasonable accuracy and fairness."
SP:6306417f5a300629ec856495781515c6af05a363,"This paper presents a physics-inspired deep learning approach for point cloud processing motivated by the natural flow phenomena in fluid mechanics. The learning architecture jointly defines data in an Eulerian world space, using a static background grid, and a Lagrangian material space, with moving particles. The proposed method is able to naturally evolve and accumulate particle features using flow velocities generated from a generalized, high-dimensional force field. The experimental results demonstrate the efficacy of this system."
SP:0561a2174d7334e078a49ae8859a36e4d74f9b5b,"This paper proposes a new lens for studying gradient clipping, namely, robustness: informally, one expects clipping to mitigate the effects of noise, since one does not overly trust any single sample. Surprisingly, for the common problem of label noise in classification, standard gradient clipping does not in general provide robustness. On the other hand, the authors show that a simple variant of gradient clipping is robust, and is equivalent to suitably modifying the underlying loss function."
SP:414b06d86e132357a54eb844036b78a232571301, is a state-of-the-art method for imitation learning. This paper proposes a state alignment-based imitation learning method to train the imitator to follow the state sequences in expert demonstrations as much as possible. The state alignment comes from both local and global perspectives and is combined into a reinforcement learning framework by a regularized policy update objective. The results show the superiority of the proposed method on standard imitation learning settings and imitation learning with different dynamics models.
SP:91761d68086330ce378507c152e72218ed7b2196,"This paper proposes an extension of SGD called Deep Gradient Boosting (DGB), which is an extension to SGD that combines backpropagation with gradient boosting. The main idea of DGB is that back-propagated gradients inferred using the chain rule can be viewed as pseudo-residual targets of a gradient boosting problem. The resulting weight update formula can be seen as a normalization procedure of the data that arrives at each layer during the forward pass. The proposed DGB can be implemented as a separate input normalization layer (INN) and shows improved performance on image recognition tasks when compared to the same architecture without normalization layers."
SP:7709a8b907c5642479e7b6fb0b362efc4ead63ce,"This paper proposes PC-DARTS, a variant of DARTS that performs partial connection sampling to reduce the redundancy in exploring the network space, thereby performing a more efficient search without comprising the performance. In particular, it performs operation search in a subset of channels while bypassing the held out part in a shortcut. This strategy may suffer from an undesired inconsistency on selecting the edges of super-net caused by sampling different channels. To alleviate it, the paper proposes edge normalization, which adds a new set of edge-level parameters to reduce uncertainty in search. Experiments on CIFAR-10 and ImageNet demonstrate the effectiveness of the proposed method."
SP:724870046e990376990ba9f73d63d331f61788d7,This paper proposes a hybrid method that combines the best aspects of gradient-based methods and deep reinforcement learning (DRL) for model-based control. The proposed method is based on the DDPG algorithm and proposes a simple modification that uses true gradients from a differentiable physical simulator to increase the convergence rate of both the actor and the critic. Empirical results show that the proposed method can improve the performance of DDPGs without sacrificing its robustness to local minima.
SP:be0202a28bcca68edb0abe4d1c0ba1af265211e3,"This paper proposes a method to learn a task-agnostic world graph that can be used to guide the agent towards task-relevant subspaces of a 2D grid world. The proposed method is based on a binary recurrent variational autoencoder (VAE) and a hierarchical RL framework that leverages structural and connectivity knowledge from the learned world graph to bias exploration towards task relevant waypoints and regions. The method is evaluated on a suite of challenging maze tasks and shows that using world graphs significantly accelerates RL, achieving higher reward and faster learning."
SP:e8a3a0f77dab336ce50c9dc941f7350173916e04,"This paper proposes a new type of a function constructing network, called the white box network, which arranges function blocks to construct a target function to reveal its design. The network uses discretized layers, thus rendering the model interpretable without disordering the function blocks. The authors also introduce an end-to-end PathNet structure through this discretization by considering function blocks as neural networks and connecting them to the appropriate neural networks."
SP:b7f4fda6497a1c20fd57f029be5f1b2e2780e227,"This paper proposes a self-supervised goal-conditioned imitation learning algorithm for learning goal-reaching policies from scratch. The key observation is that in the multi-task setting, trajectories that are generated by a sub-optimal policy can still serve as optimal examples for other tasks. Based on this observation, the authors propose a very simple algorithm to learn behaviors without any demonstrations, user-provided reward functions, or complex reinforcement learning methods. The algorithm simply maximizes the likelihood of actions the agent actually took in its own previous rollouts, conditioned on the goal being the state that it actually reached. Empirical results show that the proposed algorithm is able to learn goal reaching behaviors from scratch without the need for an explicit reward function or expert demonstrations."
SP:1c7cf7417825208feac9fe3b3488a51ad1e72270,"This paper proposes Zeno++, a new asynchronous stochastic gradient descent (SGD) algorithm that is robust to Byzantine failures of the workers. The proposed algorithm is based on the idea of estimating the descent of the loss value after the candidate gradient is applied, where large descent values indicate that the update results in optimization progress. The algorithm is shown to converge to the optimal solution for non-convex problems under Byzantine failures. Experimental results show that the proposed algorithm outperforms existing approaches."
SP:d16ed9bd4193d99774840783347137e938955b87," adversarial examples are usually crafted samples with a small magnitude of the perturbation. In this paper, the authors introduce “unrestricted” perturbations that manipulate semantically meaningful image-based visual descriptors – color and texture – in order to generate effective and photorealistic adversarial example. The proposed methods are effective against JPEG compression, feature squeezing, adversarially trained model, and image classification and image captioning tasks on complex datasets."
SP:f4f7dd96b7865fe2d4c6bddf82875f0c9377c3b4,"This paper proposes Learning to Control (LTC), a method for few-shot learning of entity recognition in NLP tasks. The idea is to train a controller to execute an optimal sequence of read and write operations on an external memory with the goal of leveraging diverse activations from the past and provide accurate predictions. The controller is trained with two degrees of memory plasticity, one for the encoder and the other for the decoder. Experiments on the Stanford Task-Oriented Dialogue dataset show the effectiveness of the proposed method."
SP:2e9235485b79d0b22ec8b565b19bfa26804ccbe1,"This paper proposes a method to learn a set of primitive motor primitives that can be used to perform robotic manipulation tasks. The method is based on learning a sequence of primitive primitives and then recomposing these primitives to form the original demonstration. The proposed method is evaluated on reaching and pushing tasks, where it is shown that the learned primitives capture semantically meaningful aspects of a demonstration. "
SP:c7c37aeebec7f33c1015f1fa3dd2a36d7b437d1c,"This paper proposes a general algorithm for single episode transfer in a family of environments with related dynamics. The main idea is to use a probe and an inference model to rapidly estimate underlying latent variables of test dynamics, which are then immediately used as input to a universal control policy. This modular approach enables integration of state-of-the-art algorithms for variational inference or RL. Moreover, the approach does not require access to rewards at test time, allowing it to perform in settings where existing adaptive approaches cannot. The proposed method significantly outperforms existing adaptive methods and shows favorable performance."
SP:f2f1aff9a5b91d748b24fee0155367f650401aab,"This paper proposes a three-head neural network architecture for AlphaZero, a two-head network architecture that outputs two estimates — policy and value estimates — for one input game state. The proposed architecture can learn a third action-value head on a fixed dataset the same as for two head neural networks. This paper conducts an empirical study on the performance of the proposed architecture in the game of Hex. "
SP:89d6d55107b6180109affe7522265c751640ad96,This paper proposes a method for policy transfer in reinforcement learning that combines adaptation reward with environmental reward to improve the transfer of policies between domains. The proposed method is called Adapt-to-Learn (ATL) and it is based on the idea of adapting the source policy to learn to solve a target task with significant transition differences and uncertainties. The authors show that the proposed method leads to a significantly reduced sample complexity of transferring the policies between the tasks. 
SP:626021101836a635ad2d896bd66951aff31aa846,This paper proposes a method to build scale-equivariant convolutional networks with steerable filters. The proposed method is based on tensor expansion and 2-dimensional convolution. The authors also generalize other common blocks to be scale equivariant. Empirical results on MNIST-scale and STL-10 datasets show that the proposed method outperforms the state-of-the-art methods.
SP:6316f750b8c69e55e61926c34e3ba5acbd7228ad,"This paper proposes a method for the task of 3D scan completion, i.e., plausibly filling in regions that were missed in the raw scans. The proposed method works directly on input point clouds, does not require paired training data, and hence can directly be applied to real scans for scan completion. The authors evaluate the approach qualitatively on several real-world datasets (ScanNet, Matterport3D, KITTI), quantitatively on 3D-EPN shape completion dataset, and demonstrate realistic completions under varying levels of incompleteness."
SP:270c679b322f69a943bf7f6b938dc1bf663d3c6f,"This paper studies the problem of generating fake data in the presence of an authenticator and an attacker. The authors cast the problem as a maximin game, characterize the optimal strategy for both attacker and authenticator in the general case, and provide the optimal strategies in closed form for the case of Gaussian source distributions. The analysis reveals the structure of the optimal attack and the relative importance of data collection for both authenticators and attackers. Based on these insights, the authors design practical learning approaches and show that they result in models that are more robust to various attacks on real data."
SP:a7e7619667892806a6f4038cbe4b1c6cd0eec0ed,"This paper proposes a new adversarial training method for adversarial learning. The proposed method is motivated by the fact that the high dimensional distribution is poorly represented by limited data samples, and the proposed method trains a robust model with sensible adversarial examples, without a significant drop in natural accuracy. The paper theoretically shows that the Bayes rule is the most robust multi-class classifier with the 0-1 loss under the proposed approach. The authors also propose a novel and efficient algorithm to train the robust model. "
SP:9ca0b8d270e3fea3ba8f88c8f1ba50d8a8f7e4b8,"This paper proposes an online knowledge distillation method that transfers not only the knowledge of the class probabilities but also that of the feature map using the adversarial training framework. The proposed method trains multiple networks simultaneously by employing discriminators to distinguish the feature maps distributions of different networks. By training a network to fool the corresponding discriminator, it can learn the other network’s feature map distribution. Discriminators and networks are trained concurrently in a minimax twoplayer game. "
SP:e43fc8747f823be6497224696adb92d45150b02d,This paper proposes a novel sentiment word embedding model for low-frequency words and sentences. The proposed method is based on Bayesian estimation and maximum likelihood estimation. The method is evaluated on both semantic and sentiment analysis tasks. The experimental results show that the proposed method outperforms the baseline methods in sentiment analysis. 
SP:72d32a2ae382f63e055ab3eafcc9276b10fba985,"This paper proposes a two-phase training method, called Prestopping, for noise-free training under any type of label noise. The first phase, called early stopping, trains a deep neural network before the noisy labels are memorized. The second phase, named maximal safe set, trains the network again after the early stopping phase. The proposed method is evaluated on simulated and real-world noisy data sets, and compared with four state-of-the-art methods."
SP:8316872d8b388587bf25f724c80155b25b6cb68e,"This paper proposes a method for action generalization in reinforcement learning. The method is based on unsupervised representation learning over a collection of data samples reflecting the diverse properties of that action. The authors propose a reinforcement learning architecture which works over these action representations, and propose regularization metrics essential for enabling generalization. Experiments demonstrate the generalizability of the representation learning method and policy. "
SP:f534d51192eaacc6cb6bfd365e6d959d9dd498b2,"This paper proposes a method to store word embeddings in word2vec and GloVe embedding matrices for NLP tasks. The proposed method is inspired by quantum computing, where the embedding matrix can be represented by a single two-dimensional complex unit-norm vector. The authors propose two related methods, word2ket and word2kXS, to store the word embedding for training and inference in a highly efficient way. Theoretical results show that the proposed method achieves a 100-fold or more reduction in the space required to store and access the vectors with almost no drop in accuracy in NLP."
SP:3df499068ffe6c995457c2174f987cb0ae3c2551,"This paper proposes a method for imitation learning that learns a repertoire of behaviors from a set of demonstrations by augmenting the state-action pairs with behavioral descriptions. The authors show that the learned policy can be effectively manipulated to express distinct behaviors. The proposed method is tested on the build-order planning problem in StarCraft II, where a high-level policy controls the build order decisions for a bot that has otherwise scripted modules for low-level tasks. "
SP:db15d3cc3e95173ca6d4fd88313d89a739d1c910,"This paper studies the lottery ticket hypothesis, which suggests that small, sparsified neural networks can be trained as long as the network is initialized properly. The authors conduct an in-depth investigation of the structure of winning lottery tickets. They discover that there exist many lottery tickets that can achieve equally good accuracy much before the regular training schedule even finishes. They provide insights into the structure and structure of these early winning tickets with supporting evidence. "
SP:06d2a46282e34302050e81a1be8a2627acb159ee,"This paper proposes an unknown-aware deep neural network (UDN) to tackle the problem of detecting unknowns in image classification. UDN uses a learned ensemble of product operations to balance the contradictory requirements of accurately classifying known objects and correctly rejecting unknowns. To further improve the performance of UDN, the authors propose an information-theoretic regularization strategy that incorporates the objective of rejecting knowns into the learning process. The experimental results show that UDN outperforms the state-of-the-art in the accuracy of unknown rejection."
SP:fa3e729469e74cac44745008fe65c01cc97c9820,This paper proposes a method for variational inference (VI) for approximate Bayesian inference for deep neural networks. The main idea is to train a variational distribution that approximates the posterior over model parameters with a simpler and tractable distribution that is simpler and expressive yet sufficiently expressive. This is achieved by starting with a coarse approximation and iteratively refining it. The method is shown to improve a bound on the approximation (the Evidence Lower BOund) and observe this empirically across a variety of benchmark tasks. 
SP:8e20d28a2a3a6f8f0b6a29a09a10fb8c7a011e86,This paper proposes a method for contextual categorical sequence generation based on policy gradient estimators. The proposed method uses correlated MC rollouts to control the variance of the gradient estimator. The method is tested on two tasks: neural program synthesis and image captioning. 
SP:ab51af66e626b1b03bbf0de7a5237370e941925c,"This paper proposes a stochastic goal recognition control (S-GRC) problem with two main stages: (1) deceptive opponent modeling based on maximum entropy regularized Markov decision processes (MDPs) and (2) goal recognition under proactively static interdiction. The main idea is to use the worst case distinctiveness (wcd) as a measure of the nondistinctive path without revealing the true goals, the task of S-G RC is to interdict a set of actions that improve or reduce the wcd. The proposed method is evaluated on two environments: random generated connected graph and real road network."
SP:e9d173bdf0b650fd093226cfb4607032c905cf61,"This paper proposes a method to generate large mini-batch sizes for GANs. The method is inspired by the use of Coreset-selection in active learning. To create effectively large batches of ‘real’ images, the authors create a cached dataset of Inception activations of each training image, randomly project them down to a smaller dimension, and then use Coreset selection on those projected activations at training time. Experiments show that this method substantially reduces training time and memory usage for modern GAN variants, that it reduces the fraction of dropped modes in a synthetic dataset, and that it allows GAN-based anomaly detection to reach a new state-of-the-art in anomaly detection."
SP:f174ef07670a31a3ce647910c59040a19ea52d7a,"This paper investigates the performance of recurrent neural networks (RNNs) trained with maximum likelihood (MNL) on Brownian motion and sketch datasets. The authors find that RNNs are sub-optimal in the information plane. Instead of optimally compressing past information, they extract additional information that is not relevant for predicting the future. They show how constraining past information by injecting noise into the hidden state can improve the ability of RNN to extract predictive information for both maximum likelihood and contrastive loss training."
SP:f87a75fa12ddeb7538c4522d025e679f2c6dd237,"This paper proposes a method to mitigate delusional bias in approximate Q-learning by training Q-approximators with labels that are “consistent” with the underlying greedy policy class. To this end, the authors introduce a simple penalization scheme that encourages Q-labels used across training batches to remain (jointly) consistent with the expressible policy class, and propose a search framework to be generated and tracked, thus mitigating the effect of premature (implicit) policy commitments. Experimental results demonstrate that these methods can improve the performance of Q-Learning in a variety of Atari games, sometimes dramatically."
SP:827b0d2e2e3cf434c02b7f221bb9b2e0388e48b8,"This paper proposes a generative latent variable model, called SPACE, that combines the best of spatial-attention and scene-mixture approaches. SPACE can explicitly provide factorized object representations for foreground objects while also decomposing background segments of complex morphology. It also resolves the scalability problems of previous methods by incorporating parallel spatial attention and thus is applicable to scenes with a large number of objects without performance degradations. The experiments show that SPACE achieves the above properties consistently in comparison to SPAIR, IODINE, and GENESIS."
SP:73d7d614378cbb6a8d7347dca790675674e0eadb,"This paper proposes FALCON, a method to compress convolutional neural networks (CNNs) based on depthwise separable convolution. The proposed method is based on EHP, which is a mathematical formulation to approximate the standard convolution kernel. The authors also propose a generalized version of the proposed method, which further improves the accuracy while sacrificing a bit of compression and computation reduction rates. The experimental results show that the proposed methods outperform standard CNN models by up to 8x compression and 8x computation reduction while ensuring similar accuracy."
SP:35d45ed014320d8dff22f3531f805d15fa91dafb,"This paper proposes four improvements to the Batch Normalization (BN) algorithm. The main contributions are: 1. A method for reasoning about the current example in inference normalization statistics, fixing a training vs. inference discrepancy, recognizing and validating the powerful regularization effect of Ghost Batch normalization for small and medium batch sizes, examining the effect of weight decay regularization on the scaling and shifting parameters, and identifying a new normalization algorithm for very small batch sizes by combining the strengths of Batch and Group Normalization. Experiments on six datasets validate the effectiveness of the proposed improvements."
SP:39d187474524c6b7de1ce6fd811ec53edae0a8fc,"This paper proposes a method to train generative adversarial networks (GANs) for differentially private federated learning (DP-DP) in the federated setting, where the data is stored at the edge and the modeler may only access aggregated outputs such as metrics or model parameters. The method is based on GANs trained with differential privacy guarantees. The proposed method is applied to both text and image datasets. The results show that the proposed method can identify and fix problems in the data, generate new modeling hypotheses, and assign labels. "
SP:1931ec4c3cd0dbb411cf1bc0f9776b7e26e3ad78,"This paper proposes a method for generating long range diverse and distinctive behaviors to achieve a specific goal location. The proposed method combines the complementary strengths of both non-parametric techniques and parametric ones. Given the starting and ending state, a memory bank is used to retrieve motion references that are provided as source material to a deep network. The synthesis is performed by the deep network that controls the style of the provided motion material and modifies it to become natural. On skeleton datasets with diverse motion, the proposed method outperforms existing parametric and nonparametric baselines. The generated sequences are useful as subgoals for actual physical execution in the animated world."
SP:3a09bdf2e5a17d271f890fd28113202afb9ae761,This paper studies the problem of hierarchical explanation of neural network predictions. The authors identify two desirable properties for hierarchical explanation: non-additivity and context independent importance attributions within hierarchies. They propose Sampling and Contextual Decomposition (SCD) algorithm and SOC algorithm and extend previous post-hoc explanation algorithm based on the new formulation of N-context independent importance and develop two effective hierarchical explanation algorithms. The experimental results show that the proposed explanation algorithms consistently outperform the compared methods over several datasets and models. 
SP:9ec1740e58d1b07a6b1c6130ec7e23c370efb701,This paper proposes a new method for learning saliency maps for deep convolutional neural networks (CNNs) that is much more efficient than popular gradient methods. The method works by measuring information at the end of each network scale which is then combined into a single saliency map. The proposed method is at least 97x faster than Guided Backprop and much more accurate. 
SP:7f11fa931f4085f7227cc870eba4a3aac4b1bf42,This paper proposes a method for non-autoregressive text generation based on position modeling. The proposed method is based on a latent variable that is used to model the position of the generated words. The method is evaluated on machine translation and paraphrase generation tasks. The experimental results show that the proposed method outperforms several strong baselines. 
SP:e1c40112901b6ff905ae0e221fd3df4f545acd08,"This paper proposes a Random Path GAN (RPGAN) that uses random paths in the generator network to capture the factors of variation in the image generation process. The authors show that the latent space of the RPGAN consists of random paths, which are sampled randomly from the standard Gaussian distribution of the input vectors. This allows to understand the role of different generator layers in the process of image generation. The experimental results demonstrate that the proposed method outperforms the state-of-the-art in terms of generation quality and incremental learning."
SP:1fec5468baaccb4a956399a829b62ac47494a6ac,"This paper proposes DeepSphere, a graph-based spherical convolution method for spherical convolutions. The proposed method is based on a graph representation of the sampled sphere, where the vertices and neighbors are represented by a Laplacian-based graph. The authors provide theoretical analysis of the effect of the number of vertices on the equivariance of the convolution. They also provide empirical results on a variety of spherical image classification tasks."
SP:ae544fa9abd539e0c2e77fdb5541f5c5194feb9f,"This paper studies the problem of learning representation invariant representations for domain adaptation. The authors point out that the search for invariance favors the compression of representations, which may have a bad impact on adaptability of representations expressed as a minimal combined domain error. By considering the risk of compression, the authors show that weighting representations can align representation distributions without impacting their adaptability. This supports the claim that representation invariance is too strict a constraint. "
SP:39126802d517f93bdcbc47708a6aa1ed13bf2800,"This paper proposes a method for inferring user interface attributes from an input image. The method is based on a black box rendering engine and a set of attributes (e.g., colors, border radius, shadow or text properties) that can be used to generate a suitable synthetic training dataset, and then train specialized neural models to predict each of the attribute values. To improve pixel-level accuracy, the authors also use imitation learning to train a neural policy that refines the predicted attribute values by learning to compute the similarity of the original and rendered images in their attribute space, rather than based on the difference of pixel values. The proposed method is applied to the task of inferring Android Button attribute values and achieve 92.5% accuracy."
SP:1c5d31363faf2b8c43f2698ad426bfffcc02ad03,"This paper studies the problem of robust transfer learning, in which a model is trained on one task and re-purposed on another. The authors show that robust networks contain robust feature extractors, and train classifiers on top of these extractors to produce new models that inherit the robustness of their parent networks. They then consider the case of “fine-tuning” a network by re-training end-to-end in the target domain. They show that by using lifelong learning strategies, it is possible to produce accurate and robust models with little data, and without the cost of adversarial training. "
SP:06a047ae70a1a25dc6e8f317d6e492e211ad17ce,This paper proposes a neural iterated learning (NIL) algorithm that allows for the emergence of a more structured type of language. The authors propose a probabilistic model of NIL and provide an explanation of why the advantage of compositional language exist. The experiments confirm that the emerged languages largely improve the generalizing power of the neural agent communication.
SP:add48154b31c13f48aef740e665f23694fa83681,"This paper proposes Adversarial Variational Inference and Learning (AdVIL) to perform inference and learning in a general Markov random field (MRF). AdVIL employs two variational distributions to approximately infer the latent variables and estimate the partition function of an MRF, respectively. The two distributions provide an estimate of the negative log-likelihood of the MRF as a minimax optimization problem, which is solved by stochastic gradient descent. The proposed method is proven convergent under certain conditions. Empirical results on various undirected generative models, including restricted Boltzmann machines (Ackley et al., 1985), deep Boltzmanis machines (Salakhutdinov & Hinton, 2009), and Gaussian restricted Boltzman machines (Hinton & SalakhUTdinov, 2006), on several real datasets."
SP:b875f6417663e43dded41b6a6f1b9ab49ad954a2,"This paper proposes a reward function for goal-conditioned reinforcement learning. The reward function is based on a simple indicator reward function, where the reward is given when the robot's observation exactly matches a target goal observation. The paper also proposes two methods to further speed up convergence with indicator rewards: reward balancing and reward filtering. The experiments show that the proposed method can learn in continuous state spaces without knowledge of the ground-truth state."
SP:8ae78a6640be13e511242eab64101f74ebc4b30a,"This paper studies the problem of certified robustness verification for neural networks with complex self-attention layers. In particular, the authors propose a method to certify the robustness of a Transformer model to cross-position dependency and cross-nonlinearity. The proposed method is based on the Interval Bound Propagation (IBP) algorithm. The authors show quantitatively and qualitatively that the certified bounds computed by their algorithm consistently reflect the importance of input words in sentiment analysis, which justifies that these bounds are meaningful in practice. "
SP:92cb7b1e88f3c8883ae6123c19e1ba24622464e6,"This paper proposes a weakly supervised pretraining method for pretrained language models for entity-related question answering tasks. The proposed method is based on a zero-shot fact-completion task, where the goal is to train the model to capture knowledge about real-world entities. The paper shows that the proposed method outperforms BERT on a number of question answering and entity typing tasks. "
SP:4395d6f3e197df478eee84e092539dc370babd97,"This paper tackles the problem of discovering novel classes in an image collection given labelled examples of other classes. The authors propose to leverage the information contained in the labelled images in order to learn a general-purpose clustering model and use the latter to identify the new classes in the unlabelled data. The proposed method combines three ideas: (1) the common approach of bootstrapping an image representation using the labeled data only introduces an unwanted bias, and that this can be avoided by using self-supervised learning to train the representation from scratch on the union of labelled and unlabeled data; (2) the use rank statistics to transfer the model’s knowledge of the labelled classes to the task of clustering the unlabeling images; and, (3) the training the data representation by optimizing a joint objective function on the labelled-and-unlabeled subsets of the data."
SP:068c4e93c135968aef2637d2bfcba727a3c0f001,"This paper proposes a new method for visual planning that combines data-driven perception and planning. The proposed method builds on top of topological memory (SPTM) which is a recent and promising method for learning to plan goal-directed behavior from observations of a dynamical system obtained offline, e.g., images obtained from self-supervised robot interaction. However, SPTM is constricted in its ability to generalize to changes in the domain, as its graph is constructed from direct observations and thus requires collecting new samples for planning. In this paper, the authors propose Hallucinative Topological Memory (HTM), which overcomes these shortcomings by training an energy function using contrastive predictive coding and a conditional VAE model that generates samples given a context image of the domain and use these hallucinated samples for building the connectivity graph, allowing for zero-shot generalization to domain changes. In simulated domains, the proposed method outperforms conventional SPTM and visual foresight methods in terms of both plan quality and success in long-horizon planning."
SP:907d92896eda706e1526debb5a87b41bb1e978e0,"This paper proposes a method to reduce spurious biases in large-scale benchmark datasets. The authors argue that existing benchmarks are overly populated with a great deal of similar (thus non-tail) problems, which in turn, leads to a major overestimation of true AI performance. To address this challenge, the authors propose AFLITE, an iterative greedy algorithm that adversarially filters out data points to identify a reduced dataset with more realistic problem distributions and considerably less spurious biases. They apply AFLITE to popular benchmarks that are practically solved and present filtered counterparts as new challenge datasets where the model performance drops considerably."
SP:82777947d2377efa897c6905261f5375b29a4c19,"This paper proposes a method to train a prototypical few-shot model for a single class, where the goal is to predict the likelihood of an unseen query belonging to a group of examples without any given counterexamples. The authors propose to use a null class centered around zero, and enforce centering with batch normalization. The proposed method is tested on Omniglot, MiniImageNet, and MNIST datasets, and achieves.98 classification accuracy on the matched test set and.8 on the unmatched test set."
SP:4a6df2b39643f548dab806a0b128fe5a3ce4dadc,"This paper proposes GraphZoom, a multi-level framework for improving both accuracy and scalability of unsupervised graph embedding algorithms. The proposed method first performs graph fusion to generate a new graph that effectively encodes the topology of the original graph and the node attribute information. This fused graph is then repeatedly coarsened into much smaller graphs by merging nodes with high spectral similarities. Then, the proposed method progressively refine the embeddings obtained at the coarsest level to increasingly finer graphs. Experimental results show that the proposed approach can substantially increase the classification accuracy and significantly accelerate the entire graph-embedding process by up to 40.8x."
SP:e33a92e3a6acc668fa2022237e6d947b2eb8bd76,"This paper proposes a method to predict pixels relatively, by predicting new pixels relative to previously generated pixels (or pixels from the conditioning context, when available). The authors show that this form of prediction fare favorably to its absolute counterpart when used independently, but their coordination under an unified probabilistic model yields optimal performance. Experiments on multiple benchmarks for unconditional image generation, image colorization, and super-resolution indicate that their presented mechanism leads to improvements in terms of likelihood compared to the absolute prediction counterparts."
SP:4224604c2650710cdf5be3ab8acc67c891944bed,"This paper proposes a method for estimating quantities defined by the stationary distribution of a Markov chain. The method is based on estimating a ratio that corrects for the discrepancy between the stationary and empirical distributions, derived from fundamental properties of the empirical distribution, and exploiting constraint reformulations based on variational divergence minimization. The authors prove its consistency under general conditions, provide an error analysis, and demonstrate strong empirical performance on benchmark problems such as PageRank and off-policy policy evaluation."
SP:235998cafe7b558b6f6cf6c49b689ce84004af5d,"This paper proposes a method to train models that are less sensitive to spurious patterns in natural language processing. The method is based on the idea of counterfactual revising, where a human is given a set of documents and their initial labels, and is tasked with revising each document so that it accords with a target target label, retains internal coherence, and avoids unnecessary changes. The authors show that models trained on original data fail on their counterfactually-revised counterparts and vice versa. They also show that classifiers trained on combined datasets perform remarkably well, just shy of those specialized to either domain."
SP:b720eb5b6e44473a9392cc572af89270019d4c42,"This paper presents a theoretical analysis of CNN channels as spatial frequency and orientation selective filters that can be used to link basic human visual perception models to their characteristics. The authors characterize the frequency tuning of channels in trained image classification deep CNNs (e.g., VGG-16) by applying grating stimuli of different spatial frequencies and orientations as input. They conclude that sensitivity to spatial frequencies that have lower contrast masking thresholds and a definite and strong orientation selectivity are important attributes of deep CNN channels that deliver better perceptual quality features."
SP:e2c726a1c3e3ecbec198c4dd804a4298aacec3ad," DDI prediction task is formulated as a structure prediction problem, and a graph energy neural network (GENN) is proposed to explicitly model link type correlations. Experiments on two real world DDI datasets demonstrated that GENN is superior to many baselines without consideration of link type correlation and achieved 13.77% and 5.01% PR-AUC improvement."
SP:1f2a27579404aa165303789fdce9b3ed54f7b0c6, to learn discrete representations of audio segments through a wav2vec-style self-supervised context prediction task. The algorithm uses either a Gumbel-Softmax or online k-means clustering to quantize the dense representations. Experiments show that BERT pre-training achieves a new state of the art on TIMIT phoneme classification and WSJ speech recognition tasks.
SP:f9c5b74b8bea5161d33676d9290d7b9d7e81d7b6,"This paper proposes an actor-critic reinforcement learning method for collaborative filtering. The proposed method trains a critic network to approximate ranking-based metrics, and then updates the actor network to directly optimize against the learned metrics. In contrast to traditional learning-to-rank methods that require re-running the optimization procedure for new lists, the critic-based method amortizes the scoring process with a neural network and can directly provide the (approximate) ranking scores for new list. The experimental results on three large-scale datasets demonstrate the effectiveness of the proposed method."
SP:2444a83ae08181b125a325d893789f074d6db8ee,"This paper proposes a multi-step TD-learning method for off-policy reinforcement learning. The main idea is to use truncated Q-functions to represent the return for the first n steps of a target-policy rollout w.r.t. the full action-value and shifted Q-function to represent farsighted return after this truncated rollout. The authors prove that the combination of these short and long-term predictions is a representation of the full return, leading to the Composite Q-learning algorithm. The results show that the proposed method outperforms TD3 and TD3(∆) in terms of data-efficiency."
SP:64564b09bd68e7af17845019193825794f08e99b,"This paper proposes a method for learning a robotic system that can be used to perform dexterous manipulation tasks in a real-world setting. The proposed method is based on a combination of three components: (1) an on-board perception module, (2) an off-board reward function, and (3) a reset mechanism that allows the system to learn without manual resets. The system is evaluated on a set of dexterous robotic manipulation tasks, where it is shown to perform better than baselines. "
SP:ee4d59fa9487ecdcd663a4a7833689d1754aac7c,"This paper studies the problem of adversarial robust generalization in deep neural networks. The authors show that with more unlabeled data, we can learn a model with better adversarial generalization. The key insight of their results is based on the risk decomposition theorem, in which the expected robust risk is separated into two parts: the stability part which measures the prediction stability in the presence of perturbations, and the accuracy part which evaluates the standard classification accuracy. They further prove that for a specific Gaussian mixture problem illustrated by Schmidt et al. (2018), adversarially robust generalisation can be almost as easy as the standard generalisation in supervised learning if a sufficiently large amount of unlabelled data is provided."
SP:8d92aa968c590a352cb34c9fa1dbe77dff19519f,", this paper proposes a method to estimate the advantage of a policy in a MDP using the order statistics of the path ensemble. This allows the policy gradient to be controlled by policies with promotion or prevention inclinations. The proposed method is evaluated on MuJoCo continuous control, Terrain locomotion, Atari games, and sparse-reward environments. The results show that the proposed method outperforms the baselines."
SP:2162408ce2a3267724b5f8f0abec41d4dc714220,"This paper proposes precision gating (PG), an end-to-end trainable dynamic dual-precision quantization technique for deep neural networks. PG computes most features in a low precision and only a small proportion of important features in higher precision to preserve accuracy. The proposed method is applicable to a wide variety of DNN architectures and significantly reduces the computational cost of execution with almost no accuracy loss. The experiments indicate that PG achieves excellent results on CNNs, including static compressed mobile-friendly networks such as ShuffleNet. Compared to the state-of-the-art prediction-based quantization schemes, PG achieves the same or higher accuracy with 2.4x less compute on ImageNet. PG obtains a 1.2% improvement in perplexity per word on LSTM on Penn Tree Bank dataset."
SP:0c2c9b80c087389168acdd42af15877fb499449b,"This paper studies the problem of unsupervised domain adaptation (UDA) in the setting where the source domain is noisy and the target domain is unlabeled. The authors propose a new problem setting called wildly UDA (WUDA). They show that WUDA ruins all UDA methods if taking no care of label noise in SD, and to this end, they propose a Butterfly framework, which maintains four models (e.g., deep networks) simultaneously, where two take care of all adaptations (i.e., noisy-to clean, labeled-to-unlabeled, and SD to TD-distributional) and the other two can focus on classification in TD. They conduct experiments on simulated and real-world datasets to show the effectiveness of the proposed method."
SP:f3cc10ce2f77aeb2a6a3bae5631602452c14d403,This paper proposes an off-policy actor-critic algorithm with an auxiliary decoder that trains end-to-end and matches state-of-the-art performance across both model-free and model-based algorithms on many challenging control tasks. The proposed method is based on the idea that the image reconstruction loss is the essential ingredient that enables efficient and stable representation learning in image-based RL. The experimental results show that adding a simple auxiliary reconstruction loss to a model free RL algorithm achieves comparable results to the state of the art on the suite of continuous control tasks from Tassa et al. (2018). 
SP:917bc9151a5829e97efd9bd0d0b2a3d1771b3265,"This paper proposes a new dropout technique called multi-sample dropout to accelerate training and improve the generalization of deep neural networks. The dropout is a simple but efficient regularization technique that randomly selects a subset of neurons from the input in each training iteration. The proposed dropout creates multiple dropout samples. The loss is calculated for each sample, and then the sample losses are averaged to obtain the final loss. This technique can be easily implemented without implementing a new operator by duplicating a part of the network after the dropout layer while sharing the weights among the duplicated fully connected layers."
SP:5ad4b9e837e08d995b545b0b2734bc8fa4fafc43,"This paper proposes a method to learn disentangled filters in convolutional neural networks (CNNs). The proposed method is based on a Label Sensitive Gate (LSG) structure, where redundant channels experience a periodical shutdown as flowing through a learnable gate varying with input labels. To reduce redundant filters during training, LSG is constrained with a sparsity regularization, which imposes each filter’s attention to just one or few classes, namely class-specific. Extensive experiments demonstrate the effectiveness of the proposed method in generating sparse and highly class-related representation of the input."
SP:c9a512b6bc59aacbec2d5608284e29a7746172cf,"This paper proposes a communication minimization-based method for learning decentralized Q-functions in multi-agent reinforcement learning. The proposed method is based on two information-theoretic regularizers, which maximize mutual information between agents’ action selection and communication messages while minimizing the entropy of messages between agents. The authors show how to optimize these regularizers in a way that is easily integrated with existing value function factorization methods such as QMIX. Empirical results show that the proposed method significantly outperforms baseline methods and allows to cut off more than 80% communication."
SP:562f1a50f80d760a4be35095cd795cdb0f69a890,"This paper proposes a GAN-based algorithm for solving programming puzzles. The proposed algorithm, named Troublemaker, generates a diverse set of puzzles that are difficult for the solver to solve. The algorithm is trained to generate challenging problems for a variety of state-of-the-art puzzle-solving techniques. The authors evaluate the proposed algorithm on a number of tasks and show that it is able to solve challenging problems."
SP:627b515cc893ff33914dff255f5d6e136441d2e2,"This paper proposes a method to decompose a policy into a set of primitives and a meta-policy, where each primitive can decide for themselves whether they wish to act in the current state. Each primitive chooses how much information it needs about the state to make a decision, and the primitive that requests the most information is the one that acts in the environment. The paper shows that the proposed method outperforms both flat and hierarchical policies in terms of generalization. "
SP:4d135a76ab151dd0adcf92c5ed8d3c717d256520,This paper proposes a model-based planning framework that learns a latent reward prediction model and then plans in the latent state-space. The latent representation is learned exclusively from multi-step reward prediction which is shown to be the only necessary information for successful planning. The proposed method is tested in multi-pendulum and multi-cheetah environments where several pendulums or cheetahs are shown to the agent but only one of them produces rewards. The experimental results show that the proposed method can successfully learn an accurate latent reward model in the presence of the irrelevant information while existing model based methods fail. 
SP:03c61ba3d6fe01bd0bc3469cd408c370527d9d69,"This paper proposes two methods to reduce the number of parameters in BERT-large. First, the authors propose to use a self-supervised loss that focuses on modeling inter-sentence coherence, and show it consistently helps downstream tasks with multi-sentences inputs. Second, they propose to scale up to much larger ALBERT configurations that still have fewer parameters but achieve significantly better performance. They establish new state-of-the-art results on the GLUE, RACE, and SQuAD benchmarks."
SP:5dd50f3e6cef6b82192a1d37b35469dc7fb443ce,"This paper proposes a Transformer-based architecture for multi-modal multi-task learning. The main idea is to use a spatio-temporal cache mechanism to store the spatial dimension of the input in addition to the hidden states corresponding to the temporal input sequence. The proposed architecture enables a single model to support tasks with multiple input modalities as well as asynchronous multi- task learning, thus the proposed architecture is referred to as OmniNet. Experiments show that OmniNet can learn to perform tasks of part-of-speech tagging, image captioning, visual question answering, and video activity recognition."
SP:6c8e2dd1d6224dffb95dbf729b159f00bfb05721,"This paper proposes a new method for quantifying the predictive uncertainty of deep learning models. The proposed method, called discriminative jackknife (DJ), is a formal inference procedure that constructs predictive confidence intervals for a wide range of regression models, is easy to implement, and provides rigorous theoretical guarantees on (1) and (2). The DJ procedure uses higher-order influence functions (HOIFs) of the trained model parameters to construct a leave-one-out estimator of predictive confidence interval. DJ computes HOIFs using a recursive formula that requires only oracle access to loss gradients and Hessian-vector products, hence it can be applied in a post-hoc fashion without compromising model accuracy or interfering with model training."
SP:057a035c4eeeb5fe985b20d0266126d66d9d243f,"This paper proposes a new GAN model for video generation. The proposed model is based on GANs trained on Kinetics-600 and UCF-101 datasets. The main idea is to decompose the discriminator of the GAN into a discriminator and a video discriminator. The discriminator is trained on the Kinetics dataset, and the video discriminators are trained on UCF101 and Kinetics600. The video decoder is trained to produce high-quality video samples. "
SP:a89ee8eb2f60d9d522993a57d656f0ef726d86d6,"This paper studies the problem of few-shot learning, where the representation is obtained from a classifier pre-trained on a large-scale dataset of a different domain, assuming no access to its training process, while the base class data are limited to few examples per class and their role is to adapt the representation to the domain at hand rather than learn from scratch. The authors propose a spatial attention mechanism that allows focusing on objects and suppressing background clutter. They also show that the proposed method can be easily adapted to novel classes, without meta-learning."
SP:d236f0b38414442af00b9be5e5d39e138f0069a2,"This paper proposes a method for generating structured objects that satisfy structural constraints that are difficult to capture with examples alone. The proposed method, called constrained adversarial networks (CANs), embed the constraints into the model during training by penalizing the generator whenever it outputs invalid structures with high probability. The method is applied to constrained images, molecules, and video game levels, and shows that it can generate valid structures that are both high-quality and novel."
SP:110f0b86431f0a93cf48e08fe445e32172a37eae,"This paper proposes a new learnable activation function based on Adaptive Piecewise Linear units (APL) that is able to approximate any continuous non-linearity in a closed interval. The proposed activation function is based on Symmetric-APL activation function, which is a symmetric combination of ReLU and APL activation functions. The authors show that the proposed activation functions can be used to improve the robustness of deep neural networks to adversarial attacks."
SP:4787aff0fb84beb13cde0d40c32d3a743d8e4082,"This paper proposes to use a Dirichlet layer to enrich the output of a classification black-box with a measure of uncertainty to improve the trustability of the system. The proposed method is based on the Dirichlett layer, which is a probabilistic neural network that works in parallel to the black box classifier and uses Dirichlets as the fusion layer with the classifier. The authors propose a rejection system that selects the more confident predictions, discarding those more uncertain, leading to an improvement in trustability."
SP:1207bf6cf93737d63e1a7cc1ff3a99bf9d6098f9,"This paper proposes to use blockwise adaptive stepsize in Adagrad to improve the generalization performance of Adam and RMSprop. The proposed method is based on the idea that blockwise adaptivity is less aggressive than adaptivity to individual coordinates, and can have a better balance between adaptivity and generalization. Theoretical analysis shows that the proposed method has comparable regret in online convex learning and convergence rate for optimizing nonconvex objective as its counterpart with coordinate-wise adaptive step-size, but is better up to some constant. Experimental results show that it converges faster and improves the performance over Nesterov’s accelerated gradient and Adam."
SP:0334d79349e9fb8ca32751b7ad29f82e00a5381c,"This paper proposes a video dataset called CATER, which is a synthetic video dataset with controllable object and scene bias. The dataset is generated synthetically using a library of standard 3D objects, and tests the ability to recognize compositions of object movements that require long-term reasoning. It also provides a plethora of diagnostic tools to analyze modern spatiotemporal video architectures by being completely observable and controLLable. The authors also provide insights into some of the most recent state-of-the-art deep video architectures."
SP:b637c75acbe9d0152384b632f2e92a0d248cb720,"This paper proposes Boundary-Calibration GANs (BCGANs), which leverage the boundary information from a set of pre-trained classifiers using the original data. In particular, the authors introduce an auxiliary boundary-calibration loss (BC-loss) into the generator of GAN to match the statistics between the posterior distributions of original data and generated data with respect to the boundaries of the classifiers. The BC-loss is provably unbiased and can be easily coupled with different GAN variants to improve model compatibility. Experimental results demonstrate that BCGANs not only generate realistic images like original GAN, but also achieves superior model compatibility than the original GGANs."
SP:93616e31fa1dc64d130c0c44cbb73c0412b24a97,"This paper proposes a new adversarial training method based on a generic learning-to-learn (L2L) framework. Specifically, instead of applying the existing hand-designed algorithms for the inner problem, the proposed method learns an optimizer, which is parametrized as a convolutional neural network. At the same time, a robust classifier is learned to defense the adversarial attack generated by the learned optimizer. The proposed method is evaluated on CIFAR-10/100 datasets."
SP:0a66c3540383c76689258d2fffe0571ed944c1e7,"This paper studies the problem of Inverse Reinforcement Learning (IRL) on Markov Decision Processes (MDPs), where the goal is to estimate state, action, and feature constraints in the environment that motivate an agent to maximize cumulative rewards subject to these constraints on their behavior. The proposed method is based on the Maximum Entropy IRL framework, which allows us to reason about the likelihood of an expert agent’s demonstrations given our knowledge of an MDP. The algorithm iteratively infers the Maximum Likelihood Constraint to best explain observed behavior, and is evaluated on both simulated behavior and recorded data."
SP:2a5fba69a6287b87a19bcd745d2e4326bbb723de,"This paper proposes a deep recurrent neural network architecture that approximates known visual cortical circuits (Mély et al., 2018). This architecture, which the authors refer to as the γ-Net, learns to solve contour detection tasks with better sample efficiency than state-of-the-art feedforward networks, while also exhibiting a classic perceptual illusion, known as the orientation-tilt illusion. Correcting this illusion significantly reduces the accuracy by driving the network to prefer low-level edges over high-level object boundary contours."
SP:4f094a3f7eeb302738c2b482fbaca56e34ac6a99,"This paper proposes a context-aware object detection method that leverages the conditional random field (CRF) model to enforce the semantics context constraints in the CNN-based object detector. The proposed method, called conCNN, uses a stack of common CNN operations to model the mean-field inference method for CRF. ConCNN can be seamlessly plugged into any existing region based object detection paradigm. The experimental evaluation on the COCO datasets confirms that conCNN improves the AP of object detection by 2 percentage points."
SP:74d63293d2f8a41a14743bfcd8939fca5e804fdb," the BatchNorm layer is vulnerable to adversarial perturbations. The authors hypothesize that the use of different normalization statistics during training and inference (mini-batch statistics for training and moving average of these values at inference) is the main cause of this adversarial vulnerability in the B batchNorm layer. They empirically proved this by experiments on various neural network architectures and datasets. To circumvent this issue, the authors propose RobustNorm (RobustNorm or RN) and experimentally show that it is not only resilient to adversarially perturbation but also inherits the benefits of Batchnorm layer."
SP:f16d3e61eda162dfee39396abbd594425f47f625,"This paper studies the problem of over-fitting in deep neural networks trained by simple first-order methods. The authors propose two regularization methods: (i) regularization by the distance between the network parameters to initialization, and (ii) adding a trainable auxiliary variable to the network output for each training example. Theoretically, the authors prove that gradient descent training with either of these two methods leads to a generalization guarantee on the clean data distribution despite being trained using noisy labels. The generalization bound is independent of the network size, and is comparable to the bound one can get when there is no label noise."
SP:67335658ec9de6ba3fa352ca4de073ac51f2f703,"This paper proposes a method to improve the performance of convolutional neural networks (CNNs) for regression with respect to the CNN Gaussian Process kernel (CNN-GP) and the Convolutional Neural Tangent Kernel (CNTK). The proposed method is based on a new operation called Local Average Pooling (LAP), which preserves efficient computability of the kernel and inherits the spirit of standard data augmentation using pixel shifts. Extensive experiments on CIFAR-10 and Fashion-MNIST show that LAP consistently improves performance of CNN-GP and CNTK."
SP:4ffab7f7f9fc09fdf59602228d231c6f6330fb98,"This paper proposes a method for combining model-free Q-learning with model-based Monte-Carlo Tree Search (MCTS) to improve the performance of MCTS. In particular, the proposed method uses a learned prior over state-action values is used to guide the model to estimate an improved set of state-actions values, which are then used in combination with real experience to update the prior. The proposed method can be implemented on top of any Q-Learning agent with access to a model. Experiments on Atari and physical reasoning tasks demonstrate the effectiveness of the method. "
SP:ab451cc0ec221864a5da532eceba0f021f30def4,"This paper proposes a method for single-image-based 3D view synthesis at arbitrary camera positions along the X-axis, or ""Deep 3D Pan"" with “t-shaped” adaptive kernels equipped with globally and locally adaptive dilations. The proposed network architecture, the monster-net, is devised with a novel t-shaped adaptive kernel with locally and globally adaptive dilation, which can efficiently incorporate global camera shift into and handle local 3D geometries of the target image’s pixels for the synthesis of naturally looking 3D panned views when a 2-D input image is given. Extensive experiments were performed on the KITTI, CityScapes, and VICLAB STEREO indoors dataset to prove the efficacy of the proposed method."
SP:e308cf28f7bd5d8e6c36517e2845298ccd401f5d,"This paper studies the variational auto-encoders (VAEs) from an information theoretic perspective. The authors define the concept of capacity for VAEs and propose a variational lower bound for the capacity of a VAE. They show that the optimal generative model is the one optimising the capacity-constrained InfoMax (CCIM), a theoretical objective learning the maximal informative model while maintaining bounded the network capacity. The theoretical results are confirmed by the experimental results on MNIST and CIFAR-10."
SP:ef4a0c82cc364b797fba0ba86a91d9945b66a193,"This paper proposes a method for embedding node attributes in a network using a Skip-gram-based approach. The proposed method is based on the idea of pooling observations from different neighborhoods of different sizes. The paper also proposes a multiscale approach to embeddings that can capture attribute-neighborhood relationships over multiple scales. Experiments on social, web and citation network datasets show the effectiveness of the proposed method. "
SP:70d92189aedeb4148b61b987d97a3c15898dd834,"This paper studies the phase transitions in the Information Bottleneck (IB) objective, which is defined on the encoding distribution p(z|x) for input X, target Y and representation Z, where sudden jumps of dI(Y;Z) dβ and prediction accuracy are observed with increasing beta. The authors define IB phase transitions as a qualitative change of the IB loss landscape, and show that the transitions correspond to the onset of learning new classes. They derive a formula that provides a practical condition for IB phase transition, and draw its connection with the Fisher information matrix for parameterized models. Based on the theory, they present an algorithm for discovering phase transition points."
SP:fecfd5e98540e2d146a726f94802d96472455111,"This paper proposes a new advantage function estimation method for reinforcement learning. The main idea is to identify the independence property between current action and future states in environments, which can be further leveraged to effectively reduce the variance of the advantage estimation. The independence property can be naturally utilized to construct a novel importance sampling advantage estimator with close-to-zero variance even when the Monte-Carlo return signal yields a large variance. To further remove the risk of the high variance introduced by the new estimator, the authors propose to combine it with existing Monte-carlo estimator via a reward decomposition model learned by minimizing the estimation variance. Experiments demonstrate that the proposed method achieves higher sample efficiency compared with existing advantage estimation methods in complex environments in tabular and function approximation settings."
SP:f0d84396e0ede7969d3f3f55549d214f20daf1b0,"This paper proposes a bias reduction method for infinite horizon off-policy policy evaluation. The proposed method is doubly robust in that the bias vanishes when either the density ratio or value function estimation is perfect, and the bias can also be reduced when either of them is accurate. Both theoretical and empirical results show that the proposed method yields significant advantages over previous methods. "
SP:73f8dddb09333a739c609cc324a1e813d29f8874,"This paper proposes a novel Metric-Softmax loss for few-shot learning. The Metric Softmax loss is trained on the whole label set and learns more discriminative feature than episodic training. In the second stage, a task-adaptive transformation is proposed to adapt the classifier to novel classes. The proposed method achieves state-of-the-art performance on mini-ImageNet and CUB-200-2011 benchmarks."
SP:cde2a84c463cdab9b19fcbdaf1cfe20d0187dcfa,"This paper proposes a data-driven approach to improve the accuracy of numerical solvers. The proposed method utilizes an advanced numerical scheme with a fine simulation resolution to acquire reference data, then, employ a neural network that infers a correction to move a coarse thus quickly obtainable result closer to the reference data. The experiments show that the proposed method can improve the simulation accuracy of the given numerical method."
SP:e6534cd49bdc266dbeb111682ad37ef9d666e31e,"This paper proposes a method to learn to compress and store a representative dataset from a non-i.i.d data stream while only observing each sample once. The proposed method consists of a series of discrete autoencoders, each equipped with their own memory. Each added module is trained to reconstruct the latent space of the previous module using fewer bits, allowing the learned representation to become more compact as training progresses. This modularity has several advantages: 1) moderate compressions are quickly available early in training, which is crucial for remembering the early tasks, 2) as more data needs to be stored, earlier data becomes more compressed, freeing memory, and 3) unlike previous methods, the approach does not require pretraining, even on challenging datasets."
SP:4ada8234990b4dbcdecb6bafeb6f509263661ae8,"This paper proposes a method for multi-label learning based on deep neural networks. The proposed method is based on a Bidirectional Representation learning where the label dependency is also integrated and deep convolutional networks that handle image data. The model scales linearly in the number of instances and trains deep neural network that encode both input data and output labels, then, obtains a metric space for testing data. Experiments on a number of tasks on multi-labels tasks demonstrate that the proposed model is better than related methods based on systematic metric and its extendability."
SP:d81a0edd94cc0b32734c42f1fb65d7070f963f86,"This paper studies the effect of delay on the learning rate in asynchronous training. The authors show that the degree of delay interacts with the learning rates, to change the set of minima accessible by an asynchronous stochastic gradient descent algorithm. They derive closed-form rules on how learning rate can be changed, while keeping the accessible set the same. Specifically, for high delay values, they find that learning rate should be kept inversely proportional to the delay. They also extend this analysis to include momentum, and find momentum should be either turned off, or modified to improve training stability."
SP:05587c2ba9ff9bf3574604a60f614dd807c95e22,This paper proposes a model-free representation learning method for reinforcement learning based on hindsight value estimation. The proposed method learns a value function that takes future observations as an additional input and uses them to learn a model of future quantities of interest that can be used to predict the value function. The authors show that the proposed method outperforms the existing model-based methods in several Atari games.
SP:6388fb91f2eaac02d9406672760a237f78735452,"This paper proposes a novel rewiring operation for the task of graph classification. In particular, the authors propose to rewire the graph in a way that is less noticeable compared to existing operators. They then use reinforcement learning to learn the attack strategy based on the proposed rewired operation. Experiments on real-world graphs demonstrate the effectiveness of the proposed framework. "
SP:233b12d422d0ac40026efdf7aab9973181902d70," for denoising problems. The paper proposes to use Stein’s unbiased risk estimator (SURE) as an unbiased estimator of the prediction error for the denoised problem. However, the computation of the divergence term in SURE is difficult to implement in a neural network framework, and the condition to avoid trivial identity mapping is not well defined. To solve this problem, the paper proposes a close form expression of SURE for prediction error, which leads to a bootstrap and aggregation scheme to prevent the CNN from converging to a trivial solution. Experimental results show that the proposed algorithm provides consistent improvement in various inverse problems."
SP:978555e8eced096b92b37a91fc16b60f7d99c2b6,"This paper proposes a Bayesian meta-learning method for few-shot classification with imbalanced tasks. The main idea is to balance the effect of the meta-knowledge and task-specific learning within each task. To do so, the authors formulate the objective into a variational inference framework and tackle it using Bayesian inference. Experiments show that the proposed method outperforms the baselines on multiple tasks and class-imbalanced datasets."
SP:2395947721c4a337701a7c61cd4ba5c0e38fcc9b,"This paper proposes a method for learning to imitate expert behavior from demonstrations. The main idea is to provide the agent with an incentive to match the demonstrations over a long horizon, by encouraging it to return to demonstrated states upon encountering new, out-of-distribution states. This is achieved by giving the agent a constant reward of r = +1 for matching the demonstrated action in a demonstrated state, and r = 0 for all other behavior. Theoretically, the authors show that SQIL can be interpreted as a regularized variant of behavioral cloning (BC) that uses a sparsity prior to encourage long-horizon imitation. Empirically, SQIL outperforms BC and GAIL on a variety of image-based and low-dimensional tasks in Box2D, Atari, and MuJoCo."
SP:37a4825aaeb899187b957d9ed9ae657617f4a055,"This paper proposes a method to learn stable and temporally coherent feature spaces for points clouds that change over time. The authors propose a temporal loss function that takes into account higher time derivatives of the point positions, and encourages mingling, i.e., to prevent the aforementioned halos. They combine these techniques in a super-resolution method with a truncation approach to flexibly adapt the size of the generated positions. They show that their method works for large, deforming point sets from different sources."
SP:af54d04f219d381208c049b8a9c59b8cdd1783e0,"This paper proposes an end-to-end method to learn a transport cost function for aligning multiple datasets. The proposed method is based on the Sinkhorn algorithm, which learns the transport function from side information. The side information captures subset correspondence between two data sets, i.e., certain subsets of points in the data sets are known to be related. The method is evaluated on three datasets: images, single-cell RNA-seq, and marriage-matching."
SP:fc86b06a367f6790c76b89ec3bfe4cb8627c540a,", the paper proposes a method to detect anomalies in large datasets under a fully unsupervised setting. The key idea is to learn the representation underlying normal data. To this end, the authors leverage the latest clustering technique suitable for handling high dimensional data. This hypothesis provides a reliable starting point for normal data selection, and iterates between hypothesizing normal candidate subset based on clustering and representation learning. The reconstruction error from the learned autoencoder serves as a scoring function to assess the normality of the data. Experimental results on several public benchmark datasets show that the proposed method outperforms state-of-the-art methods and is comparable to semi-supervised techniques."
SP:9e831d3595c15ca34cadb3c4a5b02230593b4ccb,"This paper proposes Projection-Based Constrained Policy Optimization (PCPO), a two-step method for learning control policies that optimize a reward function while satisfying constraints due to considerations of safety, fairness, or other costs. The first step performs a local reward improvement update, while the second step reconciles any constraint violation by projecting the policy back onto the constraint set. The authors theoretically analyze PCPO and provide a lower bound on reward improvement, and an upper bound on constraint violation, for each policy update. They further characterize the convergence of PCPO based on two different metrics: L norm and Kullback-Leibler divergence. "
SP:068a0bb2497373acad5f70e66c61b71465b2de3d,"This paper analyzes the inner mechanism of word embedding methods and shows that the embedding can be viewed as a low rank transformation from the word-context co-occurrence space to the embeddings space, which preserves the relative distances among words. The paper also shows that symmetric factorization can be suboptimal and how to improve the model with asymmetric factorisation. The experiments on real datasets verify the analysis."
SP:b2d099c78b48aab509ab64027ca49e9a47079fc0,"This paper proposes X-Forest, a new method for the task of similarity measurement. The proposed method is based on the idea of Random Projection Trees (RP Trees), which is an extension of the work of Ma & Manjunath (1996). The authors propose to use a combination of two existing methods for similarity measurement: (1) RP Trees and (2) Random Projections Trees. The authors show that the proposed method outperforms the existing methods in terms of accuracy, efficiency, and speed."
SP:77b8bed08af8be8af0c65a72a6e22cfb02645d02,"This paper proposes a hybrid method to reduce the simulation bias of finite-length MCMC chains using gradient-based optimisation. The proposed method can generate low-biased samples by increasing the length of MCMC simulation and optimising the MCMC hyper-parameters, which offers attractive balance between approximation bias and computational efficiency. The experimental results show that the proposed method achieves promising results on popular benchmarks when compared to MCMC and VI methods."
SP:64f2744e938bd62cd47c1066dc404a42134953da,This paper proposes a method for learning latent confounders for causal inference in the presence of missing data. The proposed method is based on variational autoencoders (VAEs) that are adapted to the missing values. The authors propose two variants of the VAEs that can be used as a pre-processing step or as a multiple imputation strategy to take into account the variability due to missing values in the data. Empirical results on simulated data show that the proposed method performs better than existing methods. 
SP:971d0d94adf5113ee1bef8df9ea7dbd508cf4cbc,"This paper proposes a neural architecture search algorithm to construct compact reinforcement learning (RL) policies, by combining ENAS (Vinyals et al., 2015) and ES (Salimans et al. 2017) in a highly scalable and intuitive way. By defining the combinatorial search space of NAS to be the set of different edge-partitionings (colorings) into same-weight classes, the authors represent compact architectures via efficient learned edge partitionings. For several RL tasks, they manage to learn colorings translating to effective policies parameterized by as few as 17 weight parameters, providing > 90% compression over vanilla policies and 6x compression over state-of-the-art compact policies."
SP:18aaba3423e81e9437b509d1a5e24836ef5635f6,This paper proposes a framework for learning representations of time-series using group transformers. The proposed framework generalizes the Wavelet Transform (WFT) and the Continuous Wavelet Transformer (CWT) by introducing non-linear transformations of the affine transformations of a mother filter leading to wavelet filter-bank. The authors also propose a parameterization of such a nonlinear map such that it can be learned efficiently and jointly with any DNN. The experiments on diverse time series datasets demonstrate the expressivity of the proposed method.
SP:3058e6bc5e8c62af325c214c9e1436d6cdf09204,"This paper proposes a generalization of graph convolutional networks (GCN) to non-Euclidean spaces, e.g. hyperbolic or spherical spaces. The authors introduce a unified formalism that can interpolate smoothly between all geometries of constant curvature, leveraging gyro-barycentric coordinates that generalize the classic Euclidean concept of the center of mass. Empirical results on node classification and distortion minimization tasks demonstrate the effectiveness of the proposed method."
