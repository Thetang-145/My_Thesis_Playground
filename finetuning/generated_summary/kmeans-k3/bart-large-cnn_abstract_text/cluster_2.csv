paper_id,summary
SP:b19df5243359791fbaad005d6f13d7e9fdb0ff63,"This paper proposes to decompose joint action spaces into restricted role action spaces by clustering actions according to their effects on the environment and other agents. The role selector searches in a smaller role space and at a lower temporal resolution, while role policies learn in significantly reduced primitive action - observation spaces. The paper further integrates information about action effects into the role policies to boost learning efficiency and policy generalization. By virtue of these advances, the proposed method outperforms the current state - of - the - art MARL algorithms and achieves rapid transfer to new environments with three times the number of agents."
SP:7deb61890d97422a0fe141ca807f968c70ab239a,"This paper studies the behavior of stochastic subgradient descent ( SSGD ) method applied to over - parameterized nonsmooth optimization problems that satisfy an interpolation condition. By leveraging the composite structure of the empirical risk minimization problems, the authors prove that SSGD converges, respectively, with rates O(1 / ) and O(log(1/ ) ) for convex and strongly - convex objectives when interpolation holds. These rates coincide with established rates for the stochastically gradient descent ( SGD ) method, applied to smooth problems that also satisfy an extrapolation condition. The analysis provides a partial explanation for the empirical observation that sometimes SGD and SSGD behave similarly for training smooth and nons mooth machine learning models.   The authors also prove that the rate $ O(\sqrt{1/\log 1/\alpha)$ is optimal for the subgradient method in the convex   and interpolation setting."
SP:c7e0b3fedc0d0409d662dd612b529fdacad2b03e,"This paper proposes to use a transformer - based model as a "" reservoir "" model for random initialization in machine translation ( MT ) and language modelling ( LMs ). The main idea is to use random initialization as a proxy for non - linearity in the transformer layers. The authors show that adding random initialization to transformer layers leads to a reduction in wall - clock compute time until convergence ( WCTC ), as well as improved performance on MT and LMs. The paper is well - written, easy to follow, and easy to understand."
SP:ba9f1d4738ec67a440346f3ac6c4cf35f7232077,"This paper studies the connection between group representation theory and steerable CNNs. In particular, it shows that kernel constructed by filter transform can be interpreted in the group representation framework and that filter transformed kernels can be used to convolve input / output features in different group representation. The paper also provides a novel and simple approach to implement steerable convolutional operators to improve the robustness on geometry transformation of data."
SP:c1116fbb4d058eb6be195b5d13d19a55ba86b602,"This paper proposes an optimal neural program synthesis approach to the multimodal program synthesis task where the goal is to find a program that satisfies user - provided constraints while maximizing the program ’s score with respect to a neural model. Specifically, the problem is in which the user intent is expressed using combination of natural language ( NL ) and input - output examples. At the core of the proposed method is a top - down recurrent neural model that places distributions over abstract syntax trees conditioned on the NL input. This model not only allows for efficient search over the space of syntactically valid programs, but it also allows us to leverage automated program analysis techniques for pruning the search space based on infeasibility of partial partial programs with constraints. The experimental results show that our method substantially outperforms prior state - of - the - art techniques in terms of accuracy and explores fewer states during search."
SP:55e02d79146bbb42f1ab6d4fafa2db5ddbe599b0,This paper proposes a method for predicting the specificity of a protein with respect to a target target using a structure - based molecular interaction graph. The method is based on a protein graph convolutional neural network ( PGCN ) that uses the Rosetta energy function ( RFE ) to determine the topology and energetic features of the graph to determine substrate specificity. The model is robust to small mutational changes. The proposed method also readily lends itself to the design of novel enzymes with tailored specificity against disease targets. The authors compare the proposed method with previously used machine learning models and show that its performance in classification tasks is equivalent or better.
SP:7727eeb7b17ad94ddfa0cf24e64a9626d83a8876,"Double Q - learning is a classical method for reducing overestimation bias, which is caused by taking maximum estimated values in the Bellman operation. This paper shows that such underestimation bias may lead to multiple non - optimal fixed points under an approximate approximate Bellman operator. To address the concerns of converging to non - optimal stationary solutions, this paper proposes a simple but effective approach as a partial fix. This approach leverages an approximate dynamic programming to bound the target value. Experiments on the Atari benchmark tasks demonstrate its significant improvement over baseline algorithms."
SP:1d630b69f95392a5ef3d7d580b523e077a3555a8,"This paper proposes a two - step training framework for deep generative models ( DGMs ) of high - dimensional natural images. The first step is to train a low - resolution sampler ( decoder network ) to generate images in low - frequency bands by training a sampler in the wavelet domain. Then, the high - resolution decoder is used to map the generated images to the latent space of interest using a GAN - based image super - resolution model. The proposed method is shown to improve the generative quality of the sampler and to reduce the training cost substantially. On ImageNet 512×512, the proposed method achieves a Fréchet Inception Distance ( FID ) of 10.59 – beating the baseline BigGAN model – at half the compute ( 256 TPU-v3 cores )."
SP:b943a73b1ec34867371325748dc3a91ff4011947,"This paper studies few - shot learning ( FSL ) from the perspective of self - supervised learning ( SSL ). FSL aims at distilling transferable knowledge on existing classes with large - scale labeled data to cope with novel classes for which only a few labeled data are available. The authors first summarized the supervised FSL methods and explained why SSL is suitable for FSL. Then they further analyzed the main difference between supervised training and self -supervised training on FSL and obtained the bound for the gap between self - supervised loss and supervised loss. Finally, they proposed potential ways to improve the test accuracy under the setting of FSL in theory."
SP:bd552f98e6a447cefa6b1a9bbdf40bc6539fb643,"This paper studies the convergence properties of a two - layer teacher - student neural network with two hidden layers. The authors show that the input weights of student neurons eventually align with one of the teacher neurons, suggesting a distinct convergence nature for “ not - too - wide ” neural networks that there might not be any local minima near the initialization. They also show that under the most basic settings, all student neurons must align with the teacher neuron at any local minimum. The methodology is extendable to more general cases, where the proof can be reduced to analyzing the properties of the angular distance ( AD ) function. Finally, the authors demonstrate that these properties can be easily proved."
SP:0f62846913ec10b44ed32845770da0565479dc75,"This paper proposes Deep Adaptive Semantic Logic ( DASL ), a framework for automating the generation of deep neural networks that incorporates user - provided formal knowledge to improve learning from data. The authors provide formal semantics that demonstrate that our knowledge representation captures all of first order logic and that finite sampling from infinite domains converges to correct truth values. The representation improves on prior neuro - symbolic work by avoiding vanishing gradients, allowing deeper logical structure, and enabling richer interactions between the knowledge and learning components. The paper illustrates the proposed framework through a toy problem in which one can add structure to an image classification task and demonstrate that knowledge of that structure reduces data requirements by a factor of 1000. The experiments show that the addition of commonsense knowledge improves performance by 10.7 % in conditions of data scarcity."
SP:2f19259d65fab904c1b771244da3dcb2f8aa0c26,"This paper studies the relationship between feedforward residual neural networks ( ResNets ) and iterative computations. The authors show that even though such networks can express iterative solutions, they do not learn them when trained conventionally on computer vision tasks. They then introduce regularizations to encourage iterative convergent computation and introduce a Lipschitz constraint on the residual functions using spectral normalization to make the networks more convergent. Experiments on standard visual recognition tasks ( MNIST, CIFAR-10, Cifar-100 ) and challenging recognition tasks with partial occlusions ( Digitclutter ) show that the proposed regularization method does not improve classification accuracy or provide a useful inductive bias for such networks."
SP:6c14506b8b2b06043409d912e6bf877651aaa665,"This paper proposes two new normalization techniques for out - of - distribution ( OOD ) generalization. The first one is called SelfNorm, which recalibrates statistics ( channel - wise mean and variance ) for IID data. The second one, called CrossNorm, is a variant of SelfNorm that uses attention to recalibrate statistics between feature maps. Experiments are conducted on both supervised and semi - supervised settings to show the effectiveness of the proposed methods."
SP:2774abdc11917321dd4994af0f0da1ff824bea03,"This paper proposes to use attention mechanism in the convolutional encoder of an RL agent to extract task - relevant information without the need for data augmentations or contrastive losses. The proposed attention mechanism is implemented in a simple, yet effective, way by augmenting a simple attention module in the CNN of an encoder. Experiments on the DeepMind Control Suite environments show that the proposed attention module can extract interpretable task - relevance information such as agent locations and movements without the use of data augations or augmentations, and significantly improve the sampleefficiency and final performance of the agents."
SP:31a7051d08d19c01e11f1fac2f3041ed2fa28f15,"This paper proposes an extension of GradNorm ( Chen et al., 2018 ) for training multi - task neural networks, where different tasks share and thus compete for the network parameters. GradNorm eases the fitting of all individual tasks by dynamically equalizing the contribution of each task to the overall gradient magnitude. However, it does not prevent the individual tasks ’ gradients from conflicting, i.e., pointing towards opposite directions, and thus resulting in a poor multitask performance. In this work, the authors propose an extension to GradNorm that addresses this problem by dynamically homogenizing not only the gradient magnitudes but also their directions across tasks. For this purpose, they add a layer of task - specific rotation matrices that aligns all the task gradients. They also analyze the theoretical guarantees on the algorithm stability and convergence. Finally, they show that their experiments on several real - world datasets and network architectures show that Rotograd outperforms previous approaches for multitask learning."
SP:ac9ebd027b92527d9a87b13ad11d002d99a2b0f6,"This paper proposes a new I2I translation constraint, called Minimal Geometry - Distortion Constraint ( MGC ), which promotes the consistency of geometry structures and reduces the unwanted distortions in translation by reducing the randomness of color transformation in the translation process. To facilitate estimation and maximization of MGC, an approximate representation of mutual information called relative Squared - Loss ( SQUALL ) is proposed. The effectiveness of the proposed MGC is demonstrated on quantitative and qualitative comparisons with the state - of - the - art methods on several benchmark datasets."
SP:92a38d7d18f07f68b8f93c61180e2cc1dddd21de,"This paper studies the sampling sensitivity of point sampling patterns in point cloud GANs. The paper proposes a sampling spectrum to represent the different sampling sensitivities of discriminators. It also proposes a middle - point sampling - aware baseline discriminator, PointNet - Mix, which improves all existing point cloud generators by a large margin on the sampling - related metrics. Extensive experiments show that sampling - insensitive discriminators produce shape point clouds with point clustering artifacts, while sampling - over - sensitive discriminators fail to guide valid shape generation."
SP:16c4be3eb162bc81cb3343c2fc115eb8e926a5b5,"This paper proposes a novel vote attack method to attack capsule neural networks ( CapsNets ) by directly attacking the votes of the output capsules. Specifically, the authors propose a novel novel method to circumvent the class - conditioned reconstruction part of the detection - aware attack paradigm by inserting the vote attack into the original detection - based attack paradigm, bypassing the detection detection method. Extensive experiments demonstrate the superior attack performance of the proposed novel attack method."
SP:dbd093dff7a38ba8882bb8119c34623ddaaf4cc6,"This paper proposes a meta - reinforcement learning algorithm for online adaptation where the agent needs to trade - off between two types of behaviour within the same episode. The proposed method learns an informed policy ( i.e., a policy receiving as input the description of the current task ) that is used to both construct task - specific and task - generalization policies. The authors propose to use privileged information in the form of a task descriptor at train time to improve the learning of recurrent policies. They evaluate their algorithm in a variety of environments that require sophisticated exploration / exploitation strategies and show that it outperforms vanilla RNNs, Thompson sampling and the task - inference approaches to meta - re - reward learning."
SP:bd89d254fbf31db61db237d08ab42981e27c52df,"This paper proposes an adaptive policy learning method to learn offline RL policies in a real - world sequential recommendation system ( SRS ), where the offline dataset is not available for online sampling and the simulator is generated by an offline dataset. The authors argue that due to the stochasticity and unsteadiness of the real world and the unavailability of online sampling in SRS, the distortion of the simulator in the offline setting is inevitable. To deal with this issue, the authors propose to learn to adapt to diverse simulators generated by the dataset in an offline RL setting. The proposed method is based on the model learning technique and is shown to outperform the existing methods in both synthetic and real world settings."
SP:1a166b28cf684e0d5759bd629f6a53370d2bf11c,"This paper proposes a method for learning goal - reaching policies from scratch without expert demonstrations or a value function. The method is based on imitation learning, where trajectories generated by the agent are used as successful trajectories for reaching the final state of the goal. The agent learns to imitate the trajectories it generates by relabeling them with the policy of the previous iteration, and maximizes the likelihood of the actions taken along these trajectories under the goal that was actually reached, under the current policy. The proposed method is shown to converge to a policy that achieves the goal within a fixed number of iterations. Experiments show that the proposed method outperforms a number of baselines in several benchmark tasks.  "
SP:c306530164d677e670554eeba8203c66bb3d9f7a,"This paper proposes a method for non - autoregressive text to speech ( TTS ) models. The proposed method builds on top of FastSpeech ( Ren et al., 2019 ), which uses a teacher model for duration prediction and knowledge distillation to simplify the data distribution in output. However, the proposed method has two main drawbacks : 1 ) the teacher - student distillation pipeline is complicated and time - consuming, 2 ) the duration extracted from the teacher model is not accurate enough, and the target mel - spectrograms distilled from teacher model suffer from information loss due to data simplification, both of which are addressed by directly training the model with ground - truth training instead of the simplified output from teacher, and introducing more variation information of speech ( pitch, energy and more accurate duration ) as conditional inputs in training and use predicted values in inference. In addition, the authors propose a method that is the first attempt to directly generate speech waveform from text in parallel, enjoying the benefit of fully end - to - end inference. The experimental results show that the proposed methods can achieve a 3x training speed - up over the previous fastSpeech model."
SP:79e9fb20d383816f54738ce70d137131ebc10290,"This paper studies the problem of unsupervised dimension reduction ( UDR ) in the language of tempered distributions, i.e., approximating an empirical probability density function pemp(x) by another tempered distribution q(x ) whose support is in a k - dimensional subspace. The problem is reduced to the minimization of the distance between q and pemp, D(q, pemp ) over a set of generalized functions. This infinite - dimensional formulation allows to establish a connection with another classical problem of data science — the sufficient dimension reduction problem ( SDR ). An algorithm for UDR induces an algorithm for SDR and vice versa. The authors introduce a nonnegative penalty function R(f ) that “ forces ” “forces ” the “ distributions ” to obey a two - step iterative two - dimensional two - stage iterative scheme. They demonstrate the method on 3 UDR and 1 SDR using synthetic data and standard datasets."
SP:93e54522e6c2b805905d21fc968fc40866f2898b,"This paper proposes Feature Contrastive Learning ( FCL ) to improve the robustness and sensitivity of image classification models. FCL leverages two notions : contextual feature utility and contextual feature sensitivity. The former is used to encourage the model to be more sensitive to features that have higher contextual utility, while the latter is used for sensitivity to rare or underrepresented patterns. Experiments on CIFAR-10 and ImageNet show that FCL achieves a better balance between sensitivity and robustness."
SP:f03c50f15022c4f56ac2b3085354ffed38ad1145,"This paper proposes a generative adversarial imitation learning ( GAIL ) algorithm for imitation learning. The key idea of GAIL is to learn a latent representation of the state space of the expert and the agent by regularizing the discriminator network. The discriminator is trained with adversarial training to maximize the mutual information between the latent representation and the states of the agent and the expert. The latent representation is then disentangled from the full set of optimal states and actions taken by the agent. The authors show that their method is able to imitate in a diverse range of control problems, including balancing, manipulation and locomotive tasks."
SP:ef18f4188426bc01be309633b486884b0e7a81a4,"This paper studies the generalization properties of a pruned neural network. The authors show that the convex region near a desirable model with guaranteed generalization enlarges as the neural network model is pruned, indicating the structural importance of a winning ticket. The number of samples required for achieving zero generalization error is proportional to the number of the non - pruned weights in the hidden layer. Theoretical results are acquired from learning a pruning neural network of one hidden layer, while experimental results are further provided to justify the implications in pruning multi - layer neural networks."
SP:eed6cb2f8caed39f8295f4aeb6e044c2ac981c4d,"This paper proposes a method to automatically learn the labels for augmented data based on the distance between the clean distribution and augmented distribution. The method is built on label smoothing and is guided by the calibration - performance over a hold - out validation set. The authors show that AutoLabel is a generic framework that can be easily applied to existing data augmentation methods, including AugMix, mixup, and adversarial training. Experiments on CIFAR-10 and ImageNet show that the proposed method can improve the accuracy and calibration performance, especially under distributional shift."
SP:0d5017e1a405bf86e3bac40e6e59886d4bf48450,"This paper proposes RELIC, a self - supervised representation learning method that enforces invariant prediction of proxy targets across augmentations through an invariant regularizer. The authors show how data augmentations can be more effectively utilized through explicit invariance constraints on the proxy classifiers employed during pretraining. The RELIC method generalizes contrastive learning by using causality. Empirically, RELIC significantly outperforms competing methods in terms of robustness and out - of - distribution generalization on ImageNet and on Atari."
SP:8f80a6f79f78c6421857f392c9a5e98061d7eb60,"This paper proposes a visual transformer network ( VTNet ) to learn informative visual representations for object goal navigation ( OOD ). The main idea is to exploit the spatial relationships among all the object instances in a scene and to emphasize the spatial locations of objects and image regions so that directional navigation signals can be learned. The authors also develop a pre - training scheme to associate the visual representations with navigation signals, and thus facilitate navigation policy learning. Experiments in the artificial environment AI2Thor demonstrate that VTNet significantly outperforms state - of - the - art methods in unseen testing environments."
SP:3e7cbe3dff592ef371e48dd86be7719fc5343f17,"This paper proposes a communication - efficient secure aggregation method for federated learning that reduces the amount of communication / computation resources by a factor of $ \sqrt{n/log n } / log n$ without sacrificing data privacy, where $ n$ is the number of clients. The key idea is to design the topology of the secret - sharing nodes of the graph corresponding to the secure aggregation primitive of the existing solution. The authors provide theoretical guarantees on the reliability / privacy of the proposed scheme and provide a sufficient condition on the Erdos - Rényi graph as G, and provide extensive experiments to demonstrate that the proposed method achieves the same levels of reliability and data privacy as the conventional scheme while using only 50 % of the resources required in the conventional framework."
SP:00fae41e0eca0a1575cd7b2dcfabf0dc5c9c8b8a,"This paper proposes a time - independent Lagrangian - based auction design method to compare the performance of two auctions. The proposed method is inspired by the recent work of Duetting et al. ( 2019 ), which uses a neural network architecture to find optimal auctions using an inner maximization loop to compute optimal misreports. The authors propose an additional neural network to further improve the performance. They demonstrate the effectiveness of their approach by learning competitive or strictly improved auctions compared to the existing auction design methods."
SP:a0e8061beb5e9a6c631419861559d22b8d645cb4,This paper proposes a general learning approach to fine - tune both supervised and unsupervised pre - trained representations to downstream tasks by integrating two heads upon the backbone of pre - learned representations : a classifier head with an improved contrastive contrastive loss to leverage the label information in an instance - dependent way and a categorical contrastive learning loss to fully exploit the intrinsic structure of data in a category - consistent way. The proposed method is evaluated on a variety of downstream tasks and achieves state - of - the - art results for fine - tuning.
SP:87e5b552c13d73bd85249062a152c6c140e594a9,"This paper proposes a new metric called “ genuine adversarial accuracy ” to measure the robustness of classifiers against adversarial perturbations. It is motivated by the observation that standard adversarial training suffers from a tradeoff between accuracy on clean data and accuracy on the adversarially perturbed samples. The authors propose to use “ authentic ” adversarial examples, i.e. samples whose predicted classes are unchanged even if the perceptual classes are changed. Theoretically, the authors prove that a single nearest neighbor ( 1 - NN ) classifier is the most robust classifier according to the “ real ” robustness metric."
SP:2fda410b9281c5e253d385bc4382ec168bc161f3,"This paper studies the problem of fairness in link prediction via graph neural networks. The authors propose an algorithm, FairAdj, to empirically learn a fair adjacency matrix with proper graph structural constraints for fair link prediction, and in the meanwhile preserve predictive accuracy as much as possible. The main contribution of this paper is to theoretically relate the graph connections to dyadic fairness on link predictive score in learning link predictive scores, and show that regulating weights on existing edges in a graph contributes to fairness conditionally. The proposed algorithm is empirically validated empirically to demonstrate that it achieves a fair fairness in terms of various statistics, and at the same time enjoys a favorable fairness - utility trade - off."
SP:b614e9fbec58e9efa7722d2ec4a60fc93d210f92,"This paper proposes a new autoencoder - based generative model, DEAE, that uses disentangled representation and regularization to improve the quality of exploration in latent space and achieve controllable synthesis. The encoder of DEAE first turns the input sample into a latent code, then explores the latent code space through directed interpolation to aid the interpolated latent code. The decoder is then regularized to force the obtained latent representation to maintain perfect disentanglement. Experiments demonstrate that DEAE can improve the performance of downstream tasks by synthesizing attribute - controlled augmented samples and eliminate dataset bias for fairness problems."
SP:c934adb14926a00ef9c73c9773cb0b3a2669921e,"This paper proposes a new principled Bayesian memory allocation scheme that bridges the gap between episodic and semantic memory via a hierarchical latent variable model. The authors take inspiration from traditional heap allocation and extend the idea of locally contiguous memory to the Kanerva Machine, enabling a novel differentiable block allocated latent memory. They simplify the process of memory writing by treating it as a fully feed forward deterministic process, relying on the stochasticity of the read key distribution to disperse information within the memory. Experiments on CIFAR10, DMLab Mazes, Celeb - A and ImageNet32 show that the proposed scheme improves performance in memory writing."
SP:e63d7d8c581019e17585fb9c0eac33d6836e187d," and attention mechanisms have advanced state - of - the - art deep learning models for many machine learning tasks. Despite significant empirical gains, there is a lack of theoretical analyses on their effectiveness. This paper addresses this problem by studying the sample complexity and loss landscape of attention - based neural networks. The results show that, under mild assumptions, every local minimum of the attention model has low prediction error, and attention models require lower sample complexity than models without attention. Besides revealing why popular self - attention works, the theoretical results also provide guidelines for designing future attention models. Experiments on various datasets validate the theoretical findings."
SP:f739d199fdee26f09994e3f9487aec1eab0f2e89,"This paper extends the concept of expected free energy ( EFE ), which is a core quantity in active inference, and claims that EFE can be treated as a negative value function. Theoretically, the authors show that the value of EFE is related to the expected prior preference ( prior preference ) of the agent. Motivated by this connection, they propose a simple but novel method for learning a prior preference from experts. The proposed method, called prior preference learning ( PRL ), is based on Bayesian inference with a biologically plausible model of an agent's behavior. PRL is applied to the problem of active inference in the case of inverse RL, where the agent has access to an expert's prior preference for an observation, and the agent must choose an action that is consistent with this prior preference in order to perform the active inference."
SP:5592b79e49eba95c15103a3348f2bde57b60f2ab,"This paper proposes a data augmentation method to improve generalization in both adversarial and standard learning by using out - of - distribution ( OOD ) data. The proposed method improves generalization theoretically using OOD data in each learning scenario and complemented their theoretical analysis with experiments on CIFAR-10, CifAR-100, and a subset of ImageNet. The results indicate that undesirable features are shared even among image data that seem to have little correlation from a human point of view. The authors also present the advantages of the proposed method through comparison with other data augmentations methods, which can be used in the absence of unlabeled data."
SP:3cac7a2c310165ed0de46d8e5546c3bfbd639158,"This paper proposes a new meta - RL method called Fast Linearized Adaptive Policy ( FLAP ) that learns a shared linear representation of the policy and adapts to a new task by predicting a set of linear weights instead of updating a meta - policy via gradient descent. A separate feed - forward network is trained simultaneously with the policy so that during adaptation, FLAP can directly use the adapter network to predict these linear weights. FLAP achieves significantly stronger performance on out - of - distribution tasks with up to 8X faster adaptation run - time speeds when compared to prior methods such as MAML."
SP:21a1bd4ada0723c96c0dbf7a142a2faf5defa4e3,This paper proposes a distributed stochastic proximal gradient descent ( DSPGD ) algorithm to solve the optimization problem of kernel k - means under federated settings. It also proposes a communication efficient mech anism ( CEM ) to reduce the communication cost. The experimental results show that the federated kernelk - means achieves the highest clustering quality with the communication costs significantly reduced.
SP:be568dd3fea51ce33a6d1e4b07dda5aee6342395,"This paper proposes a new method to reduce the training / search / extraction time and the complexity of the training and subsequent extraction algorithms for CNNs. The proposed method, CompOFA, is an extension of Once - For - All ( OFA ) that trains several models at once with a constant training cost. The authors propose to reduce this search space and hence the training budget by constraining search to models close to the accuracy - latency Pareto frontier. They also show that this smaller design space is dense enough to support equally accurate models for a similar diversity of hardware and latency targets while also reducing the training complexity. They demonstrate that even with simple heuristics we can achieve a 2x reduction in training time and an orders of magnitude reduction in search time compared to the state of the art."
SP:04b84d26cf282dbb753cbf27f14c334f65d3f8ec,"This paper studies the problem of meta - learning in the presence of adversarial samples. The authors propose a new algorithm, ADML ( Adversarial Meta - Learner ), which is robust to adversarial adversarial examples. The proposed method optimizes the initialization of a learning model in an adversarial manner. The experiments are conducted on two widely - used image datasets, MiniImageNet and CIFAR100. The results show that the proposed method outperforms the baselines in terms of both accuracy and robustness."
SP:dfbaa6b53c4e8328d52666ad4641fc917bf0c0b3,"This paper proposes a new algorithm for decoding Bose - Chaudhuri - Hocquenghem ( BCH ) code. The algorithm is based on permutation decoding, which is NP - hard, but the authors propose a data - driven framework for permutation selection combining domain knowledge with machine learning concepts such as node embedding and self - attention. The authors show that their method outperforms the existing suboptimal decoding algorithms in terms of the bit error rate. They also show that the choice of permutation is a key insight in permutation decoder."
SP:c860a7b0952d708e7851c9bc4b63d246f64d1cba,"This paper proposes an intermediate task for unsupervised clustering in text classification, where the goal is to reduce the number of labeled examples needed for the target task. The proposed intermediate task consists of clustering clusters of text samples and training BERT on predicting the cluster labels. The authors test this hypothesis on various data sets and show that this additional classification step can significantly reduce the demand for labeled examples mainly for topical classification tasks. They further discuss under which conditions this task is helpful and why it is helpful."
SP:ea37f5882fd98dd4ce233077bb3069517d4ed4ea,"This paper presents an empirical study of several popular generative models in the context of model - based reinforcement learning ( MBRL ), where the goal is to learn a generative model that can be used to improve the performance of a control agent. The authors compare these models on a set of tasks where the control agent is random, and they show that the mixture density net ( MNDN ) outperforms all other models by a large margin. They also show that deterministic models are on par with probabilistic models, and that heteroscedasticity at training time improves predictions at longer horizons. Finally, the authors propose a metric for evaluating MBRL models, predicting their asymptotic performance when using them on the control problem of Acrobot."
SP:4e25ba3714d78ba59a0d8efbb65e0ef5201702f8,"This paper proposes an affine disentangled GAN model that can explicitly disentangle affine transformations in a self - supervised and rigorous manner. The main idea is to decompose the affine transformation matrix into separate transformation matrices and inferring the transformation parameters by maximum likelihood estimation. The features learned by ADIS - GAN are axis - aligned and scalable, where transformations such as rotation, vertical zoom, horizontal and vertical translation can be explicitly selected and learned. Experiments on MNIST, CelebA, and dSprites datasets demonstrate the effectiveness of the proposed method."
SP:121f8420cfb49c6d80b5ebb4051e85947182594a,"This paper proposes a representation bank for self - supervised representation learning. The representation bank consists of positive and negative samples extracted from the same dataset, augmented with strong and weakly augmented samples, respectively. Stronger augmentations are used in the representation bank to avoid the distortions induced by the stronger augmentations. The proposed method achieves top - 1 accuracy of 76.2 % on ImageNet with a standard ResNet-50 architecture with a single - layer classifier fine - tuned. This is almost the same as 76.5 % accuracy with a fully supervised ResNet - 50. Moreover, the proposed method outperforms the previous self - supervised and supervised methods on both the transfer learning and object detection tasks."
SP:af54e542223097c315ecd677d0b968e9a0b2a1d4,"This paper proposes a method for de - identification of the face of a patient using MRI images. The proposed method is based on a conditional, multi - scale, 3D GAN architecture that takes a patient ’s MRI scan as input and generates a 3D volume in which the brain is not modified but the face has been de - identified. Compared to the classical removal - based techniques, the proposed method successfully de - identifies the face while not revealing the identity of the patient. The paper is well - written, easy to follow, and easy to understand. The method is evaluated on a variety of MRI datasets."
SP:0ac3964bd2320341488476d60f57b75d2a79f92c,"This paper proposes a new graph pooling method based on multiset encoder - decoder architecture for graph neural networks. The proposed method is based on a global pooling layer ( GMT ) that captures the interaction between nodes according to their structural dependencies. The authors show that GMT satisfies both injectiveness and permutation invariance, as well as the Weisfeiler - Lehman graph isomorphism test. The experimental results on several graph classification and link prediction tasks demonstrate the effectiveness of the proposed method."
SP:76848e7ac3e6709e92f6a6db60269cb5177495d1,"This paper studies the problem of over - squashing in graph neural networks ( GNNs ). The authors propose a new explanation for this problem, which they call a bottleneck. The bottleneck causes the over - sqashing of exponentially growing information into fixed - size vectors, which hinders the propagation of information between distant nodes in the graph. They show that GCN and GIN are more susceptible to over - Squashing than GAT and GGNN. They also show that breaking the bottleneck improves the state - of - the - art results without any tuning or additional weights."
SP:90d8fa381446923902e42b259392e5e975e6caa1,This paper proposes a method for cross - domain sentiment analysis based on matching source and target domain data distributions. The main idea is to train a classifier in a source domain that is invariant to the source domain but generalizable to a related target domain. The proposed method is based on a cross - classifier that is trained on the source data distribution and the target data distribution. Theoretical analysis and empirical analysis are provided to demonstrate that the proposed method induces large margins between different classes in an embedding space.   The main contribution of this paper is to propose a new domain adaptation method for sentiment analysis.
SP:893fd7440b82f5da0d4c0944928810322eaee2f0,"This paper proposes a challenge task to evaluate the effect of gender bias in state - of - the - art NLI models on the presence of gender stereotypes using occupations. The challenge task consists of training a model on a gender - neutral premise and testing a hypothesis based on gender - specific stereotypes. Three models ( BERT, RoBERTa, BART ) are evaluated on MNLI and SNLI data sets. The results show that all three models are prone to gender - induced bias in their predictions. The paper also shows that augmenting the training dataset with gender - balanced data can help reduce bias in certain cases."
SP:a32ab755bd249c393b70938036ce8e810c0c439f,"This paper revisits variational intrinsic control ( VIC ), an unsupervised reinforcement learning method for finding the largest set of intrinsic options available to an agent. In the original work by Gregor et al. ( 2016 ), two VIC algorithms were proposed : one that represents the options explicitly, and the other that does it implicitly. The authors show that the intrinsic reward used in the latter is subject to bias in stochastic environments, causing convergence to suboptimal solutions. To correct this behavior and achieve the maximal empowerment, two methods respectively based on the transitional probability model and Gaussian mixture model are proposed. The experimental results demonstrate the effectiveness of the proposed methods."
SP:b4df2c4627a6d46c5100133e38c4bea20b296dd8,This paper proposes to use an ensemble of relatively small deep neural networks to improve sample efficiency in the low data regime for image classification problems with a few labeled examples per class. The authors conduct extensive experiments on popular datasets and architectures and show that deep ensembling is a simple yet effective technique that outperforms current state - of - the - art approaches for learning from small datasets. They compare different ensemble configurations to their deeper and wider competitors given a total fixed computational budget and provide empirical evidence of their advantage.
SP:4a0ee01f4897efa81659f37ef0468ee8195bbc4f," neural networks ( SBNNs ) are quantized neural networks that use positive 0 / 1 binary weights instead of the - 1 / 2 binary weights used by state - of - the - art BNNs. However, they suffer from a fixed and limited compression factor that may result insufficient for some devices with very limited resources. In this work, the authors propose Sparse Binary Neural Networks, a novel model and training scheme that allows to introduce sparsity in binary neural networks by using positive 0/1 binary weights. The authors show the properties of their method through experiments on linear and convolutional networks over MNIST and CIFAR-10 datasets."
SP:5be8539ad02595ad3c7a2d7afe8cbb3e9924467d,"This paper proposes a post hoc calibration method for predictive uncertainty estimation in deep learning models. The main idea is to estimate the probability that a model prediction is correct using a surrogate for class membership probabilities. This surrogate is used to measure how confident ( or uncertain ) we should be about the result. The calibration error is the difference between predicted error rates and actual error rates, as measured by collecting data into bins based on pmax = maxi p softmax i bins. The proposed method is based on the expected calibration error ( ECE ) Guo et al. ( 2017 ) but other measures have been used, including the Brier score ( DeGroot & Fienberg, 1983 ), which is also used in the work of Ovadia et al ( 2019 ). The method uses outlier exposure to calibrate the model probabilities."
SP:ea503f67e38fce7dee9cc4996b55b8959911f030,"This paper studies the expressive power of graph neural networks and graph kernels from an empirical perspective. The authors compare the graph representations and similarities produced by these algorithms against those generated by a well - known but intractable graph similarity function. They also investigate the impact of node attributes on the performance of the different models and kernels. Their results reveal interesting findings, for instance, that theoretically more powerful models do not necessarily yield higher - quality representations, while graph kernels are shown to be very competitive with graph neural network."
SP:0cf7b7d929f50e0b7f4fda5e1f68e5ade2f7c29b,"This paper proposes a new self - supervised image animation method that warps the source image based on the motion of the driving video and recovers the warping artifacts by inpainting. The proposed method, named PriorityCut, is a novel data augmentation approach that uses occlusion information in image animation indicating the locations of warping artifact to regularize discriminator predictions on in - painting.    The main contributions of this paper are :   1. Prior art works on image generation are mostly warp - based, which is not suitable for image animation. This paper proposes to use the top - k mask augmentation method for image generation to overcome this limitation. 2. It proposes a method for in -painting to recover the warp artifacts from the warped source image. 3. The method is evaluated on CIFAR-10 and ImageNet datasets and compared with CutMix."
SP:60b535fc6cbc1a7a26ad53f706ebb17de346dc4f,This paper proposes to learn independent causal mechanisms ( ICM ) by learning disentangled representations of multiple data generation processes ( mechanism ) in a self - supervised manner. The main idea is to learn a model that disentangles each mechanism and approximates the ground - truth mechanisms from observational data. The proposed method is based on a mixture of disentangling prior and disentanglement loss. The authors provide sufficient conditions under which the mechanisms can be learned using a single generative model with an unconstrained mixture prior. They show identifiability of the learned mechanisms w.r.t. the ground truth mechanisms and compare their approach to disentangle representations on various downstream tasks.
SP:44d4e24428d043a69b40013919cda0e8e7bff99c,"This paper proposes a self - labeling approach for predicting molecular graphs from 2D chemical compound images. The main idea is to use a fully - connected graph as a mediating layer between the graph representation of the target graph and that of the source graph in the target domain. The target graph is modeled using the graph embedding method of [ 1 ], where the graph is represented by a fully connected graph representation ( $ V$ ) of a chemical compound ( $ U$ ) given a 2D image of the chemical compound $ U$. The source graph is then mapped to a target graph ( $ W$ ) by a graph - aligning method ( $ GALA$ ). The authors propose a domain adaptation strategy for domain adaptation from the source domain where they have access to the expensive labels V in the source ( source ) domain to the target ( target ) domain where only normal labels W are available. The proposed self - labeling approach is evaluated on the Maybridge data set and achieves better performance than the current state - of - the - art self - labeled approach."
SP:ad906dd9a176cffd283593321ff6b9ad19595528,"This paper proposes a novel deep learning framework to solve the energy consumption estimation problem in a chiller plants energy optimization problem. The proposed method is based on domain knowledge in the structure and loss design of deep network to build a nonlinear model with lower redundancy function space. Specifically, a Neural Network with monotonic constraints is designed to mimic the physical behavior of the system. The experimental results show the superiority of the proposed method in the proposed energy optimization compared to the existing ones."
SP:6cb65ee5d2926858570601eeeade24fe86c7f32f,"This paper proposes a method for multi - task spatio - temporal forecasting based on the Conditional Average Treatment Effect ( CATE ) estimation method in causal inference. The authors integrate the causal attention with the CATE estimation method and propose a novel graph fusion mechanism to significantly reduce the parameters’ scale. They conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various components, and the time efficiency of the CausalTrans framework."
SP:223980a1954d626d90ff54d8dc61b5d85a6b349c,"This paper studies the problem of identifying a mixture of discrete and continuous factors of variability, which can help unravel complex phenomena. The authors propose an unsupervised framework called coupled mixture VAE ( cpl - mixVAE ), which utilizes multiple interacting autoencoding agents. The individual agents operate on augmented copies of training samples to learn mixture representations, while being encouraged to reach consensus on the categorical assignments. They provide theoretical justification to motivate the use of a multi - agent framework, and formulate it as a variational inference problem, and benchmarked their approach on MNIST and dSprites. They demonstrate the utility of this approach in jointly identifying cell types and type - specific, activity - regulated genes for a single - cell gene expression dataset profiling over 100 cortical neuron types."
SP:c982610ad28662c3bd13132abe1f7307d1a61b68,"This paper provides a general characterization of steerable kernel spaces for group equivariant convolutional networks ( GCNNs ). The paper shows that the kernel space of a GCNN can be viewed as a kernel of a G - steerable group ( G being any compact group ), which satisfies a constraint on the equivariance of the kernel. The authors draw an analogy between the constraints underlying steerable kernels on the one hand and the constraints on spherical tensor operators from quantum mechanics on the other hand. The main result of the paper is to show that the constraints are satisfied for any kernel of the Gsteerable group."
SP:7b2ea39069277ad0f4f79476a77ef84587a804d9,"This paper analyzes the effect of selective classification ( CL ) on group - wise accuracy disparities in vision and NLP datasets. The authors show that selective classification can improve average accuracies but magnifies existing accuracy disparities between various groups within a population, especially in the presence of spurious correlations. They observe that increasing abstentions can even decrease accuracies on some groups. They further study the margin distribution, which captures the model ’s confidences over all predictions, to better understand this phenomenon. They show that for symmetric margin distributions, selective classification monotonically improves or worsens accuracy is fully determined by the accuracy at full coverage ( i.e., the margin of the model ), and whether the distribution satisfies a symmetric assumption on the margin distributions. They also show that the selective classification uniformly improves each group on models that achieve similar full - coverage accuracies across groups, whereas selective classification worsens the accuracy disparities on some models.    The authors conclude that CL should be used with care and underscore the importance of training models to perform equally well across groups. The paper is well organized and easy to follow."
SP:f1d57ee27e901daf7e4e2b84139019e945818911,"This paper proposes a new hierarchical nonnegative CANDECOMP / PARAFAC decomposition ( hierarchical NCPD ) model and a training method, Neural NCPD, for performing hierarchical topic modeling on multi - modal tensor data. The proposed method uses a neural network architecture and backpropagation to mitigate error propagation. The paper is well organized and easy to follow."
SP:b6ddc3a560aa7155e7e927bf5360bedc36586597,"This paper proposes a collective adversarial robustness certificate for graph neural networks ( GNNs ). The main idea is to fuse multiple single - node certificates into a much stronger collective one, which is guaranteed to remain stable under adversarial perturbations. The proposed collective robustness is defined as the number of predictions that are simultaneously guaranteed to stay stable under perturbation, i.e., cannot be attacked. The authors leverage their locality property and leverage locality property - based locality property ( LAP ) to fuse the predictions of multiple nodes into a drastically stronger collective certificate. The experimental results show that the proposed collective certificate significantly outperforms the existing adversarial certificate for node classification and image segmentation."
SP:cc93dd2f68e415e2457166e78627865dc1b44697,"This paper proposes Quantile Regression GAN ( QRGAN ), a new method for training generative adversarial networks ( GANs ) that learns high - dimensional probability distributions by competitively training a generative and discriminative neural networks. The main contributions of this paper are the following :   1. The authors propose a new loss function for training a GAN that learns the distribution of real and generated data.   2. They analyze the discriminator and generator in the proposed method to see if it guides the generator well and if discriminator should not be bounded to specific numbers. 3. They show that QRGAN is more robust against mode collapse problem compared to LSGAN and WassersteinGAN."
SP:4ddb47ee77c374ae6c3e419412d92ca77260692e,"This paper investigates relevance metrics for similarity - based explanations for machine learning models. The authors propose cosine similarity of the gradients of the loss function as a relevance metric for the proposed explanation method. Three different tests are adopted to evaluate the relevance of different relevance metrics, and the authors found that cosine similarities of the gradient of the cosine function is the most relevant similarity metric. They also found that some relevance metrics perform poorly in their tests and analyzed the reasons of their failure. The experiments were conducted on CIFAR-10 and ImageNet datasets."
SP:6c2cbf2bc0f6dabe974e80ec1e82d2d12189906e,"This paper proposes to add a low - rank global attention ( LRGA ) module to graph neural networks ( GNNs ) for improving their generalization power. The LRGA module is a computation and memory efficient variant of the dot - product attention ( Vaswani et al., 2017 ). The authors show that LRGA can improve the performance of the 2 - FWL algorithm for graph isomorphism test. The paper also shows that augmenting existing GNN layers with LRGA improves state - of - the - art results in current GNN benchmarks."
SP:b4abdd28504b4c1de239eabd4e0e27d370efee71,This paper proposes an adaptive label smoothing method to improve the calibration performance of convolutional neural networks ( CNNs ) for object classification. The proposed method is based on smoothing the labels based on the relative object size in the given image. The smoothing factor is computed based on a weighted sum of smoothing factors of the relative size of the object being classified instead of relying on the context to make the correct predictions. Experiments on ImageNet-1 K show that the proposed method outperforms the hard label approach ( COCO ) and the adaptive smoothing approach ( AMSOIL ) in the classification task.
SP:5254658923e594294b69d124a8d004166852822a,"This paper proposes a two - layer fully - convolutional ReLU denoising network for training and interpreting neural networks for inverse problems. The proposed dual network is based on the duality principle, which implies that the output of the denoiser is piecewise linear filtering while the outputs of the encoder and decoder are non - linear. The authors propose to use weight decay regularization to regularize the weights of the decoder so that the path sparsity is reduced and the prediction becomes linear. Experiments on MNIST and fastMRI datasets show the effectiveness of the proposed method."
SP:085cad6bc143c8713580bddfaa71f06496dac314,This paper proposes an end - to - end speech synthesis model that learns to synthesize speech from normalised text / phonemes using a differentiable token - length prediction scheme. The key idea is to generate high - fidelity audio through a combination of adversarial feedback and prediction losses that constrain the generated audio to roughly match the ground truth in terms of its total duration and mel - spectrogram. The proposed generator is feed - forward and thus efficient for both training and inference. The resulting model is comparable to the state - of - the - art models relying on multi - stage training and additional supervision.
SP:01148cea55db606aa78d27e900818684a8bce9ab,"This paper proposes a non - parametric method for learning node representations in attributed graphs where some attributes are missing from the attribute matrix. The proposed method is based on the Wasserstein graph diffusion ( WGd ), which is used to transform node features into discrete distributions in a lower - dimensional space equipped with a metric. This allows to reduce the distortion caused by missing attributes and obtain integrated representations expressing information of both topology structure and attributes. The authors then pull the nodes back to the original space and produce corresponding point representations to facilitate various downstream tasks. To show the power of the proposed method, the authors designed two algorithms based on on it for node classification ( with missing attributes ) and matrix completion respectively, and demonstrate their effectiveness in experiments."
SP:aeeb5909f7123ef631f569b469af9715205c881f,"This paper proposes a new method for goal - conditioned reinforcement learning ( RL ) in environments with sparse extrinsic rewards. The proposed method, AMIGO, is a novel agent that combines a goal - generating teacher and an intrinsic motivation agent. The teacher learns to propose increasingly challenging and achievable goals for the student agent to learn. The student agent learns to solve the teacher's goals in a self - supervised manner. The authors show that the proposed method generates a natural curriculum of self - defined goals which ultimately allows the agent to solve challenging challenging procedurally - generated tasks. They also show that their method outperforms other intrinsic motivation and state - of - the - art RL methods."
SP:3d05bc7dca97681cb582298e318b9b973841eed3,"This paper studies the problem of private information retrieval from a dataset of files stored on a single server under both a user distortion and a user privacy constraint. The privacy requirement is that the user should be able to reconstruct the requested file with a prescribed distortion, and the identity of the retrieved file should be kept private from the server. The proposed method can be seen as an extension of the well - known concept of generative adversarial information retrieval, which allows for distortion in the retrieval process and relaxes the perfect privacy requirement. The authors initiate the study of the tradeoff between the rate - distortion - leakage tradeoff and the optimal rate - leaky - leakage tradeoff, and show that in the limit of large file sizes this allows for a concise information - theoretical formulation in terms of mutual information. They evaluate the performance of the scheme on a synthetic Gaussian dataset as well as on the MNIST and CIFAR-10 datasets."
SP:3f9e2db00fc3dcd7a40588adcb638503ec10dc09,This paper proposes a decoupled greedy learning method for graph neural networks ( GNNs ) that decouples the GNN into smaller modules and associates each module with greedy auxiliary objectives. The authors propose a lazy - update scheme during training to further improve its efficiency. The proposed method is compared with several sampling - based acceleration methods on a range of benchmark datasets. The results demonstrate the effectiveness and superior efficiency of the proposed method.
SP:5ecb1b288f7fc02aead4493f81640867bc349290,"This paper proposes a framework for answering complex queries on incomplete Knowledge Graphs using neural link predictors. Each query is converted into an end - to - end differentiable objective, where the truth value of each atom is computed by a pre - trained neural link predictor. The paper proposes two solutions to the optimisation problem, including gradient - based and combinatorial search, and evaluates them on a large dataset of incomplete knowledge graphs. The results show that the proposed method outperforms state - of - the - art methods with orders of magnitude less training data. The authors also provide an explanation of the outcome of the model in terms of the intermediate solutions identified for each of the complex query atoms."
SP:f04a522fd04c503754fdb8c52da68646d31271a4,"This paper proposes a method for checking the local robustness of neural networks with piecewise - linear activation functions. Local robustness is defined as the ability of a neural network to classifies all inputs within an $ \ell_p$-ball consistently, which precludes various forms of adversarial inputs. The authors show that such networks partition the input space into a set of convex polyhedral regions, in which the network ’s behavior is linear, and hence a systematic search for decision boundaries within the regions around a given input is sufficient for assessing robustness. Crucially, the region around a point can be analyzed using simple geometric projections, thus admitting an efficient, highly - parallel GPU implementation that excels particularly for the `2 norm, where previous work has been less effective."
SP:5297651ff873f97c07b9c47ed3eff52251661844,"This paper proposes an approach to embed objects in an affordance space, in which each dimension corresponds to an aspect of meaning shared by many actions, using text corpora. This embedding makes it possible to predict which verbs will be applicable to a given object, as captured in human judgments of affordance, better than a variety of alternative approaches. Furthermore, they show that the dimensions learned are interpretable, and that they correspond to typical patterns of interaction with objects. Finally, the dimensions can be used to predict a state - of - the - art model that predicts a state of the art for predicting a state, derived purely from human judgements."
SP:72b4f3b40c6c6fa2eb53e95ed9a10a4077ffa049,"This paper proposes EOI, a method for the emergence of individuality in multi - agent reinforcement learning ( MARL ). The proposed method learns a probabilistic classifier that predicts a probability distribution over agents given their observation and gives each agent an intrinsic reward of being correctly predicted by the classifier. The intrinsic reward encourages the agents to visit their own familiar observations, which makes the intrinsic reward signals stronger and in turn makes the agents more identifiable. Two regularizers are proposed to increase the discriminability of the classifiers. Empirically, the proposed method is shown to outperform existing MARL methods in a variety of scenarios."
SP:112509d6d3573a9d495d182fdfae6ec0327cddf5,"This paper proposes SWEEN ( Smoothed Weightsighted - Normalized - Ensembling ), a randomized smoothing method that aims to improve the performance of randomized smoothed classifiers in the face of l2 - norm adversarial attacks. The authors show the generality of the proposed method and provide theoretical analysis on how to find the optimal base classifier. They also develop an adaptive prediction algorithm to reduce the prediction and certification cost. Extensive experiments have been conducted to demonstrate the effectiveness of the method."
SP:ea892e3d199ed6121279b20061a87f43afae8796,"This paper proposes a method to learn a hierarchy of subtask tasks by learning from demonstrations. The method is based on the Ordered Memory Policy Network ( OMPN ), a model that learns a memory policy for each subtask in a demonstration. The main idea is to decompose the task into sub - tasks and learn a task decomposition network to recover the subtask boundaries in an unstructured demonstration setting. Experiments on Craft and Dial demonstrate that the proposed method can recover the task boundaries in both unsupervised and weakly supervised settings. It can also be directly applied to partially observable environments and achieve higher task decompositon performance."
SP:cc6aa977ce561a2493ae74bb694205cd67c8d890,"This paper proposes a Causal Semantic Generative model ( CSG ) for out - of - distribution ( OOD ) prediction. The CSG is based on causal reasoning to separate the effects of semantic and variation factors. The authors propose a variational Bayes method for training the model. Theoretically, the authors prove that under certain conditions, the semantic factor can identify the variation factor by fitting training data, and this semantic - identification guarantees the boundedness of OOD performance. Experiments show that the proposed CSG outperforms existing OOD prediction methods."
SP:be3f34a59e5e61dcdbc7cb085f031ba4a5a5b758,"This paper studies the problem of online learning in the setting where the reward distribution of the reward function can be arbitrarily corrupted with probability $ \mathbb{R}^p \in [ 0,12)$ with respect to the true reward distribution $ p(y|x, z)$, and the regret of the algorithm needs to be small relative to $ \sqrt{P}(Y|z)$ where $ y$ is the true $ p$ and $ z$ is a random variable.   The authors consider three settings : stochastic multi - armed bandits, linear contextual bandits, and Markov Decision Processes ( MDPs ). In each of the three settings, the authors design an algorithm with near optimal regret in the sense that its regret is smaller than $ \epsilon^{-1}^{-2}$ in the true uncorrupted reward distribution. The authors also provide empirical evidence regarding the robustness of their proposed algorithms on synthetic and real datasets."
SP:6d62a80aaebb2988df3953d4d7164e5a2fa1aa6d,"This paper proposes a termination mechanism for neural machine translation ( NMT ). The termination mechanism consists of a rewriter and an evaluator. The rewriter produces a new translation to improve the past translation and the evaluators estimates the translation quality to decide whether to terminate the rewriting process. The paper also proposes a prioritized gradient descent ( PGD ) method to train the rewriter jointly. The experiments on two translation tasks, Chinese - English and English - German, show that the proposed framework notably improves the performances of NMT models."
SP:9761fca8848868dfc9cacdab2537f8276ca76e0f,"This paper proposes a two - stage method for learning multi - modal predictive distributions for semantic segmentation. The first stage learns a categorical likelihood of the categorical labels of the data, and the second stage uses an adversarial network to sample from it an arbitrary number of coherent predictions. The authors demonstrate the utility and versatility of the approach by demonstrating the state - of - the - art results on the CIFAR-10/100 dataset and a modified Cityscapes dataset. They also show the utility of toy regression dataset to show that the proposed method can be adapted to other tasks requiring learning a calibrated predictive distribution."
SP:ce965758f1b795a56c02f45d6a8d06cb8bdf29cb,"This paper proposes a communication - based communication with error feedback ( EF ) method to deal with the error induced by contractive compressors. The main idea is to transform any contractive compressor into an induced unbiased compressor. Theoretically, the authors show that this construction can be applied to existing communication based communication methods such as Top - K or PowerSGD. Experiments are conducted to show the effectiveness of the proposed communication based EF method."
SP:4fd702490293e481c79614852ba27dd3ce9215a4,This paper proposes a new research framework for hyperparameter transfer across adjustments ( HT - AA ) to speed up the development of machine learning ( ML ) algorithms. The goal is to transfer knowledge from an old HPO to speedup a new HPO that is being developed at the same time. The authors provide four simple HT - AAA baseline algorithms and eight benchmarks to lay a solid foundation for this research framework. They also provide python packages for our baselines and benchmarks to make these benefits available to ML developers.
SP:e8f99bae5853de525450fcb8facd23cf973fc161,"This paper studies the effect of label representation on the performance of image classification models. The authors propose to use high dimensional, high entropy label representations to represent the data. They show that high dimensional label representations provide a stronger error signal than simpler numerical probabilities or text labels. They also show that features learned through label representations exhibit more robustness under various adversarial attacks and better effectiveness with a limited amount of training data.   The paper is well organized and easy to follow."
SP:4e8d924cba7367af0999b30d79250b4dc40413e1,"This paper proposes an ensemble learning method for neural networks. The main idea is to train a single model with multiple subnetworks, each of which takes as input one prediction from the full model and returns a prediction from a subnetwork that is used to make the final prediction. The goal is to improve model robustness and uncertainty performance without increasing the number of parameters in the full network. The authors propose a multi - input multi - output ( MIMO ) configuration of the network, where the output of each subnetwork is aggregated with the input of another subnetwork, and the predictions of the subnetwork are used in the final model's forward pass. The results show that the benefits of using multiple predictions can be achieved with a negligible gain in parameters over the original network's parameters without the use of multiple forward passes."
SP:d2f1c23b67c6744101034dc5e1c70765a733b169,"This paper proposes a method for sparse representation matching between two convolutional neural networks ( CNNs ), where the goal is to transfer intermediate knowledge obtained from one CNN to another by utilizing sparse representation learning. The proposed method first extracts sparse representations of the hidden features of the teacher CNN, which are then used to generate both pixel - level and image - level labels for training intermediate feature maps of the student CNN. The authors formulate SRM as a neural processing block, which can be efficiently optimized using stochastic gradient descent and integrated into any CNN in a plug - and - play manner. The experiments demonstrate that SRM is robust to architectural differences between the teacher and student networks, and outperforms other KD techniques across several datasets."
SP:e8c0f43bd5debf6544f588cd3442dc3dd62d0eee,"This paper proposes a method for learning policy representations that generalize well to unseen environments by leveraging the sequential nature of reinforcement learning. The main idea is to use a theoretically motivated policy similarity metric ( PSM ) for measuring behavioral similarity between states. The PSM assigns high similarity to states for which the optimal policies in those states as well as in future states are similar. The authors also present a contrastive representation learning procedure to embed any state similarity metric, which they instantiate with PSM, to obtain policy similarity embeddings ( PSEs ). The proposed method is evaluated on a number of benchmarks, including LQR with spurious correlations, a jumping task from pixels, and Distracting DM Control. The results show that the proposed method outperforms the baselines on all benchmarks."
SP:92f3b4942da9075440dda618f561a85f8fde5a5c,"This paper proposes distributed equivariant operators ( DA ), a disentangling approach to disentangle natural factors of variation in data ( e.g. object shape vs pose ) that relies on learning to map each of these factors to distinct subspaces of a model ’s latent representation. This approach has shown limited empirical success to date. The authors show that it introduces discontinuities in the encoder for a broad family of transformations acting on images, including simple affine transformations such as rotations and translations. Moreover, motivated by classical results from group representation theory, the authors propose an alternative, more flexible, and theoretically and empirically demonstrate the effectiveness of the proposed DA approach."
SP:ef0f58c462bc5dd1c7b78f562c42a4e17f0f252b,"This paper proposes an EM algorithm for the nonlinear Hawkes process ( HP ), a statistical framework for analyzing the timedependent interaction of neuronal spiking activities. Three auxiliary latent variables ( Pólya - Gamma variables, latent marked Poisson processes and sparsity variables ) are augmented to make functional connection weights in a Gaussian form, which allows for a simple iterative algorithm with analytical updates. The authors demonstrate the accuracy and efficiency performance of their algorithm on synthetic and real data.    The main contribution of this paper is the development of EM algorithm that can estimate the maximum a posteriori ( MAP ) estimate of the temporal dynamics of interaction and reveal the interpretable functional connectivity underlying neural spike."
SP:1156d3deac022829bda930ffcb081947609d972b,"This paper studies the gradient descent ( GD ) algorithm for training two - layer neural network models in the under - parameterized regime. The authors show that there are two distinctive phases in the GD dynamics in this regime : an early phase in which the dynamics follows closely that of the corresponding random feature model, followed by a late phase where the neurons are divided into two groups : a group of “activated ” neurons that dominate the dynamics and a group “quenched ” neuron that support the continued activation and deactivation process. In particular, when the target function can be accurately approximated by a relatively small number of neurons, this quenching - activation process biases GD to picking sparse solutions. This is qualitatively different from the dynamics associated with the “mean - field ” scaling where all neurons participate equally."
SP:9e81401a6f30c70d870a12cce0cf600557f92b80,"This paper proposes a method to decompose a CMDP problem into a reconnaissance MDP ( R - MDP ) and planning MDPs. In the reconnaissance part, a threat function is used to determine whether a given state - action pair is safe or not ; in the planning part, the agent trains a reward - seeking policy while using a fixed threat function to determine the reward. The authors also present an efficient approximation method for the threat function that can greatly reduce the difficulty of solving the problem. They demonstrate the efficacy of their method over classical approaches in benchmark dataset and complex collision - free navigation tasks."
SP:f1d4ac7d5516dd0df742e224c8c09c721d0d0886,"This paper challenges the widely - held belief that cross - entropy loss is better than square loss for deep learning. The authors explore several neural architectures and benchmark datasets for NLP, automatic speech recognition ( ASR ) and computer vision tasks to show that these architectures, with the same hyper - parameter settings as reported in the literature, perform comparably or better when trained with the square loss, even after equalizing computational resources. They argue that there is little compelling empirical or theoretical evidence indicating a clear - cut advantage to the cross-entropy loss. Furthermore, training with square loss appears to be less sensitive to the randomness in initialization, and the authors posit that training using square loss needs to be a part of best practices of modern deep learning on equal footing with cross - self - entropy."
SP:915f1f0fc4850507c28c1d609239b41775863ebe,"This paper proposes to use self - supervised learning to improve sample - efficient deep RL from pixels by augmenting reward maximization with the self - predictive representation based on structure in the agent's visual input and sequential interaction with the environment. The proposed method, called Self - Predictive Representations ( SPR ), trains an agent to predict its own latent state representations multiple steps into the future using an encoder which is an exponential moving average of the agent ’s parameters and makes predictions using a learned transition model. On its own, this future prediction objective outperforms prior methods and SPR is further improved by adding data augmentation to the future prediction loss, which forces the agent to be consistent across multiple views of an observation. SPR achieves a median human - like score of 0.415 on Atari in a setting limited to 100k steps of environment interaction and exceeds expert human scores on 7 out of 26 games."
SP:983f01c170909c8c67fd3be25f121bd61bdd8307,"This paper proposes a local node embedding method based on Personalized PageRank ( PPR ) for unsupervised representation learning of graphs. The method is based on local PageRank computations on the node embeddings, which are globally consistent in sublinear time. The proposed method is shown to be 9,000 times faster than the state - of - the - art baselines in terms of both clock time and memory consumption. It is also shown to require significantly less computation time and significantly less memory compared to DeepWalk, node2vec, VERSE, and FastRP. Extensive experiments on real - world datasets with over a billion edges show that the proposed method produces high quality representations on par with the state of the art."
SP:d11037b8fe2b10aee672ba82f69410b40181f0f9,This paper proposes a data - driven method for graph coarsening based on graph neural networks. The main idea is to train a graph neural network ( GNN ) to learn the Laplace operator on the graph and the associated projection / lift operator. The GNN is trained on both synthetic and real graphs. The proposed method is evaluated on a number of graph datasets and compared with several existing methods. The results show that the proposed method significantly outperforms the existing methods in most cases.  
SP:0d680213339f0e2aedb0be4aeed51423706b8bf6,"This paper presents a geometric deep learning algorithm based on discrete - laplacian and implicit encoders to compute the acoustic characteristics of general 3D objects at interactive rates. The method uses a point cloud approximation of each object, and each point is encoded in a high - dimensional latent space. The acoustic properties can accurately estimate these acoustic properties for arbitrary topologies and take less than 1ms per object on a NVIDIA GeForce GeForce 2080 Ti GPU. The authors also prove that the learning method is permutation and rotation invariant and demonstrate high accuracy on objects that are quite different from the training data."
SP:afc33a782c43e3d4c5c4fbf047d0b1108bc30bae,"This paper proposes Risk Extrapolation ( REx ), a method for reducing the model sensitivity to extreme distributional shifts. The main idea is to reduce the difference in risk across training domains by applying REx on a set of extrapolated domains. The authors propose a penalty on the variance of training risks ( V - Rex ) and show that variants of REx can recover the causal mechanisms of the targets, while also providing some robustness to changes in the input distribution. The proposed method is shown to outperform alternative methods such as Invariant Risk Minimization ( IRM ) in situations where these types of distribution shifts are more severe."
SP:411d5bcf7698d534ad60f581d479ff74849ba4de,"This paper proposes a neural operator for partial differential equations ( PDEs ) that parameterizes the integral kernel directly in Fourier space. The proposed Fourier neural operator is the first ML - based method to successfully model turbulent flows with zero - shot super - resolution. It is up to three orders of magnitude faster compared to the traditional PDE solvers. Additionally, it achieves superior accuracy compared to previous learning - based solvers under fixed resolution."
SP:41d268d0eac9b4c84baa156fb641aa6d3060b5a4,"This paper studies the implicit bias of gradient flow on linear neural network training. The authors propose a tensor formulation of neural networks that includes fully connected, diagonal, and convolutional networks as special cases, and investigate the linear version of the formulation called linear tensor networks. With this formulation, the authors can characterize the convergence direction of the network parameters as singular vectors of a tensorsor defined by the network. For L - layer linear Tensor networks that are orthogonally decomposable, the gradient flow finds a stationary point of the $ \ell_2 $ and $ L$-max margin problem in a “ transformed ” input space. For underdetermined regression, the paper proves that gradient flow find a global minimum which minimizes a norm - like function that minimizes the difference between the transformed input space and the original input space in a separable classification setting."
SP:e27907ef4a4e6e0f5841618fcaa7e7e0db443f91,"This paper proposes a method for optimizing slimmable neural networks from a multi - objective optimization lens, which allows for heterogeneous width - multipliers across different layers. The method is motivated by the fact that different layers affect the network ’s prediction accuracy differently and have different FLOP requirements. The proposed method is evaluated on 15 different network and dataset combinations and two types of cost objectives, i.e., two - cost objectives and two - layer cost objectives. The experiments demonstrate the effectiveness of the proposed method compared to existing alternatives in terms of accuracy, FLOPs and memory footprint."
SP:cf59403abb6ca89ccee4f8e77e9a33d99e6a00f5,"This paper proposes a federated semi - supervised learning ( FSSL ) framework for learning from labeled and unlabeled data. The main idea of FSSL is to train a model on labeled data at the server and then match it with the labeled data of clients. The proposed method is based on FedMatch, which combines FedLoss and FedMatching. The experiments show that the proposed FedMatch outperforms FedMatch in two different federated learning scenarios.  "
SP:9457b6d430a2cd864d526d7e90bf3e1ab13d6df4,"This paper proposes a self - supervised learning method for discrete event sequences. The proposed method, CoLES, uses contrastive learning to learn a low - dimensional fixed - length vector representation of the discrete event sequence. The authors show that the augmentation method underlying CoLES provides representative samples of discrete events sequences. They evaluate CoLES on several public datasets and show that CoLES representations consistently outperform other methods on different downstream tasks."
SP:385942a5bcee7384bb722a1669b541f2fac0cd36,"This paper proposes a new unsupervised dependency parsing framework that can jointly generate constituency tree and dependency graph. The proposed framework is based on the StructFormer model, which induces dependency grammar and constituency structure at the same time. The authors propose a dependency - constrained self - attention mechanism to integrate the induced dependency relations into transformer, in a differentiable manner, through a novel dependency - constraint mechanism. The experimental results show that the proposed StructFormer can achieve strong results on un supervised dependency parsing, unsupervied dependency parsing and masked language modeling."
SP:078966ff62775bba6031e47d374bda95f4a7dde3,"This paper proposes a method for learning object - centric representations from images. The proposed method is based on graph - based representation learning with object - based grounding. In particular, the proposed method learns a metric among visual objects and scene graph nodes by incorporating information from both object features and relational features. Extensive experiments on Visual Genome ( VG ) and Visual Relation Detection ( VRD ) datasets verify that the proposed model post an improvement on scene graph grounding task over current state - of - the - art approaches. Further experiments are conducted for scene graph parsing task to verify the grounding found by the model."
SP:4644dbf7466b6234d8abf69995fdfb357efcc119,"This paper proposes two variants of the RAE framework, one based on a mixture of von Mises - Fisher distributions and the other based on power spherical fused Gromov - Wasserstein ( PSSFG ). The first variant, called MSSSFM, replaces the vMF distribution by a power spherical distribution to improve the sampling time in high dimensional settings. The second variant is based on the power spherical sliced fused gromov wasserstein. The authors conduct extensive experiments to show that the new proposed autoencoders have favorable performance in learning latent manifold structure, image generation, and reconstruction."
SP:5ae2c0af82cac89a65f1cc38c43e2d05ea298901,"This paper proposes an adaptive untying criterion to speed up training for a particular kind of deep networks which contain repeated structures, such as the transformer module. The authors first train such a deep network with the weights shared across all the repeated layers till some point, then stop weight sharing and continue training until convergence. The untying point is automatically determined by monitoring gradient statistics. Empirical results show that the proposed method is able to reduce the training time of BERT by 50 %."
SP:a51710551142316b67e2fccd969fea1ece35ba39,"In this paper, the authors study the interaction inside adversarial perturbations to explain and boost the adversarial transferability of adversarial attacks. They show that interactions inside adversarially perturbed inputs can be used to improve adversarial attack transferability. They further show that the interaction in adversarial training can also be used as a unified perspective to understand current transferability - boosting methods. Based on this, they propose to penalize interactions during the attacking process, which can significantly improve the adversariate transferability, by penalizing interactions inside the perturbation."
SP:f1565319075c1442c2cb52d96443facb492c06c2," forgetting is a recurring challenge in the field of machine learning. This paper studies the relationship between the forgetting of deep neural networks ( DNNs ) and task semantics. The authors show that the deeper the DNN layers, the more likely it is to forget the previous task - specific representations. They also show that there are two types of forgetting patterns : ( 1 ) Maximum forgetting, where the forgetting is maximal for a sequence of tasks with high similarity, and ( 2 ) Deep encoder - deep decoder, where deep encoder layers tend to forget task specific features. The paper also proposes several methods to mitigate this forgetting behavior."
SP:30d7532cdcf420bff3be6b92eea3d93bce59e6bd,"This paper proposes an efficient training method for BERT. The proposed method is based on the idea of "" early bird lottery tickets "", which was recently introduced for computer vision tasks. The authors apply the proposed method to both pre - training and fine - tuning of large - scale language models such as BERT, XLNet and T5, and show that it achieves comparable performance to standard BERT with 35 % less training time. The paper is well - written and easy to follow."
SP:c547f23ff6caaf5e9f35d258490b86ae0ac8ed03,"This paper studies the robustness of f - divergences ( f - divergence functions ) in the context of supervised learning with noisy labels.   The authors derive a nice decoupling property for a family of robustness measures that decouples the variational difference from the bias term introduced due to the noise in the label noise setting. The authors show that the divergence is a linear combination of the prior on the clean distribution and a bias term added due to label noise. The paper then proposes a robustness metric that maximizes the divergence between the true variational distribution and the one obtained by adding bias term and shows that it is robust to noisy labels in this setting. When the proposed robustness measure is not robust, the authors propose two fixes to make it so. The first fix is based on the fact that the variance of the proposed measure is the sum of the variances of the two variational distributions. The second fix uses a regularization term to ensure that the two variances are decoupled in the noisy setting."
SP:841888179dcdac901889c8d62cb5234311fe28f1,"This paper proposes an ensemble - based method for re - weighting Bellman backups in off - policy deep reinforcement learning ( RL ). The proposed method re - weights target Q - values based on uncertainty estimates from an ensemble of Q - individuals. The authors show that the proposed method stabilizes and improves learning on both continuous and discrete control benchmarks. The paper also specifically investigate the signal - to - noise aspect by studying environments with noisy rewards and find that the re - weighted bellman backups significantly outperform the standard Bellman backup. Finally, the authors investigate how the proposed re -weighting method interacts with UCB Exploration by UCB using Bootstrap."
SP:afc08f203562b841180811aef943bfb63a1659ea,This paper proposes a method for estimating the distributional mismatch between support and query sets of a few - shot classification model via class - wise similarities. The method is algorithm - agnostic and can be easily extended to a range of meta - learning models. The authors also propose a novel meta - training strategy to help the model avoid being indiscriminately confident. The experimental results show that the proposed method is able to produce calibrated classification results without the loss of accuracy.
SP:12ae325ea3bce1e60195afac7d85895d2d20c29c,"This paper proposes a new method for learning video - text - to - video representations. The proposed method is based on noise contrastive learning ( NCL ), which is the current dominant paradigm in the field. NCL encourages the similarity of the representations of pairs of samples that are known to be related and pushes away dissimilar pairs. The authors argue that this behaviour is too strict, enforcing dissimilar representations even for visually similar videos or ones that share the same depicted action. To alleviate this problem, the authors propose a generative model to naturally push these related samples together : each sample ’s caption must be reconstructed as a weighted combination of other support samples ’ visual representations. This simple idea ensures that representations are not overly - specialized to individual samples, are reusable across the dataset, and results in representations that explicitly encode semantics shared between samples. The method outperforms others by a large margin on MS - R - VTT, VATEX, and MSVD."
SP:8a71d8fad25a126aff01431cacf348c05de75667,"This paper proposes a novel method, seg tok, to form the vocabulary of Chinese BERT, with the help of Chinese word segmentation ( CWS ) and subword tokenization. It also proposes three versions of multi - vocabulary pretraining ( MVP ) to improve the performance of the masked language model pre - training. The effectiveness of the proposed MVP is evaluated on a variety of Chinese language modeling tasks. The results show that the proposed method improves the performance on most of the tasks. However, there are some issues with the MVP method, especially in the downstream tasks."
SP:b93ec7bc02b48068073ffe705f71d2643e663d51,"This paper proposes a new distributed GCN training method that adopts an unbiased boundary sampling strategy to enable efficient and scalable distributed GCNs training while maintaining the full - graph accuracy. The proposed method is based on Graph - Based Boundary Sampling ( BDS ). The authors show that the proposed method can improve the throughput by up to 500 % and reduce the memory usage by up - to 58 % for distributed training, as compared with the state - of - the - art methods.  "
SP:2d4ba873d11e969ebd1fc31f9b5ab450c964d154,"This paper presents a graph neural network ( GNN ) based quantum chemistry model for accurate and fast quantum chemistry simulations. The key challenge is to accurately capture highly complex and non - linear quantum interactions of atoms in 3D space, on which forces are dependent. To this end, this paper adopts expressive message passing architecture, graph neural networks, and appropriate choice of basis and nonlinear activation functions. Experiments show that the proposed method is able to achieve 4x higher success rate than existing ML models in the large - scale catalyst dataset."
SP:8bdcf4fe6abf4739d4732b7ea8538513135dcccc,"This paper proposes a generalization bound for neural networks based on the Rademacher complexity of the weights. This bound has no dependence on the number of weights and compares favourably to other bounds when applied to convolutional networks. Inspired by this bound, the authors develop a simple yet effective fine - tuning algorithm that constrains the hypothesis class to a small sphere centred on the initial pre - trained weights, thus obtaining provably better generalisation performance than conventional transfer learning. Empirical evaluation shows that the proposed method works well, and the authors show that it is not directly constrain the radius of the search space."
SP:3a3249e97ef2345ea2264de5ed8287e16687838e,"This paper studies the phenomenon of "" decoupled find - evaluation phenomenon "", where a training configuration that yields worse performance actually yields a mask that trains to higher performance. The paper decouples the hyperparameters for mask discovery ( Hfind ) and mask evaluation ( Heval ) using unstructured magnitude pruning on vision classification tasks. It shows that certain Hfind values lead to models that have lower performance but generate masks with substantially higher eventual performance compared to using the same hyperparameter for both stages. It also shows that different H find values yield masks with materially different layerwise pruning ratios and that the find -eval phenomenon is causally mediated by these ratios."
SP:2d6f5d72b21675f74ff4cde4d16bfb36abd5795f,"This paper proposes a new metric ( m - coherence ) to measure the alignment of per - example gradients during training of deep learning models. The metric is based on the observation that the number of examples in a sample that benefit from a small step along the gradient of any one example on average is $ m$-coherence, which is a measure of how likely is each example to benefit from such a small gradient step on average. The authors show that this metric is more interpretable, cheaper to compute, and mathematically cleaner than other commonly used metrics ( e.g. $ \mathcal{O}(\sqrt{m})$, $ \Omega(m)$ and $ O(m^2)$, and show that it is closely connected to gradient diversity.   The authors experimentally study the evolution of alignment of $ m_coherence$ for ResNet and EfficientNet models on ImageNet and several variants with label noise, and they show that m _ coherence reaches moderately high values during training ( though still much smaller than real labels ) indicating that over - parameterized neural networks find common patterns even in scenarios where generalization is not possible. They also provide both a deeper confirmation of CG, but at the same point puts into sharp relief what is missing from the theory in order to provide a complete explanation of generalization in neural networks."
SP:e7c5de9a475d0ba71bc79580e8436024fb2c6f59,"This paper considers the problem of automatically constructing sufficient statistics for implicit generative models where the evaluation of the likelihood function is intractable but sampling data from the model is possible. The authors frame the problem as learning mutual information maximizing representations of the data with the help of deep neural networks. The infomax learning procedure does not need to estimate any density or density ratio. The paper applies the approach to both approximate approximate Bayesian computation and recent neural likelihood methods, boosting their performance on a range of tasks."
SP:c5997bf2348e94949684f45fbd418661e85220c1,"This paper proposes a fully unsupervised image - to - image translation model ( TUNIT ) that simultaneously learns to separate image domains and translate input images into the estimated domains. The proposed model is trained with full labels and generalizes well on various datasets, and is robust against the choice of hyperparameters ( pseudo domains ). The experimental results show that the proposed model achieves comparable or even better performance than the set - level supervised model."
SP:0cd97e64e638cabbeea0fdef3e9c5b33f4000f72,"This paper studies gradient descent training of wide neural networks and the corresponding implicit bias in function space. In particular, it shows that the solution of training a width - n shallow ReLU network is within n-1/2 of the function which fits the training data and whose difference from initialization has smallest 2 - norm of the weighted second derivative with respect to the input. The curvature penalty function 1/\� is expressed in terms of the probability distribution that is utilized to initialize the network parameters, and they compute it explicitly for various common initialization procedures. The solution function is the natural cubic spline interpolation of training data. While similar results have been obtained in previous works, this analysis clarifies important details and allows us to obtain significant generalizations."
SP:8b885142facbb3b8db41ec9d83822cee81324694,"This paper proposes a method to fix the unstable weight decay in Adam using Stable Weight Decay ( SWD ). The main idea of SWD is to replace the L2 regularization in Adam with the SWD regularization, which is more stable. The authors show that SWD has two main advantages over L2 : ( 1 ) SWD can be applied to any adaptive gradient method that uses momentum, such as stochastic gradient descent ( SGD ), and ( 2 ) it does not require extra hyperparameters like L2 and decoupled weight decay."
SP:a3206dc71e32ba1830895bf442d3840f3331a532,This paper proposes a method to combine the strengths of both Translation Memory ( TM ) and Neural Machine Translation ( NMT ). The main idea is to treat the matched sentence pair of TM as the additional signal and apply one encoder enhanced by the pre - trained language model ( PLM ) to encode the TM information and source sentence together. The authors also extend the sentence level retrieval method to the n - gram retrieval method that is used in the PLM language model. The experiments show that the proposed method can significantly improve the translation quality and show strong adaptation for an unknown or new domain.
SP:72b43991a242872b2ceb1861e8ffbdf26c9f4818,"This paper tries to interpret modern deep convolutional networks from the principles of rate reduction and ( shift ) invariant classification. The authors show that the basic iterative gradient ascent scheme for maximizing the rate reduction of learned features naturally leads to a deep network, one iteration per layer, where architectures, operators, and parameters of the network are all explicitly constructed layer - by - layer in a forward propagation fashion. All components of this “ white box ” network have precise optimization, statistical, and geometric interpretation. The preliminary experiments indicate that such a network can already learn a good discriminative deep representation without any back propagation training. Moreover, all linear operators of the so - derived network naturally become multi - channel convolutions when we enforce classification to be rigorously shift - infariant."
SP:f8b02cf1b918b0956761829ec6ef9127596071ec,"This paper studies the implicit acceleration of gradient flow in over - parameterized two - layer linear models. The authors show that implicit acceleration emerges from a conservation law that constrains the dynamics to follow certain trajectories. More precisely, gradient flow preserves the difference of the Gramian matrices of the input and output weights and the amount of acceleration depends on both the magnitude of that difference ( which is fixed at initialization ) and the spectrum of the data. In addition, and generalizing prior work, the authors prove their results without assuming small, balanced or spectral initialization for the weights, and establish interesting connections between the matrix factorization problem and Riccati type differential equations."
SP:e5f086c806be88d50e461a782b5b00124f4656fb,"This paper proposes CLIME, a framework for generating interpretable explanations of a machine learning model that is robust to out - of - distribution ( OOD ) sampling and adversarial attacks. The framework is based on uniform sampling of user - defined sub - instances of the model and a surrogate interpretable model, which is trained to be locally faithful on perturbed instances. The paper also proposes an efficient estimation algorithm that is able to certifiably measure the true value of metrics such as fidelity up to any desired degree of accuracy, which can help in building trust in the generated explanations. Experiments show that the proposed CLIME framework can be applied to any ML model, and extensive experiments demonstrate its versatility on real - world problems."
SP:b1d5ef15772e192eb8c8a0e65b3c21ee7c794295,"This paper proposes a multi - grained language model ( AMBERT ), which learns representations of both fine and coarse tokenizations of pre - trained language models on the basis of both contextualized representations of words and sequences of contextualized phrases. The main idea is to use two encoders : one for processing the sequence of words, and one for generating the contextualized representation of the phrase. The model is trained on standard NLU benchmarks in Chinese and English, including CLUE, GLUE, SQuAD, and RACE. The results show that the proposed method outperforms the existing best performing models in almost all cases, particularly the improvements are significant for Chinese. The paper also proposes a variant that uses half of the model's inference time."
SP:fd1cfe80343d3789227d99d836a5674374a234f5,"This paper proposes a new Transformer - based model for semantic parsing. The main idea is to incorporate Long Short - Term Memory ( LSTM ) into the Self - Attention mechanism of the original Transformer to capture more local context of phrases. Experimental results show that the proposed model captures the detailed meaning better than Transformer, raises local context awareness and achieves strong competitive performance on Geo, M - SOT and Atis datasets."
SP:2056a65a7500d79465685af883083cd706277c1f,"This paper proposes a composite adversarial training ( CAT ) method to improve the robustness of deep neural networks ( DNNs ) against adversarial perturbations. The main idea is to train a model with multiple adversarial losses, such that the model is robust to both individual perturbation models as well as compositions of them. The proposed method is evaluated on CIFAR-10 and ImageNet and compared with a number of baselines. The results show that CAT outperforms the baselines in most cases."
SP:006e5b9ac9a8eb7223843731488bfefbd8eb09bd,"This paper proposes a new recurrent neural network architecture for learning abstract rules. The proposed method, called Emergent Symbol Binding Network ( ESBN ), is a recurrent network augmented with an external memory that enables a form of variable - binding and indirection. This binding mechanism allows symbol - like representations to emerge through the learning process without the need to explicitly incorporate symbol - processing machinery, enabling the ESBN to learn rules in a manner that is abstracted away from the particular entities to which those rules apply. The authors show that this architecture displays nearly perfect generalization of learned rules to novel entities given only a limited number of training examples, and outperforms a number of other competitive neural network architectures."
SP:4171ce45966ac499f51450a19fb233934c0847f0,"This paper proposes a new framework, Translation between Augmented Natural Languages ( TANL ), to solve many structured prediction language tasks including joint entity and relation extraction, nested named entity recognition, relation classification, semantic role labeling, event extraction, coreference resolution, and dialogue state tracking. Instead of tackling the problem by training task - specific discriminative classifiers, the proposed framework frames it as a translation task between augmented natural languages, from which the task - relevant information can be easily extracted. The proposed framework can match or outperform task-specific models on all tasks, and achieves new state - of - the - art results on several tasks."
SP:8f1b2fc6829e0bdfcc981020b0dcf3e63a947910,"This paper studies the problem of unlabeled entity problem in NER ( entity recognition ) models, where the entities of a sentence may not be fully annotated. The authors identify two causes of performance degradation of NER models. One is the reduction of annotated entities and the other is treating unlabelled entities as negative instances. The first cause has less impact than the second one and can be mitigated by adopting pretraining language models, while the second cause seriously misguides a model in training and greatly affects its performances. Based on the above observations, the authors propose a general approach, which can almost eliminate the misguidance brought by unlabelling entities. The key idea is to use negative sampling that, to a large extent, avoids training NER model with unlabeled entities. Experiments on synthetic datasets and real - world datasets show that the proposed method is robust to unlabelED entity problem and surpasses prior baselines."
SP:dd76ece8d92a8a230a8b43033d8cb2368c677a94,"This paper proposes an acoustic word embedding method based on stochastic neighbor embedding ( SNE ), which maps a vector space of fixed, reduced dimensions to a sequence of embeddings. Two encoder neural networks are trained : an acoustic encoder that accepts speech signals in the form of frame - wise subword posterior probabilities obtained from an acoustic model and a text encoder using subword transcriptions. The Euclidean distance between coordinates in the embedding space reflects the phonetic confusability between corresponding sequences. Compared to a triplet loss criterion, the proposed method is shown to have more effective gradients for neural network training, and it also gives more accurate results with low - dimensional embedding when the two encoder networks are used in tandem in an approximate phonetic matching task, and when the other encoder network is used standalone in an acoustic matching task."
SP:9142189126b8612ac0acee6fe18a0cfcb70b6545,"This paper proposes a reinforcement learning algorithm for stationary mean - field games, where the goal is to learn a pair of mean field state and stationary policy that constitute the Nash equilibrium. The authors propose a fictitious play algorithm that alternatively updates the mean state and the policy via gradient - descent and proximal policy optimization, respectively. The algorithm is in stark contrast with previous literature which solves each single - agent reinforcement learning problem induced by the iterative updates of both mean and policy. Theoretically, the authors prove that the proposed algorithm converges to the Nash equilibria at a sublinear rate. This seems to be the first provably convergent RL algorithm for mean field games."
SP:c498f8a199da1818fe64ed88b0825c5aad688aec,"This paper studies the problem of approximate probabilistic inference on a joint distribution defined by a normalizing flow model. The authors first show that this task is computationally hard for a large class of flow models. Motivated by this hardness result, the authors propose a new generative model with the property that its composition with the given model approximates the target conditional distribution. By parametrizing this new distribution as another flow model, they can efficiently train it using variational inference and also handle conditioning under arbitrary differentiable transformations. Since the resulting approximate posterior remains a flow, it offers exact likelihood evaluation, in the sense of likelihood evaluation of the joint distribution. They also experimentally demonstrate that their approach is comparable to simple MCMC in terms of sample quality."
SP:1d0f27f61c9d32911b8bd15d6b82ef5eec644f0f,"This paper proposes a new evaluation criteria for evaluating cell membrane segmentation. The evaluation criteria is based on the observation that human perception of cell segmentation is very different from that of computer segmentation, and the authors propose a new criterion to resolve this inconsistency. The paper also presents a new Electron Microscopy ( EM ) dataset for cell membrane with multiple iterative annotations and uncompressed high - resolution raw data. The dataset is called U - RISC and it is the largest annotated EM dataset for the Cell membrane. The authors also conduct a subjective experiment to show that the proposed evaluation criteria matches human perception."
SP:8ca7aff87c82be69c9542550c814f52c9419ab0a,"This paper proposes a new suite of benchmarks for continual learning ( CL ) based on a new modular architecture and learning algorithm. The modular architecture consists of a task - driven prior over the exponential search space of all possible ways to combine modules, enabling efficient learning on long streams of tasks, and a learning algorithm that leverages the learned modules to solve the current task. The learning algorithm leverages a module - based approach to transfer knowledge from previous tasks and to scale memory and compute sub - linearly with the number of tasks. The experiments show that the proposed method outperforms the state - of - the - art on widely used CL benchmarks while yielding superior performance on the more challenging benchmarks."
SP:cc819c61f408e88f247eb87946187ccec3dad32e,"This paper proposes a generative unsupervised meta - learning approach for few - shot classification tasks. The key idea is to generate pairs of in - class and out - of - class samples from the latent space in a principled way, which can be used to create synthetic classes for the training and validation data of a meta - task. The proposed approach, LASIUM, outperforms or is competitive with the baselines on the benchmark datasets of CIFAR-10 and SVHN."
SP:b25771e5c214a352f74ba6196fbd88bca6c43c98,"This paper studies injectivity of fully connected and convolutional ReLU layers and networks. The injectivity is studied in two ways : global injectivity with iid Gaussian matrices, and stability of inverting an injective network via worst - case Lipschitz constants of the inverse. The authors also use arguments from differential topology to study injectivity in deep networks and prove that any injective layer can be approximated by injectivity by an ReLU network."
SP:a95a153d3fe9bcf535ebf8514f51d00df483f210,"This paper proposes a continuous conditional generative adversarial network ( CcGAN ) for image generation conditional on continuous, scalar conditions ( regression labels ). The authors claim two contributions : ( 1 ) They propose empirical losses for conditional GANs ( cGANs ) that are mathematically distinct and can be applied to regression labels ; ( 2 ) Since regression labels are scalar and infinitely many, conventional label input methods ( e.g., combining a hidden map of the generator / discriminator with a one - hot encoded label ) are not applicable. The proposed ccGAN is able to generate diverse, high - quality samples from the image distribution conditional on a given regression label. The experiments on the Circular 2 - D Gaussians, RC-49, and UTKFace datasets show that the proposed method outperforms cGAN."
SP:10dd09ab315870631d1451d200f2c87a023f8226,This paper proposes an active learning ( AL ) algorithm that uses semi - supervised learning ( SSL ) as the training scheme to improve the convergence rate of a classification network by actively querying unlabeled instances to improve convergence to the labeled set. The authors argue that the AL algorithms that seek diversity on labeled samples can be improved upon when using SSL as a training scheme. The proposed AL algorithm is a natural fit to the Assay - Based Semi - Supervised Learning ( ASSL ) and the authors hope their work can catalyze research combining AL and SSL as opposed to an exclusion of either of them.
SP:7f3947c3fa5b09674507d8f3e10d9280376ecb94,"This paper proposes a novel federated learning method for distributed training of neural network models, where a server acts as a middleman between a set of randomly selected devices and a global server. The authors point out a fundamental dilemma, in that the minima of the local - device level empirical loss are inconsistent with those of the global empirical loss, and propose a dynamic regularizer for each device at each round, so that in the limit the global and device solutions are aligned. They demonstrate both through empirical results on real and synthetic data as well as analytical results that their scheme leads to efficient training, in both convex and non - convex settings, while being robust to large number of devices."
SP:a3fbb073b0e2371b20d5d9df6ab829673f90354f," image classification is one of the most important tasks in computer vision. In recent years, self - supervised representation learning methods have emerged as a promising approach for improving the performance of these tasks. However, these methods are computationally challenging. In this work, the authors focus on accelerating contrastive learning algorithms with little or even no loss of accuracy. Their insight is that, unlike traditional contrastive loss, similarity on the intermediate layers is a good surrogate of the final similarity, and they exploit this observation by introducing additional intermediate contrastive losses to truncate the back - propagation and update only a part of the parameters for each gradient descent update. They also do selection based on intermediate losses to filter easy regions for each image, which further reduces the computational cost. The authors apply their method to SimCLR ( Chen et al., 2020a ), SwAV ( Cen et al. 2020 ), and other downstream tasks."
SP:5b5e705ea1ee1b857e17e64d560a39052804949d,"This paper studies the global convergence and global optimality of actor - critic reinforcement learning in the single - time - step setting, where the actor and critic are updated simultaneously in the policy gradient direction computed by the critic. The paper focuses on the linear function approximation setting and the deep neural network setting. In the former setting, the authors prove that the actor sequence converges to a globally optimal policy at a sublinear O(K(K+1 / 2 ) rate, where K is the number of iterations. The latter setting shows that under the broader scope of policy optimization with nonlinear function approximation, the same results are also obtained."
SP:26705a4dc305cce336f657c5937d1f5b4209548a,"This paper proposes to represent log files in a few levels of abstraction including field level, log level, and log sequence level. The representation is in vector format and serve as interfaces to downstream applications. The authors use a version of Transformer Networks ( TNs ) to encode numerical and textual information that is suitable for log embeddings. They show how a number of log processing applications can be readily solved with their representation."
SP:165c51a16f17fb8726e968f8b34742b62011d60e,"This paper proposes a mathematical formalism for understanding the properties of deep convolutional neural networks ( CNNs ), motivated by the similarities between trained CNN kernels and oriented Gabor filters for addressing this problem. The core idea is to split convolution layers into a succession of wavelet packet decompositions ( wavelets ), which are modulated by freely - trained mixture weights. The authors evaluate their approach with three variants of wavelets decomposition with the AlexNet architecture for image classification as an example. The first variant relies on the separable wavelets while the other two implement the 2D dual - tree."
SP:d0a284da462584724ba6a3a48c9e986d391233f6,"This paper proposes a coach - player framework for dynamic multi - agent teams, where agents with different capabilities may join or leave “on the fly ” without altering the team ’s overarching goals. In this dynamic team setting, the players only have a partial view of the environment, while the coach has a complete view. The authors propose an attention mechanism for both the players and the coach, and incorporate a variational objective to regularize learning. They also design an adaptive communication method to let the coach decide when to communicate with different players. The experimental results demonstrate the effectiveness of the proposed method on zero - shot generalization to new team compositions with varying numbers of heterogeneous agents."
SP:4eb662b527d556758aaa1a0b589495fcc337fad0,"This paper studies influence functions in deep neural network models with non - convex loss functions. The authors provide a comprehensive and large - scale empirical study of successes and failures of influence functions for deep neural networks models trained on datasets such as Iris, MNIST and CIFAR-10. The results suggest that influence functions are fragile and call for developing improved influence estimation methods to mitigate these issues. In particular, influence estimates are fairly accurate for shallow networks while for deeper networks the estimates are often erroneous, and the accuracy of influence estimates can vary significantly depending on the examined test points."
SP:5fea74a2031d097a99dacf613bedcb054b0c3831,"This paper studies the connection between pretraining on next word prediction task and text classification tasks. The authors hypothesize and verify empirically that sentence completion tasks of interest can be reformulated as sentence completion task, thus making language modeling a meaningful pretraining task. They show that language models that are pretrained using large text corpora can learn features that can linearly solve such classification tasks with O(\sqrt(T ) ) error, thus demonstrating that doing well on language modeling can be beneficial for downstream tasks. They also experimentally verify various assumptions and theoretical findings, and also use insights from the analysis to design a new objective function that performs well on some classification tasks, thus further improving the theoretical understanding of the success of language models."
SP:a67da438e9821010284416170c3699ae7ff96c99,"Membership inference attacks ( MIA ) try to detect if data samples were used to train a neural network model. As training data is very valuable in machine learning, MIA can be used to detect the use of unauthorized data. Unlike the traditional MIA approaches, addressing classification models, this paper addresses conditional image generation models ( e.g. image translation ). Due to overfitting, reconstruction errors are typically lower for images used in training. However, some images are ” universally easy ” and others are difficult. The reconstruction error alone is less effective at discriminating between easy images that were never seen before. To overcome this, the authors propose to use a novel difficulty score that can be computed for each image, and its difficulty score from the reconstruction error, is shown to achieve high MIA accuracy on an extensive number of benchmarks."
SP:6fe23ebe09f2a4e42a21598f8e9c79edeca99863,"This paper proposes a differentiable neural architecture search ( NAS ) method that formulates the continuously relaxed architecture mixing weight as a distribution learning problem. The proposed method uses pathwise derivatives of Dirichlet distribution to improve the generalization ability and induces stochasticity that naturally encourages exploration in the search space. It also proposes a simple yet effective progressive learning scheme that enables searching directly on large - scale tasks, eliminating the gap between search and evaluation phases. Extensive experiments demonstrate the effectiveness of the proposed method on CIFAR-10, ImageNet, and ImageNet-100."
SP:c590d0ed2487b42480b53fc077546a4a0bc27a78,"This paper proposes a new family of function approximators called multiplicative filter networks for approximations of low - dimensional functions. The idea is similar to sinusoidal activation networks ( SINN ) and Fourier features in positional encodings. The main difference is that instead of using a multiplicative operator, the filter functions are multiplicative in the sense that they multiply together ( linear functions of ). Empirically, the authors show that the proposed filter networks are competitive with SINNs and Gabor wavelet functions when applied to an exponential number of Fourier functions."
SP:f5be855300f63c185a006834302bd4b033b56258,"This paper proposes a teacher - student approach to gradient - based meta - learning for few - shot learning, long - tailed classification, and meta - attack. The proposed approach first optimizes the task - specific models by an inner loop and then backpropagates meta - gradients through the inner loop to update the meta - model. The number of inner - loop optimization steps has to be small ( e.g., one step ) to avoid high - order derivatives, big memory footprints, and the risk of vanishing or exploding meta - gradientients. The key idea is to employ a student network to explore the search space of task-specific models and a teacher then takes a “ leap of faith ” step. The approach is generic ; it performs well when applied to four meta learning algorithms over three tasks."
SP:0361e02d56b7d121cb5ede1cb582284cc18fc599,This paper proposes a behavior regularization method for offline reinforcement learning. The main idea is to penalize the gradient of the Q value w.r.t. the out - of - distribution actions in order to constrain the policy's overestimation of the values evaluated at out of distribution ( OOD ) actions. The authors use an analytical upper bound on KL divergence as the behavior regularizor to reduce the variance associated with sample based estimations. They also employ state - dependent Lagrange multipliers to allow more freedom of deviation to high probability ( more explored ) while simultaneously restricting low probability ( less explored ) states. The proposed method is evaluated on several offline RL benchmarks and outperforms model - free and model - based approaches.
SP:b2cfb380aa2a21f72f508b453cf5949257a5b4ec,"This paper proposes Adjoined networks as a training approach that can regularize and compress any CNN - based neural architecture. The proposed approach trains both the original and the smaller networks together. The parameters of the smaller network are shared across both the smaller architectures. The authors prove strong theoretical guarantees on the regularization behavior of the adjoint training paradigm. They complement their theoretical analysis by an extensive empirical evaluation of both the compression and regularisation behavior of adjoint networks. For resnet-50 trained adjointly on Imagenet, they are able to achieve a 13.7x reduction in the number of parameters and a 5.5x improvement in inference time without any significant drop in accuracy. For the same architecture on CIFAR-100, the authors show that the original network trained in the adjoined fashion gains about 3 % in top - 1 accuracy as compared to the same network trained   in the standard fashion."
SP:dba40073f79143e5355d194aa16db9eee0267a5d,"This paper proposes a new greedy exploration algorithm for reinforcement learning based on the idea that the main limitation of greedy exploration is its lack of temporal persistence, which limits its ability to escape local optima. The authors propose a temporally extended form of greedy that simply repeats the sampled action for a random duration. It turns out that, for many duration distributions, this suffices to improve exploration on a large set of domains. Interestingly, a class of distributions inspired by ecological models of animal foraging behaviour yields particularly strong performance."
SP:5efb581a368ace3bd085d48801a899559d6a43ef,"This paper studies the implicit regularization of gradient descent in matrix factorization. In particular, it shows that gradient flow with infinitesimal initialization is mathematically equivalent to a heuristic rank minimization algorithm, Greedy Low - rank Learning, under some reasonable assumptions. This generalizes the rank - minimization view from previous works to a much broader setting and enables us to construct counter - examples to refute the conjecture from the work of Gunasekar et al. ( 2017 ). The authors also extend the results to the case where depth < 3, and show that the benefit of being deeper is that the above magnitude has a much weaker dependence over initialization magnitude so that this rank - minimalization is more likely to take effect for initialization with practical scale."
SP:7f997cf7a63a7330fc12fd525516080c91a3cb9b,"This paper proposes a method for improving robustness of classifiers against spurious features in the form of model patching. The method trains a classifier with data augmentations that deliberately manipulate subgroup features to improve the performance of the classifier on specific subgroups of a class. The proposed method is instantiated by CAMEL, which uses a CycleGAN to learn the intra - class, inter - subgroup, and inter - group augmentations, and balances subgroup performance using a theoretically -motivated subgroup consistency method. Experiments demonstrate the effectiveness of the proposed method on 3 benchmark datasets and on a real - world skin cancer dataset."
SP:de6cea1e35a0555175e17546a93422e9a96a511e,"This paper proposes a new classifier, named Rulebased Representation Learner ( RRL ), that automatically learns interpretable nonfuzzy rules for data representation. To train the non - differentiable RRL effectively, the authors project it to a continuous space and propose a novel training method, called Gradient Grafting, that directly optimize the discrete model using gradient descent. Experimental results on 9 small and 4 large data sets show that RRL outperforms the competitive approaches, has low complexity, and is rational."
SP:e36388a9452e557dd51bf0170bf2f9da22271a49,"This paper proposes a new regret minimization ( RGM ) algorithm and its extension for structured environments. RGM leverages invariant risk minimization by recasting simultaneous optimality condition in terms of predictive regret, which enables the predictor to compete against an oracle with hindsight access to held - out environments. The structured extension adaptively highlights variation due to complex environments via specialized domain perturbations. The proposed method is evaluated on three applications : molecular property prediction, protein homology and stability prediction and show that RGM significantly outperforms previous state - of - the - art methods."
SP:cad3ed2fba57faf17a3e8899dc5a744d5358aa68,"This paper proposes a new method for cross - modal attention in text - vision BERT models. The proposed method is based on cross - probe BERT, where vision and text are jointly sampled from the same BERT model, and then the vision - based attention is combined with the text - based BERT attention. The method is evaluated on two text - image retrieval benchmarks. The results show that the proposed method outperforms the existing methods in both text retrieval and vision retrieval."
SP:51fd82de525fcb738fdeaeeae20fbb2cdf975f0c,This paper proposes a forward - looking Actor ( FORK ) for Actor - Critic algorithms for continuous state and action spaces. The proposed FORK can be easily integrated into a model - free actor - critic algorithm. The experiments on six Box2D and MuJoCo environments demonstrate significant performance improvement for FORK. A variation of FORK for BipedalWalkerHardcore can be further solved in as few as four hours using a single GPU.
SP:6e730239e6e8b43c4988dd61dca30f15dc039ef7,"This paper proposes a new federated learning algorithm FEDBE, which is based on Bayesian model ensemble ( BME ). The main idea is to aggregate local models into a global model, which can be challenging when users have non - i.i.d. data. The authors propose a Bayesian inference perspective by sampling higher - quality global models and combining them via BME, leading to much robust aggregation. They show that an effective model distribution can be constructed by simply fitting a Gaussian or Dirichlet distribution to the local models. The empirical studies validate the effectiveness of the proposed method."
SP:3ac5f437fc349a33810d0645664d1c448528af74,ily   The paper is a study of self - supervised data augmentation and data privacy in the face of data manipulation in the online learning setting. The authors have conducted extensive experiments to understand the effect of different data manipulation techniques in this setting. They have also conducted extensive analyses to understand how the data manipulation is being used in this paper. The paper has been well written and is easy to follow.  
SP:efa2343ead47263a0d09e1c17f9aa044605b9650,This paper presents a Lyapunov - based analysis of the loss function to derive an a priori upper bound on the settling time of deep neural networks. The authors formulate the supervised learning framework as a control problem where weights of the network are control inputs and learning translates into a tracking problem. An analytical formula for finite - time upper bound is provided a prior i under the assumptions of boundedness of input. The paper also proves that our loss function is robust against input perturbations.
SP:7a0ded4b3b2d08d43765ff7b722da9b9863aabd6,"This paper studies the problem of learning disentangled representations of latent variables. The authors propose to use the mutual information between each learned latent variable and the auxiliary variable to correctly identify informative latent variables and show the advantage of their method on various downstream tasks including classification, outlier detection and adversarial attack defence on both synthetic and real data. They show that the method taken by GIN for informative latent variable selection is not theoretically supported and can be disproved by experiments. They further show the improvement brought by their method in experiments in classification."
SP:0d9ba12bbf47b13a46c2225f9dc06878418daaea,"This paper proposes two novel bidirectional pooling layers for improving robustness to input variations in convolutional neural networks. The first is a down - sampling pooling layer that decomposes a feature map into various downsized sub - bands, each of which contains information with different frequencies. The second is an up - pooling step that performs the same as the downsampling step backward. The proposed method is evaluated on image classification and semantic segmentation tasks and compared with the existing methods using backbones."
SP:147239edceb17bade6ea5d3dca44e3a59998aa47,"This paper proposes a fast, distance - preserving, binary embedding algorithm to transform a high - dimensional dataset T into binary sequences in the cube {±1 } when T consists of well - spread ( i.e., non - sparse ) vectors. The proposed method applies a stable noise - shaping quantization scheme to Ax where A * is a sparse Gaussian random matrix. Moreover, the authors show that Euclidean distances among the elements of T are approximated by the ` 1 norm on the images of T under a fast linear transformation. The authors also show that the length of the binary codes required to achieve a desired accuracy is quite small, and they show it can even be compressed further without compromising the accuracy."
SP:f65e229bca3904095743e7a501b1083cc60f1e22,"This paper proposes a new hypothesis for the generalization and robustness of artificial neural networks ( ANNs ). The authors argue that the plasticity rules for the synaptic weights of recurrent neural nets ( RNNs ) are learned through gradient descent ( GD ), and that this process may be a missing ingredient for the development of ANNs that generalize well and are robust to adversarial perturbations. They provide both empirical and theoretical evidence for this hypothesis. In their experiments, they show that Plasticity rules learned by this process generalize from one type of data / classifier to others ( e.g., rules learned on synthetic data work well on well on MNIST ) and generalize with fewer updates. They also show that the classifiers learned by plasticity rule exhibit surprising levels of tolerance to adversarially perturbed inputs."
SP:f435530146fa975cb27cd375a857df9bcbd87682,"This paper proposes a graph - to - sequence method for visual question generation ( VQG ), which aims to generate visual questions with answer - awareness and region - reference. The proposed method is based on the Double Hints ( Dhariwal et al., 2018 ) method, where a graph is used to learn the implicit topology for visual hints, and then a graph network is used for generating the visual questions. The method is evaluated on the VQA2.0 and COCO - QA datasets, and compared to several state - of - the - art baselines."
SP:53a26ce11647866d3f6ba8b84ca9f13106197a8d,"This paper studies the effect of optimally tuned regularization ( OOP ) on monotonic test performance of linear regression models. Theoretically, the authors prove that optimally - tuned $ \ell_2 $ regularization can mitigate double descent in linear regression with isotropic data distribution. They also demonstrate empirically that OOP can mitigate the double descent phenomenon for more general models, including neural networks. The paper is well - written, well - organized, and easy to follow."
SP:c193ccc74b987beaf8d53a29a8529a0af5e87742,"This paper proposes a spatial dependency network ( SDN ) to improve generative modeling by better exploiting spatial regularities and coherence in images. SDN consists of feature maps at each level of a deep neural net computed in a spatially coherent way, using a sequential gating - based mechanism that distributes contextual information across 2 - D space. Experiments show that SDN augmenting the decoder of a hierarchical VAE by spatial dependency layers considerably improves density estimation over baseline convolutional architectures and the state - of - the - art among the models within the same class. In a vanilla VAE setting, SDN also improves learning learning disentangled representations, indicating that neural architectures play an important role in this task."
SP:db91512a90e75675af03c2f197751c8526d6f5e9,"This paper proposes EMaQ, a new algorithm for off - policy reinforcement learning ( RL ) in the offline setting, where a fixed collection of interactions are provided and no further interactions are allowed. The main contribution of the paper is an important simplification of BCQ ( Fujimoto et al., 2018a ), which removes a heuristic design choice and naturally restricts extracted policies to remain exactly within the support of a given behavior policy. The authors also derive a novel backup operator, which explicitly considers the number of samples and the distribution support, allowing us to derive a new sub - optimality measure of complexity for offline RL problems. In the offline RL setting – the main focus of this work – EMa Q matches and outperforms prior state - of - the - art in the D4RL benchmarks ( Fu et al, 2020a ) and is competitive with Soft Actor Critic ( SAC ) in online RL setting. The key contributions of the empirical findings are demonstrating the importance of careful generative model design for estimating behavior policies, and an intuitive notion of complexity."
SP:e2b80adeaa9208e0667a64a3f24661f77b48e487,"This paper proposes a batch selection method to improve the fairness of training a fair machine learning model. The main idea is to optimize the size of the minibatch of training samples for each class. The outer optimizer of this optimization is based on batch normalization. The inner optimizer, called FairBatch, is used to select the batch size. The proposed method is shown to be compatible with batch selection techniques for different purposes. Experiments on both synthetic and real - world datasets show that the proposed method outperforms other fairness - enhancing methods."
SP:72f26b850bb2258223c0fc71598e35ad07d690e6,"This paper studies the bounds on the Lipschitz constant of monotone deep equilibrium models ( DEQs ). The authors show that the monotonicity parameter of the DEQ model is a strong mononormative parameter, and derive simple - yet - tight bounds on both the input - output mapping and the weight -output mapping defined by these networks. They also highlight how to use these bounds to develop PAC - Bayes generalization bounds that do not depend on the depth of the network, and which avoid the exponential depth - dependence of comparable DNN bounds."
SP:bcfd4d7fd4590e3bc248a0a5422ce4b67db74a74,"This paper proposes a method for goal - conditioned reinforcement learning that leverages recent advances in density estimation to effectively learn to reach a given state using probabilistic long - term dynamics. The method is applied to both stochastic goal conditioned RL and imitation learning. The goal of the paper is to circumvent the problem of sparse rewards while addressing hindsight bias in stochastically - driven domains. In imitation learning, the proposed method can learn from extremely sparse amounts of expert data and achieves state - of - the - art results on a common benchmark."
SP:d57550b2f323b356d7e609acc35ee33039f376b4,This paper proposes a variational multi - task learning ( VMTL ) framework that uses Gumbel - softmax priors to condition the prior of each task on related tasks. The prior is represented as a mixture of variational posteriors of other related tasks and the mixing weights are learned in a data - driven manner for each individual task. The proposed method is evaluated on four benchmark datasets and achieves state - of - the - art performance.
SP:3ccdf8322f16c8a7bef82e32fad4c03969a510d1,"This paper proposes a systematic and unified benchmark for evaluating efficient long - range transformers. The Long - Range Arena ( LRA ) is a suite of tasks consisting of sequences ranging from 1 - 16 K tokens. The authors systematically evaluate ten well - established long range Transformer models ( Reformer, Linformers, Linear Transformers, Sinkhorn Transformers, Performers, Synthesizers, Sparse Transformers, and Longformers ) on the newly proposed benchmark suite.   The authors claim that their benchmark suite paves the way towards better understanding this class of efficient Transformer - based models, facilitates more research in this direction, and presents new challenging tasks to tackle."
SP:e12e410c3335b76133ceda4c865b244fbbab8580,"This paper proposes a code summarization model that combines two complementary representations of the same program : source code ( Context ) and its parsed abstract syntax tree ( Structure ). The source code is decomposed into two parts : ( 1 ) source code, and ( 2 ) the structure of source code. The model uses only language - agnostic features, i.e., source code features that can be computed directly from the AST. The paper also proposes a multilingual version of the model that jointly learns on both source code and structure. The experimental results show that the proposed method outperforms the baselines on monolingual and multi - language training. The main contribution of the paper is that it proposes a method for combining source code representation and structure representation."
SP:f46e98d48f90071831f1c0069bf74a7993be6db8,This paper proposes a new method for audio - visual navigation based on reinforcement learning. The proposed method learns a waypoint - based navigation policy and an acoustic memory network. The waypoints are learned in an end - to - end manner. The acoustic memory is used to learn a spatially grounded representation of what the agent has heard. The authors demonstrate the effectiveness of the proposed method on two datasets of real - world 3D scenes and scenes in a Replica environment.
SP:23bfe317dcef00a91ea92389b3f39d9b93972454,"This paper extends the lottery ticket hypothesis ( Frankle & Carbin, 2018 ) that suggests that neural networks rely on lucky random initial weights of subnetworks called “ lottery tickets ” that converge quickly to a solution. To test this hypothesis, the authors train a convolutional neural network to predict n steps of a two - dimensional cellular automaton in Conway ’s Game of Life. They find that networks of this architecture trained on this task rarely converge, and that networks require substantially more parameters to consistently converge. They also find that the initialization parameters that gradient descent converges to are sensitive to small perturbations. Finally, they observe a critical value0 such that training minimal networks with examples in which cells are in which probability d0 dramatically increases the chance of convergence to a fixed solution."
SP:1b5ba618d3e28d48f9205c0780f8288a08fa5392,"This paper proposes a new semi - supervised learning ( SSL ) method, RankingMatch, that considers not only the perturbed inputs but also the similarity among the inputs having the same label. A new objective function, BatchMeanTriplet loss, is proposed to improve the efficiency of the objective function. The proposed method achieves state - of - the - art performance across many standard SSL benchmarks with a variety of labeled data amounts. The paper also performs an ablation study to prove the efficacy of the proposed method against existing versions of Triplet loss."
SP:f3abccf4a2566ffbc821aba209fab15058639ad4,"This paper studies the problem of few - shot meta - learning in the online setting, where the goal is to learn a new task from a small number of training examples. The authors consider the setting where the task is presented in a sequence of tasks, and the meta - learner learns the new task by meta - training on the data from a set of previous tasks.    The authors propose a new algorithm, Meta - Learning for Sequential Learning ( MTL ), which is a meta learning algorithm that learns a task - by - task model and then meta - trains the model on the meta data from the full task set. The proposed algorithm is shown to outperform standard risk minimization and meta - adaptation methods when the number of tasks in the task set is small and the amount of supervision is low. The paper also shows that the proposed algorithm achieves better cumulative performance compared to standard supervised methods in the sequential learning setting. The results suggest that meta learning can be an important ingredient for building learning systems that continuously learn and improve over a sequence."
SP:95cb420d92ec42e12a4bbb0e66224f1c498a7161,"This paper presents a set of probes designed to test the sensitivity of pre - trained Transformer representations to syntactic structure in sentences. The probes are designed to compare the representations of pretrained Transformer models with input perturbation - based analyses of representations obtained from pretrained representations pretrained with self - supervision. The authors also connect their probe results to the attention mechanism of the Transformer architecture by relating the attention distance between two words. Results from the three probes collectively suggest that Transformers build sensitivity to larger parts of the sentence along their layers, and that hierarchical phrase structure plays a role in this process. In particular, sensitivity to local phrase structure increases along deeper layers."
SP:cb27b27a6fefc192ad1c2bd083d13eb9e51a5c44,"This paper proposes a new method for few - shot image synthesis for GANs. The main idea is to use a skip - layer channel - wise excitation module and a self - supervised discriminator in the GAN framework. The former is based on the well - known GAN - SGD structure, while the latter is a new GAN structure that uses a discriminator that is trained as a feature - encoder. The discriminator is in the form of a two - stage process : first, a skip layer is used to estimate the excitation, and second, it is used in the discriminator. The proposed method is evaluated on state - of - the - art datasets for image generation and adversarial training."
SP:c0dbeb5d94b2388595cf7ad9675c55df0bac7f8e,This paper proposes a novel dual dual solver for neural network bounding. The main idea is to relax the activation function of a neural network so that the bound is tight. The proposed method is based on a relaxation of a linear program of size linear in the number of neurons. The authors show that the proposed method recovers the strengths of the new relaxation in the dual space : tightness and a linear separation oracle. They demonstrate that this method results in significant formal verification speed - ups and recover the speed - accuracy trade - off of looser dual solvers.
SP:56e3837417dbcce0d65338dc3aac4e1a20eb0df8,"This paper proposes a method for augmenting pre - trained language models ( PTLMs ) with concept - centric commonsense knowledge. The authors propose to use generative and contrastive objectives for learning common sense from the text, and use them as intermediate self - supervised learning tasks for incrementally pre - training PTLM ( before task - specific fine - tuning on downstream datasets ). They also develop a joint pretraining framework to jointly learn generative - contrastive and inter - task learning objectives so that they can mutually reinforce each other. Extensive experimental results show that the proposed method, called CALM, outperforms existing methods on both NLU and NLG tasks."
SP:7ec69bdee021af506293c87a3b75bce1c40a03d7,"This paper studies the problem of unsupervised physical object discovery in the presence of unobserved objects in a video. The authors propose a network that uses both multi - scale pixel cues and physical motion cues to accurately segment observable and partially occluded objects of varying sizes, and infer properties of those objects. The proposed network can segment objects on both synthetic and real scenes. The discovered object properties can also be used to reason about physical events.   The main contribution of this paper is the proposed Physical Object Discovery Network ( POD - Net ), which is a neural network that disentangles 3D geometry and position of objects from video frames. The network is built on top of the ObjectNet framework."
SP:66997bc19a3ba6548fcf21f114e748bea95cad1c,"This paper proposes a novel training method to improve the robustness of deep neural networks ( DNNs ) against adversarial attacks. Specifically, the proposed method increases the margins of training samples by moving the decision boundaries of the DNN model far away from the training samples to improve robustness. The proposed method is evaluated on six publicly available datasets ( including a COVID - 19 CT image dataset ) under strong 100 - PGD white - box adversarially attacks, and the results show that the proposed IMA method significantly improved the classification accuracy on noisy data while keeping a relatively high accuracy on the noisy data."
SP:276ffd59fbf49e3ee02756da8920218102214917," of knowledge distillation is one approach to derive compact models from bigger ones. However, it has been observed that a converged heavy teacher model is strongly constrained for learning a compact student network and could make the optimization subject to poor local optima. In this paper, the authors propose ProKT, a new model - agnostic method by projecting the supervision signals of a teacher model into the student ’s parameter space. The projection is implemented by decomposing the training objective into local intermediate targets with approximate mirror descent technique. The proposed method could be less sensitive with the quirks during optimization which could result in a better localoptima. Experiments on both image and text datasets show that our proposed ProKT consistently achieves the state - of - the - art performance comparing to all existing knowledge - distillation methods."
SP:906dc21d6988953fcf57d63bbdd12973e5818d16,This paper proposes a novel channel pruning method to solve the problem of compression and acceleration of Convolutional Neural Networks ( CNNs ). The proposed method uses a hyper - structure network to generate the architecture of the main network and regularizes the computational resource of the compact network. The authors also introduce learnable layer - wise scaling factors to balance the learning performance and computational resources. Experiments on CIFAR-10 and ImageNet show that the proposed method is competitive with state - of - the - art methods.
SP:890fd9454596c051b0e9535baf73b1dd1fae67ca,"This paper proposes to use deep reinforcement learning to augment the exploration of premises for proving higher - order logic theorem proving in the presence of a large knowledge base of potential premises without learning from human proofs. The exploration mechanism is based on a simple tf - idf ( term frequency - inverse document frequency ) based lookup in a deep RL scenario. The experiments show that a theorem prover trained with this exploration mechanism but no human proofs, dubbed DeepHOL Zero, outperforms provers that are trained only on human proofs and approaches the performance of a prover training by a combination of imitation and reinforcement learning."
SP:88209417a8ad07e6103084e41709be900303ce5f,"This paper proposes a data augmentation approach called MODALS ( Modalityagnostic Automated Data Augmentation in the Latent Space ) to augment data for any modality in a generic way. The proposed approach fine - tunes four universal data transformation operations in the latent space to adapt the transform to data of different modalities. The experimental results demonstrate the effectiveness of MODALS on multiple datasets for text, image, time series and image modalities for various machine learning tasks."
SP:6d84670d321b0d584b097c630574bd748e85c9a2,"This paper establishes a global convergence result for unregularized feedforward three - layer networks under stochastic gradient descent training in the mean - field regime. The main result is a universal approximation property, natural of neural networks, which importantly is shown to hold at any finite training time ( not necessarily at convergence ) via an algebraic topology argument.    The authors first develop a rigorous framework to establish the mean field limit of three - layers networks in a two - layer network setting. Then, they show that this limit is universal and does not rely critically on convexity. Finally, the authors provide a theoretical framework to prove a global mean field convergence result."
SP:b90f893f927db9c439595fd119a565cf43c971f4,"This paper proposes a method for learning explanations of expert decisions by modeling their reward function in terms of preferences with respect to “ what if ” outcomes : Given the current history of observations, what would happen if we took a particular action? To learn these cost - benefit tradeoffs associated with the expert ’s actions, the authors integrate counterfactual reasoning into batch inverse reinforcement learning. They propose a principled way of defining reward functions and explaining expert behavior, and also satisfies the constraints of real - world decision - making — where active experimentation is often impossible ( e.g. in healthcare ). They show the effectiveness of their method in recovering accurate and interpretable descriptions of expert behavior in both real and simulated medical environments."
SP:c92916780418bfa7f0796fd9766b6d28b9eea5ef,"This paper studies the use of graph neural networks ( GNNs ) in the context of reinforcement learning. The main idea of GNN is to use a graph as a representation of the agent ’s state and action space in a continuous control setting. In this setting, the state can be arbitrary in size and the action space can not be the same across tasks. The proposed method, AMORPHEUS, is a transformer - based approach to GNN that uses the graph structure of the input graph to encode the node labels of an agent and the edges of the graph to connect the nodes if their corresponded limbs are physically connected. The authors show that the proposed method outperforms existing GNN - based methods that use the morphological information encoded in the graph does not improve their performance.  "
SP:2cf58f5cac20dccdc2034ef60e8e46b7988ebd7d,"This paper proposes a method for visual counting, which aims to predict the number of occurrences given an image and a query. The method is based on revisiting modulated convolutions that fuse the query and the image locally. The proposed method is called MoVie, short for Modulated ConVolutional bottlenecks, and it can be integrated as a module for reasoning tasks beyond counting. The experiments show that it can improve the state - of - the - art on counting - specific VQA tasks while being more efficient and outperforming prior - art."
SP:c64e77507e562f236cb69361b22fb1a7951ffb22,"This paper proposes an online poisoning attack that induces a model to misbehave in a particular way desired by the adversary, such as misclassifying certain inputs. Unlike previous model - targeted poisoning attacks, the attack comes with provable convergence to any achievable target classifier. The distance from the induced classifier to the target classifer is inversely proportional to the square root of the number of poisoning points. The authors also provide a lower bound on the minimum number of poisoned points needed to achieve a target model classifier, and in their experiments it either exceeds or matches the best state - of - the - art poisoning attack."
SP:a526023ec4cb839b83c574d31f59a9a67bc7af00,"This paper proposes a novel method for efficient deep learning on point clouds. The main idea is to apply entropy - maximizing aggregation ( EMA ) to modulate the distribution before aggregation for the maximum information entropy, and layer - wise scale recovery ( LSR ) to efficiently restore feature representation capacity. Extensive experiments show that BiPointNet outperforms existing binarization methods by convincing margins, at the level even comparable with the full precision counterpart."
SP:825b4d1db0c537a607655bb5b4bf221ec672c8af,This paper proposes a memory - augmented Transformer - based model for context - aware NLP. The main idea is to augment the self - attention layer of the Transformer model by adding memory tokens to selectively store local as well as global representations of a sequence. The paper shows that the added memory positively correlates with the model performance for machine translation and language modelling tasks on the GLUE benchmark. It also shows that adding attention patterns over the memory suggest that it improves the model ’s ability to process a global context.
SP:f0fa1b7684bc605f6edd4813c44be20988fe8b4c,"This paper proposes an unsupervised representation learning method that bridges contrastive learning with clustering for instance discrimination and encodes semantic structures discovered by clustering into the learned embedding space. Specifically, prototypes are used as latent variables to help find the maximum - likelihood estimation of the network parameters in an Expectation - Maximization framework. The authors propose ProtoNCE loss, a generalized version of the InfoNCE for contrastive loss, which encourages representations to be closer to their assigned prototypes. Experiments show that the proposed method outperforms state - of - the - art methods on multiple benchmarks with substantial improvement in low - resource transfer learning."
SP:5342a5e1d87fd17b1a2efed967dbbfeafa440ee7,This paper proposes a orthogonal multi - path ( OMP ) block to improve the robustness of neural networks against adversarial attacks. The proposed OMP block consists of two parts : ( 1 ) a block containing multiple paths to learn robust features and ( 2 ) a forward and backward correction block. The main idea of the proposed block is to impose orthogonality constraints on the paths to ensure that the parameters of these paths are orthoganal with each other. Experiments on white - box and black - box attacks show that the proposed method improves the accuracy of the neural networks significantly compared to the existing state - of - the - art adversarial defenders.
SP:776df66274ed12449fde8dcef873a593980f397c,This paper proposes a self - supervised graph attention network ( SuperGAT ) for learning graph attention in the presence of noisy graphs. The proposed method is based on two types of attention forms and two graph characteristics : homophily and average degree. The method is evaluated on 17 real - world datasets and shows improved performance over the baselines.  
SP:80a05296d6b1e4c6e9e2df01938c73029ff8487d,"This paper proposes an agent for the Introspective Diagnosis System for Medical Automatic Diagnosis ( DSMAD ), which aims to learn an agent that mimics the behavior of a human doctor, i.e., inquiring symptoms and informing diseases. The proposed agent, called INS - DS, consists of two separate yet cooperative modules, an inquiry module and an evaluation module. The inquiry module first proposes the most valuable symptom inquiry and decides to inquire only if the potential responses of this inquiry differ from the ones it has previously received. The evaluation module then proposes two evaluation metrics to evaluate the reliability and robustness of DSMAD agents. Extensive experimental results demonstrate that the proposed agent achieves the new state - of - the - art under various experimental settings and possesses the advantages of reliability and consistency compared to other methods."
SP:10ae09d90d465125433a9b4f15b1405ab017920d,"This paper proposes a new method for long - tailed fine - grained visual classification ( FGVC ) based on the Batch Confusion Norm ( BCN ) framework. The main idea of BCN is to learn a distribution of confusion strength over tailed and head categories to improve the classification performance of FGVC models. In particular, the proposed method extends the existing confusion energy - based framework to account for long tailed FGVC scenario. The proposed method is evaluated on several benchmark FGVC datasets and achieves state - of - the - art results."
SP:90f1e0fe1e9678d1e9a4dcb519d4e8fd61098ce0,"This paper proposes a new method for approximate variational reward imitation learning based on Bayesian inference over the reward. The key idea is to jointly learn an approximate posterior distribution over the rewards and an appropriate policy in a completely offline manner through a variational approach to the latent reward. In the proposed method, the reward distribution is approximated by the posterior distribution of the state - action space, which is learned jointly with the policy in an offline manner. The proposed method is evaluated on real medical data and classic control simulations and compared with Bayesian reward inference in environments beyond the scope of current methods, as well as as task performance competitive with focused offline methods."
SP:ccd251d95c0a2d8dc5ad2a148ec29955e105e71e,This paper proposes a method for learning counterfactual policies for fully and partially observable games. The proposed method is based on the idea of learning an approximate belief distribution over the state - action space using an auto - regressive model. The method is evaluated in a multi - agent setting where the agent's policy is a combination of a public - private model and a policy evaluation method. The algorithm is evaluated on the Hanabi benchmark and is shown to outperform a number of state - of - the - art methods.
SP:db408e6bfe69a9b3984f3b27ca92b802aa37af42,"This paper proposes a new algorithm for planning in large state spaces. The proposed algorithm is a combination of two well - known search mechanisms : MCTS and random shooting. The main idea is to use a random tree search ( RTS ) to search the state - space tree, and then use RTS to select the best candidates for shooting the tree. The authors claim that this combination allows them to control the bias - variance trade - off, which is usually left to the random search mechanism. The experiments show that the proposed method outperforms both random shooting ( RSTS ) and the vanilla RTS in most of the experiments."
SP:5efc271ccc555fd9aa542548838170bd4c98e957,"This paper proposes a pre - training method for learning inductive bias in the form of datasets. The main idea is to design synthetic tasks that require deduction, induction, and abduction to be performed by the model in order for the model to learn inductive biases. Three such synthetic tasks are designed in a way that the model is not aware of the mathematical knowledge behind the tasks, but only the reasoning biases. The authors propose a new pretraining method called LIME ( Learning Inductive Bias for Mathematical rEasoning ) and train a transformer - based model on these datasets. They show that LIME outperforms vanilla transformers on three very different large mathematical reasoning benchmarks."
SP:bb8e0b554d3b3314fa343c902d9e60f1a141ea30,"This paper analyzes the inductive bias of exponential weight normalization ( EWN ) on smooth homogeneous neural networks. The authors show that the gradient flow path with EWN is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. The results can be extended to hold for gradient descent via an appropriate adaptive learning rates, and the convergence rate of the loss is given by $ O(1 t(log t)$, independent of the depth of the network.   The authors also show the same results on SWN and unnormalized architectures, and demonstrate their implications on synthetic data sets and demonstrate the effectiveness of EWN."
SP:c71f9d2a602516865a0b103028186e83b52e5f00,"ily, GANs have been known to suffer from the mode collapse problem, in which some modes of the target distribution are ignored by the generator. This paper proposes a novel training procedure that dynamically spawns additional discriminators to remember previous modes of generation. Experiments show that the proposed training scheme can be plugged - in to existing GAN frameworks to mitigate mode collapse and improve standard metrics for GAN evaluation."
SP:52c48198c95826e042f9e5a512ef3265daaff882,This paper proposes a new regularization method for BERT that leverages reinforcement learning to automatically prune attention heads from BERT. The key idea is to learn a pruning policy that determines which attention heads should or should not be pruned for regularization. The proposed method is evaluated on CIFAR-10 and ImageNet. The results show that AUBER outperforms existing pruning methods by achieving up to 9.39 % better accuracy.
SP:abcbbad146f1b0d5d579c215952c95e5499a378a,"This paper proposes a method for learning correspondence between robotic agents in two different robot domains, differing in representation, physics parameters, and morphology. The authors propose dynamics cycles that align dynamic robot behavior across two domains using a cycle - consistent constraint. Once this correspondence is found, they can directly transfer the policy trained on one domain to the other without any additional fine - tuning on the other domain. They perform experiments across a variety of problem domains, both in simulation and on real robot. They show that the proposed method is able to learn correspondence across domains."
SP:006434d56992836ab9420d7d4215bc70664de304,"This paper studies the Shapley framework for explainability in deep learning models. The authors point out the drawbacks of the assumption that Shapley explainability attributes a model ’s predictions to its input features in a mathematically principled and model - agnostic way. They develop two solutions to this problem, one based on generative modelling and the other based on Shapley value function learning.   The main contributions of this paper are :   1. Demonstrate that the main drawback of the existing Shapley explanation method is that it assumes that the features of the model are uncorrelated to the input features. This assumption is not true. 2. Empirically, the authors show that “ off - manifold ” Shapley values can give rise to incorrect explanations, ( i ) in high dimensional data, ( ii ) in higher - dimensional data and ( iii ) in low dimensional data. 3. Introduce generative modeling to provide flexible access to data imputations."
SP:7cda6bccf08887c7cef66d0ac3ccefdea8f5d7c8,This paper proposes a method for learning latent embeddings of the actions and observations of an opponent agent using a variational autoencoder ( VAE ) model. The learned embedding is used to augment the model's decision policy which is trained via deep reinforcement learning without access to the opponent's local observations and actions. The proposed method is evaluated in a number of multi - agent multi - task environments and compared with several baselines. The results show that the proposed method achieves comparable performance to an ideal baseline and outperforms the baselines in most cases.
SP:c239bc531bcf7293032748af29a1b786e9d893dd,"This paper proposes Consistent Contrastive Learning ( CO2 ), a consistency regularization method for contrastive learning that encourages consistency between positive and negative samples from the same image. The method is based on instance discrimination, which is a popular method for semi - supervised learning on unlabeled data. However, it suffers from the limitation that it may not reflect the heterogeneous similarity between the query image crop and each crop from other images, taking them as equally negative while some of them may even belong to the same semantic class as the query. To address this issue, the authors propose to use the similarity of query image crops from other samples as a pseudo label to encourage consistency. Experiments on image classification, object detection, and semantic segmentation on PASCAL VOC show that the proposed method achieves better visual representations for downstream tasks."
SP:d18bab21790713e2facb053c47298fc9079ab783,"This paper studies last - iterate convergence in bilinear games for saddle - point optimization in the constrained setting. In particular, the authors study the convergence of the OGDA and OMWU algorithms for the case where the equilibrium is unique. The authors show that linear convergence is achieved with a learning rate whose value is set to a universal constant, under the assumption that the optimal solution satisfies the unique equilibrium condition. They also extend the results to more general objectives and feasible sets for the projected OGDA algorithm by introducing a sufficient condition under which OGDA converges exponentially fast with a constant learning rate. Finally, they provide experimental results to further support their theory."
SP:bbc7f77308b298c332a39747f693bc396f00a89f,"This paper proposes a federated framework for training User Verification ( UV ) models in federated setup, where each user has access to the data of only one class and user embeddings can not be shared with the server or other users. To address this problem, the proposed FedUV proposes a framework for private and secure training of UV models. In FedUV, users jointly learn a set of vectors and maximize the correlation of their instance embedding with a secret linear combination of those vectors. The authors show that choosing the linear combinations from the codewords of an error - correcting code allows users to collaboratively train the model without revealing their embedding vectors. They present the experimental results for user verification with voice, face, and handwriting data and show that FedUV is secure and efficient."
SP:40fa47cc0928e2925ef5ce6d808073f368ca2cd4,"This paper proposes a method to estimate the effective dimension of class manifolds ( CMs ) by computing their intersection with random affine subspaces of varying dimension. Theoretical analysis is provided to show that the effective CM dimension depends on the dataset, the architecture, the training procedure, the stage of training, and the number of training epochs. Experiments are conducted on CIFAR-10 and ImageNet to evaluate the effectiveness of the proposed method. The results show that well - performing models have higher effective CMs than worse performing models."
SP:09bce202ac7a750c3700a8ef3cd92cfe8ed00c39,"This paper proposes an exploration - exploitation trade - off method for reinforcement learning. The key idea is to use a curiosity - aware entropy ( E3 ) mechanism to tune the entropy of the SAC policy. The proposed method is based on the Soft Actor - Critic ( SAC ) method. The authors argue that the agent should explore more in an unfamiliar state, while less in a familiar state, so as to understand the environment more efficiently. To this purpose, they propose CAT - SAC, which utilizes the curiosity mechanism in developing an instance - level entropy temperature for unfamiliar states and decrease the entropy for familiar states. Experimental results on the difficult MuJoJo benchmark show that the proposed method significantly improves the sample efficiency."
SP:dce5eb20581a21c5de0a9fc07a8a79a1fbb28c71,"This paper proposes a model identification and experience relabeling ( MIER ) approach for learning policies and value functions for out - of - distribution tasks without using meta - re - reinforcement learning at all, by generating synthetic experience for the new task by generating a synthetic dynamics model. The proposed MIER is shown to be both efficient and extrapolates well when faced with OOD tasks at test time.    The main contributions of this paper are as follows :   1. MIER proposes a meta - learning algorithm for learning dynamics models that can be used to generate synthetic experiences for a new task. 2. It proposes a method for generating synthetic dynamics models based on a simple insight that dynamics models can be adapted efficiently and consistently with off - policy data, more easily than policies and policies. 3. It adopts a two - stage approach to learn the dynamics models. The first stage generates a synthetic experience using the learned dynamics model and value function. The second stage learns a policy using the generated synthetic experience. 4. The learned dynamics models are used to acquire policies for complex tasks autonomously."
SP:34d78aa11f9d50baf75a9646a6f9128318c3389a,"This paper proposes an Eigen - Reptile - based method for few - shot learning ( FSL ) to address the two challenges that FSL with sampling and label noise. The authors cast the meta - overfitting problem as a gradient noise problem since few available samples cause meta - learner to overfit on existing examples ( clean or corrupted ) of an individual task at every gradient step. To alleviate this problem, the authors propose an introspective self - paced learning ( ISPL ) method that constructs a plurality of prior models to determine which samples should be abandoned. The effectiveness of the proposed method has been proved theoretically and experimentally."
SP:a571bff9ffe4edafd7bc064c4d10609e6b981ce3,"This paper proposes Adversarial Batch Normalization ( AdvBN ), a method for adversarially normalizing the training distribution of deep neural networks ( DNNs ) to be robust to distributional shifts. The distribution shift is modeled as a shift in the mean and variance of deep image features, and adversarial training is used to perturb these feature statistics, rather than image pixels. Experiments show that AdvBN can improve the performance of ResNet-50 on ImageNet - C, Stylized - ImageNet, and ImageNetInstagram, as well as on semantic segmentation."
SP:6a9c46bd3cf854299f360bff136e1d79d3edb2e4,This paper proposes Variance of Gradients ( VoG ) as a proxy metric for detecting outliers in the data distribution. The authors provide quantitative and qualitative support that VoG is a meaningful way to rank data by difficulty and to surface a tractable subset of the most challenging examples for human - in - the - loop auditing.    The authors claim that data points with high VoG scores are far more difficult for the model to learn and over - index on corrupted or memorized examples.
SP:074bfacc75837bb19049be8a2890e10de073dd8e,"This paper proposes a method for improving the quality of samples generated by deep generative models. The proposed method is based on the gradient flow of entropy - regularized f - divergences between the real and the generated data distributions. The gradient flow takes the form of a non - linear Fokker - Plank equation, which can be easily simulated by sampling from the equivalent McKean - Vlasov process. By refining inferior samples, the proposed method avoids wasteful sample rejection used by previous methods ( DRS & MH - GAN ). The experimental results show that the proposed approach outperforms the state - of - the - art DOT and DDLS methods, as well as other methods such as DDLS and DGOT."
SP:74ecbc5a6d464bfa49337da9e0dd6a0fe714d4bb,"This paper proposes a variable encoder - decoder ( VECO ) pre - training approach to unify the two mainstreams in both model architectures and pret - training tasks for understanding and generation tasks. It splits the standard Transformer block into several sub - modules trained with both innersequence and cross - sequence masked language modeling, and correspondingly reorganizes certain sub - module for understanding / generation tasks during inference. The proposed approach is shown to outperform all existing cross - lingual models and state - of - the - art Transformer variants on WMT14 English to German and English - to - French translation datasets with gains of up to 1 - 2 BLEU."
SP:3d177ad50727d1a2619b68ab8a897b79d8652beb,"This paper proposes a novel intrinsic motivation for reinforcement learning that leverages multiple sensory modalities ( e.g., visual and audio ) to build a causal understanding of the physical world. The authors propose to use K - means to discover underlying auditory event clusters and train a neural network to predict the auditory events and use the prediction errors as intrinsic rewards to guide RL exploration. They first conduct an in - depth analysis of our module using a set of Atari games and then apply our model to audio - visual exploration using the Habitat simulator and active learning using the ThreeDWorld ( TDW ) simulator. The experimental results demonstrate the advantages of using audio signals over vision - based models as an intrinsic reward."
SP:014f6118ebe55ece6be23c3a10f12e4591e444b1,"This paper studies the problem of novel category discovery on single and multi - modal data with labels from different but relevant categories. The authors propose a generic, end - to - end framework to jointly learn a reliable representation and assign clusters to unlabelled data. To avoid over - fitting the learnt embedding to labelled data, the authors take inspiration from self - supervised representation learning by noise - contrastive estimation and extend it to jointly handle labelled and unlabeled data. In particular, they proposed using category discrimination on labelled data and cross - multimodal discrimination on multi - multimal data to augment instance discrimination used in conventional contrastive learning approaches. Moreover, they further employ Winner - Take - All ( WTA ) hashing algorithm on the shared representation space to generate pairwise pseudo labels to better predict cluster assignments. Experiments on large - scale multi - image benchmarks Kinetics - 400 and VGG - Sound, and image benchmarks CIFAR10 and ImageNet show the effectiveness of the proposed method."
SP:4df640f502e88ddba2d7e183625231d70b083e82,"This paper proposes a method for weakly supervised segmentation, where pixels of the same semantics need to be mapped to the same ( distinctive ) features. The authors propose 4 types of contrastive relationships between pixels and segments in the feature space, which can be learned from training images with any partial annotations in a data - driven fashion. In particular, unlabeled pixels in training images participate not only in data-driven grouping within each image, but also in discriminative feature learning within and across images. The proposed method achieves a universal weakly - supervised segmenter with significant gains on Pascal VOC and DensePose.    The paper is well organized, easy to follow, and easy to understand."
SP:f7d6099adb40a0ce2f8a3563dbd5207cf1fdea0f,"This paper proposes a simple but effective distillation strategy for unsupervised learning. The highlight is that the relationship among similar samples counts and can be seamlessly transferred to the student to boost the performance. The proposed method, BINGO, achieves new state - of - the - art performance on small scale models, i.e., 65.5 % and 68.9 % top-1 accuracies with linear evaluation on ImageNet, using ResNet-18 and ResNet - 34 as backbone, respectively, surpassing baselines ( 52.5% and 57.4 % top - 1 accuracies ) by a significant margin.    The authors propose a simple yet effective strategy to aggregate compact representations over the student with respect to instances in a bag, and the goal of distillation is to aggregate the relationship learned by the teacher and are grouped within a bag."
SP:328866aad6544c81ded8980934df31dc4472435f,"This paper proposes a generative adversarial approach to Simulation - based inference ( SBI ). SBI is a variant of SimSBI that allows for generative modeling of stochastic models, but does not require explicit likelihoods. The authors propose to reformulate the variational objective in an adversarial setting to learn implicit posterior distributions. The proposed GATSBI is amortised across observations, works in high - dimensional posterior spaces and supports implicit priors. Experiments on two SBI benchmark problems and two high - dimension simulators show that the proposed method outperforms the state - of - the - art SBI."
SP:2915e82097eae4eb8546dc500f32b3ec37e3766f,"This paper studies the identification and estimation of treatment effects ( TEs ) under limited overlap, i.e., when subjects with certain features belong to a single treatment group. The authors use a latent variable to model a prognostic score, which is widely used in biostatistics and sufficient for TEs. The model is learned as a new type of variational autoencoder ( VAE ). The TE error bounds are derived. The proposed method is compared with recent methods using ( e.g., ) synthetic datasets."
SP:ca358c9f36aac6e58ed1b3949c349d210c49a48e,"This paper proposes a framework for autonomous reinforcement learning ( ARL ), where the agent not only learns through its own experience, but also contends with a lack of human supervision to reset between trials. The authors propose a benchmark task for ARL consisting of diverse and challenging simulated tasks. They show that standard approaches to episodic RL and existing approaches struggle, underscoring the need for developing new algorithms for reinforcement learning with a greater focus on autonomy."
SP:abe51d4a9817c08f0abde5da0bb8e6ca4e02e7cf,This paper investigates the state - of - the - art knowledge - aware graph neural networks ( GNNs ) used in question answering ( QA ) systems. It investigates the reasoning capability of these GNN - based modules and whether they can provide a complex reasoning process for complex QA problems. It also investigates the existing GNN modules in the CommonsenseQA and OpenQA datasets. It finds that even a very simple graph neural counter can outperform all the existing graph neural modules on these two popular QA datasets which heavily rely on knowledge - awareness reasoning.
SP:3ea5a38e7fcd9111dcd299ad039b634e2781685f,"This paper proposes a new compression method for deep neural networks ( DNNs ) based on the Succinct Compression ( SC ) framework. The main idea of SC is to compress the representation of a DNN model and use the compressed representation for fast inference during inference time. The proposed method first transforms the DNN models as the proposed formulations in either the Element - wise or Block - wise manner. Then, the compressed representations are used for fast queries on compressed representation without decompression. Finally, the method is combined with pruning and quantization to achieve near - optimal compression. Experiments on AlexNet and VGG-16 show that the proposed method outperforms the existing methods."
SP:94c395afc794a9cc163e362078769ff83f3d20d0,"This paper proposes a new training method NetAug for improving the performance of tiny neural networks. The authors argue that training tiny models is different from training large models : rather than augmenting the data, we should augment the model, since tiny models tend to suffer from under - fitting rather than over - fitting due to limited capacity. To alleviate this issue, NetAug augments the network ( reverse dropout ) instead of inserting noise into the dataset or the network. It puts the tiny model into larger models and encourages it to work as a sub - model of larger models to get as much benefit as possible. The effectiveness of NetAug is demonstrated on image classification and object detection."
SP:9c24549b980e415616f818acbf4cf680ef8edb52," point cloud sequence is an important data representation that provides flexible shape and motion information. Prior work demonstrates that incorporating scene flow information into loss can make model learn temporally coherent feature spaces. However, it is prohibitively expensive to acquire point correspondence information across frames in real - world environments. In this work, the authors propose a super - resolution generative adversarial network ( GAN ) for dynamic point cloud sequences without requiring point correspondence annotation. Their model, Temporal Point cloud Upsampling GAN ( TPU -GAN ), can implicitly learn the underlying temporal coherence from point - cloud sequence, which in turn guides the generator to produce temporal - coherent output. In addition, a learnable masking module is proposed to adapt upsampling ratio according to the point distribution."
SP:67efe60ad37807505369b7852bc0abed29ffdda8,This paper proposes a fully pre - trained encoder - only transformer for object detection. The main idea is to use query embeddings as visual prompts to help the model attend to the target area ( prompting ) and recognize the object. The proposed method is evaluated on the COCO dataset and compared with state - of - the - art detection transformers.
SP:a1f9897496303984fc7ad469222106b14b4a6233,"This paper studies the communication complexity of local - SGD in federated learning, where clients run local SGD steps before communicating their update to an orchestrating server. The authors propose FedPAGE, which leverages the recent optimal PAGE method to further reduce the communication costs. The communication cost for each round is the same in both convex and nonconvex settings. In the convex setting, the number of communication rounds is O(3/4 S ) of SCAFFOLD ( Karimireddy et al., 2020 ) by a factor of NS, if the sampled clients have the same communication cost. The best known result is O(\sqrt{N+S }, if clients have different communication cost )."
SP:81e74765abc6524edd8fdf9a3ba107d7bddaa04b,"This paper studies the decision boundary geometry of artificial neural networks ( ANNs ) in the presence of adversarial input perturbations. The paper defines adversarial subspaces, which are spanned by orthogonal directions of minimal perturbation to the decision decision boundary from any given input sample. The main contribution of this work is to further understand the decision boundaries geometry of ANN classifiers by utilizing such adversarial inputs. To date, the most widely used defense against test - time adversarial attacks is adversarial training. Using this analysis, the authors also provide new insight into the consequences of adversarially training by quantifying the increase in boundary distance within adversarial subsets and the decrease in boundary curvature."
SP:af5c25ecf38c5c3f3387720bdc80c2c54c5699fe,"This paper proposes an unsupervised representation learning approach for self - supervised representation learning. The idea is to cluster data according to its auxiliary information ( hashtags ) and learn similar representations within the same cluster and dissimilar representations for data from different clusters. The authors argue that the auxiliary information is a form of data clustering information. The auxiliary information can be interpreted as semantically similar with the same hashtags. Based on this intuition, the authors present a two - stage weakly - supervised contrastive learning approach. The first stage clusters data based on its auxiliary data information, and the second stage learns similar representations with the help of the cluster. The proposed method is evaluated on a number of datasets."
SP:0a92fcc52970201de4a66b1e76c93dbea9dfd3f1,"This paper proposes a learning - based algorithm for sparse estimation problems. The main idea is to use an unrolled version of the classic path - following algorithm, which has been shown to be effective at sparse estimation, to learn an algorithm that can be applied to any sparse estimation problem. The proposed algorithm, called PLISA, is shown to have improved recovery accuracy compared to the unrolled variant of the algorithm. The authors also provide an analysis of the generalization ability of the proposed algorithm."
SP:5064eda9ba27060af15e81b2b317b2e4558b0ac4,"This paper proposes a hybrid action representation method to learn a compact and decodable latent representation space for a discrete - continuous hybrid action space. The agent learns the action representation in the learned representation space and interacts with the environment by decoding the hybrid action embeddings to the original action space using conventional RL algorithms. The proposed method is evaluated in a variety of high - dimensional action spaces. The results demonstrate the superiority of the proposed method when compared with previous baselines, especially for high - dimension action spaces, in controlling with discrete or continuous action."
SP:5128bf712f6b197de113c7a371b4bec36f978eca,"This paper proposes SGEM, Stochastic Gradient with Energy and Momentum, to solve a large class of general non - convex stochastic optimization problems. SGEM incorporates both energy and momentum at the same time so as to inherit their dual advantages. The authors show that SGEM features an unconditional energy stability property, and derive energydependent convergence rates in the general nonconvex setting, as well as a regret bound in the online convex setting. A lower threshold for the energy variable is also provided. The experimental results show that the proposed SGEM converges faster than AEGD and generalizes better or at least as well."
SP:11f49b0a975be87769be29e85d7e3924699cf2c9,"This paper proposes a Conditional Masked Language Model with Correction ( CMLMC ) that addresses the indistinguishability of tokens and the mismatch between training and inference in non - autoregressive machine translation ( NAR ) approaches. The proposed method is motivated by the fact that NAR approaches can be time consuming, especially for long sequences of tokens, and the authors investigate possible reasons behind this performance gap. The authors propose to use conditional masking to improve the performance of NAR models. Empirically, the authors show that the proposed method achieves state - of - the - art performance when trained on multiple datasets, a first for NAR methods."
SP:96f8ac3c6163e56d8ae1954a162bae01e6b58a0a,This paper proposes a spiking neural network for keyword - spotting. The proposed method is inspired by the WaveNet architecture. The authors propose to use a neural network with spiking dynamics instead of a dilated convolutional network as a solution to the problem of low power local signal processing ( LSP ). They show that the proposed method can achieve state - of - the - art performance on several keyword - spotting datasets.   
SP:7f20a2e4e95f857140b87b0730360b3ff2f371f4,"This paper proposes Shifty, an algorithm for training fairness - aware models in the face of demographic shift in the distribution of subgroups of the population, which is known as demographic shift. The algorithm is based on the well - established Shifty algorithm, which was originally proposed in the 1980s and used to train a fairness model. The authors show that under the assumption that subgroups become more or less likely to be a part of the distribution during training, Shifty is more likely to learn a model that is fair than a baseline that does not learn such a model. They also show that Shifty outperforms the baselines on a real - world dataset of student entrance exams and a college admissions dataset. Finally, they show that the algorithm is applicable in practice and that the high - confidence behavioral guarantees are valid."
SP:94f097921bee5fdc10ec2e7c901b2ddb876d9d41,"This paper proposes Neural Stochastic Dual Dynamic Programming ( NSDDP ), an extension of stochastic dual dynamic programming ( SDDP ) that learns to map problem instances to a piecewise linear value function within intrinsic low - dimensional space. The key idea of SDDP is to solve successive problems by solving the first one first and then solving the second one. The proposed method is evaluated on a range of synthetic and real - world optimization problems. The results show that the proposed method can significantly reduce the problem solving cost without sacrificing solution quality."
SP:3d9f5132f9ec3807dbca78462a459fd123a09b24,"This paper proposes a privacy - preserving next - token prediction protocol for language models that are fine - tuned on a private corpus after pre - training on a public corpus. The authors claim that recent data - extraction attacks have exposed that language models can memorize some training samples verbatim. This is a vulnerability that can compromise the privacy of the model ’s training data. In this work, the authors introduce a practical protocol for private next token prediction called SUBMIX. It is designed to prevent privacy violations by language models such as GPT-2 language models.   The authors show that the proposed protocol limits the leakage of information that is unique to any individual user in the private corpus via a relaxation of group differentially private prediction. Importantly, it admits a tight, data - dependent privacy accounting mechanism, which allows it to thwart existing data - extractive attacks while maintaining the utility of the language model."
SP:7f524d186ea939309c7eeb843c62b6a4b4cfbc8a,"This paper proposes an unsupervised method to detect out - of - distribution ( OOD ) samples using a k - density estimator with respect to a classification model ’s intermediate activations on indistribution samples. The proposed method leverages a recent insight about label smoothing, which the authors call the Label Smoothed Embedding Hypothesis, and show that one of the implications is that the proposed method performs better as an OOD detection method both theoretically and empirically when the model is trained with label smoothed. The authors show that their proposal outperforms many OOD baselines and they also provide new finite - sample high - probability statistical results for k - NN density estimation’s ability to detect OOD examples."
SP:aafbd6ada14cc59a272fe4bf95fac71fa18e57ab,"This paper proposes a new representation learning method for GANs and VAEs based on denoising autoencoders. The main idea is to replace the standard encoder - decoder encoder framework in GAN and VAE with a diffusion - based encoder, where the encoder is denoised and the decoder is used to learn a latent code. The difference between the proposed method and the conventional encoder / decoder lies in the fact that the denoizing score matching objective is replaced by a multi - scale denoiser autoencoder. This allows for manual control of the level of details encoded in the representation representation. The authors show how adversarial training in diffusion based models can improve sample quality and sampling speed using a new approximation of the prior at smaller noise."
SP:8cfc837d5c10d539bbd098df7134c42e4830ba25,"This paper proposes a method for goal - conditioned reinforcement learning that learns a curriculum of intermediate states to reach distant goals by planning at training time. The method is based on graph search with two steps : an E - step to plan a sequence of waypoints using graph planning and a M - step that learns to learn a goal conditioned policy to reach those waypoints. The graph planning step is done by graph - searching on the current state space, while the M-step is used to learn goal conditioned policies. The main contributions of this paper are :   1. Propose an algorithm for goal conditioned RL that uses graph planning for planning only during training and not testing.   2. Demonstrate that their method is more sample efficient than prior methods and is able to solve very long - range navigation and manipulation tasks that prior goal - conditioned RL methods and methods based on graphs search fail to solve."
SP:ef3193842e06d4a6edb8a6a86ea5bc97ee5eaa4a,"Mixup is a popular regularization technique for training deep neural networks that can improve generalization and increase adversarial robustness. To better leverage the structure of the data, this paper extends mixup to k - mixup by perturbing k - batches of training data in the direction of other randomly - chosen instances in the training set. The authors demonstrate theoretically and in simulations that k - Mixup preserves cluster and manifold structures, and extend theory studying the efficacy of standard mixup   to the k-mixup case.   The empirical results show that training with k - mixesup further improves generalization   and robustness across several network architectures and benchmark datasets of differing modalities."
SP:0fe6a9848026e5f6436a380199e27a9ad26cffed,"This paper proposes to use the embeddings produced by a lightweight network more effectively with a nonlinear classification layer. The motivation is that conventional deep networks use an abundance of nonlinearity for representation ( embedding ) learning, but they almost universally use a linear classifier on the learned embedding vectors. This could be suboptimal for a network with a limited - capacity backbone since better nonlinear classifiers could exist in the same embedding vector space. The authors advocate a non - linear kernelized classification layer for deep networks to tackle this problem. They theoretically show that their classification layer optimizes over all possible radial kernel functions on the space of embedded vectors. They then demonstrate the usefulness of this layer in learning more model - efficient classifiers in a number of computer vision and natural language processing tasks."
SP:01ee8ec81619784788eb0ce9785098e437d17a7c,"This paper analyzes the sources of bias in node representations obtained via Graph Neural Networks ( GNNs ). The paper first shows that both nodal features and graph structure lead to bias in the obtained representations. Based on this analysis, two fairness - aware data augmentation frameworks on node features and graphs are developed to reduce the bias. Extensive experiments on node classification and link prediction are carried out over real networks in the context of graph contrastive learning. The results show that the proposed methods can improve the fairness in terms of statistical parity and equal opportunity."
SP:7739dc9e37f7f1384f87d2e60281e5bb27fece99,"This paper proposes a Confounder Balanced IV Regression ( CB - IV ) algorithm to jointly remove the bias from the unmeasured confounders with IV regression and achieve better bias - variance trade - off in the nonlinear setting. The proposed algorithm consists of three main modules : ( 1 ) regressing the treatment with IVs and balancing the confounder representation ; ( 2 ) outcome regression ; and ( 3 ) treatment effect estimation. Theoretically, the authors show that the proposed algorithm is also effective under the multiplicative assumption rather than the additive separability assumption. Extensive experiments demonstrate the effectiveness of the proposed method."
SP:fdb68c39fce254b73310a3101b2fe97ba47e69fe,"This paper studies the performance of MAML in a linear regression setting with a mixture of easy and hard tasks, where hardness is related to the rate that gradient descent converges on the task. The authors show that the hardness of the tasks must vary with respect to the task hardness in order for the hard tasks to be considered easy, and that the optimal solutions of the easy tasks are optimal solutions. They also provide numerical and analytical results suggesting that these insights apply to two - layer neural networks. Finally, they provide few - shot image classification experiments that support their insights for when MAMLU should be used and emphasize the importance of training on hard tasks in practice."
SP:e8143c7880c16ee9ce7a544e0fd80f001b1b4f9f,"This paper proposes a new method for semi - blind source separation in sparse sparse BSS. The method builds on the growing field of algorithm unfolding / unrolling and leverages the data - driven knowledge from realistic simulations or ground - truth data to leverage both the learned hyperparameters and the learned variables. The proposed method, called LPALM ( Learned PALM ), is an unrolled version of the popular PALM algorithm. The authors show that the algorithm not only needs up to 10 - 10 times fewer iterations than the original PALM but also improves the separation quality, while avoiding the cumbersome hyperparameter and initialization choice of PALM. The paper also shows that it outperforms other unrolled source separation methods in the semi - Blind setting."
SP:7716315001949ab88c8a216302fe51bae872fc87,"This paper proposes a transformer - based language model with implicit self - attention for language modeling. The authors argue that the performance of transformers has a power - law relationship with model size over six orders of magnitude, and that transformers exhibit impressive scaling but their performance hinges on processing large amounts of data, and their computational and memory requirements grow quadratically with sequence length. Motivated by these considerations, the authors introduce a novel attention module called implicit self attention and construct a Legendre Memory Unit based model that exhibits an O(n ) and O(\n lnn ) dependency for memory and computation respectively. They show that for the same amount of training their model improves the loss over transformers about as much as transformers improve over LSTMs. They also demonstrate that adding global self - attentions complements our architecture and the augmented model improves performance even further."
SP:832f422b3554e89702e13c8c5690ee26f2289e3b,"This paper proposes LatentKeypointGAN, a GAN - based method for unsupervised keypoint detection for image generation. The proposed method is trained end - to - end on the classical GAN objective with internal conditioning on a set of space keypoints. The keypoints have associated appearance embeddings that respectively control the position and style of the generated objects and their parts. The authors demonstrate that the latent space provided by the proposed method provides an interpretable latent space that can be used to re - arrange the generated images by re - positioning and exchanging keypoint embedding images. In addition, the explicit generation of keypoints and matching images enables a new method for key point detection."
SP:9206ae6e31077569313838504ef6daa89ad3b59c,"This paper studies the properties of fully connected neural networks with layer normalization and shows that increasing the depth of the network leads to gradient explosion or representation shrinkage. The paper shows that this phenomenon is not restricted to a specific initialization scheme or a choice of activation function, but rather is an inherent property of the fully connected architecture itself. The authors also show that many popular normalization techniques fail to mitigate these problems. The proposed method can also be applied to residual networks to guide the choice of initialization variances."
SP:2177be818b5843c580c787f1b2d725154846feb6,"This paper proposes a line search method for finding optimal step sizes for stochastic gradient descent based on the assumption that the full batch loss behaves locally parabolically in the direction of noisy update step directions, and the trend of the optimal update step size changes slowly. The proposed method approximates the full - batch loss with a parabola estimated over several mini - batches, and learning rates are derived from such parabolas during training. The authors evaluate the proposed method on deep learning models, datasets, and batch sizes on validation and test accuracy on CIFAR and ImageNet."
SP:62233782f9046c85617d9ccfe8427eae7d1c9da7,"This paper analyzes the performance of Noise - Contrastive estimation ( NCE ) methods with respect to the ill - behaved ( flat ) loss landscape. The authors show that NCE suffers from a flat loss landscape when the noise distribution used for training the NCE method is either too flat or too dense. To address this, the authors propose a variant of NCE called eNCE which uses an exponential loss and normalized gradient descent. The experimental results show that the proposed method performs better than the original NCE when the target loss landscape is flat."
SP:ceba6c1421b2d03863007fdaf029b8b946519c1b,"Privacy and Byzantine resilience ( BR ) are two crucial requirements of modern - day distributed machine learning. This paper studies the extent to which the distributed SGD algorithm, in the standard parameter - server architecture, can learn an accurate model despite ( a ) a fraction of workers being malicious ( Byzantine ), and ( b ) the other fraction whilst being honest, providing noisy information to the server to ensure differential privacy ( DP ). The authors first observe that the integration of standard practices in DP and BR is not straightforward, and show that many existing results on the convergence of distributedSGD under Byzantine faults, especially those relying on ( \alpha, b ) Byzantine resilience, are rendered invalid when honest workers enforce DP. To circumvent this, the authors revisit the theory of ( AAA, f)-Byzantine resilience to obtain an approximate convergence guarantee. The analysis provides key insights on how to improve this guarantee through hyperparameter optimization."
SP:bc783f0c829f90931535e63687d13172879631b3,"This paper considers the problem of code editing with few exemplars. The authors propose a novel deep learning approach to solve this problem by combining edit representations extracted from support exemplars and compositionally generalizing them to the query code snippet editing via multi - extend similarities ensemble. Specifically, they parse the support and query code snippets using language - specific grammar into abstract syntax trees and apply the similarities measurement in multiple extents from individual nodes to collective tree representations for query and support sample matching, and ensemble the matching results through a similarity - ranking error estimator. They evaluate the proposed method on C# and Python datasets, and show absolute accuracy improvements compared to the baseline methods."
SP:ca0c4bdb02f7d939fb6de38b6b446ced4b5984a0,"This paper proposes a generative model for generating sequences of structured data with a global coherence problem. The proposed method is based on two parts : ( i ) one model to generate a set of relational constraints and ( ii ) a second model that generates realistic data satisfying these constraints. The authors propose a program synthesis algorithm that infers the relational constraints present in the training data, and then learns a generator model based on the resulting constraint data. In the experiments, the authors show that their approach significantly improves over the baselines in terms of capturing high - level structure in the data, while performing comparably or better in term of low - level structures."
SP:692ae0c583a1585eff1a7d9c0d3b51b7879611cc,"This paper studies the problem of set - to - hypergraph prediction, where the goal is to infer the set of relations for a given set of entities from hypergraphs. The paper proposes a new algorithm for this problem, which is based on a linear asymptotic memory scaling from exponential to linear in the number of hyperedges and a new training method that encourages iterative refinement of the predicted hypergraph. The proposed algorithm is evaluated on a single - set and a multi - set setting.    The main contributions of the paper are :   1. A new algorithm to predict and supervise the positive edges only. 2. A linear memory scaling for the hyperedge generation. 3. A training method to improve efficiency and memory usage."
SP:e3481fb6d8d1aa45d6ed4a454e781f5a2c30c57e,"This paper proposes a post - processing method to mitigate bias in deep learning models. The proposed method consists in learning a shallow neural network, called the Ethical Module, which transforms the deep embeddings of a pre - trained model to give more representation power to the discriminated subgroups. The training is supervised by the von Mises - Fisher loss, whose hyperparameters allow to control the space allocated to each subgroup in the latent space. Besides being very simple, the resulting methodology is more stable and faster than most current methods of bias mitigation."
SP:3fb5dcc8b8fb731e09c14b16480cada1c7ccfaa7,"This paper proposes a new method for not forgetting knowledge about previous classes in class - incremental learning ( CIL ). The proposed method builds on top of KD ( knowledge distillation ), which penalizes inconsistencies across models of subsequent phases in CIL. The authors propose to compute the KD loss using placebo data from a free image stream ( e.g., Google Images ) that is both simple and surprisingly effective even when there is no class overlap between the placebos and the old data.   The authors empirically observe that this method both harms learning of new classes and also underperforms to distil old class knowledge from the previous phase model. This method does not require any additional additional supervision or memory budget, and can significantly improve a number of top - performing CIL methods, in particular on higher - resolution benchmarks, such as ImageNet-1k and ImageNet - Subset. For training this function, the authors sample pseudo CIL tasks from the data in the 0 - th phase and design a reinforcement learning algorithm. The evaluation function is used to quickly judge the quality of candidate images."
SP:506e0a888c03a955b708464eed3670c04baf4912,"This paper proposes a path auxiliary algorithm for energy - based models ( EBM ) that uses a composition of local moves to efficiently explore large neighborhoods and a fast version of the algorithm that only queries the evaluation of energy function twice for each proposal via linearization of the energy function. The authors show that their path auxiliary algorithms considerably outperform other generic samplers on various discrete models for sampling, inference, and learning. The method can also be used to train deep EBMs for discrete data."
SP:4b466277aa5561a80c48d5e72559de4ce95f228b,"This paper proposes Variational Predictive Routing ( VPR ), a generative model for learning spatiotemporal hierarchical latent representations of video features in a temporal hierarchy based on their rates of change. The model is based on a neural network that predicts the latent representation of the features at each level of the latent hierarchy, based on the rate of change of these features. The latent representations are used for event detection. The proposed method is evaluated on two standard video datasets ( CIFAR-10 and SVHN ), and compared with several baselines. The results show that VPR is able to detect event boundaries, adapt to the dynamics of the data, and adapt to changes in the observed features across the levels of the model's latent hierarchy."
SP:459ef2e6bd7638020955dbb4d8ae1098619f7b95,"This paper proposes an end - to - end and single - stage pipeline for image retrieval that combines global and local features in a unified global and attention - based local features retrieval method. The proposed pipeline consists of two stages : 1 ) it removes the re - ranking process and local feature matching, and 2 ) it learns more accurate and semantic local information through combining spatial and attention with the aid of intermediate supervision. Experiments on Revisited Oxford and Paris datasets validate the effectiveness of the proposed method, and it achieves state - of - the - art performance."
SP:487cc308a1e8ee078c54b2158bcae47e920e73f8,"This paper proposes a new algorithm, RotoGrad, that jointly homogenizes gradient magnitudes and directions across tasks while ensuring training convergence. The motivation of this work is to address the problem of negative transfer in multi - task optimization, which is a two - fold problem : ( 1 ) disparities in gradient magnitude and directions between tasks ; and ( 2 ) greedily changing the gradient directions. The authors propose to tackle the problem as a whole by homogenizing the gradient direction and magnitude of the objective function. The proposed method is evaluated on the CelebA and CIFAR-10 datasets, where it is shown to outperform other homogenized gradient methods."
SP:050cd8319d84a1bd8c2ccb930ba69b33c8fb6e60,"This paper proposes a method to fuse heterogeneous neural networks with different number of layers via cross - layer alignment. The proposed method is a variant of OTFusion, which applies soft neuron association to unify different pre - trained networks to save computational resources. The authors propose a novel model fusion framework, named CLAFusion, to fuse networks with a different number   of layers. They also explore the application for model compression and knowledge distillation when applying to the teacher - student setting. Synthetic experiments indicate that the proposed method achieves a more favorable performance compared to the individual networks trained on heterogeneous data."
SP:f764eae15cd083fdb4eb2af09ac64c2d878a454f,"This paper studies the implicit regularization effect of SGD in deep reinforcement learning ( RL ). The authors show that SGD - based regularization can lead to poor generalization and degenerate feature representations in the offline RL setting. They propose an explicit regularizer, DR3, that counteracts the undesirable effects of this implicit regularizer. Experiments on Atari 2600 games, D4RL domains, and robotic manipulation from images validate the effectiveness of DR3."
SP:6fd793b27123bf80504e2ad5957455b7ec311612,"This paper proposes HyperDQN, a variant of Randomized least - square value iteration ( RLSVI ) for deep reinforcement learning ( DQN ). The proposed method is based on a probabilistic hypermodel ( meta model ) that outputs the parameter of the base model, which is jointly optimized under a specifically designed objective. The paper claims three main contributions : ( 1 ) The hypermodel is able to generate approximate posterior samples of the posterior Q - value function, ( 2 ) The posterior samples can be obtained in a more efficient way than the existing methods, and ( 3 ) The method achieves the maximum human - normalized score on the Atari suite for SuperMarioBros."
SP:b428383660928374c953f659ea1e05852dbdcd6e,"This paper proposes to learn causal representation from observational data by regularizing the learning procedure with mutual information measures according to our hypothetical causal graph. The optimization involves a counterfactual loss, based on which the authors deduce a theoretical guarantee that the causality - inspired learning is with reduced sample complexity and better generalization ability. Extensive experiments show that the models trained on causal representations learned by our approach is robust under adversarial attacks and adversarial shift."
SP:1258c05a80a17949b50e6dae13deea1d2235f456,"This paper proposes ProgFed, a progressive training framework for efficient and effective federated learning. It inherently reduces computation and two - way communication costs while maintaining the strong performance of the final models. Theoretically, the authors prove that the convergence rate of Prog Fed converges at the same asymptotic rate as standard training on full models. Extensive results on a broad range of architectures, including CNNs ( VGG, ResNet, ConvNets ) and U - net, show that the proposed method is highly effective and saves up to 20 % computation and up to 63 % communication costs."
SP:8cdaa6e0dafd750ebdb5d7a4c1987a042400662f,"This paper studies the generalization of adversarial training through the lens of the adversarial Rademacher complexity of deep neural networks ( DNNs ). The authors propose a method to overcome the difficulty of analyzing adversarial complexity of two - layer neural networks in the standard adversarial setting by removing the first layer of the DNN during training. They provide an upper bound on the adversarially trained DNN ’s adversarial R - complexity that is independent of the second layer. They also provide experiments to show that the upper bound also includes the product of weight norms and adversarial weight norms, thus providing an explanation for the bad generalization performance of adversariar training."
SP:925d6bb051e9b384669fb695085b678c11f7c11a,"This paper proposes a differentiable kernel - based estimator for differential entropy and conditional differential entropy. The proposed method builds on top of existing works on differential entropy estimation and mutual information estimation. The main contribution of this paper is the development of a fully parameterized, differentiable framework for differential and conditional entropy estimation. In addition, the proposed method can be used to derive mutual information estimators. Experiments on synthetic and real - world tasks demonstrate the effectiveness of the proposed methods."
SP:d2f3beac855f0d72c13552fecb2bdb9d42195df3,"This paper proposes a new soft - greedy operator for deep reinforcement learning, called resmax, which is a variant of softmax and \�-greedy. The key idea of resmax is to take actions proportionally to their suboptimality gap : the residual to the estimated maximal value. The authors show that resmax does not concentrate probability as quickly as softmax, and so better avoids overemphasizing sub - optimal actions that appear high - valued during learning. They also prove it is a non - expansion for any fixed exploration method that requires a state - action - specific temperature to obtain a non-expansion ( called mellowmax )."
SP:792ae8808aa6902758146aef1548c975492b833c,"This paper proposes a new concept called “ learnability lock ” for controlling the model ’s learnability on a specific dataset with a special key. In particular, the authors propose adversarial invertible transformation, which is a mapping from image to image, to slightly modify data samples so that they become “ unlearnable ”. The proposed method can be easily restored with a simple inverse transformation while remaining difficult to be detected or reverse - engineered. Experiments demonstrate the success and practicability of the method on visual classification tasks."
SP:9af10703605e620e563241e2602a50b629f3d37a,"This paper proposes a new approach for dealing with missing features in graph neural networks ( GNNs ). The proposed approach is based on minimization of the Dirichlet energy and leads to a diffusion - type differential equation on the graph. The discretization of this equation produces a simple, fast and scalable algorithm which the authors call Feature Propagation. Experiments show that the proposed approach outperforms previous methods on seven common node - classification benchmarks and can withstand surprisingly high rates of missing features when 99 % of the features are missing."
SP:cbaa3f1379fa99159899d79ccb479c0187403aca,This paper proposes a method for active learning that minimizes the discrete Wasserstein distance between a core subset of unlabeled data and the whole unlabelled data pool. The core subset is selected by minimizing the Wassersteins' distance between the labeled subset and the rest of the data set. The proposed method is based on a Generalized Benders Decomposition ( GBD ) approach that uses high - quality latent features that can be obtained by unsupervised learning on the labeled data. Experiments show that the proposed GBD approach outperforms existing active learning methods in the low - data regime where less than one percent of the training data set is labeled.
SP:4c72923f78ca6590dc11e10d1a2403076a583718,"This paper proposes a deep learning approach for de novo genome assembly. The approach is based on graph convolutional networks ( GCNs ) that are trained on a dataset generated from human genomic data to reconstruct the genome by finding a path through the assembly graph. The authors show that their model can compute scores from the lengths of the paths found by greedy search algorithms, outperforms the greedy search over the overlap lengths only, and reconstructs the correct path in the fraction of time required for the state - of - the - art de - novo assemblers. This favourable result paves the way for the development of powerful graph machine learning algorithms that can solve the genome assembly problem much quicker and possibly more accurately than human handcrafted techniques."
SP:24de906e4289c9073b6c55c747b0913b8df5e053,"This paper proposes a new meta - learning method for continual learning. The authors propose to use experience replay ( ER ) for meta - testing and also integrate it into the meta - training of online - aware continual learning ( OML ). They propose to store the samples ’ representations, instead of the samples themselves, into the replay buffer. The learned representations have better clustering structures and are more discriminative. They also introduce a meta - learneded Predictive Sample Selection ( SAP ) to replace the widely used reservoir sampling for the most significant samples to be stored, rather than relying on randomness. Experimental results show that the proposed method outperforms the state - of - the - art."
SP:3c78454f053f74930979a8054cd7c8a34b6fe63d,"This paper studies the problem of multi - agent joint Q - learning in the context of centralized training with decentralized execution ( CTDE ). The authors formulate an explicit credit assignment problem where each agent gives its suggestion about how to weight individual Q - values to explicitly maximize the joint $ Q$-value, besides guaranteeing the Bellman optimality of the joint Q-value. Theoretically, the authors give a gradient ascent solution for this problem. Empirically, they instantiate the core idea with deep neural networks and propose Explicit Explicit Credit Assignment ( ECAQ ). Extensive experiments show the effectiveness of the proposed method."
SP:0d2b225ac697679d10df25f371b2a718d4949b42,"This paper proposes a new attack framework called Greedy Model Space Attack ( GMSA ) that can be used as a new baseline for evaluating transductive - learning based defense mechanisms. GMSA is based on the principle of attacking model space for solving bilevel attack objectives, and the authors show that GMSA, even with weak instantiations, can break previous defenses, which were resilient to previous attacks, such as AutoAttack. On the positive side, the authors report a somewhat surprising empirical result of “ adversarially adversarial training ” : Adversarially retraining the model using fresh randomness at the test time gives a significant increase in robustness against attacks."
SP:e7024cae196fc5eb6a62d289a95d76b532b6a36c,"This paper studies the problem of batch normalization ( BN ) in deep learning. The authors cast BN as an approximation of the limiting case where the entire dataset is normalized jointly, and explore other ways to approximate the gradient from this limiting case. They demonstrate an approximation that removes the need to keep more than one example in memory at any given time, at the cost of a small factor increase in the training step computation, as well as a fully per - example training procedure. They further use their insights to improve batch renormalization for very small minibatches."
SP:4aa42984fcb0fd66936d668477b2719ef5c427d4,"This paper proposes a method for reducing the number of trainable parameters in large language model pre - training and fine - tuning. The main idea is to freeze the weights of the pre - trained model weights and inject rank decomposition matrices into each layer of the Transformer architecture. The proposed method is called Low - Rank Adaptation ( LoRA ). Compared to GPT-3 175B fine - tuned with Adam, LoRA performs on par or better than GPT - 3 despite having fewer trainable parameter, a higher training throughput, and no additional inference latency."
SP:b77a00beb0802f47810b03d3c4aa24d92781414f,"This paper proposes a regularized linear - chain conditional random field ( CRF ) model that can enforce a broad class of constraints, including nonlocal ones, by specifying the space of possible output structures as a regular language L. The resulting regular - constrained CRF ( RegCCRF ) has the same formal properties as a standard CRF, but assigns zero probability to all label sequences not in L. Notably, the authors show that RegCC RFs can incorporate their constraints during training, while standard CRFs are unable to respect nonlocal constraints of the data ( such as global arity constraints on output labels ). The authors also demonstrate that constrained training is never worse than constrained decoding, and show empirically that it can be substantially better in practice.   The authors demonstrate a practical benefit on downstream tasks by incorporating a Reg CCRF into a deep neural model for semantic role labeling, exceeding state - of - the - art results on a standard dataset."
SP:74c186a96c12adff178264aa84ace8d04dc7d725,"This paper proposes two end - to - end neural models for physiological measurement of the human body mass index ( HRM ) from video frames. The first model, EfficientPhys, is an end to end model that removes the need for face detection, segmentation, normalization, color space transformation, or any other preprocessing steps. The second model is a network architecture that is a combination of a convolutional backbone and a transformer. The proposed models achieve state - of - the - art accuracy on three public datasets for HRM. The authors also evaluate the latency of the proposed networks and show that our most light weight network network achieves a 33 % improvement in efficiency."
SP:3003bab6e3f7e2e21cd6cf27ee7d483d877d9fb3,"This paper proposes Hardware - Aware Latency Pruning ( HALP ) that formulates structural pruning as a global resource allocation optimization problem, aiming at maximizing the accuracy while constraining latency under a predefined budget. The proposed method leverages latency lookup table to track latency reduction potential and global saliency score to gauge accuracy drop. The paper also proposes an augmented knapsack solver that enables HALP to surpass prior work in pruning efficacy and accuracy - efficiency trade - offs. Extensive experiments show that the proposed method outperforms prior art, sometimes by large margins."
SP:c44d676c09c8e5a70d73b21b507b41a422fec809,"This paper proposes GraphEBM, an energy - based model for multi - objective molecular graph generation. The main idea is to learn a parameterized energy function that is permutation invariant. The energy function is learned by contrastive divergence and Langevin dynamics. To generate molecules with a specific property, the authors propose a simple yet effective learning strategy, which pushes down energies with flexible degrees according to the properties of corresponding molecules. The authors also explore to use GraphE BM for generating molecules towards multiple objectives via compositional generation, which is practically desired in drug discovery. The proposed method is evaluated on random, single - objective, and multi - objective molecule generation tasks."
SP:70e60fa5deef3e3ba77d05d0c3e0e7fbf396aa1d,"This paper proposes a neural - based bottom - up program synthesis method, CROSSBEAM, that trains a neural model to learn a hands - on search policy for program synthesis, instead of relying on a combinatorial search algorithm. The proposed method is trained on - policy using data extracted from its own bottom - upsourced searches on the state - of - the - art program synthesis methods. Experiments show that the proposed method learns to search efficiently, exploring much smaller smaller portions of the search space compared to other methods. The main contribution of this paper is that it proposes a method that learns to combine previously explored programs into new programs by taking into account the search history and partial program executions."
SP:daa044ffefe80bae16b014f60061d941ed8c2ba6,"This paper proposes a new training method for deep reinforcement learning ( DRL ) based on squared Bellman error regularization ( QBE ). The proposed method is a generalization of target networks, which is used to stabilize training in the presence of fast - changing target Q - values. The authors argue that target networks can inhibit the propagation of newly - encountered rewards during training, which may slow down training. To address this issue, the authors propose to regularize the QBE with a functional regularizer that is explicit and enables us to use up - to - date parameters as well as control the regularization. This leads to a faster yet more stable training method. Experiments show that the proposed method improves over target - network based methods in terms of both sample efficiency and performance."
SP:dd174014d056a7d2bc86ee99119841eafa62ed52,"This paper proposes a new graph neural network ( GNN ) architecture, GraphSNN, that incorporates structural properties of graphs into the message - passing aggregation scheme of GNNs. The authors develop a hierarchy of local isomorphism on neighborhood subgraphs, and theoretically characterize how message - passing GNN can be designed to be more expressive than the Weisfeiler Lehman test in distinguishing graph structures. To elaborate this characterization, a novel neural model is proposed and empirically verified the strength of our model on different graph learning tasks. It is shown that the proposed model consistently improves the state - of - the - art methods on the benchmark tasks without sacrificing computational simplicity and efficiency."
SP:beb9ba0261e176bfc50e9bf5bed2b6169d388285,"This paper proposes a novel prediction interval ( PI ) method for uncertainty quantification, which addresses three major issues with the state - of - the - art PI methods. First, existing PI methods require retraining of neural networks ( NNs ) for every given confidence level and suffer from the crossing issue in calculating multiple PIs. Second, they usually rely on customized loss functions with extra sensitive hyperparameters for which fine tuning is required to achieve a well -calibrated PI, and they usually underestimate uncertainties of out - of-distribution ( OOD ) samples leading to over - confident PI. Third, this paper addresses OOD identification challenge by introducing an initialization scheme which provides reasonably larger PIs of the OOD samples than those of the in - distribution samples. The proposed PI3NN method calculates PIs from linear combinations of three NNs, each of which is independently trained using the standard mean squared error loss. The coefficients of the linear combinations are computed using root - finding algorithms to ensure tight PIs for a series of confidence levels without retraining NNs and it completely avoids the cross issue."
SP:4b44a834e2212bacb4c2d9408a81f1efc76a670b,"This paper proposes a fully online meta - learning ( FOML ) algorithm that stays fully online without resetting back to the pre - trained weights. The main idea is to use meta - training and meta - adapting to adapt to changing tasks and input distributions in online settings. The proposed algorithm is evaluated on two public online learning datasets, Rainbow - MNIST and CIFAR100, and compared with several baselines. The experimental results show that the proposed method is able to learn new tasks faster than the state - of - the - art online learning methods."
SP:fbae35cb171b3a3eb7c5d4bc83881ed7c4a70aae,"This paper proposes a differentiable scaffolding tree ( DST ) that utilizes a learned knowledge network to convert discrete chemical structures to locally differentiable ones. DST enables a gradient - based optimization on a chemical graph structure by back - propagating the derivatives from the target properties through a graph neural network ( GNN ). The empirical studies show that DST is both effective and sample efficient, and the learned graph parameters can also provide an explanation that helps domain experts understand the model."
SP:61b59899cf6ae442d9f8f5226e79708a4280cfb2,This paper proposes a knowledge - augmented approach to predict lab test response for a target lab result. The proposed method models drug - lab interaction and diagnosis - lab interactions as graphs and predicts patients ’ response for target lab test results. It also takes into consideration patients’ past lab responses to personalize the prediction. Experiments on real - world datasets demonstrate the effectiveness of the proposed solution in reducing prediction errors by a significant margin.
SP:8623cebb515c4a736427449b46ad2cdf8b806b77,"This paper proposes an open - set single domain generalization ( OS - SDG ) setting, where target domains may contain unseen classes out of the source label space. The authors propose a CrossMatch approach to improve the performance of SDG methods on identifying unknown classes by leveraging a multi - binary classifier. The CrossMatch generates auxiliary samples out of source domain label space by using an adversarial data augmentation strategy. They also adopt a consistency regularization on generated auxiliary samples between multibinary classifiers and the model trained by the model on unknown class identification. Experimental results on benchmark datasets prove the effectiveness of CrossMatch on enhancing the performance in the OS -SDG setting."
SP:126f8ffb855aa22eda4d681a499953879ed3679e,"This paper studies two trust region methods based on Kullback - leibler divergence for policy optimization in reinforcement learning, namely Wasserstein policy optimization ( WPO ) and Sinkhorn trust region ( SPO ). Theoretically, they show that WPO guarantees a monotonic performance improvement, and SPO provably converges to WPO as the entropic regularizer diminishes. Experiments across tabular domains and robotic locomotion tasks further demonstrate the performance improvement of both approaches."
SP:999eacf6500c87205584a3256d7ca45b3016fb1c,"This paper proposes a forget - and - re - learn framework for shaping the learning trajectories of artificial neural networks. The forgetting step selectively removes undesirable information from the model, and the relearning step reinforces features that are consistently useful under different conditions. The proposed framework unifies many existing iterative training algorithms in the image classification and language emergence literature, and allows us to understand the success of these algorithms in terms of the disproportionate forgetting of undesirable information. The authors leverage this understanding to improve upon existing algorithms by designing more targeted forgetting operations."
SP:2789859517b6624730b14a7e010444a72d3dd3ed,"This paper proposes a new offline - online setting for batch reinforcement learning ( batch RL ), where an agent is trained offline and evaluated online with access to a new batch of data during the evaluation phase. The goal is to improve the performance of batch RL, which has been shown to be limited in both theory and practice without strong assumptions on the data - collection process or a good policy. To enable better performance, the authors propose an extension to batch RL that allows the agent to adapt to new situations without having to precommit to a policy. The experiments show that standard RL agents trained offline or online can outperform agents trained only online, sometimes by a large margin, highlighting the potential of this new setting."
SP:76625a25e770415599a34122110d61cb3b7e614c,"This paper studies the problem of domain generalization ( DG ) via learning to reduce domain shift with an episodic training procedure. Theoretically, the authors give a PAC - style generalization bound for discrepancy - optimal meta - learning and further make comparisons with other DG bounds including ERM and domain - invariant learning. The theoretical analyses show that there is a tradeoff between classification performance and computational complexity for discrepancy optimal meta learning.   The theoretical results also shed light on a bilevel optimization algorithm for DG. Empirically,   the authors evaluate the algorithm with DomainBed and achieves state - of - the - art results on two domains."
SP:6421a9759c766641fd8c128a249f1a9c5699d19c,"This paper proposes a deep neural network - based best - first search method for hard planning problems in NP - complete Sokoban domains. The authors propose a tree model to explain the existence of left heavy tails and show that the policy network is a powerful heuristic guiding the search, which can lead to left heavy tail with polynomial scaling by avoiding exploring exponentially large sub - trees. They also demonstrate the importance of random restart strategies, as are widely used in traditional combinatorial solvers, for DNN - based search to avoid left and right heavy tails."
SP:84c415bc0f120d1997289f91661ff74e7297d3bd,"This paper proposes a meta - learning method for imitation learning from video demonstrations. The key idea is to learn an imitation policy from videos of human demonstrations, and to train the imitation policy with adaptive loss based on the quality of the data. The proposed method is evaluated on two tasks : ( 1 ) translating human videos into practical robot demonstrations and ( 2 ) imitation learning on a set of tasks. The first task is to translate the human video demonstrations into robot actions, and train a policy to imitate the robot actions. The second task is an imitation learning task where the robot is given a task label and asked to imitate another robot's actions. In both cases, the goal is to minimize the distance between the actions of the robot and the label of the human action.   The proposed approach is evaluated in two settings. In the first setting, a single video demonstration is used, and the policy is trained with a loss function that adapts the loss function depending on whether or not the video is a good representation of the action. The method is compared to a number of baselines in the literature, and is shown to outperform the baselines on both a toy task and imitation learning tasks. In addition, the method does not require a large number of demonstrations in the second setting, which is helpful for data collection."
SP:fedf5c75e83d6ab41ef9d5daa9054ffe4e424ec2," is a well - known gradient - based optimizer for image classification. However, it is also well known that, even with weight decay ( WD ) and normal hyper - parameter tuning, adaptive optimizers lag behind SGD a lot in terms of generalization performance, mainly in the image classification domain. In this paper, the authors try to address this issue by regularizing the output scores and the network weights during training. They show that, without appropriately tuned regularization, such networks have the tendency to make output scores ( logits ) and network weights large, causing training loss to become too small and the model to lose adaptivity ( ability to move around and escape regions of poor generalization ) in the weight space."
SP:819df8d847a99f13ed5efdcabae8b464c12b464b,"This paper proposes a new approach to group equivariant convolutional neural networks ( G - CNNs ) that respects group symmetries when they are present in the data. The main idea is to constrain features to respect the chosen symmetricries and to use partial equivariance when necessary. The authors propose a method called Partial GCNNs, which respects group symmetry partially. The idea is that a subset of a group can be represented better than the group as a whole in some cases, e.g., rotation in [ 90 - 90 \right]^{-90 }, and the subset can be better represented by the subset than the whole group. In such cases, a model that respects symmetry partially is better suited to represent the data than a full GCNN. The proposed method is applicable to discrete groups, continuous groups, and combinations thereof.   The authors also propose an extension of the method to continuous groups."
SP:0c0ca9df96f1fa2eb8b83a47d0d5964590fef290,"This paper proposes an amortized Langevin dynamics ( ALD ) for deep latent variable models, which replaces the datapoint - wise MCMC iterations with updates of an inference model that maps observations into latent variables. The proposed ALD can be trained faster than non - amortised MCMC methods, and it can generate better samples in terms of the Fréchet Inception Distance ( FID ) compared to AVI - based methods, such as the variational autoencoder1. The authors also evaluate ALD on the image generation task using three datasets."
SP:5631097031c7e599bdeae64366ffa6e4558837c6,"This paper studies the problem of hypergraph reasoning, i.e., predicting the relationship between several entities based on the input facts. The authors observe that in logical reasoning, logical rules usually apply locally ( e.g., only three people are involved in a grandparent rule ) and sparsely ( e. g., the grandparent relationship is sparse across all pairs of people in the world ). Inspired by these observations, the authors propose Sparse and Local Neural Logic Machines ( SpaLoc ), a structured neural network for hyper graph reasoning that leverages the sparsity in hypergraph neural networks to represent the grounding of relationships such as parent and grandparent as sparse layers and uses neural networks and finite - domain quantification operations to infer new facts. To remedy the information loss in sampled sub - graphs, a novel novel sampling and label calibration paradigm based on an information - theoretic measure information sufficiency is proposed to measure information efficiency. The proposed method shows superior accuracy and efficiency on synthetic datasets compared with prior art and achieves state - of - the - art performance on several real - world knowledge graph reasoning benchmarks."
SP:9657121b01c51f78c00d06b47d3e8d678dd85d54," top - k classification accuracy is one of the core metrics in machine learning. In this work, the authors relax the assumption that k is conventionally a positive integer, such as 1 or 5, and propose to draw k from a probability distribution for training. They find that relaxing k not only produces better top - 5 accuracies, but also makes models more robust, which leads to top - 1 accuracy improvements. When finetuning publicly available ImageNet models, they achieve a new state - of - the - art on ImageNet for publicly available models with an 88.37 % top-1 accuracy and a 98.68 % top -5 accuracy."
SP:cb3188f435c54a365890e20e4d582c250d919833,"This paper proposes a fast and reliable method for solving large - scale optimal transport ( OT ) problems at an unprecedented combination of speed and accuracy. The proposed method builds on the celebrated Douglas - Rachford splitting technique and tackles the original OT problem directly instead of solving an approximate regularized problem, as many state - of - the - art techniques do. This allows to provide sparse transport plans and avoid numerical issues of methods that use entropic regularization. The algorithm has the same cost per iteration as the popular Sinkhorn method, and each iteration can be executed efficiently, in parallel, to solve the OT problem efficiently. This paper enjoys an iteration complexity $ O(1/\epsilon^2)$ compared to the best - known $ O($(1 / O))$ in the literature, and establishes a linear convergence rate for the formulation of the optimal transport problem. The authors also detail an efficient GPU implementation of the proposed method."
SP:9a087cc734a3e7f3ab848bef5e2eff37fe40f303,"This paper proposes a framework for disentangling performance gaps between clients and non - clients in federated learning. The framework is based on the idea of OOD ( out - of - sample gap ) and participation gap ( participation gap ) in meta - learning, where clients are drawn from a meta - distribution, and their data is drawn from local data distributions. The authors observe and explain differences in behavior across natural and synthetic federated datasets. They propose a semantic synthesis strategy that enables realistic simulation without naturally - partitioned data. They also call out community suggestions for future federated - learning works."
SP:da0e8c89f343abfe500eb4c1968e418c2fb52ef6,"This paper studies the few - shot learning of language models ( PLMs ) for the zero - shot setting. The authors find that PLMs with self - supervised objectives ( i.e., self - supervision ) can achieve impressive results on the multi - task datasets ( e.g., IMDB, Amazon and BERT ), but also observe some limitations of PLMs under the zero shot setting, particularly for the language understanding tasks ( GLUE ).    The authors propose to further study the potential and limitations of the PLMs for the two - shot and the single - shot settings to further improve the generalization ability of the pre - trained language models."
SP:9817dccb1a121058b23a2ef825ed339cf8b53674,"This paper proposes a method for improving the performance of the attention mechanism. The key idea of the proposed method is to use an image - based sharpener module in the attention module to improve the alignment and interpretability of attention. Specifically, the sharpener tries to align relevant parts of the encoded image with the target output. The authors claim that most of the existing attention methods fail to build clear alignment because the aligned parts are unable to well represent the target. To solve this problem, the authors propose to use a target - specific representation to refine the representation of the encoder and the decoder. Experiments on synthetic handwritten digits and real - world scene text recognition datasets show that the proposed approach outperforms the mainstream attention methods."
SP:3913ed3b3cf6494368e3be6cacb637ff85f80ee6,"This paper proposes a supervised deep learning approach to learn a complete vehicle routing plan for a fixed number of vehicles from scratch. The approach is based on the recently developed deep reinforcement learning approaches either improve an initially given solution iteratively or sequentially construct a set of individual tours. The authors argue that most of the existing learning - based approaches bypass the complex assignment problem of the customers onto an apriori given number of available vehicles and thus make them less suitable for real applications, as many logistic service providers rely on solutions provided for a specific bounded fleet size and can not accommodate short term changes to the number of vehicle. The proposed approach constructs a complete tour plan from scratch while respecting an apriori fixed set of vehicles. The experimental results show that the proposed approach achieves competitive results that incorporate the practical aspect of vehicle costs."
SP:594a813c0d0baa66738b9c8331370f861ad3c416,"This paper proposes a link prediction method for graph learning based on counterfactual inference. The idea is to learn the causal relationship between two sets of variables : ( 1 ) the observed graph structure and ( 2 ) the existence of link between a pair of nodes. The authors propose a causal model that considers the information of the node pair ( i.e., learned graph representations ) as context, global graph structural properties as treatment, and link existence as outcome. The proposed method is evaluated on two benchmark datasets and achieves state - of - the - art performance on link prediction."
SP:48a7e50451b887f55be17b2662aa11ce18791cc1,"This paper proposes a two - stage method for unsupervised feature selection via knowledge contrastive disTillation ( SOFT ) that incorporates the second - order covariance matrix with the first - order data matrix for feature selection. In the first stage, a sparse attention matrix is learned to represent the second order relations between features. The second stage builds a relational graph based on the learned attention matrix and performs graph segmentation for the selected features in the second stage. The proposed method is evaluated on 12 public datasets and compared with two SOFT baselines."
SP:14bcae11aeede63f28d1b80c05ed18a01d3e3f3c,"This paper proposes a semisupervised multi - modal VAE ( MEME ) model to model the joint distribution over heterogeneous data ( e.g. vision, language ). The proposed method is based on mutual supervision of semisupered representations learnt by mutual supervision in the latent space of the VAE. This formulation naturally allows learning from partially - observed data where some modalities can be entirely missing, something that most existing approaches either cannot handle, or do so to a limited extent. The authors demonstrate that MEME outperforms existing methods on MNIST-SVHN ( image - image ) and CUB ( image–text ) datasets. They also compare the quality of the representations learned by MEME against standard approaches and observe interesting trends in its ability to capture relatedness between data."
SP:e834a52cadebe5f125ce491273b4ad1146beae3f,"This paper proposes Deep Explore Options, a method for combining intrinsic and extrinsic rewards in a deep reinforcement learning framework. The idea is to learn a set of intrinsic rewards that are independent of each other. These intrinsic rewards can be either from multiple intrinsic sources or from a single source. The authors propose to use a J - PER method to learn these intrinsic rewards. The proposed method is evaluated on hard and easy exploration games of the Atari Suite. The results show that the proposed method outperforms the baselines in 4 of the 6 tested environments."
SP:41578dd1a4bdb043b3d68afa5f9cebb3e14f3907,"This paper proposes a new method for learning Hamiltonian dynamical systems from data. The proposed method splits the training data into stiff and nonstiff portions based on a stiffness - aware index. This classification along with a resampling technique allows the authors to apply different time integration strategies such as step size adaptation to better capture the dynamical characteristics of the Hamiltonian vector fields. The authors evaluate SANN on complex physical systems including a three - body problem and billiard model and show that SANN is more stable and can better preserve energy when compared with the state - of - the - art methods, leading to significant improvement in accuracy."
SP:bfb0a059eeb6f40a18fbd20c0eec5037a64ca09e,"This paper studies the multi - step computations in large pre - trained language models. The authors first train a transformer model on a few - shot task and then ask it to perform multistep computations when asked to perform the operation “ step by step ”, showing the results of intermediate computations. They find that these same models are able to perform multi - stage computations even in the few shot regime. They further train Transformers to emit intermediate computation steps into a “ scratchpad ” step - by - step computation, where they find that the same models can also perform complex computations with unbounded multi - steps computations, such as adding integers or executing programs.    The paper concludes with a series of increasingly complex tasks."
SP:e6c1a8b4bba287455dc9cf145b6bd1f04e2148a9,"This paper proposes a novel method for generating adversarial perturbations at the feature level of deep neural networks that are both physically and semantically differentiable. The method is based on deep image generators and a novel optimization objective. The authors show that their adversarial attacks can generate targeted feature - level attacks at the ImageNet scale that are simultaneously interpretable, universal to any source image, and physically - realizable. They also show that these attacks can reveal spurious, semantically - describable feature / class associations that can be exploited by novel combinations of natural objects. Finally, they use them to guide the design of “ copy / paste adversaries ” that can cause a targeted misclassification."
SP:873618263dc4246a39c44d0abfecfb5f688817e3,"This paper proposes a new Simulated Annealing ( SA ) method that leverages deep reinforcement learning ( RL ) to improve the global optimisation of stochastic global optimization problems. The authors propose to use a neural network to learn the proposal distribution of a set of neighbors for each solution, which is then used to optimize the SA global optimizer. The proposed method is shown to outperform existing SA methods with hand - selected parameters on a number of problems."
SP:cae31f7436920eb3946e3f5bca0ac88a73d7c3ec,"This paper studies the problem of non - stationarity in multi - agent reinforcement learning ( MARL ). It proposes a novel notion, the $ \delta$-stationarity metric, to explicitly measure the non - stability of a policy sequence in MARL. It shows that the divergence of consecutive joint policies can be bounded by the KL divergence, which is a straightforward but highly non - trivial way to control the joint policies ’ divergence. It also proposes a trust - region decomposition network ( TRD - Net ) based on message passing to estimate the joint policy divergence more accurately. The proposed method, Multi - Agent Mirror descent policy algorithm ( MAMT ), is established by adjusting the trust-region of the local policies in an end - to - end manner. The experimental results show that the proposed method can bring noticeable and stable performance improvement compared with baselines in cooperative cooperative tasks of different complexity."
SP:989b58167a15ae4fafbe27ff534d327991b6c4d7,"This paper proposes a self - supervised representation learning framework for both lip - reading and speech recognition. The proposed method, AV - HuBERT, is based on the idea of "" hidden unit Bert "", which is a multi - modal encoder - decoder model for multi - stream audio - visual speech. The key idea is to learn a set of hidden units for both audio - only speech recognition and speech - to - lips. The method is evaluated on the LRS3 lip reading dataset, where it achieves a 32.5 % WER with only 30 hours of labeled data, outperforming the state - of - the - art approach ( 33.6 % ) trained with a thousand times more transcribed video data."
SP:7c9eb8aa4a4dcb5965157d860e812d81654e3aa7,"This paper proposes a new reinforcement learning algorithm for combinatorial optimisation of graphs. The proposed algorithm, called ECORD, is based on the idea of a recurrent unit that acts as a graph neural network ( GNN ) at a single pre - processing step, before entering a fast - acting exploratory phase directed by the recurrent unit. The authors demonstrate that ECORD achieves a new SOTA for reinforcement learning algorithms on the Maximum Cut problem, and also provides orders of magnitude improvement in speed and scalability compared to the state - of - the - art."
SP:f741d980c9c560a21298e947f1605dcbab7ceeac,"This paper proposes to train a VAE with discrete latent variables by applying a direct discrete optimization to the encoder and decoder of the model. The proposed approach sidesteps the usual sampling - based approximation, reparameterization trick and amortization tricks used in standard VAE training. The authors apply the proposed approach in a variational setting using truncated posteriors in conjunction with evolutionary algorithms. The experiments show that the proposed method is more efficient than conventional discrete optimization and is competitive with non - generative approaches in zero - shot learning and denoising."
SP:deb189d37bd51b92762ce259a106d9a9e9d81ea4,"This paper proposes an unsupervised method to identify controlled effects of an agent ’s actions on the environment using counterfactual measures of blame. The method is based on the fact that humans assign blame to their actions to decide what aspects of the environment they controlled. The proposed method is called Controlled Effect Network ( CEN ) and is evaluated in a wide range of environments showing that it can accurately identify the controlled effects. CEN is also evaluated in the state - of - the - art exploration method, where it achieves substantially better performance than action - prediction methods."
SP:ea18d57904e25fd09ed0f6c9972029d78779a8a6,"This paper proposes structure - regularized pruning ( SRP ), which imposes structure regularization on the pruned structure to make sure the locations of pruned filters are aligned across different layers. Specifically, for the layers connected by the same residual, the authors select the filters of the same indices as unimportant filters. The authors apply SRP to train efficient image SR networks, resulting in a lightweight network SRPN - L and a very deep one SRPN. They conduct extensive comparisons with both lightweight and larger SR networks and show that the proposed method achieves superior performance gains over recent methods quantitatively and visually."
SP:0dee45001ae9600f485614dfe6874a516ac01db5,"This paper proposes a framework for few - shot learning that tackles large domain shift between base and novel categories. The first step of the framework trains a feature extracting backbone with the contrastive loss on the base category data. The second step, a masking module is used to select relevant features that are more suited to target domain classification. The proposed method is evaluated on a recently introduced benchmark dataset for cross - domain few shot learning. The results demonstrate that the proposed ConFeSS outperforms all previous methods and achieves competitive results against recent cross - domains methods."
SP:92aa611d71a8da597358330d84fddbb90de2cf4f,"This paper studies the question of whether the generalization performance of neural networks is due to the functions returned by gradient descent, or bias already present in the network architecture. In particular, the authors study the behavior of infinite width networks trained by Bayesian inference and finite width neural networks trained with gradient descent. They show that gradient descent can further improve generalization by selecting networks with a large margin. This conclusion is based on a careful study of the behaviour of the function returned by finite width networks. To measure the implicit bias of architecture, new technical tools are developed to both analytically bound and consistently estimate the average test error of the neural network - Gaussian process ( NNGP ) posterior. This error is found to be already better than chance, corroborating the findings of Valle - Pérez et al. ( 2019 ) and underscoring the importance of architecture. This paper finds that test performance can be substantially improved by selecting a function with a much larger margin than is typical under the NNGPs posterior."
SP:a0e3cf719a95bbc5aad2f663ba5a3169c316ee9b,"This paper proposes a new method for cross - lingual manifold mixup ( X - Mixup ) to improve the performance of target languages on a multilingual task. The proposed method is motivated by the observation that the performance gap between source and target languages is strongly associated with the cross - linguistic representation discrepancy. The authors propose a method that adaptively calibrates the representation discrepancy and gives compromised representations for target languages. Experiments on the XTREME benchmark show X -Mixup achieves 1.8 % performance gains on multiple text understanding tasks, compared with strong baselines, and reduces representation discrepancy significantly."
SP:19f8cd8f0c274b6141ba097d2ebb6d18af0986fd,"This paper studies Byzantine robust distributed or federated learning, where a central server trains a machine learning model over data distributed across multiple workers, and a fraction of these workers may deviate from the prescribed algorithm and send arbitrary messages. Most current defenses assume that the workers have identical data. For realistic cases when the data across workers are heterogeneous ( non - iid ), the authors design new attacks which circumvent current defenses, leading to significant loss of performance, and propose a simple bucketing scheme that adapts existing robust algorithms to heterogeneous datasets at a negligible computational cost. The authors theoretically and experimentally validate their approach, showing that combining bucketing with existing robust methods is effective against challenging attacks. Their work is the first to establish guaranteed convergence for the non -iid Byzantine robust problem under realistic assumptions."
SP:4d63513b9a1b9b9fc44a69b3d5679a8f48eb95e7,"This paper studies the relationship between disentanglement and multi - task learning based on hard parameter sharing. The authors perform a thorough empirical study of the representations obtained by neural networks trained on automatically generated supervised tasks. Using a set of standard metrics, the authors show that disentangling appears naturally during the process of multi - tasks neural network training.    The main contribution of this paper is the empirical study that empirically demonstrates the disentangledness of neural network representations."
SP:9851adb72e2918780f661f83f7da06eb866787be,"This paper proposes a framework of certifying robustness policies for reinforcement learning against adversarial attacks. The authors propose two types of robustness certification criteria : robustness of per - state actions and lower bound of cumulative rewards. They develop a local smoothing algorithm that uses a policy derived from Q - functions smoothed with Gaussian noise over each encountered state, which provides state level certification and the first certification for cumulative rewards under adversarial state perturbations. They also develop a global smoothing algorithms for certifying the robustness   of a finite - horizon cumulative reward. Finally, they propose an adaptive search approach that makes use of adaptive search in order to obtain tight certification bounds for the reward. They use the proposed RL robustness framework to evaluate methods that have previously been shown to be effective in the literature."
SP:78da3c97182ec1baf6a131740bf7c91a9afb2fd2,"This paper proposes a new approach to conformal prediction, which aims to output a precise set of promising prediction candidates that is guaranteed to contain a limited number of incorrect answers. Conformal prediction provides the ability to adapt to model uncertainty by constructing a calibrated candidate set in place of a single prediction, with guarantees that the set contains the correct answer with high probability. In practice, conformal sets can often become inundated with noisy candidates, which can render them unhelpful in practice. This paper proposes to trade coverage for precision by enforcing that the presence of incorrect candidates in the predicted candidate set is bounded according to a user - specified tolerance. The proposed algorithm optimizes for a generalized notion of set coverage that allows for any number of true answers for a given query ( including zero ). The experimental results demonstrate the effectiveness of this approach across a number of classification tasks in natural language processing, computer vision, and computational chemistry."
SP:b126d2f3c397633745c8833e22ace93a2470e963,"This paper studies the complexity of functions computed by a neural network. One natural measure of complexity is how the network distorts length – if the network takes a unit - length curve as input, what is the length of the resulting curve of outputs? The authors prove that the expected length distortion does not grow with depth, and indeed shrinks slightly, for ReLU networks with standard random initialization. They also generalize this result by proving upper bounds both for higher moments of the length distortion and for the distortion of higher - dimensional volumes. The theoretical results are corroborated by some experiments."
SP:b3b6d0512edfca461ea295ee8665f7f226c45d57,"This paper proposes SAFER, a behavioral prior learning algorithm that learns to extract safety skills from offline data that encodes safety requirements. The goal of SAFER is to learn a safe and successful policy from the safety skills according to the inferred safety variable and action, under safety constraints. The proposed method is based on contrastive training on safe and unsafe data. The authors demonstrate its effectiveness on several complex safety - critical robotic grasping tasks inspired by the game Operation, 1 in which SAFER outperforms baseline methods in learning successful policies and enforcing safety."
SP:a5dadb3ecc3caed3b9d9a68eda0d48a53c2d1ce2,"This paper proposes a multi - branch neural network architecture for image restoration. The proposed architecture is inspired by the Retinal Ganglion Cells ( RGC ), which is used in the human visual system to perform multiple image restoration tasks at the same time. The experiments show that the proposed architecture, CMFNet, has competitive performance results on four datasets, including image dehazing, deraindrop, deblurring, and image smoothing."
SP:263b386beee44b0b45b6f6dc3cf80d020500be62,"This paper proposes a novel approach to personalized federated learning ( PFL ) in the setting where clients may join a prediction service after it has been deployed, obtaining predictions for their own unlabeled data. The authors propose a new learning setup, Inference - Time PFL ( IT - PFL - HN ), where a model trained on a set of clients needs to be later evaluated on novel clients, i.e., clients that have not yet been deployed by the central server. The proposed method is based on a hypernetwork module and an encoder module that learns a representation for a client given its own unlabelled data. Experiments show that the proposed method generalizes better than the current FL and PFL methods, especially when the novel client has a large domain shift."
SP:960d0a63a82593f6e72275b65f0501f0469d1924,"This paper presents a method for analyzing self - supervised representation learned by deep neural networks ( SSLs ). The method is based on a conditional diffusion based generative model ( RCDM ), which is trained on the SSLs. The authors show that the RCDM is able to generate representations with better generation quality than state - of - the - art generative models while being faithful to the representation used as conditioning. The paper also shows that SSL representations are not really invariant to many data augmentation they were trained on, such as adversarial perturbations."
SP:398899e6c86b4a2a17dfa5c2f4478811f4331c1d,"This paper proves that Fp sketch, a well - celebrated streaming algorithm for frequency moments estimation, is differentially private as is when p \geq ( 0, 1 ) is in the polylogarithmic space. The paper also shows that the algorithm is exponentially better than existing DP baselines and only worse than the optimal non - private baseline by a logarithmically factor. The evaluation shows that FP sketch can achieve reasonable accuracy with differential privacy guarantee."
SP:3253b13851b5a3b5e3c8c6e24891db05903a4e57,"This paper proposes a reward - switching policy optimization ( RSPO ) method for finding novel policies that are both locally optimal and sufficiently different from existing ones. The key idea is to perform policy optimization with extrinsic rewards when a sampled trajectory is sufficiently distinct, and then switch to an intrinsic reward based on trajectory - based novelty during the optimization process. The intrinsic reward encourages the learning policy to consistently converge towards a previously undiscovered local optimum, while the novelty reward encourages exploration. The proposed method is evaluated on a wide range of RL tasks and domains, ranging from single - agent particle - world tasks and MuJoCo continuous control to multi - agent stag - hunt games and StarCraft II challenges."
SP:e3ab3aa87ab023bd9949b99a17d4b6e26c1473c0,"This paper proposes a method to speed up the sampling process of diffusion models by optimizing the degrees of freedom of their samplers. The main idea is to use gradient descent to optimize the sample quality of a diffusion model rather than fine - tuning or re - training. The authors propose a method called Differentiable Diffusion Sampler Search ( DDSS ) to do so. The method is based on the Generalized Gaussian Diffusion Models ( GGDM ), a family of non - Markovian diffusion models that allows for faster sampling compared to the standard diffusion models."
SP:7a7506f2b5500a573c0cfb8b0822e5ea725c886a,This paper proposes a lightweight P - adapter model that takes LLM embeddings as input and output continuous prompts that are used to query the large language models ( LLMs ). The authors also investigate Mixture of Experts ( MoE ) models that learn a set of continuous prompts ( “experts ” ) and select one of them as the one to query to the LLM. The experiments show that the proposed P - adapters perform comparably to the more complex MoE models in extracting factual information from BERT and RoBERTa while improving the precision and consistency over a baseline of only using natural language queries.
SP:35cdf71f027cc5168b55cc34c64bfb2f3087d6f5,"This paper proposes a method for continuous classification of time series. The main idea is to model multiple distributions of the same time series at a given point in time. The proposed method is based on the idea of adaptive distribution extraction ( ACCTS ), which extracts data distributions adaptive to the time series evolution and the model change. ACCTS also has an importance - based replay policy, which only re - samples the important samples according to the contribution of data to the model. Experiments on four real - world datasets show that the proposed method outperforms the baselines at every time point."
SP:d9b74b749aa465496763d3a3a9bf3a53e800587e,"This paper proposes a method for learning language models that can read and memorize new data at inference time, thus acquiring new knowledge immediately. The authors propose to use a kNN - based encoder - decoder architecture to learn the encoders and decoders of the memory of a language model. The encoder encoder takes as input a sequence of tokens, and the decoder takes the output of the encoder as input to the memory. The memory encoder is then used to compute the weights of the kNN decoder. Experiments are conducted on C4, arXiv, PPG-19, and formal theorems. Results show that the proposed method improves the model's performance when the number of tokens is increased."
SP:7a1bbf86c3fdb8738aa826ca330493e857d050ba,"This paper proposes an energy parametrization of the masked language modeling ( MLM ) objective. The paper interprets MLMs as energy - based sequence models and proposes a tractable sampling scheme based on the Metropolis - Hastings ( MHA ) algorithm to draw samples correctly from these models. The samples are proposed from the same masked conditionals used for training the MLMs and they are accepted or rejected based on their energy values according to the target distribution. The proposed sampling algorithm theoretically and empirically justify the sampling algorithm by showing that the masked conditional on their own do not yield a Markov chain whose stationary distribution is that of our target distribution, and our approach generates higher quality samples than other recently proposed undirected generation approaches."
SP:011626ba4fafee13d4a30e3f13c1df5b7071a7f1,"This paper proposes a learning - based data augmentation method to improve the performance of deep neural networks for various NLP tasks. The authors propose a sample re - weighting scheme to focus on difficult augmented samples after the original ones are learned confidently for more effective learning from the augmented ones. The proposed method outperforms the recent state - of - the - art augmentation schemes on various text classification tasks and GLUE benchmark by successfully discovering the effective augmentations for each task. The method is more effective on the challenging low - data and class - imbalanced regimes, and the learned augmentation policy is well - transferable to the different tasks and models."
SP:69d41a862ea189f72d4e8af2854e27b95a91fa41,"This paper studies meta - learning for offline reinforcement learning ( OMRL ) from the perspective of task - based encoders. The authors propose two modifications to FOCAL, namely intra - task attention and inter - task contrastive learning, to improve the performance and robustness of the encoder in the face of sparse reward and distribution shift. Theoretical analysis and experiments are presented to demonstrate the superior performance of the proposed modifications compared to prior algorithms across multiple meta - RL benchmarks."
SP:ed86c60850d5c8302dcf1c2167db303e778fe681,This paper proposes an inference - time improvement framework for parametric sequential generative modeling methods called belief fine - tuning ( BFT ). BFT leverages approximate dynamic programming in the form of fine tuning to determine the model parameters at each time step. It can improve the accuracy of the belief model at test time because it specializes the performance of the model at inference time. The method is evaluated on large - scale variants of the Hanabi benchmark game and approximate public belief state search in the case where the number of possible information states is too large.
SP:6150725599c10f0e26f0d7cb1fc04b5b227a4456,"This paper proposes Pixelated Butterfly, a method for sparse training of neural networks that optimizes over a continuous superset of sparse matrices with a fixed structure known as products of butterfly matrices. The main insight of the paper is that searching for a sparsity mask is difficult and expensive, so the authors propose to optimise over a product of a continuous series of products of the product of the products of a fixed set of matrices, which they refer to as the “ butterfly matrix ”. The paper also proposes two variants of the butterfly matrix : block and flat matrices to take advantage of modern hardware. Empirically, the paper shows that the proposed method can train sparse neural networks faster than the dense MLP - Mixer, Vision Transformer, and GPT-2 medium with no drop in accuracy."
SP:136e31054a55abca840f6478491972023c2296cb,"This paper proposes a conditional score - based generative model for conditional diffusion probabilistic models, which exploits the class clustering phenomenon to explicitly model the class center in the forward and reverse process of the Markov chain. The authors also provide another direction for faster sampling and more analysis of their method. They conduct extensive experiments on multiple tasks, and achieve competitive results compared with the state - of - the - art methods."
SP:fc2196f1f4ecd864398fed6640ff3f8b19870763,"This paper studies domain generalization ( DG ) approaches that rely on the assumption of the existence of fixed domain - invariant features and common hypotheses learned from a set of training domains. The authors argue that this assumption could be overly strict and sub - optimal when source domains share little information or the target domains leverages information from selective source domains in a compositional way instead of relying on a unique invariant hypothesis across all source domains. They propose a LASSO method that explores diverse latent sub - spaces and learns individual hypotheses on those sub - space features formed by the label - in - formative features captured in source and target domains.   The authors empirically evaluate their method on several well - known DG benchmarks, where it achieves state - of - the - art results."
SP:6e8e5bdeb77e3cafe1975da8411fb65118955d14,"The paper studies the performance of the kernel thinning ( KT ) algorithm of Dwivedi and Mackey ( 2021 ), which compresses a probability distribution more effectively than independent sampling by targeting a reproducing kernel Hilbert space ( RKHS ) and leveraging a less smooth squareroot kernel. The paper provides four improvements over the square - root KT algorithm. First, the authors show that KT applied directly to the target RK HS yields tighter, dimension - free guarantees for any kernel, any distribution, and any fixed function in the target hypersphere. Second, they show that, for analytic kernels like Gaussian, inverse multiquadric, and sinc, target KT admits maximum mean discrepancy ( MMD ) guarantees comparable to or better than those of square root KT without making explicit use of a square root kernel. Third, they prove that KT with a fractional power kernel yields better - than - monte - carlo ( MMD ) guarantees for non - smooth kernels. Fourth, they establish that when applied to a sum of the target and power kernels ( a procedure we call KT+), the improved MMD guarantees of power KT and the tighter individual function guarantees of target KT are the same."
SP:645c3f1864aa843d4899fc2406f694b5aab8460d,"This paper presents an open - source benchmark suite for the NP - hard MaxIMUM INDEPENDENT SET problem, in both weighted and unweighted variants. The suite offers a unified interface to various state - of - the - art traditional and machine - learning - based solvers. The authors conduct an in - depth analysis of the popular code guided tree search algorithm by Li et al. [ NeurIPS 2018 ], testing various configurations on small and large synthetic and real graphs. The analysis shows that the graph convolution network used in the tree search does not learn a meaningful representation of the solution structure, and can in fact be replaced by random values. The results from the original publication are not reproducible."
SP:155ecd17d264a084b014abdfd0362146d8fb07e0,"This paper proposes Wavelet Compressed Convolutional Neural Networks ( WCC ), a novel approach for activation maps compression for 1 - to - 1 convolutions in deep convolutional neural networks. WCC achieves compression ratios and computational savings that are equivalent to low - bit quantization rates at a relatively minimal loss of accuracy. Experiments show that the proposed method achieves compression rates equal to 2 - bit and 1 - bit with minimal degradation in image - to-image tasks. The paper is well - written and easy to follow."
SP:004865e6affad32403b7965493a53c8a7ffdda0a,"This paper studies learning dynamics for extensive form correlated equilibria in multiplayer general - sum imperfect - information extensive - form games. The authors propose a no - regret learning algorithm for correlated and coarse correlated equilibrium in extensive form games, which is a significantly more challenging setting compared to normal form games in general form. They show that the correlated distribution of play is an O(T 3/4)-approximate EFCE when all agents play T repetitions of the game according to the accelerated dynamics, which significantly improves over the best prior rate of O(\T 1/2 ). They also connect predictive ( that is, optimistic ) regret and stability of fixed point strategies through a refined perturbation analysis of a structured structured Markov chain game."
SP:ee545ff83df4d7ff256ac61fbe0eb0765f52f1d5,"This paper proposes a method called Action Quantization from Demonstrations ( AQuaDem ) to learn a discretization of continuous action spaces by leveraging the priors of demonstrations. The main idea is to learn discrete actions that are plausible in light of the demonstrator ’s behavior. By discretizing the action space, one can apply any discrete action deep RL algorithm to the continuous control problem. The paper evaluates the proposed method on three different setups : RL with demonstrations, RL with play data, and RL with human data. The proposed method consistently outperforms the baseline methods on a variety of hard manipulation tasks."
SP:4b39279b98d6aa311bb49dd1384925f9d6f66c2d,"This paper studies the problem of domain generalization in semantic segmentation. The authors propose a novel adversarial style augmentation ( AdvStyle ) approach, which generates hard stylized images during training and thus can effectively prevent the model from overfitting on the source domain. Specifically, AdvStyle regards the style feature as a learnable parameter and updates it by adversarial training. Experiments show that AdvStyle can significantly improve the model performance on unseen real domains and show that we can achieve the state - of - the - art on the considered datasets."
SP:4a2e6d70b383e4941e0bc44e7e82972b22e26792,"This paper proposes a hybrid VAE - based method for mid - air gesture recognition. The method is based on an event - guided VAE that encodes event - based data from a dynamic vision sensor ( DVS ) into a latent space representation, which is then used to compute the similarity scores between the latent representations. The proposed method is evaluated on the DVSGesture dataset and achieves 87 % classification accuracy on the task classification. The authors also show that the proposed method can encode sparse, noisy inputs into an interpretable Latent Space Representation."
SP:2e66468a6b94177e54b0052b97713ee63902c278,"This paper proposes a Sparse Hierarchical Table Ensemble ( S - HTE ) for sparse inference in tabular data when computational capacity is low. S -HTE is based on sparse hierarchical table ensembles with ferns ( oblivious decision trees ) instead of neurons. The inference is dense at the beginning of the training process and becomes sparse using an annealing mechanism, leading to an efficient final predictor. The experiments show the effectiveness of the proposed method on a standard classification and regression benchmark."
SP:b238db9252d83a13438bb747d70e635bb9945958,"This paper proposes a new offline RL method called Latent action Q - learning ( LAQ ) for learning value functions from state - only MDPs. The proposed method is based on a latent - variable future prediction model, which is used to model discrete latent actions obtained from the ground truth actions. The authors show theoretically that tabular Q learning can be used to learn the same value function under any arbitrary refinement of the action space. This theoretical result motivates the design of LAQ, which can learn effective value functions with high correlation with value functions learned using ground - truth actions in the offline setting. The experimental results show that LAQ outperforms imitation learning, oracles, and competing methods."
SP:108ebe9045a9e2b8b5aba8352733782462db8a81,"This paper proposes SWARM Parallelism1, a model - parallelism algorithm for distributed training of large models with large parameters. The main idea is to train a large Transformer model with 1 - 1 B shared parameters on a swarm of preemptible T4 GPUs with less than 400 Mb / s network throughput. To further reduce the network usage of the algorithm, the authors develop several compression - aware architecture modifications and evaluate their tradeoffs. The experiments show that SWARM parallelism1 is effective in reducing communication - intensive scenarios."
SP:91d2f094d5481651b554f58aecc2a6207057a47c,"This paper proposes online transition correction ( OTC ) to bridge offline and online reinforcement learning to address the transition bias in multi - agent reinforcement learning. The transition dynamics in offline experiences do not accord with the transition dynamics of online execution, which creates severe errors in value estimates, leading to uncoordinated and suboptimal policies. The authors propose two types of distances to measure the similarity between transitions, and propose an adaptive rank - based prioritization to sample transitions according to the transition similarity. Empirically, the authors show that OTC outperforms baselines in a variety of tasks."
SP:d0e650d568214481b07a0452ec606ccbf6d05410,"This paper proposes a logarithmic unbiased quantization ( LuQ ) method to quantize both the forward and backward phase of the training process to 4 - bit quantization. The forward phase quantization is done by quantizing the loss with respect to the outputs of intermediate neural layers. The backward phase is quantized by quantization of the output of the forward layer. The proposed method achieves state - of - the - art results in quantized forward training. The authors further improve this to degradation of only 0.64 % after a single epoch of high precision with a variance reduction method. Finally, they suggest a method that exploits the low precision format by avoiding multiplications during two -thirds of training process."
SP:f2862d1f987164ed6c3c375cd8962e57c369373b,"This paper proposes a self - attention feature - selection mechanism for few - shot learning in the setting of meta - learning, where the goal is to learn a classifier that is robust to misclassification in the presence of task - irrelevant features in the meta - training process. The authors show that threshold meta - learners, such as Prototypical Networks, require an embedding dimension that is exponential in the number task - relevant features to emulate these functions. In contrast, attentional classifiers such as Matching Networks, which are polythetic by default, are able to solve these problems with a linear embedding dimensions. To address this challenge, the authors propose a selfattention feature selection mechanism that adaptively selects the parameters of the attention mechanism adaptively. They demonstrate the effectiveness of their approach in several settings.    The main contributions of the paper are the following :   1. Propose a self attention mechanism for the problem of polytheism in meta learning. 2. Empirically show that the proposed self attention works well in both synthetic and real - world settings."
SP:e1e513fef25d29e17cdadd1b36d932a8ad8897cd,"This paper proposes a multi - agent reinforcement learning ( MRL ) environment to study emergent communication between agents using a continuous communication channel trained through reinforcement learning. The communication channel is continuous and consists of a speaker and a listener. The speaker is equipped with a vocoder that maps symbols to a continuous waveform, and the listener is trained using deep Q - learning. They show that basic compositionality emerges in the learned language representations and that noise is essential in the communication channel when conveying unseen concept combinations. They also show that they can ground the emergence of communication by introducing a caregiver to “hear ” or “speaking ” English."
SP:0e6ff65ba4a3df35947d1b6f4d438612088d90a0,This paper proposes a novel backdoor attack on pre - trained NLP models that can be adapted to a wide range of downstream NLP tasks in an effective and stealthy way. The key feature of the attack is that the adversary does not need prior information about the downstream tasks when implanting the backdoor to the pretrained model. The authors further design a simple yet effective strategy to bypass a state - of - the - art defense. Experimental results indicate that the proposed approach can compromise a wide variety of downstream language processing tasks in a stealthy and effective way.
SP:58d3ecb4a1906251e79ad883aa97cc2502642658,"This paper proposes a new framework for skill discovery, where skills are learned one after another in an incremental fashion. This framework allows newly learned skills to adapt to changes in the environment, and to not forget earlier skills after such adaptation. The authors demonstrate experimentally that in both evolving and static environments, incremental skills significantly outperform current state - of - the - art skill discovery methods on both skill quality and the ability to solve downstream tasks."
SP:2c6595408f5ec95537eaf555e5fe3d992b58c222,"This paper proposes a log - polar space convolution ( LPSC ) layer in convolutional neural networks, where the convolution kernel is elliptical and adaptively divides its local receptive field into different regions according to the relative directions and logarithmic distances. Since the receptive field grows exponentially with the number of distance levels, the proposed layer not only naturally encodes local spatial structures, but also greatly increases the single - layer receptive field. Experiments on different datasets and networks demonstrate the effectiveness of the proposed LPSS layer."
SP:7791f96b1eef277a9133975507a750d9e7c6b8ff,"This paper studies the effect of IIW compression on the generalization ability of neural networks ( NNs ). The authors propose an algorithm for the efficient approximation of the IIW and build an IIW - based information bottleneck on the trade - off between the accuracy and information complexity of NNs. They empirically identify the fitting to fitting to compression and generalization relations between IIW's compression and NNs'generalization. They also propose an MCMC - based algorithm to sample from the optimal weight posterior characterized by PIB, which fulfills the potential of IIw in enhancing NNs in practice."
SP:a733847ade77ffbf38760fc79da17893dea8d53f,"This paper studies data poisoning attacks, which add imperceptible perturbations to training data to maximize the test error. In this work, the authors investigate why these attacks work in principle. They find that the perturbation of advanced attacks are almost linear separable when assigned with the target labels of the corresponding samples. They further confirm that linear separability is indeed the workhorse for recent attacks. The finding also suggests that the shortcut learning problem is more serious than previously believed as deep models heavily relies on shortcuts."
SP:7b50be406138ad01db3ee112899f622637896fe9,"This paper proposes a new algorithm for importance sampling in offline policy evaluation. The main idea is to use importance sampling to remove assumptions on the chosen function approximations used to represent value functions and process models. The authors show that importance sampling is prone to overfitting and propose an algorithm to avoid this overfitting. They provide a theoretical justification of the proposed algorithm through a better per - state - neighbor normalization condition and show the limitation of previous attempts to this approach through an illustrative example. They further test our proposed method in a healthcare - inspired simulator and a logged dataset collected from real hospitals. The experiments show the proposed method with less overfitting, better test performance, and better overall performance compared with existing online learning algorithms."
SP:c976752a55b9ff47dc63c95a9fd7b51a81e8a42e,"This paper presents CoLLIE, a method for continual learning of how language is grounded in vision based on a pre - trained multimodal embedding model. The model learns a transformation function that adjusts the language embeddings when needed to accommodate new language use. Unlike traditional few - shot learning, the model does not just learn new classes and labels, but can also generalize to similar language use and verify the model ’s performance on two different tasks of continual learning and show that it can efficiently learn and generalize from only a few examples, with little interference with the model’s original zero - shot performance."
SP:d3371b322acfc321ee79a2e1b438d82644872fa4,"This paper proposes a novel object captioning method for novel images. The proposed method is based on the VLAF2 framework for learning visual - linguistic - linguistic models for describing novel visual information of images with novel objects. The key idea of the method is to learn an encoder - decoder model for captioning images together. The encoder encoder takes as input the caption of an image, and the decoder decoder takes the input caption of a novel image as input, and outputs the output caption of the encoder. The decoder is then used to train a novel captioning model. The authors conduct extensive experiments on the nocaps dataset to validate the effectiveness of the proposed method. They show that their proposed method outperforms state - of - the - art novel captions in all caption evaluation metrics, and surpasses the SPICE scores of human baseline models. They also perform quantitative and qualitative analysis to demonstrate how their model generates novel object captions with improved fluency, fidelity, and adequacy."
SP:9f3b6486662d80350d77a4b060d4a5b8b22a6130," features learned by overparameterized classification networks show an interesting clustering property, called neural collapse. The authors demonstrate both theoretically and empirically that neural collapse generalizes to new samples from the training classes, and – more importantly – to new classes as well, allowing foundation models to provide feature maps that work well in transfer learning and, specifically, in the few - shot setting."
SP:624c95d9ce1ee4b66274e858e2da22bef6b052c7,"This paper proposes a deep point cloud reconstruction network consisting of a 3D sparse stacked - hourglass network as for the initial densification and denoising, and a refinement via transformers converting the discrete voxels into 3D points. In particular, a newly proposed module called amplified positional encoding is designed to amplify the magnitude of positional encoding vectors based on the points ’ distances for adaptive refinements. Extensive experiments demonstrate that the proposed method achieves state - of - the - art performance among the recent studies in the ScanNet, ICL - NUIM, and ShapePart datasets."
SP:34a81ca65131576d4c14332a4e9eb3a4c344cab7,This paper proposes a new GCN training method called PipeGCN to reduce the communication overhead in distributed GCN. The main idea is to use intra - partition computation instead of communicating features and gradients among partitions for each GCN layer in each training iteration. The authors provide a theoretical convergence rate of the proposed method and also develop a smoothing method to further improve the performance. Extensive experiments have been conducted to show the effectiveness of the method.
SP:8302d49558ee0f16392d623d4e604e92db10d041,"This paper studies the problem of test time robustification, i.e., using the test input to improve model robustness in the face of unexpected perturbations in the input, changes in the domain, or other sources of distribution shift. The authors propose a simple approach that can be used in any test setting where the model is probabilistic and adaptable : when presented with a test example, perform different data augmentations on the data point, and minimize the entropy of the model ’s, or marginal, augmentations. Experiments on two baseline ResNet models, two robust ResNet - 50 models, and a robust vision transformer model demonstrate that this approach achieves accuracy gains of 1 - 8 % over standard model evaluation and generally outperforms prior augmentation and adaptation strategies when only one test point is available."
SP:a985de5e940ff3a4160b378201b8c02f68d1914a,"This paper proposes a joint optimization algorithm for jointly training the model and the policy, such that updates to either component increase a lower bound on expected return, and this bound becomes tight under certain assumptions. The proposed algorithm ( MnM ) is conceptually similar to a GAN algorithm, except that the policy is updated to produce transitions that look realistic, and the policies are updated to avoid states where the model predictions are unrealistic. The main contributions of this paper are : 1. Propose a single objective for joint optimization of model and policy. 2. Introduce a global lower bound ( global MSE ) on the expected return. 3. Empirically validate the effectiveness of the proposed joint optimization objective."
SP:a469fbcdc20b11dff4085b6fbc384e77f33cd37d,"This paper proposes an imitation learning method that combines the advantages of two existing methods, BC - SO ( behavioral cloning from observation history ) and BC - OTH ( adaptive imitation learning ). The idea is to first compute a coarse action based on the instantaneous observation, and then refine it into a final action using historical information. The proposed method is evaluated on CARLA autonomous driving from images and MuJoCo continuous control tasks. The experiments show that the proposed method outperforms all baselines.    Contributions :   1. The authors propose a model combination approach inspired by human decision making for imitation learning in the partially observed settings. They observe that behavioral cloning policies acting on single observations and observation histories each have their strengths and drawbacks, and combine them optimally could achieve the best of both worlds. Motivated by this, they propose a simple model combination algorithm. 2. They show that their method combines advantages of each method, and outperforms both."
SP:95c4533b5d1a865c4cc6a54615e7ad6357bdaad1,"This paper proposes a model - based meta - learning method for dynamics forecasting that can generalize across heterogeneous domains by partitioning them into different tasks. The proposed method has two parts : an encoder which infers the time - invariant hidden features of the task with weak supervision, and a forecaster which learns the shared dynamics of the entire domain. The encoder adapts and controls the forecaster during inference using adaptive instance normalization and adaptive padding. Theoretically, the authors prove that the generalization error of such procedure is related to the task - relatedness in the source domain, as well as the domain differences between source and target. Experiments on both turbulent flow and real - world ocean data forecasting tasks demonstrate the effectiveness of the proposed method."
SP:ec70553cb0c27e5349c1b8cce6bcaa96a83bf050,"This paper proposes a weakly supervised monocular 3D object detection method. The proposed method first detects 2D boxes on the image and select corresponding RoI LiDAR points as the weak supervision. Then, a network is adopted to predict 3D boxes by minimizing the newly proposed 3D alignment loss. Experiments show that the proposed method outperforms the existing weakly - supervised methods."
SP:34217c6a8ca43b8eeb9ddc83d6f1f0af05918984,"This paper proposes a soft gradient - based subword tokenization method for end - to - end language model training. The main idea is to learn latent subword representations from characters in a data - driven fashion. A block scoring network is used to score candidate subword blocks and learn to score them in a position - wise fashion. Experiments on English GLUE, multilingual, and noisy text datasets show that the proposed method outperforms the state - of - the - art subword - based models by 28 - 100 % while maintaining competitive quality."
SP:d26d25f2ef23a89a2c139d0dd87c4c86fddcff5e,This paper proposes the adversarial extreme value analysis ( AEVA ) to detect backdoors in black - box backdoor attacks in deep neural networks ( DNNs ). The authors show that the objective of backdoor detection is bounded by an adversarial objective. The AEVA approach is based on an extreme - value analysis of the adversary map computed from the monte - carlo gradient estimation. The effectiveness of AEVA is demonstrated by extensive experiments across multiple tasks and backdoor attacks.    The main contribution of this paper is to propose an AEVA method for detecting backdoor attacks under the hard - label scenarios where only the final output label is accessible.
SP:c6dbca0ed0799b7fec21777606f6f809eb2d8c48,"This paper proposes a method for jointly quantifying in - distribution and out - of - distribution ( OOD ) uncertainty. The proposed method is based on a Kullback - Leibler divergence criterion ( KLoS ) that captures class confusion and lack of evidence in a single score. The key idea is to use a second - order uncertainty representation for OOD uncertainty and not require OOD training data, in contrast to current second order uncertainty measures. The authors further design an auxiliary neural network, K LoSNet, to learn a refined criterion directly aligned with the refined criterion on the class - probability simplex. Experiments show that the proposed method outperforms first - order and second order measures to simultaneously detect misclassifications and OOD samples."
SP:8b4f3916dca4e627931558e14836749bd4a6792f,"This paper studies semi - supervised learning of convolutional neural networks ( CNNs ) on natural image data. The authors propose a method to learn a linear classifier from unlabeled patches of an image, where the patches are sampled from a low - dimensional manifold. They show that this method provably learns CNNs, under some natural distributional assumptions. In particular, they show that if the distribution of patches in the input images has low - dimension structure ( e.g., patch distribution is sampled from low dimensional manifold ), then it can be shown that the learned classifier is a CNN. They also provide a lower bound on the dependence of the learned CNN on the dimension of the patch distribution, which is essentially optimal."
SP:7f2f354d5cc1030bd97bd716aea8fe1d3af86b25,"This paper proposes a new face clustering method based on graph convolutional networks ( GCNs ). The main idea is to cluster faces by constructing clean graphs for GCNs instead of using kNN relations in the feature space. The graph is constructed by considering face features of the faces of the same class. The proposed Ada - NetS method is evaluated on multiple public clustering datasets and shows that it significantly outperforms the current state - of - the - art methods, proving its superiority and generalization."
SP:a3bc8e26f55e78f07de081ca85865afd52b6ae4a,This paper proposes a new method for learning robust models that generalize well on a collection of possible data distributions ( the uncertainty set ) without demographics. The authors argue that the convex condition of KL DRO may not hold for overparameterized neural networks and apply the change - of - technique technique and the analytical solution of distributionally robust optimization ( DRO ) instead. The proposed method is evaluated on DG ReID and cross - domain ReID benchmarks and shows superior performance compared to standard baselines.
SP:62c1f734b7f6c6e7d5114da6f37c9e3cdda73a23,"This paper proposes a new regularization method for graph neural networks ( GNNs ) that aims to improve the efficiency and robustness to overfitting. The main idea is to corrupt the input graph with noise and add a noise correcting node - level loss. The authors show that adding noise helps overfitting, and the noise correction loss helps ameliorate oversmoothing by encouraging diverse node latents. The regulariser applies well - studied methods in simple and straightforward ways and allows even generic GNN architectures not designed for quantum chemistry to achieve state - of - the - art results.   The authors also demonstrate the effectiveness of Noisy Nodes with non - spatial architectures on Open Graph Benchmark ( OGB ) datasets."
SP:24a1b44f37f8eedbab2047fb84600a322d289f3b,"This paper tackles the set2vec problem, which is the task of extracting a vector representation from an input set of variable number of feature vectors. The authors propose a set embedding feed - forward network based on the maximum - a - posterior ( MAP - EM ) framework with a fixed number of mixture parameters. The proposed mixture set data fitting framework allows unsupervised set representation learning via marginal likelihood maximization aka the empirical Bayes aka the Bayes Bayes framework. They also find that OTKE can be seen as a special case of their framework, specifically a single - step EM with extra balanced assignment constraints on the E - step. The experimental results demonstrate the effectiveness of the proposed method on various tasks demonstrating improved performance over the state - of - the - arts."
SP:b4f7b660b84fe7702fbcc8a96c192abc3a64f045,"This paper proposes CFS ( Contrastive Feature Selection ), a method for performing feature selection in the contrastive analysis ( CA ) setting, where the goal is to select a small number of informative features for use in unknown downstream tasks. The CA setting has received little attention from the machine learning community and the problem of unsupervised feature selection has not received the same attention. The authors present CFS on a semi - synthetic dataset, a biomedical dataset, and four real - world biomedical datasets, and find that it consistently outperforms previous state - of - the - art methods."
SP:bc4f69f23aba2034cbf14cb31bdc7a991806bbf6,"This paper studies the relationship between optimal early stopping time and model dimension and sample size of the dataset for linear regression models. Theoretical results show that when the dimension of the model exceeds the number of features, early stopping is optimal. The paper also shows experimentally that early stopping corresponds to the training process of deep neural network. The authors also study the effect of early stopping on generalization and demonstrate that it can help mitigate “ double descent ” in various settings."
SP:ede87b50cd9c4a6533f17e3e5ddfaaeaaac71dcf,"This paper proposes a quasi - Newton method for the policy gradient algorithm with entropy regularization. In the case of Shannon entropy, the resulting algorithm reproduces the natural policy gradient ( NPG ) algorithm. For other entropy functions, this method results in new policy gradient algorithms. The authors provide a simple proof that all these algorithms enjoy the Newton - type quadratic convergence near the optimal policy. They demonstrate that the proposed quasi - Newton method typically converges in single - digit iterations faster than other state - of - the - art algorithms."
SP:3535504f7599b1f39239f7cd8e09acd40fa8fdf0,This paper proposes a case - based reasoner method for text - based games ( TBGs ). The main idea is to train an agent that is able to generalize well out of the training distribution of positive and negative experiences. The agent is trained with a reward function that is a weighted combination of the reward from the previous state and the current state. The reward function is learned using a reinforcement learning algorithm. The proposed method is evaluated on a number of state - of - the - art TBGs. The results show that the proposed method outperforms the baselines in most cases.
SP:9a5dd0148a15dc5b4d2bc6762dfe8a8991f8866c,"This paper proposes a two - stage method to distill multiple word senses from a pre - trained language model ( BERT ), by using attention over the senses of a word in a context and transferring this sense information to fit multi - sense embeddings in a skip - gram - like framework. The first step is to train the sense disambiguation mechanism in BERT with a distribution over word senses extracted from the output layers of BERT. The second stage is to transfer the sense information from output layers to the context embedding layer of the BERT model. Experiments on the contextual word similarity and sense induction tasks show that this method is superior to the state - of - the - art contextual word embedding methods."
SP:e4cdba0fc7cd7f440d4436219f3959d8d5e2ad28,This paper proposes to transfer image - pretrained convolutional networks from 2D to 3D point - cloud by inflating the 2D convolution filters and finetuning the 3D layers of the network. The authors show that the network architecture and pretrained weights can be used to understand both images and point clouds. They also show that FIP can achieve competitive performance on point cloud classification with a wide range of point cloud models.
SP:dc99c307931ae9c5d4a1b998dc94cfc6ac78d11f," autoregressive generative models are commonly used, especially for those tasks involving sequential data. However, they have been plagued by a slew of inherent flaws due to the intrinsic characteristics of chain - style conditional modeling ( e.g., exposure bias or lack of long - range coherence ) severely limiting their ability to model distributions properly. In this paper, the authors propose a unique method for training the auto - regressive generative model that takes advantage of the well - designed energy - based learning objective. They show that their method is capable of alleviating the exposure bias problem and increase temporal coherence by imposing a constraint which fits joint distributions at each time step. Besides, unlike former energy based models, we estimate energy scores based on the underlying autore progressive network itself, which does not require any extra neural network. Finally, thanks to importance sampling, we can train the entire model efficiently without requiring an MCMC process. Extensive empirical results, like language modeling, neural machine translation, and image generation, demonstrate the effectiveness of the proposed approach approach."
SP:51e748c55bd4134047098559577fa3f37aa7433a,"This paper presents a unified framework that connects Wasserstein distributional robustness and adversarial training ( AT ) methods. The authors show that standard AT methods are special cases of their counterparts in their unified framework, and show that the proposed method robustifies the standard AT counterparts in various settings. Extensive experiments show that both AT methods robustify their standard AT counterpart and the proposed algorithm robustify them further compared to the vanilla AT counterparts."
SP:f192046ea8ad61bfc8e05a0ddb90a8bd15b4640b,"This paper proposes a novel unsupervised representation learning framework for multivariate time series. The proposed framework is based on the idea of bilinear temporal - spectral fusion ( BTSF ), which proposes to incorporate the spectral information and temporal - spectral relations in the feature representation of time series through cross - domain interactions with Spectrum - to - Time ( S2T ) and Timeto - Spectrum Aggregation modules. Extensive experiments are conducted on three major practical tasks for time series such as classification, forecasting and anomaly detection, which is the first to evaluate the proposed method on all three tasks. The experimental results show that the proposed framework achieves the superiority over the state - of - the - art methods and surpasses them by a large margin across downstream tasks."
SP:ef54840009afb095c67bbbc29a7824c20a375ee8,"This paper proposes a method for automatically adjusting the learning rate during gradient descent in deep neural networks. The learning rate is optimized via a simple extra gradient descent step, justified by an analysis that exploits the structure of neural network. The authors formulate first and second - order gradients with respect to learning rate as functions of consecutive weight gradients, leading to a cost - effective implementation. Extensive experimental evaluation has been conducted, validating the effectiveness of the proposed method for a plethora of different settings."
SP:263c787361cd6d4443ce516d389c694d0fe44b28,"This paper proposes a continual meta - learning method for multi - task reinforcement learning, where the agent's goal is to achieve high reward over any sequence of tasks quickly. Previous meta - RL methods require access to all the tasks during the meta - training stage, which limits the speed of learning new tasks. The proposed method, CoMPS, removes this limitation by meta training in an incremental fashion, over each task in a sequence, without revisiting prior tasks. Experiments are conducted on two subroutines : ( 1 ) learning a new task using RL and using the experience from previous tasks to perform completely offline task learning, and ( 2 ) using off - policy learning to prepare for subsequent task learning. Results are shown on several sequences of challenging continuous control tasks."
SP:2bd729b7aa045bf74e31229c9e76e57af36e804b,"This paper proposes a new threat model for backdoored poisoned classifiers, where an adversary without access to the original trigger but with knowledge of the poisoned classifier, can generate multiple effective alternative triggers. The proposed threat model is a test - time, human - in - the - loop attack method that generates the alternative triggers by first generating adversarial examples by extracting colors and then extracting adversarial images with human interaction. The authors demonstrate the effectiveness of their attack through extensive experiments on two high - resolution datasets : ImageNet and TrojAI. They also compare their approach to previous work on modeling trigger distributions and find that their method are more scalable and efficient in generating effective triggers. Last but not least, a user study demonstrates that such backdoors can be easily determined in existing poisoned classifer."
SP:e58ab0e3cff6b18013145a1a99cfa9da0a3d872f,"This paper proposes a novel method for unconditional distillation of generative adversarial networks ( GANs ), especially for the popular StyleGAN2 architecture. The main challenge of unconditional GAN distillation lies in the output discrepancy issue, where the teacher and student model yield different outputs given the same input latent code. Standard knowledge distillation losses typically fail under this heterogeneous distillation scenario. The authors conduct thorough analysis about the reasons and effects of this discrepancy issue and identify that the style module plays a vital role in determining semantic information of generated images, and propose a novel strategy for the student model, which can ensure the output consistency to the maximum extent. Extensive experiments demonstrate the effectiveness of the proposed method."
SP:2c2231743fa33b95828c6615263954ce1c05f95d,This paper proposes a graph - based method for online approximations of offline algorithms. The method uses a multi - task learning model to simultaneously detect behavioral structures which have already occurred and predict those that may come next. The main idea is to encode the behavior of an offline algorithm by encoding it in the graph of graphs. The graph is then used to predict the next state of an algorithm in an online setting. Experiments on both synthetic data and historical stock market data demonstrate the effectiveness of the method.
SP:ee3a21d2fb8a073099aa200129a53c31f3b6561d,"This paper proposes a Gaussian process ( GP ) approximation method for Bayesian Bayesian models that provides uncertainty estimates associated to the predictions made. The main idea is to reduce the cost of GPs per iteration to $ O(M)$, where $ M$ is the number of inducing points. The inducing points are learned by considering them as parameters of an approximate posterior distribution $ q$. To address this limitation, the paper proposes to use a neural network that receives the observed data as an input and outputs the inducing points locations and the parameters of $ q$. Experiments show that the proposed method performs similar or better than other state - of - the - art sparse variational GP approaches.    The main contribution of this paper is to propose a method for sparse GP approximations that can scale to larger datasets and have faster training and prediction times."
SP:f20c99b441545047a16ae524cc2e317b2c3787a2,"This paper proposes a decentralized training protocol for Byzantine - tolerant deep learning under the presence of Byzantine attackers. The proposed protocol is based on the BYOD protocol proposed in [ 1 ]. Theoretically, the authors show that the proposed protocol can be more robust to Byzantine attacks than BYOD. The authors also provide theoretical bounds for its resistance against Byzantine attacks. Experiments on image classification and language modeling demonstrate the effectiveness of the proposed method."
SP:93894f20ab2593e5237b6972fef9fe63e96af89a,"This paper presents a physics - informed learning approach to learn a hierarchy of parameterized and physics - explainable SPH - informed fluid simulators using both physics - based parameters and Neural Networks as universal function approximators. The authors present a mixed - mode approach, mixing forward and reverse mode automatic differentiation with forward and adjoint based sensitivity analyses to efficiently perform gradient - based optimization. They show that their physics informed learning method is capable of solving inverse problems over the physically interpretable parameter space, as well as over the space of Neural Network parameters ; ( b ) learning Lagrangian statistics of turbulence ; ( c ) learning the parameters of the neural network parameters ; and ( d ) extrapolating beyond training sets into more complex regimes of interest."
SP:d11b81f9ab414fcf430a03cd70c2d3246b678474,"This paper proposes a novel approach to regularize a single - deterministic neural network to obtain improved accuracy and reliable uncertainty estimates. The proposed approach adds an entropy maximization regularizer corresponding to the predictive distribution in the region of the embedding space between the class clusters by synthetically generating between - cluster samples via the convex combination of two images from different classes and maximizing the entropy on these samples. Such a data - dependent regularization guides the maximum likelihood estimation to prefer a solution that maps out - of - distribution samples to high entropy regions ( creating an entropy barrier ) and is more robust to the superficial input perturbations. Extensive experiments on two real - world datasets demonstrate that the proposed method achieves improved classification accuracy, better calibrated probabilities for in - distribution data, and reliable uncertainties estimates."
SP:365490b872464f00634dc7a50d024fceaf0a61ee,"This paper proposes a self - supervised method for generating motion - based images from still images without relying on structure representation. The proposed method, Latent Image Animator ( LIA ), is based on linear navigation in the latent space. The method is evaluated on three datasets ( VoxCeleb, Taichi, and TED - Talk ), and compared with several state - of - the - art methods. The results show that the proposed method is more efficient than the other methods in terms of both the number of samples required to generate an image and the quality of the generated images."
SP:86f9f89f84e117c86478b9afaf087f65524f5472,"Meta - learning enables algorithms to quickly learn a newly encountered task with just a few labeled examples by transferring previously learned knowledge. However, the bottleneck of current meta - learning algorithms is the requirement of a large number of meta - training tasks, which may not be accessible in real - world scenarios. To address the challenge that available tasks may not densely sample the space of tasks, this paper proposes to augment the task set through interpolation. By meta learning with task interpolation ( MLTI ), the approach effectively generates additional tasks by randomly sampling a pair of tasks and interpolating the corresponding features and labels. Theoretical analysis shows MLTI corresponds to a data - adaptationive meta - regularization and further improves the generalization."
SP:73d577e9c4f4af5e11a9e5bdb583ee0f50a315f5,"This paper proposes a new fair representation learning method called Fair Normalizing Flows ( FNF ). FNF is based on normalizing flows ( NFs ) that minimize the statistical distance between the latent representations of different groups. The main advantage of F NF is that exact likelihood computation allows us to obtain guarantees on the maximum unfairness of any potentially adversarial downstream predictor. The authors demonstrate the effectiveness of FNF in enforcing various group fairness notions, as well as other attractive properties such as interpretability and transfer learning."
SP:404d5643327f60f0f06f820033a56081f9e01900,"This paper proposes a graph neural network ( GNN ) based method for isomorphism counting for complex graph structures. The key idea is to treat edges as first - class citizens of the graph and use an edge - centric message passing scheme to learn a low - dimensional representation for each edge based on the edge adjacency. At the graph level, the input graph representation conditioned on the query is adapted to each query individually to improve their matching performance. The proposed method is evaluated on a number of benchmark datasets and achieves superior performance in comparison to the state - of - the - art baselines."
SP:5a94f18156ab2949c86de45fcf0de2e16977eebb,"This paper proposes SimFed, a framework for loosely - constrained federated learning ( APFL ) where local participants have their own personalized labels, which might not be compatible with others ( even for the same class ), and can be also possibly from a variety of multiple domains. The authors propose a novel method, namely Similarity Matching and Kernel Factorization ( SimFed ), for personalized knowledge reflection. The method measures task - level similarity based on locally learned knowledge and matches the relevant ones. SimFed also factorize the model parameters into two basis vectors and a sparse masks to significantly reduce the dimensionlaity of parameter space for alleviating knowledge collapse and information loss when reflecting the heterogeneous knowledge. Empirical results on both single and multi - domain datasets show that SimFed outperforms the current state - of - the - art federated methods."
SP:97f30bea31eccef6c770fbce1e14fd6d2493a178,"This paper proposes a method to learn object - centric representations of scenes with multiple objects. The proposed method is based on object dynamics distillation network ( ODDN ) that distills explicit object dynamic representations ( e.g., velocity ) from raw video input and a relation module that calculates object - pair interactions and applies it to the corresponding dynamic representations of objects. Experiments are conducted on tasks of video events reasoning and video prediction. The results show that visual representations of ODDN perform better in answering reasoning questions around physical events in a video compared to representaions of the previous scene representation methods."
SP:ba8e50d1fa9cb824fa3f76c0c691997cd151d760,"This paper proposes a new graph neural network ( GNN ) layer based on positional encoding ( PEG ) techniques for graph neural networks that allow using positional features of nodes given by positional encoding techniques such as Laplacian Eigenmap, Deepwalk, etc. The proposed PEG layer is generalizable to unseen graphs ( i.e., non - iid graphs ) and stable. Extensive link prediction experiments over 8 real - world networks demonstrate the advantages of PEG in generalization and scalability."
SP:cf448479f68c3194c1a9e11729bf70d7cc2ae8fd,"This paper proposes LaMer, a novel text style transfer framework based on large - scale language models. LaMer first mines the roughly parallel expressions in the non - parallel datasets with scene graphs, and then employs MLE training, followed by imitation learning refinement, to leverage the intrinsic parallelism within the data. On two benchmark tasks ( sentiment & formality transfer ) and a newly proposed challenging task ( political stance transfer ), the proposed LaMer achieves qualitative and quantitative improvements compared to the baselines. The proposed method also generates more readable and diverse expressions than previous models."
SP:8f7b2d1020d9e527118b8fb816760c13b0d0bfcb,"This paper proposes a method to answer hyper - relational queries in knowledge graphs ( KGs ), which extend the multi - hop reasoning problem to hyper - relational queries. Hyper - Relational queries are often observed in real - world KGs, and existing approaches for approximate query answering ( QA ) can not make use of qualifier pairs in the context of such queries. In this work, the authors bridge this gap and extend the existing Graph Neural Networks ( GNNs ) and Graph Neural Embedding ( GNE ) methods to handle such queries in a graph neural network setting. The authors propose a query embedding and query answering method for such queries and demonstrate the effectiveness of the proposed method on a diverse set of query patterns."
SP:5f8b58424a1a8eeb72217e75189d6f773a298a7a,"This paper proposes a new multi - budget hyperparameter optimization method, DYHPO, that learns to dynamically decide which configuration to try next, and for what budget, based on the dynamics of the learning curve dynamics of a gaussian process. The proposed method is a modification to the classical Bayesian optimization for a gray - box setup. Experiments on 50 datasets show that the proposed method outperforms state - of - the - art methods. The main contribution of this paper is to propose a new surrogate for Gaussian Processes that embeds the learning curves and a new acquisition function that incorporates multi - budgets information."
SP:99d3d94e3af5d2dc7b92c00ac1345d1d2dd0d15b,"This paper proposes a post - training quantization method for learned image compression to improve the performance of the model. The main idea is to make the model inference integer - arithmetic - only, which is much simpler than the existing training and fine - tuning based approaches. The authors further improve the discretization of the entropy parameters and extend the deterministic inference to fit Gaussian mixture models to solve the non - deterministic calculation problem. The proposed method is applicable to both learned and unsupervised image compression."
SP:85d0df515e9e555f3ea1c21d607304dfaeae69c0,This paper proposes an unsupervised noise denoising network for 3D electron microscopy images. The network is based on a recurrent network that reconstructs and removes the noise from the data by synthesizing the sequential data. The noise is denoised by a Gated Recurrent Unit ( GRU ) architecture. The proposed network is evaluated on 3D Electron Microscopy data sets. The results show that the network is able to distinguish true signal from noise and achieves comparable results compared to supervised approaches.
SP:e6275b0b103fa90dcebcdd3d3c14c830c3402972,"This paper studies the stochastic label trick in graph neural networks ( GNNs ) and label propagation in the context of node property prediction. The authors show that under certain simplifying assumptions, the so - called label trick can be reduced to an interpretable, deterministic training objective composed of two factors. The first is a data - fitting term that resolves potential label leakage issues, while the second serves as a regularization factor conditioned on graph structure that adapts to graph size and connectivity.   The authors then leverage this perspective to motivate a broader range of label trick use cases, and provide experiments to verify the efficacy of these extensions."
SP:b6cbc3661f9c440687c3dd01ee35a118c87db377,"This paper studies the theory of mind ( ToM ) in multi - agent reinforcement learning scenarios. The authors propose a new paradigm for ToM, called SymmToM, where all agents have the same capacity to communicate with other agents and move freely through a grid world. The proposed paradigm is more flexible and symmetric than the standard symmetric ToM scenario, where one agent tries to understand another agent ’s “ mental state ”. They show that the proposed paradigm requires the agent to develop a theory of state theory to understand the other agents ’ mental states. They also show that an effective strategy to solve a given problem requires developing theory to maximize the performance of each agent, and that the best agents fail to achieve performance that is comparable to agents with access to access to the mental states of other agents.  "
SP:f8ce83805eee46c6c196e8477bf10d8d7f7e0f46,"This paper proposes a zero - shot object detection method for indoor scenes. The proposed method is based on the YCB video dataset. The dataset consists of 21 objects of different sizes and categories. The method is evaluated on two tasks : ( 1 ) detect novel objects in the image with the knowledge learned from and only from seen objects, and ( 2 ) detect objects in an image that are new to the system. The first task is the novel object detection, while the second one is the object detection on the indoor scenes task.   The algorithm is trained on the image dataset using a combination of standard vision - based and object detection - based loss functions. The loss functions are optimized using a two - stage strategy. The training objective consists of two steps : 1 ) training the vision system on the original image, and 2 ) fine - tuning the object detector on the new image. The main contribution of the paper is the introduction of the zero shot detection algorithm."
SP:aa1dcd9217270010f16a00004facede942efea17,"This paper proposes a method for video prediction based on an autoregressive latent video model. The method is based on a combination of an image generator model and a causal transformer model, where the former is used to predict future frames and the latter is used for predicting future frames in the latent space of the image generator. The image generator is trained in a two - stage manner. The first stage is to predict the latent representation of the latent variable of the generator, and the second stage is the prediction of the future frame of the generated latent variable. The proposed method is evaluated on state - of - the - art video prediction benchmarks with fewer parameters, and high - resolution video prediction on complex and large - scale datasets.  "
SP:7f57896afd63bc869d2db6ddf7abbeaa71daae11,"Vision Transformers ( ViTs ) have shown competitive performance on image recognition while requiring less vision - specific inductive biases. In this paper, the authors investigate if such performance can be extended to image generation. To this end, they integrate the ViT architecture into generative adversarial networks ( GANs ), where they introduce several novel regularization techniques for training GAN models with ViTs. For ViT generators, they examine architectural choices for latent and pixel mapping layers to faciliate convergence. Empirically, their approach, named ViTGAN, achieves comparable performance to the leading CNN - based GAN model on three datasets."
SP:bbae3afcaea0a2e54904cb8daaed7df4fe37da6e,"This paper proposes to decompose the task of generative modeling in variational autoencoders into two steps : 1 ) prioritize the modeling of the visually perceptible information to achieve good sample quality, and then subsequently model the imperceptible information — the bulk of the likelihood signal—to achieve good likelihood. The authors show that the majority of the entropy in natural image data distributions is attributable to visually imperceptable information, which dominates the training objective, making it difficult for generative models to achieve competitive likelihoods without successful modeling the visually perceivable bits. The proposed decomposition of the generative model is motivated by the hypothesis that good likelihoods do not imply great sample quality."
SP:bfed56018134ec66cde9a7e958df964d4cca3164,"This paper proposes a training - free framework for estimating the variance of a Diffusion Probabilistic Model ( DPM ) using Monte Carlo methods and a pretrained score - based model. The paper first shows that optimal reverse variance and optimal KL divergence of a DPM have analytic forms w.r.t. its score function. Then, the paper proposes to estimate the analytic form of the variance and KL divergence using the Monte Carlo method and a pre - trained Score - based Model ( SAP ). Finally, the authors derive both lower and upper bounds of the optimal variance of the DPM and KL divergences, respectively, for various DPMs."
SP:3f935ba5784c3e86db72421426bc479061af1a4b,"This paper explores the feasibility of using vision transformers ( ViTs ) for medical image classification. The authors ask if it is feasible to switch from CNNs to ViTs for image classification, and if ViTs can be trivially replaced by CNNs. They conduct a series of experiments on several standard medical image benchmark datasets and tasks, and show that ViTs perform better if trained from scratch, off - the - shelf, and in a supervised / self - supervised setting."
SP:a64e0535f268901e38fd51e027c612ebcdbae1a4,"This paper studies the problem of pretraining neural language models ( NLMs ) on natural language understanding tasks. The authors show that pretraining NLMs over a large corpus involves chunking the text into training examples, which are contiguous text segments of sizes processable by the neural architecture, and highlight a bias introduced by this common practice. They prove that the pretrained NLMs can model much stronger dependencies between text segments that appeared in the same training example than it can between different training examples. This intuitive result has twofold role. First, it formalizes the motivation behind a broad line of recent successful NLM training heuristics, proposed for the pretraining and fine - tuning stages, which do not necessarily appear related at first glance. Second, it clearly indicates further improvements to be made in NLM pretraining for the benefit of natural language Understanding tasks."
SP:59066956fa2e423d5f2d2ea4f91c4ddf6afd4683,"This paper proposes a new L2O model for large - scale optimization problems. The proposed method is based on the well - established approach of meta - training of neural networks that parameterize optimization rules by neural networks, and learns those numerical rules via meta training. The authors argue that this approach is problematic in two ways : ( 1 ) scalability : the numerical rules represent extra memory overhead, and limits their applicability to optimizing larger tasks ; ( 2 ) interpretability : it is unclear what each neural network has learned in its black - box optimization rule, nor is it straightforward to compare different neural networks in an explainable way. To avoid both pitfalls, this paper proves the concept that we can “kill two birds by one stone ”, by introducing the powerful tool of symbolic regression to L _ 2 _ O models, which yields a series of insights for learnable optimizers. Leveraging these findings, the authors propose a lightweight L_2 _ O model that can be meta - trained on large _ scale _ problems and outperforms human - designed and tuned optimizers, and proves the effectiveness of the proposed method."
SP:54dfeb363beee9959aecc9e0853ff06e43bd94e4,"This paper studies the problem of adversarial robustness in reinforcement learning ( RL ), where a non - adaptive adversary can learn the defense strategy of the victim agent by observing the states, actions, etc. from previous time - steps and adapt itself to produce stronger attacks in future steps. The authors present an efficient procedure, designed specifically to defend against an adaptive RL adversary, that can directly certify the total reward without requiring the policy to be robust at each time - step. The main theoretical contribution is to prove an adaptive version of the smoothing - based defense, where the agent adds Gaussian noise to its observation at every time step before passing it through the policy function. The robustness certificates guarantee that the final total reward obtained by policy smoothing remains above a certain threshold, even though the actions at intermediate time - stages may change under the attack. They show that their certificates are tight by constructing a worst - case scenario that achieves the bounds derived in the analysis. The experiments on various environments like Cartpole, Pong, Freeway and Mountain Car show that the method can yield meaningful robustness guarantees in practice."
SP:e0f9add5fde18eaab0eeb2b10b14928acc8ec5b8,"This paper proposes a method for estimating the target performance of a model trained on labeled source data and unlabeled target data. The main idea is to learn a threshold on the model ’s confidence and use it to estimate the accuracy of the target. The target performance is defined as the fraction of examples for which the confidence of the model exceeds the threshold. The proposed method is evaluated on a number of datasets ( WILDS, ImageNet, BREEDS, CIFAR, and MNIST ), model architectures, distribution shifts ( e.g., due to synthetic corruptions, dataset reproduction, or novel subpopulations ), as well as datasets ( ImageNet ). The results show that the proposed method ATC outperforms previous methods across several model architectures and types of distribution shifts."
SP:e748bf6ee653087cae825df32a8546f9ccebfcf1,"This paper studies the problem of point set registration, where the goal is to recover a transformation that matches one point set to the other. The registration problem is formulated as a partial distribution matching ( PDM ) problem, where two point sets are regarded as discrete distributions and the goal of the learner is to partially match them. The authors propose a method for large scale PDM problem by utilizing the partial Wasserstein-1 ( PW ) discrepancy, which they show can be efficiently optimized. Specifically, they theoretically derive the Kantorovich - Rubinstein duality for the PW discrepancy, and show its gradient can be explicitly computed. Based on these theoretical results, they propose a PWAN method, which approximates the discrepancy by a neural network, and learns the transformation adversarially with the network. The proposed method is evaluated on two point - set registration tasks, and shows that the proposed PWAN is robust and scalable."
SP:f94f77696d100b2638fa2a6d82c8df47db3b6a36,This paper proposes a novel transfer learning method for hyperparameter optimization ( HPO ) that can be jointly meta - trained on a set of source tasks and then transferred efficiently on a new ( unseen ) target task. The proposed method is based on Deep Kernel Gaussian Process ( DKGP ) with Landmark Meta - Features ( DKLM ). The DKLM is designed to capture the similarity between hyperparameters configurations with an end - to - end meta - feature network that embeds the set of evaluated configurations and their respective performance. The authors experimentally validate the performance of DKLM in a range of HPO scenarios and demonstrate the empirical superiority of the method against a series of state - of - the - art methods.
SP:e3c57f3589e8ab674644d900c14b3473cd71a23f,This paper presents a method for fingerprinting deep generative models ( DGMs ) to detect and attribute fakes. The key idea is to generate a large population of models with distinct fingerprints for each model and pass the generated samples to a GAN network to detect the fakes and attribute them to a specific source. The authors propose an efficient and scalable method for the generation of the fingerprinting mechanism. The method is evaluated on synthetic and real datasets and compared with several state - of - the - art methods for fake detection and attribution.
SP:73bffd1a0856b80d29f7a2b2b68be57882531f07,"This paper proposes a method to provide post - hoc local explanations for black box machine learning models that output a prediction with high similarity between two input pairs. The main idea is to use an analogie approach to identify pairs of examples that share the same level of similarity and provide insight into ( latent ) factors underlying the model ’s prediction. The selection of analogies can leverage feature attributions, thus connecting the two forms of explanation while still maintaining complementarity. The method is applicable to both tabular and text data and is shown to provide model agnostic local explanations."
SP:6a3c4ae05d582f8896840483b08c735ced2976bc,"This paper studies the certified robustness of ensembles of deep neural networks ( DNNs ) against adversarial perturbations of small magnitude. The authors provide sufficient and necessary conditions of robustness for ensemble ML models, together with the proposed Ensemble - before - Smoothing ( ENsemble ) protocol. They also prove that an ensemble model can always achieve higher robustness than a single base model under mild conditions. Inspired by the theoretical findings, they propose the lightweight Diversity Regularized Training ( DRT ) to improve the robustness performance of ensemble models. Extensive experiments show that DRT enhanced ensemble models can consistently achieve higher certified L2 - robustness."
SP:3002b29c27709780238876d8c3f81bbd6a0f8112,"This paper studies the expressive power of low - order graph neural networks ( GNNs ). The authors propose a new recursive pooling technique of local neighborhoods that allows different tradeoffs of computational cost and expressive power. In particular, the authors prove that this model can count subgraphs of size k, and thereby overcomes a known limitation of low _ order _ graph neural network ( GRNN ). Second, they show how recurral pooling can exploit sparsity to reduce the computational complexity compared to the existing higher - order Graph Neural Networks ( GCN ). More generally, they provide a ( near ) matching information - theoretical matching graph representations that pool over representations of derived graphs."
SP:5d0cbd84336caf5f31e1f98e11f6733230e4d792,"This paper proposes a probe model called GCS for interpreting knowledge - enhanced LMs ( KI ) and exposing what kind of knowledge is integrated into these models. GCS is based on graph convolution ( GCS ), which is a convolutional neural network that maps the input input to a graph representation. The GCS model is used to analyze two KI methods, K - adapter and ERNIE, and find that only a small amount of factual knowledge is captured in these models during knowledge integration. While K - Adapter is better at integrating simple relational knowledge, complex relational knowledge is better integrated into ERNs. The paper also finds that increasing the size of the KI corpus may not lead to better KI and more fundamental advances may be needed."
SP:7e73948421e98307fceb69a316d8a4e7c4926cda,"This paper studies the effect of the adaptation learning rate in meta - learning with mixed linear regression. The authors first provide a principled way to estimate optimal adaptation learning rates that minimize the population risk of MAML. Second, they interpret the underlying dependence between the optimal learning rate and the input data. Finally, they prove that compared with empirical risk minimization ( ERM ), MAMM produces an initialization with a smaller average distance to the task optima, consistent with previous practical findings."
SP:effbc85d89b1197d9c2abcaf5ff13864135dd6e1,"This paper proposes a new method for source - free domain adaptation ( SFDA ), which aims to adapt a model trained on labelled data in a source domain to unlabelled data in an unlabeled target domain without access to the source - domain data during the adaptation phase. Existing methods for SFDA leverage entropy - minimimization techniques, which destroy model calibration and rely on the source model achieving a good level of feature - space class - separation in the target domain. This paper addresses these issues for a pervasive type of domain shift called measurement shift, characterized by a change in measurement system, which can be resolved by restoring the source features. In the source domain, the authors store a lightweight and flexible approximation of the feature distribution under the source data and adapt the feature - extractor such that the approximate feature distribution is the same under both source and target. The authors call this method Feature Restoration ( FR ) as it seeks to extract features with the same semantics from target domain as were previously extracted from the source, rather than extracting new ones. They additionally propose Bottom - Up Feature restoration ( BUFR ) — a bottom - up training scheme for FR — which boosts performance by preserving learnt structure in the later layers of a network. BUFR outperforms existing SFDA methods on real and synthetic data in terms of accuracy, calibration, and data efficiency."
SP:7d63034ec7e6a4f178681ff2a49feb485cd47116,"This paper proposes a novel FL setting that propagates adversarial robustness from high - resource users that can afford adversarial training ( AT ) to low - resource ( FL ) users that cannot afford it. The proposed method propagates robustness among non - iid users via a simple yet effective propagation propagation method that transfers robustness through carefully designed batch - designed robustness measures. The authors demonstrate the effectiveness of the proposed method through extensive experiments.    The paper is well - written, well - organized, and easy to follow. The contributions are as follows :   1. Propose a new FL setting for propagation of robustness propagation. 2. Introduce a novel method for FL propagation that propagate robustness to adversarial attacks. 3. Conduct extensive experiments to show the effectiveness and efficiency of the method."
SP:42c7a79e58b6a9f776fa6ae928bd89c194f9303f,"This paper proposes a transformer - based method for learning a mapping from observed equilibrium actions to the network structure of a network game without knowing the utility function associated with the game. The proposed method is based on the transformer - like architecture that correctly accounts for the symmetries of the problem and learns a mapping between the equilibrium actions of a player and the network structures of the game without explicit knowledge of the utility functions. The method is evaluated on three different types of network games using both synthetic and real - world data, and demonstrate its effectiveness in network structure inference and demonstrates superior performance over existing methods."
SP:1c7b9157cf8c06ca771da78895fc3af969b0fb85,"This paper proposes GraphANGEL, a relation prediction framework for transductive graphs. The main idea is to learn the latent representations of observed nodes and relations by checking whether they are similar to other subgraphs containing the considered relation. In particular, GraphAngEL uses an ANalogy SubGraph Embedding Learning ( AGEL ) method to learn a graph pattern that represents a specific logical rule. The inductive bias of this graph pattern is used to generalize to unseen relation types and leads to more explainable predictive models. Empirical results show that GraphAngel outperforms existing models in heterogeneous graph recommendation and knowledge graph completion settings."
SP:26ed25a7b42da2cf11b76a727102d8aa36d76657,"This paper studies self - supervised learning for few - shot learning in histology images. The authors propose to combine contrastive learning ( CL ) with latent augmentation ( LA ) to build a system that learns useful representations without manual labels, while LA transfers semantic variations of the base dataset in an unsupervised way. They show the superiority of CL over supervised learning in terms of generalization for such data and provide an empirical understanding for this observation. The findings in this work could contribute to understanding how the model generalizes in the context of both representation learning and histological image analysis."
SP:badbe687258cd5c282ca167b1f6fbfc6b5400dbf,"This paper proposes a method for learning continuous - time RNNs with long - term dependencies in the input data. The authors show that the vanishing or exploding of the gradient during training is the underlying reason for this issue, which is expressed by the ordinary differential equation ( ODE ) representation of the hidden state, regardless of the ODE solver ’s choice. To solve this problem, the authors provide a solution by equipping arbitrary continuous time - continuous networks with a memory compartment separated from its timecontinuous state. The memory is used to encode a continuous time dynamical flow within the RNN, which allows it to respond to inputs arriving at arbitrary time - lags while ensuring a constant error propagation through the memory path. The proposed method is called Mixed - Memory - RNN ( MMRN ). Experiments show that it outperforms other RNN - based counterparts on non - uniformly sampled data with long term dependencies."
SP:4efd22f9122fa5856a9f4302eb6875fa0c414912,"This paper proposes BiBERT, a binarized BERT model that uses a 1 - bit weight binarization method to reduce the computation and memory consumption of BERT models. The authors claim that the performance of binarised BERT suffers a significant performance drop due to the information degradation and the optimization direction mismatch. To address this issue, the authors propose a novel DMD scheme to optimize the full binarize BERT. Extensive experiments show that the proposed method outperforms the original BERT with ultra - low bit activations by convincing margins on the NLP benchmark."
SP:619bd742e92bea6241852f5a9d2b7bacf13b393a,"This paper proposes a new method for instance - aware keypoint detection and instance association using Transformer. The key idea is to use instance masks to supervise the self - attention of the Transformer model. The idea is that the instance masks can be directly obtained from the supervised attention matrix, thereby simplifying the pixel assignment pipeline. The experiments on the COCO multi - person keypoints detection challenge and the person instance segmentation task demonstrate the effectiveness and simplicity of the proposed method."
SP:14750819593136fc9ef4efd032ab6f94dc5f6a02,"This paper proposes a Pareto - efficient RL algorithm for the mean - variance ( MV ) trade - off problem. The main idea is to train an agent to maximize the expected quadratic utility function, which corresponds to an efficient policy in terms of the variance term, and then use this maximized policy as a proxy for the optimal policy in the MV tradeoff problem. In order to achieve this goal, the authors train the agent to minimize the KL - divergence between the policy and the maximizer of the expected utility function. The KL divergence is obtained by minimizing the KL term of the utility function with respect to the mean and variance terms, which is computationally feasible since gradient estimation of the mean term is not required. The proposed algorithm is evaluated on a number of synthetic and real - world datasets and compared with several baseline algorithms."
SP:f675b564b3a9c8626ce7944d752fa3e0d868428e,"This paper proposes a fast and sample - efficient method for adapting the autoencoder for end - to - end learning of a communication system using a generatively - modelled generative - modeled generative neural network ( MDN ) for domain adaptation. The proposed method utilizes feature transformations at the decoder to compensate for changes in the channel distribution and adapt only the MDN channel. Experiments on simulated datasets and real mmWave wireless channels demonstrate that the proposed method can adapt the MDNs channel using very limited number of samples, and improve or maintain the error rate of the autencoder under changing channel conditions.    Overall, this paper is well - written and easy to follow."
SP:77dc92137ea490d3e1b4b8ee1630dbe2ee0bddfa,"This paper proposes a novel interactive language model ( IMSL ) for the abductive natural language inference task ( $ \alpha$-NLI ). The authors argue that it is unnecessary to distinguish the reasoning abilities among correct hypotheses and similarly, all wrong hypotheses contribute the same when explaining the reasons of the observations. Therefore, the authors propose to group instead of ranking the hypotheses and design a structural loss called “ joint softmax focal loss ” in this paper. The experimental results show that the proposed method achieves the highest performance on the RoBERTa - large pretrained model."
SP:17cd72df5fc19398f582d27516fd742b073f79e3,This paper proposes a new method for adversarially robust out - of - distribution ( OOD ) detection and classification based on a certified OOD detector and a standard classifier for OOD - aware classifier. The detector is based on an existing method for certifiable OOD detection and the classifier is a standard OOD classifier from first principles. The main contribution of this paper is to combine the two methods to achieve the best of two worlds : certifiably OOD robust detection and non - manipulated OOD classification without loss in accuracy.
SP:9c3756f13932236aff3e8104f4fa193dcc8fde2f,"This paper proposes a new generalized transferable attack ( GTA ) problem where the attacker has a set of surrogate models trained on different datasets ( with different label sets and image sizes ), and none of them is identical to the dataset used by the victim model. The authors propose a novel method called Image Classification ( ICE ) to erase classification information for any encountered images from arbitrary dataset. Extensive experiments on Cifar-10, CIFAR-100, and TieredImageNet demonstrate the effectiveness of the proposed ICE on the proposed GTA problem. Furthermore, the authors show that existing transfer attack methods can be modified to the GTA problem, but with significantly worse performance compared with ICE."
SP:2e0447c741a3f09be1095633d870200355211260,"This paper proposes two counter - counter - false - negative pre - training methods for Discriminative Pre - trained Language Model ( PrLM ), which aims to prevent false negative predictions in the discriminative PrLM. The first method is based on defining the false negative issue in PrLM that has been ignored for a long time. The second method is on the basis of correcting the harmful gradient updates subject to false negative prediction. Experiments on GLUE and SQuAD benchmarks show that the proposed methods achieve better performance than the existing methods."
SP:281bc59d639aa76d84921b3ec4ce1ee8f1ba5b51,"This paper introduces a novel open - world semi - supervised learning setting in which novel classes may appear in unlabeled test data. The goal is to solve the class distribution mismatch problem where at the test time every input instance either needs to be classified into one of the existing classes or a new unseen class. To tackle this challenging problem, the authors propose ORCA, an end - to - end approach that assigns instances to previously seen classes or novel classes by grouping similar instances without assuming any prior knowledge. ORCA gradually increases the discriminability of the model during the training and reduces the gap between intra - class variance of seen with novel classes. Extensive experiments on image classification datasets and a single - cell dataset demonstrate that ORCA consistently outperforms alternative baselines, achieving 25 % improvement on seen and 96% improvement on novel classes of the ImageNet dataset."
SP:6c572c4c21b01a0cf3fd9ef97fbb348ef4e405ae,"This paper proposes SLIM - QN, a light - t stochastic quasi - Newton optimizer for training large - scale deep neural networks ( DNNs ). The proposed method addresses two key barriers in existing second - order methods : 1 ) the high computational cost of obtaining the Hessian matrix and its inverse in every iteration ( e.g., KFAC ) and 2 ) convergence instability due to stochastically training. To tackle the first challenge, the proposed method uses the BFGS update rule that directly approximates Hessian inverse using past parameters and gradients. To achieve stable convergence, SLIM-QN introduces momentum in Hessian updates together with an adaptive damping mechanism. Theoretical results on the convergence convergence on the stationary point of the convergence of the method are provided. On ImageNet and CIFAR-10 datasets, the method achieves near optimal accuracy 1.5× faster when compared with SGD ( 1.36× faster in wall - clock time ) and 1.85× faster using the same compute resources. The method can also be applied to other contemporary non - convolutional architectures such as Transformers."
SP:4bffce00ebb02d2e676eec897647ac14c3344deb,"Graph Neural Networks ( GNNs ) have emerged as highly successful tools for graph - related tasks. However, real - world problems involve very large graphs, and the compute resources needed to fit them to those problems grow rapidly. In addition, the noisy nature and size of real world graphs cause GNNS to over - fit if not regularized properly. Surprisingly, recent works show that large graphs often involve many redundant components that can be removed without compromising the performance too much. This includes node or edge removals during inference through GNN layers or as a pre - processing step that sparsifies the input graph. This intriguing phenomenon enables the development of state - of - the - art graph neural networks that are both efficient and accurate. This paper takes a further step towards demystifying this phenomenon and propose a systematic method called LSP, which removes a significant amount of edges from large graphs without compromising performance, accompanied by a considerable acceleration. Extensive experiments on synthetic and real world datasets demonstrate the superiority of LSP."
SP:c5e024f4e2079586298519ca868630efd7579eca,"This paper proposes IDAA ( identity - disentangled adversarial augmentation ), a data augmentation method that can modify training data to be hard positives / negatives without distorting the key information about their original identities. The key idea is to decompose a sample x to be its variational auto - encoder ( VAE ) reconstruction G(x ) plus the residual R(x), where R retains most identitydistinctive information due to an information - theoretic interpretation of the VAE ’s bottleneck space and adds it back to the original. The authors apply IDAA to different self - supervised learning methods and show that IDAA consistently improves both efficiency and generalization performance on multiple benchmark datasets."
SP:0991bc5f213bd8ab7572e2fed309e1b57a35835b,"This paper proposes a framework for testing if the difference between source ( training and target ) and target ( label ) is greater than a certain threshold. The authors argue that a sensible method for firing off a warning has to both ( a ) detect harmful shifts while ignoring benign ones, and ( b ) allow continuous monitoring of model performance without increasing the false alarm rate. To this end, the authors propose simple sequential tools for testing. They demonstrate the efficacy of the proposed framework through an extensive empirical study on a collection of simulated and real datasets.    The main contributions of this work are as follows :   1. The proposed framework is a novel approach to detect distribution shifts in the training of machine learning models. 2. It is the first framework that can detect arbitrary distribution shifts ( benign or harmful ). 3. It can detect harmful distribution shifts while not detecting benign ones. 4. It has the advantage of being able to detect harmful and benign shifts simultaneously."
SP:1c7b954273e3a9cda333385b15a3e8ed3bf8178a,"This paper proposes a method to recover physical parameters directly from a single real - world video. The method combines a neural implicit representation for appearance modeling with neural ordinary differential equations ( ODEs ) in order to obtain interpretable physical models directly from visual observations. The proposed method can precisely recover the metric length of the pendulum from the monocular video ( relative error to true length is less than 2.5 % ). The use of neural implicit representations enables the processing of high - resolution videos and the synthesis of photo - realistic imagery. The ODE has a known parametric form that allows for the identification of interpretable parameters, and the left half of the image shows our reconstruction based on physical parameters that we estimate from the input."
SP:51efd1451343f4994d857daa5490e299b812bc2d,"This paper considers a context - dependent reinforcement learning setting with an unknown finite number of not - yet - observable contexts and abrupt context changes during an episode. The authors propose a Hierarchical Dirichlet Process ( HDP ) prior for model learning, which is arguably best - suited for Markov process modeling, and derive a context distillation procedure to identify and remove spurious contexts in an unsupervised fashion. They argue that the combination of these two components allows to infer the number of contexts from data thus dealing with the context cardinality assumption. They then find the representation of the optimal policy enabling efficient policy learning using off - the - shelf RL algorithms. Finally, they demonstrate empirically ( using gym environments cart - pole swing-up, drone, intersection ) that our approach succeeds where state - of - the-art fail and elaborate on the reasons for such failures."
SP:ea167b126212b2092bc1190d7f8376bf7c54a888,"This paper proposes a framework to pretrain knowledge - based multilingual language models ( KMLMs ) on a large amount of synthetic sentences and reasoning - based multi - lingual training data using the Wikidata knowledge graph. The pretraining tasks are designed to facilitate knowledge learning, which allows the language models to not only memorize the factual knowledge but also learn useful logical patterns. Experiments are conducted on a wide range of knowledge - intensive cross - luiderual NLP tasks, including named entity recognition, factual knowledge retrieval, relation classification, and a new task designed by the authors, namely, logic reasoning."
SP:6c11cf29c90f923346372ba6f11452c36e69ad6d,"This paper proposes an approach to learning agents that act altruistically towards other agents by giving them more choice and thereby allowing them to better achieve their goals without interference. The idea is to train an agent that learns to increase the number of states that the other agent can reach in its future by rewarding them for benefiting other agents in a task - agnostic manner. The proposed approach is evaluated on three different multi - agent environments where another agent ’s success depends on the altruistic agent’s behaviour. The authors show that their unsupervised agents can perform comparably to agents explicitly trained to work cooperatively, in some cases even outperforming them."
SP:5dbc54201ba184266c5054f0d2944bd197bc307a,"This paper studies the double descent phenomenon in neural networks under and over - parametrized regimes. The main contribution of this paper is to derive the lower bound of the population loss and its lower bound on the Hessian of a neural network. The lower bound is derived using the influence function. The influence function is defined as the sum of the log - likelihood of the output of the neural network with respect to the population at the interpolation threshold. The authors show that under certain assumptions on the population function and the choice of the loss function, double descent can be observed in a finite - width neural network and its Hessian can also be observed under overparameterized and under - parameterized regimes.   The authors also show that double descent is also observed in linear regression models."
SP:b485114712055f39a7afb951dbc3db482ff523fd,"This paper studies the over - smoothing problem of deep GCNs, where node representations tend to be indistinguishable as more layers are stacked up. The authors exploit the Graph Neural Tangent Kernel ( GNTK ), which governs the optimization trajectory under gradient descent for wide GCNs. They formulate the asymptotic behaviors of G NTK in the large depth, which enables us to reveal the expressive power and trainability of GCNs at an exponential rate in the optimization process. They also extend their theoretical analysis to analyze residual connection - based techniques, which are found to be only able to mildly mitigate the exponential decay of trainability. Finally, they propose Critical DropEdge, a connectivity - aware and graph - adaptive sampling method, inspired by their theoretical insights on trainability and connectivity."
SP:25a92b3583afdc6892e59f1e769125d52c8011af,"This paper studies the problem of estimating second - order dynamics in computer vision models. In particular, the authors focus on the accuracy of waveform morphology that is necessary for many clinically impactful scenarios, e.g., estimating the second derivative of a physiological signal, such as a cardiac signal. The authors provide evidence that higher order dynamics are better estimated by neural models when explicitly optimized for in the loss function. They also show that adding second - derivative inputs also improves performance when estimating second order dynamics. The paper is well organized and easy to follow."
SP:0a88d2fcbdfab3e196bf6b9c75adb1006ab87536,"This paper proposes a symbolic mapping method to help agents learn a compositional and symmetric language in complex settings like dialog games. The authors hypothesize that language may evolve from simple tasks to difficult tasks and propose a novel architecture called symbolic mapping as a basic component of the communication system of agent. They find that symbolic mapping learned in simple referential games can notably promote language learning in difficult tasks. Further, they explore vocabulary expansion, and show that with the help of symbolic mapping, agents can easily learn to use new symbols when the environment becomes more complex."
SP:89575be04cb33b41d7a0a7b62f9496c2838a1317,"This paper proposes a hierarchical modular approach to learn agents that navigate and manipulate objects in a divide - and - conquer manner for the diverse nature of the tasks. Specifically, the policy operates at three levels of hierarchy. First infer a sequence of subgoals to be executed based on language instructions by high - level policy composition controller ( PCC ). Then discriminatively control the agent ’s navigation by a master policy by alternating between navigation policy and various independent interaction policies. Finally, infer manipulation actions with the corresponding object masks using the appropriate interaction policy. The proposed method generates a human interpretable and short sequence of actions with an environment and achieves the state - of - the - art performance on the challenging challenging ALFRED benchmark."
SP:e2c8efe00db7baba2368f4f6a37815809b9e235e,"This paper proposes Nuisance - Randomized Distillation ( NURD ) to build predictive models that perform well regardless of the nuisance - label relationship. The authors first define the nuisance-varying family, a set of distributions where the nuisance and the label are independent. Then, the authors introduce a nuisance - randomized distribution, where the label and the nuisance are also independent. Finally, they show that the representations in this distribution are the most informative of the label for chest X - ray classification. The proposed method is evaluated on several tasks where it outperforms baselines."
SP:c75998b76f4e0510fc719d25959a10fc07db1c40,"This paper proposes OTTER ( Optimal TransporT distillation for Efficient zero - shot Recognition ), which uses online entropic optimal transport to find a soft image - text match as labels for contrastive learning. OTTER is based on CLIP, but is data hungry and requires more than 400 M image - texts pairs for training. The inefficiency can be partially attributed to the fact that the image -text pairs are noisy. To address this, OTTER proposes to use InfoNCE loss to train a model to predict the pairing between images and text captions. The experimental results show that OTTER outperforms all baselines in 37 out of 37 different datasets."
SP:e83cd70377542b5d187998e2e4a7ac070f453ed6,"This paper presents Pix2Seq, a framework for object detection that casts object detection as a language modeling task conditioned on the observed pixel inputs. Object descriptions ( e.g. bounding boxes and class labels ) are expressed as sequences of discrete tokens, and a neural net is trained to perceive the image and generate the desired sequence. The approach is based mainly on the intuition that if a neural network knows about where and what the objects are, then we just need to teach it how to read them out. The proposed method achieves competitive results on the challenging COCO dataset, compared to highly specialized and well optimized detection algorithms."
SP:abc9315f61929cc1c54dfef8ff83d7eac56ec2f2,"This paper proposes a method for distilling a CNN policy network into an interpretable symbolic policy via distillation. The method is based on distillation from the CNN policy to a symbolic policy. The symbolic policy is learned by a teacher - student approach, where a policy regression algorithm called RoundTourMix is used to distill the symbolic rules to the policy network. The proposed method is shown to be more interpretable, robust and transferable than the standard CNN - based distillation method."
SP:04e7e181aeb1244ae1c4837ad416aef93ea3ea32,"This paper proposes an unsupervised image - to - image translation model for StyleGAN. The authors propose a joint - training scheme with self - supervision methods for the GANInversion encoder and the generator to better disentangle the pose - identity disentanglement. The VQSN module automatically learns to encode the shaping and composition information from the commonly shared objects inside the training - set images. Moreover, a latent - space reducing feature of the leveraged module is leveraged to reduce the latent space dimensionality of the generated images. The proposed model achieves better synthesis image quality and disentangled scores of scores compared to the baseline StyleGAN model."
SP:e51a7f45493064972585109f203a867e9828eb15,"This paper proposes a new MLP - based transformer - based model for speech processing tasks. The proposed speech - MLP is a multi - layer perceptron ( MLP ) architecture that splits feature channels into non - overlapped chunks and processes each chunk individually. The chunks are then merged together and further processed to consolidate the output. By setting different numbers of chunks and focusing on different contextual window sizes, speech -MLP learns multiscale local temporal dependency.   The proposed model is evaluated on two tasks : keyword spotting and speech enhancement. The results indicate that more complex models, such as transformers, are oftentimes not necessary for speech - processing tasks, and that simpler and more compact models should always be considered as an alternative in resource - constrained scenarios."
SP:d708d3886f4abd4552d8ccb2096df7361c803b13,"This paper studies the problem of knowledge transfer in the context of binary classification problems. The authors provide a novel lower bound on the generalization error that can be achieved by any transfer learning algorithm. The bound depends on a natural notion of distance between source and target data sets and requires minimal assumptions that enables it to be applied to a broad range of problems.   The authors also consider a more general setting where there are more than one source domains for knowledge transfer to the target task and develop new bounds on generalization errors in this setting. Finally, the authors conduct experiments on real image classification and action recognition data sets to corroborate their theoretical findings."
SP:f7511ba9ccad03233b34b1bf41bbac7361d20a57,"This paper proposes a probabilistic shape completion method for large - scale continuous geometry of 3D scenes. The proposed method is based on Generative Cellular Automata ( GCA ) that learns the multi - modal distribution and transform the formulation to process large - magnitude continuous geometry. The local continuous shape is incrementally generated as a sparse voxel embedding, which contains the latent code for each occupied cell. The authors derive that the training objective maximizes the variational lower bound of the complete shape distribution and therefore their progressive generation constitutes a valid generative model. Experiments show that the proposed method successfully generates diverse plausible scenes and outperforms deterministic models even in less ambiguous cases with a small amount of missing data."
SP:d22d8f074adbe8fb0f25fb8f8d96201b3159bf6b,This paper proposes to use behavioral priors as a generalization of state - independent temporal priors for off - policy exploration in deep reinforcement learning. The main idea is to use a probabilistic mixture of policy and temporal prior to accelerate exploration in unseen downstream tasks by dynamically sampling actions from a mixture of policies and priors. The proposed method is evaluated in two settings : ( 1 ) long - horizon continuous control tasks with sparse rewards and ( 2 ) sparse reward environments. The results show that the proposed method outperforms the proposed methods in both settings.
SP:25e06c022ae8b3cbbb8db413d7b534a1a5c92391,This paper proposes a graph - network - based scheduler for learning rate scheduling in stochastic optimization. The proposed method learns a specific scheduling mechanism without restrictions to existing principles by constructing a directed graph for the underlying neural network of the target problem. It encodes current dynamics with a graph message passing network and trains an agent to control the learning rate accordingly via reinforcement learning. Experimental results show that the proposed method can capture the intermediate layer information while being able to generalize to problems of varying scales.
SP:d73cb0471c1770607ad3e4621cfc5f170683dd8e,"This paper tackles the problem of deep object - centric learning from point clouds, which is crucial for high - level relational reasoning and scalable machine intelligence. In particular, the authors propose a framework, SPAIR3D, to factorize a 3D point cloud into a spatial mixture model where each component corresponds to one object. The Chamfer Mixture Loss is used for spatial mixture loss and an object - specification scheme is adopted to describe each object ’s location relative to its local voxel grid cell. The proposed method is evaluated on the task of detecting and segmenting an unknown number of objects from a point cloud in an unsupervised manner. The experimental results demonstrate that the proposed method has strong scalability and is capable of detection and segmentation."
SP:3c57e921c1bf23e482551ceb71702931a7f07439,"This paper studies the problem of using large language models ( LLMs ) for the task of extracting actionable knowledge from an interactive virtual environment. The authors propose a method that conditions on existing demonstrations and semantically translates the plans produced by the pre - trained LLMs to admissible actions. They show that if the number of demonstrations is large enough and the environment is interactive enough, the LMs can effectively decompose high - level tasks into low - level plans without any further training. They also show that plans produced naively by LLMs often cannot map precisely to actions. Finally, they propose a procedure that automatically translates the learned plans to actions based on previous demonstrations and show that the resulting method substantially improves executability over the baseline method."
SP:e0159d1c9df2e657892a3a0c77549df4698d9a1a,"This paper proposes a geometrical interpretation of the variational auto - encoder ( VAE ) framework. In particular, the authors show that VAEs naturally learn a Riemannian structure of the learned latent space and propose a new way to generate samples consisting in sampling from the uniform distribution deriving intrinsically from the Riemmanian manifold learned by a VAE. The proposed method is shown to be robust in the low data regime and significantly improves the generation from the vanilla VAE, which can now compete with more advanced VAE models on four benchmark datasets. Experiments on a complex neuroimaging dataset combining both high dimensional data and low sample sizes validate the method."
SP:b4b8e1727f8617894f10f20365cb68de79f0e650,"This paper proposes Transformer with a Mixture of Gaussian Keys ( Transformer - MGK ), a novel transformer architecture that replaces redundant heads in transformers with a mixture of keys at each head. The key mixtures follow a Gaussian mixture model and allow each attention head to focus on different parts of the input sequence efficiently. Compared to its conventional transformer counterpart, the proposed model accelerates training and inference, has fewer parameters, and requires less FLOPs to compute while achieving comparable or better accuracy across tasks. Empirically, the authors demonstrate the advantage of the proposed method in a range of practical applications including language modeling and tasks that involve very long sequences."
SP:82731dcce233e748f63382e09b6224a513fe9689,"This paper proposes a minimalistic recurrent network ( RPI ) for spatio - temporal navigation in a two - dimensional continuous environment. RPI uses a direct - inverse model of the environment dynamics to fuse image and action - related signals, allowing reconstruction of the action relating the two successive images, as well as prediction of the new image from its current value and the action. The proposed architecture is compared to off - the - shelf LSTM networks on identical tasks, and consistently shows better performance."
SP:1a27c397d1e73def5e724c5c6f25548975ba50fa,"This paper studies the role of input structure in feature learning in the training of deep neural networks. In particular, the authors consider the setting where the input distribution is based on a set of class - relevant patterns and the input is generated from these patterns along with some background patterns. In this setting, they show that neural networks trained by gradient descent can succeed in learning effective features, which are learned among exponentially many candidates efficiently by exploiting the data. In contrast, no linear models on data - independent features of polynomial sizes can learn to as good errors. The authors also show that if the specific input structure is removed, then no no no linear model can learn effective features in this setting. Finally, they provide theoretical evidence showing that feature learning depends strongly on the input structure and leads to the superior performance."
SP:8ada73ed7eade9ebdeef376485e849c42575bc5f,"This paper studies the robustness of feature extractors to adversarial examples generated by test - time adversaries. The authors propose a methodology to analyze the effectiveness of collision finding in finding adversarial perturbations at deeper layers of a linear feature extractor. They provide closed - form expressions for collision finding for linear features extractors and propose a bespoke algorithm to find adversarial collision for arbitrary linear feature extractsors. The bounds are tight, but the tightness is dependent on the success of the collision finding method. They also provide a quantitative comparison of the relative robustness in terms of the number of perturbed layers and number of adversarial points to identify the layers of robustly trained models.  "
SP:874b5fa51924cbcceed490d98a0ea80f74586b32,"This paper proposes a new offline reinforcement learning method based on behavior cloning and value - based episodic memory. The main idea is to learn the V - function instead of the Q - function to naturally keep the learning procedure within the offline dataset. The authors also introduce implicit planning along offline trajectories to enhance learned learned V - values and accelerate convergence. Theoretical analysis for the convergence properties of the proposed VEM method is provided. Empirical results show that the proposed method achieves superior performance in most tasks, particularly in sparse - reward settings."
SP:34f08d92681504490c2f739b0d08f79f9764b2f5,"This paper proposes a weighted adversarial training ( WAT ) method to improve the robustness of neural network classifiers. WAT learns to reweight the loss associated with individual training samples based on a notion of class - conditioned margin, with the goal of improving robust generalization. The authors formulate WAT as a bilevel optimization problem where the upper level task corresponds to learning a robust classifier, and the lower - level task is learning a parametric function. Extensive experiments demonstrate that WAT improves both clean and robust accuracy compared to related techniques and state - of - the - art methods."
SP:3ad36be6b6900aabe43da043461cf178ce977082,"This paper proposes a method for steerable equivariant graph neural networks ( SEGNNs ) that incorporate geometric and physical information in both the message and update functions. The authors define steerable node attributes ( i.e., node and edge attributes that are not restricted to invariant scalars but can contain covariant information, such as vectors or tensors ), and provide a new class of activation functions for general use with steerable feature fields. The proposed method is shown to be effective on several tasks in computational physics and chemistry and the authors provide extensive ablation studies. In addition, the authors discuss the benefits of the method through the lens of equivariance non - linear convolutions, which further allows us to pin - point the successful components of the model."
SP:8928aa83f7ebd4e310f4fe1d01ff0eb0c96e4d2b,"Differentiable physics modeling combines physics models with gradient - based learning to provide model explicability and data efficiency. Current successes have concentrated on general physics models such as rigid bodies, deformable sheets, etc. assuming relatively simple structures and forces. Their granularity is intrinsically coarse and therefore incapable of modelling complex physical phenomena. Fine - grained models are still to be developed to incorporate sophisticated material structures and force interactions. Following this motivation, this paper proposes a new differentiable fabrics model for composite materials such as cloths where we dive into the granularity of yarns and model individual yarn physics and yarn - to - yarn interactions. These forces, albeit applied to cloths, are ubiquitous in various physical systems. Through comprehensive evaluation and comparison, the authors demonstrate the model ’s model’s efficacy in learning meaningful physical parameters, data - efficiency in learning, and high - fidelity in capturing subtle dynamics."
SP:2c8358c095b10981d3015b9f6c75765419a9480d,"This paper studies the problem of transfer learning from a set of base tasks to a new set of tasks, where the goal is to learn a new task so that the agent can quickly generalise over the task distribution. The authors propose a new approach to this problem based on logical composition, which allows the agent to decide whether to learn the new task using its existing abilities or whether a task - specific skill should be learned. In the former case, the proposed algorithm generates an estimate of the optimal policy, which can be used to speed up the agent's learning process. Theoretical results are provided to show that the performance of the transferred policy can be upper bounded by the number of tasks that need to be learned and the necessary and sufficient number of such tasks to generalize over a distribution. Empirical results demonstrate that the proposed approach works well in the setting where an agent receives tasks from an unknown distribution and, starting from zero skills, is able to generalise quickly and efficiently."
SP:c85d71d05164d019cc32bf423e4c4fe20c169f41,"This paper proposes a distributed solution for multivariate time series classification ( MTSC ) based on random convolutional kernels ( ROCKET ). The proposed method, called LightWaveS, employs just 2, 5 % of the features of the original ROCKET model, while achieving accuracy comparable to recent deep learning solutions. It also scales well with more nodes and large numbers of channels. Experiments show that the proposed method can achieve speedup ranging from 9x to 65x compared to ROCKET during inference on an edge device, on datasets with comparable accuracy."
SP:db43614ca016280a79448f44a97c81c8ff5ba981,This paper proposes a new pretraining method for BERT based on a mixture of masked language models ( MLMs ). The main idea is to train multiple MLMs of different sizes to provide training signals at various levels of difficulty to push the discriminator to learn better with challenging replaced tokens. The discriminator is trained as a discriminator by backpropagating the gradient from the auxiliary MLMs using Gumbel - Softmax. The proposed method is evaluated on GLUE and SQuAD benchmarks for base - sized models.
SP:db3825633ab5d0671340390b23ab655838cc38b2,"This paper proposes an adaptive fine - tuning method for extracting relational knowledge from large pre - trained language models by a clozestyle query sentence serving as a query. The proposed method is an extension of the prompt - enhanced language models ( PRM ). PRM queries relational knowledge by a query sentence can be queried similar to knowledge graphs. However, usually large amounts of data in the form of existing knowledge graph facts and large text corpora are needed to train the required additional model. In this work, the authors propose using a completely different approach : Instead of spending resources on training an additional model, they simply perform an adaptive $ \ell_p$-fine - tuning of the pre-trained language model on the standard fill - mask task using a small training dataset of existing facts from a knowledge graph. The authors investigate the differences between adaptive prompt techniques and adaptive fine-tuning in an extensive evaluation. They also analyze the transfer learning capabilities of this adapted language model by training on a restricted set of relations."
SP:ae25d32714b2b9f7e02cc20f4a36252e20e78e4f,"This paper proposes a method for learning multi - relations in the hyperbolic space of the knowledge base embeddings in different geometric spaces. The motivation is that transitivity is a special property that can not be modeled efficiently in the Euclidean space. The authors propose to learn the relation properties in the geometric spaces and apply manifold alignment to align the shared entities. The alignment is achieved by using a transformer encoder and a transformer decoder that takes as input a set of shared entities and outputs the shared relations. The proposed method is evaluated on the OOD entity typing task, where the goal is to predict the types of the entities from the knowledge graph. Experimental results on two datasets demonstrate that the proposed approach has significantly good performances."
SP:9ab3bc525ee4a9c96518c43e4c43082655a7674f," is a one - shot learning framework for link prediction in temporal knowledge graphs. The proposed method employs a self - attention mechanism to effectively encode temporal temporal interactions between entities, and a network to compute a similarity score between a given query and a ( 1 - shot ) example. The experiments show that the proposed algorithm outperforms existing methods on sparse relations."
SP:91f92a40e12afd0702f07ae7f4175ecce57b7007,"This paper proposes a neural network - based model for learning to solve visual reasoning tasks. The main idea is to represent a solver for each task as a neural module that calls existing modules ( solvers for simpler tasks ) in a functional program - like manner. The lower modules are a black box to the calling module, and communicate only via a query and an output. A module for a new task learns to query existing modules and composes their outputs in order to produce its own output. The model effectively combines previous skill - sets, does not suffer from forgetting, and is fully interpretable. The authors test their model in learning a set of visual reasoning task, and demonstrate improved performances in all tasks by learning progressively."
SP:de33b02e7f2faec5bcae9a5516721aa1ef190572,"This paper proposes a method for improving parameter efficiency of deep convolutional neural networks with identity - preserving bottlenecks. The key idea is to introduce a channel - selectivity mechanism into the convolution layer of the neural network to allow it to select important convolution channels. The proposed method, called SCU ( Selective Convolutional Unit ), is a widely - used architectural unit in modern CNNs. SCU gradually learns channel - selectiveivity on - the - fly via the alternative usage of ( a ) pruning unimportant channels, ( b ) rewiring the pruned parameters to important channels, and ( c ) re - weighting the parameters corresponding to important kernels. The experimental results demonstrate that the proposed SCU is effective in improving the efficiency of several modern CNN architectures."
SP:2d80fa4bc440061be2234b5070503d3fa056baed," for binary classifier only from positive data and unlabeled data ( PU learning ). When the data has selection bias, it is difficult to learn the Bayes optimal classifier by conventional methods of PU learning. In this paper, the authors propose a method to partially identify the classifier. The proposed algorithm learns a scoring function that preserves the order induced by the class posterior under mild assumptions, which can be used as a classifier, by setting an appropriate threshold. Experiments show that the method outperforms previous methods for PU learning on various real - world datasets."
SP:5f312626b0613d2e07c59214c5f00db208a98717,"This paper proposes a method for detecting when an auxiliary loss is helpful and when it is not. The proposed method uses cosine similarity between gradients of tasks as an adaptive weight to detect if an auxiliary task is helpful to the main loss. The authors show that their approach is guaranteed to converge to critical points of the main task and demonstrate the practical usefulness of the proposed algorithm in a few domains : multi - task supervised learning on subsets of ImageNet, gridworld, and reinforcement learning on Atari games."
SP:e270ae3eeb7ab4fa91ba37d4d68ce10f2fa0a3b5,"This paper proposes a geometric framework to analyze the high - dimensional geometry of adversarial examples in the manifold reconstruction literature. The main idea is that for low - dimensional data manifolds embedded in high dimensional space, there are many directions off the manifold in which to construct adversarial example. The proposed geometric framework shows that adversarial training in balls around the data is sample inefficient, and that under the assumption that the data lies in a high dimensional manifold, there is a tradeoff between robustness under different norms and sample efficiency. The paper also shows that under certain assumptions on the data and on the training distribution, the training of a decision boundary is more sample efficient than the testing distribution."
SP:e07d948a79d478ecd23a0a4406d4ddd3ac5e3be3,"This paper proposes a gradient - based self - organizing map algorithm for learning interpretable representations of high - dimensional time - series data. The proposed method is motivated by the idea of discrete dimensionality reduction and deep generative modeling to learn smooth and interpretable embeddings with superior clustering performance. The authors introduce a new way to overcome the non - differentiability in discrete representation learning by integrating a Markov model in the representation space. They evaluate the proposed method on clustering and interpretability on static ( Fashion - MNIST ) time series data, a chaotic Lorenz attractor system with two macro states, as well as on a challenging real world medical time series application on the eICU data set."
SP:5915ee71ea58dbdbafa31c1ad291d1e5940a0cf4,"This paper investigates the properties of multidimensional probability distributions in the context of latent space prior distributions of implicit generative models. The authors show that distribution mismatch can be eliminated completely by the proper choice of the latent probability distribution or using non - linear interpolations. In particular, they prove that there is a trade - off between the interpolation being linear, and the latent distribution having even the most basic properties required for stable training, such as finite mean mean and variance. They also provide a general method of creating non -linear interpolations, that is easily applicable to a large family of commonly used latent distributions."
SP:19b63ca635712f1509ca6e0141303c192f2709e0,"This paper proposes to learn the parameters of shallow neural networks in hyperbolic embeddings for attention mechanisms. The main idea is to impose a hyperbolically invariant geometry on the embedding space of the attention mechanism. This is achieved by only changing the geometry of embedding embedding of object representations, and not the geometry itself. The proposed method is evaluated on machine translation ( WMT14 ), graph learning ( both on synthetic and real - world graph tasks ), and visual question answering ( CLEVR ) tasks while keeping the neural representations."
SP:f6049e9f80a63c9306c1cebcb6b229aa6da44ddc,"This paper presents an empirical security analysis of DNN fingerprinting attacks that exploit cache side - channel attacks. The authors define the threat model for these attacks : our adversary does not need the ability to query the victim model ; instead, she runs a co - located process on the host machine where the victim ’s deep learning ( DL ) system is running and passively monitors the accesses of the target functions in the shared framework. They propose two attack methods : DeepRecon, which reconstructs the architecture of the victim network using the internal information extracted via Flush+Reload, and DeepFool, which extracts the extracted internal information using Flush + Reload. Based on the extracted architecture attributes, they also demonstrate that an attacker can build a meta - model that accurately fingerprints the architecture and family of the pretrained model in a transfer learning setting. Finally, they propose and evaluate new framework - level defense techniques that obfuscate our attacker’s observations."
SP:6a3dd89db6c24a1f98e8866ef0a4c1c2c1ec6635,"This paper proposes a hierarchical network model, called Hierarchical Prediction Network ( HPNet ), to understand how spatiotemporal memories might be learned and encoded in a representational hierarchy for predicting future video frames. The model is inspired by the feedforward, feedback and lateral recurrent circuits in the mammalian hierarchical visual system. The feedforward path computes and encodes spatio - temporal features of successive complexity and a feedback path projects interpretation from a higher level to the level below. Within each level, the feed - forward path and the feedback path intersect in a recurrent gated circuit that integrates signals as well as the circuit ’s internal memory states to generate a prediction of the incoming signals, updating its internal model of the world by minimizing the prediction errors at each level of the hierarchy in the style of predictive self - supervised learning. This allows it to learn relationships among movement patterns, yielding state - of - the - art performance in long range video sequence predictions in benchmark datasets. The authors also observed that hierarchical interaction in the network introduces sensitivity to memories of global movement patterns even in the population representation of the units in the earliest level. Finally, neurophysiological evidence, showing that neurons in the early visual cortex of awake monkeys exhibit very similar sensitivity and behaviors, shows that predicting future frames from video frames is an important principle for representational learning in the visual cortex."
SP:fb74e57f35666742caf651e6da33b5defcf259a8,This paper proposes a method to compute continuous embeddings for RNA - seq data in a reference - free fashion. The proposed method is based on learning a latent representation space of the raw data. The latent space is used to compute a continuous embedding vector for each sample. The authors show that their model captures information of both DNA sequence similarity as well as DNA sequence abundance in the embedding latent space. They confirm the quality of these vectors by comparing them to known gene sub - structures and report that the latent space recovers exon information from raw RNA -Seq data from acute myeloid leukemia patients. They also show that this latent space allows the detection of genomic abnormalities such as translocations and patient - specific mutations.
SP:03aca6ff6a7f0ad2d5ccbcb15ed9536e305a9880,This paper proposes a new method for model compression based on the architecture space. The main idea is to first encode the network and then perform gradient descent in continuous space to optimize a compression objective function that maximizes accuracy and minimizes parameter count. A 1 - D CNN encoder / decoder is jointly trained to learn a mapping from discrete architecture space to a continuous embedding and back. The final continuous feature is then mapped to a discrete architecture using the decoder. Experiments are conducted on CIFAR-10/100 and VOC.
SP:0511b5d10a90e3fe814e2d35208b4a987894ea62,"This paper proposes a new framework for online planning and offline exploration that combines local model - based control, global value function learning, and trajectory optimization. The main idea is to use trajectory optimization to estimate uncertainty in value function approximation in conjunction with value function estimation in order to accelerate and stabilize the learning of global value functions. The authors show that trajectory optimization can be used to reduce the planning horizon and allow for better policies beyond local solutions. The proposed framework is applied to complex control tasks, like humanoid locomotion and dexterous in - hand manipulation."
SP:771494fda4702cd8c7efbf225b19028f91b449b9,"This paper proposes an unsupervised zero - shot and dual learning approach for neural machine translation ( NMT ) systems. The former is based on reinforcement learning, to exploit the duality of the machine translation task, and requires only monolingual data for the target language pair. The latter is trained on English - French and English - Spanish ( both directions ). The proposed method is evaluated on the UN corpus and on the newstest2014 dataset. The results show that the proposed method outperforms both the LSTM - based and the Transformers - based unsuper supervised NMT systems."
SP:1558dc03f99670f9ddccdca9c223a2baf962d438,"This paper criticizes the IRGAN framework for information retrieval ( IR ), a generative adversarial network ( GAN ) formulation for the problem of extracting the correct conditional probability distribution p(d|q ) over the documents given the query ( q ). The authors point out that the setup of IRGAN is not suitable for the exact adversarial setting, and propose a new setup where two models are trained in a co - operative rather than adversarial manner. The proposed IRGAN model is shown to outperform the state - of - the - art GAN model in a number of experiments. The paper also provides an analysis of the loss functions of the two models."
SP:6a13dda852ab075a3c0fb691476d6dc57919c729,"This paper proposes a Spike and Slab prior distribution for sparse variational auto - encoders ( VAEs ) to model sparsity in the latent space of a VAE. Sparsity is modeled using a discrete mixture recognition function, which is computationally efficient as in the standard VAE case. The authors also derive the evidence lower bound using a Hessian decomposition of the prior distribution. Experiments on two benchmark classification tasks ( MNIST and Fashion - MNIST ) show that the proposed method improves classification accuracy and robustness to the number of latent dimensions."
SP:06a22143186fa2948fbe324ccae96a62ff12064e,"This paper proposes a non - adversarial feature matching - based approach to train generative models. The proposed approach, Generative Feature Matching Networks ( GFMN ), leverages pretrained neural networks such as autoencoders and ConvNet classifiers to perform feature extraction. The experimental results demonstrate that, due to the expressiveness of the features from pretrained ImageNet classifier, even by just matching first order statistics, GFMN can achieve state - of - the - art results for challenging benchmarks such as CIFAR10 and STL10."
SP:2d7cf2f07a27d6c8e304a1b47c25387ad2e4432d,"Graph Neural Networks ( GNNs ) have revolutionized graph representation learning, but there is limited understanding of their representational properties and limitations. This paper presents a theoretical framework for analyzing the expressive power of GNN to capture different graph structures. The results characterize the discriminative power of popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, and show that they can not learn to distinguish certain simple graph structures, and then develop a simple architecture that is as powerful as the WeisfeLehman graph isomorph test. Empirically validate the theoretical findings on a number of graph classification benchmarks and demonstrate that the model achieves state - of - the - art performance."
SP:51126f2dd37ce57d2614c9044ede1e43627f0829,This paper proposes a framework for interpretable continual learning ( ICL ) based on the variational continual learning framework. The main idea is to generate saliency maps for previously performed tasks and use them to improve performance on the next task. The saliency map is generated by a model that is trained on a set of tasks. The paper also proposes a metric to evaluate the quality of the explanations generated by the model. The effectiveness of the proposed method is evaluated on a variety of continual learning tasks.
SP:27a565b3e5442b93d208652784051e640b0c1bfe,"This paper proposes a new evaluation framework for adversarial attacks on neural sequence - to - sequence ( seq2seq ) models taking meaning preservation into account. Specifically, the authors propose a new constraint for attacks on word - based machine translation ( MT ) systems and show, via human and automatic evaluation, that they produce more semantically similar adversarial inputs. Furthermore, they show that performing adversarial training with adversarial robustness is beneficial to the model in terms of robustness to the adversarial examples. The paper is well organized and easy to follow."
SP:54ddd8132bf9e4259d2c2d72b348d2bb5f9e227c,"This paper proposes a hybrid policy that combines the policies using original rewards and inverse ( negative ) rewards. The hybrid policy is based on deep Q - learning, double - Q learning, and on - policy actor - critic. The paper shows that the hybrid policy can obtain rewards up to 63.8 % higher than the original policies in some OpenAI gym games.   The paper also shows that inverse rewards are competitive with the original reward and help the original policy correct its mis - actions. The convergence of inverse policies is proved."
SP:89a732b57934d08b937c93560f391b7758e54f8a,"This paper proposes a method for learning a hierarchical disentangled object representation and a dynamics model for object parts from unlabeled videos. The object representation learns to recognize the object parts via a layered image representation, predict hierarchy via a structural descriptor that composes low - level concepts into a hierarchical structure, and model the system dynamics by predicting the future. The dynamics model predicts how each object part will move in the future by observing how they move. The method is evaluated on three tasks : segmenting object parts, building their hierarchical structure and capturing their motion distributions. Experiments on multiple real and synthetic datasets demonstrate the effectiveness of the method."
SP:bb2a655d67bed9da43f0b8ec7d888b89c217d12e,"This paper proposes Deep Determinantal Generative Classifier ( DDGC ), a novel inference method that can obtain a more robust decision boundary under any softmax neural classifier pre - trained on noisy datasets. The main idea of DDGC is inducing a generative classifier on top of hidden feature spaces of the discriminative deep model. By estimating the parameters using the minimum covariance determinant estimator, DDGC can significantly improve the classification accuracy without re - training of the deep model nor changing its architectures. In particular, the authors show that DDGC not only generalizes well from noisy labels, but also is robust against adversarial samples."
SP:0fa525cc708470b757a60117cb608bb2feaa2c50,"This paper proposes a model - free method for Hierarchical Reinforcement Learning ( HRL ) that learns subgoals and skills together, based on experiences in the environment. The proposed method is based on the idea of intrinsic motivation, which is used to identify subgoal states and learn the corresponding skill policies to achieve them. The authors demonstrate the efficiency of their method on two RL problems with sparse delayed feedback : a variant of the rooms environment and the ATARI 2600 game called Montezuma ’s Revenge."
SP:e5861538bc8bb9165cb33299bbf12dd875abf976,"This paper proposes a neural framework for solving the SAT problem. The proposed method is based on a rich embedding architecture that encodes the problem structure, and an end - to - end differentiable training procedure that mimics Reinforcement Learning. The experimental results show the superior out - of - sample generalization performance of the proposed method compared to the recently developed NeuroSAT method."
SP:ff3e5d44619df3825632b0b1a943add081364861,"This paper proposes a combination of two popular deep RL algorithms, deep neuroevolution and deep reinforcement learning ( deep RL ), to get the best of both worlds : deep RL and off - policy deep RL. Two previously existing combinations use either an ad hoc evolutionary algorithm or a goal exploration process together with the Deep Deterministic Policy Gradient ( DDPG ) algorithm. In this paper, the authors propose a different combination scheme using the simple cross - entropy method ( CEM ) and twin - delayed deep RL algorithm, which improves over the existing combination methods. They evaluate the resulting method, CEM - RL, on a set of benchmarks classically used in deep RL, and show that it offers a satisfactory trade - off between performance and sample efficiency."
SP:78b2eb326695da0b0cc4ba39a9206d11644a5e32,"This paper proposes a multi - variable LSTM recurrent neural network for both forecasting and knowledge extraction. The proposed model is equipped with hidden state matrix and update process, so as to learn variableswise hidden states, and a mixture attention mechanism and associated summarization methods to quantify the temporal and variable importance in data. Extensive experiments on real datasets demonstrate the performance and interpretability of the proposed model."
SP:1c26660569b579f060f7b4a31e321c6d2356b928,"This paper proposes a data augmentation method for defense against adversarial attacks. The proposed method trains a neural network on virtual training data as an interpolation of features from a pair of samples, with the new label remaining the same as the dominant data point. The intuition behind feature smoothing is to generate virtual data points as close as adversarial examples, and to avoid the computational burden of generating data during training. The experiments on MNIST and CIFAR-10 datasets explore different combinations of known regularization methods and show that the proposed method performs best for both adversarial and clean accuracy."
SP:88d652f9e411dd3a2e9ad651d9011e579653c6aa,"This paper proposes a theoretical framework for deep locally - connected neural networks ( DCNNs ) with ReLU nonlinearity that bridges data distribution with gradient descent rules, favors disentangled representations and is compatible with common regularization techniques such as Batch Norm. The framework is built upon teacher - student setting, by projecting the student ’s forward / backward pass onto the teacher’s computational graph. The proposed framework could help facilitate theoretical analysis of many practical issues, e.g., disentangling representations in deep networks."
SP:7842bbe0e2324cfd732db8745550733ccc3dfcdc,"This paper proposes a modular architecture of neural networks with a Behavioral Module ( BM ) and corresponding end - to - end training strategy to learn behaviors and preferences representation. The proposed method is particularly useful for user modeling ( as for dialog agents and recommendation tasks ) and allows learning personalized representations of different user states. In the experiment with video games playing, the results show that the proposed method allows separation of main task ’s objectives and behaviors between different Behavioral Modules. The experiments also show network extendability through independent learning of new behavior patterns. Moreover, the authors demonstrate a strategy for an efficient transfer of newly learned BMs to unseen tasks."
SP:300c391ff644b6889cd9ae27cf0d162dfcdd4451,"This paper proposes a differentiable formulation for neuromodulation of plasticity that allows for training neural networks with neuromiodulated plasticity. The formulation is based on Hebbian plasticity and is shown to be differentiable. It is shown that the neuromiodied plasticity of a neural network is not passive, but is actively controlled by neuromiadulation, which is itself under the control of the brain. Experiments are performed on a benchmark task for reinforcement learning and supervised learning tasks. The results show that the proposed formulation improves the performance of the neural networks on both supervised learning and reinforcement learning tasks, and that the formulation can be used to train artificial neural networks."
SP:1ab5d94d31e99351433436c026799c8aa597bf73,"This paper proposes a non - intrusive quantization technique to reduce the inference latency / memory consumption of deep neural networks. The proposed method is based on re - training the full precision model, followed by directly optimizing the corresponding binary model. The quantization training process takes no longer than the original training process. The authors also propose a new loss function to regularize the weights, resulting in reduced quantization error. Combining both help us achieve full precision accuracy on CIFAR dataset using binary quantization and achieve full accuracy on WikiText-2 using 2 bit quantization. Comparable results are also shown for ImageNet."
SP:0876b1d9a6d664808ca1ab15865679fbf638267e,"This paper proposes STOC, for Style Transfer onto Open - Ended Content ( STOC ), a method for open - ended content decomposition and recombination. The method is general purpose and can be applied to any domain, while STOC has an explicit loss, leakage filtering, designed to isolate content and style from the content representation of an image from that image's style representation, and vice versa. STOC is evaluated on few - shot learning tasks for image synthesis and data - set augmentation, and achieves state - of - the - art performance on the VGG - Face dataset."
SP:d37e15cde7765fca87595a242f0a4511b3346d46,"This paper proposes a new method to speed up deep reinforcement learning ( deep RL ) training for problems that have the property of state - action permissibility ( SAP ). Two types of SAP are defined under SAP. The first type says that after an action at is performed in a state and the agent reaches the new state st+1, the agent can decide whether the action is permissible or not permissible in state st. The second type says even without performing the action at in state _ st_, an agent can already decide whether at is permitted or not in st _ st. An action is not permitted to be tried if it can not lead to an optimal solution and thus should not be tried. The proposed method combines the proposed SAP property into two state - of - the - art deep RL algorithms to guide the agent's state exploration."
SP:20015d8b60e13300586b67c281858cbe28825c48,"This paper studies the behavior of weight - tied multilayer vanilla autoencoders under the assumption of random weights. Via an exact characterization in the limit of large dimensions, their analysis reveals interesting phase transition phenomena when the depth becomes large. This, in particular, provides quantitative answers and insights to three questions that were yet fully understood in the literature. Firstly, they provide a precise answer on how the random deep weight - tied autoencoder model performs “ approximate inference ” as posed by Scellier et al. ( 2018 ) and its connection to reversibility. Secondly, they show that deep autoen coders display a higher degree of sensitivity to perturbations in the parameters, distinct from the shallow counterparts. Thirdly, they obtain insights on pitfalls in training initialization practice."
SP:91764f80dbe2401ade38b35a8253ba05f0f86386,This paper proposes a new adversarial image construction method based on discrete cosine transform ( DCT ) for black - box adversarial attacks. The key idea is to randomly pick a low frequency component of the DCT and either add or subtract it to the target image. The proposed method can be used for both targeted and untargeted attacks. Experiments show that the proposed method is fast and can be implemented in less than 20 lines of PyTorch code to produce adversarial images.
SP:fc20ae0fbf57a1ce489c04b85c7c2f4c93dc2450,"This paper proposes a new method for option discovery in reinforcement learning that leverages the Successor Representations framework. The method is motivated by the idea of “ landmark sub - goal states ”, which are prototypical states of well - connected regions that are easily accessible from a densely - connected set of states. The authors propose a new model called Successor options, which iteratively builds options and explores in environments where exploration through primitive actions is inadequate to form the successor representations. They also design a novel pseudo - pseudo - policy for learning the intra - option policies. Finally, they demonstrate the efficacy of their approach on a collection of grid worlds and on complex high dimensional environments like Deepmind - Lab."
SP:12a172c1e2892d016b37932acfc48dcb56874a89,"This paper studies the problem of domain division, which aims to segment instances drawn from different probabilistic distributions. The problem exists in many previous recognition tasks, such as Open Set Learning ( OSL ) and Generalized Zero - Shot Learning ( G - ZSL ), where the testing instances come from either seen or unseen / novel classes with different probablity distributions. Previous works only calibrate the confident prediction of classifiers of seen classes or taking unseen classes as outliers. In contrast, this paper proposes to directly estimate and fine - tune the boundary between seen and unseen classes. In particular, the authors propose a domain division algorithm to split testing instances into known, unknown and uncertain domains, and then conduct recognition tasks in each domain. Extensive experiments demonstrate that the proposed method achieves the state - of - the - art performance on OSL and G - GZSL benchmarks."
SP:28bcf7c6a4673e9ec2b4ebed09839d85188e0b2a,"This paper proposes a neural network for classification and regression that explicitly states the layout, i.e., the layout of the output, of the network. The structure is defined by polar prototypes. For classification, each class is described by a single polar prototype and they are a priori distributed with maximal separation and equal shares on the hypersphere. For regression, they show that training can be performed as a polar interpolation between two prototypes, arriving at a regression with higher - dimensional outputs. From empirical analysis, they find that polar prototype networks benefit from large margin separation and semantic class structure, while only requiring a minimal amount of output dimensions. Moreover, they gain the ability to perform regression and classification jointly in the same space, which is disentangled and interpretable by design."
SP:d1034342785d133cf8372b8624897963cc2ee83a,"This paper studies the problem of reinforcement learning ( RL ) from the point of view of implicit preference learning. The key insight is that when a robot is deployed in an environment that humans act in, the state of the environment is already optimized for what humans want, and we can use this implicit preference information from the state to fill in the blanks. The authors develop an algorithm based on Maximum Causal Entropy IRL and use it to evaluate the idea in a suite of proof - of - concept environments designed to show its properties. They find that the initial state can be used to infer both side effects that should be avoided as well as preferences for how the environment should be organized."
SP:417a4e0acee699b3e004ad30d0ecf533a9ed987e,"This paper proposes a method for learning the dependency structure between latent variables in deep latent variable models. The proposed method combines the complementary strengths of deep generative models and probabilistic graphical models. In particular, the authors express the latent variable space of a VAE in terms of a Bayesian network with a learned, flexible dependency structure. The network parameters, variational parameters as well as the latent topology are optimized simultaneously with a single objective. Inference is formulated via a sampling procedure that produces expectations over latent variable structures and incorporates top - down and bottom - up reasoning. The authors validate their framework in extensive experiments on MNIST, Omniglot, and CIFAR-10."
SP:976dedab53e69610692a563382ada1dbb82c1e9d,"This paper proposes a top - down feedback and contrastive learning method to construct a dynamical network for solving the $ \ell_1 $-minimizing dictionary learning problem. The proposed method is based on the dynamical neural network ( DNN ), which consists of a set of neurons that interact over time in a continuous time - varying state space. The authors show that the state evolution and limit points in the associated state space can correspond to numerical solutions to certain mathematical optimization or learning problems. The main contribution of this work is to derive the true gradients of the learning process, its rigorous mathematical analysis, and numerical results on several dictionary learning problems using the proposed method."
SP:f45117a6beaeb86a70b1380b4fac3cfba37fb892,This paper proposes an encoder - decoder network for the task of semantic image segmentation and lane detection. The proposed network is based on a convolutional neural network ( CNN ) with a spatial pyramid structure and uses multiple encoders and decoders for both high - level and low - level features representations. The main contribution of this paper is the use of multiple encoder and decoder modules in the CNN for the purpose of the task. The experiments show the effectiveness of the proposed method. The paper also provides an analysis of different configurations of CNNs for different end - to - end ways.
SP:68b0a10ca06df74612d0753cc3f3ddddde806035,"This paper studies the problem of contextual bandit learning, where one only has access to a collection of logged feedback from the actions taken by a historical policy and one expects to learn a policy that takes good actions in possibly unseen contexts. The proposed approach is based on inverse propensity weights and is called Maximum Likelihood Inverse Propensity Scoring ( MLIPS ). The authors prove that MLIPS is asymptotically unbiased, and moreover, has a smaller nonasymptotic mean squared error than IPS. Results on multi - label classification problems and a large - scale ad placement dataset demonstrate the empirical effectiveness of MLIPS."
SP:8e0ed65c5dded23b34798499b2436b24422fd729,"This paper proposes a meta - learning method for few - shot image classification. The key idea is to learn how to create an individualized feature embedding specific to a given query image for better classifying, i.e., given a query image, learn to create a kernel embedding tailored for its characteristics, leading to an individualised feature space in which the query image can be more accurately classified. The kernel generator is used to learn the meta - knowledge of generating adequate convolutional kernels for different query images during training, which generalizes to generalize to unseen categories without fine - tuning. The proposed method is evaluated on three benchmark datasets ( CIFAR-10, ImageNet-100, MiniImageNet ) and compared with two other meta learning methods ( MAML and mini - ImageNet ). The results show that the proposed method outperforms the other two methods."
SP:faa3f7ffdcfb6e3b8ec0421193dae3d9987b015c,"This paper proposes a non - gradient - based evolutionary algorithm for training deep neural networks ( DNNs ). The proposed method, Deep Genetic Algorithm ( GA ), evolves the weights of a DNN with a population - based genetic algorithm and it is shown to work well on hard deep RL problems, including Atari and humanoid locomotion. The GA is faster than ES, A3C, and DQN ( it can train Atari in ∼4 hours on one workstation or ∼1 hour distributed on 720 cores ), and it enables a state - of - the - art, up to 10,000 - fold compact compact encoding technique. The authors demonstrate the latter by showing that combining DNNS with novelty search, which encourages exploration on tasks with deceptive or sparse reward functions, can solve a high - dimensional problem on which reward - maximizing algorithms ( e.g., backprop, ES, and the GA ) fail."
SP:dfdbe3267a8160f24746884cdf5297993e424231,"This paper proposes a new curiosity - based reward mechanism for reinforcement learning agents. The novelty bonus is derived from the combined reward of the agent ’s reward and the task reward, which is the sum of the reward from the agent and the rewards from the task. This is motivated by the fact that rewards are sparse in the real world and most RL algorithms struggle with this sparsity. To address this problem, this paper proposes to use episodic memory to form the novelty bonus. To determine the bonus, the current observation is compared with the observations in memory. The comparison is done based on how many environment steps it takes to reach the observation from those in memory — which incorporates rich information about environment dynamics. This allows the agent to overcome the known “ known ” “ exploitation ” problem — when the agent finds a way to instantly gratify itself by exploiting actions which lead to hardly predictable consequences. The agent outperforms the state - of - the - art curiosity method ICM in the VizDoom and DMLab environments."
SP:1e58a1c5344d1b5b7c8a40210a243700bd933d65,This paper proposes a relational transition model for describing transition models in complex uncertain domains using relational rules. The main idea is to use an iterative greedy algorithm to construct a set of deictic references that determine which objects are relevant in any given state. Feed - forward neural networks are used to learn the transition distribution on the relevant objects ’ properties. This strategy is demonstrated to be both more versatile and more sample efficient than learning a monolithic transition model in a simulated domain in which a robot pushes stacks of objects on a cluttered table.
SP:8ce00a3fedbf54a7f2c1ff414511cbb7d59b4597,"This paper proposes a new instance - wise feature selection method, which they call InvASE. The method consists of 3 neural networks, a selector network, a predictor network, and a baseline network, which are used to train the selector network using the actor - critic methodology. The selector network is capable of flexibly discovering feature subsets of a different size for each instance, which is a key limitation of existing state - of - the - art methods. They demonstrate through a mixture of synthetic and real data experiments that the proposed method significantly outperforms the existing methods."
SP:b91d6c33349df0bb6cb7e1c5e9433f0d4744b4da,"This paper proposes a domain adaptation method to adapt the source data to the unlabeled target domain. To this end, the authors propose to learn discriminative feature representations of patches based on label histograms in the source domain, through the construction of a disentangled space. With such representations as guidance, they then use an adversarial learning scheme to push the feature representations in target patches to the closer distributions in source ones. In addition, they show that their framework can integrate a global alignment process with the proposed patch - level alignment and achieve state - of - the - art performance on semantic segmentation."
SP:00922af13a21464cbc4cd7b34c196dd4f86c9247,"This paper proposes two optimistic online learning algorithms for AMSGrad and Adam by exploiting the predictability of gradients. The first algorithm is based on the observation that mini - batches of stochastic gradients in consecutive iterations do not change drastically and consequently may be predictable. The second algorithm combines the idea of momentum method, adaptive gradient method, and algorithms in OPTIMISTIC ONLINE LEARNING to speed up training deep neural nets in practice."
SP:52228b48f2776d57dd422edb33b82e247f056b75,"This paper proposes two benchmarks for image classifier robustness. The first benchmark IMAGENET - C standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety - critical applications. The second one is a new dataset called IMAGenet - P that enables researchers to benchmark a classifier ’s robustness to common perturbations. Both benchmarks evaluate performance on common corruptions and perturbation not worst - case adversarial perturbings. The authors also find that there are negligible changes in relative corruption and adversarial robustness from AlexNet - based classifiers to ResNet classifiers. However, they discover that a bypassed adversarial defense provides substantial common robustness for adversarially perturbed images."
SP:20358ea0f769e6ea9222d8e35159d711ee1b20b2,"This paper shows that dropout training can be understood as performing MAP estimation concurrently for an entire family of conditional models whose objectives are themselves lower bounded by the usual dropout objective. This discovery allows us to pick any model from this family after training, which leads to a substantial improvement on regularisation - heavy language modelling. The deterministic subvariant ’s bound is equal to its objective, and the highest amongst these models. It also exhibits the best model fit in our experiments. Together, these results suggest that the predominant view of deterministic dropout as a good approximation to MC averaging is misleading."
SP:ac1b950ad29429ae045bb5e53279014a6a0b9d2b,"This paper proposes a global soft filter pruning ( GSFP ) scheme to prune redundant filters of convolutional neural networks ( CNNs ). Specifically, the GSFP adopts a robust pruning method, which measures the global redundancy of the filter in the whole model by using the soft pruning strategy. In addition, in the model recovery process after pruning, the cumulative saliency strategy is used to improve the accuracy of pruning. Experiments show that GSFP is effective on many CNN architectures and different data sets."
SP:621e41d4199e333ec7f9d0936d4e34c918f39c11,"This paper proposes a cross - lingual document classification framework ( CACO ) to transfer knowledge between related language pairs for text classification. The main idea is to jointly train a character - based embedder and a word - based classifier. The embedder derives vector representations for input words from their written forms, and the classifier makes predictions based on the word vectors. Joint character representation for both the source language and the target language allows the embedder to generalize knowledge about source language words to target language words with similar forms. The authors also propose a multi - task objective that can further improve the model if additional cross - linguistic or monolingual word embedding models are available."
SP:544e421f9c747640d949f433e3091763508b7237,"This paper proposes a new method for temporal action localization based on marginalized average attention ( MAAN ). The MAAN employs a novel marginalized average aggregation ( MAA ) module and learns a set of latent discriminative probabilities in an end - to - end fashion. The MAA samples multiple subsets from the video snippet features and takes the expectation over all the averaged subset features. Theoretically, the MAA module is shown to reduce the difference in responses between the most salient regions and the others. Extensive experiments on two large - scale video datasets show that the proposed MAAN achieves a superior performance."
SP:9f98c9bac99003741dd14e093b54d692c0b0e8d8,"This paper proposes a new model for natural language processing ( NLP ) based on the framework of Holographic Reduced Representation ( HRR ). HRR is used to reduce the number of nodes in word - level and chunk - level representations in natural language models. The authors propose two variants of their HRR - based language models, one with a word embedding and the other with a chunk embedding. The proposed models are evaluated on a corpus of natural language datasets and compared with a number of state - of - the - art NLP models."
SP:5908b6acfed0e7c51e203c72eba907e6635e6c60,"This paper proposes a novel point - based value iteration algorithm for POMDPs with active perception and planning. Specifically, the authors propose a greedy strategy for observation selection that aims to minimize the uncertainty in state - action space. They develop a novel Point - based Value Iteration algorithm that incorporates the greedy strategy to achieve near - optimal uncertainty reduction for sampled belief points. They demonstrate the proposed algorithm and demonstrate its performance and computational advantage in a range of robotic scenarios where the robot simultaneously performs active perception / planning and observation selection."
SP:0adec4abec17b3aab0c6eb69d11925dc20544950,"This paper proposes an adaptive representation loss for deep neural networks to reduce the distribution shift in training. The adaptive weight assigns small values to hard examples, reducing the influence of noisy gradients. On the other hand, the less - weighted hard sample receives the proposed representation loss. The low - weightsed data gets nearly no training signal and can get stuck in embedding space for a long time, so the proposed loss aims to encourage their training by letting them learn a better representation from its superior neighbours but not participate in learning of top layers. Experiments show that curriculum learning needs random sampling between tasks for better training and the proposed method is easy to combine with existing stochastic algorithms like SGD."
SP:8b555b9f24044bc68c204169d6a37e262361d706,"This paper proposes a new heuristic for learning heuristics for combinatorial optimization problems. The proposed heuristic is based on attention layers with benefits over the Pointer Network, and the authors show how to train this model using REINFORCE with a simple baseline based on a deterministic greedy rollout, which is more efficient than using a value function. The experimental results show that the proposed model significantly improves over recent learned heuristic for the Travelling Salesman Problem ( TSP ) and two variants of the Vehicle Routing Problem ( VRP ) and the Orienteering Problem ( OP ), outperforming a wide range of baselines and getting results close to optimal results."
SP:efb76bcf1dbd9a9cf6b5db74b5d4256a9f9e9e73,This paper proposes a differentiable neural architecture search ( DNAS ) framework to efficiently explore the exponential search space with gradient - based optimization. The proposed DNAS is based on the idea of quantizing different layers with different bit - widths. Experiments on CIFAR-10 and ImageNet show that the proposed method can achieve the state - of - the - art compression of ResNet on small model sizes.
SP:ea4173f8265bc50296de51c4ee7ecb6b8f78bec0,"This paper proposes a new attention model that modifies the attention network in a two - stage fashion. The first stage models the attention distribution from the input to the next stage as a prior distribution conditioned on the output, and the second stage modulates the output distribution to the attention. The proposed posterior attention model is shown to have better BLEU score and alignment accuracy than existing attention models. The paper is well organized and easy to follow."
SP:987e2c14abc091d4d3ef9b48fb2046408eb1f59e,"This paper proposes a new method for image - to - image translation from source to target using CycleGAN. The proposed method, called HarmonicGAN, aims to learn bi - directional translations between the source and the target domains by introducing a smoothness term over the sample graph to attain harmonic functions to enforce consistent mappings during the translation. The method is evaluated on a number of applications including medical imaging, object transfiguration, semantic labeling, and for a medical imaging task in particular. It turns CycleGAN from a failure to a success, halving the mean - squared error and generating images that radiologists prefer over competing methods in 95 % of cases."
SP:885a69003bad0e79cb2872a4e5c772191ad7e34f,"This paper studies the exploding and vanishing gradient problem ( EVGP ) in recurrent neural networks ( LSTMs ). The authors propose a stochastic algorithm ( h - Detach ) that is specific to LSTM optimization and targeted towards addressing this problem. Specifically, they show that when the weights of the neural network are large, the gradient components through the linear path ( cell state ) in the computational graph get suppressed. Based on the hypothesis that these components carry information about long term dependencies ( which the authors show empirically ), their suppression can prevent the neural networks from capturing them.   The authors show significant improvements over vanilla L STM gradient based training in terms of convergence speed, robustness to seed and learning rate, and generalization using our modification of LST M gradient on various benchmark datasets."
SP:9aaff3777321347d1194884af5690b0b5185eff9,"This paper proposes a Bayesian approach to training real binary weight networks from scratch by approximating the posterior distribution of binary weights. The posterior distribution is parameterized as a policy network trained with a reinforcement learning scheme. During the training phase, the authors generate binary weights on the fly since what they actually maintain is the policy network, and all the binary weights are used in a burn - after - reading style. At the testing phase, they can sample binary weight instances for a given recognition architecture from the learnt policy network. The performance of SnapQuant is evaluated with several visual recognition tasks including ImageNet."
SP:29d1f6d0661a51e56c59bbb106da56700fc22d9a," data is scattered across different servers and exchanging or pooling it is often impractical or prohibited. This paper proposes a Bayesian nonparametric framework for federated learning with neural networks. Each data server is assumed to train local neural network weights, which are modeled through the framework. An inference approach is developed to synthesize a more expressive global network without additional supervision or data pooling. The experimental results demonstrate the efficacy of the proposed method on two popular image classification datasets."
SP:ab1f2bd216635d63450688866c729a501bd7e9d0,"This paper studies the problem of differentiable games in which players optimise multiple, interdependent objectives in parallel. The authors propose a new method that they call Stable Opponent Shaping ( SOS ) and prove that LookAhead converges locally to equilibria and avoids avoidance in all differentiable all games. They also provide a theoretical guarantee that SOS does not exhibit ‘arrogant ’ behaviour directly at odds with convergence. Finally, they present a new variant of LOLA method that is more stable than LOLA and show that it outperforms LOLA experimentally."
SP:bdafb5fca09a775a8c92d2826d5dc977d28091c2,"This paper proposes a method to predict the quality of segmentation results given different segmentation algorithms on different datasets using a low dimensional feature space. The shape feature of a segmentation result is captured using the value of loss function when the segmentation is tested using a Variational Auto - Encoder ( VAE ) system. The paper form the feature space using shape feature which is a strong prior information shared among different data, so it is capable of predict the qualities of segmentations results. The proposed method is evaluated on several recent segmentation methods for the medical segmentation task. The results show that the proposed method consistently provides reliable prediction on the quality prediction."
SP:60738395d9efe2b3fe3a00c542ebb4261e54386c,"This paper proposes an untrained simple image model, called the deep decoder, which is a deep neural network that can generate natural images from very few weight parameters. The proposed model is simple in the sense that each layer has an identical structure that consists of only one upsampling unit, pixel - wise linear combination of channels, ReLU activation, and channelwise normalization. This underparameterization enables the proposed model to compress images into a concise set of network weights, which enables the model to have state - of - the - art performance for denoising and inverse problems."
SP:1c9bad3bd4d670172f65aa0304e9837ecafc6b3d,"This paper presents an end - to - end neural architecture for program synthesis from natural language ( NL ). The authors propose a pretrained word embedding and a bi - directional multi - layer LSTM for processing word sequences. The decoder features a doubly - recurrent LSTMs, for which the authors propose novel signal propagation schemes and soft attention mechanism. The proposed method is evaluated on a large dataset of problems proposed in a previous work. The results show that the proposed method performs on par with or better than the method proposed in the previous work ( SAPS ) in 92 % of cases."
SP:d2ec231bb6153a303e5110e671dea14c2721e636,"This paper presents a novel adversarial defense method for deep neural networks against adversarial attacks. The authors show that even the most successful L∞ defense methods have lower L0 robustness than the undefended networks and are still highly susceptible to L2 perturbations. They present a novel robust classification model that performs analysis by synthesis using learned synthesis. The results suggest that our approach yields state - of - the - art robustness on MNIST against L0, L2 and L\infty perturbation.  "
SP:91a24e7f4b952c37441feab4a7e8555014c856a4,"This paper proposes a new method for training generative adversarial networks ( GANs ) by controlling the spectra of weight matrices in the discriminator of the generator. The main idea is to use spectral normalization to control the slow singular value decay of the spectral representation of the matrices. The authors propose a new reparameterization approach to control this spectra. The proposed method is evaluated on CIFAR-10/100, STL-10, and Imagenet datasets. The results show that compared to other methods, the proposed method achieves better performance in generating images with competitive quality."
SP:8115fd9b681198d62100c36794926fb57dc0a4f5,"This paper introduces Anderson accelerated value iteration ( A2VI ) for value iteration in reinforcement learning, which is an extension of Anderson Accelerated Value Iteration ( AAVI ). The paper also extends AAVI to deep Q - learning ( DA2Q ), which results in a deep Anderson accelerated Q - Learning algorithm. Theoretical analysis and empirical results are provided for both theoretical analysis and experiments on toy problems and Atari games."
SP:bd79b0c0af778a36008a0c0cf2fb6393fd2789d4,"This paper proposes a new method, SupportNet, for class incremental learning ( CIL ), where the goal is to learn new knowledge without forgetting the previously learned knowledge, which is known as catastrophic forgetting. The proposed method combines the strength of deep learning and support vector machine ( SVM ) where SVM is used to identify the support data from the old data, which are fed to the deep learning model together with the new data for further training. Two powerful consolidation regularizers are applied to stabilize the learned representation and ensure the robustness of the learned model. The experimental results show that the proposed method significantly outperforms the state - of - the - art incremental learning methods on various tasks."
SP:d228d213f79716774043cea253305fecece659ec,"This paper conducts an empirical study on the unit selectivity of neural networks ( NNs ) and compares it with the precision, class - conditional mean activity selectivity ( CCMAS ), top - class selectivity, and localist selectivity measures. The results show that there are no 100 % selective localist units in AlexNet and the most selective hidden units are only responding strongly to a small minority of images from within a category. The authors also found that generated activation maximization ( AM ) of units in fc6 and conv5 produced interpretable images of objects over 50 %, whereas precision and CCMAS measures provide a much higher level of selectivity."
SP:b9deae0392e0160b400d76c549d382e235196f8c,"This paper proposes a novel family of Graph Neural Networks ( GNNs ) for solving community detection problems in a supervised learning setting. Specifically, the authors propose a GNN - based method for solving the problem of node - wise classification of a graph. The proposed method is based on the stochastic block model ( SBM ), which has been shown to be the state - of - the - art for community detection in graph neural networks. The authors show that the proposed method can be trained in a data - driven manner and without access to the underlying generative models, and they show that it can match or even surpass the performance of the belief propagation algorithm on binary and multiclass stochastically block models. They also show that under certain simplifications and assumptions, the loss values at any local minimum is close to the loss value at the global minimum."
SP:a9ed31090e55f6152fc31c7512af5d634cc7225a,"This paper studies the problem of coefficient recovery in the context of dictionary learning, where the goal is to learn a linear combination of a few columns of a matrix ( e.g., a dictionary ) and the sparse weights forming the linear combination are known as coefficients. Since the dictionary and coefficients parameterizing the linear model are unknown, the corresponding optimization is inherently non - convex. This was a major challenge until recently, when provable algorithms for dictionary learning were proposed. Yet, these provide guarantees only on the recovery of the dictionary, without explicit recovery guarantees on the coefficients. This potentially limits the utility of existing provable dictionary learning methods in applications where coefficient recovery is of interest. To this end, the authors develop a simple Neurally plausible alternating Optimization - based Dictionary Learning algorithm, which recovers both the coefficients and dictionary. The proposed algorithm is also scalable and amenable for large scale distributed implementations in neural architectures, by which we mean that it only involves simple linear and non - linear operations."
SP:85232b72a2643d6dc81cf952ccbb95192032b7c5,"This paper proposes a new loss function and training scheme for learning binary hash codes with any differentiable model and similarity function. The loss function improves over prior methods by using log likelihood loss on top of an accurate approximation for the probability that two inputs fall within a Hamming distance target. The training scheme obtains a good estimate of the true gradient by better sampling inputs and evaluating loss terms between all pairs of inputs in each minibatch. To fully leverage the resulting hashes, the authors use multi - indexing. The experiments demonstrate that these techniques provide large improvements to the similarity search tasks."
SP:3bd4ccff7f48380d2db8dff2c4ca515894a7f1db,"This paper proposes a novel method for neural architecture search ( NAS ) based on graph neural networks ( GHNs ). The main idea is to use a hypernetwork to predict the weights of a neural network given an architecture, which is then used as a surrogate search signal to perform NAS. The method is evaluated on CIFAR-10 and ImageNet datasets and compared with other random search methods. The results show that the proposed method is faster than the baselines."
SP:65ccf43cd4e033d22239069057f5200d49f33724, is a generative adversarial imitation learning ( GAIL ) approach that leverages expert demonstrations to learn discriminator functions. The key idea is to perform multiclass classification to learn the discriminator function where non - expert demonstrations are regarded as being drawn from an extra class. Experiments in continuous control tasks demonstrate that the proposed method learns better policies than the baseline GAIL baseline when the number of expert demonstrations is small.
SP:e8427949a98effbd37ce7604fa11f240e2342196,"This paper proposes a new class of neural networks, called INNs, for inverse inference problems where the inverse process of the forward process is not well - defined. In this setting, it is necessary to determine the posterior parameter distribution of the parameters of the system in a latent space that is unknown to the model. The INNs solve this problem by learning an inverse process in latent space using additional latent output variables. The paper provides a theoretical analysis of the INNs and shows that the posterior distribution can be learned implicitly. In addition, the paper provides an experimental analysis of INNs.   "
SP:75c9bb53bac29bdb390f9ba5707caee4ab1f5925,"This paper proposes a new method for quantifying the uncertainty of deep neural networks ( NNs ). The main idea is to replace the fixed mixing weights of a mixture model with an adaptive, input - dependent distribution ( i.e., the probability of each component ) represented by an NN, and by considering uncountably many mixture components. The resulting model can be seen as the continuous counterpart to mixture density networks and is therefore referred to as compound density networks. The authors empirically show that the proposed model results in better uncertainty estimates and is more robust to adversarial examples than previous approaches."
SP:e1e38289285c1b8fdb318e4f6d37a198a08787a2,"This paper proposes to relax weight determinism and use a full variational distribution over weights for more efficient coding schemes and consequently higher compression rates. In particular, following the classical bits - back argument, they encode the network weights using a random sample, requiring only a number of bits corresponding to the KullbackLeibler divergence between the sampled variational distributions and the encoding distribution. The proposed method sets new state - of - the - art in neural network compression, as it strictly dominates previous approaches in a Pareto - dominated manner. On the benchmarks LeNet-5/MNIST and VGG-16 / CIFAR-10, their approach yields the best test performance for a fixed memory budget, and vice versa, it achieves the highest compression rates for fixed test performance. By imposing a constraint on the compression rate, they are able to explicitly control the compression while optimizing the expected loss on the training."
SP:ad70d8cf3a4558aab0d3b7155594464a3debd912,"This paper proposes ProxylessNAS, a differentiable neural architecture search ( NAS ) algorithm that directly learns the architectures for large - scale target tasks and hardware platforms. The main contributions of this paper are as follows :   1. It addresses the high memory consumption issue of differentiable NAS and reduce the computational cost ( GPU hours and GPU memory ) to the same level of regular training while still allowing a large candidate set. 2. It also applies proxylessNAS to specialize neural architectures for hardware with direct hardware metrics ( e.g. latency ) and provide insights for efficient CNN architecture design.   3. It removes the restriction of repeating blocks in previous proxy - based NAS works and allow all of the blocks to be learned and the blocks that are not found to be optimal on the target task to be used in the proxy task. The experimental results on CIFAR-10 and ImageNet demonstrate the effectiveness of directness and specialization. On ImageNet, the directness - based approach achieves better results than previous proxy-based approaches with only 200 times fewer GPU hours than the direct approaches."
SP:e5b70d43d301d1980fae02623ea711976b429c14,"This paper proposes to modify the linear penalties in the Lagrangian dual of a two - player min - max game from linear to second - order ones. The motivation of this change is to avoid the instability and potential lack of convergence associated with the additive linear penalties used in the standard two player, max - max games. The authors argue that this modification results in a more practical training procedure in non - convex, large - data settings. In particular, the use of second order penalties allows training the penalized objective with a fixed value of the penalty coefficient, thus avoiding the instability caused by the additive penalty in two player games. In addition, the authors derive a method for efficiently computing the gradients associated with second order penalty gradients. The resulting algorithm performs well empirically, learning an appropriately fair classifier on a number of benchmarks."
SP:e4720b8e4efdb222c45eafd47fd8a7fbf15d881d,"This paper studies the problem of learning discrete latent variable models in deep generative models. In particular, the authors focus on the reweighted wake - sleep ( RWS ) algorithm ( Bornschein & Bengio, 2015 ) for discrete latent variables and continuous latent variables. The RWS algorithm is based on the Bornscheine - Bengio ( B&B ) algorithm for discrete variables and the continuous relaxation algorithm for continuous variables.   The authors propose to use a path - wise derivative for the samples in RWS and show that it outperforms both control - variate schemes for the former and continuous - relaxation methods for the latter. The authors also show that RWS learns better models and inference networks with increasing numbers of particles, and that its benefits extend to the continuous latent variable model as well."
SP:7459ae5b1d886e68930c4c9e21df508bc8ab3c9a,"This paper proposes a method to train structured prediction energy networks ( SPENs ), which provide efficient test - time inference using gradient - based search on a smooth, learned representation of the score landscape. The main idea is to evaluate predictions using a scalar reward function, which may be easily assembled from human knowledge or non - differentiable pipelines, but searching through the entire output space to find the best output with respect to this reward function is typically intractable. To solve this problem, the authors propose to use efficient truncated randomized search in the reward function to train the SPEN network. The authors show that the proposed method yields state - of - the - art results in structured prediction tasks. In particular, it yields previously unknown local improvements, providing effective supervision to SPEN."
SP:638c1bc09992029b78bd83f0127594dcccb96c06,"This paper studies the problem of policy search in the domain of Robust Policy Search ( RPS ). The authors propose a framework called EffAcTS to select a subset of trajectories from a large number of training trajectories to learn robust policies. The key idea is to collect as much data as possible to select such a subset and apply it to an existing method, namely EPOpt, and experimentally validate the gains in sample efficiency and the performance of our approach on standard continuous control tasks. In addition, the authors also present a Multi - Task Learning perspective to the problem."
SP:491c239713a6489f0b1790ca26db54a1813c67ae,This paper proposes a two - timescale network ( TTN ) architecture for learning nonlinear value functions. The main idea is to learn a nonlinear representation of the value function in a linear setting and then use the learned representation to update the value estimates of a linear policy. The authors show that the nonlinearity of the representation can be approximated by a linear function approximation and provide convergence guarantees for the proposed TTNs. They also provide an empirical study of the performance of the proposed method compared to other non - linear value function approximation methods.
SP:327d606cf3813b00a009a7785e08ef9e11f89493,"This paper proposes a hybrid model - based and model - free approach, LEArning and Planning with Semantics ( LEAPS ), consisting of a multi - target sub - policy that acts on visual inputs, and a Bayesian model over semantic structures. When placed in an unseen environment, the agent plans with the semantic model to make high - level decisions, proposes the next sub - target to execute, and updates the semantic models based on new observations. The proposed method is evaluated in visual navigation tasks using House3D, a 3D environment that contains diverse human - designed indoor scenes with real - world objects."
SP:d7c26f43bc68d160095b1f50447528843d79edbd,"This paper proposes a new end - to - end deep learning method to tackle the two problems : 1 ) Poor generalization ability of unobserved driving environment when diversity of training driving dataset is limited and 2 ) Lack of accident explanation ability when driving models don't work as expected. The proposed method is composed of perception module for see and think and driving module for behave, and trained it with multi - task perception - related basic knowledge and driving knowledge stepwisely. Specifically segmentation map and depth map ( pixel level understanding of images ) were considered as what & where and how far knowledge for tackling easier drivingrelated perception problems before generating final control commands for difficult driving task. The results of experiments demonstrated the effectiveness of multitask perception knowledge for better generalization and hard navigation tasks."
SP:b6bd98cc70fab97e1245cbb63a42ef89ab7e7ed5,"This paper studies the trade - off between the standard accuracy of a model and its robustness to adversarial perturbations. The authors show that there exists an inherent tension between the goal of adversarial robustness and that of standard generalization, and that training robust models may not only be more resource - consuming, but also lead to a reduction of standard accuracy. They also corroborate a similar phenomenon observed in practice, and argue that this phenomenon is a consequence of robust classifiers learning fundamentally different feature representations than standard classifiers. In particular, the features learned by robust models tend to align better with salient data characteristics and human perception."
SP:9c9275d75cd95b1b82e0cbb1421e3d3ade1ce33a,"This paper proposes a new method for training deep neural networks without backpropagation. The proposed method, Equilibrium Propagation ( EPR ), is based on local learning rules and does not rely on neurons having a mechanism for back - propagating an error gradient. However, it has a major practical limitation : inference involves doing an iterative optimization of neural activations to find a fixed - point, and the number of steps required to closely approximate this fixed point scales poorly with the depth of the network. In response to this problem, the authors propose a feed - forward network to initialize the iterative inference procedure for EPR, which learns to approximate the state of the fixed point using a local learning rule. After training, this initializing network can be used for inference, resulting in a learned feedforward network. The experiments show that this network appears to work as well or better than the original version of EPR."
SP:ac9ea91eb465517de495477cf67bc94d5ed1b0cb,"This paper proposes a new zeroth - order ( ZO ) stochastic optimization algorithm, ZO - signSGD, which enjoys the dual advantages of gradient - free operations and sign - SGD : it requires only the sign information of gradient estimates but is able to achieve a comparable or better convergence speed than SGD - type algorithms. The convergence rate is shown to be $ O(d/\sqrt{t}$ where $ d$ is the number of optimization variables and $ T$ is number of iterations. In addition, the authors analyze the effects of different types of gradient estimators on the convergence of ZO-signSGD and propose several variants of the algorithm. On the application side, they explore the connection between the proposed algorithm and black - box adversarial attacks in robust deep learning and demonstrate the superior performance of the proposed method on the generation of adversarial examples."
SP:5f79b11777f6ef1d70c85418bfc2e4616dd7d960,"This paper proposes a new optimization method to reduce the computation efforts of convolutional neural networks by pruning the output of the following activation or pooling layers : ( 1 ) a filter conducts a series of multiply - accumulate ( MAC ) operations, ( 2 ) a checkpoint is set to determine whether a filter could terminate early based on the intermediate result, and ( 3 ) a fine - tuning process is conducted to recover the accuracy drop due to the applied checkpoints. The proposed method is evaluated on CIFAR-10/100 datasets and compared with the state - of - the - art method. The experimental results show that the proposed method can save approximately 50 % MAC operations with less than 1 % accuracy drop."
SP:7801e9c854ad7d960c0d24fda15597af6994c23f,This paper investigates the use of temporal dependency in ASR to mitigate adversarial attacks. The authors propose to exploit the temporal dependency of audio data to gain discriminative power against adversarial examples. They show that input transformation developed from image adversarial defense provides limited robustness improvement and is subtle to advanced attacks. They also show that temporal dependency can be exploited to gain discriminating power and is resistant to adaptive attacks.  
SP:51830b811a8e39b4f0a5b7609df719e026fac6a1,"This paper proposes a new generative model for image generation based on composition. The key idea is to structure the generator of a GAN to consider objects and their relations explicitly, and generate images by means of composition. This is motivated by the compositional way in which humans structure a visual scene in terms of objects. The authors evaluate their approach on several multi - object image datasets and find that the generator learns to identify and disentangle information corresponding to different objects at a representational level. They also show that the generated images are more faithful to the reference distribution."
SP:fb59990b8da0e95d8202383478a456667de60449,"This paper proposes a new learning setting called reference - based variational autoencoders, where the goal is to learn a representation where a set of target factors are disentangled from others, and the only supervision comes from an auxiliary “ reference set ” that contains images where the factors of interest are constant. The proposed model exploits the weak supervisory signal provided by the reference set to learn from minimal supervision. The authors validate the ability of the proposed model on tasks such as feature learning, conditional image generation or attribute transfer, and show that it is able to learn representations with minimal supervision from unlabeled images."
SP:dbc1983d9b9d72aa14f8e8515d793d2bbde26c9c,"This paper proposes a method for continual online learning of deep neural network models using stochastic gradient descent to update model parameters and an expectation maximization algorithm with a Chinese restaurant process prior to developing and maintaining a mixture of models to handle non - stationary task distributions. This allows for all models to be adapted as necessary, with new models instantiated for task changes and old models recalled when previously seen tasks are encountered again. The proposed method MOLe outperforms alternative prior methods, and enables effective continuous adaptation in non - stationary task distributions such as varying terrains, motor failures, and unexpected disturbances."
SP:5665e5f006f84927beb0440e145f476e02538077,This paper proposes a distributed RL training method to improve the performance of RNN - based RL agents. The proposed method is based on distributed prioritized experience replay ( REINFORCE ) with a single network architecture and fixed set of hyperparameters. The method is evaluated on Atari games and achieves state - of - the - art performance on most of the games. The paper also investigates the effect of parameter lag and representational drift on the performance and proposes an improved training strategy to mitigate it.
SP:47ace37f31a46d5ee85c283e62ddb71a12f2c5c4,"This paper proposes a hierarchical generative model for spatiotemporal multi - agent trajectories. The proposed model is based on a hierarchical framework that leverages programmatically produced weak labels for spatio - temporal modeling. The model is instantiated in a hierarchical manner and can be applied to both real - world and synthetic settings. Experiments are conducted on both quantitative and qualitative evaluations, including a user study comparison conducted with professional sports analysts."
SP:1a90cdf028068528b0559e7d44bf26dda20310bd,"This paper proposes a graph - structured variational recurrent neural network ( GRNN ) that learns to integrate temporal information, from a learned dynamics model, with ambiguous visual information ( visual information from a vision model ) in the context of interacting agents. Graph - VRNN is trained end - to - end to infer the current state of the world, as well as to forecast future states. The authors show that their method outperforms various baselines on two sports datasets, one based on real basketball trajectories and one generated by a soccer game engine."
SP:8392f04b7265f665ba6d44d297bca245d44b4708,"This paper proposes a method for end - to - end training of a base neural network that integrates calls to existing black - box functions by approximating them with a differentiable neural network in a way that drives the base network to comply with the black - function function interface during the end-to - end optimization process. The authors show that by leveraging the existing precise black -box function during inference, the integrated model generalizes better than a fully differentiable model, and learns more efficiently compared to RL - based methods."
SP:13fb86de763a0b34ac6fa34ea9dfbd1c476ce43e,This paper proposes a method for meta - learning that uses a mixture of hierarchical Bayesian models over the parameters of an arbitrary function approximator such as a neural network. The method is generalizing the model - agnostic metalearning ( MAML ) algorithm ( Finn et al. 2017 ). The main contribution is a stochastic expectation maximization procedure to jointly estimate parameter initializations for gradient descent as well as a latent assignment of tasks to initializations. This approach better captures the diversity of training tasks as opposed to consolidating biases and better generalization performance on the standard miniImageNet benchmark for 1 - shot classification. The authors also derive a novel and scalable non - parametric variant of their method that captures the evolution of a task distribution over time.
SP:a410144dbe19713a06c63da87d9fb58b999a7492,This paper proposes a meta - auxiliary learning method for image classification. The auxiliary task is a hierarchical sub - class classification task where the goal is to improve the generalisation performance of the main classification task. The main idea of the proposed method is to train a multi - task evaluator to determine sub - task target labels for the auxiliary task and use them to guide the meta - learner towards these sub - tasks. The proposed method MAXL is evaluated on three CIFAR image classification datasets and compared with several baselines. The results show that MAXL outperforms the baselines and is competitive with a method that uses human - defined auxiliary tasks.
SP:76248e1c914c60ce69de244fe7ec62488d01e161,This paper proposes a neural network based representation for open set recognition. The main idea is to represent instances from the same class as close to each other while instances from different classes are further apart. The proposed method is evaluated on three datasets from two different domains. Results show that the proposed method achieves statistically significant improvement when compared to other approaches on two datasets.
SP:d4ee856bbf2dfb6390e5247086fec2e52dcb6858,"This paper proposes a method for training low - precision networks by starting with pretrained fp32 precision baseline networks and fine - tuning, and then using larger batches along with matched learning rate annealing to combat noise introduced by quantizing weights and activations during training. The number of iterations required by stochastic gradient descent to achieve a given training error is related to the square of ( a ) the distance of the initial solution from the final plus ( b ) the maximum variance of the gradient estimates. The authors show that both energy and area scale down quadratically with the reduction in precision. They also demonstrate ResNet -18, ResNet-34, ResNets-50, ResResNet-152, Inception - v3, densenet161, and VGG - 16bn networks on the ImageNet classification benchmark that, at 8 - bit precision exceed the accuracy of the full - precision baseline models after one epoch of finetuning, thereby leveraging the availability of pretrained models."
SP:6bfdc37b346e6ddfa049e0414647f4beda8ede3f,This paper proposes an end - to - end model for post - bouncing trajectory prediction and surface properties inferring from a single image. The proposed method is based on a physics - based model ( PIM ) and a visual - based method ( VIM ). The authors propose a new dataset of 5k RGB - D videos of bouncing trajectories of a foam ball to probe surfaces of varying shapes and materials in everyday scenes. The experiments show that the proposed method outperforms baselines in predicting post - bounce trajectories and inferring physical properties of a scene.
SP:010bd055310c363d3cb0fbe0e11546de58220e15,"This paper studies the vulnerability of deep neural networks to adversarial attacks. The authors show that adversarial vulnerability increases with the gradients of the training objective when viewed as a function of the inputs. For most current network architectures, the authors prove that the `1 - norm of these gradients grows as the square root of the input size, and thus becomes increasingly vulnerable with growing image size.    The authors also show that the vulnerability does not depend on the network ’s weight distribution at initialization, but rather on the gradient of the objective function. The experiments confirm that the conclusions still hold after usual training."
SP:5fa3ae057e55be6b71cc94a7dbfe31e54e1c536f,"This paper proposes an agent modeling framework that encourages agents to learn to probe. The probing agent learns to interact with the environment and with a target agent ( i.e., a demonstrator ) to maximize the change in the observed behaviors of that agent. Through probing, rich behaviors can be observed and are used for enhancing the agent modeling to learn a more accurate mind model of the target agent. The framework consists of two learning processes : i ) imitation learning for an approximated agent model and ii ) pure curiosity - driven reinforcement learning for probing policy to discover new behaviors. The experimental results suggest that the agent model learned by our framework generalizes better in novel scenarios than the ones learned by passive observation, random probing, and other curiositydriven approaches do."
SP:3af184a5529d6ec2a0862efd1af80ef5b50d2952,"This paper proposes a modification to ANNs that mimics biological neuromodulators to enable them to adjust their activation sensitivities in run - time based on input patterns. The modification connects a new type of ANN nodes, which mimic the function of biological neuromechanical modulators and are termed modulators, to enable other traditional ANN nodes to adjust activation sensitivity in run time. In this manner, it enables the slope of the activation function to be context dependent. This modification produces statistically significant improvements in comparison with traditional ANNs in the context of Convolutional Neural Networks and Long Short - Term Memory networks."
SP:287a577834fd2820a939a1113b39146a22727491,"This paper proposes a neural analysis and synthesis framework ( NANSY ) that can manipulate voice, pitch, and speed of arbitrary speech signals. The proposed method is based on perturbation of information in the original input signal ( formant, pitch and frequency response ) to selectively take essential attributes to reconstruct the input signal. The method does not require any labels associated with speech data such as text and speaker information, but rather uses a new set of analysis features, which allows for fully self - supervised training. Experiments on zero - shot voice conversion, pitch shift, and time - scale modification show that the proposed method can achieve significant improvement in performance."
SP:90f35ad1ec0c38b0817f5678ee2a5c4f0e08fb38,"This paper studies the generalization properties of gradient - based bilevel programming ( BVP ). BVP is a well - studied algorithm for hyperparameter optimization. The authors provide an expectation bound for uniform stability of the validation set and a bound for the cross - validation set based on uniform stability. They also provide an upper bound on the performance of the gradient based bVP under uniform stability conditions. Finally, they show that gradient based algorithms can be better than cross validation under certain conditions. The main contribution of this paper is the theoretical analysis."
SP:42f52aec3a776d87daa5fd72b8e6325d12c88d63,"This paper proposes a novel knowledge distillation approach to facilitate the transfer of dark knowledge from a teacher to a student. The main idea is to learn the teacher models that are friendly to students and, consequently, more appropriate for knowledge transfer. In other words, at the time of optimizing a teacher model, the proposed algorithm learns the student branches jointly to obtain student - friendly representations. The proposed algorithm demonstrates outstanding accuracy in several well - known knowledge distilling techniques with various combinations of teacher and student models even in the case that their architectures are heterogeneous."
SP:e15a1c21229233fd97dc1dfa0a4ef48b69dc9f95,"In this paper, the authors propose a new definition of out - of - distribution ( OOD ) learning, which they call expansion function. The expansion function characterizes to what extent the variance is amplified in the test domain over the training domains, and therefore give a quantitative meaning of invariant features. The authors also provide a theoretical understanding of what kind of invariance can guarantee OOD generalization, and what does it mean by saying an OOD problem is learnable. Extensive experiments on benchmark OOD datasets demonstrate that the proposed expansion function has a significant advantage over baselines in terms of model selection criterion."
SP:37b04b9068d39bcf0a581eb8181d13cf1a8926bf,"This paper proposes a Variational Continual Bayesian Meta - learning ( VC - BML ) algorithm for online meta - learning, where tasks arrive sequentially and follow a non - stationary distribution. The authors propose a Dynamic Gaussian Mixture Model with a Chinese Restaurant Process ( GMM ) for meta - parameters and a dynamic mixtures at the meta - parameter level. They also develop a more robust posterior approximation method – structured variational inference for the sake of avoiding forgetting knowledge. Experiments on tasks from non - stationary distributions show that the proposed method is superior in transferring knowledge among diverse tasks and alleviating catastrophic forgetting in an online setting."
SP:776d5b02b8d3a8bbcc1f52706f3887c384cb149e,"This paper proposes a probabilistic algorithm for the solution of boundary value problems ( BVPs ), which are ordinary differential equations ( ODEs ) that are subject to boundary conditions. The main idea is to use a Gauss - Markov prior for the posterior distribution over the solution in linear time, at a quality and cost comparable to that of well established, non - Probabilistic methods. The authors also introduce uncertainty quantification, mesh refinement, and hyperparameter adaptation to improve the efficiency of the algorithm. The proposed method is compatible with other statistical modelling tool - chains."
SP:86aac0c6b75fdc12f84bba342934865616f866d4,"This paper considers the problem of reward mixing Markov decision processes ( MDPs ), where a reward function is drawn from one of multiple possible reward models at the beginning of every episode, but the identity of the chosen reward model is not revealed to the agent. The latent state space, for which the dynamics are Markovian, is not given to an agent in this setting. The authors propose an algorithm that does not require any assumptions on the dynamics of the dynamics and study the problem in full generality. The proposed algorithm is the first efficient algorithm that finds an - optimal - policy after exploring in a partially observed MDP where the observation space is smaller than the Markov state space."
SP:1a3c70ae9cf2a806d603f4b9e7ca6e10b720a956,This paper proposes a two - step procedure called Single - cause perturbation ( SCP ) to estimate the multi - cause treatment effect in the context of conditional average treatment effect estimation ( CATE ). The main idea is to augment the observational dataset with the estimated potential outcomes under single - cause interventions and then perform covariate adjustment on the augmented dataset. The proposed procedure is evaluated on extensive synthetic and real - world synthetic data sets. The experimental results show that the proposed procedure achieves the claimed gain on CATE in most cases.
SP:247bc6675cce89d51558537daf63dadb0c4307f8,"This paper proposes a multi - wavelet based neural operator learning scheme for computing the inverse operator map between the input and the solution space of a partial differential equation. The proposed method compresses the associated operator ’s kernel using fine - grained wavelets. The projected kernel is trained at multiple scales derived from using repeated computation of multiwavelet transform. This allows learning the complex dependencies at various scales and results in a resolution - independent scheme. By learning the mappings between function spaces, the proposed method has the ability to find the solution of a high - resolution input after learning from lower - resolution data."
SP:1153785e6a016cfee2644952a772aa08927299b6,"This paper proposes a novel method for approximating the gradient of sign function in Fourier frequency domain using the combination of sine functions for training binary neural networks ( BNNs ), namely frequency domain approximation ( FDA ). The proposed approach does not affect the low - frequency information of the original sign function which occupies most of the overall energy, and high - frequency coefficients will be ignored to avoid the huge computational overhead. In addition, the authors embed a noise adaptation module into the training phase to compensate the approximation error. Experiments on several benchmark datasets and neural architectures illustrate that the binary network trained using the proposed method achieves the state - of - the - art accuracy."
SP:33b95ea8da4d30b8e8f9d3fe3acca023d4b8d831,"This paper proposes to use multi - area RNNs with neuroscience - inspired architecture constraints to derive key features of multi - region computation. In particular, the authors show that incorporating multiple areas and Dale’s Law is critical for biasing the networks to learn biologically plausible solutions. The authors also leverage the full observability of the RNNS to show that output - relevant information is preferentially propagated between areas. These results suggest that cortex uses modular computation to generate minimal sufficient representations of task information."
SP:db3ced65d67e3373fb3936ec50f41c8ef010bbbe,"This paper proposes structured attention graphs ( SAGs ), which are compactly represent sets of attention maps for an image by visualizing how different combinations of image regions impact the confidence of a class. The authors argue that a single saliency map provides an incomplete understanding since there are often many other maps that can explain a classification equally well, and propose to utilize a beam search algorithm to systematically search for multiple explanations for each image. Results show that there are indeed multiple relatively localized explanations for many images, and naively showing multiple explanations to users can be overwhelming and does not reveal their common and distinct structures."
SP:f2b385bfd9ada0e26aa8829214b424f58582d9f7,"This paper studies how the choice of training objective affects the transferability of the hidden representations of convolutional neural networks trained on ImageNet. The paper shows that many objectives lead to statistically significant improvements in ImageNet accuracy over vanilla softmax cross - entropy, but the resulting fixed feature extractors transfer substantially worse to downstream tasks. The choice of loss has little effect when networks are fully fine - tuned on the new tasks, and the differences among loss functions are apparent only in the last few layers of the network. The results suggest there exists a trade - off between learning invariant features for the original task and features relevant for transfer tasks."
SP:b66b5e24f68563e2e200eda660f0dbaff53efeff,"This paper proposes selective backpropagation through time ( SBTT ) to learn generative models of latent dynamics in neural time - series data. The key idea is to learn a latent dynamics model for each time step of a neural time series. The latent dynamics is modeled using a deep generative model of the population dynamics between neurons. The authors propose to learn the latent dynamics by back - propagation through time in the latent space of the time series, and then use the learned dynamics to infer missing samples by combining observations with the learned latent dynamics. The proposed SBTT method is evaluated on sequential autoencoders and shows improved performance compared to the state - of - the - art methods."
SP:3513a83806e71006b86d60b779d8bd6bb87c3546,"This paper proposes a hierarchical approach to sequence - to - sequence learning with quasi - synchronous grammars, where each node in the target tree is transduced by a neuron in the source tree. Both the source and target trees are treated as latent and induced during training. The authors develop a neural parameterization of the grammar which enables parameter sharing over the combinatorial space of derivation rules without the need for manual feature engineering. They apply this latent neural grammar to various domains—a diagnostic language designed to test for compositional generalization ( SCAN ), and small - scale machine translation, and find that it performs favorably compared to the standard sequence to sequence learning algorithms."
SP:d06fc251f2a9287f7a2236a188349628d8f39d9a,"This paper proposes a new algorithm to solve Group Elastic Net with application to function - on - scalar feature selection, where a functional response is modeled against a very large number of potential scalar predictors. The proposed algorithm exploits the sparsity structure of the Augmented Lagrangian to greatly reduce the computational burden, and extends the algorithm to the functional principal component framework. Empirical results show that the proposed algorithm achieves better CPU time gains compared to its best existing competitors."
SP:e0b53f76f3a6b756fedd09926f9cf034f89f4a5a,"This paper proposes a mixture model of multi - level marked point processes to identify potential heterogeneity in the observed data. Specifically, the authors study a matrix matrix whose entries are marked log - Gaussian Cox processes and cluster rows of such a matrix. An efficient semi - parametric Expectation - Solution ( ES ) algorithm combined with functional principal component analysis ( FPCA ) of point processes is proposed for model estimation. The effectiveness of the proposed framework is demonstrated through simulation studies and real data analyses."
SP:3aa213076f3e9f9838ac654517df2fe1fca33499,"This paper proposes Online Meta - Adaptive Control ( OMAC ), an online multi - task learning approach for adaptive nonlinear control. The approach is motivated by robot control, where a robotic system encounters a sequence of new environmental conditions that it must quickly adapt to. A key emphasis is to integrate online representation learning with established methods from control theory, in order to arrive at a unified framework that yields both control - theoretic and learning - theoretic guarantees. The authors provide instantiations of their approach under varying conditions, leading to the first non - asymptotic end - to - end convergence guarantee for multi -task non - linear control. OMAC can also be integrated with deep representation learning."
SP:cb274c93a169b199ea09120ca02105a3f16b31c5,"This paper proposes three improvements to the existing certified bound propagation based interval bound propagation ( IBP ) methods to improve their certified robustness guarantees. The authors first identify two issues in existing methods, namely exploded bounds at initialization and the imbalance in ReLU activation states, and improve IBP training to mitigate these issues. They also propose to fully add Batch Normalization ( BN ) to each layer in the model to reduce the imbalance. Finally, the authors propose to tighten the certified bounds and balance ReLU activations during training to improve the performance of IBP.    The authors show that their proposed improvements improve the SOTA performance on CIFAR-10 and TinyImageNet."
SP:18ffeb199a670fb2b1f4417b8653479001944dab,"This paper proposes a novel change point detection method that is robust against adversarial attacks. The proposed method is based on the Huber $ \epsilon$-contamination framework, which in particular allows the contamination distributions to be different at each time point. The authors derive the minimax - optimal optimal localisation rate, which is a function of the contamination proportion under certain conditions. Extensive numerical experiments are conducted with comparisons to existing robust change - point detection methods.   The authors demonstrate a phase transition phenomenon in change points detection, which shows a significant increase in the number of positive change points detected compared to negative change points."
SP:d03617b5fc446768809cf015c9234b0c9386a690,"This paper studies the power of learning via mini - batch stochastic gradient descent and batch gradient descent ( SGD and GD ) on the population loss and empirical loss, respectively, of a differentiable model or neural network. The authors show that SGD / GD can always simulate learning with statistical queries ( SQ ), but their ability to go beyond that depends on the precision ρ of the gradient calculations relative to the minibatch size b ( for SGD ) and sample size m ( for GD ). With fine enough precision, namely when b \leq \lambda is small enough, SGD can go beyond SQ learning and simulate any sample - based learning algorithm and thus its learning power is equivalent to that of PAC learning. In particular, with polynomially many bits of precision ( i.e., when ρ is exponentially small ), both SGD & GD can both simulate PAC learning regardless of the mini - batches size."
SP:1de2864fe2f53e25596a9bd2c61e2048e79296f6,"This paper considers the problem of generating a discrete probability distribution over a set of N points with a Wasserstein distance of $ \mathbb{R}_{\min}(N)$ defined over $ N$ points. The distribution is non - convex in the sense that the number of points in the distribution is $ N^{-1,\ldots, N}$ times larger than the total number of atoms in the set $ N$. The authors consider a variant of the Lloyd - type algorithm for generating such a distribution, where the atoms are represented by a power cell instead of a Voronoi cell. The authors show that under some assumptions on the distribution $ \min_{\infty}$ and $ \ldots$, the distance between the distribution and the distribution of atoms can be minimized with high probability. They also provide upper and lower bounds for the convergence of the algorithm.    The main result of the paper is that, when the power cell is added to the original algorithm, it converges to a distribution with a small $ \Omega(Wasserstein)$ distance with probability $ 1/\sqrt{\frac{W}{\log T } \log T}$, where $ W_{\Omega(\log T)$ is the distance from the true distribution to the distribution. This result is consistent with the fact that spurious critical points can be identified in the discrete distribution. The paper also shows that, under some conditions, the distribution can converge to a uniform distribution with probability at least $ \log(W_{\tilde)-\frac{1/2}{T}$."
SP:c3d364aeee55230a436c3ce4e8dc8310ee73959e,"This paper proposes a new self - attention mechanism for video understanding that leverages the rich structures of spatio - temporal relations in videos by dynamically generating relational kernels and aggregating relational contexts. The authors propose a relational feature transform, dubbed the relational self attention ( RSA ), which leverages relations in space and time, i.e., motion information, for effective representation. The proposed RSA network is evaluated on the Something - Something-Something-Vain&Vain benchmarks for video action recognition. The experiments show that the RSA network substantially outperforms its conventional convolution and self-attention counterparts, achieving the state - of - the - art on the standard motion - centric benchmarks."
SP:2c2530069d5cab485629090243da464d107feadd,"This paper studies the mean field theory of multilayer neural networks in the large - width regime. The authors show that, in this regime, the learning dynamics of a large multi - layer neural network is closely related to the infinite - width limit of the network, and a random fluctuation around this limit is expected from a large width expansion to the next order. This fluctuation has previously been studied only in the case of shallow networks, where previous works employ heavily technical notions or additional formulation ideas amenable only to that case. The main difficulty in this work is to find a formulation that must capture the stochastic dependency across not only time but also depth. In this work, the authors propose a framework based on the neuronal embedding framework recently introduced by Nguyen and Pham [ 17 ], that captures the limiting fluctuation that is inherent in the limit of this limit. They apply the result to show a stability property of gradient descent mean field training : along the training trajectory, it progressively biases towards a solution with “ minimal fluctuation ” in the learned output function, even after the network has been initialized at or converged ( sufficiently fast ) to a global optimum. This extends a similar phenomenon previously shown only for shallow networks with a squared loss in the empirical risk minimization setting to a more general setting.   The authors demonstrate through the framework the complex interaction among neurons in this second - order limit, with cross - layer dependency and the nonlinear time evolution inherent in this limit, that a limit theorem is proven to relate quantitatively and quantitatively this limit to the fluctuation realized by large - wide networks."
SP:a3d927854d9d7fd39b8d05a79666810d585d5062,"This paper proposes a novel parameterization of dissipative brackets from metriplectic dynamical systems appropriate for learning irreversible dynamics with unknown a priori model form. The proposed method learns generalized Casimirs for energy and entropy guaranteed to be conserved and nondecreasing, respectively. The authors provide benchmarks for dissipative systems demonstrating learned dynamics are more robust and generalize better than either "" black - box "" or penalty - based approaches. In addition, the authors show exact preservation of a fluctuation - dissipation theorem, ensuring thermodynamic consistency.   The authors claim that this work is an important first step toward handling more complicated dissipative chaotic systems ubiquitous to science and engineering problems."
SP:32e8e83e06b1e9a4dad761334d5947c91bfd1853,"This paper proposes a sample selection - based algorithm for fair and robust training. The authors formulate a combinatorial optimization problem for the unbiased samples in the presence of data corruption. They propose a greedy algorithm that is efficient and effective in practice. Experiments show that their algorithm obtains fairness and robustness that are better than or comparable to the state - of - the - art technique, both on synthetic and benchmark real datasets."
SP:991127729bf067fe27fdd7ed360aab39e4df5921,"This paper proposes to introduce inductive biases in the function space of Bayesian neural networks ( BNNs ) by introducing periodic activation functions. The authors show that periodic activations of BNN weights can be viewed as a translation - invariant, stationary Gaussian process ( GP ) prior. They also show that this connection can be extended to triangular wave and periodic ReLU activations as well. In the experiments, they show that the proposed method achieves comparable performance for in - domain data and capture sensitivity to perturbed inputs in deep neural networks for OOD detection."
SP:d61a2aecfea4612c473b4e6fd41f3dc2fcbb04a1,"This paper studies the problem of providing feedback to an autonomous agent that is trying to learn to classify Markov Decision Processes ( MDPs ) in an interactive setting. The agent is given an MDP with a reward function and dynamics model, and the goal is to classify the MDP as either correct or broken. To this end, the paper proposes an autoregressive algorithm that uses an agent to sample differential trajectories from the input MDP and a classifier to determine the correct or wrong MDP based on the dynamics and reward model. The paper also proposes a cooperative objective between the agent and the classifier in order to sample the differential trajectory of the agent ’s MDP. The proposed method is evaluated on a dataset of 7,274 student submissions to a single assignment."
SP:daf99ad91613d6e11b13315ccbd1bbe25094ae4b,"This paper proposes a new approach to explain deep reinforcement learning ( DRL ) models by learning high - level latent object features from disentangled representations and a mimic tree that extracts the causal impact of the latent features on DRL action values. To jointly optimize both the fidelity and the simplicity of the mimic tree, the authors derive a novel Minimum Description Length ( MDL ) objective based on the Information Bottleneck ( IBM ) principle. The paper also proposes a novel MCRTS algorithm that explores different splits to find the IB - optimal mimic tree. Experiments show that the proposed method achieves strong approximation performance with significantly fewer nodes than baseline models."
SP:84560de78af979354fff83d1370d8675c1e9191f,"This paper proposes a Bayesian framework GLIM for modeling the structure of dynamic predictions over time. In particular, the authors model these trajectories by assuming predictions update according to a latent of information flow, which is inferred from historical data. The GLIM framework is based on the Gaussian latent information martingale ( GMM ) structure. The authors show that GLIM outperforms three popular baseline methods, producing better estimated posterior probability path distributions measured by three different metrics.    The main contribution of this paper is to propose a Bayes framework for modeling dynamic predictions of future binary probability paths, which can be used in a variety of settings such as weather forecasts, political prognostications, and financial projections. By elucidating the dynamic structure of prediction over time, this paper hopes to help individuals make more informed choices."
SP:0c4bfb44e0a353256692d5e5ae96f65c1a14363d,"This paper studies the problem of pure exploration with fixed confidence in stochastic bandit environments. The goal is to answer a query about the environment with a given level of certainty while minimizing her sampling budget. For this problem, instance - specific lower bounds on the expected sample complexity reveal the optimal proportions of arm draws an Oracle algorithm would apply. These proportions solve an optimization problem whose tractability strongly depends on the structural properties of the environment, but may be instrumental in the design of efficient learning algorithms. The Frank - Wolfe - based Sampling ( FWS ) is a simple algorithm whose sample complexity matches the lower bounds for a wide class of pure exploring problems. The algorithm is computationally efficient as it relies on a single iteration of Frank - Wolfe algorithm applied to the lower - bound optimization problem. The authors apply FWS to various pure exploration tasks, including best arm identification in unstructured, thresholded, linear, and Lipschitz bandits."
SP:0947a0f08fba53d3c8af9b78dd64e6e10fc73e32,"This paper proposes a new method for black - box function evaluation in combinatorial spaces ( sequences, trees, and graphs ) that leverages deep generative models ( DGMs ) to learn a latent representation of structures that can be used in a surrogate model for black box function evaluations. The proposed method, LADDER, aims to overcome the limitation of the DGM - based surrogate model in that it only uses the information learned by the generative model, which may not have the desired inductive bias. To overcome this drawback, the authors propose a principled approach that explicitly integrates the structural information from decoded structures with the learned latent space representation for better surrogate modeling. Experiments on real - world benchmarks show that the proposed method significantly improves over the existing BO over latent space method, and performs better or similar to state - of - the - art methods."
SP:37adabdc6615c5199a481553c8ccc06d57363614,"This paper studies the representation of state - action value functions in regret minimization in finite - horizon Markov Decision Processes ( MDPs ) with linear structure. The authors first derive a necessary condition on the representation, called universally spanning optimal features ( UN ISOFT ), to achieve constant regret in any MDP with linear reward function. They then demonstrate that this condition is also sufficient for two optimistic algorithms ( LSVI - UCB and ELEANOR ) by deriving a constant regret bound for these classes of problems. Finally, they propose an algorithm for representation selection and prove that it achieves constant regret when one of the given representations, or a suitable combination of them, satisfies the UNISOFT condition."
SP:92566b664ab2f6ee9b73f29327aeef85d14ecf60,"This paper proposes a differentiable contact model that can capture contact mechanics : frictionless / frictionless contact mechanics as well as elastic /inelastic contact mechanics. The proposed contact model extends the scope of Lagrangian and Hamiltonian neural networks by allowing simultaneous learning of contact and system dynamics. The authors demonstrate this framework on a series of challenging physical systems with different coefficients of restitution and friction. The learned dynamics can be used as a physics simulator for downstream gradient - based optimization tasks, such as planning and control."
SP:82d59a3609dfd458f90f23d4e477c8b497e9dc18,"This paper investigates the hypothesis that the complexity of the function a deep neural network ( NN ) is learning can be deduced by its training dynamics, which is known as Benevolent Training Hypothesis ( BTH ). The paper shows that the Lipschitz constant close to the training data affects various aspects of the parameter trajectory, with more complex networks having a longer trajectory, bigger variance, and often veering further from their initialization. They also show that NNs whose 1st layer bias is trained more steadily ( i.e., slowly and with little variation ) have bounded complexity even in regions of the input space that are far from any training point. Finally, they find that steady training with Dropout implies a training with steady training and that good training behavior can be a useful bias towards good generalization."
SP:9b329c915fa8d4045c167c9df37a49ee314d190e,"In this paper, the authors show that any distribution can be decomposed as a disjoint mixture of few distributions for which a Forster transform exists and can be computed efficiently. The main application of this result is the first polynomial - time algorithm for distribution - independent PAC learning of halfspaces in the Massart noise model with strongly polynomials sample complexity, i.e., independent of the bit complexity of the examples. Previous algorithms for this learning problem incurred sample complexity scaling polynoclearly with the bit - complexity, even though such a dependence is not information - theoretically necessary."
SP:e5229305af00067ae2dbabd903e585964aec8928,"This paper proposes a Bayesian adversarial attack method for graph classification models. The proposed method is black - box, query - efficient, and parsimonious with respect to the perturbation applied. The authors empirically validate the effectiveness and flexibility of the proposed method on a wide range of graph classification tasks involving varying graph classification task.   The authors also analyse common interpretable patterns behind the adversarial samples, which may shed further light on the robustness and robustness to adversarial perturbations of the target models."
SP:4999e5664383066fdacd14be6242c7b83f85f3dd,"This paper studies the problem of online label shift adaptation in the online setting, where the test - time label distribution is continually changing and the model must dynamically adapt to it without observing the true label. The authors first show that the lack of true label does not hinder estimation of the expected test loss, which enables the reduction of the online label distribution shift adaptation to conventional online learning. Based on this observation, two adaptation algorithms inspired by classical online learning techniques such as FTL and Online Gradient Descent ( OGD ) are proposed and regret bounds are derived. Empirically, the authors empirically verify their findings under both simulated and real world label distribution shifts and show that OGD is particularly effective and robust to a variety of challenging label shift scenarios."
SP:806515ae07fb1c9d02773592005d53d4158ef102,"This paper considers the problem of detecting and localization of gradual changes in the distribution of a sequence of time - ordered observations. The authors propose a general method for detecting and localizing gradual changes that does not require a specific data generating model, a particular data type, or prior knowledge about which features of the distribution are subject to change. The proposed method has proven theoretical guarantees for both detection and localization.   The main contributions of this paper are :   1. Propose a general algorithm for detecting gradual distributional changes. This is different from the existing abrupt setting which assumes a discontinuity jump in distribution, and is unrealistic for some applied settings. 2. Utilize relaxed assumptions on the distribution and data type to achieve the proposed method."
SP:7a3c8a7b17ecab19361d36e1d3d73fa35b71214c,"This paper proposes a biologically plausible neural network algorithm for solving blind source separation ( BSS ) problems in the online setting where data samples are streamed one at a time and the NN computes the sources on the fly without storing any significant fraction of the data in memory. The algorithm is based on the Independent Component Analysis ( ICA ) neural network ( NN ), and the authors propose a novel objective function for ICA from which they derive biologically plausible NN, including both neural architecture and the synaptic learning rules. Interestingly, our algorithm relies on the total activity of the output neurons in the biological circuit by the total time - evolution process by the neuromodulators. In the brain, this could be accomplished by neuromulators."
SP:22f8b517a3df65144412938f5891c463d7bae0ab,"This paper studies the behavior of recurrent neural networks ( RNNs ) in three neuroscience - inspired tasks : discrimination, interval discrimination, and time reproduction. The authors propose a method to derive the reduced dynamics of networks by generating a compact directed graph describing the essence of the dynamics with regards to behavioral inputs and outputs. Using this representation, they can partition the solutions to each task into a handful of types and show that neural features can partially predict them. Taken together, these results shed light on the concept of the space of solutions and its uses both in Machine learning and in Neuroscience."
SP:9b08a0f547ead3b59077a43b1052c6d46a0730f6,This paper proposes a conditional density estimation method called Arbitrary conditional likelihood estimation with energy ( ACE ) that can simultaneously estimate the distribution p(xu | xo ) for all possible subsets of unobserved features xu and observed features xo. The proposed method is designed to avoid unnecessary bias and complexity — it specifies densities with a highly expressive energy function and reduce the problem to only learning one - dimensional conditionals ( conditionals ). Experiments show that ACE achieves state - of - the - art performance on standard benchmarks and unsupervised learning settings.
SP:f2b14f5854e6aa6922795d1d2051b7402486cef6,"This paper proposes an adaptive weighted loss function for single image super - resolution ( SISR ) to train deep networks focusing on challenging situations such as textured and edge pixels with high uncertainty. Specifically, it introduces variance estimation characterizing the uncertainty on a pixel - by - pixel basis into the solution so the targeted pixels in a high - resolution image can be prioritized according to their importance to visual quality. For the first time, the authors demonstrate that such uncertainty - driven loss function can achieve better results than MSE or L1 loss for a wide range of network architectures. Experimental results show that the proposed loss has achieved better PSNR performance than traditional loss functions without any increased computation during testing."
SP:9997583f40fa648adf57bb4fc34228f357be0cf1,"This paper proposes the first general PAC - Bayesian generalization bounds for adversarial robustness, that estimate, at test time, how much a model will be invariant to imperceptible perturbations in the input. The main idea of the paper is to estimate the risk of a hypothesis over all the possible adversarial attacks in the worst - case using the PAC - bayesian framework, and to bound the averaged risk on the perturbation for majority votes ( over the whole class of hypotheses ). The theoretical analysis has the advantage to provide general bounds ( i ) that are valid for any kind of attacks ( i.e., the adversarial attack ), ( ii ) tight thanks to the PAC-Bayesian framework and ( iii ) that can be directly minimized during the learning phase to obtain a robust model on different attacks at the test time.   The main contributions of this paper are the following :   1. Propose general bounds that are applicable to adversarial and non - adversarial settings. 2. Theoretically founded analysis that provides general bounds. 3. The tightness of the bounds. 4. A method for minimizing the risk during the test phase."
SP:90b72e8dc41584e38f25dff9fb2853f5b11dc8fa,"This paper proposes a probabilistic entity representation ( PERM ) model for logical reasoning over Knowledge Graphs ( KGs ). The proposed PERM encodes entities as a multivariate Gaussian density with mean and covariance parameters to capture its semantic position and smooth decision boundary, respectively. PERM also defines the closed logical operations of projection, intersection, and union. The authors demonstrate that PERM significantly outperforms the state - of - the - art methods on various public benchmark KGs datasets. They also evaluate PERM ’s competence on a COVID - 19 drugrepurposing case study and show that their proposed work is able to recommend drugs with substantially better F1 than current methods."
SP:b6184c9732dbb7eba7c20cae8869d975c428efe4,This paper proposes a forward - mode differentiation with sharing ( FDS ) algorithm to tackle memory scaling and gradient degradation issues in gradient - based hyperparameter optimization ( GPO ) for tasks with long horizons ( many gradient steps ). FDS is a simple and efficient algorithm that tackles memory scaling issues with forward - modes differentiation ( FMD ) and gradient degrading issues by sharing hyperparameters that are contiguous in time. The authors provide theoretical guarantees about the noise reduction properties of FDS and demonstrate its efficiency empirically by differentiating through 10 gradient steps of unrolled optimization. The proposed FDS significantly outperforms greedy gradient based alternatives on CIFAR-10 where the performance is significantly better than the state - of - the - art.
SP:9c3a326e5ee4e862923d3bf9415f32a077db8534,"This paper proposes a method to improve the consistency of neural sequence models by adding a logical reasoning module to them. The method is based on the idea that human reasoning can be understood as an interplay between two systems, intuitive and associative ( System 1 ) and logical ( System 2 ). The proposed method uses neural inference to mediate between the logical System 1 and the intuitive and logical System 2. The authors explore several variations on this theme in which candidate generations from a neural sequence model are examined for logical consistency by a symbolic reasoning module, which can either accept or reject the generations. Experimental results show that this approach can increase the coherence and accuracy of neurally - based generations."
SP:d77d046095e4c8336c0c76ac48cb046923230753,"This paper considers the problem of off - policy evaluation ( OPE ) in continuous treatment settings. In this setting, one aims to estimate the mean outcome under a new treatment decision rule using historical data generated by a different decision rule. Most existing works on OPE focus on discrete treatment settings, but to handle continuous treatments, the authors develop a novel estimation method for OPE using deep jump learning. The key ingredient of the method lies in adaptively discretizing the treatment space using deep discretization, by leveraging deep learning and multiscale change point detection. The method is further justified by theoretical results, simulations, and a real application to Warfarin Dosing."
SP:4d085e57286fdd36143108a002d16914222c239a,"This paper proposes a variational inference algorithm for continuous - time dynamical systems based on a Gaussian process approximation on the diffusion level with posterior inference for Markov jump processes. The authors provide the exact evolution equations for the prior and posterior marginal densities of the diffusion process, which are computationally intractable. Therefore, they develop a new continuous time variational algorithm by combining a path - wise Kullback - Leibler divergence with a Markov Jump Process approximation. They obtain Bayesian latent state estimates for arbitrary points on the real axis and for real - world examples.    The authors extensively evaluate their algorithm under the assumption under the assumptions of assumption 1 and assumption 2. They show that their method outperforms the baselines."
SP:d1f396e691f9d331adfb7b694a99c50e8004331f,"This paper studies the effect of the spectrum of sensing matrices on the recovery performance of expectation propagation algorithm ( EP ) in phase - retrieval and sensing problems. The authors consider a nonlinear inverse problem y = f(Ax ), where observations y are the componentwise nonlinear transformation of Ax and A is a known linear mapping. They define a notion for the spikiness of A and show the importance of this measure in the performance of the EP. They show that matrices with spikier spectrums are better for EP, while in 1 - bit compressed sensing problems, less spiky ( flatter ) spectrums offer better recoveries."
SP:ee66604d4da9fd04826e90ccbb94f0499eba4c63,"This paper proposes a new method for generalized zero - shot learning ( GZSL ) that addresses the domain shift problem by progressively improving cross - domain transferability and category discriminability of visual representations. The proposed Dual Progressive Prototype Network ( DPPN ) constructs two types of prototypes that record prototypical visual patterns for attributes and categories, respectively. With attribute prototypes, the network alternately searches attribute - related local regions and updates corresponding attribute prototypes to progressively explore accurate attribute - region correspondence. The category prototypes are learned collaboratively in a unifed framework, which makes visual representations of both attribute and category prototypes more coherent and distinctive. Experiments on four benchmarks demonstrate the effectiveness of the proposed method."
SP:61eb6297568c3f6869fbb03eaf6a21260de5466c,"This paper presents an end - to - end deep learning approach for removing defocus blur from a single image, so as to have an all - in - focus image for consequent vision tasks. A pixel - wise Gaussian kernel mixture ( GKM ) model is proposed for representing spatially variant defocus blurs in an efficient linear parametric form. Then, a deep neural network called GKKMNet is developed by unrolling a fixed - point iteration of the GkM - based deblurring. Extensive experiments show that the proposed method not only noticeably outperforms existing defocus deburring methods, but also has its advantages in terms of model complexity and computational efficiency."
SP:18bf447c90935c373e5ec4cdfbbf8f2a273d2edb,"This paper proposes a self - supervised video representation learning ( SSVRL ) method that exploits compressed videos and captures mutual information between two input streams. Specifically, a motion vector based Cross - Guidance Contrastive learning approach ( MVCGC ) is proposed to directly decode RGB frames and motion vectors from compressed videos on - the - fly. To enhance the representation ability of the motion vectors, the authors design a cross guidance contrastive learning algorithm based on on InfoNCE loss, where motion vectors can take supervision signals from RGB frames as input and motion signals from motion vectors as output. The experimental results show that the proposed method is state of the art while being significantly more efficient than its competitors."
SP:8c7b1d976d9758cd534c565ec31a23f97892e503,"This paper proposes a Bayesian treatment to mitigate overconfidence in ReLU - based Bayesian neural networks ( BNNs ) that are asymptotically overconfident near the training data, but not far away from them. The authors propose to use Gaussian processes ( GP ) instead of ReLU features in the infinite - width limit of a BNN to mitigate this overconfidence issue. They show that the GP - based overconfidence mitigation can be applied post - hoc to any pre - trained ReLU BNN at a low cost. They also show that this approach can be used in practice to improve the predictive power of finite ReLU neural networks."
SP:e77276f61626e896f6a985296f1d832129242cdf,"This paper considers the problem of selecting a formula for identifying a causal quantity of interest among a set of available formulas. The authors assume a sequential setting in which the investigator may alter the data collection mechanism in a data - dependent way with the aim of identifying the formula with lowest asymptotic variance in as few samples as possible. They formalize this setting by the bestarm - identification bandit framework where the standard goal is replaced with the goal of learning the arm that will produce the best estimate. They introduce new tools for constructing finite - sample confidence bounds on estimates of the asymPTotic variance that account for the estimation of potentially complex nuisance functions, and adapt the best - arm - identification algorithms of LUCB and Successive Elimination to use these bounds. They validate their method by providing upper bounds on the sample complexity and an empirical study on artificially generated data."
SP:471361588bfc6c6033631509d1e43e77fd9721ce,"This paper studies the communication cost of stochastic gradient descent in distributed learning and proposes a new algorithm ErrorCompensatedX that uses the compression error from the previous two steps of an existing variance reduced algorithm. The authors show that adding back the previous step ’s compression error is not enough to compensate for the bias caused by the compression. To this end, the authors propose to use the full compression error and provide a unified theoretical analysis for this class of variance reduced algorithms, with or without error compensation. They show that the proposed algorithm can achieve the same convergence rate as the one achieved with the training error added and without compression.  "
SP:3b7ff0dc668cac2191d95fcc4dc6e0335dec3206,"This paper proposes a new approach to explainability in graph neural networks ( GNNs ). The approach is based on two phases : ( 1 ) global explainability, which systematizes the globally important patterns, and ( 2 ) local explainability. In the first phase, a global explainer is used to explain the global patterns, while in the second phase a local explainer adapts the explanations in the local context. The proposed approach is evaluated on both synthetic and real - world datasets. The results show the superiority of the proposed approach in terms of AUC on explaining graph classification over the leading baselines."
SP:9b5a62d3a2b27bc60da28980e9fb0ecdff1215c0,"This paper proposes a new method for generating counterfactual explanations for graph neural networks ( GNNs ) that are robust to noise. The main idea is to model the common decision logic of a GNN and use it to generate an explanation that is robust to the noise in the input graph. This is different from existing methods that generate explanations by identifying a subgraph of an input graph that has a strong correlation with the prediction. The authors argue that existing methods do not do this because they can easily overfit the noise, and also because removing an identified subgraph does not necessarily change the prediction result. To address these issues, the authors propose a novel method that generates an explanation from the subgraphs of input graphs by explicitly modelling the decision boundaries of the GNN. The proposed method is shown to outperform existing methods on several public datasets."
SP:4edb870786c9cea2c6075359cb4e79b02a8e2f5f,This paper proposes a method to learn a discriminator for voice synthesis that preserves content and voice style from source speech. The discriminator is decomposed into content and style discriminator with self - supervised representation learning and adversarial feedback. Experiments show that the proposed method achieves better generalization to the voice style of the converted speech compared to previous methods.  
SP:9fbb0c6beb3f8f88972f13dcf0e1fe7db03233c7,This paper proposes a Siamese shape - aware feature learning network and a voxel - to - BEV target localization network for sparse 3.3D object tracking in point clouds. The shape is learned by the Siameses on the 2D and z - axis of the point cloud. The target is identified by the voxels on the BEV feature map. The proposed method is evaluated on KITTI and nuScenes datasets and shows superior performance.
SP:8b788c78680a54c453a04f4551436763ee57585e,"This paper proposes a Fourier feature encoding method for multi - dimensional positional encoding in attention - based deep models such as Transformer. The method is based on learnable Fourier features that are modulated by a multi - layer perceptron. The Fourier representation is particularly advantageous for a spatial multi -dimensional position, where L2 distances or more complex positional relationships need to be captured. Experiments on several public benchmark tasks show that the proposed method outperforms existing methods by both improving the accuracy and allowing faster convergence."
SP:d2ac1b6381315bce4449f09bd519f33a2a42d714,"This paper considers the problem of learning the causal MAG of a system from observational data in the presence of latent variables and selection bias. Constraint - based methods are one of the main approaches for solving this problem, but the existing methods are either computationally impractical when dealing with large graphs or lacking completeness guarantees. This paper proposes a novel computationally efficient recursive constraint - based method that is sound and complete. The key idea of the approach is that at each iteration a specific type of variable is identified and removed. This allows us to learn the structure efficiently and recursively, as this technique reduces both the number of required conditional independence ( CI ) tests and the size of the conditioning sets. The former substantially reduces the computational complexity, while the latter results in more reliable CI tests.   The authors provide an upper bound on the required CI tests in the worst case. They further provide a lower bound. The upper bound of our proposed approach and the lower bound at most differ by a factor equal to $ O(1/\epsilon^{-1})$ for the worst cases. The experimental results to compare the proposed approach with the state - of - the - art on both synthetic and real - world structures on both real and synthetic datasets have been provided."
SP:49a4912ce457f5f5ec62c44fa10444af8075fabf,"This paper proposes a dynamic Thompson sampling framework for stochastic multi - arm bandit and linear contextual bandit with finitely many arms. The proposed dynamic Thompson Sampling framework dynamically determines the duration of each batch in order to balance the exploration - exploitation trade - off. The authors show that dynamic batch allocation achieves the same ( asymptotic ) regret bound of a fully sequential one while carrying out only O(log T ) batch queries. The dynamic batch policy is shown to have exponential reduction, reducing the number of interactions from T to O(Log T ).   The authors also demonstrate experimentally that dynamic batches allocation dramatically outperforms natural baselines."
SP:653a519e3c799c25e0d0b4240322642040b121a3,This paper studies the problem of learning domain - invariant representations in multi - source DA and domain generalization. The main contributions of this paper are two - fold : 1. It develops novel upper - bounds for the target general loss in terms of two kinds of domain invariant representation. 2. It studies the pros and cons of enforcing learning each domain - invariant representation and the trade - off between enforcing and learning them. The paper also conducts experiments to inspect the trade off of these representations for offering practical hints regarding how to use them in practice and explore other interesting properties of our developed theory.
SP:2a7bee950cd07494d59dfee60ac2e86cc0e481b1," super - resolution ( SR ) networks have obtained promising results with moderate model size. However, it is hard to be applied to SR networks directly, because filter pruning for residual blocks is well - known tricky. To address the above issues, this paper proposes aligned structured sparsity learning ( ASSL ), which introduces a weight normalization layer and applies L2 regularization to the scale parameters for sparsity. This paper also proposes a sparsity structure alignment penalty term, which minimizes the structure alignment penalties across different layers. ASSL achieves superior performance gains over recent methods quantitatively and visually."
SP:e9830bb9e7d3ddc3bd1c2994590fdb5d8f3668be,"This paper proposes an intrinsic reward for exploration in deep multi - agent reinforcement learning ( MARL ) based on the insight that individual Q - values induced by agents ’ utility functions are the embeddings of local action histories and can capture the interaction between agents due to reward backpropagation during centralized training. The proposed intrinsic reward encourages the agents to explore informative local experiences via prediction errors of individual Q values and utilize episodic memory to exploit explored informative experiences to boost policy training. Empirically, the authors demonstrate the advantages of the proposed method by didactic examples, and demonstrate its significant outperformance over state - of - the - art MARL on challenging tasks in the StarCraft II."
SP:c7e33d479575c88e22282ee6fd4f978bcd3c06ed,"This paper studies the problem of list - decodable linear regression, where an adversary can corrupt a majority of the examples. The goal is to output a small list of hypothesis vectors such that at least one of them is close to the target regression vector. The main result is a Statistical Query ( SQ ) lower bound of d for this problem. The SQ lower bound qualitatively matches the performance of previously developed algorithms, providing evidence that current upper bounds for this task are nearly best possible."
SP:7b258252a9063514348f5fa8d9c85afd85748747,"This paper proposes a model for predicting the patient health status and disease progression over time using a system of expert - designed ODEs with machine - learned machine learning ( MLE ). The proposed model is based on the Latent Hybridisation Model ( LHM ), which integrates the expert and latent variables in the system of differential equations of Ordinary Differential Equations (ODEs ). This model is evaluated on synthetic data as well as real - world intensive care data of COVID - 19 patients. The empirical results show that the proposed model consistently outperforms previous works."
SP:3ea9e86e5755ef84d28e3163c60531ace5d62e3a,"This paper studies the problem of few - shot learning in the context of meta - learning, where the goal is to learn task - specific representation for each new task by finding an initial representation requiring minimal per - task adaptation ( i.e. a fine - tuning - based objective ). The authors present a theoretical framework for analyzing a MAML - like algorithm, assuming all available tasks require approximately the same representation. They then provide risk bounds on predictors found by finetuning via gradient descent, demonstrating that the method provably leverages the shared structure. They illustrate these bounds in the logistic regression and neural network settings. In contrast, the authors establish settings where learning one representation for all tasks (i.e. using a “ frozen representation ” objective ) fails. Notably, any such algorithm can not outperform directly learning the target task with no other information, in the setting where no training data is available."
SP:8ba5a2ac80f7c53f81ad008e96c033ecad14ac0d,"This paper proposes a method for learning a compositional and grounded meaning representation of language from grounded data, such as paired images and texts. The method, called G2L2, maps each word to a syntactic type and a neuro - symbolic semantic program, which is then used to learn compositional meaning representations. To facilitate learning in an exponentially growing compositional space, the authors introduce a joint parsing and expected execution algorithm, which does local marginalization over derivations to reduce the training time. The proposed method is evaluated on two domains : visual reasoning and language - driven navigation. The results show that G22 can generalize from small amounts of data to novel compositions of words, and that it generalizes well to novel syntactic types."
SP:16c458651815813efdcbe8ba1205bbddbe3e4e68,"This paper proposes a stochastic Newton algorithm for homogeneous distributed stochastically convex optimization. In this setting, each machine can calculate its own gradient for the same population objective. The authors show that their method can reduce the number, and frequency, of required communication rounds compared to existing methods without hurting performance, by proving convergence guarantees for quasi - self - concordant objectives ( e.g., logistic regression ). They also provide empirical evidence for their method."
SP:d7e479d59f82d4c55372a68ca7b4516f2871f346,"This paper proposes a density - aware distance ( DCD ) based on Chamfer distance ( CD ) and Earth Mover's Distance ( EMD ) to measure the similarity between two point clouds. The authors claim that CD is insensitive to mismatched local density and EMD is usually dominated by global distribution while overlooks the fidelity of detailed structures. DCD is more sensitive to disparity of density distributions and is stricter with detailed structures and significantly more computationally efficient than EMD. In addition, the authors propose a novel point discriminator module that estimates the priority for another guided downsampling step, and it achieves noticeable improvements under DCD together with competitive results for both CD and E MD."
SP:e4b302009520770814ff2c096020b779a9fc38fe,"This paper studies the relationship between knowledge distillation and the discrepancy between the predictive distributions of the teacher and the student. The authors show that there often remains a surprisingly large discrepancy, even in cases when the student has the capacity to perfectly match the teacher. They identify difficulties in optimization as a key reason for why the student is unable to match the teachers. They also show how the details of the dataset play a role in how closely the student matches the teacher — and that more closely matching the teacher paradoxically does not always lead to better student generalization."
SP:895c7e03f9e4dadb94be1f39d61bf0b5e1533f4f,"This paper proposes coresets for k - decision trees, which is a recursive partition of a matrix ( 2D - signal ) into k+1 block matrices ( axis - parallel rectangles, leaves ), where each rectangle is assigned a real label. The regression or classification loss to a given matrix D of N entries ( labels ) is the sum of squared differences over every label in D and its assigned label by t. This paper provides a small summarization that approximates this loss to every such tree, up to a multiplicative factor of 1/\sqrt{1 + \� }. The optimal k - tree of C is a ( 1+\�)-approximation to the optimal k tree of D up to 1 / \sqrt{\frac{1}{\varepsilon }. Experimental results on sklearn and lightGBM show that applying coresets on real - world data - sets boosts the computation time of random forests and their parameter tuning by up to x10 % while keeping similar accuracy."
SP:f3ece96b15ec06d703925df2061ed9694ec3bca5,"This paper studies the identification of m arms with largest means under a fixed error rate $ \delta$ ( fixed - confidence Top - m identification ), for misspecified linear bandit models. This problem is motivated by practical applications, especially in medicine and recommendation systems, where linear models are popular due to their simplicity and the existence of efficient algorithms, but in which data inevitably deviates from linearity. In this work, the authors first derive a tractable lower bound on the sample complexity of any $ \�$-correct algorithm for the general Top-m identification problem. They then describe the first algorithm for this setting, which is both practical and adapts to the amount of misspecification. Finally, the algorithm is evaluated on both synthetic and real - world data, showing competitive performance with respect to existing baselines."
SP:e71c5e39b8d8d1640d6de2352ac51ddd52eea89d,"This paper proposes a self - supervised method for learning disentangled graph representations from graph neural networks ( GNNs ). The key idea is to learn graph - level representations with a contrastive learning method, which is able to disentangle the latent factors of the graph. The method is motivated by the fact that the graph typically arises from a complex interaction of many latent factors and the existing methods for GNN learning neglect the entanglement of these latent factors, resulting in the learned representations being suboptimal for downstream tasks and difficult to be interpreted. To this end, the authors propose a novel factor - wise learning manner, which can force the factorized representations to independently reflect the expressive information from different latent factors. Extensive experiments demonstrate the superiority of the method against several state - of - the - art baselines."
SP:0a7edbbdabab11273689c40c517001eb46491113,"This paper studies the problem of quantifying the robustness of a trained neural network to input uncertainties using stochastic simulation. The main idea is to consider the network as a statistical hypothesis test, where the network is considered to be robust if the estimated probability of failure is lower than a critical level. The authors derive theoretical guarantees that are nonasymptotic w.r.t. sample size. Theoretical analysis is based on an Importance Splitting simulation generating samples of rare events. Experiments tackling large scale networks outline the efficiency of the method making a low number of calls to the network function."
SP:c1db485ff1ff9573daa421e167225654babb55ac,"This paper proposes a conditional generative modeling framework based on deep polynomial neural networks ( PNNs ) for two - variable inputs, i.e., the noise variable and the conditional variable. The proposed framework, called CoPE, enables a polynomials expansion of two input variables and captures their auto - and cross - relations. The authors show how CoPE can be trivially augmented to accept an arbitrary number of input variables in five tasks ( class - conditional generation, image - to - image translation, attribute - guided generation, attributeguided generation, and super - resolution generation ). The thorough evaluation suggests that the proposed framework can be useful for tackling diverse conditional generation tasks."
SP:5a75bc7a3ea0ce971cfceebbc1c2434e3aa2584d,"This paper proposes a two - sample test for neural tangent kernel ( NTK ) and maximum mean discrepancy ( MMD ) statistics. Theoretically, the authors show a connection between NTK and MMD, which is used to explain the Type - I error and testing power of the two sample test. The proposed method is computationally efficient and memory - efficient, and can be used for online implementation. Experiments on synthetic and real - world datasets validate the theory and demonstrate the effectiveness of the proposed method."
SP:1df2ffbbe56b8018067820980b93af2a8b57f891,"This paper proposes a class - disentanglement method to extract class - dependent information from the input space of a neural network. The main idea is to train a variational autoencoder ( VAE ) to decompose an input image into a set of sub - images, where the former is reconstructed by the VAE and the latter is used to extract the necessary information for classification. The paper applies the proposed method to both clean and adversarial images and shows that the former decomposes the input image in a way that the latter retains only necessary information. Based on this observation, the paper proposes two methods for adversarial detection and defense of adversarial attacks. The adversarial defense method is shown to outperform the original adversarial results on the original image while the detection method outperforms the original results on clean images. The proposed method also provides novel interpretations to classification and attack models."
SP:2789874561620ba7894c4672f935056bb911e919,"This paper proposes a differentially private federated Thompson sampling ( FTS ) algorithm for Bayesian optimization ( BO ) in federated learning ( FL ) setting. The proposed algorithm is based on the differential privacy ( DP ) framework for adding DP to iterative algorithms, and integrates DP into FTS to preserve user - level privacy. The authors also leverage the ability of this general DP framework to handle different parameter vectors, as well as the technique of local modeling for BO, to further improve the utility of our algorithm through distributed exploration ( DE ). The resulting DP - FTS - DE algorithm is endowed with theoretical guarantees for both the privacy and utility and is amenable to interesting theoretical insights about the privacy - utility trade - off. Experiments on real - world experiments show that the proposed algorithm achieves a high utility with a strong privacy guarantee ( small privacy loss ) and induces a trade-off between privacy and privacy."
SP:be7d6b81736a2c3f89abd8771b41b18802e88832,"This paper proposes a Gaussian process - Bayesian Bernoulli mixture model ( GP - BM ) for active learning in multi - label active learning ( AL ), where the goal is to accurately quantify a data sample ’s overall contribution to a correlated label space and choose the most informative samples for cost - effective data sampling. The BM encodes label correlations using a Bayesian neural network and outputs a predictive distribution that provides both the label prediction and their correlations in the form of a label covariance matrix. The GP predicts coefficients of mixture components that help to recover the final set of labels and a variational inference algorithm is developed to tackle the non - conjugacy introduced along with the mapping process for efficient end - to - end posterior inference. Experiments on real - world multi - labeled datasets demonstrate the state - of - the - art AL performance of the proposed model."
SP:2b7270b0370c193300bcbbb5fb0a4101b3329d99,This paper proposes to use a polar coordinate system for end - to - end latency reduction in streaming - based lidar perception models. The proposed method uses multi - scale padding from neighboring sectors of a point cloud to increase spatial context and improves the core polar convolutional architecture by introducing feature undistortion and range stratification. The experimental results on the nuScenes dataset show significant improvements over other streaming based methods.
SP:7ae2c5b7d9c8a6c8f4a353606aa419929c47f31b,"This paper proposes to use stochastic invariant score function estimators for structured latent variable models. The main idea is to extend the Gumbel - Max trick to define distributions over structured domains. In particular, the authors highlight a family of recursive algorithms with a common feature. The authors claim that this feature allows them to construct reliable gradient estimates and control variates without additional constraints on the model. In the experiments, they consider various structured latent variables models and achieve results competitive with competitive with relaxation - based counterparts."
SP:415d363c66a6967c1daca9dc02001b85bf7f0752,"This paper proposes a method to adaptively and selectively fine - tune CNNs for image denoising. The method is based on a pre - trained CNN model on synthetic data that is able to faithfully reconstruct the structure of catalytic nanoparticles at extremely low signal - to - noise ratios. To avoid overfitting, the method optimizes a single multiplicative scaling parameter ( the GainTuning ) of each channel in the convolutional layers of the CNNs on the synthetic data. Experiments show that the proposed method can boost the performance of the denoiser on nearly every image in a held - out test set, even for test images differing systematically from the training data, either in noise level or image type."
SP:90afa1102683b456bc72a54abef466326827546a,"This paper proposes a fully differentiable architecture for simultaneous semantic and instance segmentation ( a.k.a panoptic segmentation ). The proposed architecture consists of a convolutional neural network and an asymmetric multi - way cut problem solver. The latter solves a combinatorial optimization problem that elegantly incorporates semantic and boundary predictions to produce a pan - optic labeling. The formulation allows to directly maximize a smooth surrogate of the quality metric by backpropagating the gradient through the optimization problem w.r.t. the objective function. Experimental evaluation on Cityscapes and COCO datasets shows the effectiveness of the proposed method. Overall, this paper shows the utility of using optimization in tandem with deep learning in a challenging large scale real - world problem and showcases benefits and insights into training such an architecture."
SP:1952e174d9ec7b83ad1d394ece7fe77ea1f6d78d,"This paper proposes Recursive Bayesian Networks ( RBNs ), which generalize and unify PCFGs and DBNs, combining their strengths and combining the strengths of both as special cases. The RBN allows for continuous latent variables, which is not possible in dynamic Bayesian networks. The authors also derive an analytic approximation of the marginal data likelihood ( evidence ) and marginal posterior distribution, allowing for robust parameter optimisation and Bayesian inference. The capacity and diverse applications of RBN are illustrated on two examples : ( 1 ) synthetic data for segmentation and tree induction from noisy sequences, and ( 2 ) hierarchical music analysis from the raw note level."
SP:5f29b169d3e4bbaeeec85e1aeebe2094fae4be6e,"This paper proposes a constrained backpropagation ( CBP ) algorithm based on the pseudo - Lagrange multiplier method to obtain the optimal set of weights that satisfy a given set of constraints. The defining characteristic of the proposed CBP algorithm is the utilization of a Lagrangian function ( loss function plus constraint function ) as its objective function. The proposed algorithm outperforms the state - of - the - art methods on ImageNet, e.g., with binary weights."
SP:3ddf8e2e108fb261bb23aec8a27a25aba7523dc1,"This paper studies active learning for Gaussian Process Classification ( GPC ) in discrete and continuous instance space. The existing active learning strategies that maximize the Estimated Error Reduction ( EER ) aim at reducing the classification error after training with the new acquired instance in a onestep - look - ahead manner. The computation of EER - based acquisition functions is typically prohibitive as it requires retraining the GPC with every new query, and it can not be combined with gradient - based optimization techniques to efficiently explore the continuous instances space for query synthesis. To overcome these critical limitations, the authors propose an efficient EER based active learning algorithm for GPC that combines the joint predictive distribution of label pairs as a one - dimensional integral, and derive the gradient chain rule to efficiently calculate the gradient of the acquisition function, which leads to the first query synthesis active learning ( JSAL ) algorithm implemented by the proposed algorithm. Experiments on both synthetic and real - world datasets demonstrate the computational efficiency of the proposed algorithms."
SP:fa1fac04cd4ccb1f3eaf80807db09f9683ce6b50,"This paper studies the effect of unbounded parameter gradients on the training of continuous VAE models. The authors propose a new energy function for the variational autoencoder ( VAE ) model with infinite gradients, which they call the over - and under - regularized energy function. They show that under this setting, both over - regularization ( both with and without the under regularization setting ) and sub - optimal feature selection can lead to poor sample quality and suboptimal feature selection, respectively. They conclude that unbounded gradients in the energy function of the VAE model may lead to ill - advised heuristics, and large gradients should be accommodated."
SP:2611cfd6e0696a57d061687993cef1fe5c95999d,"This paper studies the bandit problem with graph feedback in the setting of a directed graph $ G$ where $ V$ is the collection of bandit arms and $ E$ are the incident arms. The authors propose two notions of the fractional weak domination number $ \delta$ and the k - packing independence number $ k$ for the regret. They show that the two notions are inherently connected via aligning them with the linear program of the weakly dominating set and its dual, and utilize the strong duality theorem to prove a general regret upper bound and a lower bound. They also show that for several special families of graphs with bounded degree, one can get rid of the $ \log \V^{3}$ factor and establish optimal regret."
SP:e50dec57af337839cbde4b65fb7b431785fda44d,"This paper proposes Neighbourhood Shapley values ( NSH ) for model agnostic feature attributions for model outcome at a particular instance by simulating feature absence under a global population distribution. The authors argue that the use of global population can lead to potentially misleading results when local model behaviour is of interest, hence they consider the formulation of neighbourhood reference distributions that improve the local interpretability of Shapley value. By doing so, they find that the Nadaraya - Watson kernel regressor can be expressed as a self - normalised importance sampling estimator. Empirically, they observe that NSHs identify meaningful sparse feature relevance attributions that provide insight into local model behavior. They also increase on - - manifold explainability and robustness to the construction of adversarial classifiers."
SP:35bdeb78f9fe74e754177fb54b48e7399dc8590d,"This paper proposes a method for generating cycle - consistent virtual state - action sequences to improve the data efficiency of deep reinforcement learning ( RL ). The proposed method is based on a dynamics model that predicts future states in a latent space based on the current state and action, and a trajectory cycle predictor that predicts the previous states by a backward dynamics model. The authors augment the actions to generate a trajectory to meet the cycle consistency constraint, which can significantly enhance the training data efficiency. They validate the effectiveness of the proposed method on the Atari and DeepMind Control Benchmarks."
SP:ca09e472cbcf2ac8c8c9b192a87df2ed59218210,"This paper proposes a new framework for analyzing the robustness of deep neural networks to noisy labels. The framework is based on the observation that the predictive power of a linear model trained on a small set of clean labels is a function of the alignment of the network's architecture with target / noise functions. The paper shows that a network is more robust to noise if its architecture is more aligned with the target function than the noise. The authors provide both theoretical and empirical evidence to support their hypothesis. In particular, they show that when the network is well - aligned with target function, its predictive power in representations could improve upon noisy - label - training methods in terms of test accuracy and outperform more sophisticated methods that use clean labels."
SP:903727fe028684623a8ccadec210e641ecffc685,"This paper proposes a new method for learning reward functions for tasks that require specifying tasks by providing examples of successful outcomes. The key idea is to learn a reward function directly from transitions and successful outcomes, without learning an intermediate reward function. The authors propose a control algorithm that maximizes the future probability of these successful outcome examples. They show that their method satisfies a new data - driven Bellman equation, where examples take the place of the typical reward function term in the reward function learning process."
SP:39ccbd5909a1d7ed212fe92d8d6843c2c70dfe1f,"This paper studies differentially private stochastic optimization in convex and non - convex settings. For the convex case, the authors focus on the family of non - smooth generalized linear losses ( GLLs ). Their algorithm for the l2 setting achieves optimal excess population risk in near - linear time, while the best known differentially public algorithms for general convex losses run in superlinear time. The algorithm for l1 setting has nearly - optimal excess risk, and circumvents the dimension dependent lower bound of [ AFKT21 ] for general non - smoothed convex loss. In the lp setting, they also extend all the results above for the non - smoother l_2 setting to the l_p setting with only polylogarithmic overhead in the rates. Finally, they provide the first method for non - Smoothly Convex ( NCC ) optimization with rate $ O(1 n/4 + d 1/6)$, which matches the best existing non - private algorithm."
SP:99a476f71e6901aefe281f11fb72ff78265a5b6e,"This paper studies cooperative bandit learning under three scenarios : stochastic message - passing over stochastically - varying networks, instantaneous reward sharing over a network with random delays, and adversarially - corrupted rewards. In each of these scenarios, the authors propose decentralized algorithms that achieve competitive performance, along with near - optimal guarantees on the incurred group regret as well as an improved delayed - update algorithm that outperforms the existing state - of - the - art on various network topologies. The authors also present tight network - dependent minimax lower bounds on the group regret. The proposed algorithms are straightforward to implement and obtain competitive empirical performance."
SP:d3e896a65470f2439bc7753b4f66e152306b2d6f,"This paper proposes a post - training quantization algorithm for vision transformers to reduce the memory storage and computational costs. The quantization task can be regarded as finding the optimal low - bit quantization intervals for weights and inputs, respectively. To preserve the functionality of the attention mechanism, the authors introduce a ranking loss into the conventional quantization objective that aims to keep the relative order of the self - attention results after quantization. Moreover, they thoroughly analyze the relationship between quantization loss of different layers and the feature diversity, and explore a mixedprecision quantization scheme by exploiting the quantization strategy of exploiting the diversity in the feature distribution. The effectiveness of the proposed method is verified on several benchmark datasets and datasets."
SP:aa6b1328585b5916267a3ff4f9119e7aa4ce2bb5,"This paper studies the convergence of double - Q learning with a constant learning rate. The main contributions of the paper are two - fold :    1. The authors propose a new analysis method for synchronous double Q - learning, which improves the results of ( Xiong et al., 2020 ) by an order of magnitude in terms of its dependence on all major parameters.   2. They provide a time complexity analysis of the double Q learning algorithm with a global optimum with a complexity of $ \tilde{O}(\tilde{\Omega_\gamma)$, where $ \gamma$ is the discount factor and $ L$ is a parameter related to the sampling strategy for asynchronous double - q learning. The analysis shows that the synchronous algorithm converges faster than the asynchronous algorithm, but at the same time, the global convergence rate is the same as the one of ( Yoon et al, 2019 )."
SP:04fd4d83717c4f7e1a4b5651a59200151f33411d,This paper proposes a method for out - of - distribution ( OOD ) detection in semi - supervised learning settings. The main challenges in this setting are i ) lack of labeled data and ii ) OOD samples could be unseen during training. The authors present an approach called STEP that learns a new structure - keep - unzipping ( STU ) algorithm for OOD detection by introducing a new technique : Structure - Keep - Unzipping. The proposed method is evaluated on two OOD benchmarks and compared with other SSL methods.  
SP:6bf8b94483b26033795b0eda9649518027f5e1c2,"This paper proposes a one - stage multi - task framework for visual grounding tasks. Specifically, it leverage a transformer architecture, where two modalities are fused in a visual - linguistic encoder and decoder. In the decoder, the model learns to generate contextualized lingual queries which are then decoded and used to directly regress the bounding box and produce a segmentation mask for the corresponding referred regions. Experiments show that the proposed method outperforms state - of - the - art methods on both REC and RES tasks. The authors also show that a simple pre - training schedule ( on an external dataset ) further improves the performance. Extensive experiments and ablations illustrate that the model benefits greatly from contextualized information and multi -task training."
SP:29b552b36696c9bda72f3ab4f31605d98880fd6b,"This paper studies the problem of multiclass boosting in the setting where the weak learner is an agnostic PAC learner for a class and the goal is to learn a combination of weak hypotheses by repeatedly calling the strong learner.    The paper focuses on an especially natural formulation in which the weak hypotheses are assumed to belong to an easy - to - learn base class, and the weak learners are agnostic to the standard classification loss with respect to that class. The goal of the overall boosting algorithm is then to learn   a combination   of weak hypothesis by repeatedly   calling the   weak learners. The paper also study the resources required for boosting, especially how they depend on the number of classes, and show that the weak - learner ’s accuracy parameter must be smaller than an inverse polynomial in k, showing that the returned weak hypotheses must be nearly the best in their class when k is large, and also prove a trade - off between number of oracle calls and resources required."
SP:f63b050773871338c48b778c362172e4b72477a4,"This paper proposes a method for unsupervised image segmentation and object - centric scene generation based on clustering object embeddings in a differentiable fashion using a stochastic stick - breaking process. The clustering procedure also leads to randomly ordered object representations, but without the need of initialising a fixed number of object representations. This is used to develop a new model, GENESIS - V2, which can infer a variable number of objects without using RNNs or iterative refinement. Experiments show that the proposed method outperforms the baselines in terms of both object segmentation performance and the quality of scene generation on established synthetic datasets."
SP:408deb9e5577ee7118b836fee77135df641fe545,"This paper studies the problem of online point - wise conformal inference, where the data generating distribution is allowed to vary over time in an unknown fashion. The authors propose an adaptive approach that achieves the coverage frequency over long - time intervals irrespective of the true data generating process by modelling the distribution shift as a learning problem in a single parameter whose optimal value is varying over time and must be continuously re -estestestered. The proposed method is a general wrapper that can be combined with any black - box method that produces point predictions of the unseen label or estimated quantiles of its distribution.   The authors test their method on two real world datasets and find that its predictions are robust to visible and significant distribution shifts."
SP:e6e5b1e2428abcf1a163ec1cce15cd299f9a544f,"This paper proposes a pose estimation method for multi - person pose estimation in crowded scenes that is free of bounding box detection and keypoint grouping. The proposed method, PINet, first applies the Part - based Pose Generation ( PPG ) module to infer multiple coarse poses for each person from his / her body parts. Those coarse poses are refined by the Pose Refinement module through incorporating pose priors, and finally are fused in the Pose Fusion module. Experiments on several crowded scenes pose estimation benchmarks demonstrate the superiority of PINet."
SP:e76f048c3dccffcb8bcc6a66f6165fc19d175610,This paper studies the Bellman operator for S - Rectangular robust Markov decision processes ( RMDPs ) with L_\infty - unconstrained rectangular ambiguity sets. The authors propose a homotopy continuation method with a bisection method to solve S - rectangular ambiguity in quasi - linear time in the number of states and actions. The algorithm improves on the cubic time required by leading general linear programming methods. The experimental results show that the proposed method outperforms a leading commercial optimization package by several orders of magnitude.
SP:c4af66a64a5c2bd58ca2e29dbc4b27d5bf4b63b8,This paper studies the use of machine - learned predictions to improve the worst - case guarantees of online algorithms for online knapsack problem with very weak predictions. The paper systematically derives online algorithms that attain the best possible competitive ratio for any fixed prediction and extends the results to more general settings such as generalized one - way trading and two - stage online knapack. The results show that even seemingly weak predictions can be utilized effectively to provably improve the performance of online algorithm.    The main contributions of this paper are :   1. Theoretical analysis of the competitive ratio between two online algorithms. 2. Theorems on how to use weak predictions for online algorithms in the case of a generalized one way trading problem. 3. A systematic analysis of how to apply weak predictions to two stage online kappa - packing.
SP:1d478d4fa3f5df0ded963ef164325667fd744dbb,This paper proposes a model - based episodic memory of trajectories to improve the sample efficiency of episodic control. The main idea is to learn a trajectory embedding of past trajectories and use this embedding to guide the agent towards good policies. The paper also proposes a complementary learning model for episodic and regularized learning. The proposed method is evaluated on a variety of environments including stochastic and non - Markovian settings. Results show that the proposed method outperforms other strong RL agents.
SP:551174c1266b5f4b6aaf5432a4c713386f90898c,"This paper proposes a new semi - supervised learning method ( DP - SSL ) for unlabeled data by generating probabilistic labels from noisy pseudo labels. The proposed method is based on data programming ( DP ), where a label model is used to generate noisy labels from the pseudo labels generated by the self - supervised pseudo label generator. The method is evaluated on four standard SSL benchmarks and achieves better performance than existing SSL methods, especially when only a small number of labeled samples are available."
SP:d1d6a40a8bde62a21da4fc18a076e344c84ab0d0,"This paper proposes a multi - view pose transformer ( MVP ) model for estimating multi - person 3D poses from multi - views images. The proposed method is based on a hierarchical scheme to represent query embeddings for skeleton joints and introduces an inputdependent query adaptation approach for efficient estimation. The method achieves 92.3 % AP25 on the challenging Panoptic dataset, improving upon the previous best approach [ 40 ] by 9.8 %.   The main contributions of this paper are as follows :   1. MVP represents skeleton joints as learnable query embedding and let them progressively attend to and reason over the multi - viewed information from the input images to directly regress the actual 3D joint locations. 2. A hierarchical scheme is proposed to concisely represent queries of multi - body skeleton joints. 3. A RayConv operation to integrate the view - dependent camera geometry into the feature representations for augmenting the projective attention is also introduced. The experimental results show that the proposed method outperforms the state - of - the - art methods on several benchmarks while being much more efficient."
SP:2e147bd5321e25bb27d2531fd58c46460a1e5320,"This paper considers the problem of learning sparse supports of unknown sparse vectors from a fixed family of sparse vectors. The support recovery problem is formulated as a 1 - bit compressed sensing problem, where each vector in the family has at most k non - zero elements, and the goal is to reconstruct the supports of all vectors from the family using the sign of the inner product between the query vector and the response vector. The second problem is to design queries such that the sparse vectors can be approximately reconstructed based on the error - free responses of the queries. The problem is posed as a generalization of support recovery and approximate recovery problems, and these problems can be seen as generalizations of the previous work of Gandikota et al. 2020. The authors prove the existence of learning algorithms for the first problem which work without any assumptions on the unknown vectors. They also show the existence and the performance of two learning algorithms on the second problem."
SP:e3388e479a825be429f3a878e2c4d8b05903ff10,"This paper studies the problem of bandit quickest changepoint detection, where sensing actions ( or sensors ) are sequentially chosen, and only measurements corresponding to chosen actions are observed. The authors first derive an information - theoretic lower bound on the detection delay for a general class of finitely parameterized probability distributions. Then they propose a computationally efficient online sensing scheme that seamlessly balances the need for exploration of different sensing options with exploitation of querying informative actions. They derive expected delay bounds for the proposed scheme and show that these bounds match the information - theoretic lower bounds at low false alarm rates. They then perform a number of experiments on synthetic and real datasets demonstrating the effectiveness of the proposed method."
SP:268260e9452ba2bc57e50a6b7b3328233137ac9b,"This paper proposes a unified SGD - type algorithm for stochastic bilevel, min - max, and compositional nested problems. The three problems share a nested structure, but existing works often treat them separately, thus developing problem - specific algorithms and analyses. This paper unifies several SGD-type updates for stochiastic nested problems into a single SGD approach that they term ALternating Stochastic Gradient dEscenT ( ALSET ) method. By leveraging the hidden smoothness of the problem, this paper presents a tighter analysis of ALSET for stochedastic gradient descent - type algorithms in stochedicated nested problems, which improves or matches the best - known sample complexity in the respective cases. The authors also explain why simple SGD type algorithms for the three problems all work well in practice without the need for further modifications."
SP:82ad52361bc5b2c421f1dc6b76e1a5520570fc6c,"This paper proposes a Siamese sampling and reasoning method for video question answering ( VQA ). The key idea is to generate sparse and similar clips from the same video using siamese techniques, and use these samples to train a multi - modal model for the task of video QA. The proposed method is evaluated on a number of popular video question answer benchmarks and achieves state - of - the - art performance. The main contributions of this paper are : 1. A Siameses sampling mechanism for generating similar clips of the same videos, 2. A new method for integrating the interdependent knowledge between contextual clips into the network inference, 3. The ability of the model to produce the refined label by propagating the weights of inter - relations among all clips."
SP:160022e2cd61159da92f92e85520b7062a337a8d,"This paper proposes to reduce the computational and memory complexity of a large class of structured models by viewing the central inference step as a matrix - vector product and using a low - rank constraint. The proposed method is applied to parameterized structured models for language modeling, polyphonic music modeling, and probabilistic context - free grammars. The authors show that their approach matches the accuracy of standard structured models at large state spaces while providing practical speedups."
SP:238592ad73927194cdf0c0cf9ae2e48ca86e182c,"This paper proposes Sample Average Uncertainty ( SAU ) as a simple and efficient uncertainty measure for Bayesian contextual bandits. SAU is a frequentist approach that directly estimates the uncertainty of the outcomes based on the value predictions. The authors show theoretically that the uncertainty measure estimated by SAU asymptotically matches the uncertainty provided by Thompson Sampling, as well as its regret bounds. They confirm empirically our theory by showing that SAU - based exploration outperforms current state - of - the - art deep Bayesian bandit methods on several real - world datasets at modest computation cost."
SP:ffc5b18f7e18607b2934e5aa199e7542005d79f4,This paper proposes a method for learning discrete behavior embeddings from behavioral videos. The authors propose to disentangle the dynamic behavioral factors ( pose dynamics ) from time - to - time behavioral factors by using a disentangled behavior embedding ( DBE ) model. They also propose a stochastic temporal model ( VDBE ) for generating interpretable behavioral videos by combining their DBE and VBDE methods. The proposed method is evaluated on two downstream tasks ( behavioral generation and behavior decoding ).
SP:bf78a450e4aad6b87fdeb8ec0d68adaaff7b595b,"This paper proposes a conditional 3D conditional generative model that can synthesize high - resolution 3D shapes using simple user guides such as coarse voxels. It marries the merits of implicit and explicit 3D representations by leveraging a novel hybrid 3D representation. The core of DMTET includes a deformable tetrahedral grid that encodes a discretized signed distance function and a differentiable marching tetrahedra layer that converts the implicit signed distance representation to the explicit surface mesh representation explicitly on the surface mesh. Unlike deep 3D generative models that directly generate explicit representations such as meshes, the model can synthesise shapes with arbitrary topology. The proposed method significantly outperforms existing work on conditional shape synthesis from coarse - voxel inputs."
SP:2bc0bd6aa2a12691b16145f0d23542c4c86e3a44,"This paper proposes sliced mutual information ( SMI ) as a surrogate measure of statistical dependence. SMI is defined as an average of MI terms between one - dimensional random projections. The authors show that SMI preserves many of the structural properties of traditional MI, while gaining scalable computation and efficient estimation from samples. In contrast to classic MI, SMI can grow as a result of deterministic transformations, which enables leveraging SMI for feature extraction by optimizing it over processing functions of raw data."
SP:e220b348901b476c2afd95f97630fb5400582f40,"This paper proposes a computationally efficient two - step constrained two - stage lookahead constrained BO acquisition function ( 2 - OPT - C ) for both sequential and batch settings. The authors argue that being non - myopic is even more important in constrained problems because of the effect of discontinuities in the sampled acquisition function surface. To enable fast acquisition function optimization, the authors develop a novel likelihoodratio - based unbiased estimator of the gradient of the two - steps optimal acquisition function that does not use the reparameterization trick. In numerical experiments, 2 - OPT - C typically improves query efficiency by 2x or more over previous methods, and in some cases by 10 x or more."
SP:51fbd861422647912f275b48861ea3c4812afdc8,"This paper proposes a multi - dimensional distributional distributional Q network ( MD3QN ) that extends distributional RL to model the joint return distribution from multiple reward sources. The authors show that the proposed method can capture not only the randomness in returns for each source of reward, but also the rich reward correlation between the randoms of different sources. They also prove the convergence for the joint distributional Bellman operator by minimizing the Maximum Mean Discrepancy ( MMD ) between joint return distributions and its Bellman target. The proposed method is evaluated on MuJoCo environments with richly correlated reward functions, and it outperforms previous RL methods utilizing multi - dimension reward functions in the control setting."
SP:1f85c93d6bbfd65bf497c92c9cd534d799753097,"This paper proposes a method for surface reconstruction from 3D images. The method, called CorticalFlow, is based on the Ordinary Differential Equation (ODE ) framework. The proposed method learns to deform a reference template mesh from a 3D image by applying a set of diffeomorphic transformations. To reduce topological errors introduced by its discrete resolution, the paper derives numeric conditions to improve the manifoldness of the predicted triangle mesh. To exhibit the utility of the proposed method, the authors demonstrate its performance for the challenging task of brain cortical surface reconstruction."
SP:2f31d9cf4ad17ad08344439ca0aef7ec91944545,"This paper studies the problem of non - convexity in the setting where a user may choose to delete data points from a model in the privacy of their own will and not in the interest of the model's privacy. In this setting, there are many existing works that provide privacy guarantees for adaptive and non - adaptive deletion sequences. The main contribution of this paper is a general reduction from the deletion guarantees against adaptive sequences to deletion guarantees using differential privacy and its connection to max information. The authors show in theory how how prior work for non - convex non - privacy fails against adaptive deletions sequences, and use this intuition to design a practical attack against the SISA algorithm of Bourt.  "
SP:7150006590e268ab732c9be6c9048f67a377f956,This paper studies the conditional value - at - risk optimisation in Bayes - adaptive Markov decision processes ( MDPs ). The authors show that a policy optimising CVaR in this setting is risk - averse to both the epistemic uncertainty due to the prior distribution of the MDP and the aleatoric uncertainty caused by the inherent stochasticity of the underlying MDP. They reformulate the problem as a two - player stochastically game and propose an approximate algorithm based on Monte Carlo tree search and Bayesian optimisation. The proposed algorithm is evaluated on a number of synthetic and real - world datasets. The results show that the proposed algorithm outperforms the baselines.
SP:a94f39406f73d7483ddd744ed2f03c78b8bc5d44,"This paper studies the behavior of shallow ReLU networks trained with the logistic loss via gradient descent on binary classification data where the underlying data distribution is general, and the ( optimal ) Bayes risk is not necessarily zero. In this setting, it is shown that gradient descent with early stopping achieves population risk arbitrarily close to optimal in terms of not just logistic and misclassification losses, but also in terms calibration, meaning the sigmoid mapping of its outputs approximates the true underlying conditional distribution arbitrarily finely. Moreover, the necessary iteration, sample, and architectural complexities of this analysis all scale naturally with a certain complexity measure of the true conditional model. The required number of data samples, network nodes, and gradient descent iterations all shrink if the distribution satisfies a natural notion of simplicity. This is in contrast with prior analyses of gradient descent which either only consider the training risk or can only handle restricted conditional models."
SP:a9c786cbb61e1f10f3542161b13e43a1a68ab34d,"This paper proposes a method for coordinated group detection to combat the spread of misinformation on social media. The coordination detection framework is based on a neural temporal point process with prior knowledge. Specifically, the authors jointly learn a Gibbs distribution of group assignment based on how consistent an assignment is to ( 1 ) the account embedding ( 2 ) and ( 3 ) the location of the point in the observed data. The authors apply the proposed method on a COVID-19 Vaccine Tweets dataset. The detection result suggests presence of suspicious coordinated efforts on spreading misinformation about COVID - 19 vaccines."
SP:b5c6e967a26a02861db2ecd620e9061db0c03e59,"This paper studies a model problem with a non - linear structure, which is a binary classification problem with two smooth smooth curves on the unit sphere. The paper shows that when the neural network depth is large relative to certain geometric properties that set the difficulty of the problem and the network width and number of samples are polynomial in the depth, randomly - initialized gradient descent quickly learns to correctly classify all points on the two smooth curves with high probability. To my knowledge, this is the first generalization guarantee for deep networks with nonlinear data that depends only on intrinsic data properties. In particular, via fine - grained control of the decay properties of the NTK, the authors demonstrate that if the network is sufficiently deep, the NT K can be locally approximated by a translationally invariant operator on the manifold and stably inverted over smooth functions, which guarantees convergence and generalization."
SP:8f6bee3be43df6b6e80804974014caaafe08c49e,"This paper proposes a new method ReACGAN for training a classifier - based generative adversarial network ( cGAN ). The main idea is to exploit the relational information in the class - labeled dataset to improve the performance of the classifier. The authors propose to use the data - to - data cross - entropy loss ( D2D - CE ) instead of the standard cross entropy loss in ACGAN. The proposed method is evaluated on state - of - the - art generation results on CUB200, ImageNet and CUB100 datasets. The experiments show that the proposed method outperforms the original ACGAN in most cases."
SP:080e80746a87228b156408ff649ab7a17f44e92d,"This paper proposes an extensive - form double oracle ( XDO ) algorithm for two - player zero - sum games that is guaranteed to converge to an approximate Nash equilibrium linearly in the number of infostates. The authors also introduce Neural XDO ( NXDO ), where the best response is learned through deep RL and the exploitability is controlled with the same amount of computation. They also find that XDO outperforms PSRO and NFSP on a sequential multidimensional continuous - action game."
SP:bda04facef4f34679fc4e17b8ea1aae74c3d649f,"This paper proposes a permutation - invariant variational autoencoder ( VAE ) model for graph - level unsupervised representation learning. The proposed model learns to match the node order of input and output graph, without imposing a particular node order or performing expensive graph matching. Experiments are conducted for graph reconstruction, generation and interpolation, and graph classification and regression."
SP:e17ea6aeba78c9dfc25596d8b35a2a4f1f1f6763,"This paper proposes to decouple the depth and scope of GNNs – to generate representation of a target entity ( i.e., a node or an edge ), first extract a localized subgraph as the bounded - size scope, and then apply a GNN of arbitrary depth on top of the subgraph. The proposed method is evaluated on seven graphs and six backbone GNN architectures and achieves significant accuracy improvement with orders of magnitude reduction in computation and hardware cost."
SP:4890f251db559a0a572afc66e0c1f899b577d9ff,"This paper studies the well - conditioned affine coupling of normalizing flows. The authors show that the Jacobian of the latent - to - observable - variable transformation is triangular, allowing the likelihood to be computed in linear time. They also show that a padded version of the input distribution with iid Gaussians can be approximated with better conditioned flows.    The main contributions of this paper are :   1. 	 The authors provide theoretical evidence for the benefits of Gaussian padding when training Normalizing Flows ( NF ) for generating tractable likelihood with affine - coupling models. The proof leverages deep connections between affine couplings, underdamped Langevin dynamics, and Hénon maps. The results also inform the practice of training affine Couplings."
SP:5ffa81488ed1092deb89bd5e150fa146325057ce,"This paper studies the problem of online coupon allocation in the context of real - time and fast - response in the real - world e - commerce market, where the goal is to allocate coupons within a fixed budget while maximizing users ’ retention on the e -commerce platform. Specifically, the problem is usually formulated as a Lagrangian problem, which requires re - learning the policy from scratch once the value of the multiplier variable $ \lambda$ is updated, causing a great computation overhead. To address this problem, the authors propose a $ \� - generalization $ \eta$-generalization method to lead the policy learning process, which can be executed according to different $ \log \log(\lambda)$ values adaptively, thus avoiding re - training new polices from scratch. Moreover, a novel offline reinforcement learning method and an off - policy evaluation algorithm are proposed for policy learning and policy evaluation, respectively. The proposed method can help enterprises develop a coupons allocation policy which greatly improves users’ retention rate on the platform while ensuring the cost does not exceed the budget. Finally, experiments on the simulation platform and real - life e - online market validate the effectiveness of the approach."
SP:6b04cc7b4e45b9e65a1d34c15e3f75a2ef27d601,"This paper proposes a method for source - free domain adaptation ( SFDA ), where the source pretrained model is adapted to the target domain in the absence of source data. The method is based on the observation that target data, which might no longer align with the source domain classifier, still forms clear clusters. The authors capture this intrinsic structure by defining local affinity of the target data and encourage label consistency among data with high local affinity. They observe that higher affinity should be assigned to reciprocal neighbors, and propose a self - regularization loss to decrease the negative impact of noisy neighbors. The experimental results demonstrate that the inherent structure of the intrinsic structure of target features is an important source of information for domain adaptation."
SP:ac1bf04ff782e5892a0bc5fe5949848ca8e731c2,"This paper proposes an end - to - end trainable Euclidean embedding for a geometrically - interpretable and generic pooling mechanism for aggregating a set of features into a fixed - dimensional representation. In particular, it treats elements of a set as samples from a probability distribution and proposes a sliced - Wasserstein distance to learn from set - structured data effectively. The proposed method is evaluated on a wide variety of set - based data, including point - cloud, graph, and image classification tasks, and demonstrate that it provides superior performance over existing set representation learning approaches."
SP:6cb2f0cbc076f8680cb00411790629f8e1478053,This paper studies the stability of recurrent neural networks ( RNNs ) in the presence of hidden states and hyperparameters. The authors propose a family of RNN models that can be formulated using stochastic bilevel optimization ( SBO ) and prove that under mild conditions there is no vanishing or exploding gradient in training the proposed SBO - RNN. The proposed method is evaluated on several benchmark datasets and achieves better performance compared to the existing methods with fewer parameters and less training data.
SP:d3a4300e21ca215334f256f0467a428470548fe4,"This paper studies the problem of minimizing power consumption in systems with multiple power - saving states. The paper proposes a learning - augmented online algorithm for this problem that makes decisions based on ( potentially inaccurate ) predicted lengths of the idle periods. The proposed algorithm is based on a learning model that predicts the length of the next power saving state based on the current state's energy consumption and wake - up cost. The algorithm is shown to be near - optimal when predictions are accurate and degrades gracefully with increasing prediction error, with a worst - case guarantee almost identical to the optimal classical algorithm for the problem. A key ingredient in this algorithm is a new algorithm for online ski rental problem in the learning augmented setting with tight dependence on the prediction error. The experimental results support the theoretical findings with experiments."
SP:22aba6284123af0ecd6605ee4e89b351bd7e10a3,"This paper studies the problem of multi - source transfer learning in the setting where the source and target tasks are linearly combined to learn the target task. The authors propose a new transferability metric based on the optimal combining coefficients of the linearly converged linear model. The transferability measure is expressed by the sample sizes, the model complexity, and the similarities between target and source tasks. Theoretical results on the transferability of the proposed metric are provided for the setting of linear linearly converge linearly to the optimal combined coefficient of the optimal linear model and the sample complexity of the linear model is also analyzed. Experiments on image classification tasks show that the proposed transferability measures outperform the existing transfer learning algorithms in multi - sources and few - shot transfer learning problems."
SP:0fb8dcf15e0d43547d566fdba7bc70b3bb600005,"This paper proposes a method for visual search based on the asymmetry property of some classical search tasks, i.e., finding a target among distractors B can be easier than finding B among A in the same search task. The authors propose a computational model that takes a target and a search image as inputs and produces a sequence of eye movements until the target is found. The model integrates eccentricity - dependent visual recognition with target - dependent top - down cues. The experiments show that the proposed method outperforms other baselines in six paradigmatic search tasks that show asymmetry in humans."
SP:f0cc968ea9da4884dcdaf6d0c75ea9f1511bdfc3,"This paper studies the problem of training certifiable robust models against adversarial examples. The authors argue that the tightness of the upper bound is an important factor in building certifiably robust models, and that Interval Bound Propagation ( IBP ) training uses much looser bounds but outperforms other models that use tighter bounds. In addition, the authors identify another key factor that influences the performance of certifiable training : smoothness of loss landscape. They find significant differences in the loss landscapes across linear relaxation - based methods and that the current state - of - the - arts method often has a landscape with favorable optimization properties. Moreover, to test the claim, they design a new certified training method with the desired properties. The proposed method achieves a decent performance under a wide range of perturbations."
SP:a158f8772a9dada059ffd1d6d7838ed40d8483da,This paper considers the problem of online linear regression in the stochastic setting. The authors derive high probability regret bounds for online ridge regression and the forward algorithm. This enables them to compare online regression algorithms more accurately and eliminate assumptions of bounded observations and predictions. They advocate for the use of the forward algorithms in lieu of ridge regression due to its enhanced bounds and robustness to the regularization parameter. They also explain how to integrate it in algorithms involving linear function approximation to remove a boundedness assumption without deteriorating theoretical bounds. They showcase this modification in linear bandit settings where it yields improved regret bounds. Numerical experiments are provided to illustrate their results and endorse their intuitions.
SP:17ff9a2133aebf2d1b1787e8efc49d709389c0e7,"This paper proposes a two - time - scale extension of the extragradient ( EG ) method for nonconvex - convex nonconcave minimax problems. The proposed method is based on EG+ and EG++ with anchoring, two variants of EG, respectively. The paper further proposes a backtracking line - search version, called FEG - A, for the case where the problem parameters are not available. The authors provide a fast O(1 / k ) rate on the squared gradient norm for their proposed method under the smooth convex - concave setting. They also provide a stochastic analysis of FEG."
SP:4e38973033de24fc183c6112e1146f8eef0ddaea,"This paper studies uniformity testing in the setting where the alternative class is restricted to Mallows models. The uniform distribution can be distinguished from Mallows model with O(m 1/2 ) samples based on simple pairwise statistics, which allows us to test uniformity using only two samples, if m is large enough. The paper also considers uniformity test with central and local differential privacy ( DP ) constraints. Central DP requires O(max_1/\�0, 1 / p m ) samples, where $ \ell_0 $ is the privacy budget parameter. Local DP requires $ O(\max{1 / \�0, 1/\sqrt{0})$ samples. Interestingly, the uniformity tested algorithm is straightforward to apply to the local DP scenario, since it works with binary statistics that is extracted from ranking data."
SP:99a835191a3ba8372e391b6d3316e9b68e543295,"This paper proposes a score - based algorithm for learning directed acyclic graphs ( DAGs ), which is vertex - greedy and requires at most a polynomial number of score evaluations. The authors show how recent polynomials for learning DAG models are a special case of this algorithm, thereby illustrating how these order - based algorithms can be rigorously interpreted as score based algorithms. This observation suggests new score functions and optimality bounds, which they explore in detail. Finally, they provide extensive experiments suggesting that this algorithm indeed optimizes the score in a variety of settings."
SP:b60989706296b963b6671c01f22384978a334be1,"This paper proposes a method to improve the adversarial robustness of convolutional neural networks ( CNNs ) by introducing a dilation network in the backbone of the network. The proposed method is motivated by the observation that adversarially robust CNNs are vulnerable to adversarial attacks and that there is a trade - off between the accuracy and robustness. To this end, the proposed method proposes to use a neural network with a two - stage architecture, where the first stage consists of a standard CNN and the second stage is a D - CNN with a dilated output layer. The first stage is used for adversarial training, while the second one is used to update the output of the CNN. Experiments on standard and adversarial error bounds show the effectiveness of the proposed methods.   "
SP:77ed765e911a4e5f2bfba13cbd2403500a5d05e6,"This paper studies model - based reward - free reinforcement learning with linear function approximation for episodic Markov decision processes ( MDPs ). The authors propose a provably efficient algorithm UCRL - RFE under the linear mixture MDP assumption, where the transition probability kernel of the MDP can be parameterized by a linear function over certain feature mappings defined on the triplet of state, action, and next state. In the exploration phase, the agent interacts with the environment and collects samples without the reward, while in the planning phase, a specific reward function is given, and the agent uses samples collected from the explored phase to learn a good policy. The lower bound matches the lower bound in terms of the dependence on $ \varepsilon$ and $ d$ if H = d$.    The authors show that to obtain an $ \epsilon$-optimal policy for arbitrary reward function, UCRL-RFE needs to sample at least $ \tilde{O}(\sqrt{H}(H^{2d|2})$ episodes to obtain $ \Omega(H^2)$ optimal policy."
SP:28563ba0975f56ddb662cd46e85de78bb6024d36,"This paper proposes a method for online forecasting of future events with seasonal patterns. The proposed method is based on the Shifting Seasonal Matrix Factorization ( SSMF ) approach that can adaptively learn multiple seasonal patterns ( regimes ), as well as switching between them. The method works in an online setting, i.e., processes each observation in constant time and memory, and it works in two ways : 1 ) it learns regime shifts by detecting regime shifts in seasonal patterns as the data stream evolves ; 2 ) it effectively realizes regime shifts without human intervention by using a lossless data compression scheme. The experiments show that the proposed method outperforms state - of - the - art methods by accurately forecasting upcoming events on three real - world data streams."
SP:e4bb07033001be4d04695ef058f426d49fe440be,"This paper proposes a learning - based method for solving non - linear assignment problems. The proposed method, called WeaveNet, is based on a neural network architecture that consists of a core module and a feature - weaving layer. The core module is used for solving the combinatorial problem of assignment, and the feature weaving layer is used to improve the communication between the two modules in a parameter - efficient way. The method is evaluated on a number of real - world assignment problems and compared with the state - of - the - art algorithmic method. The results show that the proposed method achieves better performance compared to the previous methods."
SP:8a559e21d45661eef427b310e5fe8488d5749137,"This paper systematically studies the impact of various self - supervised learning proxy tasks on different architectures and threat models for 3D point clouds with adversarial training. Specifically, they study MLP - based ( PointNet, ConvNet, DGCNN, and PCT ) 3D architectures for point cloud recognition and adversarial robustness. They demonstrate that appropriate applications of self - supervision can significantly enhance the robustness of 3D deep learning models against adversarial attacks. The analysis reveals that local feature learning is desirable as it limits the adversarial propagation between the point - level point clouds. This insight also explains the success of convolution and the jigsaw proxy task in achieving stronger 3D adversarial defense."
SP:657c5a1114c0d054b9e767d85990bbbb0492912d,"This paper proposes a method for computing iterative projections of close - by points over widely - used functions. The main idea is to compute the projection in each iteration of a Bregman - like algorithm. The method is based on the FISTA algorithm, which has been shown to enjoy near - optimal regret bounds and convergence rates. However, it suffers from a computational bottleneck of computing the projections in potentially each iteration. Motivated by this trade - off in runtime v/s convergence rates, the authors propose to improve the runtime of computing certain Bregmen projections by a factor of $ \tilde{O}(n\log(n)$ where $ n$ is the number of iterations and $ log(n ) is the dimension of the function space.   Theoretical results show orders of magnitude reduction in runtime in preliminary computational experiments. The proposed method can be used to adapt the away - step - Wolfe algorithm to use this information and enable early termination."
SP:8dae43d6b5cebb7ef6c39437d997b390c2380536,"This paper considers the problem of learning the natural parameters of a k - parameter minimal exponential family from i.i.d. samples in a computationally and statistically efficient manner. The authors focus on the setting where the support as well as the natural parameter are appropriately bounded. While the traditional maximum likelihood estimator for this class of exponential family is consistent, asymptotically normal, and asymPTotically efficient, evaluating it is computationally hard. In this work, the authors propose an efficient computationally efficient estimator that is consistent as well    under mild conditions. They provide finite sample guarantees to achieve an error of $ \alpha$ in the parameter estimation with sample complexity $ O(poly(k/\alpha)$ and computational complexity $ \widetilde{O}(\poly(\k / \alpha)$. They show that their estimator can be viewed as the maximum likelihood estimation of a re - parametric exponential family belonging to the same class as the standard exponential family."
SP:4f9ddb697e86356fb293ef34a69ca3702c4e8164,"This paper proposes a differentiable renderer for the problem of predicting intrinsic object properties from a single image by combining the advantages of rasterization and ray - tracing. The key idea is to use a path - trace network to predict the geometry, reflectance and lighting prediction of an image without requiring any ground - truth prediction. The proposed method is evaluated on synthetic and real - world datasets and compared with several state - of - the - art physics - based and path - tracing - based approaches."
SP:6ac1c8556e7131939cc582f513bc9921470e1b09,This paper proposes a differentiable differentiable training method for soft - argmax localization. The main idea is to minimize the expectation of the localization error by sampling from a continuous formulation of the output distribution of a neural network. The sampling process is differentiable and can be used in conjunction with the soft argmax operation. The proposed method is evaluated on a variety of localization tasks and compared with the conventional soft arg max method.
SP:478c05c90090f9d80b72ac352c488073b45a5d8b,"Graph Contrastive Learning ( GCL ) has emerged to learn generalizable representations from contrastive views. However, it is still in its infancy with two concerns. One is that changing the graph structure through data augmentation may mislead the message passing scheme, as such graph changing action deprives the intrinsic graph structural information, especially the directional structure in directed graphs. The other is that GCL usually uses predefined contrastive view with hand - picking parameters, which does not take full advantage of the contrastive information provided by data augmentations, resulting in incomplete structure information for models learning. In this paper, the authors design a directed graph data augmentation method called Laplacian perturbation and theoretically analyze how it provides contrastive info without changing the directed graph structure. Moreover, they present a directed graphs contrastive learning framework, which dynamically learns from all possible easy - to - hard graph structural views generated by Laplastic perturbations. Then they use it using multi - task curriculum learning to progressively learn from multiple easy-to - difficult graph structural features. Experiments on various benchmarks reveal that the proposed method outperforms the state - of - the - art approaches."
SP:85b383d2f722f7bff438840e423f5cb4c67d5980,"This paper proposes a new benchmark for multi - environment symbolic interactive language grounding ( SILG ), which unifies a collection of diverse grounded language learning environments under a common interface. The benchmark consists of grid - world environments ( RTFM, Messenger, NetHack ), symbolic counterparts of visual worlds ( ALFWorld, Touchdown ), and symbolic versions of visual scenes ( TEM ). The authors also propose the first shared model architecture for RL on these environments, and evaluate recent advances such as egocentric local convolution, recurrent state - tracking, entity - centric attention, and entity - centered attention.   The authors find that many recent modelling advances do not result in significant gains on environments other than the one they were designed for, and that the best models significantly underperform humans on SILG, which suggests ample room for future work."
SP:23c8db56f59f778fe812a5dd161f7a1f21c3cdba,"This paper proposes a new model for a mixture of experts networks ( MoE ) for image recognition. The proposed model is a sparse version of the Vision Transformer, where each input is processed by a different number of parameters of a dense network. The authors propose an extension to the routing algorithm that can prioritize subsets of each input across the entire batch, leading to adaptive per - image compute. This allows V - MoE to trade - off performance and compute smoothly at test - time, while requiring as little as half of the compute at inference time. The experimental results demonstrate the potential of the proposed model."
SP:c5235f41dfb8b5cc478f11c5d5e0ab0b8676871e,"This paper studies the expressivity of a 1 - hidden layer network with $ n$ neurons when the activation is smooth in a constrained optimization formulation where the feasible region is the nice local region, and proves that every KKT point is a nearly global minimizer under mild technical conditions. The paper also shows that projected gradient methods on this constrained formulation significantly outperform SGD for training narrow neural nets.    The main contributions of this paper are two - fold :   1. Prove that as long as the width m > 2n / d ( where d is the input dimension ) of the network is sufficiently wide, its expressivity is strong, i.e., there exists at least one global minimiser with zero training loss. 2. If so, does the loss function exhibit a benign optimization landscape? In this work, the authors provide partially affirmative answers to both questions."
SP:0be529f5254afd59dcfa6b34a359c7037e7a8323,"This paper proposes a Continuous Mean - Covariance Bandit ( CMCB ) model to explicitly take into account option correlation in risk - aware multi - armed bandit models. Specifically, the learner sequentially chooses weight vectors on given options and observes random feedback according to the decisions. The agent ’s objective is to achieve the best trade - off between reward and risk, measured with option covariance. To capture different reward observation scenarios in practice, the authors consider three feedback settings, i.e., full information, semi - bandit and full bandit feedback. The authors propose novel algorithms with optimal regret and bounding the risk of selected actions based on sampling strategy properties. The experimental results also demonstrate the superiority of the algorithms."
SP:472a90bb175b0286765c5a47b040e1a58f594a05,This paper proposes a new algorithm for Positive Semidefinite ( PSD ) factorization that generalizes the Multiplicative Update ( MMU ) algorithm for Nonnegative Matrix Factorization ( NMF ). The proposed method is an extension of the multi - multiplicative update algorithm for NMF that preserves the non - negativity of the updates by scaling with positive diagonal matrices. The authors show that under their update scheme the squared loss objective is non - increasing and fixed points correspond to critical points. The analysis relies on Lieb’s Concavity Theorem. The paper also shows that the proposed method can be also used as a primitive to calculate blockdiagonal PSD factorizations and tensor PSD factorsizations. Experiments on real and synthetic data demonstrate the effectiveness of the proposed algorithm.
SP:83abd6d149d88cc6e96cbc4d488e4fe9dc2a4fcb,"This paper proposes a meta - domain - specific - domain invariant ( mDSDI ) framework for domain generalization ( DG ). The key insight is to disentangle features in the latent space while jointly learning both domain - invariant and domains - specific features in a unified framework. The proposed method is optimized through the meta - learning framework to adapt from source and target domains, targeting a robust generalization on unseen domains. The authors empirically show that the proposed method achieves competitive results with state - of - the - art techniques in DG. A further ablation study with a generated dataset, background - Colored - MNIST, confirms the hypothesis that domain -specific information is essential, leading to better results when compared with only using domain - Invariant."
SP:4191474c75e2fedf514f0f3001a67a047eb74c30,"This paper proposes a diffusion - based generative model for conditional image synthesis, where the goal is to improve the sample - efficiency and sample - coverage of the generative process. The proposed method is based on augmenting the original image synthesis model with a series of ablations. The ablations are based on the idea from [ 1 ]. The authors also propose a simple compute - efficient method for classifier guidance to trade off diversity for fidelity using gradients from a classifier. Experiments show that the proposed method can achieve FID of 2.97 on ImageNet 128, 4.59 on Imagenet 256, and 7.72 on imagenet 512 with as few as 25 forward passes per sample.  "
SP:fe3cab08596cde4c14ecf6fca8d0f95b02bab229,"This paper proposes a few - shot learning method that leverages out - of - distribution ( OOD ) samples to improve the performance of pretrained networks. The proposed method is based on the idea of distance from prototypes to OOD samples, which maximizes the distance between in - distribution samples and those from outside target classes. The main idea is to use a feature extractor to extract features from unlabeled samples and use the extracted features to drive the classifier to avoid irrelevant features by maximizing the distance to prototypes. The method is simple to implement, agnostic to feature extractors, lightweight without any additional cost for pre - training, and applicable to both inductive and transductive settings. Extensive experiments on various standard benchmarks demonstrate that the proposed method outperforms the baseline methods in most cases."
SP:b1f65724926f136979829b7a6c870bc31f38f591,"This paper studies the problem of prioritization in experience replay reinforcement learning, where the goal is to learn a policy that maximizes the return of a Bellman update. The authors propose two new methods to compute the prioritization weight, namely ReMERN and ReMERT, and provide theoretical justifications for previous criteria, such as TD error, recentness and corrective feedback. Theoretically, the authors show that data with higher hindsight TD error and better on - policiness and more accurate Q value should be assigned with higher weights during sampling, thus most previous criteria only consider this strategy partially."
SP:601ebf30b3c6aa35fcef49633aa8eb0acd0f2c66,"This paper studies the problem of sequential prediction with expert advice in a nonstationary environment with long - term memory guarantees in the sense of Bousquet and Warmuth [ 4 ]. The authors propose a linear - time algorithm that improves on the best known regret bounds [ 27 ], which incorporates a relative entropy projection step. This projection is advantageous over previous weight - sharing approaches in that weight updates may come with implicit costs as in for example portfolio optimization. In addition, the authors also give an algorithm to compute this projection step in linear time."
SP:b2439973063e827b3cbe92306a2fdee3286b6b44,"This paper considers the problem of contextual linear bandits motivated by routing applications in navigational engines and recommendation systems. In this setting, the learner is presented with a set of actions $ \tilde{X}_R$ of possible actions, and the goal is to learn the identity of the best action $ \max_t \le \le 1 \le w\le R$ such that regret $ O(d log T)$ and exp(O(\d log d)$ are satisfied. The authors propose two cutting - plane algorithms for this problem. The first algorithm learns a hidden value $ w_t$ of the hidden value of the optimal action $ x_t\le w$ by minimizing the utility $ \textrm{W}_t$. The second algorithm is for a variant of this problem where $ \Omega_d \log T$ is the total distance between the true point w.i.d. and the hyperplanes the separation oracle returns. In both cases, the regret is $ O(\log d)$.   The authors also consider a variant where only $ \log(d)$ of actions are available, and they design an algorithm with regret O(log d ) regret and list size poly(d ) for this variant. Finally, the authors propose an algorithm for a weaker variant of the problem in which $ \mathcal{O}(\log O)$ regret is satisfied only if $ \frac{O(d\log T)^2 \log d}{log T }.    This paper considers linear bandits in convex geometry and proposes a new algorithm for it. The algorithm is based on an extension of a previous algorithm for linear bandits to the convex set of centroid centroids. The proposed algorithm is evaluated on a convex subset of the centroid of convex sets."
SP:abe83c7e0bcf4829742609d709637e2f84d8a4d9,"This paper proposes a method for searching for optimizers for gradual automated machine learning ( AutoML ) that allow data scientists to apply their intuition. The method is based on functional programming and uses orthogonal combinators for composing machine learning operators into pipelines. It describes a translation scheme from pipelines and associated hyperparameter schemas to search spaces for AutoML optimizers. The paper presents Lale, an open - source sklearn - compatible AutoML library, and evaluates it with a user study."
SP:0d7f1cae577ed598048b64617e85ca6bd5c6d7fa," meta - learning aims to learn a weight initialization for a neural network such that a small number of weight changes results in low generalization error. The authors show that patterned sparsity emerges from this process, with the pattern of sparsity varying on a problem - by - problem basis. They find that selective sparsity results in better generalization and less interference in a range of few - shot and continual learning problems. Moreover, they find that sparse learning also emerges in a more expressive model where learning rates are meta - learned."
SP:05037e1850003a725a466b64d3e32aa2aed458fb,"This paper considers the problem of multi - view multi - component ( MVC ) modeling, where the goal is to identify common components from multiple datasets or views. The authors propose a method called ShICA ( Shared Independent Component Analysis ) that models each view as a linear transform of shared independent components contaminated by additive Gaussian noise. They show that this model is identifiable if the components are either non - Gaussian or have enough diversity in noise variances. They then show that in some cases multi - set canonical correlation analysis can recover the correct unmixing matrices, but that even a small amount of sampling noise makes Multiset CCA fail. To solve this problem, they propose to use joint diagonalization after Multi - Set CCA, leading to a new approach called the ShICA - J. They also propose to leverage non - gaussianity of the components using a maximum - likelihood method, which is both more accurate and more costly. They provide empirical evidence on fMRI and MEG datasets."
SP:44dd1faa1813c433fd7581d05cae3df440bfb93e,"This paper proposes a new method for training multi - agent reinforcement learning agents to collaborate well with human partners without using human data. The proposed method, called Fictitious Co - Play ( FCP ), is based on a two - player collaborative cooking simulator that has been recently been proposed as a challenge problem for coordination with humans. The authors show that FCP agents score significantly higher than self - play ( SP ), population play ( PP ), and BCP ( population play ) when paired with novel agent and human partners. They also show that humans also report a strong subjective preference to partnering with FCP - trained agents over all baselines."
SP:21c84bd720b1e90ea0f88fbf8fd24dbcb49b547c,"This paper proposes a centralised policy gradient method for cooperative multi - agent reinforcement learning, which optimises over the joint action space, rather than optimising over each agent ’s action separately as in MADDPG. The proposed method, FACMAC, learns a centralized but factored critic, which combines per - agent utilities into a joint action - value function via a non - linear monotonic function, as in QMIX. The authors evaluate FACMAC on variants of the multi - agents particle environments, a novel multi -agent MuJoCo benchmark, and a challenging set of StarCraft II micromanagement tasks. The experimental results demonstrate that FACMAC outperforms other baselines on all three domains."
SP:1c8351b8a6cdf1212840388e19a596729b3bfda4,"This paper proposes a biologically plausible key - value mechanism for long - term memory in neural networks based on biologically plausible three - factor plasticity rules. In particular, the proposed key value mechanism is a combination of biologically plausible plasticity rule and attractor dynamics. The same rules are recovered when network parameters are meta - learned. The proposed method is evaluated on memory - augmentation tasks of continual recall, hetero - attentive memory, and sequence learning. The results show that the proposed method performs on par with classical Hopfield networks on these tasks."
SP:7ad6da2c63859d64970e9b35326e9ceab48add47,"This paper proposes stochastic and online gradient descent methods for pairwise learning, where the loss function depends on a pair of instances. A notable difference from the existing studies is that they only pair the current instance with the previous one in building a gradient direction, which is efficient in both the storage and computational complexity. They develop novel stability results, optimization, and generalization error bounds for both convex and nonconvex models as well as both smooth and smooth and non - smooth as well. Their study resolves an open question on developing meaningful generalization bounds for OGD using a very small fixed size. They also extend their algorithms and stability analysis to develop differentially private SGD algorithms for Pairwise Learning."
SP:cb11dacc930d71a616ee2fbe4acfae030f9dca59,"This paper proposes REDO, a class - agnostic framework to reconstruct the Dynamic Objects from RGBD or calibrated videos. REDO aims to handle different object dynamics including rigid motion, non - rigid motion and articulation, and aim to reconstruct different categories of objects with one unified framework. The authors introduce a canonical 4D implicit function which is pixel - aligned with aggregated temporal visual cues. They also develop a 4D transformation module which captures object dynamics to support temporal propagation and aggregation. They study the efficacy of REDO in extensive experiments on synthetic RGBD and real - world datasets."
SP:8ae97752e74b4395774575009031abcb6ba5cea7,"This paper provides a non - asymptotic analysis of linear stochastic approximation ( LSA ) algorithms with fixed stepsize. The analysis is based on new results regarding moments and high probability bounds for products of matrices which are shown to be tight. In particular, the high probability bound on the performance of LSA under weaker conditions on the sequence { ( An,bn ) : n 2 N\sqrt{N } } than previous works establishes polynomial concentration bounds with order depending on the stepsize, and in particular that no Gaussian or exponential high - probability bounds can hold. However,   the authors show that our conclusions cannot be improved without additional assumptions on the sequences of random matrices.    The paper is well organized and easy to follow."
SP:86c1e937755e35efafecc09dfe2606ffb1653a41,"This paper extends the options framework for temporal abstraction in reinforcement learning from discounted Markov decision processes ( MDPs ) to average - reward ones. The authors propose general convergent off - policy inter - option learning algorithms, intra - option algorithms for learning values and models, as well as sample - based planning variants of our learning algorithms. They also extend the notion of option - interrupting behavior from the discounted to the average - return MDP formulation. The experiments show the efficacy of the proposed algorithms with experiments on a continuing version of the Four - Room domain."
SP:7e4e1e20e7c253d02c6ae58457fb30029f130f0c,"This paper proposes an auxiliary self - supervised learning task for visual transformers ( VTs ) to learn spatial relations within an image with only a negligible computational overhead. The proposed auxiliary task is designed jointly with the standard ( supervised ) training and it does not depend on specific architectural choices, thus it can be easily plugged in the existing VTs. The authors empirically analyse different VTs, comparing their robustness in a small training set regime, and show that, despite having a comparable accuracy when trained on ImageNet, their performance on smaller datasets can be largely different. Moreover, the authors propose an auxiliary task to further improve the final accuracy of the VTs in a limited training regime."
SP:0132ef17585e293b23e9dc45189c0989d829b52a,"This paper proposes a new method for label - free alignment in hyperbolic spaces. The proposed method, Hyperbolic Procrustes Analysis ( HPA ), is based on the Riemannian geometry of the Lorentz model of hyperboloid space. HPA consists of three components : translation, scaling, and rotation. The efficacy of HPA, its theoretical properties, stability and computational efficiency are demonstrated in simulations. Finally, HPA is evaluated on three batch correction tasks involving gene expression and mass cytometry data."
SP:3580ac64f09e3021de5d4c92411bcc0f3c5d10f3,"This paper studies the trade - off between differentially private point queries and sum queries and point queries with sub - population uncertainty. The authors show that in the setting of pure differential privacy, the uncertainty principle governs the tradeoff between accuracy for the population of interest ( sum queries ) vs. accuracy for its component sub - populations ( point queries ). They also provide a mitigation strategy and create a collection of benchmark datasets that can be used for public study of this problem."
SP:c0e64dc8acfaed3e4d7745af12fd34003d0e5017,This paper proposes a method for combining RL and planning to overcome the drawbacks of both in long - horizon navigation and goal - conditioned reinforcement learning ( RL ). The main idea is to decompose a task into a series of sub - tasks and train a planner RL agent and a path - planner jointly in a top - down manner. The planner is trained to find the shortest path to a distant goal that provides dense reward / guidance while the RL agent learns to increase the difficulty of each sub - task by increasing the number of layers in the tree. The method is evaluated on navigation and continuous control tasks and significantly improves the sample efficiency and success rate.
SP:9911693a04a300b5a93634fb0267ef83e5489d77,"This paper proposes a Bayesian framework for generating local explanations for black box models. The main idea of the paper is to use Bayesian methods to generate consistent, stable, and reliable explanations with guarantees with guarantees in a computationally efficient manner. Specifically, the Bayes framework is used to obtain Bayesian versions of LIME and KernelSHAP which output credible intervals for the feature importances, capturing the associated uncertainty. The authors also carry out a detailed theoretical analysis that leverages the aforementioned uncertainty to leverages how many perturbations to sample, and how to sample for faster convergence. Experimental evaluation with multiple real world datasets and user studies demonstrate that the efficacy of the proposed framework."
SP:5efb4b81bd37c70640e8768e9dfb5bba14a0cfb8,This paper studies the performance of Adder neural networks ( ANNs ) in the presence of unordered heavy tails. The authors propose a novel method for tackling existing heavy tails in ANNs with only a modification of classifier where ANN features are clustered with their tails well - defined through proposed angle - based constraint on the distribution parameters to encourage high diversity of tails. Experiments conducted on several benchmarks and comparison with other distributions demonstrate the effectiveness of proposed approach for boosting the performance for boosting ANNs.
SP:cbccb65457564992d534504c0d060da44cafce8c,"This paper studies the phenomenon of gradient starvation in over - parametrized neural networks. Gradient starvation occurs when the cross - entropy loss is minimized and only captures a subset of features relevant for the task, while ignoring other predictive features that are not relevant. This paper provides a theoretical explanation for the emergence of such feature imbalances in neural networks using tools from Dynamical Systems theory. The authors identify simple properties of learning dynamics during gradient descent that lead to this imbalance, and prove that such a situation can be expected given certain statistical structure in training data. Based on this formalism, the authors develop a novel but simple regularization method aimed at decoupling feature learning dynamics, which improves accuracy and robustness in cases hindered by gradient starvation."
SP:8f6fe37cb0a332b66e10cc00261a44622841c8c6,"This paper studies the role of AI in human - machine collaborative games, specifically in the cooperative card game Hanabi. The paper conducts a single - blind evaluation of teams of humans and AI agents in Hanabi, with both rule - based and learning - based agents. In addition to the game score, they also quantify subjective measures of the human ’s perceived performance, teamwork, interpretability, trust, and overall preference of AI teammate. They find that humans have a clear preference toward a rule based AI agent ( SmartBot ) over a state - of - the - art learning based AI teammate ( Learning - based Agent ). This result has implications for future AI design and reinforcement learning benchmarking."
SP:2a05e333fc1a14057515ef3addde9a40152373db,"This paper proposes a method for visual question generation ( VQG ), which aims to generate human - like neural questions from an image and potentially other side information ( e.g., answer type or the answer itself ). The proposed method leverages double visual and answer hints to generate better quality questions. The key rationale is that visual hints are not available naturally. Despite they proposed a simple rule - based similarity matching method to obtain candidate visual hints, they could be very noisy practically and thus restrict the quality of generated questions. In this paper, the authors present a novel learning approach for double - hints based on double - visual - and - answer - hint learning, which can be cast as a weakly supervised learning problem with noises. Experimental results on two benchmark datasets show that the proposed method outperforms the state - of - the - art approaches by a large margin on a variety of metrics, including both automatic machine metrics and human evaluation."
SP:15756d6ef47b39ded404acea2135c93bd5ee1062,"This paper proposes Generalized Data Weighting ( GDW ) to mitigate label noise and class imbalance by manipulating gradients at the class level. To be specific, GDW unrolls the loss gradient to class - level gradients by the chain rule and reweights the flow of each gradient separately. In this way, it achieves a significant performance improvement on both noise and label noise. Extensive experiments in various settings verify the effectiveness of GDW."
SP:7a8f56a01bec51ebf70d9ff689005a62cccfe5c6,"This paper proposes a spatio - temporal language grounding task where the goal is to learn to describe behavioral traces of an embodied agent using language grounded in other sensory modalities. This is achieved by training a truth function that predicts if a description matches a given history of observations. The descriptions involve time - extended predicates in past and present tense as well as spatio-temporal references to objects in the scene. To study the role of architectural biases in this task, the authors train several models including models including multimodal models including Transformer architectures and transformer architectures. They test models on two classes of generalization : 1 ) generalization to randomly held - out sentences ; 2 ) generalisation to grammar primitives. They observe that maintaining object identity in the attention computation is instrumental to achieving good performance on generalization overall, and that summarizing object traces in a single token has little influence on performance performance. They also discuss how this opens new perspectives for language - guided autonomous embodied agents."
SP:3d4a9d439bc84c3b0e6600f6985a23bdf95cd67f,"This paper proposes a new method for multiple object tracking and segmentation in video. The proposed method is based on prototypical cross - attention network ( PCAN ), which first distills a space - time memory into a set of prototypes and then employs cross attention to retrieve rich information from the past frames. To segment each object, PCAN adopts a prototypical appearance module to learn a set   of contrastive foreground and background prototypes, which are propagated over time. The effectiveness of the proposed method has been evaluated on both one - stage and two - stage video instance tracking / segmentation benchmarks."
SP:1175ad16382b349ab1a39895150172d266abe571,"This paper studies the role of gradient flow in the optimization of deep neural networks. The main result of the paper is that gradient flow is a discrete variant of gradient descent in the sense that it approximates gradient descent. The degree of approximation depends on the curvature of the trajectory of the gradient flow. The paper shows that over deep linear neural networks with homogeneous activations, gradient flow trajectories enjoy favorable curvature, suggesting they are well approximated by gradient descent, which is an open question in the theory of deep learning. This finding allows the paper to translate an analysis of gradient - flow into a guarantee that gradient descent efficiently works."
SP:b8412e9ce82ce92125fe7cd3aff7bea8b906d16e,"This paper considers a stochastic multi - armed bandit ( MAB ) problem with delayed impact of actions. In this setting, actions taken in the past impact the arm rewards in the subsequent future, which is prevalent in the real world. For example, the capability to pay back a loan for people in a certain social group might depend on historically how frequently that group has been approved loan applications, which may have a long - term impact on the likelihood of them getting the loan. The authors propose an algorithm that achieves a regret of $ \tilde{O}(\KT 2/3)$ where K is the number of arms and T is the learning horizon, where $ T$ is the time horizon in the bandit setting. The goal is to maximize the collected utilities over time while taking into account the dynamics created by the delayed impacts of historical actions.   The algorithm is based on the regret decomposition of regret into $ \Omega(T)$ and $ \sqrt{T } \log T$, with $ \mathcal{T}$ being the regret of actions taken during the learning process. The proposed algorithm is shown to have a regret lower bound of $ O(KT 2 / 3 ) $ and show a matching regret upper bound $ \log(KT2/3 ) $. The main contributions of the paper are as follows :   1. 	 The authors formulate this delayed and longterm impact of action within the context of actions with delayed delayed impact in the multi armed bandits setting. They generalize the MAB setting to encode the dependency of this “ bia ” due to the delayed “ action history during learning ”. They show that the long term regret is independent of the action history and long term action history. They also show that regret decomposes into a “ short term regret ” and “ medium term regret. ”    2. The algorithm achieves an $ O(\KT)$ regret and shows a regret matching lower bound."
SP:9c1d678dff5f609197dc3cfb67b841827f4a439a,This paper proposes an end - to - end solution for video instance segmentation ( VIM ) that efficiently encodes the context within the input clip. The key idea is to utilize concise memory tokens as a means of conveying information as well as summarizing each frame scene. The features of each frame are enriched and correlated with other frames through exchange of information between the precisely encoded memory tokens. The proposed method is evaluated on the latest benchmark sets and achieves state - of - the - art performance while having a considerably faster runtime ( 89 FPS ). The method can also be applied to near - online inference for processing a video in real - time.
SP:6c922eaa358f6fb9771690b1240e4f6f08a35b69,"This paper proposes a graph embedding method called residual2vec that can be applied to graph embeddings. The method is based on random graphs drawn from a graph via random walks. The authors show that random walks are biased by the degree of each node, where a node is sampled proportionally to its degree. To overcome this bias, the authors propose to use a random graph drawn from the same graph with the same degree as the context node. The proposed method is evaluated on two tasks : link prediction and clustering performance, and graph clustering and edge prediction performance. The results show that the proposed method outperforms the baseline methods in both tasks."
SP:851eac96135b577a5014166edcb43db6a190cf4b,"This paper studies the problem of estimating the power of discrete distributions in the context of local differential privacy ( DP ), i.e. when $ f(x ) = \mathbb{R}^T $ and $ \mathcal{P}$ samples $ f$ are $ \alpha$-locally differentially private ( LDP ), meaning that each $ x$ is produced using one individual attribute $ \pi$ of the dataset $ f$. The authors propose two privacy mechanisms that are sequentially interactive or non - interactive, depending on whether the data is publicly available or not. In the non - inter - active case, the authors propose a two - step procedure that attains the parametric rate ( $ \nα2 $-1 / 2 $ when $ \� $ goes to 2 ), which is similar to the results obtained in the multinomial model. However, due to the privacy constraint, the rates obtained are slower and similar to those obtained in Gaussian model by Collier et al. [ 9 ]. The authors also give lower bounds results over all α - LDP mechanisms and all estimators using the private samples."
SP:a0408b54f88a26479f33f36bb27e0a675f637ccd,"This paper studies the problem of online multiclass classification in a setting where the learner ’s feedback is determined by an arbitrary directed graph. While including bandit feedback as a special case, feedback graphs allow a much richer set of applications, including filtering and label efficient classification. For this new algorithm, the authors prove surrogate regret bounds that hold, both in expectation and with high probability, for a large class of surrogate losses. Their bounds are of order B \sqrt{B }, where B is the diameter of the prediction space, K is the number of classes, T is the time horizon, and ρ is the domination number ( a graph - theoretic parameter affecting the amount of exploration ). In the full information case, they show that GAPPLETRON achieves a constant surrogate regret of order, and also prove a general lower bound of order max { BK, \� T }."
SP:490262589efce6fb10b913431ec6db8d4e5b2dec,"This paper studies the problem of explainable clustering in the setting first formalized by Dasgupta, Frost, Moshkovitz, and Rashtchian ( ICML 2020 ). In particular, a k - clustering is said to be explainable if it is given by a decision tree where each internal node splits data points with a threshold cut in a single dimension ( feature ) and each of the k leaves corresponds to a cluster. The authors give an algorithm that outputs a clustering that is oblivious to the data points and runs in time O(dk log k ), independent of the number of data points. Their upper and lower bounds also generalize to objectives given by higher p - norms. This improves over the previous best upper bounds of O(k ) and O(\k), respectively, and nearly matches the previous lower bound for k - means."
SP:6a9e47be710ddaf386bffc54d003d7dc2b67fdc3,"This paper proposes a multilingual pre - trained language model ( PrLM ) that supports both explicit universal dependency parsing and implicit language modeling. The proposed multilingual PrLM uses Syntax in terms of universal dependency parse as not only a pre - training objective but also learned representation in the downstream task use. Experiments are conducted on two multilingual language understanding ( NLU ) benchmarks and linguistic structure parsing datasets, demonstrating the effectiveness and stronger cross - lingual modeling capabilities of the proposed model."
SP:94f4b65214a648cbc84f13beba45a825e2e9901a,"This paper proposes Dual - Aspect Collaborative Transformer ( DACT ) to learn embeddings for the node and positional features separately, instead of fusing them together as done in existing ones, so as to avoid potential noises and incompatible correlations. The positional features are embedded through a novel cyclic positional encoding ( CPE ) method to allow Transformer to effectively capture the circularity and symmetry of VRP solutions. The authors also train DACT using Proximal Policy Optimization and design a curriculum learning strategy for better sample efficiency. Results show that DACT outperforms existing Transformer based improvement models, and exhibits much better generalization performance."
SP:e5c8680d8da9e7548fcb9bb5c073848eb80e1dd0,"This paper proposes a method for evaluating the performance of state - of - the - art generative models in the context of Bayesian optimization. The method is based on the assumption that the Bayes error of a generative model is invariant under an invertible transformation ( e.g., a normalizing flow ). The authors show that this assumption holds for Gaussian Gaussian distributions. They then use this assumption to derive exact Bayes errors for the learned flow models, which are then used to evaluate the intrinsic hardness of standard benchmark datasets. They also show that by varying the temperature of the learned models, they can generate synthetic datasets that closely resemble the standard benchmark dataset.  "
SP:2896679f0472522bc3334178cd7574494cf12b7b,"This paper proposes an initialization method for neural network parameters that is both automated and architecture agnostic. The method is based on a scalar multiplier variable in front of each parameter block, and then optimizing these variables using a simple numerical scheme. Grad Init accelerates the convergence and test performance of many convolutional architectures, both with or without skip connections, and even without normalization layers. It also improves the stability of the original Transformer architecture for machine translation, enabling training it without learning rate warmup using either Adam or SGD."
SP:f69731403592fa5bdd4ca327708582d615aa131c,"This paper proposes a new linear - mixed - effect model for estimating disease progression using longitudinal data. The proposed method is based on a diffeomorphism - based approach that learns the Euclidean distance metric as the push - forward of a linear function. The authors propose to use a Riemannian manifold to embed the data in a patient - specific trajectories distributed around a central geodesic, and learn a few interpretable parameters characterize subject trajectories at the cost of a prior choice of the metric, which determines the shape of the trajectories. The results compare favorably to the 56 methods benchmarked in the TAD challenge."
SP:438e906f52c4c0538956b51a2270b3ac498b27a8,"This paper proposes a new routing - by - memory mechanism for convolutional neural networks ( CNNs ). In each stage of the network, parallel procedural units ( PUs ) are introduced, which consist of a memory head and a procedure. For an intermediate feature, the memory head searches its closest memory and forward it to the corresponding procedure to assign similar intermediate features to the same specialized procedures. In this way, different procedures are tailored to different features and therefore tackle them better with the proposed mechanism can be trained efficiently using a four - step training strategy. Experimental results show that the proposed method improves the performance of VGGNet, ResNet, and EfficientNet with a negligible extra computational cost."
SP:d240173080cd3647dbaa5173a6422396f226775b,"This paper studies the equivariance properties of polynomials under symmetries of scalar products. The authors show that a scalar product is equivariant to translation, rotation, reflection ( Parity ), boost ( Relativity ), and permutations of scalars. They further show that polynomial functions can be parameterized universally in terms of a lightweight scalar collection ( scalar - based method ). Finally, the authors provide some numerical examples to support their theoretical results."
SP:72c0f47566904deb27d8157da30807ec1d6b5685," object detection is a fundamental task in computer vision. The most commonly used loss functions for bbox regression are the Intersection over Union ( IoU ) loss and its variants. In this paper, the authors generalize existing IoU based losses to a new family of power IoU losses that have a power Iou term and an additional power regularization term with a single power parameter $ \alpha$. The authors also analyze properties such as order preservingness and loss / gradient reweighting. Experiments on multiple object detection benchmarks and models demonstrate the superiority of the proposed loss function over IoU - based losses."
SP:397125177d7007316d67194ec00d5dc57b44ac79,"This paper proposes Distributionally Robust Imitation Learning ( DROIL ), a distributionally robust imitation learning method for MDPs where the reward function is not given but demonstrations from experts are. The authors show that DROIL can be seen as a framework that maximizes a generalized concept of entropy. DROIL optimizes both stationary and non - stationary policies and, unlike prevalent previous methods, it does not require repeatedly solving an inner reinforcement learning problem.   The authors also develop a novel approach to transform the objective function into a convex optimization problem over a class of loss functions that are additive over state and action spaces. Experiments on synthetic data and a highway driving environment show the effectiveness of DROIL."
SP:58f220bbbed8d3e0633b408fca3b6838c4ad323d,"This paper proposes general post - processing algorithms for individual fairness ( IF ) in the setting where the learner only has access to the predictions of the original model and a similarity graph between individuals guiding the desired fairness constraints. The authors cast the IF post -processing problem as a graph smoothing problem corresponding to graph Laplacian regularization that preserves the desired “ treat similar individuals similarly ” interpretation. The theoretical results demonstrate the connection of the new objective function to a local relaxation of the individual fairness. Empirically, the postprocessing algorithms correct individual biases in large - scale NLP models such as BERT, while preserving accuracy."
SP:ef791aa29decd839e7e583c9d1f71e8309ca87ef,"This paper proposes a structure - aware dual graph aggregation network ( SADGA ) for the cross - domain Text - to - SQL task. The proposed network is based on the graph structure to provide a unified encoding model for both the question - graph and the database schema, and a question - schema linking method to learn the mapping between words in the question and tables / columns in the database schemas. Empirical results show that the proposed method achieves 3rd place on the challenging T2S benchmark Spider."
SP:a2fa25a4539a38af61a0993f65ecc14339f26c2e,This paper proposes two new strategies to improve the performance of stochastic computation graphs. The first is to increase the scale parameter of the Gumbel noise during training. The second is to use a more complex discrete - continuous computation graph with multiple discrete components. The authors show that these models generalize better than standard discrete and continuous models on several benchmark datasets.
SP:bb3ec363e90269db4a2ba99d8107cb56f86e68f0,"This paper studies the robustness of Bayesian neural networks ( BNNs ) under covariate shift. The authors show that a BNN with high - fidelity approximate inference via full - batch Hamiltonian Monte Carlo ( HMC ) does not generalize as well as a Bayesian model with average inference. They also show that the same issue does not affect approximate inference procedures or classical maximum a - posteriori ( MAP ) training. Finally, the authors propose two novel BNN models that improve robustness to covariate shifts and show that their proposed models can generalize better."
SP:f86ec7042e9b73ae071704a6d3ed17d7e3da1b75,"This paper studies the evaluation of meta - learning methods in two settings : in - distribution ( ID ) and out of distribution ( OOD ). The authors identify that most existing few - shot classification benchmarks instead reflect OOD evaluation, as they use disjoint sets of train ( base ) and test ( novel ) classes for task generation. They also show that meta - learners that perform better on existing OOD datasets may perform significantly worse in the ID setting. Finally, the authors provide suggestions on how to construct FSL benchmarks to allow for ID evaluation as well as more reliable out - of - distribution evaluation."
SP:371f77148b4f00a929f7c118b1bb7c5a6238d264,"This paper proposes an open rule induction method for rule generation. The authors argue that the current LM - based rule generation methods are “ learning rules from rules ”, which limits these methods to only produce “ canned ” rules whose patterns are constrained by the annotated rules, while discarding the rich expressive power of open rules. To this end, the authors propose the Orion method, which aims to induce open rules utilizing the knowledge in LMs. They conduct extensive experiments to verify the quality and quantity of the inducted open rules, and the automatically inducted rules even outperform the manually annotated rule inductions."
SP:8be2e0ea4a83fe32a4859f456007a829e5e9270a,"This paper proposes Implicit Constraint Q - learning ( ICQ ), a novel offline RL algorithm that alleviates the extrapolation error by only trusting the state - action pairs given in the dataset for value estimation. ICQ extends ICQ to multi - agent tasks by decomposing the joint - policy under the implicit constraint. Experimental results demonstrate that ICQ achieves state - of - the - art performance in the challenging StarCraft II task."
SP:1939b24b68970c33ca16ce238deed257f76d009e,"This paper proposes a non - uniform perturbation method for adversarial training of machine learning models. The key idea of the proposed method is to introduce semantically meaningful feature dependencies in adversarial examples ( AEs ). The proposed perturbations are based on the empirical data distribution, both on the correlation between the features and the importance of the features themselves. Experiments are conducted on malware classification, credit risk prediction, and spam detection. Results show that the proposed approach is more robust to real - world attacks compared to uniform AEs."
SP:417b30930b245667d777e5d90ee80dd41546760e,"This paper extends the theory of Tikhonov regularization to generalized self - concordant loss functions ( GSC ). The main result is that, under some assumptions on the source and capacity conditions of the GSC, the iterated regularization scheme can be used to obtain fast and optimal rates of excess risk estimation. The results are obtained for GSCs that contain the logistic loss.    The main contributions of this paper are :   1. Extensive theoretical analysis of the convergence rate of the excess risk estimator of a GSC under the source - capacity condition assumption. 2. The convergence of the optimal rate of a regularized GSC to the optimal excess risk. 3. Fast and optimal convergence rates are obtained using iterated Tikhonenov regularisation."
SP:1caeee4f00b52fe356ff4e5dd004d0203e838370,"This paper proposes a new kind of linear transform named Deformable butterfly ( DeBut ) that generalizes the conventional butterfly matrices and can be adapted to various input - output dimensions. The proposed DeBut layer can be applied as a drop - in replacement of standard fully connected and convolutional layers and demonstrate its superiority in homogenizing a neural network and rendering it favorable properties such as light weight and low inference complexity, without compromising accuracy. The natural complexity - accuracy tradeoff arising from the myriad deformations of DeBut layers also opens up new rooms for analytical and practical research."
SP:d345ce1d7afc367ee1a9fb68d50ff1b2219f02cb,"This paper proposes MetA Reusable Knowledge ( MAM ), a method for mitigating catastrophic forgetting in neural networks. Catastrophic forgetting occurs when the weights of a network are overwritten during the training of a new task, causing forgetting of old information. This paper proposes a method that keeps a set of shared weights among tasks as a common knowledge base ( KB ) that is not only used to learn new tasks, but also enriched with new knowledge as the model learns new tasks. The proposed method uses a metalearning approach to incrementally enrich the KB with new KB knowledge and to foster weight reusability among tasks. By using MAM, the authors achieve state of the art results in several popular benchmarks, surpassing the best performing methods in terms of average accuracy by over 10 % on the 20 - Split - MiniImageNet dataset."
SP:722c52467e384058f8fdffa254d0e8db47440a64,"This paper proposes a data - driven framework for scheduling heuristics in exact MIP solver. The proposed framework learns from data describing the performance of primal heuristic on two classes of challenging instances. The authors formalize the learning task and propose an efficient algorithm for computing such a schedule. Empirically, the proposed method is able to reduce the average primal integral by up to 49 % on two types of challenging instance."
SP:5a21f0a49731dcb1d68deb06a75138e8e9d514d5,"This paper studies a setting in which trajectory labels are generated by an unknown parametric model and the learner receives binary feedback only once at the end of an episode. The setting is an extreme test case for theory, but it is also arguably more representative of real - world applications than the traditional requirement in RL practice that the learners receive feedback at every time step. The authors provide a statistically and computationally efficient algorithm that achieves sub - linear regret in this setting."
SP:e66bd9582058ba0f6091bb1042ce2ecfdaae1515,"This paper proposes a novel edge representation learning framework based on Dual Hypergraph Transformation ( DHT ) that transforms the edges of a graph into the nodes of a hypergraph. This dual hypergraph construction allows us to apply message - passing techniques for node representations to edges, and then cluster or drop edges to obtain holistic graph - level edge representations. Experiments validate the effectiveness of DHT on graph generation and graph classification."
SP:e398873e29b05176e1d52dc6f86a59a4f405e6fd,"This paper studies the sufficiency of mutual information maximization ( MI ) based objectives for learning state representations in the context of reinforcement learning ( RL ). The paper considers the question of how much mutual information is required for a state representation to be sufficient for learning and representing an optimal policy. The authors consider the case of MDPs with a two - stage MDP structure, where the MDP objective is to maximise mutual information ( mutual information ) between the state representation and the optimal policy, and study several popular MI objectives. They find that two of these objectives can yield insufficient representations given mild and common assumptions on the structure of the state representations. The theoretical results are verified with empirical experiments on a simulated game environment with visual observations."
SP:50181f740910195d3a50dd7d7f8cbb1c476d730b,"This paper proposes a novel method for sparse steerable convolution ( SS - Conv ) for sparse 3D object semantic analysis. The method is based on a feature - sharing module that takes advantage of the advantage of SE(3)-equivariant deep feature learning on sparse tensors. The authors also propose a general pipeline for precise estimation of object poses, wherein a key design is a Feature - Steering module. The proposed method is evaluated on three tasks ( pose estimation, pose refinement, and pose tracking ). The results show that the proposed method outperforms existing methods on all metrics."
SP:d746bfb200577c980d92727bb0b1a3c23e7bfdc5,"This paper proposes a dynamic token sparsification framework to prune redundant tokens progressively and dynamically based on the input tokens in vision transformers. Specifically, a lightweight prediction module is added to different layers to estimate the importance score of each token given the current features, and a masking strategy is proposed to differentiably prune a token by blocking its interactions with other tokens. The proposed method greatly reduces the FLOPs and improves the throughput by over 40 % while the drop of accuracy is within 0.5 %. DynamicViT models can achieve very competitive complexity / accuracy trade - offs compared to state - of - the - art CNNs and Vision Transformer models on ImageNet."
SP:d0b6cde42b1cba5e6e3c7c5131426fd84adbd3d7,"This paper studies the distribution - free inference in continuous - time regression. The authors consider the setting where the features X are continuously distributed with respect to the underlying regression function E[Y | X ]. In this setting, they show that any confidence interval with non - vanishing width must have non vanishing width, even as sample size tends to infinity. In contrast, at the other extreme, if X takes only a small number of possible values, then inference is trivial to achieve.   The authors also show that there are several distinct regimes in between the finite and the continuous setting, where vanishing - width confidence intervals are achievable if and only if the effective support size of the distribution of X is smaller than the square of the sample size. The main results are :   1. In the finite - time setting, all confidence intervals of the form $ \hat p(y|x)$ are non vanishing. This is because the support size is a function of the dimensionality of the feature space. 2. At the extreme, any confidence intervals with vanishing width greater than $ \widetilde{P}(Y|X)$ can not be non vanishing, even if X is a small fraction of the total number of features in X.   3. The extreme setting is the case where the feature set X is Gaussian and the regression function is the conditional mean of a Gaussian distribution. This setting is similar to the extreme setting in [ 1 ], but the authors show that the confidence intervals for this conditional mean can not have vanishing width."
SP:123952325765c040c3078fc7dca2b6d370e55590,"This paper proposes Representation Neutralization for Fairness ( RNF ), a method for reducing the discrimination of DNN models by debiasing only the task - specific classification head of the encoder of the DNN model. RNF leverages a bias - aware model to generate proxy annotations for sensitive attributes in low - resource settings. The proposed method is evaluated on CIFAR-10, SVHN, and ImageNet. Results show that the proposed method can effectively reduce the discrimination with minimal degradation in the classification head's performance."
SP:210eb2c811f966bb1ac53932cacabbad9bb608fe,This paper proposes a new convolutional neural network ( CNN ) layer that is invariant to translations and rotations. The main idea is to use Bessel functions ( Bessels ) in the convolution layer of CNNs to make CNNs more robust to translation and rotation. The proposed B - CNNs are shown to be more robust than standard CNNs in the case of translation invariance and rotation invariance. The paper is well written and easy to follow.
SP:ee51ecbd476d5b65903c942a62be89ff5d91698b,"This paper proposes a new large - scale solver for kernel ridge regression. The proposed approach combines partitioning with random projections and iterative optimization to reduce space and time complexity while provably maintaining the same statistical accuracy. In particular, the authors construct suitable partitions directly in the feature space rather than in the input space to promote orthogonality between the local estimators, thus ensuring that key quantities such as local effective dimension and bias remain under control. The authors characterize the statistical - computational tradeoff of the model, and demonstrate the effectiveness of the method by numerical experiments on large scale datasets."
SP:1f096d6fabd5b1fde43d06c552d46d87cd35cb4a,"This paper proposes a communication method for reinforcement learning agents that learns to communicate discrete tokens via word embedding from a learned continuous space. The authors argue that the one - hot communication strategy of using one hot vectors as discrete communication tokens prevents agents from acquiring more desirable aspects of communication such as zero - shot understanding. To address this problem, the authors propose to use discrete tokens that are learned in a similar way as word embeddings in natural language processing ( NLP ) and show in a decision theoretic framework that their communication strategy optimizes communication over a wide range of scenarios. In self - play experiments, they validate that their trained agents learn to cluster tokens in semantically - meaningful ways, allowing them communicate in noisy environments where other techniques fail, and demonstrate both that agents using their method can effectively communicate and effectively respond to human human communication and that humans can understand human communication."
SP:8630ccc627534f9033bced04e2137a897ffef701,"This paper proposes CoAtNets, a transformer - based network architecture that combines the strengths of convolutional and self - attention networks. The authors show that depthwise convolution and attention can be unified via simple relative attention and vertically stacking convolution layers and attention layers in a principled way. The proposed architecture achieves state - of - the - art performance under different resource constraints across various datasets.   The paper is well - written and easy to follow."
SP:d3ecbeeffa5ab365743ba8653c6739f24742ee31,"This paper proposes a new second - order oracle bound for the expected risk of a weighted majority vote. The bound is based on a novel parametric form of the Chebyshev - Cantelli inequality, which is amenable to efficient minimization. The authors also derive a new concentration of measure inequality, called PAC - Bayes - Bennett, which they use for empirical estimation of the new bound. The empirical evaluation shows that the new bounds improve on the work of Masegosa et al [ 2020 ]."
SP:5bac542a6532d43cf100e085398b4a4783719814,"This paper proposes a weakly - supervised method for the task of audio - visual video parsing. The proposed method exploits both the common and diverse event semantics across videos to identify audio or visual events. In addition, the proposed method explores event co - occurrence across audio, visual, and audio - Visual streams. The discovered supervisory signals across different videos and modalities can greatly facilitate the training with only video - level annotations."
SP:8fd6a03c1794afa524328d45f4232eacf6f86693,"This paper proposes a personalized FL algorithm called QuPeD for collective ( personalized model compression ) training via knowledge distillation ( KD ) among clients who have access to heterogeneous data and resources. The authors propose an alternating proximal gradient update for solving this compressed personalization problem, and propose an algorithm for learning quantized models through a relaxed optimization problem, where quantization values are also optimized over. Experiments are conducted to validate the effectiveness of the proposed algorithm on personalized FL methods, FedAvg, and local training."
SP:fca8b4f1e765cf1724a37f0ae9a7dac1cb79c8b1,"This paper proposes a new method for constrained clustering based on deep generative models. The proposed DC - GMM model is based on the framework of stochastic gradient variational inference ( SDVI ). The key idea is to use a prior distribution over the data conditioned on the prior clustering preferences ( i.e., pairwise constraints ). These constraints guide the clustering process towards a desirable partition of the data by indicating which samples should or should not belong to the same cluster. The authors provide extensive experiments to demonstrate the effectiveness of the proposed method."
SP:84379c0c881b7390ecc22fb398edfaf66d1af1ff,"This paper proposes Neural Tangent Kernel ( NTK ), a kernel - based method for training infinitely - wide neural networks. The authors propose a near input - sparse approximation algorithm for NTK, by sketching the polynomial expansions of arc - cosine kernels. The convolutional counterpart of NTK ( CNTK ) can transform any image using a linear runtime in the number of pixels. They prove a spectral approximation guarantee for the NTK matrix, by combining random features of the arc - cosmicine kernels with a linear regressor. They benchmarked their methods on various large - scale regression and classification tasks, and show that a linear Regressor based on the proposed NTK features matches the accuracy on the CIFAR-10 dataset."
SP:fa2668083ff3bb592c29a4c6822ae96ff54d0dbe,This paper proposes a multi - range 3D motion prediction framework for multi - person motion prediction. The proposed Multi - Range Transformers model is composed of a local - range encoder for individual motion and a global - range decoder for social interactions. The local range and global range encoders are trained jointly with a decoder that takes the corresponding pose as a query. The global range and local range decoders attend to both the local and global features of the encoder. The decoder predicts motion for each person by taking a corresponding pose and the global range of the decoder is used for social interaction. The model is evaluated on long - term motion prediction and generates diverse social interactions by automatically dividing 15 people into different interaction groups.
SP:0a0e07af37c8fe8580639b1df62d27b6f63f8dee,"This paper proposes a new approach, model predictive program synthesis ( MPPS ), that uses program synthesis to automatically generate the guiding programs for long - horizon planning problems. The approach trains a generative model to predict the unobserved portions of the world, and then synthesizes a program based on samples from this model in a way that is robust to its uncertainty. In the experiments, the authors show that their approach significantly outperforms non - program - guided approaches on a set of challenging benchmarks, including a 2D Minecraft - inspired environment."
SP:5bb42b178b0d27da271bfa60e633fdac718638c4,"This paper studies the problem of causal imitation learning in the presence of a mismatch between the behavior of the demonstrator and the imitator. The mismatch occurs when there is information in the environment that is different from that of the monkey being imitated ( e.g., a different set of sensors ), or when the environment model is not the same as the one observed by the monkey. The main contribution of this paper is to propose a graphical algorithm for determining the mismatch. The algorithm is based on Zhang et al. ( 2020 ), but the authors extend it to the setting of sequential decision - making, which is more challenging than the standard single - stage setting. They also provide a graphical criterion for determining if the imitation is causal imitation. Finally, the authors conduct experiments on synthetic data to verify their theoretical results."
SP:85bd81f0c5b6ccbc421ebbaf6f5c72164bc70b7f,"This paper presents a slot - wise, object - based transition model that decomposes a scene into objects and aligns them to maintain a consistent order across time, and predicts how those objects evolve over successive frames. The model is trained end - to - end without supervision using transition losses at the level of the object - structured representation rather than pixels. A novel alignment module is introduced to deal with two issues that are not handled satisfactorily by other transition models : object persistence and object identity. The combination of an objectlevel loss and correct object alignment over time enables the model to outperform a state - of - the - art baseline, and allows it to deal well with object occlusion and re -appearance in partially observable environments."
SP:f32eddbb5c33a8422c075579ff08aa9833338d44,"This paper studies a generic importance sampling weighted ERM algorithm for using adaptively collected data to minimize the average of a loss function over a hypothesis class and provides first - of - their - kind generalization guarantees and fast convergence rates. Their results are based on a new maximal inequality that carefully leverages the importance sampling structure to obtain rates with the good dependence on the exploration rate in the data. For regression, the fast rates leverage the strong convexity of squared - error loss. For policy learning, they provide regret guarantees that close an open gap in the existing literature whenever an open - gap exists."
SP:f549a0c231b71bae0acbed6e3afb41890ee89cd9,"This paper proposes a reweighting strategy for kernel - reweighted regression. The proposed method is based on a doubly non - negative matrix that is used to reparametrize the sample weights. Experiments are conducted on CIFAR-10, SVHN, and Cifar-100 datasets."
SP:fe12e13602925b9400fd596a987755beb10aa3d1,"This paper proposes a gradient estimator for training models with categorical discrete latent variables. The categorical setting is a natural extension of the binary random variable setting, where previous gradient estimators are usually based on continuous relaxations. The proposed estimator is based on importance sampling and statistical couplings. The main idea is to reparameterize categorical variables as sequences of binary variables and Rao - Blackwellization. The experimental results show that the proposed estimators provide state - of - the - art performance, even with additional additional Rao - blackwellization parameters."
SP:e16fdf963ec2f9c0d79fa404e47e7862a5d6e922,"This paper proposes a new predictor - based predictor for neural architecture search ( NAS ). The proposed method, called WeakNAS, is a paradigm shift from fitting the whole architecture space using one strong predictor, to progressively fitting a search path towards the high - performance sub - space through a set of weaker predictors. Extensive experiments demonstrate that WeakNAS costs fewer samples to find top - performance architectures on NAS - Bench-101 and NAS-Bench-201 compared to state - of - the - art ( SOTA ) predict - based NAS methods, and requires at least 7.5x less samples. The paper also achieves a new SOTA result of 81.3 % in the ImageNet MobileNet Search Space."
SP:8f74abb04037ba2e59dcf8320dc555b149f68ed8,"This paper proposes a method for long - term exploration based on a globally consistent coordinate system with fixed additive latent dynamics. The key idea is to learn a global coordinate system of latent codes that are globally consistent, so that agents can reach more states in the long term while still optimizing a local objective. The method is called EDDICT ( Entropic Desired Dynamics for Intrinsic ConTrol ), and it is shown to be tractable and interpretable. The authors also show that the proposed method can be far more exploratory compared to prior methods, as demonstrated by improved state coverage and increased unsupervised performance on hard exploration games."
SP:c731a78c3e7f98ccd0253b51a0d42bf8deeb71f9,This paper proposes a fragment - based generative RL method for generating chemically realistic and pharmacochemically acceptable molecules with large docking scores using a molecular docking program. The generated molecules are generated by a fragment based generation method and a novel error - based experience replay ( PER ) method. The authors show that PER improves the predictive error - PER ( FREED ) performance and the generated molecules of higher quality compared to existing methods while achieving state - of - the - art performance on two of three targets in terms of the docking scores of generated molecules.   The authors also show that the proposed method can be applied to generative models for drug design.
SP:b938bca513e7de1231212064caf8877a78d8b612,"This paper studies the problem of learning directed acyclic graphical models from observational data in general settings without specific distributional assumptions. The approach is information - theoretic and uses a local Markov boundary search procedure in order to recursively construct ancestral sets in the underlying graphical model. Perhaps surprisingly, the authors show that for certain graph ensembles, a simple forward greedy search algorithm suffices to learn the Markov boundaries of each node. This substantially improves the sample complexity, which is at most polynomial in the number of nodes. This is then applied to the entire graph under a novel identifiability condition that generalizes existing conditions from the literature. As a matter of independent interest,   the authors establish finite - sample guarantees for the problem   of recovering Markov bounds from data."
SP:af08109d4c45dc9401efb0e63c22167e9da28adb,"This paper studies differential privacy ( DP ) algorithms in the setting where each user has a single sample and the privacy protection is enforced at the level of each user ’s data. In this setting, the authors show that, as long as each user receives sufficiently many samples, we can learn any privately learnable class via an (, )DP algorithm using only $ O(log(1/\sqrt{d})$ users. The authors also show that such algorithms can be used even in the local model, where $ d$ is the probabilistic representation dimension. In both cases, they show a nearly - matching lower bound on the number of users required.   The main contribution of this paper is a generalization of global stability that allows the use of public randomness, and the authors employ a correlated sampling strategy to show that the global stability can be boosted to be arbitrarily close to one."
SP:da4f21d107a7f442c4d3e3ec13bdb44b041e07cf,"This paper studies the convergence of value iteration networks ( VINs ) that learn the transition and reward models of a latent Markov decision process whose value predictions fit the data. In particular, the authors consider a linear parametrization of the value function and show that the gradient descent of VIN converges to global optima in both nonlinearity and non - linearity introduced by the implicit representation. The authors also derive convergence rates for this implicit representation that are substantially faster than its explicit counterpart. Finally, empirical results in some simple domains that illustrate the theoretical findings are provided."
SP:992aa07d4f815d1c81f967374590eece933833b1,"This paper proposes a method for refining knowledge graph ( KG ) embeddings based on the PSL - KGI framework. The method is motivated by the observation that KGs extracted from text sources are often noisy and lead to poor performance in downstream application tasks such as KG - based question answering. The authors propose a KG refinement framework called IterefinE which iteratively combines the two techniques – one which uses ontological information and inferences rules, and the other which does not. Experiments on a range of KG benchmarks show that the proposed method is able to reject noisy facts from KGs and at the same time infer higher quality new facts."
SP:676fc4a3041af22e8f20ccba7daa2a0b1f5d6af5,"This paper proposes a novel evaluation framework for knowledge base completion ( KB ) methods. The proposed framework is based on a new evaluation data structure that uses KB queries, i.e., facts where one entity is missing from the KB and the correct answers are randomly removed. The authors construct a data set FB14k - QAQ and evaluate a number of state - of - the - art KB embeddings models on their new benchmark. The results show that the current state of KB embedding models does not necessarily translate to good performance on the actual completion task. The paper also provides a simple yet effective method for thresholding KB queries to improve the performance of existing embedding methods."
SP:83fe0a496a79bcf97ccba1c6d34b7d11e7d5c330,"This paper proposes an Alternating Roles Dialog Model ( ARDM ) framework to generate human - like responses for dialog system tasks. ARDM uses a pretrained language model to model each speaker separately and takes advantage of the large pre - trained language models such as BERT and GPT-2. It requires no supervision from human annotations such as belief states or dialog acts to achieve effective conversations. It outperforms or is on par with state - of - the - art methods on two popular task - oriented dialog datasets. It can generalize to more challenging, non - supervised tasks such as persuasion."
SP:b11c06b7c4ef1aa43c59f808a679425e302d158e,"This paper studies the problem of estimating the probability that the classification predicted by a deep neural network ( DNN ) is correct ( or in the Top 5 ). The authors define the notion of implied loss and prove that if an uncertainty measure is an implied loss, then low uncertainty means high probability of correct ( top k ) classification on the test set. They demonstrate empirically that these values can be used to measure the confidence that a DNN is correct and propose confidence measures for top k which can be evaluated by binning values on the tested set. The proposed method is simple to use on existing networks and the proposed confidence measures are easy to implement."
SP:ab9666e15f2a0113d96cb4b47b1cbb30fa1f7982,"This paper studies the generalization performance of neural networks at large depths. The authors show that in the large depth limit, random networks before training are Gaussian Processes governed by a kernel called Neural Tangent Kernel ( NTK ), which simplifies in much the same way as that of the NTK kernel. They show that there are large regions of hyperparameter space where networks can only memorize the training set in the sense that they reach perfect training accuracy but completely fail to generalize outside the training data set. By comparing CNNs withand without-global average pooling, they show that CNNs without averaging pooling have very nearly identical learning dynamics to Fully Connected Networks ( FCNs ) and Convolutional Neural Networks ( CNNs ). The paper also shows that gradient descent training of wide neural networks is described by NTK that is related to NTK and the theoretical results are confirmed by experiments on real datasets."
SP:d3470c35aae48bf92439a55fdb98ccf07100e567,"This paper proposes a graph - based method, GRAPHQA, for the estimation of the quality of protein models. The method is based on Graph - based Representation Learning ( GRAPH ), which is used to model the sequential and 3D structure of protein molecules. The paper is well - written and easy to follow. The proposed method is evaluated on both hand - engineered and representation - learning approaches. The experimental results show that the proposed method performs better than the state - of - the - art in terms of both accuracy and computational efficiency.  "
SP:5188280131b58a35d3deda126a0754aea8fa6e58,"This paper revisits the loss function of linear neural networks from the perspective of the geometry of the functional space. The functional space is either the set of all linear maps from input to output space or a determinantal variety, i.e., a set of linear maps with bounded rank. The authors draw a distinction between pure critical points and spurious critical points, which only depend on the function space, and arise from the parameterization of this space by the network ’s weights. They apply this perspective to revisit and extend the literature on the loss functions of linear networks with different loss functions and different parameterizations. Their analysis clearly illustrates that the absence of “ bad ” and “ smooth convex losses ” is true for arbitrary smooth losses in the case of architectures that can express all linear map ( “ non - filling architectures ” ) but it holds only for the quadratic loss for linear networks."
SP:ee71597ceab23eb4db1d6608f15f80ad51f7ff6d,"This paper proposes a framework SEED ( Sampling, Encoding, and Embedding Distributions ) for inductive and unsupervised representation learning on graph structured objects. Specifically, given an input graph, the proposed SEED framework samples a number of subgraphs whose reconstruction errors could be efficiently evaluated, and encodes the subgraph samples into a collection of sub graph vectors. Theoretical analysis and empirical study demonstrate the close connection between SEED and graph similarity evaluation."
SP:d9406fdf0a180a5efc6f15ba8739524665f0f9d2,"This paper studies the Counterfactual regret minimization ( CFR ) methods for solving extensive games with imperfect information. The authors propose a new CFR algorithm that adopts a lazy update strategy to avoid traversing the whole game tree in each round. They prove that the regret of Lazy - CFR is almost the same as that of the vanilla CFR and only needs to visit a small portion of the game tree, which is provably faster than the standard CFR. They also conduct experiments to show that the proposed algorithm is fast in practice."
SP:023aa3dca1cf7992b22993a7088e8a74c92bb47e,"This paper proposes Distribution Matching Prototypical Network ( DMPN ) for Unsupervised Domain Adaptation ( UDA ), which learns transferable features by minimizing the feature distribution discrepancy between the source and target domains. The authors model the deep features from each domain as Gaussian mixture distributions and propose two new domain discrepancy losses with probabilistic interpretations. The first one minimizes the distances between the corresponding Gaussian component means of the source feature distribution and target feature distribution, while the second one minimises the pseudo negative log likelihood of generating the target features from source features. Extensive experiments are conducted over two UDA tasks over state - of - the - art approaches over the Digits Image transfer task and VisDA 2017 dataset. The hyper - parameter sensitivity analysis shows that the proposed method is robust w.r.t hyper - parametereter changes."
SP:40be996e8bb86e887077b762b87c7c34a786ac98,"This paper proposes a new method for conditioning CNFs on signals of interest for conditional image generation and downstream predictive tasks. The main idea is to partition the latent space into a class - specific supervised code and an unsupervised code that is shared among all classes for efficient use of labeled information. Since the partitioning strategy ( slightly ) increases the number of function evaluations ( NFEs ), the proposed method also employs gating networks to learn the error tolerances of its ordinary differential equation (ODE ). Empirically, this paper shows empirically that the proposed InfoCNF improves the test accuracy over the baseline while yielding comparable likelihood scores and reducing the N FEs on CIFAR10 on time - series data."
SP:97764e3393216106ff2ac3f550845acf4636119f,"This paper studies the approximation of the value function of an infinite - horizon discounted Markov Reward Processes ( MRP ) with nonlinear functions trained with the Temporal - Difference ( TD ) learning algorithm. The authors consider this problem under a certain scaling of the approximating function, leading to a regime called lazy training. In this regime the parameters of the model vary only slightly during the learning process, a feature that has recently been observed in the training of neural networks, where the scaling arises naturally, implicit in the initialization of their parameters. Both in the under and over - parametrized frameworks, the authors prove exponential convergence to local and global minimizers of the above algorithm in the lazy training regime. They then give examples of such convergence results in the case of models that trained with non - lazy TD learning."
SP:c518e4030f12b0f59ad1d7c0fc0ebd313c68ef95,"This paper proposes to use hypothesis verification as a reinforcement learning problem, where an agent is given a hypothesis about the dynamics of the world, and given an action to generate observations which can help predict whether the hypothesis is true or false. The authors exploit the underlying structure in the majority of hypotheses – they can be formulated as triplets ( pre - condition, action sequence, post - condition ). Once the agents have been pretrained to verify hypotheses with this structure, the agents can be fine - tuneded to verify more general hypotheses. The experiments show that agents trained end - to - end with the reward fail to learn to solve this problem. This work takes a step towards a “ scientist agent ” that develops an understanding of the   world by generating and testing hypotheses about its environment."
SP:6fa2f842b1bc993ed8024a3ce13dbd91529c61be,"This paper proposes a method to predict the latent representations of a given formula given a set of rewrites ( i.e. transformations ) applied to a given statement “ rewrite rule ”, by embedding the formula in a vector space, such that the vector can be used to predict whether a statement can be rewritten by other theorems. The authors define a rewrite rule as the set of transformations that can be successfully performed on a statement, and use graph neural networks ( GNNs ) to perform several steps of approximate reasoning in a fixed dimensional latent space. They perform sequences of rewrite steps both in formula space and in latent space, and compare the quality of embeddings of the resulting formulas to their predicted latent representations. The experiments show that graph neural network can make non - asymptotic predictions about the rewrite - success of statements, and even when they propagate predicted latent representation for several steps, even if they propagate for a few steps."
SP:a77ab500a5e7d4ea8430871d1e603941e92974fd,"This paper proposes a method for learning monocular dense depth estimation from images. The method is based on a global - local network architecture with an inductive bias. The global network consists of a global encoder and a global decoder and is trained with a loss function that minimizes the KL divergence between the global and local encodings of the input and output of the global network. In addition, the global encoders and global decoders are augmented with a KL divergence loss. The proposed method is evaluated on three image datasets and compared with a variety of state - of - the - art monocular depth estimation methods. The results show that the proposed method outperforms all of the other methods."
SP:2afba5e24478da4e9d493887c7cf00e288cc0deb,"This paper extends the idea of word pieces in natural language models to machine learning tasks on opaque ids. This is achieved by applying hash functions to map each id to multiple hash tokens in a much smaller space, similarly to a Bloom filter. The authors show that by applying a multi - layer Transformer to these Bloom filter digests, they are able to obtain models with high accuracy. They outperform models of a similar size without hashing and, to a large degree, model of a much larger size trained using sampled softmax with the same computational budget. The key observation is that it is important to use a multi-layer Transformer for Bloom filter Digests to remove ambiguity in the hashed input. They believe this provides an alternative method to solving problems with large vocabulary size."
SP:745dd86d7f7bba79a02d27922003b764b620f83e," - style clustering is proposed for the problem of finding 3D parts for objects in unseen categories. The proposed method is based on agglomerative clustering, which learns a grouping policy to progressively group small part proposals into bigger ones in a bottom - up fashion. The clustering policy is designed to restrict the local context for extracting part - level features, which encourages the generalizability to unseen categories without seeing any annotated samples. On the largescale fine - grained 3D part dataset, PartNet, they demonstrate that their method can transfer knowledge of parts learned from 3 training categories to 21 unseen testing categories."
SP:868fc6df740b04963442d5abcfe2f4845585cfc8,"This paper proposes a technique called “ neuron editing ” that learns how neurons encode an edit for a particular transformation in a latent space by defining an editing transformation on those neurons. By performing the transformation in this latent space, the authors encode fairly complex and non - linear transformations to the data with much simpler distribution shifts to the neuron ’s activations. The technique has the advantage of being generally applicable to a wide variety of data domains, modalities, and applications. The authors first demonstrate it on image transformations and then move to two main applications in biology : removal of batch artifacts representing unwanted noise and modeling the effect of drug treatments to predict the synergy between drugs."
SP:6dee6932e64fe47bb44dd42fc242fa9d89b8d89c,"This paper proposes a meta - learning approach for few - shot image classification and many - shot segmentation. The proposed method is based on first - order meta learning of initializations for deep neural networks that must produce dense, structured predictions given an arbitrary amount of training data for a new task. The authors propose a novel neural network architecture built for parameter efficiency and parameter efficient and fast learning which they call EfficientEfficientNeuralNetwork. They also propose a new benchmark dataset, FP - k, for the empirical study of how Meta - learning systems perform in both few-shot and many-shot settings. The experimental results show that the proposed method outperforms random and ImageNet - trained initializations on the FSS-1000 dataset and larger datasets.  "
SP:ec6f390f6d45fb79c33ae5d9c8a24cadb96fbd60,"This paper proposes a new method for semi - supervised few - shot learning based on Prototypical Random Walk Networks ( PRWN ). PRWN is a prototypical network that learns compact and well - separated class representations from a large amount of unlabeled data. The proposed method is built on top of the PN ( Ren et al., 2018 ) and a random walk loss that enables the network to learn representations that are compact. Experiments show that the proposed method achieves state - of - the - art performance on a variety of benchmark datasets."
SP:d12e687bd2ee9fa60554312e644bb0a6487974f1,"This paper proposes a new self - supervised training objective, Contrastive Sensor Fusion ( SSF ), which exploits coterminous data from multiple sources to learn useful representations of every possible combination of those sources. This method uses information common across multiple sensors and bands by training a single model to produce a representation that remains similar when any subset of its input channels is used. SSF is evaluated on a dataset of 47 million unlabeled remote sensing data."
SP:4d8e054f07006b4f896721b5c24da805727d2c22,"This paper proposes a new neural network pruning method that trains the unpruned weights from their final trained values using the same learning rate schedule as weight rewinding. The proposed method, Learning Rate Rewinding ( LRR ), rewinds the weights to their values from earlier in training and retrains them from there using the original training schedule. The authors show that LRR outperforms fine - tuning, forming the basis of a network - based pruning algorithm that matches the accuracy and compression ratios of several more network - specific state - of - the - art techniques."
SP:3bb1c79f9482e09828eda45fbb2e654f37219365,"This paper proposes a new notion of margin, called all - layer margin, for analyzing the generalization performance of deep neural networks. The main idea of the paper is to analyze the output margin of a neural network in terms of the all - layers of the network, i.e., the number of layers in the network after the output layer. The paper shows that a large output margin is associated with good generalization in deep networks, and theoretically proposes a theoretically inspired training algorithm for increasing this margin. The proposed algorithm improves both clean and adversarially robust test performance over strong baselines in practice."
SP:3d44f27468087280e85dfb1fc7291db05179fe6d,"This paper proposes a knowledge - grounded dialogue generation model with a disentangled response decoder to isolate parameters that depend on knowledge - grounded dialogues from the entire generation model. The decoder is the major part of the model that can be learned from a large number of ungrounded dialogued dialogues and unstructured documents, while the remaining small parameters can be well fitted using the limited training examples. Experiments on two benchmarks indicate that with only 1/8 training data, the proposed model can achieve the state - of - the - art performance and generalize well on the two benchmarks."
SP:9b555f7fe743f5effdbdc8701ed519ce3159c4b0,"This paper proposes a new neural machine translation model ( NMT ) framework that leverages non - parallel bilingual data for training and decoding. The authors propose a mirror - generative NMT ( MGNMT ) architecture that integrates the source to target translation model, the target to source translation model and two language models into a single unified architecture. The main idea of the paper is that the source and target language models share the same latent semantic space, therefore both translation directions can learn from the non parallel data more effectively. The proposed method is evaluated in a variety of language pairs and scenarios, including resource - rich and low - resource situations. The results show that the proposed method outperforms existing approaches."
SP:d7a530a0ec4112095a58cef4cda9646f8ca6449d,"This paper studies the role of entropy term in maximum entropy in deep reinforcement learning ( DRL ). In particular, it shows that the entropy term is the only term that matters in Soft Actor Critic ( SAC ) and that without it, there is no algorithm that can match the performance of SAC on Mujoco. Based on this insight, the authors propose a simple non - uniform sampling method for selecting transitions from the replay buffer during training and show that their algorithm outperforms SAC in this setting. They also show that the same non - uniform sampling scheme can be applied to any SAC variant."
SP:545e8da553fcb47d84eaa044d8a4947d3cd3230e,"This paper studies the vulnerability of industrial copyright detection systems to adversarial attacks. The authors propose to use a well - known music identification method and implement this system in the form of a neural net, and then attack this system using simple gradient methods. Adversarial music created this way successfully fools industrial systems, including the AudioTag copyright detector and YouTube ’s Content ID system. The goal of the paper is to raise awareness of the threats posed by adversarial examples in this space and to highlight the importance of hardening copyright detection system to attacks."
SP:b511822850da3bf1079a36ed6f5ad4db80fbc424,This paper proposes a method to decompose the final activation map of a deep neural network ( DNN ) for visual explanation of deep metric learning ( DML ). The idea is to generate point - to - point activation intensity maps ( P2P maps ) between two input images by decomposing final activation of the DNN. The authors show that the proposed method can be applied to both cross - view pattern discovery and interactive retrieval applications.    The main contribution of this paper is to propose a decomposition method for DML that decomposes final activation maps of a neural network into points and points with high intensity. The method is applied to DML for image similarity analysis.
SP:67bf71219fe6bedec5f5525200e734638e4a6ca2,"This paper considers the problem of continual learning in an online setting, where the agent has access to a large number of new environments over the course of its lifetime. The authors propose a new algorithm for online learning that combines model - based planning with model - free policy learning, AOP. They show that AOP is able to achieve strong performance in this setting by combining the benefits of both planning and uncertainty estimation in a single algorithm. They also show that the proposed algorithm AOP gracefully deals with novel situations, adapting behaviors and policies effectively in the face of unpredictable changes in the world."
SP:11159cb878a436a5d4fc6edb4132f2cc3c1b3f72,"This paper proposes to replace the softmax attention mechanism by two alternative sparsity - promoting transformations : sparsemax and TVMAX. With sparsemax, sparse attention weights are obtained sparsely by selecting relevant features. With TVMAX, the authors propose TVMAX to select relevant groups of features and improve interpretability. The experimental results show that TVMAX outperforms the other attention mechanisms in terms of humanrated caption quality and attention relevance."
SP:fb0c3ce3db6ad674ddc615bdc6203cdcbe42c804,"This paper proposes a graph neural network - based recurrent model for predicting the evolution of dynamic graphs. The main idea is to use graph neural networks to predict the topology of a graph, and then use a generative model to generate graph instances corresponding to the predicted topology at the next time step. The authors evaluate the proposed model on several real - world datasets and show that it outperforms the baselines."
SP:ff722957a1765c0568426ed88dd910a6b74054ef,"This paper proposes a method for imputing missing features and estimating the distribution of target assignments given incomplete data. The generator network is trained to generate imputations that a discriminator network is tasked to distinguish. A predictor network is then trained using the imputed samples from the generator network to capture the classification uncertainties and make predictions accordingly. The proposed method is evaluated on CIFAR - 10 image dataset as well as three real - world tabular classification datasets, under different missing data scenarios."
SP:c051b0fe779d9e4131016970b7ba469b596f3009,"This paper proposes an important sampling method for long - horizon estimation of off - policy estimation. The problem is formulated as solving for the fixed point of a certain operator, and the proposed method computes the importance ratios of stationary distributions. The proposed method is based on the RKHSs framework, and is shown to outperform existing importance sampling - based methods. The paper is well - written and easy to follow."
SP:065c900843011a71b70ed35357a2f71fe83872a7,"The paper considers the mixture model ( GMM ), which is a probabilistic framework that allows us to define a dataset containing K different modes. In a traditional GMM paradigm, it is straightforward to compute in closed - form the conditional likelihood p(x|k, \� ) and the responsibility probability p(k|x, \tilde{x } ) which describes the distribution index corresponds to the data. The authors propose a modified GAN to allow them to define the distribution p(z|k, \�), where z is the corresponding latent representation of x, as well as p( k|x,\� ) through an additional classification network which is trained with the GAN in an “ end - to - end ” fashion. These techniques allow us to discover interesting properties of an unsupervised dataset, including dataset segments and generating new “ outdistribution ” data by smooth linear interpolation across any combinations of the modes in a completely unsuper supervised manner."
SP:2da1608209058d214f8671062cc9eb0833ba4831,This paper presents a method for training large capacity neural networks with significantly improved accuracy and lower dynamic computational cost. The authors propose a new residual block architecture that gates convolutional channels in a fine - grained manner. They also introduce a generally applicable tool batch - shaping that matches the marginal aggregate posteriors of features in a neural network to a pre - specified prior distribution. Experiments on CIFAR-10 and ImageNet datasets for image classification and Cityscapes for semantic segmentation show that the proposed method can slim down large architectures but with higher accuracy.
SP:f90e9f0eb53f92601bdfa3f7bf86f71d037aad30,"This paper proposes a probabilistic importance inference approach for pruning deep neural networks ( DNNs ). Specifically, the authors test the significance of the relevance of a connection in a DNN to the DNN ’s outputs using a nonparemetric scoring test and keep only those significant ones. Experimental results show that the proposed approach achieves better lossless compression rates than existing techniques."
SP:64cbbb6a2f6847ef71cd5a23ba3e4cc5c815a56e,This paper proposes a method for hierarchical reinforcement learning based on repeated action sequences that can be compressed to yield a compact code of action trajectories to learn nested behavioral hierarchies of arbitrary depth with actions of arbitrary length. The learned temporally extended actions provide new action primitives that can participate in deeper hierarchies as the agent learns. The authors demonstrate the relevance of this approach for tasks with non - trivial hierarchical structure and show that the approach can be used to accelerate learning in recursively more complex tasks through transfer.
SP:e1ccfb3a684aef8a0fb36194eb16af1667811e81,"This paper proposes a new probabilistic generative model called the Hierarchical Bayes Autoencoder ( HBAE ). The proposed model consists of a multimodal decoder in the form of an energy - based model ( EBM ), instead of the commonly adopted unimodal Gaussian distribution. The decoder is trained using variational inference, similar to a VAE, to recover latent codes conditioned on inputs. For the decoder, the authors use an adversarial approximation where a conditional generator is trained to match the conditional generator of the EBM. The model is also capable of modeling sets, by inferring a latent code for a set of examples, and sampling set members through the multimodality decoder. In both single image and set cases, the model generates plausible variations consistent with the input data and generates realistic unconditional samples."
SP:1130a391afa30d1e0fddadedd2a3aaa70a4cb751,"This paper proposes a new normalization technique called cross - normalization for off - policy temporal difference ( TD ) learning. The idea is to use a mixture of on - policy transitions and feature normalization to improve the performance of TD algorithms. The authors show that the proposed technique improves over the naive application of existing normalization techniques in a range of TD settings. The main contribution of the paper is the introduction of cross normalization, which is an extension of batch normalization that re - centers data for two different distributions."
SP:f9cafaa5131176290fa069e6d24046c079cd9eea,"This paper proposes a method based on adversarial training strategy to learn discriminative features unbiased and invariant to the bias and confounding effects. The method is applied to synthetic data, medical images, and a gender classification dataset. The results show that the learned features by the method not only result in superior prediction performance but also are uncorrelated with the bias or confounding variables."
SP:783049ff463edd1283c058c6106a3e1f9a033df4,"This paper proposes a lightweight LSTM - based character - level language model based on Transformer. The main idea is to factorize the calculation paths by grouped embedding operators and use inter - group linear operators to prevent performance degradation from the group strategy. The proposed Group - Transformer achieves better performance on two benchmark tasks, enwik8 and text8.1, compared to the existing Transformer - based models."
SP:946c26d371297c88d0ac246257104099b4585edc,"This paper proposes a method for training generative models with hierarchical - latent - variable structures. The proposed method is based on Optimal Transport ( OT ), which is an alternative non - variational autoencoder ( VAE ) framework. Theoretically, OT has been shown to improve the convergence of the generative model in terms of the number of samples and the convergence rate of the KL divergence. This paper shows that OT can be applied to hierarchical - latent - variable models without the need for complex optimisation schemes and inference networks. The experiments show that the proposed method outperforms other VAE baselines and is more effective than the original VAE."
SP:309b47441d227ffa33f96f9f16f2addc607e5bb0,"This paper proposes a conceptually simple autoregressive video generation model based on a three - dimensional self - attention mechanism for generating high - quality video continuations outside of narrow domains and often struggle with fidelity and realism. The proposed method is shown to achieve competitive results across multiple metrics on popular benchmark datasets such as YouTube videos, Kinetics and a large scale action recognition dataset. The authors also present results on the Kinetics dataset exhibiting phenomena such as camera movement, complex object interactions and diverse human movement. While modeling these phenomena consistently remains elusive, the authors hope that their results, which include occasional realistic continuations, encourage further research on comparatively complex, large scale datasets, such as Kinetics, will be useful for future research."
SP:ad8fcdbc47a50dd2bf58aba2bc6cfe199e84dd4d,"This paper proposes a latent feature generation framework for zero - shot ICD coding, where the goal is to improve the prediction on codes that have no labeled data without compromising the performance on seen codes. The framework generates semantically meaningful features by exploiting ICD code hierarchical structure and a novel cycle architecture that reconstructs the relevant keywords. To the best of our knowledge, this is the first adversarial generative model for the generalized 0 - shot learning on multi - label text classification, and the proposed method improves the performance by 3 % ( absolute improvement ) from the previous state of the art."
SP:3ce82ae297e5759ab957babe9927062e7a71b0ba,"This paper proposes a forward prediction objective for simultaneously learning embeddings of states and action sequences to improve sample efficiency in reinforcement learning ( RL ). In particular, the authors propose a self - supervised representation learning method to simultaneously learn the embedding of the state and the action sequences. Experiments on goal - conditioned continuous control from pixel observations demonstrate the effectiveness of the proposed method."
SP:11ce1616e721340eea9e80dad7460c77355ac7d1,"This paper proposes a meta - learning framework that leverages cross - task relations in knowledge bases to efficiently transfer knowledge from previous tasks to the new ones. The proposed framework is motivated by the way of knowledge organization in knowledge base and addresses the challenge of task heterogeneity by a learned meta - knowledge graph. In particular, the proposed framework, called ARML framework, automatically extracts the relational meta - relations and constructs the meta - Knowledge graph. ARML can quickly find the most relevant structure for a new task and tailor the learned structure knowledge to the task - specific meta - learner. Extensive experiments on 2D toy regression and few - shot image classification tasks demonstrate the superiority of ARML over other baselines."
SP:37c209cd1c628b5c2f2b282fbeaf4bbf437c7670,"This paper proposes a method for controlling attributes of the generated language ( e.g. switching topic or sentiment ) without modifying the model architecture or fine - tuning on attribute - specific data and entailing the significant cost of retraining. The method combines a pretrained LM with one or more simple attribute classifiers that guide text generation without any further training of the LM. In the canonical scenario, the attribute models are simple classifiers consisting of a user - specified bag of words or a single learned layer with 100,000 times fewer parameters than the pre - trained LM. Sampling entails a forward and backward pass in which gradients from the attribute model are obtained from the LM using a forward pass and a backward pass from the self - attention mechanism. Experiments demonstrate control a range of topics and sentiment styles, and extensive automated and human annotated evaluations show attribute alignment and fluency."
SP:12d0980bfea2de880905a0b87b40856969bb1c58,This paper proposes a new unsupervised representation learning method based on a Laplacian pyramid representation of the input data. The proposed method is based on an autoencoder approach where the noisy input data is generated by corrupting clean data in the gradient domain. The authors demonstrate that the learned representations are robust to single - scale corruption compared to the original unlabeled data. They also demonstrate that learned representations perform well when transferred to other vision tasks.
SP:12afc1b259e51a31cbeb72366d2b93fbee1aafaa,"Neural networks are over - sensitive to small input changes in natural language processing ( NLP ) while under - sensitive in large fraction of input text deletions. This paper aims to address the problem of under - sensitivity by ensuring that models do not become more confident in their predictions as arbitrary subsets of words from the input text are deleted. The authors develop a novel technique for formal verification of this specification for models based on the popular decomposable attention mechanism by employing the efficient yet effective interval bound propagation ( IBP ) approach. Using this method, they can efficiently prove, given a model, whether a particular sample is free from the under - sensitization problem and compare different training methods to address it. In the experiments on the SNLI and MNLI datasets, the authors observe that IBP training leads to a significantly improved verified accuracy with respect to standard training."
SP:14257af9fe83522c6e5b5d6b0d68945b944e30fb,"This paper proposes a new method for off - policy deep reinforcement learning ( RL ) that leverages a replay memory in the replay memory. The key idea is to represent transitions in a data graph and link its structure to soft divergence. By selecting a subgraph with a favorable structure, the authors construct a simple Markov Decision Process ( MDP ) for which exact Q - values can be computed efficiently as more data comes in, resulting in a QGRAPH. The authors show that the Q - value for each transition in the simplified MDP is a lower bound of the lower bound for the same transitions in the original continuous Q - learning problem. By using these lower bounds in TD learning, the proposed method is less prone to soft divergences and exhibits increased sample efficiency while being more robust."
SP:c92c97e47d8b218dfd009bbf61f5b3547b395f91,"This paper studies the problem of unsupervised domain adaptation ( UDA ), where the goal is to generalize a hypothesis from a labeled source domain to an unlabeled target domain. The authors study the effect of the embedding complexity of the source embedding on the generalization to the target domain, both theoretically and empirically. Theoretically, the authors show that the complexity of source and target embedding is related to the upper bound on the target risk, and they provide a theoretical framework to apply this framework to multilayer neural networks. Finally, they propose a strategy that mitigates sensitivity to the embeddings complexity. The proposed method is empirically shown to achieve performance on par with or better than the best layer - dependent complexity tradeoff."
SP:f3f3c6fbae757836551b3f1ee54a7d1e040132b8,"This paper studies generalization error bounds for stochastic gradient Langevin dynamics ( SGLD ) and several other noisy gradient methods. The authors develop a new framework, Bayes - Stability, for proving algorithm - dependent generalization bounds. The new framework combines ideas from both PAC - Bayesian theory and the notion of algorithmic stability. The main contributions of this paper are :   1. A new generalization bound for the continuous Langevin dynamic is derived by developing a new Log - Sobolev inequality for the parameter distribution at any time.   2. The Bayes stability method is extended to the setting where the total loss is the sum of a bounded loss and an additional $ \ell_2 $ regularization term. 3. The proposed bounds are more desirable when the noise level of the process is not very small, and do not become vacuous even when T tends to infinity. 4. The experiments demonstrate that the proposed bounds can distinguish randomly labelled data from normal data, which provides an explanation to the intriguing phenomena observed in Zhang et al. ( 2017a )."
SP:a82fcd1d3196ddf078cfe8f4bc6f445d9d2bdc11,"This paper investigates the role of hippocampal CA1 neurons in continual learning in the context of two different spatial navigation strategies. The authors apply demixed principal component analysis ( dPCA ) on neuronal recordings from 612 hippocampal neurons of rodents learning to perform allocentric and egocentric spatial tasks. The components uncovered using dPCAs from the firing activity reveal that hippocampusal neurons encode relevant task variables such as decisions, navigational strategies and reward location.   The authors also compare this hippocampal features with standard reinforcement learning algorithms, highlighting similarities and differences. Finally, the authors demonstrate that a standard deep reinforcement learning model achieves similar average performance when compared to animal learning, but fails to mimic animals during task switching."
SP:51acf1f8108683dce543a1fb4a61fbd593f9b4cc,"This paper proposes a tree search based policy optimization method for continuous environments. The main idea is to use a pre - trained policy to build the MCTS tree in a continuous action space and update the policy gradient using off - policy trajectories are non - trivial. To overcome these challenges, the authors propose limiting tree search branching factor by drawing only a few action samples from the policy distribution and defining a new loss function based on the trajectories ’ mean and standard deviations. The experiments show that the proposed method significantly improves the policy on nearly all the environments and achieves a 2.5 % improvement over the baseline algorithm."
SP:1ce3bc4d31712886f7dcada5b5ae67c3c376819a,"The lottery ticket hypothesis claims that neural networks contain sparse subnetworks, which, if appropriately initialized ( winning tickets ) are capable of matching the accuracy of the full network when trained in isolation. This paper aims to answer the following open questions : can we find winning tickets with few data samples or few labels? can we even obtain “ good ” tickets without supervision? The authors find that winning tickets found in these scenarios are, perhaps surprisingly, competitive with winning tickets generated on the full ImageNet dataset when evaluated on ImageNet classification task."
SP:dbcebe5b73486885d9f4478b258047c02f8481a2,"Neural reading comprehension models have recently achieved impressive generalisation results, yet still perform poorly when given adversarially selected input. In this work, the authors focus on the complementary problem of excessive prediction undersensitivity where input text is meaningfully changed, and the model ’s prediction does not change when it should. They formulate a noisy adversarial attack which searches among semantic variations of comprehension questions for which a model still erroneously produces the same answer as the original question – and with an even higher probability – and show that – despite comprising unanswerable questions – SQuAD2.0 and NewsQA models are vulnerable to this attack and commit a substantial fraction of errors. This indicates that current models — current models, even where they can correctly predict the answer — are not necessarily aware of all information provided in a given comprehension question and the authors further experiment with both data augmentation and adversarial training as defence strategies to decrease a model’s vulnerability to undersensitivity attacks on held out evaluation data."
SP:5da870060778de460c1abe91562d6f3e707efef4,"This paper proposes a model - based approach to safety for reinforcement learning agents that allows the agent to look into the future and be aware of the future consequences of its actions. It learns the transition dynamics of the environment and generate a directed graph called the imaginative module. The imaginative module is used to predict whether the current actions of the agent can cause it to end up in dangerous states in the future. The proposed method can be seen as a “ plug - and - play ” approach to ensuring safety, as it is compatible with any existing RL algorithm and any task with discrete action space. Experiments on two gridworld environments and a self - driving car simulator demonstrate that the proposed method visits unsafe states significantly less frequently than a baseline."
SP:c2796f28fb067138303df8d424d646f4ada31558,"This paper proposes a novel architecture, Physics - aware Difference Graph Networks ( PA - DGN ), which exploits neighboring information to learn finite differences inspired by physics equations. The proposed architecture leverages data - driven end - to - end learning to discover underlying dynamical relations between the spatial and temporal differences in given sequential observations. The authors demonstrate the superiority of PA - DDGN in the approximation of directional derivatives and the prediction of graph signals on the synthetic data and the real - world climate observations from weather stations."
SP:db8ed4f4fc3967f5dd4d208d5d029730eb99e840,"This paper studies the problem of training structured neural networks with nonsmooth regularization ( e.g., $ \ell_1 $ norm ) and constrained constraints. The authors formulate training as a constrained non - smooth optimization problem, and propose a convergent proximal - type stochastic gradient descent ( ProxSGD ) algorithm. They show that under properly selected learning rates, with probability 1, every limit point of the sequence generated by the proposed Prox SGD is a stationary point. Theoretical analysis and numerical experiments are provided to support the theoretical analysis."
SP:2ca1f4da9faee79768764cda5d09d949cc942acc,"This paper proposes an end - to - end differentiable image compression framework for lossy image compression that bypasses the quantization step by relying on a non - deterministic compression codec. The decoder maps the input image to a distribution in continuous space from which a sample can be encoded with expected code length being the relative entropy to the encoding distribution, i.e. it is bits - back efficient and non - differentiable. The proposed method is straight - forwardly trained using standard gradient - based optimizers on the CLIC 2018 dataset and show that their method is competitive with the state - of - the - art on low bitrates."
SP:788fd2b6956dd69bf7752d39ea21883947128c8a,"This paper proposes a new method for super - resolution ( SR ) from compressed C - JPG images. The proposed method consists of two components : ( 1 ) a functional noise elimination ( FNO ), which is used to eliminate the noise in noise elimination in traditional SR approaches ; and ( 2 ) a cycle loss ( cycle loss ), used to improve the performance of SR generation. The two components of FNO are combined to form a new SR generation model. Experiments show that the proposed method achieves better results than existing state - of - the - art methods, and is competitive with the existing methods in terms of quality."
SP:18dd92f2f55020be4f5a089b3b251327e47886f4,This paper proposes a fully convolutional neural network for spatio - temporal decision - making in image - based spatiotemporal data. The network is trained by learning a feature hierarchy that produces predictions at different sampling levels that are merged together to preserve both coarse and fine detail. The proposed method is applied to the problem of predicting probability maps of high - frequency signals from single - location labels of a soccer match. The method is shown to perform well in an extreme case of weakly supervised learning where there is only a single pixel correspondence between ground - truth outcomes and the predicted probability map. The model is also shown to be able to provide not only an accurate evaluation of observed events but also a visual interpretation of the results of other potential actions.
SP:1ae31baf383fc520687b255d9cac14c3b040e253,"This paper proposes an inductive graph - based matrix completion ( IGMC ) model, which is based on graph neural networks ( GNNs ). The main idea is to factorize the rating matrix into the product of low - dimensional latent embeddings of rows ( users ) and columns ( items ) instead of factorizing the matrix directly into the output of a matrix factorization process ( e.g., factorization of a neural network ). IGMC is inductive - it can generalize to users / items unseen during the training ( given that their interactions exist ) and can even transfer to new tasks, and its transfer learning experiments show that a model trained out of the MovieLens dataset can be directly used to predict Douban movie ratings with surprisingly good performance. Extensive experiments are conducted to show the effectiveness of the proposed method."
SP:c5cb1b50e17a69e88d5ae28848e265215162da1e,"This paper considers the problem of unconstrained minimization of a smooth objective function in R in the setting where only function evaluations are possible. The authors propose and analyze stochastic zeroth - order method with heavy ball momentum. In particular, SMTP, a momentum version of the stochastastic three - point method ( STP ) Bergou et al. ( 2019 ), is proposed. The complexity results for non - convex, convex and strongly convex functions are provided. The proposed SMTP significantly outperforms STP and all other methods that the authors considered in their numerical experiments."
SP:a216cfc29937eb398ea98cb1aea3481c9aed8240,This paper proposes Action Semantics Network ( ASN ) for multi - agent reinforcement learning ( MAS ) systems. MASs are multi - agents where each agent makes individual decisions but all of them contribute globally to the system evolution. The paper proposes a network architecture that explicitly represents action semantics between agents and characterizes different actions ’ influence on other agents using neural networks based on the action semantics. The proposed ASN can be easily combined with existing deep RL algorithms to boost their performance. ASN is evaluated on StarCraft II and NeuralMMO and shows improved performance.
SP:efaf3a440dc17e05177832083ffbc23760ed7c97,"This paper proposes to exploit the underlying structures of the state - action value function, i.e., the Q function, for both planning and deep reinforcement learning ( RL ). Specifically, the authors investigate the low - rank structure, which widely exists for big data matrices, and verify empirically the existence of low - ranked Q functions in the context of control and deep RL tasks. The authors propose a general framework to exploit this structure by leveraging Matrix Estimation ( ME ) techniques. This leads to a more efficient planning procedure for classical control, and additionally, it also leads to better performance on Atari games."
SP:430336893b247b7bd45687d78b0d0511a7369e87,"This paper proposes a new algorithm for off - policy reinforcement learning ( batch DRL ), which aims to sample - efficient learning from a given data set without additional interactions with the environment. The proposed algorithm, called best - action imitation learning ( BAIL ), first selects from the batch the actions it believes to be high - performing actions for their corresponding states ; it then uses those state - action pairs to train a policy network using imitation learning. Experiments show that BAIL achieves state - of - the - art performance on the Mujoco benchmark."
SP:94078964876667e8a5d9ae7728d779d5b91a576e,"This paper proposes DeepXML, an algorithm for deep extreme multi - label learning ( DML ), which aims to jointly learn feature representations and classifiers to automatically tag data points with the most relevant subset of labels from an extremely large label set. The proposed method splits training of head and tail labels by learning word embeddings on head labels and transferring them through a novel residual connection to data impoverished tail labels. The authors also increase the amount of negative training data available by extending state - of - the - art negative sub - sampling techniques and re - ranking the set of predicted labels to eliminate the hardest negatives for the original classifier.    The proposed algorithm is 10x faster at training than XML - CNN and AttentionXML. It is also empirically determined to be up to 19 % more accurate than leading techniques for matching search engine queries to advertiser bid phrases."
SP:b1b1252d82fa1bea18309e0b0b894e0f28f48bc9,"This paper proposes an end - to - end variational hashing - based collaborative filtering approach that uses the novel concept of self - masking : the user hash code acts as a mask on the items ( using the Boolean AND operation ), such that it learns to encode which bits are important to the user, rather than the user ’s preference towards the underlying item ( i.e., the item that the mask belongs to ). The authors also make available an efficient implementation of the self -masking, which experimentally yields < 4 % runtime overhead compared to the standard Hamming distance."
SP:80898d0f2b2c8dc3388fa9164e529eae36aa1b21,"This paper studies the problem of mode collapse in generative adversarial networks ( GANs ). The authors propose a set of statistical tools to quantitatively measure the mode collapse. The key idea is to calibrate the GAN ’s learned distribution using two simple yet effective “ black - box ” methods. The first method is based on the well - known “ distance metric ”, which measures the distance between the output of a GAN and the ground truth distribution. The second method uses the distance metric to measure the quality of the learned distribution. Both methods are shown to be effective in calibrating the learned GAN distribution without access to the original model parameters or training data."
SP:e5b5dda2f024cfda10526e744aa035e0165af58a,"This paper proposes to train two - layer neural networks that are beyond the NTK regime and are still governed by the Taylor expansion of the network by randomizing the weights. The authors show that the optimization landscape of randomized two layer networks is nice and amenable to escaping - saddle algorithms. They also prove concrete generalization and expressivity results on these randomized networks, which match the generalization results of NTKs."
SP:cef7ea513eb3e42be4edf40e4ee1701a969bcbea,"This paper proposes a graph filter assessment tool, Graph Filter Discriminant Score ( GFD ), for evaluating the effectiveness of graph filters for semi - supervised node classification tasks. The authors claim to provide an in - depth analysis on the optimal graph filters, which shows that there is no single filter as a “ silver bullet ” that performs the best on all possible graphs, and that different graph properties are in favor of different graph filters. Based on these findings, the authors develop Adaptive Filter Graph Neural Network ( AFGNN ), a simple but powerful model that can adaptively learn data - specific filters. Experimental results on both synthetic and real - world benchmark datasets have demonstrated the flexibility in learning an appropriate filter and consistently provides state - of - the - art performance across all the datasets."
SP:3c5ec9dbcf914c8901e4e35f3c2a7df4707422ab,"This paper studies the effect of distributionally robust optimization ( DRO ) on overparameterized neural networks. The authors propose a stochastic DRO algorithm, with convergence guarantees, to efficiently learn models that minimize the worst - case training loss over a set of pre - defined groups. They show that naively applying group DRO to over - parameterized neural models can fit the training data, and any model with vanishing average training loss also already has vanishing worst - cases training loss. Instead, the poor worst case performance arises from poor generalization on some groups, and the authors propose coupling group DRo models with increased regularization to achieve stronger - than - typical - robustness on a stronger-than - typical task, while maintaining high average accuracies."
SP:eb1ee2e0f7d8466a04b58508ecb3da7b667eecdf,"This paper proposes a new local explanation method for black - box classifiers. The proposed method is based on the idea of distribution controllers, which is a simple but effective mask predictor for local explanation. The distribution controllers are obtained as a function of the input features and the classification loss. The classification loss is used to optimize the proposed predictor. The experimental results demonstrate that the proposed method also outperforms other local explanation methods in terms of faithfulness and explainability."
SP:32ea7cbc47cbdb1f703f4e07c31ce90abe083424,"This paper proposes a deep network that can be trained to tackle image reconstruction and classification problems that involve detection of multiple object instances, without any supervision regarding their whereabouts. The proposed method is able to learn to detect recurring structures in the training dataset by learning to reconstruct images. It can also learn to localize structures when only knowledge on the occurrence of the object is provided. The challenge in training such a network is the non - differentiable top - K selection process, which is lifted the training optimization problem by treating the result of top - k selection as a slack variable, resulting in a simple, yet effective, multi - stage training. The network learns to extract the most significant K patches, and feeds these patches to a task - specific network, e.g., auto - encoder or classifier, to solve a domain specific problem."
SP:da1c5f6351d531482e90b86c3cceb52850c520de,"This paper proposes a method for neural neural program synthesis ( NSP ), where the goal is to generate a program that can be executed to match a state change in the assembly code. The method is based on reinforcement learning and consists of two main components : policy network and value network. The policy network is used to learn a set of policies for the generation of the program, and the value network is the one that predicts the output of the policy. The two components are trained jointly with a Monte Carlo Tree Search ( MCTS ) approach. The paper also proposes a multi - entropy policy sampling method to alleviate online update correlations. The proposed method is evaluated on a few simple NSP tasks and compared with several baselines."
SP:0d4687fc36c02e27d1b95d532a3947589f92b1da,This paper studies the effect of model architecture on the speed of training in the context of gradient descent optimization. The authors use the ideas from prior work that shows gradient descent can be modeled as a first - order ODE and use ODE’s coefficient matrix H to characterize the convergence rate. They introduce a simple analysis technique that enumerates H in terms of all possible “ paths ” in the network. They show that changes in model architecture parameters reflect as changes in the number of paths and the properties of each path.
SP:3e3bc8f617df742a395e7d315ec3810a42071294,"This paper shows that fully connected wide ReLU - neural networks trained with squared loss are essentially a sum of two parts : the first is the minimum complexity solution of an interpolating kernel method, while the second contributes to the test error only and depends heavily on the initialization. This decomposition has two consequences : ( a ) the second part becomes negligible in the regime of small initialization variance, which allows us to transfer generalization bounds from minimum complexity interpolating kernels methods to NNs ; ( b ) in the opposite regime, the test - error of wide NNs increases significantly with the initialization variance.    The main contribution of this paper is to make the bias of initialization on strongly overparametrized NNs under gradient descent explicit."
SP:b15ea009a36a0a76728dfc103d668d6781a8a99a,This paper proposes a new method for 3D object detection based on pseudo - LiDAR. The proposed method builds on top of the recently proposed pseudo - LIDAR framework for stereo object detection. The main contributions of this paper are : 1. A new depth estimation method based on the combination of a depthpropagation algorithm and a new loss function to improve the depth estimation of far away objects. 2. An improvement in the performance of the proposed method on the KITTI object detection benchmark by 40 % compared to the previous state - of - the - art method. 3. A method to leverage the sparse depth information from the pseudo - LIDAR sensors to improve depth estimation.
SP:983d84502264633f3385d426c1d4601a0744ea9a,"This paper proposes a principled adversarial example detection method that can withstand norm - constrained white - box attacks. The proposed method is motivated by one - versus - the - rest classification, in a K class classification problem, where the K base detectors where the i - th detector is trained to discriminate natural data of class i from adversarial examples perturbed from other classes. The authors further devise a generative to detecting / classifying adversarial samples by interpreting each base detector as an adversarial sample. The paper provides a comprehensive evaluation of the above adversariar example detection / classification methods, and demonstrate their competitive performances and compelling properties."
SP:461e9308d050bc3dc7b35233452668bb31f5d491,"This paper proposes an intrinsic reward method for agent exploration in sparse reward environments. The intrinsic reward encourages the agent to take actions that lead to significant changes in its learned state representation. The proposed intrinsic reward is based on the observation that the agent is rewarded for interacting with objects that it can control. The agent is also encouraged to visit states that it has not previously visited in the past. The method is shown to be more sample efficient than existing exploration methods, particularly for procedurally - generated MiniGrid environments. In addition, the authors analyze the learned behavior as well as the intrinsic reward received by the agent and show that intrinsic reward does not diminish during the course of training."
SP:c002c20b5e8696588e029c0f65e88860418826c4,"This paper considers the large - scale query - document retrieval problem, where given a query ( e.g., a question ), the goal is to retrieve the set of relevant documents ( paragraphs containing the answer ) from a large document corpus. The retrieval phase first reduces the solution space, returns a subset of candidate documents, and then re - ranks the documents. This retrieval phase is less well studied compared to the scoring phase, where scoring phase has seen significant advances recently due to the BERT - style pre - training tasks on cross - attention models. In this paper, the retrieval phase requires to be highly efficient, returning candidates in time sublinear to the number of documents. The paper presents a comprehensive study on the embedding - based retrieval models on paragraph - level pretraining tasks on Inverse Cloze Task (ICT ), Body First Selection ( BFS ), Wiki Link Prediction ( WLP ), and the combination of all three. The results show that the Transformer models can improve over the widely - used BM - 25 as well as embedding models without Transformers on these tasks."
SP:4e161e08a624f87633dfb49dfd46bd1665e15189,"This paper proposes a new graph convolutional network architecture, BiGraphNet, that eliminates pooling layers in graph neural networks. The main idea is to replace the sequence of graph convolutions and pooling in hierarchical architectures with a single single - parametric bipartite operation that transforms the graph structure between different input and output graphs. The authors show that the proposed architecture can be used to build efficient architectures such as graph skip connections, and graph autoencoders.   The authors also demonstrate that the general Bi - GraphNet formalism provides the flexibility and adaptability for graph neural network architectures."
SP:9b9b6ee9014e5538442ba76d6059ed01f59ec8fb,This paper proposes a feature - wise transformation layer for few - shot classification. The proposed method is based on affine transforms to simulate different feature distributions under different domains in the training stage. The authors also apply a learning - to - learn approach to search for the hyper - parameters of the feature transformation layers. Extensive experiments are conducted on five public datasets to demonstrate the effectiveness of the proposed method.
SP:df46627cb984a56bba36d510bfc52e00751e9107,"This paper proposes a continuous convolutional neural network for the problem of Lagrangian fluid simulation. The authors use spatial convolutions as the main differentiable operation to relate particles to their neighbors in the continuous domain. They show that their network architecture can simulate different materials, generalizes to arbitrary collision geometries, and can be used for inverse problems. In addition, they demonstrate that their continuous convolutions outperform prior formulations in terms of accuracy and speed."
SP:3e17f333cf07183969c02bb66afdd3ccbf25bb19,"This paper proposes BatchEnsemble, an ensemble method for learning neural networks that is both parallelizable across devices and parallelizable within a device. The method is based on the Hadamard product of a shared weight matrix among all ensemble members and a rank - one matrix per member. The proposed method is shown to have computational and memory costs that are significantly lower than typical ensembles. It is also shown that the proposed method can easily scale up to lifelong learning on Split - ImageNet which involves 100 sequential learning tasks."
SP:a123a425ef3eb6188833d5a42e851bc3fa59df65,"This paper proposes a neural network - based PDE solver for both forward and inverse problems. The proposed method is grid free, mesh free, and shape free. The network is trained to minimize deviations of the learned function from the strong PDE solution and satisfy the boundary conditions. The resulting solution in turn is an explicit smooth differentiable function with a known analytical form. Unlike other numerical methods such as finite differences and finite elements, the derivatives of the desired function can be analytically calculated to any order. This framework therefore, enables the solution of high order non - linear PDEs. The method is demonstrated on several free shape 2D second order systems with application to EIT, diffusion and wave equations."
SP:973d0ad0faadcf7298300f2758de9154205e7113,"This paper studies the problem of reasoning about large neural networks, specifically binarized neural networks ( BNNs ), from the perspective of SAT solvers. The authors argue that the main bottleneck for all methods is their ability to reason about large BNNS efficiently. They propose two changes to the BNN architecture and the training procedure to get a simpler network without sacrificing accuracy on the primary task, SAT. The experimental results demonstrate that their approach scales to larger deep neural networks compared to existing work for existential and probabilistic queries about the network, perform explanation generation, etc."
SP:ca985e758f195bd04fb9f24b290a83974d6d308b,"This paper studies the expressive power of graph neural networks falling within the message - passing framework ( GNNmp ). Two results are shown : first, GNNMP are shown to be Turing universal under sufficient conditions on their depth, width, node attributes, and layer expressiveness. Second, it is discovered that GNNNNs can lose a significant portion of their power when their depth and width is restricted. The proposed impossibility statements stem from a new technique that enables the repurposing of seminal results from distributed computing and leads to lower bounds for an array of decision, optimization, and estimation problems involving graphs."
SP:a98ae70a91850bbe624c307ba61d3daeb2494b82,"This paper proposes a localised generative flow ( LGF ) to address the limitation of flow - based density models based on continuous bijections in learning target distributions with complicated topologies. The proposed LGF is composed of stacked continuous mixtures of bijection, which enables each bijection to learn a local region of the target rather than its entirety. Unlike normalising flows, LGFs do not permit exact computation of log likelihoods, so the authors propose a simple variational scheme that performs well in practice. The experimental results show that the proposed LGFs yield improved performance across a variety of density estimation tasks."
SP:3adc341dece170f428195e4dccadfb5f5daddf2d,"This paper studies the environment bias in Vision - and - Language Navigation ( VLN ). The authors propose two ways of explaining this bias : ( 1 ) The authors claim that VLNs are biased towards training environments, and ( 2 ) they explore several kinds of semantic representations which contain less low - level visual information, hence the agent learned with these features could be better generalized to unseen testing environments.   The authors conduct a series of experiments to demonstrate the hypothesis that environment bias plays a key role in the performance drop in unseen environments. They first show that neither the language nor the underlying navigational instructions lead to the agent's performance decrease in the unseen environment. Then, they propose a novel method for feature replacement based on environment re - splitting and feature replacement. The experimental results show that the proposed method can significantly decrease the performance gap between seen and unseen environments without changing the baseline agent model or the training method."
SP:298e0043e99f586d314fbd9d16fdc6ae885e1ebb,"This paper proposes to use human feedback as an auxiliary reward function in deep reinforcement learning ( DRL ) to accelerate and optimize the training of an RL agent. Human feedback is provided by placing electrodes on the human scalp and monitoring what are known as event - related electric potentials ( E2P ) signals. The implicit feedback is then used to augment the agent ’s learning in the RL tasks. The authors show that the definition of error - potential is generalizable across different Atari games, and they show that error -potentials of an observer can be learned for a specific game and the definition used as - is for another game without requiring re - learning of the error - probabilities. They propose two different frameworks to combine recent advances in DRL into an error - potentially based feedback system in a sample - efficient manner, allowing humans to provide implicit feedback while training in the loop, or prior to the training. Finally, they scale the implicit human feedback ( via ErrP ) based RL to reasonably complex games and demonstrate the significance of their approach through synthetic and real user experiments."
SP:a8395f8b877e1eebaef9ff2e8b4e488d55a74ef4,"This paper proposes laconic image classification as a novel way to compare the performance of diverse image classifiers. The goal in this setting is to minimise the amount of information ( entropy ) required in individual test images to maintain correct classification. Given a classifier and a test image, the goal is to compute an approximate minimal - entropy positive image for which the classifier provides a correct classification, becoming incorrect upon any further reduction. The proposed method generalizes similar methods explored in previous works.   The authors propose two complementary frameworks for computing the minimal entropy positive images of both human and machine classifiers, in experiments over the ILSVRC test - set, i.e., reduced resolution and reduced crop. The experiments show that both humans and machines exhibit a texture bias, with humans having higher precision than machines classify those of humans, as well as reduced resolution for machines. The paper is well organized and easy to follow."
SP:81cec8f907d8fa0653b5bc08af1f59bfefd49619,This paper studies the robustness of adversarial attacks on neural networks. The authors show that the adversarial examples occupy a very small cone in the decision space which is surrounded by a large area corresponding to the correct class. They identify a family of defense techniques that are based on the instability assumption. The defenses include deterministic lossy compression algorithms and randomized perturbations to the input that all lead to similar gains in robustness. They present a comprehensive experimental analysis of when and why perturbation defenses work and potential mechanisms that could explain their effectiveness ( or ineffectiveness ) in different settings.
SP:a136b98e0ed478144ce9dd26e2b6d611543124e8,"This paper proposes a neural 3D mapping network that takes as input 2.5D video streams captured by a moving camera, and lift them to 3D feature maps of the scene, by disentangling the scene content from the motion of the camera. The proposed network is applied to semi - supervised and unsupervised learning of 3D moving object detectors. The paper also proposes a contrastive loss to replace the standard color regression loss, and show that this leads to better performance on complex photorealistic data.   The main contribution of this paper is to propose a neural network for view prediction in self - supervised 3D object detection. To the best of my knowledge, this is the first work that empirically shows view prediction to be a scalable self - supervised task for 3D visual recognition."
SP:6fd61604a2eeb8a2cbbda6c40807cebef6d40f2f,"This paper studies the problem of unsupervised domain translation ( UDT ), where the goal is to find meaningful correspondences between two domains without explicit pairings between them. The authors define UDT in a rigorous, non - ambiguous manner, explore the implicit biases present in the approach and demonstrate the limits of the approaches. Specifically, they show that mappings produced by these methods are biased towards low energy transformations, leading them to cast UDT into an Optimal Transport ( OT ) framework by making this implicit bias explicit. This not only allows them to provide theoretical guarantees for existing methods, but also to solve UDT problems where previous methods fail, and propose a simple, dynamical approach to solve the problem."
SP:8bb3ce11ad773685f6e41d90db3e7a5481e5ba47,This paper proposes a new regularization method for neural networks. The proposed method rotates the input layer of each layer of a neural network in an unsupervised manner. The method is different from Dropout which rotates each neuron / channel independently. The authors use a noise analysis method to interpret the difference between RotationOut and Dropout in co - adaptation reduction. The experiments on vision and language tasks show the effectiveness of the proposed method.
SP:37620ae8dc5683eb2843792e0aa4cbe6cba366f7,"This paper proposes a data - free method to generate adversarial perturbations ( UAPs ) for a given CNN in a data free manner. The key idea is to optimize the dilate loss function to maximise the Euclidean norm of the output output before non - linearity at any layer. The authors show that the adversarial generation with full training data can be approximated to a formulation without data by the proposed method. Extensive experiments demonstrate that their method not only has theoretical support, but achieves higher fooling rate than the existing data free work."
SP:2fd7d5507a8727db743dc89379a6f021d31ed39a,"This paper proposes a meta - learning approach to transfer neural architecture search ( NAS ) to multiple datasets and multiple tasks. The key idea is to train a meta neural architecture for each new task and use it to adapt to a new task quickly through a few gradient steps. The proposed method, T - NAS, is evaluated on two datasets ( CIFAR-10 and ImageNet ) and two learning paradigms ( few - shot learning and supervised learning ). Extensive experiments show the effectiveness of the proposed method in both settings."
SP:1314a79ba12474adb33ff31b3cb22bed25b94fb7,"This paper proposes a stochastic neural network architecture for discriminative learning by directly modeling activation uncertainty and encouraging high activation variability. The proposed SE - SNN is simpler to implement and faster to train, and produces state - of - the - art results on network compression by pruning, adversarial defense and learning with label noise. Compared to existing SNNs, the proposed method is more efficient to implement, can be trained faster, and is robust to adversarial attacks and label noise better."
SP:bd4935d4fcf33f60f22e0f2fd9f7dc8ddfab6d17,"This paper proposes a meta - learning algorithm for generating curious agents. The algorithm consists of two parts : an outer loop that learns a reward function that adapts to the agent ’s curiosity level, and an inner loop that performs reinforcement learning using the adapted reward function. The outer loop is composed of a neural network and the inner loop consists of a set of building blocks such as buffers, nearest - neighbor modules, and custom loss functions. The inner loop learns the reward function and the outer loop uses the modified reward function to perform reinforcement learning. The experiments show that the proposed algorithm is more generalizable than human - designed meta - learned algorithms."
SP:6dff0f3a84809ae0ba9f58f36303597f1ba6dcc5,"This paper proposes a new approach for Any - Code - to - Code Generation ( AnyC2C ) that leverages the strict syntax of programming languages to model a code snippet as a tree – structural language modeling ( SLM ). The proposed SLM estimates the probability of the program ’s abstract syntax tree ( AST ) by decomposing it into a product of conditional probabilities over its nodes. The authors present a neural model that computes these conditional probabilities by considering all AST paths leading to a target node. Unlike previous structural approaches that have severely restricted the kinds of expressions that can be generated in this task, the proposed approach can generate arbitrary expressions in any programming language. The model significantly outperforms both seq2seq and a variety of existing structured approaches in generating Java and C code."
SP:7fc60d6fd1cfcc135c34f9664d172d3fd1c0ae0a,"This paper presents some theoretical work to explain why gradient descent methods are so successful in solving non - convex optimization problems in learning large - scale neural networks ( NNs ). The authors introduce a tool called canonical space and prove that the objective functions in learning NNs are convex in the canonical model space. They further elucidate that the gradients between the original NN model space and the canonical space are related by a pointwise linear transformation, which is represented by the so - called disparity matrix. Furthermore, they have proved that gradient descent algorithms surely converge to a global minimum of zero loss provided that the disparity matrices maintain full rank. In particular, the chance to have singular disparity matrix is extremely slim."
SP:78a536138570fe9b5d88350e4b16d598a7db1fe0,This paper proposes a method for interactive graph - based segmentation based on instance - aware graph neural networks ( GNNs ). The main idea is to use a discrete Potts model of a GNN as the instance model and then use a class - aware heuristic ( ILP ) to optimize the global optimum of the GNN. The authors show that ILP is able to achieve competitive results on the semantic ( and panoptic ) segmentation on the PASCAL VOC 2012 and Cityscapes dataset. They also demonstrate that their interactive approach can reach 90.6 % mIoU on the VOC validation set with an overhead of just 3.5 % on the standard validation set.
SP:2eb90879ddbc39b6b5c05152784d6044d1940513,"This paper proposes a real - time adversarial defense based on a learned saliency model for image classification. The proposed method is motivated by the fact that adversarial perturbations can cause a shift in the salient features of an image, which can lead to adversarial misclassification. The authors propose to use a learnt saliency map to capture this shift in saliency and propose a CNN that distinguishes between adversarial and natural images using salient pixels as its input. The defense is evaluated on MNIST, CIFAR-10, and DeepFool attacks. The results show that the proposed method can detect adversarial images generated by strong attacks."
SP:fe5510d05ff091a5f133f2dbcd1b23d8d58d2c3e,"This paper studies the problem of estimating the global adversarial robustness of a machine learning model, i.e., the probability that its prediction at any point sampled from the ( unknown ) input distribution is susceptible to adversarial attacks. The authors first show how concentration inequalities can be employed to compute global robustness with estimation error upper - bounded by, for any > 0 selected a priori. They then provide statistically sound analysis of the robustness / accuracy trade - off for a variety of neural networks architectures and training methods on MNIST, Fashion - MNIST and CIFAR. They empirically observe that robustness and accuracy tend to be negatively correlated for networks trained via stochastic gradient descent and with iterative techniques, while a positive trend is observed between them in Bayesian settings."
SP:8f5616a1480b68c04b496ed498d237d5a7e87794,"This paper studies the problem of risk - aware policy optimization in the context of robust reinforcement learning ( RRL ). The authors propose a novel method based on Wasserstein distance ( WSD ) to connect transition kernel disturbance to the state disturbance, i.e., reduce an infinite - dimensional optimization problem to a finite - dimensional risk aware problem. They show the existence of optimal robust policies, provide a sensitivity analysis for the perturbations, and then design a novel robust learning algorithm that leverages WSD. The effectiveness of the proposed algorithm is verified in the Cart - Pole environment."
SP:d85963f5f0f6b20cf08f2a7c169ae33a45db7de2,"This paper proposes a method to approximate mixed strategy Nash equilibria in multi - player continuous games. The main idea is to use the pushforward measure technique to represent a mixed strategy in continuous spaces. This allows us to generalize the Gradient - based Nikaido - Isoda ( GNI ) function to measure the distance between the players ’ joint strategy profile and a Nash equilibrium. The proposed method is shown to converge to a stationary Nash equilibrium under the convexity assumption on payoff functions, the same popular setting as in previous studies. Experiments are conducted on quadratic games, general blotto games, and GAMUT games."
SP:280d85cd8164a268f9d496ae5f17189c50f30dc1,"This paper proposes a method to augment training data for text classification using natural language explanations ( NL ). NL explanations are unstructured and inherently compositional, resulting in low recall and limited generalization ability. To overcome these challenges, the authors propose a novel Neural Execution Tree ( NExT ) framework to transform NL explanations into executable logical forms by semantic parsing, which substantially increases the coverage of each NL explanation. Experiments on two NLP tasks ( relation extraction and sentiment analysis ) demonstrate its superiority over baseline methods."
SP:a9b5f7257dedd719cfe341fca275776734af1d98,"This paper proposes a method for verifying the robustness and consistency of neural networks based on the verification of their training parameters. The main idea is to train a neural network that is robust to perturbations in the training parameters such that it is consistent with the verification parameters. This can be applied to RNNs with recurrent neural networks and to specifications that are more complex than simple adversarial robustness, e.g., requiring that a robot periodically visits a charging station or that a language model always produces bounded length sentences. The method is shown to be applicable to both RNN - based and non - RNN based models, and it is shown that the verified training method produces models that are both robust and consistent with specifications."
SP:3903680e07b676409e3cf6a1044b67291fe38630,"This paper proposes a regularization method for domain randomization to reduce the variance in the learned policies. The proposed method is motivated by the idea of domain generalization, which aims to generalize to a wide range of visually different environments. The main idea is to regularize the learned representations of the learned state representations by minimizing the Lipschitz constant of the policy ’s randomization parameters. To this end, the authors formalize the problem into a two - stage process. First, a domain randomizer is applied to the parameters of the regularization objective, and second, the learned representation of the environment is regularized during training. The authors show that their method is more efficient and robust to robust learning than the standard domain randomisation ( DRR )."
SP:c79046dc56b9ee9c926f87386046422ea134ae8d,"This paper studies the problem of deep metric learning ( DML ) and proposes a simple and effective framework to sample pairs in a batch of data for updating the model. The key to this framework is to define a robust loss for all pairs over a mini - batch of training data, which is formulated by distributionally robust optimization ( DPO ). The flexibility in constructing the uncertainty decision set of the dual variable allows us to recover state - of - the - art results on several benchmark data sets."
SP:38420928e40ef80c0136ad607b9275f9ab1e0769,"This paper studies the problem of finding a local minimum in a non - convex finite - sum minimization problem. The authors propose a stochastic trust region ( STR ) algorithm for this problem, which improves the state - of - the - art result by a factor of $ O(1/\sqrt{k})$ in the case of Hessian Hessian oracle queries. They also develop Hessian - free STR algorithms which achieve the lowest runtime complexity.    The main contributions of this paper are the following :   1. Propose a novel Hessian estimator for the nonconvex setting. 2. Introduce a sample - efficient STR algorithm that finds an $ \sqrt{\log(n)$-approximate local minimum within $ \tilde{O}(n/\exp(n ) \log(sqrt(n))$ stochastically random Hessian queries. 3. Conduct extensive experiments to verify the theoretical conclusions and the efficiency of proposed algorithms."
SP:28a35b70b5e6915af28cacebc4ea50690c9534af,"This paper proposes Farkas layers, a geometrically - motivated method for training deep neural networks that ensures at least one neuron is active at a given layer. The proposed method is applied to residual networks with ReLU activation. The authors empirically demonstrate a significant improvement in training capacity in the absence of batch normalization or methods of initialization across a broad range of network sizes on benchmark datasets.   The main contributions of this paper are : 1. Introduce a new method for linear programming based on farkas ; 2. Empirically demonstrate that the proposed method can improve the training capacity of deep networks without the use of any regularization or weight initialization ; 3. Utilize the results from linear programming to propose a new training method for deep networks."
SP:1d325b148e3efe407241c1f1cbe8d17400499741,"This paper studies the problem of computing computationally - efficient robustness certificates for deep classifiers with differentiable activation functions in the l2 norm efficiently using convex optimization. The authors show that if the eigenvalues of the Hessian of the network (curvatures of the networks ) are bounded, they can compute a robustness certificate in $ l_2 $ norm efficiently. Second, they derive a computationally efficient upper bound on the curvature of a deep network to boost its certified robustness against adversarial examples. Finally, the authors propose a Curvature - based Robust Training ( CRT ) method to boost the certified accuracy of deep neural networks."
SP:33f6f5aa0d4655e5d75fe612e0eff05e579d45c5,"This paper proposes a novel method for compressed sensing recovery using untrained deep generative models. The method is based on the recently proposed Deep Image Prior ( DIP ), wherein the convolutional weights of the network are optimized to match the observed measurements. The authors show that this approach can be applied to solve any differentiable linear inverse problem, outperforming previous unlearned methods. Unlike various learned approaches based on generative model, this method does not require pre - training over large datasets, and it does not need to be trained over large dataset. This paper also introduces a novel learned regularization technique, which incorporates prior information on the network weights, which reduces reconstruction error, especially for noisy measurements."
SP:23c0f621e6041003b59bf0532130760694cf6a4a,"This paper proposes a hierarchical reinforcement learning ( HRL ) framework TAIC, which learns the temporal abstraction from past experience or expert demonstrations without task - specific knowledge. TAIC learns latent representations of action sequences by regularizing the latent space by adding information - theoretic constraints. Specifically, it maximizes the mutual information between the latent variables and the state changes. The learned abstraction allows us to learn new tasks on higher levels more efficiently, and the experiments show that TAIC is an effective technique in increasing the convergence rate and sample efficiency of RL algorithms."
SP:4e54c9196ba1eb2b6a0b0eee41e4a6f3a9de72dd,"This paper proposes a layer - wise sampling strategy to scale GCN - like models to larger graphs and deeper layers due to the over - expansion of neighborhoods across layers. The proposed method samples the nodes layer by layer conditionally based on the factors of the bi - directional diffusion between layers, and construct a mini - batch of nodes with a self - attention mechanism to learn suitable weights for the sampled nodes, which allows the model to be able to incorporate both the first - order and higher - order proximities during a single layer propagation process without extra recursive propagation or skip connection. Extensive experiments on three large benchmark graphs demonstrate the effectiveness and efficiency of the proposed method."
SP:bb0af9c011ef982c34fcadb545f6b5771818e7fa,"This paper presents a state - space model for videos that explicitly reasons about objects and their positions, velocities, and interactions. The model is constructed by combining an image model and a dynamics model in a compositional manner and improves on previous work by reusing the dynamics model for inference, accelerating and regularizing training. The authors also demonstrate the strength of the model as a simulator for sample efficient model - based control in a task with heavily interacting objects. The experiments show that the proposed method outperforms previous unsupervised models and approaches the performance of supervised baselines."
SP:e67b463bc0aec2345925d609fa521ea49df57fd9,This paper proposes a new variational autoencoding ( VAE ) model that combines the best properties of VAE and generative adversarial networks ( GAN ). The proposed model optimizes the divergence between the model distribution and the true data distribution using adversarial training. The authors propose to use an implicit likelihood instead of an explicit likelihood such as Gaussian or Laplace which have limited flexibility in high dimensions and are unnatural for modelling images. The experimental results show that the proposed model achieves the state - of - the - art trade - off between generation and reconstruction quality on CIFAR-10 and TinyImagent datasets.
SP:87056d0147ddcaf5d78f6888b05161fbdbb3346c,"This paper studies adversarial attacks on Bayesian classifiers. The authors show that the Bayesian optimal classifier is vulnerable to adversarial examples in certain class distributions, while the optimal classifer is robust in others. They show conditions under which all points can be made arbitrarily close to the optimal decision boundary and show that this can happen even when the classes are easy to separate, when the ideal classifier has a smooth decision surface and when the data lies in low dimensions. They introduce new datasets of realistic realistic images of faces and digits where the Bayes - Optimal classifier can be calculated efficiently. They find that standard CNN training consistently finds a vulnerable classifier even when optimal classifiers is robust while large - margin methods often find a robust classifier with the exact same training data."
SP:a7b3a35e6a79084bdfd1e4a963dfa081279cd8bb," top - 1 accuracy is a popular metric for evaluating the performance of neural networks. This metric measures the top-1 accuracy of a neural network trained on a given set of test examples. The paper proposes a new metric, called pruning identified exemplars ( PIEs ), which is based on the observation that certain classes of examples are more affected by the introduction of sparsity than others. The authors show that removing PIE images from the test - set greatly improves top -1 accuracy for both sparse and non - sparse models."
SP:4b17edaa7ec6201891433320d85f9a415656b763,"This paper proposes KG - A2C1, an agent that builds a dynamic knowledge graph while exploring and generates actions using a template - based action space. The key idea is to use the knowledge graph to reason about game state and to constrain natural language generation as the keys to scalable exploration of combinatorially large natural language actions. The proposed method is evaluated in a wide variety of text - based IF games. Results show that the proposed method outperforms current IF agents in most cases."
SP:b1784ecbb8f36eef9cae33d61ce60d80c2f9c38d,"This paper proposes a data - dependent Gaussian prior objective ( D2GPo ) to improve the performance of maximum likelihood estimation ( MLE ) in language generation tasks. The proposed objective is based on the Kullback - Leibler divergence term ( KLL ), which is used in smoothing the training of MLE. The authors claim that MLE suffers from negative diversity ignorance in the sense that it treats all incorrect predictions as being equally incorrect. To address this issue, the authors propose to use an additional KLL term that penalizes the MLE loss by introducing an extra divergence term based on a data dependent Gaussian prior objective. The experimental results show that the proposed method makes effective use of a more detailed prior in the data and has improved performance in typical tasks, including supervised and unsupervised machine translation, text summarization, text captioning, and image captioning."
SP:7c29cb5a32b14e1392408dc5daba4cd35848bea9,"This paper proposes a new calibration method for deep neural networks ( DNNs ). The proposed method is based on focal loss and temperature scaling. The main idea is to replace the widely used cross - entropy loss with focal loss. The authors show that focal loss can be combined with temperature scaling to yield state - of - the - art calibrated models. They also show that the proposed method also preserves the confidence of the model's correct predictions, which is desirable for downstream tasks."
SP:cd6b8417ec8bcb773c78cff677bb0a76d6b3f6f3,"This paper proposes LiPopt, a polynomial optimization framework for computing tighter upper bounds on the Lipschitz constant of neural networks. The underlying optimization problem is either linear ( LP ) or semidefinite ( SDP ) programming. The authors show how to use the sparse connectivity of a network, to significantly reduce the complexity of computation. This is specially useful for convolutional as well as pruned neural networks, and the authors conduct experiments on networks with random weights and networks trained on MNIST, showing that in the particular case of the $ \ell_\infty$-Lipshitz constant, the proposed approach yields superior estimates."
SP:31c9dc0dd8806daddc9cb48c56ec819577fe46cd,"This paper proposes a self - supervised learning approach for video features. The proposed method extends the BERT model for text sequences to the case of sequences of real - valued feature vectors by replacing the softmax loss with noise contrastive estimation ( NCE ). The authors also show how to learn representations from sequences of visual features and sequences of words derived from ASR ( automatic speech recognition ). Experiments on downstream tasks such as video classification, captioning and segmentation show the effectiveness of the proposed method."
SP:0f24424d10f1201dd25e8c56354e10afc9b2b11c,"This paper proposes a data - augmentation method for neural networks. The main idea is to train a neural network that selects a subset of the input data that is relevant for the subsequent application of a given neural network. This is achieved by training both the associated selection masks as well as the neural network simultaneously such that a good model performance is achieved while, at the same time, only a minimal amount of data is selected. During the inference phase, only the parts selected by the masks have to be transferred between the server and the client. Experiments show that it is often possible to significantly reduce the number of data needed to be selected without affecting the model performance much."
SP:aa4fcf5b2cae05c5c6a903c24e4992b56655dee2,This paper proposes a novel method for detecting out - of - distribution ( OOD ) samples in deep neural networks ( DNNs ). The proposed method is based on the Outlier Exposure ( OE ) technique and a novel loss function for OE is proposed. Experiments on both image and text classification tasks show that the proposed OOD detection method outperforms existing methods. The paper also shows that the combination of the proposed method with the Mahalanobis distance - based classifier achieves better results than the baseline methods.
SP:89bc528ef801182365ac279e8963803afccb391d,"This paper proposes an end - to - end deep learning model for RNA secondary structure prediction that can effectively take into account the inherent constraints in the problem. The key idea of E2Efold is to directly predict the RNA base - pairing matrix, and use an unrolled algorithm for constrained programming as the template for deep architectures to enforce constraints. Extensive experiments on benchmark datasets demonstrate the superior performance of the proposed method."
SP:b68560cce8c64ebe0ca5e6534b3732c775d36452,"This paper proposes a setting where biases are involved when agents internalise an environment, and agents have different biases. Each agent asynchronously internalises their own predictive model of the environment and forms a virtual simulation within which the agent plays trials of the episodes in entirety. The authors focus on developing a collective policy trained solely inside agents ’ simulations, which can then be transferred to the real - world environment. The key idea is to let agents imagine together ; make them take turns to host virtual episodes within which all agents participate and interact with their own biased representations. Since agents’ biases vary, the collective policy developed while sequentially visiting the internal simulations complement one another ’s shortcomings and achieve significantly higher returns than the best individually trained policies."
SP:bd1dc08b4fd9a5cc78d26d7eb7f05dbb4a629ab1,"This paper proposes a dialog generation model that learns a semantic latent space by maximizing the correlation between the features extracted from prompt and responses. The model learns the pair relationship between the prompts and responses as a regression task on the latent space, instead of classification on the vocabulary using MLE loss, enables the model to view semantically related responses collectively. Experimental results show that the proposed model eliminates the generic response problem, while achieving comparable or better results compared to the baseline methods."
SP:ef0d5fd333ed60feb3946d24002e9a90642aea66,This paper proposes a Gaussian light and shadow ( GLAS ) method to estimate the spatial impact of deep models by the feature perturbation inspired by light - shadow in nature. GLAS provides a useful coarseto - fine control for fine - grained classification. The authors also devised the ability to identify multiple instances through recursive GLAS. The effectiveness of GLAS is demonstrated on the ImageNet Large scale Visual Recognition Challenge dataset.
SP:d17ca20cc527c28ab7358cb5b14954e5fb56409f,"This paper proposes a new method for training neural networks called network deconvolution to remove pixel - wise and channel - wise correlations before the data is fed into each layer of the network. The method is motivated by the observation that existing convolutional kernels are in effect re - learning redundant data by applying a kernel to overlapping regions shifted across the image. The proposed method can be efficiently calculated at a fraction of the computational cost of a convolution layer. Extensive experiments show that the proposed method is able to deliver performance improvement in all cases on the CIFAR-10/100/100, MNIST, Fashion - MNIST, Cityscapes, and ImageNet datasets."
SP:e1b0de9a36bf8359df368b7a55a7f23e99d88db7,This paper proposes a quantization method for generative adversarial neural networks ( GANs ) based on neural network quantization. The authors apply existing quantization methods to quantize weights in GAN models to 1 - bit or 2 - bit representations with results of quality comparable to original models. The generator and discriminator networks show different sensitivities upon the quantization precision. The author also proposes a multi - precision algorithm to help find an appropriate quantized precision of GAN ’s given image qualities requirements.
SP:58c4905f59f04a50b30d27c99521126a6455d38a,This paper studies the last - iterate convergence of HGD in a variety of settings beyond the bilinear and convex - strongly - concave settings. The main result is that HGD converges linearly to a stationary point at the end of the last iterate. The paper also proves convergence rates for stochastic HGD and for some parameter settings of the HGD algorithm in the case of the Mescheder et al. ( 2017 ).   The paper is well organized and easy to follow.
SP:d8556b52272321a1415ac2d85bb12e88b51ee73a,"This paper studies the stability of the forward and backward process of learning Resnet blocks. Specifically, the authors show that the stability is guaranteed for $ \tau$-1/\sqrt{L}$, where $ L$ is the number of residual blocks and $ \sqrt{\log(L)$ is a scalar. The authors also show that if ResNet is properly over - parameterized, it is guaranteed to find the global minima which significantly enlarges the range of stability. Empirically, they show that with $ \mathcal{T}$= 1 / L, deep ResNet can be easily trained even without normalization layer and adding a normalisation layer can improve the performance."
SP:cf70dc496825ece2f28fdf4f1a6f4316c69e0e48,"This paper proposes a method to train sparse neural networks with a fixed parameter count and a fixed computational cost throughout training. The method updates the topology of the network during training by using parameter magnitudes and infrequent gradient calculations to achieve a given level of accuracy compared to prior dense - to - sparse training methods. The authors demonstrate state - of - the - art sparse training results on the ImageNet - 2012 dataset, CIFAR-10 dataset, and RNNs on the WikiText -103 dataset."
SP:d2d2b892518d54d0e63e26a056f2298be3be2610,"This paper studies the interpretability of generative models by introducing a new method to find meaningful directions in the latent space of any generative model along which we can move to control precisely specific properties of the generated image like the position or scale of the object in the image. The method does not require human annotations and is particularly well suited for the search of directions of directions encoding simple transformations of the generative image, e.g., position of object in image. They demonstrate the effectiveness of their method qualitatively and quantitatively, both both for GANs and for image generation qualitatively. They also show that the position of an object can be controlled within the image using their method.    The main contributions of this paper are :   1. Introduce a method to control the latent variables of a generative network by controlling the directions in latent space that can be taken to control specific properties such as position and scale of object. 2. Utilize a GAN model to generate images with the proposed method. 3. Empirically show that their method is competitive with other methods in terms of interpretability."
SP:1c63389e972d4652fac831e9d11609cd3c3c371a,"This paper proposes a physics - as - inverse - graphics - based model for unsupervised physical parameter estimation of systems from video, where the differential equations governing the scene dynamics are known but labeled states or objects are not available. Existing physical scene understanding methods require either object state supervision, or do not integrate with differentiable physics to learn interpretable system parameters and states. This framework allows to perform long term extrapolative video prediction, as well as vision based model - predictive control. The proposed method significantly outperforms related unsuper supervised methods in long - term future frame prediction of systems with interacting objects. The controller ’s interpretability provides unique capabilities in goal - driven control and physical reasoning for zero - data adaptation."
SP:c6b8b682bf3087a65cb2379700b8a0183853c2af,"This paper proposes a GCN - based method for few - shot learning where only a few clean labeled examples are given for each class. The graph structure of clean and noisy data is modeled by a graph per class and graph convolutional networks ( GCN ) are used to predict class relevance of noisy examples. For each class, the GCN is treated as a binary classifier learning to discriminate clean from noisy examples using a weighted binary cross - entropy loss function, and then the “ clean ” probability is exploited as a relevance measure. Each noisy example is weighted by its relevance when learning a classifier for the end task. The proposed method is evaluated on an extended version of a few -shot learning problem, where the few clean examples of novel classes are supplemented with additional noisy data. Experimental results show that the proposed method significantly improves the classification accuracy over the existing methods."
SP:dd9c9a5dccbba5dd15b03ca6b314a9e153e95548,"This paper proposes a new objective function for graph neural networks ( GNNs ) that maximizes the Mutual Information ( MI ) between edge features and message passing channels. The MI is reformulated as a differentiable objective via a variational approach. The authors show that the newly introduced objective enables the model to preserve edge information, and empirically corroborate the enhanced performance of MI - maximized models across a broad range of learning tasks including regression on molecular graphs and relation prediction in knowledge graphs."
SP:f1cf63d728da51b4f83eb50ef69e3788b3a5ed74,This paper proposes a new verifier for verifying the properties of generative models. The proposed method is based on a generative model that encodes the latent representation of the latent space of the network into a latent vector. The latent vector is then used to compute the probability distribution of the output of the generative network. The output of this latent vector can then be used to certify the non - trivial properties of the model. The verifier is evaluated on both deterministic and probabilistic abstract interpretation. The experimental results show that the proposed method outperforms the state - of - the - art methods for verification on a variety of tasks.
SP:2b0887dcf09249e8cee30d38163aeb9ef1e92b27,"This paper studies the performance degradation of graph neural networks ( GNNs ) when the model depth reaches the suspended animation limit ( SOD ), where the model will not respond to the training data any more and become not learnable. To resolve the problem, this paper introduces the GRESNET ( Graph Residual Network ) framework in this paper, which creates extensively connected highways to involve nodes ’ raw features or intermediate representations throughout the graph for all the model layers. Extensive empirical experiments on real - world benchmark datasets demonstrate the effectiveness of the introduced new graph residual terms from the norm from the perspective of the norm preservation perspective, which will help avoid dramatic changes to the node ’s representations between sequential layers. Detailed studies about the proposed framework for many existing graph neural network models, including GCN, GAT and LOOPYNET, will be reported in the paper with extensive empirical experiments."
SP:dc436ade4d04072de35a90e5e4a1bfebfddb04e9,"This paper proposes a non - linear parametric CNN - based face reconstruction method for ill - posed face image reconstruction. The proposed method is based on a convolutional neural network ( CNN ) that regresses the face shape and texture directly from the unlabeled unlabelled and labeled face images. In particular, the proposed method disentangles identity, expression, pose, and lighting representations, which improves the overall reconstruction performance and facilitates facial editing applications, e.g., expression transfer. Extensive experiments demonstrate that the proposed model produces high - quality reconstruction compared to state - of - the - art methods and is robust to various expressions, pose, and lighting conditions."
SP:f7bc06697b09e2d59ec06b2cbcf3c0828ece32ae,"This paper proposes a model for imitation learning in a setting where partial knowledge about the transition kernel is not available. The proposed model, called eMDP, uses a synthetic kernel to simulate the transition of state components for which the unknown kernel is known, and extracts from demonstrations the next state from the state for which this kernel is unknown. The next state is then stitched from the two components s and su using a policy gradient algorithm. The experiments show that the proposed model achieves superior performance compared to the simulation - free alternative in the case of multiplayer games."
SP:82cce92821e8168ab4a6fd67573b66c1d17673b8,"This paper proposes a self - supervised reinforcement learning method for robotic manipulation tasks with sparse rewards that maximizes the mutual information between the context state and the state of interest. The intrinsic reward function is based on maximizing mutual information from the states of interest and the context states. The proposed mutual information based state - control ( MISC ) approach is evaluated on two robotic manipulation environments ( OpenAI Gym and the Gazebo robot navigation environment ). The results show that MISC is able to learn to manipulate the object, such as pushing and picking up, purely based on the intrinsic mutual information rewards."
SP:5db63d39cfd8132bec832ab64b8fbd403b3b8df0,"This paper proposes a novel trojaned attack method for large neural network models, which is programmable that the malicious misclassification target is not fixed and can be generated on demand even after the victim ’s deployment. The proposed method outperforms existing studies in capability, generality, and stealthiness. The authors also show that the attack is not limited in a small domain and can affect applications of different target classes."
SP:35ea626ee4dd1a7a368a660eb852192924966b7f,This paper proposes a new few - shot regression ( FSR ) algorithm for drug discovery. The proposed algorithm is based on a combination of a deep neural network with a kernel function and a differentiable kernel algorithm. The choice of kernel is critical and the proposed algorithm learns to find the appropriate kernel for each task during inference. Experiments show that the proposed method outperforms the state - of - the - art algorithms on both toy and novel benchmarks.
SP:91ca4c3ee07617356250bae9f4ef9799b3b134ff,"This paper proposes a framework to characterize which reasoning tasks a neural network can learn well, by studying how well its computation structure aligns with the algorithmic structure of the relevant reasoning process. The authors define this algorithmic alignment and derive a sample complexity bound that decreases with better alignment. This framework offers an explanation for the empirical success of popular reasoning models, and suggests their limitations.   Theoretically, there is limited understanding of why and when a network structure generalizes better than others, although they have equal expressive power. In this paper, the authors show that GNNs align with DP and thus are expected to solve these tasks. On several reasoning tasks, the theory is supported by empirical results."
SP:a52aee8da5cf5acd2baf3c2a62cb679e13b18bd5,"This paper proposes a new metric for benchmarking conditional GANs. The proposed metric is based on the Fréchet Joint Distance ( FJD ), which is defined as the distance between joint distributions of images and conditioning distributions. The authors show that FJD can be used as a promising single metric for CGAN benchmarking and model selection. They conduct experiments on a controllable synthetic dataset to highlight the benefits of FJD compared to existing metrics."
SP:fa822e8472efae17c7dfde8258057898383ecbbb,"This paper proposes to learn to identify ‘ decision states ’, which are parsimonious sets of states in which decisions made by an agent can affect the future states it can reach in an environment. The authors use the VIC framework, which maximizes an agent ’s ‘ empowerment ’ and formulate a sandwich bound on the empowerment objective that allows identification of decision states. Unlike previous work ( Goyal et al. 2019 ), the decision states are discovered without extrinsic rewards – simply by interacting with the world.   The authors show that the decision state is 1 ) often interpretable, and 2 ) lead to better exploration on downstream goal - driven tasks in partially observable environments."
SP:a19a51df7e28a5d3380be4fba13842efbfe3efec,"This paper proposes SEFT ( Set Functions for Time Series ), a method for irregularly sampled and asynchronous time series with unaligned measurements. The method is based on recent advances in differentiable set function learning, and scales well to very large datasets and online monitoring scenarios. The authors extensively compare their method to competitors on multiple healthcare time series datasets and show that it performs competitively while significantly reducing runtime."
SP:4ae89d64460b08749acc192004545c1fa8b7553b,This paper proposes a method for training convolutional neural networks ( CNNs ) to model audio priors by explicitly utilizing the harmonic structure of the input audio signal. The method is based on convolution kernels that are supported by sets of harmonic series instead of by local neighborhoods. The authors empirically show that current network architectures for audio processing do not show strong evidence in capturing such priors. The proposed method is evaluated on unsupervised audio restoration and generalization performance for audio generation.
SP:c81a2b3fd1c56b9b18e4a358e3ff8b40aea5256a,"This paper proposes a data - echoing technique to reduce the total computation used by earlier stages of the training pipeline and speed up training whenever computation upstream from accelerators dominates the training time. Data echoing reuses ( or “echoes ” ) intermediate outputs from earlier pipeline stages in order to reclaim idle capacity. The authors investigate the behavior of different data echoing algorithms on various workloads, for various amounts of echoing, and for various batch sizes. They find that in all settings, at least one data echoing algorithm can reduce a factor of 3.25 decrease in wall - clock time for training when reading training data over a network."
SP:b4cf56d3fa7d65cacde33f17cd04bd5bbc52dd71,"This paper proposes a novel algorithm for learning policies that can rapidly learn from limited feedback. The key idea is to leverage successor features to provide enhanced generalization and fast task inference by leveraging the reward function in a setting where the rewards are only exposed briefly after a long unsupervised phase. The author ’s main contribution is to combine two existing approaches, Successor Features ( SP ) and VISR ( VISR ), to solve the difficulty of generalization beyond the finite set of behaviors being explicitly learned in SP. The proposed VISR algorithm learns controllable features that can be leveraged through the successor features framework. The authors empirically validate VISR on the full Atari suite and show human - level performance on 12 games and beating all baselines."
SP:83500230586a9134f910ad067b7233dc563dc1ba,"This paper presents a theoretical analysis of functional approximations of deep neural networks ( DNNs ). The main contributions are two - fold :   1. Theoretical ( in shallow networks ) and experimentally probing properties of these networks reveals insights into the effect of standard initializations, the value of depth, the underlying loss surface, and generalization.    2. One key result is that generalization results from smoothness of the functional approximation combined with a flat initial approximation. This smoothness increases with number of units, explaining why massively overparameterized networks continue to generalize well."
SP:7225825e353b711a7d023f706fafe5e17e4e2fb2,This paper proposes a new method for image - to - image translation in GANs. The main idea is to add an attention mechanism to the discriminator of a GAN so that it can better estimate the probability that its input is real and create an attention map that highlights the critical features for such prediction. The attention map is then used by the generator to produce more plausible and realistic images. The proposed method is evaluated on a number of image datasets and compared with other GAN - based methods on both qualitative and quantitative evaluation.
SP:41c089ba65393174dae1dc136f79030a0a4fc532,"This paper explores the role of multiplicative interaction layers as a unifying framework to describe a range of classical and modern neural network architectural motifs, such as gating, attention layers, hypernetworks, and dynamic convolutions. The authors show that such layers strictly enrich the representable function classes of neural networks and conjecture that multiplicative interactions offer a particularly powerful inductive bias when fusing multiple streams of information or when conditional computation is required. They therefore argue that they should be considered in many situation where multiple compute or information paths need to be combined, in place of the simple and oft - used concatenation operation, the multiplicative operation."
SP:5144391584e6d3825e12684b7c053e4e282cff2b,"This paper proposes a new algorithm for active learning with deep neural network models. The proposed algorithm, Batch Active learning by Diverse Gradient Embeddings ( BADGE ), samples groups of points that are disparate and high magnitude when represented in a hallucinated gradient space, which is designed to incorporate both predictive uncertainty and sample diversity into every selected batch. Crucially, BADGE trades off between uncertainty and diversity without requiring any hand - tuning hyperparameters. The experimental results show that BADGE consistently performs as well or better than other active learning methods, making it a useful option for real world active learning problems."
SP:ce6023b1e6bf45b071a6f5457b2575425ae03366,This paper proposes a method for self - explanation in deep neural networks ( DNNs ). The main idea is to use a mixture of low level features and high level features in the hidden layers of a DNN to improve the interpretability of the network. The method is based on the GLM architecture. The experiments are conducted on CIFAR-10 and MNIST datasets. The results show that the proposed method outperforms the vanilla DNN on Cifar-10 while being more self - explaining.
SP:b70ceead1bf6c7dc684c74501716e7012b891022,"This paper proposes a new adversarial training method for extreme classification. The main idea is to train a classifier by sampling negative samples from the data using an adversarial model that mimics the data distribution. The authors claim that the adversarial sampling mechanism produces negative samples at a cost only logarithmic in the number of classes C, thus still resulting in cheap gradient updates. The paper also provides a mathematical proof that the proposed method can be used in conjunction with uniform negative sampling.  "
SP:29b52fee83309268d9864f3b1fc3617948577d41,"This paper proposes a model - based approach for efficient exploration that leverages a low dimensional encoding of the environment learned with a combination of model based and model - free objectives. The proposed approach uses intrinsic rewards that are based on a weighted distance of nearest neighbors in the low dimensional representational space to gauge novelty and leverage these intrinsic rewards for sample - efficient exploration with planning routines. The authors claim that intrinsic rewards can be used to justify more gradient steps in - between every environment step in order to ensure the model accuracy. They test their approach on a number of maze tasks, as well as a control problem and show that their exploration approach is more sample - efficiency compared to strong baselines."
SP:257c98dc1a9f3efcbf9544d9ee2ff524b000543d,"This paper studies out - of - distribution ( OOD ) detection in the setting of few - shot classification, where the goal is to learn to classify examples from unseen classes using only a few labeled examples per class. The authors propose two new methods for OOD detection based on a combination of two existing methods, FOL and FOL+OOD, and establish two new benchmark datasets based on four popular few shot classification datasets. The proposed methods are evaluated using standard metrics on two benchmark datasets and show improved results with our proposed methods.  "
SP:a3632b773143dfb3a8f104c6b658dfa1167d155b,"This paper proposes a generative model of sequence generation that unifies decoding in directed and undirected neural sequence models. The generative framework models the process of generation rather than a resulting sequence, and under this framework, the authors derive various neural sequence model as special cases, such as autoregressive, semi - autore Progressive, and refinement - based non - auto - regressive models. They demonstrate this by evaluating various decoding strategies for a cross - lingual masked translation ( LCT ) task. The experiments show that generation from the generative generation model is competitive with the state - of - the - art on WMT'14 English - German translation. The authors also demonstrate that the proposed approach enables constant - time translation with similar performance to linear time translation from the same model by rescoring hypotheses with an autooregressive model."
SP:eca5e2be9831dfb79c4f5e633cbfadcfd2e00eb1,"This paper proposes a two - stage method for the recognition of mathematical expressions ( MEs ). In the first stage, an object detection network is used to identify the math symbols of the input image, and in the second stage a LaTeX sequence is generated by a seq2seq model equipped with attention mechanism. The detection of mathematical symbols and the structural analysis of mathematical formulas are carried out separately in two steps, which effectively improves the recognition accuracy and enhances the generalization ability. The experiment shows that the proposed method significantly outperforms the end - to - end method."
SP:923fee8623da1569a7f54a57b4b326f29440b4c0,This paper proposes a vector quantization method that aims at preserving the quality of the reconstruction of the network outputs rather than its weights. The method only requires a set of unlabelled data at quantization time and allows for efficient inference on CPU by using bytealigned codebooks to store the compressed weights. Experiments validate the approach by quantizing a high performing ResNet-50 model to a memory size of 5 MB ( 20 * compression factor ) while preserving a top - 1 accuracy of 76.1 % on ImageNet object classification and by compressing a Mask R - CNN with a 26 * factor.
SP:74850ad70241948f93fed95ba1f0ac11360437c1,"This paper proposes a new Transformer - based model for solving the Mathematics Dataset ( mathdaset ). The model is based on the Tensor Product Transformer ( TPR ) framework, which is used to represent the relation structure between the input and output products of a Transformer cell. The main contribution of this paper is a novel attention mechanism, called TP - Attention, which explicitly encodes the relations between each Transformer cells and the other cells from which values have been retrieved by attention. The proposed attention mechanism resolves ambiguities introduced by multiple layers of standard attention by explicitly encoding the relations among the cells. The paper is well organized and easy to follow. The experiments show that the proposed model is able to solve math problems in the math dataset."
SP:d319df820c6630c409fab32097652a083e8f53ea,"This paper proposes an optimization method to learn a more general classification function. The main idea is to reformulate a learning algorithm as a procedure for searching for a source code that maps input features to classes, and derive a necessary and sufficient condition for generalization using a universal cognitive similarity metric, namely information distance, based on Kolmogorov complexity. To showcase the theoretical findings, the authors show that corrupted or perturbed input features belong to the empirical sample set, but typically not to the training and test sets, and demonstrate through extensive systematic experiments that a model trained on encoded input features is significantly more robust to common corruptions, e.g., Gaussian and shot noise, as well as adversarial perturbations.    The main contribution of this paper is to formulate an optimization problem to improve the degree to which the training data set is representative of the empirical data set, which consists of real - world input samples. When samples are drawn from an underrepresented or unrepresented subset during inference, the gap between the training accuracies and inference accuracies can be significant."
SP:b8e86f5e89330d81ba4967a7ed2dbfb56375d8a0,"Graph pooling is a critical ingredient in graph classification and graph - based regression tasks. In this paper, the authors propose a graph pooling operation based on compressive Haar transforms, called HaarPooling, which is computed by following a chain of sequential clusterings of the input graph. The input of each pooling layer is transformed by the compressed Haar basis of the corresponding clustering. The proposed method operates in the frequency domain by the synthesis of nodes in the same cluster and filters out fine detail information. By the sparsity of the Haar Transforms, the proposed method achieves state - of - the - art performance on diverse graph classification problems."
SP:17bea301d6718ef5f28864dd2445552b3cf65eeb,The paper proposes a sample - based point cloud decoder architecture for variable - sized 3D point clouds. The main idea is to adapt the encoder network to match the semantics of the input point clouds in order to improve the decoder's effectiveness over naive feedforward encoders. The paper proposes three sample based decoder architectures and compares their performance to each other and show their improved effectiveness over feedforward architectures.   The paper is well organized and easy to follow.
SP:51d826ead5d1d9cb89d493ce4c39728651bbc57b,"This paper studies the effect of real - world noise on the generalization performance of deep neural networks ( DNNs ). The authors present a benchmark of real world noisy labels at 10 controlled noise levels across a variety of noise levels and architectures, architectures, methods, and training settings. They show that : ( 1 ) Deep Neural Networks generalize much better on real world noise than synthetic noise ; ( 2 ) DNN ’s may not learn patterns first on noisy data ; ( 3 ) When networks are fine - tuned, noisy labels are more difficult for robust DNN methods to improve ; and ( 4 ) Robust learning methods that work well on synthetic noise may not work as well on real noise, and vice versa."
SP:9873f78fb2821afdbb5551700e6ab6a0e8bcb9f0,This paper proposes a rule - exemplar method for learning from a mixture of human supervision and rule - denoising supervision. The idea is to jointly denoise the supervision using soft - implication loss and use the denoised supervision to train a classifier. The proposed method is evaluated on a variety of tasks and compared with several existing methods. The results show that the proposed method outperforms the existing methods on most tasks.
SP:6f2c656dbb7629f652a4291d6971625184d8118b,Graph Neural Networks ( GNNs ) are a class of deep models that operate on data with arbitrary topology represented as graphs. This paper proposes a memory - based GNN ( MemGNN ) and graph memory network ( GMN ) to jointly learn node representations and coarsen the graph. The experimental results show that the proposed models achieve state - of - the - art results in eight out of nine graph classification and regression benchmarks. The paper also shows that the learned representations could correspond to chemical features in the molecule data.
SP:81bc52d734c86975d741b6482d65ca71a9d81620,"This paper studies the effect of initialization in deep linear networks and provides a rigorous proof that drawing the initial weights from the orthogonal group speeds up convergence relative to the standard Gaussian initialization with iid weights. The authors show that for deep networks, the width needed for efficient convergence to a global minimum is independent of the depth, whereas the width is linearly in the depth. The results demonstrate how the benefits of a good initialization can persist throughout learning, especially in very deep non - linear networks according to the principle of dynamical isometry."
SP:9f5d95fc89c2f0d59d04838aa180f3db67997dfa,"This paper proposes a method to compress deep neural networks down to 2 - bits without hurting the accuracy. The main idea is to optimize the bit allocation of weights and activations for deep CNNs compression. The authors first explore the additivity of output error caused by quantization and find that additivity property holds for deep neural network which are continuously differentiable in the layers. Based on this observation, they formulate the optimal bit allocation problem of weight and activation allocation in a joint framework and propose a very efficient method to solve the optimization problem via Lagrangian formulation. The proposed method can compress deep CNN ResNet-50 to 2 bits with only 0.7 % accuracy loss. To the best of my knowledge, this is the first paper that reports 2 - bit results on deep CNN."
SP:7191d7b217a12b1bf9c47d790896a8227c14cc3d,"This paper proposes an extension of the Wasserstein GAN ( WGAN ) framework to the problem of learning a generative model for GANs. The authors propose to use an encoder network as the encoder of WGANs, and a generator as the generator. The encoder and generator are trained jointly using an iterative primal dual optimization ( PDE ) process. The paper provides a generalization error bound for the proposed iWGANs and a probabilistic interpretation of the proposed model under the framework of maximum likelihood estimation. The proposed method is evaluated on state - of - the - art datasets and shows a competitive and stable performance compared to the baselines."
SP:cca6ae14fd0dd12352855e594acf7f3263bb1f24,"This paper proposes a new CrowdSourcing model for anaphoric annotation, where annotators annotate a set of markables to a coreference chain whose number can not be predefined. The authors use a nonparametric partially pooled structure, fitting jointly with the ability of the annotators hierarchical community profiles. The proposed model is more resilient to different crowdsourcing setups, and it provides insights into the community of workers. It is also flexible enough to be used in standard annotation tasks for classification where it achieves on par performance with the state - of - the - art."
SP:4295cae4a56a02eb21c486408c1bf37a7483cb49,"This paper proposes to use intrinsic motivation to accelerate exploration in sparse reward reinforcement learning by learning separate intrinsic and extrinsic task policies and schedule these different drives. The intrinsic reward is learned as successor feature control ( SFC ), which is general and not task - specific. The proposed intrinsic drive ( SID ) agent is evaluated on three different environments with pure visual inputs. The results show a substantially improved exploration efficiency with SFC and the hierarchical usage of the intrinsic drives."
SP:9fa22eb03a79bce0fc1c8e84ae8640e010701eca,"This paper proposes a method for weakly - supervised video moment retrieval that leverages a multi - level attention mechanism to learn richer multimodal representations. The proposed method is comprised of a Frame - By - Word interaction module as well as a novel Word - Conditioned Visual Graph ( WCVG ). It also incorporates a novel application of positional encodings, commonly used in Transformers, to learn visual - semantic representations that contain contextual information of their relative positions in the temporal sequence through iterative message - passing.   The proposed wMAN model not only outperforms the state - of - the - art weakly supervised method on the DiDeMo dataset by a significant margin but also obtains an improvement of 10 % for the Recall@1 accuracy metric over strongly - supervised SOTA methods."
SP:27ac670353f34ee7a23bb7622f80c1dfbc0985e0,"This paper proposes an image - guided rendering method that combines image - based rendering and GAN - based image synthesis. The main idea is to train an object - specific deep neural network to synthesize the view - dependent appearance of an object using an RGB video of the object, which is used to reconstruct a proxy geometry via multi - view stereo stereo. Based on this 3D proxy geometry, the appearance of a captured view can be warped into a new target view as in classical Image - based Rendering ( IBR ). To composite multiple reprojected images to a final output, a composition network that outputs photo - realistic results is learned. Experiments on synthetic and real data demonstrate the effectiveness of the proposed method."
SP:257d124367b1da9a595dc11a9df750d6bade298e,"This paper presents a sparse representation of model uncertainty for deep neural networks ( DNNs ) that relies on an inverse formulation of Multivariate Normal Distribution ( MND ) as an information form. The authors show that the model uncertainty can be estimated in this form using a scalable Laplace Approximation scheme, which involves a diagonal correction of the Kronecker - factorized eigenbasis. As this makes the inversion of the information matrix intractable an operation that is required for a full Bayesian analysis, the authors devise a novel low - rank approximation of this eigenbais that exploits spectral sparsity of DNN. Methods to realize this sparsification are provided that develops into a memory - wise tractable sampling computations. Both theoretical analysis and empirical evaluations over various benchmarks show the superiority of our approach over existing methods."
SP:2e03ceba4004b82f86f8349352a8ee4520e9c35d,"This paper proposes a load - balanced hashing ( AHash ) method, which can generate as few empty bins as possible and is more efficient compared with One Permutation Hashing ( OPH ) and densification strategies. The main drawback of OPH is that the load of the bins ( the number of elements in a bin ) could be unbalanced, which leads to the existence of empty bins and false similarity computation. Therefore, the authors propose to use AHash to solve the problem of unbalanced load. The proposed method is shown to be much more efficient than OPH and the densification strategy. The experiments on real datasets validate the claim.  "
SP:d73827ab98b0ff6bd92abfefea43a5f88ea40de2,"This paper proposes a method for extracting features from phase shift data by adding a graph structure to each data point and constructing a suitable machine learning architecture for it. The proposed method is based on the fact that in almost all machine processes there is a phase shift in the measurement of the time steps. It is difficult for classical methods, like multi - layer perceptron, to identify or quantify this phase shift because they depend on the order of the input vectors ’ components. The authors propose a robust method that only changes the order in which all the data points are collected. The method is evaluated on two simulation datasets and one synthetic dataset. The results show that the proposed method outperforms the baselines."
SP:0df5ad333eb4ff9cca7f2d117909e2ce533a65d8,"Neural conditional text generation systems have achieved significant progress in recent years, showing the ability to produce highly fluent text. However, the inherent lack of controllability in these systems allows them to hallucinate factually incorrect phrases that are unfaithful to the source, making them often unsuitable for many real world systems that require high degrees of precision. In this work, the authors propose a novel confidence oriented decoder that assigns a confidence score to each target position. This score is learned in training using a variational Bayes objective, and can be leveraged at inference time using a calibration technique to promote more faithful generation. Experiments on a structured data - to - text dataset – WikiBio ( Lebret et al., 2016 ) show that our approach is more faithful than existing state - of - the - art approaches, according to both automatic metrics and human evaluation."
SP:03307deac29173b2968fbd08f95fc77eb1f82410," pruning is one of the most common methods for pruning neural networks. This paper extends magnitude - based pruning from a single layer optimization to a multi - layer optimization based on the observation that magnitude pruning indeed minimizes the Frobenius distortion of a linear operator corresponding to a single - layer layer. Based on this observation, the authors propose a simple pruning method, termed lookahead pruning, by extending the single - level optimization to multi - layers optimization. The experimental results demonstrate that the proposed method consistently outperforms magnitude-based pruning on various networks, including VGG and ResNet, particularly in the high - sparsity regime."
SP:dc80fdc75bc14ae19fe4ba9b85c35ce00b12856f,"This paper proposes a decentralized stochastic gradient descent ( SGD ) algorithm that uses quantized communication between parallel workers in a graph - based decentralized SGD setting. The main idea is to communicate a provably bounded number of bits per iteration, while converging at the same asymptotic rate as the original algorithm does with full - precision communication. The authors prove in theory that Moniqua communicates a quantized message with probability $ 1/\sqrt{d}(d)$ where $ d$ is the number of workers in the graph. They also show empirically that the proposed algorithm converges faster with respect to wall clock time than other quantized decentralized algorithms."
SP:86c61a658d07ab86e2d84cef7e480bf7a06e4ddb,"This paper proposes a new family of partial models for reinforcement learning that are provably causally correct and fast to learn. The authors claim that previous works on partial models have shown that partial models can be causally incorrect if they are confounded by the observations they don't model, and can therefore lead to incorrect planning. To address this problem, the authors propose a general family of models that is provably correct but fast because they do not need to fully model future observations. The main contribution of the paper is the introduction of a new class of partial model that is fast because it only models part of the observation and not all of it."
SP:c70479b2096a52584b242de58272ca8d8565feea,"The paper proposes a new variational autoencoder ( VAE ) model that learns a succinct common representation of two correlated data variables for conditional and joint generation tasks. The proposed Wyner VAE model is based on two information theoretic problems — distributed simulation and channel synthesis, in which Wyner ’s common information arises as the fundamental limit of the succinctness of the common representation. The utility of the proposed approach is demonstrated through experiments for joint and conditional generation with and without style control using synthetic data and real images."
