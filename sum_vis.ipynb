{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9326216a-ad6d-43aa-af8a-668e5be0c4dc",
   "metadata": {},
   "source": [
    "# Summaries Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3507480c-4441-4edf-8248-1418b7964f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "RAWDATAFILES = {\n",
    "    \"train\": \"training_complete.jsonl\",\n",
    "    \"val\": \"validation_complete.jsonl\",\n",
    "    \"test\": \"testing_with_paper_release.jsonl\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "de5a4202-0619-452d-9232-0cc9ddeeed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_cluster(data_split, features = 'Ent_Rel',model='kmeans-k3',ver=1):\n",
    "    filepath = f\"clustering/{features}/{model}-{data_split}-v{ver}.csv\"\n",
    "    print(f\"importing clusters from {filepath}\")\n",
    "    return pd.read_csv(filepath).drop_duplicates().drop(columns='sum_id')\n",
    "\n",
    "def import_fullpaper(data_split, raw=True):\n",
    "    if raw: \n",
    "        filepath = f\"dataset_MuP/{RAWDATAFILES[data_split]}\" \n",
    "    else: \n",
    "        filepath = f\"{main_path}/dataset_MuP/{data_split}_iden.jsonl\"\n",
    "    print(f\"importing full paper from {filepath}\")\n",
    "    with open(filepath, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "    result = []\n",
    "    for i, json_str in enumerate(json_list):\n",
    "        data = json.loads(json_str)\n",
    "        result.append({\n",
    "            'paper_id': data['paper_id'], \n",
    "            'heading': 'ABSTRACT', \n",
    "            'text': data['paper']['abstractText'],\n",
    "        })\n",
    "    \n",
    "        sections = [{'paper_id': data['paper_id'], **sec} for sec in data['paper']['sections']]\n",
    "        result += sections\n",
    "    return  pd.DataFrame(result).drop_duplicates()\n",
    "\n",
    "def import_graph(data_split):\n",
    "    filepath = f\"PL-Marker/_scire_models/MuP/summary/{data_split}_re.json\"\n",
    "    print(f\"importing graph data from {filepath}\")\n",
    "    with open(filepath, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "    return pd.DataFrame([json.loads(json_str) for json_str in json_list]).drop(columns=['ner', 'relations'])\n",
    "\n",
    "def import_gen_sum(data_split):\n",
    "    model = \"bart-large-cnn_abstract+introduction-1+conclusion_text\"\n",
    "    filepath = f\"finetuning/generated_summary/{data_split}/{model}.csv\"\n",
    "    return pd.read_csv(filepath)\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3f3606a2-acbe-46bf-9b5c-e8e00841b01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2sum(sent_list):\n",
    "    return ' '.join([' '.join(sent) for sent in sent_list])\n",
    "    \n",
    "def prepare_df(data_split):\n",
    "    cluster_df = import_cluster(data_split)\n",
    "    fullpaper_df = import_fullpaper(data_split)\n",
    "    graph_df = import_graph(data_split)\n",
    "    graph_df['summary'] = graph_df['sentences'].apply(sent2sum)\n",
    "    graph_df.rename(columns={'doc_key': 'paper_id'}, inplace=True)\n",
    "    merge_sum_df = cluster_df.merge(graph_df, on=['paper_id', 'summary'])\n",
    "    return merge_sum_df, fullpaper_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b68b48-4d61-4f8a-a280-2b4a9db71c7c",
   "metadata": {},
   "source": [
    "## Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f251d29a-20b9-43a0-8621-3b0030f9b8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing clusters from clustering/Ent_Rel/kmeans-k3-train-v1.csv\n",
      "importing full paper from dataset_MuP/training_complete.jsonl\n",
      "importing graph data from PL-Marker/_scire_models/MuP/summary/train_re.json\n"
     ]
    }
   ],
   "source": [
    "cluster_df = import_cluster(\"train\")\n",
    "fullpaper_df = import_fullpaper(\"train\")\n",
    "graph_df = import_graph(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ad711bf2-3d35-47fc-b977-5345edae7df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2sum(sent_list):\n",
    "    return ' '.join([' '.join(sent) for sent in sent_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "64cad11d-38b4-4340-91ef-867c45295581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentences</th>\n",
       "      <th>predicted_ner</th>\n",
       "      <th>predicted_re</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>[[This, paper, investigates, kernel, ridge, -,...</td>\n",
       "      <td>[[[3, 7, Method], [15, 16, OtherScientificTerm...</td>\n",
       "      <td>[[0, []], [1, [[[19, 20], [23, 24], 'USED-FOR'...</td>\n",
       "      <td>This paper investigates kernel ridge - less re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:b80bc890180934092cde037b49d94d6e4e06fad9</td>\n",
       "      <td>[[This, paper, presents, a, novel, way, of, ma...</td>\n",
       "      <td>[[[11, 13, Method], [16, 17, OtherScientificTe...</td>\n",
       "      <td>[[0, [[[11, 13], [16, 17], 'USED-FOR'], [[16, ...</td>\n",
       "      <td>This paper presents a novel way of making full...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939</td>\n",
       "      <td>[[This, paper, proposes, a, new, framework, th...</td>\n",
       "      <td>[[[5, 5, Generic], [9, 12, Method], [16, 17, O...</td>\n",
       "      <td>[[0, [[[9, 12], [16, 17], 'USED-FOR'], [[5, 5]...</td>\n",
       "      <td>This paper proposes a new framework that compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP:a1e2218e6943bf138aeb359e23628676b396ed66</td>\n",
       "      <td>[[This, work, proposes, a, deep, reinforcement...</td>\n",
       "      <td>[[[4, 10, Method], [13, 15, Task], [18, 20, Ta...</td>\n",
       "      <td>[[0, [[[4, 10], [13, 15], 'USED-FOR'], [[13, 1...</td>\n",
       "      <td>This work proposes a deep reinforcement learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66</td>\n",
       "      <td>[[This, paper, proposes, 3, deep, generative, ...</td>\n",
       "      <td>[[[4, 6, Method], [9, 9, Method], [13, 14, Oth...</td>\n",
       "      <td>[[0, [[[4, 6], [22, 26], 'USED-FOR'], [[13, 14...</td>\n",
       "      <td>This paper proposes 3 deep generative models b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18929</th>\n",
       "      <td>SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695</td>\n",
       "      <td>[[This, paper, presents, a, RNN, -, RL, based,...</td>\n",
       "      <td>[[[4, 8, Method], [11, 13, Task]], [[16, 16, G...</td>\n",
       "      <td>[[0, [[[4, 8], [11, 13], 'USED-FOR']]], [1, []...</td>\n",
       "      <td>This paper presents a RNN - RL based method fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18930</th>\n",
       "      <td>SP:4706017e6f8b958c7d0825fed98b285ea2994b59</td>\n",
       "      <td>[[This, paper, proposes, a, new, pointwise, co...</td>\n",
       "      <td>[[[5, 7, Method]], [[27, 27, Generic], [31, 31...</td>\n",
       "      <td>[[0, []], [1, [[[33, 33], [37, 37], 'USED-FOR'...</td>\n",
       "      <td>This paper proposes a new pointwise convolutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18931</th>\n",
       "      <td>SP:4706017e6f8b958c7d0825fed98b285ea2994b59</td>\n",
       "      <td>[[This, paper, presents, a, new, pointwise, co...</td>\n",
       "      <td>[[[5, 10, Method], [14, 14, Generic], [17, 17,...</td>\n",
       "      <td>[[0, [[[17, 17], [19, 19], 'CONJUNCTION'], [[1...</td>\n",
       "      <td>This paper presents a new pointwise convolutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18932</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>[[This, paper, proposes, to, model, various, u...</td>\n",
       "      <td>[[[6, 7, Metric], [9, 14, Method], [16, 18, Me...</td>\n",
       "      <td>[[0, [[[6, 7], [9, 14], 'PART-OF'], [[16, 18],...</td>\n",
       "      <td>This paper proposes to model various uncertain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18933</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>[[The, authors, proposed, a, Bayesian, graph, ...</td>\n",
       "      <td>[[[4, 8, Method], [10, 11, Task]], [[15, 15, G...</td>\n",
       "      <td>[[0, [[[4, 8], [10, 11], 'USED-FOR']]], [1, [[...</td>\n",
       "      <td>The authors proposed a Bayesian graph neural n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18934 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          paper_id  \\\n",
       "0      SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc   \n",
       "1      SP:b80bc890180934092cde037b49d94d6e4e06fad9   \n",
       "2      SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939   \n",
       "3      SP:a1e2218e6943bf138aeb359e23628676b396ed66   \n",
       "4      SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66   \n",
       "...                                            ...   \n",
       "18929  SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695   \n",
       "18930  SP:4706017e6f8b958c7d0825fed98b285ea2994b59   \n",
       "18931  SP:4706017e6f8b958c7d0825fed98b285ea2994b59   \n",
       "18932  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb   \n",
       "18933  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb   \n",
       "\n",
       "                                               sentences  \\\n",
       "0      [[This, paper, investigates, kernel, ridge, -,...   \n",
       "1      [[This, paper, presents, a, novel, way, of, ma...   \n",
       "2      [[This, paper, proposes, a, new, framework, th...   \n",
       "3      [[This, work, proposes, a, deep, reinforcement...   \n",
       "4      [[This, paper, proposes, 3, deep, generative, ...   \n",
       "...                                                  ...   \n",
       "18929  [[This, paper, presents, a, RNN, -, RL, based,...   \n",
       "18930  [[This, paper, proposes, a, new, pointwise, co...   \n",
       "18931  [[This, paper, presents, a, new, pointwise, co...   \n",
       "18932  [[This, paper, proposes, to, model, various, u...   \n",
       "18933  [[The, authors, proposed, a, Bayesian, graph, ...   \n",
       "\n",
       "                                           predicted_ner  \\\n",
       "0      [[[3, 7, Method], [15, 16, OtherScientificTerm...   \n",
       "1      [[[11, 13, Method], [16, 17, OtherScientificTe...   \n",
       "2      [[[5, 5, Generic], [9, 12, Method], [16, 17, O...   \n",
       "3      [[[4, 10, Method], [13, 15, Task], [18, 20, Ta...   \n",
       "4      [[[4, 6, Method], [9, 9, Method], [13, 14, Oth...   \n",
       "...                                                  ...   \n",
       "18929  [[[4, 8, Method], [11, 13, Task]], [[16, 16, G...   \n",
       "18930  [[[5, 7, Method]], [[27, 27, Generic], [31, 31...   \n",
       "18931  [[[5, 10, Method], [14, 14, Generic], [17, 17,...   \n",
       "18932  [[[6, 7, Metric], [9, 14, Method], [16, 18, Me...   \n",
       "18933  [[[4, 8, Method], [10, 11, Task]], [[15, 15, G...   \n",
       "\n",
       "                                            predicted_re  \\\n",
       "0      [[0, []], [1, [[[19, 20], [23, 24], 'USED-FOR'...   \n",
       "1      [[0, [[[11, 13], [16, 17], 'USED-FOR'], [[16, ...   \n",
       "2      [[0, [[[9, 12], [16, 17], 'USED-FOR'], [[5, 5]...   \n",
       "3      [[0, [[[4, 10], [13, 15], 'USED-FOR'], [[13, 1...   \n",
       "4      [[0, [[[4, 6], [22, 26], 'USED-FOR'], [[13, 14...   \n",
       "...                                                  ...   \n",
       "18929  [[0, [[[4, 8], [11, 13], 'USED-FOR']]], [1, []...   \n",
       "18930  [[0, []], [1, [[[33, 33], [37, 37], 'USED-FOR'...   \n",
       "18931  [[0, [[[17, 17], [19, 19], 'CONJUNCTION'], [[1...   \n",
       "18932  [[0, [[[6, 7], [9, 14], 'PART-OF'], [[16, 18],...   \n",
       "18933  [[0, [[[4, 8], [10, 11], 'USED-FOR']]], [1, [[...   \n",
       "\n",
       "                                                 summary  \n",
       "0      This paper investigates kernel ridge - less re...  \n",
       "1      This paper presents a novel way of making full...  \n",
       "2      This paper proposes a new framework that compu...  \n",
       "3      This work proposes a deep reinforcement learni...  \n",
       "4      This paper proposes 3 deep generative models b...  \n",
       "...                                                  ...  \n",
       "18929  This paper presents a RNN - RL based method fo...  \n",
       "18930  This paper proposes a new pointwise convolutio...  \n",
       "18931  This paper presents a new pointwise convolutio...  \n",
       "18932  This paper proposes to model various uncertain...  \n",
       "18933  The authors proposed a Bayesian graph neural n...  \n",
       "\n",
       "[18934 rows x 5 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_df['summary'] = graph_df['sentences'].apply(sent2sum)\n",
    "graph_df.rename(columns={'doc_key': 'paper_id'}, inplace=True)\n",
    "graph_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fc4694a4-6424-4fac-9eaf-f4fd1d4e4e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>summary</th>\n",
       "      <th>cluster</th>\n",
       "      <th>sentences</th>\n",
       "      <th>predicted_ner</th>\n",
       "      <th>predicted_re</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>This paper investigates kernel ridge - less re...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[This, paper, investigates, kernel, ridge, -,...</td>\n",
       "      <td>[[[3, 7, Method], [15, 16, OtherScientificTerm...</td>\n",
       "      <td>[[0, []], [1, [[[19, 20], [23, 24], 'USED-FOR'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:b80bc890180934092cde037b49d94d6e4e06fad9</td>\n",
       "      <td>This paper presents a novel way of making full...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[This, paper, presents, a, novel, way, of, ma...</td>\n",
       "      <td>[[[11, 13, Method], [16, 17, OtherScientificTe...</td>\n",
       "      <td>[[0, [[[11, 13], [16, 17], 'USED-FOR'], [[16, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939</td>\n",
       "      <td>This paper proposes a new framework that compu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[This, paper, proposes, a, new, framework, th...</td>\n",
       "      <td>[[[5, 5, Generic], [9, 12, Method], [16, 17, O...</td>\n",
       "      <td>[[0, [[[9, 12], [16, 17], 'USED-FOR'], [[5, 5]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP:a1e2218e6943bf138aeb359e23628676b396ed66</td>\n",
       "      <td>This work proposes a deep reinforcement learni...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[This, work, proposes, a, deep, reinforcement...</td>\n",
       "      <td>[[[4, 10, Method], [13, 15, Task], [18, 20, Ta...</td>\n",
       "      <td>[[0, [[[4, 10], [13, 15], 'USED-FOR'], [[13, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66</td>\n",
       "      <td>This paper proposes 3 deep generative models b...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[This, paper, proposes, 3, deep, generative, ...</td>\n",
       "      <td>[[[4, 6, Method], [9, 9, Method], [13, 14, Oth...</td>\n",
       "      <td>[[0, [[[4, 6], [22, 26], 'USED-FOR'], [[13, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18929</th>\n",
       "      <td>SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695</td>\n",
       "      <td>This paper presents a RNN - RL based method fo...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[This, paper, presents, a, RNN, -, RL, based,...</td>\n",
       "      <td>[[[4, 8, Method], [11, 13, Task]], [[16, 16, G...</td>\n",
       "      <td>[[0, [[[4, 8], [11, 13], 'USED-FOR']]], [1, []...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18930</th>\n",
       "      <td>SP:4706017e6f8b958c7d0825fed98b285ea2994b59</td>\n",
       "      <td>This paper proposes a new pointwise convolutio...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[This, paper, proposes, a, new, pointwise, co...</td>\n",
       "      <td>[[[5, 7, Method]], [[27, 27, Generic], [31, 31...</td>\n",
       "      <td>[[0, []], [1, [[[33, 33], [37, 37], 'USED-FOR'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18931</th>\n",
       "      <td>SP:4706017e6f8b958c7d0825fed98b285ea2994b59</td>\n",
       "      <td>This paper presents a new pointwise convolutio...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[This, paper, presents, a, new, pointwise, co...</td>\n",
       "      <td>[[[5, 10, Method], [14, 14, Generic], [17, 17,...</td>\n",
       "      <td>[[0, [[[17, 17], [19, 19], 'CONJUNCTION'], [[1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18932</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>This paper proposes to model various uncertain...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[This, paper, proposes, to, model, various, u...</td>\n",
       "      <td>[[[6, 7, Metric], [9, 14, Method], [16, 18, Me...</td>\n",
       "      <td>[[0, [[[6, 7], [9, 14], 'PART-OF'], [[16, 18],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18933</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>The authors proposed a Bayesian graph neural n...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[The, authors, proposed, a, Bayesian, graph, ...</td>\n",
       "      <td>[[[4, 8, Method], [10, 11, Task]], [[15, 15, G...</td>\n",
       "      <td>[[0, [[[4, 8], [10, 11], 'USED-FOR']]], [1, [[...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18934 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          paper_id  \\\n",
       "0      SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc   \n",
       "1      SP:b80bc890180934092cde037b49d94d6e4e06fad9   \n",
       "2      SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939   \n",
       "3      SP:a1e2218e6943bf138aeb359e23628676b396ed66   \n",
       "4      SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66   \n",
       "...                                            ...   \n",
       "18929  SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695   \n",
       "18930  SP:4706017e6f8b958c7d0825fed98b285ea2994b59   \n",
       "18931  SP:4706017e6f8b958c7d0825fed98b285ea2994b59   \n",
       "18932  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb   \n",
       "18933  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb   \n",
       "\n",
       "                                                 summary  cluster  \\\n",
       "0      This paper investigates kernel ridge - less re...        2   \n",
       "1      This paper presents a novel way of making full...        2   \n",
       "2      This paper proposes a new framework that compu...        2   \n",
       "3      This work proposes a deep reinforcement learni...        2   \n",
       "4      This paper proposes 3 deep generative models b...        1   \n",
       "...                                                  ...      ...   \n",
       "18929  This paper presents a RNN - RL based method fo...        2   \n",
       "18930  This paper proposes a new pointwise convolutio...        2   \n",
       "18931  This paper presents a new pointwise convolutio...        0   \n",
       "18932  This paper proposes to model various uncertain...        1   \n",
       "18933  The authors proposed a Bayesian graph neural n...        0   \n",
       "\n",
       "                                               sentences  \\\n",
       "0      [[This, paper, investigates, kernel, ridge, -,...   \n",
       "1      [[This, paper, presents, a, novel, way, of, ma...   \n",
       "2      [[This, paper, proposes, a, new, framework, th...   \n",
       "3      [[This, work, proposes, a, deep, reinforcement...   \n",
       "4      [[This, paper, proposes, 3, deep, generative, ...   \n",
       "...                                                  ...   \n",
       "18929  [[This, paper, presents, a, RNN, -, RL, based,...   \n",
       "18930  [[This, paper, proposes, a, new, pointwise, co...   \n",
       "18931  [[This, paper, presents, a, new, pointwise, co...   \n",
       "18932  [[This, paper, proposes, to, model, various, u...   \n",
       "18933  [[The, authors, proposed, a, Bayesian, graph, ...   \n",
       "\n",
       "                                           predicted_ner  \\\n",
       "0      [[[3, 7, Method], [15, 16, OtherScientificTerm...   \n",
       "1      [[[11, 13, Method], [16, 17, OtherScientificTe...   \n",
       "2      [[[5, 5, Generic], [9, 12, Method], [16, 17, O...   \n",
       "3      [[[4, 10, Method], [13, 15, Task], [18, 20, Ta...   \n",
       "4      [[[4, 6, Method], [9, 9, Method], [13, 14, Oth...   \n",
       "...                                                  ...   \n",
       "18929  [[[4, 8, Method], [11, 13, Task]], [[16, 16, G...   \n",
       "18930  [[[5, 7, Method]], [[27, 27, Generic], [31, 31...   \n",
       "18931  [[[5, 10, Method], [14, 14, Generic], [17, 17,...   \n",
       "18932  [[[6, 7, Metric], [9, 14, Method], [16, 18, Me...   \n",
       "18933  [[[4, 8, Method], [10, 11, Task]], [[15, 15, G...   \n",
       "\n",
       "                                            predicted_re  \n",
       "0      [[0, []], [1, [[[19, 20], [23, 24], 'USED-FOR'...  \n",
       "1      [[0, [[[11, 13], [16, 17], 'USED-FOR'], [[16, ...  \n",
       "2      [[0, [[[9, 12], [16, 17], 'USED-FOR'], [[5, 5]...  \n",
       "3      [[0, [[[4, 10], [13, 15], 'USED-FOR'], [[13, 1...  \n",
       "4      [[0, [[[4, 6], [22, 26], 'USED-FOR'], [[13, 14...  \n",
       "...                                                  ...  \n",
       "18929  [[0, [[[4, 8], [11, 13], 'USED-FOR']]], [1, []...  \n",
       "18930  [[0, []], [1, [[[33, 33], [37, 37], 'USED-FOR'...  \n",
       "18931  [[0, [[[17, 17], [19, 19], 'CONJUNCTION'], [[1...  \n",
       "18932  [[0, [[[6, 7], [9, 14], 'PART-OF'], [[16, 18],...  \n",
       "18933  [[0, [[[4, 8], [10, 11], 'USED-FOR']]], [1, [[...  \n",
       "\n",
       "[18934 rows x 6 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_sum_df = cluster_df.merge(graph_df, on=['paper_id', 'summary'])\n",
    "merge_sum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "96c8942f-4d12-403f-9571-2acc2b1511b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_diff_list = []\n",
    "for paper_id in set(merge_sum_df.paper_id):\n",
    "    df = merge_sum_df[merge_sum_df.paper_id==paper_id]\n",
    "    if len(set(df.cluster))==3: paper_diff_list.append(paper_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "73d4a12a-c2a3-4500-9335-193c91f3086b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 2: The paper analyzes the relationship between relative quantization errors and fixed - point formats for zero - centered normal distributions and finds a linear model which fits the best exponent length of the fixed - point data type given a standard deviation . These insights are then unified with parameterized clipping activation ( PACT ) to normalize incoming floating point data into the desired fixed point range . To handle the network with sole 8 - bit multiplications a forward pass in floating precision is used to compute batch norm statistics for the main 8 - bit forward / backward pass . Additional adjustments are made between successive layers and residual layers which rely on reusing some statistics of the previous layer .\n",
      "Cluster 1: The authors propose a new quantization flow to train DNNs using only 8 - bit fixed - point multiplications . They show that 8 - bit fixed point can represent different exponent ranges based on fractional length , thus choosing the right fractional length is critical . They then empirically derive a formula to calculate the optimal fractional length for a tensor based on its standard deviation . The authors combine PACT ( learnable clip threshold ) with fixed - point quantization , and propose a two - pass method to handle batch norm . They can achieve a small accuracy improvement ( < 1 % ) when training from scratch or fine - tuning on ImageNet using a variety of small models ( ResNet-18 and MobileNet variants ) , compared to other quantization - aware training methods .\n",
      "Cluster 0: This paper describes a novel quantization framework that involving only fix - point 8 - bit multiplication for DNN execution . The paper first highlights the advantages of the fixed - point numeric format . The paper then conducts some statistical study and derive an empirical formula to relate the fraction length of the fix - point representation with the standard deviation of the value distribution . After that , the paper introduces a novel approach to determine the right format for each layer during the forward propagation of the training . The proposed solution , F8Net , has been evaluation on ImageNet using multiple DNN structures ( e.g. , MobileNet , ResNet ) .  \n",
      "Cluster 1: The paper proposes a low - precision DNN inference models with 8 - bit fixed point . To realize the number of fraction bits , the author uses the variance of DNN parameters and combines it with PACT approach in QAT . The new approach is evaluated in various neural networks such as MobileNet V1 / V2 and ResNet18/50 on ImageNet for image classification and the result are mostly par with the state of the art approaches .\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "paper_id = paper_diff_list[n]\n",
    "paper_id = \"SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e\"\n",
    "df = merge_sum_df[merge_sum_df.paper_id==paper_id]\n",
    "for idx, row in df.iterrows():\n",
    "    print(f\"Cluster {row.cluster}: {row.summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f08edf13-636c-4dbd-91cb-df30dd8dde89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>heading</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195895</th>\n",
       "      <td>SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e</td>\n",
       "      <td>ABSTRACT</td>\n",
       "      <td>Neural network quantization is a promising com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195896</th>\n",
       "      <td>SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e</td>\n",
       "      <td>1 INTRODUCTION</td>\n",
       "      <td>Real-time inference on resource-constrained an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195897</th>\n",
       "      <td>SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e</td>\n",
       "      <td>2 RELATED WORK</td>\n",
       "      <td>Quantization is one of the most widely-used te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195898</th>\n",
       "      <td>SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e</td>\n",
       "      <td>3 ANALYSIS OF FIXED-POINT REPRESENTATION</td>\n",
       "      <td>In this section, we first introduce the fixed-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195899</th>\n",
       "      <td>SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e</td>\n",
       "      <td>3.1 ADVANTAGES OF FIXED-POINT ARITHMETIC</td>\n",
       "      <td>Fixed-point number is characterized by its for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195900</th>\n",
       "      <td>SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e</td>\n",
       "      <td>3.2 STATISTICAL ANALYSIS FOR FIXED-POINT FORMAT</td>\n",
       "      <td>For a predefined bit-width, integer, which is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195901</th>\n",
       "      <td>SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e</td>\n",
       "      <td>3.3 CHOOSING OPTIMAL FIXED-POINT FORMAT</td>\n",
       "      <td>With the above observations, we are interested...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195902</th>\n",
       "      <td>SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e</td>\n",
       "      <td>4 METHODS</td>\n",
       "      <td>In this section, we discuss our proposed train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195903</th>\n",
       "      <td>SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e</td>\n",
       "      <td>4.1 UNIFYING PACT AND FIXED-POINT QUANTIZATION</td>\n",
       "      <td>To quantize a positive value x with unsigned f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195904</th>\n",
       "      <td>SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e</td>\n",
       "      <td>4.2 UPDATING BN AND FRACTIONAL LENGTH</td>\n",
       "      <td>Double Forward for BN Fusion. To quantize the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195905</th>\n",
       "      <td>SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e</td>\n",
       "      <td>4.3 RELATING SCALING FACTORS BETWEEN ADJACENT ...</td>\n",
       "      <td>As shown in (4), there are still two extra fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195906</th>\n",
       "      <td>SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e</td>\n",
       "      <td>6 CONCLUSION</td>\n",
       "      <td>Previous works on neural network quantization ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195907</th>\n",
       "      <td>SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e</td>\n",
       "      <td>7 APPENDIX</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195908</th>\n",
       "      <td>SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e</td>\n",
       "      <td>7.1 MORE EXPERIMENTAL DETAILS</td>\n",
       "      <td>More Details for Conventional Training. For co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195909</th>\n",
       "      <td>SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e</td>\n",
       "      <td>7.2 MORE DETAILS FOR STATISTICAL ANALYSIS</td>\n",
       "      <td>For the toy example in Fig. 3, we sample 10, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195910</th>\n",
       "      <td>SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e</td>\n",
       "      <td>7.3 DERIVATION FOR FIXED-POINT AND PACT RELATION</td>\n",
       "      <td>Here we derive the relationship between PACT a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195911</th>\n",
       "      <td>SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e</td>\n",
       "      <td>7.4 DOUBLE SIDE QUANTIZATION FOR WEIGHT AND MO...</td>\n",
       "      <td>In (2), we only give the formula for fixed-poi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195912</th>\n",
       "      <td>SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e</td>\n",
       "      <td>7.5 DERIVATION OF EFFECTIVE WEIGHT</td>\n",
       "      <td>Here we derive the equation of effective weigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195913</th>\n",
       "      <td>SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e</td>\n",
       "      <td>7.6 PRIVATE FRACTIONAL LENGTHS ENABLING DIFFER...</td>\n",
       "      <td>Here we analyze the effect of using private fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195914</th>\n",
       "      <td>SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e</td>\n",
       "      <td>7.7 MORE DISCUSSION OF THE OPTIMAL FRACTIONAL ...</td>\n",
       "      <td>Here we give some further discussion of using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195915</th>\n",
       "      <td>SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e</td>\n",
       "      <td>7.8 FRACTIONAL LENGTH FOR RESNET50</td>\n",
       "      <td>Here we provide more results of fractional len...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195916</th>\n",
       "      <td>SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e</td>\n",
       "      <td>7.9 ANALYZING SEARCHING SPACE OF FRACTIONAL LE...</td>\n",
       "      <td>In the main paper, we adopt the largest possib...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paper_id  \\\n",
       "195895  SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e   \n",
       "195896  SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e   \n",
       "195897  SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e   \n",
       "195898  SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e   \n",
       "195899  SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e   \n",
       "195900  SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e   \n",
       "195901  SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e   \n",
       "195902  SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e   \n",
       "195903  SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e   \n",
       "195904  SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e   \n",
       "195905  SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e   \n",
       "195906  SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e   \n",
       "195907  SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e   \n",
       "195908  SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e   \n",
       "195909  SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e   \n",
       "195910  SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e   \n",
       "195911  SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e   \n",
       "195912  SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e   \n",
       "195913  SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e   \n",
       "195914  SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e   \n",
       "195915  SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e   \n",
       "195916  SP:9e9fdc790ae44306844c7ae6c82aaf2dc8e69e0e   \n",
       "\n",
       "                                                  heading  \\\n",
       "195895                                           ABSTRACT   \n",
       "195896                                     1 INTRODUCTION   \n",
       "195897                                     2 RELATED WORK   \n",
       "195898           3 ANALYSIS OF FIXED-POINT REPRESENTATION   \n",
       "195899           3.1 ADVANTAGES OF FIXED-POINT ARITHMETIC   \n",
       "195900    3.2 STATISTICAL ANALYSIS FOR FIXED-POINT FORMAT   \n",
       "195901            3.3 CHOOSING OPTIMAL FIXED-POINT FORMAT   \n",
       "195902                                          4 METHODS   \n",
       "195903     4.1 UNIFYING PACT AND FIXED-POINT QUANTIZATION   \n",
       "195904              4.2 UPDATING BN AND FRACTIONAL LENGTH   \n",
       "195905  4.3 RELATING SCALING FACTORS BETWEEN ADJACENT ...   \n",
       "195906                                       6 CONCLUSION   \n",
       "195907                                         7 APPENDIX   \n",
       "195908                      7.1 MORE EXPERIMENTAL DETAILS   \n",
       "195909          7.2 MORE DETAILS FOR STATISTICAL ANALYSIS   \n",
       "195910   7.3 DERIVATION FOR FIXED-POINT AND PACT RELATION   \n",
       "195911  7.4 DOUBLE SIDE QUANTIZATION FOR WEIGHT AND MO...   \n",
       "195912                 7.5 DERIVATION OF EFFECTIVE WEIGHT   \n",
       "195913  7.6 PRIVATE FRACTIONAL LENGTHS ENABLING DIFFER...   \n",
       "195914  7.7 MORE DISCUSSION OF THE OPTIMAL FRACTIONAL ...   \n",
       "195915                 7.8 FRACTIONAL LENGTH FOR RESNET50   \n",
       "195916  7.9 ANALYZING SEARCHING SPACE OF FRACTIONAL LE...   \n",
       "\n",
       "                                                     text  \n",
       "195895  Neural network quantization is a promising com...  \n",
       "195896  Real-time inference on resource-constrained an...  \n",
       "195897  Quantization is one of the most widely-used te...  \n",
       "195898  In this section, we first introduce the fixed-...  \n",
       "195899  Fixed-point number is characterized by its for...  \n",
       "195900  For a predefined bit-width, integer, which is ...  \n",
       "195901  With the above observations, we are interested...  \n",
       "195902  In this section, we discuss our proposed train...  \n",
       "195903  To quantize a positive value x with unsigned f...  \n",
       "195904  Double Forward for BN Fusion. To quantize the ...  \n",
       "195905  As shown in (4), there are still two extra fac...  \n",
       "195906  Previous works on neural network quantization ...  \n",
       "195907                                                     \n",
       "195908  More Details for Conventional Training. For co...  \n",
       "195909  For the toy example in Fig. 3, we sample 10, 0...  \n",
       "195910  Here we derive the relationship between PACT a...  \n",
       "195911  In (2), we only give the formula for fixed-poi...  \n",
       "195912  Here we derive the equation of effective weigh...  \n",
       "195913  Here we analyze the effect of using private fr...  \n",
       "195914  Here we give some further discussion of using ...  \n",
       "195915  Here we provide more results of fractional len...  \n",
       "195916  In the main paper, we adopt the largest possib...  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullpaper_df[fullpaper_df.paper_id==paper_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ce8e5c-6c52-4d67-a76b-644c109398df",
   "metadata": {},
   "source": [
    "## Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d7fcd85c-4334-4c34-a2c8-4a1dca583ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing clusters from clustering/Ent_Rel/kmeans-k3-val-v1.csv\n",
      "importing full paper from dataset_MuP/validation_complete.jsonl\n",
      "importing graph data from PL-Marker/_scire_models/MuP/summary/val_re.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>summary</th>\n",
       "      <th>cluster</th>\n",
       "      <th>sentences</th>\n",
       "      <th>predicted_ner</th>\n",
       "      <th>predicted_re</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:7f4b788b00a2a10bcd60351c3e04c8f597101e96</td>\n",
       "      <td>This paper studies FL under local differential...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[This, paper, studies, FL, under, local, diff...</td>\n",
       "      <td>[[[3, 3, Task], [5, 8, OtherScientificTerm]], ...</td>\n",
       "      <td>[[0, [[[5, 8], [3, 3], 'FEATURE-OF']]], [1, [[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:7f4b788b00a2a10bcd60351c3e04c8f597101e96</td>\n",
       "      <td>This paper studies a low communication algorit...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[This, paper, studies, a, low, communication,...</td>\n",
       "      <td>[[[4, 6, Method], [8, 10, Task], [13, 15, Mate...</td>\n",
       "      <td>[[0, [[[4, 6], [8, 10], 'USED-FOR'], [[13, 15]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:7f4b788b00a2a10bcd60351c3e04c8f597101e96</td>\n",
       "      <td>The paper proposed a differentially private tr...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[The, paper, proposed, a, differentially, pri...</td>\n",
       "      <td>[[[4, 7, Method], [9, 10, Method]], [[17, 18, ...</td>\n",
       "      <td>[[0, [[[4, 7], [9, 10], 'USED-FOR']]], [1, []]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP:632666b52c7c551d67fbbe70c06ed589c3a5e187</td>\n",
       "      <td>This submission works on the neural machine tr...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[This, submission, works, on, the, neural, ma...</td>\n",
       "      <td>[[[5, 8, Task]], [[18, 19, OtherScientificTerm...</td>\n",
       "      <td>[[0, []], [1, [[[18, 19], [21, 22], 'CONJUNCTI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP:632666b52c7c551d67fbbe70c06ed589c3a5e187</td>\n",
       "      <td>This paper proposes a method to introduce * * ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[This, paper, proposes, a, method, to, introd...</td>\n",
       "      <td>[[[4, 4, Generic], [9, 10, OtherScientificTerm...</td>\n",
       "      <td>[[0, [[[14, 18], [25, 30], 'USED-FOR'], [[4, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>SP:18aaba3423e81e9437b509d1a5e24836ef5635f6</td>\n",
       "      <td>This paper defines a set of learnable basis fu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[This, paper, defines, a, set, of, learnable,...</td>\n",
       "      <td>[[[11, 13, Method], [16, 16, Generic]], [[26, ...</td>\n",
       "      <td>[[0, [[[11, 13], [16, 16], 'USED-FOR']]], [1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>SP:18aaba3423e81e9437b509d1a5e24836ef5635f6</td>\n",
       "      <td>A typical Wavelet Transform is built through t...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[A, typical, Wavelet, Transform, is, built, t...</td>\n",
       "      <td>[[[2, 3, Method], [8, 14, OtherScientificTerm]...</td>\n",
       "      <td>[[0, [[[22, 23], [26, 27], 'FEATURE-OF'], [[8,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3601</th>\n",
       "      <td>SP:3058e6bc5e8c62af325c214c9e1436d6cdf09204</td>\n",
       "      <td>This paper builds a new graph convolutional ne...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[This, paper, builds, a, new, graph, convolut...</td>\n",
       "      <td>[[[5, 10, Method], [13, 18, Method], [21, 25, ...</td>\n",
       "      <td>[[0, [[[13, 18], [5, 10], 'USED-FOR']]], [1, [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3602</th>\n",
       "      <td>SP:3058e6bc5e8c62af325c214c9e1436d6cdf09204</td>\n",
       "      <td>The authors propose using non - Euclidean spac...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[The, authors, propose, using, non, -, Euclid...</td>\n",
       "      <td>[[[4, 7, OtherScientificTerm], [9, 9, Method]]...</td>\n",
       "      <td>[[0, [[[4, 7], [9, 9], 'USED-FOR']]], [2, [[[3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3603</th>\n",
       "      <td>SP:3058e6bc5e8c62af325c214c9e1436d6cdf09204</td>\n",
       "      <td>In this paper , the authors address representa...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[In, this, paper, ,, the, authors, address, r...</td>\n",
       "      <td>[[[7, 8, Task], [10, 13, OtherScientificTerm]]...</td>\n",
       "      <td>[[0, [[[10, 13], [7, 8], 'USED-FOR']]], [1, [[...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3604 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         paper_id  \\\n",
       "0     SP:7f4b788b00a2a10bcd60351c3e04c8f597101e96   \n",
       "1     SP:7f4b788b00a2a10bcd60351c3e04c8f597101e96   \n",
       "2     SP:7f4b788b00a2a10bcd60351c3e04c8f597101e96   \n",
       "3     SP:632666b52c7c551d67fbbe70c06ed589c3a5e187   \n",
       "4     SP:632666b52c7c551d67fbbe70c06ed589c3a5e187   \n",
       "...                                           ...   \n",
       "3599  SP:18aaba3423e81e9437b509d1a5e24836ef5635f6   \n",
       "3600  SP:18aaba3423e81e9437b509d1a5e24836ef5635f6   \n",
       "3601  SP:3058e6bc5e8c62af325c214c9e1436d6cdf09204   \n",
       "3602  SP:3058e6bc5e8c62af325c214c9e1436d6cdf09204   \n",
       "3603  SP:3058e6bc5e8c62af325c214c9e1436d6cdf09204   \n",
       "\n",
       "                                                summary  cluster  \\\n",
       "0     This paper studies FL under local differential...        2   \n",
       "1     This paper studies a low communication algorit...        1   \n",
       "2     The paper proposed a differentially private tr...        1   \n",
       "3     This submission works on the neural machine tr...        1   \n",
       "4     This paper proposes a method to introduce * * ...        2   \n",
       "...                                                 ...      ...   \n",
       "3599  This paper defines a set of learnable basis fu...        2   \n",
       "3600  A typical Wavelet Transform is built through t...        2   \n",
       "3601  This paper builds a new graph convolutional ne...        1   \n",
       "3602  The authors propose using non - Euclidean spac...        2   \n",
       "3603  In this paper , the authors address representa...        2   \n",
       "\n",
       "                                              sentences  \\\n",
       "0     [[This, paper, studies, FL, under, local, diff...   \n",
       "1     [[This, paper, studies, a, low, communication,...   \n",
       "2     [[The, paper, proposed, a, differentially, pri...   \n",
       "3     [[This, submission, works, on, the, neural, ma...   \n",
       "4     [[This, paper, proposes, a, method, to, introd...   \n",
       "...                                                 ...   \n",
       "3599  [[This, paper, defines, a, set, of, learnable,...   \n",
       "3600  [[A, typical, Wavelet, Transform, is, built, t...   \n",
       "3601  [[This, paper, builds, a, new, graph, convolut...   \n",
       "3602  [[The, authors, propose, using, non, -, Euclid...   \n",
       "3603  [[In, this, paper, ,, the, authors, address, r...   \n",
       "\n",
       "                                          predicted_ner  \\\n",
       "0     [[[3, 3, Task], [5, 8, OtherScientificTerm]], ...   \n",
       "1     [[[4, 6, Method], [8, 10, Task], [13, 15, Mate...   \n",
       "2     [[[4, 7, Method], [9, 10, Method]], [[17, 18, ...   \n",
       "3     [[[5, 8, Task]], [[18, 19, OtherScientificTerm...   \n",
       "4     [[[4, 4, Generic], [9, 10, OtherScientificTerm...   \n",
       "...                                                 ...   \n",
       "3599  [[[11, 13, Method], [16, 16, Generic]], [[26, ...   \n",
       "3600  [[[2, 3, Method], [8, 14, OtherScientificTerm]...   \n",
       "3601  [[[5, 10, Method], [13, 18, Method], [21, 25, ...   \n",
       "3602  [[[4, 7, OtherScientificTerm], [9, 9, Method]]...   \n",
       "3603  [[[7, 8, Task], [10, 13, OtherScientificTerm]]...   \n",
       "\n",
       "                                           predicted_re  \n",
       "0     [[0, [[[5, 8], [3, 3], 'FEATURE-OF']]], [1, [[...  \n",
       "1     [[0, [[[4, 6], [8, 10], 'USED-FOR'], [[13, 15]...  \n",
       "2     [[0, [[[4, 7], [9, 10], 'USED-FOR']]], [1, []]...  \n",
       "3     [[0, []], [1, [[[18, 19], [21, 22], 'CONJUNCTI...  \n",
       "4     [[0, [[[14, 18], [25, 30], 'USED-FOR'], [[4, 4...  \n",
       "...                                                 ...  \n",
       "3599  [[0, [[[11, 13], [16, 16], 'USED-FOR']]], [1, ...  \n",
       "3600  [[0, [[[22, 23], [26, 27], 'FEATURE-OF'], [[8,...  \n",
       "3601  [[0, [[[13, 18], [5, 10], 'USED-FOR']]], [1, [...  \n",
       "3602  [[0, [[[4, 7], [9, 9], 'USED-FOR']]], [2, [[[3...  \n",
       "3603  [[0, [[[10, 13], [7, 8], 'USED-FOR']]], [1, [[...  \n",
       "\n",
       "[3604 rows x 6 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_sum_df, fullpaper_df = prepare_df('val')\n",
    "merge_sum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ca08407d-3bf4-4878-807f-950e8d38bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_diff_list = []\n",
    "for paper_id in set(merge_sum_df.paper_id):\n",
    "    df = merge_sum_df[merge_sum_df.paper_id==paper_id]\n",
    "    if len(set(df.cluster))==3: paper_diff_list.append(paper_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "de6e6929-43ae-46a8-a4c0-506985fffc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 2: This paper adopts the framework of unsupervised skill learning . To solve the problem that the discriminator will have low confidence in the unseen data thus providing a low intrinsic reward , the paper derives an information gain auxiliary objective that involves training an ensemble of discriminators and rewarding the policy for their disagreement . The paper conducts extensive experiments on tabular grid world and 57 games of the Atari Suite .\n",
      "Cluster 1: The paper proposes a novel unsupervised skill discovery algorithm . Beginning with the family of such methods ( DIAYN , VIC , etc ) that learn a discriminator to distinguish skills given some observations of the trajectory and a policy that executes a skill conditioned on the ( discrete ) skill random variable Z , the premise of the paper is that such methods on their own will fail when new states are encountered during the skill learning process as the discriminator would not have had sufficient data to learn to distinguish novel states . The paper proposes a novel reward bonus that works in addition to a base method such as DIAYN ( DIversity is All You Need ) , such that this bonus “ reimburses ” the policy for visiting states where the discriminator uncertainty is high ( measured using a form of disagreement across an ensemble of discriminators ) . Experiments on the pedagogical 4 - room environment and the Atari suite of environments demonstrates the benefit of the proposed reward bonus in not only learning more skills ( or “ empowerment ” in the VIC nomenclature ) , but the learnt skills are also superior for downstream tasks ( external reward ) and lifetime state coverage .\n",
      "Cluster 1: This paper identifies a source of pessimism in DIAYN - style methods for exploring new parts of the state space . They argue that this issue is due to using a single point estimator as a discriminator and that capturing the epistemic uncertainty of the discriminator could serve as an additional signal to guide exploration . They achieve this by using an ensemble of discriminators and incorporating the epistemic uncertainty across the ensemble into an additional intrinsic reward to the diversity of skills reward ( through a mixing parameter $ \\lambda$ ) . They examine this method against DIAYN - style methods and count - based methods and show that this new approach broadly outperforms both these classes of methods .    \n",
      "Cluster 0: This paper is concerned with unsupervised RL where an extrinsic reward signal is not available . The objective is for the agent to master the environment by exploring it while learning a diverse set of skills . This is done by simultaneously training a policy conditioned on a latent variable and a discriminator that tries to infer the latent variable from trajectories . The authors identify that the intrinsic rewards used in skill discovery result in the agent being pessimistic towards exploring novel parts of the environment . To alleviate this , the authors propose a new auxiliary objective , which results in a bonus based on the disagreement of an ensemble of discriminators . Empirical results on the grid world and Atari show improvements in skill discovery and solving downstream tasks compared to baselines .\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "paper_id = paper_diff_list[2]\n",
    "df = merge_sum_df[merge_sum_df.paper_id==paper_id]\n",
    "for idx, row in df.iterrows():\n",
    "    print(f\"Cluster {row.cluster}: {row.summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d9efa9c4-5f8e-44bf-b0f7-101e69d7a12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This paper studies the problem of unsupervised skill learning. The authors propose an exploration bonus that penalizes the discriminator for not having seen enough training data to produce accurate and confident skill classifications, leading to a low intrinsic reward for the agent and effective penalization of the sort of exploration needed to actually maximize the objective. To solve this problem, the authors derive an information gain auxiliary objective that involves training an ensemble of discriminators and rewarding the policy for their disagreement. They demonstrate empirically that DISDAIN improves skill learning both in a tabular grid world (Four Rooms) and the 57 games of the Atari Suite.\n"
     ]
    }
   ],
   "source": [
    "gen_sum_df = import_gen_sum('val')\n",
    "for sum in gen_sum_df[gen_sum_df.paper_id==paper_id]['summary']: print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8078425-2d7e-42d6-9d07-52e4f208b640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
