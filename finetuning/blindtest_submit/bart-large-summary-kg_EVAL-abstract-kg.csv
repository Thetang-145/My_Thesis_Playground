paper_id,summary
SP:b19df5243359791fbaad005d6f13d7e9fdb0ff63,"This paper proposes a new role-based learning for scalable multi-agent learning with decomposing complex tasks into roles. The role selector is used to learn the role space and temporal resolution, and the action effects are used to guide the role discovery. The proposed method achieves better learning efficiency and policy generalization than MARL algorithms, and it can be applied to the bi-level learning hierarchy. The paper also proposes a StarCraft II micromanagement benchmark."
SP:7deb61890d97422a0fe141ca807f968c70ab239a,This paper proposes a new stochastic subgradient descent (SSGD) method for over-parameterized nonsmooth optimization problems with interpolation condition. The authors show that the composite structure of SSGD can be used to solve empirical risk minimization problems with a composite structure. The main contribution of the paper is to show that SGD can be combined with SGD and SSGD to improve the performance of smooth and nonsmoothed machine learning models. The paper also shows that the proposed rates are better than existing rates for smooth problems and strongly-convex objectives. 
SP:c7e0b3fedc0d0409d662dd612b529fdacad2b03e,This paper studies the problem of learning transformers with non-linear “reservoir” layers and regular transformer layers. The authors show that the wall-clock compute time of these layers can be used to compute the number of layers in a machine translation. They also provide a theoretical analysis of this problem.    The paper is well written and easy to follow. The main contribution of the paper is the theoretical analysis. The theoretical analysis is clear and the empirical results are convincing. 
SP:ba9f1d4738ec67a440346f3ac6c4cf35f7232077,"This paper studies the problem of steerable CNN. The authors propose a new group representation theory for the function space structure of a steerable kernel function. The kernel is represented by filter transformed kernels, and the group representation can be used to represent the kernel as a group of kernels. The group representation is then used to train the steerable convolution operators. The proposed method is evaluated on a variety of tasks, and it is shown that the proposed method outperforms existing methods."
SP:c1116fbb4d058eb6be195b5d13d19a55ba86b602,"This paper proposes a new optimal neural synthesis approach for program synthesis. Multimodal program synthesis uses user input to synthesize a program from user input, where the user-provided constraints are a set of abstract syntax trees. The proposed method uses a top-down recurrent neural model to predict the program’s score using noisy signals (e.g., natural language or input-output examples). The authors show that the proposed method achieves better performance on the multimodal synthesis dataset (STRUCTUREDREGEX) than existing techniques. "
SP:55e02d79146bbb42f1ab6d4fafa2db5ddbe599b0,"This paper studies the robustness of key life processes, i.e. proteins such as Protease enzymes. The authors propose two methods for predicting protease specificity landscapes based on sequence patterns. The first is a protein graph convolutional neural network (PGCN) that predicts the substrate specificity landscape of a protease enzyme based on the sequence motifs. The second is a structure-based molecular interaction graph based on a Rosetta energy function that predicts topology and energetic features. The PGCN model is able to predict the specificity of the NS3/4 protease (Hepatitic C virus) in the presence of mutational changes. The experiments show that PGCNs can achieve better performance on classification tasks than other machine learning models. "
SP:7727eeb7b17ad94ddfa0cf24e64a9626d83a8876,"This paper proposes a method to reduce the overestimation bias in Double Q-learning by using approximate Bellman operator for the non-optimal fixed points. The approach is based on approximate dynamic programming, where the Bellman operation is used to learn the optimal stationary solutions. The authors show that the proposed method outperforms baseline algorithms on a variety of Atari benchmark tasks. "
SP:1d630b69f95392a5ef3d7d580b523e077a3555a8,"This paper proposes a two-step training framework for deep generative models (DGMs) trained on high-dimensional natural images. The proposed models are based on BigGAN and VQVAE-2, both GAN-based image super-resolution models (e.g., ESRGAN). The authors use compute resources to train the models, and use Wavelet-based down-sampling method to extract structural information from low-frequency bands. The sampler is trained on the wavelet domain, and the decoder is trained using a wavelet super-resolution decoder network to generate images from the pixel-space. The model is evaluated on ImageNet, and compared to the BigGAN model on Fréchet Inception Distance (FID) and on a few other datasets. The authors show that the proposed model has better generative quality than pixel-based methods, and that the training cost is lower than end-to-end models."
SP:b943a73b1ec34867371325748dc3a91ff4011947,"This paper studies self-supervised learning (SSL) algorithms for Fewshot learning(FSL). The authors propose a pre-trained embedding network for downstream FSL tasks, which is a combination of SSL and supervised training for FSL. The authors show that the embedding networks can be used to improve the test accuracy of FSL with supervised training. They also show that supervised FSL methods can achieve better test accuracy than supervised training in terms of test accuracy. "
SP:bd552f98e6a447cefa6b1a9bbdf40bc6539fb643,"This paper proposes a new method for training two-layer teacher-student networks. The main idea is to use first order methods to train ultra-wide neural networks with finite width with a finite width. The authors show that the global minima of the initialization of the teacher neurons are the same as the local minima for the student neurons. They then propose a new Angular Distance (AD) function, which can be used to train the student networks. Experimental results show the effectiveness of the proposed methodology."
SP:0f62846913ec10b44ed32845770da0565479dc75,"This paper proposes a framework for learning deep neural networks with user-provided formal knowledge from data. The framework, Deep Adaptive Semantic Logic (DASL) is based on the Deepadaptive Semantics Logic (DSL) framework. DASL learns a knowledge representation of the first order logic, which is then used to learn the formal semantics. The authors show that finite sampling of the truth values in infinite domains can lead to vanishing gradients, and that the representation learned by prior neuro-symbolic work can be used to improve the performance of the DASCL’s representation. The paper also shows that the structure of the image classification task can be learned from the structure learned by DASl, which can be applied to the visual relationship detection task. "
SP:2f19259d65fab904c1b771244da3dcb2f8aa0c26,"This paper proposes a new regularization approach for the learning of iterative solutions in feedforward residual neural networks (ResNets) for iterative recurrent computations. Iterative computations are computations where the goal is to find a solution to a sequence of problems. ResNets are trained to find iterative solution to these problems by iterative convergence and iteration. The authors show that the Lipschitz constraint on residual functions of the residual functions can be used as a regularization for the iterative convergent computation. They also show that this regularizations can reduce the inductive bias of the ResNs.  The authors propose a new method for recurrence regularization and spectral normalization. The proposed method is based on soft gradient coupling between the ResNet and the recurrent “ResNet” ResNet, where the recurrent network is a “resnet” and the one trained by the recurrent ResNet is the “reward” one. They show that their method can improve the classification accuracy of the RecNets on a variety of visual recognition tasks such as MNIST, CIFAR-10, Cifar-100, and Digitclutter."
SP:6c14506b8b2b06043409d912e6bf877651aaa665,"This paper studies the problem of normalization techniques for deep neural networks. The authors show that they can be used to generalize independent and identically distributed (IID) data. The main contribution of the paper is a new normalization method called SelfNorm, which is a combination of SelfNorm and CrossNorm to improve OOD generalization. SelfNorm is based on attention, where attention is used to learn the channel-wise mean and variance of the feature maps. The paper also shows that SelfNorm can be combined with CrossNorm in order to improve the OOD performance. "
SP:2774abdc11917321dd4994af0f0da1ff824bea03,"This paper proposes a new attention module for reinforcement learning (RL) agents. Attention mechanisms are inductive biases that can be used in reinforcement learning and control. The authors show that they can be applied to neural network architectures with high dimensional inputs (e.g., pixels) and unsupervised pre-training (e., language, speech, vision). The authors also show that the proposed approach can be combined with supervised learning and/or generative modeling for multiple domains, including vision, language, and speech. The proposed module is evaluated on the DeepMind Control Suite environments and shows that it improves the sampleefficiency of agents trained with the proposed attention module. "
SP:31a7051d08d19c01e11f1fac2f3041ed2fa28f15,"This paper proposes a gradient-based approach for multitask networks, called Rotograd, which is based on GradNorm. The authors propose an extension of GradNorm to the problem of learning the network parameters. The main idea is to use game theory to learn the gradient magnitude of the gradient magnitudes of the task gradients. Theoretically, the authors show that it is possible to converge to the optimal gradient magnitude in practice. They also show that the proposed approaches perform better than existing approaches in multitask learning. The experiments on real-world datasets and network architectures demonstrate the effectiveness of rotograd."
SP:ac9ebd027b92527d9a87b13ad11d002d99a2b0f6,"This paper studies the geometry distortion problem of the I2I translation problem. The authors consider the randomness of color transformation in the translation process, where the domain mapping function is a mapping function, and the goal is to minimize the distance between the input and the target domain. The paper proposes a new mapping function called Minimal Geometry-Distortion Constraint (MGC), which is a I2i translation constraint. MGC is based on the approximate representation of mutual information between the source and target domains, and is used for the estimation and maximization of MGC.  The authors show that MGC outperforms state-of-the-art methods on several benchmark datasets. "
SP:92a38d7d18f07f68b8f93c61180e2cc1dddd21de,"This paper studies the problem of point sampling patterns in point cloud GANs. The authors propose two sampling-oversensitive discriminators, PointNet-Max and PointConv, to generate valid shape point clouds with point clustering artifacts. PointNet++ and DGCNN are the two main sampling-oversensitive discriminators. The sampling spectrum of metrics in the sampling spectrum includes perceptual metrics as well as the sampling pattern of the discriminator design. The empirical results show that the sampling-related metrics of the two point cloud generators outperform the middle-point sampling-aware baseline discriminator (PointNet-Mix)."
SP:16c4be3eb162bc81cb3343c2fc115eb8e926a5b5,"This paper proposes a novel detection-aware attack paradigm based on the vote attack. The proposed method is based on a class-conditional reconstruction based detection method. The key idea is to train a CNN with small quasi-imperceptible artificial perturbations on the input images, and then use these images to train the CNNs. The authors show that the proposed method outperforms the state-of-the-art CNNs in terms of adversarial robustness."
SP:dbd093dff7a38ba8882bb8119c34623ddaaf4cc6,"This paper proposes a new algorithm for the learning of recurrent policies in meta-reinforcement learning, where the goal is to learn a policy that is able to adapt to new tasks in an online adaptation setting. The proposed algorithm is based on privileged information from the task descriptor of the policy, which is used as a proxy for the information about the behaviour of the agent. The authors propose a method to learn an informed policy that can adapt to different task embeddings by using the parameters sharing and an auxiliary objective. They show that the proposed approach reduces the learning sample complexity by a factor of 2.5, and it outperforms Thompson sampling and other task-inference approaches. They also provide exploration/exploration strategies to improve the performance of their algorithm."
SP:bd89d254fbf31db61db237d08ab42981e27c52df,"This paper proposes a new approach to improve the fidelity of the simulator in RL by reducing the number of trial-and-errors in realworld applications. The authors propose a new paradigm for learning an RL policy from offline data using a model learning technique. The simulator is used to learn optimal policies from a dataset, and then the policy is learned from the offline dataset using an online dataset. The paper shows that the adaptive policy can be used in both synthetic environments and a real-world ride-hailing platform, and that the dynamics of the dynamics can be learned from stochasticity. The proposed method is shown to achieve robust recommendations for the distortion problem. "
SP:1a166b28cf684e0d5759bd629f6a53370d2bf11c,"This paper studies the problem of reinforcement learning (RL) algorithms with sparse rewards for goal-reaching behaviors. The authors propose a new algorithm that uses imitation learning to learn goal reaching policies using expert demonstrations and value function. The algorithm is based on supervised imitation learning, and it is shown that it is able to learn a policy that achieves the goal with high performance bounds. The RL objective is learned using an iterated supervised learning procedure. The paper also shows that the proposed RL algorithms are able to achieve high performance on a variety of benchmark tasks. "
SP:c306530164d677e670554eeba8203c66bb3d9f7a,"This paper proposes a teacher-student distillation pipeline to improve the performance of autoregressive models for speech. The teacher model is trained to predict the duration of a speech waveform using the speech waveforms, and the student model is used to predict a sequence of conditional inputs, which are the variation information of speech (e.g., pitch, energy, duration, etc.). The teacher is then used to train a FastSpeech model, which is a combination of the autoregression teacher model and the Fastspeech model trained with the teacher model. The authors show that the proposed model is able to achieve better performance than the state-of-the-art on the one-to-many mapping problem in TTS, a variant of knowledge distillation. The paper also shows that the training speed-up of the proposed method is comparable to that of the state of the art. "
SP:79e9fb20d383816f54738ce70d137131ebc10290,"This paper studies the unsupervised dimension reduction problem (UDR) with tempered distributions in a k-dimensional subspace, where the tempered distribution q(x) is the empirical probability density function. The problem is formulated as the minimization of the distance between the two distributions of a nonnegative penalty function R(f) and the true distribution Q(x). The authors propose a new infinite-dimensional formulation, which is based on generalized functions. The optimization problem is then formulated as an optimization problem with ordinary functions, and a second algorithm is proposed to solve the second problem. The authors show that the proposed algorithm is able to achieve the minimisation of I(f ) + λR(f). The proposed method is evaluated on synthetic data and two datasets with synthetic data as well as synthetic data with real data. "
SP:93e54522e6c2b805905d21fc968fc40866f2898b,This paper proposes a method to improve the robustness of a model trained on rare or underrepresented patterns. Feature Contrastive Learning (FCL) is used to train a model on features with contextual feature utility and contextual feature sensitivity. The authors show that FCL improves the sensitivity and robustness for models trained on the same dataset. They also show that the generalization performance of models trained with FCL is improved when the noise is reduced. 
SP:f03c50f15022c4f56ac2b3085354ffed38ad1145,"This paper proposes a new algorithm for training autonomous agents from high dimensional observations. The proposed algorithm is based on adversarial learning with a latent representation in the discriminator network. The authors propose mutual information constraints on the latent representation to encourage imitation in the shared feature space. They show that they can achieve state-of-the-art performance on a variety of control problems (e.g. balancing, manipulation and locomotive tasks). They also show that the agent embodiment and environment appearance are important factors in domain differences. "
SP:ef18f4188426bc01be309633b486884b0e7a81a4,This paper studies the lottery ticket hypothesis (LTH) in the context of pruning multi-layer neural networks. The authors propose a new algorithm for pruning a pruned neural network with non-pruned weights in the hidden layer. The algorithm is based on (an accelerated) stochastic gradient descent algorithm. The paper shows that the pruned network performs better than an unpruned network in terms of test accuracy and sample complexity compared to the prune network.  The authors also show that the proposed algorithm achieves a guaranteed generalization of the winning ticket. 
SP:eed6cb2f8caed39f8295f4aeb6e044c2ac981c4d,"This paper studies the relationship between accuracy and generalization of data augmentation approaches for neural networks. The authors propose AutoLabel, a new dataset-augmented version of AugMix and mixup for training models. AutoLabel is based on a hold-out validation set, which is used to evaluate the calibration-performance of AutoLabel. The paper shows that AutoLabel outperforms AugMix on CIFAR-10 and ImageNet. "
SP:0d5017e1a405bf86e3bac40e6e59886d4bf48450,"This paper proposes a causal framework for self-supervised representation learning based on the Invariant Causal Mechanisms (RELIC) for selfsupervised objective, Representation Learning. The authors propose two methods for heuristic proxy classification tasks and data augmentations. The invariance constraints on proxy classifiers are used for pretraining the proxy classifier, and the invariance regularizer is used for generalization guarantees for the invariant prediction of proxy targets. The two methods are evaluated on ImageNet with human-level performance and out-of-distribution generalization on Atari. RELIC outperforms the other methods in terms of robustness, out of-sample generalization, and robustness on unlabeled data. "
SP:8f80a6f79f78c6421857f392c9a5e98061d7eb60,"This paper proposes a visual Transformer Network (VTNet) for informative visual representation in navigation. The structure of VTNet is based on the VTNet HYPONYM-OF structure, where the visual representations of the observed scene are used to guide navigation actions. The visual representations are learned using navigation signals from the navigation signals. Object goal navigation signals are used as directional navigation signals to guide the visual representation. The informative representation of the informative representation is learned by using attention operations on the object and region features in VTNet. The spatial-aware descriptors learned by VTNet are also used to learn the spatial-specific descriptors for the object/region features. Experiments on the artificial environment AI2-Thor show that VTNet performs better than other methods. "
SP:3e7cbe3dff592ef371e48dd86be7719fc5343f17,This paper proposes a secure aggregation primitive for privacy-preserving federated learning for neural network models. The proposed solution is based on the communication-computation efficient secure aggregation for communication/computational resources. The key idea is to use a G. Erdős-Rényi graph as the topology instead of a complete graph. The topology of the secret-sharing nodes can be computed by sparse random graphs. The authors show that the proposed scheme improves the reliability/privacy of the scheme compared to other recent work in the literature. 
SP:00fae41e0eca0a1575cd7b2dcfabf0dc5c9c8b8a,"This paper studies the problem of finding anincentive compatible auction in Auction Design. The authors propose a theoretical approach to solve this problem by using neural network architectures to find optimal auctions. The proposed approach is based on hyper-parameter search, where the optimal misreports are computed using an inner maximization loop. The optimization procedure is then applied to a two-player game with stationary utility functions. The theoretical auction design is applied to the time-independent Lagrangian. The experimental results show that the proposed neural network achieves competitive performance."
SP:a0e8061beb5e9a6c631419861559d22b8d645cb4,"This paper studies the problem of fine-tuning a pre-trained model for a downstream task on a large-scale dataset. The authors propose a general learning approach called Bi-tunning, which is a combination of supervised and unsupervised pre-training approaches for learning representations for downstream tasks. The main idea is to use discriminative knowledge of labels and intrinsic structure of data to guide the training of the classifier head and the projector head. The former can be used to fine-tune methods that rely on the former, while the latter is used for boosting the performance of the latter. The proposed method is evaluated on a variety of fine -tuning tasks and shows that the proposed method can improve the accuracy in a low-data regime. "
SP:87e5b552c13d73bd85249062a152c6c140e594a9,"This paper studies the problem of robustness of classifiers against adversarial accuracy and adversarial training in the presence of clean data. The authors propose a new measure, the norm-based distance metric, to measure the robustness against classifiers. It is based on the fact that the accuracy of the classifier depends on the test accuracy as well as the accuracy in the adversarially perturbed samples. The distance metrics are based on invariance-based adversarial examples, and the authors show that it can be used to improve the performance of a classifier. The main contribution of the paper is to show that the distance metric is a good way to evaluate the classifiers' robustness to adversarial perturbations. "
SP:2fda410b9281c5e253d385bc4382ec168bc161f3,"This paper studies the problem of fairness in algorithmic designs with graph-structured data. The authors propose a new fairness concept called dyadic fairness, which is based on the notion of edges in a graph. They show that the distance between the edges in the graph is a measure of the difference in the predictive relationship between the two nodes. They then propose an algorithm called FairAdj to learn a fair adjacency matrix for fair link prediction with graph structural constraints. The proposed method is evaluated on a fairness-utility tradeoff and shows that the proposed method achieves better dyadic unfair. "
SP:b614e9fbec58e9efa7722d2ec4a60fc93d210f92,"This paper proposes a new information compression framework called Autoencoders. The idea is to use GAN-based adversarial training to train an autoencoder with a generative ability similar to it. The authors use Gaussian prior knowledge from VAE to guide the synthesis and disentangle the latent code from the disentangled latent code. The encoder is then used to learn the latent representation of the encoder and the encoders in a latent code space, and directed interpolation is used to encourage exploration in latent space (e.g., interpolation) and regularization for controllable synthesis. The proposed method is evaluated on attribute-controllable augmented samples and shows that DEAE can achieve better dataset bias than DEAE for fairness problems. "
SP:c934adb14926a00ef9c73c9773cb0b3a2669921e,"This paper proposes a Bayesian memory allocation scheme for episodic and semantic memory in a human memory model. The hierarchical latent variable model is used to learn the differentiable block allocated latent memory. The compressed representation is learned from the serial event (episodic memory) and the read key distribution. The allocation scheme is applied to memory conditional image generation with binarized MNIST and binarised Omniglot. The Kanerva Machine is trained with locally contiguous memory. Experiments on CIFAR10, DMLab Mazes, Celeb-A and ImageNet32×32 demonstrate the effectiveness of the proposed allocation scheme."
SP:e63d7d8c581019e17585fb9c0eac33d6836e187d,"This paper studies the problem of self-attention in deep learning models for machine learning tasks. Attention mechanisms and the loss landscape of attention-based neural networks are well-studied in the literature. The authors show that the local minimum of an attention model is a local minimum in terms of the prediction error, and that the sample complexity of these models is lower than that of other attention models. "
SP:f739d199fdee26f09994e3f9487aec1eab0f2e89,This paper studies active inference in Bayesian modeling with a biologically plausible model. The authors propose two reinforcement learning (RL) algorithms for active inference with a negative value function for the expected free energy (EFE) and a free energy principle for the prior preference. The proposed method is based on prior preference learning with theoretical connection and active inference for inverse RL problem with EFE-based rewards.
SP:5592b79e49eba95c15103a3348f2bde57b60f2ab,"This paper proposes a data augmentation method for generalization between adversarial and standard learning. The proposed method is based on the observation that adversarial training does not generalize well to unseen data. The authors propose to use OOD data for the learning scenario, and show that the proposed method can generalize better than existing data augmentation methods. The method is evaluated on CIFAR-10 CONJUNCTION and ImageNet."
SP:3cac7a2c310165ed0de46d8e5546c3bfbd639158,"This paper proposes a Fast Linearized Adaptive Policy (FLAP) method for metareinforcement learning (meta-RL) method. FLAP is based on a shared linear representation of the policy. The adapter network is used to learn the linear weights for the policy by gradient descent. The separate feed-forward network is then used for the adaptation run-time. The authors show that FLAP outperforms prior methods on continuous-control meta-RL benchmarks, and achieves better average return than prior methods in out-of-distribution tasks."
SP:21a1bd4ada0723c96c0dbf7a142a2faf5defa4e3,This paper proposes a federated kernel k-means algorithm for the optimization problem in federated settings. The proposed algorithm is based on communication efficient mech anism (CEM) to reduce the communication cost of the algorithm. The authors provide an approximate solution to the approximate solution and provide a theoretical analysis of the communication efficiency of the proposed algorithm. They show that the proposed DSPGD has O(1/T) rate and CEM can be used to improve the communication costs of the federated kernels. They also provide some theoretical guarantees on the clustering quality of the kernel k - means compared to the standard kernels. 
SP:be568dd3fea51ce33a6d1e4b07dda5aee6342395,"This paper studies the problem of constant training cost for CNNs. The authors consider the combinatorial explosion of sub-optimal model configurations, and propose a new approach to train models with different deployment targets for resource-intensive tasks. They show that architectures with different hardware & latency constraints have different performance and accuracy. They also show that models with diversity of hardware and latency targets have different design space (e.g. CompOFA) and different search space (i.e. ImageNet). The authors show that in the search space, the search is more expensive than in the state of the art, and that the complexity of the search increases as the number of tasks increases. They then show that the search, the accuracy-latency Pareto frontier, and the heuristics are more efficient than the state-of-the-art. "
SP:04b84d26cf282dbb753cbf27f14c334f65d3f8ec,This paper proposes a meta-learning algorithm for the initialization of a learning model in an adversarial manner. The authors propose ADML (ADversarial Meta-Learner) which uses both clean and adversarial samples for the training of a model on limited data. They show that ADML outperforms the state-of-the-art in terms of accuracy and robustness on image datasets such as MiniImageNet and CIFAR100. They also show that it can be used to train adversarial models with attack mechanisms. 
SP:dfbaa6b53c4e8328d52666ad4641fc917bf0c0b3,"This paper studies the problem of suboptimal decoding algorithms in the context of communication applications with error correction codes. The authors propose a data-driven framework that uses permutation to perform permutation selection in the form of a maximum likelihood rule for decoding of transmitted codewords. The proposed framework combines domain knowledge and machine learning concepts such as node embedding, self-attention, and self-supervised learning. Experimental results show that the simulated Bose Chaudhuri Hocquenghem (BCH) code has a better bit error rate than the baseline decoders. "
SP:c860a7b0952d708e7851c9bc4b63d246f64d1cba,This paper proposes a fine-tuning BERT for the text classification task. The task is an unsupervised classification task with labeled data. The authors propose finetuning the task using the finetuned version of BERT. The main idea is to learn the classification step for the labeled examples in the topical classification tasks. The intermediate task is done by using unsupersupervised clustering. The experimental results show that the proposed BERT outperforms the state-of-the-art.
SP:ea37f5882fd98dd4ce233077bb3069517d4ed4ea,"This paper proposes a fixed (random shooting) control agent for generative models with multimodal posterior predictives. The authors show that models trained with mixture density nets are more robust than probabilistic counterparts, and that they can be used to solve a control problem with heteroscedasticity. They also show that MBRL with the proposed framework can achieve better sample complexity than MBRL without a training schedule. "
SP:4e25ba3714d78ba59a0d8efbb65e0ef5201702f8,"This paper proposes Affine Disentangled GAN (ADIS-GAN), a Generative Adversarial Network that uses the affine transformation properties of images as an affine regularizer to reduce inductive bias. The affine matrix is composed of transformation matrices, and the transformation parameters are computed by maximum likelihood estimation. The authors show that ADIS-GAN is able to disentangle features from disentangled representations, which is a significant improvement over previous approaches. The experiments on MNIST, CelebA, and dSprites datasets demonstrate the effectiveness of the proposed features. "
SP:121f8420cfb49c6d80b5ebb4051e85947182594a,"This paper studies the problem of representation learning with contrastive learning methods. Representation learning is an important problem in the context of unsupervised learning, where the goal is to learn representations that are robust to distortions in the input image. The authors propose a new contrastive loss based on data augmentations to improve the generalizability of the learned representations. The proposed method is based on a fully supervised upper bound on the unclassification error of the representation bank. The main contribution of the paper is to show that the proposed method improves the top-1 accuracy of the fully supervised ResNet-50 architecture and the single-layer classifier fine-tuned on ImageNet. "
SP:af54e542223097c315ecd677d0b968e9a0b2a1d4,"This paper proposes a new method for de-identifying facial features from magnetic resonance imagery (MRI) for the task of De-identification. The proposed method is based on a combination of MRI de-imagenation techniques to identify privacy-sensitive facial features. The authors show that the proposed method can achieve better performance than removal-based techniques on a variety of medical analyses such as segmentation, age prediction, and medical analyses of the brain. They also show that they can be combined with a deep learning framework to improve the performance of their proposed method."
SP:0ac3964bd2320341488476d60f57b75d2a79f92c,"This paper proposes a multi-head attention based global pooling layer, called Graph Multiset Transformer (GMT), which is based on the Weisfeiler-Lehman test for graph representations. The authors show that the pooling function can be used to learn the compact form of a graph by pooling the node representations. They also show that they can be combined with hierarchical graph pooling methods to learn a representation for graphs. They show that GMT improves the injectiveness, permutation invariance, and memory and time efficiency on several graph classification benchmarks. The paper also shows that the proposed methods are competitive with existing node clustering approaches in terms of the performance of hierarchical node pooling."
SP:76848e7ac3e6709e92f6a6db60269cb5177495d1,"This paper studies graph neural network (GNN) models of long-range problems, where the graph is a set of nodes with exponentially growing information, and the goal is to predict the next node in the graph. The authors propose to use GNNs for this prediction task, which is based on the observation that the prediction task can be solved by a GNN with a long range interaction. The main idea is to use a bottleneck to train the GNN, which can be used as a proxy for the number of nodes in a graph.  The authors show that the bottleneck can be applied to a variety of GNN models, including GAT, GGNN, GIN, and GCN. "
SP:90d8fa381446923902e42b259392e5e975e6caa1,This paper studies the problem of cross-domain generalizable classifiers in the context of Sentiment analysis. The authors propose two methods for learning domain-agnostic representations from annotated data. The first is a domain adaptation method that learns a set of data distributions for each domain. The second is a method that uses a prototypical distribution to learn the representations of the domains. The proposed method is evaluated on a variety of datasets.
SP:893fd7440b82f5da0d4c0944928810322eaee2f0,"This paper proposes a new evaluation methodology for evaluating gender-biased stereotypes in natural language processing. The evaluation of genderbias is an important part of natural language understanding, and the authors propose to use inference for the evaluation of the performance of the NLI models on the task of evaluating gender stereotypes. The authors propose a challenge task to evaluate the gender bias of NLI model on a set of occupations, where the goal is to find a gender-balanced dataset. The debiasing techniques are evaluated on MNLI and SNLI data-sets. The results show that the models are able to identify genderinduced prediction errors in BERT, RoBERTa, BART, and BART."
SP:a32ab755bd249c393b70938036ce8e810c0c439f,"This paper proposes a new unsupervised reinforcement learning method called Variational intrinsic control (VIC) that combines two existing VIC algorithms, one based on the transitional probability model and the other based on a Gaussian mixture model. The latter is motivated by the fact that the intrinsic reward in the former is not the same as the intrinsic options in the latter. The authors show that the two methods can be combined using the transitional probabilities of the two, and that they can be used in stochastic environments."
SP:b4df2c4627a6d46c5100133e38c4bea20b296dd8,"This paper studies the problem of image classification with ensemble of relatively small deep networks in the low data regime. The authors propose a technique called deep ensembling, which can be applied to small data domains. They show that this technique can achieve better sample efficiency than state-of-the-art approaches, and they also show that they can be used to learn ensemble configurations. "
SP:4a0ee01f4897efa81659f37ef0468ee8195bbc4f,This paper proposes a new model and training scheme called Sparse Binary Neural Networks (SBNN) for Internet of Things (IoT) devices. The main idea is to use quantized neural networks instead of binary neural networks (BNNs) in order to reduce the computational power and storage requirements and improve the processing speed of DNN-based applications for InternetOf-Things (IOT). The authors show that they have a fixed and limited compression factor of $\mathcal{O}(\sqrt{T})$ and that they can achieve speed-up of up to 1.5x faster than binary networks with positive 0/1 binary weights compared to -1/+1 weights. The authors also show that SBNNs can achieve better compression rates and generalization than BNNs with sparsity. The proposed method is evaluated on MNIST and CIFAR-10 datasets for linear and convolutional networks and shows that it achieves better performance than DNNs.
SP:5be8539ad02595ad3c7a2d7afe8cbb3e9924467d,This paper proposes a post hoc calibration method for model calibration on corrupted data. The method uses outlier exposure to estimate the model probabilities based on the class membership probabilities of the model outputs. The authors propose a baseline method based on softmax probabilities for predicting the predictive uncertainty of a model using softmax probability. The proposed method is based on Stochastic Variational Bayesian Inference (SVBI) for deep learning and model ensembles (e.g. temperature scaling). The authors show that the calibration error of the proposed methods is lower than the predicted error rates and actual error rates of the models. They also show that their calibration error is close to the true accuracy of the machine learning model. 
SP:ea503f67e38fce7dee9cc4996b55b8959911f030,This paper studies the expressive power of graph neural networks and graph kernels in the context of machine learning problems with graphs. The authors propose two approaches to learn the graph properties of non-isomorphic graphs by learning the graph representations and the similarity/distance of graphs. They show that these two algorithms achieve better expressive power than those based on graph kernels and graph models. They also show that models trained with these two types of graph attributes are more expressive than those trained with graph kernels.
SP:0cf7b7d929f50e0b7f4fda5e1f68e5ade2f7c29b,"This paper proposes a new data augmentation techniques for regularizing non-warp-based image generation, called CutMix. The main idea is to use them to improve the performance of image animation. The proposed augmentation approach, called PriorityCut, is based on the idea of using occlusion information to regularize discriminator predictions for inpainting the warping artifacts in a warped image. The key idea of the proposed method is to learn the identity of the inpainted regions of a driving video by learning the distance between the keypoint distance and the pixel-wise difference between the image and the target image, and then using these two keypoints to train a self-supervised image animation approaches.    The main contribution of the paper is to show that the proposed methods are able to achieve better performance than vanilla CutMix and other image animation models in terms of low-level similarity and feature embedding distance. "
SP:60b535fc6cbc1a7a26ad53f706ebb17de346dc4f,"This paper studies the problem of learning disentangled representations from observational data. The authors propose a self-supervised generative model that learns to disentangle the independent latent variables in a data generation process. The proposed model is based on an unconventional mixture prior, which allows to learn the groundtruth mechanisms in observational data without the need for disentanglement. The paper shows that the proposed approach can achieve better performance on downstream tasks than the state-of-the-art in terms of intervention, covariant shift, and noise."
SP:44d4e24428d043a69b40013919cda0e8e7bff99c,"This paper proposes a graph aligning approach for rich or detailed labels on a 2D image of molecular graph structure (W). The idea is to use a mediating representation V, where f is the normal labels W, and the f is a fully mediating layer. The model is trained by domain adaptation on the Maybridge data set, and is shown to perform better than a pretrained model. The paper also shows that the proposed self-labeling approach can be applied to predicting chemical compound graphs on 2D images."
SP:ad906dd9a176cffd283593321ff6b9ad19595528,This paper proposes a domain knowledge based deep learning framework for chiller plants energy optimization problems. The authors propose to use domain knowledge from image classification and NLP to train a deep network to model realworld physical systems. The proposed framework is able to learn complex systems with a linear model and a nonlinear model in the redundancy function space. The main contribution of the paper is the use of domain knowledge for the small sample size problem in the input-output monotonic problem of energy consumption estimation for chillers. The method is evaluated on a cooling system with a data center and shows that the proposed framework can achieve better performance than existing ones for energy optimization.
SP:6cb65ee5d2926858570601eeeade24fe86c7f32f,This paper proposes a new framework for predicting the causal effects of a graph. The framework is based on the collaborative causal spatio-temporal fusion transformer (CausalTrans). The authors propose a new spatial graph fusion mechanism that is able to predict the causal effect of each node in the graph. They show that CausalTrans improves the time efficiency of the model components in terms of error reduction compared to the baseline methods. The authors also show that the multi-head attention with Taylor’s expansion and softmax can reduce the time complexity of the models. 
SP:223980a1954d626d90ff54d8dc61b5d85a6b349c,"This paper proposes a novel unsupervised framework called coupled mixture VAE (cpl-mixVAE) to solve the problem of learning a mixture of discrete and continuous factors of variability. The authors propose to use interacting autoencoding agents to learn the multi-agent framework, and then use it to solve a variational inference problem. The proposed approach is evaluated on a single-cell gene expression dataset with cortical neuron types and on MNIST and dSprites. The results show that the proposed approach can learn type-specific, activity-regulated genes."
SP:c982610ad28662c3bd13132abe1f7307d1a61b68,"This paper studies group equivariant convolutional networks (GCNNs) with symmetry priors. The authors show that convolutions with G-steerable kernels can be used as convolutions for models with symmetric priors, and that the equivariance constraint on kernels is equivalent to the G-stakeability constraint on convolutions. They also show that the compact group G HYPONYM of a compact group can be approximated by a G-Steerable kernel spaces. Finally, the authors prove the Wigner-Eckart theorem for spherical tensor operators based on quantum mechanics, and show that these constraints can be applied to steerable kernels as well as other constraints such as generalized reduced matrix elements and ClebschGordan coefficients. "
SP:7b2ea39069277ad0f4f79476a77ef84587a804d9,This paper studies the problem of selective classification in the presence of abstentions and spurious correlations. It shows that the average accuracies for selective classification with respect to the margin distribution of the training data are highly correlated with the true margin distribution. The authors then propose a new metric for measuring the accuracies of the selective classification. The new metric is based on the left-log-concave concavity of the margin distributions. They show that the new metric can be used to measure the full-coverage accuracy disparities between the two models. They also show that distributionally-robust models have better full-cover coverage accuracies. 
SP:f1d57ee27e901daf7e4e2b84139019e945818911,"This paper proposes a new training method, Neural NCPD, for topic modeling on large-scale data with complex multi-modal structure such as video data analysis, temporal document classification, and multi-layer network analysis. The authors propose a new neural network architecture and backpropagation for neural NCPD for hierarchical topic modeling. The latent hierarchical structure of multi- modal data can be used to learn the topic model. "
SP:b6ddc3a560aa7155e7e927bf5360bedc36586597,"This paper proposes a new adversarial robustness certificate for graph neural networks. The proposed certificate is based on the notion of locality property, which is defined as the distance between the nodes in the graph and the nodes of the node classifier. The authors show that the proposed certificate can be applied to a variety of tasks such as node classification, image segmentation, and named-entity recognition. They also show that their proposed collective certificate is more robust than single-node certificates. "
SP:cc93dd2f68e415e2457166e78627865dc1b44697,This paper studies the problem of learning high-dimensional probability distributions with generative and discriminative neural networks. The authors propose a modification methodology of loss functions to improve the performance of GANs. The proposed method is based on the Wasserstein distance approximation. The main contribution of the paper is to show that the proposed method can achieve better performance than the state-of-the-art in terms of robustness. 
SP:4ddb47ee77c374ae6c3e419412d92ca77260692e,"This paper studies the problem of similarity-based explanation in machine learning models. The authors propose a set of relevance metrics to measure the similarity between the gradients of the two gradients. These metrics are based on the cosine similarity between gradients, which is a well-studied property of the metrics. "
SP:6c2cbf2bc0f6dabe974e80ec1e82d2d12189906e,"This paper studies the generalization power of Graph Neural Networks (GNNs) under algorithmic alignment in the graph isomorphism test. The authors propose a new LRGA module in GNNs that is able to learn the kernel’s feature map from a randomly initialized two-layer MLP, which is then used to update the RGNN using polynomial kernels in the 2-FWL update step. They show that LRGA can be used to learn GNN layers that are more expressive than existing GNN architectures using LRGA. They also show that dot-product attention can be added to the kernel to improve its generalization properties. "
SP:b4abdd28504b4c1de239eabd4e0e27d370efee71,"This paper studies objectness measures for calibration of Convolutional Neural Networks (CNNs) in the context of classification and transfer learning tasks. The authors propose a new approach based on objectness and label smoothing to improve the calibration of classification CNNs. The proposed approach is based on the idea that the relative object size of the smoothing factor can be used as a proxy for the relative smoothness of the class activation maps of the CNN. They show that the proposed approach can improve the performance of CNNs for classification, as well as transfer learning.   "
SP:5254658923e594294b69d124a8d004166852822a,"This paper studies the dual network optimization problem in medical imaging. The authors propose a new convex duality framework, which is based on convex solvers. The main idea is to use neural networks to solve inverse problems with weight decay regularization in neural networks for path sparsity.  The authors show that the proposed method is able to achieve state-of-the-art performance on MNIST and fastMRI datasets. "
SP:085cad6bc143c8713580bddfaa71f06496dac314,"This paper studies the problem of text-to-speech synthesis pipelines. The authors propose a differentiable alignment scheme based on token length prediction. It is based on adversarial feedback, prediction losses, and a mel-spectrogram. The model is trained with soft dynamic time warping to improve the performance of the spectrogram-based prediction loss. The paper shows that the proposed model achieves better mean opinion score than existing models. "
SP:01148cea55db606aa78d27e900818684a8bce9ab,"This paper proposes a new representation learning approach for real-world graphs. The proposed method is based on the Wasserstein graph diffusion (Wasserstein metric) to learn the distribution representations of nodes in a lower-dimensional space. The authors propose a non-parametric framework, where nodes are represented as a set of non-topological features, and the attributes of the attributed graph are represented by a decomposition of the attribute matrix. The nodes are then represented by point representations, which can be used for downstream tasks such as node classification, matrix completion, and node classification with missing attributes. The paper shows that the proposed representation method outperforms existing algorithms for node classification and matrix completion."
SP:aeeb5909f7123ef631f569b469af9715205c881f,"This paper studies the problem of reinforcement learning (RL), where the goal-conditioned “student” policy is trained with adversarially Motivated Intrinsic GOals. The agent is an AMIGO, which is an agent trained with meta-learning. The goal-generating teacher is the agent’s agent, and the agent is trained using goal-generated teacher. The teacher is trained to generate sparse extrinsic rewards for the agent. The environment reward is a “constructively adversarial” objective. The authors show that the intrinsic motivation of the agent and the RL methods can be improved by the proposed method. "
SP:3d05bc7dca97681cb582298e318b9b973841eed3,"This paper proposes a new data-driven framework based on generative adversarial models. The authors propose to use a dataset of files for information retrieval from which a model can be trained using private information retrieval. The privacy level is defined as the distance between the user distortion and the user privacy constraint. The paper also proposes a rate-distortion-leakage tradeoff between the two, which is based on the mutual information between the information-theoretical formulation and the actual retrieval process. The proposed scheme uses a constrained minimax game to learn the tradeoff curve between the download rate, the distortion, and user privacy leakage. Experiments on the synthetic Gaussian dataset, MNIST and CIFAR-10 datasets show that the proposed scheme performs better than a data-based approach on the MNIST dataset and achieves better performance than an achievable scheme based on source coding."
SP:3f9e2db00fc3dcd7a40588adcb638503ec10dc09,"This paper proposes a decoupled greedy learning method for GNNs (DGL-GNN) for graph-related applications where the node embeddings are very large and they are used in large scale settings. The main idea is to learn a GNN with a set of modules that are greedy auxiliary objectives, and then update each module according to the greedy auxiliary objective. The authors propose a lazy-update scheme, where each module is updated according to a greedy auxiliary goal. They show that their method can be used for time or memory limited applications, where the fidelity of the model is highly dependent on the number of modules. They also show that the proposed model achieves better efficiency and accuracy than sampling-based acceleration, and that it can be combined with sampling in GNN training. "
SP:5ecb1b288f7fc02aead4493f81640867bc349290,"This paper proposes a neural link predictor for missing edges in large scale Knowledge Graphs with missing edges. The authors propose a framework to solve complex queries on incomplete knowledge Graphs. The proposed solutions are based on gradient-based and combinatorial search, where the optimisation problem is formulated as a combination of logical conjunctions (∧) and disjunctions such as existential quantifiers. The model is trained using intermediate solutions for complex query atoms, and the proposed approach is shown to outperform state-of-the-art methods on Hits@3."
SP:f04a522fd04c503754fdb8c52da68646d31271a4,This paper proposes a new procedure for evaluating the local robustness of feed-forward neural networks with piecewise-linear activation functions. The proposed approach is based on a highly-parallel GPU implementation of the `2 norm' of the model. The authors show that the `p-ball consistently converges to the ‘2 norm’ of the network when the number of adversarial inputs is small. They also show that their approach is more robust than existing approximate verification approaches and verifiers. 
SP:5297651ff873f97c07b9c47ed3eff52251661844,This paper proposes a new approach for embedding of objects in the affordance space of text corpora. The key idea is to use the knowledge of object “affordance” in the space of dimensions to learn a mental representation of objects based on human judgements of object similarity. The authors show that this embedding is better than existing approaches in terms of performance. 
SP:72b4f3b40c6c6fa2eb53e95ed9a10a4077ffa049,"This paper proposes a method for the emergence of individuality (EOI) in multi-agent reinforcement learning (MARL). It aims to improve the efficiency and productivity of the division of labor in human society. The authors propose a probabilistic classifier based on the EOI to learn the probability distribution of each agent’s intrinsic reward signals. It is shown that it can be used to improve multi-adversarial cooperation, and it can also be used for multi-agents cooperation. Empirically, the authors show that the proposed MARL algorithms are able to achieve better performance than existing methods in several multi- agent cooperative scenarios."
SP:112509d6d3573a9d495d182fdfae6ec0327cddf5,This paper studies the problem of certified robustness of Randomized smoothing with a base classifier. The authors propose a Smoothed WEighted ENsembling (SWEEN) scheme for randomized smoothed classifiers. SWEEN is an adaptive prediction algorithm that can be used to improve the prediction and certification cost of the SWEen models. The paper also shows that SWEE models are more robust to l2-norm adversarial attacks than candidate models.  The authors also show that small models can be trained with SWEED models with small training time.   The main contribution of the paper is a theoretical analysis of the effect of ensembling generality on the performance of the proposed model. 
SP:ea892e3d199ed6121279b20061a87f43afae8796,This paper studies the problem of learning hierarchical structures for the learning process in complex real-world tasks. The authors propose an Ordered Memory Policy Network (OMPN) to learn a subtask hierarchy for the task decomposition in an unstructured demonstration with subtask boundaries. The OMPN is able to generalize well to partially observable environments. Experiments show that the proposed model performs better than existing baselines such as Craft and Dial in both unsupervised and weakly supervised settings.
SP:cc6aa977ce561a2493ae74bb694205cd67c8d890,"This paper proposes a Causal Semantic Generative model (CSG) based on causal reasoning. The CSG learns a semantic factor, a variation factor, and a domain-specific correlation between the semantic factor and the variation factor. The proposed methods are applied to OOD prediction using variational Bayes for learning and prediction with the causal invariance principle. The authors show that the proposed baselines can achieve OOD generalization error of 0.5-1.5% when the semantic-identification is used for adaptation."
SP:be3f34a59e5e61dcdbc7cb085f031ba4a5a5b758,"This paper studies the problem of robust estimation for unsupervised learning problems with adversarially corrupted rewards. The authors propose a new online algorithm to estimate the corrupted rewards of a stochastic reward. The algorithm is based on the idea that the uncorrupted reward distribution of the online algorithm can be used as a proxy for the regret of the algorithm. They show that the algorithm can estimate corrupted rewards with small regret. They also show that robust online algorithms can achieve near optimal regret in a variety of scenarios, including stoachastic multi-armed bandits, linear contextual bandits, and Markov Decision Processes (MDPs). "
SP:6d62a80aaebb2988df3953d4d7164e5a2fa1aa6d,"This paper proposes RewriterEvaluator, an encoder-decoder architecture for neural machine translation (NMT). It consists of a rewriter and an evaluator to improve the translation quality. The rewriter uses prioritized gradient descent (PGD) method to train the rewriter, and the evaluation is based on Rewriter-evaluator's termination policy. The authors show that the proposed framework can improve the performance of NMT models such as Transformer, Transformer-NMT, and Transformer+NMT on a variety of translation tasks such as Chinese-English and English-German. They also show that it can be applied to the rewriting process."
SP:9761fca8848868dfc9cacdab2537f8276ca76e0f,"This paper proposes a new black-box segmentation framework for learning of calibrated stochastic mappings from images, Ambiguities, and unsystematic annotation. The proposed model consists of a two-stage, cascaded strategy for calibrated adversarial refinement. The core design of the proposed framework is to learn a calibrated predictive distribution for tasks such as semantic segmentation and unsupervised learning. Experiments on the multigrader LIDC dataset and Cityscapes dataset demonstrate the effectiveness of the approach."
SP:ce965758f1b795a56c02f45d6a8d06cb8bdf29cb,"This paper studies distributed compute systems for stochastic optimization algorithms for large-scale machine learning applications. The authors propose error feedback (EF) for compressed communication between two systems, and propose a new alternative to EF for contractive compressors such as Top-K or PowerSGD. The main contribution of the paper is a new construction for the induced unbiased compressor and the contractive compressor. The proposed approach is shown to outperform EF in terms of reduced memory requirements, communication complexity guarantees, and assumptions. The paper also shows that the partial participation in federated learning can be improved by using unbiased compressors."
SP:4fd702490293e481c79614852ba27dd3ce9215a4,"This paper proposes a new machine learning (ML) algorithm called Hyperparameter Optimization (HPO) for hyperparameter search. HPO is an extension of hyperparameters optimization (HOO) in the context of HPO, where the goal is to find the optimal solution to a hyperparametrized problem. The authors show that HPO can be used to improve the performance of existing HT-AA baseline algorithms and benchmarks. The paper also shows that the HPO algorithm is more efficient than the baseline, and can be applied to a variety of tasks. "
SP:e8f99bae5853de525450fcb8facd23cf973fc161,"This paper studies the problem of learning high dimensional, high entropy label representations from data labels. The authors propose a new image classifier for audio labels that can be used in the context of classification. They show that audio labels are more robust to adversarial attacks than categorical probabilities and numerical probabilities. They also show that they are more sensitive to the error signal than text. Finally, they show that the label representations learned by the proposed label representations (e.g., spectrograms, Gaussian mixtures, uniform random matrices, and constant matrices) are better than those learned by standard label representations such as the standard text (categorical) labels.  "
SP:4e8d924cba7367af0999b30d79250b4dc40413e1,"This paper proposes a new approach to train ensemble neural networks with forward passes. The proposed methods are based on forward passes to improve the prediction performance of the network. The key idea is to use a single model’s capacity to train subnetworks with a single forward pass. The authors show that the proposed methods improve the accuracy, the calibration error, and the negative log-likelihood of the prediction. They also show that their methods are more robust than out-of-distribution variants such as ImageNet, CIFAR10, and ImageNet."
SP:d2f1c23b67c6744101034dc5e1c70765a733b169,This paper proposes a method for learning intermediate knowledge from sparse representation learning. The method is based on Sparse Representation Matching (SRM) which uses sparse representations of the hidden features in a teacher CNN and a student network. The intermediate feature maps in the student network are learned by pixellevel and image-level labels. The neural processing block in the SRM is trained by stochastic gradient descent. The authors show that SRM performs better than KD techniques. 
SP:e8c0f43bd5debf6544f588cd3442dc3dd62d0eee,"This paper proposes a novel approach to learn policies with sequential structure in the representation learning process. The authors propose a theoretically motivated policy similarity metric (PSM) to measure behavioral similarity between two policies. The proposed approach is different from existing approaches in that it uses a contrastive representation learning procedure to learn the state similarity metric between two policy similarity embeddings (PSEs1). The authors show that the proposed PSEs can achieve better generalization than existing approaches on three benchmarks: LQR, jumping task, and Distracting DM Control Suite. "
SP:92f3b4942da9075440dda618f561a85f8fde5a5c,"This paper proposes a new approach for disentanglement based on distributed equivariant operators. The key idea is to use the latent representation of the model as a proxy for the object shape, and then use the encoder to disentangle the latent space between the two factors. The proposed approach is shown to achieve better disentangled representations than existing models using distributed operators. Empirical results show the effectiveness of the proposed approach."
SP:ef0f58c462bc5dd1c7b78f562c42a4e17f0f252b,"This paper proposes a statistical framework for measuring the timedependent interaction of neuronal spiking activities based on the Hawkes process. The influence pattern of the influence pattern is modeled by the nonlinear Hawkes processes, and the authors propose an iterative algorithm based on analytical updates. The functional connection weights are modeled in Gaussian form, with auxiliary latent variables such as sparsity variables, latent marked Poisson processes and Pólya-Gamma variables. The expectationmaximization (EM) algorithm is used to estimate the maximum a posteriori (MAP) estimate. The authors show that the proposed algorithm is able to capture the temporal dynamics of interaction in neural spike trains with interpretable functional connectivity. The algorithm is evaluated on synthetic and real data."
SP:1156d3deac022829bda930ffcb081947609d972b,"This paper studies the gradient descent (GD) algorithm for two-layer neural network models. The authors consider the under-parameterized regime of the GD dynamics in the random feature model. They show that it has random featurelike behavior, and that the quenching-activation process of GD with “quenched” neurons leads to a continued activation and deactivation process. They also show that the “implicit regularization” of GD dynamics with quenched process leads to “mean-field” scaling in the parameter regimes. "
SP:9e81401a6f30c70d870a12cce0cf600557f92b80,"This paper studies constrained Markov decision process (CMDP) problems in reinforcement learning problems. The authors propose a model to solve the CMDP problem with prescribed safety constraints. The MDPs in CMDP are reconnaissance MDP (R-MDP) and planning MDP [1], which are both MDP with MDP constraints. In R- MDP, the reward-seeking policy is a fixed threat function, and in P-MPD, the threat function is a Q-function analogue of danger. The paper proposes an approximation method to the R - MDP by using a generative model to predict the threat of the state-action pair. The proposed method is evaluated on a benchmark dataset and complex collision-free navigation tasks, and shows that the proposed method performs better than existing approaches."
SP:f1d4ac7d5516dd0df742e224c8c09c721d0d0886,"This paper proposes a new cross-entropy loss for neural architectures for classification tasks. The authors show that the cross-Entropy loss is equivalent to the square loss in NLP and can be used to train neural architectures on benchmark datasets for NLP, automatic speech recognition (ASR) and computer vision tasks. They also show that these architectures can be trained in hyper-parameter settings. They show that this square loss can improve the performance of NLP on classification with cross-estentropy. "
SP:915f1f0fc4850507c28c1d609239b41775863ebe,"This paper studies the problem of self-supervised objectives for reward maximization in deep reinforcement learning. The authors propose Self-Predictive Representations (SPR), a method to learn the latent state representations of the agent’s representations. The encoder is trained using an exponential moving average, and the target representations are learned using a transition model. The paper shows that SPR outperforms prior methods in sample-efficient deep RL, and achieves a median human-normalized score on Atari. SPR also outperforms expert human scores in a limited data regime."
SP:983f01c170909c8c67fd3be25f121bd61bdd8307,"This paper proposes a method for generating single-node representations from a single node’s embedding. InstantEmbedding uses local PageRank computations to compute the embedding of each node in a graph. The proposed approach is based on compact representations of graphs, which can be used to generate globally consistent representations. The authors show that the proposed method is able to learn representations that are globally consistent across different nodes in a given graph. They also show that their method can be combined with existing unsupervised embeddings to achieve state-of-the-art performance on a variety of machine learning tasks such as node classification, link prediction, and visualization. "
SP:d11037b8fe2b10aee672ba82f69410b40181f0f9,"This paper proposes a new graph coarsening algorithm based on deep learning on graphs. The main idea is to use the Laplace operator and the projection/lift operators to learn a coarse graph with edge weight. The authors propose a framework to learn the coarsens of the coarse graph using the framework. The proposed method is evaluated on both synthetic and real networks. The method is shown to achieve better performance than other popular graph-coarsening methods on several metrics including reduction ratios, graph sizes, and graph types. "
SP:0d680213339f0e2aedb0be4aeed51423706b8bf6,"This paper studies the problem of generating environmental acoustic effects in dynamic environments. Acoustic properties such as scattering characteristics of 3D audio content creation, acoustic scene analysis, and localization are of great interest in the field. The paper proposes a geometric deep learning algorithm that learns these characteristics by combining discrete-laplacian and implicit encoders, and then uses numeric solvers to learn acoustic properties for interactive applications. The proposed multi-layer network is able to learn arbitrary topologies, and the proposed learning method achieves state-of-the-art accuracy."
SP:afc33a782c43e3d4c5c4fbf047d0b1108bc30bae,"This paper studies the problem of Risk Extrapolation (REx) in machine learning prediction systems, where the model’s sensitivity to extreme distributional shifts can be affected by the number of causal and anti-causal elements. The authors propose a robust optimization based on the perturbation set of extrapolated domains (MMREx) for robust optimization. They show that REx improves the robustness of REx against causally induced distributional shift and covariate shift in terms of robustness. They also show that their approach is more robust than existing methods such as Invariant Risk Minimization."
SP:411d5bcf7698d534ad60f581d479ff74849ba4de,"This paper proposes a new architecture for learning partial differential equations (PDEs) by using neural networks to learn mappings between finite-dimensional Euclidean spaces. The neural operators are used to learn the mapping between function spaces using neural operators, and they are then used to solve PDEs. The authors propose a new ML-based method, called Fourier neural operator, which is based on the integral kernel in the Fourier space of the neural operator. It achieves better accuracy than PDE solvers in terms of fixed resolution and zero-shot super-resolution for turbulent flows. "
SP:41d268d0eac9b4c84baa156fb641aa6d3060b5a4,"This paper studies the tensor formulation of neural networks. The authors propose a gradient flow for linear neural network training with infinitesimal step size. The gradient flow is based on gradient descent with singular vectors in the gradient flow. The convergence direction of the network parameters depends on the singular vectors of a tensor, and the network is trained to predict the convergence direction using the singular vector. The paper shows that gradient flow can be used for separable classification in the `2/L max-margin problem in the “transformed” input space of a “linear tensor networks” with orthogonally decomposable input space. The global minimum of gradient flow in the transformed input space is a weighted `1 and `2 norms’ with a norm-like function.  The paper also provides convergence assumptions for underdetermined regression. "
SP:e27907ef4a4e6e0f5841618fcaa7e7e0db443f91,"This paper studies the problem of optimizing slimmable networks. Slimmable neural networks have been a popular topic in recent years. They are particularly useful in resource-constrained settings such as mobile devices, where the number of devices is limited and the storage cost of the model is high. The authors propose a multiobjective optimization lens to optimize slimable networks with heterogeneous width-multipliers. The proposed approach is based on the idea that the width multipliers are shared weights and width-multiers can be used to optimize sub-networks with different performance profiles. The main contribution of the paper is to show that the proposed algorithm can be combined with width- multipliers to improve the performance of sub-neighboring networks. The method is evaluated on MobileNetV2 on the ImageNet dataset and compared to alternatives. "
SP:cf59403abb6ca89ccee4f8e77e9a33d99e6a00f5,"This paper studies federated semi-supervised learning (FSL) in the federated learning setting, where each client has access to a subset of the server’s data. The goal is to learn a set of expert knowledge that can be used to train a federated model. The authors propose a method called Federated Semi-Supervised Matching (FedMatch) that uses the inter-client consistency loss to improve the performance of FedMatch. They show that FedMatch outperforms the baselines in terms of performance on a variety of tasks."
SP:9457b6d430a2cd864d526d7e90bf3e1ab13d6df4,"This paper studies the problem of self-supervised learning with discrete event sequences for real-world users. The authors propose CoLES, a low-dimensional fixed-length vector representations for downstream machine learning tasks based on contrastive learning. CoLES can be used in the discrete event sequence domain in a self supervised setting, where the goal is to learn a sequence of discrete events from a set of events. The main contribution of the paper is a new augmentation method for learning discrete events sequences using CoLES. Experiments on public datasets show that CoLES representations perform better than existing methods on downstream tasks."
SP:385942a5bcee7384bb722a1669b541f2fac0cd36,"This paper proposes a new model, StructFormer, for unsupervised dependency parsing and constituency parsing in natural language grammars such as dependency grammar and constituency grammar. The proposed model is based on a parsing framework that constructs a constituency tree and a dependency graph using a dependency-constrained self-attention mechanism. The authors also propose a transformer based on induced dependency relations in the transformer. Experiments show the effectiveness of the proposed model in unstructured and masked language modeling, as well as in unclassified constituency parsing. "
SP:078966ff62775bba6031e47d374bda95f4a7dde3,"This paper proposes a method for learning structured representations from images. The proposed method is based on an annotated mapping of the nodes of scene graphs and object bounding boxes. The authors show that the proposed method can be used to train a model on the scene graph grounding task, which is a popular scene graph parsing task. The method is evaluated on Visual Genome (VG) and Visual Relation Detection (VRD) datasets and shows that it outperforms state-of-the-art approaches."
SP:4644dbf7466b6234d8abf69995fdfb357efcc119,"This paper proposes a new framework for learning the distribution of data using a Relational regularized autoencoder (RAE) that is able to learn a distribution over the latent space. The proposed approach is based on a spherical sliced fused GromovWasserstein (SFG) which is a mixture of von Mises-Fisher distributions. The main contribution of the paper is that it uses the inner discrepancy between the discrepancy and the relational discrepancy between a reconstruction loss and relational regularization. The authors also propose a variant of the SSFG, which uses the power spherical distribution to reduce the sampling time in high dimension settings. Experiments show that the proposed RAE framework outperforms the state-of-the-art in terms of discrepancies. "
SP:5ae2c0af82cac89a65f1cc38c43e2d05ea298901,This paper proposes a new approach for training deep networks with repeated structures in the transformer module. The key idea is to use deep linear networks as a theoretic analysis for the adaptive untying criterion. The authors show that the proposed method can reduce the training time of BERT and reduce the computational costs of training. They also provide a theoretical analysis of the effect of repeated layers on the performance of the deep learning model sizes. 
SP:a51710551142316b67e2fccd969fea1ece35ba39,This paper studies the interaction inside adversarial perturbations to improve adversarial transferability and interaction in the context of transferability-boosting methods. The authors show that the negative correlation between the transferability of adversarial transfers and the interaction between the two is a strong indicator of the effectiveness of DNNs for negative correlation. They then propose two methods to improve transferability in the attacking process by using interactions. 
SP:f1565319075c1442c2cb52d96443facb492c06c2,"This paper studies Catastrophic forgetting in deep learning models. The authors consider the problem of feature reuse in the context of neural representations and task semantics, where the task representations are learned by a neural network (hidden) representations and the task semantics are encoded in a set of deep layers. They show that the deeper layers can be used for forgetting by sequential training on task representational subspaces. They also show that for maximal forgetting of task sequences with intermediate similarity to the original task sequences, there is no interference between the two tasks.  "
SP:30d7532cdcf420bff3be6b92eea3d93bce59e6bd,"This paper proposes a new training algorithm for pre-training and fine-tuning large-scale language models such as BERT, XLNet, T5, and Deep, heavily overparameterized language models for natural language processing (NLP) tasks. The proposed training algorithm, called EarlyBERT, is based on the idea of Early-Bird Lottery Tickets for computer vision tasks, where the goal is to train a BERT model with structured winning tickets. The authors show that the training process is computationally efficient, and that the computation resources and the training time can be used to reduce the model complexity and reduce the inference time. The paper also shows that the model compression can improve the performance of large NLP models by reducing the computational resource demands. "
SP:c547f23ff6caaf5e9f35d258490b86ae0ac8ed03,"This paper studies the problem of learning with noisy labels. The authors propose a new f-divergence measure for classifier’s predictions and supervised labels, which is based on a variational form of the decoupling property of the variational difference between the classifier and the supervised labels.  The authors show that under certain assumptions on the clean distribution and the bias term of the divergence, the f-derivergence measures are robust to label noise. They also show that they are more robust than UCSC-REAL. Finally, the authors provide some theoretical guarantees on the robustness of these metrics.   "
SP:841888179dcdac901889c8d62cb5234311fe28f1,This paper proposes a new method for learning the uncertainty estimates for ensemble-based weighted Bellman backups with Q-ensemble. The proposed method is evaluated on continuous and discrete control benchmarks on both lowdimensional and high-dimensional environments. The authors show that the proposed method can achieve better performance than Bellman backbones on both challenging domains. They also show that their ensemble can outperform weighted bellman backups on UCB Exploration and Soft Actor-Critic and Rainbow DQN. 
SP:afc08f203562b841180811aef943bfb63a1659ea,This paper proposes a new few-shot classification framework for modeling uncertainty in fewshot classification problems. The proposed method uses meta-learning models to train a model using meta-training to learn the distributional mismatch between the class-wise similarities between the training data and the test data. The training strategy is then used to train the model for calibrated classification. The prediction of uncertainty is based on the random sampling of tasks and the dataset shift. The authors show that the proposed method is able to achieve state-of-the-art accuracy.
SP:12ae325ea3bce1e60195afac7d85895d2d20c29c,"This paper proposes a new method to learn video-text representations using a dominant paradigm. The proposed method is based on a generative model, where the representations are generated from a set of visually similar videos. The idea is to use noise contrastive learning to learn dissimilar representations. The method is evaluated on VATEX, MSVD, and ActivityNet. The results show that the proposed method performs better than others such as MSR-VTT and VATE."
SP:8a71d8fad25a126aff01431cacf348c05de75667,"This paper proposes a method for pre-trained language models (PLMs) for Chinese natural language processing (NLP) tasks with a single vocabulary. The method is based on Chinese word segmentation (CWS) and subword tokenization. The authors propose a masked language model pre-training where the single vocabulary is used to train the models expressiveness by multi-vocabulary pretraining (MVP). The proposed method, seg tok, is used in Chinese BERT to improve the expressiveness of Chinese PLMs. Experiments on sequence labeling tasks and sentence level tasks show that it is able to achieve better performance than seg-tok and char based vocabulary for Chinese PLM."
SP:b93ec7bc02b48068073ffe705f71d2643e663d51,"Graph Convolutional Networks (GCNs) are widely used in graph-based learning tasks. However, GCNs are not well-suited for real-world large graphs. The authors propose a method called BDS-GCN, which combines graph partition and distributed GCN training with an unbiased boundary sampling strategy to improve the full-graph accuracy of the proposed method. The proposed method is based on the idea that boundary nodes in a partitioned subgraph can be represented as GCN structures, and that the memory and the communications between the boundary nodes can be used to learn GCN architectures. Experiments show that the performance of the method is comparable to state-of-the-art methods in terms of throughput and accuracy."
SP:2d4ba873d11e969ebd1fc31f9b5ab450c964d154,"This paper proposes a new model for quantum chemistry simulations for catalyst discovery in the context of renewable energy applications. The proposed model, ForceNet, is a graph neural network with a surrounding 3D molecular structure to model per-atom forces in the 3D space. The authors propose an expressive message passing architecture to improve the model scaling of ForceNet. They show that ForceNet is able to learn both basis and non-linear activation functions, and can achieve better success rate than existing ML models for atomic forces. "
SP:8bdcf4fe6abf4739d4732b7ea8538513135dcccc,"This paper studies the problem of fine-tuning deep neural networks with Rademacher complexity. The authors propose a new regularisation method for the problem. The proposed method is based on transfer learning, where the parameters of the network are learned from the initialisation of the neural network. The main contribution of the paper is to show that the proposed method can be used to improve the generalization performance of neural networks. "
SP:3a3249e97ef2345ea2264de5ed8287e16687838e,"This paper studies the problem of model pruning in the context of mask discovery and mask evaluation. The authors propose a lottery ticket framework, where the model is trained with a set of hyperparameters for mask discovery (Hfind), mask evaluation (Heval), and unstructured magnitude pruning for vision classification tasks. The training configuration of the mask is then used as a training configuration for the final mask. The paper shows that the Hfind values of the masks can be decoupled from the masks by using layerwise pruning ratios, and that these ratios can lead to a decoupling find-eval phenomenon when the masks are trained with different hyperparameter for different stages.  The paper also shows that one-shot structured pruning can be used to improve the performance of the model. "
SP:2d6f5d72b21675f74ff4cde4d16bfb36abd5795f,"This paper studies the Coherent Gradients (CG) theory and proposes a new metric called Coherent Coherence (CoCo) to measure the alignment of per-example gradients. CoCo is an extension of the O(m) metric, which measures the coherence between the gradients of a pair of gradients in the training process. The authors show that CoCo can be used as a metric for measuring the generalization performance of neural networks trained with neural networks. The paper also provides a theoretical analysis of CoCo."
SP:e7c5de9a475d0ba71bc79580e8436024fb2c6f59,"This paper proposes a new approach to approximate Bayesian computation and neural likelihood methods based on summary statistics for implicit generative models. The proposed approach is based on the evaluation of the likelihood function of the model. The authors propose an infomax learning procedure where the model is trained on a set of sufficient statistics, and the goal is to learn a likelihood function that is close to the density or density ratio. The approach is evaluated on three different tasks."
SP:c5997bf2348e94949684f45fbd418661e85220c1,"This paper proposes a new image-to-image translation model, called TUNIT. The proposed model is based on set-level supervision for data collection, where the goal is to learn a set of hyperparameters (i.e., pseudo domains) for each of the image domains. The model is trained on paired images and domain labels. The authors show that the proposed model performs better than a set -level supervised model on data collection with full labels. They also provide a semi-supervised scenario, where TunIT is used to learn the estimated domains. "
SP:0cd97e64e638cabbeea0fdef3e9c5b33f4000f72,"This paper studies the problem of estimating the curvature penalty function of wide neural networks. The main idea is to use the probability distribution of the network parameters as the parameter of the initialization procedures, and to use it as the bias in function space. The solution function is approximated by a natural cubic spline interpolation, which is a weighted second derivative of the original solution function. The authors show that using the uniform distribution allows for asymmetric initialization of the constant curvature of the solution function, and that it can be used for initialization procedures. They also show that the regularization strength of spatially adaptive smoothing splines for training trajectories with multivariate regression and activation functions can be improved by using a width-n shallow ReLU network. "
SP:8b885142facbb3b8db41ec9d83822cee81324694,"This paper proposes a new regularization technique called Weight decay for deep neural networks called Adaptive Momentum Estimation (AdamW). The authors show that weight decay outperforms L2 regularization and decoupled weight decay in adaptive gradient methods such as L1 regularization, decoupling weight decay, and L2-based regularization in deep learning libraries. The authors also show that the Stable Weight Decay (SWD) method can be used to solve the unstable weight decay problem in the Adam variants of Adam, and that the SWD method is more stable than L1 and dec2 regularizations. Finally, the authors provide a theoretical analysis of the effect of the hyperparameter of Adam variants on the performance. "
SP:a3206dc71e32ba1830895bf442d3840f3331a532,This paper studies the translation quality of neural machine translation (NMT) with Translation Memory (TM) in the context of sentence level retrieval. The authors propose a new method to improve the performance of NMT with a pre-trained language model (PLM). The encoder is used to encode the TM information and the NMT decoder is trained to extract the semantic relationship between the encoder and the TM. The n-gram retrieval method is based on the sentence level retrieved method from the PLM. The paper shows that the proposed methods can improve the information flow between the TM and NMT. 
SP:72b43991a242872b2ceb1861e8ffbdf26c9f4818,This paper studies the problem of rate reduction in deep (convolutional) networks with (shift) invariant classification. The authors propose an iterative gradient ascent scheme for the rate reduction of learned features in a deep network. The proposed architectures are based on linear operators in multi-channel convolutions. The main contribution of the paper is to show that a convolutional network in the spectral domain with linear operators can learn a discriminative deep representation. 
SP:f8b02cf1b918b0956761829ec6ef9127596071ec,"This paper studies the implicit acceleration of gradient flow in over-parameterized two-layer linear models. The authors propose a conservation law for implicit acceleration based on the spectrum of the gradient flow. They show that the acceleration is a function of the width of the spectrum and the number of Gramian matrices. They also provide a matrix factorization problem as well as Riccati type differential equations. Finally, they provide a small, balanced or spectral initialization of the weights."
SP:e5f086c806be88d50e461a782b5b00124f4656fb,"This paper proposes a new approach to learn an opaque model’s behavior in the context of explainable AI. The proposed framework, CLIME, is based on uniform sampling of user-defined subspaces in the LIME framework. The authors propose a surrogate interpretable model, LIME, which can be used to learn a model that is interpretable in the presence of adversarial attacks. The model is trained with a perturbation procedure, and the model is evaluated on a variety of real-world problems. The paper shows that CLIME can learn an ML model that can be interpretable using CLIME. "
SP:b1d5ef15772e192eb8c8a0e65b3c21ee7c794295,"This paper studies the problem of pre-trained language models for natural language understanding (NLU). The authors propose AMBERT, a Multi-grained BERT based on BERT, which is an extension of BERT with multi-word expressions to natural lexical units. The main idea is to use the fine-gained and coarse-gated tokenizations in the pre-train language model to train a pre-trained language model with contextualized representations of the words and contextualized embeddings of the phrases. The encoder and the encoder of the pre - trained language model is trained using English.  The authors show that the proposed models perform better than existing models on several benchmark datasets (e.g., CLUE, GLUE, SQuAD, RACE).  "
SP:fd1cfe80343d3789227d99d836a5674374a234f5,"This paper proposes a new task for natural language utterance, called Semantic parsing. The task is to learn a machine-readable information representation from natural language. The authors propose a Transformer for semantic parsing, which is based on the PhraseTransformer architecture. The Self-Attention mechanism in the Transformer learns the local context of phrases using Long Short-Term Memory (LSTM). The model is trained on the Atis dataset using a Neural Network. The proposed model is evaluated on Geo, MSParS datasets and shows that the proposed model can learn detailed meaning. "
SP:2056a65a7500d79465685af883083cd706277c1f,This paper proposes a new training method for multiple adversarial losses in deep neural networks (DNNs). The authors propose to use composite adversarial training (CAT) to improve the DNN robustness against the combinations of multiple perturbations. The authors show that CAT improves the robustness of individual perturbation models in terms of the number of perturbed pixels and spatial transformations. The paper also shows that CAT outperforms the state-of-the-art on several benchmark datasets. 
SP:006e5b9ac9a8eb7223843731488bfefbd8eb09bd,This paper proposes a new recurrent network called Emergent Symbol Binding Network (ESBN) based on external memory for variable-binding. ESBN learns the rules of a set of abstract rules and uses the binding mechanism to learn the symbol-like representations in the learning process. The authors show that the proposed architecture outperforms competitive neural network architectures on high-dimensional sensory data. 
SP:4171ce45966ac499f51450a19fb233934c0847f0,"This paper proposes a framework for structured prediction language tasks where the task-specific discriminative classifiers are used to solve the problem. The proposed framework is based on the idea of a translation task, where the goal is to learn a language model from a set of augmented natural languages, and then use it to learn the model to solve a task. The model is trained on a variety of tasks, and the proposed model is evaluated on a number of tasks with different hyperparameters. The results show that the proposed approach is able to achieve state-of-the-art performance on most of the tasks."
SP:8f1b2fc6829e0bdfcc981020b0dcf3e63a947910,"This paper studies the problem of unlabeled entity recognition (NER) models trained with named entities. The authors propose a novel approach to improve the misguidance of NER models trained on unlabelled entities. In particular, the authors propose to use negative instances as negative samples to train the pretraining language models. The proposed model is evaluated on synthetic datasets and real-world datasets and shows that the proposed model performs better than prior baselines. The model also performs well on well-annotated datasets."
SP:dd76ece8d92a8a230a8b43033d8cb2368c677a94,"This paper proposes a new acoustic word embedding, called Acoustic Neighbor Embeddings, which is based on stochastic neighbor embedding (SNE) for sequential inputs. The key idea is to embed the embedding space of fixed, reduced dimensions in the vector space of the input word embeddings. The embedding vectors are then used to encode the subword transcriptions. The acoustic encoder is trained with frame-wise subword posterior probabilities for the speech signals, which are computed using an acoustic model. The authors show that the proposed method achieves better recognition accuracy than the triplet loss criterion for neural network training with the same number of gradients. "
SP:9142189126b8612ac0acee6fe18a0cfcb70b6545,This paper proposes a new reinforcement learning algorithm for stationary mean-field games. The authors propose a fictitious play algorithm based on gradient-descent and proximal policy optimization to learn a policy and a policy that is optimal for Nash equilibrium. The algorithm is applied to the single-agent reinforcement learning problem and is shown to converge to the optimum. 
SP:c498f8a199da1818fe64ed88b0825c5aad688aec,"This paper proposes a new framework for approximate probabilistic inference with a normalizing flow model for the joint distribution. The authors propose a new method for training a generative model using variational inference, where the model is trained with arbitrary differentiable transformations. The task is to learn a joint distribution over a set of flow models for a given task. The distribution is learned using a flow model, and it is then used to train a distribution that is close to the approximate posterior. The paper shows that it can be used for likelihood evaluation, inversion, and sampling. The proposed approach is evaluated on a variety of inference tasks for inverse problems, and the sample quality of the proposed approach outperforms MCMC baselines."
SP:1d0f27f61c9d32911b8bd15d6b82ef5eec644f0f,"This paper proposes a new evaluation criterion for cell membrane segmentation based on the Perceptual Hausdorff Distance (PHD). The evaluation criterion is based on a new dataset called U-RISC, which is an annotated Electron Microscopy (EM) dataset for the Cell membrane. The authors show that the proposed evaluation criteria can be applied to both segmentation methods and iterative manual annotation. "
SP:8ca7aff87c82be69c9542550c814f52c9419ab0a,"This paper studies the problem of catastrophic forgetting in Continual Learning (CL) in the context of short streams of tasks. The authors propose a modular architecture and a learning algorithm based on this learning algorithm. The modular architecture consists of modules for atomic skills, and the learning algorithm is based on a task-driven prior in the exponential search space. The paper shows that the proposed learning algorithm outperforms the state-of-the-art CL benchmarks on a variety of benchmarks for catastrophic forgetting. "
SP:cc819c61f408e88f247eb87946187ccec3dad32e,This paper proposes a new unsupervised meta-learning approach for synthetic meta-tasks. The proposed approach uses generative models to learn metatasks from the latent space. The authors propose two techniques: random selection and clustering and/or augmentation. The algorithms are able to learn synthetic classes for each meta-task. The experimental results on benchmark datasets show that the proposed approach outperforms the state-of-the-art in few-shot classification tasks.
SP:b25771e5c214a352f74ba6196fbd88bca6c43c98,"This paper studies injectivity in fullyconnected and convolutional ReLU layers and networks. Injectivity is an important problem in generative models for compressed sensing and inverse problems. The authors consider the problem of well posedness, where it is important to be able to perform inference in a tractable model. In injectivity is defined as the difference between the weight matrices of the injectivity and the global injectivity of the iid Gaussian matrices. The main contribution of this paper is a new argument for injecting injectivity into deep networks based on differential topology. The argument is based on random projections of the Lipschitz map of an injective ReLU network, and is shown to improve the stability of the resulting injective network. Empirically, the authors show that the proposed argument can improve the performance of neural networks in nonlinear inverse and inference problems."
SP:a95a153d3fe9bcf535ebf8514f51d00df483f210,This paper proposes a continuous conditional generative adversarial network (CcGAN) for image generation. CcGAN is a generative model that learns a discriminator to generate images from a continuous dataset. The discriminator is trained using a combination of a generator and a hidden map. The generator is trained with a soft-vacuous loss (HVDL) and the discriminator with a hard vicinal loss (SVDL). Empirical results show that the proposed method outperforms the state-of-the-art. 
SP:10dd09ab315870631d1451d200f2c87a023f8226,"This paper studies the sample complexity of deep learning (DL) with unlabeled instances for the task of Active learning (AL). Semisupervised learning (SSL) is used for this task, and SSL and AL are two popular DL-based AL algorithms. The authors show that the rate of convergence of AL algorithms with SSL can be bounded by the diversity of the data, and that the AL algorithm can achieve a better convergence rate than the classification network with the same number of labeled samples. They also show that AL and SSL (ASSL) algorithms can achieve better annotation efficiency than SL. Finally, the authors propose a pool-based Al, called convergence rate control (CRC), which can be used to improve the performance of the deep neural network trained with the SSL algorithm and the AL with the proposed AL algorithm. The proposed method is shown to outperform the state-of-the-art ASSL."
SP:7f3947c3fa5b09674507d8f3e10d9280376ecb94,"This paper proposes a federated learning method for distributively training neural network models. The proposed scheme is based on the notion of local-device level empirical loss, which is a global empirical loss that is a function of the number of devices in the network. The authors show that the proposed scheme can be applied to both convex and non-convex settings, where devices can be used for parallelizing gradient computation. The paper also shows that the inexact minimization can be achieved by using a dynamic regularizer.  The authors also provide a theoretical analysis of the Federated Learning problem, showing that the device level computations can be improved by using device heterogeneity. The theoretical analysis is also supported by experiments on real and synthetic data."
SP:a3fbb073b0e2371b20d5d9df6ab829673f90354f,"This paper studies the problem of optimizing similarity (dissimilarity) between self-supervised and supervised representations for computer vision tasks. The authors propose a new method, SimCLR, that uses intermediate contrastive losses to improve the performance of the representations compared to the supervised counterparts. The main idea is to use contrastive learning to learn the similarity between the intermediate layers of the two intermediate layers, and then use these intermediate losses to guide the selection of the final representation. The paper shows that the proposed method is able to achieve better performance than MOCO, MOCR, and SwAV on ImageNet linear classification and downstream tasks."
SP:5b5e705ea1ee1b857e17e64d560a39052804949d,"This paper studies the problem of actor-critic in reinforcement learning algorithms. The authors consider the single-timescale setting, where the bi-level or two-timecale updates are not available. The actor is trained using linear or deep neural networks to learn the policy gradient direction for the actor. The critic update is performed by a Bellman evaluation operator. The rate of convergence of the actor and the global optimality of the critic are studied. The sublinear O(K−1/2) rate is used to evaluate the performance of the sublinear rate. Finally, the authors propose a nonlinear function approximation for policy optimization, which can be combined with an actorcritic with deep neural network to obtain a globally optimal policy."
SP:26705a4dc305cce336f657c5937d1f5b4209548a,"This paper proposes a new representation for log embeddings, called Logs. Logs are a family of log files that encode events, messages, and transactions in a vector format. Log files are used in computer systems to store structured textual and numerical data, and they can be used to represent sequential forms of data such as natural languages, temporal signals, and log level. The authors propose to use Transformer Networks (TNs) to encode both numerical and textual information in the representation. The proposed representation can be applied to a variety of log processing applications, from the log level to the log sequence level."
SP:165c51a16f17fb8726e968f8b34742b62011d60e,This paper studies the problem of deep convolutional neural networks (CNNs). The authors propose a new approach based on wavelet decompositions based on freely-trained mixture weights. The proposed AlexNet architecture can be used for image classification. The two main feature extraction properties of the two are directional selectivity and shift invariance. The authors also propose a variant of the separable wavelet packet transform to improve the accuracy rate of AlexNet. The theoretical theory behind the proposed network is well-motivated and the experimental results demonstrate the effectiveness of the proposed method.
SP:d0a284da462584724ba6a3a48c9e986d391233f6,"This paper studies the problem of dynamic composition in Coordinating teams. The authors propose a coach-player framework where the goal is to learn the optimal team strategy in a multi-agent particle environment. The learning objective is based on a variational objective. The adaptive communication method is also proposed. The proposed method is evaluated on a variety of resource collection tasks, and the results show that the proposed methods achieve better zero-shot generalization for team compositions with heterogeneous agents. "
SP:4eb662b527d556758aaa1a0b589495fcc337fad0,This paper studies the problem of estimating group influences in deep neural networks. Influence functions in deep learning are important for machine learning interpretability and uncertainty estimation. The authors propose a post-hoc method based on the Hessian and the gradients of the model. They show that the influence functions of deep learning with non-convex loss functions can be used to improve the accuracy of the network architecture and improve the performance of deeper networks. They also show that these influence estimation methods can be applied to non-consvex setups. 
SP:5fea74a2031d097a99dacf613bedcb054b0c3831,This paper proposes a new pretraining task called language modeling for next word prediction with large text corpora. Autoregressive language models are used to train downstream tasks with zero-shot usage. The authors show that language models can learn features for classification tasks with crossentropy (log-perplexity) and can be used as an objective function for the classification tasks of interest. 
SP:a67da438e9821010284416170c3699ae7ff96c99,"This paper studies the problem of membership inference attacks (MIA) against classification models such as image translation and conditional image generation models. The authors propose a new approach for membership attacks based on the reconstruction error of the neural network model. The main idea is to use the difficulty score of the membership error as a proxy for membership error, and then use reconstruction error to estimate the reconstruction errors of the training set. The paper shows that the MIA accuracy is better than the original membership error in terms of both difficulty score and reconstruction error. "
SP:6fe23ebe09f2a4e42a21598f8e9c79edeca99863,This paper proposes a differentiable architecture search method for the distribution learning problem with random variables in a continuously relaxed architecture mixing weight. The Dirichlet distribution of the random variables is learned by pathwise derivatives. The gradient-based optimizer is used to optimize the Dirichlett parameters. The authors show that the proposed formulation improves the generalization ability in terms of stochasticity. The proposed method is evaluated on NASBench201 and CIFAR-10 and ImageNet. The experimental results show the effectiveness of the proposed method. 
SP:c590d0ed2487b42480b53fc077546a4a0bc27a78,"This paper proposes a new linear function approximator based on Fourier or Gabor basis functions. The authors propose to use neural networks to approximate low-dimensional-but-complex functions in the presence of signed distance functions and neural radiance fields. The proposed method can be applied to a wide range of problems, including multiplicative filter networks, sinusoidal nonlinearities, Fourier features, and positional encodings. The main contribution of the paper is to show that these elements can be combined with ReLU networks to improve the positional encoding performance of deep networks with high dimensional inputs. "
SP:f5be855300f63c185a006834302bd4b033b56258,"This paper proposes a teacherstudent scheme for gradient-based meta-learning algorithms with an inner loop that learns task-specific models and a meta-model. The algorithm is based on a lightweight computation graph, where the meta-gradients are computed using the gradients of the meta - model. The inner-loop optimization steps are based on high-order derivatives, and the inner loop is used to learn the meta for each task. The authors show that the proposed algorithm is able to learn a good meta-neural network with high memory footprints, and it can be applied to a variety of tasks including few-shot learning, long-tailed classification, meta-attack, and long-tail classification."
SP:0361e02d56b7d121cb5ede1cb582284cc18fc599,"Offline Reinforcement Learning (RL) is an important problem in RL. Offline RL algorithms are usually off-policy RL algorithms. Behavior regularization is a common technique in off-Policy algorithms to improve the generalization performance of the Reformer Learning agent. However, behavior regularized offline reinforcement learning suffers from catastrophic performance degradation due to the out-of-distribution (less explored) actions. This paper proposes an analytical upper bound for the KL divergence of the behavior regularizor using state-dependent Lagrange multipliers for the regularization term. The gradient penalty term for the gradient of the Q value is used for the policy evaluation objective. The authors also provide sample based estimations for the sampled batch. The experimental results show that BRAC+ outperforms model-free and model-based approaches on several offline RL benchmarks."
SP:b2cfb380aa2a21f72f508b453cf5949257a5b4ec,This paper studies the problem of compressing deep neural networks. The authors propose a new one-shot learning paradigm for training networks with edge-devices. Adjoined networks are trained with a CNN-based neural architecture. The main idea is to use the regularization behavior of the adjoint training paradigm in order to reduce the inference time. The proposed architecture is evaluated on CIFAR-100 and Resnet-50 using Imagenet. The experiments show that the proposed network achieves better top-1 accuracy than the original network. 
SP:dba40073f79143e5355d194aa16db9eee0267a5d,"This paper studies the problem of exploration in reinforcement learning (RL). The authors propose a new exploration algorithm, called greedy exploration, which is based on the notion of dithering. The authors show that the complexity of greedy exploration is bounded by a local optima, and that it is equivalent to the existing counterparts such as-greedy. They then propose to use duration distributions for exploration based on ecological models of animal foraging behaviour, and show that these distributions can be used to improve the generality."
SP:5efb581a368ace3bd085d48801a899559d6a43ef,This paper studies the problem of matrix factorization in implicit regularization of gradient descent. Gradient Flow with infinitesimal initialization is a variant of gradient flow with a nuclear norm. The authors show that gradient flow can be used as a heuristic rank minimization algorithm in Greedy Low-Rank Learning. They also show that the norm minimization can be improved by using rank minimisation view. 
SP:7f997cf7a63a7330fc12fd525516080c91a3cb9b,"This paper proposes a two-stage framework to improve the robustness of models in the context of skin cancer classification. The main idea is to use CycleGAN to learn intra-class, inter-subgroup augmentations of the data augmentations for the classifier. The authors show that the proposed CAMEL improves the robust error of the baseline by a factor of 2.5 on the real-world skin cancer dataset. The paper also shows that the theoretically-motivated subgroup consistency regularizer and the robust objective of CAMEL can be applied to model patching. "
SP:de6cea1e35a0555175e17546a93422e9a96a511e,"This paper studies the problem of learning a non-differentiable RRL. Rule-based models such as decision trees, Ensemble methods, and fuzzy/soft rules have been shown to perform well on large data sets. The authors propose a new training method called Gradient Grafting to train a discrete model by gradient descent. The proposed classifier, Rulebased Representation Learner (RRL), learns interpretable nonfuzzy rules for the data representation and then uses it to map the continuous space to discrete parameters and structures. The paper shows that RRL achieves better scalability than existing approaches on both small and 4 large datasets. "
SP:e36388a9452e557dd51bf0170bf2f9da22271a49,"This paper proposes a new regret minimization (RGM) algorithm for structured environments. RGM is based on invariant risk minimization, which is an extension of IRM. The authors show that RGM can be applied to a wide range of biological applications, including molecular property prediction, protein homology and stability prediction, and molecular scaffolds. The proposed method is evaluated on a variety of synthetic and real-world datasets."
SP:cad3ed2fba57faf17a3e8899dc5a744d5358aa68,"This paper proposes a new BERT for NLP tasks. It uses cross-modal attentions for text-vision BERT models for language-vision tasks such as text-image retrieval and text-speech recognition. The proposed architecture, called cross-probe BERT, is based on text and vision probes. It is able to perform crossmodal attention with a small computation cost. The authors demonstrate the effectiveness of the proposed method on large-scale search and textvision retrieval."
SP:51fd82de525fcb738fdeaeeae20fbb2cdf975f0c,"This paper proposes a new Actor-Critic algorithms, called FORK, which is a model-free ActorCritic algorithm based on the forward-looking Actor. The actor is trained in continuous state and action spaces in Box2D and MuJoCo environments. ForK is trained on a GPU, and can be applied to BipedalWalkerHardcore. The authors show that the proposed algorithms outperform the baselines."
SP:6e730239e6e8b43c4988dd61dca30f15dc039ef7,"This paper proposes a new aggregation algorithm, FEDBE, based on the Bayesian inference perspective. The authors propose a federated learning approach to learn a global model with local models. The local models are learned from the Gaussian or Dirichlet distribution of the local models, and the global model is learned from a Bayesian model Ensemble. The global models are trained using neural networks. The aggregation method is based on an existing aggregation method, and it can be applied to non-i.i.d. data.  The authors show that the proposed aggregation algorithm (FEDBE) can be used for regularizing users’ model training. "
SP:3ac5f437fc349a33810d0645664d1c448528af74,This paper proposes a new method for training deep neural networks. The proposed method is based on the idea that the weights of a neural network can be represented as a weighted sum of its weights. The authors show that the proposed method can be used to train a network with a large number of weights. They also show that their method is able to achieve better performance than the baselines. 
SP:efa2343ead47263a0d09e1c17f9aa044605b9650,"This paper studies the priori finite time convergence analysis of deep neural networks with settling time in the deterministic control theoretic setting. The authors propose a Lyapunov based analysis of the settling time of the loss function with input perturbations, and derive a priori upper bound of the prior for this loss function based on the analytical formula. They then propose a control theory framework for deep learning with the tracking problem, and show that this priori guarantees of finite-time convergence can be obtained for any network with control inputs. Finally, they provide a supervised learning framework for this control problem."
SP:7a0ded4b3b2d08d43765ff7b722da9b9863aabd6,This paper studies the problem of disentanglement of representations in machine learning. The authors propose a method based on incompressible-flow networks (GIN) to learn the compact and disentangled representation of latent variables. The proposed method uses GIN to perform informative latent variables selection using mutual information between the latent variables and an auxiliary variable. The method is evaluated on synthetic data and two downstream tasks: outlier detection and adversarial attack defence on synthetic and real data.
SP:0d9ba12bbf47b13a46c2225f9dc06878418daaea,"This paper studies the problem of downsampling in convolutional neural networks. In this lossy process, feature maps are generated by pooling operations on the feature maps. The goal is to reduce the number of receptive fields in the input variations. The authors propose LiftPool, a bidirectional pooling layers (LiftUpPool and LiftUpPool) that is based on LiftPool. LiftDownPool is an up-pooling layer that is trained with the pooling function of LiftUppool. The main contribution of the paper is the Lifting Scheme for signal processing.  The authors show that the proposed methods have better robustness against input corruptions and perturbations than existing backbones for image classification and semantic segmentation.  "
SP:147239edceb17bade6ea5d3dca44e3a59998aa47,"This paper proposes a stable noise-shaping quantization scheme for embedding method based on stable noise. The proposed approach is based on a fast linear transformation of Euclidean distances using the `1 norm' of the ` 1 norm. The embedding dimension of the embedding is defined by a sparse Gaussian random matrix, where T is the number of binary sequences. The authors show that the proposed method can be applied to well-spread data with high-dimensional dataset. The time complexity of the method is shown to be much lower than existing binary embedding methods. The quantization error of the proposed quantization based on polynomial decay is also demonstrated. The accuracy of the binary codes is shown on natural images."
SP:f65e229bca3904095743e7a501b1083cc60f1e22,"This paper studies the problem of backpropagation in artificial neural nets (ANNs). The authors propose a new process for training ANNs based on synaptic plasticity rules, called Gradient Descent (GD). GD is used to learn rules for recurrent neural nets [1]. The rules are used to train MNIST/Fashion MNIST on synthetic data. The authors show that GD improves the robustness and generalization of the classifiers in terms of tolerance to adversarial perturbations in the genetic setting [2]. The authors also show how GD can be used to improve the performance of the perceptron algorithm and the multiplicative weights method [3]. "
SP:f435530146fa975cb27cd375a857df9bcbd87682,"This paper proposes a graph-to-sequence model for visual question generation (VQG) that combines image, side information, and side information to generate human-like questions from an image. The image is used for generating referential and meaningful questions from visual objects in the image, and the side information is used to generate visual questions. The learning paradigm for visual questions is based on answer-awareness, region-reference, and a learning paradigm that combines answer-aware and region-based knowledge. The proposed VQG is evaluated on VQA2.0 and COCO-QA datasets, and shows that the proposed model performs better than baselines in the setting.   "
SP:53a26ce11647866d3f6ba8b84ca9f13106197a8d,"This paper studies the double-descent phenomenon in linear regression models with isotropic data distribution. The authors propose two learning algorithms, linear regression and neural networks, which are based on optimally-tuned `2 regularization for double descent. The proposed algorithms are evaluated on a variety of test risk scalings using tuned regularization. "
SP:c193ccc74b987beaf8d53a29a8529a0af5e87742,This paper studies the problem of building image generators (decoders) with spatial regularities in the context of generative modeling. The authors propose a neural network that can be used as a decoder to learn the spatial dependency networks (SDNs) in the 2-D space. The SDN decoder is trained with a sequential gating-based mechanism to extract contextual information from the feature maps in a deep neural net. The spatial dependency layers of the decoder are used for density estimation using baseline convolutional architectures and hierarchical VAE. The results show that the SDN is able to learn large images with high spatial dependency and can learn disentangled representations. 
SP:db91512a90e75675af03c2f197751c8526d6f5e9,"This paper studies the problem of Off-policy reinforcement learning (RL) in the offline setting. The authors propose a new prior approach for offline RL, called EMaQ, which uses a backup operator to estimate the sub-optimality bounds of the policies. The proposed algorithm is based on a proposal distribution, where the goal is to learn a set of policies from a dataset of interactions, and then use a heuristic design choice to choose the best behavior policy. Empirically, the authors show that EMaq achieves better performance than Soft Actor Critic (SAC) on D4RL benchmarks, and is also able to achieve sub-optimal performance in the online RL setting.  The authors also show that the proposed approach can be used to improve the performance of off-policy RL methods, such as BCQ. The main contribution of the paper is to use a generative model design for estimating behavior policies, and to use the function approximator as a proxy for the behavior policies. "
SP:e2b80adeaa9208e0667a64a3f24661f77b48e487,"This paper studies the problem of fair machine learning model for demographic disparity in machine learning systems. Existing techniques for model fairness are based on data preprocessing and model training with minibatch sizes. The authors propose a new batch selection algorithm called FairBatch, which uses an outer optimizer to solve the inner problem, and an inner optimizer for the training algorithm. The optimization is based on the PyTorch code, which is used in batch selection in model training. It is shown to achieve faster convergence than other batch selection techniques, and it is also shown to improve fairness measures such as equal opportunity, equalized odds, and demographic parity. "
SP:72f26b850bb2258223c0fc71598e35ad07d690e6,"This paper studies the generalization bounds for monotone DEQs with Lipschitz constants. The authors show that the monotonicity parameter of the monotonic DEQ is a function of the number of parameters of the infinitely-deep network. They show that under certain assumptions on the Lipschnitz constant, the bounds for these models converge to a deep equilibrium (DEQ) model. They also show that these bounds can be extended to models with multiscale convolutional structure. "
SP:bcfd4d7fd4590e3bc248a0a5422ce4b67db74a74,"This paper studies the problem of goalconditioned reinforcement learning in stochastic domains. The authors consider two settings: imitation learning and goal-conditioned learning. In imitation learning, the goal is to find a solution that maximizes the reward of the agent in a given task. In the goal conditioned learning setting, the agent is given a set of tasks and the goal function is to learn a solution to the task. The goal conditioned on the task is a probabilistic long-term dynamics and a desired value function. The proposed approach is based on density estimation. The paper shows that the proposed approach can achieve better performance than the state-of-the-art when it is trained with expert data. In goal conditioned reinforcement learning, it is shown that it is able to learn sparse rewards."
SP:d57550b2f323b356d7e609acc35ee33039f376b4,"This paper proposes a probabilistic inference framework for simultaneously learning multiple related tasks, called variational multi-task learning VMTL. The authors consider the variational Bayesian inference problem in multi-tasks learning, where the priors for the task relatedness are Gumbel-softmax priors. The prior is a mixture of variational posteriors, and the mixing weights are learned by learning a shared inductive bias between the representations and the classifiers. The paper shows that the proposed model can achieve state-of-the-art performance on a variety of benchmark datasets. "
SP:3ccdf8322f16c8a7bef82e32fad4c03969a510d1,"This paper studies the problem of long sequence lengths in Transformers. The authors propose a systematic and unified benchmark, Long-Range Arena, to evaluate the model quality of vanilla Transformer models in long-context scenarios. The main idea is to use the similarity between the text and natural, synthetic images, and mathematical expressions, to measure the quadratic self-attention complexity of the models. The proposed benchmark suite shows that the performance of the proposed model quality is comparable to the state-of-the-art in the long-range environments. "
SP:e12e410c3335b76133ceda4c865b244fbbab8580,This paper proposes a multilingual code summarization model for non-parallel data. The model is based on the Structure of source code (Context) and Context for machine learning models. The proposed model uses language-agnostic features such as source code and features from AST as the source code. Structure and Context are then used for representation learning on code. The authors show that the proposed model can perform well in a variety of programming languages. 
SP:f46e98d48f90071831f1c0069bf74a7993be6db8,"This paper proposes a reinforcement learning approach for audio-visual navigation based on recurrent aggregations of the audio observations from the sound source. The key idea is to use the waypoints in the audio and visual data to learn the geometry of an unmapped space, and then use the learned waypoints to guide the navigation policy. The proposed approach is evaluated on real-world 3D scenes and Replica."
SP:23bfe317dcef00a91ea92389b3f39d9b93972454,"This paper studies the problem of lottery tickets, where the goal is to find the best lottery ticket for each ticket in a lottery ticket hypothesis. The authors propose a new architecture for this task, which uses a small CNN to learn update rules for the lottery tickets. They show that this architecture can be used to train networks with different learning abilities. They also show that the initialization parameters for gradient descent can be learned with this architecture. "
SP:1b5ba618d3e28d48f9205c0780f8288a08fa5392,"This paper proposes a new method for semi-supervised learning (SSL) for unlabeled data with consistency regularization. The proposed method, RankingMatch, is based on the BatchMean Triplet loss, which is a new objective function with computational efficiency. The authors show that RankingMatch achieves state-of-the-art performance on several SSL benchmarks, including CIFAR-10, and outperforms SVHN in terms of accuracy, accuracy, and accuracy. "
SP:f3abccf4a2566ffbc821aba209fab15058639ad4,"This paper proposes a new formulation for the sequential learning setting. Few-shot meta-learning methods have been studied in the online setting, where meta-training and adaptation are used to train learning systems. The authors propose a new problem, called metalearning, where the goal is to find the optimal solution to a set of sequential learning problems. The problem is formulated as a binary optimization problem, and the authors show that meta-learned algorithms can achieve better sample complexity than empirical risk minimization methods in terms of regret, and can also achieve better bi-level optimizations in the variable-shot settings in sequential learning, such as zero-shot learning. The paper also provides a theoretical analysis of the performance of meta-trained algorithms on sequential learning algorithms in both the many-shot and zero-shoot settings. "
SP:95cb420d92ec42e12a4bbb0e66224f1c498a7161,"This paper studies the problem of learning contextual representations for NLP tasks using pretrained Transformer models. The authors propose a Transformer architecture that learns representations for sentence-level syntax by self-supervision. The proposed Transformer representations are evaluated on a variety of probes and show representational invariance to perturbations such as random permutations of n-grams. In particular, they show that the attention mechanism has a syntactic distance between the syntactic position and the local phrase structure, and that the sensitivity of the representations to perturbing the word position depends on the global phrase structure. The paper also shows that the representations learned by the Transformer networks can be used to improve the performance of Transformers networks in terms of self- supervision. "
SP:cb27b27a6fefc192ad1c2bd083d13eb9e51a5c44,"This paper studies the problem of generating high-fidelity images for Generative Adversarial Networks (GAN) with large-scale GPU-clusters. The authors propose a few-shot image synthesis task for GAN with a minimum computing cost of $\mathcal{O}(\sqrt{T}$)$, where $T$ is the number of pixels in the image, and $O$ is a number of frames. They show that the light-weight GAN structure with 1024 × 1024 resolution can be learned with a skip-layer channel-wise excitation module and a self-supervised discriminator with a feature-encoder. They also show that their model is able to achieve better performance than StyleGAN2 on several datasets across different image domains. "
SP:c0dbeb5d94b2388595cf7ad9675c55df0bac7f8e,"This paper studies neural network bounding for neural network verification systems. The authors propose specialised dual solvers for learning neural network bounds. The main idea is to learn a customised solver for each of the dual variables. The relaxation is based on a linear program, where the relaxation is defined as a linear relaxation of piecewise linear activations in the dual space, and the dual algorithm is used to learn the relaxation.  The authors show that the proposed method can achieve better bounds than off-the-shelf solvers in terms of speed-accuracy trade-offs. They also show that it can be combined with dual approaches to learn weaker relaxations, such as tightness and linear separation oracle.   "
SP:56e3837417dbcce0d65338dc3aac4e1a20eb0df8,"This paper proposes a new pre-trained language models (PTLM) based on the concept-aware language model (CALM)1. The main idea is to learn commonsense knowledge of everyday concepts in relational commonsense Knowledge (e.g., text-to-text transformer). The PTLMs are trained using a pre-training framework that combines masked token prediction, masked span infilling, and T5-style PTLM. The authors show that they can achieve state-of-the-art performance on NLU and NLG tasks. They also show that the generative and contrastive objectives can be used to improve common sense. Finally, they show that task-specific fine-tuning can improve the performance of PTLm. "
SP:7ec69bdee021af506293c87a3b75bce1c40a03d7,"This paper studies the problem of unsupervised physical object discovery in the context of 3D geometry. The authors propose a new framework to learn 2D segments from video frames. The framework is based on the idea of object interactions in physics, where the object properties of physical events are encoded in multi-scale pixel cues and physical motion cues. The model is evaluated on both synthetic and real scenes. "
SP:66997bc19a3ba6548fcf21f114e748bea95cad1c,"This paper proposes a new training method for improving the DNN robustness against adversarial attacks on convolutional neural networks (DNNs). Adversarial samples are generated by attack algorithms that are trained on white noises. The authors propose an IMA method to improve the margins of a DNN model by learning decision boundaries. The proposed method, Increasing Margin Adversary (IMA) Training, is evaluated on clean data and noisy data. The results show that the proposed method improves the robustness and classification accuracy of DNN applications such as COVID-19 diagnosis and life-critical applications."
SP:276ffd59fbf49e3ee02756da8920218102214917,This paper proposes a model-agnostic method called ProKT. ProKT distills the knowledge from a teacher model into a compact student network. The teacher model is trained using supervision signals in the student’s parameter space. The training objective is based on local intermediate targets. The proposed method uses an approximate mirror descent technique to learn the projection of the teacher model. The authors show that ProKT outperforms existing knowledge distillation methods on both image and text datasets. 
SP:906dc21d6988953fcf57d63bbdd12973e5818d16,"This paper proposes a channel pruning method for compression of Convolutional Neural Networks (CNNs). The main idea is to use a hyper-structured network instead of a hyperstructure network to learn the architecture of the main network. The authors use FLOPs to regularize the computational resource of the compact network, and then use the regularization term to improve the performance of the network. They also use layer-wise scaling factors to reduce the gradients, and they use hyper-gradient descent to optimize the gates. The proposed method is evaluated on CIFAR-10 and ImageNet, and compared to state-of-the-art methods."
SP:890fd9454596c051b0e9535baf73b1dd1fae67ca,"This paper studies the problem of automated higher-order logic theorem proving. The authors propose a new exploration mechanism for the theorem prover based on imitation and reinforcement learning. It can be seen as an extension of the exploration approach in the deep reinforcement learning scenario, where the goal is to learn a prover that can be used in combination with imitation or reinforcement learning to solve the prover. The main contribution of the paper is the exploration of premises in the context of human proofs. The exploration approach is based on DeepHOL Zero."
SP:88209417a8ad07e6103084e41709be900303ce5f,"This paper studies the problem of data augmentation in models for machine learning tasks. Data augmentation methods are typically used to augment the data modality of a model, but the modality can be different from the original data. The authors propose a new and automated data augmentmentation approach, called MODALS, which can be applied to image processing functions and word-replacing rules for text data. They show that MODALS can perform universal data transformation operations in the latent space, which allows them to transform the input data into different modalities. "
SP:6d84670d321b0d584b097c630574bd748e85c9a2,"This paper studies the mean field limit of neural networks in the nonlinear and nontrivial dynamical limit of learning dynamics. The authors propose a rigorous framework for computing the meanfield limit for large-width neural networks. The main contribution of the paper is a theoretical analysis of the two-layer networks and the three-layer ones. The mean field regime of the optimization efficiency of the unregularized feedforward three-layered networks is studied, and the global convergence result of the mean-field limit is obtained. The paper also provides a theoretical guarantee for the global approximation property of the neural networks under the algebraic topology argument for neural networks with neural networks consisting of neuronal embedding in the probability space. The global convergence guarantee is based on regularity and convergence mode assumptions. "
SP:b90f893f927db9c439595fd119a565cf43c971f4,"This paper studies the problem of learning explanations of expert decisions in real-world decision-making with interpretable parameterizations for introspecting and auditing policies. The authors propose a batch inverse reinforcement learning approach based on counterfactual reasoning for costbenefit tradeoffs between expert’s actions and the unknown reward function. The key idea is to learn the reward functions for expert behavior and then use these reward functions to guide the policy evaluation in the batch setting. Experiments on both real and simulated medical environments demonstrate the effectiveness of the batch,counterfactual inverse RL learning approach."
SP:c92916780418bfa7f0796fd9766b6d28b9eea5ef,"This paper studies the problem of graph-based continuous control. The authors propose a transformer-based approach called AMORPHEUS, which is based on graph neural networks (GNN). They show that GNNs with a graph structure that is similar to graph structure can generalize better than GNN-based methods. They also show that they can generalise to graphs with physical morphology that are similar to the state and action space dimensions of the graph. They then show that the models trained with Multitask Reinforcement Learning can achieve better generalisation and data efficiency. Finally, they show that their message passing scheme can be combined with morphological information in a message-passing scheme. "
SP:2cf58f5cac20dccdc2034ef60e8e46b7988ebd7d,"This paper studies the problem of visual counting in the context of explicit, symbolic models. The authors propose a new alternative based on modulated convolutions, called MoVie, which uses a forward-pass to perform inference in the presence of a residual bottleneck. The proposed module consists of two modules: (1) the number’ related questions in the original generic VQA models, and (2) a module for counting the number of objects in a natural image. The experimental results show that the proposed module outperforms prior-art on three benchmarks, including common object counting, COCO, and reasoning tasks. "
SP:c64e77507e562f236cb69361b22fb1a7951ffb22,"This paper proposes a poisoning attack on a model. The attack is based on online convex optimization. The authors show that the attack achieves provable convergence on the target classifier, and that it is more robust than other model-targeted poisoning attacks. They also show that their attack can be used as an online attack to improve the attack success rate. "
SP:a526023ec4cb839b83c574d31f59a9a67bc7af00,"This paper proposes BiPointNet, a model binarization approach for deep learning on point clouds based on edge devices. The authors propose a new resource constraint for real-time point cloud applications with edge devices, where the information entropy is bounded by the number of scale-sensitive structures. They show that binarized models can improve the performance of point clouds with scale distortion in optimization, and propose two new challenges: scale distortion and aggregation-induced feature homogenization. They also propose a distribution based on Entropy-Maximizing Aggregation (EMA) to improve the feature representation capacity by using Layer-wise Scale Recovery (LSR) to reduce the size of the distribution. Experimental results show that the proposed techniques perform well on both speedup and storage saving on real-world resource-constrained devices. "
SP:825b4d1db0c537a607655bb5b4bf221ec672c8af,"This paper proposes a self-attention architecture for Transformer-based models for natural language processing tasks. The transformer learns context-aware representations from a trainable memory. The Transformer model is trained with a dedicated layer to store the global information in the memory. Memory-augmented neural networks (MANNs) are used to learn representations from the general-purpose memory of the representations. The authors show that MANNs are able to perform better than RNNs and LSTMs on a variety of tasks such as question answering, language modeling, and backpropagation. The model is also able to learn the global context of a masked language model from memory tokens. "
SP:f0fa1b7684bc605f6edd4813c44be20988fe8b4c,"This paper proposes Prototypical Contrastive Learning (PCL), an unsupervised representation learning method based on the Expectation-Maximization framework. PCL learns low-level features for instance discrimination by clustering the semantic structures in the embedding space. These prototypes are then used for maximum-likelihood estimation of the network parameters. The authors show that PCL outperforms instance-wise contrastive learning and clustering in low-resource transfer learning. "
SP:5342a5e1d87fd17b1a2efed967dbbfeafa440ee7,This paper studies the problem of training deep neural networks on clean images with invisible perturbations. The authors propose a block called Orthogonal Multi-Path (OMP) block that can be used to train neural networks with robust features. The OMP block combines forward learning and backward correction to improve the performance of the neural networks.  The authors show that the l∞ bound of the white-box PGD attack is tighter than for vanilla neural networks trained on CIFAR10. They also show that neural networks can defend against black-box attacks and adversarial defenders. 
SP:776df66274ed12449fde8dcef873a593980f397c,"This paper proposes a new attention mechanism for graph neural networks. The authors propose a graph attention model for noisy graphs. The proposed method, SuperGAT, is based on a self-supervised task where edges are represented as attention forms, and the edges are modeled as edges of a graph. The attention forms are then used to learn the edges of the graph, which are then fed to a self supervised task. The paper shows that the expressive attention can be used to identify mislinked neighbors in the graph.  The authors also show that the proposed method can be combined with other graph characteristics such as homophily, average degree, self-smoothing, and attention forms to improve the performance of the proposed models. Experiments are conducted on several real-world datasets to demonstrate the effectiveness of their proposed recipe."
SP:80a05296d6b1e4c6e9e2df01938c73029ff8487d,"This paper proposes a dialogue system for medical automatic diagnosis (DSMAD). The agent is trained using reinforcement learning methods, and it is shown that DSMAD agents achieve better diagnostic accuracy than DSMAD with a Markov decisionmaking process. The agent can be used for diagnosis and for diagnosing processes. The proposed DSMAD agent consists of three cooperative modules: an inquiry module, an introspective module, and a diagnostic module. The evaluation metrics show that the proposed INS-DS achieves better reliability and robustness compared to other DSMAD methods. "
SP:10ae09d90d465125433a9b4f15b1405ab017920d,"This paper proposes a new adaptive batch-wise regularization for natural world distribution with fine-grained and long-tailed properties. Batch Confusion Norm (BCN) is used to improve the performance of FGVC classifier by learning the discriminative parts of the image features of fine details. The BCN term is used for overfitting the FGVC model with an extra attention mechanism to learn the discriminant parts. The authors show that the BCN loss can be used for cross-entropy loss with class predictions. The proposed approach is evaluated on iNaturalist2018, which is a natural world distributions dataset. "
SP:90f1e0fe1e9678d1e9a4dcb519d4e8fd61098ce0,"This paper studies the inverse reinforcement learning problem in ill-posed nature, where the goal is to learn a policy that maximizes the reward of an inner-loop MDP solver. The authors propose Approximate Variational Reward Imitation Learning (AVRIL), a new method for Bayesian reward inference in this setting. AVRIL uses a variational approach to learn the latent reward of the policy, which is then used to estimate the approximate posterior distribution of the reward. The proposed method is evaluated on real medical data and control simulations. The results show that the proposed methods perform better than existing methods in the small tabular setting. "
SP:ccd251d95c0a2d8dc5ad2a148ec29955e105e71e,This paper proposes a new search procedure called Learned Belief Search (LBS) for partially observable environments. LBS is an extension of prior search approaches for fully observable environments where the exact belief distribution is not known. The key idea is to use a supervised task to learn approximate auto-regressive counterfactual belief for the policies in both single and multiagent environments. The proposed LBS uses a public-private model architecture to learn policies with rollouts. The computational cost of learning the hidden information is reduced by using LBS. The empirical results show that LBS achieves state-of-the-art performance on Hanabi in multi-agent settings. 
SP:db408e6bfe69a9b3984f3b27ca92b802aa37af42,"This paper studies the problem of Planning in large state spaces. The authors propose a new algorithm, Shoot Tree Search (STS), which is a combination of MCTS and random shooting. The main idea of STS is to use TD(n) as the tree search context. It is shown that STS can reduce the bias-variance trade-off."
SP:5efc271ccc555fd9aa542548838170bd4c98e957,"This paper studies inductive bias in neural architectures. The authors propose a new pre-training methodology called LIME, which uses transformer networks to learn inductive biases in different tasks. They show that these inductive biased tasks can be used to improve the performance of the model on synthetic tasks such as induction, deduction, and abduction. They also show that LIME can achieve better performance on large mathematical reasoning benchmarks than vanilla transformers. The main contribution of the paper is to show that the computation cost of LIME is much lower than other pre-train approaches. "
SP:bb8e0b554d3b3314fa343c902d9e60f1a141ea30,"This paper studies the gradient descent for weight normalized smooth homogeneous neural nets with inductive bias. The authors propose a new exponential weight normalization (EWN), which is an extension of the exponential or cross-entropy loss. The main idea is to use gradient flow to train networks with gradient flow instead of gradient flow in the gradient flow path in the EWN. They show that gradient flow with adaptive learning rate can converge faster than gradient flow without gradient flow. They also show that the asymptotic convergence rate of EWN can be improved by using SGD for sparse EWN solutions. "
SP:c71f9d2a602516865a0b103028186e83b52e5f00,"This paper studies the mode collapse problem in generative adversarial networks (GANs). The authors propose a new training scheme for GANs that is based on the Catastrophic Forgetting in continual learning. The authors show that the proposed training procedure improves the classification accuracy of the discriminators, and that they are more robust to mode collapse than existing GAN frameworks. Empirical results show the effectiveness of the proposed metrics in GAN evaluation. "
SP:52c48198c95826e042f9e5a512ef3265daaff882,"This paper proposes a regularization method called AUBER, which is based on reinforcement learning. The main idea is to learn a proxy score for the head importance of the attention heads in BERT. The proxy score is then used to train a pruning policy that prunes attention heads based on the proxy score. The authors show that the pruned attention heads outperform other heuristic-based methods in terms of accuracy. They also show that they can be combined with other heuristics such as rule-based policies to improve the performance."
SP:abcbbad146f1b0d5d579c215952c95e5499a378a,"This paper studies the problem of imitation learning in robotics problems, where the goal is to learn a correspondence between physics simulators and a real robot. The correspondences are learned from unpaired and randomly collected data. The authors propose a framework for fine-tuning the correspondence between the representation, physics parameters, and morphology. The correspondence is learned by learning dynamics cycles for dynamic robot behavior with a cycle-consistency constraint. The paper shows that the proposed framework can learn dynamic state-action trajectories for the simulated arm and the real robot arm in a variety of problem domains (simulation, simulation, and real robot). The paper also shows that this framework can be applied to uncalibrated monocular video. "
SP:006434d56992836ab9420d7d4215bc70664de304,This paper studies the problem of explainability in model development. Explainability is an important problem in AI. The authors propose two solutions for Shapley explainability on the data manifold. The first is based on the Shapley framework. The second is a Shapley value-function based on generative modelling. The theoretical results show that the two solutions are equivalent to each other. 
SP:7cda6bccf08887c7cef66d0ac3ccefdea8f5d7c8,"This paper proposes a new method for opponent modelling based on local observations. Existing methods are based on using local observations to train the model. The authors propose a new modelling technique based on variational autoencoders to learn the embeddings for the local actions and the chosen actions. The proposed method is based on deep reinforcement learning, where the embedding is learned using the opponent’s information. The paper shows that the proposed method outperforms the baseline method in terms of the number of observed world state and chosen actions as well as the received rewards. "
SP:c239bc531bcf7293032748af29a1b786e9d893dd,"This paper proposes a new contrastive learning framework, Consistent Contrast (CO2), for unsupervised visual representation learning with unlabeled data. CO2 uses a consistency regularization term in order to improve the top-1 accuracy of Momentum Contrast (MoCo) on the ImageNet linear protocol. It is also applied to image classification, object detection, and semantic segmentation using PASCAL VOC. Experiments show that CO2 is able to improve top-5 accuracy on several tasks with labeled semi-supervised settings."
SP:d18bab21790713e2facb053c47298fc9079ab783,This paper studies the convergence rates of the Optimistic Gradient Descent Ascent (OGDA) and Optimistic Multiplicative Weights Update (OMWU) for saddle-point optimization in the constrained setting. The authors show that OGDA and OMWU converge faster than OGDA in bilinear games with probability simplex under the condition of an exponentially small learning rate. They also show that the learning rate of OGDA converges faster than linear last-iterate convergence with a universal constant.  The authors also provide a theoretical analysis of the smoothness of the objective function and the uniqueness of the optimal solution. 
SP:bbc7f77308b298c332a39747f693bc396f00a89f,"This paper proposes a federated setup for User Verification (UV) models. The framework is based on the Federated UserVerification (FedUV) framework for private and secure training of UV models. FedUV uses a secret user-defined linear combination between instance embeddings and the loss functions of the UV models, where the embedding vectors of the model are encoded as linear combinations. The authors then use voice, face, and handwriting data to perform user verification. The error-correcting code is then used to improve the performance of FedUV compared to other approaches."
SP:40fa47cc0928e2925ef5ce6d808073f368ca2cd4,"This paper proposes a new method for training deep neural network classifiers. The proposed method is based on the geometry of class manifolds (CMs), which is a well-studied geometry of the model. The authors propose a technique to learn the boundaries between two CMs, which are defined by the margin between the input and the output of the network. The margin is defined as the distance between two points in the random affine subspaces of the CMs.  The authors show that the proposed technique can be used to train CMs with different generalization, robustness, and training set size, as well as label randomization, stage of training, class, ensemble size, and random initialization. They also show that their method can be applied to real neural networks.   "
SP:09bce202ac7a750c3700a8ef3cd92cfe8ed00c39,"This paper studies the problem of learning policies with action noise in reinforcement learning (RL). The authors consider the setting where the environment states are unknown and the goal is to learn a policy that maximizes the entropy of the policy with respect to the entropy temperature of the environment. The authors propose Soft Actor-Critic (SAC), a method to learn policies with high entropy in the presence of action noise. SAC is based on Curiosity-Aware entropy Temperature (CAT-SAC) which uses a curiosity mechanism to estimate the instance-level entropy temperature for each environment state. The state prediction error is used as a proxy for the curiosity of the learned policy. The experiments on the MuJoCo benchmark show that the entropy improves the sample efficiency of CAT-SAC."
SP:dce5eb20581a21c5de0a9fc07a8a79a1fbb28c71,"This paper proposes a meta-reinforcement learning algorithm for learning policies in the out-of-distribution (OOD) setting. The proposed method is based on the idea of meta-regressive meta-learning, where the agent is trained on a set of policies and the goal is to learn a policy that maximizes the performance of the agent. The authors show that the proposed method can achieve better performance than existing methods on a variety of OOD tasks. "
SP:34d78aa11f9d50baf75a9646a6f9128318c3389a,"This paper studies meta-learning techniques for the few-shot learning (FSL) problem with label noise. The authors consider the gradient noise problem in the meta-overfitting problem, where the label noise of a meta-learner is added to the FSL by sampling noise from the training data. They propose an Eigen-Reptile (ER) that uses historical taskspecific parameters to learn meta-parameters for gradient noise. They also propose Introspective Self-Paced Learning (ISPL) to train prior models with noisy labels. They show that the proposed methods outperform state-of-the-art methods on several tasks. "
SP:a571bff9ffe4edafd7bc064c4d10609e6b981ce3,"This paper studies the problem of adversarial training for models trained with distributional shifts in the presence of small adversarial perturbations. The authors propose Adversarial Batch Normalization (AdvBN) to improve the generalization performance of semantic segmentation. AdvBN is based on adversarially crafted distributions for images, and is able to learn the mean and variance of deep image features. The proposed method is evaluated on ImageNet variants such as Stylized-ImageNet and ImageNetInstagram. The ResNet-50 model is shown to improve classification scores."
SP:6a9c46bd3cf854299f360bff136e1d79d3edb2e4,This paper proposes a proxy metric for outliers in the data distribution. The proxy metric is Variance of Gradients (VoG) and is based on human-in-the-loop auditing. The model is trained to predict the VoG scores of the outliers. The authors show that the models are able to identify outliers with high VoG.
SP:074bfacc75837bb19049be8a2890e10de073dd8e,"This paper studies the problem of deep generative modeling. The authors propose a new technique for generating generated samples from real-world data. The proposed method, Discriminator Gradient f low (DGf low), is based on the non-linear Fokker-Plank equation for the gradient flow. The main idea is to use entropy-regularized f-divergences between the generated samples and the real and the generated data distributions.  The authors show that DGf low improves the quality of generated samples for generative models such as VAEs and Normalizing Flows as well as GANs and vector-valued critics.   "
SP:74ecbc5a6d464bfa49337da9e0dd6a0fe714d4bb,"This paper proposes a new model architecture for cross-lingual understanding tasks, called VECO. The proposed model consists of two modules: an encoder-decoder Transformer and a sub-modular Transformer. The sub-modules of the Transformer block consist of innersequence and cross-sequence masked language modeling, which are used to learn multilingual representations. The model architectures are trained on a variety of pre-training tasks and various tasks. The inference for understanding and generation tasks is performed using the sub-modes. The authors show that the proposed model performs well on the XTREME benchmark, and is able to achieve state-of-the-art performance on a number of cross-languages understanding tasks (e.g., question answering, sequence labeling, and sentence retrieval). The authors also show that VECo can achieve better performance than other cross-latent models on a range of generation tasks. "
SP:3d177ad50727d1a2619b68ab8a897b79d8652beb,"This paper studies the problem of Reinforcement Learning (RL) with intrinsic motivation in the context of auditory event prediction, where the goal is to learn a causal understanding of the physical world. The authors propose a novel module based on Atari games, where K-means are used to model auditory event clusters. The neural network is trained to predict auditory events from acoustic data. The model is then used to perform audio-visual exploration in a Habitat simulator and active learning in a ThreeDWorld (TDW) simulator.  The authors show that the prediction errors of the intrinsic rewards can be used to improve the performance of the model in active learning. They also show that audio signals are able to learn intrinsic rewards better than vision-based models for RL explorations."
SP:014f6118ebe55ece6be23c3a10f12e4591e444b1,"This paper proposes a new framework for self-supervised representation learning based on noise-contrastive estimation. The proposed framework is based on the end-to-end framework, where the cluster assignments are learned from unlabelled data, and the clusters are used to train the representation. The authors show that the proposed framework outperforms existing contrastive learning approaches in terms of instance discrimination, category discrimination, and cross-modal discrimination. The paper also shows that it can be applied to both labelled and unlabeled data. The experimental results on image benchmarks such as CIFAR10 and ImageNet demonstrate the effectiveness of the framework."
SP:4df640f502e88ddba2d7e183625231d70b083e82,"This paper studies the problem of weakly supervised segmentation, where the task is to learn a segmentation model from a set of partial annotations (e.g., image-level tags, object bounding boxes). The authors consider the semi-supervised metric learning problem, which is an important problem in the semi supervised learning literature. Existing methods for weak supervision are based on weak supervision, where coarse annotations are used to learn coarse annotations in the feature space. In this paper, the authors propose to use Class activation maps and conditional random fields to learn sparse labels with broad region coverage in sparse annotations. The authors show that by using these two methods, they can achieve better performance than existing methods in the weak supervision task. They also show that the proposed Pascal VOC can be used to train a universal weakly trained segmenter. "
SP:f7d6099adb40a0ce2f8a3563dbd5207cf1fdea0f,"This paper studies the problem of self-supervised learning in a pretext task with slow convergence. The authors propose a distillation strategy for unsupervised training, where the goal is to improve the performance of small scale models compared to their supervised counterpart. The proposed method is based on contrastive learning based methods. The main contribution of the paper is a new method, Bag of InstaNces aGgregatiOn, which distills the training data into a bag of instances, which is then used for optimization. Experiments on ImageNet show that BINGO achieves better top-1 accuracies than other baselines on linear evaluation. "
SP:328866aad6544c81ded8980934df31dc4472435f,"This paper studies the problem of simulating-based inference (SBI) with stochastic models in the context of statistical inference. The authors propose a new adversarial approach called GATSBI, which combines SBI with generative adversarial networks (GANs). Inference is performed in high-dimensional posterior spaces with implicit priors. The variational objective of the implicit posterior distributions is defined in the adversarial setting, and the likelihoods of the posterior distributions are computed using the model of camera optics. The paper shows that the GANs can be used to perform Bayesian inference with high-dimensionality in the presence of high-dimensions, and that GATS can be applied to sequential posterior estimation with high dimensions. The experimental results on SBI benchmark problems and high-dense simulators show that the proposed method performs better than the SBI approach."
SP:2915e82097eae4eb8546dc500f32b3ec37e3766f,"This paper proposes a generative prognostic model for the task of causal inference. The model learns to predict the individualized treatment effects from a latent variable, which is then used as a prognostic score for biostatistics. The proposed method is evaluated on a variety of (semi-)synthetic datasets and shows that the proposed method outperforms existing methods. "
SP:ca358c9f36aac6e58ed1b3949c349d210c49a48e,"This paper studies the problem of Reinforcement learning (RL) in episodic environments, where the goal is to learn a model that is robust to extrinsic interventions. The authors propose a new framework called EARL1, which is a combination of two existing RL algorithms for episodic simulated environments. The main idea of the framework is to use a set of simulated benchmark tasks in RL, and then use them to train them on real-world platforms such as robots. Experiments show that the proposed approaches are able to achieve state-of-the-art performance on episodic RL, while also achieving higher levels of autonomy than existing approaches. "
SP:abe51d4a9817c08f0abde5da0bb8e6ca4e02e7cf,"This paper studies the question answering (QA) problem in AI and NLP fields. The authors propose a set of modules for QA systems with human-level reasoning capability. The modules are based on Graph Neural Networks (GNNs) and can be used as pre-trained language models (LMs). The modules can be applied to a variety of tasks in the human reasoning process. The reasoning can be done using knowledge graphs (KGs). The reasoning functionality of the GNN-based modules is evaluated on two QA benchmark datasets, CommonsenseQA and OpenBookQA. The GNN modules are shown to be able to perform better than the graph neural counter in QA, and they can also be used to perform QA in a knowledge-powered QA. "
SP:3ea5a38e7fcd9111dcd299ad039b634e2781685f,"This paper proposes a three-stage framework for Deep Neural Networks (DNN) compression, called Succinct Compression, which combines pruning, quantization, and pruning. The proposed method is based on a combination of two existing techniques: Pruning and Quantization. The method is evaluated on AlexNet/VGG-16 inference, where it outperforms Huffman Coding in terms of performance, space consumption, and inference runtime. The authors also show that the proposed method can be applied to DNN models trained with Sucinct Data Structures for fast queries using a compressed representation.    The authors propose three different formulations of the proposed methods in the Element-wise or Block-wise manner. The execution pipelines for the proposed model formulations are based on the execution pipelines of the three existing methods. The experimental results show the effectiveness of the method compared to Quantization, Pruning, and Pruning. "
SP:94c395afc794a9cc163e362078769ff83f3d20d0,"This paper proposes a new training method for tiny neural networks called Network Augmentation (NetAug). The training method is based on the idea of training a network (reverse dropout) on a small subset of the training data and then fine-tuning the model on the rest of the data. The main idea is to train a small model with a limited capacity, which is then used to fine-tune the network. The authors show that the proposed method can achieve better performance than existing regularization techniques such as dropout, data augmentation, and dropout on large neural networks with noise. They also show that NetAug is able to perform well on ImageNet, Cars, and Pascal VOC. "
SP:9c24549b980e415616f818acbf4cf680ef8edb52,"This paper proposes a new model for learning temporally coherent feature spaces from point cloud sequence. The model is based on Point cloud sequence, a data representation with flexible shape and motion information. The point correspondence information is learned from real-world environments, where scene flow information is available. The generator is trained to generate a temporally coherence output, and the point distribution is used as a learnable masking module to improve the upsampling ratio. The authors show that the proposed method can achieve state-of-the-art performance on both quantitative and qualitative evaluation for learning temporal coherence, and also improves the performance on an upampling task.   The authors propose to learn dynamic point cloud sequences in two domains: a fluid dynamical system with particles and human action scanned data, where the point correspondence annotation is provided. "
SP:67efe60ad37807505369b7852bc0abed29ffdda8,"This paper studies the problem of large-scale pre-training for detection transformers. The authors propose a separated training paradigm, FP-DETR, which is a 12-layer transformer with self-attention. The model is trained with query positional embeddings and visual prompts from textual prompts for NLP. The task adapter is then used to learn it for object detection. The proposed method is evaluated on the COCO dataset and shows that it achieves better robustness and generalization compared to other recent methods on small-size datasets."
SP:a1f9897496303984fc7ad469222106b14b4a6233,"This paper studies federated Averaging (FedAvg), a federated learning algorithm called FedPAGE, which is based on the optimal PAGE method. The authors consider the convex setting, where the communication round is the number of communication rounds, and the goal is to minimize the communication cost between the clients and the server. In this setting, the authors show that FedAE can achieve better communication complexity than local methods for federated convex and nonconvex optimization. They also provide a theoretical analysis of the communication rounds of FedPAGES in the nonconvolutional setting. "
SP:81e74765abc6524edd8fdf9a3ba107d7bddaa04b,"This paper studies the problem of adversarial attacks on artificial neural networks (ANNs) using mathematical operations. The authors show that the decision boundary geometry of ANN classifiers with adversarial perturbations can be approximated by a decision boundary in the form of a random subspace, and that the adversarial subspace can be represented as a subset of the original network. The paper then proposes a training procedure that combines adversarial attack with a redistribution of proximal class labels, boundary curvature, and boundary distance. The proposed training procedure is evaluated on a variety of benchmark datasets."
SP:af5c25ecf38c5c3f3387720bdc80c2c54c5699fe,This paper proposes a weakly-supervised contrastive learning approach for unsupervised clustering. The proposed approach is based on auxiliary data information (e.g. hashtags) that is used to represent the clusters in the Instagram image. The auxiliary information is learned by using direct downstream labels to represent supervision signals. The authors show that the proposed approach outperforms the baseline representation learning methods on unstructured constructed clusters with auxiliary information. 
SP:0a92fcc52970201de4a66b1e76c93dbea9dfd3f1,"This paper studies the problem of recovering sparse parameters from observational data in machine learning. Recovering sparse parameters in observational data is an important problem in the context of sparse estimation problems, where the hyperparameters of the problem distribution of interest are unknown. The authors propose two algorithms to solve this problem. The first algorithm, PLISA, is a path-following algorithm that is based on the Provable Learning-based Iterative Sparse recovery Algorithm. The empirical Rademacher complexity of PLISA improves the recovery accuracy and generalization ability of the PLISA with respect to the number of observations. The second algorithm is a unrolled algorithm with convergence, stability, and other algorithmic properties. The theoretical analysis shows that the two techniques are useful for learning-based algorithms, and that they can be used to improve the generalization performance. "
SP:5064eda9ba27060af15e81b2b317b2e4558b0ac4,"This paper studies the problem of Reinforcement Learning (RL) in the hybrid action RL setting. The authors propose Hybrid Action Representation (HyAR), a compact and decodable latent representation space for a unified homogeneous action space with discretization. The latent space is represented by an embedding table and a conditional Variational Auto-Encoder (VAE). The action representation is learned by unsupervised environmental dynamics prediction. The representation space is learned using DRL algorithms. The paper shows that HyAR outperforms existing baselines for high-dimensional action spaces. "
SP:5128bf712f6b197de113c7a371b4bec36f978eca,"This paper proposes Adaptive Gradient Descent (AGD), a new method for stochastic gradient descent (SGEM) for nonconvex optimization problems. AEGD is based on the Stochastic Gradient (SG) method, which is an extension of SGEM. The authors show that SGEM has the same unconditional energy stability property as SGDM, and that it can converge faster than SGDM in the online convex setting. "
SP:11f49b0a975be87769be29e85d7e3924699cf2c9,"This paper studies the problem of non-autoregressive (NAR) approaches for inference in the context of CMLMC. NAR models have been shown to perform better than their AR counterparts on multiple datasets. The main contribution of this paper is to propose a new AR framework, which is based on the distillation of the raw data without distillation. The authors show that the performance of the NAR model on the multiple datasets is comparable to the state-of-the-art NAR counterparts. "
SP:96f8ac3c6163e56d8ae1954a162bae01e6b58a0a,"This paper studies the problem of ultra-low power local signal processing for edge applications on always-on devices. Neuromorphic processors have a limited power budget in this domain due to their computational power. The authors propose WaveSense, a spiking neural network based on the WaveNet architecture. WaveSense uses neural dynamics and fixed time-constant to learn the neural dynamics of a neural network, and a feed-forward architecture to perform the neuromorphic implementation. The proposed model is evaluated on two datasets for keyword-spouting, showing that the proposed network performs better than the state-of-the-art CNNs and LSTMs."
SP:7f20a2e4e95f857140b87b0730360b3ff2f371f4,"This paper studies the problem of fairness in machine learning for social applications. The authors propose a technique called Shifty, which is based on the Shifty algorithms. The main idea is to learn algorithms that have high-confidence behavioral guarantees on the unfair behavior, and then use these algorithms to solve “demographic shift’s challenges. The proposed algorithm is evaluated on a real-world dataset of university entrance exams, and shows that the proposed algorithm can achieve state-of-the-art performance on these models. "
SP:94f097921bee5fdc10ec2e7c901b2ddb876d9d41,This paper proposes Stochastic dual dynamic programming (SDDP) for multi-stage stochastic optimization. SDDP is a trainable neural model that learns a piece-wise linear value function in the intrinsic low-dimension space. The authors show that SDDP has the worst-case complexity in terms of the number of decision variables in the decision space. They also show that the SDDP solver is able to solve low dimensional problems. 
SP:3d9f5132f9ec3807dbca78462a459fd123a09b24,"This paper proposes a new protocol for private next-token prediction based on the relaxation of group differentially private prediction in language models. The protocol, called SUBMIX, is a data-dependent privacy accounting mechanism, and it can be used to prevent data-extraction attacks. The authors show that the proposed protocol can prevent privacy violations on language models trained on a private corpus. The proposed model is based on transformer-based models, such as GPT-2, and is shown to be able to perform well on the task."
SP:7f524d186ea939309c7eeb843c62b6a4b4cfbc8a,"This paper proposes a new unsupervised method for OOD samples. The proposed method is based on the k-NN density estimate from a classification model. The model is trained using label smoothing, which is a variant of Label Smoothed Embedding Hypothesis. The paper shows that the proposed k-NN density estimation can be used to estimate OOD examples with finite-sample high-probability statistical results. The experimental results show the effectiveness of the proposed proposal compared to other OOD baselines."
SP:aafbd6ada14cc59a272fe4bf95fac71fa18e57ab,"This paper proposes a denoising score matching objective for diffusion-based representation learning with stochastic differential equations in the continuous time domain. Diffusion-based methods are commonly used in the literature for learning representations in the discrete time domain, and the denoised score matching framework is a popular method for representation learning. The authors propose to use denoizing score matching to improve the performance of models trained with denoises. The proposed approach is based on a non-adversarial generative model, where the supervised signal is generated from the latent codes of the latent code. The representations are trained with GANs and VAEs. The results show that the proposed approach can improve the sample quality of state-of-the-art models in semi-supervised image classification. The paper also provides an approximation of the prior for adversarial training on smaller noise scales, which improves the sampling speed. "
SP:8cfc837d5c10d539bbd098df7134c42e4830ba25,"The paper proposes a new algorithm for goal-conditioned reinforcement learning (RL) for tasks where the goal is to reach a distant goal. The algorithm is based on the idea of Classifier-Planning (C-Placing), which is a curriculum of intermediate states that are learned by planning. The goal is learned by M-step and E-step, and the goal-conditional policy is learned using expectation maximization. The paper shows that the proposed method is able to achieve better performance than prior methods on a variety of tasks, including navigation, manipulation, expert demonstrations, reward shaping, offline data, and graph planning. "
SP:ef3193842e06d4a6edb8a6a86ea5bc97ee5eaa4a,"This paper proposes a new regularization technique for deep neural networks called Mixup. Mixup is a data augmentation approach to improve the generalization performance of models trained with a data augmentation approach. It is based on the idea that the local distributional structure of the data manifold can be used to learn the cluster and manifold structures of the training data, and the local structure can then be used for the k-mixup case.  Mixup uses the Wasserstein metric of the interpolation of the displacement interpolation between the global cluster and the manifold support structure, which is used to estimate the optimal transport between clusters and manifolds. Averaging weights are computed by using the beta distribution of the Averaged weights of the two distributions.  The authors propose a procedure based on α, where α is the distance between the clusters and the manifolds of the clusters. The authors show that the proposed procedure can improve the robustness of a fully-connected network trained with synthetic datasets for binary classification on a set of perturbed training datasets with a global cluster.    The main contribution of the paper is to show that mixup regularization can improve generalization and robustness against adversarial robustness.  It is also shown that the performance of the proposed method can be improved by k-Mixup for perturbed learning datasets with k-mixture regularization and 1-mixed regularization. "
SP:0fe6a9848026e5f6436a380199e27a9ad26cffed,"This paper proposes a lightweight network with a nonlinear classification layer to learn embeddings for a linear classifier. The proposed network is based on a limited-capacity backbone. The authors show that the nonlinearity in the embedding vector space of nonlinear classifiers can be used to improve the performance of deep networks for representation (embedding) learning. The nonlinear kernelized classification layer is then used to train deep networks with a classification layer. The radial kernel functions in the classification layer are used to learn the radial kernel function of the non-linear classifier, which is then applied to train the layer for model-efficient classifiers on computer vision and natural language processing tasks."
SP:01ee8ec81619784788eb0ce9785098e437d17a7c,"Graph Neural Networks (GNNs) are used to learn node representations. Node representation learning is an important problem in the context of graph classification and link prediction. In this paper, the authors propose two fairness-aware data augmentation frameworks based on nodal features and graph structure. The authors show that the proposed schemes improve the fairness of GNN-based learning mechanisms in terms of statistical parity and equal opportunity. They also show that real networks can be used for graph contrastive learning and node classification. "
SP:7739dc9e37f7f1384f87d2e60281e5bb27fece99,"This paper studies the problem of estimating treatment effects from observational data in two-stage regression with instrumental variable (IV) in a linear setting. The authors propose a new method, 2SLS, that combines two modules: treatment regression and outcome regression. The CB-IV algorithm is based on a multiplicative assumption on the additive separability of noise, which is a well-studied result in the literature. The main contribution of the paper is the theoretical analysis of the bias-variance trade-off of imbalanced treatment distributions in the presence of unmeasured confounders and the confounding bias of nonlinear IV regression variants. The paper also provides a balanced representation of the confounder balancing for treatment effect estimation based on the balanced confoundingers representation. The experimental results show that the proposed CB- IV algorithm performs better than state-of-the-art methods such as IV regression and confounding methods in the setting of IV regression."
SP:fdb68c39fce254b73310a3101b2fe97ba47e69fe,"This paper studies the problem of few-shot image classification in the linear regression setting. The authors propose a new gradient descent algorithm, called MAML, which is based on stochastic gradient descent steps. The main idea is to learn the optimal solutions for a set of easy tasks optimal solutions, and then use these optimal solutions to train two-layer neural networks. The paper shows that the proposed algorithm achieves better performance than non-adaptive learning (NAL) in both easy and hard tasks. The empirical results show that the MAMPL outperforms NAL in both the hard tasks and in the easy tasks."
SP:e8143c7880c16ee9ce7a544e0fd80f001b1b4f9f,"This paper studies the problem of semi-blind source separation in sparse BSS. Sparse Blind Source Separation (BSS) is a well-studied problem in real-world applications such as astrophysics, remote sensing, etc. The authors propose a Proximal Alternating Linearized Minimization (PALM) algorithm, which is an extension of the learned Learned PALM (LPALM), which is used in the unrolled source separation setting. Unrolling PALM uses the learned PALM hyperparameters and the variables in the learned LPALM to learn the hyperparameter choice. The proposed algorithm is shown to achieve better separation quality than the standard unrolled algorithms. "
SP:7716315001949ab88c8a216302fe51bae872fc87,This paper proposes a Legendre Memory Unit based model with implicit self-attention. The proposed model is based on transformers with a power-law relationship between the model size and the sequence length. The authors show that the proposed model has better performance than LSTMs with the same loss. The paper also shows that the model is able to learn a sequence of words in a sequence with global self attention. 
SP:832f422b3554e89702e13c8c5690ee26f2289e3b,"This paper studies the problem of unsupervised keypoint detection using GANs. The authors propose LatentKeypointGAN, a two-stage GAN with internal conditioning on the space keypoints. The keypoint embeddings in the keypoints are generated by the appearance embedding of the image content. LatentkeypointGAN is able to learn the interpretable latent space by re-positioning the key points in the image. The paper also proposes a GAN-based method for unsupersupervised learning of keypoints in the latent space. Experiments show the effectiveness of the proposed method. "
SP:9206ae6e31077569313838504ef6daa89ad3b59c,This paper studies the problem of non-perturbative analysis of signal propagation in deep fully-connected neural networks with mean field formalism. The authors propose a new layer normalization method for deep fully connected neural networks. The proposed method is based on a combination of an initialization scheme and an activation function. The method is shown to improve the initialization variances of residual networks.  
SP:2177be818b5843c580c787f1b2d725154846feb6,This paper studies the problem of finding optimal step sizes for stochastic gradient descent in the presence of inherent noise. The authors propose a new line-search method for the full-batch loss with step sizes that are close to the optimal update step size. The proposed approach is based on a piece-wise constant learning rate schedule and is shown to outperform SGD in terms of validation and test accuracy. The paper also shows that the proposed approach outperforms line search approaches in Deep Learning across models. 
SP:62233782f9046c85617d9ccfe8427eae7d1c9da7,"This paper proposes a statistically consistent method for unnormalized probabilistic models based on noise-contrastive estimation (NCE). NCE is based on the exponential loss in the flat (loss landscape) loss landscape. The noise distribution of NCE can be used as the noise distribution for NCE. The exponential loss is used for eNCE, which is an extension of the NCE in the exponential family. The authors show that normalized gradient descent can be applied to NCE, and show that it can improve the performance."
SP:ceba6c1421b2d03863007fdaf029b8b946519c1b,"This paper studies the problem of differential privacy in distributed machine learning with noisy information. The authors propose a distributed SGD algorithm based on parameter-server architecture, where the model is trained using a distributed learning algorithm. They provide an approximate convergence guarantee based on (α, f)-Byzantine resilience to Byzantine faults in the distributedSGD. They also provide a theoretical guarantee for hyperparameter optimization for DP and BR. Finally, they show that the proposed approaches can converge faster than DP, BR, and DP. "
SP:bc783f0c829f90931535e63687d13172879631b3,"This paper studies the problem of query code snippet editing in the context of support and query code snippets. The authors propose a deep learning approach to solve the code editing problem, where the goal is to find a common pattern for each query code, and then use support exemplars to generate edit representations for that common pattern. The proposed learning approach is based on a multi-extent similarities ensemble, where each editing exemplar is used to generate an editorial pattern that is then used as a support exemplar for the query code. The similarity-ranking error estimator is then applied to the edit representations generated by the multi-expectation similarities ensemble. The results show that the proposed method outperforms non-composite baselines on C # and Python datasets.  The authors also propose a language-specific grammar for abstract syntax trees, which can be used for query and support sample matching."
SP:ca0c4bdb02f7d939fb6de38b6b446ced4b5984a0,"This paper studies the problem of generating high-level structure in deep generative models for realistic sequence data (e.g., text and music). The authors propose a novel approach to capture the global structure of a generative model by using relational constraints on the relational constraints of the model. The relational constraints are learned by a program synthesis algorithm. The authors show that the proposed approach is able to capture both local coherence and global coherence of the models. They also show that their approach can capture the high -level structure better than state-of-the-art. "
SP:692ae0c583a1585eff1a7d9c0d3b51b7879611cc,"This paper studies the problem of set-to-hypergraph prediction in the setting where hyperedges are not available. The authors propose a new training method for iterative refinement, which is based on the idea that the hyperedge can be represented as a set of positive edges. The paper also proposes a new model that is able to learn the contributions of each set-of-hypergraphic model. The proposed model is evaluated on a variety of tasks, including particle physics, biological systems, combinatorial optimization, and scaling problems such as run-time complexity. The results show that the proposed model can achieve better performance than state of-the-art in terms of efficiency and constant memory usage."
SP:e3481fb6d8d1aa45d6ed4a454e781f5a2c30c57e,"This paper studies the problem of gender bias in facial recognition. The authors propose a post-processing method for training models with biases. It is based on a shallow neural network, called Ethical Module, which is a combination of deep embeddings in a pre-trained model and the representation power of a deep learning algorithms. The paper also proposes a new von Mises-Fisher loss for the latent space. The proposed methodology is shown to achieve better performance than bias mitigation."
SP:3fb5dcc8b8fb731e09c14b16480cada1c7ccfaa7,"This paper studies the problem of class-incremental learning (CIL) in the context of knowledge distillation (KD), where the goal is to distill the KD loss from new class data to old class data. The authors propose a phase model to learn the old class knowledge from the new class knowledge. The evaluation function is a combination of a reinforcement learning algorithm and a free image stream (e.g., Google Images). The authors show that the new image stream can be used as a substitute for the placebo data in KD loss. The paper also shows that old class exemplars with a large memory budget can be learned from the image stream. The proposed method is evaluated on a number of higher-resolution benchmarks (ImageNet-1k, ImageNet-Subset) and compared to other top-performing CIL methods. "
SP:506e0a888c03a955b708464eed3670c04baf4912,"This paper proposes a new approach for modeling discrete structure in Energy-based Models (EBMs) by sampling from discrete distributions. The approach is based on the Markov Chain Monte Carlo (MCMC) and it uses an informed proposal to learn the energy changes of a Markov chain Monte Carlo with local updates. The authors propose a path auxiliary algorithm based on composition of local moves, which can be applied to any EBM. The proposed algorithm is evaluated on high dimensional discrete data for deep EBMs. The results show that the proposed path auxiliary algorithms outperform generic samplers and discrete models in both sampling and inference."
SP:4b466277aa5561a80c48d5e72559de4ce95f228b,"This paper proposes a new neural probabilistic inference system called Variational Predictive Routing (VPR) for learning the latent representations of video features in a temporal hierarchy. The idea is to learn the spatiotemporal hierarchy of the video features from sequential data, and then use the learned representations to train hierarchical generative models with layerwise representations. VPR learns the organisation of representations in the model and the event detection mechanism based on the learned latent representations. The hierarchical renewal process is applied to continuous data. The VPR is able to learn event boundaries for timeagnostic rollouts. Experiments on several video datasets demonstrate the effectiveness of the proposed framework in model-based reinforcement learning. "
SP:459ef2e6bd7638020955dbb4d8ae1098619f7b95,This paper studies the problem of image retrieval with global features. The authors propose a re-ranking process to extract global features from the original images. They show that it improves the performance of local feature learning by using spatial and channel attention and intermediate supervision. The proposed approach is evaluated on Oxford and Paris datasets and shows that it outperforms the RANSAC algorithm for local feature matching with convolutional neural networks. 
SP:487cc308a1e8ee078c54b2158bcae47e920e73f8,"This paper proposes a new algorithm called RotoGrad for negative transfer, which is an extension of Pytorch implementation. The main idea is to use shared network parameters to learn the gradient magnitude of the gradient directions, and then apply it to the gradient magnitudes. Multitask learning is an important problem in applications domains such as computer vision, reinforcement learning, and multi-label classification. The authors show that RotoGr outperforms existing methods on a variety of complex problems such as CelebA and computer vision tasks on the NYUv2 dataset."
SP:050cd8319d84a1bd8c2ccb930ba69b33c8fb6e60,"This paper proposes a model fusion framework for pre-trained neural networks based on soft neuron association for Layer-wise model fusion with optimal transport. The proposed framework, CLAFusion, is based on the cross-layer alignment for heterogeneous neural networks with a number of layers of neural networks. The authors show that networks trained with OTFusion on heterogeneous data are able to achieve better performance than networks trained on homogeneous data. The framework is able to perform layer-wide model fusion using dynamic programming, and it is also able to learn residual networks with finetuning process. Experiments on the CIFAR10 dataset demonstrate the effectiveness of the proposed model compression and knowledge distillation in the teacher-student setting."
SP:f764eae15cd083fdb4eb2af09ac64c2d878a454f,"This paper studies the implicit regularization of overparameterized deep networks in the context of supervised learning in the offline deep RL setting. The authors propose DR3, a new implicit regularizer based on stochastic gradient descent (SGD) for supervised learning. DR3 is based on the explicit regularizer, DR3 HYPONYM, which is a special case of SGD in the supervised learning setting.  The authors show that DR3 improves the performance and stability of DR3 in unlearning, robotic manipulation, D4RL domains, and Atari 2600 games.   "
SP:6fd793b27123bf80504e2ad5957455b7ec311612,"This paper proposes HyperDQN, a new algorithm for deep RL based on RLSVI for obtaining posterior samples from a non-linear neural network trained with Q-values. The proposed method uses a probabilistic hypermodel, a meta model, which is a combination of the base model and the probabilistically hypermodel. The hypermodel is used to generate approximate posterior samples for the Q-value functions for the exploratory action sequences. The posterior samples are then used for exploration. The exploration method is evaluated on SuperMarioBros in the Atari suite and shows that the proposed method outperforms DQN with a maximum human-normalized score, and outperforms exploration bonus and randomized exploration methods."
SP:b428383660928374c953f659ea1e05852dbdcd6e,"This paper proposes a new approach to learn causal representations from observational data. The authors propose a new learning procedure based on a hypothetical causal graph to learn mutual information measures between the cause, effect and spurious correlated variables in the representation. The proposed model is evaluated on a variety of downstream tasks, including image classification and recommender systems. The results show that the proposed approach improves the generalization ability and reduced sample complexity of causality-inspired learning with a counterfactual loss in optimization. "
SP:1258c05a80a17949b50e6dae13deea1d2235f456,"This paper proposes a federated learning scheme called ProgFed, which is a distributed learning scheme that uses edge devices to train a model. The authors propose a progressive training framework called ProGFed, where each edge device is trained on a limited network bandwidth, and the model is trained using a combination of gradient compression and distillation. The asymptotic rate of Progfed is shown to be a good trade-off between the computation and communication costs of the proposed models. The proposed training approach is evaluated on a variety of tasks, including simple classification, medical image segmentation, and convolutional neural networks. The experiments show that the proposed approach performs better than compression and other existing architectures such as ResNet, ConvNets, VGG, and U-net."
SP:8cdaa6e0dafd750ebdb5d7a4c1987a042400662f,"This paper studies the problem of adversarial attacks on Deep neural networks. Adversarial training is an important problem in deep neural networks, as it can be used to improve the performance of the model. The authors propose a new method to reduce the adversarial Rademacher complexity of deep neural nets by using two-layer neural networks with a single layer. The proposed method is based on the product of weight norms, and the authors show that the proposed method can achieve better performance than adversarially trained weight norms."
SP:925d6bb051e9b384669fb695085b678c11f7c11a,"This paper proposes a novel approach to improve the performance of KNIFE-based estimators for differential entropy and mutual information in real-world tasks. The proposed method is based on high-dimensional synthetic data, and it can be used to train neural networks to perform well on a variety of tasks such as visual domain adaptation, textual fine-tuning, and textual fair classification. Experiments show the effectiveness of the proposed method."
SP:d2f3beac855f0d72c13552fecb2bdb9d42195df3,"This paper studies the suboptimality gap in reinforcement learning in tabular and deep RL. The authors propose Soft-greedy operators for exploration in action-value methods for reinforcement learning, such as   ε - greedy, softmax, and resmax. The main contribution of the paper is to show that these operators are suboptimal in practice.    The authors then propose a non-expansion of the exploration hyperparameter in softmax to allow it to be used for non-explanation.  The softmax policy is based on the state-action specific temperature of the softmax operator. It is shown that it is able to achieve better coverage of the states-space than resmax and softmax. "
SP:792ae8808aa6902758146aef1548c975492b833c,"This paper studies the problem of how to improve the performance of deep learning models in the presence of adversarial invertible transformation. The authors propose a new concept called ""learnability lock"" that can improve the learnability of a model using a learnability lock. The key idea is to use a universal transformation function to learn the class-wise perturbation of the model to improve its learnability on the dataset. The proposed method is evaluated on a variety of visual classification tasks."
SP:9af10703605e620e563241e2602a50b629f3d37a,"This paper proposes a new approach to learn missing features in graph neural networks (GNNs) for modeling relational data. The proposed approach is based on the minimization of the Dirichlet energy of the diffusion-type differential equation between the graph and the edges of the graph. The authors show that the proposed algorithm, Feature Propagation, can be applied to real-world applications where features in the graph are not available in social networks. They also show that their approach can be used for graph machine learning applications where missing features can be useful. The experimental results show that this approach can achieve better performance than existing methods on common node-classification benchmarks."
SP:cbaa3f1379fa99159899d79ccb479c0187403aca,"This paper studies the problem of unsupervised learning with limited labeled data. Active learning is an important problem in the context of deep learning, where the goal is to learn a model that is able to learn from limited labelled data. The authors propose a novel heuristics for sample selection strategies based on the fact that the core set of the unlabeled data pool has a discrete Wasserstein distance. The core set is an integer optimization problem, and the problem is formulated as a Generalized Benders Decomposition algorithm. The main contribution of the paper is to propose a new strategy based on latent features learned by unstructured learning. The optimization approach is shown to outperform existing baselines on three different data sets, and outperforms them in the low budget regime."
SP:4c72923f78ca6590dc11e10d1a2403076a583718,This paper proposes a method for assembling genomes using geometric deep learning. The proposed approach is based on the idea of manual inspection for genome reconstruction. The assembly graph is composed of a genomic sequence and a graph convolutional network is used to map the genome to the telomere. The dataset is generated from human genomic data. The model is trained using a greedy search algorithm to find the best graph topology. The authors show that the proposed graph machine learning algorithms can solve the de novo genome assembly problem faster than human handcrafted techniques. 
SP:24de906e4289c9073b6c55c747b0913b8df5e053,"This paper studies the problem of catastrophic forgetting in Continual learning with meta-learning. The authors propose a new meta-testing method based on experience replay (ER) to improve the performance of metacontinual learning algorithms. The ER is used in meta-training for continual learning representations, and the authors show that ER can be used for meta-test in the context of metatraining. The paper also shows that reservoir sampling can improve the replay buffer in the case of meta-learned Predictive Sample Selection, and that the proposed method can achieve better performance than state-of-the-art in the online-aware nature of OML."
SP:3c78454f053f74930979a8054cd7c8a34b6fe63d,"This paper studies the problem of multi-agent joint Q-learning with Decentralized Execution (CTDE) in the context of explicit credit assignment problem. The authors propose two methods to solve the multi-adversarial credit assignment in complex problems. The first method, called ECAQ, is based on centralized training, where each agent is given a set of Q-values and the goal is to maximize the Bellman optimality equation of the joint Q -value of the Q-value. The second method, CTDE, uses gradient ascent solution to solve this problem. Experiments show that the proposed method outperforms the baselines in credit assignment. "
SP:0d2b225ac697679d10df25f371b2a718d4949b42,"This paper studies the problem of adversarial robustness in the context of NeurIPS 2020. The authors propose a new attack framework called Greedy Model Space Attack (GMSA), which attacks the model space of a transductive adversarial model. GMSA is based on weak instantiations of the test-time input of the model, which is used to train the model. They show that GMSA can achieve better robustness than other defense mechanisms in terms of the threat analysis perspective. "
SP:e7024cae196fc5eb6a62d289a95d76b532b6a36c,"This paper studies the problem of batch normalization in the training of neural networks. The authors propose a new per-example training procedure where the gradient of the training step computation is approximated by a function class of the inference model. They show that the approximation can be improved by using identity shortcuts. They also show that batch renormalization can be used for small minibatches. Finally, they show that normalization can improve model accuracy."
SP:4aa42984fcb0fd66936d668477b2719ef5c427d4,"This paper proposes LoRA, a Low-Rank Adaptation (LRA) method for language model adaptation. LoRA uses a Transformer architecture with trainable rank decomposition matrices to learn the trainable parameters for downstream tasks. The authors show that LoRA achieves better performance than GPT-3 175B on RoBERTa with a small GPU memory requirement. "
SP:b77a00beb0802f47810b03d3c4aa24d92781414f,"This paper studies the problem of structured prediction with non-local constraints in CRFs. The authors show that CRFs with global arity constraints (i.e., nonlocal ones) are more robust to distributions with nonlocal dependencies than regular-constrained CRF (RegCCRF). The authors also show that models trained with these constraints perform better than RegCCRFs in terms of performance on downstream tasks.   The authors propose a deep neural model for semantic role labeling, where the constraints in the decoding are incorporated into the constraints of the training. They show that the constraints can be used to improve the performance of constrained decoding, and that it can be combined with the constraints from the deep neural network. They also provide a theoretical analysis of the CRF’s Markov assumption, and show that it holds for the output structures. "
SP:74c186a96c12adff178264aa84ace8d04dc7d725,"This paper studies the problem of camera-based physiological measurement. The authors propose two methods: 1) “endto-end” models, which are based on transformer or convolutional backbone, and 2) a “core” network with a computational budget of $O(\sqrt{T})$ where $T$ is the number of images. The main contribution of the paper is to propose two neural models, EfficientPhys, which combines preprocessing steps in neural models such as segmentation, normalization, color space transformation, and face detection. Experimental results show that the proposed models achieve better accuracy and lower latency on raw video frames."
SP:3003bab6e3f7e2e21cd6cf27ee7d483d877d9fb3,"This paper proposes Hardware-Aware Latency Pruning (HALP) for structural pruning of a network architecture. Structural pruning is a global resource allocation optimization problem in which the goal is to reduce the latency of the network architecture and improve the inference speed. The problem is formulated as an augmented knapsack solver, where the top-1 accuracy changes are computed as a reward maximization problem. The paper proposes two metrics to evaluate the performance of the proposed pruning: latency reduction potential and global saliency score. The latency lookup table is used to compute the latency reduction of the filter importance ranking and the global salency score, and HALP is also used to estimate the accuracy drop. The performance of HALP on ImageNet and VOC datasets for classification and detection tasks is compared with prior art on ResNet-50/-101 pruning and SSD pruning on VOC. The pruning efficacy and accuracy-efficiency trade-off between HALP and prior art are also compared."
SP:c44d676c09c8e5a70d73b21b507b41a422fec809,"This paper proposes GraphEBM, a molecular graph generation method based on energy-based models (EBMs) that can be used for both permutation invariance and multi-objective generation. The authors propose a learning strategy based on Langevin dynamics, where the energy function is defined as a contrastive divergence between the permutation and the objective function. The graphEBM is trained using compositional generation to generate molecular graphs that are invariant to permutation changes in the molecular graphs. The proposed method is evaluated on a variety of molecular graph discovery tasks."
SP:70e60fa5deef3e3ba77d05d0c3e0e7fbf396aa1d,"This paper proposes a new combinatorial search algorithm CROSSBEAM, which is based on a neural model to learn a hands-on search policy for bottom-up synthesis. The proposed approach uses the learned neural model as the search history and partial program executions to learn the search space. The authors show that the proposed approach can achieve state-of-the-art performance on three domains: string manipulation, logic programming, and string manipulation."
SP:daa044ffefe80bae16b014f60061d941ed8c2ba6,This paper studies the problem of minimizing the squared Bellman error in Deep Reinforcement Learning. The authors propose a functional regularizer to reduce the squared bellman error of the target networks during training. The proposed regularization is based on the up-to-date parameters of target networks with lagging parameters. They show that the fast-changing target Q-values improve the sample efficiency and improve the performance of target-network based methods in Atari environments. They also show that their approach is more efficient than the squared-Bellman error. 
SP:dd174014d056a7d2bc86ee99119841eafa62ed52,"This paper studies the problem of graph neural networks (GNNs) in the hierarchy of local isomorphism in graph subgraphs. The authors propose a new neural model called GraphSNN, which is based on the Weisfeiler Lehman test. The proposed model is able to learn the graph structures of the nodes in the graph by using a simple model. The model outperforms state-of-the-art methods on several benchmark tasks."
SP:beb9ba0261e176bfc50e9bf5bed2b6169d388285,"This paper proposes a new prediction interval (PI) method for uncertainty quantification based on retraining of neural networks (NNs) to improve the confidence level. Previous PI methods are based on the standard mean squared error loss for NNs, but they are over-confident PIs. The authors propose a new PI3NN method for training PIs with customized loss functions with sensitive hyperparameters, and fine tuning the well-calibrated PI. They show that their method improves predictive uncertainty quality and robustness compared to state-of-the-art approaches in OOD samples identification and in-distribution samples. They also show that the initialization scheme for PIs trained with the new initialization scheme can be used to identify OOD and PIs in the OOD identification challenge. "
SP:4b44a834e2212bacb4c2d9408a81f1efc76a670b,"This paper studies the problem of online meta-learning for complex and high-dimensional problems, where the input distributions are not known and the goal is to learn an intelligent system. The authors propose a new Fully Online MetaLearning (FOML) algorithm, which is able to learn functions such as trackers, detectors, and classifiers from deep networks. They show that FOML outperforms existing online learning methods on the Rainbow-MNIST, and CIFAR100 datasets. They also show that the proposed model can be adapted to new environments by learning algorithms such as gradient descent. "
SP:fbae35cb171b3a3eb7c5d4bc83881ed7c4a70aae,"This paper studies the problem of structural design of functional molecules in the chemical science and engineering task of molecular optimization, which is an important application in many applications such as drug discovery. Deep generative models and combinatorial optimization methods have been used in recent years to solve this problem. The authors propose a differentiable scaffolding tree (DST), which is a graph neural network (GNN) that can be used for gradient-based molecular optimizations based on the chemical graph structure. The DST is trained by brute-force enumeration, where each node in the graph is represented as a set of locally differentiable ones, and the derivatives of each node are represented by a graph parameters. The knowledge network is then used to learn discrete chemical structures from the graph parameters, which can then be used as input to the GNN. "
SP:61b59899cf6ae442d9f8f5226e79708a4280cfb2,"This paper proposes a knowledge-augmented approach to improve the performance of Personalized medical systems. The authors propose a patient representation for sequential information, which can be used to represent both disease and lab tests. The proposed solution is evaluated on two real-world datasets and shows that the proposed solution has better prediction errors than the state-of-the-art. "
SP:8623cebb515c4a736427449b46ad2cdf8b806b77,"This paper studies the problem of single domain generalization (SDG) in the context of real-world applications. The authors propose a CrossMatch approach to improve the performance of SDG methods for identifying unknown classes. CrossMatch uses an adversarial data augmentation strategy to train a robust model from the diversity of source domain. The model is trained using OS-SDG, where the source label space is the source domain and target domains are the target domains. The proposed model uses consistency regularization on the auxiliary samples to ensure that the model is robust to unknown class identification.  The authors show that the proposed CrossMatch improves the performance on several benchmark datasets for the OS- SDG setting. "
SP:126f8ffb855aa22eda4d681a499953879ed3679e,This paper proposes Trust-region methods for policy optimization in reinforcement learning with Kullback-Leibler divergence. The key idea is to use Lagrangian duality to encourage close-form policy updates. The authors show that Wasserstein policy optimization (WPO) and Sinkhorn policy optimization with Lagrangians can achieve better monotonic performance improvement than SPO and WPO with sample insufficiency. They also show that SPO is more efficient than policy gradient methods on tabular domains and robotic locomotion tasks. 
SP:999eacf6500c87205584a3256d7ca45b3016fb1c,"This paper studies the problem of forgetting in the context of learning trajectories in artificial neural networks. The authors propose a new forget-and-reluarn framework for iterative training algorithms for image classification. The main idea is to use a relearning step to learn the features of the model, and then use a forgetting step to remove undesirable information from the model. The forgetting operations are then used to train the algorithms with different forgetting operations in different stages of the training process. "
SP:2789859517b6624730b14a7e010444a72d3dd3ed,"This paper studies the problem of Batch RL in the offline-online setting, where the data-collection process is offline and the agent has access to only a small subset of the data. The authors propose a new offline-offline manner to train RL agents in a more efficient and scalable manner than existing RL agents. They show that batch RL agents can achieve sufficient coverage and a better policy than existing agents in this setting. "
SP:76625a25e770415599a34122110d61cb3b7e614c,"This paper proposes a new episodic training procedure for domain generalization (DG) based on episodic learning procedure for learning the domain shift in the presence of Y-divergence between source-domain samples. The authors provide a PAC-style generalization bound for discrepancyoptimal meta-learning, which is a combination of ERM and domain-invariant learning. The proposed algorithm is evaluated on DomainBed and DomainNet and achieves state-of-the-art performance on both classification and computational complexity. "
SP:6421a9759c766641fd8c128a249f1a9c5699d19c,"This paper studies the problem of PSPACE-hard planning problems, where the goal is to find the optimal solution to a set of NP-complete domains. The authors propose two search methods, best-first search and Monte Carlo tree search, which are both based on deep reinforcement learning. The main idea is to use the policy and value networks in the DNN-based best-faster search, and use random restart strategies in the Monte-Carlo tree search. The paper shows that the two search algorithms have similar cost distribution, and that the cost distribution of the search algorithms can be improved by using the value network in the policy network. "
SP:84c415bc0f120d1997289f91661ff74e7297d3bd,This paper proposes a new method for meta-imitation learning from human demonstrations. The proposed method is based on the adaptive loss to learn a meta-policy from human videos. The method is evaluated on a variety of vision-based tasks and shows that it outperforms the baseline. 
SP:fedf5c75e83d6ab41ef9d5daa9054ffe4e424ec2,This paper proposes Adaptive Optimizers for Over-parameterized deep networks for classification and ranking problems. Adaptive optimizers such as Adam are gradient-based optimizers that are able to adaptively tune the weights of the networks in the weight space. The authors show that adaptive optimizers can achieve better generalization performance than SGD in the image classification domain with weight decay (WD) and normal hyper-parameters tuning. The main contribution of the paper is to provide a theoretical analysis of the effect of tuned regularization on the network weights. 
SP:819df8d847a99f13ed5efdcabae8b464c12b464b,"This paper proposes a new model for equivariance in group equivariant architectures. The model is based on the symmetries between edge orientations and face poses of a camera. The distribution is rotated MNIST. The authors show that partial and full equivariances can be obtained by equivarient networks such as Partial G-CNNs, which are able to achieve a full-equivariance. The proposed method can be applied to discrete groups, continuous groups, and continuous groups with rotations. "
SP:0c0ca9df96f1fa2eb8b83a47d0d5964590fef290,"This paper proposes a new Markov chain Monte Carlo (MCMC) for approximating intractable distributions with Langevin dynamics.  The authors propose a deep latent variable model called Langevin autoencoder (LAE) which is based on the latent space EBM. The inference model learns the latent variables from the prior distribution of the latent variable. The latent variable is a prior distribution over the energy-based model. The stationary distribution is used to train the ALD. The authors show that ALD can be used for scalable inference on large-scale datasets, and that it is able to achieve better performance than LD and AVI-based methods. ALD is also able to learn target distributions in both conditional and unconditional cases.   The experiments show that LAE outperforms existing non-amortized MCMC methods on a variety of datasets including SVHN, CIFAR-10, CelebA-HQ, and toy datasets. "
SP:5631097031c7e599bdeae64366ffa6e4558837c6,"This paper studies hypergraph reasoning in large domains. The authors propose a structured neural network that can be used as a structured hypergraph neural network to learn logical rules in the context of logical reasoning. The proposed model, called SpaLoc, uses a sparsification loss on the intermediate layers in the SpaLoc model to learn the grounding of relationships using sparse tensors and finite-domain quantification operations. In addition, a training and inference-time sub-sampling is used to improve the performance of SpaLoc. The sampling and label calibration paradigm is based on information-theoretic measure information sufficiency. The paper shows that SpaLoc achieves state-of-the-art accuracy and efficiency on several real-world knowledge graph reasoning benchmarks."
SP:9657121b01c51f78c00d06b47d3e8d678dd85d54,This paper studies the problem of differentiable sorting and ranking in machine learning. The authors study the top-k classification accuracy of top-1 and top-5 accuracy of ImageNet models on ImageNet. They show that these two models are close to each other in terms of both the number of iterations and the number (number of iterations) of the training set. They also show that top-2 accuracies are better than top-3 accuracies. 
SP:cb3188f435c54a365890e20e4d582c250d919833,This paper proposes a method for approximate regularized problem with sparse transport plans. The proposed method is based on the Douglas-Rachford splitting technique. The authors show that the speed and accuracy of the proposed method are better than the Sinkhorn method in terms of both computation times and accuracy. The method also achieves a linear convergence rate for the OT problem with primal-dual stopping criterion. 
SP:9a087cc734a3e7f3ab848bef5e2eff37fe40f303,"This paper studies the distribution of distributions in Federated learning data. The authors propose a new dataset synthesis strategy for realistic simulations of generalization in federated learning. The main idea is to learn a meta-distribution over the local data distributions, which is then used to learn the performance gaps between the local and global data distributions. The performance gap is defined as the difference between the out-of-sample gap and the participation gap between the global and local distributions.  The authors then propose a semantic synthesis strategy to solve the performance gap. The proposed framework is evaluated on both natural and synthetic federated datasets."
SP:da0e8c89f343abfe500eb4c1968e418c2fb52ef6,"This paper studies the problem of self-supervision of pre-trained language models (PLMs) trained with supervised finetuning. The authors consider the few-shot setting, where the goal is to improve the generalization of the LMs. They propose two pre-training techniques for PLMs: (1) the BERT family, and (2) the PLMs trained with PLMs in the zero-shoot setting. They show that PLMs can achieve state-of-the-art performance on a variety of language understanding tasks, including GLUE, IMDB, and Amazon dataset."
SP:9817dccb1a121058b23a2ef825ed339cf8b53674,This paper proposes a new attention mechanism for tasks where the attention mechanism is trained with a sharpener module. The key idea is to learn the alignment between the attention and the representation. The proposed approach is evaluated on a variety of real-world scene text recognition datasets and shows that the proposed approach performs better than existing ones such as soft and hard attention.
SP:3913ed3b3cf6494368e3be6cacb637ff85f80ee6,"This paper studies the problem of combinatorial optimization problems such as the vehicle routing problem, where the apriori given number of available vehicles is a complex assignment problem. The authors propose a supervised deep learning framework to solve this problem. They propose a post-processing scheme to train the supervised approach. They show that their method outperforms state-of-the-art approaches."
SP:594a813c0d0baa66738b9c8331370f861ad3c416,"This paper proposes a new link prediction method for graph learning based on counterfactual inference. The key idea is to use the clustering effect between the observed graph structure and the correlated variables (e.g., clustering of nodes) as a proxy for the causal relationship between the variables. The authors show that the proposed method is able to learn the causal relationships between the two variables, and that it can be applied to a wide range of graph-based applications. It is also shown that the learned representations can be used to learn both observed and counterfactually links for graph representations. Experiments on several benchmark datasets demonstrate the effectiveness of the proposed graph learning method."
SP:48a7e50451b887f55be17b2662aa11ce18791cc1,"This paper studies the problem of unsupervised feature selection for ranking features. The authors propose a knowledge contrastive disTillation (SOFT) model that uses sparse attention matrix to learn the second-order relations between features, which is then used to select the best ranking features from a relational graph by graph segmentation. They show that SOFT outperforms state-of-the-art methods in terms of performance. "
SP:14bcae11aeede63f28d1b80c05ed18a01d3e3f3c,"This paper proposes a new multimodal variational autoencoders (VAEs) for the joint distribution of heterogeneous data such as vision, language, and language. The authors propose Mutually supErvised MultimodAL VAE (MEME), which is an alternative to semisupervised VAEs. The key idea is to use idiosyncratic representations in the recognition model, which are mixtures of mixtures and factorisations, to learn the modalities and the relatedness between data. The paper shows that MEME achieves better performance than existing baselines on a variety of metrics for partial and complete observation schemes. The proposed representations are also able to be trained with mutual supervision."
SP:e834a52cadebe5f125ce491273b4ad1146beae3f,"This paper proposes a new approach to explore options in a Reinforcement Learning agent to learn directed behaviors. Intrinsic Motivation is used to motivate the Reinforcement learning agent to explore the environment. Deep Explore Options is a new Deep Reinforcement LMs with unrelated intrinsic rewards. The authors propose a transitionselection algorithm called J-PER, which is based on the interest of multiple agents to learn an auxiliary task with intrinsic reward learning. The proposed architecture is able to learn a shared representation between the intrinsic and extrinsic rewards, which can be used to learn interesting behaviors in high dimensional spaces. Experiments on the Atari Suite show the effectiveness of Deep Explore options in both hard and easy exploration games. "
SP:41578dd1a4bdb043b3d68afa5f9cebb3e14f3907,"This paper proposes a method for learning Hamiltonian dynamical systems with high stiffness. The main idea is to use the stiffness-aware neural network (SANN) to learn the stiff and nonstiff portions of a dynamical system. The SANN is based on the stiffness index of the SANN, which is a combination of the stiffness of the Hamiltonian vector fields. The authors show that SANN can learn both the stiff-and-nonstiff components of a system with high energy. They also show that the accuracy of SANN outperforms state-of-the-art methods on the three-body problem and the billiard model. "
SP:bfb0a059eeb6f40a18fbd20c0eec5037a64ca09e,"This paper proposes a new multi-step computation method for the task of generating realistic text and synthesizing computer programs. The proposed method is based on the scratchpad method. The authors show that the proposed method can be applied to a variety of tasks, and that it is able to achieve state-of-the-art performance. The paper also shows that it can be used to train language models for multistep computations."
SP:e6c1a8b4bba287455dc9cf145b6bd1f04e2148a9,"This paper studies the problem of featurefool attacks on deep networks. The authors propose two methods to attack adversarial perturbations on deep image generators and an optimization objective to improve the performance of feature-level adversarial attacks. The main idea is to learn feature-class associations between natural objects in the input image and the target image, and then use them to train targeted feature -level attacks on the ImageNet scale. The proposed attacks are based on targeted misclassification, where the target is a natural image. The paper shows that these attacks are effective against “copy/paste” adversaries."
SP:873618263dc4246a39c44d0abfecfb5f688817e3,This paper proposes Simulated annealing (SA) which is a stochastic global optimisation technique for discrete and continuous variable problems. The main idea of SA is to use a SA optimiser with handpicked components to solve the problem. The proposed method uses a policy to learn the proposal distribution of the problem and the neighbour proposal distribution. The handpicked component is composed of a temperature annealed schedule and a set of neighbours. The authors show that the proposed proposal distribution is better than the existing SA baselines with hand-selected parameters. They also show that Neural SA outperforms the existing solvers in terms of solution quality and wall clock time. 
SP:cae31f7436920eb3946e3f5bca0ac88a73d7c3ec,"This paper studies the problem of non-stationarity in the learning process. The authors propose a notion called δ-stability measurement, which is a new notion for measuring the non-starity of a policy sequence. The key idea is to use the measurement indicators to measure the policy changes of agents, and then use the learned algorithms to estimate the KL-divergence between the two policies. The joint policy divergence is defined by the trust-region decomposition dilemma, where the joint policy is computed using a pairwise Markov random field, and the joint policies’ divergence is computed by a policy factorization based on mean-field approximation.  The authors then propose a Multi-Agent Mirror descent policy algorithm, called MAMT, which solves the non -stationarity problem using MAMR. The proposed method has a lower computational complexity than existing baselines on cooperative tasks.   "
SP:989b58167a15ae4fafbe27ff534d327991b6c4d7,"This paper proposes a self-supervised representation learning framework for audio-visual speech. Video recordings of speech contain both related audio and visual information, and the goal is to learn a speech representation that can be used for lip-reading and automatic speech recognition. AV-HuBERT uses transcribed video data and labeled data from LRS3. The proposed self-training is based on multi-stream video input, where the multimodal hidden units are represented as multi-batches. The authors show that AV-HuberT achieves better relative WER reduction than state-of-the-art approach on WER. "
SP:7c9eb8aa4a4dcb5965157d860e812d81654e3aa7,"This paper studies the problem of combinatorial optimisation in real-world applications such as logistics and natural sciences. In particular, it considers Reinforcement learning (RL), where the goal is to find the optimal solution to a set of problems with pre-solved instances. In this setting, graph neural networks (GNNs) are used to solve the decision step, and a pre-processing step is used to train the GNN. A recurrent unit is used for the fast-acting exploratory phase. The authors show that ECORD, an RL algorithm based on ECORD HYPONYM, can solve the Maximum Cut problem with SOTA. ECORD is also shown to be faster than other RL algorithms in terms of scalability. "
SP:f741d980c9c560a21298e947f1605dcbab7ceeac,"Discrete latent variables are an important part of the generation process of real world data. Variational Autoencoders (VAEs) are a class of VAEs with discrete latents. The authors propose a discrete variational method to approximate the latent states of the decoder network. The approach is based on a combination of two VAE mechanisms: amortization and reparameterization trick. The main contribution of the paper is a direct discrete optimization of the encoding model, which is a variant of direct discrete optimizer. The direct optimization can be seen as an extension of direct optimization in zero-shot’ learning, where the network weights are computed by gradient ascent.  The authors show that direct optimization is able to achieve better performance than direct optimization on large neural networks and smaller networks.  They also show that they can achieve better results than non-generative approaches.   "
SP:deb189d37bd51b92762ce259a106d9a9e9d81ea4,"This paper proposes a new unsupervised method called Controlled Effect Network (CEN), which is based on counterfactual measures of blame. The proposed approach is a reward-based task where the goal is to identify the controllable aspects of the environment. The authors show that CEN is a better exploration method than existing methods based on action-prediction. CEN can be used as an intrinsic motivator for reinforcement learning agents, and it can be applied to controlled effects. The experimental results show that it outperforms existing action-precision models."
SP:ea18d57904e25fd09ed0f6c9972029d78779a8a6,"This paper proposes a new model compression technique called network pruning, which is a combination of neural architecture search and knowledge distillation. The main idea is to regularize the structure-regularized pruning (SRP) by using filters to remove unimportant filters from the network. The authors show that it can be used to improve the performance of SR networks by reducing the number of residual blocks in the residual. They also show that SRP can be applied to image SR networks such as lightweight network SRPN-L and SRPN."
SP:0dee45001ae9600f485614dfe6874a516ac01db5,"This paper proposes a new model for few-shot learning methods based on sparsely labeled novel category data. The model is based on the abundantly labeled base category data, which is used to train a model on the sparsely unlabeled domain categories. The proposed framework is able to handle large domain shift by using a contrastive loss on the base categories data and a feature extracting backbone to learn the features. The masking module is used for target domain classification and the backbone is used as a classifier. The authors show that it can achieve state-of-the-art performance on the cross-domain few-hot learning benchmark. The framework is also able to perform better than cross-domains methods and meta-learning approaches. "
SP:92aa611d71a8da597358330d84fddbb90de2cf4f,"This paper studies the problem of generalization of neural networks with infinite width networks via Bayesian inference. The authors show that gradient descent can be used for generalisation of networks with finite width networks. The main contribution of the paper is to show that the implicit bias of architecture is a function of the width of the network, and that the NNGP posterior can be computed by gradient descent. The paper also shows that the average test error of gradient descent for functions with minimum a posteriori functions is the same as the error of chance. Finally, the paper provides a theoretical analysis of the effect of the implicit biases of architecture and gradient descent on generalisation."
SP:a0e3cf719a95bbc5aad2f663ba5a3169c316ee9b,"This paper studies the problem of cross-lingual transfer in the context of large-scale pre-trained multilingual representations. In particular, the authors study the cross-linking representation discrepancy between the two representations. The authors show that X-Mixup performs better than other baselines on the XTREME benchmark on text understanding tasks. "
SP:19f8cd8f0c274b6141ba097d2ebb6d18af0986fd,"This paper studies Byzantine robust distributed or federated learning, where the goal is to defend against attacks on heterogeneous (non-iid) datasets. The authors propose a robust algorithms for heterogeneous datasets using the bucketing scheme, and show that the proposed robust algorithms are robust against attacks using bucketing and robust algorithms with robust algorithms without bucketing are robust to attacks. They also show that under certain realistic assumptions, the proposed algorithm achieves a guaranteed convergence in the non-Iid Byzantine robust problem. "
SP:4d63513b9a1b9b9fc44a69b3d5679a8f48eb95e7,"This paper studies the problem of disentanglement in multi-task learning. The authors propose a new metric for disentangled representations, which is based on hard parameter sharing between the representations learned by automatically generated supervised tasks for neural networks. The paper shows that the proposed metrics can be used to evaluate the performance of different types of representations trained with neural networks, and that they can be applied to a wide range of tasks. "
SP:9851adb72e2918780f661f83f7da06eb866787be,"This paper proposes a framework for certifying Robust Policies (CROP) in reinforcement learning with adversarial state perturbations. CROP uses a local smoothing algorithm with Gaussian noise to estimate the Q-functions of the policy, and then uses adaptive search to compute the lower bound of cumulative rewards and the robustness certification criteria such as robustness and per-state actions. The authors provide tight certification bounds for the reward of a finite-horizon cumulative reward under adversarial attacks. The proposed methods are evaluated on a variety of Atari games and demonstrate the effectiveness of the proposed methods for empirically robust RL. "
SP:78da3c97182ec1baf6a131740bf7c91a9afb2fd2,"This paper proposes a new approach for conformal prediction in large-scale settings where the coverage property is not known. The proposed approach is based on a calibrated candidate set, which is used to reduce the model uncertainty in the presence of noisy candidates. The authors show that the proposed algorithm is able to achieve a true positive rate of $\epsilon$ with a small number of iterations. They also show that their algorithm can be applied to a variety of classification tasks including computer vision, natural language processing, and computational chemistry."
SP:b126d2f3c397633745c8833e22ace93a2470e963,"This paper studies the problem of learning ReLU networks with random initialization. The authors propose a new unit-length curve for the network, which is a function of the number of parameters of the neural network. They show that the complexity of the functions can be reduced by using this curve of outputs. They also provide upper bounds for the higher moments of the length distortion and the distortion of higher-dimensional volumes. "
SP:b3b6d0512edfca461ea295ee8665f7f226c45d57,"This paper studies the problem of learning policies in reinforcement learning (RL) problems with safety constraints and sparse rewards. Behavioral priors are commonly used in RL to learn policy primitives. The authors propose SAFEty skill pRiors (SAFER), a behavioral prior learning algorithm for safe policy learning with behavioral priors. SAFER uses offline data to learn the safety variable and abstract action, and contrastive training between safe and unsafe data to enforce the safety requirements. The paper shows that SAFER outperforms baseline methods for learning policies and policies with safety and safety skills in the inference stage. "
SP:a5dadb3ecc3caed3b9d9a68eda0d48a53c2d1ce2,"This paper proposes a multi-branch restoration model based on the Human Visual System, Retinal Ganglion Cells. The authors propose a new multi-branch architecture based on CMFNet, which can be applied to a variety of restoration tasks, including image restoration, image dehazing, deraindrop, deblurring, etc. The proposed method is evaluated on three different datasets and compared to other learning based restoration methods. The results show that the proposed method can achieve state-of-the-art performance on all three tasks."
SP:263b386beee44b0b45b6f6dc3cf80d020500be62,"This paper proposes a personalized federated learning (PFL) approach to tackle the problem of data heterogeneity in PFL. The authors propose a new approach called IT-PFLHN, which uses a hypernetwork module and an encoder module to learn a personalized model from unlabeled clients. The hypernetwork is a client representation of the personalized model and the encoder network is a prediction service. The proposed approach is evaluated on three benchmark datasets and compared to FL and PFL methods. The results show that it outperforms FL in terms of multi-task learning and domain adaptation."
SP:960d0a63a82593f6e72275b65f0501f0469d1924,"This paper proposes a conditional diffusion based generative model (RCDM) to learn representations from self-supervised models. The proposed model is able to achieve better generation quality than existing generative models, and is also able to generate representations that are more interpretable than neural networks. The authors demonstrate that the proposed SSL (backbone) representation can be used to learn SSL representations from a supervised representation and an SSL representation from an SSL model. The SSL projector embedding is also used to perform tasks such as classifications. "
SP:398899e6c86b4a2a17dfa5c2f4478811f4331c1d,"This paper proposes a well-celebrated streaming algorithm called Fp sketch, which is a variant of the well-computed streaming algorithm for frequency moments estimation. The key idea is to use the logarithmic factor of the non-private baseline as a proxy for the evaluation code. The authors show that Fp sketches can achieve better accuracy than DP baselines in terms of differential privacy guarantee compared to the standard DP baseline. "
SP:3253b13851b5a3b5e3c8c6e24891db05903a4e57,"This paper proposes a new paradigm for diverse strategies in complex RL environments. Reward-Switching Policy Optimization (RSPO) is a paradigm that uses trajectory-based novelty measurement for the optimization process. RSPO uses extrinsic rewards for policy optimization and intrinsic rewards for exploration. The learning policy learns a sampled trajectory from the sampled trajectory, and the goal is to maximize the intrinsic diversity reward between the trajectories learned by the two policies. The authors show that RSPo is able to learn trajectories that are more diverse than existing strategies, and that the learned trajectories can be used for exploration and policy optimization. Experiments are conducted on single-agent particle-world tasks, MuJoCo continuous control, multi-agent stag-hunt games, and StarCraftII challenges."
SP:e3ab3aa87ab023bd9949b99a17d4b6e26c1473c0,"This paper studies diffusion models, a class of generative models that can be seen as a combination of GANs and autoregressive models. The authors propose a new sampling process for the optimization procedure based on gradient rematerialization and reparametrization trick. The diffusion model is trained using flexible non-Markovian samplers (GGDM). The authors show that the sample quality scores of the GGDM sampler can be used to improve sample quality of the GAN, and that the likelihood scores obtained by the diffusion model can be improved by the proposed method.  The authors also show that their method can be applied to a pre-trained diffusion model as well as a fast sampler.  "
SP:7a7506f2b5500a573c0cfb8b0822e5ea725c886a,"This paper proposes a new lightweight model for P-Adapters, called P-Adapter, which is a combination of lightweight models (e.g., lightweight models) and LLMs. The main idea is to use LLM’s embeddings to generate a natural language prompt for the P-adapters, and then use the embedding layer of the LLMs to encode the factual information. The authors show that the PAdapters are able to achieve better precision and consistency than the baseline on natural language queries. "
SP:35cdf71f027cc5168b55cc34c64bfb2f3087d6f5,"This paper proposes a new continual learning task, Continuous Classification of Time Series (CCTS), where the goal is to learn the vital signs in a multi-distribution form. CCTS is an extension of one-shot classification, where the key idea is to train a model on a set of data distributions, and then use the learned model to predict the next time series. The authors propose a new concept, called Adaptive importance-based replay policy, which is based on Adaptive Multi-Distribution Extraction Policy (AMDP). The authors show that the adaptability of the Adaptive model training policy can be improved by adapting to different data distributions. They also show that their method can achieve better performance on real-world datasets than baselines."
SP:d9b74b749aa465496763d3a3a9bf3a53e800587e,"This paper studies the problem of language models with internal representations of past inputs. The authors propose to use approximate kNN lookup in the memory of the language models to improve the performance on a variety of benchmarks, including generic webtext (C4) and books (PG-19) for language modeling. Language models are trained using theorems from the literature, and the authors show that the model is able to perform well on these benchmarks."
SP:7a1bbf86c3fdb8738aa826ca330493e857d050ba,"This paper proposes a new masked language modeling (MLM) objective for models trained with energy-based sequence models. The authors propose a tractable sampling scheme based on the Metropolis-Hastings Monte Carlo algorithm. The sampling algorithm is based on two parametrizations: (1) the stationary distribution of the Markov chain, and (2) the probability distribution. The proposed approach is shown to perform better than undirected generation approaches. "
SP:011626ba4fafee13d4a30e3f13c1df5b7071a7f1,"This paper studies the problem of data augmentation in deep neural networks for NLP tasks. It focuses on low-data or classimbalanced regimes with labeled samples, where informative training signals are not available. It proposes an augmentation strategy for each task based on a learning data augmentmentation policy based on the learned augmentation policy. The proposed policy is based on learning a reward function to encourage the policy to perform well on each task. The paper also proposes a sample re-weighting scheme to improve the performance of the model. Experiments on text classification tasks show that the proposed augmentation schemes perform better than learning-based augmentation on the same task. "
SP:69d41a862ea189f72d4e8af2854e27b95a91fa41,"Meta-learning is an important problem in offline reinforcement learning (OMRL). The augmented state of the task identity is important for RL algorithms. The paper proposes to use the intra-task attention mechanism and inter-task contrastive learning objectives as well as a sparse reward for task representation learning. The proposed SOTA OMRL algorithms, FOCAL, are evaluated on a variety of meta-RL benchmarks. "
SP:ed86c60850d5c8302dcf1c2167db303e778fe681,This paper proposes a new inference-time improvement framework for parametric sequential generative modeling methods for the problem setting where the belief state of a partially observable Markov system is unknown. The authors propose two methods for belief state modeling in multi-agent settings: (1) belief fine-tuning (BFT) and (2) approximate dynamic programming to fine-tune the model parameters. BFT improves the accuracy of the belief model in the approximate public belief state search in imperfect-information games. It also improves the performance of the model when the dynamics model is trained with specialization.
SP:6150725599c10f0e26f0d7cb1fc04b5b227a4456,"This paper studies the problem of overparameterized neural networks. Sparse model training can be expensive due to the computational cost and slow training runtime. The authors propose a new method called Pixelated Butterfly, which uses sparse matrices as the sparsity mask. The proposed method uses a fixed sparsity pattern to train the network layers (e.g., attention, MLP). The fixed structure is composed of products of butterfly matrices. The paper shows that the proposed method outperforms dense MLP-Mixer and GPT-2 medium on ImageNet classification and WikiText-103 language modeling tasks. "
SP:136e31054a55abca840f6478491972023c2296cb,"This paper proposes a score matching method for controllable generative models. The key idea is to use the Markov chain as the class center of a conditional diffusion probabilistic model, and then use the score matching to learn the data distribution. The method is based on faster sampling. The authors show that the proposed framework outperforms state-of-the-art methods on CIFAR-10 and FID score for conditional image generation. "
SP:fc2196f1f4ecd864398fed6640ff3f8b19870763,"This paper studies the problem of domain generalization (DGD) approaches with fixed domain-invariant features and common hypotheses. The assumption is that the invariant hypothesis is invariant in the latent sub-spaces, and the label-informative features are invariant for the label prediction task. The authors propose a new method, LASSO, which uses label-influential features to learn latent subspaces. The proposed method is evaluated on a variety of DG benchmarks and shows that it achieves state-of-the-art generalization performance."
SP:6e8e5bdeb77e3cafe1975da8411fb65118955d14,This paper studies the problem of reproducing kernel Hilbert space (RKHS) in the context of independent sampling. The authors propose a kernel thinning (KT) algorithm for estimating the probability distribution of a kernel with dimension-free guarantees. They show that KT can be used to approximate the RKHS in the case of a square-root kernel. They also show that the target KT has the same maximum mean discrepancy (MMD) guarantees as the squared-root KT.   The authors also provide some theoretical guarantees for the target and power kernels. 
SP:645c3f1864aa843d4899fc2406f694b5aab8460d,"This paper studies the problem of tree search in graph neural networks (GNNs), where the goal is to find a solution to a set of NP-hard problems. The authors propose a guided tree search algorithm based on the benchmark suite of weighted and unweighted variants of the open-source benchmark suite for the NP-Hard MAXIMUM inDEPENDENT SET problem. The proposed algorithm is based on a graph convolution network that learns a solution structure from random values, and then uses a GNN to train a solver based on reinforcement learning. The algorithm achieves competitive solution quality and extensibility in terms of code quality and code size. The paper also shows that the proposed tree search is competitive with other algorithmic techniques such as graph kernelization. "
SP:155ecd17d264a084b014abdfd0362146d8fb07e0,This paper studies the problem of quantization for compressing Convolutional Neural Networks (CNNs). The authors propose a new approach for activation maps compression for 1 × 1 convolutions in 1×1 convolutions of CNNs. The main idea is to use a hardware-friendly Haar-wavelet transform to compress the image compression. The authors show that the compression ratios and the computational savings of WCC with low bit quantization rates and low compression ratios can be improved by the proposed network architecture. 
SP:004865e6affad32403b7965493a53c8a7ffdda0a,"This paper studies the problem of learning in games with correlated and coarse correlated equilibria in normal-form games with sequential and simultaneous moves and imperfect information. The authors propose a new accelerated learning dynamics that can be used to learn correlated-and-covariant equilibriums in such games. The main idea is to use no-regret learning dynamics to learn an extensive-form correlated equilibrium (EFCE) with O(T 3/4)-approximate EFCE in the correlated distribution of play. Theoretically, the authors show that the accelerated dynamics can be combined with a structured Markov chain to provide a refined perturbation analysis for the stability of certain fixed point strategies.  The authors also provide theoretical guarantees for the prior rate of the learned framework of -regret."
SP:ee545ff83df4d7ff256ac61fbe0eb0765f52f1d5,"This paper proposes Action Quantization from Demonstrations (AQuaDem), a method for discretization of continuous action spaces using priors of demonstrations. The authors propose a discrete action deep RL algorithm to solve the continuous control problem in Reinforcement Learning (RL), where the goal is to maximize the maximum of the action-value function in the action space. They show that the proposed method achieves better sample efficiency than existing continuous control methods on a variety of hard manipulation tasks. The proposed method is evaluated on a number of different setups, including Imitation Learning, RL, demonstrations, and RL with human data."
SP:4b39279b98d6aa311bb49dd1384925f9d6f66c2d,"This paper proposes an adversarial style augmentation (AdvStyle) approach for hard stylized images. AdvStyle uses domain generalization to train a robust model on labeled synthetic (source) data. The style features are learned by using a channelwise mean of the style features. The adversarial image is trained using adversarial training, and the style feature is used to train the adversarial model. Experiments on synthetic-to-real semantic segmentation benchmarks show that AdvStyle improves the performance of models trained with AdvStyle in domain generalized image classification. "
SP:4a2e6d70b383e4941e0bc44e7e82972b22e26792,This paper proposes a neuromorphic gesture analysis system with high temporal resolution for event-based gesture data from Dynamic Vision Sensor (DVS). The key idea is to use a latent space representation to learn the similarity of mid-air gesture data. The model is trained using neuromorphic hardware. The experimental results on the DVSGesture dataset show that Hybrid GuidedVAE improves classification accuracy.
SP:2e66468a6b94177e54b0052b97713ee63902c278,"This paper studies the accuracy of neuron-based networks on tabular data. Deep learning is an important area of research in the field of machine learning, where the computational capacity of deep learning methods is limited due to the lack of computational capacity. The authors propose PyTorch implementation, which uses an annealing mechanism to perform S-HTE inference on the internal representations of ferns. The accuracy is evaluated on a classification and regression benchmark, and it is shown that it is better than the state-of-the-art. "
SP:b238db9252d83a13438bb747d70e635bb9945958,"This paper proposes a new offline RL method for learning value functions based on undirected stateonly experience. Latent Action Q-learning (LAQ) uses tabular Q-Learning to learn the value function in discrete Markov decision processes (MDPs). The refinement of the action space of a value function is based on a latent-variable future prediction model. The value functions are learned using ground truth actions. Value functions are then used to train domain-specific low-level controllers.  The paper shows that LAQ outperforms competing methods in three environments: 2D grid world, 3D visual navigation, and imitation learning oracles.  "
SP:108ebe9045a9e2b8b5aba8352733782462db8a81,"This paper proposes a new model-parallel training algorithm, SWARM Parallelism1, for large models for deep learning applications with low-latency and high-bortwidth interconnect. The proposed models are based on GPU clusters and are trained with dedicated GPU clusters. The authors show that the proposed approach is able to reduce the network throughput of a large Transformer language model trained with a swarm of preemptible T4 GPUs by using shared parameters. They also show that SWARM can be used to train temporary randomized pipelines. "
SP:91d2f094d5481651b554f58aecc2a6207057a47c,"Offline reinforcement learning with a fixed dataset is an important problem in real-world applications. Offline reinforcement learning for policies trained on the fixed dataset can be challenging because of the transition dynamics in offline experiences. Offline and online experiences can be biased due to the online transition correction (OTC) based on sampling probabilities. To address this issue, the authors propose to use the online data to train an agent policy that is more similar to the behavior policy than the policy learned on the offline data. The agent policies are then trained using OTC for online tuning and online execution. The authors show that OTC improves the deployment efficiency and sample efficiency compared to other baselines on a variety of tasks. "
SP:d0e650d568214481b07a0452ec606ccbf6d05410,"This paper studies the computational footprint of Deep Neural Networks (DNNs) training with 4-bit quantization. The authors propose a new unbiased quantization for quantized neural network training, which is based on logarithmic unbiased quantized (LUQ) method for both the forward and backward phase. The proposed method is able to handle the low precision format in the training process, and it is also able to be applied to intermediate neural layers. Experiments on ResNet50 on ImageNet show that the proposed method performs better than high precision fine-tuning and a variance reduction method."
SP:f2862d1f987164ed6c3c375cd8962e57c369373b,"This paper studies the problem of meta-learning Boolean functions in the natural world. The authors propose to use threshold meta-learners (Prototypical Networks, Matching Networks) with a linear embedding dimension to learn the functions. Polythetic classifications based on shared patterns of features are shown to outperform monothetic classifications in terms of the number of features. The main contribution of the paper is to show that attentional classifiers trained on these problems with the linear embeddings can be used to learn better performance on other problems with attentional models for misclassification. The paper also proposes a selfattention feature-selection mechanism to select the non-discriminative features to be used in the meta-training process. "
SP:e1e513fef25d29e17cdadd1b36d932a8ad8897cd,"This paper proposes a continuous acoustic channel for learning emergent communication in multi-agent reinforcement learning for Human communication. The continuous communication channel is used to learn emergent language with channel characteristics that are useful for emerging language. The communication channel consists of discrete symbols and a lossy continuous channel. A vocoder is trained to generate a continuous waveform of the communication channel, which is then fed to a deep Q-learning platform. The platform is trained using deep reinforcement learning to learn the continuous signalling. The proposed environment and training methodology is evaluated on a variety of tasks in the messaging environment."
SP:0e6ff65ba4a3df35947d1b6f4d438612088d90a0,"This paper studies the problem of NLP backdoor attacks on NLP models trained on downstream language tasks. The authors propose a new task-agnostic backdoor attack called BadPre, which can be applied to any pre-trained NLP model. The key idea of BadPre is to train a malicious model to misprediction the target language, and then use the backdoor to train downstream models using a transfer learning process. The proposed approach is shown to improve performance on downstream NLP tasks."
SP:58d3ecb4a1906251e79ad883aa97cc2502642658,"This paper proposes a new framework for skill discovery in the evolving or expanding environment. The goal is to learn a set of skills that can be used to improve the performance of the agent in the future. The proposed framework is based on the idea of reward-free, unsupervised discovery of skills, where the agent is given a sequence of tasks and a reward that encourages the agent to perform well in each task. The authors show that the learned skills can improve the skill quality in both evolving and static environments. "
SP:2c6595408f5ec95537eaf555e5fe3d992b58c222,This paper proposes a new convolutional neural network architecture based on regular quadrilateral convolution kernels. The proposed LPSC is able to learn local spatial structures in a single-layer receptive field. The network architecture is based on convolutions in the convolutions of the convolution kernel. The authors also propose a log-polar space pooling technique to improve the performance of the proposed convolution. Experiments on a variety of tasks demonstrate the effectiveness of the new network architecture.
SP:7791f96b1eef277a9133975507a750d9e7c6b8ff,"This paper studies the non-vacuous bounds for NNs under PAC-Bayes theorem. The authors show that the IIW-based information bottleneck is a major bottleneck in ML research, and propose a new algorithm for the approximation of IIW. The algorithm is based on IIW’s property for deep learning, and can be applied to NNs with varying batch sizes, overparameterization, and noisy labels. The paper also shows that the optimal weight posterior of the MCMC-based algorithm can be approximated by the PIB of NNs (PIB). The authors also show that IIW compression and generalization can be used to improve the performance of the NNs. "
SP:a733847ade77ffbf38760fc79da17893dea8d53f,"This paper studies Indiscriminate data poisoning attacks against deep models. The authors propose to use perturbations that are linear separable, i.e. imperceptible to normal features. They show that these attacks are more effective than the standard synthetic perturbation, and that they are more robust to the imperceptibility of the data. They also show that the linear separability of these attacks is the main reason for their effectiveness. Finally, they show that such shortcuts can be used to improve the performance of deep models in practice. "
SP:7b50be406138ad01db3ee112899f622637896fe9,"Offline policy optimization is an important problem in real-world decisionmaking problems. In this paper, the authors propose a new estimator called Importance sampling for offline policy evaluation, which uses function approximations for value functions and process models. The algorithm is based on a per-state-neighborhood normalization condition. The proposed method is evaluated on a healthcare-inspired simulator and a logged dataset. The authors show that the proposed method achieves better overfitting than batch reinforcement learning algorithms."
SP:c976752a55b9ff47dc63c95a9fd7b51a81e8a42e,"This paper proposes a multimodal embedding model, CoLLIE, which is a model for continual learning. The model is based on a transformation function to learn new language embeddings and images in the semantic space. The authors show that the model performs better than few-shot learning on zero-shot and continual learning than it does on similar language use. "
SP:d3371b322acfc321ee79a2e1b438d82644872fa4,"This paper studies the problem of object captioning (NOC) in the context of image captioning models for visual data. The authors propose a new framework that combines the VLAF2 for Visual-Linguistic Adequacy, Fidelity, and Fluency with linguistics to improve the Fidelity and the fidelity. The proposed method is evaluated on the nocaps dataset and compared to BERT and CLIP. The results show that the proposed method improves the SPICE scores of human baseline and provides better caption evaluation metrics than existing captioned models. The model also performs well on both quantitative and qualitative analysis. "
SP:9f3b6486662d80350d77a4b060d4a5b8b22a6130,"This paper studies few-shot learning problems where the goal is to learn representations for classification. The authors propose two special-purpose algorithms to solve these problems. First, the authors propose a clustering property called neural collapse, which is a regularization term for the features of overparameterized classification networks. Second, they propose a classifier to learn the representations of the classifier. The main contribution of the paper is to use these two foundation models to learn feature maps for transfer learning. "
SP:624c95d9ce1ee4b66274e858e2da22bef6b052c7,"This paper proposes a method for point cloud reconstruction based on 3D scanning. Point cloud reconstruction is an important problem in 3D imaging, and this paper focuses on the problem of 3D point cloud. The main idea is to use a 3D sparse stacked-hourglass network to perform densification and denoising. The proposed method is based on the 3D dense stacked-hoursglass network. The method is evaluated on the ICL-NUIM, ScanNet, and ShapeNetPart datasets."
SP:34a81ca65131576d4c14332a4e9eb3a4c344cab7,"This paper studies the convergence of Graph Convolutional Networks (GCNs) on graph-structured data. The authors show that the convergence rate of GCN training with stale features and stale feature gradients is better than vanilla distributed GCN with a smoothing method. They also provide theoretical convergence guarantee for large-scale GCNs, and show that PipeGCN has a better convergence rate than full-graph training methods in terms of accuracy, training efficiency, and model scalability. "
SP:8302d49558ee0f16392d623d4e604e92db10d041,This paper studies the problem of test time robustification in deep neural networks with in-distribution test points. The authors propose two methods for test time adaptation: (1) ResNet-50 models and (2) a robust vision transformer model. The proposed approach outperforms prior augmentation and adaptation strategies in terms of model evaluation. The main contribution of the paper is a theoretical analysis of the model robustness in the presence of distribution shift in the model training process. The paper also provides some theoretical guarantees for the assumptions. 
SP:a985de5e940ff3a4160b378201b8c02f68d1914a,"This paper studies the problem of RL and planning with a single objective. The authors propose a new template, called MSE, to learn a model for RL and a policy for planning. The goal is to minimize the expected return of the lower bound of the objective mismatch between the model and the policy. The paper shows that the proposed algorithm (MnM) achieves better performance than GAN. The main contribution of the paper is to show that MSE can be used to train a model that can learn a policy that is more accurate than the current state-of-the-art. "
SP:a469fbcdc20b11dff4085b6fbc384e77f33cd37d,"This paper proposes a model combination approach for behavioral cloning based on human decision making. Behavioral cloning policies are learned from single observations and observation histories rather than from observation histories. The key idea is to use instantaneous observation for coarse action, and then use a control policy to predict the next state of the environment based on the current state. The authors show that this approach is able to learn a coarse-to-fine “imitation-learned” imitator, and that it can be combined with other baselines such as CARLA autonomous driving, MuJoCo continuous control tasks, and images. Experiments on the CARLA driving task demonstrate the effectiveness of the proposed method. "
SP:95c4533b5d1a865c4cc6a54615e7ad6357bdaad1,"This paper proposes a model-based meta-learning method called DyAd. DyAd is based on the idea that deep learning models can be used for dynamics forecasting. The authors show that DyAd has two parts: an encoder that predicts time-invariant hidden features, and a forecaster that predicts the shared dynamics between the encoder and the forecaster. The encoder is trained with weak supervision. The forecaster is trained using adaptive instance normalization and adaptive padding. The procedure is shown to have a lower generalization error than existing approaches. "
SP:ec70553cb0c27e5349c1b8cce6bcaa96a83bf050,"This paper studies the problem of monocular 3D object detection in 3D scene understanding. The authors propose a new annotation process for weakly supervised monocular3D detection, which is based on manually annotated 3D box labels for LiDAR point clouds. The proposed method is evaluated on KITTI and shows that the proposed method outperforms fully supervised methods. "
SP:34217c6a8ca43b8eeb9ddc83d6f1f0af05918984,"This paper proposes a deep Transformer model called CHARFORMER, which is a combination of a GBST and a block scoring network. The main idea is to learn a set of characters that represent the latent subword representations of the input language. The authors show that the proposed model is competitive with existing models in terms of competitive quality. The experimental results on English GLUE and multilingual, and noisy text datasets show that CHARFORMer performs better than other subword-based models."
SP:d26d25f2ef23a89a2c139d0dd87c4c86fddcff5e,"This paper studies the problem of detecting backdoor attacks on deep neural networks (DNNs) in the presence of a backdoor in the training data. The authors propose a new adversarial objective for backdoor detection based on an optimization perspective. The proposed solution is based on the idea of adversarial extreme value analysis (AEVA), which can be applied to backdoors in black-box neural networks. The main idea of AEVA is to use monte-carlo gradient estimation to estimate the singularity of the adversarial map of the backdoorinfected example, which is then used to train a DNN with a backdoor trigger. The paper shows that the proposed approach is able to detect backdoor attacks in a variety of black-board hard-label scenarios."
SP:c6dbca0ed0799b7fec21777606f6f809eb2d8c48,"This paper proposes a new Kullback-Leibler divergence criterion, KLoS, which is based on the class-probability simplex. The authors propose to use in-distribution samples to improve the performance of the classifier in the context of uncertainty estimation in OOD training data. The main idea is to use evidential models to learn the secondorder uncertainty representation of the OOD data, which can be used as a second-order uncertainty measures. The paper also proposes a refined criterion based on an auxiliary neural network, KloSNet, that is trained with the KLoLSNet. The empirical results show that the new class-wise divergence measure is better than existing measures, and that the proposed measures are more robust to misclassifications and OOD samples. "
SP:8b4f3916dca4e627931558e14836749bd4a6792f,"This paper proposes a semi-supervised algorithm for learning a linear classifier with datadependent features from unlabeled data. The algorithm is based on natural distributional assumptions on the distribution of patches in a low-dimensional manifold. The authors provide a lower bound on the dimension of the patch distribution, and show that it can be used to train CNNs with natural image data. "
SP:7f2f354d5cc1030bd97bd716aea8fe1d3af86b25,"This paper studies the representation capacity of Graph Convolutional Networks (GCN) in the face images. The authors propose a new algorithm called Ada-NETS, which is based on clean graphs. The main idea is to learn the kNN relations in the feature space of kNNs, and then use these relations to train GCN-based methods to learn face graphs. It is shown that this graph can be used to learn GCNs with clean yet rich edges. It can also be used as an adaptive neighbour discovery strategy to find edges in the graph. The paper also shows that Ada-NetS achieves better generalization than state-of-the-art methods on public clustering datasets. "
SP:a3bc8e26f55e78f07de081ca85865afd52b6ae4a,"This paper proposes a new approach to cross-domain representation learning for cross-dataset cross-data evaluation. The proposed approach, Unit DRO, is based on distributionally robust optimization (DRO), which is a general framework for learning robust models with protected demographic features. It leverages demographics information such as domain information, camera IDs, and domain information to learn the features. The authors show that under the convex condition of KL DRO with the uncertainty set, the proposed approach outperforms existing baselines such as large-scale DG ReID and cross-domains ReID on a reweighted dataset. "
SP:62c1f734b7f6c6e7d5114da6f37c9e3cdda73a23,This paper studies the problem of molecular property prediction with Graph Neural Networks (GNNs) in the context of oversmoothing. The authors propose a novel noise correction loss to prevent overfitting in GNNs. The proposed noise correcting node-level loss is a regulariser that can be applied to any node latents. The paper shows that the proposed methods can be used to improve the performance of the regulariser. The experimental results on Noisy Nodes and non-spatial architectures on the Open Graph Benchmark (OGB) datasets demonstrate the effectiveness of the proposed GNN toolkit for 3D molecular property detection. 
SP:24a1b44f37f8eedbab2047fb84600a322d289f3b,"This paper studies the set2vec problem, where the goal is to learn a vector representation of the set embedding feed-forward network. The authors propose two approaches to learn the complex interaction between set elements: (Set)Transformers and (Optimal Transport Kernel Embedding) embedding (OTKE). The proposed approaches are based on self attention, which is an extension of self attention in self attention. The proposed framework is based on the single-step EM with balanced assignment constraints on the E-step. Theoretically, the authors show that the mixture distribution of the i.i.d. samples is a function of the variable number of feature vectors in the mixture, and the mixture parameters can be represented by a mixture set data fitting framework. ExpectationMaximization (EM) steps are used to approximate the MAP-EM steps. The paper also shows that the proposed approach outperforms OTKE and prior-induced model regularization on two tasks."
SP:b4f7b660b84fe7702fbcc8a96c192abc3a64f045,This paper proposes a contrastive analysis (CA) setting where the goal is to find the most informative features for unknown downstream tasks using unsupervised feature selection in the CA setting. The proposed method is based on the machine learning community for feature selection. The authors show that the proposed method outperforms state-of-the-art methods in a number of unsupersupervised and semi-synthetic datasets as well as real-world biomedical datasets. 
SP:bc4f69f23aba2034cbf14cb31bdc7a991806bbf6,"This paper studies the problem of early stopping in over-training neural networks. The authors consider the case of linear regression models, where the model is trained on a set of features and the goal is to generalize the learned model to new tasks. They show that the optimal early stopping time and the model dimension can be used to improve the generalization of linear models. They also show that early stopping can improve the performance of “double descent” in the presence of a deep neural network. "
SP:ede87b50cd9c4a6533f17e3e5ddfaaeaaac71dcf,This paper proposes a new quasi-Newton method for learning policy gradient algorithms for reinforcement learning (RL) problems. Regularization of the entropy functions of the policy gradient algorithm is used to improve the stability of entropy functions for exploration. The proposed algorithm is a natural policy gradient (NPG) algorithm with Shannon entropy. The authors show that the proposed method achieves Newton-type quadratic convergence with respect to state-of-the-art algorithms in both synthetic and industrial-scale examples. 
SP:3535504f7599b1f39239f7cd8e09acd40fa8fdf0,This paper studies the problem of grounded language understanding in Text-based games (TBG). The authors consider two problems: generalization and sample efficiency in TBGs. The authors propose a general method based on case-based reasoning based on a on-policy neural agent to solve TBGs using deep reinforcement learning (RL) methods. They show that the proposed approach can achieve better out-of-distribution generalization than existing methods. 
SP:9a5dd0148a15dc5b4d2bc6762dfe8a8991f8866c,"This paper proposes a two-stage method for learning multi-sense embeddings from pre-trained contextual language models for language understanding tasks with resource-constrained systems. The proposed skip-gram-like framework is based on the BERT model, which is a combination of the output layer of BERT and the sense disambiguation mechanism of the model. The approach uses the distribution over word senses from BERT to learn the sense information for the multi- sense embedding. The method is evaluated on contextual word similarity and sense induction tasks on multiple benchmark data sets. The results show that the proposed method performs better than existing methods on the embedding-based topic model (ETM). "
SP:e4cdba0fc7cd7f440d4436219f3959d8d5e2ad28,"This paper studies the problem of 2D image and 3D point-cloud understanding using computer vision models. The authors propose a new architecture for training a neural net model to generate images from a neural network and then transfer the images to a 2D model. The model is trained using a combination of image-pretrained model and point cloud model, where the 2D convolutional filters are used to generate the 3D points and the point cloud is trained with batch normalization layers. The proposed model is evaluated on few-shot classification, and shows that the FIP improves the data efficiency and finetuning efforts of existing models. "
SP:dc99c307931ae9c5d4a1b998dc94cfc6ac78d11f,"This paper proposes a method to train an autoregressive generative model on sequential data for tasks with sequential data. The proposed method is based on an energy-based learning objective, where the goal is to learn the energy scores of the network. The method is motivated by the observation that, in chain-style conditional modeling, the distribution of the learned energy scores can be highly correlated with the number of samples in the MCMC process. The authors propose a constraint to ensure that the joint distributions of the two distributions are close to each other. They then use this constraint to train the model by importance sampling, which is a common practice in the literature. They show that the proposed method can improve the performance of their method on the exposure bias problem and the long-range coherence. They also show that their method can also improve the temporal coherence and the performance on various benchmarks such as language modeling, neural machine translation, and image generation."
SP:51e748c55bd4134047098559577fa3f37aa7433a,"This paper studies the problem of robustness against adversarial attacks in deep neural networks (DNNs). The authors propose an adversarial training (AT) method to improve the robustness of a DNN-based classifier trained with adversarial examples. The AT-based methods are based on PGD-AT and TRADES, where the pointwise adversary is used to train the worst-case adversarial example. The authors then propose a unified framework for Wasserstein distributional robustness using AT methods and risk functions. They show that the AT methods are more robust than their AT counterparts. "
SP:f192046ea8ad61bfc8e05a0ddb90a8bd15b4640b,"This paper studies the problem of unsupervised representation learning for multivariate time series with complex dynamics and sparse annotations. The authors propose a new contrastive learning framework, Bilinear Temporal-Spectral Fusion (BTSF), which combines data augmentation techniques for contrastive training with dropout for capturing long-term dependencies and capturing global context. BTSF uses an iterative bilinear temporal-spectral fusion module to learn representations of time series based on cross-domain interactions, and then uses dropout to augment the time series by segment-level augmentation using time slicing. The paper shows that the proposed method outperforms state-of-the-art methods in terms of alignment and uniformity."
SP:ef54840009afb095c67bbbc29a7824c20a375ee8,"This paper proposes a new algorithm for optimizing the learning rate of deep neural networks by gradient descent. The main idea is to use the gradient descent step as a learning rate for the first and second-order gradients of the weight gradients. The authors show that this approach can be applied to any learning rate, model architecture and batch size. They also show that it can be used as an optimizing scheme for learning rates, learning rate and model weights. "
SP:263c787361cd6d4443ce516d389c694d0fe44b28,"This paper proposes a continuous meta-learning method for sequential multi-task learning. Prior meta-reinforcement learning algorithms, such as continual meta-policy search (CoMPS) and continual continual learning (CoL) are not well-suited for offline meta-training. The authors propose a new method, CoMPS, that combines prior continual learning with off-policy meta-regression methods. The proposed method is evaluated on a variety of continuous control tasks, and shows that CoL outperforms prior continual training."
SP:2bd729b7aa045bf74e31229c9e76e57af36e804b,"This paper studies the “backdoor” poisoning attack against classification models. The authors propose to use a threat model to poison the poisoned classifier by using adversarial examples to fool the classifier. The proposed procedure is based on Denoised Smoothing, which is a well-studied technique for backdoored classifiers. The paper shows that the proposed method is able to generate triggers that are more sensitive to human interaction in smoothed adversarial images. Experiments on two high-resolution datasets, ImageNet and TrojAI, show that this approach can achieve better performance than the state-of-the-art on modeling trigger distributions."
SP:e58ab0e3cff6b18013145a1a99cfa9da0a3d872f,"This paper studies the problem of distilling unconditional GANs in the heterogeneous distillation scenario in the context of content generation tasks. The authors propose a new distillation method, called StyleGAN2, which is based on the distillation of a GAN with a style module. The idea is to distill the semantic information from the teacher and student model using an initialization strategy to ensure that the output consistency between the two. The proposed approach is shown to achieve better performance than existing GAN distillation methods in the distilling styleGAN2 architecture."
SP:2c2231743fa33b95828c6615263954ce1c05f95d,This paper proposes a new methodology for offline algorithms in online settings. The authors propose a multi-task learning model to learn behavioral structures from graphs. The proposed methodology is evaluated on synthetic data and historical stock market data.
SP:ee3a21d2fb8a073099aa200129a53c31f3b6561d,"This paper studies the problem of estimating uncertainty estimates for Bayesian models with Gaussian Processes (GP). They consider the case where the latent function is Gaussian, and the model is trained with sparse GP approximations. Sparse GPs and variational inference are used for inferring q. The authors show that the proposed method can achieve better training and prediction times than sparse variational GP approaches. They also show that it is possible to learn inducing points locations from a neural network. "
SP:f20c99b441545047a16ae524cc2e317b2c3787a2,"This paper proposes a new protocol for secure (Bhinetolerant) decentralized training with Byzantine tolerance in distributed training algorithms. The authors consider the hardest problems in deep learning, such as scientific collaborations and volunteer computing, where the number of clients is large and the communication overhead is high. They show that such systems are vulnerable to Byzantine attackers in image classification and language modeling. They propose a protocol that is robust to Byzantine and Sybil attacks, and provide theoretical bounds for the resistance. They also show that the proposed protocol has communication efficiency in terms of communication efficiency. "
SP:93894f20ab2593e5237b6972fef9fe63e96af89a,"This paper proposes a mesh-free Lagrangian method, Smoothed particle hydrodynamics (SPH), for the problem of weaklyand strongly compressible turbulence in astrophysics and engineering applications. The authors use physics based parameters and Neural Networks to learn universal function approximators for SPH informed fluid simulators. They use forward and adjoint based sensitivity analyses to perform gradient based optimization. The learning algorithm is based on a mixed mode approach, where the Neural Network parameters are learned in a hierarchy of models, and the physical structure of the physical symmetries are learned from training data. The physics informed learning method is applied to inverse problems with physically interpretable parameter space, and is shown to improve generalizability on time scales and Reynolds numbers."
SP:d11b81f9ab414fcf430a03cd70c2d3246b678474,"This paper proposes Mix-MaxEnt, a new approach for training a deterministic neural network. The proposed approach uses an entropy maximization regularizer to learn a predictive distribution over the embedding space of a class clusters. The approach is based on a cross-entropy loss, where the samples are generated by a convex combination of images. The key idea is to generate out-of-distribution samples with high entropy regions, which are then used for maximum likelihood estimation using a data-dependent regularization. The authors show that the proposed solution achieves better classification accuracy and uncertainty estimates than Mix-maxEnt on a variety of real-world datasets such as CIFAR-10, CifAR-100, and Cifar-100. "
SP:365490b872464f00634dc7a50d024fceaf0a61ee,This paper proposes a self-supervised autoencoder called Latent Image Animator (LIA) that learns a structure representation for driving videos from driving videos. The proposed model is a combination of two existing approaches: Generative Adversarial Networks (GANs) and auto-encoder animating images. The main contribution of the paper is to use the structure representation from GANs to train an animation-model with modules for the extraction of structure information from the video. The model is evaluated on two TED-talk datasets and one VoxCeleb dataset. The results show that the proposed model performs better than state-of-art methods on all three datasets. 
SP:86f9f89f84e117c86478b9afaf087f65524f5472,"This paper proposes a new meta-learning framework, called MLTI, which is based on data-adaptive meta-regularization. The main idea is to learn a set of meta-training tasks that can be used to improve the generalization performance of the proposed MLTI. The proposed approach is evaluated on a variety of tasks, including image recognition, pose prediction, molecule property prediction, and medical image classification. The MLTI framework outperforms state-of-the-art strategies on all three datasets. "
SP:73d577e9c4f4af5e11a9e5bdb583ee0f50a315f5,"This paper proposes a new approach to improve the fairness of downstream predictors trained on encoding sensitive data. Fair representation learning is a well-studied problem in the literature, and this paper proposes to use Fair Normalizing Flows (FFN) to reduce the maximum unfairness of an adversarial downstream predictor. The proposed FNF is based on normalizing flow, which allows the encoder to learn the statistical distance between the latent representations of the sensitive groups. The authors show that FNF improves the fairness guarantees of learned representations with respect to the sensitive attributes. The FNF also improves the properties of FNF in terms of interpretability and transfer learning. "
SP:404d5643327f60f0f06f820033a56081f9e01900,"This paper studies the problem of learning subgraph patterns on graphs for graph-based tasks. The authors propose a low-dimensional representation for graph neural networks (GNNs) based on the node-centric message passing mechanism in GNNs. They show that they can be used for complex structure matching and subgraph isomorphism counting, and they show that COUNT-GNN is a GNN that can be applied to subgraphs. The paper also proposes a backtracking framework to reduce the computational cost. The main contribution of the paper is to provide a graph representation for each edge in the graph, which is then used to encode the fine-grained structural information in the edge. The graph representation is used to represent the graph level, and the edge is used for encoding graph structures. The edge-centric message passing scheme is also used for the edge level. "
SP:5a94f18156ab2949c86de45fcf0de2e16977eebb,"This paper proposes Agnostic Personalized Federated Federated Learning (APFL), a loosely constrained federated learning framework for personalized labels. The proposed method combines Similarity Matching and Kernel Factorization (SimFed) to achieve task-level similarity using locally learned knowledge. The method is evaluated on both singleand multi-domain datasets and shows that the proposed method is able to achieve state-of-the-art performance in terms of knowledge collapse and information loss on heterogeneous knowledge. "
SP:97f30bea31eccef6c770fbce1e14fd6d2493a178,"This paper proposes an Object Dynamics Distillation Network (ODDN) to learn object dynamic representations from raw video input. The key idea is to use object-centric representations of scenes as object-centric representations of objects. The object dynamics are represented as abstract entities, and the abstract entities can be represented as physical events. The ODDN uses a relation module to learn the object-pair interactions between objects, and then uses it to learn dynamic representations of the objects, such as velocity. The proposed approach is evaluated on video events reasoning and video prediction. The model is trained using object dynamic clues, occlusion, objects collision, and reconstruction. The results show that the proposed model achieves state-of-the-art scene decomposition quality and segmentation quality."
SP:ba8e50d1fa9cb824fa3f76c0c691997cd151d760,"Graph neural networks (GNN) are widely used in graph-based learning tasks, where the goal is to learn a set of nodes for a given task. The task is to predict the link/motif between two nodes in a graph. The nodes are represented as a set (e.g. link/mosaic) of nodes, and they are represented by random node features, node distance features, and node features. The problem is that the number of node features can be very large, and the complexity of the solution can be quite high. The authors propose to use positional encoding (PE) techniques such as Laplacian Eigenmap and Deepwalk to encode the positional features in GNNs. The PEG is a mathematical analysis of the PEG layers and the node features in the GNN layers. The theoretical analysis shows that the permutation equivariance of PEG has a significant effect on the link prediction and the generalization. The paper also shows that PEG can be used in real-world networks for link prediction."
SP:cf448479f68c3194c1a9e11729bf70d7cc2ae8fd,"This paper proposes LaMer, a text style transfer framework based on large-scale language models. LaMer uses non-parallel datasets to train models with weak supervision. The authors show that the intrinsic parallelism of the data can be improved by imitation learning refinement and MLE training. The paper also shows that LaMer can learn parallel expressions from scene graphs. The model is evaluated on a new task called sentiment & formality transfer and political stance transfer. "
SP:8f7b2d1020d9e527118b8fb816760c13b0d0bfcb,"This paper proposes a new paradigm for representation learning on knowledge graphs (KGs) called Multi-Hop logical reasoning, which combines one-hop link prediction and logical queries. It uses a hyper-relational modeling paradigm to model KGs in a fine-grained context, where the key-value pairs of typed edges are represented by classical, triple-based graphs. The authors show that the proposed algorithms are able to answer complex queries in hyper-Relational KGs, which is an important problem in real-world KG applications. The proposed approaches can be applied to approximate query answering (QA) in the context of Graph Neural Networks and query embedding techniques. The main contribution of the paper is the use of qualifier pairs in the proposed approaches, which can be used to improve the performance of the QA. In particular, the proposed method is able to generate queries that are query patterns that are similar to the query patterns used in QA, which are then used as qualifiers for the queries. "
SP:5f8b58424a1a8eeb72217e75189d6f773a298a7a,"This paper proposes a new method called DYHPO, which is based on Bayesian optimization for the gray-box setup. The authors propose a surrogate for Gaussian Processes with multi-budget information, where the acquisition function of the surrogate depends on the learning curve dynamics and the hyperparameter configurations. The paper shows that the proposed technique can achieve better performance than existing Gray-box hyperparameters optimization techniques, and can be applied to multibudget search mechanisms.  The authors also show that the performance of the proposed method is comparable to other hyper-parameter optimization baselines."
SP:99d3d94e3af5d2dc7b92c00ac1345d1d2dd0d15b,This paper studies the problem of image compression with rate-distortion. The authors propose a non-deterministic calculation for the post-training quantization of the image compression model. The main idea is to use deterministic inference for the Gaussian mixture models. They show that the proposed methods can achieve better performance than the state-of-the-art image compression models in a cross-platform consistent manner. They also show that their training and fine-tuning based approaches can achieve comparable performance. 
SP:85d0df515e9e555f3ea1c21d607304dfaeae69c0,"This paper proposes a fully unsupervised Noise Reconstruction and Removal Network for denoising scanning electron microscopy images with nanoscale resolution. The proposed architecture is based on gated recurrent units, which can be used to remove noise from the sequential data. The network is trained with a combination of partially supervised and fully supervised training. Experiments show that the proposed network performs better than supervised approaches on 3D electron microscopeopy data sets. "
SP:e6275b0b103fa90dcebcdd3d3c14c830c3402972,"This paper studies the problem of label trick use cases in graph neural networks (GNNs) and label propagation. The authors consider two tasks: node property prediction and node classification. In the former, stacked message-passing layers are used to generate predictive embeddings with neighborhood information. The latter is used to propagate unlabeled nodes by spreading label information through a parameter-free diffusion process. The training pipeline is based on statistical properties of the features and labels, and the label trick is a deterministic training objective. The main contribution of the paper is to provide a data-fitting term for the label leakage issues, which is a regularization factor that depends on the graph structure. The paper also provides an Open Graph Benchmark (OGB) leaderboard."
SP:b6cbc3661f9c440687c3dd01ee35a118c87db377,"Theory of mind (ToM) is a well-studied topic in human intelligence and machines. ToM agents are trained to solve tasks with predefined roles (e.g., speaker-listener scenarios). In this paper, the authors consider the multiagent environment SymmToM, where the agent is given a grid world and the goal is to solve a set of tasks. The authors propose a strategy based on the theory of mind to solve SymmtoM using the ToM model. They show that the proposed strategy is able to achieve better performance than existing multi-agent deep reinforcement learning models on a variety of mental states. "
SP:f8ce83805eee46c6c196e8477bf10d8d7f7e0f46,"This paper studies the problem of unsupervised object detection in a robot vision system. The authors propose a new zero-shot object detection algorithm, called Zero-Shot Object Detection (ZOD), which uses visual data collecting and processing technology to train robots to detect objects in a manufacturing environment. The proposed method is based on a manufacturing setup, where the robot is given a set of orientations and illumination, and a vision system is trained to predict which objects are in the scene. The object size level of the object is then used to train the vision system to predict the object size. The method is evaluated on indoor scenes and outdoor scenes, including a car, a bike, and people. The results show that ZOD outperforms the state-of-the-art on the dataset."
SP:aa1dcd9217270010f16a00004facede942efea17,"This paper studies the problem of video prediction, where the goal is to generate high-resolution (256x256) videos with an autoregressive latent video prediction model for high-fidelity future frames. Video prediction is a very important problem in the video prediction literature, and this paper proposes a video prediction tool based on the idea of autoregression of the latent space of the image generator model. The authors propose a method that combines top-k sampling and data augmentation to improve video prediction quality. The proposed method is shown to outperform state-of-the-art approaches on several video prediction benchmarks. "
SP:7f57896afd63bc869d2db6ddf7abbeaa71daae11,"This paper studies vision-specific inductive biases in Vision Transformers (ViTs) for image recognition. The ViT architecture consists of generative adversarial networks (GANs), and the ViT generators are trained with regularization methods to improve self-attention. The authors show that the ViTs trained with these regularization techniques can outperform GANs trained with ViTs. The proposed approach is evaluated on three datasets: CIFAR-10, CelebA and LSUN bedroom."
SP:bbae3afcaea0a2e54904cb8daaed7df4fe37da6e,This paper studies the problem of image generative modeling with variational autoencoders. Good likelihoods are known to be competitive for high-dimensional image data distributions. The authors consider the case where the entropy of natural image distributions with visually imperceptible information is bounded by the number of visually perceptible bits in the likelihood signal. They show that models trained with competitive likelihoods can achieve good sample quality in terms of both the performance of the models as well as the quality of the training data. 
SP:bfed56018134ec66cde9a7e958df964d4cca3164,"Diffusion probabilistic models (DPMs) are widely used in generative models. In this paper, the authors consider the inference of DPMs, where the score function is computed by a score-based model. The authors propose a training-free inference framework, called Analytic-DPM, to estimate the variance in the reverse process of a DPM with optimal reverse variance and optimal KL divergence. The analytic forms of the optimal reverse variances are derived from the Monte Carlo method and the pretrained score-by-model. The lower and upper bounds of the estimate are obtained by using the analytic-DPM as the log-likelihood of the DPM. "
SP:3f935ba5784c3e86db72421426bc479061af1a4b,This paper studies the problem of automated medical image diagnosis in the context of convolutional Neural Networks (CNNs). The authors propose a transformer-based models for medical image classification and segmentation tasks. The authors show that vision transformers (ViTs) perform better than CNNs and transformers on a variety of tasks including medical image benchmark datasets and tasks in a supervised and self-supervised setting. They also show that CNNs perform better on ImageNet compared to CNNs. 
SP:a64e0535f268901e38fd51e027c612ebcdbae1a4,"This paper studies the problem of pretraining Neural Language Models (NLMs) in the presence of semantically related non-related non-neighboring sentences. The authors propose a new neural architecture, which is based on the pretraining example design. The pretrained NLM is trained with NLM training heuristics for both pretraining and fine-tuning stages, and it is shown that it performs better than the standard pre-trained NLM.  The authors also show that the self-improving representations of self-optimized NLM can improve the performance of NLM pretraining on Natural Language Understanding tasks such as sentence representations and open domain question answering abilities."
SP:59066956fa2e423d5f2d2ea4f91c4ddf6afd4683,"This paper proposes a new optimization procedure called Learning to Optimize (L2O), which uses neural networks to learn optimization rules using meta-training. The L2O model is based on a holistic symbolic representation and analysis framework. The authors show that the optimization rule can be learned by the neural networks, and that the scalability of the optimization procedure can be improved by the use of the learned optimization rule. The paper also provides a theoretical analysis of the interpretability and memory overhead of the L2Os. Finally, the authors demonstrate that the L1O model performs better than human-designed and tuned optimizers on large-scale problems."
SP:54dfeb363beee9959aecc9e0853ff06e43bd94e4,"This paper studies the problem of randomized smoothing based defenses against adversarial attacks. The authors propose a new defense strategy based on the Neyman-Pearson Lemma, where the adversarial perturbation is modeled as Gaussian noise, and the goal is to learn a policy that is robust to the perturbations. The defense strategy is based on an adaptive RL adversary, which is trained with the same procedure as the adaptive RL adversaries.  The authors show that the proposed method is robust in a variety of environments, including Pong, Cartpole, Mountain Car, Freeway, and Pong. "
SP:e0f9add5fde18eaab0eeb2b10b14928acc8ec5b8,"This paper studies the problem of predicting the target domain accuracy from labeled source data and unlabeled target data. The authors propose Average Thresholded Confidence (ATC), a new threshold for predicting the model’s confidence. The proposed method is based on toy distributions, and it is shown that ATC outperforms prior methods on a variety of datasets including MNIST, CIFAR, BREEDS, ImageNet, WILDS, and dataset reproduction. "
SP:e748bf6ee653087cae825df32a8546f9ccebfcf1,"This paper studies the partial distribution matching (PDM) problem in the registration problem, where the goal is to obtain a good registration for a transformation. The authors propose a method to solve the large scale PDM problem with partial Wasserstein-1 (PW) discrepancy. The PW discrepancy is derived from the Kantorovich-Rubinstein duality of the PW discrepancy, and a neural network is trained to generate PW discrepancy using the neural network. The paper shows that the proposed PWAN performs better than state-of-the-art methods on several point set registration tasks. It is also shown that the coherence regularizer can be used to avoid unrealistic deformations in non-rigid transformations. "
SP:f94f77696d100b2638fa2a6d82c8df47db3b6a36,This paper studies hyperparameter optimization (HPO) in machine learning models. The authors consider transfer learning for HPO and propose a new approach called Landmark Meta-features (DKLM) which is based on the Deep Kernel Gaussian Process surrogate. DKLM is able to learn the similarity between hyperparameters configurations in a contextualized dataset-specific similarity representations. The proposed method is shown to outperform stateof-the-art baselines on OpenML and HPO meta-datasets.
SP:e3c57f3589e8ab674644d900c14b3473cd71a23f,This paper proposes a new method for deep fake detection based on the fingerprinting mechanism. The key idea is to use a 128-bit fingerprint to identify the identifiable models. The authors show that the proposed method is able to achieve better performance than the state-of-the-art in terms of both deep fake and real-world datasets. 
SP:73bffd1a0856b80d29f7a2b2b68be57882531f07,This paper proposes a method for learning post-hoc explanations for black box models in classification and regression settings using tabular and text data. The main idea is to use model agnostic local explanations for similarity learners trained on tabular or text data to learn the feature attributions for the black box similarity learner. The proposed method is based on the idea that the similarity between two models is a submodular function of the (latent) factors of the model. The authors show that the proposed method can be used for learning the feature attribute for the explanation in the context of machine learning by learning the analogies between the two models. They also show that their method can also be applied to the healthcare utilization application. 
SP:6a3c4ae05d582f8896840483b08c735ced2976bc,"This paper studies the robustness of deep neural networks (DNN) against adversarial examples in the presence of perturbations. The authors propose a new ensemble-before-Smoothing strategy for bounded model-smoothing analysis. The ensemble models are trained with a diversified gradient and a confidence margin, and the authors show that the ensemble models achieve better certified robustness than a single model. The paper also shows that ensemble protocols are more robust than single ML model under empirical and theoretical defense approaches. "
SP:3002b29c27709780238876d8c3f81bbd6a0f8112,"This paper studies the problem of message passing Graph Neural Networks (GNNs) for learning with graphs. The authors propose a recursive pooling technique of local neighborhoods, where each node is represented as a subgraph, and each node in the subgraph is represented by a graph. The model is trained to learn subgraphs from the graph representations of derived (sub-)graphs, which are then aggregated to form the final subgraph.  The authors show that the proposed strategies and lower bounds on the computational cost and expressive power of higherorder GNNs are better than the state-of-the-art in terms of computational complexity compared to the higher-order gNNs. They also provide a near (matching information-theoretic lower bound on the counting subgraph's computational complexity, which is a result of sparsity. "
SP:5d0cbd84336caf5f31e1f98e11f6733230e4d792,This paper studies the problem of knowledge integration (KI) methods for pretrained language models (LMs) to extract factual knowledge from external knowledge in the context of LMs. The authors show that KI methods perform better than vanilla LMs in terms of catastrophic forgetting of already learned knowledge due to the lack of external knowledge. They propose a probe model based on Graph Convolution Simulator (GCS) to train knowledge-enhanced LMs such as K-Adapter and ERNIE. The GCS model is used in the KI process and it is shown that it is able to learn knowledge-augmented LMs with KI. The KI corpus is then used to train KI models that are able to capture factual knowledge.  The authors also show that the K-Adapters can be used to learn time-related knowledge such as relational knowledge from K-ADAM and K-ACADAM. 
SP:7e73948421e98307fceb69a316d8a4e7c4926cda,This paper proposes a new adaptation (inner loop) learning rate for fast adaptation in MAML. The adaptation learning rate of mixed linear regression is used in meta-learning. The authors show that the optimal adaptation learning rates for MAMM can be used to reduce the population risk of the initialization of the model. The empirical risk minimization (ERM) is also shown to be better than the empirical risk maximization (EMM) for initialization. 
SP:effbc85d89b1197d9c2abcaf5ff13864135dd6e1,"This paper studies the problem of source-free domain adaptation (SFDA), where the source-domain data is used to train a model on unlabelled data and the target model is trained on labelled data. The authors propose two methods to improve the performance of SFDA by using entropy-minimization techniques. The first method, Feature Restoration (FR), uses a bottom-up training scheme to train the FR. The second method, BUFR, uses a source model to learn the feature-space class-separation between the source and target data. BUFR is shown to achieve better accuracy and calibration on both real and synthetic data compared to standard SFDA methods."
SP:7d63034ec7e6a4f178681ff2a49feb485cd47116,"This paper proposes a distributed learning schema called Federated learning (FL) for model robustness. The authors propose a propagation approach based on batch-normalization statistics to improve the adversarial robustness of non-iid users in the learning setting. The propagation approach is based on adversarial training (AT) for centralized learning, where the FL users are highresource users and the FL process is decentralized. The proposed method is shown to achieve FL remarkable robustness on raw data. "
SP:42c7a79e58b6a9f776fa6ae928bd89c194f9303f,This paper studies the utility function of a game with a utility function. The utility function is defined as a function of the number of interactions in the game. The authors propose a transformer-like architecture for mapping symmetries between the network structure and the equilibrium actions. The proposed method is evaluated on both synthetic and real-world data for network games and shows that the proposed method outperforms existing methods in terms of network structure inference. 
SP:1c7b9157cf8c06ca771da78895fc3af969b0fb85,"This paper proposes a new relation prediction framework called ANalogy Subgraph Embedding Learning (GraphANGEL) which uses heterogeneous graphs for relation prediction. The graph pattern is used as a logical rule for explainable predictive models, and the inductive bias is used for generalization. The authors show that the proposed model is able to generate explainable heat maps of attention scores, which are more interpretable than existing models such as heterogeneous graph based recommendation and knowledge graph completion. "
SP:26ed25a7b42da2cf11b76a727102d8aa36d76657,"This paper studies few-shot learning in histology images. The authors focus on cross-domain tasks in real clinics problems, where the goal is to learn a few images from a set of well-labeled datasets and rare abnormal samples. They propose contrastive learning (CL) and latent augmentation (LA) to improve the few-shoot system by learning semantic variations between the labeled and unlabeled training data. They show that CL outperforms supervised learning and supervised learning in terms of generalization on the data. "
SP:badbe687258cd5c282ca167b1f6fbfc6b5400dbf,"This paper studies the problem of irregularly-sampled time series in Recurrent neural networks (RNNs) with continuous-time hidden states. The authors consider the case where the hidden state is a timecontinuous state, and the RNN is trained with the ODE solver. They show that the gradient of the gradient during training is a function of the memory compartment of the recurrent neural networks. The memory path of an RNN can be decomposed into a continuous -time dynamical flow, and it is shown that the memory path has constant error propagation. They also show that Mixed-Memory-RNN can achieve better performance than RNN-based counterparts on non-uniform sampled data with long-term dependencies. "
SP:4efd22f9122fa5856a9f4302eb6875fa0c414912,"This paper proposes BiBERT, a pre-trained BERT for Natural Language Processing (NLP) tasks where the goal is to reduce the computation and memory consumption of BERT. Previous compression approaches such as binarization are based on bitwise operations and 1-bit parameters, but the performance bottlenecks of binarized BERT are not well-studied. The authors propose a new method that uses Bi-Attention structure and DirectionMatching Distillation (DMD) scheme to train a fully binarised BERT model. The proposed method is evaluated on the NLP benchmark and compared with quantized and fully-bounded BERT models. BiBERt outperforms the baseline and the fully-binarized models. "
SP:619bd742e92bea6241852f5a9d2b7bacf13b393a,This paper proposes a method for keypoint detection and instance association based on Transformer. The key idea is to use the self-attention in the Transformer to learn the association information between the keypoints grouping and the instance association. The authors show that the proposed approach is able to learn an instance association with the help of supervising self-tweets. They also show that their approach can be applied to multi-person keypoint prediction and instance segmentation. 
SP:14750819593136fc9ef4efd032ab6f94dc5f6a02,"This paper proposes a new approach for sequential decision making in reinforcement learning (RL). The authors propose a new variance term, MV trade-off, to measure the Pareto efficiency of MV-efficient policies. The variance term is defined as the difference between the expected quadratic utility function and the expected value function of the policy. The authors show that the variance term can be computed by gradient estimation of the variance. The proposed approach can be applied to existing methods, and it is shown that it can achieve better performance than existing methods in terms of computational difficulties."
SP:f675b564b3a9c8626ce7944d752fa3e0d868428e,"This paper proposes a new approach to learn a mixture density network (MDN) for end-to-end learning for a communication system. The authors propose a test-time domain adaptation for the autoencoder system, which is based on a fully-trained channel model and an autoncoder. The encoder and decoder neural networks are trained in parallel, and the MDN channel model is trained on unlabeled data. The proposed method uses feature transformations to learn the channel distribution of the decoder and the encoder. They show that the proposed method has a lower error rate than the standard auto-encoder, and is able to learn an MDN with a higher error rate. The method is tested on simulated datasets and real mmWave wireless channels."
SP:77dc92137ea490d3e1b4b8ee1630dbe2ee0bddfa,"This paper studies the abductive natural language inference task (αNLI), where the inference network is trained with an interactive language model. The authors propose a new structural loss, called joint softmax focal loss, which is an extension of the existing structural loss (joint softmax focal loss) to the αNLI task. The proposed model can be used to train the model in the context of the αNsLI task, and the authors show that IMSL with RoBERTa-large pretrained model can outperform ACC and AUC on ICSL with Interactive Model with Structural Loss (IMSL). The authors also show that the reasoning abilities of the proposed model are better than those of ACC."
SP:17cd72df5fc19398f582d27516fd742b073f79e3,This paper studies the problem of certifiably adversarially robust OOD detection. The authors propose a method that combines a certifiable OOD detector and a classifier in an OOD aware classifier. The proposed method is based on the assessment of uncertainy in machine learning for safety-critical systems. The main idea is to use deep neural networks to make overconfident predictions for OOD samples. They show that the proposed classifier can be used to solve the asymptotic overconfidence problem in neural networks. They also provide a theoretical analysis of the detection performance of non-manifold OOD data.
SP:9c3756f13932236aff3e8104f4fa193dcc8fde2f,"This paper studies transfer attacks on Deep Neural Networks (DNNs) in the query-free black-box setting. The authors propose a method called Image Classification Eraser (ICE) to extract the classification information from the surrogate models and the white-box surrogate models. The transfer attack is based on the Generalized Transferable Attack (GTA) problem, where the target dataset is the victim model and the target model is the surrogate model. ICE is shown to outperform other transfer attack methods in the GTA problem on Cifar-10, CIFar-100, and TieredImageNet."
SP:2e0447c741a3f09be1095633d870200355211260,"This paper proposes a discriminative PrLM for contextualized representation. The authors show that PrLMs with pre-training methods can suffer from a false negative issue in the presence of gradient updates, and propose a pre-trained language models to address this issue. The proposed model is evaluated on GLUE and SQuAD benchmarks."
SP:281bc59d639aa76d84921b3ec4ce1ee8f1ba5b51,"This paper proposes ORCA, an end-to-end approach to semi-supervised learning in real-world settings where unlabeled test data is available and labeled training data is unavailable. ORCA is based on the uncertainty adaptive margin, which is an extension of ORCA. The authors show that ORCA improves the discriminability of the model in terms of the uncertainty of the class distribution mismatch problem.  The authors also show that the ORCA outperforms other baselines on image classification datasets and a single-cell dataset, and novel classes in the ImageNet dataset. "
SP:6c572c4c21b01a0cf3fd9ef97fbb348ef4e405ae,"This paper proposes SLIM-QN, a light stochastic quasi-Newton optimizer for large-scale DNNs. The authors propose to use momentum and adaptive damping mechanism to improve the stability of the Hessian updates in the L-BFGS training in stochedastic training. The BFGS update rule is based on a Hessian inverse with gradients, and the authors show the convergence of SLIM - QN with stable convergence under the same computational cost as SGD.   The authors also show that the convergence instability of SGD with the same number of compute resources is lower than the convergence stability in the same amount of wall-clock time.  Finally, the authors provide a theoretical analysis of the computational cost of the second-order methods in the second order methods in large-size DNN. They also provide theoretical analysis on the performance of the SLIM QN on large datasets such as ImageNet, Transformers, and other non-convolutional architectures. "
SP:4bffce00ebb02d2e676eec897647ac14c3344deb,Graph Neural Networks (GNNs) are well-suited for graph-related tasks. GNNs can be used to solve problems with redundant components in large graphs. The paper proposes a systematic method for graph pruning called Locality-Sensitive Pruning (LSP). LSP is a pre-processing step that prunes the graph with node or edge removals. The pruning is based on locality properties that are learned during pruning. LSP can be applied to large graphs with edges and sparsified graph. Experiments on synthetic and real-world datasets demonstrate the effectiveness of LSP. 
SP:c5e024f4e2079586298519ca868630efd7579eca,"This paper studies the problem of data augmentation in contrastive self-supervised learning. The authors propose a new adversarial augmentation method, IDAA, which is based on identity disentangled adversarial perturbation (IDAA). IDAA augments the input data with hard positives/negative samples, and the VAE objective is a variational auto-encoder (VAE) reconstruction. IDAA is shown to improve the efficiency and generalization performance on several benchmark datasets. "
SP:0991bc5f213bd8ab7572e2fed309e1b57a35835b,"This paper proposes a new method to detect harmful shifts in machine learning models. The authors propose to use a set of tests to detect distribution shifts in the data distribution. These tests are based on non-sequential methods, and these are designed to detect arbitrary shifts. The proposed method is based on sequential tools to estimate the risk function of interest (i.e., the accuracy and calibration). The tracking process is then based on the aggregation of statistical evidence from the tracking process by constructing time-uniform confidence sequences. The model is trained with a false alarm rate that depends on the number of samples in the model. Experiments on simulated and real datasets demonstrate the effectiveness of the proposed framework."
SP:1c7b954273e3a9cda333385b15a3e8ed3bf8178a,"This paper proposes a new method for long-term prediction in state space. The proposed method is based on neural networks to model the dynamics of diverse physical systems. The authors use neural implicit representations for appearance modeling and neural ordinary differential equations (ODEs) for interpretable physical models based on visual observations. They show that the proposed model is able to identify physical parameters for reconstruction from real-world videos such as pendulum motion, processing of high-resolution videos, and synthesis of photo-realistic imagery. They also show that they can identify the relative error of the embedding of the embedded neural ODE in the known parametric form. They demonstrate that their proposed method outperforms existing approaches on large training datasets."
SP:51efd1451343f4994d857daa5490e299b812bc2d,"This paper proposes a new framework for Markov process modeling based on the sticky Hierarchical Dirichlet Process (HDP) prior for model learning. The key idea is to use a context distillation procedure to remove spurious contexts from the training data. The authors show that it can be combined with a Bayesian approach and variational inference to improve the performance of the model. They also show that the optimal policy can be learned using RL algorithms for policy learning. Finally, they show that their framework can be applied to various state-of-the-art methods."
SP:ea167b126212b2092bc1190d7f8376bf7c54a888,"Knowledge enriched language representation learning is an important problem in knowledge-intensive NLP tasks. The paper proposes a framework to train knowledge based multilingual language models (KMLMs) on monolingual knowledge graph data. The pretraining tasks are based on intraand inter-sentence structures of the data, and the goal is to learn logical patterns from the language models. The authors show that the pretrained language models are able to learn factual knowledge from Wikidata knowledge graphs. They also show that pretrained KMLMs can be used to perform knowledge-intensive cross-lingual NLP task such as factual knowledge retrieval, relation classification, and named entity recognition."
SP:6c11cf29c90f923346372ba6f11452c36e69ad6d,"This paper studies the problem of learning agents that can be trained in a task-agnostic manner to learn an altruistic behaviour in a multi-agent environment. The authors propose a new concept called “external supervision”, which is an extension of reinforcement learning agents where the goal is to learn a “good” agent’s behaviour in the presence of external supervision. They show that this concept can be applied to both artificial agents as well as human agents. They also show that the proposed approach can be used in multi- agent environments. Finally, they show that unsupervised agents can learn them better than them in some cases."
SP:5dbc54201ba184266c5054f0d2944bd197bc307a,"This paper proposes a Neural Tangent Kernel for neural networks with finite-width neural networks. Double descent is a well-studied problem in linear and kernel regression models. The authors show that the interpolation threshold of double descent behaviour is the optimum of the Hessian of a Hessian with a population loss. They then propose a new loss function for double descent with the same loss function in neural networks and Hessian spectra. They show that under certain assumptions on the influence functions of the parametric model, the double descent can be approximated by the population loss, and they show that their models are able to approximate double descent."
SP:b485114712055f39a7afb951dbc3db482ff523fd,"Graph convolutional networks (GCNs) are widely used for graph-structured data. The over-smoothing problem of deep GCNs is a well-studied and well-understood problem in the literature. The authors consider the problem of learning node representations in the expressive space, and propose a gradient descentbased optimizer, DropEdge. The optimization trajectory is based on gradient descent with Graph Neural Tangent Kernel (GNTK) for wide GCNs, and gradient descent for deep GCN. The theoretical framework provides a theoretical framework for residual connection-based techniques for the exponential decay of trainability and dropping trainability in GNTK. The empirical results show that the exponential rate of the optimization process in the optimization of a wide and deep GCNN with asymptotic behaviors such as large depth, expressive power, trainability, and optimization perspective are better than the expressivity and trainability of the counterparts in infinite-width and finite-width."
SP:25a92b3583afdc6892e59f1e769125d52c8011af,"This paper studies the problem of camera-based vital sign measurement. The authors propose a new loss function for neural models to capture higher-order dynamics such as optical flow and acceleration, which are commonly used in computer vision methods for first-order dynamic such as blood pressure and arterial disease. The proposed loss function is based on the second derivative in the training procedure of a second derivative of the first derivative in a training procedure. The second derivative is used to capture the cardiac pulse in cardiac measurements, such as heart rate and summary statistics. The paper shows that the waveform morphology of the waveforms can be used for clinically impactful scenarios, and that the accuracy of waveform morphologies can be improved. The model is also able to capture left ventricle ejection time (LVET) intervals. "
SP:0a88d2fcbdfab3e196bf6b9c75adb1006ab87536,"This paper studies the problem of emergent communication in multi-agent language learning. The authors propose a new architecture, symbolic mapping, for the communication system. The symbolic mapping is based on referential games, where the goal is to learn simple interactions between agents in a human language. The paper shows that the symbolic mapping can be used for language learning in a variety of settings, including compositional and symmetric language. They also show that the process can be applied to multi-adversarial language learning, and that the complexity of the process is also reduced. "
SP:89575be04cb33b41d7a0a7b62f9496c2838a1317,"This paper proposes a hierarchical modular approach to train Robotic agents to perform domestic chores using natural language directives. The agents are trained in a divide-andconquer manner, where the goal is to learn a set of subgoals from the language instructions. Each subgoal is represented by a hierarchy of policy that is learned in a hierarchical manner. The agent’s navigation policy and independent interaction policies are learned from the master policy. The interaction policy is used to learn object masks for manipulation actions. The hierarchical agent is evaluated on the ALFRED benchmark. Compositional Reasoning is also applied."
SP:e2c8efe00db7baba2368f4f6a37815809b9e235e,"This paper proposes Nuisance-Randomized Distillation (NURD) for predictive models. NURD is based on the notion of nuisance-label relationship between two distributions, the nuisance-randomized distribution and the distribution of the nuisance variable. The authors show that the relationship between the two distributions can be used to improve the model's performance in prediction problems. The main contribution of the paper is a new representation of the distribution in a nuisance-differential family, which can be combined with existing representations such as the NIST. The paper also shows that the proposed models can improve the performance of models trained with non-lung patches for pneumonia by using spurious correlations between the nuisance and covariates in the background. The experiments on two tasks, chest X-ray classification and a few other tasks demonstrate the effectiveness of the proposed model."
SP:c75998b76f4e0510fc719d25959a10fc07db1c40,"This paper proposes Optimal TransporT distillation for zero-shot Recognition (OTTER), a new method for training computer vision models for predefined categories. OTTER is based on online entropic optimal transport for soft image-text match for contrastive learning. The model is trained using pretrained image and text encoders. The authors show that OTTER outperforms the baselines on a variety of dataset/architecture settings, including Google Open Images, multi-label ImageNet, and ImageNet-C."
SP:e83cd70377542b5d187998e2e4a7ac070f453ed6,"This paper proposes Pix2Seq for object detection using prior knowledge from a language modeling task. Object descriptions such as bounding boxes, class labels, and class labels are used to train a neural net to generate an image. The proposed approach is based on task-specific data augmentations, and it is shown to outperform existing detection algorithms on the COCO dataset. "
SP:abc9315f61929cc1c54dfef8ff83d7eac56ec2f2,"This paper proposes a new approach to train policy networks using Deep vision models in visual reinforcement learning (RL). The approach is based on hierarchical reasoning, where the goal is to learn an interpretable symbolic policy with geometric and numerical symbols and operators. The key idea is to distill the interpretability of the policy network into a policy network that can be used to train a policy. The authors propose a policy regression algorithm called RoundTourMix, which distills the symbolic rules into a set of symbolic rules. They show that the distilled symbolic policy outperforms CNN based RL agents in terms of interpretability. "
SP:04e7e181aeb1244ae1c4837ad416aef93ea3ea32,"This paper proposes a new unsupervised image-to-image translation task called PIVQGAN. StyleGAN2.0 is a combination of StyleGAN and GANInversion encoders, where the GAN inversion encoder is trained with a joint-training scheme and self-supervision methods, and the generator is used for pose-identity disentanglement and fine-grained level styling (identity) from exemplar sources. The VQSN module is used to extract shaping and composition information from the training-set images. The latent-space reducing feature is also used to improve the model applications such as posture-identification disentangling, synthesis image quality, and disentangled scores.    The authors show that the PivQGAN can achieve state-of-the-art performance on Unsupervised Image-to -image translation. The authors also demonstrate that the segmentation-like“masks” masks generated by PIVZGAN can be used to learn the identity of the pose. "
SP:e51a7f45493064972585109f203a867e9828eb15,"This paper proposes a new multi-layer perceptron (MLP) architecture called speech-MLP, which is based on the idea of multiscale local temporal dependency. The proposed model is able to handle a variety of speech processing tasks such as speech synthesis, speech enhancement, speech recognition, and speech enhancement. The model is evaluated on three benchmark datasets: Google speech command V2-35, LibriWords, and a dataset (VoiceBank) for speech enhancement and keyword spotting. The authors show that the proposed model can achieve better performance on these tasks than transformer-based solutions. "
SP:d708d3886f4abd4552d8ccb2096df7361c803b13,"This paper proposes a new lower bound on the generalization error of a transfer learning algorithm with respect to the number of labeled training data for massive models trained on labeled data. The lower bound is based on the computational complexity of the transfer learning algorithms. The authors show that it is possible to learn the source/target data distributions of the source domains for knowledge transfer in the setting where the data collection and labeling are done in parallel. The upper-bounds are based on weighted empirical risk minimization on the source(s) and target data sets, and the lower bounds are derived from transfer learning base-lines."
SP:f7511ba9ccad03233b34b1bf41bbac7361d20a57,"This paper proposes a probabilistic shape completion method for continuous geometry of large-scale 3D scenes. The formulation is based on Generative Cellular Automata, which is a multi-modal distribution. The key idea is to learn a sparse voxel embedding of the local continuous shape from the latent code of the generative model, and then use progressive generation to generate a complete shape distribution with a variational lower bound. The proposed approach is shown to perform better than deterministic models. "
SP:d22d8f074adbe8fb0f25fb8f8d96201b3159bf6b,"This paper studies the problem of exploration in deep reinforcement learning, where the goal is to learn a policy that is able to transfer from one task to another. Behavioral priors are used to solve this problem, and the authors propose a probabilistic mixture of policy and temporal prior for off-policy reinforcement learning. The authors show that the temporal consistency of state-independent temporal priors leads to reduced generality and restricted transferability. The proposed approach is evaluated on a variety of sparse reward settings and long-horizon continuous control tasks and outperforms baselines."
SP:25e06c022ae8b3cbbb8db413d7b534a1a5c92391,"This paper studies the problem of stochastic optimization in deep neural networks. The authors propose a scheduling mechanism called Learning rate scheduling, which uses pre-defined rules to optimize the learning rate of a neural network using a directed graph. The scheduling mechanism is based on reinforcement learning, where the agent learns a learning rate using reinforcement learning and a graph message passing network to learn the dynamics. The scheduler learns intermediate layer information and the reward collection procedure for training. The proposed framework is evaluated on several benchmarking datasets, including Fashion-MNIST, CIFAR10, GLUE, and image classification. The results show that the proposed GNS outperforms baselines for CNN and Transformer models in terms of learning rate and language understanding."
SP:d73cb0471c1770607ad3e4621cfc5f170683dd8e,This paper proposes a new object-specification scheme for deep object-centric learning. The proposed framework is based on the Chamfer Mixture Loss in the variational training pipeline. The authors show that the proposed framework can learn a 3D point cloud for high-level relational reasoning and scalable machine intelligence. They also show that their scheme can be applied to SPAIR3D and unsupervised scene decomposition. 
SP:3c57e921c1bf23e482551ceb71702931a7f07439,"This paper proposes a method to learn actionable knowledge from large language models (LLMs) for interactive environments with natural language. LMs are used to learn high-level tasks from natural language, and they can be used to train LMs to perform actionable steps. The method is evaluated on the VirtualHome environment, where it outperforms the LLM baseline in terms of executability, correctness, and human evaluation. "
SP:e0159d1c9df2e657892a3a0c77549df4698d9a1a,"This paper proposes a Variational Autoencoder framework based on geometrical interpretation of the Riemannian structure of the learned latent space. The authors show that vanilla VAE models do not perform as well as the VAEs on the benchmark datasets.  The authors then propose a new VAE that is able to learn a Riemanian manifold for the uniform distribution. The proposed method is shown to perform well on the complex neuroimaging dataset with high dimensional data and low sample sizes. Finally, the authors demonstrate that the proposed method can be applied to deep generative models in the low data regime."
SP:b4b8e1727f8617894f10f20365cb68de79f0e650,"This paper proposes a new transformer architecture, Transformer-MGK, that combines redundant heads in the transformer architecture with a mixture of keys in a Gaussian mixture model. Multi-head attention is added to the attention heads to improve the performance of transformers on natural language processing (NLP) and computer vision tasks. The proposed model is evaluated on the Wikitext-103 and Long Range Arena benchmark and shows that the proposed model outperforms the baseline transformers in terms of accuracy. The authors also show that the Transformer - MGK can be used for training with FLOPs. "
SP:82731dcce233e748f63382e09b6224a513fe9689,"This paper proposes a new minimalistic recurrent architecture called Resetting Path Integrator (RPI) which is based on a direct-inverse model of environment dynamics for the reconstruction of the action in a two-dimensional continuous environment with proprioception and linear and angular velocity. The authors show that RPI is able to recover the internal state of a minimal model with respect to the image signal, and it is also able to learn a cognitive map of the environment. The proposed architecture is evaluated on a variety of tasks and compared to LSTM networks."
SP:1a27c397d1e73def5e724c5c6f25548975ba50fa,"This paper studies the problem of feature learning in neural networks on practical data. The authors propose a new statistical query model based on a polynomial algorithm. The main idea is to learn a set of class relevant patterns from the input data, and then use gradient descent to train neural networks to solve these problems. The paper shows that linear models can learn data-independent features that are polynomially larger than the polynometric sizes of the linear models.  The paper also shows that the structure of the input distribution can be used to learn the features for prediction. "
SP:8ada73ed7eade9ebdeef376485e849c42575bc5f,This paper studies the robustness of machine learning models against adversarial examples in the presence of test-time adversaries. The authors provide lower bounds for the model’s robustness against arbitrary classification functions. They also provide a methodology for training fixed feature extractors with closed-form expressions for collision finding. They show that the proposed method is robust to collisions and that it can be used to train a classifier with better robustness than existing training methods. 
SP:874b5fa51924cbcceed490d98a0ea80f74586b32,"Offline reinforcement learning (RL) is an important problem in RL for real-world problems. Offline RL algorithms rely on regularization or constraints to reduce the extrapolation error. The authors propose a framework to learn a V-function from the learning procedure in an offline dataset. The Q-function is learned by implicit planning on the V-values from the offline trajectories. Expectile V-Learning (EVL) is used to improve generalization. The proposed method, Value-based Episodic Memory (VEM), is evaluated on three tasks: optimal value learning, behavior cloning, and sparse-reward tasks."
SP:34f08d92681504490c2f739b0d08f79f9764b2f5,This paper proposes a new adversarial training framework for robust generalization in the presence of adversarial perturbations in neural network classifiers trained with robustness. The authors propose to use the importance weight of the parametric function of the class-conditioned margin to train the robust classifier. They show that this approach can achieve better clean and robust accuracy compared to state-of-the-art baselines and other MAML-based approaches. They also provide a bilevel optimization problem for weighted adversarial learning.
SP:3ad36be6b6900aabe43da043461cf178ce977082,"This paper proposes a new method for equivariant non-linear convolutions. The proposed model combines geometric and physical information in the message and update functions of steerable MLPs in a model with steerable node and edge attributes. The model is composed of two components: (1) a vector of covariant information (e.g., force, velocity, position) and (2) vector of vector of vectors of the vector of the position. The vector is used to represent the node and edges as invariant scalars. The activation functions are used to encode the steerable feature fields in the MLPs.  The authors show that the proposed method can achieve state-of-the-art performance in terms of computational physics, chemistry, and computational physics. The authors also demonstrate that the equivariance of SEGNNs can be achieved by non-logarithmic non-langevin message aggregation and linear (steerable) point convolutions, and that the invariant message aggregation can be combined with linear (non-linear message aggregation. "
SP:8928aa83f7ebd4e310f4fe1d01ff0eb0c96e4d2b,"This paper studies the problem of differentiable physics modeling with gradient-based learning. Differentiable physics models include physics models such as rigid bodies, deformable sheets, and rigid bodies with force interactions such as individual yarn physics, yarn-to-yarn interactions, and force interactions between material structures. The authors propose a differentiable fabrics model for composite materials such as cloths, where the physical systems are complex physical phenomena and the granularity of yarns can be very differentiable. Fine-grained models are used to model the material structures and the force interactions. It is also used to learn the dynamics and design for inverse problems and inverse problems. The model learns the physical parameters of the physical system, and the model is trained with high-fidelity and high-efficient data-efficiency. The experiments show that the proposed model is able to capture the subtle dynamics and the design. "
SP:2c8358c095b10981d3015b9f6c75765419a9480d,"This paper proposes a new framework based on logical composition for reinforcement learning based on the assumption that the task-specific skill can be represented as a Boolean expression. The authors propose a transfer learning approach to learn the optimal policy from the unknown distribution, where the goal is to transfer the learned policy to a new task. The proposed algorithm is based on an algorithm that learns the distribution of the new task from the known distribution. The approach is evaluated on a variety of tasks and shows that the proposed approach outperforms other transfer learning approaches."
SP:c85d71d05164d019cc32bf423e4c4fe20c169f41,"This paper studies the problem of multivariate time series classification (MTSC) in the context of machine and deep learning solutions. The authors propose a distributed solution to the MTSC problem, called LightWaveS, which uses random convolutional kernels instead of the popular ROCKET. The proposed solution is based on wavelet scattering transformation, distributed feature selection, and distributed learning. The paper shows that the proposed solution achieves better prediction accuracy than the state-of-the-art in many real-world environments. "
SP:db43614ca016280a79448f44a97c81c8ff5ba981,"This paper proposes a novel Adversarial learning curriculum for text encoders based on Mixture Of Signals for auxiliary generators. The proposed AMOS is a unified auxiliary model that combines MLMs in a unified manner. The discriminator is trained to predict the replaced tokens from the encoder, and the discriminator uses a discriminator trained with mixture weights to train an encoder to predict replaced tokens using auxiliary masked language models (MLMs). The authors show that AMOS performs better than pretrained models on GLUE and SQuAD benchmarks compared to ELECTRA and BERT base-sized models in terms of pretraining efficiency."
SP:db3825633ab5d0671340390b23ab655838cc38b2,"This paper studies the relational fact extraction task, where the goal is to extract relational knowledge from a set of knowledge graph facts. The authors propose to use a clozestyle sentence as a pre-trained language model to learn relational knowledge, and then use adaptive fine-tuning on the fill-mask task to improve the precision of the language models. The model is trained using a combination of complex prompting techniques as well as adaptive fine -tuning. The approach is evaluated on a variety of tasks, and the results show that the proposed language model has better transfer learning capabilities than other baselines."
SP:ae25d32714b2b9f7e02cc20f4a36252e20e78e4f,"This paper studies the problem of multi-relations in Knowledge bases. The authors propose a representation learning framework to learn relation properties such as symmetry, inversion, and composition. The properties are derived from Euclidean embedding models, and the authors show that the hyperbolic space can be used to model the transitivity of the embeddings in geometric spaces. The proposed approach is evaluated on two datasets, YAGO3 and CIFAR-10, and shows that the proposed approach can achieve good performance with low dimensions and small training rates. "
SP:9ab3bc525ee4a9c96518c43e4c43082655a7674f,"This paper proposes a new one-shot learning framework for link prediction on temporal knowledge graphs with frequency distribution. The proposed method uses a self-attention mechanism and a network to learn temporal interactions between entities. The authors show that the proposed algorithm is able to learn sparse relations in the presence of data scarcity, which is an important problem in many low-shooting learning methods. "
SP:91f92a40e12afd0702f07ae7f4175ecce57b7007,This paper proposes a new solver based on a neural module to solve a given task. The proposed model is evaluated on a variety of visual reasoning tasks. The authors show that the proposed model performs better than the attention-based baseline. The main contribution of the paper is the use of human judges to guide the reasoning process. 
SP:de33b02e7f2faec5bcae9a5516721aa1ef190572,"This paper studies the channel-selectivity of a convolutional layer. The authors propose a new architectural unit, Selective Convolutional Unit (SCU), to improve the parameter efficiency of CNNs with bottlenecks. SCU is trained by pruning unimportant channels in training, and the identity (e.g. residual) connection between the pruned parameters and the original parameters is updated during postprocessing. Experiments show that SCU-based models perform better than baselines in terms of model compression. "
SP:2d80fa4bc440061be2234b5070503d3fa056baed,"This paper studies the problem of PU learning for Bayes optimal classifier with positive data and unlabeled data. The authors propose a new algorithm to learn the scoring function for the classifier, which is based on a threshold. They show that the proposed method outperforms existing methods in PU learning on real-world datasets. "
SP:5f312626b0613d2e07c59214c5f00db208a98717,"This paper proposes a new approach to reduce the statistical inefficiency of neural networks by using auxiliary losses to improve the representations. The auxiliary loss is used to replace the main loss in the auxiliary task. The proposed algorithm is evaluated on three domains: multi-task supervised learning, reinforcement learning, and reinforcement learning on Atari games. "
SP:e270ae3eeb7ab4fa91ba37d4d68ce10f2fa0a3b5,This paper proposes a geometric framework for learning the high-dimensional geometry of adversarial examples in machine learning models. Adversarial examples are defined as low-dimensional data manifolds in the manifold reconstruction literature. The decision boundary between the two manifolds is defined as the difference between the nearest neighbor classifiers and the ball-based adversarial training with sufficient sampling conditions.  The authors show that the decision boundary for the low-dimensions of the manifold can be used to learn the misclassifications. The authors also provide a theoretical analysis of the robustness of the norms. 
SP:e07d948a79d478ecd23a0a4406d4ddd3ac5e3be3,"This paper proposes a new representation learning framework based on interpretable discrete dimensionality reduction and deep generative modeling for high-dimensional time series. The authors propose a new Markov model for probabilistic interpretation of our method. The proposed method is based on the self-organizing map algorithm, which is an extension of the original self-organized map algorithm. The main contribution of the paper is the use of discrete representations of time series to learn smooth and interpretable embeddings. The paper also proposes a way to improve the non-differentiability of discrete representation learning in the presence of data features. Experimental results on the eICU data set demonstrate the effectiveness of the proposed model in terms of clustering, interpretability, and clustering performance."
SP:5915ee71ea58dbdbafa31c1ad291d1e5940a0cf4,"This paper proposes a multidimensional probability distributions for latent space prior distributions for implicit generative models. The authors show that linear interpolations on the latent space of random latent vectors can lead to distribution mismatch between the prior distribution and the latent probability distribution of the latent distribution. They also show that non-linear interpolations can be used to reduce the distribution mismatch. Finally, they provide a finite mean for the latent distributions. "
SP:19b63ca635712f1509ca6e0141303c192f2709e0,"This paper studies the geometry of embedding of object representations in shallow networks in the hyperbolic space of shallow networks with embeddings in the embedding space of ubiquitous attention mechanisms. The authors propose a new approach to learn representations of objects that are embeddable in the space of the embedded space. The proposed approach is based on the idea that the embeds of objects can be represented as a set of nodes in a graph, and that the semantic distance between nodes in the graph can be computed as a function of the distance between the nodes.  The proposed method is evaluated on a variety of synthetic and real-world graph tasks, and achieves state-of-the-art performance on neural machine translation in WMT’14."
SP:f6049e9f80a63c9306c1cebcb6b229aa6da44ddc,"This paper studies attacks on the architecture information of deep neural networks (DNN). The authors propose a new attack called DeepRecon, which is based on a cache side-channel technique, Flush+Reload, to extract the internal information from the DNN fingerprinting attacks. The authors show that this attack can be used to attack the architecture of a DNN by using a threat model to learn the architecture attributes of the victim model. They also show that the attack can also be used in the transfer learning setting, where a pretrained model is trained using a meta-model. The paper also provides empirical security analysis on DNNs’ vulnerability against cache side -channel attacks.    The paper proposes a new framework-level defense techniques to defend against the fingerprinting process in deep learning (DL) system. The main idea is to train black-box networks with a shared framework, and then use the shared framework to train the network architecture. The proposed framework is then applied to a variety of complex networks, such as VGG19, ResNet50, and ResNet100, and is shown to be robust to forward propagation."
SP:6a3dd89db6c24a1f98e8866ef0a4c1c2c1ec6635,"This paper proposes a hierarchical network model for predicting future video frames. The model is based on feedforward, feedback and lateral recurrent circuits in a mammalian hierarchical visual system. The spatiotemporal memories in the representational hierarchy are encoded by recurrent connections. The feed-forward path and the feedback path are used to encode spatotemporal features in the model. The hierarchical interaction in the network is also used to learn the internal memory states. The prediction errors are computed on a frame-to-frame basis. The authors show that the proposed model is able to perform long range video sequence predictions on benchmark datasets. "
SP:fb74e57f35666742caf651e6da33b5defcf259a8,"This paper proposes a method to learn continuous embeddings for kmers from raw RNA-seq data. The authors use a model to learn DNA sequence similarity and DNA sequence abundance in the embedding latent space, and then use the latent space to extract exon information from the raw RNA - Seq data for the classification of kmers in acute myeloid leukemia patients. They show that the learned vectors can be used to detect genomic abnormalities in the presence of translocations and patient-specific mutations. They also provide a visualization and analysis of the learned representation space for the analysis and the detection of genomic abnormalities."
SP:03aca6ff6a7f0ad2d5ccbcb15ed9536e305a9880,"This paper proposes a new approach for model compression based on Architecture Compression. The proposed approach is based on a 1-D CNN encoder/decoder, which maps the network to a weight or filter space. The key idea is to use continuous embedding and back to compute the parameter count of the embedding. The compression objective function is computed by gradient descent in the continuous space of the gradient descent during the compression phase. The authors show that the proposed architecture is able to compress the dataset on CIFAR-10/100, FMNIST, SVHN, and SVNIST on visual recognition tasks. "
SP:0511b5d10a90e3fe814e2d35208b4a987894ea62,"This paper proposes a new “plan online and learn offline” framework, where the goal is to learn a value function that can be used to guide exploration and local model-based control as well as global value function learning. The key idea is to use approximate value functions to learn policies that cover the planning horizon, and then use trajectory optimization for temporally coordinated exploration and estimating uncertainty for value function approximation. The internal model is trained to predict the value function, and the local solutions are then used to train the internal model. The authors show that the proposed components can be applied to control tasks such as humanoid locomotion and dexterous in-hand manipulation."
SP:771494fda4702cd8c7efbf225b19028f91b449b9,"This paper proposes a novel approach to unsupervised and semi-supervised machine translation (MTT) based on parallel data. The proposed approach is based on zero-shot and dual learning, where the goal is to learn the duality of the machine translation task using reinforcement learning. The authors show that the proposed NMT system is able to achieve better performance on the UN corpus than the standard NMT based on English-French and English-Spanish. The paper also shows that the new method can achieve better results on the en− →fr task than the LSTM-based UNsupervised DMT system. "
SP:1558dc03f99670f9ddccdca9c223a2baf962d438,"This paper proposes a framework for Information-Retrieval (IRGAN) based on IRGAN. The framework is based on Generative Adversarial Networks (GANs), which can be applied to multiple domains. The main idea is to learn a conditional probability distribution over the input data, and then use a generator to predict the distribution of the distribution. The generator is trained using a minimax loss function, and the loss curves are learned using adversarial formulation. The authors show that the proposed models can be trained in adversarial fashion in a co-training like setup, where each task is represented by a different model."
SP:6a13dda852ab075a3c0fb691476d6dc57919c729,This paper studies the problem of approximate inference for intractable generative models with variational auto-encoders (VAEs) for approximate inference in the context of interpretability. The authors propose a new approach to learn sparse representations for sparse representations in the latent space of a VAE by using the Spike and Slab prior distribution to learn the sparsity of a latent space in the VAE. The sparsity is defined as the difference between the number of latent dimensions of the input and the latent code of the latent variable.  The authors show that the approximate posterior inference in this VAE case is more robust than the standard VAE in terms of classification accuracy and robustness. 
SP:06a22143186fa2948fbe324ccae96a62ff12064e,"This paper proposes a non-adversarial feature matching-based approach for training generative models. The approach uses pretrained neural networks, such as autoencoders and ConvNet classifiers, to perform feature extraction. The proposed approach is based on first order statistics, and is evaluated on two challenging benchmarks, CIFAR10 and STL10."
SP:2d7cf2f07a27d6c8e304a1b47c25387ad2e4432d,"Graph Neural Networks (GNNs) are widely used for representation learning of graphs. However, they are not well-studied in practice. This paper proposes a novel neighborhood aggregation scheme for GNNs that can be applied to graph representation learning. The proposed GNN variants, such as Graph Convolutional Networks and GraphSAGE, are shown to perform well on node and graph classification tasks. The theoretical framework also shows that the GNN can be used to learn graph structures. The authors also show that the proposed architecture is able to outperform the WeisfeilerLehman graph isomorphism test."
SP:51126f2dd37ce57d2614c9044ede1e43627f0829,"This paper proposes a new framework for interpretable continual learning (ICL) based on the variational continual learning framework. The ICL idea is similar to previous continual learning approaches, where the objective is to maximize the average classification accuracy of the ICL. The authors propose a metric based on saliency maps to measure the generalization performance of ICL, and show that ICL achieves the best overall continual learning performance. "
SP:27a565b3e5442b93d208652784051e640b0c1bfe,This paper proposes a new evaluation framework for adversarial attacks on seq2seq models. Adversarial examples are generated by perturbations to the model during adversarial training. The authors show that the robustness of the model against the adversarial robustness against the meaning-preserving attacks can be measured by human and automatic evaluation. The paper also shows that the constraints of word-based MT systems can be used to improve the performance of machine translation (MT). 
SP:54ddd8132bf9e4259d2c2d72b348d2bb5f9e227c,"This paper studies the problem of learning policies with inverse rewards and inverse (negative) rewards in reinforcement learning algorithms. The authors show that policies with these two rewards are more likely to be mis-actions than policies with policies with the inverse rewards. They also show that such policies can be learned with deep Q-learning and double Q-learned with on-policy actor-critic. They show that these two algorithms can learn hybrid polices with different rewards with the same rewards, and that these policies can learn better policies than policies without the inverse policies. "
SP:89a732b57934d08b937c93560f391b7758e54f8a,"This paper proposes a new formulation for learning a hierarchical, disentangled object representation and a dynamics model from unlabeled videos. The object parts are represented as a layered image representation, and the hierarchical structure is represented by a structural descriptor. The PSD model is trained on both real and synthetic datasets, and is shown to perform well on two tasks: motion distributions and segmenting object parts. The structural descriptor is also used to learn low-level concepts such as system dynamics."
SP:bb2a655d67bed9da43f0b8ec7d888b89c217d12e,"This paper proposes a new inference method, Deep Determinantal Generative Classifier (DDGC), which uses noisy training datasets to train deep neural networks with noisy (incorrect) class labels in Large-scale datasets. The main idea is to use a softmax neural classifier trained with noisy datasets to learn the decision boundary of a discriminative deep model over hidden feature spaces in a generative classifier with a minimum covariance determinant estimator. The DDGC is then trained with the noise-handling training method to train a deep model with noisy labels and adversarial samples. Experiments on CIFAR10 dataset show that the proposed deep model achieves better test accuracy than the state-of-the-art in terms of classification accuracy with noisy training labels. "
SP:0fa525cc708470b757a60117cb608bb2feaa2c50,"This paper proposes Hierarchical Reinforcement Learning (HRL) methods based on action selection policies with sparse delayed reward feedback for large-scale applications such as huge state spaces and sparse delayed feedback in RL. Abstraction is an important problem in HRL and existing approaches for subgoal discovery for HRL are limited in their ability to handle subgoals. The authors propose a model-free method that uses incremental unsupervised learning to learn skills from an internal reward signal to guide subgoal attainment. The skill policies are learned using a temporal abstraction, and the skills are learned via intrinsic motivation learning mechanism. The proposed approach is evaluated on a variety of RL problems such as Montezuma’s Revenge, ATARI 2600 game, and rooms environment."
SP:e5861538bc8bb9165cb33299bbf12dd875abf976,This paper proposes a neural framework for the Circuit Satisfiability problem. The model is trained to solve the SAT problem using a rich embedding architecture and an end-to-end differentiable training procedure for Reinforcement Learning. The authors show that the proposed framework achieves better out-of-sample generalization than the NeuroSAT method. 
SP:ff3e5d44619df3825632b0b1a943add081364861,"This paper proposes a sample efficient off-policy deep RL algorithm, called Deep Deterministic Policy Gradient (DDPG) algorithm, which is an extension of the recently proposed sample efficient Off-Policy Deep RL algorithm DDPG. The main idea is to use Deep neuroevolution and deep reinforcement learning (deep RL) algorithms to perform policy search in the hyper-parameter setting. The authors propose to combine them into a single approach, and use them in a combination scheme, where the goal exploration process and goal exploration can be combined with an ad hoc evolutionary algorithm and a Deep deterministic policy Gradient. The proposed method is evaluated on CEM-RL, where it is shown that the sample efficiency of the proposed method improves the performance of CEM - RL. "
SP:78b2eb326695da0b0cc4ba39a9206d11644a5e32,"This paper proposes a new model for predicting the future of multivariate time series. The model is based on the IMV-LSTM, which uses a hidden state matrix and an update process to learn the variableswise hidden states. The authors show that it is able to perform better than existing baselines on both forecasting and knowledge extraction on multi-variate data. They also show that the mixture attention mechanism and summarization methods can be used to learn temporal and variable importance. It is also shown that the end-to-end framework for forecasting can be applied to knowledge extraction. "
SP:1c26660569b579f060f7b4a31e321c6d2356b928,"This paper proposes a new data augmentation method called feature smoothing, which is an extension of the recently proposed weight decay and logit squeezing. The main idea is to use virtual training data to train a neural network with interpolation of features from virtual data points. The authors show that the proposed method can improve the adversarial and clean accuracy of the trained model. The proposed method is evaluated on MNIST and CIFAR10 datasets."
SP:88d652f9e411dd3a2e9ad651d9011e579653c6aa,"This paper proposes a theoretical framework for learning disentangled representations of a deep convolutional neural network (DCNN) with ReLU nonlinearity. The framework is based on gradient descent rules for learning the data distribution. The authors show that the proposed framework can be applied to any data distribution with Gaussian inputs and independence of activation. The proposed framework is also applicable to the teacher-student setting, where the teacher’s computational graph has a projection nature.  The authors also provide some regularization techniques, such as Batch Norm, that can be used to improve the performance of deep networks."
SP:7842bbe0e2324cfd732db8745550733ccc3dfcdc,This paper proposes a new approach to learn a behavior repertoire from the prefrontal cortex (PFC) of dialog agents. The authors propose a modular architecture of neural networks with a Behavioral Module (BM) and an end-to-end training strategy that combines connectivity and the human behavior formation process. The proposed approach combines the learning of behaviors and preferences representation with a new property that can be used for user modeling and recommendation tasks. The paper also proposes a strategy for transfer of newly learned BMs to other BMs by independent learning of new behavior patterns. Experiments on video games playing demonstrate the effectiveness of the proposed method.
SP:300c391ff644b6889cd9ae27cf0d162dfcdd4451,"This paper studies plastic changes in synaptic connectivity in lifelong learning. The authors propose a differentiable Hebbian plasticity, which can be used to model the changes in neuromodulation of plasticity in neural networks. They show that this differentiable formulation can be applied to neural networks trained with gradient descent. They also show that the self-modifying abilities of the brain can be leveraged for learning and adaptation in biological reinforcement learning. Finally, the authors show that neurmodulated plasticity can improve the performance of neural networks on a variety of reinforcement learning and supervised learning tasks. "
SP:1ab5d94d31e99351433436c026799c8aa597bf73,"This paper proposes a new quantization technique to reduce the inference latency/memory consumption of Deep Neural Networks. The authors propose a full precision model for non-intrusive quantization, where the loss function is a reduced quantization error. They show that the binary quantization improves the full precision accuracy over 2 bit quantization and the 1.5 bits hybrid model on WikiText-2. The proposed techniques are evaluated on CIFAR dataset and ImageNet. The quantization training process is shown to outperform the training process in terms of accuracy."
SP:0876b1d9a6d664808ca1ab15865679fbf638267e,"This paper proposes a domain-independent method to learn a style embedding using a deep metric-learning technique. The method combines a content encoder with a variational autoencoder (VAE), a to-be-trained style encoder and an auxiliary loss. The VAE reconstruction loss is used to learn the style information in the reconstruction. The style information is then used in the content representation, and the style representation is used for the content-style decomposition and recombination. Decompositions are used for classification and for learning the composition of the content. Recombinations are also used for data set augmentation for data-set augmentation. The authors show that the proposed STOC is able to achieve state-of-the-art performance on several few-shot learning tasks, including a face-recognition task, and an emotion-recognization task. "
SP:d37e15cde7765fca87595a242f0a4511b3346d46,This paper proposes a method for deep reinforcement learning (deep RL) training for problems with state-action permissibility (SAP). The main idea is to use the SAP property in deep RL algorithms to improve the performance of state-actions exploration. The authors propose to use SAP guidance to guide the training during the training. 
SP:20015d8b60e13300586b67c281858cbe28825c48,"This paper studies the problem of training multilayer autoencoders with random weights with large dimensions. The authors propose a random deep weight-tied autoencoder model for approximate inference. They show that the training initialization practice can be improved by adding a layer-wise pre-training, batch normalization, and a tanh activation to the training process. They also provide a theoretical analysis of the phase transition phenomena and the reversibility of the Lipschitz activations. "
SP:91764f80dbe2401ade38b35a8253ba05f0f86386,This paper studies the search problem for the construction of adversarial images from model evaluations. The authors propose a new search strategy based on an iterative principle to find the low frequency component in a discrete cosine transform (DCT). The proposed method is able to find both targeted and untargeted attacks. The proposed algorithm is also able to detect adversarial black-box attacks. Experimental results on ResNet-50 demonstrate the effectiveness of the proposed method. 
SP:fc20ae0fbf57a1ce489c04b85c7c2f4c93dc2450,"This paper proposes a new method for learning temporal abstractions for understanding the curse of dimensionality in Hierarchical Reinforcement Learning. The authors propose a hierarchical framework called options framework, where the goal is to learn task-agnostic transferable skills. Option discovery is done by using heuristics based on the fact that the bottleneck states are not well connected regions, but rather “landmark” sub-goals. The proposed method is able to discover bottlenecks faster than existing methods for discovering bottleneck states. The model is based on Successor options, a model that learns Successor representations for options from primitive actions, and uses a pseudo-reward to learn intra-option policies. The approach is evaluated on grid worlds and complex high dimensional environments such as Deepmind-Lab."
SP:12a172c1e2892d016b37932acfc48dcb56874a89,"This paper studies the problem of domain division in probabilistic distributions. The authors propose a domain division algorithm for recognition tasks such as Open Set Learning (OSL) and G-ZSL, where the goal is to find the best classifiers for a given set of known, unknown and uncertain domains. The decision boundary is defined in an unsupervised way, and the probabilistically way is used to define the decision boundary. The proposed framework consists of two statistical tools: bootstrapping and KolmogorovSmirnov (K-S) Test. The experimental results show that the proposed approach outperforms the state-of-the-art on both OSL and G -ZSL benchmarks."
SP:28bcf7c6a4673e9ec2b4ebed09839d85188e0b2a,"This paper proposes a neural network for classification and regression. The main idea is to learn the layout structures of the neural network by minimizing angular distances between the input and output dimensions. The proposed solutions include softmax cross-entropy, mean squared error, simplicity (Occam’s Razor) and maximum margin separation of inductive structures such as polar prototype networks. The structure of these networks is based on polar prototypes, which are constructed from a set of polar prototypes. The authors show that they have maximal separation between the output dimensions of the prototypes and the output of the network. The paper also shows that training with angular distances can improve the performance of regression and classification with higher-dimensional outputs. Finally, the paper shows that polar interpolation can be used for training with training with large margin separation and semantic class structure in the case of the polar prototype network. "
SP:d1034342785d133cf8372b8624897963cc2ee83a,"This paper proposes a new algorithm for learning the preferences of Reinforcement learning (RL) agents. The idea is to use implicit preference information as a reward function to learn features from the reward function. The algorithm is based on Maximum Causal Entropy IRL, and it is shown to work well in proof-of-concept environments. "
SP:417a4e0acee699b3e004ad30d0ecf533a9ed987e,"This paper proposes a method to learn the dependency structure between latent variables between deep generative models and probabilistic graphical models in a modeling and inference framework. The latent variable space of a variational autoencoder (VAE) is modeled as a Bayesian network with a flexible dependency structure. The network parameters and the variational parameters are learned using a single objective. Inference is performed using top-down and bottom-up reasoning based on the latent variable values. The sampling procedure is used for Inference. The proposed framework is evaluated on MNIST, Omniglot, and CIFAR-10. The model is shown to outperform structured variational autooencoders baselines. "
SP:976dedab53e69610692a563382ada1dbb82c1e9d,"This paper proposes a dynamical neural network with interconnected neurons. It combines the computational properties of a massively parallel computer architecture with the power and throughput efficiency of a single dynamical network. The authors show that the dynamical networks can be trained with top-down feedback, contrastive learning, and spiking neurons.  The authors also show that their computational system can be used to solve dictionary learning problems. "
SP:f45117a6beaeb86a70b1380b4fac3cfba37fb892,"This paper studies the problem of model-based lane detection in the presence of weak visual appearance and prior information. The authors propose to use Convolutional neural networks (CNNs) to learn a spatial pyramid structure and an encoder-decoder structure to train the nets for the task of lane detection and semantic image segmentation. The network is then used to train a network for lane detection using the encoder -decoders module. Empirically, the authors show that the proposed evaluation methods can achieve state-of-the-art performance in terms of pixel-level accuracy and multi-scale context. "
SP:68b0a10ca06df74612d0753cc3f3ddddde806035,"This paper proposes a new approach for batch learning based on logged bandit feedback. The proposed approach, Maximum Likelihood Inverse Propensity Scoring (MLIPS), is an extension of Exponential Models (POEM) to the batch contextual bandit learning setting, where the goal is to learn a policy that performs better than off-policy training data. The authors propose two approaches to this problem: Policy Optimizer, which is based on the Inverse propensity weights of the historical policy, as well as a new surrogate policy that uses logged action-context pairs to learn the maximum likelihood surrogate policy. The paper shows that MLIPS achieves better nonasymptotic mean squared error than IPS on multi-label classification problems and large-scale ad placement dataset. The surrogate policy technique is also shown to perform better than other error reduction techniques. "
SP:8e0ed65c5dded23b34798499b2436b24422fd729,"This paper proposes a new learning framework for few-shot classification tasks based on meta-learning. Meta-learning is a popular learning framework that is used in many meta-training methods. The main idea is to use individualized feature embedding for classifying the query images using a kernel generator, and then use a meta-learner for model optimization, parameter initialization, and similarity metric. The meta-knowledge is then used to train convolutional kernels with the help of the kernel generator. The authors demonstrate the effectiveness of the proposed method on a few-shoot classification data sets such as Omniglot and miniImageNet. "
SP:faa3f7ffdcfb6e3b8ec0421193dae3d9987b015c,"This paper studies the problem of backpropagation in gradient-based learning algorithms for Deep artificial neural networks (DNNs). The authors propose a new evolutionary algorithm for training neural networks with free parameters. Evolution strategies (ES) outperform backprop-based algorithms such as Q-learning, policy gradients, and policy gradient. The proposed operation is a finite-difference approximation of the gradient, and it allows it to be used for stochastic gradient descent. The authors show that the proposed evolutionary algorithm can be applied to a wide range of deep reinforcement learning (RL) problems such as Atari, humanoid locomotion, DQN, A3C, ES, and Deep GA. They also show that non-gradient-based evolutionary algorithms can be used to improve the DNN scales. "
SP:dfdbe3267a8160f24746884cdf5297993e424231,"This paper proposes a new reinforcement learning algorithm based on an episodic memory for learning a novelty bonus. The novelty bonus is based on the fact that the agent can be trained in a variety of visually rich 3D environments such as VizDoom, DMLab, and MuJoCo. The agent is trained on a set of navigational tasks where the environment dynamics are known and the agent is able to adapt to the environment. The paper also proposes a curiosity module in the ant that encourages the agent to explore the environment in a way that encourages sparsity. Experiments show that the proposed agent outperforms the curiosity method and the ICM. "
SP:1e58a1c5344d1b5b7c8a40210a243700bd933d65,This paper studies the problem of representation for transition models in complex uncertain domains. The authors propose an iterative greedy algorithm to learn deictic references for each transition distribution using Feed-forward neural networks. The key idea is to use relational rules to learn the representation for each rule. The proposed strategy outperforms a monolithic transition model in the simulated domain.
SP:8ce00a3fedbf54a7f2c1ff414511cbb7d59b4597,"This paper proposes a new instance-wise feature selection method called INVASE, which is based on the actor-critic methodology. INVASE consists of two components: a selector network and a predictor network. The selector network is trained using the baseline network, and the predictor network is learned using the selector network. Experiments on synthetic and real data experiments show that INVASE outperforms state-of-the-art methods."
SP:b91d6c33349df0bb6cb7e1c5e9433f0d4744b4da,This paper proposes a domain adaptation method based on per-pixel annotations for supervised models such as convolutional neural networks. The proposed framework is based on a global alignment process and patch-level alignment. The annotations are used for model finetuning and are used to improve the performance of the models. The authors show that the proposed framework improves the performance in terms of semantic segmentation and predicting structured outputs. 
SP:00922af13a21464cbc4cd7b34c196dd4f86c9247,This paper studies the problem of online optimization algorithms for AMSGrad and Adam. The authors consider the mini-batch of stochastic gradients in deep neural nets. They show that optimistic algorithms for Adam can improve the predictability of gradients. They then propose two algorithms based on the momentum method and adaptive gradient method. The algorithms are evaluated on OPTIMISTIC ONLINE LEARNING.
SP:52228b48f2776d57dd422edb33b82e247f056b75,"This paper presents a new benchmark for image classifier robustness, IMAGENET-C, for the corruption robustness topic. The authors show that the classifier’s robustness under common perturbations can be affected by common corruptions as well as perturbation of the training data. They also show that by using the proposed benchmark, the classifiers can be more robust in safety-critical applications. "
SP:20358ea0f769e6ea9222d8e35159d711ee1b20b2,"This paper studies the problem of dropout estimation in dropout training. The authors propose a new dropout objective based on the deterministic subvariant’s bound. They show that the lower bounds for stochastic subvariants have lower bounds on the power mean of the sampled dropout masks. They then propose a family of conditional models that can be used as a model to estimate the dropout mean of any given model in the family. They also propose a deterministic dropout for MC averaging. Finally, they show that their regularisation-heavy language modelling can improve the performance."
SP:ac1b950ad29429ae045bb5e53279014a6a0b9d2b,"This paper proposes a robust pruning method for GSFP, called GSFP. The main idea is to prune layers of filters in a convolutional Neural Networks (CNNs) by using a cumulative saliency strategy to improve the accuracy of the pruning. The authors show that the saliency of a filter depends on the number of layers in the network, and the global redundancy of the model. They then propose a soft pruning strategy for the GSFP that uses a normalization formula to normalize the weights of the layers of the network. They show that this pruning can improve the model recovery process. They also show that it improves the compression ratio and the test accuracy of GSFP on a variety of CNN architectures and data sets. "
SP:621e41d4199e333ec7f9d0936d4e34c918f39c11,This paper proposes a novel transfer learning scheme for cross-lingual subword similarity. The key idea is to use a character-based embedder and a word-based classifier to learn the joint character representation. The embedder learns the vector representations from written forms and the word vectors are used to train the classifier. The model is trained with a multi-task objective and is evaluated on CACO models in low-resource settings and cross-linkingual word embedding models on related language pairs. The results show that the proposed model performs better than the state-of-the-art on cross-latent or monolingual resources.
SP:544e421f9c747640d949f433e3091763508b7237,"This paper proposes a new method for improving the performance of the marginalized average aggregation (MAAN) module in MAAN. The main idea is to use the latent discriminative probabilities of the MAA module to improve the generalization performance of MAAN in dense and integral action regions. The authors show that MAAN can be used to learn the class activation sequences of a video snippet features, and then use the learned algorithm to reduce the complexity of MAA. They also show that the proposed algorithm can be applied to weakly-supervised temporal action localization on large-scale video datasets. "
SP:9f98c9bac99003741dd14e093b54d692c0b0e8d8,"This paper studies the problem of neural models for Natural Language Processing with structureless distributed representations. The authors propose a new language models, called Holographic Reduced Representation (HRR), which is a structured compositional representation based on HRR. The proposed models are able to capture the structures in both wordlevel and chunk-level representations, and can be used as a representational form. The models can also be used to represent crude linguistic roles. "
SP:5908b6acfed0e7c51e203c72eba907e6635e6c60,"This paper studies the problem of partially observable Markov decision processes (POMDPs) for decision-making in robotic scenarios. The authors propose a greedy strategy for observation selection based on a point-based value iteration algorithm that uses sampled belief points to achieve near-optimal uncertainty reduction. The algorithm is based on POMDP models with stochastic outcome, where the goal is to find a known distribution that is close to the true distribution in real-world scenarios. To achieve this goal, the authors propose two computations: (1) a reachable subspace of belief simplex, and (2) a selection process that uses a solver to select the optimal action space. Experiments show that the proposed computations can achieve better performance in active perception, planning, and planning decision."
SP:0adec4abec17b3aab0c6eb69d11925dc20544950,This paper studies the problem of distribution shifting in weight of top layers in Deep neural networks. The authors propose a new curriculum learning for training a network. The main idea is to use the internal covariate shift in the network forward pass as a representation loss for low weighted samples to reduce the data complexity and improve the network training. The proposed curriculum loss is a combination of adaptive weight and representation loss. The theoretical results show that the curriculum loss performs better than standard stochastic algorithms such as SGD. 
SP:8b555b9f24044bc68c204169d6a37e262361d706,"This paper studies the problem of combinatorial optimization problems with hyperparameters. The authors propose a Pointer Network to solve the Travelling Salesman Problem (TSP). The model is based on REINFORCE with attention layers. The baseline is a deterministic greedy rollout with a value function, and it is shown that the model is able to converge to a good baseline with the same number of attention layers as the baseline. The heuristics are then applied to the Vehicle Routing Problem (VRP) and the Orienteering Problem (OP) and show that it can converge to good baselines. "
SP:efb76bcf1dbd9a9cf6b5db74b5d4256a9f9e9e73,"This paper studies the time and space complexity of neural network inference with network quantization in the context of embedded and mobile devices with limited computational and memory resources. The authors propose a differentiable neural architecture search (DNAS) framework for the exponential search space based on gradient-based optimization. The problem is formulated as a novel neural network search problem, where the design space is represented as a set of embeddings, and the goal is to find the optimal solution for each embedding in this set. The proposed quantization methods are evaluated on CIFAR-10 and ImageNet, and show that the proposed quantized models perform better than full precision models in terms of model size and computational cost."
SP:ea4173f8265bc50296de51c4ee7ecb6b8f78bec0,"This paper proposes Posterior Attention Models (PAM), a new architecture for neural architectures that uses attention in the decoding stage. Posterior attention models are based on the posterior attention distribution, where the attention is learned in a hierarchical fashion. The authors show that posterior attention models achieve better BLEU score and alignment accuracy compared to other attention models on translation and morphological inflection tasks."
SP:987e2c14abc091d4d3ef9b48fb2046408eb1f59e,"This paper studies the problem of unpaired image-to-image translation in the manifold view of the problem. The authors propose a new method, called CycleGAN, for bi-directional translations. The main idea is to use the smoothness term in the sample graph of the harmonic functions to learn consistent mappings between the artifacts and degenerated transformations. The paper shows that the similarity-consistency property of these mappings can be used to improve the interpretability of the resulting model. The proposed method is evaluated on a variety of applications, including object transfiguration, semantic labeling, and medical imaging. The results show that CycleGAN outperforms the state of the art in terms of interpretability."
SP:885a69003bad0e79cb2872a4e5c772191ad7e34f,"This paper studies exploding and vanishing gradient problem (EVGP) in Recurrent neural networks. The problem is formulated as a stochastic algorithm (h-detach) for LSTM optimization, where the gradient components of an EVGP are a linear path (cell state) in LSTMs. The authors show that the components have long term dependencies, and that the dependencies can be computed by an L STM.  The authors also show that, under certain conditions, the gradients of the path can be approximated by a simple L-divergence.  Finally, the authors provide convergence speed and robustness guarantees for vanilla LSTm gradient based training on several benchmark datasets. "
SP:9aaff3777321347d1194884af5690b0b5185eff9,This paper presents a Bayesian deep learning perspective on real binary weight networks from the perspective of the posterior distribution of binary weights. The authors propose a reinforcement learning scheme to train a policy network to learn the posterior distribution of the binary weights in a burn-after-reading style. The recognition architecture is based on the policy network that learns the binary weight instances from a set of nested parameter structure. The proposed method is evaluated on a variety of visual recognition tasks such as ImageNet and SnapQuant.
SP:29d1f6d0661a51e56c59bbb106da56700fc22d9a,This paper proposes a Bayesian nonparametric framework for federated learning with neural networks. The inference approach is based on a global network with local neural network weights. The authors show that the proposed framework can achieve state-of-the-art performance on image classification datasets. The proposed approach is also able to solve several federated training problems with supervision and data pooling.
SP:ab1f2bd216635d63450688866c729a501bd7e9d0,"This paper studies the problem of learning from adversarial examples in differentiable games. The authors propose a new algorithm called Opponent-Learning Awareness (LOLA), which is based on Stable Opponent Shaping (SOS). The authors show that SOS improves the performance of LOLA in a variety of differentiable game settings. They also provide theoretical guarantees for their algorithms."
SP:bdafb5fca09a775a8c92d2826d5dc977d28091c2,"This paper proposes a learning system for rare events in the feature space of classifiers/regressors. The key idea is to learn the shape feature of the prior information of the classifier/regressor. The shape feature is defined as a function of the number of classes in the low dimensional feature space, and the loss function is used to learn a segmentation result from the Variational Auto-Encoder(VAE). The VAE uses ground truth masks to encode the shapes of the shapes. The representation of the shape is then used to represent the qualities of segmentation results in the one-dimensional feature space. The paper shows that the proposed alarm system is able to achieve state-of-the-art performance on the medical segmentation task using segmentation algorithms."
SP:60738395d9efe2b3fe3a00c542ebb4261e54386c,"This paper studies the problem of inverse problems such as denoising, inpainting, reconstruction, and reconstruction with few and noisy measurements. Deep neural networks such as convolutional neural networks are commonly used for these inverse problems. The authors propose two tools, wavelets and deep decoder, for compressing images. The main contribution of the paper is to show that underparameterization can lead to overfitting in deep decoders, which is a common problem in untrained simple image model. The paper also proposes a theoretical analysis of the output dimensionality of the neural networks and how it affects the performance of neural networks trained with them. The theoretical analysis shows that the network weights are more sensitive to the input dimension than wavelet-based thresholding, and that the weight parameters of the convolutions are more robust to noise. Finally, the paper proposes a new upsampling unit and a pixel-wise linear combination of channels, ReLU activation, and channelwise normalization. The experimental results show that the proposed tools perform better than existing imagegenerating deep neural networks on natural images."
SP:1c9bad3bd4d670172f65aa0304e9837ecafc6b3d,"This paper proposes SAPS, an end-to-end neural network based on SAPS for Program synthesis in natural language (NL) for multi-sentence NL specifications. The proposed architecture combines abstract syntax trees, pretrained word embedding, bi-directional multi-layer LSTM, and a soft attention mechanism for the decoder. The authors show that the proposed method outperforms SAPS in terms of performance on a variety of tasks, including NL analyzer, source code generator, and end-user programming. "
SP:d2ec231bb6153a303e5110e671dea14c2721e636,"This paper studies the problem of adversarial perturbations of MNIST, a popular model for computer vision. The authors propose a novel attack on the neural network model, which is based on the L∞ defense, where the input binarization is replaced by a decision-based attack. They show that the L0 robustness of undefended networks with deep neural networks is better than the L2 robustness for MNIST with class-conditional data distributions. They also show that adversarial attacks can be used to improve the model's robustness against MNIST. "
SP:91a24e7f4b952c37441feab4a7e8555014c856a4,"This paper proposes a framework to train GANs based on spectra of weight matrices in the discriminator. The authors propose a reparameterization approach to learn the weight matrix of GAN with slow singular value decays, which is an important problem in the context of Generative Adversarial Networks (GANs). The main idea is to use regularizers and constraints to generate spectra for the spectra, which are then used to train a discriminator based on the learned spectra. The proposed method is evaluated on CIFAR-10, STL-10 and ImgaeNet datasets and shows that the proposed method performs better than existing methods. "
SP:8115fd9b681198d62100c36794926fb57dc0a4f5,"This paper proposes a new accelerated value iteration algorithm, Anderson Accelerated Value Iteration (A2VI), which uses the Anderson acceleration technique to accelerate value iteration in reinforcement learning methods. A2VI is an approximate method for policy evaluation, which can be applied to both toy problems and Atari games. The proposed method can be used as a Deep Q-learning algorithm. The authors show that the proposed algorithm can achieve state-of-the-art performance on both toy and Atari tasks."
SP:bd79b0c0af778a36008a0c0cf2fb6393fd2789d4,This paper proposes a method for the catastrophic forgetting problem in the class incremental learning scenario. The proposed SupportNet combines deep learning and support vector machine (SVM) in the SupportNet. The model is based on consolidation regularizers. The authors show that the proposed method outperforms existing incremental learning methods on several tasks. 
SP:d228d213f79716774043cea253305fecece659ec,"This paper proposes a new measure of top-class selectivity for recurrent neural networks (RNNs), which is based on activation maximization (AM) images. The proposed measure, called localist selectivity, is a combination of two measures: precision and class-conditional mean activity selectivity CCMAS. The authors show that the proposed measures improve the performance of AlexNet on fc6 and conv5.  "
SP:b9deae0392e0160b400d76c549d382e235196f8c,"This paper studies the problem of community detection with graph neural networks. Community detection is a node-wise classification problem with graphs, where the goal is to find the node with the highest signal-to-noise ratio. The authors consider the problem in a supervised learning setting, where each node is represented as a family of random graph families (e.g., a stochastic block model). Community detection can be done using spectral methods or posterior inference with probabilistic graphical models. The main contribution of this paper is to propose a belief propagation algorithm that can be applied to binary and multiclass Stochastic block models. In particular, it uses a learning perspective to learn a non-backtracking operator that predicts the local minimum and global minimum/minima of the computational threshold. The results show that they are more efficient than the belief propagation method, and that they can be used to train GNNs on real-world datasets. "
SP:a9ed31090e55f6152fc31c7512af5d634cc7225a,"This paper studies the dictionary learning problem, where the goal is to learn a dictionary with sparse weights in a linear combination of the coefficients of the dictionary. The authors propose two provable algorithms for dictionary learning with provable dictionary learning methods for coefficient recovery. In particular, the authors propose a linear model, called NoODL, which is a combination of linear and non-linear operations. The optimization is based on the assumption that the coefficients are linear in the dictionary, and that the geometric rate is constant. The algorithm is shown to outperform state-of-the-art techniques in terms of the number of iterations and the performance of neural architectures."
SP:85232b72a2643d6dc81cf952ccbb95192032b7c5,"This paper proposes a new training scheme for learning binary hash codes with a differentiable model and a similarity function. The loss function is based on a log likelihood loss, which is used to learn binary hash code. The authors show that the proposed loss function performs better than prior methods. The paper also shows that multi-indexing can be used to find hashes that are close to the Hamming distance target. The proposed techniques are tested on several similarity search tasks on ImageNet and SIFT 1 M."
SP:3bd4ccff7f48380d2db8dff2c4ca515894a7f1db,"This paper studies the problem of neural architecture search (NAS) for task-specific neural network topology. The authors propose Graph HyperNetwork (GHN) to reduce the search cost by using graph neural network for inference. They show that GHNs are able to learn the architecture of a network faster than regular hypernetworks and premature early stopping. They also show that they can achieve better validation accuracy than random search methods such as CIFAR-10 and ImageNet. Finally, they show that the speed-accuracy tradeoff between networks can be improved by using GHNs in the anytime prediction setting. "
SP:65ccf43cd4e033d22239069057f5200d49f33724,"This paper proposes a method for generative adversarial imitation learning based on expert demonstrations. The idea is to use expert demonstrations to learn the optimal policy from expert demonstrations for Imitation learning. The method is based on multiclass classification, where the discriminator functions are learned using the method. The proposed method is evaluated on a variety of continuous control tasks and shows that the proposed method can learn policies with better performance than the generative imitation learning baseline. "
SP:e8427949a98effbd37ce7604fa11f240e2342196,"This paper studies the inverse problem in natural science, where the hidden system parameters are unknown. The authors propose to use neural networks to solve the task by using the Invertible Neural Networks (INNs) to learn the latent output variables of the INNs. The INNs are trained to predict the forward process of a model in the inverse process by using invertibility of the latent variables. The paper shows that INNs can learn the unrecoverable parameters in the parameter space of multi-modalities in parameter space.  The paper also shows that the INN is able to recover the parameter correlations between the parameters of the model. "
SP:75c9bb53bac29bdb390f9ba5707caee4ab1f5925,"This paper proposes a mixture model approach for deep neural networks (NNs). The ensemble method is based on a scoring rule for the ensemble of NNs, where the prediction uncertainty depends on the mixture components. The authors propose a finite mixture model based on uniform mixing weights. The adaptive, input-dependent distribution is used to replace the fixed mixing weights in the NN. The proposed model is shown to have better uncertainty estimates than other approaches. The experimental results show that the proposed mixture density networks are more robust than compound density networks."
SP:e1e38289285c1b8fdb318e4f6d37a198a08787a2,"This paper studies the problem of model size reduction in deep learning, where the memory footprint of a model class (e.g., deep neural networks) is large and the communication bandwidth and storage requirements are high. The authors propose Shannon-style coding schemes that use a full variational distribution over the empirical weight distribution of the model class, which is a combination of techniques such as pruning, quantization, and pruning. They show that the KullbackLeibler divergence between the sampled variational distributions of the sampled weights and the weights of a random sample of the network weights is a constraint on the compression rate of the encoded network weights, and that the compression rates of these coding schemes are close to the optimal compression rates in terms of the number of bits-back argument. They then propose a method for neural network compression using VGG-16/CIFAR-10, and show that it achieves better compression rates than existing approaches on a fixed memory budget than the encoding scheme with a variational family. "
SP:ad70d8cf3a4558aab0d3b7155594464a3debd912,"This paper proposes a new architecture search method, Differentiable NAS, for large-scale target tasks. The proposed method is based on ProxylessNAS, which is an extension of Proxyless NAS. The main idea is to use a continuous representation of the network architecture to compute the GPU hours and the GPU memory. The authors show that the proposed method performs better than MobileNetV2 on CIFAR-10, ImageNet, and ImageNet with top-1 accuracy. "
SP:e5b70d43d301d1980fae02623ea711976b429c14,"This paper studies the problem of Lagrangian dual in non-convex settings with additive linear penalties. The authors propose a training procedure to solve this problem in both non-vex, large-data settings. The main idea is to use secondorder penalties to penalize the penalized objective with a penalty coefficient that depends on the dimension of the data. The paper shows that the second-order ones are better than the linear penalties in the case of linear constraints.  The paper also provides an algorithm to train the classifier in the stochastic mini-batch settings, where the constrained objective is a deterministic saddle-point equilibrium. The algorithm is shown to improve the performance of the two-player min-max games."
SP:e4720b8e4efdb222c45eafd47fd8a7fbf15d881d,"This paper studies the problem of sampling discrete latent variables for highvariance gradient estimators. Discrete latent-variable models have been studied in the literature for a long time, and it has been shown that the former can be approximated by control-variate schemes and continuous-relaxation methods, while the latter can only approximate the latter. The authors propose a pathwise derivative, where the branch paths in the model are sampled from a set of continuous latent variable models, and the paths are computed using a RWS. They show that the importance weighted autoencoder (RWS) can be used to train the models and inference networks. They also show that it can be combined with state-of-the-art methods for discrete latent-variance models."
SP:7459ae5b1d886e68930c4c9e21df508bc8ab3c9a,"This paper studies the problem of structured output prediction tasks, where the output space is a set of labeled training data and the goal is to learn a scalar reward function based on human knowledge and non-differentiable pipelines. The authors propose to use a truncated randomized search for the reward function of structured prediction energy networks (SPENs) for test-time inference using gradient-based search. They show that SPENs can be trained with supervision and that the learned reward function can be used for unknown local improvements. "
SP:638c1bc09992029b78bd83f0127594dcccb96c06,"This paper proposes an active learning based framework, EffAcTS, for learning policies in a simulation environment. The proposed method is based on the Multi-Task Learning perspective, where the goal is to learn a set of environment model parameters that are robust to changes in the environment. These parameters are then used to learn robust policies that are transferable across different environments. The authors show that the proposed framework can improve sample efficiency and reduce the cost of the proposed method, EPOpt. Empirically, the proposed approach is shown to perform well on continuous control tasks. "
SP:491c239713a6489f0b1790ca26db54a1813c67ae,"This paper proposes a two-timescale network (TTN) architecture for learning nonlinear value function approximations for policy evaluation and control. The main idea is to use a fixed basis and a fixed representation to learn a linear function approximation for the value function in the form of a value function, which is then used to train the reinforcement learning agents. The authors propose two extensions for nonlinear function approximation: nonlinear gradient temporal difference learning and Q-learning. The paper shows that the proposed algorithms can be used in the linear setting, where the dependent features of the linear component are replaced by a nonlinear representation. The proposed approach is evaluated on a variety of data-efficient least-squares methods as well as linear policy evaluation algorithms and eligibility traces. The results show that TTNs are able to achieve better performance than other existing linear value function approximation algorithms in both the linear and nonlinear setting."
SP:327d606cf3813b00a009a7785e08ef9e11f89493,"This paper studies the problem of learning deep reinforcement learning agents with intrinsic semantic regularities in man-made environments. The authors propose LEArning and Planning with Semantics (LEAPS), a multi-target sub-policy and a Bayesian model that uses visual inputs to learn the semantic structures of the sub-policies. The semantic model is trained to predict the actions of sub-problems in the environment. The paper shows that LEAPS performs better than other baselines in terms of semantic content compared to existing baselines. The main contribution of the paper is the use of House3D, a 3D environment with real-world objects in human-designed indoor scenes, to train visual navigation tasks."
SP:d7c26f43bc68d160095b1f50447528843d79edbd,"This paper studies the problem of training deep learning driving models in an unobserved driving environment. The authors propose a new method that combines multi-task perception-related basic knowledge with driving knowledge. The driving model consists of a perception module, a driving module, and a vision module. In the vision module, the depth map and the pixel level understanding of images are used to train the driving model. The depth map is used to learn the control commands for a difficult driving task. The vision module is used for the easier drivingrelated perception problems. The proposed method achieves a better average sucess rate than the benchmark method on a variety of navigation tasks. The generalization and accident explanation ability are improved by using multitask perception knowledge and the driving module. "
SP:b6bd98cc70fab97e1245cbb63a42ef89ab7e7ed5,"This paper studies the robustness of a model trained with adversarial perturbations against adversarial robustness and generalization. The authors show that the accuracy of the model is not affected by the perturbation, and that robust classifiers are able to learn feature representations that are more robust than classifiers. They also show that robust models can learn features from salient data characteristics and human perception."
SP:9c9275d75cd95b1b82e0cbb1421e3d3ade1ce33a,"This paper proposes a method for reverse-mode automatic differentiation in Deep neural networks, called backpropagation. The proposed method is based on local learning rules for gradient-based training of neural networks. The authors propose an iterative optimization of neural activations for inference using an initializing network and a feedforward network for Initialized Equilibrium Propagation with a local learning rule for the feed-forward network. Experimental results show that the proposed network performs better than Equilibrium propagation with the same number of iterations. "
SP:ac9ea91eb465517de495477cf67bc94d5ed1b0cb,"This paper studies the convergence rate of ZO-signSGD with gradient-free operations and signSGD. The authors show that the latter has a higher convergence speed than SGD-type algorithms, and that the sign information of gradient estimates can be used to improve the latter. They also show that gradient estimators can improve the convergence of ZOO-signSVGD with sign SGD. Finally, they show that ZO is able to achieve better performance than ZO on MNIST and CIFAR-10 on image classification datasets. "
SP:5f79b11777f6ef1d70c85418bfc2e4616dd7d960,"This paper proposes a new optimization method for convolutional neural networks with energy-limited edge device. The proposed method is based on the multiplicative multiply-accentuate (MAC) operations in the convolutionan filter. The authors propose a new checkpoint for the MAC process, which is a fine-tuning process to improve the accuracy drop. The method is evaluated on the CIFAR-10 example model and the Network in Network. The results show that the proposed method achieves better accuracy drop than the state-of-the-art method."
SP:7801e9c854ad7d960c0d24fda15597af6994c23f,"This paper studies the problem of learning adversarial examples for neural network models with unique data properties. The authors propose to use temporal dependency on the audio data as a measure of the discriminative power, which is used to measure the ability of the adversarial inputs to discriminate power. They show that using domain-specific data properties can be used to learn adversarial example with domain-dependent data properties, which can be useful for learning principles. They also provide an image adversarial defense against input transformation, and show that adaptive attacks can improve the robustness of ASR systems. "
SP:51830b811a8e39b4f0a5b7609df719e026fac6a1,"This paper proposes a new generative model for generating images from real-world images. Deep generative models can be used to learn representations from images, but they can be biased by core inductive biases. The proposed approach is based on a GAN with a generator that generates the images from a composition of images. The generated images are then passed through a generative network to generate the object representations. The resulting representations are then used to train the GAN. The approach is evaluated on multi-object image datasets. The results show that the generated images have a reference distribution that is similar to the reference distribution of the original images. "
SP:fb59990b8da0e95d8202383478a456667de60449,"This paper studies the problem of learning disentangled representations for computer vision tasks from visual data. The authors propose a deep generative model, reference-based variational autoencoders, for this learning setting. The proposed model is able to learn disenangled representations with minimal supervision. The objective function is learned by adversarial learning. The model is evaluated on three tasks: feature learning, conditional image generation, and attribute transfer."
SP:dbc1983d9b9d72aa14f8e8515d793d2bbde26c9c,"This paper proposes a method for continual online adaptation using deep neural network models for rapid online adaptation. The proposed method is based on meta-learning, where a mixture of models is trained on non-stationary task distributions with the expectation maximization algorithm based on the Chinese restaurant process. The online learning procedure uses stochastic gradient descent to learn the model parameters, and then uses SGD to perform online adaptation via SGD. The authors show that the proposed MOLe outperforms prior methods in continuous adaptation for non-stable task distributions such as motor failures, unexpected disturbances, and varying terrains. They also show that predictive models can be used to control the performance of the predictive model. "
SP:5665e5f006f84927beb0440e145f476e02538077,"This paper studies distributed prioritized experience replay for RNN-based RL agents. The authors consider the problem of distributed training of RL agents, and propose a training strategy called Recurrent Replay Distributed DQN. It combines a single network architecture with hyperparameters and a parameter lag to reduce representational drift and recurrent state staleness. It is shown to improve the human-level performance on Atari games. "
SP:47ace37f31a46d5ee85c283e62ddb71a12f2c5c4,This paper proposes a hierarchical framework for learning sequential generative models for coordinated multi-agent trajectory behavior in offensive basketball gameplay. The approach is based on programmatically produced weak labels for the spatiotemporal regime. The authors show that hierarchical models can be used to learn long-term coordination between agents in these settings. The intermediate variables are then used to train hierarchical models for high-level behavioral semantics. Experiments on synthetic settings demonstrate the effectiveness of the proposed approach on both quantitative and qualitative evaluations. 
SP:1a90cdf028068528b0559e7d44bf26dda20310bd,This paper proposes a new vision model for interacting agents. The proposed method uses ambiguous visual information to extract temporal information from the dynamics model. The method is evaluated on two sports datasets: one with real basketball trajectories and one with a soccer game engine. The results show that the proposed method outperforms baselines on both.
SP:8392f04b7265f665ba6d44d297bca245d44b4708,"This paper proposes a method for end-to-end training of a base neural network for approximating complicated functions in Deep neural networks with gradient descent methods. The main idea is to use a differentiable neural network to learn the functionality of the input to blackbox functionality using a neural network trained on the base network. The black-box functions are defined as functions that can be approximated by a blackbox function interface. The authors propose a new “Estimate and Replace” paradigm for training the neural network, which is based on the “differentiable estimator” and its external blackbox non-differentiable counterpart. The integrated model is shown to perform better than a fully differentiable model trained with a black -box function for inference and inference with the integrated model. "
SP:13fb86de763a0b34ac6fa34ea9dfbd1c476ce43e,"This paper studies the problem of learning a task with data-driven inductive bias. The authors propose a function approximator for the mixture of hierarchical Bayesian models trained on a neural network. The main idea is to use stochastic expectation maximization procedure for parameter initializations for gradient descent and hierarchical Bayes. The proposed approach is shown to improve the diversity of training tasks and improve generalization on the miniImageNet benchmark for 1-shot classification. Finally, the authors show that the proposed method improves the task distribution on a few-shot regression tasks. "
SP:a410144dbe19713a06c63da87d9fb58b999a7492,"This paper proposes Meta Auxiliary Learning (MAXL) for image classification, a hierarchical sub-class image classification task. The main idea of MAXL is to use a meta learner to learn the sub-classes of the principal task, and then use the learned representations to train a multi-task evaluator. The authors show that MAXL outperforms baseline auxiliary learning methods on CIFAR datasets. "
SP:76248e1c914c60ce69de244fe7ec62488d01e161,This paper proposes a neural network based representation for the open set recognition problem. The proposed representation is based on the NeurIPS framework. The authors show that the proposed representation can achieve better performance than the state-of-the-art on a variety of datasets. 
SP:d4ee856bbf2dfb6390e5247086fec2e52dcb6858,"This paper studies the problem of embedded deep network inference. The authors propose a new method for training 4-bit models with cosine similarity. The main idea is to learn a set of baseline networks that are fp32 precision, and then fine-tune the training error using stochastic gradient descent. Theoretical results show that the finetuning improves the accuracy of full-precision baseline networks, and the performance of VGG-16bn networks on the ImageNet classification benchmark. "
SP:6bfdc37b346e6ddfa049e0414647f4beda8ede3f,"This paper proposes a new approach to learn surface properties from sensor inputs for post-bounce trajectories. The proposed model consists of three modules: Physics Inference Module (PIM), Visual Inference module (VIM) and Bounce. The PIM learns the physical parameters and the physical properties for bouncing restitution and effective collision normals. The VIM learns physical parameters for the physical interactions and the Bounce learns the physics simulations. The model is evaluated on the Bounce Dataset and shows that the proposed model outperforms the baselines on the dataset. "
SP:010bd055310c363d3cb0fbe0e11546de58220e15,"This paper studies the problem of adversarial image perturbations in neural networks. The authors consider the case where the target image is imperceptible to perturbation and the network architectures are not robust. They show that the gradients of the network’s weight distribution have a `1-norm’, which can be used to improve the adversarial vulnerability. They also provide a theoretical analysis of the effect of these gradients on the image size. "
SP:5fa3ae057e55be6b71cc94a7dbfe31e54e1c536f,"This paper proposes a new agent modeling for mind model. The framework consists of two learning processes: pure curiosity-driven reinforcement learning for probing policy and imitation learning for approximating an approximated agent model. In the interactive agent modeling scheme, the probing agent is trained with a probing agent. The proposed approach is evaluated on a variety of tasks. The agent model is shown to perform better than existing ones in terms of distilling optimal planning, collaboration, competition, and policy net. "
SP:3af184a5529d6ec2a0862efd1af80ef5b50d2952,"This paper proposes a modification to Neural Networks (ANNs) to improve the activation sensitivities of biological neurons. The modification is based on the fact that the firing modes of a biological neuron have multiple peripheral factors (e.g., neuromodulators). The authors show that by modifying the activation function of the biological neurons, the modulators can be used to modify the parameters of the ANN nodes. The authors also show that the proposed modification improves the performance of Convolutional Neural Networks and Long Short-Term Memory networks."
SP:287a577834fd2820a939a1113b39146a22727491,"This paper proposes a neural analysis and synthesis (NANSY) framework for voice, pitch, and frequency response. NANSY is based on the idea of self-supervised training with information perturbation, which is a popular training strategy in the multilingual setting. The key idea is to use the information bottleneck as an information bottleneck to train the analysis features for controllable synthesis. The authors show that the performance of synthesis networks with these bottleneck structures can be improved by selfsupervised learning. The main contribution of the paper is to show that NANSy can be used in a multilingual dataset for a variety of applications such as zero-shot voice conversion, pitch shift, and time-scale modification. The paper also shows that it can improve the reconstruction quality and controllability. "
SP:90f35ad1ec0c38b0817f5678ee2a5c4f0e08fb38,This paper proposes a new (gradient-based) bilevel programming framework for hyperparameter optimization. The authors consider the overfitting problem in the validation set of a validation set where the optimization properties are not uniform. They show that gradient-based algorithms with regularization terms on the outer and inner levels are more robust to overfitting than cross-validation algorithm with expectation bound. They also show that feature learning and data reweighting can be used to improve the generalization performance of noisy labels. 
SP:42f52aec3a776d87daa5fd72b8e6325d12c88d63,"This paper proposes a knowledge distillation approach for the transfer of dark knowledge from teacher to student. The idea is to distill the knowledge from the teacher model to the student model, and then use the student models to learn the student-friendly representations. The authors propose an algorithm to learn student branches from the student branches. The algorithm is based on the idea that the teacher and student models can be trained in a similar way. The proposed approach is evaluated on a variety of datasets and shows that the proposed technique improves the performance of the teacher models and the resulting student models in terms of accuracy and convergence speed. "
SP:e15a1c21229233fd97dc1dfa0a4ef48b69dc9f95,"This paper studies the problem of extracting invariant features in machine learning. The authors consider the OOD problem, where the out-of-distribution (OOD) distribution is a function of the model selection module in an OOD learning algorithm. The invariance of OOD generalization can be used to improve the generalization error bounds of the algorithms. The main contribution of the paper is to provide a new model selection criterion for the theory. The paper shows that the proposed new benchmark OOD datasets outperform existing baselines."
SP:37b04b9068d39bcf0a581eb8181d13cf1a8926bf,"This paper studies the problem of meta-learning with a stationary distribution in the online setting. The authors propose a Dynamic Gaussian Mixture Model for the meta-parameters of VC-BML, which is based on the Chinese Restaurant Process. Dynamic mixtures can be used to represent the number of component distributions in the parameter space, which can be then used as a proxy for the true non-stationary distribution of the model parameters.  The authors show that the proposed Dynamic Mixture model can be applied to the negative knowledge transfer problem, where the goal is to learn a negative representation of the true parameter space. The paper also shows that the point estimation method for the posteriors of model parameters can be combined with structured variational inference for avoiding forgetting knowledge. "
SP:776d5b02b8d3a8bbcc1f52706f3887c384cb149e,"This paper studies the problem of learning a probabilistic BVP solver that can solve ODE boundary value problems in linear time. The authors propose a new algorithm, called BVP, which is based on the Gauss-Markov prior and it is able to solve BVPs with manifold learning. The main idea is to learn the posterior distribution of a posterior distribution with linear time, and then use this posterior distribution as a model for mesh refinement, hyperparameter adaptation, and uncertainty quantification.  The authors show that the proposed algorithm can achieve better performance than non-probabilistic methods on the first-order boundary value problem, and also on the higher-order problems. They also show that BVP can achieve polynomial convergence rates and adaptive step-size selection. "
SP:86aac0c6b75fdc12f84bba342934865616f866d4,"This paper studies episodic reinforcement learning in the context of reward-mixingMarkov decision process (MDP). The goal is to learn a near optimal policy in a partially observable system. The reward model is learned by switching reward-models, and the reward models are trained to predict the reward function. The authors propose a polynomial-time algorithm for learning a near-optimal policy in the observation space and the latent state space. The algorithm is based on algorithmic and analysis techniques to solve the problem. The theoretical results show that the dynamics of the reward model can be modeled as a time-horizon, and that the proposed algorithm can be applied to a variety of partially observed environments. "
SP:1a3c70ae9cf2a806d603f4b9e7ca6e10b720a956,"This paper proposes a two-step procedure for conditional average treatment effect estimation based on Single-cause Perturbation (SCP) for multi-cause treatment effect. It is based on covariate adjustment for the augmented dataset, which is a simple yet effective way to improve the estimator. The main contribution of the paper is to provide a theoretical analysis of the confounding bias in the multi-cause treatment effect problem. The paper also provides a theoretical justification for the effectiveness of the proposed procedure. Experimental results on synthetic and semi-synthetic experiments show that the proposed SCP performs better than existing methods."
SP:247bc6675cce89d51558537daf63dadb0c4307f8,"This paper proposes a multiwavelet-based neural operator learning scheme for learning an operator’s kernel from fine-grained wavelets. The projection of the kernel is based on multiwavelets polynomial bases, and the inverse operator map is computed using inverse multiwavelett filters. The proposed method is able to learn time-varying equations such as the Burgers’ equation, the Darcy Flow, the Navier-Stokes equation and the Korteweg-de Vries (KdV) equation. The model is shown to achieve state-of-the-art accuracy in terms of relative L2 error compared to neural operator approaches. The method also uses mappings between function spaces to learn a resolution-independent scheme. "
SP:1153785e6a016cfee2644952a772aa08927299b6,"This paper studies the problem of learning full-precision weights for Binary neural networks (BNNs) with 1-bit with sign function. The authors consider the optimization difficulty of BNNs with sine functions such as frequency domain approximation (FDA) and the gradient of sign function in the Fourier frequency domain. They show that the approximate gradient of the sign function is a good approximation of the true sign function with low-frequency information. They then propose a noise adaptation module to reduce the approximation error. They also show that back-propagation improves the performance of the approximations. Finally, they propose a method to learn a binary network with high-frequency coefficients."
SP:33b95ea8da4d30b8e8f9d3fe3acca023d4b8d831,"This paper studies the problem of multi-area RNNs with neuroscience-inspired architecture constraints. The authors propose to use Recurrent neural networks (RNNs) to represent the cortical areas of the brain in neuroscience-based tasks. The main idea is to use a modular computation to compute the minimal sufficient representations of task information in the cortex for each cortical area for each task. The proposed networks are based on Dale’s Law, which allows for the coordination of multiple brain areas. Theoretically, the authors show that the proposed computations are more efficient than the standard constrained multi- area RNN with the same number of neurons. "
SP:db3ced65d67e3373fb3936ec50f41c8ef010bbbe,This paper studies the problem of learning saliency maps for convolutional neural networks (CNNs) for image classification. The authors propose to use structured attention graphs (SAGs) to learn attention maps for each image of interest. These maps are then used to train a classifier with high confidence. The proposed approach is based on diverse sampling to learn a compact and representative SAG for visualization. The beam search algorithm is then applied to learn the saliency map of the image regions. The experiments show that the proposed SAGs perform better than standard SAGEs in terms of user accuracy and user study for comparative counterfactual questions on image classifications.
SP:f2b385bfd9ada0e26aa8829214b424f58582d9f7,"This paper studies the transferability of hidden representations of convolutional neural networks trained on ImageNet with centered kernel alignment. The authors show that the test accuracy of loss functions and regularizers on image classification tasks can be improved by using these representations as representations for downstream tasks using fixed feature extractors. They also show that these objectives can improve ImageNet accuracy over vanilla softmax cross-entropy and hyperparameter combinations for class separation. Finally, they demonstrate that these features can be used for transfer tasks by learning invariant features and features for the downstream tasks."
SP:b66b5e24f68563e2e200eda660f0dbaff53efeff,"This paper proposes a neural network training strategy called selective backpropagation through time (SBTT) for deep generative models of latent dynamics. SBTT is a sequential autoencoders that uses both electrophysiological and calcium imaging data for the inference of neuronal population dynamics using interface bandwidths. The authors show that SBTT can capture the high-frequency temporal structure of neural population activity and the spatial sampling and temporal frequency of sampling in neural interfaces. They also show that with limited, highbandwidth sampling, SBTT improves the performance of pretrain dynamics models trained with SBTT on sparsely-sampled data. "
SP:3513a83806e71006b86d60b779d8bd6bb87c3546,"This paper proposes a hierarchical approach to sequence-to-sequence learning for sequence prediction tasks using neural networks. The approach uses a neural network to predict the local distribution of the input sequence using the neural parameterization of the grammar. The hierarchical approach is based on quasi-synchronous grammars. The authors propose a combinatorial space of derivation rules that can be used to train the models. The proposed approach is evaluated on three domains: style transfer, small-scale machine translation, and compositional generalization (SCAN) on a diagnostic language navigation task with latent neural grammar."
SP:d06fc251f2a9287f7a2236a188349628d8f39d9a,This paper proposes a new algorithm for function-on-scalar feature selection in Group Elastic Net. The proposed algorithm is based on the Functional Principal Components of the Augmented Lagrangian. The authors show that the proposed algorithm can be used to improve the sparsity structure of Group ElasticNet in the ultrahigh dimensional settings. They also show that their approach outperforms competitors in simulations. 
SP:e0b53f76f3a6b756fedd09926f9cf034f89f4a5a,This paper proposes a functional principal component analysis (FPCA) for model estimation. Structured point process data is used as a matrix. The matrix is composed of log-Gaussian Cox processes. The authors show that the proposed framework can be applied to real data analyses. 
SP:3aa213076f3e9f9838ac654517df2fe1fca33499,"This paper proposes Online Meta-Adaptive Control (OMAC), an online multi-task learning approach for adaptive nonlinear control with adversarial disturbance and unknown environmentdependent nonlinear dynamics in a nonlinear system. The authors propose a unified framework for learning control-theoretic and learning-thoroughness guarantees for the robotic system. OMAC uses a shared representation to learn the environmentdependent dynamics and the environment dependent dynamics in the shared representation. They show that OMAC achieves a non-asymptotic endto-end convergence guarantee for multi-tasks non-linear control. They also show that the proposed approach can be applied to robot control. Finally, the authors show the superiority of OMAC over adaptive control approaches and deep representation learning."
SP:cb274c93a169b199ea09120ca02105a3f16b31c5,"This paper studies the problem of certifiable robustness guarantees for neural networks with bound propagation based certified robust training methods. The authors propose two methods: interval bound propagation (IBP) and CROWN-IBP, which are both SOTA (SOTA) methods. They show that they are robust to exploding bounds and that they can be used to improve the per-batch training complexity of neural network training. The main contribution of the paper is to propose a weight initialization method for IBP training, which can be combined with Batch Normalization (BN) for ReLU activation states, and regularization for certified bounds.  The authors also propose Fast-Certified-Robust-Training, which uses BN to regularize the model and improve the certified error of TinyImageNet. The proposed SOTA is based on the network architecture of SOTA, and it is shown that it can achieve a wamrup of CIFAR-10. "
SP:18ffeb199a670fb2b1f4417b8653479001944dab,"This paper proposes a new change point detection method for adversaries. The authors propose a Huber ε-contamination framework for adversarial attacks. The proposed method is based on the phase transition phenomenon of change points detection, which is a well-studied problem in the literature. The main contribution of the paper is to provide a minimax lower bound for the computationally-feasible method. The paper also provides theoretical justification for the proposed method. "
SP:d03617b5fc446768809cf015c9234b0c9386a690,"The paper proposes a new empirical loss based on batch Gradient Descent (GD) for learning the empirical loss. The empirical loss is based on statistical queries (SQ) and SGD. The authors show that SGD and GD can be used to improve the performance of PAC learning with fine enough precision compared to GD and GD with minibatch size.  The authors also show that the population loss can be improved by SGD, GD, and GD.  "
SP:1de2864fe2f53e25596a9bd2c61e2048e79296f6,"This paper studies the minimization problem of the “Lloyd’s algorithm” in the context of machine learning and inverse problems with discrete data. The authors consider the problem of minimizing the Wasserstein error of the model distribution of a model probability distribution over a set of discrete data with Voronoi cells. Power cells are considered as spurious critical points, and the goal is to minimize the error term.  The authors propose a new algorithm based on the point cloud in the ambient space, which is a variant of the Lloyd-type algorithm with a uniform probability distribution.   The main contribution of the paper is to show that the proposed algorithm converges to a point cloud with a Poliak-Łojasiewicz inequality, which leads to a significant reduction in the WASSERSTEIN distance cost.  In addition, the authors also provide bounds on the gradient descent of the algorithm."
SP:c3d364aeee55230a436c3ce4e8dc8310ee73959e,"This paper proposes a new feature transform called relational self-attention (RSA) for deep learning. The relational feature transform is based on rich structures of spatio-temporal relations between relational kernels and relational contexts. The key idea is to use correspondence relations between the representation and the motion information in the representation. The authors show that dynamic transforms can be used to improve video understanding by using convolution layers in Transformer networks. The proposed RSA network outperforms the convolution and self -attention counterparts on motion-centric benchmarks such as Diving48, FineGym and Something-Something-V1&V2."
SP:2c2530069d5cab485629090243da464d107feadd,"This paper studies the mean field theory of multilayer neural networks. The authors propose a new mean field limit for learning dynamics in multilayers. The main contribution of the paper is a new formulation for the stochastic dependency between the network depth and the number of layers. Theoretically, the authors show that the limiting fluctuation distribution of a system of dynamical equations, the second-order mean field, can be defined as a function of the size of the network, and that it can be used to define a new loss function for shallow networks with a squared loss in the empirical risk minimization setting. The paper also provides a theoretical analysis for the multilayered case."
SP:a3d927854d9d7fd39b8d05a79666810d585d5062,"This paper proposes a framework for learning a dynamical system from time-series data with inductive biases for predictive extrapolation. The proposed framework is based on the Hamiltonian/Lagrangian form of the structure of a Hamiltonian / Lagrangian dynamics, where the energy of the flow map is defined by the symplectic structure of the flows. The process of learning a generalized Casimirs is then used to estimate the entropy of the generalized Casimiros, which is used as a parameterization of dissipative brackets in metriplectic dynamical systems. The authors show that the inductive bias of the proposed framework can be reduced to a minimal bias in a black-box model form, which can be used to improve the performance of the system. The system is evaluated on a variety of data-driven modeling and machine learning (ML) tasks, where it is shown that the learned dynamics can outperform the state-of-the-art penalty-based approaches. "
SP:32e8e83e06b1e9a4dad761334d5947c91bfd1853,"This paper proposes a sample selection-based algorithm for fair and robust training in Trustworthy AI. Fairness and robustness are two important components of the unbiased model, and the goal of the training algorithm is to ensure that the unbiased selection of samples is not corrupted by data corruption. The authors propose a combinatorial optimization problem for unbiased selection, where the optimization problem is solved by a greedy algorithm. The algorithm is evaluated on synthetic and benchmark real datasets, and shows that the proposed algorithm achieves better fairness than the state-of-the-art technique, as well as robustness. The sampling step for batch selection is also used to improve the performance of the algorithm."
SP:991127729bf067fe27fdd7ed360aab39e4df5921,"This paper studies the problem of out-of-domain detection with deep neural networks. The authors propose a new class of neural network models with hidden data biases in the function space. The models are based on inductive biases that are defined in terms of function space, where the network weights are determined by a translation-invariant, stationary Gaussian process priors. They show that the authors can use periodic activation functions such as triangular wave and periodic ReLU activation functions to improve the performance of Bayesian neural networks on in-domain data. They also show that these activations are invariant to sinusoidal (Fourier) activations, and that perturbed inputs are not."
SP:d61a2aecfea4612c473b4e6fd41f3dc2fcbb04a1,"This paper studies the problem of coding education with interactive programs with user interaction and complex dynamic systems (e.g., mouse based games). The authors propose two autonomous methods for generating feedback for interactive programs based on unit tests. The first method is based on classifying Markov Decision Processes (MDPs) and using a dynamics and reward model to learn the MDP. The second method uses an agent and an autoregressive model to train a cooperative objective. The authors show that the proposed method is able to generate an automatic feedback system for interactive code assignments with anonymized student submissions. "
SP:daf99ad91613d6e11b13315ccbd1bbe25094ae4b,"This paper proposes a new approach to learn low-level input features from superpixels and attentions. The authors propose a Represent And Mimic (RAMi) framework that uses an identifiable latent representation to represent the independent factors of variation in a DRL action values. The key idea is to learn a disentangled representation of high-level latent object features, which is then used to train a mimic tree to predict the DRL actions. The IB-optimal mimic tree is trained using the Information Bottleneck (IB) principle. The paper shows that the mimic tree achieves better fidelity than baseline models in terms of decision rules, latent traversals, causal impacts, and human evaluation results."
SP:84560de78af979354fff83d1370d8675c1e9191f,"This paper proposes a Bayesian framework for learning the structure of dynamic predictions using Gaussian latent information martingale. The authors propose to use historical data to learn the latent process of information flow. The first, second, and third stages of the process are modeled as trajectories, and the second stage is modeled as a sequence of probability estimates of future binary outcomes.  The authors show that the proposed approach can learn probability paths such as martingales structure, volatility, and political prognostications as well as weather forecasts and financial projections. The proposed GLIM outperforms baseline methods on several metrics for estimating posterior probability path distributions. "
SP:0c4bfb44e0a353256692d5e5ae96f65c1a14363d,"This paper studies the problem of active pure exploration in generic stochastic bandit environments with fixed confidence. The problem is formulated as an optimization problem with proportions that depend on the sampling budget and the structural properties of the environment. The authors derive instance-specific lower bounds for the expected sample complexity of the problem, and propose an Oracle algorithm to solve it using the Frank-Wolfe algorithm for the lower-bound optimization problem. They show that the proposed FWS outperforms state-of-the-art algorithms for pure exploration tasks such as arm identification. "
SP:0947a0f08fba53d3c8af9b78dd64e6e10fc73e32,"This paper studies the problem of drug design, where the goal is to design a drug that can be used in physical lab experiments. The authors propose Bayesian optimization (BO) to solve the problems of optimizing combinatorial spaces such as sequences, trees, and graphs. The main idea is to use deep generative models (DGMs) to learn a latent representation of structures, which can then be used as a surrogate model for the surrogate model trained with a DGM. The surrogate model is trained using the latent space representation of the surrogate modeling, which is then used to evaluate the function evaluation on the discrete structure of the function with respect to a discrete structure.  The authors show that the proposed approach, LADDER, outperforms BO on a variety of real-world benchmarks, and outperforms LADER on a number of state-of-the-art methods. "
SP:37adabdc6615c5199a481553c8ccc06d57363614,"This paper proposes a new representation of state-action value functions for regret minimization based on the representation of the linear structure of the MDP with a linear reward function. The main idea is to use the universally spanning optimal features (UNISOFT) as the Bellman closure assumption. The authors show that this condition can be applied to a variety of problems, including low-rank MDPs, zero inherent Bellman error, and optimistic algorithms such as LSVI-UCB and ELEANOR. The proposed algorithm can be used for representation selection, and it is shown that it has a constant regret bound for optimistic algorithms. "
SP:92566b664ab2f6ee9b73f29327aeef85d14ecf60,"This paper proposes a differentiable contact model for contact mechanics (e.g., frictionless/frictional, elastic/inelastic, etc.) in physical systems such as legged robots, robotic manipulators, and physical systems with contacts. The contact model is based on the Lagrangian or Hamiltonian dynamics in a neural network architecture. The authors show that the energy conservation of the dynamics depends on the inductive bias of the contact model, which is a result of the simultaneous learning of contact and system properties. The proposed approaches are based on differential equations, where the joint angles between the contact and the system are defined as the coefficients of restitution. The dynamics of the differentiable physics simulator can be used to learn the dynamics for downstream gradient-based optimization tasks such as planning and control. The model can also be used for inequality constraints. The experimental results on 2D and 3D physical systems demonstrate the effectiveness of the proposed framework."
SP:82d59a3609dfd458f90f23d4e477c8b497e9dc18,"This paper studies the Benevolent training Hypothesis (BTH) in the context of deep neural network (NN). BTH is a stochastic training procedure in which the training dynamics of the NN are perturbed during training. The authors show that the complexity of NNs with 1st layer bias is bounded by the Lipschitz constant of the parameter trajectory. They also show that NNs have bounded complexity under the assumption that the input space is a dropout. Finally, they provide a training and datadependent generalization bound for NNs."
SP:9b329c915fa8d4045c167c9df37a49ee314d190e,"This paper studies the problem of distribution-independent PAC learning of halfspaces in the Massart noise model. The authors propose a new operation called Forster transform, where the distribution is a disjoint mixture of few distributions, and the anticoncentration properties of the distribution are learned. The polynomial-time algorithm is proposed to solve the distribution-dependent PAC learning problem.  The authors show that the polynomially sample complexity of the Poisson-Time algorithm is O(1/\sqrt{T})^2, which is a significant improvement over existing algorithms in the sample complexity. The bit complexity is also improved."
SP:e5229305af00067ae2dbabd903e585964aec8928,"This paper proposes a Bayesian optimisation-based attack method to improve the robustness of graph classification models trained with Graph neural networks. The proposed method is based on Bayesian optimization, and it is shown that the proposed method improves the adversarial robustness on several graph classification tasks. The authors also show that their method can be applied to a variety of real-life applications such as biochemistry and social network analysis."
SP:4999e5664383066fdacd14be6242c7b83f85f3dd,"This paper studies the problem of online label shift adaptation in the online setting, where the test-time label distribution changes over time. The authors propose two adaptation algorithms, Follow The Leader (FTL) and Online Gradient Descent (OGD), which are based on online learning techniques. The main contribution of the paper is the estimation of the expected test loss. The regret bounds are established for both simulated and real world label distribution shifts, and the model is shown to be robust to label shift scenarios."
SP:806515ae07fb1c9d02773592005d53d4158ef102,This paper proposes a method for detecting and localizing gradual changes in the presence of discontinuity jump in the data generating model. The proposed method is based on time-ordered observations of the distribution of the time-order observations for detection and localization of gradual changes. The authors show that the features of a distribution with prior knowledge can be used as a proxy for the prior knowledge of the features in the distribution. The method is then applied to both detection and the localization. The experimental results demonstrate the effectiveness of the proposed method.
SP:7a3c8a7b17ecab19361d36e1d3d73fa35b71214c,"This paper studies the problem of blind source separation (BSS) problems in the brain. The authors consider linear BSS problems in signal processing with Independent Component Analysis (ICA). The authors show that the ICA neural network (NN) is biologically plausible, and that the neural architecture and synaptic learning rules of a biologically plausible NN can be used as an objective function for ICA.  The authors then propose an algorithm based on synaptic plasticity, which is able to learn biophysical variables in the neural circuit. The NN is then trained by synaptic weight update. The proposed algorithm is shown to perform well on both extracellular calcium and the local field potential of nitric oxide."
SP:22f8b517a3df65144412938f5891c463d7bae0ab,"This paper studies the problem of unsupervised learning with recurrent neural networks (RNNs). The authors show that RNNs are able to learn a task-related behavior with neural activity in the space of solutions for a given task. The authors then propose a two-neuron network to solve the task using discrete dynamical regimes, and show that the diversity of the learned representations can be used to improve the performance of the RNN. They also show that under certain conditions, the representation learned by RNN can be better than the original neural data. "
SP:9b08a0f547ead3b59077a43b1052c6d46a0730f6,"This paper studies the problem of density estimation of covariates in unsupervised learning. The authors propose a new method called Arbitrary Conditioning with Energy (ACE) to solve the problem. ACE is based on the notion of arbitrary conditional density estimation, where the conditional distribution is defined as the sum of the covariates of the joint distribution. The densities are computed by learning one-dimensional conditionals, and then the energy function is used to estimate the densities. ACE uses prior knowledge to guide the inference, and is shown to reduce the complexity. The proposed approach is also shown to perform better than prior methods on several benchmarks for data imputation and arbitrary conditional likelihood estimation. "
SP:f2b14f5854e6aa6922795d1d2051b7402486cef6,"This paper proposes a new MSE or L1 loss function for low-level vision, called single image super-resolution (SISR) in the context of spatial adaptation. SISR is an adaptive weighted loss for deep networks that can be used in situations such as textured and edge pixels, where the visual information is not available in the pixel-by-pixel basis. The paper shows that the smooth areas in the photographic images are more informative than the texture and edge areas. The authors also show that the variance estimation is a good way to regularize the SisR solutions with a sparsity prior, and that the uncertainty estimation can be useful for regularizing SISRs with high-resolution image (mean) and low-resolution images (mean). Finally, the authors show that their uncertainty-driven loss performs better than MSE/L1 loss in terms of visual quality and computation compared to other loss functions.  "
SP:9997583f40fa648adf57bb4fc34228f357be0cf1,This paper studies PAC-Bayesian generalization bounds for adversarial robustness. The authors propose a PACBayesian framework for estimating the averaged risk of perturbations in the learned model under the worst-case analysis. The main contribution of the paper is a theoretically founded analysis that shows that the robust model can be used to defend against attacks such as adversarial attacks. The paper also provides theoretical guarantees for the learning phase.
SP:90b72e8dc41584e38f25dff9fb2853f5b11dc8fa,"This paper proposes a new querying mechanism based on Knowledge Graphs (KGs) for large and incomplete databases. Logical reasoning is an important problem in many domains. The authors propose a query answering process based on low-dimensional visualization of the Gaussian representations of the query representations. The query representations are based on spatial geometries such as boxes, boxes, and boxes. The proposed approach is based on the Probabilistic Entity Representation Model (PERM) which is a Multivariate Gaussian density to represent the entities and the semantic position of the entities. The main contribution of the paper is a new end-to-end objective function for the union, the projection, and the intersection of the two logical operations of projection and intersection. The paper also proposes two transformation tricks for the unions. The experimental results show that PERM outperforms state-of-the-art methods on F1 and public benchmark KG datasets. PERM also performs well on the logical query reasoning problem in the COVID-19 drugrepurposing case study."
SP:b6184c9732dbb7eba7c20cae8869d975c428efe4,"This paper proposes a new algorithm for few-shot meta-learning based on Gradient-based hyperparameter optimization. The main idea is to use forward-mode differentiation to solve the memory scaling issues and gradient degradation issues in memory scaling. The proposed algorithm has theoretical guarantees on the noise reduction properties of the proposed algorithm, as well as on the greedy gradientbased alternatives compared to black-box methods. The authors also provide a theoretical analysis of the hyperparameters of the algorithm. The theoretical analysis shows that the algorithm achieves better performance on CIFAR-10 in terms of the number of iterations and the hyper parameter search ranges. "
SP:9c3a326e5ee4e862923d3bf9415f32a077db8534,This paper proposes a new neural sequence model for candidate generations for structured tasks. The proposed approach is based on neural inference for neural System 1 and logical System 2. The authors propose a symbolic reasoning module to improve the logical consistency of the candidate generations. They show that the proposed approach improves the coherence and accuracy of neurally-based generations in terms of both story generation and grounded instruction-following. 
SP:d77d046095e4c8336c0c76ac48cb046923230753,"This paper proposes an off-policy evaluation (OPE) for continuous treatment settings such as personalized dose-finding, where the treatment decision rule is based on historical data. The OPE is applicable to discrete treatment settings in the context of OPE. The authors propose an estimation method based on deep jump learning to estimate the OPE for continuous treatments. The proposed method uses deep discretization to learn the treatment space. The experiments show the effectiveness of the proposed OPE methods for discrete treatments and multiscale change point detection. "
SP:4d085e57286fdd36143108a002d16914222c239a,This paper proposes a new modeling framework for inference in time-series data for natural sciences and engineering applications. The model is based on a Markov jump process with a subordinated diffusion process. The authors use evolution equations to model prior and posterior marginal densities. The diffusion level is approximated by a Gaussian process approximation and posterior inference. The Bayesian latent state estimates are obtained by path-wise Kullback-Leibler divergence. The point estimates of unknown system parameters are obtained using variational expectation maximization. The proposed algorithm is evaluated on real-world examples.
SP:d1f396e691f9d331adfb7b694a99c50e8004331f,"This paper studies the problem of nonlinear inverse problem. The authors propose a nonlinear mapping from linear mapping to nonlinear transformation. The model is based on the nonlinear processing function, and the proposed model can be applied to signal processing problems such as compressed sensing, phase retrieval, and phase-retrieval problems. The main contribution of the paper is a new recovery methods based on expectation propagation algorithm (EP) and spikiness of sensing matrices (e.g., the spectrum of sensing matrix). The authors show that EP recovers the EP with spikier spectrums, which is a good measure for recovery. The paper also shows that EP can be used to recover the recovered EP from the spectrum. "
SP:ee66604d4da9fd04826e90ccbb94f0499eba4c63,"This paper proposes a new approach to learn the auxiliary semantic information for Generalized Zero-Shot Learning (GZSL). The proposed approach is called Dual Progressive Prototype Network (DPPN) and is based on attribute prototypes. The proposed DPPN uses attribute prototypes to generate prototypical visual patterns that can be used as attribute-related local regions. The authors show that the cross-domain transferability and category discriminability of the visual representations can be improved by using the attribute prototypes in DPPNs. The paper also shows that the attribute localization ability of visual representations is improved by the use of the unifed framework for visual representations. Finally, the authors demonstrate that the proposed approach can be applied to the domain shift problem of GZSL. "
SP:61eb6297568c3f6869fbb03eaf6a21260de5466c,This paper studies the problem of removing defocus blur from images. The authors propose an end-to-end deep learning approach for removing the all-in-focus image from a deep neural network trained with GKMNet. They show that the accuracy of models trained with this approach can be improved by using a fixed-point iteration for GKMs. They also provide a spatially variant amount of mixing coefficients for the mixing coefficients in GKMS and a scale-recurrent attention module to improve the performance of the deep network. 
SP:18bf447c90935c373e5ec4cdfbbf8f2a273d2edb,"This paper proposes a new model for SSVRL based on the multi-instance InfoNCE loss. The proposed method is based on a cross guidance contrastive learning algorithm, which is a cross-encoder-decoder architecture. The main idea is to learn the mutual information between the RGB frames and the motion vectors in low-resolution optical flows from compressed videos with visual content. The authors show that the proposed MVCGC outperforms the state-of-the-art methods on several downstream tasks."
SP:8c7b1d976d9758cd534c565ec31a23f97892e503,"This paper studies the problem of overconfidence in ReLU Bayesian neural networks (BNNs) under the infinite-width limit. The authors propose a Bayesian treatment for the overconfidence of ReLU nets, which is based on the Gaussian process (GP). The authors show that the features of a BNN with infinite ReLU features are asymptotically better than those of Bayesian linear models. They also show that it can be used to train BNNs with finite GP. Finally, they show that their model can be applied to the GP posterior of a ReLU BNN. "
SP:e77276f61626e896f6a985296f1d832129242cdf,This paper proposes a new bestarm-identification bandit framework. The authors propose two tools for finite-sample confidence bounds for the estimation of potentially complex nuisance functions: LUCB and Successive Elimination. The main contribution of the paper is to provide asymptotic variance bounds for best-arm identification algorithms based on the bounds obtained by the bounds derived by LucB. The proposed method is shown to have lower sample complexity than existing methods and achieves better upper bounds than existing best-armed-identifying algorithms. 
SP:471361588bfc6c6033631509d1e43e77fd9721ce,This paper studies the scalability of distributed learning with stochastic gradient descent. The authors consider the communication cost of the gradient with respect to the number of iterations of training without compression. They show that the algorithm with biased compression has a compression error of $\epsilon$ and that the variance of the stochedastic gradient is bounded by a moving average of the history gradients. The convergence speed of the asymptotic convergence rate of ErrorCompensatedX is shown by a unified theoretical analysis framework for variance reduced algorithms. 
SP:3b7ff0dc668cac2191d95fcc4dc6e0335dec3206,"This paper studies the problem of explainability of graph neural network (GNN) explainers. The authors propose a performant paradigm for multi-grained explainability based on a pre-training and fine-tuning idea to improve the explainer’s local explainability and global explainability. The model is trained on a graph, where the class-wise patterns are represented by a local context and the local context is represented by the global context. The explainer is trained using the pre-train phase, and the fine-tune phase is used to improve explainer's performance on both synthetic and real-world datasets. The proposed explainer outperforms existing baselines in explaining graph classification on AUC."
SP:9b5a62d3a2b27bc60da28980e9fb0ecdff1215c0,"This paper proposes a new method for providing counterfactual explanations for graph neural networks (GNNs). The proposed methods are based on a subgraph, where the noise is added to the input graph and the explanations are computed using human intuition. The authors show that GNNs can be used to provide common decision logic for GNN with common decision boundaries, and they can also be used as a GNN to provide explanations for graphs with edges."
SP:4edb870786c9cea2c6075359cb4e79b02a8e2f5f,"This paper studies the problem of voice conversion in the context of self-supervised representation learning. The authors propose VoiceMixer, an information bottleneck based on adversarial feedback to improve the generalization of the discriminator in the presence of content and style discriminator. The proposed model is evaluated on the transfer of audio quality and audio quality of the converted speech containing source speech style. "
SP:9fbb0c6beb3f8f88972f13dcf0e1fe7db03233c7,"This paper proposes a Siamese voxel-to-BEV tracker for tracking in sparse 3D point clouds. The tracking is based on sparse point clouds, where the shape information is encoded in a dense 3D shape, and the template feature embedding is learned from the template’s feature. The paper proposes to use the Siamesa shape-aware feature learning network and a voxell-to -BEV target localization network to learn discriminative features. The proposed method is evaluated on KITTI and nuScenes datasets and shows that it outperforms state-of-the-art methods."
SP:8b788c78680a54c453a04f4551436763ee57585e,"This paper proposes a new positional encoding method based on learnable Fourier features for attention-based deep model architectures such as Transformer. The proposed multi-layer perceptron is used to trainable encoding using learnable Fourier feature mapping. The representation maps the spatial multi-dimensional position (e.g., image, pixel positions) to L2 distances and positional relationships. The authors show that the proposed methods achieve faster convergence compared to existing methods, and can be used to learn a more accurate Fourier feature representation. "
SP:d2ac1b6381315bce4449f09bd519f33a2a42d714,"This paper proposes a recursive constraint-based method to solve the problem of large graphs. The system is modeled as a causal MAG with observational data. The problem is formulated as a problem where the latent variables and the selection bias of the system are determined by the causal MAG. Constraint-based methods are used to solve this problem. The authors show that the former has a lower computational complexity than the latter, and that the latter has a better upper bound on the number of CI tests required for CI tests. They also show that their approach is more efficient than the state of the art in terms of both synthetic and real-world structures. Finally, they provide completeness guarantees for their technique."
SP:49a4912ce457f5f5ec62c44fa10444af8075fabf,"This paper proposes a new batch Thompson Sampling framework for online decision making problems with information parallelism. The main idea is to learn a batch policy for exploration-exploitation trade-off, where the goal is to minimize the (asymptotic) regret bound of a batch Thompson sampling policy. The authors show that this batch policy can achieve exponential reduction in the number of iterations of the batch policy. They also show that the dynamic batch allocation performs better than natural baselines such as static batch allocations."
SP:653a519e3c799c25e0d0b4240322642040b121a3,"This paper studies the problem of Domain Adaptation (DA). Domain adaptation (DA) is an important problem where the goal is to learn representations that are invariant to domain-invariant perturbations. The authors consider the problem in multiple source DA and domain generalization (DG) settings, and propose to use upper-bounds on the target general loss as upper-bound for domain- invariant representations. They show that these representations are not always invariant, and that they can be used to improve the performance of DA. They also provide a theoretical analysis of their theory."
SP:2a7bee950cd07494d59dfee60ac2e86cc0e481b1,"This paper proposes a new model compression technique called network pruning based on L2 regularization to reduce sparsity in SR networks. The proposed method is based on an aligned structured sparsity learning strategy, where the weight normalization layer is added to align the network parameters. The authors also propose a sparsity structure alignment penalty term to ensure that the norm of soft mask gram matrix is aligned with the pruned filter locations in the layers. The experimental results show the effectiveness of the proposed method."
SP:e9830bb9e7d3ddc3bd1c2994590fdb5d8f3668be,"This paper studies the problem of exploration in multi-agent reinforcement learning with EMC. The authors propose a factorized MARL algorithms, where the embeddings of local actionobservation histories are used to train the agent to explore the environment. The goal is to maximize the mutual information between the agent and the environment, and the agent is encouraged to explore as much as possible. The agent is trained with an episodic memory for policy training, which is then used to learn the ""induced"" individual Q-values (e.g., individual utility functions) for local execution. The intrinsic rewards are used for coordinated exploration. The proposed method is evaluated on a variety of tasks, including StarCraft II micromanagement benchmark, and compared to other MARL baselines. "
SP:c7e33d479575c88e22282ee6fd4f978bcd3c06ed,This paper studies the problem of list-decodable linear regression with Gaussian covariates. The authors propose a new Statistical Query (SQ) lower bound for the problem. The upper bounds for this task are based on upper bounds on the noise distribution of the hypothesis vectors of the regression vector. They show that the SQ lower bound is better than existing algorithms. 
SP:7b258252a9063514348f5fa8d9c85afd85748747,"This paper studies the problem of learning a system’s temporal behaviour in a small sample regime. The authors propose two Machine Learning (ML) approaches to this problem. The first is based on systems of Ordinary Differential Equations (ODEs), which can be used to learn ML models with expert domain knowledge from pharmacology. The second is a latent hybridisation model (LHM), which combines expert-designed ODEs with machine-learned Neural ODE. The proposed LHM is evaluated on synthetic data and shows that it is able to learn observable quantities from expert and latent variables. "
SP:3ea9e86e5755ef84d28e3163c60531ace5d62e3a,"This paper studies the problem of representation learning for meta-learning in the context of rapid learning of new tasks. The authors propose two works, MAML and fine-tuning-based objective, for per-task adaptation. The main idea is to learn a representation for each task by per-tasks, which is then used as a “frozen representation” objective. The proposed algorithm is based on the theoretical framework of few-shot learning, and the proposed method uses a shared structure to learn the shared representations. The paper shows that the proposed risk bounds for the predictors obtained by finetuning the predicted predictors using gradient descent are tight in both logistic regression and neural network settings."
SP:8ba5a2ac80f7c53f81ad008e96c033ecad14ac0d,"This paper proposes a new lexicalist approach to learn a compositional and grounded meaning representation of language from grounded data such as paired images and texts. The authors propose a neuro-symbolic semantic program in symbolic form, where the syntactic type of adjective is represented by a neural network embedding, and the semantic program is represented as a neuro - symbolic semantic program with lexical meanings. The paper shows that the learned meaning programs can be used to learn compositional compositions of words, and that the training time is exponential in the exponentiallygrowing compositional space. The proposed joint parsing and expected execution algorithm are used for learning the learning of the joint parsing. The experimental results show that the proposed G2L2 can achieve state-of-the-art performance in two domains: visual reasoning and language-driven navigation."
SP:16c458651815813efdcbe8ba1205bbddbe3e4e68,"This paper proposes a stochastic Newton algorithm for homogeneous distributed stochastically convex optimization. The proposed method achieves better convergence guarantees than existing methods for communication rounds and quasi-self-concordant objectives (e.g., logistic regression). The main contribution of the paper is to show that the population objective can be approximated by stochedastic gradients and stochy Hessian-vector products. The authors also provide a theoretical analysis of the convergence of the proposed method. "
SP:d7e479d59f82d4c55372a68ca7b4516f2871f346,"This paper proposes a new similarity measure called Density-aware Chamfer Distance (CD) and Earth Mover’s Distance (EMD) to measure the distance between two points in a point cloud. The two metrics are based on the notion of mismatched local density. The authors show that the global distribution of the EMD can be used as a global distribution for the CD, and that it is able to capture the disparity of density distributions. It is also shown that the CD can capture more detailed structures than EMD. The paper also shows that the DCD can be applied to the point cloud completion task."
SP:e4b302009520770814ff2c096020b779a9fc38fe,"This paper proposes to use knowledge distillation to improve the performance of a small student network in a teacher model (e.g. ensemble of networks). The idea is to distill the knowledge of the teacher model into a small set of predictive distributions, and then use it to optimize the student generalization. The authors propose a dataset for distillation, and show that it can achieve better performance than the state-of-the-art. "
SP:895c7e03f9e4dadb94be1f39d61bf0b5e1533f4f,"This paper proposes a new algorithm for learning a (k, ε)-coreset of decision trees in the context of machine learning. The coreset is composed of a k-tree and a partition tree. The partition trees are based on the computational geometry of partition trees, and the decision trees are the axis-parallel rectangles. The error parameter of the partition tree is computed as a function of the number of nodes in the tree.  The goal of the algorithm is to learn an optimal k-trees, which is then used as a regression or classification loss. The authors show that the resulting coresets can be used for random forests and parameter tuning, as well as sklearn and lightGBM. The performance of the coresets is evaluated on real-world data-sets, showing that the accuracy and computation time of these coresets are comparable to those of random forests. "
SP:f3ece96b15ec06d703925df2061ed9694ec3bca5,"This paper studies the problem of top-m identification in medicine and recommendation systems. The authors propose a new algorithm, called δ-correct algorithm, for the Top-M identification problem. The problem is formulated as a fixed-confidence Top-mu identification (TMA) problem with misspecified linear bandit models. The main idea of the problem is to learn a linearity of the structure of the problems, which is then used as a tractable lower bound on the sample complexity of the upper bound. The proposed algorithm is tested on both synthetic and real-world data, and is shown to outperform existing algorithms in both settings."
SP:e71c5e39b8d8d1640d6de2352ac51ddd52eea89d,This paper proposes a new self-supervised learning method for disentangled graph representation learning. The proposed method is based on the Disentangled Graph Contrastive Learning (DGCL) method. The authors propose a new contrastive learning objective based on a factor-wise discrimination objective. The method is evaluated on both synthetic and real-world datasets and compared to state-of-the-art baselines.
SP:0a7edbbdabab11273689c40c517001eb46491113,"This paper studies the robustness of large scale networks under stochastic simulation in the context of Statistical Reliability Engineering. The authors propose a statistical hypothesis test for robustness assessment, which is a popular technique in the literature. The proposed procedure is based on Importance Splitting simulation. Theoretical guarantees are provided for the theoretical guarantees. The empirical results show that the proposed method can achieve better robustness than existing methods."
SP:c1db485ff1ff9573daa421e167225654babb55ac,"This paper studies the problem of unsupervised image generation with Deep polynomial neural networks (PNNs) in the context of generative modeling in machine learning. PNNs are commonly used for conditional generation tasks such as super-resolution and image-to-image translation. The authors propose a new framework called CoPE to learn a two-variable inputs: a noise variable and a conditional variable. The noise variable is a function of the input variables, and the conditional variable is the output of the PNN. The two-variance inputs are learned by single-variable Polynomial expansions. The proposed framework is able to learn auto-and cross-correlation between the two input variables. CoPE is shown to perform well on a variety of tasks including attributeguided generation, class-conditional generation, and inverse problems. "
SP:5a75bc7a3ea0ce971cfceebbc1c2434e3aa2584d,This paper proposes a new approach to estimate the MMD statistic for NTK based two-sample tests using a neural tangent kernel (NTK) and MMD. The approach is based on the connection between NTK test statistic properties such as Type-I error and testing power. Theoretical results show that the proposed MMD statistics improve the memory and computational complexity of the online implementation. Empirical results on synthetic and real-world datasets demonstrate the effectiveness of the theory. 
SP:1df2ffbbe56b8018067820980b93af2a8b57f891,This paper proposes a new method for detecting and defense of adversarial attacks. The proposed method is based on a variational autoencoder G (G) with class-disentanglement. The main idea is to learn the minimum necessary information for a neural net D (D) using the class-dependent information from the variational auto-encoder G. The authors show that the proposed method outperforms the former by a large margin. The paper also shows that it can detect clean images and adversarial images.
SP:2789874561620ba7894c4672f935056bb911e919,"This paper proposes a federated Thompson sampling (FT) algorithm for Bayesian optimization (BO) in the federated learning (FL) setting. The authors show that the privacy guarantee of FTS has a differentially private FTS with differential privacy (DP) for deep neural networks, and that DP can be used to improve user-level privacy for iterative algorithms. The proposed algorithm is based on local modeling for BO, where the DP framework is used to learn the parameter vectors. The utility of the proposed algorithm, DP-FTS-DE, is evaluated on real-world experiments. The theoretical guarantees of the utility and privacy of DP-FT-DE are shown. "
SP:be7d6b81736a2c3f89abd8771b41b18802e88832,"This paper studies the problem of Multi-label classification (MLC) in the sparse label setting, where the data is not available to the model. The authors propose a new model, called AL, that is able to learn sparse labels from sparse data. The main idea is to use a Bayesian Bernoulli mixture of label clusters to learn the global pattern of label correlations. The mixture component is then used to predict the label correlations between the two clusters. The proposed model is evaluated on real-world multi-label datasets."
SP:2b7270b0370c193300bcbbb5fb0a4101b3329d99,"This paper proposes a new streaming data source called lidar perception models with end-to-end latency. The main idea is to use cartesian coordinate systems to learn the spatial context of a point cloud, and then use a polar coordinate system to map the point cloud to a set of rectangular regions. The spatial context is learned by multi-scale padding. The authors show that the proposed methods are able to perform well on the nuScenes dataset. The core polar convolutional architecture is based on feature undistortion and range stratified convolutions. "
SP:7ae2c5b7d9c8a6c8f4a353606aa419929c47f31b,This paper studies the problem of learning latent variables for deep learning models with prior knowledge in the presence of biased gradients. The authors propose a learning approach to learn the latent variable using a differentiable surrogate to guide the training. The surrogate is trained with a Gumbel-Max trick to learn distributions in structured domains. The score function estimators are used for optimization and differentiable surrogates are used to train the model. The main contribution of the paper is the formulation of recursive algorithms such as stochastic invariant. The feature is used to improve the gradient estimates and control variates of structured latent variable models compared to relaxation-based counterparts.
SP:415d363c66a6967c1daca9dc02001b85bf7f0752,"This paper studies the problem of image denoising in deep convolutional neural networks (CNNs) with large datasets. The authors propose a new method, GainTuning, which uses a multiplicative scaling parameter to improve the performance of CNNs. The main idea is to use a noisy image to train denoisers, and then use the learned models to extract features from the noisy image. The proposed method is evaluated on a variety of image-denoising benchmarks and shows that it outperforms the state-of-the-art CNNs on these benchmarks."
SP:90afa1102683b456bc72a54abef466326827546a,This paper proposes a fully differentiable architecture for simultaneous semantic and instance segmentation with panoptic segmentation. The proposed architecture consists of a convolutional neural network and an asymmetric multiway cut problem solver. The latter is used to solve the combinatorial optimization problem for panoptical labeling with semantic and boundary predictions. The optimization problem is formulated as a gradient-based optimization problem where the objective is to find a smooth surrogate of the panoptimistic quality metric. The authors show that the proposed approach can be used to perform large scale real-world problem with optimization and deep learning. The experimental results on Cityscapes and COCO datasets demonstrate the effectiveness of the proposed approaches.
SP:1952e174d9ec7b83ad1d394ece7fe77ea1f6d78d,"This paper proposes Recursive Bayesian Networks (RBNs), a family of sequence models based on Probabilistic context-free grammars (PCFGs) and dynamic Bayesian networks (DBNs). PCFGs and DBNs can be viewed as nested hierarchical dependencies (tree structures). The authors show that continuous latent variables can be used to represent the joint distribution of a tree-structured Bayesian network, which can be either discrete or continuous. The maximum posterior estimates are obtained by gradient descent on the continuous latent variable. The authors also show that the exponential number of possible structures and the number of continuous variables is sufficient for joint inference, robust parameter optimisation, and Bayesian inference.    The authors demonstrate that the performance of RBNs on a variety of tasks, including change point detection, hierarchical clustering, and segmentation with noisy sequences, is comparable to the performance on synthetic data. "
SP:5f29b169d3e4bbaeeec85e1aeebe2094fae4be6e,"This paper proposes a pseudo-Lagrange multiplier method for constrained backpropagation (CBP) algorithm. The objective functions of deep neural networks are known to be objective functions with backward propagation of errors (backpropagating) and the loss functions of objective functions are known as loss functions with weight precision.  The authors propose a posttraining method for CBP by using the constraint functions of the learning algorithm: two-bit shift weight constraints and binary weights. The authors show that the proposed CBP can be combined with GoogLeNet, ResNet-18, and GoogleNet in ImageNet and achieves better top-1 accuracy than existing methods.   "
SP:3ddf8e2e108fb261bb23aec8a27a25aba7523dc1,This paper proposes a new acquisition function to improve the data/label efficiency in Active learning. The acquisition function is based on the Gaussian Process Classification (GPC) framework. Active learning strategies are used to reduce the classification error by using active learning strategies for Estimated Error Reduction (ER). The authors propose a query synthesis active learning algorithm that uses gradient-based optimization techniques for query synthesis in a continuous instance space and a discrete instance set (pool-based scenario). The EER-based acquisition functions are trained in an onestep-look-ahead manner. The authors show that the gradient of the acquisition function can be computed using a gradient chain rule. The one-dimensional integral is used to learn the joint predictive distribution of label pairs. The proposed algorithms are evaluated on synthetic and real-world datasets and show that it performs better than state-of-the-art algorithms in terms of sampling efficiency. 
SP:fa1fac04cd4ccb1f3eaf80807db09f9683ce6b50,"This paper studies the problem of continuous variational autoencoder (VAE) models where the parameter gradients are unbounded gradients. The authors consider the case where the data is a low-dimensional manifold (e.g., natural images). They show that the energy functions of bounded gradients can lead to numerical instabilities when the number of parameters in the model is large. They then propose a VAE energy function that can be used to regularize the parameters of the model. The paper also shows that the over-regularization and underregularization can be combined to improve the performance of the autoencoders. "
SP:2611cfd6e0696a57d061687993cef1fe5c95999d,"This paper studies graph feedback in the bandit problem, where the goal is to find a directed graph with min-max regret. The authors propose a dual linear program with fractional weak domination number and k-packing independence number to solve them. The regret upper bound is based on a strong duality theorem. The lower bound relies on the fact that the optimal regret is bounded by the bounded degree of the graphs. "
SP:e50dec57af337839cbde4b65fb7b431785fda44d,"This paper studies the problem of model agnostic feature attributions based on Shapley values for sparse feature relevance attributions. The authors propose a self-normalised importance sampling estimator based on the Nadaraya-Watson estimator, which is a kernel regressor with neighbourhood reference distributions. They show that the Shapley analysis improves the on-manifold explainability and robustness of adversarial classifiers. "
SP:35bdeb78f9fe74e754177fb54b48e7399dc8590d,"This paper studies the problem of feature representations for deep reinforcement learning (RL) and proposes to use them for feature learning in order to improve the data efficiency of RL feature representation learning. The authors propose to use a backward dynamics model to model the trajectory cycle of a trajectory in PlayVirtual, which is composed of state-action sequences, i.e., un-experienced or less-empirical trajectories (e.g. state-actions). The authors show that this trajectory has a cycle consistency constraint, and that the dynamics model can be used to learn the dynamics of the trajectory. The proposed method is evaluated on the Atari and DeepMind Control Suite benchmarks and shows that the proposed method achieves better performance than existing designs. "
SP:ca09e472cbcf2ac8c8c9b192a87df2ed59218210,"This paper studies the robustness of neural network architectures with noisy labels on large real-world datasets. The authors propose a framework to measure the robusts of a network’s architecture against noisy labels. The proposed architecture and target/noise functions are trained with a linear model with clean labels. They show that the proposed representations have better predictive power and better test accuracy than other representations trained with noisy-label-training methods, and that their architecture is more robust against noise than other methods. "
SP:903727fe028684623a8ccadec210e641ecffc685,"This paper studies the problem of Reinforcement learning (RL) algorithms. The authors propose a method to learn a reward function using RL algorithm with hyperparameters. The proposed method is based on a data-driven Bellman equation, where the intermediate reward function is a function of the number of transitions in the two-stage process, and the goal is to learn the value function. The paper shows that the proposed approach can achieve better performance than prior methods. "
SP:39ccbd5909a1d7ed212fe92d8d6843c2c70dfe1f,"This paper studies the problem of differentially private stochastic optimization in convex and non-convex settings. The authors propose a new algorithm for the l2 setting with near-linear time. The proposed algorithm is based on the general non-smooth convex losses, and is able to obtain a dimension dependent lower bound on the nearly-optimal excess population risk. The algorithm is also able to converge to the optimal excess risk in the l1 setting. The paper also shows that the proposed method can be applied to the non-strongly convex l2-case and the lp setting."
SP:99a476f71e6901aefe281f11fb72ff78265a5b6e,This paper studies the cooperative bandit problem in large-scale decision-making. The authors consider the problem of communication between stochastic networks with arbitrary corruptions and delays. They show that message-passing with adversarially corrupted rewards with random delays can incur group regret with tight network-dependent minimax lower bounds. They also show that decentralized algorithms can achieve near-optimal guarantees in these environments. 
SP:d3e896a65470f2439bc7753b4f66e152306b2d6f,"This paper proposes a new transformer for computer vision applications. The key idea is to use a post-training quantization algorithm to improve the performance of vision transformers trained on mobile devices. The authors propose a quantization task with optimal low-bit quantization intervals. The quantization objective is based on a ranking loss, and the attention mechanism is a weighted sum of the quantization loss and the feature diversity. The attention map is a nuclear norm of the attention map. The proposed mixedprecision quantization scheme is evaluated on the ImageNet dataset and shows that the proposed method improves the top-1 accuracy of the DeiT-B model."
SP:aa6b1328585b5916267a3ff4f9119e7aa4ce2bb5,This paper studies the overestimation issue of Q-learning in the context of synchronous double-Q-learning. The authors propose a sampling strategy to achieve the global optimum in asynchronous double-learning with a polynomial learning rate. The convergence rate is shown to be faster than the constant learning rate under the assumption that the state-action space is a finite-time analysis. The paper also shows that the asynchronous algorithm has a lower time complexity than the synchronous algorithm. 
SP:04fd4d83717c4f7e1a4b5651a59200151f33411d,"This paper studies semi-supervised learning (SSL) studies in OOD detection settings, where the distribution of labeled data is different from that of the unlabeled and test data. In this setting, SSL algorithms can be applied to real-world applications. The authors propose a technique called Structure-Keep Unzipping (STU) to improve the performance of the proposed approach STEP in the setting where the labeled data and in-distribution data are not available. STU is based on the optimization algorithm from [1]. It uses a representation space to represent the OOD samples and the unknown distribution. Experiments show that the proposed STEP approach performs better than other methods in detection."
SP:6bf8b94483b26033795b0eda9649518027f5e1c2,"This paper proposes a two-stage setup for visual grounding for visual reasoning. The main idea is to use a one-stage multi-task framework to learn visual grounding tasks such as phrase localization and referring expression comprehension/segmentation. The proposed transformer architecture consists of two modalities: a visual-lingual encoder and a decoder. The model learns contextualized lingual queries from contextualized information, and then uses the learned model to generate contextualized expressions for the decoder to use as a bounding box. The learned segmentation mask is used to represent the referred regions. The contextualized model is compared to state-of-the-art methods on both REC and RES tasks. The pre-training schedule is also evaluated on an external dataset. "
SP:29b552b36696c9bda72f3ab4f31605d98880fd6b,"This paper studies the problem of multiclass boosting, an algorithmic approach to improve the performance of the agnostic PAC learner (e.g. weak learner). Multiclass boosting is a well-studied and well-motivated problem in the literature. The main contribution of this paper is a new boosting algorithm for weak hypotheses. The authors propose AdaBoost, a boosting algorithm that can be applied to both weak and moderately inaccurate hypotheses. They show that the weak-learner calls are more accurate than the strong learner calls. They also show that AdaBoost can improve the classification loss of an agnosticPAC learner."
SP:f63b050773871338c48b778c362172e4b72477a4,"This paper proposes a new unsupervised learning of object-representations. The proposed model, GENESIS-V2, is based on a clustering procedure for randomly ordered object representations. The authors show that the proposed method outperforms existing methods on both simulated and real-world datasets with limited visual complexity.   The authors also show that GENESis-v2 is able to learn a variable number of object representations using RNNs and iterative refinement, which is more efficient than existing paradigms such as the embedding-based approach. "
SP:408deb9e5577ee7118b836fee77135df641fe545,"This paper proposes a black box method for point predictions. The framework is based on conformal inference, where the data generating distribution is sampled from a data generating process. The learning problem is to learn the distribution shift in the data generated by the distribution shifts. The authors show that the adaptive approach has a better coverage frequency than conformal in terms of the number of samples. The proposed method is evaluated on a variety of real world datasets."
SP:e6e5b1e2428abcf1a163ec1cce15cd299f9a544f,"This paper studies the problem of multi-person pose estimation in crowdsed scenes. The authors propose Pose-level Inference Network (PINet), a direct pose-level inference strategy based on bounding box detection and keypoint grouping. The PINet learns complete pose cues from visible body parts as well as visual body cues for global pose cues. The Pose Refinement module uses pose priors to refine coarse poses using Part-based Pose Generation (PPG) and PINet for coarse poses with overlapping and occlusions. PINet is trained with discriminative body parts and the Pose Fusion module is used to learn the pose cues for each person bounding boxes. The proposed PINet achieves state-of-the-art performance on several crowded scenes pose estimation benchmarks. "
SP:e76f048c3dccffcb8bcc6a66f6165fc19d175610,This paper proposes a new algorithm for Bellman operator for S-rectangular robust Markov decision processes (RMDPs) in robust reinforcement learning algorithms. The proposed algorithm is based on the homotopy continuation method and bisection method. The authors show that the proposed algorithm has quasi-linear time in terms of S-ratio ambiguity in the form of cubic time. They also show that it can be combined with a leading commercial optimization package to achieve better cubic time than leading general linear programming methods. 
SP:c4af66a64a5c2bd58ca2e29dbc4b27d5bf4b63b8,"This paper studies the online knapsack problem. The authors propose two online algorithms based on machine-learn predictions. The first is generalized one-way trading, and the second is two-stage onlineknapsack. The competitive ratio of the online algorithms is studied. The upper and lower bound are provided."
SP:1d478d4fa3f5df0ded963ef164325667fd744dbb,"This paper proposes a new episodic control for reinforcement learning based on a model-based episodic memory of trajectories. The proposed architecture combines dynamic hybrid control with model- based, episodic and habitual learning in order to train a complementary learning model that uses the memory to guide the agent. The authors show that the proposed model outperforms existing reinforcement learning agents in both stochastic and non-Markovian settings."
SP:551174c1266b5f4b6aaf5432a4c713386f90898c,"This paper proposes a new SSL method called DP-SSL, which is based on the data programming (DP) scheme for learning probabilistic labels for unlabeled data. The authors propose to use pseudo labels to represent unlabeling data as pseudo labels, and use DP methods to learn initial labeling functions (LFs). The DP methods are based on human experts, and can be trained using DP methods. The proposed SSL method is evaluated on a variety of SSL benchmarks, and the results show that DP -SSL outperforms SSL methods in terms of classification accuracy and annotation accuracy on test data. "
SP:d1d6a40a8bde62a21da4fc18a076e344c84ab0d0,"This paper proposes a multi-view Pose transformer (MvP) for estimating multi-person 3D poses from multi-views images. MvP uses a geometrically guided attention mechanism, called projective attention, to capture cross-view information. The proposed pipeline is evaluated on the Panoptic dataset, and the accuracy of MvP is shown to be better than state-of-the-art methods. The authors also propose a hierarchical scheme to learn query embeddings of multi -person skeleton joints from query embedding of the MvP. The SMPL model is then used for recovering human mesh from the reconstructed human mesh. "
SP:2e147bd5321e25bb27d2531fd58c46460a1e5320,"This paper studies the problem of support recovery and approximate recovery problems with 1-bit compressed sensing with sparse vectors in the family of sparse vectors. The authors consider the setting where the input is noisy responses and the goal is to recover sparse vectors with error-free responses. The problem is formulated as a learning problem with unknown vectors, and the learning algorithms are used to solve the problem. The learning model is trained to predict the query complexity."
SP:e3388e479a825be429f3a878e2c4d8b05903ff10,This paper studies the bandit quickest changepoint detection problem. The authors propose an online sensing scheme based on an information-theoretic lower bound on the detection delay of finitely parameterized probability distributions. The proposed scheme is based on the expected delay bounds on the number of abrupt changes in temporal behavior patterns. The paper shows that the proposed method can be applied to both synthetic and real datasets. 
SP:268260e9452ba2bc57e50a6b7b3328233137ac9b,"This paper studies the problem-specific algorithms and analyses of Stochastic nested optimization in machine learning applications. The authors consider two problems: stochastic bilevel and min-max. The main contribution of the paper is a new analysis of the convergence rate of SGD-type updates for nested problems with nested structure. They show that they converge faster than non-nested problems, and that the sample complexity of a nested problem is bounded by the number of iterations of the nested problem. They also show that the problem has a hidden smoothness of the problem, which is a result of the regularity conditions. "
SP:82ad52361bc5b2c421f1dc6b76e1a5520570fc6c,"This paper proposes a transformer-based model for supervised learning. The authors propose a reasoning strategy based on Siamese Sampling and Reasoning (SiaSamRea) approach to learn interdependent knowledge in a network. The reasoning strategy consists of three modules: siamese knowledge generation, siameses sampling mechanism for sparse and similar clips, and soft label reasoning. The paper shows the effectiveness of SiaSia on VideoQA benchmarks. "
SP:160022e2cd61159da92f92e85520b7062a337a8d,"This paper proposes a new approach to learn structured distributions for latent probabilistic representations from observed data. The proposed models are based on Hidden Markov Models (HMMs) and Probabilistic Context-Free Grammars (PCFGs). The proposed approach reduces the computational and memory complexity of learning the latent representations of the observed data and the number of hidden states in the combinatorial spaces. The central inference step is based on a matrix-vector product, where the rank of the hidden states is used as the speed. The authors show that the proposed approach achieves better performance than existing structured models on large state spaces and unsupervised grammar induction with neural parameterized structured models. The performance of the proposed models is also shown to be competitive with other models in terms of accuracy. "
SP:238592ad73927194cdf0c0cf9ae2e48ca86e182c,"This paper studies the exploration-exploration dilemma in Reinforcement Learning. The authors propose Thompson Sampling, a new Bayesian exploration strategies based on the technique from Bayesian learning. The main idea is to use the Sample Average Uncertainty (SAU) as an uncertainty measure for contextual bandits, which is a frequentist approach. The uncertainty measure is based on Bayesian approaches to estimate the outcomes uncertainty, and the authors show that the computational intractability of probability distributions with respect to the action-value function is a major factor in the regret bounds of outcome models. They also show that approximation techniques can be used to improve the exploration -exploration trade-offs. Finally, the authors provide a drop-in replacement for epsilongreedy exploration, and show that SAU-based exploration has a modest computation cost compared to deep Bayesian bandit methods on real-world datasets."
SP:ffc5b18f7e18607b2934e5aa199e7542005d79f4,"This paper studies the problem of learning robust behavioral embeddings from video. The authors propose Disentangled Behavior Embedding (DBE), a method to learn a set of discrete behavior representations from video by using an end-to-end approach. The main idea is to use dynamic behavioral factors (pose) in a deep autoencoder to encode the dynamic behavior factors (poses) in the video, and then use a stochastic temporal model to predict the pose dynamics of the pose. The proposed method is evaluated on two tasks: fine-grained behavioral motif generation and behavior decoding. The results show that DBE outperforms VDBE on both tasks."
SP:bf78a450e4aad6b87fdeb8ec0d68adaaff7b595b,"This paper proposes a deep 3D conditional generative model called DMTET, which is a hybrid 3D representation that combines implicit and explicit 3D representations. The user guides are composed of coarse voxels, and the reconstructed surface is represented by DMTTE. The model is shown to outperform existing implicit approaches in terms of reconstruction and adversarial losses. The paper also shows that the model is able to learn complex 3D animal shapes. "
SP:2bc0bd6aa2a12691b16145f0d23542c4c86e3a44,"This paper studies the statistical dependence of Mutual Information (MI) between two data points. Mutual information (MI), a surrogate measure of dependence between data points, is a well-studied topic in the literature, and it is well-known that it has structural properties such as information theory, statistics, and machine learning. The authors propose a sliced MI (SMI) to measure the statistical scalability of MI. The SMI is based on deterministic transformations, and is trained using processing functions of raw data. The theoretical results show that SMI outperforms MI in terms of both the estimation and the estimation of high-dimensional MI. Moreover, it is shown that it is able to capture structural properties of MI, such as scalable computation, estimation, and estimation. Finally, the authors show that the SMI can be used for feature extraction, independence testing, and feature extraction for theory. "
SP:e220b348901b476c2afd95f97630fb5400582f40,This paper proposes a new multi-step lookahead constrained BO method based on unreliable bruteforce derivative-free optimization for the Monte Carlo rollout acquisition function. The authors show that the proposed method achieves better query efficiency than myopic methods in terms of expected improvement compared to non-myopic Bayesian optimization. The main contribution of the paper is a reparameterization trick to improve the performance of unconstrained BO methods in the unconstrain setting. The paper also provides a theoretical analysis of the constraints on the sampled acquisition function surface and the number of feasible and infeasible regions.  The authors also provide a likelihoodratio-based unbiased estimator for acquisition function optimization and show that their methods perform better than 2-OPT-C and other methods. 
SP:51fbd861422647912f275b48861ea3c4812afdc8,"This paper studies joint distribution modeling in RL. The authors propose a new distributional RL for the joint return distribution, where the return distribution is computed as a scalar value functions in the value network, and the reward is computed using distributional reinforcement learning (DQN). The authors use hybrid reward architectures (HRA) to learn the source-specific value functions for the reward, which are then used to train a joint distributional Bellman operator. The empirical algorithm is based on Maximum Mean Discrepancy (MMD3QN), which is an extension of the Multi-Dimensional Distributional DQN [1]. The authors show that the proposed method is able to obtain a rich return distribution with richly correlated reward functions in a control setting with multi-dimensional reward functions. "
SP:1f85c93d6bbfd65bf497c92c9cd534d799753097,"This paper proposes a geometric deep-learning model called CorticalFlow, a flow Ordinary Differential Equation (ODE) framework. The model is based on diffeomorphic transformations, where the template mesh’s topological properties are represented by a discrete resolution. Theoretical results show that the manifoldness of the manifold under the numeric conditions of the topological errors can be approximated by the discrete resolution, and that its performance on brain cortical surface reconstruction is comparable to its state-of-the-art counterpart in terms of computation time. The paper also shows that the generation of surfaces from the surface reconstruction methods is computationally efficient. "
SP:2f31d9cf4ad17ad08344439ca0aef7ec91944545,"This paper studies the problem of data deletion algorithms in the non-convex setting, where the update sequence is a non-adaptive deletion sequence. The authors study the computational cost of models with differential privacy and max information. They show that adaptive deletion sequences with provable deletion guarantees are more computationally efficient than those with deletion guarantees. They also show that the SISA algorithm can be used as an attack against non-vex models. They then propose two training methodologies: MNIST and Fashion-MNIST."
SP:7150006590e268ab732c9be6c9048f67a377f956,"This paper studies the problem of risk-averse Bayes-adaptive reinforcement learning in the setting where the prior distribution of MDPs with epistemic uncertainty and aleatoric uncertainty is unknown. In this setting, the conditional value at risk (CVaR) is used for policy optimising CVaR. The authors consider the problem in a two-player stochastic game and propose an approach to solve the problem using Monte Carlo tree search and Bayesian optimisation. The proposed approach outperforms baseline approaches in this problem."
SP:a94f39406f73d7483ddd744ed2f03c78b8bc5d44,"This paper studies the problem of binary classification data for shallow ReLU networks. Deep networks are used to solve arbitrary prediction problems where the data distribution, joint distribution, and the training time are unknown. The authors propose a new method for estimating the logistic and misclassification losses. The proposed method is based on gradient descent with early stopping.   The authors show that gradient descent can be used to estimate the population risk of a population misclassifying rate, which is a measure of the optimality of a given population. The paper also shows that the proposed method has a compactly-supported marginal. "
SP:a9c786cbb61e1f10f3542161b13e43a1a68ab34d,"This paper proposes a new methodology for coordinated group detection for misinformation in social media. The proposed method is based on deep learning based coordination detectors. The detectors are based on prior knowledge from the temporal logic, pre-defined filtering functions, and the neural temporal point process in the coordination detection framework. The authors show that the detectors have limited expressive power due to the sparsity of account activities on social media in the presence of misinformation campaigns on coordinated accounts. The method is evaluated on the COVID-19 Vaccine Tweets dataset and on a real-world dataset and shows that it performs better than a theoretically guaranteed variational inference approach in terms of mean-field approximation. "
SP:b5c6e967a26a02861db2ecd620e9061db0c03e59,"This paper studies the binary classification task, a model problem where the structure of the model problem is a low-dimensional nonlinear structure. The authors consider a deep fully-connected neural network trained on nonlinear data, where the network width is bounded by a unit sphere, and the network depth is a function of the number of nodes in the unit sphere. They show that the generalization guarantee of deep networks trained on this nonlinear dataset is a result of a fitting resource called network depth, which can be applied to any classification problem with smooth curves. They also show that under mild regularity conditions, the reduction to dynamics in the neural tangent kernel (NTK) regime can be approximated by a translationally invariant operator on manifolds. The convergence and generalization properties of NTK are obtained by fine-grained control on the decay properties of the NTK. "
SP:8f6bee3be43df6b6e80804974014caaafe08c49e,"This paper studies Conditional Generative Adversarial Networks (cGAN), a family of cGANs with auxiliary classifier GANs with softmax cross-entropy loss (ACGAN). The main idea is to use class information in the GAN to improve the diversity of the class-labeled dataset. The relational information of a class-labelled dataset is then used to train the classifier. The authors show that ReACGAN on CIFAR10, Tiny-ImageNet, CUB200, and ImageNet datasets with differentiable augmentations can achieve state-of-the-art performance. Model weights and the software package can be used to learn representative cGAN. The proposed D2D-CE and StyleGAN2 architecture are also shown to perform well. "
SP:080e80746a87228b156408ff649ab7a17f44e92d,"This paper proposes a new reinforcement learning (RL) algorithm called Policy Space Response Oracles (PSRO) for two-player zero-sum games. PSRO is based on the extensive-form double oracle algorithm, Extensive-Form Double Oracle (XDO), which is a deep RL method for approximate Nash equilibrium in large games with infostates. The authors show that PSRO can achieve approximate Nash equilibria in high-dimensional continuous-action sequential games with large games. They also show that the best responses obtained by XDO are better than the best response obtained by Neural XDO (NXDO) in deep RL. Finally, they compare PSRO with NFSP and NFSP in a sequential multidimensional continuous-actions game and show that XDO has better exploitability than PSRO and CFR. "
SP:bda04facef4f34679fc4e17b8ea1aae74c3d649f,"This paper studies the problem of graph structured data in deep neural networks. The authors propose a new graph-level unsupervised representation learning method, called node clustering, which uses a permutation-invariant variational autoencoder to learn graphs with adjacency matrices. The proposed model is able to learn the node order of a graph, which can then be used to train a model for graph reconstruction. The extracted representations are then used for downstream graphs-level classification and regression. "
SP:e17ea6aeba78c9dfc25596d8b35a2a4f1f1f6763,"This paper studies the limited scalability of Graph Neural Networks (GNNs) with limited graph and model sizes. The authors show that the subgraph of a GNN with bounded-size scope can be represented as a subgraph with critical neighbors in the receptive field of the GNN. The GNN can be used to learn an informative representation of the local neighborhood of a node, and the critical neighbors are then used to represent the global neighborhood of the node.  The authors also show that GNNs with limited expressivity can suffer from oversmoothing due to the large number of critical neighbors, which leads to expensive computation. To address this issue, the authors propose to use function approximation (GraphSAGE) and topological learning (GIN) as well as graph signal processing (GCN) to improve the expressive power of GNN by decoupling the graph and the global graph. The design of the proposed design is evaluated on graphs and backbone GNN architectures."
SP:4890f251db559a0a572afc66e0c1f899b577d9ff,"This paper studies the problem of normalizing flows in latent-variable generative models with tractable likelihood in linear time. Affine-coupling models are known to have representational power, but they are often ill-conditioned Jacobians. The authors propose a new architecture, called Normalizing flows, where the Jacobian of the latent-to-observable-variable transformation is replaced by a nearly-singular Jacobian, and the network is trained with affine couplings. The main idea is to train the affine coupling flows on the log-concave distribution of the input distribution, and then use the well-conditional affine-cooupling flows to normalize the regular distributions.  The authors show that underdamped Langevin dynamics and Hénon maps of a structured dynamical system with symplectic diffeomorphisms can be approximated by affine coupled architectures, and that the iid Gaussians can be used to approximate a padded version of the output distribution.   "
SP:5ffa81488ed1092deb89bd5e150fa146325057ce,"This paper studies the problem of coupons allocation policy learning in an online e-commerce environment. The authors propose a method to learn a coupon allocation policy by solving a Lagrangian problem in the form of a Lagrangian multiplier variable. The proposed method is based on the BCORLE(λ) framework, where the goal is to find a policy that maximizes the user’s “retention rate” in the policy space. The paper proposes an offline reinforcement learning method, an off-policy evaluation algorithm, and a policy learning process based on λ-generalization method. The approach is evaluated on a simulation platform and a real-world e -commerce market."
SP:6b04cc7b4e45b9e65a1d34c15e3f75a2ef27d601,"This paper studies domain adaptation (DA) in the context of domain generalization. The authors propose a new method called Domain Domain Adaptation (DDA), which is based on the notion of local affinity between the source and target domains. The idea is to learn the intrinsic structure of the source domain and the target domain by using a self regularization loss on the noisy neighbors. The proposed method is evaluated on 2D image and 3D point cloud recognition datasets. The results show that the proposed method outperforms existing DA methods."
SP:ac1bf04ff782e5892a0bc5fe5949848ca8e731c2,"This paper proposes a new pooling method for learning representations from sets. The proposed method is based on the end-to-end trainable Euclidean embedding for sliced-Wasserstein distance between two sets of data points. The key idea is to use a geometrically-interpretable and generic pooling mechanism to learn a fixed-dimensional representation of the data points, which is then used to learn the features of the set. The authors show that the proposed method outperforms existing set representation learning approaches on set-structured data such as point-cloud, graph learning, and image/video recognition."
SP:6cb2f0cbc076f8680cb00411790629f8e1478053,This paper studies the problem of training stability of recurrent neural networks (RNNs) with SBO-RNN. The authors propose a stochastic bilevel optimization (SBO) for RNNs with feedforward and backpropagation. The SBO problem is formulated as a simple optimization problem with hidden states and hyperparameters. The main contribution of the paper is to propose a new RNN that can solve the RNN problem with stochedastic gradient descent (SGD) in an SBO setting. The proposed approach is evaluated on several benchmark datasets.
SP:d3a4300e21ca215334f256f0467a428470548fe4,This paper studies the online problem of minimizing power consumption in the online ski rental problem. The authors propose a new algorithm for minimizing power-saving states with energy consumption and wake-up costs. The algorithm is based on a learning augmented online algorithm with predicted lengths of the idle periods. The paper shows that the proposed algorithm has the worst-case guarantee of $O(\sqrt{T})$ with respect to the prediction error. The proposed algorithm is shown to be efficient in the learning augmented setting. 
SP:22aba6284123af0ecd6605ee4e89b351bd7e10a3,This paper studies the transferability of multi-source transfer learning problems with large sample sizes. The authors propose a mathematical framework to measure transferability between different learning models with different sample sizes and task similarities. They show that the optimal combining coefficients for transferability can be obtained by optimizing the model complexity and the sample sizes of different models for different tasks. They also provide a quantifiable transferability measure based on a parameterized model. The proposed approach is evaluated on image classification tasks and transfer learning algorithms in both multi- source and few-shot scenarios.
SP:0fb8dcf15e0d43547d566fdba7bc70b3bb600005,"This paper studies the problem of visual search in the presence of asymmetry in the search image. The authors propose a new computational model based on a search image that can be used to train a computational model on a given search image, which is then used to learn a task-specific training. The model is trained on ImageNet, where it is trained with eccentricity-dependent visual recognition and target-dependent top-down cues. The proposed model is evaluated on a variety of paradigmatic search tasks with asymmetry, and it is shown that the model is able to learn search asymmetry better than human behavior. Visual search asymptotically outperforms other neural network models in terms of classical perceptual properties. "
SP:f0cc968ea9da4884dcdaf6d0c75ea9f1511bdfc3,This paper studies the problem of certifiable training in the presence of adversarial examples. The authors show that the tightness of the upper bound for certifiably robust models is tighter than that of the best-case loss. They also show that models trained with looser bounds for Interval Bound Propagation (IBP) training are more robust than models trained on the same loss landscapes. They then propose a state-of-the-arts method that combines tightness and smoothness to improve the performance of the proposed method. 
SP:a158f8772a9dada059ffd1d6d7838ed40d8483da,"This paper studies the problem of online linear regression in the stochastic setting with bounded observations. The authors consider the online regression algorithms in the online ridge regression and forward algorithm with high probability regret bounds. They show that the robustness of the regularization parameter of the forward algorithm is a function of the ridge, and that it can be used to improve the regret bounds of the algorithms with linear function approximation. They also show that this modification can be applied to the linear bandit settings. "
SP:17ff9a2133aebf2d1b1787e8efc49d709389c0e7,"This paper proposes a new extragradient (EG) method for minimax problems in the nonconvex-nonconcave setting. The authors propose a two-time-scale variant of EG with slowO(1/k) rate for the squared gradient norm in the smooth structured non-convexus nonconcavity setting, and an extra anchored gradient (EG+) for the smooth convex-concaves setting. EG+ is an extension of EG+ that uses the anchoring technique in EG. FEG-A is a backtracking line-search version of the backtracking version of FEG. The theoretical results show that EG+ and EAG are more efficient than EG+ with fast O(1 / k) rate, and FEG is more efficient with a negative comonotonicity condition in the saddle-gradient operator. "
SP:4e38973033de24fc183c6112e1146f8eef0ddaea,This paper studies the problem of uniformity testing on statistical data with rankings. The authors consider the local DP scenario where the alternative class is a large domain and the uniform distribution is a pairwise statistics. The central DP algorithm is based on the Mallows models. The main contribution of the paper is to propose a uniformity test algorithm for the localDP scenario. The paper shows that it is possible to train a Mallows model with pairwise statistical statistics and a uniform distribution that is close to the one learned by the MallOWS model. The algorithm is also shown to be computationally efficient.   
SP:99a835191a3ba8372e391b6d3316e9b68e543295,"This paper studies the problem of learning statistical models with sparse structure. The authors propose a greedy scorebased algorithm for learning DAGs with directed acyclic graphs. The proposed approach is based on vertex-greedy, and is shown to have the worst-case exponential runtime for greedy algorithms. The paper also shows that the proposed algorithm can be combined with polynomial-time algorithms in order-based algorithms to improve the sample and computational complexity bounds. "
SP:b60989706296b963b6671c01f22384978a334be1,This paper studies the problem of adversarial robustness of convolutional neural networks (CNNs). The authors propose a neural architecture dilation algorithm to improve the performance of backbone CNNs. The authors show that the dilation architecture improves the accuracy and adversarial perturbations of the backbone CNN. The proposed algorithm is evaluated on several real-world datasets and benchmark neural networks.
SP:77ed765e911a4e5f2bfba13cbd2403500a5d05e6,"This paper proposes a new linear function approximation for episodic Markov decision processes (MDPs) for model-based reward-free reinforcement learning. The main idea is to use the linear Mixture MDP assumption in the MDP as a transition probability kernel in the planning phase, and then use the reward function as a reward function in the exploration phase to learn the ε-optimal policy. The proposed algorithm is based on UCRL-RFE with Bernstein-type bonus. The authors show that the proposed upper bound is better than the lower bound. "
SP:28563ba0975f56ddb662cd46e85de78bb6024d36,"This paper proposes a Shifting Seasonal Matrix Factorization approach called SSMF. The proposed method is based on a lossless data compression scheme, and it uses regime shifts in the data stream of events to learn the seasonal patterns of events. The authors show that the proposed algorithm performs better than baseline methods on real-world data streams. "
SP:e4bb07033001be4d04695ef058f426d49fe440be,"This paper studies the problem of assignment in informatics, i.e., how to solve a real-world assignment problems in the presence of NP-hardness or incomplete input. The authors propose to use exact solvers to solve assignment problems, where the objective functions and prior assumptions are unknown. The main contribution of the paper is a new neural network architecture called WeaveNet. The core module consists of a feature weaving layer and a learning-based 7 method. The proposed algorithms can be applied to real problems such as stable matching and non-linear assignment problems. The paper also proposes a new approximation algorithms for these approximation algorithms. The model is evaluated on a combinatorial problem and shows that the proposed algorithmic method is able to achieve state-of-the-art performance."
SP:8a559e21d45661eef427b310e5fe8488d5749137,This paper studies the robustness of 3D deep learning models against adversarial attacks on 3D point cloud data in safety-critical applications such as autonomous driving. The authors propose to use adversarial training on self-supervised learning proxy tasks to train threat models to predict the point clouds from the threat models. The proposed DGCNN and convolution-based (DGCNN) as well as transformer-based and PCT) 3D architectures are evaluated on a jigsaw proxy task and 3D adversarial robustness for 3D Point cloud recognition. The results show that the proposed method is able to achieve better robustness against 3D perturbations compared to self-smoothing and adversarial learning baseline. 
SP:657c5a1114c0d054b9e767d85990bbbb0492912d,"This paper studies the problem of online mirror descent with O(T) regret, where the goal is to minimize the number of iterations needed to converge to the optimal solution. The authors propose a new optimization algorithm, called Frank-Wolfe, which is based on the FISTA and mirror descent algorithms. The main contribution of the paper is to provide near-optimal regret bounds on the convergence rates and convergence rates of these two algorithms. They also provide a theoretical analysis of the runtime v/s convergence rates for these algorithms. "
SP:8dae43d6b5cebb7ef6c39437d997b390c2380536,"This paper studies the problem of parameter estimation with finite sample guarantees for k-parameter minimal exponential family with natural parameters, i.e. i.i.d. samples. The authors propose a new estimator based on maximum likelihood estimator for the exponential family, and show that it is computationally efficient. The proposed method uses maximum likelihood estimation for the re-parametrized distribution of the original exponential family. They also show that the sample complexity of the estimator is bounded."
SP:4f9ddb697e86356fb293ef34a69ca3702c4e8164,"This paper proposes a hybrid differentiable renderer, DIBR++, for predicting intrinsic object properties in inverse graphics. DIB-R++ is based on a compact and expressive shading model. The renderer uses environmental lighting and spatially-differential material models to generate photorealistic effects. The authors provide direct estimation for light transport and spherical basis functions for direct estimation of light transport. The proposed approach is evaluated on synthetic and real data with both material and lighting disentanglement. The experimental results show that the proposed approach outperforms existing rasterization-based approaches in various artistic applications such as relighting, material editing and relighting."
SP:6ac1c8556e7131939cc582f513bc9921470e1b09,"This paper proposes a differentiable training method called sampling-argmax, which is based on a continuous formulation of the output distribution of the differentiable sampling process. The main idea is to use a soft- argmax operation to train the neural network. The model is trained in the same differentiable manner, but the probability map is differentiable, and pixel-wise supervision is added to the map. The proposed method is evaluated on a variety of localization tasks, and the results show that the proposed sampling -argmax operation performs better than the soft-argmax operation on most of the localization tasks. The authors also provide an upper bound on the average error of the proposed method."
SP:478c05c90090f9d80b72ac352c488073b45a5d8b,"Graph Contrastive Learning (GCL) aims to learn generalizable representations from contrastive views. In GCL, the data augmentation is used to augment the contrastive information in the graph structure, such as directional structure of directed graphs. The authors propose a message passing scheme, where the graph changing action is passed through the directed graph structure. They show that it can improve the performance of GCL by using hand-picking parameters in the predefined contrastive view. They also demonstrate that it is possible to use Laplacian perturbation to improve the quality of directed graph contrastive learning framework. Finally, they show that the proposed model is able to learn structural features of the directed graphs better than other GCL models."
SP:85b383d2f722f7bff438840e423f5cb4c67d5980,"This paper studies the common interface of grounded language learning environments with a common interface. The authors propose SILG, a shared model architecture for RL with grid-world environments such as RTFM and Messenger. The SILG is composed of symbolic counterparts of visual worlds in the action space, language specification, and plan complexity, and is able to handle complex scenes such as ALFWorld, which is a multi-environment benchmark.  The authors show that SILG can improve the performance of language grounding in these environments by using the shared architecture in environments where the entities are represented as a set of entities.  They also show that the proposed shared architecture can be used to train a pretrained LM, recurrent state-tracking, entity-centric attention, and egocentric local convolution. "
SP:23c8db56f59f778fe812a5dd161f7a1f21c3cdba,"This paper proposes Vision MoE (V-MoE), a Vision Transformer, which is a variant of Vision-based Neural Language Processing (NLP). The authors propose a routing algorithm to improve the performance of V-MoEs in the context of Natural Language Processing. The authors show that the proposed extension can be used for adaptive per-image compute, and that it can be combined with existing networks such as V-MOE for image recognition. The proposed extension is also applied to scale vision models such as Computer Vision. The experimental results on ImageNet show that V-moE is able to outperform the standard 15B parameter model in terms of performance."
SP:c5235f41dfb8b5cc478f11c5d5e0ab0b8676871e,"This paper studies the problem of constrained optimization of neural networks with n (sample size) neurons in 1-hidden-layer networks. The authors propose a new loss function for the loss function in the benign optimization landscape. The global minimizer is a zero training loss for the KKT point of the network. The local-min or saddle points are the nice local region in the network, and the activation is a function of the number of neurons.  The authors show that SGD can be used to train narrow neural nets with projected gradient methods for KKT points, and that the constrained formulation of SGD outperforms the state-of-the-art in the constrained optimization formulation.   The main contribution of the paper is a theoretical analysis of gradient descent for narrow networks. "
SP:0be529f5254afd59dcfa6b34a359c7037e7a8323,"This paper studies the problem of risk-aware multi-armed bandit models with variance. The authors propose a new risk measures, called option correlation, which is a measure of the variance of the risk of a bandit model. Theoretically, the authors show that the variance is a function of the number of options in the bandit training set, and that it depends on the weight vectors of the training set. The paper also shows that the covariance structure of the CMCB can be used to estimate the concentration of the option covariance of the optimal bandit regret.  The authors then propose two algorithms with matching lower bounds on the optimal regrets of the algorithms. The algorithms are based on the sampling strategy properties of bandit analysis, where the analytical techniques are used to compute the concentration and the estimated covariance for each of the selected actions."
SP:472a90bb175b0286765c5a47b040e1a58f594a05,"This paper studies the nonnegative Matrix Factorization (NMF) problem in the PSD factorization task, where the objective is to find r × r-dimensional PSD matrices in Positive Semidefinite (PSD) factorization. The problem is formulated as a matrix geometric mean of appropriate PSD matrixrices in the form of positive diagonal matrices, and the goal is to minimize the matrix $\mathcal{O}(\sqrt{T})$ matrix $\epsilon$ of the matrix. The authors propose a non-commutative extension of the non-computative extension, the Matrix Multiplicative Update (MMU) algorithm, which is based on Lee-Seung’s algorithm. The proposed algorithm is shown to improve the performance of NMFs in terms of the squared loss objective. The paper also shows that the proposed method can be applied to both real and synthetic data. "
SP:83abd6d149d88cc6e96cbc4d488e4fe9dc2a4fcb,"This paper proposes Domain Generalization (DG) as a new model for learning domain invariant representations. The authors propose a meta-learning framework to learn a domain-specific representation for generalization. The proposed framework is based on the idea of domain-invariant information, which can be represented as a set of features in the latent space.  The authors provide a unified framework for learning the domain invariance view and show that the proposed mDSDI outperforms state-of-the-art techniques in terms of generalization capability. "
SP:4191474c75e2fedf514f0f3001a67a047eb74c30,"This paper proposes a new architecture for unconditional image synthesis based on the BigGAN-deep framework. The proposed method uses gradients to improve the sample quality of diffusion models and generative models. The authors show that the proposed method improves the diversity and fidelity of the generated images by using the gradients in the classifier to improve sample quality. The method is evaluated on ImageNet 128 ⇥ 128, ImageNet 256 ⇥ 256, and ImageNet 512 ⇥ 512. The experimental results show the effectiveness of the proposed classifier guidance and upsampling diffusion models on FID."
SP:fe3cab08596cde4c14ecf6fca8d0f95b02bab229,"This paper proposes a new method for few-shot learning with out-of-distribution samples. The proposed method is based on unlabeled samples (i.e., query data) and is able to extract irrelevant features from the data. The key idea is to learn a classifier from out- of-dispersion samples and then use the out-distributed samples to train the classifier. The authors show that the proposed approach can be used in inductive and transductive settings. They also show that their method outperforms existing pretrained networks on a variety of architectures. "
SP:b1f65724926f136979829b7a6c870bc31f38f591,"This paper studies the problem of experience replay in reinforcement learning. Prioritized sampling is a popular technique for sampling samples from a dataset. The authors propose two criteria for prioritization: TD error and recentness. TD error is a measure of the regret minimization objective, while recentness measures the recentness and corrective feedback are two criteria that are used in the prioritization.  The authors show that the optimal prioritization strategy for Bellman update can be obtained by maximizing the TD error of the optimal strategy. They also show that this strategy can be combined with ReMERT for temporal ordering of states and ReMERN for the error network. Finally, they show that these methods are able to achieve better prioritization weight than existing methods in terms of on-policiness and Q value. They show that their methods outperform other prioritized sampling algorithms on several RL benchmarks such as Meta-World, MuJoCo, Atari, and Atari."
SP:601ebf30b3c6aa35fcef49633aa8eb0acd0f2c66,"This paper studies the problem of sequential prediction in a nonstationary environment with expert advice. The authors propose a linear-time algorithm with relative entropy projection step, where the projection step has linear time and the implicit costs of weight updates are bounded by long-term memory guarantees. They show that the proposed projection is more efficient than weight-sharing approaches in portfolio optimization."
SP:b2439973063e827b3cbe92306a2fdee3286b6b44,"This paper studies the problem of learning a convex geometry with a hidden d-dimensional value. The authors propose two algorithms to solve the problem. The first algorithm, called Steiner’s formula, is based on the O(d log d) regret and the list size poly(d) regret. The second algorithm, named “Steiner”, uses routing applications from contextual linear bandits to learn a variant of the routing applications in navigational engines and recommendation systems. Both algorithms are nearly tight algorithms for solving the problem, and the regret of the proposed algorithm is comparable to that of the cutting-plane algorithms. The main contribution of the paper is to provide a theoretical analysis of the regret for the two algorithms. "
SP:abe83c7e0bcf4829742609d709637e2f84d8a4d9,"This paper studies the problem of automated machine learning (AutoML) in the context of data scientists. The authors propose two pipelines that use orthogonal combinators to learn compositional code. The main idea is that the search spaces of AutoML optimizers can be represented as hyperparameter schemas, which can be used as a translation scheme between two different search spaces. The two pipelines are then used to train the machinelearning operators in these two pipelines. The paper shows that the two pipelines can be combined in a sklearn-compatible AutoML library called Lale, which is a combination of Lale and AutoML.   The paper also shows that, when combined with the hyperparameters of the two search spaces, the proposed translation scheme can achieve state-of-the-art results in terms of performance on the user study."
SP:0d7f1cae577ed598048b64617e85ca6bd5c6d7fa,"This paper studies the problem of weight initialization for neural network weights on small datasets. The authors consider the problem-by-problem basis of the pattern of sparsity in the training data. The generalization error is defined as the difference between the generalization of the weight initialization and the learning algorithm. The paper shows that in the few-shot and continual learning problems with patterned sparsity, both generalization and interference can be improved by meta-learning with adaptable features. The main contribution of the paper is to study the inductive bias of meta-learned neural network systems in the presence of selective sparsity. In particular, the authors show that sparse learning can lead to better generalization than sparse learning with sparse gradient descent."
SP:05037e1850003a725a466b64d3e32aa2aed458fb,This paper studies the problem of shared response modeling in multi-view learning problem. The authors propose a multi-set canonical correlation analysis for unmixing matrices with sampling noise. The approach is based on joint diagonalization between the common components and the shared independent components. The proposed model is called Shared Independent Component Analysis (ShICA). The authors show that the proposed method can achieve state-of-the-art performance on both fMRI and MEG datasets.   
SP:44dd1faa1813c433fd7581d05cae3df440bfb93e,This paper proposes a new multi-agent reinforcement learning technique called Fictitious Co-Play (FCP) that combines self-play (SP) with population play (PP) and behavioral cloning play (BCP) to learn agents that are “human-aware” agents such as BCP and “behavioral cloning play”. The authors propose a two-player collaborative cooking simulator and show that it can be used to train agents with human co-players. They also show that their approach improves the generalization of agents in competitive domains. 
SP:21c84bd720b1e90ea0f88fbf8fd24dbcb49b547c,"This paper proposes a method for cooperative multi-agent reinforcement learning in discrete and continuous action spaces. The proposed approach is based on deep deterministic policy gradients to estimate the policies. The centralised policy gradient estimator is a non-linear monotonic function, and the centralised but factored critic is a joint action-value function that combines per-agent utilities and the joint action -value function. The authors show that the proposed MADDPG outperforms the state-of-the-art multi-actor actor-critic method (MADDPG) by a large margin. The main contribution of the paper is the use of nonmonotonic factorisation to improve the representation of the critic. The paper also shows that it can be applied to a variety of tasks with monolithic, or monotonically factored critics. "
SP:1c8351b8a6cdf1212840388e19a596729b3bfda4,"This paper proposes a new key-value mechanism for memory-augmented neural networks for machine learning. The key-values are learned using three-factor plasticity rules, which are based on Hebbian plasticity for storage and attractor dynamics for storage. These rules are learned by modifying the network parameters. The proposed network is evaluated on a variety of autoassociative memory tasks, including continual recall, continual recall with heteroscedastic memory, and sequence learning. Compared to existing variants of augmented networks, the proposed network performs better than Hopfield networks in most of these tasks. The authors also show that the proposed Hopfield network can be used as a model of biological long-term memory."
SP:7ad6da2c63859d64970e9b35326e9ceab48add47,"This paper proposes a new approach for streaming data for pairwise learning with stochastic and online gradient descent methods. It focuses on two machine learning tasks: bipartite ranking and metric learning. The proposed approach is based on the online gradient ascent (OGD) algorithm. Theoretical results show that OGD can achieve better generalization error bounds for convex and nonconvex problems as well as smooth and nonsmooth problems. The theoretical results also show that the loss function of OGD has a scalability issue, and that the gradient direction is not optimal. The paper also shows that the generalization bounds obtained by OGD on the buffering set are better than the ones obtained by differentially private SGD algorithms and other techniques for optimization and stability analysis. "
SP:cb11dacc930d71a616ee2fbe4acfae030f9dca59,"This paper proposes REDO, a class-agnostic framework for Dynamic Objects based on RGBD or calibrated videos. The proposed modules are based on a unified framework for the problem setting. The core component is a canonical 4D implicit function based on aggregated temporal visual cues. The object dynamics, such as rigid motion, non-rigid motion, articulation, and occlusion, are modeled by a 4D transformation module. Experiments on real-world video data 3DPW show that REDO outperforms dynamic reconstruction methods."
SP:8ae97752e74b4395774575009031abcb6ba5cea7,"This paper studies the problem of linear stochastic approximation (LSA) algorithms with fixed stepsize. The authors consider the case where the products of matrices are random estimates and the stepsize is fixed. The central limit theorems are covariance matrices, and the authors show that random estimates have polynomial concentration bounds. They also provide high probability bounds for LSA with high stepsize, and show that these bounds can be extended to Gaussian or exponential high probability.  The authors also provide some theoretical guarantees for these bounds.  Finally, the authors provide some numerical experiments to demonstrate the effectiveness of the proposed methods in machine learning tasks."
SP:86c1e937755e35efafecc09dfe2606ffb1653a41,"This paper proposes a new options framework for temporal abstraction in reinforcement learning. The authors propose discounted Markov decision processes (MDPs) and average-reward MDPs, which can be combined with samplebased planning variants in learning algorithms such as intra-option algorithms and samplebased planner variants. They show that those can achieve better convergence proofs in the Four-Room domain than existing algorithms. They also show that the option-interrupting behavior of the discounted MDP can be reduced to the average reward formulation."
SP:7e4e1e20e7c253d02c6ae58457fb30029f130f0c,"This paper studies the problem of learning representations that are robust to convolutional inductive bias. The authors propose to use Visual Transformers (VTs) instead of Convolutional networks (CNNs) to learn the global relations between image elements. They show that VTs have better representation capacity than CNNs in terms of their local properties in the visual domain. They also show that the robustness of VTs in the small training set regime is better than common CNNs. Finally, the authors propose an auxiliary selfsupervised task that uses images from the VTs to learn spatial relations between images. The proposed method is evaluated on ImageNet and shows that it achieves better accuracy than VTs on the task and (supervised) training."
SP:0132ef17585e293b23e9dc45189c0989d829b52a,"This paper proposes a geometric approach for label-free alignment of hierarchical datasets. The authors propose to use Hyperbolic spaces to learn informative representations of hierarchical data. The key idea is to use the Riemannian geometry of the Lorentz model of hyperbolic space as a basis for the HPA. The proposed HPA has theoretical properties such as stability, computational efficiency, and translation and scaling. Experiments on gene expression and mass cytometry data show its effectiveness on batch correction tasks. "
SP:3580ac64f09e3021de5d4c92411bcc0f3c5d10f3,"This paper studies the problem of differentially private query answering systems with a logarithmic factor of the accuracy. The authors consider the uncertainty principle, which is a well-studied problem in the literature. The main contribution of this paper is to propose a new algorithm based on privacy-protected microdata. The key idea is to use the log(d) factor for the sum query and the point queries, and to use noisy answers for the point query. Theoretical results show that the proposed lower bounds are better than the ones for pure, approximate, and concentrated differential privacy. "
SP:c0e64dc8acfaed3e4d7745af12fd34003d0e5017,"This paper studies Goal-conditioned reinforcement learning (RL) in the context of long-horizon tasks with sparse reward and inefficient exploration. The authors propose a curriculum of tree-structured sub-tasks where dense feedback is used to guide the path-planner and the RL agent to learn dense feedback. The planner is trained using an easy-to-hard curriculum, and the agent is trained with a bottom-up traversal of the tree. Planning, the environment model, is trained to learn the optimal planning policy for each sub-task.  The authors show that CO-PILOT outperforms SAC and PPO in both navigation and continuous control tasks, and outperforms RL and planning (RRT). The success rate and sample efficiency are also improved. "
SP:9911693a04a300b5a93634fb0267ef83e5489d77,This paper proposes a Bayesian framework for generating local explanations for black box explanations for model credibility. The proposed framework is based on the idea that local explanations can be generated by hyper-parameter tuning. The authors propose two techniques for generating explanations based on these techniques. The first is to use LIME and KernelSHAP. The second is to learn the feature importances using credible intervals. The experimental results show the effectiveness of the proposed framework. 
SP:5efb4b81bd37c70640e8768e9dfb5bba14a0cfb8,"This paper studies the problem of energy-efficient neural networks and hardware accelerations with multiplications in convolutional neural networks (CNNs). The authors propose a new approach to reduce the low energy cost of ANNs by learning fatter tails in the feature space. The main idea is to use an angle-based constraint on the diversity of tails to encourage the distribution parameters of the weights to be more diverse. The authors show that the proposed method is able to learn heavy tails in ANNs with unordered heavy tails and unordered weights in CNNs.  The authors also show that their method can be used to train heavy tails with filters, features, and similarity measurement for property difference between the filters and the features. The method is evaluated on a variety of benchmarks and shows that their approach can improve the performance of ANN's on classification. "
SP:cbccb65457564992d534504c0d060da44cafce8c,"This paper studies the gradient descent phenomenon in learning proclivity in over-parameterized neural networks with feature imbalances. The authors propose Gradient Starvation, a regularization method based on a formalism that guarantees that the learning dynamics of gradient descent can be used to improve the performance of the feature learning dynamics on a task with different features. The theoretical analysis is based on the Dynamical Systems theory. The main contribution of the paper is the theoretical analysis of the cross-entropy loss, which shows that the predictive features of the gradients are not independent of the statistical structure, and that gradient starvation can lead to the imbalance. The paper also provides theoretical guarantees on the accuracy and robustness of the proposed regularized method."
SP:8f6fe37cb0a332b66e10cc00261a44622841c8c6,"This paper studies the problem of superhuman AI in competitive games with superhuman AI. The authors propose to use deep reinforcement learning to train a superhuman AI teammate in human-machine collaborative games such as Go and StarCraft. The AI teammate is trained using a combination of rule-based and learning-based agents. The learning techniques are used to train the AI teammate using different learning techniques. The goal is to improve the performance of the AI teammates compared to those trained with other AI teammates. The paper shows that the objective team performance of AI teammates is better than those trained using other subjective metrics such as interpretability, trust, and teamwork. "
SP:2a05e333fc1a14057515ef3addde9a40152373db,"This paper proposes a new method for visual question generation (VQG) for human-like neural questions with image and side information. The model uses double visual and answer hints to train a model that can generate both uninformative and non-referential questions. The learning approach is based on a weakly supervised learning problem, where the candidate visual hints are generated by a rule-based similarity matching method. The proposed method is evaluated on several benchmark datasets and compared with other approaches on a variety of metrics such as automatic machine metrics and human evaluation."
SP:15756d6ef47b39ded404acea2135c93bd5ee1062,"This paper studies the problem of label noise and class imbalance in the context of GDW. The authors propose a new method called Generalized Data Weighting (GDW) to address the class imbalance and label noise. GDW uses gradient descent step to learn the class-level weights for GDW, and then uses a chain rule to compute the loss gradient. The paper shows that GDW achieves better computational cost than instance weighting methods in the uniform noise setting of CIFAR10. "
SP:7a8f56a01bec51ebf70d9ff689005a62cccfe5c6,"This paper studies the spatio-temporal language grounding task, where the goal is to learn a language that can be used by embodied agents to communicate with sensorimotor modalities. Language is a grounded language, and the goal of the task is to find a set of words that are useful for communicating with the embodied agent. The task is formulated as the task of learning a language to describe the behavior of an embodied agent in the presence of behavioral traces. The authors propose two models, multimodal Transformer architectures, which are based on attention computations to learn the latter. The proposed models are evaluated on a variety of tasks, and show that the proposed models achieve better generalization than the state-of-the-art in terms of randomly held-out sentences and grammar primitives. The attention computation in Transformers is based on object identity, and it is shown that the attention computation improves the generalization of Transformers."
SP:3d4a9d439bc84c3b0e6600f6985a23bdf95cd67f,"This paper proposes Prototypical Cross-Attention Network (PCAN) for online multiple object tracking and segmentation using rich spatio-temporal information. PCAN is based on single frame predictions for the segmentation mask. The authors show that the cross-attention is able to capture the rich information in the space-time memory, which is useful for the task of multi-object tracking. They also show that PCAN can learn contrastive foreground and background prototypes using a prototypical appearance module. "
SP:1175ad16382b349ab1a39895150172d266abe571,"This paper studies the optimization of gradient flow in deep learning. The authors show that gradient flow has a favorable curvature of the gradient flow trajectory, and that it can be used as an approximate numerical solution for the initial value problem of gradient gradient flow. Gradient flow has homogeneous activations in deep neural networks, and they can be optimized using gradient descent. The paper also shows that gradient descent can achieve a global minimum using random initialization. Finally, the paper shows how gradient flow can be efficiently optimized using deep linear neural networks. "
SP:b8412e9ce82ce92125fe7cd3aff7bea8b906d16e,"This paper studies the problem of multi-armed bandits with delayed and longterm impact of actions. The setting is a bandit setting, where the goal is to maximize the matching regret lower bound. The authors consider the setting where the action history is not available for learning, and the goal of the bandit literature is to learn a fair algorithms. The algorithm is based on a feedback loop, and is able to learn delayed impacts of historical actions. "
SP:9c1d678dff5f609197dc3cfb67b841827f4a439a,This paper proposes a new end-to-end solution for video instance segmentation (VIS) using transformers. The proposed method is based on Inter-frame Communication Transformers (IFC) and is able to perform near-online inference without overhead. The authors show that the proposed per-clip pipeline performs better than per-frame methods in terms of performance on several benchmark sets. 
SP:6c922eaa358f6fb9771690b1240e4f6f08a35b69,"This paper proposes a new graph embedding method called residual2vec, which is based on the random walks’ bias to learn the structural properties of graphs. The authors show that the sampling of context nodes from random walks can be used as a biased sampler to train the embedding methods. The paper also shows that the degree of random walks in random walks has a significant impact on the performance of the proposed method. "
SP:851eac96135b577a5014166edcb43db6a190cf4b,"This paper studies the problem of estimating non-linear functionals of discrete distributions with local differential privacy. The authors consider the non-interactive case, where the discrete distribution is a multinomial model and the power sum functional is a quadratic risk. They show that plug-in type estimators (e.g., MLE) are more sensitive to private samples than estimators based on α-LDP mechanisms. They also show that the privacy mechanisms (PM) can be applied to the non interactive case as well. Finally, they propose a two-step procedure to solve the sequentially interactive case. "
SP:a0408b54f88a26479f33f36bb27e0a675f637ccd,"This paper studies the problem of online multiclass classification with directed graph. The authors propose a new algorithm called GAPPLETRON, which uses arbitrary feedback graphs to learn the learner’s feedback. They show that the surrogate regret bounds for the proposed algorithm can be derived from the graph-theoretic parameter known as the domination number. They also provide a lower bound for the surrogate losses. Finally, the authors show that their algorithm performs better on synthetic data than other baselines."
SP:490262589efce6fb10b913431ec6db8d4e5b2dec,"This paper proposes a new threshold cut for single dimension (feature) clustering. The key idea is to use a decision tree for k-clustering, where each feature is represented as a cluster and each cluster is represented by a k-means objective. The authors propose a new algorithm for explainable clustering based on this algorithm. The upper and lower bounds are based on the Ω(log k) lower bound on the k-medians objective, and the upper bounds are O(k) and O(K). "
SP:6a9e47be710ddaf386bffc54d003d7dc2b67fdc3,"This paper proposes a pre-trained language model (PrLM) for downstream natural language processing tasks with limited resources. The multilingual PrLM uses language universality to learn limited resources for low-resource languages. The model is based on multilingual-BERT, which is a learned representation of the language. The authors show that the model is able to perform better than multilingual prLM in terms of universal linguistic structure clues and PrLM interpretability. The paper also provides a theoretical analysis of the monolingual linguistic structure knowledge of PrLMs. "
SP:94f4b65214a648cbc84f13beba45a825e2e9901a,"This paper proposes a deep architecture for vehicle routing problems (VRPs) called Transformer, which is based on the Dual-Aspect Collaborative Transformer (DACT). The Transformer is an extension of the positional encoding (PE) method for representing VRP solutions, and it can be used to train learning improvement models for VRP. The key idea is to learn embeddings for both node and positional features from the Transformer. The proposed Transformer learns the symmetry of VRP solution (e.g., cyclic sequences) by using cyclic positional encoding as a way to encode the positional features. The authors also propose a curriculum learning strategy to improve sample efficiency. Proximal Policy Optimization is used to optimize the DACT. Experiments on synthetic and benchmark instances show that DACT outperforms Transformer based improvement models. "
SP:e5c8680d8da9e7548fcb9bb5c073848eb80e1dd0,"This paper studies the Bayes error of generative models trained with normalizing flows. The authors consider the data-driven classification problem, where the data distribution is unknown and the goal is to estimate the classification error. In this setting, the authors propose a technique called Holmes-Diaconis-Ross integration, which is based on the invertible transformation. They show that it is able to recover Gaussian base distributions, and it is also able to reduce the Bayesian error of flow models. They also show that the proposed approach can improve the performance of classification models on synthetic datasets and benchmark datasets. "
SP:2896679f0472522bc3334178cd7574494cf12b7b,"This paper proposes GradInit, an automated and architecture agnostic method for initializing neural networks. GradInit is based on a heuristic, where the network parameters are computed by a scalar multiplier variable, and the hyperparameters are learned by normalizing the network layer with a norm. The authors show that GradInit can be used to train convolutional architectures with skip connections, and that it can be combined with SGD, Adam, and SGD for learning rate warmup. It is also used for machine translation with a Transformer architecture."
SP:f69731403592fa5bdd4ca327708582d615aa131c,"This paper studies the problem of interpretability of linear mixed-effect models for disease progression in longitudinal data. The authors propose a new metric based on diffeomorphism for the Euclidean metric, based on the reproducible kernel Hilbert space. The main idea is to use interpretable parameters to represent the subject trajectories in the Riemannian manifold, and then use the interpretable models to predict the progression profiles. The proposed approach is based on ADNI, and the authors show that the proposed metric update improves the forecasting of imaging and clinical biomarkers in the TADPOLE challenge. "
SP:438e906f52c4c0538956b51a2270b3ac498b27a8,"This paper proposes a routing-by-memory mechanism for CNN architectures. The mechanism is based on a four-step training strategy to train Neural Networks with parallel procedures. The main idea is to learn the semantic features of each procedure sequence, and then use these features to train the network. The PU consists of a memory head, a procedure, and the memory head of the PU. The paper shows that these specialized procedures can be used to train specialized neural networks. The proposed method is evaluated on VGGNet, ResNet, and Tiny ImageNet on CIFAR-100 benchmarks, showing EfficientNet’s accuracies and the performance of the proposed method."
SP:d240173080cd3647dbaa5173a6422396f226775b,"This paper studies the problem of learning high-order tensor objects with symmetry-enforcing constraints in classical physics. The authors propose two frameworks based on irreducible representations, which are based on fundamental symmetries and coordinate freedoms of physical law in neural networks. Theoretically, the authors show that these fundamental symmetsries can be used to learn physical laws with rotation, translation, and reflection (parity). The authors then propose a scalar-based method to learn polynomial functions. The scalars are scalar products, scalar contractions, and scalar product-based methods. Experimental results demonstrate the effectiveness of the theory. "
SP:72c0f47566904deb27d8157da30807ec1d6b5685,"This paper studies the problem of bbox regression in computer vision. The authors propose a new loss function, the Intersection over Union (IoU) loss, which is based on the power IoU term. The power parameter α is defined as the sum of the power regularization term of the IoU losses. The paper shows that IoUbased losses can achieve better performance than the state-of-the-art in terms of both order preservingness and loss/gradient reweighting. "
SP:397125177d7007316d67194ec00d5dc57b44ac79,"This paper studies the problem of imitation learning a policy in the Markov Decision Process (MDP) setting in the imitation learning problem, where the goal is to learn a reward function that maximizes the performance of the policy in a given environment. The problem is formulated as a distributionally Robust Imitation Learning (DROIL) task where the policy is learned by adversarial construction. The authors propose a framework for DROIL based on the generalized concept of entropy in Maximum Entropy Inverse Reinforcement Learning, which is a convex optimization problem with polynomial number of variables. The proposed approach is able to learn an objective function that is convex with respect to the state and action spaces of the loss functions. The approach can also be applied to stationary and non-stationary policies. The optimization method is evaluated on synthetic data and a highway driving environment, and it outperforms existing methods. "
SP:58f220bbbed8d3e0633b408fca3b6838c4ad323d,"This paper proposes a new approach for algorithmic fairness in ML systems, called Post-processing. The main idea is to use post-processing to improve the performance of the model by reducing the number of parameters in the objective function. To this end, it uses retraining on the similarity graph to enforce fairness constraints. The authors also propose a graph smoothing problem based on graph Laplacian regularization to solve the IF post-processing problem. The paper shows that the proposed post -processing algorithms can improve the individual fairness (IF) of large-scale NLP models such as BERT by reducing individual biases. "
SP:ef791aa29decd839e7e583c9d1f71e8309ca87ef,"This paper proposes a unified encoding model for natural language question and database schema. The proposed encoding method, called SADGA, is based on a unified modeling of the question-graph and the schema-graph. The model is able to learn the database schemas from the query and the answer. The paper also proposes a structure-aware aggregation method, Local Graph Linking and DualGraph Aggregation Mechanism. The proposal is evaluated on the Text-to-SQL benchmark Spider."
SP:a2fa25a4539a38af61a0993f65ecc14339f26c2e,"This paper proposes a new approach to learn discrete-continuous computation graphs from discrete probability distributions. The authors propose to use stochastic softmax tricks to improve the performance of neural networks with discrete and continuous model components in supervised and reinforcement learning. The main idea is to use a discrete component to represent the graph’s execution paths as sequential discrete components, and then use a continuous component to compute the computation graphs. The paper shows that the scale parameter of Gumbel noise perturbations can be used as a scale parameter for the learning behavior of the learned models. The proposed strategies are evaluated on several benchmark datasets and show that the complex discrete-stochastic models perform better than their continuous counterparts. "
SP:bb3ec363e90269db4a2ba99d8107cb56f86e68f0,"This paper studies the problem of high-fidelity approximate inference in Bayesian neural networks (BNNs) with a full-batch Hamiltonian Monte Carlo. The authors show that the covariate shift of the Bayesian model average can be used to improve the performance of Approximate Bayesian inference compared to training. They also show that classical estimation can be improved by incorporating linear dependencies between features. Finally, they show that priors can improve the robustness of BNNs with approximate inference procedures and maximum a-posteriori (MAP) training."
SP:f86ec7042e9b73ae071704a6d3ed17d7e3da1b75,"This paper studies the problem of meta-learning evaluation in two settings: in-distribution [ID] and out-of-disribution [OD] settings. In the ID setting, the task distribution is used for train and test tasks, and the OOD setting is used to evaluate the performance of the model in the ID vs. ID setting. The authors propose two methods to perform OOD evaluation on OOD datasets. First, they use metalearning theory and FSL applications to train the model selection, and then they use them for task generation. Second, they show that the performance on few-shot classification benchmarks is comparable to ID evaluation on FSL benchmarks. "
SP:371f77148b4f00a929f7c118b1bb7c5a6238d264,"This paper studies the open rule induction problem in the context of language model (LM)-based rule generation, where rules are generated from a knowledge base (KB). The authors propose two methods for open rules: KB-based rule induction and LM-based rules generation. Both methods are based on data commonalities. The authors show that the open rules are more expressive than LMs for free text and have a rich expressive power. They also show that open rules can be used for relation extraction, and that they can be more efficient than manually annotated rules.   The authors also provide a theoretical analysis of the inference systems that are used to generate open rules. The main result is that the Orion (open rule induction) system is able to generate more open rules than the LMs. "
SP:8be2e0ea4a83fe32a4859f456007a829e5e9270a,"This paper studies the problem of offline multi-agent reinforcement learning in real-world scenarios. The authors propose a new offline RL algorithm, called Implicit Constraint Q-learning (ICQ), which is able to recover the extrapolation error of a single-agent counterpart in the offline multiagent RL. The main idea is to learn a joint-policy with an implicit constraint on the number of agents in the state and action space of the agents. The value estimation is performed using the state-action pairs of the two agents.  The authors show that ICQ can achieve state-of-the-art performance on a variety of multi- agent tasks. "
SP:1939b24b68970c33ca16ce238deed257f76d009e,"This paper studies the problem of real-world adversaries against neural network based detectors. The authors propose uniform norm-bounded perturbations for adversarial examples (AEs) to improve the imperceptibility of machine learning models for security related applications. AEs are used in domains such as finance, social networks, malware, and credit risk prediction. The main idea is to use non-uniform perturbation bounds for the feature dependencies of the features in these applications, which are semantically meaningful dependencies on the empirical data distribution. The proposed approach improves the robustness certification of the proposed method against the proposed methods."
SP:417b30930b245667d777e5d90ee80dd41546760e,"This paper studies spectral filtering for learning with kernels in the context of statistical properties. The authors show that the excess risk of existing regularization schemes (e.g., Tikhonov regularization) has faster convergence rates than those of the standard regularization scheme (i.e., the proximal point method) when the source and capacity conditions of the learning task are different. They then propose a generalized self concordant loss functions (GSC), such as logistic loss, which can be used as loss functions for estimators. The theoretical results show that this GSC can achieve fast and optimal rates for GSC with an iterated Tikhonoov regularisation scheme and a proximal method for optimization. "
SP:1caeee4f00b52fe356ff4e5dd004d0203e838370,"This paper proposes a new linear transform for input-output dimensions, Deformable Butterfly (DeBut), which is based on butterfly matrices. It can be used to compress neural networks with sparsity in the DeBut layer. The authors show that DeBut is more efficient than fully connected and convolutional layers in terms of light weight and inference complexity. They also show that it has a natural complexity-accuracy tradeoff. "
SP:d345ce1d7afc367ee1a9fb68d50ff1b2219f02cb,"This paper studies the problem of Catastrophic Forgetting (CF) in artificial neural networks. The authors propose a method for weight reusability based on the common Knowledge Base (KB) and propose a metalearning approach for KB. The proposed method, called MetA Reusable Knowledge (MARK), uses shared weights between the weights in the network to reduce the forgetting of old information. The paper shows that the proposed methods achieve better average accuracy than existing methods on a variety of benchmarks. "
SP:722c52467e384058f8fdffa254d0e8db47440a64,"This paper studies the problem of Mixed Integer Programming (MIP) with primal heuristics, where the goal is to find exact solvers for the exact MIP. The problem is formulated as a set of hard-coded rules for the solvers to solve the problem. The authors propose a data-driven framework to learn the scheduling heuristic of the perfect MIP solver, which is a combination of MIP heuristic and the exact solver. The algorithm is based on an existing algorithm for learning the schedule of the optimal solution, and the authors show that this algorithm can be applied to a variety of real-world applications. "
SP:5a21f0a49731dcb1d68deb06a75138e8e9d514d5,"This paper studies the problem of reinforcement learning (RL) in the context of binary feedback, where the goal is to maximize the sublinear regret of the reward signal. The authors propose a new algorithm, which is based on an unknown parametric model that predicts the trajectory labels of trajectories in the environment. They show that it can achieve sublinear regrets in real-world applications such as self-driving cars, robotics, and reinforcement learning. They also show that their algorithm can be applied to RL practice."
SP:e66bd9582058ba0f6091bb1042ce2ecfdaae1515,"This paper proposes Dual Hypergraph Transformation (DHT) as an edge representation learning framework for graph neural networks for representing graph-structured data. The proposed method is based on node embedding and graph pooling methods, where nodes in a hypergraph are represented as edges in a graph, and edges in the graph are used for discrimination. The message-passing techniques for node representations are based on dual hypergraph construction. The authors show that they can learn edge representations from hypergraphs that are more holistic graph-level edge representations. They also show that the proposed method performs better than other graph representation learning methods on several graph datasets for graph representation and generation and graph classification tasks. "
SP:e398873e29b05176e1d52dc6f86a59a4f405e6fd,"This paper studies mutual information (MI) maximization for learning representations of data in reinforcement learning (RL). The authors consider the problem of learning representations for learning in RL using MI objectives. The MI objectives are based on samples of high-dimensional observations from a simulated game environment, where irrelevant and redundant information is available. The authors propose to use MI based objectives to learn representations of the MDP. The state representation of the optimal policy is then used as a state representation for learning the optimal representations. The proposed methods are evaluated on a variety of simulated game environments with visual observations."
SP:50181f740910195d3a50dd7d7f8cbb1c476d730b,"This paper proposes Sparse Steerable Convolution (SS-Conv) for 3D image classification. The authors propose to use sparse tensors to train a steerable convolution to perform 3D 3D semantic analysis. The proposed pipeline is based on the SE(3)-equivariant deep feature learning and uses the Feature-Steering module to perform pose refinement. The paper shows that the proposed pipeline outperforms existing methods on three different tasks: instance-level 6D pose estimation, category-level6D pose and size estimation, and 3D object semantic analysis on dense, volumetric data. The efficiency of the proposed SS-conv outperforms other convolutions in terms of accuracy and efficiency. "
SP:d746bfb200577c980d92727bb0b1a3c23e7bfdc5,This paper proposes a new approach for self-attention in vision transformers. The authors propose a dynamic token sparsification framework to replace redundant tokens in the layers with informative tokens for image recognition. The proposed method is based on hierarchically pruning the layers to remove redundant tokens. The key idea is to use a lightweight prediction module to estimate the importance score based on the features of the features. The prediction module is trained using an attention masking strategy to mask the redundant tokens from the layers. The method is evaluated on ImageNet and FLOPs and shows that the proposed method improves the accuracy and throughput of the proposed DynamicViT models compared to CNNs and vision transformer models. 
SP:d0b6cde42b1cba5e6e3c7c5131426fd84adbd3d7,"This paper studies the problem of data analysis problems with distributional assumptions. The authors propose two methods: cross-validation methods and conformal prediction. The proposed methods are based on distribution-free guarantees for predictive inference, which allows for inference of a regression function (e.g., inference on the conditional mean). The authors show that the proposed methods can achieve better performance than holdout methods, and that the inference guarantees can be extended to the finite setting and the continuous setting. The main contribution of the paper is that the confidence interval of a confidence interval with non-vanishing width can be used as a proxy for the sample size. The paper also provides some theoretical guarantees for the vanishing-width confidence intervals. Finally, the authors demonstrate the effectiveness of the proposed inference for E [Y |X] in a finite setting."
SP:123952325765c040c3078fc7dca2b6d370e55590,"This paper proposes Representation Neutralization for Fairness (RNF), a new mitigation technique for bias mitigation methods for DNN models trained with learning debiased encoders. The main idea is to use the fairness sensitive information in the encoder to improve the performance of the classification head in the task-specific classification head of the DNN model by using neutralized representations of the training data. The bias-amplified model is then used to learn proxy annotations for sensitive attributes from instance-level annotations. The RNF framework is evaluated on a variety of benchmark datasets to demonstrate the effectiveness of the proposed RNF for the discrimination of DNNs in terms of their performance on tasks with high and low-resource settings."
SP:210eb2c811f966bb1ac53932cacabbad9bb608fe,This paper studies the problem of medical imaging with Bessel-CNNs. The authors propose to use convolutional Neural Networks (CNN) to perform image analysis with translations and rotations. They show that convolutions can be used to learn Bessel functions in physics. They also show that Bessel function can be applied to the convolution of the convronal layer. 
SP:ee51ecbd476d5b65903c942a62be89ff5d91698b,"This paper proposes a large-scale solver for kernel ridge regression called ParK. The approach combines partitioning, random projections, iterative optimization, and partitioning. The authors show that the proposed approach improves both the statistical accuracy and the space and time complexity of the model. The paper also provides a statistical-computational tradeoff between the feature space and the input space. "
SP:1f096d6fabd5b1fde43d06c552d46d87cd35cb4a,"This paper studies the problem of learning discrete tokens for Neural agents in reinforcement learning settings. The authors propose a new technique for learning discrete communication tokens in a continuous space. The key idea is to use one-hot vectors to encode discrete communication token in the continuous space, and then use these tokens to communicate with the agent. The proposed method is evaluated on a variety of tasks, including zero-shot understanding, zero-hot communication, and human communication. "
SP:8630ccc627534f9033bced04e2137a897ffef701,"This paper studies the inductive bias of Transformers for computer vision. The authors show that the model capacity of Transformers is much larger than that of convolutional networks, and that they are more efficient than they are in terms of generalization. They also show that CoAtNets, a class of hybrid models such as “coat” nets and “self-attention,” are better than convolution layers and attention layers. They show that relative attention improves the performance of depthwise Convolution and self-Attention by relative attention in the hybrid models. Finally, they show that JFT-3B improves CoAtNet's top-1 accuracy on ImageNet-21 K. "
SP:d3ecbeeffa5ab365743ba8653c6739f24742ee31,"This paper studies the second-order oracle bound for the expected risk of a weighted majority vote under a parametric form of the ChebyshevCantelli inequality (i.e., one-sided). The authors propose a new form for the optimization challenge to find prior oracle bounds. The authors show that the proposed form is equivalent to the PAC-Bayesian bounding and the Bennett’s inequality, and that it can be used as an empirical estimation of the oracle upper bound.  The authors also provide a theoretical analysis of the proposed bounds. "
SP:5bac542a6532d43cf100e085398b4a4783719814,"This paper proposes a new audio-visual video parsing task for audio or visual event categories. The proposed method is based on common and diverse event semantics for both audio and visual events, where cross-modality co-occurrence is defined by supervisory signals. The authors show that the proposed method can achieve better performance than existing methods in weakly-supervised audio-video video parsing. They also show that their parsing model is more interpretable than previous methods. "
SP:8fd6a03c1794afa524328d45f4232eacf6f86693,"This paper proposes a federated learning (FL) algorithm for learning a global model from heterogeneous data. The authors propose a combination of a quantized and personalized FL algorithm for collective (personalized model compression) training using knowledge distillation (KD) in the context of collective (private) personalized model compression. The proposed algorithm is based on the relaxed optimization problem, and is able to compress quantized models with different quantization parameters and different model dimensions/structures. The compressed personalization framework is a compressed personalisation framework based on alternating proximal gradient update, which is a common technique in the (federated) learning process. The paper shows that the compressed model has a smaller model dimension than a standard compressed model with the same quantization values, and can achieve better performance than FedAvg and other personalized FL methods such as QuPeD and local training of clients."
SP:fca8b4f1e765cf1724a37f0ae9a7dac1cb79c8b1,"This paper proposes a new framework for constrained clustering in machine learning. The framework is based on stochastic gradient variational inference with partially labeled data, where the prior information is used to train a model (DC-GMM) with domain knowledge with probabilistic relations. The model is trained using deep generative models. The authors show that the proposed approach has better robustness on two data sets compared to deep constrained clustersering methods. The proposed approach is also shown to perform well in real-world applications."
SP:84379c0c881b7390ecc22fb398edfaf66d1af1ff,"This paper proposes Neural Tangent Kernel (NTK), a convolutional counterpart of NTK (CNTK) for infinitely-wide neural networks with least squares loss. NTK regression can be viewed as an extension of the recent work on finitely-wide Neural networks with polynomial expansions of arc-cosine kernels with random features and leverage score sampling. The authors propose a near input-sparsity time approximation algorithm for NTK for learning with a near-optimal spectral approximation guarantee for the NTK matrix. Theoretically, the authors show that NTK improves the performance of the linear regressor and the CNTK features on the CIFAR-10 dataset. Empirical results on large-scale regression and classification tasks demonstrate the effectiveness of the proposed methods. "
SP:fa2668083ff3bb592c29a4c6822ae96ff54d0dbe,"This paper proposes a framework for multi-person 3D motion trajectory prediction. The proposed Multi-Range Transformers model consists of a local-range encoder and a global-residual encoder to capture social interactions. The human pose trajectory is represented by a Transformer decoder, and the prediction is performed using the local and global-reward encoder features. Experiments show that the proposed model is able to achieve state-of-the-art performance on long-term motion prediction."
SP:0a0e07af37c8fe8580639b1df62d27b6f63f8dee,"This paper studies the problem of long-horizon planning in reinforcement learning, where the goal is to learn a guiding program that can be used to solve a programming task. It proposes a generative model that learns a program from a set of training examples, and then uses a strategy to generate a program based on this strategy. It is shown that the proposed approach outperforms non-program-guided approaches on several benchmarks in the 2D Minecraft-inspired environment."
SP:5bb42b178b0d27da271bfa60e633fdac718638c4,"This paper studies causal imitation learning in sequential settings in the context of Imitation learning. The authors consider the problem of naïve imitation, where the goal is to imitate the imitator’s behavior (DO) in a single-stage decision-making. They propose a graphical criterion to measure the imitability of the demonstrator, and propose an algorithm to improve imitability. They show that the proposed algorithm can achieve better imitability than the state-of-the-art. "
SP:85bd81f0c5b6ccbc421ebbaf6f5c72164bc70b7f,"This paper studies the problem of object-structured representation learning with transition losses. The authors propose two transition models: object persistence and object identity. The object persistence model is based on the alignment module, and the object identity model uses the objectlevel loss and object alignment. The paper shows that the proposed model performs better than the baseline in terms of object occlusion and re-appearance in partially observable environments. "
SP:f32eddbb5c33a8422c075579ff08aa9833338d44,"This paper proposes a contextual bandit algorithm based on Empirical risk minimization (ERM) in machine learning (classification, regression, and off-policy policy learning). The authors propose a generic importance sampling weighted ERM algorithm with adaptively collected data. The authors show that fast rates for classification and regression with convexity of squared-error loss can be obtained with maximal inequality. The regret guarantees for policy learning with regret guarantees are also provided. The main contribution of the paper is a theoretical analysis of the fast convergence rates of the proposed algorithms. The theory is well-motivated and easy to follow. "
SP:f549a0c231b71bae0acbed6e3afb41890ee89cd9,"This paper studies the problem of kernel-reweighted regression with low sample sizes and covariate perturbations in machine learning tasks. The authors propose a mitigation strategy to tackle these problems by reweighting the weighting matrix with a doubly non-negative matrix. The paper shows that the reweighted matrix has the same predictive power as the original models, but with a lower uncertainty set. The proposed weighting matrices are based on log-determinant divergence and Bures-Wasserstein distance, which is a well-studied and well-motivated idea. The main contribution of the paper is the use of first-order methods for adversarially reweight the estimate."
SP:fe12e13602925b9400fd596a987755beb10aa3d1,"This paper studies the problem of low-variance reparameterization gradients with continuous relaxation. The authors propose a new estimator based on importance sampling, statistical couplings, and Rao-Blackwellization. They show that the estimator can be trained with binary random variables, and that it can be used to train models with discrete latent variables. They also show that their estimator performs better than REINFORCE with a leave-one-out-baseline estimator."
SP:e16fdf963ec2f9c0d79fa404e47e7862a5d6e922,"This paper proposes a new architecture search method called Neural Architecture Search (NAS). The main idea is to use a proxy accuracy predictor to predict the architecture of a given architecture, and then use a search path to find the high-performance sub-space. The search path is based on the search path of weaker predictors that predict the top architectures. The paper shows that using a predictor that predicts the architecture space of a well-performed architecture is a good predictor for well-performing architectures.  The paper also shows that by using a coarse-to-fine iteration, the ranking of sampling space can be improved.  WeakNAS outperforms SOTA on ImageNet MobileNet Search Space and NAS-Bench-201. "
SP:8f74abb04037ba2e59dcf8320dc555b149f68ed8,"This paper studies the problem of learning a globally consistent coordinate system with latent codes. The authors propose to use Entropic Desired Dynamics (EDDICT) to learn the Intrinsic ConTrol (ICDICT). The key idea is to use EDDICT’s globally consistent codes in order to make it tractable with tractable learning and interpretable latent space. The local objective is to learn a fixed additive latent dynamics that is invariant to changes in the global objective. The proposed method is evaluated on a variety of hard exploration games, including Montezuma “s Revenge” and unsupervised. The results show that the proposed method performs better than prior methods."
SP:c731a78c3e7f98ccd0253b51a0d42bf8deeb71f9,"This paper proposes a new reward scoring function for drug design in reinforcement learning (RL) based on the molecular docking program in physical simulation (MDP). In RL, the goal is to find a protein-small molecule binding affinity in a realistic and qualified chemical space. The exploration problem is formulated as docking score optimization, which is a well-studied exploration problem in the literature. The authors propose a new RL framework for finding pharmacochemically acceptable molecules with docking scores that are close to the docking scores of pharmacologically acceptable molecules. The proposed method is based on fragment-based generation method, error-priorized experience replay (PER), and Explorative Experience replay for Drug design (FREED). Experiments show that the proposed model performs better than previous methods on de novo and scaffold-based schemes. "
SP:b938bca513e7de1231212064caf8877a78d8b612,"This paper studies the complexity of directed acyclic graphical models on observational data. The authors propose a local Markov boundary search procedure to recover ancestral sets of a graphical model from ancestral sets. The proposed approach is based on a forward greedy search algorithm to recover the Markov boundaries of a graph ensembles with a backward pruning phase. Theoretically, the authors show that the resulting graph has an identifiability condition on the number of nodes in the graph, and that the sample complexity of the algorithm is bounded by a finite-sample guarantees. Empirical results on polytrees with polynomial time demonstrate that the proposed approach can recover discrete or continuous distributions with minimal assumptions."
SP:af08109d4c45dc9401efb0e63c22167e9da28adb,"This paper studies the problem of learning with differential privacy (DP). The authors propose a ("","") DP algorithm for privately learnable class with public randomness. The privacy protection is based on the probabilistic representation dimension of the local model. The authors provide a nearly-matching lower bound for ""DP algorithms"". The authors also provide a correlated sampling strategy to improve the global stability."
SP:da4f21d107a7f442c4d3e3ec13bdb44b041e07cf,"This paper studies the problem of estimating the per-state expected cumulative rewards in reinforcement learning approaches that are based on the latent Markov decision process in transition and reward models. The authors propose a new deep neural-network function-approximation methods, where the value iteration networks are trained with implicit representations of value functions. The implicit representation is trained by stochastic gradient descent (SGD) and the explicit counterpart is learned by gradient descent for global optima. The convergence rates for the two cases are shown to be close to each other. "
SP:992aa07d4f815d1c81f967374590eece933833b1,"This paper proposes a novel KG refinement task for KGs. The authors propose a new KG-based question answering framework based on the IterefinE framework. The key idea is to use embeddings from text sources for inferring new facts in Knowledge Graphs (KGs). The authors use two techniques to improve the KGS refinement: (1) using inferences rules and (2) using the ontological information in KG embedding. The proposed techniques are evaluated on a variety of KG benchmarks, including ComplEx and KG benchmark. "
SP:676fc4a3041af22e8f20ccba7daa2a0b1f5d6af5,"This paper proposes a new evaluation paradigm for model selection criteria for Knowledge base completion (KBC) methods. The proposed method is based on binary predictions for KBC quality, where the likelihood ranking is a function of the evaluation data structure. The authors show that KB embeddings models have better prediction separability than KB embedding models with real-world entities in KB. They also show that the proposed method, called FB14k-QAQ, outperforms KB in a ranking task on a benchmark. The main contribution of the paper is the introduction of a new thresholding in TransE, which improves the classification F1 score of TransE by a factor of 1.5 for ranking-based and classification-based evaluation. "
SP:83fe0a496a79bcf97ccba1c6d34b7d11e7d5c330,"This paper proposes a framework called Alternating Roles Dialog Model (ARDM) to learn dialog system models for tasks with human annotations. The framework is based on language priors for down-stream NLP tasks where the goal is to generate dialog response generation using pre-trained language models such as BERT and GPT-2. ARDM is trained using a large pretrained language model and human annotations such as belief states, dialog acts, and dialog acts. It is also trained with supervision to learn the human-like responses to conversations. Experiments on task-oriented dialog datasets such as CamRest676 and MultiWOZ show that ARDM performs better than state-of-the-art methods on non-collaborative tasks like persuasion."
SP:b11c06b7c4ef1aa43c59f808a679425e302d158e,"This paper proposes a deep neural network for classification with softmax values. The proposed method is based on the binning values of the confidence measures for Top k. The authors propose a new uncertainty measure, the implied loss, which is defined as the difference between the two values. They show that the proposed method can be applied to a wide range of networks."
SP:ab9666e15f2a0113d96cb4b47b1cbb30fa1f7982,"This paper studies the generalization of neural networks with different architectures and hyperparameters. The authors propose a new kernel called Neural Tangent Kernel (NTK) that can be used for gradient descent with wide neural networks. NTK has a spectrum that is much wider than the NNGP kernel, and can be applied to Gaussian Processes. They show that NTK can achieve better generalization than other architectures such as Fully Connected Networks (FCNs) and Convolutional Neural Networks (CNNs). The authors also show that CNNs with average pooling are better than FCNs in terms of learning dynamics. "
SP:d3470c35aae48bf92439a55fdb98ccf07100e567,"This paper proposes a new graph-based method for protein folding, GRAPHQA, which combines geometric invariance and computational efficiency. The authors show that GRAPHA is able to learn a 3D structure of the protein’s structure, which can be used as a basis for learning a sequence of protein models. The paper also shows that the learned structure can be combined with existing hand-engineered and representation-learning approaches to achieve state-of-the-art performance. "
SP:5188280131b58a35d3deda126a0754aea8fa6e58,"This paper studies the landscape of linear networks in terms of the loss function of a neural network. The network’s weights are defined as the geometry of the functional space and the parameterization of this space. The paper shows that pure critical points are better than spurious critical points, and that the determinantal variety of linear neural networks (i.e., linear maps with bounded rank) is better than the pure critical point. The authors also show that the loss functions and parameterizations in linear networks are more general than in non-filling architectures. The main contribution of the paper is to show that linear networks with bounded loss landscape are more robust to smooth convex losses than linear networks that have quadratic loss. "
SP:ee71597ceab23eb4db1d6608f15f80ad51f7ff6d,"This paper studies the problem of unsupervised graph learning in the context of predictive or information retrieval tasks. The authors propose a new graph similarity evaluation for learning processes based on reconstruction error based loss functions. The proposed SEED framework is based on the embedding of the subgraph vector distribution in the output vector representation of a graph. The subgraph vectors are then used as input to the embeddings of subgraph samples, and the output vectors are used as output vectors to generate the final graph.  The authors show that SEED can achieve state-of-the-art performance on several public benchmark datasets. "
SP:d9406fdf0a180a5efc6f15ba8739524665f0f9d2,"This paper studies counterfactual regret minimization (CFRM) methods for twoplayer zero-sum extensive games with imperfect information. The authors propose a new CFR algorithm called Lazy-CFR, which is based on the lazy update strategy. The main idea is to use vanilla CFR for large-scale games where the game tree is not fully connected to the environment. The regret is shown to be lower than vanilla CFR, and Lazy -CFR is also shown to have a lower regret than CFR."
SP:023aa3dca1cf7992b22993a7088e8a74c92bb47e,"This paper studies the problem of unsupervised domain adaptation (UDA) methods for transferable features from source domain to target domain. The authors propose a new method called Distribution Matching Prototypical Network (DMPN) that uses Gaussian mixture distributions to learn deep features from labeled source data and domain discrepancy losses in the DMPN. The proposed method is based on explicit feature distribution modeling, where the feature distribution discrepancy between source and target domain is computed using Gaussian component means. The paper shows that the proposed method achieves better mean accuracy than existing state-of-the-art approaches on the Digits Image transfer task. "
SP:40be996e8bb86e887077b762b87c7c34a786ac98,"This paper proposes Continuous Normalizing Flows (CNFs), a family of deep generative models for tasks where the latent space is a highdimensional latent code. CNFs are useful for conditional image generation and downstream predictive tasks. The authors propose InfoCNF, a conditional CNF that combines the unsupervised code and the class-specific supervised code in a single conditional. The main idea is to use gating networks to improve the error tolerances of ordinary differential equation (ODE) solvers by partitioning the data into two parts: (1) a partitioning strategy for extrapolation, and (2) a Gating network for exact likelihood estimation.  The authors demonstrate the effectiveness of the proposed method on CIFAR10 with NFEs. The likelihood scores of the learned model are better than the baseline. "
SP:97764e3393216106ff2ac3f550845acf4636119f,"This paper studies the problem of learning nonlinear functions for approximation of the value function. The authors propose a Temporal-Difference (TD) learning algorithm for learning the approximation of nonlinear function in a lazy training regime. The problem is formulated as an optimization problem, where the objective is to find an approximating function that is close to the true value function in the learning process. In the regime, the model is trained with non-lazy TD learning, and the goal is to learn a model that converges to a value function close to its true value. The main contribution of the paper is to show that the proposed algorithm achieves exponential convergence in a relatively simple and effective way. The paper also provides theoretical guarantees for the convergence of the algorithm.   The authors also provide a theoretical analysis of the effect of lazy training on the performance of neural networks trained with underand over-parametrized frameworks. "
SP:c518e4030f12b0f59ad1d7c0fc0ebd313c68ef95,"This paper studies the reinforcement learning problem for hypothesis verification. The problem is formulated as a problem where agents are given an action sequence, a pre-condition, and a post-condition. The agent has to decide whether to accept the action sequence or not. The goal is to minimize the number of times that the agent takes the action, and to make sure that they accept the post-conditions."
SP:6fa2f842b1bc993ed8024a3ce13dbd91529c61be,"This paper studies the problem of approximate reasoning in the fixed dimensional latent space of graph neural networks. The authors propose a rewrite-success of statements in the latent space, which is a special case of the rewrite steps in the formula space and latent space. The rewrite rule is based on the rewrite rule in the vector space, and the authors show that the embeddings of the proposed embedding are better than those of the original and predicted latent representations. The paper also shows that the learned representations are more interpretable than the original representations. "
SP:a77ab500a5e7d4ea8430871d1e603941e92974fd,This paper proposes a new approach to measure depth based on images and sparse depth measurements. The approach is based on a global-local network architecture that is able to capture the inductive bias of natural intelligent agents. The authors show that the global parameters of the network can be used to estimate the metric agent motion. The proposed method is evaluated on a variety of datasets.
SP:2afba5e24478da4e9d493887c7cf00e288cc0deb,"This paper studies the problem of learning word pieces for machine learning tasks using natural language models. The authors propose Bloom filter, a multi-layer Transformer for Bloom filter digests. They show that this method can solve a variety of problems with large vocabulary size and large computational budget. They also show that models trained with sampled softmax can achieve better accuracy than models trained without hashing. "
SP:745dd86d7f7bba79a02d27922003b764b620f83e,"This paper proposes a learningbased agglomerative clustering framework based on a grouping policy for small part proposals. The proposed method is based on the largescale fine-grained 3D part dataset, PartNet. The key idea is to use a local context to learn the part-level features from the data. The authors show that the proposed approach outperforms existing shape segmentation baselines in terms of knowledge of parts. "
SP:868fc6df740b04963442d5abcfe2f4845585cfc8,"This paper proposes a generative adversarial network (GAN) to generate images of black-hired men from input/output datasets, where they can be used to train generative neural networks. The authors use a discriminator to learn the target distribution of the source distribution and target distribution, and then use an autoencoder to generate transformed data using an editing transformation on the transformed data. The transformation is based on a latent space in the latent trained space, which is used to generate complex and non-linear transformations. The paper shows that this technique can be applied to different data domains, modalities, and applications in biology (e.g., removal of batch artifacts, removal of drug treatments). "
SP:6dee6932e64fe47bb44dd42fc242fa9d89b8d89c,"This paper studies the problem of few-shot image classification and reinforcement learning with meta-learning methods. The authors propose a new meta-training method for the few shot setting, which is based on the first-order meta-learned of initializations for deep neural networks. The main idea is to learn the initializations of the neural network by ensembling many models, and then use these initializations to perform dense, structured predictions. The paper shows that the proposed method is able to achieve better generalization error than the state-of-the-art on a small benchmark dataset, FP-k. "
SP:ec6f390f6d45fb79c33ae5d9c8a24cadb96fbd60,"This paper proposes Prototypical Random Walk Networks (PRWN), a new SS-FSL approach called Prototypic Networks (PN) for few-shot learning with unlabeled data. Prototypically Networks (PN) is a SS-FSL approach based on Prototypicial Random Walk Network (PWN) that uses a random walk semi-supervised loss to learn representations from the unlabelled data. The network learns representations by using a prototypical random walk notion to learn compact and well-separated class representations using graph-NN parameters. The proposed model outperforms the state-of-the-art in the 1-shot mini-Imagenet case, and it also outperforms fully supervised prototypical networks in the 2-shot classification task. The paper also shows that the proposed model is more robust to distractors than the state of the art in the mini-imagenet setting. The authors also provide a discriminative power test to evaluate the performance of the proposed baseline."
SP:d12e687bd2ee9fa60554312e644bb0a6487974f1,"This paper proposes a new self-supervised learning objective for remote sensing based on Contrastive Sensor Fusion. The proposed method is based on the idea of fused multi-sensor representations, which is an extension of the multi-channel information in multi-source sensing applications. The key idea is to use unlabeled data to train the model to learn a representation of the data, and then use the encoder to learn representations from this dataset. Experiments on the remote sensing classification task demonstrate the effectiveness of the proposed method."
SP:4d8e054f07006b4f896721b5c24da805727d2c22,"This paper studies the problem of fine-tuning neural network pruning algorithms. The authors propose a new retraining technique, called Weight rewinding, which uses a learning rate schedule to re-weight the unpruned weights in the training process. They show that Weight Rewinding improves the accuracy and compression ratios of the proposed network-agnostic pruning algorithm. They also show that the proposed method is more efficient than other re-winding techniques."
SP:3bb1c79f9482e09828eda45fbb2e654f37219365,"This paper studies the problem of robustness of deep neural networks in the presence of adversarial attacks. The authors propose a theoretical inspired training algorithm to learn the all-layer margin, which is the (normalized) output margin of a neural network in the adversarially robust setting. The proposed algorithm is based on the Jacobian and hidden layer norms of neural nets. The theoretical results show that the proposed algorithm improves the robust test error of deep networks. "
SP:3d44f27468087280e85dfb1fc7291db05179fe6d,This paper studies the problem of knowledge-grounded dialogue generation from ungrounded dialogues and unstructured documents. The authors propose a new response generation model based on a disentangled response decoder. The model is trained on a set of limited training examples with small parameters. The proposed model is evaluated on a variety of benchmarks with out-of-domain knowledge.
SP:9b555f7fe743f5effdbdc8701ed519ce3159c4b0,"This paper proposes a parallel corpus for neural machine translation models (NMT) with non-parallel bilingual data for training and decoding. Existing approaches are based on the use of parallel bilingual data to train the NMT on the non-preparable bilingual data. The authors propose a single unified architecture, mirror-generative NMT (MGNMT), which combines a source to target translation model with a target to source translation model and a language models. The proposed MGNMT is shown to perform better than existing approaches in both resource-rich and low-resource situations. The main contribution of the paper is to show that the translation models trained on the latent semantic space of language models and language models can be used for decoding and translation models for decoding. "
SP:d7a530a0ec4112095a58cef4cda9646f8ca6449d,"This paper studies the sample efficiency of maximum entropy reinforcement learning algorithms for Deep Reinforcement Learning (DRL). The authors propose a new entropy term for maximum entropy algorithms for the bounded nature of the action spaces. The entropy term is used in Soft Actor Critic (SAC), which is a Mujoco benchmark. The authors show that the entropy maximization of SAC can be used to speed up the training of the SAC. The main contribution of the paper is a non-uniform sampling method for the transitions in the replay buffer. The proposed streamlined algorithm outperforms SAC on continuous control tasks."
SP:545e8da553fcb47d84eaa044d8a4947d3cd3230e,"This paper proposes a new classifier for the task of protecting the web from adversarial attacks on machine learning models. The proposed system is based on neural network based systems and uses gradient methods to train the system using a neural net. The authors show that the proposed method is able to identify the source of the attacks, and that they can be used to train a classifier that can detect the source and target of the attack. They also show that their method can be applied to other industrial systems such as AudioTag copyright detector and YouTube’s Content ID system. "
SP:b511822850da3bf1079a36ed6f5ad4db80fbc424,This paper proposes a visual explanation for deep metric learning. The framework is based on the idea that the overall activation map of a learning representation can be represented as a set of point-to-point activation intensity. The model can be used for both cross-view pattern discovery and interactive retrieval. The authors show that the proposed framework can improve the performance of the model compared to classification. 
SP:67bf71219fe6bedec5f5525200e734638e4a6ca2,"This paper proposes Adaptive Online Planning (AOP), an online lifelong learning scenario where the goal is to learn a continual learning agent that is able to adaptively adapt to new environments. The authors propose a new setting where the learning agent is a planner and the environment is a set of compact networks. The planner is a continuous learning agent, and the dynamics of the environment can be controlled by the planner. The algorithm is based on the idea that the planner can learn to adapt to the environment in a way that is consistent with the environment.  The authors show that AOP can adapt to different environments in a similar way to previous model-free policy learning methods. They also show that they can learn failure modes that are similar to the ones in previous models. "
SP:11159cb878a436a5d4fc6edb4132f2cc3c1b3f72,This paper proposes a new softmax attention mechanism based on sparsity-promoting transformations such as sparsemax and Total-Variation Sparse Attention (TVMAX). The key idea is to use sparsemax for sparse attention weights and TVMAX for sparse features. The authors show that the TVMAX transformation improves interpretability and improves the humanrated caption quality and attention relevance compared to other attention mechanisms such as TVMAX. Experiments are conducted on the Microsoft COCO and Flickr30k datasets.
SP:fb0c3ce3db6ad674ddc615bdc6203cdcbe42c804,"This paper proposes a new model for predicting the evolution of dynamic graphs in graph mining. Neural networks are used to model structured data such as graphs. The authors propose a graph neural network and a recurrent architecture to learn temporal evolution patterns of dynamic graph. The graph instance is learned by a generative model, and the topology of the graph is learned from the graph instance. The model is evaluated on two real-world datasets and two artificial datasets with common network evolving dynamics. "
SP:ff722957a1765c0568426ed88dd910a6b74054ef,"This paper proposes a method for imputing missing features from incomplete datasets to machine learning applications. The missing data imputation techniques are commonly used for filling missing values. The authors propose a method to generate imputations from incomplete data using a generator network trained on the imputations generated by a discriminator network. The imputed samples are then used to train a predictor network that predicts the distribution of missing values, and the generator network is used to estimate the classification uncertainties. The method is evaluated on CIFAR-10 image dataset and real-world tabular classification datasets and shows that the proposed method can improve the performance of generating imputations in a classification task with class uncertainties."
SP:c051b0fe779d9e4131016970b7ba469b596f3009,This paper studies the problem of on-policy evaluation in the context of high-fidelity simulators. The authors propose a new estimator based on Reproducing Kernel Hilbert Spaces (RKHSs) to estimate the importance ratios of stationary distributions of a known behavior policy over a stationary distribution. The estimator is based on the asymptotic consistency and finite-sample generalization of the estimator. The proposed approach is evaluated on two real-life applications: healthcare and robotics. The results show that the proposed estimator outperforms existing importance-sampling-based methods in terms of curse of horizon.
SP:065c900843011a71b70ed35357a2f71fe83872a7,This paper proposes a probabilistic framework for training a dataset using a Mixture Model (MM) called Gaussian MM. The dataset consists of two large datasets: the paintings dataset and the fashion images. The two modes are based on the Gaussian distribution of the data and the two modes of the dataset are unlabelled modes. The authors propose a plausible method for estimating the probabilities of the two mode distributions. The proposed method is based on a GAN that predicts the distribution of each mode. The GAN is then used to train a classification network using the GAN.  The authors show that the proposed method can be used to estimate the conditional likelihood of the model. They also show that using smooth linear interpolation on the “outdistribution” data can improve the performance. 
SP:2da1608209058d214f8671062cc9eb0833ba4831,"This paper proposes a method for training large capacity neural networks in a fine-grained-level. The authors propose a residual block architecture for convolutional channels, which can be trained in a more efficient and efficient manner than a standard deep-learning architecture. The proposed method is based on batch-shaping, where the network is trained with the marginal aggregate posteriors of features in the neural network, which are defined by a pre-specified prior distribution. The technique is applied to the gates of the gates, and is shown to improve the accuracy and the dynamic computational cost of the proposed method. Empirical results on CIFAR-10 and ImageNet datasets for image classification and Cityscapes for semantic segmentation show that the proposed architecture performs better than the state-of-the-art ResNet34 gated networks on ImageNet with top-1 accuracy. The complexity of the ResNet18 model is also improved over the existing architecture. "
SP:f90e9f0eb53f92601bdfa3f7bf86f71d037aad30,This paper proposes a probabilistic importance inference approach for pruning DNNs. Deep neural networks (DNNs) are a special case of DNN with energy and computational resources. The authors propose a new approach to prune the DNN’s outputs by using a nonparemetric scoring test. The proposed approach achieves better lossless compression rates than existing techniques.
SP:64cbbb6a2f6847ef71cd5a23ba3e4cc5c815a56e,"This paper proposes a new approach for hierarchical reinforcement learning. The proposed method is based on iteratively compressing action trajectories into nested behavioral hierarchies, which can then be used as action primitives for learning deeper hierarchies. The approach uses a transfer between different sub-goal structure, where the subgoal structure is learned from the perspective of the compact code of actions. The authors show that the proposed approach can improve the performance of learning in the presence of non-trivial hierarchical structure."
SP:e1ccfb3a684aef8a0fb36194eb16af1667811e81,"This paper proposes a probabilistic generative model, Hierarchical Bayes Autoencoder (HBAE), which is a variant of Autoencoders, which are generative models for complex data (e.g., images). The models are unimodal Gaussian decoders. The authors propose a multimodal decoder based on an energybased model (EBM) that is trained with a conditional generator to predict the EBM distribution. The decoder is trained using adversarial approximation to the decoder. The model is evaluated on both single image and set cases, and is shown to be able to generate realistic unconditional samples. "
SP:1130a391afa30d1e0fddadedd2a3aaa70a4cb751,This paper studies the problem of normalization in reinforcement learning (RL) algorithms. It proposes a mixture of on-and off-policy transitions to improve the optimization stability. It also proposes a batch normalization for the normalization. The authors show that cross-normalization improves the performance of DDPG and TD3 on MuJoCo benchmark tasks. 
SP:f9cafaa5131176290fa069e6d24046c079cd9eea,"This paper studies the problem of face recognition with spurious associations of confounding variables in the presence of bias and confounding effects in machine learning applications. The authors propose two techniques, stratification and residualization, to learn precomputed features for confounding variables, which can be used to train end-to-end deep learning methods. The proposed method is based on an adversarial training strategy to learn discriminative features from the data. The method is evaluated on synthetic data and medical images and shows that the proposed method outperforms state-of-the-art methods."
SP:783049ff463edd1283c058c6106a3e1f9a033df4,"This paper proposes a lightweight model, GroupTransformer, for character-level language modeling with limited resources. The lightweight model uses grouped embedding operators to perform calculation paths using inter-group linear operators. The authors show that the proposed group strategy outperforms LSTM-based models on several benchmark tasks (e.g. enwik8 and text8). "
SP:946c26d371297c88d0ac246257104099b4585edc,"This paper proposes a non-likelihood-based framework for training generative models with hierarchical-latent-variable structures. The proposed approach is based on Variational Autoencoders, which can be used to train models with deep-latency hierarchies. Optimal Transport is used to optimize the models using Optimal Transformer. The authors show that the proposed method is able to generate a generative model with a deep- latent hierarchy, and that it can achieve better performance than the Wasserstein Autoencoder with Maximum Mean Discrepancy divergence. "
SP:309b47441d227ffa33f96f9f16f2addc607e5bb0,"This paper studies the problem of generating natural video from video. The authors propose a three-dimensional self-attention mechanism to train autoregressive video generation models with three different methods: video-specific neural network architectures, latent variable models, and adversarial training. They show that they can achieve state-of-the-art results on a variety of benchmark datasets. They also show that their methods are able to generate continuations with high realism in terms of their inherent stochasticity. "
SP:ad8fcdbc47a50dd2bf58aba2bc6cfe199e84dd4d,"This paper proposes a new method for zero-shot classification of ICD codes. The proposed method is based on a latent feature generation framework, which can be used to learn a generalized zero-Shot ICD coding. The key idea is to use the ICD code hierarchical structure and a cycle architecture to learn the keywords for each code. The authors show that the proposed method outperforms existing methods on the public MIMIC-III dataset. "
SP:3ce82ae297e5759ab957babe9927062e7a71b0ba,"This paper studies the sample efficiency of self-supervised representation learning in reinforcement learning (RL). The authors propose a forward prediction objective for embeddings of states and action sequences, which can be used for policy learning. The authors show that the embedding of the structure of the environment’s dynamics can improve sample efficiency for model-free RL with low-dimensional states. The paper also shows that the action embedding can be useful for the learning of high-quality policies with pixel observations. The goal-conditioned continuous control can also be used to improve the performance of the learned policies."
SP:11ce1616e721340eea9e80dad7460c77355ac7d1,"This paper proposes a framework for meta-learning for tasks with cross-task relations. The proposed framework is based on a meta-knowledge graph, which is a combination of knowledge bases for knowledge organization and meta-learner. The authors show that the proposed framework improves the model interpretability and reduces the task heterogeneity. The experimental results show that ARML performs better than other baselines. "
SP:37c209cd1c628b5c2f2b282fbeaf4bbf437c7670,"This paper proposes a Plug and Play Language Model (PPLM) for controllable language generation. The model architecture and fine-tuning are based on attribute-specific data. The PPLM uses a pretrained LM and attribute classifiers to perform text generation, where the gradients are learned by retraining the attribute model. The authors show that the PPLMs perform better than other attribute models on both automated and human annotated evaluations for attribute alignment and fluency. "
SP:12d0980bfea2de880905a0b87b40856969bb1c58,"This paper proposes a new unsupervised learning framework for learning robust representations from unlabeled data. The agent is trained with domain knowledge, and the goal is to learn representations that are robust to noisy input data in the gradient domain. The proposed approach is based on denoising autoencoder to learn data representations that can be used to train representations for vision tasks on visual benchmarks. The authors show that the proposed approach can achieve state-of-the-art performance on a variety of vision tasks."
SP:12afc1b259e51a31cbeb72366d2b93fbee1aafaa,"This paper studies the under-sensitivity problem in natural language inference with neural networks. The authors propose a technique for formal verification of this specification by using interval bound propagation (IBP) approach. The proposed method is based on a decomposable attention mechanism, and the authors show that they can improve the performance of existing training methods in terms of under-sensitive performance. They also show that IBP training can achieve better verified accuracy on SNLI and MNLI datasets. "
SP:14257af9fe83522c6e5b5d6b0d68945b944e30fb,"This paper studies the problem of learning the Q-values of a Markov Decision Process (MDP) from data graph. The transition in the MDP is a continuous Q-learning problem with Q-value, and the authors propose a new structure based on soft divergence between the state and action spaces of a subgraph with favorable structure. The QGRAPH is then used to learn the hyperparameters. The authors provide lower bounds on the sample efficiency of the proposed method based on TD learning. The proposed algorithm has a replay memory capacity of $O(\sqrt{T})$ and can be used for network updates. "
SP:c92c97e47d8b218dfd009bbf61f5b3547b395f91,This paper studies the problem of unsupervised domain adaptation in multilayer neural networks with domain-invariant embeddings. The authors propose an approach to solve the problem using domain-irreversible domain-agnostic embedding. The key idea is to use a theoretical framework to model the embedding complexity of the generalization of multilayers neural networks. The paper shows that the proposed strategy achieves better performance than the layer-dependent complexity tradeoff. 
SP:f3f3c6fbae757836551b3f1ee54a7d1e040132b8,"The paper proposes a new framework for computing algorithm-dependent generalization error bounds for stochastic gradient Langevin dynamics (SGLD). The framework is based on PAC-Bayesian theory and algorithmic stability. The Bayes-Stability method is used to derive the data-dependency generalization bounds for data-dependent SGLD. The authors show that the bounds are tight for continuous Langevin dynamic under the Log-Sobolev inequality of the parameter distribution. The bounds are also tight for noisy gradient methods (e.g., momentum, Entropy-SGD, mini-batch and acceleration). The authors also show that under the bounded loss and the `2 regularization term of the total loss, the bound is tight for the bounded losses. Finally, the authors provide some theoretical guarantees for the bounds."
SP:a82fcd1d3196ddf078cfe8f4bc6f445d9d2bdc11,"This paper studies continual learning of navigational strategies in biological and machine learning. The authors propose Demixed Principal Component Analysis (dPCA), a method for continual learning with hippocampal CA1 neurons with populationlevel activity in the hippocampus. The main idea is to use continual learning to learn spatial memory and goal-directed spatial navigation using the hippocampus, and then use the hippocampus to train the spatial navigation strategies in continual learning.  The authors show that dPCA is able to learn the components of the hippocampal neurons, including the decision-making process and the reward location of the task variables (e.g., decisions, navigation, etc.). The authors also show that the firing activity of dPCAs can be used to improve the performance of a deep reinforcement learning model compared to animal learning, and that hippocampal features are more robust to task switching than other reinforcement learning algorithms."
SP:51acf1f8108683dce543a1fb4a61fbd593f9b4cc,"This paper proposes Monte Carlo Tree Search (MCTS), a tree search based policy optimization method for continuous environments (e.g., Go) where the tree search branching factor is bounded. The main idea of the approach is to use a pre-trained policy as a bootstrapping tree search, where the goal is to find a policy that minimizes the MCTS branching factor in a continuous action space. The authors propose a hybrid approach to the TPO, which uses a TPO to perform policy optimization in the continuous space.  The main contribution of the paper is to show that the policy gradient can be computed using off-policy mCTS trajectories, and that it can be applied to continuous domains such as Go. The paper also shows that the branching factor can be used to bootstrap the policy bootstrapped in the case where the policy distribution is unknown. "
SP:1ce3bc4d31712886f7dcada5b5ae67c3c376819a,"This paper studies the lottery ticket hypothesis in the context of neural network optimization. The authors consider sparse subnetworks in neural networks, where the number of neurons in the network is small and the accuracy of the network depends on the size of the initializations. They propose to use supervision to guide the generating process. They show that winning tickets on the ImageNet dataset are better than winning tickets in the standard ImageNet classification task."
SP:dbcebe5b73486885d9f4478b258047c02f8481a2,"This paper studies the problem of excessive prediction undersensitivity in Neural reading comprehension models. The authors consider the complementary problem of learning models with spurious surface patterns, where the adversarially selected input is masked by semantically invariant text perturbations. They propose two defence strategies: data augmentation and adversarial training. They show that the proposed model is robust to undersensitivity attacks on held out evaluation data, and they also show that they are robust in the biased data setting with a train/evaluation distribution mismatch. Finally, they show that their model can outperform the state-of-the-art NewsQA models on F1."
SP:5da870060778de460c1abe91562d6f3e707efef4,"This paper studies the problem of safety of reinforcement learning (RL) agents in real-world tasks. The authors propose a model-based approach to improve the safety of RL agents in the presence of bad incentives. The proposed approach is based on the idea of a directed graph, called an imaginative module, where the goal is to minimize the safety penalty in the reward function. The paper shows that the proposed approach performs better than a baseline in a self-driving car simulator and gridworld environments."
SP:c2796f28fb067138303df8d424d646f4ada31558,"This paper studies the dynamics of physical systems. The authors propose a deep learning models for physics-regulating observations on an unstructured grid. The main idea is to learn the discretization error of the finite differences between two points in the space of neighboring information, and then use the neighboring information to compute finite differences based on physics equations. The architecture is based on PA-DGN, which is able to learn dynamical relations between points in space. The paper shows that the approximation of directional derivatives and the prediction of graph signals using synthetic data and real-world climate observations from weather stations can be used to improve the performance of the architecture."
SP:db8ed4f4fc3967f5dd4d208d5d029730eb99e840,"This paper studies the problem of nonsmooth regularization and constraints in structured neural networks (NN). The authors propose a new regularization function and a constraint set for ProxSGD for sparse or binary neural networks. The constraints are based on interval constraints, where the learning rates are bounded by a stationary point. The authors show that the constraints are equivalent to the `1-norm' of nonsnooth regularisation, which is a well-studied problem in the literature. The paper also shows that the constraint set can be used to improve the performance of ProxSVGD. "
SP:2ca1f4da9faee79768764cda5d09d949cc942acc,This paper proposes a framework for lossy image compression based on a non-deterministic compression codec. The encoder is trained using approximate methods to approximate compression algorithms. The proposed framework is based on gradient-based optimizers. The authors show that it can achieve state-of-the-art rate-distortion curves with low bitrates on the Kodak dataset and Probabilistic Ladder Networks (PLNs) on the CLIC 2018 dataset.
SP:788fd2b6956dd69bf7752d39ea21883947128c8a,This paper studies the Super Resolution (SR) problem in compressed JPG (C-JPG) image processing operations. The SR structure consists of two components: a functional sub-model and a cycle loss. The authors propose a hybrid loss function for SR generation using the SR solver. The proposed approach is shown to outperform state-of-the-art methods in the SR issue. 
SP:18dd92f2f55020be4f5a089b3b251327e47886f4,This paper proposes a fully convolutional network architecture for the surface of pass probabilities based on single-location labels from professional soccer matches. The network is trained with low-level inputs and a feature hierarchy. The sampling levels of the network are determined by coarse and fine detail. The proposed approach is applied to weakly supervised learning and is shown to improve the performance of spatiotemporal decision-making analysis in a variety of sports. 
SP:1ae31baf383fc520687b255d9cac14c3b040e253,"This paper proposes a new inductive matrix completion model based on the side information of the content (side information) matrix, i.e., the user’s age, movie‘s genre, and the movie ’s genre. The authors use IGMC to train a graph neural network (GNN) with low-dimensional latent embeddings. The model is trained on the MovieLens dataset, and is evaluated on Douban movie ratings. It outperforms other matrix completion methods on the Douban dataset. It also performs better than transductive baselines. Long-range dependencies are important for modeling recommender systems, and this paper proposes to use this type of side information to improve the performance of inductive matrices completion models. "
SP:c5cb1b50e17a69e88d5ae28848e265215162da1e,This paper proposes a stochastic zeroth-order method based on heavy ball momentum. The main idea is to learn a smooth objective function for unconstrained minimization. The method is evaluated on a variety of learning to continuous control tasks and compared to STP and other derivative-free optimization algorithms as well as policy gradient methods. The complexity of SMTP_IS is shown to be much smaller than other methods.    The main contribution of the paper is to propose importance sampling to improve SMTP. 
SP:a216cfc29937eb398ea98cb1aea3481c9aed8240,This paper studies the problem of multiagent systems (MASs). The authors propose a new deep learning architecture for multiagent coordination mechanisms. The proposed Action Semantics Network (ASN) is a network architecture based on the action semantics learned by neural networks. The authors show that ASN outperforms the state-of-the-art deep reinforcement learning (DRL) algorithms and other network architectures in StarCraft II micromanagement and Neural MMO. The ASN also outperforms other DRL approaches.
SP:efaf3a440dc17e05177832083ffbc23760ed7c97,"This paper proposes a new framework for planning and deep reinforcement learning (RL) based on value-based methods. The framework is based on Matrix Estimation (ME) techniques, where the Q function is a state-action value function, and the goal is to learn the global structures of the Q functions based on system dynamics. The proposed framework uses the low-rank structure of Q functions in big data matrices to learn control and deep RL tasks. The authors propose a planning procedure for classical control and a scheme for “low-rank” tasks. Experiments on control tasks and Atari games demonstrate the effectiveness of the proposed approach."
SP:430336893b247b7bd45687d78b0d0511a7369e87,"This paper studies batch reinforcement learning for sample-efficient learning in Deep Reinforcement Learning (DRL). The authors propose Best-Action Imitation Learning (BAIL), an off-policy DRL algorithms for the batch DRL setting where the goal is to maximize the Q functions in the action space. BAIL uses imitation learning to learn a policy network with state-action pairs, and it is shown that it can achieve better performance on the Mujoco benchmark. The algorithm is well-written and easy to follow."
SP:94078964876667e8a5d9ae7728d779d5b91a576e,"This paper proposes a new DeepXML algorithm for the task of deep extreme multi-label learning, where feature representations and classifiers are used for short text documents. The key idea is to use word embeddings from the Slice algorithm to train a deep XML architecture that can be used to train pretrained embeddits for the pretrained embeddeddings. The authors show that by using negative sub-sampling techniques for negative training data, they can achieve better accuracy than existing leading techniques in terms of search engine queries and advertiser bid phrases. They also show that the proposed architecture is able to perform better than XML-CNN and AttentionXML."
SP:b1b1252d82fa1bea18309e0b0b894e0f28f48bc9,"This paper studies the problem of hashing-based collaborative filtering with binary vector representations (hash codes). The authors propose to use Hamming distance between the hash codes of the user hash code and the mask of the mask, which is based on a Boolean AND operation. The authors show that the Hamming distances can be used to improve the performance of recommendations by reducing the runtime overhead of the distance computation. The proposed approach is evaluated on the NDCG and compared to other baselines. "
SP:80898d0f2b2c8dc3388fa9164e529eae36aa1b21,"This paper studies the problem of generating adversarial networks (GANs) for images with low-level perceptual quality. The authors propose a new evaluation metrics for image synthesis based on the mode collapse of the GAN’s learned distribution. The main contribution of the paper is a new toolset for evaluating GANs with mode collapse, which is based on statistical tools. The paper also proposes a new GAN learned distribution that can be used to estimate the model parameters."
SP:e5b5dda2f024cfda10526e744aa035e0165af58a,"This paper studies the problem of over-parametrized neural networks and linearized models trained with Neural Tangent Kernels (NTKs) under the NTK theory. The authors consider the quadratic case, where the number of parameters of the network is bounded by the Taylor expansion of the neural network, and the dimension factor of the dimension of the model is unknown. They show that under mild distributional assumptions, the optimization landscape of randomized two-layer networks trained with escaping-saddle algorithms can be approximated by a Taylor expansion on the network. They also show that it can be used to train networks with higher-order terms in the Taylor series, and that it is possible to use a randomization technique to improve the sample complexity bounds. "
SP:cef7ea513eb3e42be4edf40e4ee1701a969bcbea,"This paper proposes a new graph filter design for graph convolutional filters. The authors propose a new loss term, called Adaptive Filter Graph Neural Network (AFGNN), which is based on the Graph Filter Discriminant Score (GFD). The authors show that AFGNN is able to learn the optimal filter for each node in a graph. They also show that the proposed model can learn the data-specific filters for different graphs. The proposed model is evaluated on both synthetic and real-world benchmark datasets."
SP:3c5ec9dbcf914c8901e4e35f3c2a7df4707422ab,"This paper studies the problem of group DRO for overparameterized neural networks on the i.i.d. test set. Distributionally robust optimization (DRO) is a popular method for training models with spurious correlations. The authors show that the average training loss of a model with a vanishing worst-case training loss is the best-case worst-group generalization under the overparametersized regime. They then propose a stochastic optimization algorithm to improve the performance of the group DROs by regularizing the worst-groups by early stopping. They show that this regularization improves the performance on the natural language inference task and the image tasks. They also show that it improves the average generalization of the best group accuracies. Finally, they provide convergence guarantees for the stochastically optimization algorithm."
SP:eb1ee2e0f7d8466a04b58508ecb3da7b667eecdf,"This paper studies the problem of local explanation methods for the decision of black-box classifiers. The authors propose a new classification loss based on ad hoc constraints on the relevance scores of the mask predictor. The proposed method uses a neural network to predict the distribution of relevance scores, and then uses it to train the neural network. The paper shows that the proposed method has better faithfulness and explainability than others. "
SP:32ea7cbc47cbdb1f703f4e07c31ce90abe083424,"This paper proposes a new deep network for image reconstruction and classification problems. The task-specific network, called auto-encoder or classifier, is a domain specific network with patches. It is a non-differentiable top-K selection process where the top-k selection process is based on a slack variable. The authors show that the proposed method is able to identify recurring structures in the training optimization problem. They also show that it performs better than state-of-the-art in terms of detection of multiple object instances. "
SP:da1c5f6351d531482e90b86c3cceb52850c520de,"This paper proposes AutoAssemblet, a neural program synthesis algorithm based on self-learning reinforcement learning for large code space. The authors propose a multi-entropy policy sampling technique to improve the online update correlations between different tasks. The synthesis is based on a combination of Policy networks and value networks for Monte Carlo Tree Search, which is a popular technique for task generating instructions. Experimental results show that AutoAsemblet achieves better success rates than other baselines on a variety of basic programming tasks."
SP:0d4687fc36c02e27d1b95d532a3947589f92b1da,"This paper studies the problem of gradient descent optimization in a neural network architecture design space. The authors propose a new model architecture based on the ODE’s coefficient matrix H, which is a first-order ODE for gradient descent. They show that the speed of training and the accuracy of the proposed model architecture are important factors in the convergence rate. They also provide an analysis technique for model architecture modifications. "
SP:3e3bc8f617df742a395e7d315ec3810a42071294,"This paper studies the problem of initialization for overparametrized neural networks (NNs) and kernel methods. The authors propose a new initialization scheme based on gradient descent. The main idea is to use the minimum complexity solution of an interpolating kernel method with a squared loss to initialize fully-connected wide ReLU-NNs. They show that the initialization variance of wide NNs with the squared loss is bounded by the test error of the first, and the second. They also provide generalization bounds for the initialization scheme. "
SP:b15ea009a36a0a76728dfc103d668d6781a8a99a,This paper proposes a pseudo-LiDAR framework based on stereo depth estimation using stereo images. The proposed approach is based on a combination of a stereo network architecture and a loss function to perform depth estimation of faraway objects. The depth estimates are then used to train a depthpropagation algorithm. The authors show that the proposed approach achieves better detection accuracy than standard depth estimation and stereo-based 3D object detection on KITTI object detection benchmark.
SP:983d84502264633f3385d426c1d4601a0744ea9a,"This paper proposes a new detection mechanism for the K class classification problem. The proposed method, GAT-Generative-Adversarial-Training (GAT-GAT), uses a generative model to generate adversarial examples for each K class. The authors show that the proposed method can be used to train a base detector on the unnormalized density model on classconditional data, which is then used as the base detector for the k-th detector. The paper also provides a theoretical analysis of the proposed GAT."
SP:461e9308d050bc3dc7b35233452668bb31f5d491,"This paper studies the problem of exploration in model-free reinforcement learning in sparse reward environments. The authors propose to use intrinsic rewards as intrinsic rewards to encourage exploration in exploration. They show that the intrinsic reward can be used to encourage the agent to explore in environments where extrinsic rewards are not available. They also show that their method can be applied to procedurally-generated tasks such as MiniGrid, where high-dimensional observations are available. "
SP:c002c20b5e8696588e029c0f65e88860418826c4,"This paper studies the large-scale query-document retrieval problem, where the goal is to retrieve documents from a large document corpus with sparse handcrafted features. The authors propose a retrieval algorithm with a score-based retrieval algorithm, which is based on a scoring phase, and a retrieval phase based on the score of the embedding-based Transformer model trained on pre-training tasks with cross-attention models. They show that Transformer models perform better than BM-25 and embedding models on paragraph-level pre-train tasks such as Inverse Cloze Task (ICT), Body First Selection (BFS) and Wiki Link Prediction (WLP). They also show that information Retrieval (IR) methods do not perform well in this problem. "
SP:4e161e08a624f87633dfb49dfd46bd1665e15189,"This paper proposes a graph convolution operator for graph neural network architectures. Graph neural networks are widely used in applications such as learning relational representations, point clouds, social graphs, molecular structures, and social graphs on irregular domains. Graph convolution operations and non-parameterized pooling or expansion layers are used to represent the representational hierarchy between the graphs. The authors propose a framework for multi-graph aggregation and show that the proposed framework is able to achieve better performance than the existing methods in terms of memory requirements for hierarchical networks. The proposed framework also shows that graph convion and pooling are more efficient than single parametric bipartite graph convualtion and single-graph convolution with parameterized transformation. Finally, the authors show that their framework can be applied to a variety of different architectures such as BiGraphNet, graph autoencoders, and graph skip connections. "
SP:9b9b6ee9014e5538442ba76d6059ed01f59ec8fb,"This paper proposes a new metric function for few-shot classification algorithms. The metric function is used to represent the feature embeddings of the image features. The feature-wise transformation layers are trained using affine transforms to learn the feature distributions. The learning-to-learn approach learns the hyper-parameters of the feature-wise transformation layers, which are then used to train the metric-based models. The authors demonstrate the effectiveness of the proposed methods in the domain generalization setting. "
SP:df46627cb984a56bba36d510bfc52e00751e9107,"This paper proposes a new approach for Lagrangian fluid simulation based on a convolutional network. The proposed approach is based on moving particles through a graph structure, where the moving particles are represented as moving particles in a continuous domain. The authors use N-D convolutions to represent the continuous domain, and the network architecture is then used to solve inverse problems. The results show that the proposed continuous convolutions perform better than prior formulations in terms of accuracy and speed. "
SP:3e17f333cf07183969c02bb66afdd3ccbf25bb19,"This paper proposes a new ensemble method called BatchEnsemble1, which is a variant of the Batch Ensemble1. The key idea is to use a Hadamard product to estimate the weight matrix of the ensemble, and then use the ensemble’s cost to compute the accuracy and predictive uncertainty of the single neural networks. Ensembles can be used for lifelong learning on sequential learning tasks, where the mini-batch is used to train the neural networks, and the ensemble is used as a benchmark to compare the performance of different ensembles. The authors show that Batchensemble performs better than BatchElements on out-of-distribution tasks, and is faster than progressive neural networks on CIFAR-10 CONJUNCTION and CifAR-100. The computational and memory costs are also improved. "
SP:a123a425ef3eb6188833d5a42e851bc3fa59df65,"This paper proposes a neural network-based partial differential equations solver for forward and inverse problems. The solver is mesh free and shape free, and can be used to solve any strong PDE solution with boundary conditions. The solution is obtained by using a trained neural network to solve the solution using an explicit smooth differentiable function in an analytical form. The authors show that the proposed algorithm can solve both forward and inverse problems with Robust boundary conditions constraints and regularizers. The proposed framework is well-motivated and easy to follow. The numerical methods such as finite differences, finite elements, and other numerical methods are well-studied, and the proposed method can be applied to free shape 2D second order systems such as Electrical Impedance Tomography (EIT) and diffusion and wave equations."
SP:973d0ad0faadcf7298300f2758de9154205e7113,"This paper studies the problem of explaining why BNNs are better than deep neural networks in deep learning. The authors propose Binarized Neural Networks (BNNs), a family of networks that can be used to generate explanations for Boolean logic. In particular, they are used to train logic-based reasoners, such as SAT solvers. These tools are useful tools for explanation generation and can be applied to both existential and probabilistic queries in a network. The proposed network is trained using a BNN architecture and a training procedure. The experimental results show that the proposed approach performs better than existing work for existential, probabilistically queries, and is more accurate than other methods. "
SP:ca985e758f195bd04fb9f24b290a83974d6d308b,"This paper studies the expressive power of graph neural networks with message-passing framework (GNNmp) in the presence of node attributes and layer expressiveness. The authors show that GNNmp can achieve lower bounds on the expressiveness of GNNs when the number of nodes in the graph is small. They then propose a technique to approximate the impossibility statements of these lower bounds. They show that this approximation can be used for a variety of tasks, including distributed computing. They also show that the lower bounds can be extended to graphs. "
SP:a98ae70a91850bbe624c307ba61d3daeb2494b82,"This paper proposes a new localised generative flows (LGF) model for target distributions with complicated topologies. The authors propose to use continuous bijections in flow-based density models to approximate the target distributions. The proposed LGFs are composed of stacked continuous mixtures of Bijections, where the bijection is a variational scheme, and the log likelihoods are a function of the number of samples. The paper shows that the proposed method is able to learn a good LGF model with fewer parameters compared to other flow -based methods. The experimental results on density estimation tasks show that LGFs perform better than normalising flows."
SP:3adc341dece170f428195e4dccadfb5f5daddf2d,This paper studies the problem of training neural agent models in the context of VLN. The authors propose to use environment re-splitting and feature replacement to perform diagnosis experiments using feature replacement in order to improve the performance of the agent. The agent model is trained using ResNet features to capture the low-level visual appearance of the semantic representations of the language and the navigational graph. These features are then used to train the agent using a baseline agent model and a training method. Experiments are conducted on two datasets: R4R and CVDN.
SP:298e0043e99f586d314fbd9d16fdc6ae885e1ebb,"This paper proposes a new DRL algorithm based on implicit human feedback for RL tasks where the agent’s learning is limited to RL tasks with expert labeling and demonstrations. The system is based on a system that learns implicit human interactions between state-action pairs in an Atari-type environment, where the human feedback is a mixture of expert and non-expert humans. The authors propose a new paradigm where the RL agent is trained to learn to predict the future state of the environment from the past state, and the system learns to learn the implicit human inputs of the agent. The paper also proposes an auxiliary reward function that can be used to guide the learning of the game. The error-related event potentials, which are an extension of the error-based feedback system in DRL, are learned by using the electroencephalogram (EEG) cap, and they are used to train the DRL algorithms.  The paper provides a definition for the game, and shows that the game can be learned using these two frameworks. They also provide some theoretical guarantees for the performance of the proposed DRL as well as a theoretical justification for the use of them.   Finally, the paper shows that their approach can be applied to a variety of complex environments (games) where the implicit humans feedback can be useful for the agent's learning. They show that the proposed approach performs well in both synthetic and real user experiments."
SP:a8395f8b877e1eebaef9ff2e8b4e488d55a74ef4,This paper studies the problem of laconic classification for diverse image classifiers. The authors propose two new reductions for classification: crop and colour reduction. The proposed reductions are based on complementary frameworks for learning the approximate minimal-entropy positive image from a classifier trained on the ILSVRC test-set. Theoretical results show that these two reductions are able to improve the performance of machine classifiers and reduce the texture bias of ILSVARC-trained models. 
SP:81cec8f907d8fa0653b5bc08af1f59bfefd49619,This paper studies the problem of perturbation defenses for Convolutional Neural Networks. The authors propose a new instability assumption for defense techniques based on the instability assumption in the decision space. They show that deterministic lossy compression algorithms and randomized perturbations are robust against perturbated adversarial examples. 
SP:a136b98e0ed478144ce9dd26e2b6d611543124e8,"This paper studies the problem of view prediction in 3D visual recognition. The authors propose a scalable self-supervised task for 3D object detection based on view prediction, where the goal is to predict the position of objects in a scene from a moving camera. The proposed task is based on Predictive coding theories, and the authors show that contrastive prediction losses are better than color regression loss. They also show that the proposed model is able to learn visual representations for unsupervised learning of 3D moving object detectors and semi-supervision learning of threeD object detectors. "
SP:6fd61604a2eeb8a2cbbda6c40807cebef6d40f2f,"This paper studies the problem of Unsupervised Domain Translation (UDT) in the context of Optimal Transport (OT) framework. The authors propose a model for UDT that can be applied to a variety of applications, including image captioning, natural language translation, and domain translation. The model is based on a dynamical formulation of OT and CycleGAN. The proposed model is able to perform well on the task of domain translation and achieves state-of-the-art theoretical guarantees. "
SP:8bb3ce11ad773685f6e41d90db3e7a5481e5ba47,"This paper proposes a new regularization method called RotationOut for neural networks, which is based on Dropout. Dropout replaces the neuron/channel in the neuron with a recurrent layer, and the convolutional layers are replaced with recurrent layers. The authors show that Rotation out outperforms Dropout on vision and language tasks. They also provide a noise analysis method for co-adaptation reduction using Dropout as well as Rotation Out. "
SP:37620ae8dc5683eb2843792e0aa4cbe6cba366f7,"This paper proposes a method to improve the performance of Universal Adversarial Perturbations (UAP) in CNN by using sequential optimization for adversarial perturbation. Dilate loss is a dilate loss for sequential optimization, which is a regularization of the Euclidean norm. The authors show that the proposed method has a better fooling rate than data-free work. They also show that their method is more robust to crafting adversaries than Data-free approaches. "
SP:2fd7d5507a8727db743dc89379a6f021d31ed39a,"This paper proposes a new transferable neural architecture search method, called T-NAS, which can be applied to both few-shot learning and supervised learning tasks. The main idea is to learn a meta-architecture for each task and then use the meta-learning to find the best architecture for the task. The proposed method is evaluated on a variety of tasks and compared to other NAS methods. The results show that the proposed method outperforms the state of the art."
SP:1314a79ba12474adb33ff31b3cb22bed25b94fb7,"This paper studies the problem of training Stochastic neural networks (SNNs) with label noise. The authors consider a variety of paradigms, including dropout, Bayesian neural networks, variational information bottleneck (VIB) and noise regularized learning. They show that SNNs are more robust than SE-SNN in terms of generalization, robustness, network compression, and adversarial defense against adversarial attack. They also show that pruning improves the performance of the network compression by a significant margin. "
SP:bd4935d4fcf33f60f22e0f2fd9f7dc8ddfab6d17,"This paper proposes a new inner loop for reinforcement learning based on the reward signal of an agent’s reward signal. The reward signal is learned by meta-learning, where the agent is trained to generate curious behavior by using curiosity mechanisms. The inner loop is trained by transferring neural network weights from the outer loop to the inner loop. The authors show that this approach can be applied to a variety of ML papers, and that it can be used to improve the performance of existing meta-RL methods.  The authors propose a rich language of programs, which is composed of neural networks with buffers, nearest-neighbor modules, and custom loss functions. They show that the proposed curiosity algorithms perform better than human-designed published curiosity algorithms, and are able to perform grid navigation, acrobot, and ant. "
SP:6dff0f3a84809ae0ba9f58f36303597f1ba6dcc5,This paper proposes a new approach for AnyC2C. The proposed approach is based on tree-structural language modeling (SLM) to generate a code snippet from a strict syntax of programming languages. The authors propose a neural model to predict conditional probabilities using AST paths. The model is evaluated on both Java and C# code and compared to seq2seq and other structured approaches. The results show that the proposed approach performs better than other structural techniques for generating expressions. 
SP:7fc60d6fd1cfcc135c34f9664d172d3fd1c0ae0a,"This paper studies gradient descent methods for non-convex optimization problems with large-scale neural networks (NN). The authors consider the case where the NN model space and canonical space are large NNs, and the objective functions for NNs are over-parameterized. The authors propose a pointwise linear transformation of the gradients, called the disparity matrix, which is a full-rank condition on the full rank of the gradient. They show that gradient decent algorithms are able to achieve a global minimum of zero loss under the singular disparity matrices. They also show that the learning of NNs is better than normal convex optimization."
SP:78a536138570fe9b5d88350e4b16d598a7db1fe0,"This paper studies the problem of deep learning based segmentation models on large-scale ground truth data sets. The authors propose interactive graph-based segmentation algorithms to improve the connectivity between nodes in the graph. The proposed algorithms are based on RGB, where the global optimum is defined by a discrete Potts model with an instanceaware heuristic. These algorithms are trained using feature maps generated by DCNN. They are then used for interactive annotation. The experimental results on PASCAL VOC 2012 and Cityscapes dataset demonstrate the effectiveness of the interactive approach on semantic (and panoptic) segmentation on the VOC validation set and mIoU. They also provide a weakly supervised learning framework. "
SP:2eb90879ddbc39b6b5c05152784d6044d1940513,"This paper proposes a new adversarial defense based on gradient-based saliency tools for adversarial examples. Adversarial perturbations are defined as the difference between the salient features of an image and the salient features of a CNN. The authors show that the learned saliency model can be used to improve the performance of the baseline by using the saliency map from the learned model as a baseline. The proposed defense is evaluated on MNIST, CIFAR-10, and ASSIRA and shows that the learnt saliency models can improve the computational cost of real-time defense. "
SP:fe5510d05ff091a5f133f2dbcd1b23d8d58d2c3e,"This paper studies the global adversarial robustness guarantees of machine learning models. The authors consider the problem of local robustness properties of local models, i.e., their measurability in the presence of adversarial attacks. They show that the global robustness of a model is determined by concentration inequalities, and that the concentration inequalities can be used to estimate the global perturbations of the model. They then propose two training methods for MNIST, Fashion-MNIST, and CIFAR, and show that these methods improve the robustness/accuracy trade-off of these neural networks architectures and training methods. They also show that their robustness and accuracy trade-offs can be improved by stochastic gradient descent and iterative pruning techniques. "
SP:8f5616a1480b68c04b496ed498d237d5a7e87794,"This paper studies the problem of robustness to perturbations in a system dynamics, i.e., the transition probability of the system dynamics. The authors propose a new robust learning algorithm, Wasserstein Robust, which is based on the risk-aware optimal Bellman equation. They show that the optimal policy can be obtained by minimizing the distance between the reference transition kernel and the transition kernel disturbance. They also provide a sensitivity analysis for the perturbation. The proposed algorithm is evaluated on the Cart-Pole environment."
SP:d85963f5f0f6b20cf08f2a7c169ae33a45db7de2,"This paper studies the problem of learning Nash equilibria in multi-player continuous games. The authors propose a new method for learning mixed strategy Nash equilibrium in multi -player games, where the goal is to find a Nash equilibrium that is close to the true Nash equilibrium. The main idea is to use a pushforward measure technique to learn a mixed strategy in continuous spaces, and then use a gradient descent algorithm to find the Nash equilibrium using the joint strategy profile and Nash equilibrium with the pure ones. The proposed method is evaluated on a variety of games, including quadratic games, blotto games, and GAMUT games, showing that the proposed method achieves better performance than previous works on Nash equilibrium, and is also able to achieve a stationary Nash equilibrium when the payoff functions have a convexity assumption."
SP:280d85cd8164a268f9d496ae5f17189c50f30dc1,"This paper studies the problem of training deep neural networks to perform NLP tasks on labeled data. The authors propose a novel Neural Execution Tree (NExT) framework1 for text classification, which uses NL explanations to generate executable logical forms from NL explanations. The NExT is based on a modularized model that learns the semantics of the NL explanation, and then uses them for augmenting model learning. The proposed method is evaluated on a variety of tasks, including relation extraction, sentiment analysis, and multi-hop question answering."
SP:a9b5f7257dedd719cfe341fca275776734af1d98,"This paper studies the robustness of machine learning models against misclassification in the context of Formal verification. The authors propose a verification procedure to verify whether a language model is robust to perturbations of the input features. The proposed method is based on a verified training method, and it can be applied to both recurrent neural network architectures and complex specifications such as the specifications for temporal properties and adversarial robustness. Experiments show that the proposed training method improves the performance of the models in terms of robustness and robustness to misclassifications."
SP:3903680e07b676409e3cf6a1044b67291fe38630,"This paper studies the problem of reinforcement learning in the context of visual domain randomization, where the goal is to learn a constant of the learned state representations. The authors propose a new method to solve this problem. The proposed technique is shown to achieve better generalization scores than the state-of-the-art in terms of the number of policies and the randomization parameters. "
SP:c79046dc56b9ee9c926f87386046422ea134ae8d,"This paper studies the problem of deep learning for Deep metric learning (DML). The authors consider the pairwise binary classification problem in DML, which is an important problem in computer vision. The authors propose a framework for training a model that is robust to imbalanced data pairs. The robust loss is based on distributionally robust optimization, where the uncertainty decision set of the dual variable is used to estimate the complexity of the complicated losses and hard example mining methods. The proposed method is evaluated on two benchmark data sets and shows that the proposed method performs better than the state of the art. "
SP:38420928e40ef80c0136ad607b9275f9ab1e0769,"This paper proposes a new trust region method based on inexact gradient and Hessian estimation for non-convex finite-sum minimization with a local minimum. The main idea is to use a stochastic trust region (STR) algorithm to compute the (, √)-approximate local minimum for (, \epsilon, \mu) under the assumption of differential estimations. The authors show that the convergence rate of the Hessian estimator is O(1/\sqrt{T})$ and that the runtime complexity of Hessian-free STR algorithms is O(\sqrt{\T})$. The authors also provide some theoretical guarantees for the algorithms. "
SP:28a35b70b5e6915af28cacebc4ea50690c9534af,This paper proposes a new method for training deep neural networks. The proposed method is based on a geometrically motivated method. The authors propose a linear programming for Farkas layers and a batch normalization and weight initialization. ReLU activation is used for residual networks. Experimental results on benchmark datasets show that the proposed network sizes are competitive with the state-of-the-art. 
SP:1d325b148e3efe407241c1f1cbe8d17400499741,"This paper studies the problem of computing robustness certificates for deep classifiers with differentiable activation functions. The authors propose a new robustness certificate based on the minimum distance between the decision boundary of the classifier and the adversarial examples. They show that it is computationally-efficient differentiable upper bound for a deep network with curvature of the Hessian of the eigenvalues of the network with l2 norm. They also provide a lower bound for the classification output. The regularization term for the network is derived from the curvature bound of the deep network, and it is a nonconvex optimization.  The authors show that the regularizer improves the certified accuracy of CRT and CROWN’s certificate, and that the proposed Curvature-based Robustness Certificate (CRC) outperforms adversarial training in terms of certified accuracy."
SP:33f6f5aa0d4655e5d75fe612e0eff05e579d45c5,This paper proposes a method for compressed sensing recovery from untrained deep generative models. The proposed method is based on Deep Image Prior (DIP) and uses convolutional weights in the network to learn the network weights. The learned regularization technique uses prior information in the learned network weights to reduce the reconstruction error. The authors show that the proposed method performs better than existing approaches on the fitting problem. They also provide a DIP optimization approach for overparameterized single-layer networks. 
SP:23c0f621e6041003b59bf0532130760694cf6a4a,"This paper studies the problem of temporal abstraction in reinforcement learning (RL) in the context of real-world problems with long time horizons. The authors propose a new HRL framework, TAIC, to solve the temporal abstraction problem with latent representations of action sequences. The proposed approach is based on information-theoretic constraints on the latent space and the pre-defined subgoals of the hierarchies, which are the hand-tuned network structure and the set of possible pre-specified sub-goals.  The authors show that the proposed technique achieves better convergence rate and sample efficiency than existing RL algorithms.  "
SP:4e54c9196ba1eb2b6a0b0eee41e4a6f3a9de72dd,"This paper studies the problem of graph convolutional network (GCN) for graph representation learning. The authors propose a new layer-wise sampling strategy for GCNs. The proposed method is based on the self-attention mechanism, and the authors show that the proposed method can achieve better performance than existing GCNs in terms of time complexity. "
SP:bb0af9c011ef982c34fcadb545f6b5771818e7fa,"This paper proposes STOVE, a state-space model for videos. It combines an image model and a dynamics model for inference. The model is able to learn a physical system that can be used for model-based control. The authors show that the performance of the proposed model outperforms unsupervised models and supervised baselines. "
SP:e67b463bc0aec2345925d609fa521ea49df57fd9,This paper studies the mode collapsing problem in the autoencoding model with variational autoencoders (VAE) and generative adversarial networks (GAN). The authors propose a new approach to train a VAE model with implicit likelihood (Gaussian and Laplace) and an adversarially trained discriminator. The authors show that the proposed model is able to achieve λ-Jeffreys divergence with respect to the model distribution. They also show that their model can achieve mode-seeking and mass-covering behaviour on CIFAR-10 and TinyImagent datasets.
SP:87056d0147ddcaf5d78f6888b05161fbdbb3346c,"This paper studies the problem of adversarial attacks on CNN classifiers trained with unreasonably linear extrapolation. The authors propose a Bayes-Optimal classifier for class distributions with geometry of high dimensions. They show that the optimal classifier with smooth decision surface is robust to attacks on the data distribution. They also show that it can be trained with large-margin methods. Finally, they show that adversarial examples can be used to improve the performance of the classifier. "
SP:a7b3a35e6a79084bdfd1e4a963dfa081279cd8bb,"This paper proposes Neural network pruning techniques to improve the top-1 accuracy of sparse and non-sparse models by pruning identified exemplars (PIEs) from the network. The main idea is to prune the abstract representations of the PIE images, which are then used for fine-grained classification. Theoretical results show that the top1 test set accuracy of the pruned images is better than the original image quality. The authors also show that sparsity can be reduced by the pruning. "
SP:4b17edaa7ec6201891433320d85f9a415656b763,"This paper studies the problem of text-based simulations such as Interactive Fiction games, where the goal is to learn a natural language that can be used as a dynamic knowledge graph to guide the action generation and action generation in combinatorially-large text-by-text-based action spaces. The authors propose KG-A2C1, which is a template-based approach to learn the action space size of a game state from a knowledge graph. They show that this approach can improve the performance of reinforcement learning agents for natural language understanding and partial observability. They also show that KG - A2C outperforms IF agents in a variety of IF games. "
SP:b1784ecbb8f36eef9cae33d61ce60d80c2f9c38d,"This paper studies the problem of maximum likelihood estimation (MLE) for sequence prediction problems such as language generation, text summarization, and detailed training prediction. The authors propose a data-dependent Gaussian prior for the Kullback-Leibler divergence term, which is a generalization of the MLE loss. They show that it can be used to reduce the negative diversity ignorance in MLE. They also show that the prior topological order of tokens can also be used as a prior topology. The proposed method is evaluated on a variety of language generation tasks such as supervised and unsupervised machine translation, textual summarization and image captioning."
SP:7c29cb5a32b14e1392408dc5daba4cd35848bea9,This paper proposes a new calibration approach called Temperature scaling for DNNs. The proposed approach uses a cross-entropy loss and a focal loss to calibrate the models. The authors show that the proposed approach improves the accuracy and calibration. 
SP:cd6b8417ec8bcb773c78cff677bb0a76d6b3f6f3,"This paper proposes a polynomial optimization framework called LiPopt, which is based on sparse connectivity in neural networks with Lipschitz constant. The authors show that sparse connectivity can reduce the complexity of computation by reducing the number of parameters in the network. They also show that the proposed approach can achieve better performance than baselines on a variety of optimization problems. They show that their approach achieves better performance on MNIST than networks with random weights and networks with networks trained with networks. "
SP:31c9dc0dd8806daddc9cb48c56ec819577fe46cd,"This paper proposes a self-supervised learning approach for video features. The proposed method uses sequences of real-valued feature vectors to learn representations from sequences of visual features and sequences of words. The BERT model is then used to learn text sequences from the sequences. The authors show that the proposed methods outperform existing methods on three tasks: video classification, captioning and segmentation. "
SP:0f24424d10f1201dd25e8c56354e10afc9b2b11c,This paper proposes a new framework for training machine learning models. The main idea is to use a public storage server to store the data from the inference phase of the model. The model is trained using a combination of selection masks and a neural network. The data transfer between the two models is done via the masks. The authors show that the proposed framework is able to achieve state-of-the-art performance.
SP:aa4fcf5b2cae05c5c6a903c24e4992b56655dee2,"This paper studies the problem of out-of-distribution (OOD) detection in deep neural networks for classification tasks. The authors propose a methodology for training a neural network to detect outof-disentropy (OOD), where the outlier exposure (OE) technique is applied to the loss function of the neural network. They show that the OE can be used as a loss function for OOD detection on both image and text classification tasks, and that it can be applied to novel class distributions as well. The proposed method is evaluated on the OOD detector task as well as on the Mahalanobis distance-based classifier."
SP:89bc528ef801182365ac279e8963803afccb391d,"This paper proposes a new end-to-end deep learning model for RNA secondary structure prediction, E2Efold. The authors propose an unrolled algorithm for constrained programming, where the RNA base-pair matrix is represented as a set of RNA molecules. The proposed unrolled algorithms can be used to train deep architectures to solve the constraints in deep architectures. Empirical results on several benchmark datasets show that it outperforms SOTA and other algorithms in terms of inference time, and is able to solve pseudoknotted structures."
SP:b68560cce8c64ebe0ca5e6534b3732c775d36452,"This paper studies the problem of learning a collective policy in a real-world environment. The authors propose a method to learn a policy that is robust to biases in a virtual simulation, where the agents’ simulations are trained with biased representations. They show that the proposed collective policies are more robust than individually trained policies. They also provide a theoretical analysis of the relationship between internal simulations and internal simulations."
SP:bd1dc08b4fd9a5cc78d26d7eb7f05dbb4a629ab1,"This paper proposes Generic responses HYPONYM, a new open-domain dialog generation model for semantic latent space. The proposed model learns to generate semantically related responses from a prompt. The model is trained on a one-to-one task, and then used to generate a generic response problem. The authors show that the proposed model achieves better coherence than existing baselines. "
SP:ef0d5fd333ed60feb3946d24002e9a90642aea66,"This paper proposes a new salient explanation method called Gaussian light and shadow (GLAS) that uses feature perturbation to improve the discriminative features in deep models. The authors show that GLAS can improve the coarseto-fine control by using scalability of Gaussian mask in GLAS, and it can be used to make life-affecting decisions in the fine-grained classification task.  The authors also show that the scalability improves the performance of GLAS in fine-gained classification dataset on the ImageNet Large Scale Visual Recognition Challenge.  "
SP:d17ca20cc527c28ab7358cb5b14954e5fb56409f,"This paper studies the problem of network deconvolution in the context of neural network training. The authors propose a new procedure for learning pixel-wise and channel-wise correlations between neural network models. The proposed procedure is based on convolutional kernels, which can be used to remove redundant data from the training data. The paper shows that the proposed method can achieve faster convergence than existing methods.  The authors also show that the resulting convolution layer has a lower computational cost compared to the original network.  "
SP:e1b0de9a36bf8359df368b7a55a7f23e99d88db7,"This paper studies the problem of generative adversarial neural networks (GANs). The authors propose a new quantization method, QGAN, for GANs based on CNN quantization methods for the extreme low bits of edge devices (e.g., smartphones). They show that the proposed quantization algorithm is able to achieve better quantization precision than existing GAN models. The authors also show that QGAN can achieve better 1-bit or 2-bit representations than existing models on CIFAR-10 and CelebA."
SP:58c4905f59f04a50b30d27c99521126a6455d38a,"This paper studies the problem of convex-concave min-max optimization in the bilinear and convex strongly concave settings, where the averageiterate convergence results are nonconvex. The authors propose a new algorithm, Simultaneous Gradient Descent/Ascent (SDA), which is a generalization of natural algorithms such as Simultaneously Optimized Descent and Ascent. The main contribution of SDA is that it is able to converge to the last iterate of the last-iterate converges in the convex setting. Theoretically, the authors show that SDA converges to the optimal solution of a convex problem under the “sufficient bilinearly” condition, which is an important condition for convex problems. Empirically, SDA achieves linear convergence in the case of the HAMILTONIAN GRADIENT DESCENT (HGD) algorithm. The convergence rates of stochastic HGD are also shown. "
SP:d8556b52272321a1415ac2d85bb12e88b51ee73a,"This paper studies the stability of ResNet with over-parameterization requirement. The authors show that the ResNet block hl has global minima with gradient descent. They also show that a normalization layer in deep ResNet is equivalent to a vanilla feedforward network. Finally, they show that global convergence can be achieved with respect to the forward process. "
SP:cf70dc496825ece2f28fdf4f1a6f4316c69e0e48,"This paper proposes a method for training sparse neural networks in the presence of dense networks. Sparse neural networks outperform dense networks in terms of accuracy in inference. The proposed method is based on floating-point operations (FLOPs) and uses the fixed parameter count and the fixed computational cost to improve the performance of dense-to-sparse training methods. The method uses parameter magnitudes and infrequent gradient calculations to learn the topology of the network, which is then used to train a trainable sparse model. Experiments on the WikiText-103 dataset show that the proposed approach achieves better accuracy than prior techniques. The experiments also show that RNNs and WideResNets outperform MobileNet v1 and WideRNNs on the ImageNet-2012 dataset and CIFAR-10 dataset. "
SP:d2d2b892518d54d0e63e26a056f2298be3be2610,"This paper proposes a generative process to learn the latent space of an image. The generative model is trained to generate a set of embeddings for each image, which are then used to train a GAN. The GANs are trained using a combination of GAN and variational auto-encoders. The proposed method is evaluated on both synthetic and real-world datasets."
SP:1c63389e972d4652fac831e9d11609cd3c3c371a,"This paper proposes a new model for unsupervised physical parameter estimation of systems from video. The model is based on differential equations for scene dynamics, where the labeled states are represented by objects and the state and velocity representations are learned by object state supervision. The proposed approach is able to perform long-term future frame prediction of systems with interacting objects. The framework is applied to vision-based model-predictive control, long term extrapolative video prediction, vision-actuated model-based control for pendulum system, and goal-driven control for physical reasoning. The authors show that the proposed approach can achieve better performance compared to existing state-of-the-art in terms of accuracy and interpretability compared to the state of the art in the physics-as-inverse-graphics approach. "
SP:c6b8b682bf3087a65cb2379700b8a0183853c2af,"This paper proposes a new classifier based on Graph Convolutional Networks (GCN) for class relevance. The proposed method is based on a weighted binary cross-entropy loss function for the binary classifier. The GCN-implicit “clean” probability is used as the relevance measure, and the graph per class is used to learn the structure of clean and noisy data. The method is evaluated on a few-shot learning problem, and shows that the proposed method achieves better classification accuracy than the standard transductive approach. "
SP:dd9c9a5dccbba5dd15b03ca6b314a9e153e95548,This paper studies the mutual information (MI) problem in Graph Neural Networks (GNNs). The authors propose a differentiable objective for MI that can be used to train a model with edge features and message passing channels. The objective is based on a variational approach to learn the MI of a GNN. The model is trained using MI-maximized models on a variety of learning tasks such as relation prediction in knowledge graphs and regression on molecular graphs. The representation vector is a parameterized transform matrix. The authors show that the proposed objective is able to capture the edge information of the model. 
SP:f1cf63d728da51b4f83eb50ef69e3788b3a5ed74,"This paper studies the certification of generative models. Generative networks are models that can be used for specifying visual transformations. The authors propose two verification methods to certify the generative networks. The first verifier, APPROXLINE, is a deterministic and probabilistic abstract interpretation of the network’s latent space. The second verifier is a sufficient non-convexity."
SP:2b0887dcf09249e8cee30d38163aeb9ef1e92b27,"This paper proposes a spectral graph convolutional operator for graph neural networks (GNNs). GNNs are used to solve the suspended animation problem, where the model depth is bounded by a suspended animation limit. The authors propose a new GRESNET (Graph Residual Network) framework to learn connected highways between nodes and intermediate representations in a graph, which are then used to train the model layers. The graph residual terms are learned from a norm preservation perspective, and the model is trained using residual learning methods. Experiments are conducted on graph data, and real-world benchmark datasets. "
SP:dc436ade4d04072de35a90e5e4a1bfebfddb04e9,"This paper proposes a novel reconstruction process based on face prior knowledge from limited scan data. The authors propose to use linear 3D morphable models (3DMM) to learn face pre-trained on limited scan images. The proposed method is based on convolutional neural networks (CNN) and uses a nonlinear parametric model trained on hybrid batches of unlabeled and labeled face images from unconstrained photo collections. The model is trained in a semi-supervised manner with an adversarial loss in the form of a center loss. The dataset is used to train the models and the identity and expression representations of the models. The models are evaluated on a variety of facial images (identity, pose, lightings, and expressions). The results show that the proposed model is able to learn the identity, the pose, and the lighting representations of a given facial image, and can transfer the model to facial editing applications such as expression transfer. "
SP:f7bc06697b09e2d59ec06b2cbcf3c0828ece32ae,"This paper proposes a new transition kernel for Model-based imitation learning methods. The transition kernel is based on partial knowledge of the state components of an unknown transition kernel. The authors use Reinforcement Learning (RL) to solve imitation problems in multiplayer games, where the goal is to learn a policy evaluation. The key idea of the transition model is that the transition kernel can be used to learn the transition of state components. The paper shows that the policy gradient algorithm and the model trained with the proposed transition model outperform a simulation-free alternative. "
SP:82cce92821e8168ab4a6fd67573b66c1d17673b8,"This paper proposes a selfsupervised Reinforcement Learning approach to learn useful skills using a manually-designed reward function for reinforcement learning. The proposed method is based on intrinsic mutual information rewards, where the external reward function is the intrinsic objective and the goal is to maximize the mutual information between the agent and the environment. The authors demonstrate the effectiveness of the proposed approach on simulated robotic manipulation tasks such as OpenAI Gym and a navigation task on the Gazebo simulator. They also show that learning with a pre-trained policy and a mutual information discriminator can improve the performance of learning for task rewards. "
SP:5db63d39cfd8132bec832ab64b8fbd403b3b8df0,"This paper proposes a new attack against neural network (NN) trojaning attacks. The attack is based on the idea that the weight parameters of NN models can be misclassified as fixed target classes. The authors show that it can be used to improve the malicious functionality of the NN trojaned attacks on small datasets, and that it is more robust than adversarial attacks on large models. They also show that the trojaned model trained on a large-scale dataset has biased behavior towards the target class. They show that this can be achieved by using a trojan attack on a small domain, and then using the trojans attack on the large domain. Finally, they show that their trojanking attack method can improve the performance of large models in terms of capability and stealthiness. "
SP:35ea626ee4dd1a7a368a660eb852192924966b7f,"This paper studies few-shot regression (FSR) problems in the context of drug 1 discovery, where the goal is to find a drug that can be used for drug discovery. The authors propose a new FSR 6 algorithm based on deep kernel learning and a differentiable kernel 8 algorithm. The proposed algorithm is able to learn a kernel for each task, which is then used for inference. It is shown to outperform state-of-the-art algorithms on a variety of real-world benchmarks. "
SP:91ca4c3ee07617356250bae9f4ef9799b3b134ff,"This paper proposes a new framework for reasoning tasks using Graph Neural Networks (GNNs) for tasks where the network structure is different from the original network structure. The authors show that GNNs have expressive power, and that they can be used to learn tasks with different network structures. They also provide a sample complexity bound for the alignment between the network and the original neural network. Finally, the authors propose a new algorithmic paradigm called dynamic programming (DP) that can be applied to reasoning tasks such as visual question answering, shortest paths, and intuitive physics. The experimental results show that DP is able to achieve better performance than the state-of-the-art on these reasoning tasks. "
SP:a52aee8da5cf5acd2baf3c2a62cb679e13b18bd5,"This paper studies the problem of model benchmarking in Conditional Generative Adversarial Networks (cGANs). The authors propose a new metric called Fréchet Joint Distance (FJD) to measure the distance between the joint distributions of a pair of cGAN-based models. The authors show that FJD is a better metric than existing metrics for measuring the properties of models, such as image quality, conditional consistency, intra-conditioning diversity, and object masks. They also show that the FJD can be used for model selection, cGAN benchmarking, and model selection on a controllable synthetic dataset. "
SP:fa822e8472efae17c7dfde8258057898383ecbbb,This paper proposes a VIC framework for exploration in partially observable environments. The goal is to identify decision states for exploration on downstream goal-driven tasks that are partially observable. The empowerment objective is based on the notion of extrinsic rewards. The authors show that the identification of decision states leads to better exploration. 
SP:a19a51df7e28a5d3380be4fba13842efbfe3efec,This paper proposes a new architecture for irregularly-sampled and asynchronous time series on real-world datasets such as healthcare applications. The framework is based on unaligned measurements for classifying irregularly sampled time series. The authors show that the proposed method can achieve better data efficiency than competitors on healthcare time series datasets. The proposed method is also able to learn deep neural networks with differentiable set function learning. Experiments are conducted on online monitoring scenarios.
SP:4ae89d64460b08749acc192004545c1fa8b7553b,"This paper studies the inductive bias of convolutional neural networks (CNNs) for image recognition. The authors show that deep networks have inductive biases for natural image priors, and that they can also be used for audio signals. The main contribution of the paper is to show that they are able to perform supervised musical source separation with Harmonic Convolution, and they can be used in unsupervised audio restoration.    The authors also show that the local neighborhoods can be learned by convolutionally kernels with harmonic series, which is an interesting observation. "
SP:c81a2b3fd1c56b9b18e4a358e3ff8b40aea5256a,"This paper studies the problem of data echoing in deep neural networks. The authors propose a new training pipeline, called ResNet-50, which uses a combination of GPUs and specialized hardware accelerators for neural network training. They show that the proposed data echoing algorithm performs better than the baseline on a variety of workloads, including disk I/O, data preprocessing, and data streaming. They also provide a theoretical analysis of the performance of the proposed training pipeline."
SP:b4cf56d3fa7d65cacde33f17cd04bd5bbc52dd71,"This paper studies the problem of generalization in a Markov decision process with controllable subspace, where the goal is to learn a policy that performs better than other policies. Successor features are used to solve the generalization problem in the grounded feature space of the reward function. The authors propose a new algorithm called Variational Intrinsic Successor FeatuRes (VISR) for task inference based on the successor features framework. The proposed method is evaluated on the Atari suite and achieves state-of-the-art human-level performance. "
SP:83500230586a9134f910ad067b7233dc563dc1ba,This paper proposes a new functional view of deep neural networks. The authors show that the smoothness of the functional approximation and flat initial approximation can be used to improve generalization. They also show that these two initializations can be combined to improve the generalization performance of the network. The paper also shows that the functional view can be applied to massively overparameterized networks.
SP:7225825e353b711a7d023f706fafe5e17e4e2fb2,"This paper studies the problem of image-to-image translation in a supervised and unsupervised manner. The authors propose a generative Adversarial Network (GAN) to solve the problem. The proposed approach is based on the notion of imbalance problem in GAN-based methods, which is the imbalance between mode collapse and diminished gradients. The generator and discriminator are trained with relative model capacities, and the generator is trained with an attention mechanism that learns the attention map of the generator and the discriminator. Experiments on image transfer tasks demonstrate the effectiveness of the proposed GuideGAN framework."
SP:41c089ba65393174dae1dc136f79030a0a4fc532,"This paper studies the problem of inductive bias in neural networks. The authors propose a multiplicative interaction for neural network architectural motifs such as gating, attention layers, hypernetworks, and dynamic convolutions. Multiplicative interaction layers are primitive operations in neural network architectures, and the authors propose to use them to learn multiplicative interactions between layers. They also propose a conditional computation for the concatenation operation."
SP:5144391584e6d3825e12684b7c053e4e282cff2b,"This paper proposes a new algorithm for batch active learning using deep neural network models. The proposed algorithm, Diverse Gradient Embeddings (BADGE), combines predictive uncertainty and sample diversity to improve the performance of Batch Active learning. The authors show that BADGE improves the performance in terms of uncertainty and diversity in the hallucinated gradient space, and it can be applied to real world active learning problems with different batch sizes. "
SP:ce6023b1e6bf45b071a6f5457b2575425ae03366,"This paper studies the problem of self-explaining models for decision making parameters. The authors propose a new architecture, called General Linear Models (GLMs), which uses a feature leveling architecture to extract low level features and high level features from the hidden layer of a GLM layer in a deep neural networks (DNNs). The main idea is to use a per-layer basis to learn the high-level features and the low-level ones from the GLM layers. The main contribution of the paper is to show that the non-linearity of activation functions in activation functions can be used to explain the model reasoning process. The paper also shows that the performance of the proposed models is comparable to main-stream architectures."
SP:b70ceead1bf6c7dc684c74501716e7012b891022,"This paper studies the gradient cost of softmax regression with uniform negative sampling. The authors propose a training method to estimate the gradient signal from the data distribution using an adversarial model. The training method uses negative samples from the adversarial sampling mechanism to reduce the gradient variance of the classifier. The bias is reduced by using non-uniform sampling, and the authors show that the gradient updates are competitive in terms of training time on large scale data sets. "
SP:29b52fee83309268d9864f3b1fc3617948577d41,This paper proposes a novel approach for efficient exploration in lowdimensional encoding of the environment using modelbased and model-free objectives. The novelty of the proposed approach is based on the weighted distance of nearest neighbors in the low dimensional representational space. The intrinsic rewards of the intrinsic rewards are used to encourage novelty and to encourage the exploration to be more efficient. The proposed approach uses intrinsic rewards to guide the planning routines in the representation space of planning routines. The experimental results on maze tasks and a control problem show that the proposed exploration approach performs better than baselines. 
SP:257c98dc1a9f3efcbf9544d9ee2ff524b000543d,"This paper proposes a new learning model for few-shot classification. The main idea is to use it to learn out-of-distribution inputs, and then use it as a proxy for the true distribution of the data. The authors show that the proposed methods are able to perform well on a variety of tasks in the few-shooting setting, including few-shots classification, out- of-distributions detection, and out of distribution detection in the many-shot setting. They also show that their methods can be used to improve the performance of the task on a number of benchmark datasets. "
SP:a3632b773143dfb3a8f104c6b658dfa1167d155b,"This paper proposes a framework for training undirected neural sequence models, such as BERT, BERT+ and BERT+, for discriminative natural language understanding tasks such as question-answer and natural language inference. The authors propose to use monotonic generation to train directed sequence models with a cross-lingual masked translation model, and then use these models for generating sequences. They show that the proposed framework can be used for generation and decoding in both directed and undirecting models, and that the decoding in the generalized model of sequence generation can be combined with the decoding strategies in the autoregressive model. They also show that their approach is able to achieve better performance than linear-time translation, and can also perform better than the existing approach for constant-times translation. "
SP:eca5e2be9831dfb79c4f5e633cbfadcfd2e00eb1,This paper proposes a two-stage approach for LaTeX sequence recognition from a printed mathematical expression image. The method uses an object detection algorithm to learn the math symbols from position information. The seq2seq model is then used to generate LaTeX sequences using an attention mechanism. The model is evaluated on ExpRate(expression recognition rate) against an end-to-end method.
SP:923fee8623da1569a7f54a57b4b326f29440b4c0,"This paper proposes a vector quantization method based on the ResNet-50 model. The proposed method uses bytealigned codebooks for compressed weights, and it uses unlabelled data to reduce the loss reconstruction error of in-domain inputs. The authors show that the proposed method improves the performance of inference using the CPU in terms of top-1 accuracy. The compression factor is also used to improve the memory footprint of convolutional network architectures. "
SP:74850ad70241948f93fed95ba1f0ac11360437c1,"This paper proposes a new attention mechanism, TP-Attention, which uses Tensor-Product Representations in the Transformer to generate an explicit representation of relation structure. The model is based on the TP-Transformer’s attention maps, and it is shown that the attention can be used to capture ambiguities in the representation-building. The paper also shows that the TensorProduct Transformer (TP-T) can be applied to free-form math wordproblems in the Mathematics Dataset. Pretrained models are also shown to be able to learn representations that are more interpretable."
SP:d319df820c6630c409fab32097652a083e8f53ea,"This paper studies the problem of generalization of Deep artificial neural networks with identically distributed training and test sets. The authors propose a procedure to learn the source code from the empirical sample set with real-world input samples. The learning algorithm is based on the Kolmogorov complexity of the universal cognitive similarity metric, the information distance between the channel codes. The optimization problem is formulated as a classification function with a condition on the features of the classifier. The model is trained with corrupted or perturbed input features and adversarial perturbations such as Gaussian and shot noise. The proposed model is able to recover the corrupted input features, and the model can also recover the corruptions with projected gradient descent. "
SP:b8e86f5e89330d81ba4967a7ed2dbfb56375d8a0,"This paper proposes a new graph pooling operation called HaarPooling, which is based on compressive Haar transforms to improve the performance of GNNs on graph classification and graph-based regression tasks. The key idea is to use the sparsity of the Haar basis for the pooling layer, and to use sequential clusterings for the clustering. The authors show that the resulting GNN achieves better performance on diverse graph classification problems than the state-of-the-art GNN. "
SP:17bea301d6718ef5f28864dd2445552b3cf65eeb,"This paper studies the problem of learning the shape representations of 3D objects from point clouds. The authors propose to use encoder networks to learn the semantics of their input point clouds, and then use fully-connected networks to generate shape representations using sample-based point-cloud decoders. The key idea is that the point feature distribution of the input point cloud is sampled from the sampled features, and that the precision of the decoder architectures can be improved by using these sampled features.  The authors show that the shape representation learned by sample- based point-Cloud decoder can be used to learn a better shape representation than the one learned by feedforward architectures. "
SP:51d826ead5d1d9cb89d493ce4c39728651bbc57b,"This paper studies the problem of controlling synthetic noise in deep learning. The authors propose a new benchmark of realworld noisy labels, where the noise levels of the networks are controlled. They show that Deep Neural Networks (DNNs) can be used to learn real-world noise in the presence of controlled noise levels. Robust learning methods are also used to train synthetic noise.  The authors also show that robust DNN methods can be trained on noisy data. "
SP:9873f78fb2821afdbb5551700e6ab6a0e8bcb9f0,This paper proposes a rule-exemplar method for collecting human supervision for labeled data. The training algorithm is based on a soft implication loss with coverage and label variables. The model is trained with latent coverage variables and denoised rules. The proposed algorithm is shown to outperform existing methods on a variety of tasks. The authors also show that the proposed algorithm can be combined with clean and noisy supervision.
SP:6f2c656dbb7629f652a4291d6971625184d8118b,"Graph neural networks (GNNs) are a class of deep models. GNNs are trained with a memory layer to learn node representations from graphs. The authors propose two networks, a memory-based GNN (MemGNN) and a graph memory network (GMN) to learn hierarchical graph representations. The paper shows that the proposed layer improves the performance of these networks on graph classification and regression benchmarks. The representations are based on chemical features in molecule data."
SP:81bc52d734c86975d741b6482d65ca71a9d81620,"This paper studies the problem of initialization in deep learning systems. The authors propose a new initialization scheme, called orthogonal group initialization, which is based on the notion of orthogonality. The main idea is to learn a set of initial parameter values for gradient-based optimization for deep neural networks, which are then used to compute the convergence times of the model. The paper shows that the orthogonic group initialization can achieve better convergence than Gaussian initialization with iid weights, and that the global minimum of the global optimum is also better than the optimal global minimum. In addition, the authors also show that the resulting initialization can be used for learning deep non-linear networks with dynamical isometry. "
SP:9f5d95fc89c2f0d59d04838aa180f3db67997dfa,"This paper studies the problem of high rate compression with 2-bit quantization in deep neural networks. The authors propose a joint framework to solve the optimal bit allocation problem with Lagrangian Formulation, which is a well-studied optimization problem in deep CNNs. The main contribution of the paper is to show that the additivity property of deep neural network has a significant impact on the accuracy of the output error. The paper also provides a theoretical analysis of the effect of coarse quantization on the performance of the layers. "
SP:7191d7b217a12b1bf9c47d790896a8227c14cc3d,"This paper proposes a new metric for measuring the convergence of a Wasserstein GAN (WGAN) model. The authors propose a new framework for measuring WGANs, iWGAN, which is a combination of auto-encoders with a generative network and an iterative primal dual optimization process. The paper shows that the proposed model achieves better generalization error bound than autoencoder GANs in terms of maximum likelihood estimation. The model also achieves better performance on the measurement of quality check. "
SP:cca6ae14fd0dd12352855e594acf7f3263bb1f24,"This paper studies the problem of anaphoric annotation in the context of crowdsourcing, where the goal is to train a model that can be used for both coreference and NLP tasks. Crowdsourcing is an important problem in the community, as it can be difficult to train models that are robust to sparsity in crowdsourcing environments due to the MPA. In this paper, the authors propose a new model that uses a stick breaking process to learn a nonparametric partially pooled structure. The proposed model is evaluated on a large-scale crowdsourced anaphora dataset. The authors show that the proposed model outperforms the state-of-the-art on a variety of annotation tasks for classification and expert annotation."
SP:4295cae4a56a02eb21c486408c1bf37a7483cb49,"This paper studies the problem of exploration in sparse reward reinforcement learning with intrinsic motivation in sparse extrinsic reward signal. The intrinsic reward is a successor feature control (SFC) which is a combination of intrinsic reward and bonus rewards. It is a mixture policy where the intrinsic rewards are learned from local information and the bonus rewards are learnt from the intrinsic drives. It uses statistics over complete trajectories to learn the intrinsic motivation and stabilize learning. It outperforms other methods that use local information to learn intrinsic motivation. The exploration efficiency of SFC is evaluated in three environments: DeepMind Lab, VizDoom and DeepMind Control Suite."
SP:9fa22eb03a79bce0fc1c8e84ae8640e010701eca,"This paper proposes a method for weakly-supervised video moment retrieval. The authors propose a multi-level co-attention mechanism to learn multimodal representations from video-sentence pairs. The proposed mechanism consists of a Frame-By-Word interaction module, Word-Conditioned Visual Graph (WCVG) and a Word-Conditional Visual Graph. The key idea is to learn the latent correspondence between visual and language representations. Transformers are learned using positional encodings for Transformers. The approach is based on iterative message-passing to learn visual-semantic representations. The representations are evaluated on DiDeMo and Charades-STA datasets on the Recall@1 accuracy metric. "
SP:27ac670353f34ee7a23bb7622f80c1dfbc0985e0,"This paper proposes a method to learn a 3D proxy geometry from video. The proxy geometry is learned from video by using a multi-view stereo, where each view is represented as a video. This proxy geometry can then be used to train a deep neural network to predict the view-dependent effects (e.g., specular highlights) on the diffuse surfaces of the video, which are then used for warping. The paper shows that the proposed method is able to achieve state-of-the-art performance on both synthetic and real-world datasets. "
SP:257d124367b1da9a595dc11a9df750d6bade298e,"This paper proposes a sparse representation of model uncertainty for deep neural networks (DNNs) based on diagonal correction of the Kronecker-factored eigenbasis in a scalable Laplace Approximation scheme. This operation is used for full Bayesian analysis. The authors show that spectral sparsity of DNNs with low-rank approximation can be reduced by using low-ranks approximation to the eigenbais of the information matrix. They also show that sparsification can be used for memory-wise tractable sampling computations. Finally, they show that their approach is more efficient than existing methods."
SP:2e03ceba4004b82f86f8349352a8ee4520e9c35d,"This paper studies the problem of false similarity computation in high-dimensional data. The authors propose Minwise Hashing (MinHash) to learn set similarities between two sets of set similarities and compact high-dense data for learning and searching. MinHash uses a permutation (hash function) to compute MinHash values for each pair of sets, and then uses Permutation Hashing to compute the MinHash value for each set. They show that AHash is more efficient than OPH and other densification strategies for densification. They also provide a remedial strategy called densification, which is a variant of Amortization Hashing for empty bins. "
SP:d73827ab98b0ff6bd92abfefea43a5f88ea40de2,"This paper proposes a new method for feature extraction for periodic signals. The proposed methods are based on a multi-layer perceptron, which is a combination of rotating shafts in a robotic system and a mechanized transportation vehicle. The key idea is to use a robust method to extract features from phase shift data using cyclic permutation on the graph data. The authors show that the proposed method is able to recover the periodicity of the shaft’s rotation and the phase shifts. "
SP:0df5ad333eb4ff9cca7f2d117909e2ce533a65d8,"This paper studies the problem of controlling the controllability of Neural conditional text generation systems. The authors propose a new calibration technique for faithful generation, which is based on the variational Bayes objective. The calibration technique is used to reduce the inference time and improve the precision of real world systems. They show that the proposed approach outperforms state-of-the-art approaches on a structured data-to-text dataset, WikiBio, and human evaluation. "
SP:03307deac29173b2968fbd08f95fc77eb1f82410,"This paper proposes a new pruning method called lookahead pruning, which is based on the notion of Frobenius distortion in the linear operator of a linear operator with a single layer. The authors show that the proposed method is able to achieve better performance than magnitude-based pruning for pruning modern architectures. The main contribution of the paper is that it uses single layer optimization for multi-layer optimization instead of multi-layered pruning. The paper also provides a theoretical analysis of the performance of the method on a variety of networks including VGG and ResNet."
SP:dc80fdc75bc14ae19fe4ba9b85c35ce00b12856f,"This paper proposes Decentralized stochastic gradient descent (SGD), a technique for decentralized SGD with quantized communication between parallel workers in a graph. The authors show that the proposed algorithm has an asymptotic rate of $O(\sqrt{T})$ with full-precision communication, which is much faster than Moniqua with 4-bits-per-parameter communication. The paper also shows that the algorithm has a better wall clock time than the existing quantized decentralized algorithms with bit-budget. "
SP:86c61a658d07ab86e2d84cef7e480bf7a06e4ddb,"This paper studies the problem of jointly modeling future observations in the context of reinforcement learning. The authors propose a new approach to this problem, where the goal is to learn a partial model that can be used to predict future observations from the current state of the art. The main idea is to use the partial model as a surrogate for the full model. The partial model is then used to train a full model that predicts future observations. The proposed approach is evaluated on a variety of datasets, and the results show that the proposed approach outperforms the baselines."
SP:c70479b2096a52584b242de58272ca8d8565feea,"This paper proposes a new variational autoencoder (VAE) model for conditional and joint generation tasks that uses a succinct common representation of two correlated data variables. The model is based on the Wyner VAE, which combines a common representation (the shared concept) with local representations (e.g., the common representation in the shared concept). The common representation is then used as a regularization term to ensure that the shared information between the two variables is not lost. The paper shows that the proposed model outperforms VAE variants as well as a variational information bottleneck method in both joint and conditional generation.  The paper also provides a theoretical analysis of the performance of the model on a variety of information theoretic problems such as distributed simulation and channel synthesis. "
