paper_id,summary
SP:b19df5243359791fbaad005d6f13d7e9fdb0ff63,This paper proposes a hierarchical learning framework for role - based multi - agent multi - task decomposition. The key idea is to first decompose joint action spaces into restricted role action spaces by clustering actions according to their effects on the environment and other agents. The proposed method is evaluated on the StarCraft II micromanagement benchmark. The paper shows that the proposed method outperforms the current state - of - the - art MARL algorithms on 9 out of the 14 scenarios that comprise the challenging StarCraft II benchmark and achieves rapid transfer to new environments.
SP:7deb61890d97422a0fe141ca807f968c70ab239a,"This paper studies the behavior of the stochastic subgradient descent ( SSGD ) method applied to overparameterized nonsmooth optimization problems that satisfy an interpolation condition. By leveraging the composite structure of the empirical risk minimization problems, the authors prove that SSGD converges, respectively, with rates O(1/ ) and O(log(1 / ) ) for convex and strongly - convex objectives when interpolation holds. These rates coincide with established rates for SGD methods applied to smooth problems. The analysis provides a partial explanation for the empirical observation that sometimes SGD and SSGD behave similarly for training smooth and nonsmoot machine learning models."
SP:c7e0b3fedc0d0409d662dd612b529fdacad2b03e,"This paper proposes to use non - linear "" reservoir "" layers to improve the performance of transformer - based neural networks. In particular, the authors introduce a new metric AUCC to measure the performance - efficiency trade - off between transformer and reservoir layers. The authors also propose to skip the backward pass by approximating top - layer gradients using an approach they call backskipping, with a relatively small sacrifice in performance. Experimental results show that the proposed method outperforms the state - of - the - art transformer architectures without updating all the layers."
SP:ba9f1d4738ec67a440346f3ac6c4cf35f7232077,"This paper studies the connection between the recent steerable CNN structure based on group representation theory and the conventional transformed filters. To this end, the authors propose a new approach ( FILTRA ) to use filter transform to establish steerability between features in different group representation in cyclic group CN and dihedral group DN. The authors show that filter transformed kernels can be used to convolve input / output features in the different group representations and provide a novel and simple approach to implement steerable convolution operators. Experiments are executed on multiple datasets to verify the feasibility of the proposed approach."
SP:c1116fbb4d058eb6be195b5d13d19a55ba86b602,"This paper proposes an optimal neural synthesis approach for multi - modal program synthesis, where the goal is to find a program that satisfies user - provided constraints while maximizing the program ’s score with respect to a neural model. Specifically, they focus on multimodal synthesis tasks in which the user intent is expressed using combination of natural language ( NL ) and input - output examples. At the core of their method is a top - down recurrent neural model that places distributions over abstract syntax trees conditioned on the NL input. This model not only allows for efficient search over the space of syntactically valid programs, but it also allows us to leverage automated program analysis techniques for pruning the search space based on infeasibility of partial programs. The experimental results on the STRUCTUREDREGEX dataset show that their method substantially outperforms prior state - of - the - art techniques in terms of accuracy and explores fewer states during search."
SP:55e02d79146bbb42f1ab6d4fafa2db5ddbe599b0,This paper presents a protein graph convolutional neural network ( PGCN ) that uses Rosetta energy function to predict the topology and energetic features of the interaction between protease and substrate in order to determine the substrate specificity landscape of a protease enzyme. The proposed method is applied to the prediction of the specificity of the NS3/4 protease from Hepatitic C virus. The method is based on the structure - based molecular interaction graph generated by Rosetta and the energy function. The authors compare the performance of the proposed method with other machine learning models and show that its performance in classification tasks is equivalent or better than the other methods.
SP:7727eeb7b17ad94ddfa0cf24e64a9626d83a8876,"This paper focuses on the underestimation bias in double Q - learning. The authors show that under the perturbation of approximation error, double - Q learning may have multiple non - optimal fixed points. To address this issue, the authors propose a doubly - bounded estimator that utilizes an abstracted dynamic programming as a lower bound estimation to rule out the potential non - optimal fixed points in the model. The experiments show that the proposed method has shown great promise in improving both sample efficiency and convergence performance."
SP:1d630b69f95392a5ef3d7d580b523e077a3555a8,"This paper proposes a novel two - step training framework for deep generative models ( DGMs ) of high - dimensional natural images. First, it generates images in low - frequency bands by training a sampler in the wavelet domain. Then, it super - resolves these images from the wavelets back to the pixel - space with a novel wavelet super - resolution decoder network. Since the sampler and decoder can be trained in parallel and operate on much lower dimensional spaces than end - to - end models, the training cost is substantially reduced. On ImageNet 512x512, the proposed model achieves a Fréchet Inception Distance ( FID ) of 10.59 – beating the baseline BigGAN model – at half the compute ( 256 TPU - v3 cores ). Surprisingly, it is even able to outperform BigGAN in image quality at 512×512 resolution."
SP:b943a73b1ec34867371325748dc3a91ff4011947,"This paper provides a theoretical analysis of self - supervised learning ( SSL ) for few - shot learning ( FSL ). In particular, the paper analyzes the difference between SSL and supervised training for FSL. The paper shows that SSL can achieve comparable performance to supervised training under two assumptions : 1 ) a pre - trained embedding network with self - supervision and 2 ) the number of new classes available for training. The authors also provide a bound for the gap between the self - supervised loss and the supervised loss on FSL, and propose two ways to improve the test accuracy under SSL."
SP:bd552f98e6a447cefa6b1a9bbdf40bc6539fb643,"This paper studies the convergence properties of two - layer teacher - student neural networks. The authors show that the student neurons align with one of the teacher neurons at the local minima. They also show that under the most basic settings, all student neurons must align with the teacher neuron at any local maxima. Then, they extend the analysis to more general cases, where the proof can be reduced to analyzing the properties of a special class of functions that we call angular distance ( AD ) function. Finally, they demonstrate that these properties can be easily verified numerically."
SP:0f62846913ec10b44ed32845770da0565479dc75,"This paper proposes a framework for learning deep neural networks that incorporates user - provided formal knowledge to improve learning from data. Specifically, the authors propose a framework called Deep Adaptive Semantic Logic ( DASL ) that incorporates declarative knowledge in the form of arithmetic relations satisfied by unlabeled image triplets. The authors provide formal semantics that demonstrate that their knowledge representation captures all of first - order logic and that finite sampling from infinite domains converges to correct truth values. Experiments on MNIST toy problem and visual relationship detection task show that the addition of commonsense knowledge improves performance by 10.7 % in conditions of data scarcity."
SP:2f19259d65fab904c1b771244da3dcb2f8aa0c26,"This paper proposes a regularization method for feedforward residual neural networks ( ResNets ) to encourage the networks to learn iterative solutions. The authors define three indices of iterative convergence to quantify the degree to which the networks learn an iterative solution. To make the networks more iterative, they manipulate the degree of weight sharing across layers using soft gradient coupling. This new method provides a form of recurrence regularization and can interpolate smoothly between an ordinary ResNet and a “ recurrent ” ResNet ( i.e., one that uses identical weights across layers and thus could be physically implemented with a recurrent network computing the successive stages iteratively across time ). They also impose a Lipschitz constraint on the residual functions using spectral normalization to make them more convergent. However, the authors show that the gradient coupling does not improve classification accuracy on standard visual recognition tasks."
SP:6c14506b8b2b06043409d912e6bf877651aaa665,"This paper proposes two new normalization techniques for out - of - distribution ( OOD ) robustness. The first method, SelfNorm, uses attention to recalibrate statistics ( channel - wise mean and variance ), while the second one, CrossNorm, exchanges the statistics between feature maps. The authors show that the two normalization methods can complement each other in OOD generalization, though exploring different directions in statistics usage. Extensive experiments on different domains ( vision and language ), tasks ( classification and segmentation ), and settings ( supervised and semi - supervised ) show the effectiveness of the proposed methods."
SP:2774abdc11917321dd4994af0f0da1ff824bea03,"This paper proposes to use an attention module in the convolutional encoder of an RL agent in order to improve the sample efficiency and the final performance of the agents. The attention module consists of two modules : ( 1 ) a simple attention module that maps the input pixel to an input vector, and ( 2 ) an encoder module that takes the input vector as input and outputs an output vector. The proposed method is evaluated on the DeepMind Control Suite tasks. The results show that the proposed method outperforms the existing methods in terms of sample efficiency."
SP:31a7051d08d19c01e11f1fac2f3041ed2fa28f15,"This paper proposes an extension to the GradNorm method for multitask learning, which aims to minimize negative transfer among tasks by homogenizing the gradient magnitudes and directions across tasks. To this end, it adds a layer of task - specific rotation matrices that aligns all the task gradients. The authors also analyze the algorithm through the lens of game theory, providing theoretical guarantees on the algorithm stability and convergence. The experiments on several real - world datasets and network architectures show that Rotograd outperforms previous approaches for multitasking learning."
SP:ac9ebd027b92527d9a87b13ad11d002d99a2b0f6,"This paper proposes a new constraint for unsupervised geometry - invariant image translation, called minimal geometry - distortion constraint ( MGC ) as a general I2I translation constraint to guarantee the consistency of geometry structure of source and translated images, and thus reduce translation mismatch in the translation process. The authors observe that the pixel values before and after translation are usually highly correlated if the geometric structure is preserved because the color transformation is more regular within specific object regions. Based on this observation, the authors propose a mutual information ( MI)-based dependency measure that models the nonlinear relationships of pixel values in the source and translation images. To estimate MI from data, they propose the relative Squared - Loss Mutual Information ( rSMI ) which can be efficiently estimated in an analytic form. The experimental results demonstrate that MGC achieves high quality translation to maintain the geometry of images in original domain."
SP:92a38d7d18f07f68b8f93c61180e2cc1dddd21de,"This paper proposes a sampling - aware discriminator for 3D point cloud GANs. The authors show that sampling - insensitive discriminators ( e.g. PointNet-Max ) produce shape point clouds with point clustering artifacts, while sampling - oversensitive discriminators fail to guide valid shape generation. They propose the concept of sampling spectrum to depict the different sampling sensitivities of discriminators. They further study how different evaluation metrics weigh the sampling pattern against the geometry and propose several perceptual metrics forming a sampling spectrum of metrics. Guided by the proposed sampling spectrum, they discover a middle - point sampling-aware baseline discriminator, PointNet - Mix, which improves all existing point cloud generators by a large margin on sampling - related metrics."
SP:16c4be3eb162bc81cb3343c2fc115eb8e926a5b5,"This paper investigates the adversarial robustness of the recently proposed Capsule Networks ( CapsNets ). The authors show that adversarial examples can manipulate the votes from primary capsules by manipulating the votes of the output capsules. Motivated by these two observations, the authors propose a novel vote attack where they attack votes of CapsuleNets directly. The vote attack is not only effective but also efficient by circumventing the routing process. Furthermore, they integrate the vote attack into the detection - aware attack paradigm, which can successfully bypass the class - conditional reconstruction based detection method. Extensive experiments demonstrate the superior attack performance of our vote attack on CapsNet on adversarial attacks."
SP:dbd093dff7a38ba8882bb8119c34623ddaaf4cc6,"This paper proposes IMPORT, a meta - reinforcement learning algorithm that uses privileged information in the form of a task descriptor at train time to improve the learning of recurrent policies. IMPORT learns an informed policy ( i.e., a policy receiving as input the description of the current task ) that is used to both construct task embeddings from the descriptors, and to regularize the training of the recurrent policy through parameters sharing and an auxiliary objective. This approach significantly reduces the learning sample complexity without altering the representational power of RNNs, by focusing on the relevant characteristics of the task, and by exploiting them efficiently. The authors evaluate IMPORT against the main approaches to online adaptation on environments that require sophisticated exploration / exploitation strategies. It is shown that IMPORT can learn better strategies than Thompson Sampling approaches, and faster than recurrent neural network policies and Task Inference approaches."
SP:bd89d254fbf31db61db237d08ab42981e27c52df,"This paper proposes a method to learn an RL policy from offline data in the real - world sequential recommendation system ( SRS ). The method is based on the model learning technique to learn the policy from an offline dataset, e.g., to learn a simulator from the dataset, and train optimal policies in the simulator. Instead of increasing the fidelity of models for policy learning, the authors handle the distortion issue via learning to adapt to diverse simulators generated by the offline dataset. The adaptive policy is suitable to real - life environments where dynamics are changing and have stochasticity in the offline setting. Experiments are conducted in synthetic environments and a real world ride - hailing platform. The results show that the method overcomes the distortion problem and produces robust recommendations in the unseen real world."
SP:1a166b28cf684e0d5759bd629f6a53370d2bf11c,"This paper proposes a method for goal - reaching reinforcement learning. The method is based on the idea that any trajectory taken by an agent can be turned into an optimal one using hindsight relabelling, and that imitation of these trajectories enables an agent to ( iteratively ) learn goal reaching policies from scratch. The authors show that this iterated supervised learning procedure optimizes a bound on the RL objective, derive performance bounds of the learned policy, and empirically demonstrate improved performance and robustness over current RL algorithms."
SP:c306530164d677e670554eeba8203c66bb3d9f7a,"This paper proposes FastSpeech 2, a fast and high - quality end - to - end TTS system to address the issues in the existing fastSpeech system. The main idea is to directly train the model with ground - truth mel - spectrograms to simplify the training pipeline and also avoid the information loss compared with the current fastspeech. The authors also introduce more variance information including pitch and energy to improve the duration accuracy and improve pitch prediction by introducing continuous wavelet transform. Experimental results show that the proposed method can achieve a 3x training speed - up over FastSpech."
SP:79e9fb20d383816f54738ce70d137131ebc10290,"This paper studies the problem of unsupervised dimension reduction ( UDR ) in the language of tempered distributions, i.e., approximating an empirical probability density function pemp(x ) by another tempered distribution q(x) whose support is in a k - dimensional subspace. The problem is reduced to the minimization of the distance between q and pemp, D(q, pemp ), over a pertinent set of generalized functions. This infinite - dimensional formulation allows to establish a connection with another classical problem of data science — the sufficient dimension reduction problem ( SDR ). The authors introduce a nonnegative penalty function R(f ) that “ forces the support of f to be k-dimensional. ” Then they present an algorithm for minimization I(f) + \lambda^2 ( alternating scheme ), based on the idea of two - step iterative computation, where a ) an adaptation to real data and to fake data sampled around a kdimensional subspace found at a previous iteration, b ) calculation of a new k - dimension subspace, and c ) an alternating scheme. They demonstrate the method on 4 UDR and 1 SDR problems using synthetic data and standard datasets."
SP:93e54522e6c2b805905d21fc968fc40866f2898b,"This paper proposes Feature Contrastive Learning ( FCL ), a novel approach to balance robustness and sensitivity in deep neural network training. Unlike previous work that only enforces robustness, FCL aims to promote model sensitivity to perturbations of high utility features, and inhibit model sensitivity of low utility features. The performance of FCL is validated on both synthetic and real image classification datasets."
SP:f03c50f15022c4f56ac2b3085354ffed38ad1145,"This paper proposes a novel method for imitation learning based on adversarial learning. The proposed method is based on the idea of mutual information between the discriminator network and the expert network. The discriminator is trained to learn a latent representation of the task completion data, which is then used to train the agent to imitate the expert. The method is evaluated on a variety of tasks, including balancing, manipulation, and locomotion tasks. The results show that the proposed method outperforms other baselines."
SP:ef18f4188426bc01be309633b486884b0e7a81a4,"This paper provides a theoretical analysis of learning one - hidden - layer pruned neural networks, which offers formal justification of the improved generalization of the winning ticket observed from empirical findings in LTH. They characterize analytically the impact of the number remaining weights in a pruned network on the required number of samples for training, the convergence rate of the learning algorithm, and the accuracy of the learned model. They also provide extensive numerical validations of their theoretical findings. Their theoretical results are acquired from learning a pruning neural network of one hidden layer, while experimental results are further provided to justify the implications in pruning multi - layer neural networks."
SP:eed6cb2f8caed39f8295f4aeb6e044c2ac981c4d,"This paper proposes AutoLabel to automatically learn the labels for augmented data based on the distance between the clean distribution and augmented distribution. The proposed method is built on label smoothing and is guided by the calibration - performance over a hold - out validation set. The authors show that AutoLabel is a generic framework that can be easily applied to existing data augmentation methods, including AugMix, mixup, and adversarial training. Experiments on CIFAR-10, Cifar-100 and ImageNet show that the proposed method can improve models ’ accuracy and calibration performance, especially under distributional shift. Additionally, AutoLabel can help adversarial robustness by bridging the gap between clean accuracy and robustness."
SP:0d5017e1a405bf86e3bac40e6e59886d4bf48450,"This paper proposes a new self - supervised representation learning method, RELIC, that enforces invariant prediction of proxy targets across augmentations through an invariance regularizer which yields improved generalization guarantees. The authors show how data augmentations can be more effectively utilized through explicit invariance constraints on the proxy classifiers employed during pretraining. Further, using causality, the authors generalize contrastive learning using refinements and show that learning on refinements is a sufficient condition for learning useful representations ; this provides an alternative explanation to MI for the success of contrastive methods. Empirical results show RELIC significantly outperforms competing methods in terms of robustness and out - of - distribution generalization."
SP:8f80a6f79f78c6421857f392c9a5e98061d7eb60,"This paper proposes a visual transformer network ( VTNet ) for object goal navigation. The idea is to learn a spatial - aware visual representation of the observed scene, which can be used to guide the agent towards a target object based on observations of the agent. The proposed method is based on the Transformer Network ( TNN ) architecture, which is used to encode object and region features as well as their location cues as spatial descriptors and then incorporates all the encoded descriptors through attention operations to achieve informative representation for navigation. In addition, the authors also develop a pre - training scheme to associate the visual representations with navigation signals, and thus facilitate navigation policy learning. Experiments in the artificial environment AI2 - Thor demonstrate that VTNet significantly outperforms state - of - the - art methods in unseen testing environments."
SP:3e7cbe3dff592ef371e48dd86be7719fc5343f17,"This paper proposes communication - computation efficient secure aggregation ( CCESA ) for federated learning. The key idea is to design the topology of the secret - sharing nodes ( denoted by the assignment graph G ) as sparse random graphs instead of the complete graph corresponding to the existing solution. The authors first obtain a sufficient condition on G to guarantee reliable and private federate learning. Then, they suggest using the Erdős - Rényi graph as G, and provide theoretical guarantees on the reliability / privacy of the proposed scheme. Through extensive real - world experiments, the authors demonstrate that their scheme, using only 50% of the resources required in the conventional scheme, maintains virtually the same levels of reliability and data privacy in practical Federated learning systems."
SP:00fae41e0eca0a1575cd7b2dcfabf0dc5c9c8b8a,This paper presents a novel approach to the problem of designing an incentive - compatible auction that maximizes expected revenue. The authors propose to use a time - independent Lagrangian instead of a non - stationary objective function. They also propose a novel formulation of auction learning as a twoplayer game between an Auctioneer and a Misreporter and a new architecture ALGnet. They demonstrate the effectiveness of their approach by learning competitive or strictly improved auctions compared to prior work.
SP:a0e8061beb5e9a6c631419861559d22b8d645cb4,"This paper proposes Bi - Tuning, a general learning approach to finetune both supervised and unsupervised pre - trained representations to downstream tasks. The proposed method generalizes the vanilla fine - tuning by integrating two heads upon the backbone of pre - training representations : a classifier head with an improved contrastive cross - entropy loss to better leverage the label information in an instance - contrastive way, and a projector head with a newly - designed categorical contrastive learning loss to fully exploit the intrinsic structure of data in a category - consistent way. Comprehensive experiments confirm that Bi -tuning achieves state - of - the - art results for fine - tuned models by large margins ( e.g. 10.7 % absolute rise in accuracy on CUB in low - data regime )."
SP:87e5b552c13d73bd85249062a152c6c140e594a9,"This paper proposes a new measure for the robustness of classifiers called "" genuine adversarial accuracy "". The paper argues that standard adversarial training does not provide a good measure of robustness to adversarial perturbations. To this end, the paper proposes to use a new metric called "" 1 - NN robustness "", which measures the distance between a classifier and its nearest neighbors. This metric is based on the maximum perturbation norm, which is defined as the difference between the class of the perturbed data points and the original data points.   The paper shows that this metric does not favor a model with invariance - based adversarial examples, i.e. samples whose predicted classes are unchanged even if the perceptual classes are changed."
SP:2fda410b9281c5e253d385bc4382ec168bc161f3,"This paper studies the problem of fairness in graph - structured data. Specifically, they focus on dyadic fairness, which articulates a fairness concept that a predictive relationship between two instances should be independent of the sensitive attributes. Based on this, they theoretically relate the graph connections to Dyadic fairness on link predictive scores in learning graph neural networks. Subsequently, they propose an algorithm, FairAdj, to empirically learn a fair adjacency matrix with proper graph structural constraints for fair link prediction, and in the meanwhile preserve predictive accuracy as much as possible. Empirical validation demonstrates that our method delivers effective dyadic fair in terms of various statistics, and at the same time enjoys a favorable fairness - utility tradeoff."
SP:b614e9fbec58e9efa7722d2ec4a60fc93d210f92,"This paper proposes a new generative autoencoder, called DEAE, which uses disentangled representation and regularization to guarantee the validity of exploration in latent space and achieve controllable synthesis. The encoder of DEAE first turns the input sample into a disentanglement latent code, then explores the latent code space through directed interpolation. To aid the interpolated latent code in successfully outputting a meaningful sample, after the decoder, the encoder ’s output is regularized to force the output by ’reusing ’ the encoders to maintain perfect disentangling, which implicitly improves the quality of interpolated sample. Experiments demonstrate that DEAE can improve the performance of downstream tasks by synthesizing attribute - controlled augmented samples. DEAE also helps to eliminate dataset bias."
SP:c934adb14926a00ef9c73c9773cb0b3a2669921e,"This paper proposes a new Bayesian Bayesian memory allocation scheme that bridges the gap between episodic and semantic memory via a hierarchical latent variable model. The authors take inspiration from traditional heap allocation and extend the idea of locally contiguous memory to the Kanerva Machine, enabling a novel differentiable block allocated latent memory. They simplify the process of memory writing by treating it as a fully feed forward deterministic process, relying on the stochasticity of the read key distribution to disperse information within the memory. Experiments show that this allocation scheme improves performance in memory conditional image generation, resulting in new state - of - the - art conditional likelihood values on binarized MNIST, Omniglot and Celeb - A."
SP:e63d7d8c581019e17585fb9c0eac33d6836e187d,"This paper studies the effect of attention mechanisms on the loss landscape of neural networks. The authors show that, under mild assumptions, every local minimum of the attention model has low prediction error, and attention models require lower sample complexity than models without attention. Besides revealing why popular self - attention works, the theoretical results also provide guidelines for designing future attention models."
SP:f739d199fdee26f09994e3f9487aec1eab0f2e89,"This paper extends the concept of expected free energy ( EFE ), which is a core quantity in active inference, and claims that EFE can be treated as a negative value function from an RL perspective. Motivated by this connection, the authors propose a novel inverse RL algorithm for designing EFE - based rewards, by learning a prior preference from expert demonstrations. The experiments show the applicability of active inference based rewards using EFE to an inverse RL problem."
SP:5592b79e49eba95c15103a3348f2bde57b60f2ab,"This paper proposes a data augmentation method to improve generalization in both adversarial and standard learning by using out - of - distribution ( OOD ) data that are devoid of the abovementioned issues. Theoretical analyses demonstrate how our proposed method can improve robust and standard generalization. The experimental results on CIFAR-10, CifAR-100, and a subset of ImageNet suggest that OAT can help reduce the generalization gap in adversarial learning."
SP:3cac7a2c310165ed0de46d8e5546c3bfbd639158,"This paper proposes a new method for meta - reinforcement learning, called Fast Linearized Adaptive Policy ( FLAP ). The main idea is to learn a shared linear representation of the policy so that when adapting to a new task, it suffices to predict a set of linear weights. A separate adapter network is trained simultaneously with the policy such that during adaptation, we can directly use the adapter network to predict these linear weights instead of updating a meta - policy via gradient descent, such as in prior meta - RL methods like MAML, to obtain the new policy. The application of the separate feed - forward network not only speeds up the adaptation run - time significantly, but also generalizes extremely well to very different tasks that prior MetaRL methods fail to generalize to. Experiments on standard continuous - control metaRL benchmarks show FLAP presenting significantly stronger performance on out - of - distribution tasks with up to double the average return and up to 8X faster adaptation run time speeds."
SP:21a1bd4ada0723c96c0dbf7a142a2faf5defa4e3,"This paper proposes a federated kernel k - means algorithm to solve the optimization problem of kernel k means under federated settings. The authors propose a distributed stochastic proximal gradient descent ( DSPGD ) algorithm to determine an approximate solution to the optimization of kernelk - means, and a communication efficient mech anism ( CEM ) is designed to reduce the communication cost. Theoretical analysis shows that the convergence rate of the proposed algorithm is O(1/T ), where T is the number of iterations. Experimental results show that the federated kerne l k - meant achieves the highest clustering quality with the communication costs reduced by more than 60 % in most cases."
SP:be568dd3fea51ce33a6d1e4b07dda5aee6342395,"This paper proposes CompOFA, a design space for Once - For - All ( OFA ) networks that uses compound couplings between model dimensions to speed up the process of one - shot training and neural architecture search with hardware latency constraints. The authors show that intractably large architectural search spaces are unnecessary for both accuracy and diversity of models, so they introduce a simple heuristic that vastly shrinked the search space without losing on Pareto optimality. They also show that this smaller search space is dense enough to support equally accurate models for a similar diversity of hardware and latency targets, while reducing the complexity of the training and subsequent extraction algorithms."
SP:04b84d26cf282dbb753cbf27f14c334f65d3f8ec,"This paper proposes an adversarial meta - learning algorithm, called ADML ( Adversarial Meta - Learner ), which leverages clean and adversarial samples to optimize the initialization of a learning model. The authors show that the proposed method is robust to adversarial attacks and outperforms MAML - AD ( Finn et al., 2017 ) on two image datasets, MiniImageNet and CIFAR100, in terms of accuracy and robustness."
SP:dfbaa6b53c4e8328d52666ad4641fc917bf0c0b3,"This paper proposes a method to improve the decoding performance of linear error correction codes by using a self - attention mechanism. The proposed method is based on the idea of permutation groups ( PGs ), which is used to select the most likely permutation from a set of possible permutations. The method is evaluated on the Bose - Chaudhuri - Hocquenghem ( BCH ) code, where the authors show that the proposed method outperforms the baselines."
SP:c860a7b0952d708e7851c9bc4b63d246f64d1cba,"This paper proposes to use Bag of Words ( BOW ) to partition the unlabeled training data into relatively homogeneous clusters of text instances and treat these clusters as labeled data for an intermediate text classification task, and train BERT – with or without additional MLM pretraining – with respect to this multi - class problem, prior to the final fine - tuning over the actual target - task labeled data. Extensive experimental results demonstrate the practical value of this strategy on a variety of benchmark data, most prominently when the training data available for the target task is relatively small and the classification task is of topical nature. The authors further analyze the results to gain insights as to when this approach would be most valuable and propose future directions to expand the present work."
SP:ea37f5882fd98dd4ce233077bb3069517d4ed4ea,"This paper presents a new benchmark for model - based reinforcement learning ( MBRL ) by comparing generative models using a fixed ( random shooting ) control agent. The authors find that on an environment that requires multimodal posterior predictives, mixture density nets outperform all other models by a large margin. When multimodality is not required, deterministic models are on par, in fact they consistently ( although non - significantly ) outperform their probabilistic counterparts. They also found that heteroscedasticity at training time, perhaps acting as a regularizer, improves predictions at longer horizons. At the methodological side, they design metrics and an experimental protocol which can be used to evaluate the various models, predicting their asymptotic performance when using them on the control problem. Using this framework, they improve the state - of - the - art sample complexity of MBRL on Acrobot by two to four folds."
SP:4e25ba3714d78ba59a0d8efbb65e0ef5201702f8,"This paper proposes an affine regularizer for GANs that can explicitly disentangle affine transformations in a self - supervised and rigorous manner. The objective is inspired by InfoGAN, where an additional affine transformation regularizer acts as the inductive bias. The affine transform regularizer is derived by decomposing the affine matrix into separate transformation matrices and inferring the transformation parameters by maximum likelihood estimation. Unlike the disentangled representations learned by existing approaches, the features learned by ADIS - GAN are axis - aligned and scalable, where transformations such as rotation, horizontal and vertical zoom, horizontal skew, and vertical translation can be explicitly selected and learned. The proposed method successfully disentangles these features on the MNIST, CelebA and dSprites datasets."
SP:121f8420cfb49c6d80b5ebb4051e85947182594a,"This paper proposes CLSA, a new contrastive learning method for image augmentation. The key idea is to use the distributional divergence between the weakly and strongly augmented images over the representation bank to supervise the retrieval of strongly augmented queries from a pool of candidates. This avoids an overoptimistic assumption that could overfit the distorted queries containing distorted visual structures into the positive targets, while still being able to distinguish them from the negative samples by leveraging the distributions of weakly augmented counterparts. The proposed method achieves top-1 accuracy of 76.2 % on ImageNet with a standard ResNet-50 architecture with a single - layer classifier fine - tuned. This is almost the same as 76.5 % of top - 1 accuracy with a fully supervised ResNet - 50."
SP:af54e542223097c315ecd677d0b968e9a0b2a1d4,"This paper proposes a new method for de - identification of MRI images. The main idea is to use a GAN architecture to generate a 3D image of a patient ’s MRI scan, where the brain is not modified, but the face has been de - identified. The proposed method is based on C - DeID - GAN, which is a multi - scale, 3D GAN. The authors show that the proposed method can produce images that appear completely genuine but do not actually contain any privacy - sensitive information. They also show that their method protects privacy substantially better than existing methods without strongly affecting the performance."
SP:0ac3964bd2320341488476d60f57b75d2a79f92c,"This paper proposes a multi - head attention based global pooling layer that captures the interaction between nodes according to their structural dependencies for hierarchical graph pooling. The proposed method, Graph Multiset Transformer ( GMT ), encodes the given set of node embedding as a multiset to uniquely embed two different graphs into two distinct embeddings, and considers both the global structure of the graph and their task relevance in compressing the node features. The paper shows that GMT satisfies both injectiveness and permutation invariance, such that it is at most as powerful as the Weisfeiler - Lehman graph isomorphism test, and can be easily extended to the previous node clustering approaches for hierarchical graphs. The experimental results show that GMT significantly outperforms state - of - the - art graphs pooling methods on graph classification benchmarks with high memory and time efficiency, and obtains larger performance gain on graph reconstruction and generation tasks."
SP:76848e7ac3e6709e92f6a6db60269cb5177495d1,"This paper proposes a new explanation for the problem of over - squashing in GNNs : a bottleneck that causes the information to be squashed into a fixed - length vector. The paper shows that GCN and GIN are more susceptible to this problem than GAT and GGNN, and that prior work that extensively tuned GNN models of long - range problems suffer from over - Squashing. The authors also show that breaking the bottleneck improves the state - of - the - art results without any tuning or additional weights."
SP:90d8fa381446923902e42b259392e5e975e6caa1,"This paper proposes a new method for cross - domain sentiment analysis based on learning a prototypical distribution for the source domain in a cross - domains embedding space which is trained to be domain - agnostic. The authors use a Gaussian mixture modal ( GMM ) to estimate the parameters of the prototypical distributions using a subset of source samples for which the classifier is confident about its predictions. As a result, larger margins between classes are introduced to reduce the effect of "" domain shift "" on the performance of a trained classifier in the target domain. Theoretical and empirical analysis are provided to demonstrate that the method is effective."
SP:893fd7440b82f5da0d4c0944928810322eaee2f0,"This paper presents an evaluation methodology to measure gender bias in NLI models. The authors propose a challenge task to test whether a model's gender bias is different from the gender - neutral premise against a gender - specific hypothesis. The challenge task is based on the idea that the bias is propagated in the models with respect to occupational stereotypes. The results suggest that three models ( BERT, RoBERTa, BART ) trained on MNLI and SNLI data - sets are significantly prone to gender induced prediction errors. They also find that debiasing techniques such as augmenting the training dataset can help reduce such bias in certain cases."
SP:a32ab755bd249c393b70938036ce8e810c0c439f,"This paper revisits the variational intrinsic control ( VIC ) method proposed by Gregor et al. ( 2016 ), which is an unsupervised reinforcement learning method for finding the largest set of intrinsic options available to an agent. The authors show that the intrinsic reward used in the latter is subject to bias in stochastic environments, causing convergence to suboptimal solutions. To correct this behavior and achieve the maximal empowerment, the authors propose two methods respectively based on the transitional probability model and Gaussian mixture model."
SP:b4df2c4627a6d46c5100133e38c4bea20b296dd8,"This paper studies the use of neural ensembles for image classification problems with limited data. The authors propose to use an ensemble of relatively small deep neural networks to solve the problem of image classification with a few labeled examples per class and improve sample efficiency in the low data regime. They show that deep ensembling is a simple yet effective technique that outperforms current state - of - the - art approaches for learning from small datasets. They compare different ensemble configurations to their deeper and wider competitors given a total fixed computational budget and provide empirical evidence of their advantage. Furthermore, they investigate the effectiveness of different losses and show that their choice should be made considering different factors."
SP:4a0ee01f4897efa81659f37ef0468ee8195bbc4f,"This paper proposes Sparse Binary Neural Network ( SBNN ), a method to further compress Binary Neural Networks ( BNNs ) by introducing sparsity, while reducing their required computations. The approach is based on quantization of weights in the 0 / 1 binary domain and a highly sparse initialization of the network. It is formulated as a mixed optimization problem and solved using a modified version of the BNN training algorithm with -1 / 1 weights. The method has been evaluated on feed - forward linear and convolutional network on MNIST and CIFAR-10 data sets, respectively. The achievable compression rate of SBNN is much higher than simple BNN, making it a feasible alternative for IoT devices and sensors."
SP:5be8539ad02595ad3c7a2d7afe8cbb3e9924467d,"This paper proposes a simple post hoc calibration method for predictive uncertainty estimates for deep learning models. The main idea is to calibrate the model on corrupted data. The method is based on the idea of Brier score, which is a popular calibration method in deep learning. The idea is that the model outputs a class probability for a given data point, and this class probability is used as a surrogate for the true class probability of the data point. The paper proposes to use the Brier Score as a proxy for the actual class probability. The proposed method is shown to be more accurate than other calibration methods."
SP:ea503f67e38fce7dee9cc4996b55b8959911f030,"This paper studies the expressive power of graph neural networks and graph kernels from an empirical perspective. Specifically, they compare the graph representations and similarities produced by these algorithms against those generated by a wellaccepted, but intractable graph similarity function. They also investigate the impact of node attributes on the performance of the different models and kernels. Their results reveal interesting findings. For instance, they find that theoretically more powerful models do not necessarily yield higher - quality representations, while graph kernels are shown to be very competitive with GNNs."
SP:0cf7b7d929f50e0b7f4fda5e1f68e5ade2f7c29b,"This paper proposes a new method for image generation based on inpainting. The main idea is to use the occlusion information in image animation to regularize discriminator predictions. The proposed method is based on CutMix, a data augmentation technique that cuts and mixes patches of different images to regularise discriminator prediction. The method is evaluated on three datasets : VoxCeleb, BAIR, and Tai - Chi - HD."
SP:60b535fc6cbc1a7a26ad53f706ebb17de346dc4f,"This paper proposes a method to learn independent causal mechanisms ( ICM ), which directly model multiple data generation processes ( mechanisms ) in a coarse granularity. The authors propose to learn a model that disentangles each mechanism and approximates the groundtruth mechanisms from observational data. They outline sufficient conditions under which the mechanisms can be learned using a single self - supervised generative model with an unconventional mixture prior, simplifying previous methods. Moreover, they prove the identifiability of the model w.r.t. the mechanisms in the self - supervision scenario. Experiments show that the ICM model is generally more robust against interventions, covariant shifts, and noise compared to disentangled representations."
SP:44d4e24428d043a69b40013919cda0e8e7bff99c,"This paper proposes a method for graph recognition from images. The authors propose a novel rich labeling framework by introducing the use of fully mediating representations. They show that the rich labeling can be performed by graph alignment, and they show that it enables data efficient domain adaption and ( 4 ) reaches state - of - the - art performance on Maybridge compound data set. In the case of graph recognition, they empirically show that their method is able to adapt to a new domain of chemical compounds, with previously unseen atom or bond types."
SP:ad906dd9a176cffd283593321ff6b9ad19595528,This paper proposes a monotonic neural network ( MNN ) to solve the problem of energy optimization in the cooling system of a data center. The main idea is to use the input - output of the neural network to constrain the input of the chiller power model to conform to physical laws and provide accurate function space about chiller plants. The proposed MNN can help the subsequent optimization step and improve 1.5 % the performance of optimization compared with the state - of - the - art methods.
SP:6cb65ee5d2926858570601eeeade24fe86c7f32f,"This paper proposes a new method for spatio - temporal forecasting based on the causal attention. The authors use the Conditional Average Treatment Effect ( CATE ) estimation method in causal inference and propose a novel and fast multi - head attention evolved from Taylor ’s expansion instead of softmax. They further design a spatial graph fusion mechanism to significantly reduce the parameters ’ scale. They conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various model components, and the time efficiency of our CausalTrans."
SP:223980a1954d626d90ff54d8dc61b5d85a6b349c,"This paper proposes an unsupervised framework called coupled mixture VAE ( cpl - mix VAE ), which utilizes multiple interacting autoencoding agents to learn mixture representations, while being encouraged to reach consensus on the categorical assignments. The authors provide theoretical justification to motivate the use of a multi - agent framework, and formulate it as a variational inference problem. They benchmarked their approach on MNIST and dSprites, achieving state - of - the - art categorical assignment while preserving interpretability of the continuous factors. They then demonstrate the utility of this approach in jointly identifying cell types and type - specific, activity - regulated genes for a single - cell gene expression dataset profiling over 100 cortical neuron types."
SP:c982610ad28662c3bd13132abe1f7307d1a61b68,"This paper provides a general characterization of steerable kernel spaces for compact ( point - symmetry ) groups G and their homogeneous spaces. The authors use the Wigner - Eckart theorem for spherical tensor operators to show that steerable kernels are fully understood and parameterized in terms of 1 ) generalized reduced matrix elements, 2 ) Clebschordan coefficients, and 3 ) harmonic basis functions on homogenous spaces. This work provides such a characterization for practically relevant case of G being any compact group, considering both real and complex representations. Thereby, the authors demonstrate that the endomorphism bases, CleBSch - Gordan coefficients and harmonic basis function can usually be determined."
SP:7b2ea39069277ad0f4f79476a77ef84587a804d9,"This paper analyzes the effect of selective classification on the accuracy disparities between groups within a population, especially in the presence of spurious correlations. The authors show that selective classification can improve average accuracies, but it can simultaneously magnify existing accuracy disparities. They observe this behavior consistently across five vision and NLP datasets. Surprisingly, increasing abstentions can even decrease accuracies on some groups. To better understand this phenomenon, they study the margin distribution, which captures the model ’s confidences over all predictions. For symmetric margin distributions, they prove that whether selective classification monotonically improves or worsens accuracy is fully determined by the accuracy at full coverage and whether the distribution satisfies a property we call left - log - concavity. Motivated by their analysis, they train distributionally - robust models that achieve similar full - coverage accuracies across groups and show that the selective classification uniformly improves each group on these models."
SP:f1d57ee27e901daf7e4e2b84139019e945818911,"This paper proposes a hierarchical nonnegative CANDECOMP / PARAFAC decomposition ( hierarchical NCPD ) model and a training method, Neural NCPD, for performing hierarchical topic modeling on multi - modal tensor data. The proposed method utilizes a neural network architecture and backpropagation to mitigate error propagation. Experimental results demonstrate the effectiveness of the proposed method on both real and synthetic datasets."
SP:b6ddc3a560aa7155e7e927bf5360bedc36586597,"This paper proposes the first collective robustness certificate for adversarial robustness. The key idea is to use a single adversarial perturbation of a single graph, image, or document to certify the robustness of the predictions. The proposed approach is based on the locality property of graph neural networks, which guarantees that perturbations to the input graph only affect predictions in a close neighborhood. The authors propose to fuse multiple single - node certificates into a drastically stronger collective certificate. The experimental results show that the proposed collective approach yields much stronger certificates than existing methods."
SP:cc93dd2f68e415e2457166e78627865dc1b44697,"This paper proposes Quantile Regression GAN ( QRGAN ), which uses quantile regression to minimize the 1 - Wasserstein distance between real and generated data distribution as a novel approach in modification of loss functions for improvement of GANs. The proposed method is based on LSGAN and WGAN. The main contribution of this paper is to study the output space of discriminator and gradients of fake samples to see if the discriminator guides the generator well. And they found that discriminator should not be bounded to specific numbers. QRGAN exposes high robustness against mode collapse problem. Furthermore, QRGAN obtains an apparent improvement in the evaluation and comparison of Frechet Inception Distance ( FID ) for generation performance."
SP:4ddb47ee77c374ae6c3e419412d92ca77260692e,"This paper investigates relevance metrics that can provide reasonable explanations to users. Specifically, they adopted three tests to evaluate whether the relevance metrics satisfy the minimal requirements for similarity - based explanation. Their experiments revealed that the cosine similarity of the gradients of the loss performs best, which would be a recommended choice in practice. In addition, they showed that some metrics perform poorly in our tests and analyzed the reasons of their failure."
SP:6c2cbf2bc0f6dabe974e80ec1e82d2d12189906e,"This paper proposes adding a low - rank global attention ( LRGA ) module to GNNs to improve their generalization power. The authors show that adding the LRGA module to a specific family of expressive GNN models provides algorithmic alignment to a powerful graph isomorphism test, namely the 2 - FWL algorithm. In more detail, the authors consider the recent Random Graph Neural Network ( RGNN ) framework and prove that it is universal in probability. They also show that RGNN augmented with LRGA aligns with 2 FWL update step via polynomial kernels and bound the sample complexity of the kernel ’s feature map when learned with a randomly initialized two - layer MLP."
SP:b4abdd28504b4c1de239eabd4e0e27d370efee71,"This paper proposes an adaptive label smoothing method to improve the calibration performance of CNNs. The authors use bounding box information for a portion of the ImageNet dataset ( Russakovsky et al., 2015 ) to train different classifiers. They show that their approach can be used to train CNNs that are calibrated and have better localization performance on the challenging MS - COCO dataset ( Lin et al, 2014 ) after fine - tuning, compared to approaches that use hard labels or traditional labels. Their methods provide the lowest accuracy and an order of magnitude reduction in average confidence."
SP:5254658923e594294b69d124a8d004166852822a,This paper proposes a convex duality framework for the two - layer fully - convolutional ReLU denoising network. The main idea is to use the weight decay regularization of CNNs to train the convex neural network while the prediction is piece - wise linear filtering. Experiments on MNIST and fastMRI datasets confirm the effectiveness of the dual network optimization problem.
SP:085cad6bc143c8713580bddfaa71f06496dac314,"This paper presents an end - to - end speech synthesis model that uses a differentiable alignment scheme based on token length prediction to produce high - fidelity audio. The proposed generator is feed - forward and thus efficient for both training and inference. It learns to produce audio through a combination of adversarial feedback and prediction losses constraining the generated audio to roughly match the ground truth in terms of its total duration and mel - spectrogram. The resulting model achieves a mean opinion score exceeding 4 on a 5 point scale, which is comparable to the state - of - the - art models relying on multi - stage training and additional supervision."
SP:01148cea55db606aa78d27e900818684a8bce9ab,This paper proposes a non - parametric framework for node representation learning to utilize incomplete node - attribute information. The key idea is to embed nodes into a low - dimensional discrete Wasserstein space through matrix decomposition and diffusion. This allows us to reduce the distortion caused by missing attributes and obtain integrated representations expressing information of both topology structure and attributes. The proposed method is applied to node classification ( with missing attributes ) and matrix completion.
SP:aeeb5909f7123ef631f569b469af9715205c881f,"This paper proposes a meta - learning method to improve the sample complexity and efficacy of RL algorithms in solving the exploration problems they face. The proposed method is based on the idea of a teacher and a student agent, where the teacher is a goal - generating agent and the student agent is a policy conditioned on the teacher's goal - conditioned policy. The teacher is incentivized to generate goals that are challenging but not impossible, while the student is rewarded to achieve the goal. The authors show that their method generates a natural curriculum of self - proposed goals which ultimately allows the agent to solve challenging procedurally - generated tasks where other forms of intrinsic motivation and state - of - the - art RL methods fail."
SP:3d05bc7dca97681cb582298e318b9b973841eed3,"This paper considers the problem of information retrieval from a dataset of files stored on a single server under both a user distortion and a user privacy constraint. Specifically, a user requesting a file from the dataset should be able to reconstruct the requested file with a prescribed distortion, and in addition, the identity of the file should be kept private from the server. The proposed model can be seen as an extension of the well - known concept of private information retrieval by allowing for distortion in the retrieval process and relaxing the perfect privacy requirement. The authors show that the optimal rate - distortion - leakage tradeoff is convex and that in the limit of large file sizes this allows for a concise information - theoretical formulation in terms of mutual information. Moreover, the authors propose a new data - driven framework by leveraging recent advancements in generative adversarial models which allows a user to learn efficient schemes in term of download rate from the data itself."
SP:3f9e2db00fc3dcd7a40588adcb638503ec10dc09,"This paper proposes a decoupled greedy learning method for GNNs, which decouples the GNN into smaller modules and associates each module with greedy auxiliary objectives. This allows GNN layers to be updated during the training process without waiting for feedback from successor layers, thus making parallel GNN training possible. The method achieves improved efficiency without significantly compromising model performances, which would be important for time or memory limited applications. Further, the authors propose a lazy - update scheme during training to further improve its efficiency."
SP:5ecb1b288f7fc02aead4493f81640867bc349290,"This paper proposes a framework for answering complex queries on incomplete Knowledge Graphs. The authors translate each query into an end - to - end differentiable objective, where the truth value of each atom is computed by a pre - trained neural link predictor. They then analyse two solutions to the optimisation problem, including gradient - based and combinatorial search. In their experiments, the proposed approach produces more accurate results than state - of - the - art methods — black - box neural models trained on millions of generated queries — without the need of training on a large and diverse set of complex queries."
SP:f04a522fd04c503754fdb8c52da68646d31271a4,"This paper proposes a method for verifying the robustness of neural networks with piecewise - linear activation functions. The method is based on geometric projections of the input space into a set of convex polyhedral regions in which the network ’s behavior is linear. The authors show how the regions around a point can be analyzed using simple geometric projections, thus admitting an efficient, highly - parallel GPU implementation that excels particularly for the `2 norm, where previous work has been less effective. Empirically, the authors show that their approach is far more precise than many approximate verification approaches, while at the same time performing multiple orders of magnitude faster than complete verifiers, and scaling to much deeper networks."
SP:5297651ff873f97c07b9c47ed3eff52251661844,"This paper proposes an approach to embed objects in an affordance space, in which each dimension corresponds to an aspect of meaning shared by many actions, using text corpora. This embedding makes it possible to predict which verbs will be applicable to a given object, as captured in human judgments of affordance, better than a variety of alternative approaches. Furthermore, it shows that the dimensions learned are interpretable, and that they correspond to typical patterns of interaction with objects. Finally, the dimensions can be used to predict a state - of - the - art mental representation of objects, derived purely from human judgements of object similarity."
SP:72b4f3b40c6c6fa2eb53e95ed9a10a4077ffa049,"This paper proposes a method for the emergence of individuality ( EOI ) in multi - agent reinforcement learning ( MARL ). Specifically, the proposed method learns a probabilistic classifier that predicts a probability distribution over agents given their observation and gives each agent an intrinsic reward of being correctly predicted by the classifier. The intrinsic reward encourages the agents to visit their own familiar observations, which makes the intrinsic reward signals stronger and in turn makes the agents more identifiable. Two regularizers are proposed to increase the discriminability of the classifiers. The proposed method is compatible with centralized training and decentralized execution ( CTDE ). Empirically, it outperforms existing methods in a variety of multi - agents cooperative scenarios."
SP:112509d6d3573a9d495d182fdfae6ec0327cddf5,"This paper proposes a method to improve the robustness of randomized smoothed classifiers. The proposed method is based on the smoothed weighted ensembling ( SWEEN ). The authors show that the proposed method can achieve optimal certified robustness w.r.t. our defined $ \gamma$-robustness index. Furthermore, the authors provide a theoretical analysis to prove that the optimal SWEen model can be obtained from training under mild assumptions. They also develop an adaptive prediction algorithm to reduce the prediction and certification cost. Extensive experiments show the effectiveness of the proposed approach."
SP:ea892e3d199ed6121279b20061a87f43afae8796,This paper proposes a method to learn the subtask hierarchy from the demonstration trajectory. The authors propose a novel Ordered Memory Policy Network ( OMPN ) that can represent the sub - task structure and leverage it to perform unsupervised task decomposition. The method uses a bottom - up recurrence and a top - down recurrence to implement horizontal update and vertical expansion respectively. Experiments on Craft and Dial demonstrate that the proposed method can achieve better task performance compared with strong baselines.
SP:cc6aa977ce561a2493ae74bb694205cd67c8d890,"This paper proposes a Causal Semantic Generative model ( CSG ) for out - of - distribution ( OOD ) image classification tasks. The CSG is based on a causal reasoning approach to separate the semantic and variation factors. The authors show that under certain conditions, CSG can identify the semantic factor by fitting training data, and this semantic - identifiability guarantees the boundedness of OOD generalization error and the success of adaptation. Empirical study shows improved OOD performance over prevailing baselines."
SP:be3f34a59e5e61dcdbc7cb085f031ba4a5a5b758,"This paper studies the robustness of online learning algorithms under adversarial corruptions. In particular, the authors consider the case where the reward from the environment can be arbitrarily corrupted with probability $ \mathbb{R}(0, 12)$, where $ R$ is the strength of the adversary. The authors propose a robust exploration scheme that maintains robust optimistic estimates of rewards at each state - action pair. They also extend this to the more general case where they modify the UCRL2 algorithm ( Auer et al., 2009 ) by maintaining robust estimates of the estimated rewards and transition probabilities. They show that an extension of a UCB style exploration scheme achieves an optimal penalty of $ O(T)$ in terms of time complexity."
SP:6d62a80aaebb2988df3953d4d7164e5a2fa1aa6d,"This paper proposes Rewriter - Evaluator, a neural machine translation ( NMT ) framework that consists of a rewriter and an evaluator. The rewriter produces a new translation to improve the past translation and the evaluators estimates the translation quality to decide whether to terminate the rewriting process. The authors also propose a prioritized gradient descent ( PGD ) method that facilitates training the rewriters and the Evaluators jointly. Extensive experiments on two translation tasks, Chinese - English and English - German, show that the proposed framework significantly improves the performance of NMT models and significantly outperforms previous baselines."
SP:9761fca8848868dfc9cacdab2537f8276ca76e0f,"This paper proposes a two - stage method to learn a multimodal predictive distribution for semantic segmentation. In the first stage, the authors model the data with a categorical likelihood, and in the second, they train an adversarial network to sample from it an arbitrary number of coherent predictions. The model can be used independently or integrated into any black - box segmentation framework to facilitate learning of calibrated stochastic mappings. The authors demonstrate the utility and versatility of the approach by attaining state - of - the - art results on the multigrader LIDC dataset and a modified Cityscapes dataset. In addition, they use a toy regression dataset to show that the core design can be adapted to other tasks."
SP:ce965758f1b795a56c02f45d6a8d06cb8bdf29cb,"This paper proposes a new approach for dealing with biased compressors. The main idea is to use unbiased compressors instead of contractive compressors, which are not unbiased. The authors propose a new construction for transforming any compressor into an unbiased one using a compressed EF - like approach. Besides theoretical superiority, the authors also provide an experimental evaluation on an array of classification tasks with CIFAR10 dataset corroborating their theoretical findings."
SP:4fd702490293e481c79614852ba27dd3ce9215a4,"This paper proposes a new research framework called hyperparameter transfer across adjustments ( HT - AA ) to speed up the development of machine learning ( ML ) algorithms. The authors provide four simple baseline algorithms and eight benchmarks changing various aspects of ML algorithms, their hyper parameter search spaces, and the neural architectures used. The best baseline, on average and depending on the budgets for the old and new HPO, reaches a given performance 1.2 – 3.6x faster than a prominent HPO algorithm without transfer. As HPO is a crucial step in ML development but requires extensive computational resources, this speedup would lead to faster development cycles, lower costs, and reduced environmental impacts."
SP:e8f99bae5853de525450fcb8facd23cf973fc161,"This paper proposes a new paradigm for image classification task by using speech as the supervised signal. The authors show that high dimensional, high entropy labels achieve comparable accuracy to text ( categorical ) labels on the standard image classification tasks. However, features learned through our label representations exhibit more robustness under various adversarial attacks and better effectiveness with a limited amount of training data. These results suggest that label representation may play a more important role than previously thought."
SP:4e8d924cba7367af0999b30d79250b4dc40413e1,"This paper proposes a method for training multiple independent subnetworks within a neural network. The main idea is to use a single model's capacity to train multiple subnets that independently learn the task at hand. By ensembling the predictions made by the subnets, the method improves model robustness without increasing compute. The method is evaluated on CIFAR-10, Cifar-100, and ImageNet, and compared to previous methods."
SP:d2f1c23b67c6744101034dc5e1c70765a733b169,"This paper proposes Sparse representation learning ( SRM ) to transfer intermediate knowledge from one CNN to another by utilizing sparse representation learning. SRM first extracts sparse representations of the hidden features of the teacher CNN, which are then used to generate both pixellevel and image - level labels for training intermediate feature maps of the student network. The authors formulate SRM as a neural processing block, which can be efficiently optimized using stochastic gradient descent and integrated into any CNN in a plugand - play manner. Extensive experiments demonstrate that SRM is robust to architectural differences between the teacher and student networks, and outperforms other KD techniques across several datasets."
SP:e8c0f43bd5debf6544f588cd3442dc3dd62d0eee,"This paper proposes a novel policy similarity metric ( PSM ) for measuring behavioral similarity between states. The PSM assigns high similarity to states for which the optimal policies in those states as well as in future states are similar. The authors also present a contrastive representation learning procedure to embed any state similarity metric, which they instantiate with PSM to obtain policy similarity embeddings ( PSEs ). Experiments show that the proposed method improves generalization on diverse benchmarks, including LQR with spurious correlations, a jumping task from pixels, and Distracting DM Control Suite."
SP:92f3b4942da9075440dda618f561a85f8fde5a5c,"This paper proposes a new approach to disentangle natural factors of variation in data ( e.g. object shape vs pose ) by using distributed equivariant operators in the latent space. The approach is motivated by the group representation theory. The authors show that this approach introduces topological defects ( i.e. discontinuities in the encoder ) for a broad family of transformations acting on images, including simple affine transformations such as rotations and translations. Moreover, the authors propose an alternative, more flexible approach, which relies on distributed equivarian operators, potentially acting on the entire latent space, and theoretically and empirically demonstrate the effectiveness of their approach. Their work lays a theoretical foundation for the recent success of a new generation of models using distributed operators."
SP:ef0f58c462bc5dd1c7b78f562c42a4e17f0f252b,"This paper proposes an EM algorithm to fit neural spike trains in the continuous - time regime. Three auxiliary latent variables are augmented to make the corresponding EM algorithm in a closed form to improve efficiency. The EM algorithm has analytical updates with drastically improved efficiency. As shown in experiments, the EM algorithm is even more efficient than the maximum likelihood estimation ( MLE ) for the parametric Hawkes process in high dimensional cases."
SP:1156d3deac022829bda930ffcb081947609d972b,"This paper studies the dynamics of gradient descent ( GD ) in two - layer neural network models under different parameter regimes. In the under - parameterized regime, the authors find that the neurons are divided into two groups : a group of a few ( maybe none ) “activated ” neurons that dominate the dynamics and a group "" quenched "" neurons that support the continued activation and deactivation process. In particular, when the target function can be accurately approximated by a relatively small number of neurons, this quenching - activation process biases GD to picking sparse solutions. This neural network - like behavior is continued into the mildly over - parameterized regime where it undergoes a transition to a random featurelike behavior where the inner - layer parameters are effectively frozen during the training process. This is qualitatively different from the GD dynamics associated with the "" mean - field "" scaling where all neurons participate equally and the test performance is much more robust to the change of network width."
SP:9e81401a6f30c70d870a12cce0cf600557f92b80,"This paper proposes a method to solve constrained Markov decision process ( CMDP ) problems by decomposing the CMDPs into a pair of MDPs : reconnaissance MDP ( R - MDP ) and planning MDP. In the former, the authors train a reward - seeking policy while using a fixed threat function to determine the safeness of each action. The latter, they use a generative model to predict the outcome of any given sequence of actions and initial state. The authors also present an efficient approximation method for the threat function that can greatly reduce the difficulty of solving R - RDP. They demonstrate the efficacy of their method over classical approaches in benchmark dataset and complex collision - free navigation tasks."
SP:f1d4ac7d5516dd0df742e224c8c09c721d0d0886,"This paper argues that the cross - entropy loss is not necessarily better than the square loss for training modern neural networks for classification tasks. The authors argue that there is little compelling empirical or theoretical evidence indicating a clear - cut advantage to the cross-entropy loss. They explore several major neural architectures and a range of standard benchmark datasets for NLP, ASR, and computer vision tasks to show that these architectures, with the same hyperparameter settings as reported in the literature, perform comparably or better when trained with square loss, even after equalizing computational resources. Cross - entropy appears to have a slight edge on computer vision task."
SP:915f1f0fc4850507c28c1d609239b41775863ebe,"This paper proposes a method to improve sample efficiency in reinforcement learning by augmenting reward maximization with self - supervised objectives based on structure in its visual input and sequential interaction with the environment. The proposed method, called Self - Predictive Representations ( SPR ), trains an agent to predict its own latent state representations multiple steps into the future using an exponential moving average of the agent ’s parameters and makes predictions using a learned transition model. On its own, this future prediction objective outperforms prior methods for sample - efficient deep RL from pixels. It further improves performance by adding data augmentation to the future prediction loss, which forces the agent to be consistent across multiple views of an observation. The experimental results show that SPR achieves a median human - normalized score of 0.415 on Atari in a setting limited to 100k steps of environment interaction."
SP:983f01c170909c8c67fd3be25f121bd61bdd8307,"This paper proposes an efficient method for generating single - node representations using local PageRank computations. The proposed method is based on the Personalized PageRank ( PPR ), which is a high - order similarity matrix based on which local node embeddings are computed via hashing. The authors provide theoretical guarantees on the locality of the computation, as well as the proof of the global consistency of the generated node embedding. Empirically, the authors show that their method is able to produce high - quality representations on par with state - of - the - art methods, with efficiency several orders of magnitude better in clock time and memory consumption."
SP:d11037b8fe2b10aee672ba82f69410b40181f0f9,"This paper proposes a method for graph coarsening based on graph neural networks. The main idea is to use the Laplace operator on the coarse graph and the associated projection / lift operators to choose the edge weights. The paper shows that the choice of edge weights for the coarse graphs may be suboptimal, and proposes a GNN - based method to learn the edge weight assignment map with GNN to improve the quality of the coarsing quality. Experiments show that the proposed method GOREN significantly improves the performance of the existing graph - based methods under different evaluation metrics."
SP:0d680213339f0e2aedb0be4aeed51423706b8bf6,"This paper presents a method to predict the scattering properties of 3D objects based on discrete - laplacian and implicit encoders. The method uses a point cloud approximation of each object, and each point is encoded in a high - dimensional latent space. The proposed method can accurately estimate these acoustic properties for arbitrary topologies and takes less than 1ms per object on a NVIDIA GeForce RTX 2080 Ti GPU. The authors also prove that their learning method is permutation and rotation invariant and demonstrate high accuracy on objects that are quite different from the training data."
SP:afc33a782c43e3d4c5c4fbf047d0b1108bc30bae,"This paper proposes Risk Extrapolation ( REx ), a method for robust optimization over perturbation set of extrapolated domains. REx is motivated as a form of robust optimization. The authors propose a penalty on the variance of training risks ( V - REx ) as a simpler variant. They prove that variants of REx can recover the causal mechanisms of the targets, while also providing some robustness to changes in the input distribution ( “ covariate shift ” ). By appropriately trading - off robustness and robustness, REx outperforms alternative methods such as Invariant Risk Minimization in situations where these types of shift co -occur."
SP:411d5bcf7698d534ad60f581d479ff74849ba4de,"This paper proposes a new neural operator for partial differential equations ( PDEs ). The proposed method is based on the Fourier operator, which can be seen as a generalization of the classical neural operator. The key idea is to parameterize the integral kernel directly in Fourier space, allowing for an expressive and efficient architecture. Experiments on Burgers ’ equation, Darcy flow, and Navier - Stokes equation demonstrate the effectiveness of the proposed method."
SP:41d268d0eac9b4c84baa156fb641aa6d3060b5a4,"This paper studies the implicit bias of gradient flow ( GD ) on linear neural networks. The authors propose a tensor formulation of neural networks that includes fully - connected, diagonal, and convolutional networks as special cases, and investigate the linear version of the formulation called linear tensor networks. With this formulation, the authors can characterize the convergence direction of the network parameters as singular vectors of a tensorsor defined by the network. For underdetermined linear regression, they prove that gradient flow finds a global minimum which minimizes a norm - like function that interpolates between weighted `1 and `2 norms in the transformed input space."
SP:e27907ef4a4e6e0f5841618fcaa7e7e0db443f91,This paper proposes a new training method for slimmable neural networks. The main idea is to jointly optimize the width - multipliers for different layers and the shared weights. The method is based on stochastic gradient descent ( SDE ). The proposed method is evaluated on two types of cost objectives : FLOPs and memory footprint. The results show that the proposed method outperforms the existing methods.
SP:cf59403abb6ca89ccee4f8e77e9a33d99e6a00f5,"This paper proposes a new method for federated semi - supervised learning ( SSL ), where each client only has access to partially labeled data and the rest of the data is only available at the server. The proposed method, FedMatch, is based on the idea of the "" label - at - client "" problem, where the labels are provided by the server but not by the clients. The authors propose a new loss function, called "" consistency loss "", which aims to maximize the agreement between the models trained at different clients, and the parameter decomposition for disjoint learning which decomposes the parameters into one for labeled and the other for unlabeled data for preservation of reliable knowledge, reduction of communication costs, and disjunction learning. Experimental results show that FedMatch significantly outperforms both local SSL methods and naive combinations of federated learning algorithms with SSL algorithms on diverse and realistic scenarios."
SP:9457b6d430a2cd864d526d7e90bf3e1ab13d6df4,This paper proposes a new self - supervised learning method for discrete event sequences. The main idea is to use contrastive learning to learn embeddings of discrete event sequence data. The proposed method is based on the idea of contrastive augmentation. The method is evaluated on several public datasets and showed to outperform other methods on different downstream tasks.  
SP:385942a5bcee7384bb722a1669b541f2fac0cd36,"This paper proposes a new unsupervised parsing method, StructFormer, that can induce dependency and constituency grammars at the same time. To this end, the authors propose a new parsing framework that can jointly generate constituency tree and dependency graph. Then they integrate the induced dependency relations into transformer, in a differentiable manner, through a novel dependency - constrained self - attention mechanism. Experimental results show that the proposed method can achieve strong results on un - supervised constituency parsing, un - supervision dependency parsing, and masked language modeling. The proposed model can leverage parsing results to achieve strong performance on masked language model tasks."
SP:078966ff62775bba6031e47d374bda95f4a7dde3,"This paper proposes a method to learn a metric between visual objects and scene graph nodes by incorporating information from both object features and relational features. The proposed method is evaluated on Visual Genome ( VG ) and Visual Relation Detection ( VRD ) datasets. Extensive experiments on VG and VRD datasets verify that the proposed method post an improvement on scene graph grounding task over current state - of - the - art approaches. Further experiments on scene Graph Parsing task verify the grounding found by our model can reinforce the performance of the existing method. Empirical results indicate that our grounding method outperforms existing mapping methods. Moreover, we also verify the value of our model in enhancing the performance on weakly supervised scene graph parsing."
SP:4644dbf7466b6234d8abf69995fdfb357efcc119,"This paper proposes a new relational discrepancy, named spherical sliced fused Gromov Wasserstein ( SSFG ), that can find an important area of projections characterized by a von Mises - Fisher distribution. Then, the authors introduce two variants of SSFG to improve its performance. The first variant, called MSSFG, replaces the vMF distribution by a mixture of von Mise - Fisher distributions to capture multiple important areas of directions that are far from each other. The second variant, named PSSFG, replaces vMF with a power spherical distribution to improve the sampling time in high dimension settings. The authors conduct extensive experiments to show that the new proposed autoencoders have favorable performance in learning latent manifold structure, image generation, and reconstruction."
SP:5ae2c0af82cac89a65f1cc38c43e2d05ea298901,This paper proposes a simple weight sharing method to speed up the training of deep networks with repeated layers and showed promising empirical results on BERT training. The method is motivated by the successes of weight sharing models in the literature as well as the theoretic analysis on deep linear networks. Empirical results show that the proposed method is able to reduce the training time of BERT by 50 %.
SP:a51710551142316b67e2fccd969fea1ece35ba39,"This paper studies the transferability of adversarial perturbations from the perspective of interactions between perturbation units based on game theory. The authors show that the multi - step attack tends to generate adversarial attacks with large interactions. They also provide a unified view to understand current transferability - boosting methods. To this end, the authors propose a new loss to penalize interactions during the attacking process to improve the adversarial transferability."
SP:f1565319075c1442c2cb52d96443facb492c06c2,"This paper studies catastrophic forgetting in deep neural networks. The authors analyze the role of different layers in catastrophic forgetting. They find that the forgetting is not evenly distributed throughout the layers, but concentrated at the higher layers. They also provide an analytic argument and empirical picture relating forgetting to task semantic similarity, where they find that maximal forgetting occurs for task sequences with intermediate similarity, and together these show that forgetting is most severe for tasks with intermediate similarities. They show that mitigation methods all stabilize higher layer representations, but vary on whether they enforce more feature reuse, or store tasks in orthogonal subspaces."
SP:30d7532cdcf420bff3be6b92eea3d93bce59e6bd,"This paper proposes an efficient training method for large - scale BERT models for both pre - training and fine - tuning. The proposed method is based on the Lottery Ticket Hypothesis, which proposes to prune the self - attention and fully - connected sub - layers inside a transformer to identify structured winning tickets in the early stage of BERT training. Extensive experiments on GLUE and SQuAD demonstrate that the proposed method can save 35 - 45 % training time without sacrificing accuracy, when compared to standard BERT with much less training time."
SP:c547f23ff6caaf5e9f35d258490b86ae0ac8ed03,"This paper studies the robustness of f - divergence measures in the presence of label noise. The authors derive a nice decoupling property for a family of robust f - divergences when label noise presents, where the divergence is shown to be a linear combination of the variational difference defined on the clean distribution and a bias term introduced due to the noise. In addition to the analytical results, the authors present thorough experimental evidence."
SP:841888179dcdac901889c8d62cb5234311fe28f1,"This paper proposes ensemble - based weighted Bellman backups, which re - weights target Q - values based on uncertainty estimates from a Q - ensemble. The authors show that the proposed method stabilizes and improves learning on both continuous and discrete control benchmarks. They also investigate the signal - to - noise aspect by studying environments with noisy rewards, and find that weighted bellman backups significantly outperform standard Bellman backup. Furthermore, the authors investigate the effect of UCB exploration on the performance of existing off - policy RL methods."
SP:afc08f203562b841180811aef943bfb63a1659ea,"This paper proposes a method for task calibration in the context of few - shot classification. Specifically, the authors propose to measure the distributional mismatch between support and query sets via class - wise similarities, and propose novel meta - training that lets the model predict with careful confidence. The proposed method is algorithm - agnostic and readily expanded to include a range of meta - learning models. Through extensive experiments including dataset shift, they present that their training strategy helps the model avoid being indiscriminately confident, and thereby, produce calibrated classification results without the loss of accuracy."
SP:12ae325ea3bce1e60195afac7d85895d2d20c29c,"This paper proposes a novel method for learning video - text - to - video representations. The main idea is to use a generative model to naturally push these related samples together. Specifically, the authors propose a weighted combination of other support samples ’ visual representations. This simple idea ensures that representations are not overly - specialized to individual samples, are reusable across the dataset, and results in representations that explicitly encode semantics shared between samples, unlike noise contrastive learning. The proposed method outperforms others by a large margin on MSR - VTT, VATEX, ActivityNet, and MSVD for video-to - text and text -to - video retrieval."
SP:8a71d8fad25a126aff01431cacf348c05de75667,"This paper proposes a novel method, seg tok, to re - build the vocabulary of Chinese BERT, with the help of Chinese word segmentation ( CWS ) and subword tokenization. The authors also propose three MVP strategies for enhancing the Chinese PLMs. Experiments show that the proposed method improves the performances of Chinese PLM on sentence level tasks, and MVP improves PLMs ’ downstream performance, especially the models ’ performance on sequence labeling tasks."
SP:b93ec7bc02b48068073ffe705f71d2643e663d51,"This paper proposes an unbiased boundary sampling strategy to enable efficient and scalable distributed GCN training while maintaining the full - graph accuracy. The proposed method is based on graph partition and distributed training for tackling the challenge posed by the GCN structures, especially the excessive amount of boundary nodes in each partitioned subgraph. Empirical evaluations and ablation studies validate the effectiveness of the proposed BDS - GCN, e.g., boosting the throughput by up to 500 % and reducing the memory usage by up - to 58 % for distributed GCNs training."
SP:2d4ba873d11e969ebd1fc31f9b5ab450c964d154,"This paper proposes a GNN - based model for predicting atomic force fields in quantum chemistry. The model is based on graph neural networks ( GNNs ) with message passing and non - linear activation functions. The proposed model is evaluated on the new large - scale quantum chemistry dataset OC20, which contains 200+ million atomic relaxations relevant to the discovery of new catalysts for renewable energy storage and other energy applications. The authors show that the proposed model reduces the estimation error of atomic forces by 30 % compared to existing ML models and generalizes well to out - of - distribution structures."
SP:8bdcf4fe6abf4739d4732b7ea8538513135dcccc,"This paper investigates different regularisation methods for fine - tuning deep learning networks. The authors provide two new bounds on the generalization performance of neural networks based on the distance of the final weights from their initial values. The MARS distance is a more appropriate metric in the parameter space of convolutional networks than Frobenius distance. Several new algorithms are presented that enable an experimental comparison between different regularization strategies. The empirical results corroborate the theoretical investigation, demonstrating that constraining MARS - based distance is more effective than constraining Euclidean distance."
SP:3a3249e97ef2345ea2264de5ed8287e16687838e,"This paper investigates the phenomenon of "" decoupled find - evaluation phenomenon "", where the hyperparameters for mask discovery ( Hfind ) and mask evaluation ( Heval ) decouple. The paper shows that different Hfind values yield masks with materially different layerwise pruning ratios and that the decoupling phenomenon is causally mediated by these ratios. The results show that this phenomenon holds across a number of models, datasets, configurations, and also for one - shot structured pruning."
SP:2d6f5d72b21675f74ff4cde4d16bfb36abd5795f,"This paper proposes a new metric called m - coherence to study the evolution of the alignment of per - example gradients in the course of training. The metric is more interpretable, cheaper to compute, and mathematically cleaner than other commonly used metrics such as O(m ) instead of O(M ). The paper also provides an interesting analysis of the recently proposed Coherent Gradients ( CG ) theory that provides a simple, unified explanation for memorization and generalization in neural networks."
SP:e7c5de9a475d0ba71bc79580e8436024fb2c6f59,"This paper proposes a neural - based approach to constructing low - dimensional sufficient statistics for likelihood - free inference in implicit generative models. The proposed approach is based on the infomax principle, where the neural network is used to learn the mutual information maximizing representations of the data with the help of deep neural networks. The method is applied to both approximate Bayesian computation and recent neural likelihood methods, boosting their performance on a range of tasks."
SP:c5997bf2348e94949684f45fbd418661e85220c1,"This paper proposes an unsupervised image - to - image translation model ( TUNIT ), which uses pseudo - labels to separate the image domains and translate the input images into the estimated domains. The idea is to use a guiding network to provide pseudo - label for the image translation task and an image - level model to translate the image into the pseudo - domain. The proposed model is evaluated on a variety of image datasets and shows comparable or better performance than the set - level supervised model trained with full labels."
SP:0cd97e64e638cabbeea0fdef3e9c5b33f4000f72,"This paper studies the implicit bias of gradient descent in function space of wide ReLU networks. The main result is to show that the training trajectory of the network outputs a function that interpolates the training data and has the minimum possible weighted 2 - norm of the second derivative with respect to the input. This corresponds to an spatially adaptive interpolating spline. This result can be interpreted as making the RKHS norm explicit, thus providing an interpretable description of the bias. The result generalizes to multivariate regression and different activation functions."
SP:8b885142facbb3b8db41ec9d83822cee81324694,This paper proposes a stable weight decay ( SWD ) method to fix the unstable weight decay problem from a dynamical perspective. The proposed SWD method uses a bias correction factor on decoupled weight decay to make weight decay more stable during training. The experimental results show that SWD makes significant improvements over L2 regularization and decouple weight decay in our experiments.
SP:a3206dc71e32ba1830895bf442d3840f3331a532,"This paper proposes a novel method to combine the strengths of both Translation Memory ( TM ) and Neural Machine Translation ( NMT ). The authors use the universal memory encoder to simultaneously encode the TM information and source sentence, and use the pointer - network to manipulate the information flow from TM to the NMT decoder. They also use the n - gram matching algorithm to find similar sentences, making it easier for them to obtain the training corpus of the TMGNMT model and expand the model ’s application scenarios. Experiments on English to French translation shows that the proposed models can significantly improve the translation quality and show strong adaptation for an unknown or new domain."
SP:72b43991a242872b2ceb1861e8ffbdf26c9f4818,"This paper proposes to interpret modern deep ( convolutional ) networks from the principles of rate reduction and ( shift ) invariant classification. The authors show that the basic iterative gradient ascent scheme for maximizing the rate reduction of learned features naturally leads to a deep network, one iteration per layer. The architectures, operators ( linear or nonlinear ), and parameters of the network are all explicitly constructed layer - by - layer in a forward propagation fashion. The results show that such a network can already learn a good discriminative deep representation without any back propagation training. Moreover, all linear operators of the so - derived network naturally become multi - channel convolutions when we enforce classification to be rigorously shift - invariant. Simulations and experiments on basic data sets clearly verify the so constructed ReduNet achieves the desired functionality and objective."
SP:f8b02cf1b918b0956761829ec6ef9127596071ec,"This paper studies the implicit acceleration of gradient flow in two - layer linear models. The authors show that implicit acceleration emerges from a conservation law that constrains the dynamics to follow certain trajectories. More precisely, gradient flow preserves the difference of the Gramian matrices of the input and output weights and the amount of acceleration depends on both the magnitude of that difference ( which is fixed at initialization ) and the spectrum of the data. In addition, and generalizing prior work, the authors prove their results without assuming small, balanced or spectral initialization for the weights, and establish interesting connections between the matrix factorization problem and Riccati type differential equations."
SP:e5f086c806be88d50e461a782b5b00124f4656fb,"This paper proposes a new explanation framework CLIME that is model - agnostic and can operate on constrained subspaces of inputs. The main contribution of this paper is to address the problem of out - of - distribution ( OOD ) sampling in the LIME framework, which is known to be unstable and susceptible to adversarial attacks as a result of the rigidity of the perturbation procedure. To address this issue, the authors propose a theoretically sound framework based on uniform sampling of user - defined subspace. Through logical constraints, they afford the end - user the flexibility to delineate the precise subspace of the input domain to be explained. This allows experts to drill down and uncover bugs and biases hidden deep inside the model. For testing the quality of generated explanations, they develop an efficient estimation algorithm that is able to certifiably measure the true value of metrics such as fidelity up to any desired degree of accuracy."
SP:b1d5ef15772e192eb8c8a0e65b3c21ee7c794295,"This paper proposes a novel pre - trained language model, called AMBERT, which uses both fine - grained and coarse - granular tokenization. The proposed model uses two encoders, one to process the sequence of words and the other to process sequence of phrases, and utilizes shared parameters between them. Experiments have been conducted on benchmark datasets for Chinese and English, including CLUE, GLUE, SQuAD, RACE, and CLUE."
SP:fd1cfe80343d3789227d99d836a5674374a234f5,"This paper proposes a new Transformer - based model for semantic parsing. The main idea is to incorporate LSTM into the Self - Attention mechanism of the original Transformer to capture more local context of phrases. Experimental results show that the proposed model captures the detailed meaning better than Transformer, raises local context awareness and achieves strong competitive performance on Geo, MSParS and Atis datasets, and leads to SOTA performance on Atis dataset."
SP:2056a65a7500d79465685af883083cd706277c1f,"This paper proposes CAT, a new adversarial training method to improve the robustness of deep neural networks ( DNNs ) against combinations of multiple perturbations. The authors propose a new class of adversarial attacks that “compose ” multiple adversarial perturbation models, which render most existing adversarial defense methods ineffective. To address this problem, the authors propose CAT, which is a novel training method that flexibly integrates and optimizes several adversarial losses, leading to significant robustness improvement with respect to individual perturbings as well as their “ composition ”. CAT outperforms other adversarial methods by large margins in defending against the compositions of pixel perturbational models and spatial transformations, while incurring limited impact on clean inputs."
SP:006e5b9ac9a8eb7223843731488bfefbd8eb09bd,"This paper proposes a new recurrent network architecture for learning abstract rules from images. The proposed architecture, called Emergent Symbol Binding Network ( ESBN ), is a recurrent network augmented with an external memory that enables a form of variable - binding and indirection. This binding mechanism allows symbol - like representations to emerge through the learning process without the need to explicitly incorporate symbol - processing machinery, enabling the ESBN to learn rules in a manner that is abstracted away from the particular entities to which those rules apply. The authors show that this architecture displays nearly perfect generalization of learned rules to novel entities given only a limited number of training examples, and outperforms a number of other competitive neural network architectures."
SP:4171ce45966ac499f51450a19fb233934c0847f0,"This paper proposes a new framework, TANL, to solve many structured prediction language tasks including joint entity and relation extraction, nested named entity recognition, relation classification, semantic role labeling, event extraction, coreference resolution, and dialogue state tracking. The authors frame it as a translation task between augmented natural languages, from which the task - relevant information can be easily extracted. The approach can match or outperform task - specific models on all tasks, and in particular, achieves new state - of - the - art results on several datasets. They accomplish this while using the same architecture and hyperparameters for all tasks and even when training a single model to solve all tasks at the same time ( multi - task learning ). Finally, the framework can also significantly improve the performance in a low - resource regime, thanks to better use of label semantics."
SP:8f1b2fc6829e0bdfcc981020b0dcf3e63a947910,"This paper studies the impact of unlabeled entities on NER models and how to effectively eliminate them. Through empirical studies performed on synthetic datasets, the authors find two causes : the reduction of annotated entities and treating unlabelled entities as training negatives. The first cause has fewer influences than the second one and can be mitigated by adopting pretraining language models. The second cause seriously misleads the models in training and greatly affects their performances. Based on the above observations, the paper proposes a novel method that is capable of eliminating the misguidance of unlabelling entities during training. The core idea is to apply negative sampling that avoids training NER model with unlabeling entities. Experiments on synthetic dataset and real - world datasets demonstrate that the model handles unlabeling entities well and significantly outperforms previous baselines."
SP:dd76ece8d92a8a230a8b43033d8cb2368c677a94,"This paper proposes a novel acoustic word embedding called Acoustic Neighbor Embeddings where speech or text of arbitrary length are mapped to a vector space of fixed, reduced dimensions by adapting stochastic neighbor embedding ( SN ) to sequential inputs. The Euclidean distance between coordinates in the embedding space reflects the phonetic confusability between their corresponding sequences. Compared to a triplet loss criterion, the proposed method is shown to have more effective gradients for neural network training. Experimentally, it also gives more accurate results with low - dimensional embeddings when the two encoder neural networks are used in tandem in a word ( name ) recognition task and when the text encoder network is used standalone in an approximate phonetic matching task."
SP:9142189126b8612ac0acee6fe18a0cfcb70b6545,"This paper proposes a reinforcement learning algorithm for stationary mean - field games, where the goal is to learn a pair of state and policy that constitutes the Nash equilibrium. The authors propose a fictitious play algorithm that alternatively updates the mean-field state and the policy via gradient descent and proximal policy optimization, respectively. The algorithm is in stark contrast with previous literature which solves each single - agent reinforcement learning problem induced by the iterates mean field states to the optimum. Furthermore, the authors prove that the algorithm converges to the Nash equilibria at a sublinear rate. To the best of the knowledge, this seems to be the first provably convergent RL algorithm for mean field games."
SP:c498f8a199da1818fe64ed88b0825c5aad688aec,"This paper proposes a method for approximate probabilistic inference on the joint distribution defined by a normalizing flow model. The authors first show that this task is computationally hard for a large class of flow models. Motivated by this hardness result, the authors propose a framework for approximate inference. Specifically, their method trains a new generative model with the property that its composition with the given model approximates the target conditional distribution. By parametrizing this new distribution as another flow model, they can efficiently train it using variational inference and also handle conditioning under arbitrary differentiable transformations. Since the resulting approximate posterior remains a flow, it offers exact likelihood evaluation, inversion, and efficient sampling. They provide an extensive empirical evidence showcasing the flexibility of our method on a variety of inference tasks with applications to inverse problems."
SP:1d0f27f61c9d32911b8bd15d6b82ef5eec644f0f,"This paper proposes a new high - resolution Electron Microscopy dataset, U - RISC, for cell membrane segmentation. The authors also propose a new evaluation criterion, called Perceptual Hausdorff Distance ( PHD ), to measure the quality of cell segmentation results. PHD is a human - perception based evaluation criterion based on human perception. Experiments on a small scale dataset show that the new criterion is more consistent with human perception, and the evaluation criteria of PHD and existing deep learning segmentation methods are re - examined."
SP:8ca7aff87c82be69c9542550c814f52c9419ab0a,"This paper proposes a new benchmark for continual learning ( CL ). The benchmark is based on the idea of modularization, where each task is solved by the composition of a handful of neural modules, which can be either borrowed from previous tasks or trained on the new task. The authors propose a task - driven prior over the exponential search space of all possible ways to combine modules, enabling efficient learning on long streams of tasks. The experiments show that this modular architecture and learning algorithm perform competitively on widely used CL benchmarks while yielding superior performance on the more challenging benchmarks."
SP:cc819c61f408e88f247eb87946187ccec3dad32e,"This paper proposes a generative model to generate synthetic meta - tasks for few - shot classification tasks. The proposed method is based on the idea of latent space interpolation ( LSA ), which is used to generate pairs of in - class and out - of - class samples from the latent space in a principled way to create synthetic classes for the training and validation data of a meta - task. The authors show that the proposed approach, LASIUM, outperforms or is competitive with current unsupervised learning baselines on the most widely used benchmark datasets on the Omniglot dataset."
SP:b25771e5c214a352f74ba6196fbd88bca6c43c98,"This paper studies the injectivity of fully connected and convolutional ReLU layers and networks. The authors show that an expansivity factor of two is necessary and sufficient for injectivity by constructing appropriate weight matrices. They show that global injectivity with iid Gaussian matrices, a commonly used tractable model, requires larger expansivity between 3.4 and 10.5. They also characterize the stability of inverting an injective network via worst - case Lipschitz constants of the inverse via differential topology. The results establish a theoretical basis for the study of nonlinear inverse and inference problems using neural networks."
SP:a95a153d3fe9bcf535ebf8514f51d00df483f210,"This paper proposes a continuous conditional generative adversarial network ( CcGAN ) for image generation conditional on continuous, scalar conditions ( regression labels ). The authors reformulate existing empirical cGAN losses to be appropriate for the continuous scenario, and propose a novel method to incorporate regression labels into the generator and the discriminator. Two empirical discriminator losses ( HVDL and SVDL ), a novel empirical generator loss and a novel label input method are proposed to overcome the two problems of existing cGANs. A new benchmark dataset, RC - 49, is also proposed for generative image modeling conditional on regression labels. The experiments on the Circular 2 - D Gaussians, RC-49, and UTKFace datasets show that the proposed model is able to generate diverse, high - quality samples from the image distribution conditional on a given regression label."
SP:10dd09ab315870631d1451d200f2c87a023f8226,"This paper proposes a method to combine active learning ( AL ) and semisupervised learning ( SSL ) to reduce the sample complexity of fully - supervised learning ( SL ). The authors argue that the diversity - based AL algorithms that seek diversity on labeled samples can be improved upon when using SSL as the training scheme, and propose an AL algorithm that instead focuses on controlling the convergence rate of a classification network by actively querying instances to improve the rate of convergence upon inclusion to the labeled set. They name this AL scheme convergence rate control ( CRC ), and their experiments show that a deep neural network trained using a combination of AL and SSL can quickly achieve high performance using far less labeled samples than SL."
SP:7f3947c3fa5b09674507d8f3e10d9280376ecb94,"This paper proposes FedDyn, a federated learning method for training neural network models. The proposed method is based on exact minimization, where at each round, each participating device updates its regularizer so that the optimal model for the regularized loss is in conformity with the global empirical loss. The authors show that their approach is fully agnostic to device heterogeneity and robust to large number of devices, partial participation and unbalanced data. They demonstrate both through empirical results on real and synthetic data as well as analytical results that their scheme leads to efficient training in both convex and non - convex settings."
SP:a3fbb073b0e2371b20d5d9df6ab829673f90354f,"This paper proposes a method to speed up the training of self - supervised learning algorithms by using contrastive learning. The main idea is to use intermediate contrastive losses to reduce the computational cost of gradient descent. The authors show that the intermediate loss is a good surrogate of the final similarity between the input and output images. To this end, the authors propose to truncate the back - propagation and update only a part of the parameters for each gradient descent update. They also do selection based on the intermediate losses to filter easy regions for each image. They apply their method to recently proposed MOCO, SimCLR, SwAV, and SwAV V2 and show that their method can save the training time with almost no loss on the final performance of the downstream tasks."
SP:5b5e705ea1ee1b857e17e64d560a39052804949d,"This paper studies the global convergence and global optimality of actor - critic. The authors focus on the more practical single - timescale setting, where the actor and critic are updated simultaneously. Specifically, in each iteration, the critic update is obtained by applying the Bellman evaluation operator only once while the actor is updated in the policy gradient direction computed using the critic. Moreover, the authors consider two function approximation settings where both the Actor and Critic are represented by linear or deep neural networks. For both cases, the actor sequence converges to a globally optimal policy at a sublinear O(K−1/2 ) rate, where K is the number of iterations. To the best of the knowledge, they establish the rate of convergence of single - timecale actor - Critic with linear function approximation for the first time. Also, under the broader scope of policy optimization with nonlinear function approximation, they prove that actorcritic with deep neural network finds the globally optimal policies at an O(1/3 ) rate."
SP:26705a4dc305cce336f657c5937d1f5b4209548a,"This paper proposes to represent log files in a vector - based way. The authors use a transformer network to encode numerical and textual information that is suitable for log embeddings. They show how a number of log processing applications can be readily solved with their representation.    The authors propose to represent logs at a few levels of abstraction including field level, log level, and sequence level. The representation for each level can be computed from the previous level. These representations are in vector format and serve as interfaces to downstream applications."
SP:165c51a16f17fb8726e968f8b34742b62011d60e,"This paper proposes a method to constrain the behavior of convolutional layers by splitting them into a succession of wavelet packet decompositions, which are modulated by freely - trained mixture weights. The method is motivated by the similarities between trained CNN kernels and oriented Gabor filters for addressing this problem. The authors evaluate their approach with three variants of the wavelet decomposition with the AlexNet architecture for image classification as an example. The first variant relies on the separable wavelet transform while the other two implement the 2D dual - tree real and complex wavelet transforms, taking advantage of their feature extraction properties such as directional selectivity and shift invariance. The experiments show that they achieve the accuracy rate of standard AlexNet, but with a significantly lower number of parameters."
SP:d0a284da462584724ba6a3a48c9e986d391233f6,"This paper proposes a coach - player framework for multi - agent reinforcement learning, where the players have a partial view of the environment, while the coach has a complete view. The coach coordinates the players by distributing individual strategies, and the players execute independently with local views and the coach ’s strategy. The authors propose a variational objective to regularize the learning and introduce an intuitive method to suppress unnecessary distribution of strategies. They also design an adaptive communication strategy to minimize communication from the coach to the agents. They apply their methods on resource - collection tasks in multiagent particle environments. The experimental results on the resource collection task demonstrate the effectiveness of the coach agent."
SP:4eb662b527d556758aaa1a0b589495fcc337fad0,"This paper provides a comprehensive analysis of the successes and failures of influence functions in deep learning with non - convex loss functions. The authors conduct extensive experiments on datasets including Iris, MNIST, CIFAR-10, Cifar-100, and ImageNet and architectures including LeNet, VGGNets, ResNets and ResNet-50. They show that the accuracy of influence estimates can vary significantly depending on the examined test points and the network architecture, depth and width of the network, as well as the extent of model parameterization and regularization techniques have strong effects on influence functions. These results suggest that in general influence functions are fragile and call for developing improved influence estimation methods to mitigate these issues in non convex setups."
SP:5fea74a2031d097a99dacf613bedcb054b0c3831,"This paper studies the connection between the pretraining task of next word prediction and text classification tasks. The authors hypothesize that classification tasks of interest can be reformulated as sentence completion tasks, thus making language modeling a meaningful pre - training task. Theorems 4.1 and 4.2 show that language models that are - optimal in cross - entropy ( log - complexity ) learn features that can linearly solve such classification tasks with O(\sqrt{\sqrt{O}(\epsilon ) ) error, thus demonstrating that doing well on language modeling can be beneficial for downstream tasks. They experimentally verify various assumptions and theoretical findings, and also use insights from the analysis to design a new objective function that performs well on some classification tasks, such as the Quad objective."
SP:a67da438e9821010284416170c3699ae7ff96c99,"This paper proposes a new method for membership inference attacks ( MIA ), which aims to detect if data samples were used to train a neural network model. The main idea is to use the reconstruction error of the training data to discriminate between easy and hard images. The authors propose to use a novel difficulty score that can be computed for each image, and its computation does not require a training set. The method is evaluated on an extensive number of benchmarks demonstrating its effectiveness compared to strong baseline methods."
SP:6fe23ebe09f2a4e42a21598f8e9c79edeca99863,"This paper proposes a differentiable architecture search method by formulating it into a distribution learning problem. The authors treat the continuously relaxed architecture mixing weight as random variables, modeled by Dirichlet distribution. This formulation improves the generalization ability and induces stochasticity that naturally encourages exploration in the search space. Furthermore, to alleviate the large memory consumption of differentiable NAS, the authors propose a simple yet effective progressive learning scheme that enables searching directly on large - scale tasks, eliminating the gap between search and evaluation phases. Extensive experiments demonstrate the effectiveness of the proposed method."
SP:c590d0ed2487b42480b53fc077546a4a0bc27a78,"This paper proposes a new class of function approximators for low - dimensional functions. The proposed method is based on the multiplicative filter networks ( MFNs ), which simply multiply together ( linear functions of ) sinusoidal or Gabor wavelet functions applied to the input. This representation has the notable advantage that the entire function can simply be viewed as a linear approximator over an exponential number of Fourier or Wavelet basis functions, respectively. Despite this simplicity, when compared to recent approaches that use Fourier features with ReLU networks or Sinusoidal activation networks, the proposed method largely outperforms or matches the performance of these approaches on the domains highlighted in these previous works."
SP:f5be855300f63c185a006834302bd4b033b56258,"This paper proposes a teacher - student scheme for the gradient - based meta - learning algorithms to allow them run more steps of inner updates to task - specific models while being immune to the risk of vanishing or exploding gradients. The key idea is to employ a student network to adequately explore the search space of task-specific models ( e.g., by more than ten steps ) and a teacher network to take a one - step "" leap "" toward the regions probed by the student. The teacher not only arrives at a high - quality model but also defines a lightweight computation graph for meta - gradientients. This approach is generic ; it performs well when applied to four meta learning algorithms over three tasks : few - shot learning, long - tail classification, and meta - attack."
SP:0361e02d56b7d121cb5ede1cb582284cc18fc599,"This paper proposes a behavior regularization method for offline reinforcement learning. The main idea is to use an analytical upper bound on KL divergence as the behavior regularizor to reduce variance associated with sample based estimations. The authors also employ state - dependent Lagrange multipliers for the regularization term to avoid distributing KL divergence penalty across all states of the sampled batch. To prevent catastrophic performance degradation due to rare out - of - distribution actions, the authors also add a gradient penalty term to the policy evaluation objective to penalize the gradient of the Q value w.r.t the out of distribution actions. The experimental results on challenging offline RL benchmarks illustrate the benefits of the improvements."
SP:b2cfb380aa2a21f72f508b453cf5949257a5b4ec,"This paper introduces Adjoined networks as a training approach that can regularize and compress any CNN - based neural architecture. The one - shot learning paradigm trains both the original and the smaller networks together. The parameters of the smaller network are shared across both the architectures. The authors prove strong theoretical guarantees on the regularization behavior of the adjoint training paradigm. They complement their theoretical analysis by an extensive empirical evaluation of both the compression and regularisation behavior of adjoint networks. For resnet-50 trained adjointly on Imagenet, they are able to achieve a 13.7x reduction in the number of parameters1 and a 3x improvement in inference time without any significant drop in accuracy. For the same architecture on CIFAR-100, they achieve a 99.7 x reduction in parameters and a 5x improvement on inference time."
SP:dba40073f79143e5355d194aa16db9eee0267a5d,"This paper proposes a new exploration method called z - greedy, which is an extension of greedy exploration. The authors argue that greedy exploration lacks temporal persistence, which limits the agent's ability to escape local optima. To address this limitation, the authors propose to replace actions with temporally extended sequences of actions, or options, to modulate the inductive bias associated with - greedy. Experimental results show that the proposed method outperforms greedy exploration on a large set of domains, including sparse - reward and dense - reward."
SP:5efb581a368ace3bd085d48801a899559d6a43ef,"This paper studies the implicit regularization properties of gradient flow in matrix factorization. The authors show that gradient flow with infinitesimal initialization is mathematically equivalent to a heuristic rank minimization algorithm, Greedy Low - Rank Learning ( GLRL ) under some reasonable assumptions. They also extend the results to the case where depth < 3, and show that the benefit of being deeper is that the above convergence has a much weaker dependence over initialization magnitude so that this rank minimisation is more likely to take effect for initialization with practical scale."
SP:7f997cf7a63a7330fc12fd525516080c91a3cb9b,"This paper proposes CAMEL, a two - stage framework for improving the robustness of classifiers. The first step is to learn a CycleGAN to learn the intra - class, inter - subgroup augmentations, and balance subgroup performance using a theoretically - motivated subgroup consistency regularizer, accompanied by a new robust objective. The second stage is to train a classifier with data augmentations that deliberately manipulate subgroup features. The authors demonstrate CAMEL ’s effectiveness on 3 benchmark datasets, with reductions in robust error of up to 33 % relative to the best baseline. Lastly, CAMEL successfully patches a model that fails due to spurious features on a real - world skin cancer dataset."
SP:de6cea1e35a0555175e17546a93422e9a96a511e,"This paper proposes a new classifier, named Rule - based Representation Learner ( RRL ), that learns interpretable nonfuzzy rules for data representation. To train the non - differentiable RRL effectively, they project it to a continuous space and propose a novel training method, called Gradient Grafting, that can directly optimize the discrete model using gradient descent. An improved design of logical activation functions is also devised to increase the scalability of RRL and enable it to discretize the continuous features end - to - end. Experimental results show that RRL enjoys both high classification performance and low model complexity on data sets with different scales."
SP:e36388a9452e557dd51bf0170bf2f9da22271a49,"This paper proposes a new regret minimization algorithm for biomedical applications. The proposed algorithm is based on the invariant risk minimization ( IRM ) algorithm. The main idea of IRM is to find a representation that enables the predictor to compete against an oracle with hindsight access to unseen domains. In this paper, the authors propose to use a modified IRM to find the representation that allows the model to compete with the oracle in the held - out environments. The authors also propose a structured extension adaptively highlights variation due to complex environments via specialized domain perturbations. The experimental results show that the proposed algorithm significantly outperforms previous state - of - the - art baselines."
SP:cad3ed2fba57faf17a3e8899dc5a744d5358aa68,"This paper proposes a novel architecture, cross - probe ( CP ) BERT, for effective and efficient cross - modal retrieval. The CP BERT relies on devised text and vision probes, and the cross - model attentions are conducted on a small number of probes, which is much more efficient than text - vision BERT. Systematic experiments conducted on two public datasets demonstrate the excellent effectiveness and efficiency."
SP:51fd82de525fcb738fdeaeeae20fbb2cdf975f0c,"This paper proposes a new type of Actor, named forward - looking Actor or FORK, for Actor - Critic algorithms. The proposed FORK can be easily integrated into a model - free ActorCritic algorithm. The experiments on six Box2D and MuJoCo environments with continuous state and action spaces demonstrate significant performance improvement for TD3 and SAC. A variation of TD3 - FORK further solves BipedalWalkerHardcore in as few as four hours with a single GPU."
SP:6e730239e6e8b43c4988dd61dca30f15dc039ef7,"This paper proposes a new aggregation method for federated learning, called FEDBE, which takes a Bayesian inference perspective by sampling higher - quality global models and combining them via Bayesian model Ensemble. The authors show that an effective model distribution can be constructed by simply fitting a Gaussian or Dirichlet distribution to the local models. Experiments on CIFAR-10/100 and Tiny - ImageNet show that the proposed method outperforms FEDAVG, especially when the neural networks go deeper."
SP:3ac5f437fc349a33810d0645664d1c448528af74,This paper presents a method for analyzing influence patterns in the BERT model. The main idea is to use the influence patterns to localize a DNN model ’s handling of a concept of interest. The authors show how to use multi - partite influence patterns and how BERT handles subject - verb number agreement and reflexive anaphora and quantitatively validate the sufficieny and sparsity of influence pattern in BERT by way of compression experiments and the influence concentration of discovered patterns.
SP:efa2343ead47263a0d09e1c17f9aa044605b9650,"This paper studies the training of a deep neural network from control theory perspective. The authors pose the supervised learning problem as a control problem by jointly designing loss function as Lyapunov function and weight update as temporal derivative of the LyapUNov function. Control theory principles are then applied to provide guarantees on finite time convergence and settling time of the neural network. Through experiments on benchmark datasets, the proposed method converges within the a priori bounds derived from theory. It is also observed that in some cases our method enforces faster convergence as compared to standard L1 and L2 loss functions."
SP:7a0ded4b3b2d08d43765ff7b722da9b9863aabd6,"This paper proposes a method to select informative latent variables for GIN - based flow - based models. The idea is to use the mutual information between each learned latent variables and the auxiliary variable to correctly identify informative latent variable. The paper shows that the MI criterion is not theoretically supported and can be disproved by experiments. Instead, the paper proposes to use a mutual information based on the auxiliary variables to select the informative variables. Experiments on synthetic data and real data show that the proposed method outperforms the VAR criterion."
SP:0d9ba12bbf47b13a46c2225f9dc06878418daaea,"This paper proposes a novel method for bidirectional pooling in convolutional neural networks. The proposed method is based on the classical Lifting Scheme from signal processing. The main idea is to decompose a feature map into sub - bands, each of which contains information with different frequencies. The down - pooling function is invertible, so the proposed method can be applied to any sub - band(s ) as the pooled result. Experiments show the proposed methods achieve better results on image classification and semantic segmentation using various backbones."
SP:147239edceb17bade6ea5d3dca44e3a59998aa47,"This paper proposes a fast, distance - preserving, binary embedding algorithm to transform a high - dimensional dataset T ⊆ R into binary sequences in the cube {±1}. When T consists of well - spread ( i.e., non - sparse ) vectors, the embedding method applies a stable noise - shaping quantization scheme to Ax where A is a sparse Gaussian random matrix. The authors show that Euclidean distances among the elements of T are approximated by the `1 norm on the images of {±2 } under a fast linear transformation. This again contrasts with standard methods, where the Hamming distance is used instead. The method is both fast and memory efficient, with time complexity O(m ) and space complexity $ \mathbb{O}(\sqrt{n})$ on well - spreading data. When the data is not well spread, the approach still works provided that data is transformed via a Walsh - Hadamard matrix, but now the cost is O(n log n ) per data point. Further, the authors prove that the method is accurate and its associated error is comparable to that of a continuous valued Johnson - Lindenstrauss embedding plus a quantization error."
SP:f65e229bca3904095743e7a501b1083cc60f1e22,"This paper proposes to use gradient descent ( GD ) to learn plasticity rules for the weights of RNNs. The authors argue that the plasticity rule can be learned by GD on the parameters of the RNN, and that this can be a missing ingredient for the development of ANNs that generalize well and are robust to adversarial perturbations. They provide both empirical and theoretical evidence for this hypothesis. In their experiments, the authors show that plasticityrules for the synaptic weights of recurrent neural nets are learned through GD and are found to perform reasonably well ( with no backpropagation ). In the special case of the last layer of a classification network, they show analytically that GD recovers ( and improves upon ) the perceptron algorithm and the multiplicative weights method. Finally, they argue that applying GD to learning rules is biologically plausible."
SP:f435530146fa975cb27cd375a857df9bcbd87682,"This paper proposes a method for visual question generation ( VQG ) with double hints. The key idea is to generate visual questions with answer - aware and region - aware features. The proposed method is based on Graph - to - Sequence ( GTS ) and Graph2Seq ( G2S ). The GTS is a graph - based model that learns the implicit topology end to end, and the GTS model is used to generate the visual questions. The method is evaluated on VQA2.0 and COCO - QA datasets. The results show that the proposed method outperforms the existing state - of - the - art."
SP:53a26ce11647866d3f6ba8b84ca9f13106197a8d,"This paper studies the effect of optimal regularization on the performance of linear regression algorithms. The authors show that for linear regression models with isotropic data distribution, optimally - tuned `2 regularization achieves monotonic test performance as we grow either the sample size or the model size. They also demonstrate empirically that the $ \ell_2 $ regularization can mitigate double descent for more general models, including neural networks."
SP:c193ccc74b987beaf8d53a29a8529a0af5e87742,"This paper proposes a spatial dependency layer ( SDN ) to improve the performance of variational autoencoders ( VAEs ). The proposed SDN is based on the idea of spatial dependency layers ( SDNs ), which is used to model the spatial coherence and long - range spatial dependencies in a VAE decoder. The authors show that the proposed SDNs can be applied to VAEs in a variety of settings. In the case of VAEs, SDNs are shown to outperform the state - of - the - art among the models within the same class. In a vanilla VAE setting, the authors find that a powerful SDN decoder also improves learning disentangled representations, indicating that neural architectures play an important role in this task."
SP:db91512a90e75675af03c2f197751c8526d6f5e9,"This paper proposes a simplified version of BCQ ( Fujimoto et al., 2018 ) for offline reinforcement learning, which removes a heuristic design choice and naturally restricts extracted policies to remain exactly within the support of a given behavior policy. The authors derive this simplified algorithm through the introduction of a novel backup operator, Expected - Max Q - learning ( EMaQ ), which is more closely related to the resulting practical algorithm. In addition to the distribution support, the authors explicitly consider the number of samples and the proposal distribution, allowing them to derive new sub - optimality bounds which can serve as a novel measure of complexity for offline RL problems. In the offline RL setting – the main focus of this work – EMaq matches and outperforms prior state - of - the - art in the D4RL benchmarks ( Fu et al, 2020a ) and SAC in the online RL setting. The key contributions of the empirical findings are demonstrating the importance of careful generative model design for estimating behavior policies and an intuitive notion of complexity."
SP:e2b80adeaa9208e0667a64a3f24661f77b48e487,"This paper proposes a batch selection method to improve model fairness in machine learning. The main idea is to use batch selection as an inner optimizer in SGD, where the outer optimizer is SGD with a batch size selection function. The authors show that this batch selection function can be applied to any pre - trained model, and it can be easily integrated with other batch selection techniques. The proposed method is evaluated on synthetic and real - world datasets, and compared with the state of the art."
SP:72f26b850bb2258223c0fc71598e35ad07d690e6,"This paper studies the bounds on the Lipschitz constant of monotone DEQs, a recently proposed class of impicit layer networks. The authors show that the monotonic DEQ has Lipsitz constants that can be bounded as a simple function of the strong monotonicity parameter of the network. They derive simple - yet tight bounds on both the input - output mapping and the weight -output mapping defined by these networks, and demonstrate that they are small relative to those for comparable standard DNNs. They also highlight how to use these bounds to develop PAC - Bayes generalization bounds that do not depend on any depth of network, and which avoid the exponential depth - dependence of comparable DNN bounds."
SP:bcfd4d7fd4590e3bc248a0a5422ce4b67db74a74,"This paper proposes a method for imitation learning and goal - conditioned reinforcement learning. In the imitation learning setting, the authors propose a method called Value Density Imitation Learning ( VDI ), which is based on UVD to match the expert's state - action distribution. In contrast to UVD, VDI uses demonstrations to generate goals rather than to train an intermediate network such as a discriminator or reward function. The value function and density estimate are trained using self - supervised roll - out alone, which makes intermediate networks much less prone to overfitting. The authors show that VDI can achieve state - of - the - art results on a common benchmark."
SP:d57550b2f323b356d7e609acc35ee33039f376b4,"This paper proposes a variational multi - task learning ( VMTL ) method that uses Gumbel - softmax priors to condition the prior of each task on related tasks. The proposed method is based on variational inference, where the posterior of a task is represented as a mixture of variational posteriors of other related tasks and the mixing weights are learned in a data - driven manner for each individual task. To further leverage the shared knowledge from related tasks, the authors introduce the Gumbels - Softmax prior to each task. The experiments show that the proposed method outperforms previous methods in terms of the average accuracy of all tasks."
SP:3ccdf8322f16c8a7bef82e32fad4c03969a510d1,"This paper proposes a systematic and unified benchmark, Long - Range Arena ( LRA ), to evaluate model quality under long - context scenarios. The proposed benchmark is a suite of tasks consisting of sequences ranging from 1K to 16K tokens, encompassing a wide range of data types and modalities such as text, natural, synthetic images, and mathematical expressions requiring similarity, structural, and visual - spatial reasoning. The authors systematically evaluate ten well - established long - range Transformer models ( Reformer, Linformers, Linear Transformers, Sinkhorn Transformers, Performers, Synthesizers, Sparse Transformers, and Longformers ) on the newly proposed benchmark suite.   The experimental results show that these tasks are very challenging even for long - distance models. Overall, there is no one - size - fits - all solution and trade - offs have to be made in terms of model quality and speed / memory."
SP:e12e410c3335b76133ceda4c865b244fbbab8580,"This paper proposes a multilingual code summarization model that uses only language - agnostic features, i.e., source code and features that can be computed directly from the abstract syntax tree ( AST ). The main contribution of this paper is that it proposes a new model that jointly learns on Context and Structure of source code. This model is called Code Transformer, and it is trained on all five languages for singlelanguage training, and also train the first multilingual model for code summarisation. The model is evaluated on the monolingual data from multiple programming languages, where the strongest gains are on low - resource languages."
SP:f46e98d48f90071831f1c0069bf74a7993be6db8,"This paper proposes a reinforcement learning approach for audio - visual navigation. The key idea is to use an acoustic memory to learn to set the waypoints in an end - to - end fashion. The proposed approach is evaluated on two datasets of real - world 3D scenes, Replica and Matterport3D. The results show that the proposed approach outperforms the state - of - the - art."
SP:23bfe317dcef00a91ea92389b3f39d9b93972454,"This paper investigates the effect of weight initializations on the performance of small convolutional neural networks trained to predict n steps of the two - dimensional cellular automaton Conway’s Game of Life. The authors find that networks of this architecture trained on this task rarely converge, rather, networks require substantially more parameters to consistently converge. Furthermore, they find that the initialization parameters that gradient descent converges to a solution are sensitive to small perturbations, such as a single sign change. Finally, they observe a critical value d0 such that training minimal networks with examples in which cells are alive with probability d0 dramatically increases the chance of convergence to the solution."
SP:1b5ba618d3e28d48f9205c0780f8288a08fa5392,"This paper proposes RankingMatch, a semi - supervised learning ( SSL ) method that combines the idea of consistency regularization and metric learning. The authors introduce a new objective function, BatchMean Triplet loss, which takes into account all input samples. The proposed RankingMatch achieves state - of - the - art performance across many standard SSL benchmarks with a variety of labeled data amounts."
SP:f3abccf4a2566ffbc821aba209fab15058639ad4,"This paper studies the problem of few - shot meta - learning in the context of a sequence of tasks, where data for each new task arrives incrementally. Motivated by the challenges of this setting, the authors introduce a variable - shot algorithm that optimizes for good performance after adapting with varying amounts of data. Their approach introduces a scaling rule for the learning rate that scales with the number of shots. Theoretically, they theoretically derive an algorithm that adapts to the variable amount of data and combine it with deep neural networks for effective online learning on challenging sequential problem settings. They find that their approach can outperform empirical risk minimization and a previous online meta learning method ( Finn et al., 2019 ) on two online image classification problems consisting of sequences of classification tasks and one online regression problem. Further, they find that, in the offline setting, their approach performs comparably to previous state - of - the - art algorithms in few shot learning, and provides considerable gains in the variable-shot setting."
SP:95cb420d92ec42e12a4bbb0e66224f1c498a7161,"This paper presents a series of probes designed to test the sensitivity of Transformer representations to several kinds of structure in sentences. Each probe involves swapping words in a sentence and comparing the representations from perturbed sentences against the original. The authors also connect their probe results to the Transformer architecture by relating the attention mechanism to syntactic distance between two words. Results from the three probes collectively suggest that Transformers build sensitivity to larger parts of the sentence along their layers, and that hierarchical phrase structure plays a role in this process. In particular, sensitivity to local phrase structure increases along deeper layers."
SP:cb27b27a6fefc192ad1c2bd083d13eb9e51a5c44,This paper proposes a new GAN architecture for few - shot image synthesis. The proposed architecture is based on a skip - layer channel - wise excitation module and a self - supervised discriminator trained as a feature - encoder. The model can be trained on a few hours of training on a single Nvidia GPU. The paper shows that the proposed architecture can generate images with better quality than StyleGAN2 on high - resolution images.
SP:c0dbeb5d94b2388595cf7ad9675c55df0bac7f8e,"This paper proposes a specialised specialised dual solver for neural network bounding. The main idea is to use a linear program of size linear in the number of neurons instead of the usual linear program which is usually used in the literature. The authors propose a novel dual algorithm that realises the full potential of the new relaxation by operating on a small active set of dual variables. The method recovers the strengths of the relaxation in the dual space : tightness and a linear separation oracle. At the same time, it shares the benefits of previous dual approaches for weaker relaxations : massive parallelism, GPU implementation, low cost per iteration and valid bounds at any time. As a consequence, the authors obtain better bounds than off - the - shelf solvers in only a fraction of their running time and recover the speed - accuracy trade - off of looser dual solvers if the computational budget is small."
SP:56e3837417dbcce0d65338dc3aac4e1a20eb0df8,"This paper proposes a concept - aware language model ( CALM ) to improve the commonsense learning capability of pre - trained text - to - text transformers. The authors propose both generative and contrastive objectives for learning common sense from the text, and use them as intermediate self - supervised learning tasks for incrementally pre - training PTLMs ( before task - specific fine - tuning on downstream datasets ). In addition, the authors develop a joint pretraining framework to unify the objectives so that they can mutually reinforce each other. Extensive experimental results show that the proposed method, CALM, can pack more commonsense knowledge into the parameters of a pre - train text to text transformer without relying on external knowledge graphs, yielding better performance on both NLU and NLG tasks."
SP:7ec69bdee021af506293c87a3b75bce1c40a03d7,"This paper proposes a method for unsupervised physical object discovery using self - supervised learning. The proposed method uses multi - scale pixel cues and physical motion cues to accurately segment observable and partially occluded objects of varying sizes, and infer properties of those objects. The model reliably segments objects on both synthetic and real scenes. The discovered object properties can also be used to reason about physical events."
SP:66997bc19a3ba6548fcf21f114e748bea95cad1c,"This paper proposes a novel method, Increasing Margin Adversarial ( IMA ) Training, to improve the robustness of deep neural networks for classification tasks. Specifically, the proposed method increases the margins of training samples by moving the decision boundaries of the DNN model far away from the training samples to improve robustness. The IMA method is evaluated on six publicly available datasets ( including a COVID - 19 CT image dataset ) under strong 100 - PGD white - box adversarial attacks. The proposed method significantly improved classification accuracy on noisy data while keeping a relatively high accuracy on clean data. The authors also tested the effect of adding uniform white noises to the images. The results show that IMA has the strongest overall performance and MMA is slightly better than IMA."
SP:276ffd59fbf49e3ee02756da8920218102214917,"This paper proposes ProKT, a model - agnostic knowledge distillation method that uses a dynamic teacher model to learn a compact student network. The proposed method is based on the idea of mirror descent, where the progressive teacher is aware of the learning process of the student. The method is evaluated on both image and text classification tasks. The results show that the proposed ProKT outperforms the vanilla knowledge distillations approach consistently."
SP:906dc21d6988953fcf57d63bbdd12973e5818d16,This paper proposes a new channel pruning method to solve the problem of compression and acceleration of Convolutional Neural Networks ( CNNs ). The proposed method uses a hyper - structure network ( HSN ) to generate the architecture of the main network and a regularization term to specify the computational resource of the compact network. Extensive experiments on CIFAR-10 and ImageNet show that the proposed method can outperform both conventional channel pruned methods and AutoML based pruning methods on ResNet and MobileNetV2.
SP:890fd9454596c051b0e9535baf73b1dd1fae67ca,"This paper presents a method for theorem proving in the presence of a large knowledge base of potential premises without learning from human proofs. The method is based on the exploration of premises based on a simple tf - idf ( term frequency - inverse document frequency ) based lookup in a deep reinforcement learning scenario. The authors show that their theorem prover trained with this exploration mechanism but no human proofs, dubbed DeepHOL Zero, outperforms provers that are trained only on human proofs and approaches the performance of a prover that is trained by a combination of imitation and reinforcement learning."
SP:88209417a8ad07e6103084e41709be900303ce5f,"This paper proposes MODALS ( Modalityagnostic Automated Data Augmentation in the Latent Space ) to augment data for any modality in a generic way. MODALS exploits automated data augmentation to fine - tune four universal data transformation operations in the latent space to adapt the transform to data of different modalities. The proposed method is tested on text, tabular, time - series, and image data and can be readily integrated with popular deep learning models."
SP:6d84670d321b0d584b097c630574bd748e85c9a2,"This paper provides a global convergence result for unregularized feedforward three - layer neural networks in the mean field regime. The authors first develop a rigorous framework to establish the mean - field limit of three - layers networks under stochastic gradient descent training. To that end, they propose the idea of a neuronal embedding, which comprises of a fixed probability space that encapsulates neural networks of arbitrary sizes. The identified mean field limit is then used to prove the global convergence guarantee under suitable regularity and convergence mode assumptions, which – unlike previous works on two - layer networks – does not rely critically on convexity."
SP:b90f893f927db9c439595fd119a565cf43c971f4,"This paper proposes a method for learning explanations of expert decisions by modeling their reward function in terms of preferences with respect to “ what if ” outcomes : Given the current history of observations, what would happen if we took a particular action? To learn these costbenefit tradeoffs associated with the expert ’s actions, the authors integrate counterfactual reasoning into batch inverse reinforcement learning. This offers a principled way of defining reward functions and explaining expert behavior, and also satisfies the constraints of real - world decision - making — where active experimentation is often impossible ( e.g. in healthcare ). Additionally, by estimating the effects of different actions, this method readily tackle the off - policy nature of policy evaluation in the batch setting, and can naturally accommodate settings where the expert policies depend on histories of observations rather than just current states. Through experiments in both real and simulated medical environments, this paper demonstrates the effectiveness of the proposed method in recovering accurate and interpretable descriptions of behavior."
SP:c92916780418bfa7f0796fd9766b6d28b9eea5ef,"This paper investigates the role of explicit morphological information in graph - based continous control. It ablated existing methods SMP and NERVENET, providing evidence against the belief that these methods improve performance by exploiting morphological structure encoded in graph edges. Motivated by the hypothesis that any benefits GNNs extract from the graph structure are outweighed by difficulties they create for message passing, they also propose AMORPHEUS, a transformer - based approach. The results on incompatible MTRL continious control benchmarks strongly support our hypothesis : AMOR PHEUS substantially outperforms existing GNN - based alternatives with fixed message - passing schemes in terms of sample efficiency and final performance. In addition, AMORPhEUS exhibits nontrivial behaviour such as periodic cycles of attention masks coordinated with the gait."
SP:2cf58f5cac20dccdc2034ef60e8e46b7988ebd7d,"This paper proposes a method for visual counting, which aims to predict the number of occurrences given a natural image and a query. Unlike most prior works that use explicit, symbolic models which can be computationally expensive and limited in generalization, the authors propose a simple and effective alternative by revisiting modulated convolutions that fuse the query and the image locally. Following the design of residual bottleneck, they call their method MoVie, short for Modulated ConVolutional Bottlenecks, and it only needs a single forward - pass during inference. The authors show strong performance for counting : 1 ) advancing the state - of - the - art on counting - specific VQA tasks while being more efficient ; 2 ) outperforming prior - art   on difficult benchmarks like COCO for common object counting ; 3 ) helped us secure the first place of 2020 VQ a challenge when integrated as a module for ‘ number ’ related questions in generic VQ models. Finally, they show evidence that Modulated Convolution can serve as general mechanism for reasoning tasks beyond counting."
SP:c64e77507e562f236cb69361b22fb1a7951ffb22,"This paper proposes a model - targeted poisoning attack that can target a desired model based on online convex optimization. The authors prove that the model induced by training on the original training data with these points added, converges to the target classifier as the number of poison points increases, given that the loss function is convex and proper regularization is adopted in training. They also provide a lower bound on the minimum number of poisoning points needed to reach the target model ( Theorem 4.2 ), which can be used to estimate the optimality of model - targeted poisoning attacks and also indicate the intrinsic hardness of attacking different targets. The attack is also efficient in incremental poisoning scenario as it works in an online fashion and can incrementally find poisoning points that are nearly optimal."
SP:a526023ec4cb839b83c574d31f59a9a67bc7af00,"This paper proposes a new method to improve the performance of point cloud image classification models. The proposed method is based on the idea of entropy - maximizing aggregation ( EMA ), which modulates the distribution before aggregation for the maximum information entropy, and layer - wise scale recovery ( LSR ) to restore feature representation capacity. Extensive experiments show that BiPointNet outperforms existing binarization methods by convincing margins, at the level even comparable with the full precision counterpart."
SP:825b4d1db0c537a607655bb5b4bf221ec672c8af,"This paper proposes three variants of the Transformer architecture : MemTransformer, MemCtrl, and MemBottleneck. The main idea is to add memory to the encoder - decoder architecture of Transformer to allow it to process both local and global information. The authors show that adding memory can improve the performance of the model on a variety of tasks, including language modeling, machine translation, and question answering. The paper also shows that the model is able to control the amount of memory used by the model."
SP:f0fa1b7684bc605f6edd4813c44be20988fe8b4c,"This paper presents Prototypical Contrastive Learning ( PCL ), an unsupervised representation learning method that bridges contrastive learning with clustering. Specifically, PCL introduces prototypes as latent variables to help find the maximum - likelihood estimation of the network parameters in an Expectation - Maximization framework. PCL learns an embedding space which encodes the semantic structure of data, by training on the proposed ProtoNCE loss. The experiments show that PCL outperforms state - of - the - art instance - wise contrastive methods on multiple benchmarks with substantial improvement in low - resource transfer learning."
SP:5342a5e1d87fd17b1a2efed967dbbfeafa440ee7,This paper proposes an orthogonal multi - path ( OMP ) block to improve the robustness of deep neural networks against adversarial attacks. The proposed OMP block consists of two steps : 1 ) a forward - backward correction step to force the neural network to learn features that are appropriate for all the paths and 2 ) a follow - up step to learn to fit all paths and correct the features learned by the front layers. The authors conduct experiments to show the effectiveness of the proposed method against white - box and black - box attacks.
SP:776df66274ed12449fde8dcef873a593980f397c,"This paper proposes a self - supervised graph attention network ( SuperGAT ), an improved graph attention model for noisy graphs. Specifically, they exploit two attention forms compatible with a self supervised task to predict edges, whose presence and absence contain the inherent information about the importance of the relationships between nodes. They find two graph characteristics influence the effectiveness of attention forms and self - supervision : homophily and average degree. Thus, their recipe provides guidance on which attention design to use when those two graphs characteristics are known. Their experiment on 17 real - world datasets demonstrates that their recipe generalizes across 15 datasets of them and their models designed by recipe show improved performance."
SP:80a05296d6b1e4c6e9e2df01938c73029ff8487d,"This paper proposes a novel DSMAD agent, called Introspective Diagnosis System ( INS - DS ), which is based on the introspective decision - making process of human doctors. Specifically, the inquiry module is responsible for selecting the most valuable symptom to be inquired about, while the introspection module intervenes the potential answers of this inquiry to decide whether to inquire the symptom or inform the disease. The authors also propose two evaluation metrics to validate the reliability and robustness of DSMAD methods. Extensive experimental results demonstrate thatINS - DS achieves the new state - of - the - art under various experimental settings and possesses the advantages of reliability and reliability compared to other methods."
SP:10ae09d90d465125433a9b4f15b1405ab017920d,"This paper proposes a method to address the long - tailed and inter - class differences in the natural world distribution of fine - grained visual classification ( FGVC ). The authors propose a new regularization method called Batch Confusion Norm ( BCN ), which is based on the idea of batch - wise matrix norm ( BNN ). In particular, the authors propose to use the BNN as a regularizer to deal with the long tailed distribution of the data. The proposed method is evaluated on three different FGVC datasets, and the authors show that the proposed method outperforms the existing methods on all three datasets."
SP:90f1e0fe1e9678d1e9a4dcb519d4e8fd61098ce0,This paper proposes a new algorithm for the inverse reinforcement learning problem. The main idea is to learn an approximate posterior distribution over the reward that scales to arbitrarily complicated state spaces. The posterior distribution is learned using a variational approach to the latent reward. The proposed method is evaluated on real - world medical data and control simulations. The results show that the proposed method outperforms other baselines.
SP:ccd251d95c0a2d8dc5ad2a148ec29955e105e71e,"This paper proposes a method for performing belief search in partially observable POMDPs. The key idea is to use an auto - regressive counterfactual model to generate an approximate belief for any given AOH, which is then used to perform belief search. The method is applied to two - player Hanabi self - play and multi - agent Hanabi. The results show that the proposed method outperforms the state - of - the - art in Hanabi by a large margin. The proposed method can also be applied to multi - step search."
SP:db408e6bfe69a9b3984f3b27ca92b802aa37af42,"This paper proposes a new algorithm, Shoot Tree Search ( STS ), which aims to address the dilemma between depth and breadth search in large state spaces. The core improvement is multi - step expansion, which may be used to control the depth of search and inject into planning more randomness via random multi - steps. The authors show that STS can get the best of both worlds consistently achieving higher scores. The experiments show that the effectiveness of STS stems from better balance between breadth and depth search."
SP:5efc271ccc555fd9aa542548838170bd4c98e957,"This paper proposes a new pre - training method called LIME ( Learning Inductive Bias for Mathematical rEasoning ), which aims to learn inductive bias in the form of datasets. The authors design three synthetic tasks that are intended to require the model to have these three reasoning primitives : deduction, induction, and abduction. They specifically design these synthetic tasks in a way that they are devoid of mathematical knowledge to ensure that only the fundamental reasoning biases can be learned from these tasks. This defines a new pretraining methodology called “ LIME ”. LIME significantly outperforms vanilla transformers on three large mathematical reasoning benchmarks."
SP:bb8e0b554d3b3314fa343c902d9e60f1a141ea30,"This paper analyzes the inductive bias of gradient descent for weight normalized smooth homogeneous neural nets, when trained on exponential or cross - entropy loss. The analysis focuses on exponential weight normalization ( EWN ), which encourages weight updates along the radial direction. This paper shows that the gradient flow path with EWN is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. These results can be extended to hold for gradient descent via an appropriate learning rate. The authors contrast these results with standard weight normalisation ( SWN ) and unnormalized architectures, and demonstrate their implications on synthetic data sets."
SP:c71f9d2a602516865a0b103028186e83b52e5f00,"The paper proposes a method to address the mode collapse problem in GANs. The paper argues that mode collapse is caused by the discriminator “ catastrophic forgetting ”, which is the inability to maintain classification accuracy on previously seen samples. Motivated by this observation, the paper introduces a novel training procedure that dynamically spawns additional discriminators to remember previous modes of generation. Experiments show that the proposed method can be added to existing GAN frameworks to prevent mode collapse, generate more diverse samples and improve FID & IS."
SP:52c48198c95826e042f9e5a512ef3265daaff882,"This paper proposes an approach to regularize BERT by pruning attention heads based on a proxy score for head importance. The paper proposes to use reinforcement learning to learn a pruning policy that determines which attention heads should or should not be pruned for regularization. Experimental results show that AUBER outperforms existing pruning methods by achieving up to 9.39 % better accuracy. In addition, the ablation study empirically demonstrates the effectiveness of the design choices for aUBER."
SP:abcbbad146f1b0d5d579c215952c95e5499a378a,"This paper proposes a method to learn correspondence between two domains, i.e., simulation and real - world robotics. The method is based on dynamics cycle - consistency, which aims to align dynamics trajectories across two domains using a cycle - consistent constraint. The proposed method is evaluated on a variety of problem domains, both in simulation and on a real robot. The experiments show that the proposed method can find correspondence and align two domains across different modalities, physical parameters, and morphologies. Given the alignment, the method can transfer a reinforcement learning policy trained in one domain directly to another domain without further optimizing the RL objective."
SP:006434d56992836ab9420d7d4215bc70664de304,"This paper studies the problem of on - manifold Shapley values for explainability in machine learning. The paper argues that off - manifold values are untenable because of the assumption that the model ’s features are uncorrelated. To address this problem, the paper proposes two methods : 1 ) generative modelling, which learns to learn the Shapley value function, and 2 ) directly learns the value function. Experiments on synthetic and real - world datasets show that the proposed methods outperform the existing methods."
SP:7cda6bccf08887c7cef66d0ac3ccefdea8f5d7c8,"This paper proposes a VAE - based method for learning an opponent model for multi - agent reinforcement learning. The proposed method is based on variational autoencoders, which are trained to reconstruct the local actions and observations of the opponent based on embeddings which depend only on the local observations. The embedding is used to augment the modelling agent ’s decision policy which is trained via deep reinforcement learning, and thus the policy does not require access to opponent observations. Experiments are conducted on two benchmark environments : multi - agents particle environment and level - based foraging. Results show that the proposed method can achieve comparable performance to an ideal baseline which has full access to the opponent's information."
SP:c239bc531bcf7293032748af29a1b786e9d893dd,"This paper proposes Consistent Contrastive Learning ( CO2 ), a method for contrastive learning on unlabeled images. CO2 is inspired by consistency regularization in semi - supervised learning. The authors propose to use the similarity between the query crop and other crops from other images as a pseudo label, which encourages consistency between these two similarities. Experiments show that CO2 improves Momentum Contrast ( MoCo ) by 2.9 % on top - 1 accuracy on ImageNet linear protocol, 3.8 % and 1.1 % top - 5 accuracy on 1 - 10 % labeled settings on PASCAL VOC. It also transfers to image classification, object detection, and semantic segmentation."
SP:d18bab21790713e2facb053c47298fc9079ab783,"This paper studies the last - iterate convergence of the Optimistic Gradient Descent Ascent ( OGDA ) and Optimistic Multiplicative Weights Update ( OMWU ) for bilinear games over the probability simplex. The authors show that when the equilibrium is unique, linear last - iteration convergence is achieved with a learning rate whose value is set to a universal constant, improving the result of ( Daskalakis & Panageas, 2019b ) under the same assumption. Then, the authors extend the results to more general objectives and feasible sets for the projected OGDA algorithm, by introducing a sufficient condition under which OGDA exhibits concrete last -iterate convergence rates with a constant learning rate, whose value only depends on the smoothness of the objective function. The paper also provides experimental results to support the theory."
SP:bbc7f77308b298c332a39747f693bc396f00a89f,"This paper proposes FedUV, a framework for private and secure training of UV models in federated setup. The main idea of FedUV is to jointly learn a set of vectors and maximize the correlation of their instance embeddings with a secret user - defined linear combination of those vectors. The authors show that choosing the linear combinations from the codewords of an error - correcting code allows users to collaboratively train the model without revealing their embedding vectors. They show the experimental results for user verification with voice, face, and handwriting data and show that FedUV performs on par with existing approaches, while not sharing the embedding vector with other users."
SP:40fa47cc0928e2925ef5ce6d808073f368ca2cd4,"This paper proposes a new method to estimate the effective dimension of class manifolds ( CMs ) in the space of inputs for deep neural network classifiers. The authors propose to do so by computing the intersection with random affine subspaces of varying dimension. They provide a theory for the technique and verify that their theoretical predictions agree with measurements on real neural networks. Through extensive experiments, they leverage this method to show deep connections between the geometry of CMs, generalization, and robustness. In particular, they investigate how CM dimension depends on 1 ) the dataset, 2 ) architecture, 3 ) random initialization, 4 ) stage of training, 5 ) class, 6 ) ensemble size, 7 ) label randomization, 8 ) training set size, and 9 ) model robustness to data corruption."
SP:09bce202ac7a750c3700a8ef3cd92cfe8ed00c39,"This paper proposes a novel method to improve the performance of the Soft Actor - Critic ( SAC ) algorithm. The method is based on the idea that the agent should explore more in an unfamiliar state, while less in a familiar state, so as to understand the environment more efficiently. To this end, the paper proposes to use the curiosity mechanism in developing an instance - level entropy temperature for SAC, which utilizes the state prediction error to model curiosity. The paper also proposes a new prediction - based model, X - RND, which is optimized by contrastive self - supervised learning. Experimental results on the difficult MuJoCo benchmark show that the proposed method significantly improves the sample - efficiency on complex and difficult continuous control tasks."
SP:dce5eb20581a21c5de0a9fc07a8a79a1fbb28c71,"This paper proposes a method for meta - reinforcement learning based on model identification and experience relabeling ( MIER ). The main idea is to adapt the dynamics model first by adapting the model first, and then relabel the data from the meta - training tasks with this model, and fine - tune on that data using a standard off - policy RL method. Experiments show that MIER outperforms prior meta - RL methods in the out - of - distribution setting."
SP:34d78aa11f9d50baf75a9646a6f9128318c3389a,"This paper proposes a method to address the problem of meta - overfitting in few - shot learning ( FSL ). In particular, the authors cast the problem as a gradient - based meta - learning problem and propose Eigen - Reptile ( ER ), which updates the meta - parameters with the main direction of historical taskspecific parameters to alleviate gradient noise. The main direction is computed by a special mechanism for the parameter ’s large size. The authors also propose Introspective Self - paced Learning ( ISPL ) that constructs a plurality of prior models to determine which samples should be abandoned to get a more accurate main direction. The effectiveness of ER and ISPL are proved theoretically and experimentally."
SP:a571bff9ffe4edafd7bc064c4d10609e6b981ce3,"This paper proposes Adversarial Batch Normalization ( AdvBN ), an adversarial training method to improve the robustness of image classification models. The AdvBN is based on adversarial perturbations of the mean and variance of the feature statistics of the input images, which are then used to fine - tune the classifier. The authors show that the AdvBN can improve the performance of ResNet-50 on ImageNet-C, Stylized - ImageNet, and ImageNet - Instagram."
SP:6a9c46bd3cf854299f360bff136e1d79d3edb2e4,This paper proposes Variance of Gradients ( VoG ) as a proxy metric for detecting outliers in the data distribution. The authors provide quantitative and qualitative support that VoG is a meaningful way to rank data by difficulty and to surface a tractable subset of the most challenging examples for human - in - the - loop auditing. The VoG scores are far more difficult for the model to learn and over - index on corrupted or memorized examples. VoG can be computed using checkpoints stored over the course of training and is model agnostic.
SP:074bfacc75837bb19049be8a2890e10de073dd8e,"This paper proposes a method to improve the quality of generated samples from deep generative models by refining them using gradient flow of f - divergences between the real and generator data distributions. The proposed method is based on the non - linear Fokker - Plank equation, which can be easily simulated by sampling from the equivalent McKean - Vlasov process. The method can be applied to GANs, VAEs, and Normalizing Flows. Experiments on synthetic, image, and text datasets demonstrate the effectiveness of the proposed method."
SP:74ecbc5a6d464bfa49337da9e0dd6a0fe714d4bb,"This paper presents a variable encoder - decoder ( VECO ) pre - training approach to unify the two mainstreams in both model architectures and pretraining tasks. The proposed method splits the standard Transformer block into several sub - modules trained with both innersequence and cross - sequence masked language modeling, and correspondingly reorganizes certain sub - module for understanding and generation tasks during inference. The paper provides new state - of - the - art results on various cross - lingual understanding tasks of the XTREME benchmark covering text classification, sequence labeling, question answering, and sentence retrieval. For generation tasks, the proposed method outperforms all existing cross - linguistic models and SOTA Transformer variants on WMT14 English - to - German and E2E - French translation datasets."
SP:3d177ad50727d1a2619b68ab8a897b79d8652beb,"This paper proposes an intrinsic reward function for reinforcement learning based on auditory event prediction. Specifically, the authors use a neural network to predict the auditory events and use the prediction errors as intrinsic rewards to guide RL exploration. The authors first conduct an in - depth analysis of their module using a set of Atari games. They then apply their model to audio - visual exploration using the Habitat simulator and active learning using the ThreeDWorld ( TDW ) simulator. Experimental results demonstrate the advantages of using audio signals over vision - based models as intrinsic reward to guide the RL explorations."
SP:014f6118ebe55ece6be23c3a10f12e4591e444b1,"This paper proposes an end - to - end framework to jointly learn a reliable representation and assign clusters to unlabelled data. To avoid over - fitting the learnt embedding to labelled data, they take inspiration from self - supervised representation learning by noise - contrastive estimation and extend it to jointly handle labelled and unlabeled data. In particular, they proposed using category discrimination on labelled data and cross - modal discrimination on multimodal data to augment instance discrimination used in conventional contrastive learning approaches. They further employ Winner - Take - All ( WTA ) hashing algorithm on the shared representation space to generate pairwise pseudo labels for unlabelling data to better predict cluster assignments. They thoroughly evaluate their framework on large - scale multi -modal video benchmarks Kinetics - 400 and VGG - Sound, and image benchmarks CIFAR10, CifAR100 and ImageNet."
SP:4df640f502e88ddba2d7e183625231d70b083e82,"This paper proposes a new weakly supervised segmentation method for image classification. The proposed method is based on contrastive learning, where pixels of the same semantics need to be mapped to the same ( distinctive ) features. The authors propose 4 types of contrastive relationships between pixels and segments in the feature space, which capture low - level image similarity, semantic annotation, co - occurrence, and feature affinity. The pixel - wise feature can be learned from training images with any partial annotations in a data - driven fashion. Experiments on Pascal VOC and DensePose demonstrate consistent gains over the state - of - the - art ( SOTA )."
SP:f7d6099adb40a0ce2f8a3563dbd5207cf1fdea0f,"This paper proposes a new self - supervised distillation method, named BINGO, which is short for Bag of InstaNces aGgregatiOn, which aims at transferring the relationship learned by the teacher to the student. The bag of instances indicates a set of similar samples that are grouped within a bag, and the goal of distillation is to aggregate compact representations over the student with respect to instances in a bag. The method achieves new state - of - the - art performance on small scale models, i.e., 65.5 % and 68.9 % top - 1 accuracies with linear evaluation on ImageNet, using ResNet-18 and ResNet - 34 as backbone, respectively, and surpassing baselines ( 52.5% and 57.4 % top-1 accuracies )."
SP:328866aad6544c81ded8980934df31dc4472435f,"This paper proposes GATSBI, a generative adversarial inference method for simulation - based inference ( SBI ). The main idea is to reformulate the variational objective in an adversarial setting to learn implicit posterior distributions, which is amortised across observations, works in high - dimensional posterior spaces, and supports implicit priors. The method is evaluated on two SBI benchmark problems and on two high - dimension simulators. On a model for wave propagation on the surface of a shallow water body, the method shows that it can return well - calibrated posterior estimates even in high dimensions. It also performs better than a state - of - the - art SBI approach."
SP:2915e82097eae4eb8546dc500f32b3ec37e3766f,"This paper proposes a method for the identification and estimation of individualized treatment effects ( TEs ) under limited overlap. The authors use a generative prognostic model to model a prognostic score, which is widely used in biostatistics and sufficient for TEs. The model is then learned as a new type of variational autoencoder ( VAE ) called the β - Intact - VAE. The paper provides the TE error bounds that enable representations balanced for treatment groups conditioned on individualized features. The proposed method is compared with recent methods using ( semi - synthetic ) datasets."
SP:ca358c9f36aac6e58ed1b3949c349d210c49a48e,"This paper proposes a benchmark for autonomous reinforcement learning ( ARL ), where the agent is not only learning through its own experience, but also contends with a lack of human supervision to reset between trials. The benchmark is based on an existing benchmark, but reformulates the learning tasks to reflect ARL constraints, such as the absence of explicitly available resets. The authors show that existing RL methods and methods designed for reset - free learning struggle to solve the problems in the benchmark and often get stuck in parts of the state space, underscoring the need for algorithms that can learn with greater autonomy."
SP:abe51d4a9817c08f0abde5da0bb8e6ca4e02e7cf,"This paper investigates the state - of - the - art GNN - based QA systems. The authors analyze the GNN modules for QA and analyze their reasoning capability. They find that existing GNN-based modules may only carry out some simple reasoning such as counting, and that it remains a challenging open problem to build comprehensive reasoning modules for knowledge - powered QA. To verify this point, the authors design soft / hard counter models, which achieve comparable or even better experimental results than existing Graph Neural Networks ( GNN ) based methods."
SP:3ea5a38e7fcd9111dcd299ad039b634e2781685f,"This paper proposes a three - stage framework to enable DNN inference with near - optimal compression and much better performance during inference runtime. The key insight of the proposed method leverages the concept of Succinct Data Structures, which supports fast queries directly on compressed representation without decompression. The proposed method first transforms DNN models as their proposed formulations in either Element - wise or Block - wise manner, so that the compressed representation can take advantage of the succinct data structure. Then, the method compresses transformed DNN model using Succert Data Structure. Finally, our method exploits the specialized execution pipelines for different model formulations, to retrieve relevant data for inference. The experimental results show that, our method keeps near - optimum compression, and achieves at least 8.7X/11.5X speedup on AlexNet / VGG-16 inference, compared with Huffman Coding."
SP:94c395afc794a9cc163e362078769ff83f3d20d0,"This paper proposes Network Augmentation ( NetAug ), a new training method for improving the performance of tiny neural networks. The authors argue that training tiny models are different from large models : rather than augmenting the data, we should augment the model, since tiny models tend to suffer from under - fitting rather than over - fitting due to limited capacity. To alleviate this issue, NetAug augments the network ( reverse dropout ) instead of inserting noise into the dataset or the network. It puts the tiny model into larger models and encourages it to work as a sub - model of larger models to get extra supervision, in addition to functioning as an independent model."
SP:9c24549b980e415616f818acbf4cf680ef8edb52,"This paper proposes a GAN - based method for generating spatiotemporal point cloud sequences from dynamic point cloud data. The main idea is to use a super - resolution generative adversarial network ( GAN ) to learn the underlying temporal coherence from point cloud sequence, which in turn guides the generator to produce temporally coherent output. In addition, the authors propose a learnable masking module to adapt upsampling ratio according to the point distribution. The experimental results show the effectiveness of the proposed method on the up - sampling task and the discriminative task."
SP:67efe60ad37807505369b7852bc0abed29ffdda8,"This paper proposes a fully - pre - trained detection transformer for object detection. The proposed method is based on the idea of using query positional embeddings as visual prompts to help the model attend to the target area ( prompting ) and recognize the object. To this end, the authors propose the task adapter which leverages self - attention to model the contextual relation between object query embedding and object query. Experiments on the challenging COCO dataset demonstrate that the proposed method achieves competitive performance. Moreover, it enjoys better robustness to common corruptions and generalization to small - size datasets."
SP:a1f9897496303984fc7ad469222106b14b4a6233,"This paper proposes a new federated learning algorithm, FedPAGE, which uses the recent optimal PAGE method ( Li et al., 2021 ) to further reduce the communication complexity of federated convex and nonconvex optimization. In the convex setting, the number of communication rounds is O(3/4 S ), improving the best - known result O(N S ) of SCAFFOLD ( Karimireddy et al, 2020 ) by a factor of N, where N is the total number of clients, S is the sampled subset of clients in each communication round, and NS is the target error. The authors also conduct several numerical experiments showing the effectiveness of multiple local update steps in FedPAEG and verifying the practical superiority of FedPAAGE."
SP:81e74765abc6524edd8fdf9a3ba107d7bddaa04b,"This paper proposes to characterize the decision boundary geometry of ANN classifiers by utilizing adversarial perturbations. The authors define adversarial subspaces, which are spanned by orthogonal directions of minimal perturbation to the decision boundaries from any given input sample. They find that decision boundary lies close to input samples in a large subspace, where the distance to the boundary grows smoothly and sub - linearly as one increases the dimensionality of the subspace. The geometry of the boundary is more curved within the adversarian subspace than within a random subspace of equal dimensionality. This paper provides a new perspective on the most widely used defense against test - time adversarial attacks, adversarial training, where one incorporates adversarial examples into the training procedure. They provide a new insight into the consequences of adversarial learning by quantifying the increase in boundary distance within adversarial subsets, the redistribution of proximal class labels, and the decrease in boundary curvature."
SP:af5c25ecf38c5c3f3387720bdc80c2c54c5699fe,"This paper proposes a two - stage weakly - supervised contrastive learning approach. The first stage is to cluster data according to its auxiliary information, while the second stage learns similar representations within the same cluster and dissimilar representations for data from different clusters. The authors show that the auxiliary - information - infused representations bring the performance closer to the supervised representations, which use direct downstream labels as supervision signals. The proposed method also works well with unsupervised constructed clusters ( e.g., no auxiliary information )."
SP:0a92fcc52970201de4a66b1e76c93dbea9dfd3f1,"This paper proposes a method to recover sparse parameters from observational data by unrolling a path - following algorithm. The method is based on the unrolling of the path - followed algorithm, and the authors show that this unrolling allows the algorithm to be more flexible and learnable. The authors also provide a theoretical analysis of the performance of the unrolled algorithm.   The main contributions of the paper are :   1. A theoretical analysis on the generalization properties of the algorithm. This analysis shows that the algorithm is generalizable to a broad class of sparse estimation problems. 2. An empirical analysis is provided on the Rademacher complexity of the algorithms."
SP:5064eda9ba27060af15e81b2b317b2e4558b0ac4,"This paper proposes a method to learn a compact and decodable latent representation space for discrete - continuous hybrid action space. Specifically, the authors use an unsupervised method to derive an embedding table and conditional VAE to embed the dependence between discrete action and continuous parameter via a conditional Variational Auto - Encoder ( VAE ). To further improve the effectiveness, the action representation is trained to be semantically smooth through unsuper supervised environmental dynamics prediction. Finally, the agent learns its policy with conventional DRL algorithms in the learned representation space and interacts with the environment by decoding the hybrid action embeddings to the original action space using conventional RL algorithms. The experiments demonstrate the superiority of HyAR regarding performance, learning speed and robustness in most hybrid action environment, especially in high dimensional action spaces."
SP:5128bf712f6b197de113c7a371b4bec36f978eca,"This paper proposes SGEM, Stochastic Gradient with Energy and Momentum to solve a large class of general nonconvex stochastic optimization problems, based on the AEGD method that originated in the work [ aEGD : Adaptive Gradient Descent with Energy ]. The authors show that SGEM features an unconditional energy stability property, and derive energy - dependent convergence rates in the general non - convex setting, as well as a regret bound in the online convex case. A lower threshold for the energy variable is also provided. The experimental results show that the proposed SGEM converges faster than AEGDM and generalizes better than SGDM in training some deep neural networks."
SP:11f49b0a975be87769be29e85d7e3924699cf2c9,"This paper proposes a Conditional Masked Language Model with Correction ( CMLMC ) to improve the performance of Transformer - based autoregressive ( NAR ) machine translation models. The proposed method is based on the CMLM architecture, where the decoder encodes the positional information of each token in the sentence. The decoder is then decoded by a decoder - decoder architecture where the encodings are masked. The model is trained on both raw data and distilled data. The authors show that the proposed method outperforms other NAR - based models in terms of accuracy on several datasets."
SP:96f8ac3c6163e56d8ae1954a162bae01e6b58a0a,This paper proposes a spiking neural network ( SNN ) based on the WaveNet architecture. The proposed SNN is trained using the Spike Response model ( SRM ) in combination with SLAYER algorithm Shrestha & Orchard ( 2018 ). The experimental results show that the proposed network beats the state - of - the - art of other SNNs and achieves near - SOTA performance.
SP:7f20a2e4e95f857140b87b0730360b3ff2f371f4,"This paper proposes Shifty, a class of algorithms that provides high - confidence behavioral guarantees that hold when the distribution of demographics changes between training and deployment. The proposed algorithm is based on the Student's t - test. The paper provides a constructive proof of the guarantees, a method for creating such algorithms, an evaluation on real - world data, and an open - source Shifty implementation. The experiments demonstrate that the algorithm ’s fairness guarantees are valid in practice and that Shifty is an effective tool for training models that are fair when demographic shift occurs."
SP:94f097921bee5fdc10ec2e7c901b2ddb876d9d41,"This paper proposes a neural - based approach to solve multi - stage stochastic dual dynamic programming ( MSSO ) problems. The main idea is to use a neural network to learn to map the problem instances to a piece - wise linear value function within intrinsic low - dimension space, which is then used to interact with a base SDDP solver. The proposed approach is evaluated on synthetic and real - world problems."
SP:3d9f5132f9ec3807dbca78462a459fd123a09b24,"This paper proposes a new protocol for next - token prediction, called SUBMIX, which is designed to prevent privacy violations by language models that were fine - tuned on a private corpus after pre - training on a public corpus. The main idea is to use a relaxation of group differentially private prediction to prevent the leakage of information that is unique to any individual user in the private corpus. To this end, the authors introduce a tight, data - dependent privacy accounting mechanism, which allows it to thwart existing data - extraction attacks while maintaining the utility of the language model. The authors show that the proposed method can effectively prevent existing data extraction attacks against GPT-2."
SP:7f524d186ea939309c7eeb843c62b6a4b4cfbc8a,"This paper proposes an unsupervised method to detect out - of - distribution ( OOD ) samples using a k - NN density estimate with respect to a classification model ’s intermediate activations on indistribution samples. The authors leverage a recent insight about label smoothing, which they call the Label Smoothed Embedding Hypothesis, and show that one of the implications is that the k - nN density estimator performs better as an OOD detection method both theoretically and empirically when the model is trained with label smoothed. Finally, they show that their proposal outperforms many OOD baselines and they also provide new finite - sample high - probability statistical results for k-NN density estimation’s ability to detect OOD examples."
SP:aafbd6ada14cc59a272fe4bf95fac71fa18e57ab,"This paper proposes to use diffusion - based methods ( DRL and VDRL ) to learn representations for semi - supervised image classification. In contrast to GANs and VAEs, the authors propose to learn an infinite - dimensional latent code instead of directly transforming latent codes to data samples. The authors argue that the difference allows for manual control of the level of details encoded in the representation. They also show that adversarial training can improve sample quality and improve sampling speed using a new approximation of the prior at smaller noise scales."
SP:8cfc837d5c10d539bbd098df7134c42e4830ba25,"This paper proposes an algorithm for goal - conditioned reinforcement learning that learns to reach distant goal - reaching tasks by using planning at training time to automatically generate a curriculum of intermediate states. The proposed algorithm, C - Planning, is based on the idea of expectation maximization. The E - step aims to plan a sequence of waypoints using graph planning, while the M - Step aims to learn a policy to reach those waypoints. Unlike prior methods that combine goal - conditioned RL with graph search, ours performs planning only during training and not testing, significantly decreasing the compute costs of deploying the learned policy. Empirically, the method is more sample efficient that prior methods. It is able to solve very long horizons manipulation and navigation tasks."
SP:ef3193842e06d4a6edb8a6a86ea5bc97ee5eaa4a,"This paper proposes a k - mixup method to improve the robustness and generalizability of mixup training. The main idea is to perturb the training data in the direction of other randomly - chosen instances in the training set. This is done by averaging random pairs of sets of k samples from the training dataset. This averaging is done using optimal transport, with displacement interpolation, i.e. interpolation under the Wasserstein metric. The authors demonstrate theoretically and in simulations that k - Mixup preserves cluster and manifold structures, and extend theory studying the efficacy of standard mixup to the k-mixup case. The empirical results show that training with k - mixingup further improves generalization and robustness across several network architectures and benchmark datasets of differing modalities."
SP:0fe6a9848026e5f6436a380199e27a9ad26cffed,"This paper proposes a kernelized classification layer for deep neural networks aiming to extract the best possible classifier with embeddings produced by a given representation learner. The classification layer classifies the embedding in a high dimensional RKHS while automatically learning the optimal kernel that enables this high - dimensional mapping. The authors show that a classification network with a lightweight representation learning backbone can be made more effective by replacing the usual softmax classifiers with the kernelized classifier. The proposed method is evaluated on image classification, natural language understanding, distillation, and active learning settings."
SP:01ee8ec81619784788eb0ce9785098e437d17a7c,"This paper investigates the sources of bias in GNN - based learning and proposes fairness - aware data augmentation frameworks on nodal features and graph structure to reduce the intrinsic bias. Based on the analysis, the authors propose two methods : feature masking and node sampling. The proposed strategies incur low additional computation complexity compared to non - adaptive counterparts, and are compatible to operate in conjunction with various GNN-based learning frameworks, including other fairness enhancement methods. Experimental results on real - world graphs demonstrate that the proposed adaptive augmentations can improve fairness metrics with comparable utilities to state - of - the - art in node classification and link prediction."
SP:7739dc9e37f7f1384f87d2e60281e5bb27fece99,"This paper proposes a method to estimate the treatment effect from observational data in the presence of unmeasured confounders. The proposed method is based on the idea of confounder balancing, which aims to jointly remove the bias from the unmeasureful confoundering with IV regression and achieve better bias - variance trade - off in imbalanced treatment distributions by balancing for treatment effect estimation. Specifically, the proposed method consists of three main modules : ( 1 ) treatment regression : regressing the treatment with IVs and confounds like previous nonlinear IV methods for removing the confounding from unme measured confoundingers ; ( 2 ) confoundER balancing : learning a balanced representation of confounds to eliminate the bias induced by the observed confounds ; and ( 3 ) outcome regression : Regressing the outcome with the predicted treatment and the balanced confounds representation. Extensive experiments on both synthetic and real - world datasets demonstrate the effectiveness of the proposed algorithm."
SP:fdb68c39fce254b73310a3101b2fe97ba47e69fe,"This paper analyzes the effect of task hardness and task geography on the performance of model - agnostic meta - learning ( MAML ) in the linear regression setting, where the task hardness is related to the rate that gradient descent converges on the task. The authors show that the hard tasks must be sufficiently similar to the easy ones, and that the optimal solutions of the hard task must be closely packed with the center far from the center of the easy tasks optimal solutions. They also provide numerical and analytical results suggesting that these insights apply to two - layer neural networks. Finally, they provide few - shot image classification experiments that support their insights and emphasize the importance of training MAMl on hard tasks in practice."
SP:e8143c7880c16ee9ce7a544e0fd80f001b1b4f9f,"This paper proposes an algorithm unfolding / unrolling method for sparse source separation ( BSS ). The proposed method leverages the data - driven knowledge stemming from realistic simulations or ground - truth data by learning both the hyperparameters and variables of the sparse BSS method. The method is based on the unrolling of the Proximal Alternating Linearized Minimization ( PALM ) algorithm. In contrast to most existing unrolled algorithms, which assume a fixed known dictionary during the training and testing phases, this article further emphasizes on the ability to deal with variable mixing matrices ( a.k.a. dictionaries ). It thus enables to perform semi - blind source separation, which is key to increase the generalization of the learnt model in real - world applications. The algorithm not only needs up to 10 - 10 times fewer iterations than PALM, but also improves the separation quality."
SP:7716315001949ab88c8a216302fe51bae872fc87,This paper proposes a Legendre memory module to improve the performance of transformers on the task of language modeling. The proposed method is based on the idea of implicit self - attention and the Legendre Memory Unit ( LMAU ). The authors show that the proposed method improves the performance over transformers and LSTMs for the same amount of training. They also show that adding global attention to the proposed model further improves the model's performance.
SP:832f422b3554e89702e13c8c5690ee26f2289e3b,"The paper presents LatentKeypointGAN, a GAN - based method for keypoint detection. The keypoint embedding is a set of appearance embeddings that control the position and style of the generated objects and their parts. The proposed method is trained end - to - end on the classical GAN objective with internal conditioning on the set of space keypoints. In addition, the explicit generation of keypoints and matching images enables a new, GAN-based method for unsupervised keypoints detection.    The paper provides an interpretable latent space that can be used to re - arrange the generated images by re -positioning and exchanging keypoints, such as generating portraits by combining the eyes, and mouth from different images."
SP:9206ae6e31077569313838504ef6daa89ad3b59c,"This paper studies the effect of depth on signal propagation in fully connected neural networks. The authors show that increasing the depth leads to gradient explosion or to another undesirable phenomenon we call representation shrinkage. They show that this phenomenon is not restricted to a specific initialization scheme or a choice of activation function, but rather is an inherent property of the fully - connected architecture itself. Additionally, they show that many popular normalization techniques fail to mitigate these problems. The paper also shows that RMT can also be applied to residual networks to guide the choice of initialization variances."
SP:2177be818b5843c580c787f1b2d725154846feb6,"This paper proposes a line search method to find the optimal step size for stochastic gradient descent. The main idea is to approximate the full - batch loss with a parabola estimated over several mini - batches. The proposed method is based on recent empirical findings that the fullbatch loss behaves locally parabolically in the direction of noisy update step directions, and the trend of the optimal update step size changes slowly. By exploiting these findings, this work introduces a line - search method that approximates the full-batch loss by approximating the full batch loss using the parabolas estimated over multiple mini - batch iterations. The authors show that their method outperforms SGD tuned with a piece - wise constant learning rate schedule and other line search approaches for Deep Learning across models, datasets, and batch sizes on validation and test accuracy."
SP:62233782f9046c85617d9ccfe8427eae7d1c9da7,"This paper provides a theoretical analysis of the ill - behavior of the loss landscape of noise - contrastive estimation ( NCE ) when the target and noise distributions are in an exponential family. Specifically, the paper shows that when the noise distribution is uninformative, the NCE objective suffers from an ill - behaving loss landscape. To address this, this paper proposes to replace the log loss in NCE with an exponential loss and shows that the resulting condition number is polynomial in the dimension and the parameter distance between P and Q when they belong to the exponential family, and the proposed eNCE loss can be efficiently optimized using normalized gradient descent and empirically outperforms existing methods."
SP:ceba6c1421b2d03863007fdaf029b8b946519c1b,"This paper studies the effect of DP and Byzantine resilience in distributed SGD. In particular, the authors study the impact of DP on Byzantine resilience ( BR ). They show that existing results on the convergence of SGD under Byzantine faults, especially those relying on ( α, f)-Byzantine resilience, are rendered invalid when honest workers enforce DP. To circumvent this shortcoming, they revisit the theory of ( Alpha, f - BR ) to obtain an approximate convergence guarantee. Their analysis provides key insights on how to improve this guarantee through hyperparameter optimization. Their results show that ( 1 ) an imprudent combination of standard approaches to DP and BR might be fruitless, but ( 2 ) by carefully re - tuning the learning algorithm, we can obtain reasonable learning accuracy while simultaneously guaranteeing DP."
SP:bc783f0c829f90931535e63687d13172879631b3,This paper proposes a method for code editing with few exemplars. The method is based on an ensemble approach to gather the query - support matching from multiple extents and delivers a robust composition over support editing representations for the query snippet decoding. The proposed method is evaluated on C# and Python datasets and show up to 8.6 % absolute accuracy improvements compared to non - composition baselines and other existing methods.
SP:ca0c4bdb02f7d939fb6de38b6b446ced4b5984a0,"This paper proposes a program synthesis method for generating high - level relational constraints for generating sequence data. The method is based on the idea of program synthesis, where a program is constructed from a set of constraints on the training data, which are then used to train a generative model. The authors propose a two - part approach : ( i ) a program synthesizer that generates the constraints, and ( ii ) a second model that generates data that satisfies these constraints. The proposed method is evaluated on synthetic data, as well as real - world datasets. The results show that the proposed method outperforms the existing methods in terms of generating human - like data."
SP:692ae0c583a1585eff1a7d9c0d3b51b7879611cc,"This paper proposes a method for set - to - hypergraph prediction, where the goal is to infer the set of relations for a given set of entities. The paper addresses two common scaling problems encountered in set to hypergraph tasks that limit the size of the input set : the exponentially growing number of hyperedges and the run - time complexity, both leading to higher memory requirements. The authors propose to predict and supervise the positive edges only, which changes the asymptotic memory scaling from exponential to linear. They also introduce a training method that encourages iterative refinement of the predicted hypergraph, which allows us to skip iterations in the backward pass for improved efficiency and constant memory usage. Finally, they combine both contributions in a single model that enables us to address problems with larger input set sizes."
SP:e3481fb6d8d1aa45d6ed4a454e781f5a2c30c57e,"This paper proposes a post - processing method to mitigate bias of state - of - the - art models. The proposed method consists in learning a shallow neural network, called the Ethical Module, which transforms the deep embeddings of a pre - trained model to give more representation power to the discriminated subgroups. The training is supervised by the von Mises - Fisher loss, whose hyperparameters allow to control the space allocated to each subgroup in the latent space. Besides being very simple, the resulting methodology is more stable and faster than most current methods of bias mitigation. In order to illustrate the idea in a concrete use case, the authors focus on gender bias in facial recognition and conduct extensive numerical experiments on standard datasets."
SP:3fb5dcc8b8fb731e09c14b16480cada1c7ccfaa7,"This paper proposes a novel method PlaceboCIL to address the forgetting problem in class - incremental learning ( CIL ). Specifically, the authors propose to compute the KD loss using placebo data from a free image stream ( e.g., Google Images ), which is both simple and surprisingly effective even when there is no class overlap between the placebos and the old data. When the image stream is available, they use an evaluation function to quickly judge the quality of candidate images ( good or bad placebos ) and collect good ones. For training this function, they sample pseudo CIL tasks from the data in the 0 - 9th phase and design a reinforcement learning algorithm. Their method does not require any additional supervision or memory budget, and can significantly improve a number of top - performing CIL methods, in particular on higher - resolution benchmarks, such as ImageNet-1k and ImageNet - Subset."
SP:506e0a888c03a955b708464eed3670c04baf4912,"This paper proposes a new approach to sampling from discrete energy - based models ( EBMs ). The authors propose to use a path auxiliary algorithm that uses a composition of local moves to efficiently explore large neighborhoods. They also provide a fast version of their algorithm that only queries the evaluation of energy function twice for each proposal via linearization of the energy function. They show that their path auxiliary algorithms outperform other generic samplers on various discrete models for sampling, inference, and learning. Their method can also be used to train deep EBMs for high dimensional discrete data."
SP:4b466277aa5561a80c48d5e72559de4ce95f228b,"This paper presents Variational Predictive Routing ( VPR ), a neural probabilistic inference system that organizes latent representations of video features in a temporal hierarchy, based on their rates of change, thus modeling continuous data as a hierarchical renewal process. VPR uses an event detection mechanism that relies solely on the system ’s latent representations ( without the need of a separate model ) to dynamically adjust its internal state following changes in the observed features, promoting an optimal organisation of representations across the levels of the model ‘s latent hierarchy. Experiments on several video datasets show that VPR is able to detect event boundaries, disentangle spatiotemporal features across its hierarchy, adapt to the dynamics of the data, and produce accurate timeagnostic rollouts of the future."
SP:459ef2e6bd7638020955dbb4d8ae1098619f7b95,"This paper proposes a new image retrieval method called UGLAR, which combines spatial and channel attention to learn key local information, then feeds it to CNN to learn homography transformation in images. The idea is to replace the re - ranking process with information fusion to obtain more powerful features and overcome the low efficiency of local features in storage and matching. Experiments on Revisited Oxford and Paris datasets validate the effectiveness of our approach, and we achieved state - of - the - art performance compared to other popular methods."
SP:487cc308a1e8ee078c54b2158bcae47e920e73f8,"This paper proposes a new algorithm, RotoGrad, for multi - task learning ( MTL ). The main idea is to homogenize task gradients in terms of magnitudes and directions to avoid negative transfer between tasks. The authors provide a theoretical analysis of the effect of magnitude and direction - homogenization on the stability of the overall learning process. In addition, the authors conduct extensive experiments to demonstrate the effectiveness of the proposed method."
SP:050cd8319d84a1bd8c2ccb930ba69b33c8fb6e60,This paper proposes a method to fuse heterogeneous neural networks via cross - layer alignment and layer - wise model fusion. The method is based on a dynamic programming - based algorithm to solve the unbalanced assignment problem. The authors also propose two methods to balance the number of layers between two networks. Experiments show that the proposed method achieves better performance compared to the individual networks trained on heterogeneous data without the need for any retraining.
SP:f764eae15cd083fdb4eb2af09ac64c2d878a454f,"This paper studies the effect of the implicit regularization effect of SGD in the offline deep RL setting. The authors derive the form of this implicit regularizer and, inspired by this derivation, propose a simple and effective explicit regularizer, called DR3, that counteracts this effect. DR3 improves the performance and stability of offline value - based RL methods, alleviating unlearning in Atari 2600 games, D4RL domains and robotic manipulation from images."
SP:6fd793b27123bf80504e2ad5957455b7ec311612,"This paper proposes HyperDQN, an exploration method based on a probabilistic hypermodel. The hypermodel is a combination of a base model and a meta model, which outputs the parameter of the base model. The meta model is then used to generate approximate posterior samples regarding the parameters of the Q - value function, which are used to select action sequences. The proposed method is evaluated on the Atari suite and SuperMarioBros, where it outperforms several exploration bonus methods."
SP:b428383660928374c953f659ea1e05852dbdcd6e,"This paper proposes to learn causal representation from observational data by regularizing the learning procedure with mutual information measures according to our hypothetical causal graph. The optimization involves a counterfactual loss, based on which the authors deduce a theoretical guarantee that the causality - inspired learning is with reduced sample complexity and better generalization ability. Extensive experiments show that the models trained on causal representations learned by our approach is robust under adversarial attacks and distribution shift."
SP:1258c05a80a17949b50e6dae13deea1d2235f456,"This paper proposes ProgFed, a progressive training framework for efficient and effective federated learning. It inherently reduces computation and two - way communication costs while maintaining the strong performance of the final models. Theoretically, the authors theoretically prove that Progfed converges at the same asymptotic rate as standard training on full models. Extensive experiments on different architectures from small CNNs to U - net and different tasks from simple classification to medical image segmentation show that our method is communication and computation - efficient, especially when the training budgets are limited. Interestingly, the proposed method has improved performance in vanilla learning and more robust results when learning is perturbed e.g. in the case of gradient compression."
SP:8cdaa6e0dafd750ebdb5d7a4c1987a042400662f,This paper studies the generalization of adversarial training through the lens of the adversarial Rademacher complexity. The authors provide upper bounds on the adversarially trained weight norms and show that the product of weight norms is a key factor explaining the bad generalization performance of adversary training. They provide experiments to analyze the relationship between the generalisation gap and the adversariarially training weight norms.  
SP:925d6bb051e9b384669fb695085b678c11f7c11a,"This paper proposes a kernel - based estimator for differential entropy and mutual information estimation. The main contribution of this paper is the development of a new estimator called Kernelized Neural Differential Entropy ( KNIFE ), which is fully parameterized, differentiable, and parameterized by a differentiable kernel. The proposed estimator can be used to estimate differential entropy, mutual information, and conditional differential entropy. Experiments on synthetic data and real - world tasks demonstrate the effectiveness of the proposed method."
SP:d2f3beac855f0d72c13552fecb2bdb9d42195df3,"This paper proposes a new soft - greedy operator, called resmax, that takes actions proportionally to their suboptimality gap : the residual to the estimated maximal value. It is simple to use and ensures coverage of the state - space like softmax, but focuses exploration more on potentially promising actions. It does not concentrate probability as quickly as softmax and so better avoids overemphasizing sub - optimal actions that appear high - valued during learning. Additionally, it is a non - expansion for any fixed exploration hyperparameter, unlike the softmax policy which requires a state - action specific temperature to obtain a nonexpansion ( called mellowmax ). Empirical results show that resmax encourages more exploration than softmax in RiverSwim."
SP:792ae8808aa6902758146aef1548c975492b833c,"This paper proposes a method to control the learnability of a specific dataset with a special key. The key consists of an adversarial invertible transformation ( AIT ) to modify the data samples so that they become "" unlearnable "" by machine learning models with negligible loss of visual features. Meanwhile, one can unlock the learnable of the dataset and train models normally using the corresponding key.   The proposed learnability lock leverages class - wise perturbation that applies a universal transformation function on data samples of the same label. The proposed method can be easily restored with a simple inverse transformation while remaining difficult to be detected or reverse - engineered. The experimental results demonstrate the effectiveness of the proposed method on visual classification tasks."
SP:9af10703605e620e563241e2602a50b629f3d37a,"This paper proposes a novel approach for handling missing features in graph machine learning applications that is based on minimization of the Dirichlet energy and leads to a diffusion - type differential equation on the graph. The discretization of this equation produces a simple, fast and scalable algorithm which the authors call Feature Propagation. The authors show that the proposed approach outperforms previous methods on seven common node - classification benchmarks and can withstand surprisingly high rates of missing features. On average, on average we observe only around 4% relative accuracy drop when 99% of the features are missing. Moreover, it takes only 10 seconds to run on a graph with 2.5m nodes and 123m edges on a single GPU."
SP:cbaa3f1379fa99159899d79ccb479c0187403aca,This paper proposes a method for active learning by minimizing the discrete Wasserstein distance between the labeled and unlabeled data sets. The main idea is to select a subset of the labeled data from the unlabelled data set that minimizes this distance. The authors propose a Generalized Benders Decomposition ( GBC ) algorithm to solve this problem. The GBC algorithm uses the latent features obtained by unsupervised learning on the unlabilised data set to select the core set. The proposed method is evaluated on several image classification and domain adaptation tasks. The results show that the proposed method outperforms baselines.
SP:4c72923f78ca6590dc11e10d1a2403076a583718,"This paper proposes a novel approach to solving de novo genome assembly based on graph neural networks and finding a path through the assembly graph. The authors create a dataset of assembly graphs based on real human genomic data on which the developed model was trained and evaluated. The model was also evaluated against a naive greedy approach, an exhaustive search using the positional information of reads, and an existing genome assembler Raven ( Vaser & Sikic, 2021 ). It was shown that it consistently outperforms the greedy approach and Raven in terms of reconstructed length and execution speed. More interestingly, it was also shown that the model outperformed Raven when given a highly complex graph from a repetitive region."
SP:24de906e4289c9073b6c55c747b0913b8df5e053,"This paper proposes to use experience replay ( ER ) to improve the online - aware meta - learning by incorporating it into its meta - testing procedure. The authors argue that the batch nature of ER interferes with the online nature of OML during meta - training, resulting in a loss of gradient and Hessian information during the meta - updates. To alleviate this problem, the authors propose to store the samples ’ representations, instead of the samples themselves, into the replay buffer, which allows both OML ’s online training and ER’s batch replay to be preserved. They also propose the Predictive Sample Selection, which selects the most sensitive samples into the Replay buffer. Experimental results demonstrate that the proposed method outperforms the state - of - the - art."
SP:3c78454f053f74930979a8054cd7c8a34b6fe63d,"This paper proposes Explicit Credit Assignment Joint Q - Learning ( ECAQ ), a method for multi - agent joint Q - learning. The authors formulate an explicit credit assignment problem where each agent gives its suggestion about how to weight individual Q - values to explicitly maximize the joint Q-value, besides guaranteeing the Bellman optimality. Theoretically, the authors give a gradient ascent solution for this problem. Empirically, they instantiate the core idea with deep neural networks and propose Explicit Credit assignment joint Q learning (ECAQ ) to facilitate multi -agent cooperation in complex problems. Extensive experiments justify the superior performance of this method."
SP:0d2b225ac697679d10df25f371b2a718d4949b42,"This paper presents an attack framework for adversarial robustness of transductive learning - based defense mechanisms. The authors formulate and analyze threat models for the defense mechanisms from a principled threat analysis perspective, and point out important subtleties. They propose the principle of attacking model space for solving bilevel attack objectives, and present Greedy Model Space Attack ( GMSA ), which can serve as a new baseline for evaluating the robustness based defenses. Through systematic evaluation, the authors show that GMSA, even with weak instantiations, can break previous transductionive - learning based defenses, which were resilient to previous attacks such as AutoAttack. On the positive side, they report a somewhat surprising empirical result of “ Transductive adversarial training ” : Adversarially retraining the model using fresh randomness at the test time gives a significant increase in robustness against attacks we consider."
SP:e7024cae196fc5eb6a62d289a95d76b532b6a36c,"This paper studies the problem of batch normalization, where the entire dataset is normalized jointly. The authors propose a method for performing per - example normalization in a way that does not modify the inference - time architecture. The method combines per - instance gradient computation, the maintenance of moving first and second moments, and an aggregation step that joins the information from multiple examples similar to the way that the gradients with respect to the model parameters are commonly averaged over the minibatch in SGD. Unlike previous proposed methods, the normalization does not change the function class of the inference model, and performs well in the absence of identity shortcuts."
SP:4aa42984fcb0fd66936d668477b2719ef5c427d4,"This paper proposes a low - rank adaptation ( LoRA ) method for fine - tuning Transformer language models. The proposed method freezes the weights of the pretrained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture to reduce the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine - tuned with Adam, LoRA can reduce the total number of parameters by 10,000 times and the GPU memory requirement by 3 times. Experiments show that LoRA performs on - par or better than finetuning in model quality on several tasks."
SP:b77a00beb0802f47810b03d3c4aa24d92781414f,"This paper proposes a method to constrain the output of linear - chain conditional random fields ( CRF ) by constraining the output to a regular language. The authors propose a regular - constrained CRF ( RegCCRF ), which is a generalization of CRF that can enforce a broad class of constraints, including non - local ones, by specifying the space of possible output structures as the regular language L. The authors show that the proposed method can incorporate their constraints during training, while related models only enforce constraints during decoding. They show that constrained training is never worse than constrained decoding, and show empirically that it can be substantially better in practice. Finally, they demonstrate a practical benefit on downstream tasks by incorporating a RegCC RF into a deep neural model for semantic role labeling."
SP:74c186a96c12adff178264aa84ace8d04dc7d725,"This paper proposes a new neural network architecture for camera - based physiological measurement. The proposed architecture consists of a visual transformer and a convolutional backbone. The visual transformer is an end - to - end architecture, which does not require any preprocessing steps, while the convolution is a one - stop architecture. The authors evaluate the effectiveness of the proposed architecture on three public datasets. The results show that the proposed model achieves state - of - the - art performance on the three datasets."
SP:3003bab6e3f7e2e21cd6cf27ee7d483d877d9fb3,"This paper proposes Hardware - Aware Latency Pruning ( HALP ), a method for performing structural pruning on neural networks. The proposed method is based on the idea of resource allocation, which aims at maximizing the accuracy while constraining the latency under a predefined budget. The authors propose a latency - aware neuron grouping scheme to further improve the latency reduction. The method is evaluated on ResNet, MobileNet, VGG, PASCAL VOC, and ImageNet datasets. The results show that the proposed method outperforms prior work."
SP:c44d676c09c8e5a70d73b21b507b41a422fec809,"This paper proposes GraphEBM, a molecular graph generation method via energy - based models ( EBMs ) to perform permutation invariant and multi - objective molecule generation. The authors use contrastive divergence to learn the energy function and generate samples by Langevin dynamics. To generate molecules with a specific desirable property, they propose a simple yet effective learning strategy, which pushes down energies with flexible degrees according to the properties of corresponding molecules. Further, the authors explore to use the method for generating molecules towards multiple objectives via compositional generation, which is practically desired in drug discovery. Experimental results demonstrate that the proposed method can generate realistic molecules."
SP:70e60fa5deef3e3ba77d05d0c3e0e7fbf396aa1d,"This paper proposes a neural - based approach to program synthesis. The approach is based on bottom - up search, where a neural model is trained to learn a hands - on search policy. The neural model takes into account the search history and partial program executions, and is trained on - policy using data extracted from its own bottom - ups searches on training tasks. The method is evaluated in two domains : string manipulation and inductive logic programming. The results show that CROSSBEAM learns to search efficiently, exploring much smaller portions of the program space compared to the state of the art."
SP:daa044ffefe80bae16b014f60061d941ed8c2ba6,"This paper proposes to replace the standard squared Bellman error in deep reinforcement learning with the FR Squared Bellman Error ( FR ). The main idea is to use a functional regularizer instead of an implicit one in target networks. The proposed method is evaluated on the Four Rooms environment with DNNs function approximation and show that it can approximate the true value function and learn quickly. In addition, the proposed method can be combined with DQN to improve performance."
SP:dd174014d056a7d2bc86ee99119841eafa62ed52,"This paper proposes a new GNN framework that injects structural information into the message - passing aggregation scheme of GNNs. The authors introduce a new hierarchy of local isomorphism on neighborhood subgraphs, which they call GraphSNN, and show that it is more expressive than the Weisfeiler Lehman test in distinguishing graph structures. They also show that the proposed model is better than 1 - WL in distinguishing graphs. The experimental results on node classification and graph classification tasks show the effectiveness of the proposed method."
SP:beb9ba0261e176bfc50e9bf5bed2b6169d388285,"This paper proposes a novel prediction interval ( PI ) method for uncertainty quantification. The proposed method is based on linear combinations of three neural networks, each of which is independently trained using the standard mean squared error loss. The coefficients of the linear combinations are computed using root - finding algorithms to ensure tight PIs for a given confidence level. The authors theoretically prove that PI3NN can calculate PIs with a series of confidence levels without retraining NNs and it completely avoids the crossing issue. Furthermore, the authors address OOD identification challenge by introducing an initialization scheme which provides reasonably larger PIs of the OOD samples than those of the in - distribution samples. Benchmark and real - world experiments show that the method outperforms several state - of - the - art approaches with respect to predictive uncertainty quality, robustness, and OOD sample identification."
SP:4b44a834e2212bacb4c2d9408a81f1efc76a670b,"This paper proposes a fully online meta - learning method, FOML, which does not require any ground truth knowledge of task boundaries, and does not reset the online parameters back to the meta - parameters between tasks, instead updating the parameters continually in an online fashion. The authors propose a task sampling scheme that selects datapoints at random from a buffer of all seen data, which enables effective meta - training that accelerates the speed with which the model can adapt to each new task. Experiments on Rainbow - MNIST, and CIFAR100 datasets show that the proposed method is able to learn new tasks faster than the state - of - the - art online learning methods."
SP:fbae35cb171b3a3eb7c5d4bc83881ed7c4a70aae,"This paper proposes a differentiable scaffolding tree ( DST ) to make a molecular graph locally differentiable, allowing a continuous gradient - based optimization. To the best of the knowledge, it is the first attempt to make the molecular optimization problem differentiable at the substructure level, rather than resorting to latent spaces or using RL/evolutionary algorithms. The authors constructed a general molecular optimization strategy based on DST, corroborated by thorough empirical studies."
SP:61b59899cf6ae442d9f8f5226e79708a4280cfb2,This paper proposes a personalized lab test result prediction approach that learns a strong patient representation incorporating both patient information accumulated over the visits as well as information from other similar patients. The authors model drug - lab interactions and diagnosis - lab interaction as graphs and design a knowledge - augmented approach to predict patients ’ response for a target lab result. They also take into consideration patients’ past lab responses to personalize the prediction. Experiments on real - world datasets demonstrate the effectiveness of the proposed solution in reducing prediction errors by a significant margin.
SP:8623cebb515c4a736427449b46ad2cdf8b806b77,"This paper proposes a new open - set single - domain generalization ( OS - SDG ) problem, where target domains include unseen categories out of source label space. The authors propose a novel CrossMatch approach to tackle the OS -SDG task, which generates auxiliary samples for unknown classes and improves the capability of unknown classes identification with a novel consistency regularization. Experimental results on benchmark datasets prove the effectiveness of CrossMatch on enhancing the performance of SDG methods in the OS-SDG setting."
SP:126f8ffb855aa22eda4d681a499953879ed3679e,"This paper proposes Wasserstein policy optimization and Sinkhorn policy optimization ( WPO and SPO ), two natural extensions of trust region based trust region methods based on Kullback - Leibler divergence ( TRPO and PPO ). The key idea is to directly optimize the policy distribution and derive their close - form policy updates based on the Lagrangian duality. Theoretically, the authors show that WPO guarantees a monotonic performance improvement, while SPO provably converges to WPO as the entropic regularizer diminishes. Experiments across tabular domains and robotic locomotion tasks further demonstrate the performance improvement of both approaches."
SP:999eacf6500c87205584a3256d7ca45b3016fb1c,"This paper proposes a forget - and - re - learn framework to unify a number of seemingly disparate iterative algorithms in the literature. The authors show that weight perturbation, commonly found in iterative methods, disproportionately forget undesirable information. They hypothesize that this is a key factor to the success of these algorithms, and support this conjecture by showing that how well we can selectively forgetting undesirable information corresponds to the performance of the resulting algorithms. They show that the relearning stage amplifies the unforgotten information, and distills from it features that are consistently useful under different initial conditions."
SP:2789859517b6624730b14a7e010444a72d3dd3ed," of offline - online batch RL, where the agent has access to a batch of data to train on but is also allowed to learn during the evaluation phase in an online manner. This is an extension to batch RL that allows the agent to adapt to new situations without having to precommit to a policy. The authors conduct experiments to show that standard RL agents trained in an offline - offline manner can outperform agents trained only offline or online, sometimes by a large margin, highlighting the potential of this new setting."
SP:76625a25e770415599a34122110d61cb3b7e614c,"This paper studies the discrepancy - optimal meta - learning for the problem of domain generalization ( DG ). Specifically, the authors propose a method to learn a meta - learner to optimize Y - discrepancy between unseen target and source domains only using source - domain samples. The authors provide a PAC - style generalization bound for discrepancy optimal meta learning and compare it with other DG bounds including ERM and domain - invariant learning. The theoretical results also shed light on a bilevel optimization algorithm for DG. Empirically, they evaluate the algorithm with DomainBed and achieves state - of - the - art results on two DG benchmarks."
SP:6421a9759c766641fd8c128a249f1a9c5699d19c,"This paper studies the use of DNN - based best - first search on the Sokoban domain to solve hard - planning problems. The authors show that the policy network plays an important role in the success of the search, and propose an abstract tree model to explain the existence of left heavy tails. They also show that random restarts can improve the overall search effectiveness with larger search budgets."
SP:84c415bc0f120d1997289f91661ff74e7297d3bd,This paper proposes a method for meta - imitation learning by only using video demonstrations from humans. The method uses a generative model A - CycleGAN to translate human videos into robot demonstrations using a new - designed generative models A - CycleGAN and train the meta - policy in the imagined compact latent space with the proposed adaptive loss. Experiments show that the proposed method achieves the comparable performance to the baseline on fast learning a set of vision - based tasks through watching a single video demonstration.
SP:fedf5c75e83d6ab41ef9d5daa9054ffe4e424ec2,"This paper proposes to use weight norm constrained training to improve the generalization performance of neural networks trained with gradient - based optimizers ( Adam ). The authors argue that the weight norm - constrained training can improve the adaptivity of the neural network and improve the performance of the adaptive optimizer ( SGD ) in the weight space. The main contribution of the paper is the introduction of weight norm regularization ( WN ), which is an extension of the weight decay ( WD ) technique. The WN regularization is used to force the weights of the network to be close to the norm of the training loss, which improves the generalizability of the model. The method is evaluated on a variety of tasks, optimizers and batch sizes."
SP:819df8d847a99f13ed5efdcabae8b464c12b464b,"This paper proposes a new method for group equivariant convolutional neural networks ( G - CNNs ). The main idea is to learn different levels of equivariance at each layer of the network. In particular, the authors propose to learn partial and full equivariances from data at every layer end - to - end. The proposed method is evaluated on MNIST, 6 / 9 classification, and natural image classification. The results show that the proposed method performs on par with the full - level models, and outperforms them in some cases."
SP:0c0ca9df96f1fa2eb8b83a47d0d5964590fef290,"This paper proposes an amortized Langevin dynamics ( ALD ) method for deep latent variable models. ALD replaces the datapoint - wise MCMC iterations with updates of an inference model that maps observations into latent variables. The authors prove that ALD has the target posterior as a stationary distribution under some assumptions. Furthermore, ALD can be extended to sampling from an unconditional distribution such as an energy - based model, enabling more flexible generative modeling by applying it to the prior distribution of the latent variable. Based on ALD, the authors construct a new deep latent variables model named the Langevin autoencoder ( LAE )."
SP:5631097031c7e599bdeae64366ffa6e4558837c6,"This paper proposes Sparse and local Neural Logic Machines ( SpaLoc ), a structured neural network for hypergraph reasoning. To leverage the sparsity in hypergraph neural networks, SpaLoc represents the grounding of relationships such as parent and grandparent as sparse tensors and uses neural networks and finite - domain quantification operations to infer new facts based on the input. The paper also introduces a sparsification loss to regularize the number of hyperedges in intermediate layers of a SpaLoc model. To enable training on large - scale graphs such as real - world knowledge graphs, the paper makes training and inference - time sub - sampling of the input graphs. To remedy the information loss in sampled sub - graphs, a novel sampling and label calibration paradigm based on an information - theoretic measure information sufficiency is proposed. SpaLoc shows superior accuracy and efficiency on synthetic datasets compared with prior art and achieves state - of - the - art performance on several real - life knowledge graphs."
SP:9657121b01c51f78c00d06b47d3e8d678dd85d54,"This paper proposes a new family of differentiable top - k cross - entropy classification losses, which relax the assumption of a fixed k. The authors show that relaxing k does not only produce better top - 5 accuracies, but also makes models more robust, which leads to top - 1 accuracy improvements. The paper also proposes splitter selection nets, which require fewer layers than existing selection nets and achieve new state - of - the - art results ( for publicly available models ) on ImageNet1K."
SP:cb3188f435c54a365890e20e4d582c250d919833,"This paper proposes a new method for solving large - scale optimal transport ( OT ) problems. The proposed method is built on the Douglas - Rachford splitting ( DRF ) technique, which is used to solve the original OT problem directly instead of solving an approximate regularized problem, as many state - of - the - art techniques do. This allows the authors to provide sparse transport plans and avoid numerical issues of methods that use entropic regularization. The algorithm has the same cost per iteration as the popular Sinkhorn method, and each iteration can be executed efficiently, in parallel. The authors also establish a linear convergence rate for their formulation of the OT problem. They detail an efficient GPU implementation of the proposed method that maintains a primal - dual stopping criterion."
SP:9a087cc734a3e7f3ab848bef5e2eff37fe40f303," data is drawn from a distribution of distributions, where clients are drawn from meta - distributions, and their data are from local data distributions. The authors propose a framework to disentangle performance gaps between clients and their local distributions, which they call participation gap. They also propose a dataset synthesis strategy for realistic simulation without naturally - partitioned data.   The authors present a systematic study of generalization in FL across six tasks. They observe that focusing only on out - of - sample gaps misses important effects, including differences in generalization behavior across naturally - partitioned and synthetically - divided federated datasets. They use their results to inform a series of recommendations for future works studying generalization."
SP:da0e8c89f343abfe500eb4c1968e418c2fb52ef6,This paper studies the effectiveness of powerful few - shot learning methods on pretrained language models from the BERT family in the zero - shot setting. The authors propose a simple Multi - Null Prompting ( MQP ) strategy to improve the performance and robustness of the pre - trained BERT models. They also conduct a coarse - to - fine study to learn the influence of multiple components in their proposed method.
SP:9817dccb1a121058b23a2ef825ed339cf8b53674,This paper proposes a method to improve the alignment and interpretability of the attention mechanism in image recognition tasks. The key idea is to use a sharpener module to align the relevant parts of the encoded image with the target output. The proposed method is based on the idea of target - specific sharpening. The sharpening is done by using an image sharpening module. The method is evaluated on two datasets : handwritten digits and real - world scene text recognition.
SP:3913ed3b3cf6494368e3be6cacb637ff85f80ee6,"This paper proposes a deep reinforcement learning - based approach to solve the vehicle routing problem ( VRP ), which is a combinatorial optimization problem with a fixed number of vehicles. The authors propose a supervised approach that constructs a complete tour plan from scratch while respecting an apriori fixed vehicle number. The proposed approach is shown to be much faster and easier to train than existing deep learning approaches. In addition, the authors propose an efficient post - processing scheme to further improve the performance of the proposed approach."
SP:594a813c0d0baa66738b9c8331370f861ad3c416,This paper proposes a link prediction method that uses counterfactual inference to learn the causal relationship between two variables : ( 1 ) the observed graph structure and ( 2 ) the existence of link between a pair of nodes. The proposed method uses a GNN - based model to predict both factual and counterfactually links. The method is evaluated on several benchmark datasets and compared with several baselines.
SP:48a7e50451b887f55be17b2662aa11ce18791cc1,"This paper proposes a two - stage unsupervised feature selection method based on the knowledge contrastive disTillation ( SOFT ) model that incorporates the second - order covariance matrix with the first - order data matrix for feature selection. In the first stage, the authors learn a sparse attention matrix that can represent the second order relations between features, and in the second stage, they build a relational graph using the learned attention matrix and perform graph segmentation. Experimental results on 12 public datasets show that SOFT outperforms classical and recent state - of - the - art methods, which demonstrates the effectiveness of SOFT."
SP:14bcae11aeede63f28d1b80c05ed18a01d3e3f3c,"This paper proposes a new multimodal variational autoencoder ( VAE ) model for multi - modal data. The main idea is to use a semisupervised VAE to combine information between modalities implicitly through mutual supervision. This formulation naturally allows learning from partially - observed data where some modalities can be entirely missing, something that most existing approaches either can not handle, or do so to a limited extent. The authors demonstrate that the proposed model outperforms baselines on standard metrics across both partial and complete observation schemes on the MNIST - SVHN ( image - image ) and CUB ( image – text ) datasets."
SP:e834a52cadebe5f125ce491273b4ad1146beae3f,"This paper proposes to combine intrinsic and extrinsic rewards in the Dopamine framework, to learn from intrinsic reward in Deep Reinforcement Learning. The authors introduce a new multi - agent buffer - selection algorithm, showing that agents can benefit from observing data that is interesting accoding to others. They also introduced a new architecture to combine the intrinsic reward learning as an auxiliary task, resulting in a 50% faster runtime and stronger representation. The experiments on hard and easy exploration games of the Atari Suite, following a benchmarking study to ensure fairness, show that the proposed method outperforms the baselines in 4 of the 6 tested games."
SP:41578dd1a4bdb043b3d68afa5f9cebb3e14f3907,This paper proposes a new method for learning Hamiltonian dynamical systems from data. The authors propose a new metric SAI ( stiffness - aware index ) to classify the training data into stiff and non - stiff portions. This classification along with a resampling technique allows them to apply step size adaptation strategies to better capture the dynamical characteristics of the Hamiltonian vector fields. They validate the SANN method with complex Hamiltonian dynamics including a three - body problem and billiard model and show that SANN can accurately predict the stiff dynamics and significantly outperform the existing methods.
SP:bfb0a059eeb6f40a18fbd20c0eec5037a64ca09e,"This paper proposes to train Transformer language models to perform multi - step computations by asking them to emit intermediate computation steps into a “ scratchpad ”. The scratchpad is composed of a sequence of intermediate steps, and the model is trained to predict the result of the intermediate steps. The authors show that this approach can improve the performance of Transformer models on a series of tasks ranging from long addition to the execution of arbitrary programs. They also show that the scratchpad generation window size is limited to 512 tokens."
SP:e6c1a8b4bba287455dc9cf145b6bd1f04e2148a9,"This paper proposes a novel adversarial perturbation method to attack feature - level adversarial associations in deep neural networks. The proposed method is based on deep image generators and a novel optimization objective. The authors show that the proposed method can generate targeted adversarial attacks at the ImageNet scale that are interpretable, universal to any source image, and physically - realizable. These attacks can also reveal spurious, semantically -describable feature / class associations that can be exploited by novel combinations of natural objects. They also use them to guide the design of copy / paste attacks in which one natural image is pasted into another to induce an unrelated misclassification. Based on these findings, the authors emphasize the importance of cautious deployment for vision networks and their fortification against these types of feature-level adversarial attack."
SP:873618263dc4246a39c44d0abfecfb5f688817e3,"This paper presents a neural - augmented version of simulated annealing ( SA ), where the SA chain is a trajectory from an MDP, and the proposal distribution can be viewed as a policy, which can be optimised for higher solution quality given a fixed computational budget. The proposed method, called Neural SA, is trained using a lightweight neural architecture, with a number of learnable parameters of the order of 100s or fewer. The authors show that this Neural SA with such a learnt proposal distribution outperforms SA baselines with hand - selected parameters on several problems : Rosenbrock ’s function, the Knapsack problem, the Bin Packing problem and the Travelling Salesperson problem."
SP:cae31f7436920eb3946e3f5bca0ac88a73d7c3ec,"This paper introduces a new notion, the $ \delta$-stationarity, to explicitly measure the non - stationarity of a policy sequence, which can be bounded by the KL - divergence of consecutive joint policies. The authors propose a trust - region decomposition network ( TRD - Net ) based on message passing to estimate the joint policy divergence more accurately. The proposed algorithm MAMT combines message passing and mirror descent with the purpose to satisfy the $\delta$. Experiments show that the proposed algorithm can bring noticeable and stable performance improvement compared with baselines in cooperative tasks of different complexity."
SP:989b58167a15ae4fafbe27ff534d327991b6c4d7,"This paper proposes a self - supervised representation learning framework for audio - visual speech, which masks multi - stream video input and predicts automatically discovered and iteratively refined multimodal hidden units. The proposed method, called Audio - Visual Hidden Unit BERT ( AV - HuBERT ), learns powerful audio - Visual speech representation benefiting both lip - reading and automatic speech recognition. On the largest public lip - reader benchmark LRS3 (433 hours ), AV -HuBERT achieves 32.5 % WER with only 30 hours of labeled data, outperforming the former state - of - the - art approach ( 33.6 % ) trained with a thousand times more transcribed video data ( 31 K hours ) ( Makino et al., 2019 ). The lip reading WER is further reduced to 26.9 % when using all 433 hours of labelled data from L RS3 and combined with self - training. On audio - only speech recognition, the proposed method leads to a 40 % relative WER reduction over the previous SOTA."
SP:7c9eb8aa4a4dcb5965157d860e812d81654e3aa7,"This paper proposes a new algorithm, ECORD, for combinatorial optimization on graphs. The main idea of ECORD is to restrict the GNN to a single pre - processing step, before entering a fast - acting exploratory phase directed by a recurrent unit. Experiments show that ECORD achieves a new SOTA for RL algorithms on the Maximum Cut problem, while also providing orders of magnitude improvement in speed and scalability."
SP:f741d980c9c560a21298e947f1605dcbab7ceeac,"This paper proposes a new VAE training method for VAEs with discrete latents. The main idea is to use a variational autoencoder ( VAE ) with truncated posteriors, where the posterior of the decoder is parameterized by DNNs. The authors show that this approach can be used in conjunction with evolutionary algorithms to improve the performance of the VAE. They also show that the proposed method is more efficient than amortized VAEs. The paper also shows that the method is competitive in zero - shot learning."
SP:deb189d37bd51b92762ce259a106d9a9e9d81ea4,"This paper proposes an unsupervised method to identify effects on the environment controlled by the agent. The proposed method, called Controlled Effect Network ( CEN ), is composed of a two - branch forward model and a counterfactual model that creates a normal and controlled view of the world. CEN can disentangle effects precisely, outperforming state - of - the - art approaches to detect controlled effects. The authors also evaluate CEN as an intrinsic motivator by replacing the action - prediction model in Never Give Up ’s ( Badia et al. 2020b ) episodic reward with CEN."
SP:ea18d57904e25fd09ed0f6c9972029d78779a8a6,"This paper proposes a new method for lightweight image super - resolution ( SR ) networks. The proposed method is based on the idea of structure - regularized pruning ( SRP ), which imposes regularization on the pruned structure to make sure the locations of pruned filters are aligned across different layers. Specifically, for the layers connected by the same residual, the authors select the filters of the same indices as unimportant filters and use L2 regularization to drive the weights towards zero so that eventually their absence will cause minimal performance degradation. The authors apply SRP to train efficient image SR networks, resulting in a lightweight network SRPN - L and a very deep one SRPN."
SP:0dee45001ae9600f485614dfe6874a516ac01db5,"This paper proposes a framework for few - shot learning that tackles large domain shift between base and novel categories. The first step of the framework trains a feature extracting backbone with the contrastive loss on the base category data. For the second step, a masking module is trained to select relevant features that are more suited to target domain classification. Finally, a classifier is fine - tuned along with the backbone such that the backbone produces features similar to the relevant ones. To evaluate the framework, the authors tested it on a recently introduced cross - domain few shot learning benchmark."
SP:92aa611d71a8da597358330d84fddbb90de2cf4f,"This paper investigates the effect of architecture and gradient descent on the generalization performance of neural networks. In particular, the paper focuses on two types of networks : infinite width networks trained by Bayesian inference and finite width neural networks trained with gradient descent. The paper provides an analytical generalization bound on the neural network - Gaussian process ( NNGP ) posterior, and shows that gradient descent can further improve generalization by selecting networks with a large margin. This finding corroborates the findings of Valle - Pérez et al. ( 2019 ) and underscoring the importance of architecture."
SP:a0e3cf719a95bbc5aad2f663ba5a3169c316ee9b,"This paper focuses on enhancing the cross - lingual transfer performance on cross - linguistic understanding tasks. The authors propose the X - Mixup method, which adaptively calibrates the representation discrepancy and gives compromised representations for target languages. The method uses the manifold mixup between the source and target languages to improve the performance of the source language. Experiments on the XTREME benchmark show X -Mixup achieves 1.8% performance gains on multiple text understanding tasks, compared with strong baselines, and reduces the cross-lingual representation discrepancy significantly."
SP:19f8cd8f0c274b6141ba097d2ebb6d18af0986fd,"This paper studies the problem of Byzantine robust distributed or federated learning, where a fraction of workers may deviate from the prescribed algorithm and send arbitrary messages to the server. The authors propose a simple bucketing scheme that adapts existing robust algorithms to heterogeneous datasets at a negligible computational cost. They also theoretically and experimentally validate their approach, showing that combining bucketing with existing robust algorithm is effective against challenging attacks. Their work is the first to establish guaranteed convergence for the non - iid Byzantine robust problem under realistic assumptions."
SP:4d63513b9a1b9b9fc44a69b3d5679a8f48eb95e7,"This paper studies the relationship between disentanglement and multi - task learning based on hard parameter sharing. The authors perform a thorough empirical study of the representations obtained by neural networks trained on automatically generated supervised tasks. Using a set of standard metrics, the authors show that disentangled representations appear naturally during the process of multi-task neural network training. They verify their hypotheses by training multiple models in single - and multi- task settings and investigating the level of disentangling achieved in their latent representations. In their experiments, they find that in a hard - parameter sharing scenario multi - tasks learning indeed seems to encourage disentangle. However, it is inconclusive whether disentangles representations have a clear positive impact on the models performance, as the obtained by them results in this matter vary for different datasets."
SP:9851adb72e2918780f661f83f7da06eb866787be,"This paper proposes a framework of certifying robust policies ( CROP ) for reinforcement learning against adversarial state perturbations. Specifically, CROP uses a local smoothing algorithm that uses a policy derived from Q - functions smoothed with Gaussian noise over each encountered state to guarantee the robustness of actions taken along this trajectory. The authors also propose a global smoothing method for certifying cumulative rewards. Finally, the authors evaluate the effectiveness of the proposed CROP on three Atari games."
SP:78da3c97182ec1baf6a131740bf7c91a9afb2fd2,"This paper proposes a new approach to conformal prediction, which aims to output a precise set of promising prediction candidates that is guaranteed to contain a limited number of incorrect answers. Conformal prediction provides the ability to adapt to model uncertainty by constructing a calibrated candidate set in place of a single prediction, with guarantees that the set contains the correct answer with high probability. In order to obey this coverage property, conformal sets can often become inundated with noisy candidates, which can render them unhelpful in practice. This is particularly relevant to large - scale settings where the cost (monetary or otherwise ) of false positives is substantial, such as for in - silico screening for drug discovery, where any positively identified molecular compound is then manufactured and tested. The authors propose to trade coverage for precision by enforcing that the presence of incorrect candidates in the predicted conformal set is bounded according to a user - specified tolerance. Subject to this constraint, their algorithm then optimizes for a generalized notion of set coverage ( i.e., the true positive rate ) that allows for any number of true answers for a given query ( including zero ). They demonstrate the effectiveness of this approach across a number of classification tasks in natural language processing, computer vision, and computational chemistry."
SP:b126d2f3c397633745c8833e22ace93a2470e963,"This paper studies the effect of initialization on the distortion of the length and volume of a ReLU network. The authors show that the distortion does not grow exponentially with depth, and indeed shrinks slightly. They also generalize this result by proving upper bounds for higher moments of the distortion and distortion of higher - dimensional volumes. Theoretical results are corroborated by experiments."
SP:b3b6d0512edfca461ea295ee8665f7f226c45d57,"This paper proposes SAFER, a behavioral prior learning algorithm that learns to extract a safety variable from offline data that encodes safety requirements, as well as the safe primitive skills over abstract actions in different scenarios. In the inference stage, SAFER composes a safe and successful policy from the safety skills according to the inferred safety variable and abstract action. The authors demonstrate its effectiveness on several complex safety - critical robotic grasping tasks inspired by the game Operation, in which SAFER outperforms baseline methods in learning successful policies and enforcing safety."
SP:a5dadb3ecc3caed3b9d9a68eda0d48a53c2d1ce2,"This paper proposes a multi - branch neural network architecture for image restoration. The architecture is inspired from the Human Visual System ( i.e., Retinal Ganglion Cells ), which can achieve multiple restoration tasks in a general framework. The experiments show that the proposed architecture, called CMFNet, has competitive performance results on four datasets, including image dehazing, deraindrop, deblurring, and streak rain removal."
SP:263b386beee44b0b45b6f6dc3cf80d020500be62,"This paper proposes a new federated learning setup, Inference - time PFL ( IT - PFL ), where a model trained on a set of clients needs to be later evaluated on novel unlabeled clients at inference time. The proposed approach is based on a hypernetwork module and an encoder module. Specifically, the encoder network learns a representation for a client given its unlabelled data. That client representation is fed to a hyper network that generates a personalized model for that client. The paper also analyzed the generalization error for the novel client, showing how it can be bounded using results from multi - task learning and domain adaptation."
SP:960d0a63a82593f6e72275b65f0501f0469d1924,"This paper presents an approach to visualize the representations learned by self - supervised learning models. The authors use a conditional diffusion - based generative model ( RCDM ) to generate images from a representation conditioned on a conditioning representation. They show that the generated images are faithful to the representation used as conditioning. They also show that SSL ( backbone ) representations are not really invariant to many data augmentation they were trained on, and that SSL projector embedding appear too invariant for tasks like classifications. Finally, they demonstrate that SSL representations are more robust to small adversarial perturbation of their inputs."
SP:398899e6c86b4a2a17dfa5c2f4478811f4331c1d,"This paper studies the intrinsic differential privacy of Fp sketches, a well - known streaming algorithm for frequency moments estimation. The authors prove that Fp sketch is differentially private as is when p \in ( 0, 1 ) and n M, and provide a new sensitivity definition called pure multiplicative sensitivity. The paper also provides a theoretical analysis of the space complexity of the algorithm.    The main contribution of the paper is the proof of the differential privacy property of the proposed algorithm. The main result shows that the algorithm can achieve reasonable accuracy with differential privacy guarantee."
SP:3253b13851b5a3b5e3c8c6e24891db05903a4e57,"This paper proposes a novel policy optimization method to find novel strategies that are both locally optimal and sufficiently different from existing ones. The key idea is to use a trajectory - based novelty measurement during the optimization process to encourage the learning policy to consistently converge towards a previously undiscovered local optimum. To this end, RSPO switches between extrinsic and intrinsic rewards via a trajectory-based novelty measurement. The proposed method is both general and effective across a variety of single - agent and multi - agent domains. The experiments show that it is able to discover a wide spectrum of strategies in a wide range of domains."
SP:e3ab3aa87ab023bd9949b99a17d4b6e26c1473c0,"This paper proposes a method for finding fast diffusion model samplers for Denoising Diffusion Probabilistic Models ( DDPMs ). The main idea is to optimize a perceptual loss over a space of diffusion processes that makes use of a pre - trained DDPM ’s samples by leveraging the reparametrization trick and gradient rematerialization. The proposed method, called Differentiable Diffusion Sampler Search ( DDSS ), finds a parametric family of Generalized Gaussian Diffusion Model ( GGDM ) that admits high - fidelity sampling for diffusion models by minimizing the Kernel Inception Distance ( KID ). Experiments show that the proposed method is able to significantly improve sample quality for unconditional image generation over prior methods."
SP:7a7506f2b5500a573c0cfb8b0822e5ea725c886a,"This paper proposes P - adapters, lightweight models that sit between the embedding layer and first attention layer of LLMs. They take LLM embeddings as input and output continuous prompts that are used to query the LLM. Additionally, they investigate Mixture of Experts ( MoE ) models that learn a set of continuous prompts ( “ experts ” ) and select one to query. They require a separate classifier trained on human - annotated data to map natural language prompts to the continuous ones. They perform comparably to more complex MoE models in extracting factual information from BERT and RoBERTa while eliminating the need for additional annotations."
SP:35cdf71f027cc5168b55cc34c64bfb2f3087d6f5,"This paper proposes a new continuous classification of time series ( CCTS ), which aims to achieve the high - accuracy classification at every time. The key idea is to model multiple distributions simultaneously, which is hard to achieve in existing models due to their independent identically distributed premise. Two main problems are the catastrophic forgetting and the overfitting. To overcome these two main problems, the authors propose a novel Adaptive model training policy ACCTS. Its adaptability represents in two aspects : ( 1 ) Adaptive multi - distribution extraction policy. Instead of the fixed rules and the prior knowledge, ACCTS extracts data distributions adaptive to the time series evolution and the model change. The authors also propose an Adaptive importance - based replay policy. Experiments on four real - world datasets show that ACCTS can classify more accurately than all baselines at each time step."
SP:d9b74b749aa465496763d3a3a9bf3a53e800587e,"This paper proposes to use kNN - augmented attention to improve the performance of Transformer - based language models. The key idea is to use an external memory to store the context information at inference time, which is then used to update the weights of the Transformer at test time. The idea is that the external memory can be used to store more context information than the internal memory, which can be stored in a differentiable manner. The paper shows that the performance improves with the size of external memory. The authors also show that the model is able to make use of newly defined functions and theorems during test time, and that it can generalize to larger memory sizes."
SP:7a1bbf86c3fdb8738aa826ca330493e857d050ba,"This paper proposes a sampling scheme based on the Metropolis - Hastings Monte Carlo algorithm to sample from the masked language modeling ( MLM ) objective. The authors interpret MLMs as energy - based sequence models and propose two energy parametrizations derivable from the trained MLMs. In order to draw samples correctly from these models, the authors develop a tractable sampling scheme. The proposed sampling scheme uses the same masked conditionals used for training the MLM models and they are accepted or rejected based on their energy values according to the target distribution.   The authors validate the effectiveness of the proposed parameteretrization by exploring the quality of samples drawn from these energy based models for both open - ended unconditional generation and a conditional generation task."
SP:011626ba4fafee13d4a30e3f13c1df5b7071a7f1,"This paper proposes DND, a data augmentation policy learning method for NLP tasks. The main idea is to construct more diverse and challenging samples for providing informative training signals, while avoiding the risk of losing the semantics of original samples. To this end, the authors design a novel reward function for updating the augmentation policies to construct difficult but not too different samples ( DND ). In addition, they introduce a sample re - weighting scheme to focus on difficult augmented samples after the original ones are learned confidently for more effective learning from the augmented ones. Their learning - based augmentation outperforms the recent state - of - the - art augmentation schemes on various text classification tasks and GLUE benchmark by successfully discovering the effective augmentations for each task."
SP:69d41a862ea189f72d4e8af2854e27b95a91fa41,"This paper proposes a method for offline reinforcement learning based on task - specific attention mechanism and contrastive learning. Specifically, the authors propose a batch - wise gated attention to recalibrate the weights of transition samples, and use sequence - wise self - attention to better capture the correlation within the transition ( state, action, reward ) dimensions. The authors also propose a matrix - form objective of the Momentum Contrast ( MoCo ) for task - level representation learning, by replacing its dictionary queue with a meta - batch sampled on - the - fly. Theoretical analysis and experiments are presented to demonstrate the superior performance and robustness of the end - to - end and model - free framework compared to prior algorithms across multiple meta - RL benchmarks."
SP:ed86c60850d5c8302dcf1c2167db303e778fe681,"This paper proposes an inference - time improvement framework for parametric sequential generative modeling methods called belief fine - tuning ( BFT ). BFT leverages approximate dynamic programming to determine the model parameters at each time step. It can improve the accuracy of the belief model at test time because it specializes the capacity of the model to the space of local observations. This specialization occurs after the action or policy has already been decided, so BFT does not require the belief models to process it as input. The paper shows that BFT enables approximate public belief state search in imperfect - information games where the number of possible information states is too large to track tabularly."
SP:6150725599c10f0e26f0d7cb1fc04b5b227a4456,"This paper proposes Pixelated Butterfly, a method to speed up the training of neural networks. The method uses a simple fixed sparsity pattern based on flat block butterfly and low - rank matrices to sparsify most network layers ( e.g., MLP, ViT, MLPMixer, etc. ). The proposed method is 3x faster than butterfly and speeds up training to achieve favorable accuracy - efficiency tradeoffs. On the ImageNet classification and WikiText-103 language modeling tasks, the sparse models train up to 2.5x faster with no drop in accuracy."
SP:136e31054a55abca840f6478491972023c2296cb,"This paper proposes a novel conditional diffusion probabilistic model ST - DDPM, which explicitly models the class center in the forward and reverse process, and make an elegant modification to the original formulation, which enables controllable generation and gets interpretability. To verify the effectiveness of the formulated framework, the authors conduct extensive experiments on the task of conditional image generation, free - form image inpainting Yu et al. ( 2019 ), attribute - to - image synthesis Yan et al ( 2016 ), and text to image synthesis, and achieve competitive results compared with the state - of - the - art."
SP:fc2196f1f4ecd864398fed6640ff3f8b19870763,"This paper proposes a new method for domain generalization ( DG ) based on sub - space exploration. The main idea is to learn diverse latent sub - spaces and learn individual hypotheses on them. The authors argue that this approach avoids the assumption of the existence of fixed domain - invariant features and common hypotheses learned from a set of training domains. Instead, they propose a LAtent Sub - Space Orientation ( LASSO ) method that explores diverse sub - subspaces and learns individual hypotheses. The proposed method is evaluated on several well - known DG benchmarks, where it achieves state - of - the - art results."
SP:6e8e5bdeb77e3cafe1975da8411fb65118955d14,"This paper proposes three generalizations of the ROOT KT algorithm of Dwivedi & Mackey ( 2021 ) with improved guarantees for generating compact representations of a probability distribution. Specifically, the authors show that ROOTKT yields tighter, dimension - free guarantees for any kernel, any distribution, and any fixed function in the reproducing kernel Hilbert space ( RKHS ). They also show that, for analytic kernels like Gaussian, inverse multiquadric, and sinc, target KT admits maximum mean discrepancy ( MMD ) guarantees comparable to or better than those of square - root KT without making explicit use of a square root kernel. Finally, they prove that KT with a fractional power kernel yields better - than - Monte Carlo MMD guarantees for non - smooth kernels, like Laplace and Matérn, that do not have square - roots."
SP:645c3f1864aa843d4899fc2406f694b5aab8460d,"This paper presents an open - source benchmark suite for the Maximum Independent Set ( MIS ) problem, which is an NP - hard combinatorial optimization problem. The benchmark suite provides a unified interface to various state - of - the - art traditional and machine learning - based solvers. The paper also conducts an in - depth analysis of the popular guided tree search algorithm by Li et al. [ NeurIPS 2018 ], testing various configurations on small and large synthetic and real - world graphs. By re - implementing their algorithm with a focus on code quality and extensibility, the paper shows that the graph convolution network used in the tree search does not learn a meaningful representation of the solution structure, and can in fact be replaced by random values. The tree search relies on algorithmic techniques like graph kernelization to find good solutions, and the results from the original publication are not reproducible."
SP:155ecd17d264a084b014abdfd0362146d8fb07e0,"This paper proposes Wavelet Compressed Convolution ( WCC ), a novel approach for activation maps compression for 1x1 convolutions. The WCC achieves compression ratios and computational savings that are equivalent to low bit quantization rates at a relatively minimal loss of accuracy. To this end, they use a hardware - friendly Haar - wavelet transform, known for its effectiveness in image compression, and define the convolution on the compressed activation map. WCC can be utilized with any 1×1 convolution in an existing network architecture. By combining WCC with light quantization, they show that they achieve compression rates equal to 2 - bit and 1 - bit with minimal degradation in image - to - image tasks."
SP:004865e6affad32403b7965493a53c8a7ffdda0a,"This paper proposes a no - regret learning dynamics for extensive - form correlated equilibrium ( EFCE ) in multiplayer general - sum imperfect - information extensive form games. The main contribution is to connect predictive regret minimization with the framework of - regret. One of the main technical contributions is to characterize the stability of certain fixed point strategies through a refined perturbation analysis of a structured Markov chain. Finally, experiments on standard benchmarks corroborate the theoretical findings."
SP:ee545ff83df4d7ff256ac61fbe0eb0765f52f1d5,"This paper proposes Action Quantization from Demonstrations ( AQuaDem ) to learn a discretization of continuous action spaces by leveraging the priors of demonstrations. By discretizing the action space, the proposed method can apply any discrete action deep RL algorithm to the continuous control problem. The proposed method is evaluated on three different setups : RL with demonstrations, RL with play data, and Imitation Learning. The experimental results show that the proposed methods outperform state - of - the - art continuous control methods on every setup."
SP:4b39279b98d6aa311bb49dd1384925f9d6f66c2d,"This paper proposes a novel adversarial style augmentation ( AdvStyle ) for domain generalization ( DG ) in semantic segmentation. Specifically, AdvStyle dynamically generates hard stylized images by learning adversarial image - level style feature, which can encourage the model learning with more diverse samples. Experiments on two synthetic - to - real settings show that AdvStyle can largely improve the generalization performance and achieve state - of - the - art performance. In addition, it can be employed to single DG in image classification and obtain significant improvement."
SP:4a2e6d70b383e4941e0bc44e7e82972b22e26792,"This paper proposes a novel approach for mid - air gesture recognition. The approach consists of an event - based guided Variational Autoencoder ( VAE ) and an encoder model that learns to represent sparse, high - dimensional visual data captured at the sensor in a small number of latent dimensions. The encoder is jointly trained by two classifiers such that the latent space disentangles and accurately represents target features. The algorithm represents a significant step towards self - supervised gesture recognition by measuring the similarity of gesture data in real - time with a learned, perceptually - relevant metric. The authors show that the Hybrid GuidedVAE achieves 87% classification accuracy on the DVSGesture dataset and it can encode the sparse, noisy inputs into an interpretable latent space representation."
SP:2e66468a6b94177e54b0052b97713ee63902c278,"This paper proposes a Sparse Hierarchical Table Ensemble ( S - HTE ) architecture for tabular data. The S -HTE uses ferns as the basic computing component, with a single active word for each fern, making is extremely efficient and particularly applicable for low - end CPU - based devices. The experimental results show that the accuracy results obtained by S - HTE are often comparable to state - of - the - art architectures, as measured on a recent benchmark."
SP:b238db9252d83a13438bb747d70e635bb9945958,"This paper proposes a new offline RL method called Latent action Q - learning ( LAQ ) to learn value functions from undirected state - only experience. The proposed method is based on tabular Q learning, where the value function is learned from discrete latent actions obtained through a latent - variable future prediction model. The authors show that the proposed method can recover value functions that have high correlation with value functions learned using ground - truth actions. They also show that LAQ approximates a refinement of the latent space better than clustering alternatives, and in turn, learns value functions highly correlated with ground truth. The method is evaluated in 5 environments ranging from 2D grid world to 3D visual navigation in realistic environments."
SP:108ebe9045a9e2b8b5aba8352733782462db8a81,"This paper proposes SWARM parallelism, a model parallelism method for training large models on unreliable, preemptible, poorly connected, heterogeneous unreliable devices. The authors propose SWARM to overcome the challenges of pipeline parallelism for preemptible devices with heterogeneous network bandwidths and computational throughputs. To further reduce the network usage of the approach, the authors develop several compression - aware architecture modifications and evaluate their tradeoffs. Finally, they combine their insights to train a large Transformer language model with 1.1 B shared parameters on a swarm of preemptible T4 GPUs with less than 400 Mb/s network throughput."
SP:91d2f094d5481651b554f58aecc2a6207057a47c,"This paper proposes a method for bridging offline training and online tuning in decentralized MARL. The proposed method, called Online Transition Correction ( OTC ), consists of two types of distances, i.e., embedding - based and value - based distance, to measure the similarity between transitions, and an adaptive rank - based prioritization to sample transitions for updating the agent policy according to the transition similarity. Experimental results show that OTC outperforms baselines in a variety of tasks."
SP:d0e650d568214481b07a0452ec606ccbf6d05410,"This paper proposes a logarithmic unbiased quantization ( LUQ ) method to quantize both the forward and backward phase of neural networks to 4 - bit. The authors analyze the difference between two rounding schemes : round - to - nearest and stochastic - rounding. They show that the former has lower MSE and works better for the quantization of the forward phase ( weights and activations ), while the latter is an unbiased approximation of the original data. Based on these conclusions, the authors propose to use an unbiased quantizer (LUQ ) to quantized the neural gradients to format FP4 [ 1, 3, 0 ]. Combined with a known method for quantizing the weights and activation to INT4, they achieve state - of - the - art in 4 - bits training in all the models."
SP:f2862d1f987164ed6c3c375cd8962e57c369373b,"In this paper, the authors focus on the problem of few - shot meta - learning in the context of polythetic classification. The authors show that threshold meta - learners, such as Prototypical Networks, require an embedding space that is exponential in the number of active features and that attentional classifiers are overly sensitive and susceptible to misclassification. To address this, they propose a self - attention feature - selection mechanism that adaptively dilutes non - discriminative features. They demonstrate the effectiveness of their approach in meta learning Boolean functions, and synthetic and real - world few shot learning tasks."
SP:e1e513fef25d29e17cdadd1b36d932a8ad8897cd,"This paper proposes a communication protocol between agents trained with reinforcement learning to communicate via continuous acoustic signals. The communication protocol consists of two agents : a speaker and a listener. The speaker uses a vocoder to communicate a concept to the listener, and the listener uses a decoder to translate the concept into a continuous waveform. The decoder is trained with Q - learning. The authors show that the communication protocol is established between agents communicating freely, and that basic compositionality emerges in the learned language representations. They also show that noise is essential in the communication channel when conveying unseen concept combinations, and they show that they can ground the communication by introducing a caregiver predisposed to “hearing ” or “speaking ” English."
SP:0e6ff65ba4a3df35947d1b6f4d438612088d90a0,"This paper proposes a novel backdoor attack to attack pre - trained NLP models. The authors propose a two - stage backdoor scheme to perform this attack. In the first stage, the attacker reconstructs the pre - training data by poisoning public corpus and fine - tune a clean foundation model with the poisoned data. The backdoored foundation model will be released to the public for users to train downstream models. At the second stage, to trigger the backdoors in a downstream model, the attackers can inject triggers to the input text and attack the target model. Besides, the authors also design a simple and effective trigger insertion strategy to evade a state - of - the - art backdoor detection method. Extensive experiments over 10 different types of downstream tasks and demonstrate that BadPre can achieve performance drop for up to 100 %."
SP:58d3ecb4a1906251e79ad883aa97cc2502642658,"This paper proposes a new method for skill discovery, called DISk, which learns skills incrementally in an unsupervised manner. The idea is that the skills are learned one after another in an incremental fashion, and the skill selection is done based on skill convergence. Experiments show that the proposed method outperforms the existing state - of - the - art skill discovery methods in both dynamic and static environments."
SP:2c6595408f5ec95537eaf555e5fe3d992b58c222,"This paper proposes a novel log - polar space convolution ( LPSC ) layer, where the convolution kernel is elliptical and adaptively divides its local receptive field into different regions according to the relative directions and logarithmic distances. The proposed method not only naturally encodes local spatial structures, but also greatly increases the single - layer receptive field while maintaining the number of parameters. Experiments on different tasks and datasets and datasets demonstrate the effectiveness of the proposed L PSC."
SP:7791f96b1eef277a9133975507a750d9e7c6b8ff,"This paper proposes a new information bottleneck based on the PAC - Bayes generalization guarantee, i.e., the information stored in weights ( IIW ). The paper derives an approximation of the intractable IIW and proposes a Bayesian inference algorithm grounded on stochastic gradient Langevin dynamics ( SGLD ) for sampling from the optimal weight posterior specified by IIW. Experiments show that the new information measure covers the wide ground of NN ’s behavior and can explain the performance drop w.r.t. the degree of label noise."
SP:a733847ade77ffbf38760fc79da17893dea8d53f,This paper investigates the effectiveness of data poisoning attacks. The authors find that the perturbations of advanced attacks are almost linear separable when assigned with the target labels of the corresponding samples. They further confirm that linear separability is indeed the workhorse for recent attacks. Their findings also suggest that the shortcut learning problem is more serious than previously believed as deep models heavily relies on shortcuts even if they are of an imperceptible scale and mixed together with the normal features. It also suggests that pre - trained feature extractors can be a powerful defense.
SP:7b50be406138ad01db3ee112899f622637896fe9,This paper proposes a new offline policy learning algorithm called Policy Optimization with ELigible Actions ( POELA ). The main idea is to constrain the potential action set to the set of observed actions with similar states to prevent improper avoidance to lower - reward initial states. The authors provide a theoretical justification of the proposed algorithm through a better per - state - neighbor normalization condition and show the limitation of previous attempts to this approach through an illustrative example. The experiments show the proposed method with less overfitting and better test performance compared with state - of - the - art batch reinforcement learning algorithms.
SP:c976752a55b9ff47dc63c95a9fd7b51a81e8a42e,"This paper presents CoLLIE, a method for continual learning of how language is grounded in vision. The method uses a pre - trained multimodal embedding model, where language and images are projected in the same semantic space ( in this case CLIP by OpenAI ). The model learns a transformation function that adjusts the language embeddings when needed to accommodate new language use. Unlike traditional few - shot learning, the model does not just learn new classes and labels, but can also generalize to similar language use and benefit from the semantic compositionality of language. The authors evaluate the model ’s performance on two different tasks of continual learning and show that it can efficiently learn and generalize from only a few examples."
SP:d3371b322acfc321ee79a2e1b438d82644872fa4,"This paper proposes VLAF2, a novel object captioning model that uses BERT and CLIP to improve the quality of the captions produced by the model. The key idea is to use CLIP - based rewards to encourage the model to produce captions with better linguistic fluency, fidelity, and adequacy. The proposed method is evaluated on the nocaps dataset and compared with other state - of - the - art novel captioning models."
SP:9f3b6486662d80350d77a4b060d4a5b8b22a6130,"This paper studies the problem of transfer learning in few - shot learning. The authors propose a new perspective on this problem by connecting it to the newly discovered phenomenon of neural collapse. They show that the within - class variance collapse tends to emerge in the test data associated with the classes encountered at train time and, more importantly, in new unseen classes when the new classes are drawn from the same distribution as the training classes. In addition, they show that when neural collapse emerges in new classes, then it requires very few samples to train a linear classifier on top of the learned feature representation that accurately predicts new classes."
SP:624c95d9ce1ee4b66274e858e2da22bef6b052c7,"This paper proposes a method for point cloud reconstruction based on sparse, noisy, and irregular point cloud obtained from 3D scanning. The method consists of a sparse stacked - hourglass network for densification and denoising, and a refinement via transformers converting the discrete voxels into 3D points. The proposed method improves the performance of transformer by a newly proposed module called amplified positional encoding. Extensive experiments demonstrate that the proposed method achieves state - of - the - art performance among the recent studies in the ScanNet, ICL - NUIM, and ShapeNetPart datasets."
SP:34a81ca65131576d4c14332a4e9eb3a4c344cab7,"This paper proposes a new method, PipeGCN, for efficient full - graph GCN training. The main idea is to use inter - partition communication with intra - partition computation to reduce the communication overhead in distributed GCNs. The paper also provides a theoretical analysis of the convergence of the proposed method and a smoothing method to speed up the convergence. Extensive experiments show the effectiveness of the method over vanilla distributed GCN and SOTA full - Graph training."
SP:8302d49558ee0f16392d623d4e604e92db10d041,"This paper proposes a method for test - time robustification, i.e., using the test input to improve model robustness. The authors propose a simple approach that can be used in any test setting where the model is probabilistic and adaptable : when presented with a test example, perform different data augmentations on the data point, and then adapt ( all of ) the model parameters by minimizing the entropy of the model ’s average, or marginal, output distribution across the augmentations. This objective encourages the model to make the same prediction across different augmentations, thus enforcing the invariances encoded in these augmentations and maintaining confidence in its predictions. The experiments show that this approach achieves accuracy gains of 1 - 8 % over standard model evaluation and also generally outperforms prior augmentation and adaptation strategies. For the setting in which only one test point is available, the authors achieve state - of - the - art results on the ImageNet-C, ImageNet - R, and, among ResNet-50 models, Imagenet - A distribution shift benchmarks."
SP:a985de5e940ff3a4160b378201b8c02f68d1914a,"This paper proposes a new model - based reinforcement learning algorithm that jointly optimizes the dynamics model and the policy. The main contribution of the paper is the use of a global lower bound on the expected return of the model. The paper proposes to use a GAN - like approach to train the model to produce transitions that look realistic, and update the policy to avoid states where the model predictions are unrealistic. The proposed method is evaluated on a variety of tasks. The results show that the proposed method outperforms the state - of - the - art methods on some tasks."
SP:a469fbcdc20b11dff4085b6fbc384e77f33cd37d,"This paper proposes an imitation learning method that combines the best of BC - SO and BC -OH. The authors argue that BC -SO relies excessively on extrapolating past actions, and fails to attend to important visual cues, while BC - OH relies on extrapolation only, and is suboptimally due to lack of information. To solve this problem, the authors propose a simple model combination approach inspired by human decision making : they first compute a coarse action based on the instantaneous observation, and then refine it into a final action using historical information. The experiments show that this method outperforms other baselines on CARLA autonomous driving from images and various MuJoCo continuous control tasks."
SP:95c4533b5d1a865c4cc6a54615e7ad6357bdaad1,"This paper proposes a model - based meta - learning method called DyAd to forecast physical dynamics. DyAd uses an encoder to infer the parameters of the task and a prediction network to adapt and forecast the inferred task. The model can also leverage any weak supervision signals that can help distinguish different tasks, allowing the incorporation of additional domain knowledge. Theoretically, the generalization error of such procedure is related to the task relatedness in the source domain, as well as the domain differences between source and target. On challenging turbulent flow prediction and real - world ocean temperature and currents forecasting tasks, DyAd shows superior performance of our model across heterogeneous dynamics."
SP:ec70553cb0c27e5349c1b8cce6bcaa96a83bf050,"This paper proposes a method for weakly supervised monocular 3D object detection. The main idea is to replace the 3D box labels used in existing methods with 2D boxes on the image. The proposed method is evaluated on the KITTI benchmark, where the proposed method outperforms the existing methods. The paper also proposes a network to predict 3D boxes which can tightly align with the corresponding RoI LiDAR points."
SP:34217c6a8ca43b8eeb9ddc83d6f1f0af05918984,"This paper proposes a soft gradient - based subword tokenization module ( GBST ) that automatically learns latent subword representations from characters in a data - driven fashion. GBST uses a block scoring network to score candidate subword blocks and learns to score them in a position - wise fashion using a neural network. The paper also proposes a deep Transformer model that integrates GBST and operates on the byte level. Experiments on English GLUE, multilingual, and noisy text datasets show that the proposed model outperforms a series of competitive byte - level baselines while generally performing on par and sometimes outperforming subword - based models."
SP:d26d25f2ef23a89a2c139d0dd87c4c86fddcff5e,"This paper addresses the problem of detecting backdoor attacks in black - box hard - label neural networks. The authors propose a novel adversarial adversarial approach, AEVA, which is based on the monte - carlo gradient estimation. The main idea is to use the adversarial singularity phenomenon in the training data of a backdoor - infected DNN to estimate the gradient of an adversarial map. The proposed AEVA algorithm is evaluated on three tasks with different backdoor trigger implementations and complex backdoor attack variants."
SP:c6dbca0ed0799b7fec21777606f6f809eb2d8c48,"This paper proposes a Kullback - Leibler divergence ( KLoS ), a second - order uncertainty measure that captures both in - distribution and out - of - distribution sources of uncertainty in a single score. The proposed measure is based on the class - probability simplex, where the KL divergence is computed using a prototype Dirichlet distribution. The paper further proposes an auxiliary neural network, KloSNet, to learn a refined criterion directly aligned with the evidential training objective. Experiments show that the proposed method outperforms the existing methods in detecting misclassification and OOD samples in open - world recognition."
SP:8b4f3916dca4e627931558e14836749bd4a6792f,"This paper studies the problem of learning convolutional neural networks ( CNNs ) under distributional assumptions. Specifically, it assumes that the distribution of important patches in the input images has a low - dimensional structure ( e.g., the patches are sampled from a low dimensional manifold ). Under this assumption, the paper proposes a two - step semi - supervised learning algorithm PAC that first constructs a representation based on an unlabeled set of examples, and then learns a linear classifier over the produced representation. The algorithm is very similar to the algorithm introduced by Coates et al. ( 2011 ) which empirically has performance which is close to the performance of neural networks on several image datasets. The authors show that the algorithm has run - time and sample complexity that depend on the covering number of the space of patches, and therefore the algorithm is efficient when the patches have low - dimension structure."
SP:7f2f354d5cc1030bd97bd716aea8fe1d3af86b25,"This paper proposes a novel algorithm for face clustering based on graph convolutional neural networks ( GCNs ). The main idea of the paper is to reduce the number of noise edges in the graph by transforming the features of each face into a new structure space. Then, an adaptive neighbour discovery strategy is proposed to determine a proper number of edges connecting to each face image. The proposed Ada - NetS algorithm significantly reduces the noise edges while maintaining the good ones to build a graph with clean yet rich edges for GCNs to cluster faces. Experiments on multiple public clustering datasets show that Ada - NETS significantly outperforms current state - of - the - art methods."
SP:a3bc8e26f55e78f07de081ca85865afd52b6ae4a,"This paper proposes a new method for Generalizable Person Re - ID ( DGWD - ReID ), which is based on distributionally robust optimization ( DRO ). The authors argue that the convex condition of KL DRO may not hold for overparameterized neural networks and applying KL DRo fails to generalize under distribution shifts in real scenarios. Instead, they propose a simple yet efficient approach, Unit DRO, which minimizes the loss over a reweighted dataset where important samples ( i.e., samples on which models perform poorly ) will be upweighted and others will be downweighted. Empirical results show that the proposed method achieves superior performance on large - scale DG ReID and cross - domain ReID benchmarks compared to standard baselines."
SP:62c1f734b7f6c6e7d5114da6f37c9e3cdda73a23,"This paper proposes a novel regularization technique for GNNs to improve the oversmoothing of 3D molecular property prediction tasks. Specifically, the paper proposes to corrupt the input graph with noise, and add a noise correcting node - level loss. The paper shows that the noise correction loss helps ameliorate oversmooting by encouraging diverse node latents. The experiments show that the proposed method can improve the performance on 3D property prediction task by 43 % over previous work, 12 % on OC20 IS2RS direct, and top results on 3 out of 12 of the QM9 tasks."
SP:24a1b44f37f8eedbab2047fb84600a322d289f3b,"This paper proposes a differentiable EM model for the set2vec problem. The model is built from the perspective of fitting a Gaussian mixture model to the set data that are viewed as i.i.d. samples from a mixture distribution. The authors define the set embedding feed - forward network as the maximum - a - posterior ( MAP ) estimate of the mixture which is approximately attained by a few ExpectationMaximization ( EM ) steps. The whole MAP - EM steps are differentiable operations with a fixed number of mixture parameters, allowing efficient auto - diff backpropagation for any given downstream task. Furthermore, the proposed mixture set data fitting framework allows unsupervised set representation learning naturally via marginal likelihood maximization aka the empirical Bayes. The proposed model is also shown to generalize the recent set - embedding models based on optimal transport and attention, leading to a computationally efficient model with superb performance on tasks in bioinformatics and NLP."
SP:b4f7b660b84fe7702fbcc8a96c192abc3a64f045,"The paper proposes a contrastive feature selection method for the contrastive analysis ( CA ) setting, where the goal is to select a small number of informative features for use in unknown downstream tasks. The proposed method, called Contrastive Feature Selection ( CFS ), is a method for performing feature selection in the CA setting. The method is evaluated on a semi - synthetic dataset and four real - world biomedical datasets. The results show that CFS outperforms other state - of - the - art methods."
SP:bc4f69f23aba2034cbf14cb31bdc7a991806bbf6,"This paper proposes a new model of overparametrization to study the optimal early stopping time for linear regression models. The authors show that when the model dimension exceeds the number of features, early stopping can help mitigate the so - called "" double descent "" phenomenon, where the risk as a function of model size or sample size experience two distinct phases of descent. They also show that early stopping helps mitigate double descent in multiple settings.   The authors also provide a theoretical analysis of the early stopped model."
SP:ede87b50cd9c4a6533f17e3e5ddfaaeaaac71dcf,"This paper proposes a quasi - Newton method for the policy gradient algorithm with entropy regularization. In the case of Shannon entropy, the resulting algorithm reproduces the natural policy gradient ( NPG ) algorithm. For other entropy functions, this method results in brand new policy gradient algorithms. The authors provide a simple proof that all these algorithms enjoy the Newton - type quadratic convergence near the optimal policy. Using synthetic and industrial - scale examples, the authors demonstrate that the proposed quasi - newton method typically converges in single - digit iterations, often orders of magnitude faster than other state - of - the - art algorithms."
SP:3535504f7599b1f39239f7cd8e09acd40fa8fdf0,"This paper proposes a new reinforcement learning method for text - based games ( TBGs ) based on case - based reasoning ( CBR ). The idea is to build a collection of positive experiences from the agent ’s interaction with the world in the past and use the collected experiences to act efficiently. The method can be applied in conjunction with any existing on - policy neural agent in the literature for TBGs. The experiments show that the proposed approach consistently improves existing methods, obtains good out - of - distribution generalization, and achieves new state of the art results on widely used environments."
SP:9a5dd0148a15dc5b4d2bc6762dfe8a8991f8866c,"This paper proposes a two - stage method to distill multiple word senses from a pre - trained language model ( BERT ) by using attention over the senses of a word in a context and transferring this sense information to fit multi - sense embeddings in a skip - gram - like framework. Experiments on the contextual word similarity and sense induction tasks show that this method is superior to or competitive with state - of - the - art multi - senses embedding on multiple benchmark data sets. The paper also demonstrates the benefits of using this multi -sense embedding in a downstream application, namely embedded topic modeling."
SP:e4cdba0fc7cd7f440d4436219f3959d8d5e2ad28,"This paper proposes to use image - pretrained models to understand 3D point - cloud images by inflating 2D convolutional filters to 3D filters and finetuning the inflated imagepretrained models ( FIP ). The authors conduct experiments to show the effectiveness of the proposed method. They find that the FIP can achieve competitive performance on point cloud classification, beating a wide range of point cloud models that adopt task - specific architectures and use a variety of tricks. Moreover, the authors shed light on why the image pretraining can be used for point cloud understanding from three aspects : network dissection, texture - shape representation transferring, and feature distribution distance."
SP:dc99c307931ae9c5d4a1b998dc94cfc6ac78d11f,"This paper proposes a method for training the autoregressive generative model that takes advantage of a well - designed energy - based learning objective. The proposed method is capable of alleviating the exposure bias problem and increase temporal coherence by imposing a constraint which fits joint distributions at each time step. Besides, unlike the previous energy based models, the proposed method estimates energy scores based on the underlying Autoregressive network itself, which does not require any extra network. Finally, thanks to importance sampling, the entire model can be trained efficiently without requiring an MCMC process. Extensive empirical results covering benchmarks like language modeling, neural machine translation, and image generation demonstrate the effectiveness of the proposed approach."
SP:51e748c55bd4134047098559577fa3f37aa7433a,"This paper presents a unified framework that connects Wasserstein distributional robustness with current state - of - the - art adversarial training ( AT ) methods such as PGD - AT, TRADES, MART, and AWP. The authors show that standard AT methods are special cases of their counterparts in their framework. This connection leads to an intuitive relaxation and generalization of existing AT methods and facilitates the development of a new family of distributed robustness AT - based algorithms. Extensive experiments show that the proposed distributional AT algorithms robustify further their standard AT counterparts in various settings."
SP:f192046ea8ad61bfc8e05a0ddb90a8bd15b4640b,"This paper proposes a novel unsupervised representation learning method for multivariate time series. The proposed method is based on an iterative bilinear temporal - spectral fusion ( BTSF ) module, which uses the entire time series as input and apply dropout to generate different views for training. Experiments on classification, forecasting and anomaly detection tasks have been conducted and the results show the superior performance of the proposed method."
SP:ef54840009afb095c67bbbc29a7824c20a375ee8,"This paper proposes an algorithm for automatically adjusting the learning rate during gradient descent. The authors formulate first and second - order gradients with respect to learning rate as functions of consecutive weight gradients, leading to a cost - effective implementation. They also show that the scheme can be extended to accommodate for different learning rates per layer. Extensive experimental evaluation is conducted, validating the effectiveness of the proposed method for a plethora of different settings. The proposed method has proven to be robust to both the initial learning rate and the batch size."
SP:263c787361cd6d4443ce516d389c694d0fe44b28,"This paper proposes a continual meta - reinforcement learning algorithm for multi - task learning, where the agent can not revisit previous tasks to collect data. The authors propose a method, CoMPS, that removes this limitation by meta - training in an incremental fashion, over each task in a sequence, without revisiting prior tasks. To evaluate the proposed method, the authors modify a collection of commonly used meta - RL benchmarks into continual multitask problems, with tasks presented one at a time. The proposed method outperforms other methods, achieving a higher average reward with fewer samples on average over each of the tasks in the sequence."
SP:2bd729b7aa045bf74e31229c9e76e57af36e804b,"This paper proposes a human - in - the - loop attack method to attack poisoned classifiers without access to the original trigger. The authors introduce a new threat model of poisoned classifier where one would want to break it without knowing the trigger. They construct these alternative triggers by first generating adversarial examples for a smoothed version of the classifier, created with a procedure called Denoised Smoothing, and then extracting colors or cropped portions of smoothed adversarial images with human interaction. They demonstrate the effectiveness of their attack through extensive experiments on high - resolution datasets : ImageNet and TrojAI."
SP:e58ab0e3cff6b18013145a1a99cfa9da0a3d872f,"This paper proposes a new method for unconditional GAN distillation, especially for the popular StyleGAN2 architecture. The main insight of the paper is that the main challenge of unconditional GANs lies in the output discrepancy issue, where the teacher and student model yield different outputs given the same input latent code. Standard knowledge distillation losses typically fail under this heterogeneous distillation scenario. The authors conduct thorough analysis about the reasons and effects of this discrepancy issue and identify that the style module plays a vital role in determining semantic information of generated images. Based on this finding, the authors propose a novel initialization strategy for the student model, which can ensure the output consistency to the maximum extent. The proposed latent - direction - based distillation loss further improves the distillation efficacy. Extensive experiments demonstrate the effectiveness of the approach in distilling styleGAN2, outperforming existing GAN methods."
SP:2c2231743fa33b95828c6615263954ce1c05f95d,"This paper proposes a method to approximate offline algorithms in online settings by encoding the behavior of offline algorithms into graphs and training a multi - task learning model to simultaneously detect behavioral structures which have already occurred and predict those that may come next. The proposed method is evaluated on both synthetic data and historical stock market data, where the contrast between explanation and prediction is particularly stark. Taken together, this work represents the first general and end - to - end differentiable approach for generating online approximations of online algorithms. The experiments are designed to build intuition for the methodology, and as such are confined to 1D settings."
SP:ee3a21d2fb8a073099aa200129a53c31f3b6561d,"This paper proposes input - dependent Gaussian process ( IDSGP ), a method to reduce the training cost of Gaussian processes ( GP ). The main idea is to use a neural network to compute inducing points for each potential data point, and then use a variational posterior approximation ( VI ) to compute the parameters of the posterior of the process values for the outputted inducing points. The proposed method is evaluated on several regression and binary classification problems."
SP:f20c99b441545047a16ae524cc2e317b2c3787a2,"This paper proposes a new decentralized training protocol for large - scale distributed neural networks. The proposed method, BTARD - SGD, is designed to be robust to Byzantine and Sybil attacks. The authors provide theoretical bounds for the robustness of the proposed method and show that it has a marginal communication overhead. They also conduct experiments on image classification and language modeling in presence of Byzantine attackers to demonstrate the effectiveness of the method."
SP:93894f20ab2593e5237b6972fef9fe63e96af89a,"This paper presents a method for learning physics - informed SPH - based fluid simulators. The method is based on the idea of smoothed particle hydrodynamics ( SPH ), which is a mesh - free Lagrangian method for approximate numerical solutions of the equations of fluid dynamics. The authors present a learn - able hierarchy of parameterized and physics - explainable SPH models using both physics - based parameters and Neural Networks as universal function approximators. The learning algorithm develops a mixed mode approach, mixing forward and reverse mode automatic differentiation with forward and adjoint based sensitivity analyses to efficiently perform gradient based optimization. They show that their physics informed learning method is capable of : ( a ) solving inverse problems over the physically interpretable parameter space, as well as over the space of Neural Network parameters ; ( b ) learning Lagrangians of turbulence ; ( c ) learning the underlying flow data using a combination of field based and statistical based loss functions ; and ( d ) extrapolating beyond training sets into more complex regimes of interest."
SP:d11b81f9ab414fcf430a03cd70c2d3246b678474,"This paper proposes Mix - MaxEnt, an approach to improve the uncertainty estimates of a single deterministic neural network. The idea is to use a convex combination of two images from different classes and maximize the entropy on these samples. This is achieved by synthetically generating between - cluster samples via the convex combinations of two different images. Mix - maxEnt is shown to be more robust to the superficial input perturbations than SNGP and DUQ. Experiments on CIFAR-10/100 show the effectiveness of the proposed approach."
SP:365490b872464f00634dc7a50d024fceaf0a61ee,"This paper proposes a new method for image animation by directly manipulating the latent space of a deep generative model. Specifically, the authors propose a method called Latent Image Animator ( LIA ), a self - supervised autoencoder that evades the need for explicit structure representation. The proposed method is streamlined to animate images by linear navigation in the latent spaces by linear displacement of codes in the generated video. The authors propose to learn a set of orthogonal motion directions simultaneously, and use their linear combination, in order to represent any displacement in latent space. Extensive quantitative and qualitative analysis suggests that the model systematically and significantly outperforms state - of - the - art methods on VoxCeleb, Taichi, and TED - talk datasets w.r.t. generated quality."
SP:86f9f89f84e117c86478b9afaf087f65524f5472,"This paper proposes a new meta - learning method called task interpolation ( MLTI ) to improve the number of meta - training tasks available for a given task. The authors propose to interpolate the features and labels of a pair of tasks by randomly sampling a set of tasks and interpolating the corresponding features. The proposed method is evaluated on eight datasets from diverse domains including image recognition, pose prediction, molecule property prediction, and medical image classification. The experiments show that the proposed MLTI outperforms other state - of - the - art strategies."
SP:73d577e9c4f4af5e11a9e5bdb583ee0f50a315f5,"This paper proposes a new fair representation learning method called Fair Normalizing Flows ( FNF ). FNF is based on the normalizing flow model, which is trained to minimize the statistical distance between the latent representations of different groups. The key idea is to use an encoder based on normalizing flows which allows computing the exact likelihood in the latent space, given an estimate of the input density. Experiments on several datasets show that FNF effectively enforces fairness without sacrificing utility, while simultaneously allowing interpretation of the representations and transferring to unseen tasks."
SP:404d5643327f60f0f06f820033a56081f9e01900,"This paper proposes a novel GNN - based method for subgraph isomorphism counting. The main idea is to use edge - centric message passing to encode fine - grained structural information to improve the structure matching between the queries and input graphs from the edge perspective. In addition, the proposed method modulates the input graph representation conditioned on the query to adapt to each query individually to improve their matching. Extensive experiments on several benchmark datasets demonstrate that COUNT - GNN can significantly outperform state - of - the - art GNN-based models."
SP:5a94f18156ab2949c86de45fcf0de2e16977eebb,"This paper proposes a novel approach for personalized federated learning, where each client can have their own personalized labels, which might not be compatible with others ( even for the same class ), and can be also possibly from a variety of multiple domains. The authors then study two essential challenges of the agnostic personalized Federated Learning, which are ( 1 ) Label Heterogeneity where local clients learn from the same single domain but labeling schemes are not synchronized with others and ( 2 ) Domain Hierogeneity where the clients learns from the different datasets which can be semantically similar or dissimilar to each other. To tackle these problems, the authors propose a novel method, namely Similarity Matching and Kernel Factorization ( SimFed ), which measures task - level similarity based on locally learned knowledge and matches the relevant ones for personalized knowledge reflection. Furthermore, they factorize the model parameters into two basis vectors and the highly sparse masks to significantly reduce the dimensionlaity of parameter space for alleviating knowledge collapse and information loss when reflecting the heterogeneous knowledge. They extensively validate their method in both label - and domain - heterogeneous scenarios and show that their method outperforms the current state - of - the - art baselines."
SP:97f30bea31eccef6c770fbce1e14fd6d2493a178,"This paper proposes an unsupervised learning framework ODDN, a novel approach to decompose temporal scene of multiple objects with dynamics and interactions. The proposed method distills explicit object dynamic representations ( e.g., velocity ) from raw video input. The authors also build a relation module that calculates object - pair interactions and applies it to the corresponding dynamic representations of objects. The results show that visual representations of the proposed method perform better in answering reasoning questions around physical events in a video compared to representaions of the previous scene representation methods. And the model could generate reasonable future frames given two input frames, considering occlusion and objects collision."
SP:ba8e50d1fa9cb824fa3f76c0c691997cd151d760,"This paper proposes a new layer for GNNs that uses positional encoding ( PE ) techniques such as Laplacian Eigenmap, Deepwalk, etc. for node features. The proposed PEG layer uses separate channels to update the original node features and positional features. PEG imposes permutation equivariance w.r.t. the original nodes features and rotation equivariant w.rt. the positional features simultaneously. Extensive link prediction experiments over 8 real - world networks demonstrate the advantages of PEG in generalization and scalability."
SP:cf448479f68c3194c1a9e11729bf70d7cc2ae8fd,"This paper proposes LaMer, a novel text style transfer framework based on large - scale language models. LaMer first mines the roughly parallel expressions in the non - parallel datasets with scene graphs, and then employs MLE training, followed by imitation learning refinement to leverage the intrinsic parallelism within the data. On two benchmark tasks (sentiment & formality transfer ) and a newly proposed challenging task ( political stance transfer ), LaMer achieves qualitative advances in transfer accuracy, content preservation, and fluency. Further empirical and human evaluations demonstrate that our model not only makes training more efficient, but also generates more readable and diverse expressions than previous models."
SP:8f7b2d1020d9e527118b8fb816760c13b0d0bfcb,"This paper proposes a method to answer hyper - relational queries in knowledge graphs ( KGs ). The main idea is to use a subset of first - order logic ( FOL ) to express such queries in the latent space. The proposed method is based on Graph Neural Networks ( GNNs ), and the authors show that the proposed method can answer conjunctive hyper - relational queries. The authors also show the robustness of the proposed model to a reification mechanism commonly used in graph databases to store such graphs on a physical level."
SP:5f8b58424a1a8eeb72217e75189d6f773a298a7a,"This paper proposes a new Bayesian optimization algorithm for the gray - box hyperparameter optimization ( HPO ) setting. The authors propose a new surrogate for Gaussian Processes that embeds the learning curve dynamics and a new acquisition function that incorporates multi - budget information. They demonstrate the significant superiority of DYHPO against state - of - the - art baselines through large - scale experiments comprising 50 datasets ( Tabular, Image, NLP ) and diverse neural networks ( MLP, CNN / NAS, RNN )."
SP:99d3d94e3af5d2dc7b92c00ac1345d1d2dd0d15b,"This paper proposes to use post - training quantization techniques to improve the performance of learned image compression. The main idea is to use a quantized neural network to compute the entropy of an image, which is then used to train a neural network. The authors show that this quantization technique can improve the accuracy of the image compression model in terms of cross - platform consistency.   The authors also propose to extend the deterministic inference to fit Gaussian mixture models."
SP:85d0df515e9e555f3ea1c21d607304dfaeae69c0,"This paper proposes an unsupervised noise reconstruction and removal network for denoising scanning electron microscopy images. The architecture, inspired by gated recurrent units, reconstructs and removes the noise by synthesizing the sequential data. At the same time, the network guides the network in distinguishing true signal from noise and gives comparable/ even better results than supervised approaches on 3D electron microscope data sets. The paper provides detailed performance analysis using numerical as well as empirical metrics."
SP:e6275b0b103fa90dcebcdd3d3c14c830c3402972,"Graph neural networks ( GNNs ) and label propagation are two interrelated modeling strategies designed to exploit graph structure in tasks such as node property prediction. Given that the material difference is merely whether features or labels are smoothed across the graph, it is natural to consider combinations of the two for improving performance. In this regard, it has recently been proposed to use a randomly - selected portion of the training labels as GNN inputs, concatenated with the original node features for making predictions on the remaining labels. This so - called label trick accommodates the parallel use of features and labels and is foundational to many of the top - ranking submissions on the Open Graph Benchmark ( OGB ) leaderboard. Yet despite its wide - spread adoption, there has been little attempt to carefully unpack exactly what statistical properties the label trick introduces into the training pipeline, intended or otherwise. To this end, the authors prove that under certain simplifying assumptions, the stochastic label trick can be reduced to an interpretable, deterministic training objective composed of two factors. The first is a data - fitting term that naturally resolves potential label leakage issues, while the second serves as a regularization factor conditioned on graph structure that adapts to graph size and connectivity. The authors leverage this perspective to motivate a broader range of label trick use cases, and provide experiments to verify the efficacy of these extensions."
SP:b6cbc3661f9c440687c3dd01ee35a118c87db377,"This paper proposes to model machine theory of mind in a more flexible and symmetric scenario where all agents can speak, listen, see other agents, and move freely through a grid world. An effective strategy to solve SymmToM requires developing theory of state to maximize each agent ’s rewards. The authors show that even maintaining the simple rules of the environment, modifying its parameters results in much more difficult challenges, even for models where we artificially introduce perfect information. The best agents fail to achieve performance comparable to agents with access to the gold - standard mental state of other agents."
SP:f8ce83805eee46c6c196e8477bf10d8d7f7e0f46,"This paper proposes a novel zero - shot object detection method for industrial robots that works in a flexible and dynamic manufacturing environment. The authors propose to use a modified YOLOv5 neural network to perform generalized zeroshot detection on seen and unseen objects. They also proposed a novel splitting method for YCB Video dataset to train and test gZSD algorithms. By changing the final detection layers of YOLov5, they have significantly improved its performance on the YCB video dataset split with their proposal."
SP:aa1dcd9217270010f16a00004facede942efea17,"This paper proposes an autoregressive latent video prediction model ( HARP ) for video prediction. The proposed method is based on the VQ - GAN, which is an image generator model with a causal transformer model. The authors propose to use top - k sampling and data augmentation to improve the performance of HARP. HARP is evaluated on standard video prediction benchmarks with fewer parameters, and enables high resolution video prediction on complex and large - scale datasets."
SP:7f57896afd63bc869d2db6ddf7abbeaa71daae11,"This paper proposes to use Vision Transformers ( ViTs ) for image generation in GANs. The main idea is to use ViTs as discriminators in the GAN to improve the performance of the discriminator. To this end, the paper proposes a new GAN architecture consisting solely of Transformer layers. The paper also proposes several regularization techniques to train ViTs. The experiments on standard benchmarks demonstrate that the presented model achieves comparable performance to leading CNN - based GAN models."
SP:bbae3afcaea0a2e54904cb8daaed7df4fe37da6e,"This paper proposes a two - stage training procedure to improve the ELBO performance of VAEs. The main idea is to train a high - rate model on top of a low - rate VAE, which is trained to achieve good ELBOs, but with poor sample quality. The authors argue that this is due to the fact that in natural images, only a small amount of information is relevant to the perceptual sample quality, while the rest of the information is irrelevant. To overcome this issue, the authors propose a two stage training process that trains a secondary model that is restricted to modeling visually imperceptible information. By doing so, the secondary model can improve ELBO significantly with minimal impact on the sample quality achieved by the initial low rate model."
SP:bfed56018134ec66cde9a7e958df964d4cca3164,"This paper proposes a training - free inference framework for DPMs that estimates the analytic forms of the variance and KL divergence using the Monte Carlo method and a pretrained score - based model. The authors show that both the optimal reverse variance and the corresponding optimal KL divergence of a DPM have analytic forms w.r.t. its score function. To correct the potential bias caused by the score based model, the authors derive both lower and upper bounds of the optimal variance and clip the estimate for a better result. Empirically, their analytic - DPM improves the log - likelihood of various DPM models, produces high - quality samples, and meanwhile enjoys a 20x to 80x speed up."
SP:3f935ba5784c3e86db72421426bc479061af1a4b,"This paper investigates whether it is feasible to switch to transformer - based models for medical image classification as well, or if we should keep working with CNNs – can we trivially replace CNNs with transformers? The authors consider this question in a series of experiments on several standard medical image benchmark datasets and tasks. Their findings show that, while CNNs perform better if trained from scratch, off - the - shelf vision transformers can perform on par with CNNS when pretrained on ImageNet, both in a supervised and self - supervised setting."
SP:a64e0535f268901e38fd51e027c612ebcdbae1a4,"This paper studies the problem of pretraining neural language models ( NLMs ) over a large corpus by chunking the text into training examples, which are contiguous text segments of sizes processable by the neural architecture. The authors show that the pretrained NLM can model much stronger dependencies between text segments that appeared in the same training example, than it can between text segment that appear in different training examples. This intuitive result has a twofold role. First, it formalizes the motivation behind a broad line of recent successful NLM training heuristics, proposed for the pretraining and fine - tuning stages, which do not necessarily appear related at first glance. Second, it clearly indicates further improvements to be made in NLM pretraining for the benefit of Natural Language Understanding tasks. As an example, the paper shows that including semantically related non - neighboring sentences in a pretraining example yields improved sentence representations and open domain question answering abilities."
SP:59066956fa2e423d5f2d2ea4f91c4ddf6afd4683,"This paper proposes a new method for learning to optimize ( L2O ). The method is based on the idea of symbolic regression, which is used to learn a symbolic representation of the optimization rules. The authors show that the proposed method is more interpretable and can be applied to large - scale optimization problems. The paper also proposes a lightweight meta - training method that can be meta - trained on large problems and outperforms human - designed and tuned optimizers."
SP:54dfeb363beee9959aecc9e0853ff06e43bd94e4,"This paper studies the problem of robustness against adversarial attacks in reinforcement learning. The authors propose to use randomized smoothing to improve the robustness of reinforcement learning policies. The main contribution of the paper is to extend the Neyman - Pearson Lemma to the dynamic RL setting, where the adversarial perturbation at a particular time can be a stochastic function of current and previous observations and states as well as previous actions. To this end, the authors propose policy smoothing where the agent adds a Gaussian noise to its observation at each time - step before passing it through the policy function.   The authors show that by adding Gaussian smoothing noise to the input of the policy, one can certifiably defend it against norm - bounded adversarial input perturbations of its input. They show that their method can yield meaningful robustness guarantees in practice."
SP:e0f9add5fde18eaab0eeb2b10b14928acc8ec5b8,"This paper proposes an approach to estimate the accuracy of a classifier using only labeled source data and unlabeled target data. The approach is based on the idea of average thresholded confidence ( ATC ), which estimates the accuracy as the fraction of unlabelled examples for which the model confidence exceeds a threshold. The method is evaluated on synthetic and natural distribution shift benchmarks, as well as synthetic corruptions, dataset reproduction, or novel subpopulations, and datasets ( WILDS, ImageNet, BREEDS, CIFAR, and MNIST ). ATC outperforms previous methods across several model architectures, types of distribution shifts ( e.g., synthetic corruption, dataset reproductions, and new populations ). The authors also explore the theoretical foundations of the problem, proving that, in general, identifying the accuracy is just as hard as identifying the optimal predictor and thus, the efficacy of any method rests upon ( perhaps unstated ) assumptions on the nature of the shift."
SP:e748bf6ee653087cae825df32a8546f9ccebfcf1,"This paper proposes a method to solve the point set registration task as a PDM problem, where point sets are regarded as discrete distributions, and the goal is to partially match them. The authors formulate the problem as a partial distribution matching ( PDM ) problem, and use the partial Wasserstein - 1 ( PW ) discrepancy to approximate the discrepancy between the two point sets. The proposed method is based on the Kantorovich - Rubinstein duality for the PW discrepancy, and shows its gradient can be explicitly computed. Based on these theoretical results, the authors propose a method, which approximates the discrepancy by a neural network, and learns the transformation adversarially with the network. It also incorporates an efficient coherence regularizer for non - rigid deformations to avoid unrealistic deformations. Experiments show that the proposed method can effectively handle the point sets dominated by outliers, including those containing large fraction of noise or being partially overlapped."
SP:f94f77696d100b2638fa2a6d82c8df47db3b6a36,"This paper proposes a novel transfer learning method for hyperparameter optimization ( HPO ). The proposed method is based on the landmark meta - feature extractor ( DKLM ), which is an end - to - end approach to learn task - specific hyperparameters. The key idea of DKLM is to use a set - based extractor to capture the interaction between the available hyperparamers and their respective responses, and generate task specific attributes. Experiments show that the proposed method outperforms state - of - the - art HPO baselines in both non - transfer and transfer learning settings."
SP:e3c57f3589e8ab674644d900c14b3473cd71a23f,"This paper proposes a novel fingerprinting method for GANs. The key idea is to generate a large number of GAN models with distinct fingerprints, which can then be used to identify the source of the generated samples. The proposed method is evaluated on two tasks : deep fake detection and attribution tasks. The authors show that the proposed method outperforms other methods in both tasks."
SP:73bffd1a0856b80d29f7a2b2b68be57882531f07,"This paper proposes a method to provide local explanations for black box models. The main idea is to use feature attributions to explain the similarity between a pair of inputs as determined by a black box similarity learner, and then propose analogies as a new form of explanation in machine learning to identify diverse analogous pairs of examples that share the same level of similarity as the input pair and provide insight into (latent ) factors underlying the model ’s prediction. The selection of analogies can be done by leveraging feature attribution. The authors prove that their analogy objective function is submodular, making the search for good - quality analogies efficient. They apply the proposed approaches to explain similarities between sentences as predicted by a state - of - the - art sentence encoder, and between patients in a healthcare utilization application."
SP:6a3c4ae05d582f8896840483b08c735ced2976bc,"This paper studies the certified robustness of ensemble ML models. The authors provide the necessary and sufficient conditions of robustness for different ensemble protocols. They also provide the bounded model - smoothness analysis based on the proposed Ensemble - before - smoothing strategy. Inspired by the theoretical findings, they propose the lightweight Diversity Regularized Training ( DRT ) to train certifiably robust ensemble models. Extensive experiments show that the DRT enhanced ensembles can consistently achieve higher certified L2 - robustness than existing single - and ensemble - based models."
SP:3002b29c27709780238876d8c3f81bbd6a0f8112,"This paper studies the expressive power of subgraphs in GNNs. The authors propose a new subgraph pooling technique of local neighborhoods that allows different tradeoffs of computational cost and expressive power. First, they prove that this model can count subgraph of size k, and thereby overcomes a known limitation of low - order GNN. Second, they show how recursively pooling can exploit sparsity to reduce the computational complexity compared to the existing higher - order graph neural networks. More generally, they provide a ( near ) matching information - theoretic lower bound for counting subGraphs with graph representations that pool over representations of derived ( sub-)graphs."
SP:5d0cbd84336caf5f31e1f98e11f6733230e4d792,"This paper revisits the KI process in an information - theoretic view and shows that KI could be interpreted using a graph convolution operation. The paper proposes a simple probe model called Graph Convolution Simulator ( GCS ) for interpreting knowledge - enhanced LMs and exposing what kind of knowledge is integrated into these models. The authors conduct experiments to verify that our GCS model can indeed be used to correctly interpret the K I process, and they use it to analyze two typical knowledge -enhanced LMs : K - adapter and ERNIE."
SP:7e73948421e98307fceb69a316d8a4e7c4926cda,"This paper studies the effect of the adaptation learning rate in meta - learning with mixed linear regression. The authors provide a principled way to estimate optimal adaptation learning rates that minimize the population risk of MAML. They also extend their result about the choice of α∗ to more practical regime, including deep learning. The theoretical results are well corroborated with experimental results."
SP:effbc85d89b1197d9c2abcaf5ff13864135dd6e1,"This paper proposes a method for source - free domain adaptation ( SFDA ), which aims to adapt a model trained on labelled data in a source domain to unlabelled data in the target domain without access to the source - domain data during adaptation. The authors propose to restore the source features in the source domain by storing a lightweight and flexible approximation of the feature distribution under the source data, and adapt the feature - extractor such that it realigns with that saved on the source. They also propose a bottom - up training scheme for FR, which boosts performance by preserving learnt structure in the later layers of a network. They demonstrate that BUFR outperforms existing SFDA methods on real and synthetic data in terms of accuracy, calibration, and data efficiency."
SP:7d63034ec7e6a4f178681ff2a49feb485cd47116,This paper proposes a method to transfer adversarial robustness from high resource users to low resource users during the FL process. The authors propose a simple yet effective propagation approach that transfers robustness through carefully designed batch - normalization statistics. They show that existing FL techniques can effectively propagate robustness among non - iid users. They demonstrate the rationality and effectiveness of their method through extensive experiments. The proposed method is shown to grant FL remarkable robustness.
SP:42c7a79e58b6a9f776fa6ae928bd89c194f9303f,"This paper proposes a transformer - based approach to infer the structure of games from their equilibrium actions without knowing the utility function of the game. Specifically, the authors use a permutation - invariant transformer architecture to learn a mapping from the equilibrium actions to the network structure of the games. The authors compare three types of games using a unified parameterization, which helps reveal the different nature of these games and interpret the strategic interactions they represent. The results show that the proposed method outperforms existing methods on three different types of network games using both synthetic and real data."
SP:1c7b9157cf8c06ca771da78895fc3af969b0fb85,"This paper proposes GraphANGEL, a novel relation prediction framework that predicts the relations between each node pair based on the subgraph containing the pair and other subgraphs with identical graph patterns, and has a strong inductive bias for the generalization to unseen relation types. The proposed method is evaluated on heterogeneous graph based recommendation and knowledge graph completion tasks with the state - of - the - art methods.   The main contributions of this paper are :   1. The authors propose a novel method for relation prediction in heterogeneous graphs including knowledge graphs. 2. They introduce several graph pattern searching and sampling techniques, which can efficiently find graph patterns matching the patterns in triangle and quadrangle shapes. 3. They show the capability of their model in generalizing to new relation types while producing explainable heat maps of attention scores across logics."
SP:26ed25a7b42da2cf11b76a727102d8aa36d76657,"This paper presents a few - shot learning method for histology images. The method combines contrastive learning ( CL ) with latent augmentation ( LA ) to build a few shot system. CL learns useful representations without manual labels, while LA transfers semantic variations of the base dataset in an unsupervised way. Experiments show that CL learned models generalize better than supervised learning in terms of generalization for such data and provide an empirical explanation for this."
SP:badbe687258cd5c282ca167b1f6fbfc6b5400dbf,"This paper proposes a new recurrent neural network ( RNN ) architecture for learning long - term dependencies in irregularly - sampled time - series. The authors show that ODE - RNNs suffer from the vanishing and vanishing gradient problem, making them unable to learn long term dependencies efficiently. To solve this problem, the authors propose a new architecture, called mmRNNs, where the memory is separated from the time - continuous state. This way, the RNN can respond to inputs arriving at arbitrary time - lags while ensuring a constant error propagation through the memory path. The experimental results show that the proposed architecture outperforms other RNN - based counterparts on time series with irregularly sampled data."
SP:4efd22f9122fa5856a9f4302eb6875fa0c414912,"This paper proposes BiBERT, a method to reduce the computational cost of BERT by fully binarizing the weights, embedding, and activation of the BERT model. The main idea is to use a bi - attention structure and a direction - matching distillation ( DMD ) scheme to optimize the full binarized BERT more accurately. The proposed method is evaluated on CIFAR-10 and NLP tasks. The results show that the proposed method outperforms SOTA BERT with ultra - low activation."
SP:619bd742e92bea6241852f5a9d2b7bacf13b393a,"This paper presents a new method to solve keypoint detection and instance association by using Transformer. Specifically, the authors propose a novel approach of supervising self - attention by using instance masks to supervise self - Attention to be instance - aware. The proposed method can assign the detected keypoints to their instances based on the pairwise attention scores, without using pre - defined offset vector fields or embedding like CNN - based bottom - up models. The experiments on the COCO multi - person key point detection challenge and person instance segmentation task demonstrate the effectiveness and simplicity of the proposed method, and show a promising way to control self - attentive behavior for specific purposes."
SP:14750819593136fc9ef4efd032ab6f94dc5f6a02,"This paper proposes a new algorithm, called EQUMRL, for the optimization of Pareto - efficient policies under the mean - variance ( MV ) tradeoff in reinforcement learning. The main idea is to train an agent to maximize the expected quadratic utility function, where the maximizer corresponds to the policy that is most likely to be the most efficient under the MV tradeoff. The proposed algorithm is computationally friendly as it does not require the gradient estimation of the variance. The authors also provide an experimental evaluation of the proposed algorithm on synthetic and real - world datasets."
SP:f675b564b3a9c8626ce7944d752fa3e0d868428e,"This paper proposes a method for test - time domain adaptation for a Gaussian mixture density network ( MDN ), which is generatively - modelled using a mixture of Gaussian mixtures. The main idea is to adapt the autoencoder from a source domain to a target domain using only a small labeled dataset ( and no unlabeled data ). The method utilizes feature transformations at the decoder to compensate for changes in the channel distribution, and effectively present to the decoders samples close to the source distribution. Experimental evaluation on simulated datasets and real mmWave wireless channels demonstrate that the proposed method can adapt the MDN channel using very limited number of samples, and improve or maintain the error rate under changing channel conditions."
SP:77dc92137ea490d3e1b4b8ee1630dbe2ee0bddfa,"This paper proposes a new approach to the abductive natural language inference task. The authors argue that it is unnecessary to distinguish the reasoning abilities among correct hypotheses and wrong hypotheses, and propose to group instead of ranking the hypotheses and design a structural loss called “ joint softmax focal loss ” in this paper. Based on the observation that the hypotheses are generally semantically related, the authors design a novel interactive language model aiming at exploiting the rich interaction among competing hypotheses. The experimental results show that the proposed IMSL has achieved the highest performance on the RoBERTa - large pretrained model, with ACC and AUC results increased by about 1% and 5% respectively."
SP:17cd72df5fc19398f582d27516fd742b073f79e3,This paper proposes a new adversarial robust binary discriminator ( ProoD ) for out - of - distribution ( OOD ) data. The main idea is to use a standard classifier ( ReLU ) as the discriminator and use adversarial perturbations to remove the asymptotic overconfidence of the classifier. The proposed method is evaluated on two datasets : 80 M Tiny Images and a synthetic dataset. The results show that the proposed method outperforms the baselines on OOD and synthetic datasets.
SP:9c3756f13932236aff3e8104f4fa193dcc8fde2f,"This paper proposes a new Generalized Transferable Attack ( GTA ) problem where the attacker has a set of surrogate models trained on different datasets ( with different label sets and image sizes ), and none of them is equal to the dataset used by the victim model. To solve this novel problem, the authors modify some transferable adversarial attack methods and propose a novel Image Classification Eraser method ( ICE ) to erase classification information for any encountered images from arbitrary dataset. Extensive experiments on Cifar-10, CIFAR-100, and TieredImageNet demonstrate the effectiveness of the proposed ICE on the GTA problem. Furthermore, they show that existing transfer attack methods can be modified to tackle the GTA, but with significantly worse performance compared with ICE."
SP:2e0447c741a3f09be1095633d870200355211260,"This paper focuses on the discriminative pre - trained language models ( PrLMs ), where the discriminator is trained to predict original texts from intentionally corrupted ones. The authors propose two pre - training objectives : 1 ) soft regularization by minimizing the semantic distances between the prediction and the original one to smooth the rough cross - entropy, and 2 ) hard correction to shield the gradient propagation of the false negative samples to avoid training with false negative predictions. Experimental results show that their approach boosts the baseline performance by a large margin, which verifies the effectiveness of their proposed methods and the importance of training on true negatives."
SP:281bc59d639aa76d84921b3ec4ce1ee8f1ba5b51,"This paper proposes a novel open - world semi - supervised learning setting that formalizes the notion that novel classes may appear in the unlabeled test data. The key idea in ORCA is to utilize uncertainty adaptive margin to circumvent the bias towards seen classes caused by learning seen classes faster than the novel classes. Extensive experiments on image classification datasets and a single - cell dataset demonstrate that ORCA consistently outperforms alternative baselines, achieving 25 % improvement on seen and 96% improvement on novel classes of the ImageNet dataset."
SP:6c572c4c21b01a0cf3fd9ef97fbb348ef4e405ae,"This paper proposes a new second - order method for training large - scale neural networks. The proposed method is based on the L - BFGS update rule, which directly approximates the Hessian inverse using past parameters and gradients. The authors also introduce momentum in Hessian updates together with an adaptive damping mechanism to achieve stable convergence. Theoretical results on the convergence of SLIM - QN in a stochastic setting are provided. Empirical analyses on CV models such as ResNet-50 and Vision Transformer show that SLIM-QN achieves faster convergence in the early stages."
SP:4bffce00ebb02d2e676eec897647ac14c3344deb,"This paper proposes a systematic method called Locality Sensitive Pruning ( LSP ) for graph pruning based on Locality - sensitive hashing ( LSH ) to sparsify a graph so that similar local environments of the original graph result in similar environments in the resulting sparsified graph, which is an essential feature for graph - related tasks. Extensive experiments on synthetic and real - world datasets demonstrate the superiority of LSP, which removes a significant amount of edges from large graphs without compromising the performance."
SP:c5e024f4e2079586298519ca868630efd7579eca,"This paper proposes a data augmentation method for contrastive self - supervised learning. In contrastive learning, strong augmentations may change the sample - identity of the positives, while weak augmentation produces easy positives / negatives leading to nearly zero loss and ineffective learning. The authors propose a simple adversarial method that can modify training data to be hard positives / negative without distorting the key information about their original identities. The key idea is to decompose a sample x to be its variational auto - encoder ( VAE ) reconstruction G(x ) plus the residual R(x) = x - G( x ), where the residual part retains most identitydistinctive information due to an information - theoretic interpretation of the VAE objective. They then adversarially perturb the residual in the bottleneck space and add it back to the original R(X ) as an augmentation. They apply this “ identity - disentangled adversarial augmentation ( IDAA ) ” to different SSL methods. On multiple benchmark datasets, IDAA consistently improves both their efficiency and generalization performance."
SP:0991bc5f213bd8ab7572e2fed309e1b57a35835b,"This paper proposes a method to detect distribution shift in training data. The authors propose a simple sequential method for testing if the difference between source ( training ) and target ( test ) distributions leads to a significant increase in a risk function of interest, like accuracy or calibration. The method is based on the Brier score ( Brier, 1950 ), which is used to detect harmful shifts while ignoring benign ones, and allows continuous monitoring of model performance without increasing the false alarm rate. The proposed method is evaluated on both simulated and real datasets."
SP:1c7b954273e3a9cda333385b15a3e8ed3bf8178a,"This paper proposes a method to learn a physical model from a single video clip. The method is based on a neural ODE model, where the parameters of the ODE are modeled by a neural network. The model is trained using a single short video clip, and the parameters are then used to predict the physical parameters of an underlying ODE - based physical model. The authors show that the proposed method is able to recover the metric length of the pendulum from the monocular video ( relative error to true length is less than 2.5 % )."
SP:51efd1451343f4994d857daa5490e299b812bc2d,"This paper tackles the problem of context dependent Reinforcement Learning ( C - MDP ), which is characterized by an unknown finite number of not directly observable contexts, abrupt ( discontinuous ) context changes occurring during an episode, and Markovian context evolution. The authors adapt a sticky Hierarchical Dirichlet Process ( HDP ) prior for model learning and derive a context distillation procedure, which identifies and removes spurious contexts in an unsupervised fashion. They argue that the combination of these two components allows to infer the number of contexts from data thus dealing with the context cardinality assumption. They then find the representation of the optimal policy enabling efficient policy learning using off - the - shelf RL algorithms. Finally, they demonstrate empirically ( using gym environments cart - pole swing - up, drone, intersection ) that their approach succeeds where other methods of other frameworks fail."
SP:ea167b126212b2092bc1190d7f8376bf7c54a888,"This paper proposes a framework to train a knowledge - based multilingual language model. The authors first generate a large amount of code - switched synthetic sentences from Wikidata knowledge graphs. Then based on the intra and inter - sentence structures of the generated data, they design pretraining tasks to facilitate knowledge learning, which allows the language models to not only memorize the factual knowledge but also learn useful logical patterns. Their pretrained KMLMs demonstrate significant performance improvements on a wide range of knowledge - intensive cross - lingual NLP tasks, including named entity recognition, factual knowledge retrieval, relation classification, and a new task designed by them, namely, logic reasoning."
SP:6c11cf29c90f923346372ba6f11452c36e69ad6d,"This paper proposes an unsupervised reinforcement learning agent that learns to act altruistically towards other agents by giving them more choice and thereby allowing them to better achieve their goals. Specifically, the agent learns to increase the choices another agent has by preferring to maximize the number of states that the other agent can reach in its future. The authors show that their agent outperforms the supervised baselines in three different multi - agent environments."
SP:5dbc54201ba184266c5054f0d2944bd197bc307a,"This paper studies the phenomenon of double descent in finite - width neural networks. The main contribution of the paper is the analysis of the population loss and its lower bound. The population loss is derived by leveraging influence functions. The influence functions are used to derive the lower bound on the Hessian at the optimum. The upper bound is derived using the maximum likelihood - type estimator. The authors show that the upper bound has an intimate connection with the spectrum of the Hessians at the interpolation threshold, and that the neural networks exhibit double descent behavior at this point. The paper further investigates the effect of the loss function on the double descent phenomenon."
SP:b485114712055f39a7afb951dbc3db482ff523fd,"This paper studies the trainability of wide and deep GCNs in the large - depth setting. The authors propose an edge - based sampling method, named Critical DropEdge, to overcome the exponential decay of trainability. The proposed method is based on the Graph Neural Tangent Kernel ( GNTK ), which governs the optimization trajectory under gradient descent for wide GCNs. Theoretically, the authors formulate the asymptotic behavior of GNTk to reveal the dropping trainability in the optimization process. The experimental results show that the proposed method can achieve better results compared to relevant counterparts with both infinite - width and finite - width."
SP:25a92b3583afdc6892e59f1e769125d52c8011af,"This paper studies the importance of second - order dynamics in video - based vital sign measurement. The authors propose a novel deep learning architecture that incorporates the second derivative input frames and target signals into the training procedure and evaluate it against clinical - grade contact sensor measurements. They show that the proposed architecture improves the quality of the estimated higher - order signals in terms of waveform morphology, and show that adding second - derivative inputs additionally improves performance. They also show that their model is better able to estimate left ventricle ejection time ( LVET ) intervals."
SP:0a88d2fcbdfab3e196bf6b9c75adb1006ab87536,"This paper proposes a method to help agents learn a compositional and symmetric language in complex settings like dialog games. Inspired by the theory that human language was originated from simple interactions, the authors hypothesize that language may evolve from simple tasks to difficult tasks. The authors propose a novel architecture called symbolic mapping as a basic component of the communication system of agent. They find that symbolic mapping learned in simple referential games can notably promote language learning in difficult tasks, and explore vocabulary expansion, and show that with the help of symbolic mapping, agents can easily learn to use new symbols when the environment becomes more complex."
SP:89575be04cb33b41d7a0a7b62f9496c2838a1317,"This paper proposes a hierarchical modular approach to learn agents that navigate and manipulate objects in a divide - and - conquer manner. Specifically, the policy operates at three levels of hierarchy. The first infer a sequence of subgoals to be executed based on language instructions by high - level policy composition controller ( PCC ). Then discriminatively control the agent ’s navigation by a master policy by alternating between navigation policy and various independent interaction policies. Finally, the inference manipulation actions with the corresponding object masks using the appropriate interaction policy. The proposed agent achieves state - of - the - art performance on the ALFRED benchmark."
SP:e2c8efe00db7baba2368f4f6a37815809b9e235e,"This paper proposes Nuisance - randomized distillation ( NURD ), a method to improve the performance of a model trained on a distribution where the nuisance is independent of the label. The authors define a family of distributions that differ only in the nuisance - label relationship. The distribution is called the "" nuisance - changing family "", and the authors show that under this distribution, the nuisance and the label are independent. The proposed method is based on two approaches : nuisance - randomization and distillation. The first approach uses a generative model to randomize the distribution, while the second one uses a reweighting approach to re - weight the distribution. The method is evaluated on three tasks : class - conditional Gaussians, labeling MNIST images, detecting waterbirds, and chest X - ray classification."
SP:c75998b76f4e0510fc719d25959a10fc07db1c40,"This paper proposes a novel method for zero - shot image recognition. The proposed method is based on the idea of entropic optimal transport ( OTTER ), which uses online transport to find a soft image - text match as labels for contrastive learning. OTTER is trained with only 3 M image text pairs, compared to CLIP, which requires 400 M images - text pairs for training. The authors also propose a quantitative vision - language compositionality benchmark to compare with CLIP in the appendix."
SP:e83cd70377542b5d187998e2e4a7ac070f453ed6,"This paper presents Pix2Seq, a simple and generic framework for object detection. Unlike existing approaches that explicitly integrate prior knowledge about the task, this paper simply cast object detection as a language modeling task conditioned on the observed pixel inputs. Object descriptions ( e.g., bounding boxes and class labels ) are expressed as sequences of discrete tokens, and we train a neural net to perceive the image and generate the desired sequence. The approach is based mainly on the intuition that if a neural network knows about where and what the objects are, we just need to teach it how to read them out. Beyond the use of task - specific data augmentations, the approach makes minimal assumptions about the tasks, yet it achieves competitive results on the challenging COCO dataset, compared to highly specialized and well optimized detection algorithms."
SP:abc9315f61929cc1c54dfef8ff83d7eac56ec2f2,"This paper proposes a method to distill the CNN policy into a symbolic policy, which is composed of geometric and numerical symbols and operators. The proposed method is based on a policy regression algorithm called RoundTourMix that distills the symbolic rules as teacher - student. The symbolic policy can be treated as discrete and abstracted representations of the policy network, but are found to be more interpretable, robust and transferable. Experiments show that the proposed symbolic distillation approach is experimentally demonstrated to maintain the performance and “ denoise the CNN policies ” on six specific environments."
SP:04e7e181aeb1244ae1c4837ad416aef93ea3ea32,"This paper proposes a method for image - to - image translation that aims to disentangle the pose and identity of the generated image from two exemplar sources. To this end, the authors propose a VQSN module for the generator that learns to encode the shaping and composition information from the commonly shared objects inside the training - set images. The authors also design a joint - training scheme with self - supervision methods for the GANInversion encoder and the generator. Specifically, the encoder reconstructs images from two different augmented variants of the original ones, one for pose and the other for identity. The proposed method is evaluated on CelebA, AFHQ and CelebA."
SP:e51a7f45493064972585109f203a867e9828eb15,"This paper proposes a simple MLP architecture for speech processing tasks. The main idea is to split the input features into non - overlapped chunks and process each chunk individually. The chunks are then merged together and further processed to consolidate the output. By setting different numbers of chunks and focusing on different contextual window sizes, speech - MLP learns multiscale local temporal dependency. The proposed model is evaluated on two tasks : keyword spotting and speech enhancement."
SP:d708d3886f4abd4552d8ccb2096df7361c803b13,This paper provides a new lower bound on the generalization error that can be achieved by any transfer learning algorithm ( regardless of its computational complexity ) as a function of the amount of source and target samples. The lower bound depends on a natural notion of distance that can easily be easily computed on real world data sets and requires minimal assumptions that enables it application to a broad range of problems. The authors also consider a more general setting where there are more than one source domains for knowledge transfer to the target task and develop new bounds on generalization errors in this setting. They also corroborate their theoretical findings on real image classification and action recognition data sets.
SP:f7511ba9ccad03233b34b1bf41bbac7361d20a57,"This paper proposes a probabilistic generative model for the task of shape completion from incomplete point cloud data. The proposed method is based on the Generative Cellular Automata ( cGCA ), which is an autoencoder - based model that learns the multi - modal distribution and transforms the formulation to process large - scale continuous geometry. The local continuous shape is incrementally generated as a sparse voxel embedding, which contains the latent code for each occupied cell. The training objective is proven to maximize the variational lower bound of the likelihood of sparse Voxel Embeddings. The experimental results show that the proposed method can successfully generate diverse plausible scenes faithful to the input, especially when the input suffers from a significant amount of missing data."
SP:d22d8f074adbe8fb0f25fb8f8d96201b3159bf6b,"This paper proposes a non - Markovian flow - based temporal prior for off - policy reinforcement learning. The authors argue that the current state - conditioned behavioral priors do not transfer well across domain gaps, and propose a state - independent temporal prior, which is more flexible and generalizable. They show that the proposed temporal prior can be integrated into an existing RL framework, and show that it can be used to improve the exploration efficiency in the long - horizon continuous control tasks under sparse reward settings."
SP:25e06c022ae8b3cbbb8db413d7b534a1a5c92391,"This paper proposes a novel learning rate scheduling method based on graph - network - based reinforcement learning ( GNS ). Specifically, the authors construct a directed graph for the underlying neural network of the target problem and use it to encode the current dynamics with a graph message passing network and train an agent to control the learning rate accordingly via reinforcement learning. The proposed method can capture the intermediate layer information while being able to generalize to problems of varying scales. Besides, an efficient reward collection procedure is leveraged to speed up training. The authors evaluate their framework on benchmarking datasets, Fashion - MNIST and CIFAR10 for image classification, and GLUE for language understanding."
SP:d73cb0471c1770607ad3e4621cfc5f170683dd8e,"This paper proposes a method for object - centric learning from point clouds. The proposed method is based on the Chamfer Mixture Loss ( CAML ), which is used to model the spatial mixture model on point clouds, and an object - specification scheme that describes each object ’s location relative to its local voxel grid cell. The method is evaluated on the task of unsupervised scene decomposition. The results show that SPAIR3D can generalize well to previously unseen scenes with a large number of objects without performance degeneration."
SP:3c57e921c1bf23e482551ceb71702931a7f07439,"This paper investigates the use of large language models ( LLMs ) to ground high - level tasks, expressed in natural language, to a chosen set of actionable steps ( i.e., open the fridge ) in an interactive environment. The authors find that if pre - trained LMs are large enough and prompted appropriately, they can effectively decompose high level tasks into low - level plans without any further training. However, the plans produced naively by LLMs often can not map precisely to admissible actions. To address this issue, the authors propose a procedure that conditions on existing demonstrations and semantically translates the plans to actionable actions. The proposed method is evaluated in the recent VirtualHome environment and shows that the resulting method substantially improves executability over the LLM baseline."
SP:e0159d1c9df2e657892a3a0c77549df4698d9a1a,"This paper proposes a new generative model based on the Riemannian manifold of the learned latent space of a VAE. The authors show that the latent space learned by the VAE can be seen as a manifold. Then, the authors propose a new generation process consisting in sampling from the intrinsic uniform distribution defined on this learned manifold. The proposed method is evaluated on four benchmark datasets and compared with more advanced VAEs using more complex priors, ex - post density estimation, normalizing flows or other regularization schemes."
SP:b4b8e1727f8617894f10f20365cb68de79f0e650,"This paper proposes Transformer with a Mixture of Gaussian Keys ( Transformer - MGK ), a novel transformer architecture that replaces redundant heads in transformers with a mixture of keys at each head. The proposed method is based on the Gaussian mixture model, which allows each attention head to focus on different parts of the input sequence efficiently. Compared to its conventional transformer counterpart, the proposed method accelerates training and inference, has fewer parameters, and requires less FLOPs to compute while achieving comparable or better accuracy across tasks. The method can also be easily extended to use with linear attentions."
SP:82731dcce233e748f63382e09b6224a513fe9689,"This paper proposes a method to fuse image and action related signals for navigation in a two - dimensional continuous environment. The proposed method is based on a recurrent neural network, which is trained to learn to keep track of its position relative to its starting point during a sequence of movements. The network updates its internal state using the ( possibly noisy ) self - motion signal, and occasionally resets it when the image signal is present. The authors show that the internal state of this minimal model exhibits strong correlation with position in the environment due to the direct - inverse models, is stable across long trajectories through resetting, and allows for disambiguation of visually confusing positions through integration of past movement, making it a prime candidate for a cognitive map."
SP:1a27c397d1e73def5e724c5c6f25548975ba50fa,"This paper studies the effect of input structure on the performance of neural networks. The authors consider the problem of classification problems where the labels are determined by a set of class relevant patterns and the inputs are generated from these along with some background patterns. They show that neural networks trained by gradient descent can succeed on these problems. The success relies on the emergence and improvement of effective features, which are learned among exponentially many candidates efficiently by exploiting the data ( in particular, the structure of the input distribution ). In contrast, no linear models on data - independent features of polynomial sizes can learn to as good errors. Furthermore, if the specific input structure is removed, then no Polynomial algorithm in the Statistical Query model can learn even weakly. These results provide theoretical evidence showing that feature learning in neural networks depends strongly on the input structure and leads to the superior performance."
SP:8ada73ed7eade9ebdeef376485e849c42575bc5f,This paper studies the robustness of feature extractors to adversarial examples generated by test - time adversaries. The main contribution of the paper is to provide a robustness bound for linear feature extractor based on the iterative solution of a convex program that provably finds collisions between pairs of perturbed examples at deeper layers. The paper also provides bounds on robustness for any classifier trained on top of it. The tightness of these bounds relies on the effectiveness of the method used to find collisions between perturbed pairs of examples.   The paper uses the bounds to identify the layers of robustly trained models that contribute the most to a lack of robustness as well as compare the same layer across different training methods to provide quantitative comparison of their relative robustness.
SP:874b5fa51924cbcceed490d98a0ea80f74586b32,"This paper proposes a new offline reinforcement learning method called Value - based Episodic Memory ( VEM ), which learns the V - function instead of the Q - function to naturally keep the learning procedure within the offline dataset. The paper also provides theoretical analysis for the convergence properties of the proposed VEM method, and empirical results in the D4RL benchmark show that the proposed method achieves superior performance in most tasks, particularly in sparse - reward tasks."
SP:34f08d92681504490c2f739b0d08f79f9764b2f5,"This paper proposes a novel adversarial training framework that learns to reweight the loss associated with individual training samples based on a notion of class - conditioned margin, with the goal of improving robust generalization. Inspired by MAML - based approaches, the authors formulate weighted adversarial learning as a bilevel optimization problem where the upper level task corresponds to learning a robust classifier, and the lower level task is learning a parametric function that maps from a sample ’s multi - class margin to an importance weight. Extensive experiments demonstrate that our approach improves both clean and robust accuracy compared to related techniques and state - of - the - art baselines."
SP:3ad36be6b6900aabe43da043461cf178ce977082,"This paper proposes a new type of equivariant graph neural network, called Steerable E(3 ) Equivariant Graph Neural Networks ( SEGNNs ), that can incorporate geometric and physical information in both the message and update functions. This model is composed of steerable MLPs, which are composed of two components : non - linear message aggregation and steerable message passing. The message aggregation improves upon classic linear ( steerable ) point convolutions ; steerable messages improve upon recent equivariance graph networks that send invariant messages. The node attributes could be the average edge embedding of relative positions over neighbours of a node, and could additionally include node force, spin or velocities, as we do in the N - body experiment. Extensive ablation studies have further shown the benefit over non - steerable (invariant ) message passing, and the benefit of non -linear over linear convolutions."
SP:8928aa83f7ebd4e310f4fe1d01ff0eb0c96e4d2b,"This paper proposes a new differentiable physics model for composite materials such as cloths, where the granularity of yarns and model individual yarn physics and yarn - to - yarn interactions. To this end, they propose several differentiable forces, whose counterparts in empirical physics are indifferentiable, to facilitate gradient - based learning. These forces, albeit applied to cloth, are ubiquitous in various physical systems. Through comprehensive evaluation and comparison, they demonstrate their model ’s explicability in learning meaningful physical parameters, versatility in incorporating complex physical structures and heterogeneous materials, data - efficiency in learning, and high - fidelity in capturing subtle dynamics. To our best knowledge, this model is the first differentiable model which provides sufficient granularity for heterogeneous material such as fabrics."
SP:2c8358c095b10981d3015b9f6c75765419a9480d,"This paper proposes a new method for transfer learning in reinforcement learning. The method is based on the Boolean algebra framework of Nangue Tasse et al. ( 2020 ), which allows an agent to decide which skills should be reused in a new task. The authors provide theoretical results on the performance of the transferred policy on the new task, and the number of tasks that need to be learned throughout an agent ’s lifetime to generalize over a task distribution. They also demonstrate that as a side effect of the transfer learning approach, an agent can produce an interpretable Boolean expression of its understanding of the current task."
SP:c85d71d05164d019cc32bf423e4c4fe20c169f41,"This paper presents LightWaveS, a distributed solution for multivariate time series classification ( MTSC ), which is fast both during training and inference. The proposed method uses a wavelet scattering transformation of the time series and distributed feature selection to create a solution which employs just 2,5 % of the ROCKET features, while achieving accuracy comparable to recent deep learning solutions. The method scales well with more nodes and large number of channels. In addition, it can significantly reduce the input size and also provide insight to an MtsC problem by keeping only the most useful channels. The paper presents three versions of the algorithm and their results on training time, accuracy, inference speedup and scalability."
SP:db43614ca016280a79448f44a97c81c8ff5ba981,"This paper proposes a method for training ELECTRA - style text encoders using adversarial mixture of multiple training signal generators. The main idea is to construct the corrupted text sequences by attaching multiple MLM heads to a deeper generator and sampling replaced tokens from their mixed outputs. The weights of the mixtures are learned to maximize the training signals difficulty for the discriminator, by backpropagating the reversed gradient from the discriminators through Gumbel - Softmax. The experiments on the GLUE and SQuAD benchmarks demonstrate the empirical advantages of AMOS."
SP:db3825633ab5d0671340390b23ab655838cc38b2,"This paper proposes an adaptive fine - tuning method for cloze - style fact extraction from pre - trained language models. The idea is to fine - tune a language model on the standard fill - mask task using a small training dataset of existing facts from a knowledge graph. To further reduce the amount of training data that is needed, the authors also inspect the transfer learning capabilities of the pre - training language model for knowledge extraction. The experiments show that the proposed method can significantly improve upon the best state - of - the - art baselines on the LAMA probe, with fewer training data required and without the need for an additional model."
SP:ae25d32714b2b9f7e02cc20f4a36252e20e78e4f,"This paper proposes to learn the knowledge base embeddings in different geometric spaces and apply manifold alignment to align the shared entities. The proposed method is evaluated on the out - of - taxonomy entity typing task, where the authors aim to predict the types of the entities from the knowledge graph. The main motivation is to allow different geometric space to model the various properties of relations as well as the various local structures of the knowledge bases. The manifold alignment provides a way to incorporate the local manifold structure of two entity sets. The empirical results demonstrate the superiority of the approach, especially in low dimensions and on small training rates."
SP:9ab3bc525ee4a9c96518c43e4c43082655a7674f,"This paper proposes a one - shot learning framework for link prediction in temporal knowledge graphs. The proposed method employs a self - attention mechanism to effectively encode temporal interactions between entities, and a network to compute a similarity score between a given query and a single example. The experiments show that the proposed algorithm outperforms the state - of - the - art baselines for two well - studied benchmarks while achieving significantly better performance for sparse relations."
SP:91f92a40e12afd0702f07ae7f4175ecce57b7007,"This paper proposes Progressive Module Networks ( PMN ), a multi - task learning model for visual reasoning tasks. The main idea of PMN is to train task modules in a compositional manner, by exploiting previously learned lower - level task modules. PMN can produce queries to call other modules and make use of the returned information to solve the current task. The authors show that PMN outperforms baselines without module composition on all tasks. They further analyze the interpretability of the reasoning process with human judges."
SP:de33b02e7f2faec5bcae9a5516721aa1ef190572,"This paper proposes a method to improve the parameter efficiency of CNNs with bottleneck structures. The proposed method is based on the idea of channel - selectivity, i.e., redistributing the computations to important channels. The authors propose a new architectural unit, called Selective Convolutional Unit ( SCU ), that gradually learns channel - selection via the alternative usage of ( a ) pruning unimportant channels, and ( b ) rewiring the pruned parameters to important ones. The experiments show that the SCU - based models generally achieve both model compression and accuracy improvement compared to the baselines, consistently for all tested architectures."
SP:2d80fa4bc440061be2234b5070503d3fa056baed,"This paper considers the problem of learning a binary classifier only from positive data and unlabeled data ( PU learning ). The authors propose a method to partially identify the classifier. The proposed algorithm learns a scoring function that preserves the order induced by the class posterior under mild assumptions, which can be used as a classifier by setting an appropriate threshold. Through experiments, the authors show that the method outperforms previous methods for PU learning on various real - world datasets."
SP:5f312626b0613d2e07c59214c5f00db208a98717,"This paper proposes to use cosine similarity between gradients of tasks as an adaptive weight to detect when an auxiliary loss is helpful to the main loss. The authors show that their approach is guaranteed to converge to critical points of the main task and demonstrate the practical usefulness of the proposed algorithm in a few domains : multi - task supervised learning on subsets of ImageNet, reinforcement learning on gridworld, and reinforcement learning   on Atari games."
SP:e270ae3eeb7ab4fa91ba37d4d68ce10f2fa0a3b5,"This paper proposes a geometric framework to analyze the high - dimensional geometry of adversarial examples. The authors highlight the importance of codimension in generating adversarial perturbations for low - dimensional data manifolds. They show that the choice of norm to restrict an adversary is important in that there exists a tradeoff between being robust to different norms : improving robustness under the $ \ell_\infty$ norm requires a loss of $ \tilde{O}(\sqrt{d}(1/\sqrt{\delta})$ samples compared to the $ O(d)$ norm. They also show that a common approach, training from balls around the training set, is insufficient to learn robust decision boundaries with realistic amounts of data. However, they show that nearest neighbor classifiers do not suffer from this insufficiency, due to geometric properties of their decision boundary away from data, and thus represent a potentially robust classification algorithm."
SP:e07d948a79d478ecd23a0a4406d4ddd3ac5e3be3,"This paper proposes a new representation learning framework for time series data. The proposed method is based on the idea of interpretable discrete dimensionality reduction and deep generative modeling. The authors propose a gradient - based algorithm to overcome the non - differentiability in discrete representation learning and present a gradient based version of the traditional self - organizing map algorithm that is more performant than the original one. Furthermore, to allow for a probabilistic interpretation of the method, the authors integrate a Markov model in the representation space. This model uncovers the temporal transition structure, improves clustering performance even further and provides additional explanatory insights as well as a natural representation of uncertainty.   The authors evaluate the proposed method on static MNIST data, a chaotic Lorenz attractor system with two macro states, and a challenging real world medical time series application on the eICU data set."
SP:5915ee71ea58dbdbafa31c1ad291d1e5940a0cf4,"This paper investigates the properties of multidimensional probability distributions in the context of latent space prior distributions of implicit generative models. The authors show that there is a trade - off between the interpolation being linear, and the latent distribution having even the most basic properties required for stable training, such as finite mean. They also provide a general method of creating non - linear interpolations, that is easily applicable to a large family of commonly used latent distributions."
SP:19b63ca635712f1509ca6e0141303c192f2709e0,"This paper proposes to use hyperbolic geometry as an inductive bias for the activations of deep neural networks. Specifically, the authors propose to use the geometry of embedding of object representations as an input to the attention mechanism of a deep neural network. The proposed method is based on the hyperboloid model. The authors show that the proposed method can improve the performance on a variety of tasks."
SP:f6049e9f80a63c9306c1cebcb6b229aa6da44ddc,"This paper presents an attack that extracts the architecture information of a black - box neural network using Flush+Reload, a cache side - channel technique. The authors define the threat model for these attacks : the attacker does not need the ability to query the victim model ; instead, she runs a co - located process on the host machine where the victim ’s deep learning ( DL ) system is running and passively monitors the accesses of the target functions in the shared framework. Based on the extracted architecture attributes, the attacker can build a meta - model that accurately fingerprints the architecture and family of the pretrained model in a transfer learning setting. Finally, the authors propose and evaluate new framework - level defense techniques that obfuscate our attacker’s observations."
SP:6a3dd89db6c24a1f98e8866ef0a4c1c2c1ec6635,"This paper proposes a hierarchical network model, called Hierarchical Prediction Network ( HPNet ), to understand how spatiotemporal memories might be learned and encoded in a representational hierarchy for predicting future video frames. The model is inspired by the feedforward, feedback and lateral recurrent circuits in the mammalian hierarchical visual system. The network learns by comparing the incoming signals with its prediction, updating its internal model of the world by minimizing the prediction errors at each level of the hierarchy in the style of predictive self - supervised learning. HPNet processes data in blocks of video frames rather than a frame - to - frame basis. This allows it to learn relationships among movement patterns, yielding state - of - the - art performance in long range video sequence predictions in benchmark datasets. The paper also provides neurophysiological evidence showing that neurons in the early visual cortex of the primate visual system exhibit the same sensitivity to memories of global movement patterns as units in the lowest modules of HPNet."
SP:fb74e57f35666742caf651e6da33b5defcf259a8,"This paper proposes a method to compute continuous embeddings for kmers from raw RNA - seq data, in a reference - free fashion. The authors report that their model captures information of both DNA sequence similarity as well as DNA sequence abundance in the embedding latent space. They confirm the quality of these vectors by comparing them to known gene sub - structures and report that the latent space recovers exon information from rawRNA - Seq data from acute myeloid leukemia patients. Furthermore they show that this latent space allows the detection of genomic abnormalities such as translocations and patient - specific mutations, making this representation space both useful for visualization and analysis."
SP:03aca6ff6a7f0ad2d5ccbcb15ed9536e305a9880,"This paper proposes a method to compress CNNs by first training a continuous embedding on a representation of the architecture and then performing gradient descent to determine an optimal architecture for the given task. The paper also introduces a novel theoretical analysis of CNNs which will inspire future work. The authors demonstrate the effectiveness of their approach on several visual recognition tasks such as CIFAR-10/100, FMNIST and SVHN and achieve a greater than 20x compression on Cifar-10."
SP:0511b5d10a90e3fe814e2d35208b4a987894ea62,"This paper proposes POLO, a method for planning online and learning offline in the physical world. POLO combines the strengths of trajectory optimization and value function learning. In particular, the authors propose to use trajectory optimization to learn a global value function, and then use value function estimation to estimate uncertainty in the value function. The authors show that trajectory optimization can be used to perform temporally coordinated exploration in conjunction with estimating uncertainty in value function approximation. This exploration is critical for fast and stable learning of the value functions. The proposed POLO can be applied to complex control tasks, such as humanoid locomotion and dexterous in - hand manipulation."
SP:771494fda4702cd8c7efbf225b19028f91b449b9,"This paper proposes a zero - shot dual machine translation method for low - resource languages. The proposed method is based on a multilingual NMT system ( Johnson et al., 2016 ) by applying reinforcement learning, using only monolingual data on the zero shot translation pairs, inspired by dual learning. Experiments show that this approach outperforms the multilingual model for unsupervised language pairs, on in - domain evaluations in the UN corpus. In out - of - domain evaluation, the proposed method performs as well or better than the state of the art, for comparable neural architectures including Transformers."
SP:1558dc03f99670f9ddccdca9c223a2baf962d438,"This paper proposes a new generative adversarial network ( IRGAN ) based on the framework for Information - Retrieval ( IR ). The authors point out that the proposed IRGAN uses the wrong formulation of the minimax loss function, and propose a co - training method to improve the performance of IRGAN. The proposed method is evaluated on Web - Search, Question Answering, and Content - Recommendation tasks. Results show that IRGAN does not outperform other baselines."
SP:6a13dda852ab075a3c0fb691476d6dc57919c729,"This paper proposes to use Spike and Slab prior distribution to model sparsity in the latent space of a VAE. The proposed method is based on the idea of sparse coding, which is used in sparse variational auto - encoders ( VAEs ). The key idea is to use a mixture recognition function to estimate the sparsity of the latent code. The method is shown to be computationally efficient compared to the standard VAEs. The authors also show that the resulting representations are more robust to the number of latent dimensions."
SP:06a22143186fa2948fbe324ccae96a62ff12064e,"This paper proposes a non - adversarial feature matching - based approach to train generative models. The approach, Generative Feature Matching Networks ( GFMN ) leverages pretrained neural networks such as autoencoders and ConvNet classifiers to perform feature extraction. The experimental results demonstrate that, due to the expressiveness of the features from pretrained ImageNet classifier, even by just matching first order statistics, our approach can achieve state - of - the - art results for challenging benchmarks such as CIFAR10 and STL10. Moreover, the same feature extractor is effective across different datasets."
SP:2d7cf2f07a27d6c8e304a1b47c25387ad2e4432d,"This paper studies the expressive power of GNNs for graph representation learning. The paper provides a theoretical analysis of the discriminative power of popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, and show that they can not learn to distinguish certain simple graph structures. Then the paper develops a simple architecture that is provably the most expressive among the class of Graph Neural Networks and is as powerful as the Weisfeiler - Lehman graph isomorphism test ( GIN ). Empirical results show that the proposed GIN has high representational power as it almost perfectly fits the training data, whereas the less powerful GNN variant often severely underfit the training dataset."
SP:51126f2dd37ce57d2614c9044ede1e43627f0829,"This paper proposes an interpretable continual learning ( ICL ) method, which uses saliency maps to provide explanations of previously performed tasks to improve performance on future tasks. The main idea is to generate a good explanation of a finished task, then use this to focus attention on what is important when facing a new task. The proposed method is based on the variational continual learning framework to take advantage of its flexibility and efficacy in overcoming catastrophic forgetting. Experiments show that ICL achieves state - of - the - art results in terms of overall continual learning performance as measured by average classification accuracy and explanations, which are assessed qualitatively and quantitatively using the proposed metric."
SP:27a565b3e5442b93d208652784051e640b0c1bfe,"This paper proposes a new evaluation framework for adversarial attacks on neural sequence - to - sequence ( seq2seq ) models taking the meaning preservation into account. Specifically, the authors propose a “ source - meaning preserving, target - meaning - destroying ” criterion for the adversarial examples using both manual and automatic evaluation using both human and automatic evaluations. The authors evaluate the effectiveness of adversarial training with the proposed criteria and show that it is beneficial to the model in terms of robustness to adversarial robustness without hurting test performance."
SP:54ddd8132bf9e4259d2c2d72b348d2bb5f9e227c,"This paper proposes a hybrid policy that combines the policies using original rewards and inverse ( negative ) rewards to improve the performance and stability of reinforcement learning algorithms. The authors prove the convergence of the inverse policies. The experiments show that the hybrid policy improves the performance of Q - learning, double - q - learning and on - policy actor - critic algorithms."
SP:89a732b57934d08b937c93560f391b7758e54f8a,"This paper proposes a method to learn a hierarchical, disentangled object representation and a dynamics model for object parts from unlabeled videos. The method uses a layered image representation to discover basic concepts and a structural descriptor to compose them. Experiments on multiple real and synthetic datasets demonstrate that the proposed method works well on all three tasks : segmenting object parts, building their hierarchical structure and capturing their motion distributions."
SP:bb2a655d67bed9da43f0b8ec7d888b89c217d12e,"This paper proposes a novel inference method, Deep Determinantal Generative Classifier ( DDGC ), which can obtain a more robust decision boundary under any softmax neural classifier pre - trained on noisy datasets. The main idea is inducing a generative classifier on top of hidden feature spaces of the discriminative deep model. By estimating the parameters of generative classification using the minimum covariance determinant estimator, DDGC significantly improve the classification accuracy, with neither re - training of the deep model nor changing its architectures. The paper also shows that DDGC not only generalizes well from noisy labels, but also is robust against adversarial perturbations due to its large margin property. Finally, an ensemble version of DDGC is proposed to improve its performance, by investigating the layer - wise characteristics."
SP:0fa525cc708470b757a60117cb608bb2feaa2c50,This paper proposes a model - free method for subgoal discovery in hierarchical reinforcement learning ( HRL ). The method uses incremental unsupervised learning over a small memory of the most recent experiences of the agent. The subgoal selection is done by a meta - controller that learns subgoals and skills based on experiences in the environment. The proposed method is evaluated on two RL problems with sparse delayed feedback : a variant of the rooms environment and ATARI 2600 game called Montezuma's Revenge.
SP:e5861538bc8bb9165cb33299bbf12dd875abf976,"This paper proposes a neural framework to solve the Circuit Satisfiability problem ( SAT ), which is a fundamental NP - complete problem in Computer Science. The proposed method is built upon two contributions : a rich embedding architecture that encodes the problem structure, and an end - to - end differentiable training procedure that mimics Reinforcement Learning and trains the model directly toward solving the SAT problem. The experimental results show the superior out - of - sample generalization performance of the proposed method compared to the recently developed NeuroSAT method."
SP:ff3e5d44619df3825632b0b1a943add081364861,"This paper proposes a new combination scheme using the simple cross - entropy method ( CEM ) and Twin Delayed Deep Deterministic Policy Gradient ( TD3 ), another off - policy deep RL algorithm which improves over DDPG. The authors evaluate the resulting method, CEM - RL, on a set of benchmarks classically used in deep RL. They show that the proposed method benefits from several advantages over its competitors and offers a satisfactory trade - off between performance and sample efficiency."
SP:78b2eb326695da0b0cc4ba39a9206d11644a5e32,This paper proposes an interpretable multi - variable LSTM recurrent neural network for time series with exogenous variables. The proposed model is equipped with hidden state matrix and update process to learn variableswise hidden states. The authors also develop a mixture attention mechanism and associated summarization methods to quantify the temporal and variable importance in data. Extensive experiments using real datasets demonstrate the prediction performance and interpretability of IMV-LSTM in comparison to a variety of baselines.
SP:1c26660569b579f060f7b4a31e321c6d2356b928,"This paper proposes feature smoothing, a data augmentation method with little computational overhead to improve the robustness against adversarial attacks. Feature smoothing trains a neural network on virtual training data as an interpolation of features from a pair of samples, with the new label remaining the same as the dominant data point. The intuition is to generate virtual data points as close as adversarial examples, and to avoid the computational burden of generating data during training. The experiments on MNIST and CIFAR10 datasets explore different combinations of known regularization and data augmentation methods and show that feature smoothed with logit squeezing performs best for both adversarial and clean accuracy. The paper also proposes an unified framework to understand the connections and differences among different efficient methods by analyzing the biases and variances of decision boundary."
SP:88d652f9e411dd3a2e9ad651d9011e579653c6aa,"This paper proposes a novel theoretical framework for deep neural networks with ReLU nonlinearity. The proposed framework bridges data distribution with gradient descent rules, favors disentangled representations and is compatible with common regularization techniques such as Batch Norm. The framework is built upon teacher - student setting, by projecting the student’s forward / backward pass onto the teacher ’s computational graph. The authors do not impose unrealistic assumptions ( e.g., Gaussian inputs, independence of activations, etc ). Their framework could help facilitate theoretical analysis of many practical issues such as overfitting and disentanglement in deep networks."
SP:7842bbe0e2324cfd732db8745550733ccc3dfcdc,"This paper proposes a modular architecture of neural networks with a Behavioral Module ( BMs ). The proposed method is inspired by human behavior formation process and the Pre - Frontal Cortex ( PFC ), which is a part of the brain which is responsible for behavior repertoire. The authors demonstrate the effectiveness of their approach on video games domain. The experimental results show good separation of behavior with different BMs, as well as promising results when transfer learned BMs to new tasks. The experiments also show network extendability through independent learning of new behavior patterns."
SP:300c391ff644b6889cd9ae27cf0d162dfcdd4451,"This paper introduces a biologically - inspired method for training neural networks to self - modify their weights. The authors introduce neuromodulated plasticity to let the network control its own weight changes. They build on the differentiable plasticity framework ( Miconi, 2017 ) to implement differentiable neuro - plasticity. As a result, for the first time to our knowledge, we are able to train neurommodulated plastic networks with gradient descent. The experimental results show that the proposed method improves the performance of neural networks on both reinforcement learning and supervised learning tasks. In one task, the authors show that neurom modulated plastic LSTMs with millions of parameters outperform standard LSTM on a benchmark language modeling task."
SP:1ab5d94d31e99351433436c026799c8aa597bf73,"This paper proposes an iterative quantization method to improve the accuracy of deep neural networks. The method is based on re - training the full precision model, followed by directly optimizing the corresponding binary model. The quantization training process takes no longer than the original training process. The authors also propose a new loss function to regularize the weights, resulting in reduced quantization error. Combining both help us achieve full precision accuracy on CIFAR dataset using binary quantization. We also achieve full accuracy on WikiText-2 using 2 bit quantization using binary model and 1.5 bits quantization for WikiText."
SP:0876b1d9a6d664808ca1ab15865679fbf638267e,"This paper proposes a method for open - ended style transfer from one image to another. The method is based on the idea of content - style decomposition and recombination, where the content of one image is decomposed into content and style, and the style is recombined with the content from the other image. The authors propose a VAE - style encoder - content encoder architecture, which consists of a content embedding and a style embedding, which is trained using a variational autoencoder ( VAE ). The VAE is then used to reconstruct the content representation of the image from the previous image, and then the style representation from the next image is used to generate a new image. This method is evaluated on a few - shot image classification task."
SP:d37e15cde7765fca87595a242f0a4511b3346d46,"This paper proposes a method to speed up deep reinforcement learning ( deep RL ) training for problems that have the property of state - action permissibility ( SAP ). Two types of SAP are defined. The first type says that after an action at is performed in a state and the agent reaches the new state st+1, the agent can decide whether the action is permissible or not permissible in state st. The second type defines that even without performing the action at in st, an agent can already decide whether at is permitted or not in st. An action is not permissible if the action can never lead to an optimal solution and thus should not be tried. The proposed method incorporates the proposed SAP property into two state - of - the - art deep RL algorithms to guide their state action exploration. Results show that the SAP guidance can markedly speed up training."
SP:20015d8b60e13300586b67c281858cbe28825c48,"This paper studies the behavior of weight - tied multilayer vanilla autoencoders under the assumption of random weights. The authors provide a precise characterization in the limit of large dimensions, which reveals interesting phase transition phenomena when the depth becomes large. They also provide insights on pitfalls in training initialization practice, and demonstrate experimentally that it is possible to train a deep autoencoder, even with the tanh activation and a depth as large as 200 layers, without resorting to layer - wise pre - training or batch normalization."
SP:91764f80dbe2401ade38b35a8253ba05f0f86386,"This paper proposes SimBA, a simple black - box adversarial attack algorithm that takes small steps iteratively towards the decision boundary. The key idea is to randomly pick a low frequency component of the discrete cosine transform ( DCT ) and either add or subtract it to the target image. The proposed method can be used for targeted and untargeted attacks, resulting in previously unprecedented query efficiency in both settings. SimBA can be implemented in PyTorch in under 20 lines of code."
SP:fc20ae0fbf57a1ce489c04b85c7c2f4c93dc2450,"This paper proposes a new method for option discovery in hierarchical reinforcement learning. The method is based on the idea of "" landmark states "", which are states in a well - connected region of the state space. The key idea is to cluster the states into sub - goals, which can be easily accessed. The authors also propose a new model called Successor options that leverages Successor representations to achieve the same. They also design a novel pseudo - reward for learning the intra - option policies that extends to function approximators. Finally, they describe an incremental approach that iteratively builds options and explores in environments where exploration through primitive actions is inadequate to form the successor representations."
SP:12a172c1e2892d016b37932acfc48dcb56874a89,"This paper proposes a probabilistic approach to solve the problem of domain division in zero - shot learning. In particular, the authors propose to split the testing instances into known, unknown and uncertain domains, and then conduct recognition tasks in each domain. Two statistical tools, namely, bootstrapping and Kolmogorov - Smirnov ( K - S ) Test, are introduced to uncover and fine - tune the decision boundary of each domain, and the uncertain domain is newly introduced in the framework to adopt those instances whose domain labels can not be predicted confidently. Extensive experiments demonstrate that the approach achieved the state - of - the - art performance on OSL and G - ZSL benchmarks."
SP:28bcf7c6a4673e9ec2b4ebed09839d85188e0b2a,"This paper proposes a neural network for classification and regression. The proposed network is based on polar prototypes, which are points on the hypersphere of the output space. For classification, each class is described by a single polar prototype and they are a priori distributed with maximal separation and equal shares. For regression, training can be performed as a polar interpolation between two prototypes, arriving at a regression with higher - dimensional outputs. Experiments show that polar prototype networks benefit from large margin separation and semantic class structure."
SP:d1034342785d133cf8372b8624897963cc2ee83a,"This paper proposes an algorithm, RLSP, that uses a Maximum Causal Entropy ( MCE ) model of human behavior to infer the reward function from the initial state of an agent. The authors argue that the state of the world at initialization is a source of information about human preferences, which can be used to infer both side effects that should be avoided as well as preferences for how the environment should be organized. RLSP is evaluated on a suite of proof - of - concept environments designed to show the properties of the algorithm."
SP:417a4e0acee699b3e004ad30d0ecf533a9ed987e,"This paper proposes a method for learning dependency structures between latent variables in deep latent variable models. The method combines the complementary strengths of deep generative models and probabilistic graphical models. In particular, they express the latent variable space of a variational autoencoder in terms of a Bayesian network with a learned, flexible dependency structure. The network parameters, variational parameters as well as the latent topology are optimized simultaneously with a single objective. Inference is formulated via a sampling procedure that produces expectations over latent variable structures and incorporates top - down and bottom - up reasoning over latent variables values. They validate their framework in extensive experiments on MNIST, Omniglot, and CIFAR-10."
SP:976dedab53e69610692a563382ada1dbb82c1e9d,"This paper proposes a dynamical neural network for dictionary learning. The proposed method is based on top - down feedback and contrastive learning. In particular, the authors use spiking neurons to construct the dynamical network. The authors show that the gradients are provably computable by individual neurons. They also provide a learning process, its rigorous mathematical analysis, and numerical results on several dictionary learning problems."
SP:f45117a6beaeb86a70b1380b4fac3cfba37fb892,This paper proposes a novel CNN - based method for image segmentation and lane detection. The main idea is to use multiple encoder - decoders module in end - to - end ways and show the promising results for lane detection task. The paper also proposes a small quantity of channel to reduce overfitting by considering interdependencies among channels. Extensive experiments on CUlane dataset demonstrate the effectiveness of the proposed net.
SP:68b0a10ca06df74612d0753cc3f3ddddde806035,"This paper proposes a new approach for batch contextual bandit learning from logged feedback. The proposed approach is based on Maximum Likelihood Inverse Propensity Scoring ( MLIPS ), which estimates a maximum likelihood surrogate policy based on the logged action - context pairs, and then use this surrogate policy as the proposal. Theoretical analysis shows that the proposed MLIPS estimator is asymptotically unbiased, and moreover, has a smaller nonasymptotic mean squared error than the classical IPS estimator. Experimental results on several large - scale datasets also demonstrate the empirical effectiveness of the proposed estimator, and the proposed method can also be combined with existing approaches and further improves the performance."
SP:8e0ed65c5dded23b34798499b2436b24422fd729,"This paper proposes a meta - learning method for few - shot classification. The authors propose to learn how to create an individualized feature space specific to a given query image for better classifying, i.e., given a query image, a specific feature embedding tailored for its characteristics is created accordingly, leading to an individualised feature space in which the query image can be more accurately classified. Specifically, they introduce a kernel generator as meta - learner to learn to construct feature space for query images. The kernel generator acquires meta - knowledge of generating adequate convolutional kernels for different query images during training, which can generalize to unseen categories without fine - tuning. The proposed method is evaluated on Omniglot and miniImageNet."
SP:faa3f7ffdcfb6e3b8ec0421193dae3d9987b015c,"This paper proposes a population - based genetic algorithm ( GA ) to train deep neural networks for challenging RL tasks. The authors show that GA can outperform evolutionary strategies ( ES ) and backprop - based algorithms such as Q - learning and policy gradients on challenging deep reinforcement learning ( RL ) problems, including Atari and humanoid locomotion. They also show that combining DNNs with novelty search, which encourages exploration on tasks with deceptive or sparse reward functions, can solve a high - dimensional problem on which reward - maximizing algorithms ( e.g. DQN, A3C, ES, and the GA ) fail."
SP:dfdbe3267a8160f24746884cdf5297993e424231,"This paper proposes a new curiosity method that uses episodic memory to form the novelty bonus. To determine the bonus, the current observation is compared with the observations in memory. Crucially, the comparison is done based on how many environment steps it takes to reach the current observations from those in memory — which incorporates rich information about environment dynamics. This allows us to overcome the known “ouch -potato ” issues of prior work — when the agent finds a way to instantly gratify itself by exploiting actions which lead to hardly predictable consequences. The authors test their approach in visually rich 3D environments in VizDoom, DMLab, and MuJoCo. In navigational tasks from Vizdoom, the agent outperforms the state - of - the - art curiosity method ICM. In MuJo Co, an ant equipped with our curiosity module learns locomotion out of the first - person - view curiosity only."
SP:1e58a1c5344d1b5b7c8a40210a243700bd933d65,"This paper presents a method for learning a sparse relational transition model for robotic actions. The method is based on the idea of deictic references, which is used to select a set of objects that are relevant to the task at hand, and feed - forward neural networks are used to learn the transition distribution on the relevant objects ’ properties. The approach is demonstrated to be both more versatile and more sample efficient than learning a monolithic transition model in a simulated domain in which a robot pushes stacks of objects on a cluttered table."
SP:8ce00a3fedbf54a7f2c1ff414511cbb7d59b4597,"This paper proposes a novel instance - wise feature selection method, named INVASE. The method is based on the actor - critic model, where the selector network is trained iteratively to minimize a Kullback - leibler divergence between the full conditional distribution and the selected - features - only conditional distribution of the outcome. The model consists of 3 neural networks : a selector network, a predictor network, and a baseline network. During training, each of these networks are trained to minimize the KL divergence. Experiments on synthetic and real - word data show that the proposed method outperforms existing state - of - the - art methods."
SP:b91d6c33349df0bb6cb7e1c5e9433f0d4744b4da,"This paper proposes a domain adaptation method for structured output prediction by utilizing global and patch - level adversarial learning modules. The global alignment is achieved by the output space adaptation, while the patch-level one is performed via learning discriminative representations of patches across domains. To learn such patch representations, the authors construct a clustered space of the source patches and adopt an adversarial scheme to push the target patch distributions closer to the source ones. The authors conduct extensive ablation study and experiments to validate the effectiveness of the proposed method under numerous challenges on semantic segmentation, including synthetic - to - real and cross - city scenarios, and show that their approach performs favorably against existing algorithms."
SP:00922af13a21464cbc4cd7b34c196dd4f86c9247,"This paper proposes two new optimistic algorithms for AMSGrad and Adam, respectively, by exploiting the predictability of gradients. The new algorithms combine the idea of momentum method, adaptive gradient method, and algorithms in OPTIMISTIC ONLINE LEARNING, which leads to speed up in training deep neural nets in practice. The algorithms are based on the observation that mini - batch of stochastic gradients in consecutive iterations do not change drastically and consequently may be predictable. Inspired by the similar setting in online learning literature, the authors propose two new algorithms : ( 1 ) New - OAP - AMSGRAD and ( 2 ) Optimistic - ADAGRAD. The proposed algorithms not only adapt to the informative dimensions and exhibit momentums but also take advantage of a good guess of the next gradient to facilitate acceleration. Experiments show that these algorithms are faster than the baselines."
SP:52228b48f2776d57dd422edb33b82e247f056b75,"This paper introduces two new benchmarks for image classifier robustness. The first benchmark, IMAGENET - C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety - critical applications. The second benchmark, ImageNet - P, enables researchers to benchmark a classifier ’s robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbation not worst - case adversarial perturbings. The authors find that there are negligible changes in relative corruption robusts from AlexNet classifiers to ResNet classifier. Afterward, the authors discover ways to enhance corruption and adversarial robustness, and even find that a bypassed adversarial defense provides substantial common perturbing robustness and robustness can be improved. Together these benchmarks may aid future work toward networks that robustly generalize."
SP:20358ea0f769e6ea9222d8e35159d711ee1b20b2,"This paper shows that dropout training can be understood as performing MAP estimation concurrently for an entire family of conditional models whose objectives are themselves lower bounded by the usual dropout objective. This discovery allows us to pick any model from this family after training, which leads to a substantial improvement on regularisation - heavy language modelling. The family includes models that compute a power mean over the sampled dropout masks, and their less stochastic subvariants with tighter and higher lower bounds than the fully stochastically drop out objective. The deterministic subvariant ’s bound is equal to its objective, and the highest amongst these models. It also exhibits the best model fit in our experiments. Together, these results suggest that the predominant view of deterministic dropout as a good approximation to MC averaging is misleading. Rather, deterministic Dropout is the best available approximation to the true objective."
SP:ac1b950ad29429ae045bb5e53279014a6a0b9d2b,"This paper proposes a global soft filter pruning ( GSFP ) scheme to prune redundant filters of convolutional neural networks ( CNNs ). Specifically, the GSFP adopts a robust pruning method, which measures the global redundancy of the filter in the whole model by using the soft pruning strategy. In addition, in the model recovery process after pruning, the authors use the cumulative saliency strategy to improve the accuracy of pruning. Experiments show that GSFP is effective on many classic CNN architectures and different data sets."
SP:621e41d4199e333ec7f9d0936d4e34c918f39c11,"This paper proposes a cross - lingual document classification framework ( CACO ) between related language pairs. The key idea is to jointly train a character - based embedder and a word - based classifier. The embedder derives vector representations for input words from their written forms, and the classifier makes predictions based on the word vectors. The proposed method is evaluated on CLDC between nine related languages pairs on two datasets. The results show that the proposed method can match the accuracy of CLWE - based models without using any target language data."
SP:544e421f9c747640d949f433e3091763508b7237,"This paper proposes a new method for weakly - supervised temporal action localization. The proposed method is based on the marginalized average attentional network ( MAAN ), which uses a set of latent discriminative probabilities to train the network to find the most important regions in the video. The authors provide a theoretical analysis of the properties of MAA and an explanation of the reasons MAAN alleviates the issue raised by the domination of the most salient regions. They also propose a fast algorithm to reduce the complexity of constructing MAA from O(2 ) to O(T ). Extensive experiments on two large - scale video datasets show that the proposed MAAN achieves a superior performance."
SP:9f98c9bac99003741dd14e093b54d692c0b0e8d8,"This paper proposes to use Holographic Reduced Representation ( HRR ) to learn disentangled representations for word - level and chunk - level representations in natural language processing. The proposed method is based on the VSA framework. The authors show that by using HRR as a structured compositional representation, their models are able to discover crude linguistic roles, which roughly resembles a classic division between syntax and semantics."
SP:5908b6acfed0e7c51e203c72eba907e6635e6c60,This paper studies the problem of joint active perception and planning in partially observable Markov decision processes ( POMDPs ). The authors propose a greedy strategy for observation selection that aims to minimize the uncertainty in state. They develop a novel point - based value iteration algorithm that incorporates the greedy strategy to achieve near - optimal uncertainty reduction for sampled belief points. This in turn enables the solver to efficiently approximate the reachable subspace of belief simplex by essentially separating computations related to perception from planning. The paper provides a theoretical analysis for the greedy algorithm that led to boundedness of value function difference between optimal entropy reduction and its greedy counterpart. The proposed solver is evaluated on a variety of robotic navigation scenarios.
SP:0adec4abec17b3aab0c6eb69d11925dc20544950,"This paper proposes a new curriculum learning method to improve the performance of deep neural networks. The main idea is to train the network on hard examples, where the weights of the top layers change over the course of training. The authors propose a curriculum loss that consists of two parts : a ) an adaptive weight that mitigates large early loss to avoid fluctuation and b ) an additional representation loss to enhance the training of low - weighted samples. The proposed curriculum loss is easy to combine with existing stochastic algorithms like SGD. Experimental results show the effectiveness of the proposed method on several benchmark datasets."
SP:8b555b9f24044bc68c204169d6a37e262361d706,"This paper presents a method to learn heuristics for combinatorial optimization problems. The authors propose a model based on attention layers with benefits over the Pointer Network and show how to train this model using REINFORCE with a simple baseline based on a deterministic greedy rollout, which they find is more efficient than using a value function. With the same hyperparameters, they learn strong heuristic for two variants of the Vehicle Routing Problem ( VRP ), the Orienteering Problem ( OP ) and ( stochastic variant of ) the Prize Collecting TSP ( PCTSP ), outperforming a wide range of baselines and getting close to highly optimized and specialized algorithms."
SP:efb76bcf1dbd9a9cf6b5db74b5d4256a9f9e9e73,"This paper proposes a differentiable neural architecture search ( DNAS ) framework to search for layer - wise quantization assignments for ResNet models on CIFAR-10 and ImageNet. The proposed method is based on the idea of supernet, where the number of layers, filter size, and filter size of each layer is the same as the target network. Each layer of the supernet contains several parallel edges representing convolution operators with quantized weights and activations with different precisions. The DNAS pipeline is very fast, taking less than 5 hours on 8 V100 GPUs to complete a search on ResNet18 for ImageNet, while previous NAS algorithms ( such as Zoph & Le ) typically take a few hundred GPUs for several days."
SP:ea4173f8265bc50296de51c4ee7ecb6b8f78bec0,This paper proposes a new attention model for sequence prediction. The main idea is to factorize the joint distribution of the attention and output variables into a posterior distribution conditioned on the output. The posterior distribution is then propagated to the next decoding stage. The authors show that the entropy of the posterior attention is much lower than that of soft attention. This is a significant finding that challenges the current practice of computing attention distribution without considering the output token. The running time overhead of posterior attention model is only 40 % over existing soft - attention.
SP:987e2c14abc091d4d3ef9b48fb2046408eb1f59e,"This paper proposes a new method for image - to - image translation by introducing a smoothness term over the sample graph to attain harmonic functions to enforce consistent mappings during the translation. The main idea is to learn bi - directional translations between the source and the target domains with the help of similarity - consistency, the inherent self - consistent property of samples can be maintained. The authors show that this method results in significantly improved consistency for transformations. With experiments on multiple translation tasks, the authors demonstrate that HarmonicGAN outperforms the state - of - the - art methods."
SP:885a69003bad0e79cb2872a4e5c772191ad7e34f,"This paper proposes a stochastic algorithm ( h - detach ) to address the exploding and vanishing gradient problem ( EVGP ) in recurrent neural networks. Specifically, the authors show that when the LSTM weights are large, the gradient components through the linear path ( cell state ) in the computational graph get suppressed. Based on the hypothesis that these components carry information about long - term dependencies, their suppression can prevent LSTMs from capturing them. To address this problem, h - Detach prevents gradients flowing through this path from getting suppressed, thus allowing the L STM to capture such dependencies better. The authors show significant improvements over vanilla gradient based training in terms of convergence speed, robustness to seed and learning rate, and generalization on various benchmark datasets."
SP:9aaff3777321347d1194884af5690b0b5185eff9,"This paper proposes SnapQuant, a probabilistic method for training binary weight neural networks from scratch under the Bayesian deep learning perspective. The posterior distribution is parameterized as a policy network trained with a reinforcement learning scheme. The policy network has a nested parameter structure consisting of layer - wise, filter - wise and kernel - wise parameter sharing designs, which is applicable to any neural network architecture. The performance of SnapQuant is evaluated with several visual recognition tasks including ImageNet."
SP:29d1f6d0661a51e56c59bbb106da56700fc22d9a,"This paper proposes a Bayesian nonparametric framework for federated learning with neural networks. The authors use the Beta - Bernoulli process to model the weights of the local neural network weights, which are then used to synthesize a more expressive global network without additional supervision or data pooling. They demonstrate the efficacy of their approach on two image classification problems simulated from two popular image classification datasets. They thoroughly vet the proposed models and demonstrate the utility of the proposed approach."
SP:ab1f2bd216635d63450688866c729a501bd7e9d0,"This paper proposes a new algorithm, SOS, for learning in differentiable games. The main idea is to interpolate between LOLA and a stable variant of LOLA, LookAhead. Theoretically, the authors show that the proposed algorithm has stronger convergence guarantees than LOLA. The authors also show that SOS plays on par with LOLA in the IPD, while all other methods mostly defect."
SP:bdafb5fca09a775a8c92d2826d5dc977d28091c2,"The paper proposes a VAE - based alarm system for segmentation algorithms that predicts the qualities of the segmentation results without using ground truth. The paper claims that the shape feature of a segmentation result is captured using the value of loss function when the segmentations result is tested using a Variational Auto - Encoder ( VAE ). The VAE is trained using only the ground truth masks, therefore the bad segmentations results with bad shapes become the rare events for VAE and will result in large loss value. By utilizing this fact, the paper is able to detect all kinds of shapes that are out of the distribution of normal shapes in ground truth ( GT ). Finally, we learn the representation in the one - dimensional feature space to predict the quality of segmentation representation. The proposed method outperforms the uncertainty based methods and direct regression method, and possesses better transferability to other datasets."
SP:60738395d9efe2b3fe3a00c542ebb4261e54386c,"This paper proposes an untrained simple image model, called the deep decoder, which is a deep neural network that can generate natural images from very few weight parameters. The proposed model is simple in the sense that each layer has an identical structure that consists of only one upsampling unit, pixel - wise linear combination of channels, ReLU activation, and channelwise normalization. This simplicity makes the network amenable to theoretical analysis, and it sheds light on the aspects of neural networks that enable them to form effective signal representations. The paper shows the performance of the proposed model on a number of inverse problems such as denoising."
SP:1c9bad3bd4d670172f65aa0304e9837ecafc6b3d,"This paper presents an end - to - end neural network architecture for program synthesis from natural language. The proposed method is based on a pretrained word embedding and a bi - directional multi - layer LSTM for processing of word sequences. The decoder features a doubly - recurrent LSTMs, for which the authors propose novel signal propagation schemes and soft attention mechanism. Experiments show that the proposed method performs on par with or better than the method proposed in a previous study, producing correct programs in over 92 % of cases."
SP:d2ec231bb6153a303e5110e671dea14c2721e636,"This paper presents a novel adversarial robustness defense against adversarial perturbations on the MNIST dataset. The authors show that even the widely recognized and by far most successful L∞ defense by Madry et al. has lower L0 robustness than undefended networks and is still highly susceptible to L2 perturbation. They also show that the most adversarial examples are strongly perturbed towards the perceptual boundary between the original and the adversarial class. They then present a novel robust classification model that performs analysis by synthesis using learned class - conditional data distributions. They derive bounds on the robustness and go to great length to empirically evaluate our model using maximally effective adversarial attacks by ( a ) applying decision - based, score - based, gradient - based and transfer - based attacks for several different Lp norms, ( b ) by designing a new attack that exploits the structure of our defended model and ( c ) by devising a novel decision-based attack that seeks to minimize the number of perturbed pixels ( L0 )."
SP:91a24e7f4b952c37441feab4a7e8555014c856a4,"This paper proposes a reparameterization approach for weight matrices of the discriminator in GANs, which allows us to directly manipulate the spectra of the weights matrices through various regularizers and constraints without intensively computing singular value decompositions. Theoretically, the authors show that the spectrum control improves the generalization ability of GAN. The experiments on CIFAR-10, STL-10 and ImgaeNet datasets confirm that compared to other methods, the proposed method is capable of generating images with competitive quality by utilizing spectral normalization and encouraging the slow singular value decay."
SP:8115fd9b681198d62100c36794926fb57dc0a4f5,"This paper proposes Anderson accelerated value iteration ( A2VI ), a reinforcement learning algorithm that uses Anderson acceleration technique to speed up value iteration. The proposed method is based on Anderson value iteration, which is an approximation of the policy evaluation by interpolating on historical data. The paper provides a theoretical analysis of the convergence of the proposed method and conduct experiments on both toy problems and Atari games to show the effectiveness of the method."
SP:bd79b0c0af778a36008a0c0cf2fb6393fd2789d4,"This paper proposes a novel method, SupportNet, to efficiently and effectively solve the catastrophic forgetting problem in the class incremental learning scenario. SupportNet combines the strength of deep learning and support vector machine ( SVM ), where SVM is used to identify the support data from the old data, which are fed to the deep learning model together with the new data for further training so that the model can review the essential information of the old information when learning the new information. Two powerful consolidation regularizers are applied to stabilize the learned representation and ensure the robustness of the learned model. The experimental results show that SupportNet drastically outperforms the state - of - the - art incremental learning methods and even reaches similar performance as the deep - learning model trained from scratch on both old and new data."
SP:d228d213f79716774043cea253305fecece659ec,"This paper presents a comprehensive study of unit selectivity measures in recurrent neural networks ( RNNs ). The authors compare the localist, precision, top - class, and activation maximization ( AM ) measures on AlexNet. They find that the precision and CCMAS measures provide a much higher level of selectivity than is warranted, with the most selective hidden units only responding strongly to a small minority of images from within a category. They also generate AM images that maximally activate individual units and found that under ( 5 % ) of units in fc6 and conv5 produced interpretable images of objects, whereas fc8 produced over 50 % images. These findings highlight the problem with current measures and show that new measures are required in order to provide a better assessment of learned representations in NNs."
SP:b9deae0392e0160b400d76c549d382e235196f8c,"This paper proposes a novel family of Graph Neural Networks ( GNNs ) for solving community detection problems in a supervised learning setting. In particular, the authors propose to augment GNN with the non - backtracking operator defined on the line graph of edge adjacency matrices. The authors show that, in a data - driven manner and without access to the underlying generative models, they can match or even surpass the performance of the belief propagation algorithm on binary and multiclass stochastic block models, which is believed to reach the computational threshold in these cases. In addition, they perform the first analysis of the optimization landscape of using ( linear ) GNNS to solve community detection problem, demonstrating that under certain simplifications and assumptions, the loss value at any local minimum is close to the global minimum."
SP:a9ed31090e55f6152fc31c7512af5d634cc7225a,"This paper proposes a new online dictionary learning algorithm, called NOODL, which recovers both the dictionary and coefficients exactly at a geometric rate, when initialized appropriately. The main idea is to use an IHT - based update step to recover the coefficients via gradient descent - based strategy. Theoretically, the authors show that the proposed algorithm has linear convergence to the true factors, i.e., it recovers the dictionary by choosing an appropriate gradient descent-based strategy, and recovers the coefficients by using an iterative hard thresholding ( IHT)-based update step. The proposed algorithm is also scalable and amenable for large scale distributed implementations in neural architectures, by which they mean that it only involves simple linear and non - linear operations."
SP:85232b72a2643d6dc81cf952ccbb95192032b7c5,"This paper proposes a new loss function and training scheme for learning binary hash codes with any differentiable model and similarity function. The proposed loss function improves over prior methods by using log likelihood loss on top of an accurate approximation for the probability that two inputs fall within a Hamming distance target. The novel training scheme obtains a good estimate of the true gradient by better sampling inputs and evaluating loss terms between all pairs of inputs in each minibatch. To fully leverage the resulting hash codes, the authors use multi - indexing. The authors demonstrate that these techniques provide large improvements to a similarity search tasks."
SP:3bd4ccff7f48380d2db8dff2c4ca515894a7f1db,This paper proposes a novel architecture search method based on the Graph HyperNetwork ( GHN ). The main idea is to use a graph neural network ( GNN ) to model the topology of an architecture and use it as a surrogate search signal to find the best neural network for a given task. The proposed method is evaluated on CIFAR-10 and ImageNet and compared to other random search methods. The results show that the proposed method outperforms the existing manually designed state - of - the - art models. The method is also applied to the anytime prediction setting.
SP:65ccf43cd4e033d22239069057f5200d49f33724,This paper proposes a method to improve GAIL by using non - expert demonstrations as an extra class in discriminator learning. The method is built upon the generative adversarial training procedure where we perform multiclass classification to learn discriminator functions. The proposed method can also be extended to use trajectories collected by the agent ’s previous policies. Experiments on benchmark continuous control tasks show that the proposed method performs better than GAIL especially when only a small number of expert demonstrations is available.
SP:e8427949a98effbd37ce7604fa11f240e2342196,"This paper proposes a new neural network architecture, called Invertible Neural Networks ( INNs ), for the problem of estimating the posterior of the inverse process. The INNs are based on the idea that the posterior distribution of the forward process is invertible due to the invertibility of the latent variables. The authors show that the INNs can be used to learn the posterior over parameter space, which is then used to perform point estimates for the inverse problem. Theoretically, the authors prove that INNs provide a powerful analysis tool to find multi - modalities in parameter space and uncover parameter correlations, and identify unrecoverable parameters. Experiments on synthetic data and real - world problems from medicine and astrophysics demonstrate the effectiveness of the proposed INNs."
SP:75c9bb53bac29bdb390f9ba5707caee4ab1f5925,"This paper proposes a new approach to quantifying the uncertainty of neural networks. The approach is based on the idea of mixture density networks ( MDNs ), which is a finite mixture model with uniform mixing weights. The authors propose to replace the fixed mixing weights by an adaptive, input - dependent distribution ( Specifying the probability of each component ) represented by an NN, and by considering uncountably many mixture components. The resulting model can be seen as the continuous counterpart to mixture density network and is therefore referred to as compound density networks. Experiments show that the proposed model results in better uncertainty estimates and is more robust to adversarial examples."
SP:e1e38289285c1b8fdb318e4f6d37a198a08787a2,"This paper proposes a method to compress the weights of a neural network by using a variational distribution over weights. The main idea is to use the Kullback - Leibler divergence between the sampled variational family and the encoding distribution to control the compression rate while optimizing the expected loss on the training set. The proposed method is backed by solid information - theoretic insights, yet it is simple to implement. The experimental results show that the presented coding algorithm MIRACLE outperforms previous state - of - the - art."
SP:ad70d8cf3a4558aab0d3b7155594464a3debd912,"This paper proposes ProxylessNAS that can directly learn the architectures for large - scale target tasks and target hardware platforms. It addresses the high memory consumption issue of differentiable NAS and reduce the computational cost ( GPU hours and GPU memory ) to the same level of regular training while still allowing a large candidate set. Experiments on CIFAR-10 and ImageNet demonstrate the effectiveness of directness and specialization. On Cifar-10, the model achieves 2.08 % test error with only 5.7 M parameters, better than the previous state - of - the - art architecture AmoebaNet - B, while using 6x fewer parameters. On ImageNet, the proposed method achieves 3.1 % better top - 1 accuracy than MobileNetV2, while being 1.2x faster with measured GPU latency."
SP:e5b70d43d301d1980fae02623ea711976b429c14,"This paper proposes to use second - order penalties to improve the performance of stochastic gradient descent - based fairness learning algorithms. The authors argue that the use of second order penalties allows training the penalized objective with a fixed value of the penalty coefficient, thus avoiding the instability and potential lack of convergence associated with two - player min - max games. In addition, the authors derive a method for efficiently computing the gradients associated with the second order penalty in stochastically mini - batch settings. The resulting algorithm performs well empirically, learning an appropriately fair classifier on a number of standard benchmarks."
SP:e4720b8e4efdb222c45eafd47fd8a7fbf15d881d,"This paper revisits the reweighted wake - sleep ( RWS ) algorithm for learning discrete latent - variable models. The authors show that RWS outperforms current state - of - the - art methods in learning discrete models. They also show that, unlike the importance weighted autoencoder, RWS learns better models and inference networks with increasing numbers of particles, and that its benefits extend to continuous latent variable models as well."
SP:7459ae5b1d886e68930c4c9e21df508bc8ab3c9a,"This paper proposes to use truncated randomized search in the reward function to train structured prediction energy networks ( SPENs ), which provide efficient test - time inference using gradient - based search on a smooth, learned representation of the score landscape. The key ingredient of the training algorithm is sampling from reward function through randomized search, which is used to generate informative optimization constraints to guide gradient - descent inference toward finding better prediction according to reward function. The authors show that this search - guided approach has successfully performed lightly - supervised training of SPENS with reward functions and improved accuracy over previous state - of - the - art baselines."
SP:638c1bc09992029b78bd83f0127594dcccb96c06,"This paper proposes an active learning - based framework for robust policy search. The key idea is to select a subset of trajectories from a large batch to select the ones that result in the worst performance. The authors apply this framework to an existing method, namely EPOpt, and experimentally validate the gains in sample efficiency and the performance of our approach on standard continuous control tasks. They also present a Multi - task Learning perspective to the problem of Robust Policy Search, and draw connections from our proposed framework to existing work on Multi - Task Learning."
SP:491c239713a6489f0b1790ca26db54a1813c67ae,"This paper proposes a two - timescale network ( TTN ) architecture that enables linear methods to be used to learn values, with a nonlinear representation learned at a slower timescale. The approach facilitates the use of algorithms developed for the linear setting, such as data - efficient least - squares methods, eligibility traces and the myriad of recently developed linear policy evaluation algorithms, to provide nonlinear value estimates. The authors prove convergence for TTNs, with particular care given to ensure convergence of the fast linear component under potentially dependent features provided by the learned representation. They empirically demonstrate the benefits of TTNs compared to other non - linear value function approximation algorithms."
SP:327d606cf3813b00a009a7785e08ef9e11f89493,"This paper proposes a hybrid model - based and model - free approach, LEArning and Planning with Semantics ( LEAPS ), to improve generalization of RL agents in unseen environments with diverse room layouts and object arrangements. The underlying semantic information is shared with the environments in which the agent is trained on. The semantic model in LEAPS is lightweight, interpretable and can be updated dynamically with little explorations. As illustrated in the House3D environment, LEAPS works well for environments with semantic consistencies – typical of realistic domains. On random environments, e.g., random mazes, the LEAPS degenerates to exhaustive search."
SP:d7c26f43bc68d160095b1f50447528843d79edbd,"This paper proposes a new end - to - end driving model which is composed of a perception module for see and think and a driving module for behave. The perception module is used for learning easier driving - related perception knowledge, which is able of pixel level understanding of input including what & where and how far knowledge. The driving module is trained with segmentation map and depth map first, while the former serves as what and where knowledge and the latter serves as how far. The results of experiments demonstrated the effectiveness of multitask perception knowledge for better generalization and accident explanation ability."
SP:b6bd98cc70fab97e1245cbb63a42ef89ab7e7ed5,"In this paper, the authors show that there exists an inherent tension between the goal of adversarial robustness and that of standard generalization. Specifically, training robust models may not only be more resource - consuming, but also lead to a reduction of standard accuracy. They demonstrate that this trade - off between the standard accuracy of a model and its robustness to adversarial perturbations provably exists even in a fairly simple and natural setting. These findings also corroborate a similar phenomenon observed in practice. Further, they argue that this phenomenon is a consequence of robust classifiers learning fundamentally different feature representations than standard classifiers. These differences, in particular, seem to result in unexpected benefits : the features learned by robust models tend to align better with salient data characteristics and human perception. In particular, adversarially robust learning tends to equip the resulting models with invariances that we would expect to be also present in human vision, and could pave the way towards building models that are easier to understand."
SP:9c9275d75cd95b1b82e0cbb1421e3d3ade1ce33a,This paper proposes a method for gradient - based training of neural networks that does not rely on back - propagation. The proposed method is based on the Equilibrium Propagation ( EPR ) method proposed by Scellier & Bengio ( 2017 ). The main idea is to train a feedforward network to initialize the iterative inference procedure for Equilibrium propagation. This network is trained to approximate the state of the fixed - point using a local learning rule. The experiments show that this network appears to work as well or better than the original version of EPR while requiring fewer steps to converge.
SP:ac9ea91eb465517de495477cf67bc94d5ed1b0cb,"This paper proposes a new zeroth - order ( ZO ) stochastic optimization algorithm, ZO - signSGD, which has the advantage of gradient - free operations and sign SGD. The main idea is to use the sign information of the gradient estimates to approximate the full gradient. The authors show that the proposed algorithm has a convergence rate of O(d/\sqrt{T } ) under some mild conditions, where d is the number of optimization variables and T is number of iterations. In addition, the authors analyze the effects of different types of gradient estimators on the convergence of the algorithm and propose several variants of ZO-signSGD. In the application side, the paper investigates the connection between the proposed method and black - box adversarial attacks in robust deep learning."
SP:5f79b11777f6ef1d70c85418bfc2e4616dd7d960,"This paper proposes a dynamic optimization method to reduce the computation efforts of convolutional neural networks. The method takes advantage of the fact that some convolution operations are actually wasteful since their outputs are pruned by the following activation or pooling layers. The authors propose to set a checkpoint in the MAC process to determine whether a filter could terminate early based on the intermediate result. Furthermore, a fine - tuning process is conducted to recover the accuracy drop due to the applied checkpoints. The experimental results show that the proposed method can save approximately 50 % MAC operations with less than 1 % accuracy drop for CIFAR-10 example model and Network in Network on the Cifar-10 and CifAR-100 datasets. The proposed method could promisingly make more AI applications run on edge devices."
SP:7801e9c854ad7d960c0d24fda15597af6994c23f,"This paper proposes to use temporal dependency property in audio data to characterize audio adversarial examples to improve the robustness of ASR systems against adversarial attacks. The authors propose to use a genetic algorithm to generate the adversarial example. The proposed method is compatible with any ASR model and does not require adversarial training or data augmentation. The experimental results show that while four primitive input transformations on audio fail to withstand adaptive attacks, temporal dependency is shown to be resistant to these attacks.   The authors also demonstrate the power of temporal dependency for characterizing adversarial audio generated by three state - of - the - art attacks."
SP:51830b811a8e39b4f0a5b7609df719e026fac6a1,"This paper proposes a new generative model for image generation based on the compositional way in which humans structure a visual scene in terms of objects. The key idea is to learn to generate images by means of compositionality, where each image is composed of individual objects and background. The authors show that the generator learns to identify and disentangle information corresponding to different objects at a representational level. A human study reveals that the resulting GAN is better at generating images that are more faithful to the reference distribution."
SP:fb59990b8da0e95d8202383478a456667de60449,"This paper proposes a VAE - based variational autoencoder to learn disentangled representations from unlabeled images. The main idea is to learn a representation where a set of target factors are disentanglement from others. The only supervision comes from an auxiliary “ reference set ” that contains images where the factors of interest are constant. The proposed VAE is trained using the variational inference framework where adversarial learning is used to minimize the objective function. The experimental results show that the proposed model is able to naturally address different tasks such as feature learning, conditional image generation, and attribute transfer."
SP:dbc1983d9b9d72aa14f8e8515d793d2bbde26c9c,"This paper proposes a meta - learning for online learning ( MOLe ) algorithm that uses expectation maximization, in conjunction with a Chinese restaurant process prior on the task distribution, to learn mixtures of neural network models that are each updated with online SGD. In contrast to prior multi - task and meta learning methods, this method ’s online assignment of soft task probabilities allows for task specialization to emerge naturally, without requiring task delineations to be specified in advance. The experiments show that MOLe outperforms alternative prior methods, and enables effective continuous adaptation in non - stationary task distributions such as varying terrains, motor failures, and unexpected disturbances."
SP:5665e5f006f84927beb0440e145f476e02538077,"This paper investigates the effect of experience replay on parameter lag and recurrent state staleness in RNN - based RL agents. The authors demonstrate that experience replay can lead to representational drift and recurrent states staleness, which is potentially exacerbated in the distributed training setting. They also perform an empirical study into the effects of several approaches to RNN training with experience replay, mitigating the aforementioned effects. Finally, they present an agent that integrates these findings to achieve significant advances in the state of the art on Atari - 57 ( Bellemare et al., 2013 ) and matches the state - of - the - art on DMLab - 30 ( Beattie et al, 2016 )."
SP:47ace37f31a46d5ee85c283e62ddb71a12f2c5c4,"This paper proposes a hierarchical generative model for modeling multi - agent trajectories in the context of offensive basketball gameplay. The proposed model is based on the weak - label method, which can be used to model spatiotemporal interactions between players. The authors show that the proposed model can be applied to both synthetic and real - world settings, where it is shown to be able to generate realistic trajectories of basketball gameplay over long time periods. In addition to synthetic settings, the authors also demonstrate the effectiveness of their approach in an application on modeling team offense in basketball."
SP:1a90cdf028068528b0559e7d44bf26dda20310bd,"This paper presents a method that learns to integrate temporal information, from a learned dynamics model, with ambiguous visual information, with a learned vision model, in the context of interacting agents. The method is based on a graph - structured variational recurrent neural network ( Graph - VRNN ), which is trained end - to - end to infer the current state of the ( partially observed ) world, as well as to forecast future states. They show that their method outperforms various baselines on two sports datasets, one based on real basketball trajectories, and one generated by a soccer game engine."
SP:8392f04b7265f665ba6d44d297bca245d44b4708,"This paper proposes a method for end - to - end training of a base neural network that integrates calls to existing black - box functions by approximating them with a differentiable neural network in a way that drives the base network to comply with the function interface during the optimization process. At inference time, it replaces the differentiable estimator with its external black - boxes non - differentiable counterpart such that it matches the input arguments of the black box function. Experiments show that the integrated model generalizes better than a fully differentiable model and learns more efficiently compared to RL - based methods."
SP:13fb86de763a0b34ac6fa34ea9dfbd1c476ce43e,"This paper proposes a method for meta - learning that uses a mixture of hierarchical Bayesian models over the parameters of an arbitrary function approximator such as a neural network. The method is based on the model - agnostic metalearning ( MAML ) algorithm ( Finn et al., 2017 ). The authors propose a stochastic expectation maximization procedure to jointly estimate parameter initializations for gradient descent as well as a latent assignment of tasks to initializations. This approach better captures the diversity of training tasks as opposed to consolidating inductive biases into a single set of hyperparameters. The experiments demonstrate better generalization performance on the standard miniImageNet benchmark for 1 - shot classification."
SP:a410144dbe19713a06c63da87d9fb58b999a7492,"This paper proposes a new auxiliary learning method, called Meta Auxiliary Learning ( MAXL ), for the task of image classification, where the auxiliary task is hierarchical sub - class image classification. The auxiliary task consists of two parts : ( 1 ) a meta - learner, which learns auxiliary tasks to train a multi - task evaluator to improve the generalization performance on the principal task, and ( 2 ) an auxiliary task, which is learned in an unsupervised manner. The proposed method is evaluated on three different CIFAR datasets, where it outperforms baseline auxiliary learning methods, and is competitive even with a method which uses human - defined sub class hierarchies."
SP:76248e1c914c60ce69de244fe7ec62488d01e161,This paper proposes a neural network - based approach for open set recognition. The main idea is to use a loss function that allows to use the same distance function both when training and when computing an outlier score. The proposed approach is evaluated on three datasets of malware samples and images. The results show that the proposed approach achieves statistically significant improvement compared to other approaches.
SP:d4ee856bbf2dfb6390e5247086fec2e52dcb6858,"This paper proposes a method to find low - precision networks that are close to the full - precision baseline networks. The authors first show that the accuracy of the low precision networks is close to that of the fp32 baseline networks after one epoch of fine - tuning. Then, the authors find that gradient noise due to quantization during training during training increases with reduced precision, and seek ways to overcome this noise. The number of iterations required by stochastic gradient descent to achieve a given training error is related to the square of ( a ) the distance of the initial solution from the final plus ( b ) the maximum variance of the gradient estimates. By drawing inspiration from this observation, they (a ) reduce solution distance by starting with pretrained fp 32 baseline networks and fine - tuned by using larger batches along with matched learning rate annealing to combat noise introduced by quantizing weights and activations during training."
SP:6bfdc37b346e6ddfa049e0414647f4beda8ede3f,"This paper proposes a method to model surface properties governing bounces in everyday scenes. The model learns end - to - end, starting from sensor inputs, to predict post - bounce trajectories and infer two underlying physical properties that govern bouncing restitution and effective collision normals. The proposed model, Bounce and Learn, comprises two modules – a Physics Inference Module ( PIM ) and a Visual Inference module ( VIM ). VIM learns to infer physical parameters for locations in a scene given a single still image, while PIM learns the physical interactions for the prediction task given physical parameters and observed pre - collision 3D trajectories. To achieve the results, the authors introduce the Bounce Dataset comprising 5K RGB - D videos of bouncing trajectories of a foam ball to probe surfaces of varying shapes and materials. Their proposed model learns from our collected dataset of real - world bounces and is bootstrapped with additional information from simple physics simulations."
SP:010bd055310c363d3cb0fbe0e11546de58220e15,"This paper studies the relationship between adversarial vulnerability and the gradients of the training objective of a differentiable classifier. The authors show that the gradient norm of the differentiable loss is monotonic with the square root of the input dimension. They also show that CNNs and most feed - forward networks, by design, exhibit increasingly large gradients with input dimension d, almost independently of their architecture, leaving them increasingly vulnerable to adversarial noise. They corroborate their theoretical results by extensive experiments."
SP:5fa3ae057e55be6b71cc94a7dbfe31e54e1c536f,"This paper proposes an interactive agent modeling scheme by encouraging an agent to learn to probe. The probing agent learns to interact with the environment and with a target agent ( i.e., a demonstrator ) to maximize the change in the observed behaviors of that agent. Through probing, rich behaviors can be observed and are used for enhancing the agent modeling to learn a more accurate mind model of the target agent. The framework consists of two learning processes : i ) imitation learning for an approximated agent model and ii ) pure curiosity - driven reinforcement learning for a probing policy to discover new behaviors that otherwise can not be observed. The experimental results suggest that the agent model learned by the probing agent generalizes better in novel scenarios than the ones learned by passive observation, random probing, and other curiositydriven approaches do, and can be used to enhance performance in multiple applications including distilling optimal planning to a policy net, collaboration, and competition."
SP:3af184a5529d6ec2a0862efd1af80ef5b50d2952,"This paper proposes a modification to the neural network architecture that is inspired by biological neuromodulators. Specifically, the authors introduce a new type of ANN nodes, which they call modulators, that can adjust their activation sensitivity in run - time based on the input patterns. This modification allows the activation function to be context dependent. The authors show that this modification produces statistically significant improvements in comparison with traditional ANN nodes in the context of Convolutional Neural Networks and LSTM networks."
SP:287a577834fd2820a939a1113b39146a22727491,"This paper presents a neural analysis and synthesis ( NANSY ) framework that can manipulate voice, pitch, and speed of an arbitrary speech signal. The authors propose a novel training strategy based on information perturbation. The idea is to perturb information in the original input signal ( e.g., formant, pitch, and frequency response ), thereby letting synthesis networks selectively take essential attributes to reconstruct the input signal. Because NANSy does not need any bottleneck structures, it enjoys both high reconstruction quality and controllability. Furthermore, it does not require any labels associated with speech data such as text and speaker information, but rather uses a new set of analysis features, i.e., wav2vec feature and newly proposed pitch feature, Yingram, which allows for fully self - supervised training. Experiments show that the proposed method can achieve significant improvement in performance in several applications such as voice conversion, pitch shift, and time - scale modification."
SP:90f35ad1ec0c38b0817f5678ee2a5c4f0e08fb38,"This paper studies the generalization properties of gradient - based bilevel programming algorithms in hyperparameter optimization. In particular, the paper provides an expectation bound for the unrolled differentiation algorithm based on a notion of uniform stability on validation. The paper also provides a bound on the performance of the classical cross - validation algorithm. Theoretical results suggest that the gradient based algorithms can be better than cross - validation under certain conditions. In experiments on feature learning and data reweighting for noisy labels, the authors corroborate the theoretical findings."
SP:42f52aec3a776d87daa5fd72b8e6325d12c88d63,"This paper proposes a novel knowledge distillation approach to facilitate the transfer of dark knowledge from a teacher to a student. The main idea is to learn the teacher models that are friendly to students and, consequently, more appropriate for knowledge transfer. In other words, at the time of optimizing a teacher model, the proposed algorithm learns the student branches jointly to obtain student - friendly representations. Since the main goal of the approach lies in training teacher models and the subsequent knowledge distillations procedure is straightforward, most of the existing methods can adopt this technique to improve the performance of diverse student models in terms of accuracy and convergence speed. The experimental results with in - depth analyses are presented in Section 4, and the conclusion in Section 5."
SP:e15a1c21229233fd97dc1dfa0a4ef48b69dc9f95,"This paper proposes a theoretical framework to characterize the learnability of out - of - distribution ( OOD ) generalization problems. The authors introduce a new concept of expansion function, which characterizes to what extent the variance is amplified in the test domains over the training domains, and therefore give a quantitative meaning of invariant features. Based on these, the authors prove OOD generalization error bounds and design a model selection criterion to check the model ’s variation and validation accuracy simultaneously. Extensive experiments on benchmark OOD datasets demonstrate that the proposed method has a significant advantage over baselines."
SP:37b04b9068d39bcf0a581eb8181d13cf1a8926bf,"This paper proposes a Variational Continual Bayesian Meta - learning ( VC - BML ) algorithm for online streaming tasks that follow a non - stationary distribution. The authors propose a Dynamic Gaussian Mixture Model ( GMMM ) for meta - parameters and task - specific parameters, which is based on the Chinese Restaurant Process ( CRP ). To approximate the intractable posterior of interest, the authors develop a structural variational inference method. Experiments on tasks from non - stationary distributions show that the proposed algorithm is superior in transferring knowledge among diverse tasks and alleviating catastrophic forgetting in an online setting."
SP:776d5b02b8d3a8bbcc1f52706f3887c384cb149e,"This paper proposes a probabilistic solver for the problem of boundary value problems ( BVPs ), which are ordinary differential equations subject to boundary conditions. The authors propose a Gauss - Markov prior for the solution of the problem, which allows computing a posterior distribution over the solution in linear time, at a quality and cost comparable to that of well established, non - Probabilistic methods. They also introduce uncertainty quantification, mesh refinement, and hyperparameter adaptation to improve the efficiency of the scheme. They demonstrate how these practical considerations positively impact the efficiency."
SP:86aac0c6b75fdc12f84bba342934865616f866d4,"This paper studies the problem of learning a near optimal policy in a reward mixing Markov decision process ( RM - MDP ), where the reward function is drawn from one of multiple possible reward models at the beginning of every episode, but the identity of the chosen reward model is not revealed to the agent. The authors provide the first polynomial - time algorithm that finds an -optimal policy after exploring $ \mathcal{O}(\poly(H, S, A)$ episodes, where $ H$ is the time horizon and $ S$ and $ A$ are the number of states and actions. This is the first efficient algorithm that does not require any assumptions in partially observed environments where the observation space is smaller than the latent state space.   The authors make no assumptions and study the problem in full generality. The problem requires several new ideas beyond existing algorithmic and analysis techniques for efficient exploration."
SP:1a3c70ae9cf2a806d603f4b9e7ca6e10b720a956,This paper proposes a two - step procedure to estimate the multi - cause treatment effect. The main idea is to use single - cause CATE estimators to augment the observational data with the estimated potential outcomes. The proposed method is shown to be agnostic to the exact choice of algorithm in either step. The paper shows the performance gain of the proposed method on extensive synthetic and semi - synthetic experiments.
SP:247bc6675cce89d51558537daf63dadb0c4307f8,"This paper proposes a multi - wavelet - based neural operator learning scheme that compresses the associated operator ’s kernel using fine - grained wavelets. By explicitly embedding the inverse multiwavelet filters, the proposed method learns the projection of the kernel onto fixed multi wavelet polynomial bases. This allows learning the complex dependencies at various scales and results in a resolution - independent scheme. Compared with the existing neural operator approaches, the model shows significantly higher accuracy and achieves state - of - the - art in a range of datasets."
SP:1153785e6a016cfee2644952a772aa08927299b6,"This paper proposes to approximate the gradient of the sign function in the Fourier frequency domain using the combination of sine functions for training BNNs. The proposed approach does not affect the low - frequency information of the original sign function which occupies most of the overall energy, and high - frequency coefficients will be ignored to avoid the huge computational overhead. To further compensate the subtle approximation error, the authors explore a noise adaptation module in the training phase to refine the gradient. The experimental results on CIFAR-10 and ImageNet datasets using various network architectures demonstrate the effectiveness of the proposed method."
SP:33b95ea8da4d30b8e8f9d3fe3acca023d4b8d831,"This paper proposes to use multi - area RNNs with neuroscience - inspired architecture constraints to derive key features of multi - brain computation. Specifically, the authors show that incorporating multiple areas and Dale's law is critical for biasing the networks to learn biologically plausible solutions. The authors also show that output - relevant information is preferentially propagated between areas. These results suggest that cortex uses modular computation to generate minimal sufficient representations of task information. More broadly, this paper suggests that constrained multi - network RNN can produce experimentally testable hypotheses for computations that occur within and across multiple brain areas."
SP:db3ced65d67e3373fb3936ec50f41c8ef010bbbe,"This paper proposes a new visual representation, Structured Attention Graph ( SAG ), that shows multiple explanations of an image. The SAG is based on a beam search algorithm to systematically search for multiple explanations for each image. It is shown that there are multiple relatively localized explanations for many images. The authors conduct a user study comparing the use of SAGs to traditional saliency maps for answering counterfactual questions about image classifications. The results show that user accuracy is increased significantly when presented with SAG."
SP:f2b385bfd9ada0e26aa8829214b424f58582d9f7,"This paper studies how the choice of training objective affects the transferability of the hidden representations of convolutional neural networks trained on ImageNet. The authors show that many objectives lead to statistically significant improvements in ImageNet accuracy over vanilla softmax cross - entropy, but the resulting fixed feature extractors transfer substantially worse to downstream tasks. The choice of loss has little effect when networks are fully fine - tuned on the new tasks. Using centered kernel alignment to measure similarity between hidden representations, the authors find that differences among loss functions are apparent only in the last few layers of the network. They delve deeper into representations of the penultimate layer, finding that different objectives and hyperparameter combinations lead to dramatically different levels of class separation."
SP:b66b5e24f68563e2e200eda660f0dbaff53efeff,"This paper proposes a novel neural network training strategy, selective backpropagation through time ( SBTT ), which enables learning of deep generative models of latent dynamics from data in which the set of observed variables changes at each time step. The resulting models are able to infer activity for missing samples by combining observations with learned latent dynamics. The authors test SBTT applied to sequential autoencoders and demonstrate more efficient and higher - fidelity characterization of neural population dynamics in electrophysiological and calcium imaging data."
SP:3513a83806e71006b86d60b779d8bd6bb87c3546,"This paper proposes a hierarchical approach to sequence - to - sequence learning with quasi - synchronous grammars, where each node in target tree is transduced by a node in the source tree. Both the source and target trees are treated as latent and induced during training. The authors develop a neural parameterization of the grammar which enables parameter sharing over the combinatorial space of derivation rules without the need for manual feature engineering. They apply this latent neural grammar to various domains — a diagnostic language navigation task designed to test for compositional generalization ( SCAN ), style transfer, and small - scale machine translation — and find that it performs respectably compared to standard baselines."
SP:d06fc251f2a9287f7a2236a188349628d8f39d9a,This paper proposes a new algorithm to solve the Group Elastic Net problem. The main idea is to use the sparsity structure of the Augmented Lagrangian to reduce the computational cost of the SsNAL algorithm. The proposed method is then extended to the function - on - scalar regression framework. The authors show that the proposed method can achieve a significant speed - up compared to the existing methods. The method is applied to a GWAS study detecting a SNP that may affect obesity risk in children.
SP:e0b53f76f3a6b756fedd09926f9cf034f89f4a5a,"This paper proposes a method to cluster repeatedly observed marked point processes. The proposed method is based on a mixture model of multi - level marked point process to identify potential heterogeneity in the observed data. Specifically, the authors study a matrix whose entries are marked log - Gaussian Cox processes and cluster rows of such a matrix. An efficient semi - parametric Expectation - Solution ( ES ) algorithm combined with functional principal component analysis ( PCA ) of point processes is proposed for model estimation. The effectiveness of the proposed framework is demonstrated through simulation studies and real data analyses."
SP:3aa213076f3e9f9838ac654517df2fe1fca33499,"This paper presents an online meta - adaptive control approach for adaptive nonlinear control. The proposed approach is motivated by robot control, where a robotic system encounters a sequence of new environmental conditions that it must quickly adapt to. A key emphasis is to integrate online representation learning with established methods from control theory, in order to arrive at a unified framework that yields both control - theoretic and learning - theoretic guarantees. The authors provide instantiations of their approach under varying conditions, leading to the first non - asymptotic end - to - end convergence guarantee for multi - task non - linear control. Experiments show that OMAC significantly outperforms conventional adaptive control approaches."
SP:cb274c93a169b199ea09120ca02105a3f16b31c5,"This paper proposes a method for training neural networks with certifiable robustness. The proposed method is based on interval bound propagation ( IBP ) and CROWN - IBP. The main contributions of this paper are :   1. The authors identify two important issues in existing methods, namely exploded bounds at initialization, and the imbalance in ReLU activation states and improve IBP training. To mitigate these issues and conduct faster certified training with shorter warmup, the authors derive a new weight initialization method and propose to fully add Batch Normalization ( BN ) to each layer in the model. 2. They also design regularization to explicitly tighten certified bounds and balance ReLU activations states during wamrup. 3. They are able to obtain 65.03 % verified error on CIFAR-10 and 82.36 % on TinyImageNet using very short training schedules ( 160 and 80 total epochs )."
SP:18ffeb199a670fb2b1f4417b8653479001944dab,"This paper studies the problem of change point detection under the Huber - contamination model, which allows the contamination distributions to be different at each time point. The authors derive the minimax - rate optimal localisation error rate, quantifying the cost of accuracy in terms of the contamination proportion, and propose a computationally - efficient method, which matches the lower bound under certain conditions, saving for logarithmic factors. Extensive numerical experiments are conducted with comparisons to existing robust change point Detection methods."
SP:d03617b5fc446768809cf015c9234b0c9386a690,"This paper studies the power of learning via mini - batch stochastic gradient descent ( SGD ) and batch Gradient Descent ( GD ) on the empirical loss of a differentiable model or neural network. The authors show that SGD and GD can always simulate learning with statistical queries ( SQ ), but their ability to go beyond that depends on the precision ρ of the gradient calculations relative to the minibatch size b and sample size m. With fine enough precision, namely when bρ is small enough, SGD can go beyond SQ learning and simulate any sample - based learning algorithm and thus its learning power is equivalent to that of PAC learning. This extends prior work that achieved this result for b = 1 / \epsilon. On the other hand, with low precision ( high ρ, i.e. only a few bits of precision, which is frequently the case when training deep networks ), the mini -batch size b plays an important role, and simulating arbitrary sample based methods is provably not possible using fbGD, or with bSGD with a mini-batch size that is too large, namely b = ω(log(n)/ρ2 ). Overall, except for an intermediate regime between 1 / ω and log(n / ρ ), they can precisely capture the learning power of SGD. The paper also sheds light on how well the SQ framework captures empirical averages on the population loss."
SP:1de2864fe2f53e25596a9bd2c61e2048e79296f6,"This paper studies the problem of minimizing the Wasserstein distance between a discrete distribution and a model distribution. This problem is non - convex in the sense that the unknowns are the positions of the atoms. The authors propose a modified version of Lloyd's algorithm, where the Voronoi cells are replaced by Power cells. The main result of the paper is that the approximation of a measure ρ by barycenters of Power cells yields error estimates for one step of Lloyd ’s algorithm in deterministic and probabilistic settings. In Section 3, the authors establish a Polyak - Łojasiewicz - type inequality ( Corollary 6 ) for the function FN : Y 7→12W 2 2(ρ, \deltaY ) introduced in ( 3 ), and study the convergence of a gradient descent algorithm for FN ( Theorem 7 ). The paper also provides numerical results on optimal uniform quantization in dimension d = 2."
SP:c3d364aeee55230a436c3ce4e8dc8310ee73959e,"This paper proposes a relational self - attention ( RSA ) feature transform for video understanding. The proposed RSA feature transform leverages rich structures of spatio - temporal relations in videos by dynamically generating relational kernels and aggregating relational contexts. Experiments show that the proposed RSA network substantially outperforms convolution and self - Attention counterparts, achieving the state of the art on the standard motion - centric benchmarks."
SP:2c2530069d5cab485629090243da464d107feadd,"This paper studies the second - order fluctuation in multilayer neural networks. The authors derive a system of dynamical equations, called the second order mean field limit, that captures the limiting fluctuation distribution. They demonstrate through the framework the complex interaction among neurons in this second order limit, the stochasticity with cross - layer dependency and the nonlinear time evolution inherent in the fluctuation. They apply the result to show a stability property of gradient descent mean field training : in the large - width regime, along the training trajectory, it progressively biases towards a solution with minimal fluctuation, even after the network has been initialized at or converged ( sufficiently fast ) to a global optimum."
SP:a3d927854d9d7fd39b8d05a79666810d585d5062,"This paper proposes a novel parameterization of dissipative brackets from metriplectic dynamical systems appropriate for learning irreversible dynamics with unknown a priori model form. The process learns generalized Casimirs for energy and entropy guaranteed to be conserved and nondecreasing, respectively. The authors provide benchmarks for dissipative systems demonstrating learned dynamics are more robust and generalize better than either "" black - box "" or penalty - based approaches. In addition, the authors show that for the case of added thermal noise, they guarantee exact preservation of a fluctuation - dissipation theorem."
SP:32e8e83e06b1e9a4dad761334d5947c91bfd1853,"This paper proposes a sample selection - based algorithm for fair and robust training. The authors formulate a combinatorial optimization problem for the unbiased selection of samples in the presence of data corruption. Observing that solving this optimization problem is strongly NP - hard, the authors propose a greedy algorithm that is efficient and effective in practice. Experiments show that the algorithm obtains fairness and robustness that are better than or comparable to the state - of - the - art technique, both on synthetic and benchmark real datasets."
SP:991127729bf067fe27fdd7ed360aab39e4df5921,"This paper proposes periodic activation functions for Bayesian neural networks ( BNNs ). The authors show that the periodic activation function can establish a direct connection between the prior on the network weights and the spectral density of the GP of the limiting stationary Gaussian process ( GP ) of single hidden layer BNN. They also show that this correspondence goes beyond sinusoidal ( Fourier ) activations by also covering triangular wave and periodic ReLU activation functions. Finally, they show in a range of experiments that periodic activations obtain comparable performance for in - domain data, do not result in overconfident predictions, and enable robust out - of - domain detection."
SP:d61a2aecfea4612c473b4e6fd41f3dc2fcbb04a1,This paper proposes to use an autoregressive model to classify Markov Decision Processes ( MDPs ) in a student's interactive code assignment. The agent is given an MDP and the task is to decide if the dynamics and reward model of the input MDP should be classified as correct or broken. The authors design a cooperative objective between an agent and a model to sample differential trajectories that allows a classifier to determine membership. Their method enables an automatic feedback system for interactive code assignments for coding education.
SP:daf99ad91613d6e11b13315ccbd1bbe25094ae4b,"This paper proposes a method to interpret deep reinforcement learning ( DRL ) models based on high - level latent features derived from a disentangled representation. The authors propose a Represent And Mimic ( RAMi ) framework for training 1 ) an identifiable latent representation to capture the independent factors of variation for the objects and 2 ) a mimic tree that extracts the causal impact of the latent features on DRL action values. To jointly optimize both the fidelity and the simplicity of the mimic tree, the authors derive a novel Minimum Description Length ( MDL ) objective based on the Information Bottleneck ( IB ) principle. Based on this objective, they describe a Monte Carlo Regression Tree Search ( MCRTS ) algorithm that explores different splits to find the IB - optimal mimic tree. Experiments show that our mimic tree achieves strong approximation performance with significantly fewer nodes than baseline models."
SP:84560de78af979354fff83d1370d8675c1e9191f,"This paper proposes a Bayesian framework to model the structure of dynamic predictions over time. The authors use the Gaussian latent information martingale ( GLIM ) to model a collection of such probability paths, which they call Gaussian Latent Information Martingale, or GLIM. GLIM is based on the idea that predictions update according to a latent process of information flow, which is inferred from historical data. They show that GLIM can naturally incorporate covariates, is able to produce multi - step predictions without explicitly modeling changes in covariates over time, and preserves important properties of probability paths such as the martingales structure and amount of movements."
SP:0c4bfb44e0a353256692d5e5ae96f65c1a14363d,"This paper studies the problem of active pure exploration with fixed confidence in stochastic bandit environments. The goal of the learner is to answer a query about the environment with a given level of certainty while minimizing her sampling budget. The algorithm is computationally efficient as, to learn and track the optimal proportion of arm draws, it relies on a single iteration of Frank - Wolfe algorithm applied to the lower - bound optimization problem. The authors apply FWS to various pure exploration tasks, including best arm identification in unstructured, thresholded, linear, and Lipschitz bandits. Despite its simplicity, FWS is competitive compared to state - of - art algorithms."
SP:0947a0f08fba53d3c8af9b78dd64e6e10fc73e32,This paper proposes a sample - efficient Bayesian optimization ( BO ) approach for combinatorial spaces called LADDER. The key idea is a Gaussian process based surrogate model that combines the complementary strengths of latent space representation with rich information about decoded outputs using structured kernels. Experiments on real - world benchmarks show that the BO performance is better than state - of - the - art methods and significantly better than the Naïve latent space BO method.
SP:37adabdc6615c5199a481553c8ccc06d57363614,"This paper studies the role of the representation of state - action value functions in regret minimization in finite - horizon Markov Decision Processes ( MDPs ) with linear structure. The authors first derive a necessary condition on the representation, called universally spanning optimal features ( UNISOFT ), to achieve constant regret in any MDP with linear reward function. They then demonstrate that this condition is also sufficient for these classes of problems by deriving a constant regret bound for two optimistic algorithms ( LSVI - UCB and ELEANOR ). Finally, they propose an algorithm for representation selection and prove that it achieves constant regret when one of the given representations, or a suitable combination of them, satisfies the UN ISOFT condition."
SP:92566b664ab2f6ee9b73f29327aeef85d14ecf60,"This paper proposes a differentiable contact model that can capture contact mechanics : frictionless /frictional, as well as elastic /inelastic. This model can also accommodate inequality constraints, such as limits on the joint angles. The proposed contact model extends the scope of Lagrangian and Hamiltonian neural networks by allowing simultaneous learning of contact and system properties. The authors demonstrate this framework on a series of challenging 2D and 3D physical systems with different coefficients of restitution and friction. The learned dynamics can be used as a differentiability physics simulator for downstream gradient - based optimization tasks."
SP:82d59a3609dfd458f90f23d4e477c8b497e9dc18,"This paper studies the connection between the Lipschitz constant of a neural network ( NN ) and the behavior of the stochastic training procedure of the NN. The authors first show that the NNs with a small Lipsitz constant have a shorter bias trajectory and their bias will vary less, while more complex networks have a longer trajectory, bigger variance, and often veer further from their initialization. They then show that NNs whose 1st layer bias is trained more steadily ( i.e., slowly and with little variation ) have bounded complexity even in regions of the input space that are far from any training point. Finally, they find that steady training with Dropout implies a training and datadependency generalization bound that grows poly - logarithmically with the number of parameters."
SP:9b329c915fa8d4045c167c9df37a49ee314d190e,"This paper studies the problem of learning halfspaces in the Massart noise model with strongly polynomial sample complexity, i.e., independent of the bit complexity of the examples. The main result is that any distribution can be efficiently decomposed as a disjoint mixture of few distributions for which a Forster transform exists and can be computed efficiently. The algorithm of [ DGT19 ] requires n = poly(d, b, 1 / n ) labeled examples, runs in time poly(n, b ) and achieves misclassification error $ \�+$. The dependence on b in the runtime is likely to be inherent, and there is no a priori reason to believe that the poly(b ) dependence is needed in the sample complexity. However, it is known that it is information - theoretically sufficient to achieve optimal misclassified error. This paper provides an affirmative answer to this question. In this paper, the authors show how to apply the machinery of Forster decompositions from Section 2 to adapt the algorithm of the [ D GT19 ] to obtain a new algorithm."
SP:e5229305af00067ae2dbabd903e585964aec8928,"This paper proposes a new adversarial attack method, GRABNEL1, which uses Bayesian optimisation to attack graph classifiers using Bayesian adversarial perturbation. The proposed method is black - box, query - efficient and parsimonious, and does not require policy training on a separate labelled dataset to effectively attack a new sample. It can be easily adapted to perform various modes of attacks such as deleting or rewiring edges and node injection. The authors also analyze the generated adversarial examples to link the vulnerability of graph - based machine learning models to the topological properties of the perturbed graph, which is the first analysis of this kind in the literature."
SP:4999e5664383066fdacd14be6242c7b83f85f3dd,"This paper studies the problem of online label shift adaptation in the online setting, where the test - time label distribution is continually changing and the model must dynamically adapt to it without observing the true label at test time. The authors show that the lack of true label does not hinder the estimation of the expected test loss, which enables the reduction of the online label shifting adaptation to conventional online learning. Informed by this observation, the authors propose adaptation algorithms inspired by classical online learning techniques such as Follow The Leader ( FTH ) and Online Gradient Descent ( OGD ) and derive their regret bounds. They empirically verify their findings under both simulated and real world label distribution shifts and show that OGD is particularly effective and robust to a variety of challenging label shift scenarios."
SP:806515ae07fb1c9d02773592005d53d4158ef102,"This paper proposes a nonparametric method for detecting and localizing gradual changes. The proposed method requires no prior domain knowledge, and it offers theoretical guarantees on both detection ( false positive rate, power, and consistency ) and localization ( consistency ). The authors compare their results with known external events and/or other CPD estimators."
SP:7a3c8a7b17ecab19361d36e1d3d73fa35b71214c,"This paper proposes an online blind source separation ( BSS ) algorithm based on a biologically plausible neural network. The authors propose a novel objective function for ICA from which to derive biologically plausible NN, including both the neural architecture and the synaptic learning rules. The proposed algorithm relies on modulating synaptic plasticity by the total activity of the output neurons. This could be accomplished by neuromodulators, extracellular calcium, local field potential, or nitric oxide. The online algorithm maps onto a single - layer NN that can separate independent sources without pre - processing. The synaptic weights in our NN are updated using local learning rules, extending more conventional Hebbian learning rules by a time - varying factor, which is a function of the total output activity."
SP:22f8b517a3df65144412938f5891c463d7bae0ab,"In this paper, the authors analyze the dynamics of a two - neuron network trained on a task that leads to multiple solutions. The authors first show that a network with identical hyperparameters find qualitatively different solutions. They then show that the diversity revealed with these challenging inputs corresponds to different computations performed by the network. To chart the space of solutions, they introduce a tool that reduces the dynamics into a graph that captures the essence of the computation performed. Applying it to all networks partitions the space into a handful of possible reduced dynamics. Additionally, these classes can be partially predicted using experimentally accessible neural activity obtained only in response to trained stimuli."
SP:9b08a0f547ead3b59077a43b1052c6d46a0730f6,"This paper proposes an energy - based approach for arbitrary conditional density estimation and data imputation. The main idea is to use a Gaussian mixture of Gaussians and fully - connected networks to model the exponentially many conditional distributions over a set of covariates. The proposed method, ACE, uses an energy function to specify the densities of the covariates, which can be used to estimate the distribution p(xu | xo ) for all possible subsets of unobserved features xu and observed features xo. The authors show that ACE achieves state - of - the - art performance for the arbitrary conditional / marginal density estimation task and for data imputations."
SP:f2b14f5854e6aa6922795d1d2051b7402486cef6,"This paper proposes a new adaptive weighted loss for SISR to train deep networks focusing on challenging situations such as textured and edge pixels with high uncertainty. Specifically, they introduce variance estimation characterizing the uncertainty on a pixel - by - pixel basis into SISr solutions so the targeted pixels in a high - resolution image ( mean ) and their corresponding uncertainty ( variance ) can be learned simultaneously. Moreover, uncertainty estimation allows us to leverage conventional wisdom such as sparsity prior for regularizing SISS solutions. For the first time, they demonstrate that such uncertainty - driven loss can achieve better results than MSE or L1 loss for a wide range of network architectures."
SP:9997583f40fa648adf57bb4fc34228f357be0cf1,"This paper proposes a new adversarial robustness setting for binary classification models that can be expressed as a weighted majority vote. This formulation allows the authors to derive PAC - Bayesian generalization bounds on the adversarial risk of general majority votes. The main contribution of this paper is to formalize a new setting ( Adversarially Robust PAC - bayesian setting ). The authors provide theoretical guarantees and well - founded algorithms when the model we learn is expressed as majority vote, whether for ensemble methods with weak voters, fusion of classifiers, or for multimodal / multiview learning."
SP:90b72e8dc41584e38f25dff9fb2853f5b11dc8fa,"This paper proposes a probabilistic entity representation model ( PERM ) for logical reasoning over Knowledge Graphs ( KGs ). The proposed model is based on Gaussian Gaussian density with mean and covariance parameters to capture the semantic position and smooth decision boundary, respectively. The authors also define the closed logical operations of projection, intersection, and union that can be aggregated using an end - to - end objective function. The experimental results show that the proposed PERM significantly outperforms the state - of - the - art methods on various public benchmark KG datasets on standard evaluation metrics."
SP:b6184c9732dbb7eba7c20cae8869d975c428efe4,"This paper proposes a novel forward - mode differentiation with sharing ( FDS ) algorithm for hyperparameter optimization ( HPO ). The main idea is to share hyperparameters across time steps to reduce the gradient degradation issue. The authors provide theoretical guarantees about the noise reduction properties of the algorithm, and demonstrate its efficiency empirically by differentiating through 10 gradient steps of unrolled optimization. They show that FDS outperforms greedy gradient - based alternatives in the quality of hyper parameters found, while being significantly faster than all state - of - the - art black box methods."
SP:9c3a326e5ee4e862923d3bf9415f32a077db8534,"This paper proposes a method to improve the robustness and consistency of neural sequence models by adding a symbolic reasoning module. The proposed method is inspired by the dual process theory from cognitive science. The authors use a few - shot learning approach with state - of - the - art neural language models ( GPT-3 ), which requires no additional training or fine - tuning. Experiments show that the proposed method improves the consistency and coherence of text generations as measured by human judges."
SP:d77d046095e4c8336c0c76ac48cb046923230753,"This paper proposes a method for off - policy evaluation ( OPE ) in continuous treatment settings, such as personalized dose - finding. The key ingredient of the method lies in adaptively discretizing the treatment space using deep discretization, by leveraging deep learning and multiscale change point detection. This allows us to apply existing OPE methods in discrete treatments to handle continuous treatments. The method is further justified by theoretical results, simulations, and a real application to Warfarin Dosing."
SP:4d085e57286fdd36143108a002d16914222c239a,"This paper proposes a variational inference framework for continuous - time hybrid systems. The model is based on a Markov jump process modulating a subordinated diffusion process. The authors provide the exact evolution equations for the prior and posterior marginal densities, the direct solutions of which are computationally intractable. Therefore, the authors develop a new continuous time inference algorithm, combining a Gaussian process approximation on the diffusion level with posterior inference for Markov jumping processes. By minimizing the path - wise Kullback - Leibler divergence, they obtain Bayesian latent state estimates for arbitrary points on the real axis and point estimates of unknown system parameters, utilizing variational expectation maximization. They extensively evaluate their algorithm under the model assumption and for real - world examples."
SP:d1f396e691f9d331adfb7b694a99c50e8004331f,"This paper studies the impact of the spectrum of the sensing matrices on the performance of expectation propagation algorithm ( EP ). The authors define a notion for the spikiness of spectrum of A and show the importance of this measure in the performance performance of the EP. They show that spikier spectrums are better for EP, while in 1 - bit compressed sensing problems, less spiky ( flatter ) spectrums offer better recoveries. Their results unify and substantially generalize the existing results that compare sub - Gaussian and orthogonal matrices and provide a platform toward designing optimal sensing systems."
SP:ee66604d4da9fd04826e90ccbb94f0499eba4c63,"This paper proposes a new prototype network for Generalized Zero - shot Learning ( GZSL ) that aims to improve the cross - domain transferability and category discriminability of visual representations. The proposed method is based on the progressive prototype network ( DPN ), which constructs prototypes for both attributes and categories. The DPN alternately searches attribute - related local regions and updates corresponding attribute prototypes to progressively explore accurate attribute - region correspondence. Besides, the DPN further projects category prototypes into multiple spaces to progressively repel visual representations from different categories. Experiments on four benchmarks demonstrate that the proposed method alleviates the domain shift problem and obtains new state - of - the - art performance."
SP:61eb6297568c3f6869fbb03eaf6a21260de5466c,"This paper presents an end - to - end deep learning approach for removing defocus blur from a single image, so as to have an all - in - focus image for consequent vision tasks. First, a pixel - wise Gaussian kernel mixture ( GKM ) model is proposed for representing spatially variant defocus blurring kernels in an efficient linear parametric form, with higher accuracy than existing models. Then, a deep neural network ( DNN ) is developed by unrolling a fixed - point iteration of the GkM - based deblurring. The DNN is built on a lightweight scale - recurrent architecture, with a scale - recurrent attention module for estimating the mixing coefficients in GKKM for defocus deblurring. Extensive experiments show that the GKmNet not only noticeably outperforms existing defocus deblurring methods, but also has its advantages in terms of model complexity and computational efficiency."
SP:18bf447c90935c373e5ec4cdfbbf8f2a273d2edb,"This paper proposes a new method for self - supervised video representation learning. The method is based on the idea of cross - guidance contrastive learning ( CCL ), where the proposed method uses the contrastive loss between RGB frames and motion vectors from compressed videos. The proposed method is evaluated on action recognition and action retrieval tasks. The results show that the method outperforms existing methods."
SP:8c7b1d976d9758cd534c565ec31a23f97892e503,"This paper studies the problem of asymptotic overconfidence in ReLU Bayesian neural networks ( BNNs ). In particular, the authors show that the output variance of a BNN with finitely many features is quadratic in the distance from the data region. Meanwhile, a Gaussian process ( GP ) with infinite ReLU features has a variance that grows cubically so that no overconfidence can occur. To address this issue, the paper extends the GP to finite ReLU neural networks with infinite features via the cubic spline kernel ( RGPR ). The authors also show that RGPR can be extended further to correct the BNN ’s uncertainty near the training data, by modeling residuals in the higher layers of the network."
SP:e77276f61626e896f6a985296f1d832129242cdf,"This paper considers the problem of selecting a causal quantity of interest among a set of available formulas. The authors use the best - arm - identification bandit framework where the standard goal of learning the arm with the lowest loss is replaced with the goal to learn the arm that will produce the best estimate. They introduce new tools for constructing finite - sample confidence bounds on estimates of the asymptotic variance that account for the estimation of potentially complex nuisance functions, and adapt the best-arm - identification algorithms of LUCB and Successive Elimination to use these bounds. They validate their method by providing upper bounds on the sample complexity and an empirical study on artificially generated data."
SP:471361588bfc6c6033631509d1e43e77fd9721ce,"This paper proposes ErrorCompensatedX, which uses the compression error from the previous two steps of the stochastic gradient descent ( SGD ) algorithm to fully compensate the history compression error. The authors provide a unified theoretical analysis framework that gives an intuitive evaluation for the side - effect of the compression. Numerical experiments are implemented to show the convergence and its better performance compared to other implementations."
SP:3b7ff0dc668cac2191d95fcc4dc6e0335dec3206,"This paper proposes a method to generate multi - granularity explainer for GNNs. The main idea is to use contrastive learning to learn the class - level knowledge for each class, and then fine - tune the model in the local context. The proposed method is evaluated on several datasets. The results show that the proposed method outperforms existing methods in terms of AUC."
SP:9b5a62d3a2b27bc60da28980e9fb0ecdff1215c0,"This paper proposes a novel method to generate robust counterfactual explanations on GNNs by explicitly modelling the common decision logic of GNN on similar input graphs. The main idea is to extract decision boundaries from the given GNN model to formulate an intuitive and effective and effective Counterfactual loss function. Then, the authors optimize this loss to train a neural network to produce explanations. The experiments on synthetic and real - life benchmark datasets strongly validate the efficacy of our method."
SP:4edb870786c9cea2c6075359cb4e79b02a8e2f5f,This paper proposes a method for voice - to - speech style transfer based on self - supervised representation learning and adversarial feedback. The key idea is to decompose the content and voice style from the source speech. The proposed method is evaluated on the VCTK dataset. The experimental results show the superiority of the proposed method in disentanglement and transfer performance.
SP:9fbb0c6beb3f8f88972f13dcf0e1fe7db03233c7,"This paper proposes a Siamese shape - aware feature learning network and a voxel - to - BEV target localization network to improve the tracking performance in sparse 3D point clouds. Specifically, it consists of a template feature embedding to embed the template’s feature into the potential target and then generate a dense 3D shape to characterize the shape information of the target. For localizing the tracked target, it regresses the target ’s 2D center and the z - axis center from the dense BEV feature map in an anchor - free manner. Extensive experiments on the KITTI and nuScenes datasets show that the proposed method significantly outperforms the current state - of - the - art methods by a large margin."
SP:8b788c78680a54c453a04f4551436763ee57585e,"This paper proposes a novel positional encoding method based on learnable Fourier features for multi - dimensional positional encoding. The proposed method uses a multi - layer perceptron to encode each position into a vector space. The function extracts position information based on a set of features and passes them to an MLP. The encoding function is learnable and is initialized in such a way that the inner products of our positional encodings approximate Euclidean distances. The method is parameter - efficient, in the sense that the number of parameters do not grow with sequence length. The experimental results show that the proposed method outperforms existing methods by both improving the accuracy and allowing faster convergence."
SP:d2ac1b6381315bce4449f09bd519f33a2a42d714,"This paper proposes a new constraint - based method, L - MARVEL, for the problem of learning the causal MAG of a system from observational data in the presence of latent variables and selection bias. The key idea of the approach is that at each iteration a specific type of variable is identified and removed. This allows us to learn the structure efficiently and recursively, as this technique reduces both the number of required conditional independence ( CI ) tests and the size of the conditioning sets. The former substantially reduces the computational complexity, while the latter results in more reliable CI tests. To the best of the knowledge, this is the tightest bound in the literature. The upper bound of the proposed approach and the lower bound at most differ by a factor equal to the amount of variables in the worst case."
SP:49a4912ce457f5f5ec62c44fa10444af8075fabf,"This paper proposes a batch Thompson sampling method for the stochastic multi - armed bandit and linear contextual bandit problems. The main idea is to use a dynamic batch allocation mechanism to achieve near - optimal regret guarantees while reducing the number of sequential interactions with the environment from T to O(log T ). The authors show that their proposed batch policies achieve similar regret bounds ( up to constant factors ) but with significantly fewer number of interactions. They also observe empirically that batch Thompson Sampling methods with a fixed batch size, but equal number of batches, incur higher regrets."
SP:653a519e3c799c25e0d0b4240322642040b121a3,"This paper studies the trade - off between different types of domain - invariant representations for multi - source domain adaptation ( MSDA ) and domain generalization ( DG ). The main contribution of this paper is the development of theoretical upper - bounds for the target general loss in the MSDA and DG settings. The upper bounds are based on the generalization of Theorems 1, 2, 3, and 4. The lower bound is based on Theorem 5. Theoretical analysis is provided for the two types of representations : general DI representation for learning invariant classifier which works on all source domains and compressed DI representation motivated from reducing inter - domain representation discrepancy. The paper also provides a lower bound on the target loss which governs the tradeoff between learning them. Experiments are conducted on Colored MNIST dataset and real dataset to illustrate the theoretical claims."
SP:2a7bee950cd07494d59dfee60ac2e86cc0e481b1,"This paper proposes an aligned structured sparsity learning ( ASSL ) method for lightweight image super - resolution ( SR ) networks. The proposed method is based on weight normalization layer and L2 regularization to the scale parameters for sparsity. To align the pruned filter locations across different layers, the authors propose a sparsity structure alignment penalty term, which minimizes the norm of soft mask gram matrix. The authors apply the proposed method to train efficient image SR network, named as ASSLN, with smaller model size and lower computation than SOTA lightweight image SR methods."
SP:e9830bb9e7d3ddc3bd1c2994590fdb5d8f3668be,"This paper proposes a novel exploration method for cooperative multi - agent reinforcement learning ( MARL ). The proposed method is based on the idea that Q - values, i.e., the individual utility functions used for local execution, are the embeddings of local actionobservation histories, and can capture the interaction between agents due to reward backpropagation during centralized training. The authors propose to use prediction errors of individual Q - value as intrinsic rewards for coordinated exploration and utilize episodic memory to exploit explored informative experience to boost policy training. Empirical results on more complicated StarCraft II tasks show that EMC significantly outperforms other state - of - the - art MARL baselines."
SP:c7e33d479575c88e22282ee6fd4f978bcd3c06ed,"This paper studies the problem of list - decodable linear regression, where an adversary can corrupt a majority of the examples. The goal is to output a small list of hypothesis vectors such that at least one of them is close to the target regression vector. The main result is a Statistical Query ( SQ ) lower bound of d for this problem. The SQ lower bound qualitatively matches the performance of previously developed algorithms, providing evidence that current upper bounds for this task are nearly best possible."
SP:7b258252a9063514348f5fa8d9c85afd85748747,"This paper proposes a hybrid model, Latent Hybridisation Model ( LHM ), that integrates a system of expert - designed ODEs with machine - learned Neural ODE to fully describe the dynamics of the system and to link the expert and latent variables to observable quantities. The model is evaluated on synthetic data and real - world intensive care data of COVID-19 patients. LHM consistently outperforms previous works, especially when few training samples are available."
SP:3ea9e86e5755ef84d28e3163c60531ace5d62e3a,"This paper provides a theoretical analysis of fine - tuning - based meta - learning, where the goal is to learn a task - specific representation for each task. The authors assume that there exists a set of tasks with approximately the same representation, which they call a "" shared structure "". They provide a theoretical framework for analyzing a MAML - like algorithm, and provide risk bounds on predictors found by finetuning via gradient descent, demonstrating that the method provably leverages the shared structure. In contrast, they establish settings where learning one representation for all tasks ( i.e. using a “ frozen representation ” objective ) fails, and show that any such algorithm can not outperform directly learning the target task with no other information."
SP:8ba5a2ac80f7c53f81ad008e96c033ecad14ac0d,"This paper presents Grammar - based Grounded Lexicon Learning ( G2L2 ), a lexicalist approach toward learning a compositional and grounded meaning representation of language from grounded data, such as paired images and texts. The key idea is to learn a neuro - symbolic semantic program for each word in a sentence, which is composed of a syntactic type and a semantic program. This program is then used to construct lexical meanings based on syntax. To facilitate learning in an exponentially growing compositional space, the authors introduce a joint parsing and expected execution algorithm, which does local marginalization over derivations to reduce the training time. Experiments on two domains : visual reasoning and language - driven navigation show that the model generalizes from small amounts of data to novel compositions of words."
SP:16c458651815813efdcbe8ba1205bbddbe3e4e68,"This paper proposes a stochastic Newton algorithm for homogeneous distributed stochastically convex optimization. In this setting, each machine can calculate the gradient of the same population objective, as well as the Hessian of the population objective with arbitrary vectors. The authors show that their method can reduce the number, and frequency, of required communication rounds compared to existing methods without hurting performance, by proving convergence guarantees for quasi - self - concordant objectives ( e.g., logistic regression ). In Section 4, the authors show how, for some regimes in terms of M, K, and R, their method may improve upon the rates of previous first - order methods, including FEDAC ( Yuan and Ma, 2020 ) and FEDSN - LITE ( Chen et al., 2019 ). They compare a more practical version of their method, FED SN - Lite ( Algorithm 6 ) against the other methods, showing we can significantly reduce communication compared to other first order methods."
SP:d7e479d59f82d4c55372a68ca7b4516f2871f346,"This paper proposes a new metric, Density - aware Chamfer Distance ( DCD ), to measure the similarity between two point sets. It is based on Chamfer distance ( CD ), which is a widely used metric for measuring the distance between two points, and Earth Mover's distance ( EMD ). The authors argue that the proposed DCD is more sensitive to local differences in the density of the points than CD and EMD, and that it is more computationally efficient than EMD. In addition, the authors propose a novel point discriminator module that estimates the priority for another guided downsampling step, and it achieves noticeable improvements under DCD. The proposed method is evaluated on the task of point cloud completion."
SP:e4b302009520770814ff2c096020b779a9fc38fe,"This paper studies the problem of knowledge distillation, a popular technique for training a small student network to emulate a larger teacher model, such as an ensemble of networks, to improve student generalization. The authors show that the student does not always match the teacher, and that there is a surprisingly large discrepancy between the predictive distributions of the teacher and the student. They identify difficulties in optimization as a key reason for why the student is not always able to match its teacher. They also show how the details of the dataset used for distillation play a role in how closely the student matches the teacher — and that more closely matching the teacher paradoxically does not necessarily lead to better student generalisation."
SP:895c7e03f9e4dadb94be1f39d61bf0b5e1533f4f,"This paper proposes a coreset for decision trees. The coreset is a small summarization of the loss function of a k - decision tree, which is a recursive partition of a matrix ( 2D - signal ) into k+1 block matrices ( axis - parallel rectangles, leaves ) where each rectangle is assigned a real label. The paper provides the first algorithm that outputs such a ( k, \epsilon)-coreset for every such matrix D. The size of the coreset C of D is polynomial in k log(N ) / epsilon, and its construction takes O(Nk ) time. This is by forging a link between decision trees from machine learning – to partition trees in computational geometry. Experimental results on sklearn and lightGBM show that applying our coresets on real - world data - sets boosts the computation time of random forests and their parameter tuning by up to x10, while keeping similar accuracy."
SP:f3ece96b15ec06d703925df2061ed9694ec3bca5,"This paper studies the problem of best - arm identification in linear bandit models with misspecified linear models. The problem is motivated by practical applications, especially in medicine and recommendation systems, where linear models are popular due to their simplicity and the existence of efficient algorithms, but in which data inevitably deviates from linearity. In this setting, the authors first derive a tractable lower bound on the sample complexity of any $ \delta$-correct algorithm for the general Top - m identification problem. They then describe the first algorithm for this setting which is both practical and adapts to the amount of misspecification. They derive an upper bound to its sample complexity which confirms this adaptivity and that matches the lower bound when $ \� = 0. Finally, they evaluate their algorithm on both synthetic and real - world data, showing competitive performance with respect to existing baselines."
SP:e71c5e39b8d8d1640d6de2352ac51ddd52eea89d,"This paper proposes a method to learn disentangled graph - level representations with self - supervised learning for graph neural networks ( GNNs ). In particular, the authors first identify the latent factors of the input graph and derive its factorized representations. Then they propose a novel factor - wise discrimination objective in a contrastive learning manner, which can force the factorized representation to independently reflect the expressive information from different latent factors. Extensive experiments on both synthetic and real - world datasets demonstrate the superiority of their method against several state - of - the - art baselines."
SP:0a7edbbdabab11273689c40c517001eb46491113,This paper proposes a statistical simulation to assess the robustness of a neural network to input uncertainties with a stochastic simulation inspired by the field of Statistical Reliability Engineering. The robustness assessment is cast as a statistical hypothesis test : the network is deemed as locally robust if the estimated probability of failure is lower than a critical level. The procedure is based on an Importance Splitting simulation generating samples of rare events. The paper derives theoretical guarantees that are nonasymptotic w.r.t. sample size. Experiments tackling large scale networks outline the efficiency of the method making a low number of calls to the network function.
SP:c1db485ff1ff9573daa421e167225654babb55ac,"This paper proposes a general framework, called CoPE, that enables a polynomial expansion of two input variables and captures their auto - and cross - relations. CoPE can be trivially augmented to accept an arbitrary number of input variables. The proposed framework is evaluated in five tasks ( class - conditional generation, inverse problems, edges - to image translation, image - to - image translation and attribute - guided generation ) involving eight datasets. The results show that CoPE is able to synthesize realistic images in five diverse tasks."
SP:5a75bc7a3ea0ce971cfceebbc1c2434e3aa2584d,"This paper proposes a novel neural tangent kernel ( NTK ) - MMD statistic for two - sample neural network testing. The main idea is to use NTK to compute the Maximum Mean Discrepancy ( MMD ) statistic and perform NTK - based 2 - sample tests. Theoretical analysis is provided to explain the NTK test statistic properties, such as the Type - I error and testing power, by adapting existing theories for kernel MMD. Numerical experiments on synthetic and real - world datasets validate the theory and demonstrate the effectiveness of the proposed NTK-MMD statistic."
SP:1df2ffbbe56b8018067820980b93af2a8b57f891,"This paper proposes a VAE - VAE structure to decompose an input image x into x = G(x + R(x ), where R captures the essential information for classification, while G covers all class - redundant information. The authors also propose an objective to jointly train the VAE and classifier to gain such class - disentanglement capability. They apply it to both clean images and their adversarial images and discover that the perturbations generated by adversarial attacks mainly lie in the class - dependent part x - G( x ). The decomposition results also provide novel interpretations to classification and attack models. Inspired by these observations, the authors propose to conduct adversarial detection and adversarial defense respectively on x + G(X ) and G(G(x), which consistently outperform the results on the original x."
SP:2789874561620ba7894c4672f935056bb911e919,"This paper proposes a differentially private federated Thompson sampling ( FTS ) algorithm for Bayesian optimization ( BO ) in federated learning ( FL ). The authors propose to incorporate differential privacy ( DP ) into the training of deep neural networks through a general framework for adding DP to iterative algorithms. They also leverage the ability of this general DP framework to handle different parameter vectors, as well as the technique of local modeling for BO, to further improve the utility of our algorithm through distributed exploration ( DE ). They provide theoretical guarantees for both the privacy and utility of DP - FTS - DE, which combine to yield a number of elegant theoretical insights about the privacy - utility trade - off. Finally, they empirically demonstrate that DP -FTS -DE delivers an effective performance with a strong privacy guarantee and induces a favorable trade -off."
SP:be7d6b81736a2c3f89abd8771b41b18802e88832,"This paper proposes a Gaussian process - Bayesian Bernoulli Mixture model ( GP - B2M ) for multi - label active learning ( AL ). The BM encodes label correlations using a Bayesian mixture of label clusters, where each mixture component corresponds to a global pattern of label correlations. To tackle the sparse labels under AL, the BM is further integrated with a predictive GP to connect data features as an effective inductive bias and achieve a feature - component - label mapping. A novel auxiliary variable based variational inference algorithm is developed to tackle the non - conjugacy introduced along with the mapping process for efficient end - to - end posterior inference. The model also outputs a predictive distribution that provides both the label prediction and their correlations in the form of a label covariance matrix. A principled sampling function is designed accordingly to naturally capture both the feature uncertainty ( through GP ) and label covariances ( through BM ) for effective data sampling."
SP:2b7270b0370c193300bcbbb5fb0a4101b3329d99,"This paper proposes a streaming method for 3D object detection, Lidar segmentation, and Panoptic segmentation on the nuScenes dataset. The proposed method is based on the polar coordinate system, which is a more compact representation for lidar sectors compared to previous methods. The method uses multi - scale context padding including trailing - edge padding and bidirectional padding to enhance spatial context of the streaming model with minimal latency. The authors also propose feature undistortion and range stratified convolutions to address the problem of applying convolutions on a polar grid. Experimental results show significant improvements over previous streaming methods with lower latency."
SP:7ae2c5b7d9c8a6c8f4a353606aa419929c47f31b,"This paper proposes to use score function - based gradient estimators instead of differentiable surrogates for learning structured latent variables. The authors extend the Gumbel - Max trick to define distributions over structured domains by leveraging the score function estimators for optimization. In particular, they highlight a family of recursive algorithms with a common feature we call stochastic invariant. The feature allows us to construct reliable gradient estimates and control variates without additional constraints on the model. In the experimental section, they consider various structured latent variable models and achieve results competitive with relaxation - based counterparts."
SP:415d363c66a6967c1daca9dc02001b85bf7f0752,"This paper proposes a method to adapt CNN denoisers trained on large datasets to a single test image. To avoid overfitting, it optimizes a single multiplicative scaling parameter ( the “ Gain ” ) of each channel in the convolutional layers of the CNN. The proposed method is evaluated on standard image - denoising benchmarks, boosting the performance on nearly every image in a held - out test set. The adaptive improvements are even more substantial for test images differing systematically from the training data, either in noise level or image type. The paper also demonstrates the potential of adaptive GainTuning in a scientific application to transmission - electron microscope images, using a CNN that is pre - trained on synthetic data."
SP:90afa1102683b456bc72a54abef466326827546a,This paper proposes a fully differentiable architecture for simultaneous semantic and instance segmentation ( a.k.a. panoptic segmentation ). The proposed architecture consists of a convolutional neural network and an asymmetric multi - way cut problem solver. The latter solves a combinatorial optimization problem that elegantly incorporates semantic and boundary predictions to produce a pan - optic labeling. The formulation allows to directly maximize a smooth surrogate of the pan - optical quality metric by backpropagating the gradient through the optimization problem w.r.t. the objective function. Experimental evaluation on Cityscapes and COCO datasets shows the utility of using optimization in tandem with deep learning in a challenging large scale real - world problem.
SP:1952e174d9ec7b83ad1d394ece7fe77ea1f6d78d,"This paper introduces Recursive Bayesian Networks ( RBNs ), a new probabilistic model that unifies PCFGs and DBNs by combining their strengths and containing both as special cases. The authors define a joint distribution over tree - structured Bayesian networks with discrete or continuous latent variables. The main challenge lies in performing joint inference over the exponential number of possible structures and the continuous variables. To this end, the authors provide two solutions : 1 ) for arbitrary RBN, they generalise inside and outside probabilities from PCFGS to the mixed discrete - continuous case, which allows for maximum posterior estimates of the continuous latent variable via gradient descent, while marginalising over network structures. 2 ) for Gaussian RBNS, they additionally derive an analytic approximation of the marginal data likelihood ( evidence ) and marginal posterior distribution, allowing for robust parameter optimisation and Bayesian inference.   The authors demonstrate the effectiveness of the proposed model on synthetic data and an application to the challenging task of hierarchical music analysis."
SP:5f29b169d3e4bbaeeec85e1aeebe2094fae4be6e,"This paper proposes the constrained backpropagation ( CBP ) algorithm based on the pseudo - Lagrange multiplier method to obtain the optimal set of weights that satisfy a given set of constraints. The proposed CBP algorithm is the utilization of a Lagrangian function ( loss function plus constraint function ) as its objective function. The authors considered various types of constraints — binary, ternary, one - bit shift, and two - bit - shift weight constraints. As a post - training method, CBP applied to AlexNet, ResNet, and ResNet-18 on ImageNet, which were pre - trained using the conventional back - propagation."
SP:3ddf8e2e108fb261bb23aec8a27a25aba7523dc1,"This paper proposes a new active learning strategy for Gaussian process classification ( GPC ). The proposed strategy is based on estimating the estimated error reduction ( EER ), which is the reduction of the Mean Objective Cost of Uncertainty ( MOCU ). To estimate EER, the authors derive the joint distribution of queries as a one - dimensional integral with constant computation cost and calculate the predictive posterior based on it. The authors also derive the gradient chain rule to efficiently calculate the gradient of the acquisition function, which leads to the first query synthesis active learning algorithm implementing EER - based strategies. The experiments show the effectiveness of the proposed algorithms."
SP:fa1fac04cd4ccb1f3eaf80807db09f9683ce6b50,"This paper studies the effect of unbounded gradients on the regularization of continuous variational autoencoder ( VAE ) models. The authors show that if the ultimate goal is to simultaneously avoid over - regularization ( high reconstruction errors, sometimes referred to as posterior collapse ) and underregularization ( excessive latent dimensions are not pruned from the model ), then an autoencod - based energy function with infinite gradients around optimal representations is provably required per a certain technical sense. This result suggests that heuristic modifications to or constraints on the VAE energy function may at times be ill - advised and large gradients should be accommodated to the extent possible."
SP:2611cfd6e0696a57d061687993cef1fe5c95999d,"This paper studies the problem of bandit bandits with graph feedback. The authors propose the notions of fractional weak domination number and k - packing independence number to study the min - max regret of the bandit problem. They show that the two notions are inherently connected via aligning them with the linear program of the weakly dominating set and its dual — the fractional vertex packing set. Based on this connection, they utilize the strong duality theorem to prove a general regret upper bound O ( ( ( \delta / \alpha ) 1 3 T 2 3 ) ) and a lower bound $ O(\alpha)$ where $ \alpha$ is the integrality gap of the dual linear program. They also show that for several special families of graphs, they can get rid of the ( log | V |) 1 3 factor and establish optimal regret."
SP:e50dec57af337839cbde4b65fb7b431785fda44d,"This paper proposes to use neighbourhood reference distributions to improve the local interpretability of Shapley values. The authors show that the Nadaraya - Watson estimator, a well - studied kernel regressor, can be expressed as a self - normalised importance sampling estimator. The proposed Neighbourhood SHAP values provide meaningful sparse feature relevance attributions that provide insight into local model behaviour. They also increase on - manifold explainability and robustness to the construction of adversarial classifiers."
SP:35bdeb78f9fe74e754177fb54b48e7399dc8590d,"This paper proposes a novel method, PlayVirtual, which augments cycle - consistent virtual trajectories to enhance the data efficiency for RL feature representation learning. PlayVirtual predicts future states in a latent space based on the current state and action by a dynamics model and then predicts the previous states by a backward dynamics model, which forms a trajectory cycle. Based on this, the authors augment the actions to generate a large amount of virtual state - action trajectories and enforce a trajectory to meet the cycle consistency constraint, which can significantly enhance the training efficiency. Experimental results on both the discrete control benchmark Atari and continuous control benchmark DMControl demonstrate the effectiveness of the proposed method."
SP:ca09e472cbcf2ac8c8c9b192a87df2ed59218210,"This paper investigates the effect of network architecture on the robustness of a neural network to noisy labels. The authors propose a formal framework to connect the architecture of a network to the alignments between its architecture and target / noise functions. Theoretically, the authors show that a network is more robust to noise if its architecture is more aligned with the target function than the noise. Empirically, they show that when the network is well - aligned with target function, its predictive power in representations could improve upon SOTA noisy - label - training methods in terms of test accuracy and even outperform sophisticated methods that use clean labels."
SP:903727fe028684623a8ccadec210e641ecffc685,"This paper proposes an algorithm for off - policy example - based control. The key idea of the algorithm is to directly learn to predict whether the task will be solved in the future via recursive classification, without using separate reward learning and policy search procedures. The authors show that their method satisfies a new data - driven Bellman equation, where examples take the place of the typical reward function term. Experiments show that our approach outperforms prior methods that learn explicit reward functions."
SP:39ccbd5909a1d7ed212fe92d8d6843c2c70dfe1f,"This paper studies differentially private stochastic optimization in convex and non - convex settings. In the convex case, the authors focus on the family of non - smooth generalized linear losses ( GLLs ). Their algorithm for the l2 setting achieves optimal excess population risk in near - linear time. For the l1 - case with smooth losses and polyhedral constraint, they provide the first nearly dimension independent rate, Á ( log d ( nε ) 1/3 ) in linear time, and linear - time algorithm with rate Á( 1 n1/3 + d 1/5 ( n\epsilon ) 2/5 ) for l2 - case. They also extend all their results above for the non - concave setting to the lp setting, with only polylogarithmic overhead in the rates."
SP:99a476f71e6901aefe281f11fb72ff78265a5b6e,"This paper studies the cooperative bandit problem in three different imperfect communication settings. For each setting, the authors propose decentralized algorithms that achieve competitive performance, along with near - optimal guarantees on the incurred group regret as well. Furthermore, in the setting with perfect communication, they present an improved delayed - update algorithm that outperforms the existing state - of - the - art on various network topologies. Finally, they provide tight network - dependent minimax lower bounds on the group regret."
SP:d3e896a65470f2439bc7753b4f66e152306b2d6f,"This paper proposes a post - training quantization method for vision transformers to reduce the memory storage and computational costs. The quantization task can be regarded as finding the optimal low - bit quantization intervals for weights and inputs, respectively. To preserve the functionality of the attention mechanism, the authors introduce a ranking loss into the conventional quantization objective that aims to keep the relative order of the self - attention results after quantization. Moreover, they thoroughly analyze the relationship between quantization loss of different layers and the feature diversity, and explore a mixed - precision quantization scheme by exploiting the nuclear norm of each attention map and output feature. The effectiveness of the proposed method is verified on several benchmark models and datasets."
SP:aa6b1328585b5916267a3ff4f9119e7aa4ce2bb5,"This paper studies the convergence of double Q - learning. The main contribution of this paper is the development of a finite - time analysis of double - Q learning with constant learning rate, which improves the convergence rate by an order of magnitude in terms of its dependence on all major parameters ( 1 - \�, D, L, \gamma, \tilde{O}(1-\gamma)$ ). The authors show that synchronous double Q learning attains an -accurate global optimum with a time complexity of $ O(\sqrt{L})$, and the asynchronous algorithm achieves a $ L$-accurate $ \sqrt{\gamma$-time complexity.   The main contributions of the paper are :   1. A new analysis of the dependence on the discount factor and the cardinality of the state - action space. 2. A systematic approach and a series of novel techniques to bound two nested stochastic approximation recursions. 3. A series of numerical experiments to compare the performance of synchronous and asynchronous Q learning."
SP:04fd4d83717c4f7e1a4b5651a59200151f33411d,"This paper proposes a novel semi - supervised OOD detection setting where only limited ID labeled data and many mixed unlabeled data are available. The main idea is to detect OOD samples in a detection - specific space where we maintain the same local topological structures as the original feature space. The proposed method is based on the Structure - Keep Unzipping ( STEP ) algorithm, which learns a new representation space in which OOD and ID samples can be separated well. An efficient optimization algorithm is derived to solve the objective. Comprehensive experiments show that the proposed STEP approach outperforms other methods by a large margin in most cases."
SP:6bf8b94483b26033795b0eda9649518027f5e1c2,"This paper proposes a transformer - based architecture for referring expression comprehension and segmentation. Specifically, the authors propose a transformer architecture, where two modalities are fused in a visual - lingual encoder. In the decoder, the model learns to generate contextualized lingual queries which are then decoded and used to directly regress the bounding box and produce a segmentation mask for the corresponding referred regions. The authors also show that a simple pre - training schedule ( on an external dataset ) further improves the performance. Extensive experiments and ablations illustrate that the model benefits from contextualized information and multi - task training."
SP:29b552b36696c9bda72f3ab4f31605d98880fd6b,"This paper studies the problem of multiclass boosting, where the target concept can be approximated by boosting weak hypotheses from a given base - class. The weak learner is an agnostic PAC learner for that class with respect to the standard classification loss. The goal of the overall boosting algorithm is then to learn a combination of weak hypotheses by repeatedly calling the weak learners. The authors study the resources required for boosting, especially how they depend on the number of classes k, for both the booster and the weak learning oracle. They find that the boosting algorithm itself only requires O(log k ) samples, as well as analyzing a variant of AdaBoost for our setting."
SP:f63b050773871338c48b778c362172e4b72477a4,"This paper proposes a new unsupervised object - centric image segmentation and scene generation model, GENESIS - V2, based on the IC - SBP. The method is based on embedding - based approach in which embeddings of pixels are clustered in a differentiable fashion using a stochastic stick - breaking process. Similar to iterative refinement, this clustering procedure also leads to randomly ordered object representations, but without the need of initialising a fixed number of clusters a priori. This is used to develop a new model, which can infer a variable number of object representations without using RNNs or iteration refinement. Experiments on synthetic and real - world datasets demonstrate the effectiveness of the proposed method."
SP:408deb9e5577ee7118b836fee77135df641fe545,"This paper proposes adaptive conformal inference ( ACI ), a method for forming prediction sets that are robust to changes in the marginal distribution of the data. The main idea is to model the distribution shift as a learning problem in a single parameter whose optimal value is varying over time and must be continuously re - estimated. The authors show that over long time intervals ACI achieves the target coverage frequency without any assumptions on the data - generating distribution. ACI can work with any conformity score St(· ) and quantile function Q(t ) and thus can be directly combined with other improvements to obtain shorter intervals. The experiments show that ACI is robust to visible and significant distribution shifts."
SP:e6e5b1e2428abcf1a163ec1cce15cd299f9a544f,"This paper proposes a new method for multi - person pose estimation in crowded scenes. The proposed method is based on the Pose - level Inference Network ( PINet ). PINet first applies the Part - based Pose Generation ( PPG ) to infer multiple coarse poses for each person from his/her body parts. Those coarse poses are refined by the Pose Refinement module through incorporating pose priors, and finally are fused in the Pose Fusion module. Experiments on several crowded scenes pose estimation benchmarks demonstrate the effectiveness of proposed PINet."
SP:e76f048c3dccffcb8bcc6a66f6165fc19d175610,This paper proposes a method to solve robust RMDPs with L_\ell_\infty-constrained rectangular ambiguity sets. The method is based on homotopy continuation and bisection to solve S - rectangular ambiguity in quasi - linear time. The algorithm improves on the cubic time required by leading general linear programming methods. The experimental results show that the proposed method outperforms a leading commercial optimization package by several orders of magnitude.
SP:c4af66a64a5c2bd58ca2e29dbc4b27d5bf4b63b8,"This paper studies the problem of online knapsack with frequency predictions. The problem is formulated as a generalized one - way trading problem, where the value of each item is a function of the number of items in the bag. The paper provides an upper and lower bound for the value $ \v$ of the item $ V$, and a lower bound $ u$ for the number $ p$ of items $ P$. The paper shows that for any $ P$, there exists a $ \tilde{v}$-strong frequency prediction $ P = { \v;uv}v2V$ such that the algorithm has a competitive ratio of $ O(\sqrt{O}(P)$ times the optimum for all inputs respecting the given frequency prediction P.   The paper also provides an algorithm with the best possible competitive ratio for this prediction model. The algorithm is shown to have a $ O(1 / P)$-competitive ratio if the algorithm ’s profit is at least $ \Omega(1/P)$.   This paper extends the problem to more general settings such as generalized one way trading and two - stage online knapack."
SP:1d478d4fa3f5df0ded963ef164325667fd744dbb,"This paper proposes a new model - based episodic memory of trajectories ( MBEC++ ) to improve the sample efficiency of episodic control in reinforcement learning. The authors propose to use a trajectory model to store the trajectories, and then use a memory - based planning with fast value - propagating memory writing and refining. Experiments show that MBEC+ outperforms baselines on a variety of RL tasks, including grid - world, classical control, and Atari games."
SP:551174c1266b5f4b6aaf5432a4c713386f90898c,"This paper proposes a new semi - supervised learning method called DP - SSL that uses data programming scheme to generate probabilistic labels for unlabeled data. The proposed method is based on multiple choice learning ( MCL ) based approach to automatically generate LFs from scratch in SSL style. With the noisy labels produced by the LFs, the authors design a label model to resolve the conflict and overlap among the noisy labeled, and finally infer probabilistically labels. Extensive experiments on four standard SSL benchmarks show that DP -SSL can provide reliable labels and achieve better classification performance on test sets than existing SSL methods."
SP:d1d6a40a8bde62a21da4fc18a076e344c84ab0d0,This paper proposes a multi - view pose transformer ( MVPT ) for estimating multi - person 3D poses from multi - views images. The main idea is to use a transformer - like model architecture with a novel hierarchical joint query embedding scheme and projective attention mechanism. The proposed method is evaluated on the challenging Panoptic dataset and achieves state - of - the - art results.
SP:2e147bd5321e25bb27d2531fd58c46460a1e5320,"This paper studies the problem of recovering sparse vectors from a mixture of sign responses. In particular, the authors consider the case where a family of unknown sparse vectors is fixed, where each vector has at most k non - zero elements. The first problem is to learn the supports of all vectors from the family using a sequence of noisy responses. The second problem is the reconstruction of sparse vectors such that the sparse vectors can be approximately reconstructed based on the error - free responses. This problem can be seen as a generalization of support recovery and approximate recovery problems, well - studied under the framework of 1 - bit compressed sensing. The authors prove the existence of learning algorithms for the first problem which work without any assumptions. Under a mild structural assumption on the unknown vectors, they also show the exist of learning algorithm for the second problem and rigorously analyze their query complexity."
SP:e3388e479a825be429f3a878e2c4d8b05903ff10,"This paper proposes an online sensing method for detecting abrupt changes in temporal behavior patterns. The proposed method is based on a general class of finitely parameterized probability distributions. The authors derive an information - theoretic lower bound on the detection delay for this class of probability distributions, and propose a computationally efficient online sensing scheme, which seamlessly balances the need for exploration of different sensing options with exploitation of querying informative actions. They derive expected delay bounds for the proposed scheme and show that these bounds match the information - theoretic lower bounds at low false alarm rates, establishing optimality of the proposed method. They then perform a number of experiments on synthetic and real datasets."
SP:268260e9452ba2bc57e50a6b7b3328233137ac9b,"This paper proposes a new algorithm for solving stochastic nested optimization problems. The main idea is to combine existing SGD - type updates for nested problems into a single SGD approach that the authors call the ALternating Stochastic Gradient dEscenT ( ALSET ) method. By leveraging the hidden smoothness of the problem, this paper presents a tighter analysis of ALSET for stochastically nested problems. Under the new analysis, to achieve an -stationary point of the nested problem, it requires O( -2 ) samples in total. Under certain regularity conditions, applying the proposed method to stochiastic compositional, min - max, and reinforcement learning problems either improves or matches the best - known sample complexity in the respective cases."
SP:82ad52361bc5b2c421f1dc6b76e1a5520570fc6c,"This paper proposes a Siamese sampling mechanism to generate sparse and similar clips ( i.e., siamese clips ) from the same video, and a novel reasoning strategy for integrating the interdependent knowledge between contextual clips into the network. The reasoning strategy contains two modules : ( 1 ) siamesese knowledge generation to learn the inter - relationship among clips, and ( 2 ) knowledge reasoning to produce the refined soft label by propagating the weights of inter - relationship to the predicted candidates of all clips. The proposed SiaSamRea can endow the current multimodal reasoning paradigm with the ability of learning from inside via the guidance of soft labels. Extensive experiments demonstrate that the proposed method achieves state - of - the - art performance on five VideoQA benchmarks."
SP:160022e2cd61159da92f92e85520b7062a337a8d,"This paper proposes a low - rank parameterization approach to reduce the computational and memory complexity of a large class of structured models. The proposed approach is based on the matrix - vector product and uses a low rank constraint to trade off model expressivity and speed via the rank. Experiments with neural parameterized structured models for language modeling, polyphonic music modeling, unsupervised grammar induction, and video modeling show that the proposed approach matches the accuracy of standard models at large state spaces while providing practical speedups."
SP:238592ad73927194cdf0c0cf9ae2e48ca86e182c,"This paper introduces Sample Average Uncertainty ( SAU ), a simple and efficient uncertainty measure for contextual bandits. SAU is a frequentist approach that directly estimates the uncertainty of the outcomes based on the value predictions. The authors show theoretically that the uncertainty measure estimated by SAU asymptotically matches the uncertainty provided by Thompson Sampling, as well as its regret bounds. Because of its simplicity SAU can be seamlessly applied to deep contextual bandits as a very scalable drop - in replacement for epsilongreedy exploration. Empirically, the authors show that SAU - based exploration outperforms current state - of - the - art deep Bayesian bandit methods on several real - world datasets."
SP:ffc5b18f7e18607b2934e5aa199e7542005d79f4,"This paper proposes a method to learn behavioral embeddings from unlabeled, multi - view, high - resolution behavioral videos across different animals and multiple sessions. The key idea is to disentangle the dynamic behavioral factors ( pose ) from time - invariant, non - behavioral nuisance factors ( context ) in a deep autoencoder, and exploit the temporal structures of pose dynamics. The authors further combine DBE with a stochastic temporal model to propose Variational Disentangled Behavior Embedding ( VDBE ), an end - to - end approach that learns meaningful discrete behavior representations and generates interpretable behavioral videos. Compared to competing approaches, the proposed method enjoys superior performance on downstream tasks such as fine - grained behavioral motif generation and behavior decoding."
SP:bf78a450e4aad6b87fdeb8ec0d68adaaff7b595b,This paper proposes a deep 3D conditional generative model that can synthesize high - resolution 3D shapes using simple user guides such as coarse voxels. It marries the merits of implicit and explicit 3D representations by leveraging a novel hybrid 3D representation. The core of DMTET includes a deformable tetrahedral grid that encodes a discretized signed distance function and a differentiable marching tetrahedra layer that converts the implicit signed distance representation to the explicit surface mesh representation. This combination allows joint optimization of the surface geometry and topology as well as generation of the hierarchy of subdivisions using reconstruction and adversarial losses defined explicitly on the surface mesh.
SP:2bc0bd6aa2a12691b16145f0d23542c4c86e3a44,"This paper proposes sliced mutual information ( SMI ) as a surrogate measure of dependence. SMI is defined as an average of MI terms between one - dimensional random projections. The paper shows that SMI preserves many of the structural properties of classic MI, while gaining scalable computation and efficient estimation from samples. Furthermore, and in contrast to standard MI, SMI can grow as a result of deterministic transformations. This enables leveraging SMI for feature extraction by optimizing it over processing functions of raw data to identify useful representations thereof."
SP:e220b348901b476c2afd95f97630fb5400582f40,"This paper proposes a two - step lookahead constrained Bayesian optimization algorithm ( 2 - OPT - C ), which uses the likelihood ratio method to estimate the gradient of the acquisition function. The authors argue that being non - myopic is even more important in constrained problems because fear of violating constraints pushes myopic methods away from sampling the boundary between feasible and infeasible regions, slowing the discovery of optimal solutions with tight constraints. The proposed algorithm is applicable to both batch and sequential settings, and substantially improves both query efficiency and computation time over the one previous method."
SP:51fbd861422647912f275b48861ea3c4812afdc8,"This paper proposes a multi - dimensional distributional DQN ( MD3QN ) for value - based reinforcement learning. The main idea is to model the joint return distribution from multiple sources of rewards. The authors show that the proposed method can capture not only the randomness in returns for each source of reward, but also the rich reward correlation between the rich randomness of different sources. The proposed method is based on the joint distributional Bellman operator, and the authors prove the convergence of this operator and the empirical algorithm. The empirical results show the effectiveness of the proposed approach in the control setting."
SP:1f85c93d6bbfd65bf497c92c9cd534d799753097,"This paper proposes a method to reconstruct high - resolution, accurate, and regular triangular meshes from volumetric images. The proposed method is based on the flow ODE framework, where a neural network is trained to predict a dense 3D flow vector field from an image. Then, a new Diffeomorphic Mesh Deformation ( DMD ) module, which is parameterized by a set of diffeomorphic mappings, is learned to deform a reference template towards a targeted object. The method is evaluated on the challenging task of brain cortical surface reconstruction, where the goal is to describe the inner and outer surfaces of the brain."
SP:2f31d9cf4ad17ad08344439ca0aef7ec91944545,"This paper studies the problem of data deletion in the non - convex setting. In particular, the paper focuses on the adaptive deletion problem, where a user can choose to delete data points that are adaptive to the model used to train the model. The paper provides a general reduction from deletion guarantees against adaptive sequences to deletion guarantees for non - adaptive sequences, using differential privacy and its connection to max information. It also provides a practical attack against the SISA algorithm of Bourtoule et al. ( 2021 ) on CIFAR-10, MNIST, Fashion - MNIST."
SP:7150006590e268ab732c9be6c9048f67a377f956,This paper proposes an algorithm to optimise the conditional value at risk ( CVaR ) of the total return in Bayes - adaptive Markov decision processes ( MDPs ). The authors reformulate the problem as a two - player stochastic game and propose an approximate algorithm based on Monte Carlo tree search and Bayesian optimisation. Experiments demonstrate that the proposed algorithm significantly outperforms baseline approaches for this problem.
SP:a94f39406f73d7483ddd744ed2f03c78b8bc5d44,"This paper studies the behavior of shallow ReLU networks trained with the logistic loss via gradient descent on binary classification data where the underlying data distribution is general, and the ( optimal ) Bayes risk is not necessarily zero. In this setting, it is shown that gradient descent with early stopping achieves population risk arbitrarily close to optimal in terms of not just logistic and misclassification losses, but also in terms calibration, meaning the sigmoid mapping of its outputs approximates the true underlying conditional distribution arbitrarily finely. Moreover, the necessary iteration, sample, and architectural complexities of this analysis all scale naturally with a certain complexity measure of the true conditional model. The paper also shows that any univariate classifier satisfying a local interpolation property is inconsistent."
SP:a9c786cbb61e1f10f3542161b13e43a1a68ab34d,"This paper proposes a method to detect coordinated groups on social media based on prior knowledge. The proposed method is based on a neural temporal point process ( NTP ) with prior knowledge such as temporal logic or pre - defined filtering functions. The authors propose to jointly learn a Gibbs distribution of group assignment based on how consistent an assignment is to ( 1 ) the account embedding space and ( 2 ) the prior knowledge, and use a theoretically guaranteed variational inference approach to learn a mean - field approximation for it. Experimental results on a real - world dataset show the effectiveness of the proposed method compared to state - of - the - art model in both unsupervised and semi - supervised settings. The detection result suggests presence of suspicious coordinated efforts on spreading misinformation about COVID-19 vaccines."
SP:b5c6e967a26a02861db2ecd620e9061db0c03e59,"This paper studies the problem of binary classification on two disjoint smooth curves on the unit sphere. The authors show that when the network depth is large relative to certain geometric properties that set the difficulty of the problem and ( i ) the network width and number of samples are polynomial in the depth, randomly - initialized gradient descent quickly learns to correctly classify all points on the two curves with high probability. To their knowledge, this is the first generalization guarantee for deep networks with nonlinear data that depends only on intrinsic data properties. The analysis proceeds by a reduction to dynamics in the neural tangent kernel ( NTK ) regime, where the neural network depth plays the role of a fitting resource in solving the classification problem. In particular, via fine - grained control of the decay properties of the NTK, the authors demonstrate that if the network is sufficiently deep, NTK can be locally approximated by a translationally invariant operator on the manifold and stably inverted over smooth functions, which guarantees convergence and generalization."
SP:8f6bee3be43df6b6e80804974014caaafe08c49e,"This paper proposes a new auxiliary classifier GAN, ReACGAN, to improve the stability of ACGAN. The main idea is to use the data - to - data cross - entropy loss ( D2D - CE ) to exploit the relational information in the class - labeled dataset. The experiments show that the proposed method outperforms the existing classifier - based and projection - based GANs on CIFAR10, TinyImageNet, CUB200, and ImageNet datasets."
SP:080e80746a87228b156408ff649ab7a17f44e92d,"This paper proposes an extensive - form double oracle algorithm for two - player zero - sum games that is guaranteed to converge to an approximate Nash equilibrium linearly in the number of infostates. Unlike PSRO, which mixes best responses at the root of the game, XDO mixes best response at every infostate. The authors also introduce Neural XDO ( NXDO ), where the best response is learned through deep RL. In tabular experiments on Leduc poker, they find that XDO achieves an approximate NE in a number of iterations an order of magnitude smaller than PSRO. They also find that NXDO outperforms PSRO and NFSP on a sequential multidimensional continuous - action game."
SP:bda04facef4f34679fc4e17b8ea1aae74c3d649f,"This paper proposes a permutation - invariant variational autoencoder for graph - level unsupervised representation learning. The main idea is to train an autoencoder network that is by design invariant to the order of nodes in a graph. This is achieved by training an additional permuter model to align the input graph node order with the node order of the reconstructed graph. The authors demonstrate the effectiveness of their proposed model for graph reconstruction, generation and interpolation and evaluate the expressive power of extracted representations for downstream graph-level classification and regression."
SP:e17ea6aeba78c9dfc25596d8b35a2a4f1f1f6763,"This paper proposes a method to decouple the depth and scope of GNNs. The main idea is to first extract a subgraph from the global graph, and then apply a GNN of arbitrary depth on top of the subgraph. The subgraph consists of a small number of critical neighbors, while excluding irrelevant ones. The GNN, no matter how deep it is, smooths the local neighborhood into informative representation rather than oversmoothing the global graphs into “ white noise ”. Theoretically, the paper shows that the proposed method improves the GNN expressive power from the perspectives of graph signal processing ( GCN ), function approximation ( GraphSAGE ) and topological learning ( GIN ). Empirically, on seven graphs ( with up to 110M nodes ) and six backbone GNN architectures, the design achieves significant accuracy improvement with orders of magnitude reduction in computation and hardware cost."
SP:4890f251db559a0a572afc66e0c1f899b577d9ff,This paper provides the first universal approximation guarantees for affine - coupling normalizing flows with well - conditioned affine coupling networks. The authors show that any log - concave distribution can be approximated using well - conditioned affine-coupling flows. The main contribution of the paper is to provide a theoretical proof of the universal approximation guarantee. The proof is based on the connection between affine networks and underdamped Langevin dynamics and Hénon maps. The results also inform the practice of training affine couplings.
SP:5ffa81488ed1092deb89bd5e150fa146325057ce,"This paper proposes a budget constrained offline reinforcement learning and evaluation with λ - generalization ( BCORLE(λ ) ) framework to solve the problem of budget constrained coupons allocation in e - commerce market. The proposed method consists of three components : ( 1 ) an offline policy learning method, ( 2 ) an off - policy evaluation method, and ( 3 ) an improved offline RL algorithm called batch - constrained Q - learning ( R - BCQ ) is proposed in this paper. The experiments on a simulation platform and a real mobile shopping app validate the effectiveness of the proposed methods."
SP:6b04cc7b4e45b9e65a1d34c15e3f75a2ef27d601,"This paper proposes a method for source - free domain adaptation ( SFDA ), where the source pretrained model is adapted to the target domain in the absence of source data. The method is based on the observation that target data, which might no longer align with the source domain classifier, still forms clear clusters. To capture this intrinsic structure, the authors define local affinity of the target data and encourage label consistency among data with high local affinity. They observe that higher affinity should be assigned to reciprocal neighbors, and propose a self - regularization loss to decrease the negative impact of noisy neighbors. Furthermore, to aggregate information with more context, they consider expanded neighborhoods with small affinity values. The experimental results verify that the inherent structure of target features is an important source of information for domain adaptation."
SP:ac1bf04ff782e5892a0bc5fe5949848ca8e731c2,"This paper proposes a novel method for pooling features from a set of features into a fixed - dimensional representation. The key idea is to use the sliced - Wasserstein distance between the elements of a set and a reference set. The proposed method uses a permutation - equivariant backbone to perform the pooling. The authors show that the proposed method derives an exact Euclidean embedding which is geometrically - interpretable for setstructured data. The method is evaluated on a variety of tasks, including point cloud classification, graph classification, and image recognition."
SP:6cb2f0cbc076f8680cb00411790629f8e1478053,"This paper proposes a new family of RNNs, SBO - RNN, that can be formulated using stochastic bilevel optimization ( SBO ). The main idea is to convert the SBO problem into an RNN where the feedforward and backpropagation solve the lower and upper - level optimization for learning hidden states and their hyperparameters, respectively. The authors prove that under mild conditions there is no vanishing or exploding gradient in training SBO-RNN. Empirically, the authors demonstrate that their networks can obtain good training stability by selecting proper learning rates for the lower - level problem to avoid vanishing and exploding gradients."
SP:d3a4300e21ca215334f256f0467a428470548fe4,"This paper studies the online problem of minimizing power consumption in systems with multiple power - saving states. The authors propose a learning - augmented online algorithm that makes decisions based on ( potentially inaccurate ) predicted lengths of the idle periods. The algorithm ’s performance is near - optimal when predictions are accurate and degrades gracefully with increasing prediction error, with a worst - case guarantee almost identical to the optimal classical online algorithm for the problem. A key ingredient in the approach is a new algorithm for online ski rental problem in the learning augmented setting with tight dependence on the prediction error."
SP:22aba6284123af0ecd6605ee4e89b351bd7e10a3,"This paper proposes a mathematical framework for quantifying the transferability in multi - source transfer learning problems, with both the task similarities and the sample complexity of learning models taken into account. In particular, the authors consider the setup where the models learned from different tasks are linearly combined for learning the target task, and use the optimal combining coefficients to measure transferability. Then, they demonstrate the analytical expression of this transferability measure, characterized by the sample sizes, model complexity, and the similarities between source and target tasks, which provides fundamental insights of the knowledge transferring mechanism and the guidance for algorithm designs. Furthermore, they apply their analyses for practical learning tasks, and establish a quantifiable transferable measure by exploiting a parameterized model. In addition, they develop an alternating iterative algorithm to implement their theoretical results for training deep neural networks in multi-source transfer learning tasks. Finally, experiments on image classification tasks show that our approach outperforms existing transfer learning algorithms in multi source and few - shot scenarios."
SP:0fb8dcf15e0d43547d566fdba7bc70b3bb600005,This paper proposes a method to address the problem of search asymmetry in visual search tasks. The authors propose a model called eccNET that takes a target and a search image as inputs and produces a sequence of eye movements until the target is found. The model integrates eccentricity - dependent visual recognition with target - dependent top - down cues. The proposed model is tested on six paradigmatic search tasks that show asymmetry. It is shown that eccNET is able to find the target among distractors more often than the other distractors.   The authors also show that the model provides a plausible mechanism for search asymmeter. They hypothesize that the polarity of the asymmetry arises from experience with the natural environment. They tested this hypothesis by training the model on augmented versions of ImageNet where the biases of natural images were either removed or reversed depending on the training protocol.
SP:f0cc968ea9da4884dcdaf6d0c75ea9f1511bdfc3,"This paper studies the problem of certifiable robustness training. The authors propose a new certifiable training method with tighter bounds on the worst - case loss and smoothness of the loss landscape. They find that the current state - of - the - arts method often has a landscape with favorable optimization properties. To verify their claims, they propose a certifiable learning method with tight bounds and a favorable loss landscape, which can achieve a decent performance under a wide range of perturbations."
SP:a158f8772a9dada059ffd1d6d7838ed40d8483da,"This paper studies the problem of online linear regression in the stochastic setting. The authors derive high probability regret bounds for online ridge regression and the forward algorithm. This enables them to compare online regression algorithms more accurately and eliminate assumptions of bounded observations and predictions. This paper advocates for the use of forward algorithm in lieu of ridge due to its enhanced bounds and robustness to the regularization parameter. Moreover, the authors explain how to integrate it in algorithms involving linear function approximation to remove a boundedness assumption without deteriorating theoretical bounds. They showcase this modification in linear bandit settings where it yields improved regret bounds."
SP:17ff9a2133aebf2d1b1787e8efc49d709389c0e7,"This paper proposes a two - time - scale and anchored extragradient method, named FEG, for smooth structured nonconvex - nonconcave problems. The proposed FEG has an accelerated O(1/k2 ) rate, with respect to the squared gradient norm, for the Lipschitz continuous and negative comonotone operators for the first time. The FEG also has value for smooth convex - concave problems, compared to existing works. This paper further develops its backtracking line - search version, named   FEG - A for the case where the problem parameters are not available. The stochastic analysis of FEG is also provided."
SP:4e38973033de24fc183c6112e1146f8eef0ddaea,"This paper studies the problem of uniformity testing for ranking data where the alternative class is restricted to Mallows models. The authors show that uniform distribution can be distinguished from Mallows model with O(m 1/2 ) samples based on simple pairwise statistics, which allows us to test uniformity using only two samples, if m is large enough. The proposed methods can work based on 2 samples, when m = large enough, and the authors also devised testing algorithms in the central and local differential privacy framework. They demonstrated the versatility of these testers on synthetic data. They found that they are scalable, since they could handle large m including m = 10000, and are able to detect non - uniformity with very small error."
SP:99a835191a3ba8372e391b6d3316e9b68e543295,"The paper proposes a score - based algorithm for learning directed acyclic graphs ( DAGs ). The algorithm is based on the idea of Bregman divergences, and the authors show that it can be viewed as a special case of the greedy algorithms such as GES, hill climbing, and A* search. The authors also show that recent polynomial - time algorithms for learning DAG models can be interpreted as these order - based algorithms. This observation suggests new score functions and optimality conditions, which the authors explore in detail. Finally, the authors provide extensive experiments suggesting that this algorithm indeed optimizes the score."
SP:b60989706296b963b6671c01f22384978a334be1,This paper proposes a method to improve the adversarial robustness of the backbone CNNs that have a satisfactory accuracy over the natural data. The authors propose to dilate the architecture of neural networks to increase the robustness while maintaining a competitive standard accuracy with a straightforward constraint. Theoretical analysis on the standard and adversarial error bounds naturally motivate the proposed neural architecture dilation algorithm. Experimental results on real - world datasets and benchmark neural networks demonstrate the effectiveness of the proposed algorithm to balance the accuracy and adversarially robustness.
SP:77ed765e911a4e5f2bfba13cbd2403500a5d05e6,"This paper studies the model - based reward - free reinforcement learning with linear function approximation for episodic Markov decision processes ( MDPs ), where the transition probability kernel of the MDP can be parameterized by a linear function over certain feature mappings defined on the triplet of state, action, and next state. The authors show that to obtain an $ \epsilon$-optimal policy for arbitrary reward function, UCRL - RFE needs to sample at most $ \tilde{O}(\sqrt{H}(H + d)$ episodes during the exploration phase during the planning phase. They also propose a variant of UCRL-RFE using Bernstein - type bonus and show that the sample complexity of their algorithm UCRLRFE+ matches the lower bound in terms of the dependence on accuracy ϵ and feature dimension d when H < d."
SP:28563ba0975f56ddb662cd46e85de78bb6024d36,"This paper proposes a method for forecasting future activities in data streams. The proposed method is based on shifting seasonal matrix factorization ( SSMF ), which is an online algorithm that can adaptively learn multiple seasonal patterns ( called regimes ) and switch between them in an online manner. The method is evaluated on three real - world data streams and shows that SSMF outperforms state - of - the - art baseline methods by accurately forecasting upcoming events."
SP:e4bb07033001be4d04695ef058f426d49fe440be,"This paper proposes a novel neural network architecture, WeaveNet, to solve the assignment problem. The core module, feature weaving layer, is stacked to model frequent communication between elements in a parameter - efficient way for solving the combinatorial problem of assignment. To evaluate the model, they approximated one of the most popular non - linear assignment problems, stable matching with two different strongly NP - hard settings. Experimental results showed its impressive performance among the learning - based baselines."
SP:8a559e21d45661eef427b310e5fe8488d5749137,"This paper studies the impact of self - supervised learning ( SSL ) on the adversarial robustness in 3D point cloud recognition. Specifically, the authors study the impact on PointNet, DGCNN, and transformer - based 3D architectures. Through extensive experimentation, they demonstrate that appropriate applications of SSL can significantly enhance the robustness of 3D deep learning models against adversarial attacks."
SP:657c5a1114c0d054b9e767d85990bbbb0492912d,"This paper proposes a method to speed up the computation of projections over submodular base polytopes. The main idea is to adapt the away - step Frank - Wolfe algorithm to consider combinatorial structure from previous projections, and accordingly obtain improvements over the basic AFW algorithm.   The main contributions of the paper are :   1. The authors develop a toolkit for computing projections using both discrete and continuous perspectives ( e.g., A2FW ). 2. They propose a method for convex optimization over base poly topes that enables early termination with the exact optimal solution via rounding ( T5 ) via rounding, and improved convergence rates visa restricting ( T4 ). 3. Theoretical results show orders of magnitude reduction in runtime."
SP:8dae43d6b5cebb7ef6c39437d997b390c2380536,This paper considers the problem of learning the natural parameters of a k - parameter minimal exponential family from i.i.d. samples in a computationally and statistically efficient manner. The authors propose a novel estimator via minimizing a convex loss function and obtain consistency and asymptotic normality of the same. They provide a rigorous finite sample analysis to achieve an α - approximating to the true natural parameters with O(poly(k / \alpha ) samples and O(k/\alpha ) computations. They also provide an interpretation of their estimator in terms of a maximum likelihood estimation.
SP:4f9ddb697e86356fb293ef34a69ca3702c4e8164,"This paper proposes a differentiable renderer, DIB - R++, for reconstructing realistic materials BRDFs and lighting configurations from a single image containing strong specular transport. The authors use a convolutional neural network F, parameterized by learnable weights ϑ, to predict 3D attributes of a meshM with pre - determined topology ( Spherical in the case of the paper ). They then render these parameters back to an image I using our differentiable Renderer and apply a loss L on the RGB output to compare the input image Ĩ and the rendered image I, where L(\epsilon ) = αimLim(I, I ) + αmskLmsk(V, V ) + alphaperLper(Ĩ, I) + αlapLlap(π ).   The authors demonstrate that their approach achieves superior material and lighting disentanglement on synthetic and real data compared to existing rasterization - based approaches and showcase several artistic applications."
SP:6ac1c8556e7131939cc582f513bc9921470e1b09,"This paper proposes a differentiable differentiable training method to improve the performance of detection - based localization. The main idea is to minimize the expectation of the localization error. To do so, the authors introduce a continuous formulation of the output distribution and develop a sampling process to approximate the expectation. The expectation can be approximated by calculating the average error of all samples drawn from the differentiable sampling process. The authors show that the proposed method can seamlessly replace the conventional soft - argmax operation on various localization tasks."
SP:478c05c90090f9d80b72ac352c488073b45a5d8b,"This paper proposes a directed graph data augmentation method called Laplacian perturbation and theoretically analyzes how it provides contrastive information without changing the directed graph structure. Moreover, the paper proposes to use curriculum learning to progressively learn from dynamic easy - to - difficult contrastive views. Experiments show that the proposed method can retain more structural features of directed graphs than other GCL models."
SP:85b383d2f722f7bff438840e423f5cb4c67d5980,"This paper proposes a new benchmark for evaluating language grounded agents across unique challenges posed by five symbolic interactive environments. The benchmark consists of grid - world environments that require generalization to new dynamics, entities, and partially observed worlds, as well as symbolic counterparts of visual worlds that require interpreting rich natural language with respect to complex scenes. The authors propose the first shared model architecture for RL on these environments, and evaluate recent advances such as egocentric local convolution, recurrent state - tracking, entity - centric attention, and pretrained LM using SILG."
SP:23c8db56f59f778fe812a5dd161f7a1f21c3cdba,"This paper presents a method for scaling sparsely - gated Mixture of Experts networks ( MoEs ) for image recognition. The method is based on the Vision Transformer ( ViT ), which is a sparse version of the ViT. The authors propose a new routing algorithm that can prioritize patches across the entire batch, leading to adaptive per - image compute. This allows V - MoE to trade - off performance and compute smoothly at test - time. Finally, the authors demonstrate the potential of the proposed method to scale vision models and train a 15 B parameter model that attains 90.35 % on ImageNet."
SP:c5235f41dfb8b5cc478f11c5d5e0ab0b8676871e,"This paper studies the expressivity of 1 - hidden - layer networks with fewer than n neurons when the activation is smooth. The authors show that as long as the width m > 2 n / d, there exists at least one global minimizer with zero training loss. They also identify a nice local region with no local - min or saddle points, but it is not clear whether gradient descent can stay in this nice region. Thorough numerical results show that projected gradient methods on this constrained formulation significantly outperform SGD for training narrow neural nets. In real - data experiments, the proposed method can significantly outperforms SGD."
SP:0be529f5254afd59dcfa6b34a359c7037e7a8323,"This paper proposes a continuous mean - covariance bandit ( CMCB ) model, which takes into account option correlation in the reward - risk tradeoff measured by option correlation. The authors propose a novel algorithm for the problem, and provide lower bounds for the problems to demonstrate the optimality. They also present empirical evaluations to show the superior performance of their algorithms."
SP:472a90bb175b0286765c5a47b040e1a58f594a05,"This paper proposes a non - commutative extension of the Multiplicative Update ( MMU ) algorithm for computing Positive Semidefinite ( PSD ) factorization of a matrix X with non - negative entries. PSD factorization generalizes the Non - Negative Matrix Factorization ( NMF ) problem in which we seek a collection of r - dimensional non -negative vectors { Ai } and { Bj } satisfying Xij = ai bj, for all i \in [ m, j \in n ]. The authors show that the MMU algorithm ensures that updates remain PSD by congruence scaling with the matrix geometric mean of appropriate PSD matrices, and it retains the simplicity of implementation that the multiplicative update algorithm for NMF enjoys. They demonstrate the utility of their method on real and synthetic data."
SP:83abd6d149d88cc6e96cbc4d488e4fe9dc2a4fcb,"This paper proposes a meta - domain specific - domain invariant ( mDSDI ) framework for domain generalization. The key insight is to disentangle features in the latent space while jointly learning both domain - invariant and domainspecific features in a unified framework. The domain - specific representation is optimized through the meta - learning framework to adapt from source domains, targeting a robust generalization on unseen domains. The experimental results show that the proposed method outperforms the state - of - the - art techniques in DG."
SP:4191474c75e2fedf514f0f3001a67a047eb74c30,This paper proposes to improve the FID of diffusion models by using classifier guidance to guide the diffusion model during sampling. The main idea is to use a classifier to guide a diffusion model to sample samples from the distribution of the classifier. The proposed method is evaluated on two tasks : unconditional image synthesis and conditional image synthesis. The results show that the proposed method outperforms the state - of - the - art on both tasks.
SP:fe3cab08596cde4c14ecf6fca8d0f95b02bab229,"This paper proposes to use out - of - distribution samples to improve the performance of few - shot learning ( FSL ). Specifically, the authors propose to use base samples from base classes to train the classifier to avoid irrelevant features by maximizing the distance from prototypes to out of distribution samples while minimizing that to in - distribution data. The proposed approach is simple to implement, agnostic to feature extractors, lightweight without any additional cost for pre - training, and applicable to both inductive and transductive settings. Extensive experiments on various standard benchmarks demonstrate that the proposed method consistently improves the performance for pretrained networks with different architectures."
SP:b1f65724926f136979829b7a6c870bc31f38f591,"This paper studies the problem of prioritization in off - policy reinforcement learning. The authors propose two new algorithms, ReMERN and ReMERT, to improve the performance of prioritized sampling. The main contribution of the paper is an analysis of existing prioritization methods, including PER, LFIW, DisCor, and DisCor. The paper argues that the objectives of these methods are different from the objective of RL, which can lead to a suboptimal training process. To solve this issue, the authors analyze the prioritization strategy from the perspective of regret minimization, which is equivalent to return maximization in RL. Based on this analysis, they propose two practical prioritization strategies, namely ReMern, which learns an error network, while ReMert exploits the temporal ordering of states. The proposed algorithms outperform previous prioritization algorithms in challenging RL benchmarks, including MuJoCo, Atari, and Meta - World."
SP:601ebf30b3c6aa35fcef49633aa8eb0acd0f2c66,"This paper studies the problem of sequential prediction with expert advice in a nonstationary environment with long - term memory guarantees in the sense of Bousquet and Warmuth [ 4 ]. The authors propose a linear - time algorithm that improves on the best known regret bounds [ 27 ]. This algorithm incorporates a relative entropy projection step. This projection is advantageous over previous weight - sharing approaches in that weight updates may come with implicit costs as in for example portfolio optimization. In Section 4 they derive a new “geometric - decay ” method for MPP, and show the correspondence to the current best known algorithm [ 27]."
SP:b2439973063e827b3cbe92306a2fdee3286b6b44,"The paper considers the problem of contextual linear bandits, where the learner is given a set of actions, and the goal is to select the action that maximizes the utility of the set. The paper considers two variants of the problem, one where the user is allowed to provide a list of actions and the other where they are only allowed to recommend one of them. In the former case, the paper proposes an algorithm with O(d log d ) regret and a list size poly(d ), and in the latter case the paper presents an algorithm that achieves O(log d log T ) regret. In both cases, the algorithm is based on the cutting - plane algorithm. The authors also consider a variant where the recommendation is only given if the action is better than the action on the list."
SP:abe83c7e0bcf4829742609d709637e2f84d8a4d9,"This paper proposes an open - source sklearn - compatible AutoML library, called Lale, that allows data scientists to use their domain knowledge to more selectively and efficiently automate their machine learning work. Lale uses combinators for modularity, and uses schemas both for search spaces and for type - checking. It is more expressive than the high - level interfaces of prior AutoML tools. The proposed Lale gives users fine - grained control over AutoML without requiring them to be AutoML experts."
SP:0d7f1cae577ed598048b64617e85ca6bd5c6d7fa,"This paper proposes a meta - learning approach to improve the generalization performance of the look - ahead MAML algorithm. Specifically, the paper proposes to learn a weight initialization such that a small number of weight changes results in low generalization error. Then, the learning algorithm decides which weights to change, i.e., by learning where to learn. The paper shows that patterned sparsity emerges from this process, with the pattern of sparsity varying on a problem - by - problem basis. This selective sparsity results in better generalization and less interference in a range of few - shot and continual learning problems. Moreover, this paper also finds that sparse learning also emerges in a more expressive model where learning rates are meta - learned. This paper sheds light on an ongoing debate on whether meta -learning can discover adaptable features and suggest that learning by sparse gradient descent is a powerful inductive bias for meta learning systems."
SP:05037e1850003a725a466b64d3e32aa2aed458fb,"This paper proposes a new approach to the problem of multi - view ICA. The proposed approach is based on the idea of shared independent component analysis ( ShICA ), where each view is represented as a linear transform of the shared independent components contaminated by additive Gaussian noise. The authors show that this model is identifiable if the components are either non - Gaussian or have enough diversity in noise variances. They then show that in some cases multi - set canonical correlation analysis can recover the correct unmixing matrices, but that even a small amount of sampling noise makes Multiset CCA fail. To solve this problem, they propose to use joint diagonalization after MultisET CCA, leading to a new method called ShICA - J. They show via simulations that ShICA-J leads to improved results while being very fast to fit. They further propose to leverage the non - gaussianity of the components using a maximum likelihood method, Shica - ML, that is both more accurate and more costly."
SP:44dd1faa1813c433fd7581d05cae3df440bfb93e,"This paper proposes a novel training method for multi - agent reinforcement learning, called Fictitious Co - Play ( FCP ), to improve the generalization of agents to new human co - players. FCP trains the agent partner as the best response to the population of self - play agents and their past checkpoints taken throughout training, a method the authors refer to as “ fictitious co - play ”. The authors conduct experiments on a two - player collaborative cooking simulator that has recently been proposed as a challenge problem for coordination with humans. They find that FCP agents score significantly higher than SP, PP, and BCP when paired with novel agent and human partners and humans also report a strong subjective preference to partnering with FCP agent."
SP:21c84bd720b1e90ea0f88fbf8fd24dbcb49b547c,"This paper proposes FACMAC, a multi - agent actor - critic method that learns decentralised policies with a centralised but factored critic. The centralised policy gradient estimator is based on the QMIX algorithm, which uses a non - linear monotonic function to factorize the policy gradient. The paper shows that FACMAC outperforms MADDPG and other MARL algorithms on three different domains."
SP:1c8351b8a6cdf1212840388e19a596729b3bfda4,"This paper proposes a key - value - based model for long - term memory. The key value mechanism is based on the Hebbian plasticity of the Hopfield network, which is the standard biologically plausible model of long term memory in neuroscience. This paper proposes to use a combination of biologically plausible three - factor plasticity rules to store and read out the key values. The proposed model is evaluated on three memory tasks : auto - associative memory, continual recall, heteroassociative memory and sequence learning. The results show that the proposed model performs on par with the classical Hopfield networks."
SP:7ad6da2c63859d64970e9b35326e9ceab48add47,"This paper studies the problem of pairwise learning, where the loss function depends on a pair of instances. The authors propose stochastic and online gradient descent methods for the problem. The main contribution of this paper is to develop a differentially private algorithm for the task. The algorithm is based on the idea of localized SGD. Theoretical results are provided for the convex and nonconvex problems, as well as both smooth and nonsmooth problems. The paper also provides generalization bounds for OGD using a buffering set with a fixed size."
SP:cb11dacc930d71a616ee2fbe4acfae030f9dca59,"This paper proposes REDO, a class - agnostic framework to reconstruct the Dynamic Objects from RGBD or calibrated videos. The main idea is to use a canonical 4D implicit function which is pixel - aligned with aggregated temporal visual cues, and a 4D transformation module which captures object dynamics to support temporal propagation and aggregation. The authors conduct extensive experiments on synthetic RGBD video datasets SAIL - VOS 3D and DeformingThings4D++ and on real - world video data 3DPW. They find that REDO outperforms state - of - the - art dynamic reconstruction methods by a margin."
SP:8ae97752e74b4395774575009031abcb6ba5cea7,"This paper provides a non - asymptotic analysis of linear stochastic approximation ( LSA ) algorithms with fixed stepsize. The analysis is based on new results regarding moments and high probability bounds for products of matrices which are shown to be tight. The authors derive high probability bound on the performance of LSA under weaker conditions on the sequence {(An,bn ) : n 2 N⇤} than previous works. However, in contrast, the authors establish polynomial concentration bounds with order depending on the stepsize, and show that their conclusions can be improved without additional assumptions on the sequences of random matrices."
SP:86c1e937755e35efafecc09dfe2606ffb1653a41,"This paper extends the options framework for temporal abstraction in reinforcement learning from discounted Markov decision processes ( MDPs ) to average - reward MDP. The authors propose general convergent off - policy inter - option learning algorithms, intra - option algorithms for learning values and models, as well as sample - based planning variants of the learning algorithms. The algorithms and convergence proofs extend those recently developed by Wan, Naik, and Sutton. They also extend the notion of option - interrupting behavior from the discounted to the average - return formulation. The experiments on a continuing version of the classic Four - Room domain demonstrate the efficacy of the proposed algorithms."
SP:7e4e1e20e7c253d02c6ae58457fb30029f130f0c,"This paper proposes a self - supervised auxiliary task to improve the performance of visual transformers ( VTs ). The proposed task is based on the idea of dense localization loss ( LRL ), which aims to encourage the VTs to learn spatial information from images. The authors show that the proposed LRL can improve the accuracy of different VTs on small - to medium - sized datasets, and that it is more effective in generalizing with less data. The experiments show that LRL improves the performance on several datasets and three VTs."
SP:0132ef17585e293b23e9dc45189c0989d829b52a,"This paper proposes a new method for label - free data alignment in hyperbolic space based on the Riemannian geometry of the Lorentz model. The proposed method consists of three components : translation, scaling, and rotation. The authors provide a theoretical analysis and justification of their alignment method based on new derivations of Riemanian geometry operations in the hyperboloid model. They show experimental results of accurate batch effect removal from several hierarchical bioinformatics datasets without landmark correspondence."
SP:3580ac64f09e3021de5d4c92411bcc0f3c5d10f3,"This paper studies the tradeoff between the accuracy of a point query and the sum query for differentially private query answering systems. The paper shows that the uncertainty principle governs the trade - off between accuracy for a population of interest ( "" sum query "" ) vs. accuracy for its component sub - populations ( "" point queries "" ). This uncertainty principle affects some, but not all, possible datasets. To mitigate the effects of this uncertainty principle, the paper presents lower bounds for pure, approximate, and concentrated differential privacy, and propose mitigation strategies and create a collection of benchmark datasets that can be used for public study of this problem."
SP:c0e64dc8acfaed3e4d7745af12fd34003d0e5017,"This paper proposes CO - PILOT, a method to improve the performance of goal - conditioned reinforcement learning ( RL ) and planning policies in long - horizon tasks. The main idea is to train a planner and an RL agent on a curriculum of tree - structured sub - tasks, where the planner learns to decompose a task into a few tasks and then gradually increases the interpolated sub - task sequences to train the planner. The RL agent is trained to minimize the cost of completing the sequence in each layer from top to bottom layers. The authors show that this method improves the sample efficiency and success rate on different types of tasks with sparse rewards."
SP:9911693a04a300b5a93634fb0267ef83e5489d77,This paper proposes a Bayesian framework for generating local explanations for black box classifiers. The main idea is to use the Bayesian version of LIME and SHAP to estimate the feature importance and the associated uncertainty. The authors also propose a novel sampling technique called focused sampling that leverages the uncertainty estimates to determine how to sample perturbations for faster convergence. The experimental results show that the proposed method is more stable than LIME / SHAP on an average.
SP:5efb4b81bd37c70640e8768e9dfb5bba14a0cfb8,This paper studies the problem of heavy tails in Adder neural networks ( ANNs ). The authors propose to use a mixture of multivariate Skew Laplace distributions to model the heavy - tails in ANNs. They also introduce an angle - based constraint on the distribution parameters to incorporate high diversity of distribution tails in angle space so that the overlapping can be eliminated. Experiments conducted on several benchmarks and comparison with other distributions demonstrate the effectiveness of proposed approach for boosting the performance of ANNs for improving the performance.
SP:cbccb65457564992d534504c0d060da44cafce8c,"This paper studies the phenomenon of gradient starvation in overparameterized neural networks. The authors propose a formalism for the phenomenon, which they call Gradient Starvation ( GS ), which is a phenomenon that arises when training with cross - entropy loss in neural networks, i.e., the loss is minimized by capturing only a subset of features relevant for the task, despite the presence of other predictive features that fail to be discovered. This work provides a theoretical explanation for the emergence of such feature imbalances in neural network. They also provide a novel but simple regularization method aimed at decoupling feature learning dynamics, improving accuracy and robustness in cases hindered by gradient starvation. They illustrate their findings with simple and real - world OOD generalization experiments."
SP:8f6fe37cb0a332b66e10cc00261a44622841c8c6,"This paper presents a single - blind evaluation of human - AI teaming in the cooperative card game Hanabi with both rule - based and learning - based agents. In addition to the game score, the authors quantify subjective measures of the human ’s perceived performance, teamwork, interpretability, trust, and overall preference of AI teammate. The authors find that humans have a clear preference toward a rule based AI teammate ( SmartBot ) over a state - of - the - art learning based AI agent ( Other - Play ) across nearly all subjective metrics, and generally view the learning based agent negatively. This result has implications for future AI design and reinforcement learning benchmarking, highlighting the need to incorporate subjective metrics of human-AI teaming."
SP:2a05e333fc1a14057515ef3addde9a40152373db,"This paper proposes a novel approach for visual question generation ( VQG ) based on double - hints. The proposed method consists of a question generator and a question - answer - aware discriminator. The question generator uses a visual hints predictor with a cross - modal reasoning module to determine the salient visual regions associated to the corresponding question. The discriminator is to distinguish whether a sample triplet ( i.e., the image, answer, and question ) is generated from the generator or ground - truth. Moreover, the authors design a novel hybrid reward function that combines the generator and discriminator so that it encourages the model to perform both exploration of question sample and the visual hints via policy gradient. Experimental results on two benchmark datasets show that the proposed method outperforms the state - of - the - art approaches by a large margin on a variety of metrics."
SP:15756d6ef47b39ded404acea2135c93bd5ee1062,"This paper proposes Generalized Data Weighting ( GDW ) to mitigate label noise and class imbalance by manipulating gradients at the class level. To be specific, GDW unrolls the loss gradient to class - level gradients by the chain rule and reweights the flow of each gradient separately. Besides, the authors propose a two - stage scheme embedded in a bi - level optimization framework, which does not introduce any extra computational cost. Extensive experiments in various settings verify the effectiveness of GDW."
SP:7a8f56a01bec51ebf70d9ff689005a62cccfe5c6,"This paper proposes a new task to learn a truth function that predicts if a given sentence is true of temporally - extended observations of an agent interacting with a collection of objects. The authors use a synthetic language that is far from the richness of the natural language used by humans, but it is a good first step towards learning Embodied Language Grounding of spatio - temporal concepts. They train several models including multimodal Transformer architectures, the latter implement different attention computations between words and objects across space and time. They test models on two classes of generalization : 1 ) generalization to randomly held - out sentences ; 2 ) generalisation to grammar primitives. They observe that maintaining object identity in the attention computation of our Transformers is instrumental to achieving good performance on generalization overall, and that summarizing object traces in a single token has little influence on performance. They then discuss how this opens new perspectives for language - guided autonomous embodied agents."
SP:3d4a9d439bc84c3b0e6600f6985a23bdf95cd67f,"This paper proposes Prototypical Cross - Attention Network ( PCAN ) for multi - object tracking and segmentation. PCAN first distills a space - time memory into a set of prototypes and then employs cross - attention to retrieve rich information from the past frames. To segment each object, PCAN adopts a prototypical appearance module to learn contrastive foreground and background prototypes, which are propagated over time. Extensive experiments demonstrate that PCAN outperforms current video instance tracking / segmentation competition winners on both Youtube - VIS and BDD100 K datasets."
SP:1175ad16382b349ab1a39895150172d266abe571,"This paper studies the relationship between gradient flow and gradient descent in the context of deep learning. The main result is that gradient flow trajectories are well approximated by gradient descent, and that the degree of approximation depends on the curvature around the gradient flow trajectory. This finding allows to translate an analysis of gradient flow over deep linear neural networks into a guarantee that gradient descent efficiently converges to global minimum almost surely under random initialization. Experiments show that over simple deep neural networks, gradient descent with conventional step size is indeed close to gradient flow."
SP:b8412e9ce82ce92125fe7cd3aff7bea8b906d16e,"This paper considers a stochastic multi - armed bandit problem with delayed impact of actions. In this setting, actions taken in the past impact the arm rewards in the subsequent future. The authors generalize the bandit setting to encode the dependency of this “ bias ” due to the action history during learning. The goal is to maximize the collected utilities over time while taking into account the dynamics created by the delayed impacts of historical actions. They propose an algorithm that achieves a regret of Á(KT 2/3 ) and show a matching regret lower bound of $ O(\KT^2/3)$, where K is the number of arms and T is the learning horizon."
SP:9c1d678dff5f609197dc3cfb67b841827f4a439a,This paper proposes an end - to - end video instance segmentation method based on transformers. The main idea is to use the Transformer architecture to encode the context of each frame in order to improve the communication between frames. The proposed method is evaluated on the YouTube - VIS dataset and achieves state - of - the - art performance ( AP 42.6 on YouTube - VIT 2019 ) while having a considerably fast runtime ( 89.4 FPS ).
SP:6c922eaa358f6fb9771690b1240e4f6f08a35b69,"This paper proposes a new method for graph embedding based on random walks. The authors argue that random walks can be biased due to the structural properties of graphs. Most notably, random walks are biased by the degree of each node, where a node is sampled proportionally to its degree. To mitigate this bias, the authors propose a more general framework, residual2vec, that can also compensate for other systematic biases in random walks by using random graphs. They demonstrate that this debiasing not only improves link prediction and clustering performance but also allows us to explicitly model salient structural properties in Graph embedding."
SP:851eac96135b577a5014166edcb43db6a190cf4b,"This paper studies the problem of estimating non - linear functionals of discrete distributions in the context of local differential privacy. In this setting, the data are supposed i.i.d. to be distributed according to an unknown discrete distribution p = ( p1,..., pK ). Only α - locally differentially private ( DP ) samples z1,..., zn are publicly available, where the term ’ local ’ means that each zi is produced using one individual attribute xi. We exhibit privacy mechanisms ( PM ) that are sequentially interactive ( i.e. they are allowed to use already published confidential data ) or non - interactive. The paper describes the behavior of the quadratic risk for estimating the power sum functional Fγ = \K k=1 p \� k, \� > 0 as a function of K, n, and α. In the non - interactive case, the paper studies two plug - in type estimators of Fγ, for all $ \epsilon$-0 $, that are similar to the MLE analyzed by Jiao et al. [ 18 ] in the multinomial model. However, due to the privacy constraint the rates we attain are slower and similar to those obtained in the Gaussian model by Collier et al [ 9 ]."
SP:a0408b54f88a26479f33f36bb27e0a675f637ccd,"This paper studies the problem of online multiclass classification in a setting where the learner ’s feedback is determined by an arbitrary directed graph. In this setting, feedback graphs allow a much richer set of applications, including filtering and label efficient classification. For this new algorithm, the authors prove surrogate regret bounds that hold, both in expectation and with high probability, for a large class of surrogate losses. The bounds are of order B \sqrt{KT }, where B is the diameter of the prediction space, K is the number of classes, T is the time horizon, and ρ is the domination number. In the full information case, they show that GAPPLETRON achieves a constant surrogate regret of BK. They also prove a general lower bound of order max { BK, T } showing that their upper bounds are not significantly improvable. Experiments on synthetic data show that for various feedback graphs our algorithm is competitive against known baselines."
SP:490262589efce6fb10b913431ec6db8d4e5b2dec,"This paper studies the problem of explainable clustering in the setting first formalized by Dasgupta, Frost, Moshkovitz, and Rashtchian ( ICML 2020 ). A k - clustering is said to be explainable if it is given by a decision tree where each internal node splits data points with a threshold cut in a single dimension ( feature ), and each of the k leaves corresponds to a cluster. The authors give an algorithm that outputs an explainable cluster that loses at most a factor of O(log k ) compared to an optimal ( not necessarily explainable ) clustering for the k - median objective and a factor O(k log k ) for k - means objective. This improves over the previous best upper bounds of O(\sqrt{k}) and O(\k^2), respectively, and nearly matches the previous $ \Omega(k)$ lower bound. The algorithm is remarkably simple, and it is oblivious to the data points and runs in time O(dk log k, independent of the number of data points n )."
SP:6a9e47be710ddaf386bffc54d003d7dc2b67fdc3,"This paper proposes a multilingual pre - trained language model ( PrLM ) that supports both explicit universal dependency parsing and implicit language modeling. Syntax in terms of universal dependency parse serves as not only pre - training objective but also learned representation in our model, which brings unprecedented PrLM interpretability and convenience in downstream task use. The model outperforms two popular multilingual PrLM, multilingual - BERT and XLM - R, on cross - lingual natural language understanding ( NLU ) benchmarks and linguistic structure parsing datasets."
SP:94f4b65214a648cbc84f13beba45a825e2e9901a,"This paper proposes a new transformer - based model for vehicle routing problems. The proposed model is based on the Dual - Aspect Collaborative Transformer ( DACT ), which learns embeddings for the node and positional features separately, instead of fusing them together as done in existing ones, so as to avoid potential noises and incompatible correlations. The positional features are embedded through a novel cyclic positional encoding ( CPE ) method to allow Transformer to effectively capture the circularity and symmetry of VRP solutions ( i.e., cyclic sequences ). The authors train DACT using Proximal Policy Optimization and design a curriculum learning strategy for better sample efficiency. They apply DACT to solve the traveling salesman problem ( TSP ) and capacitated vehicle routing problem ( CVRP ). Results show that DACT outperforms existing Transformer based improvement models, and exhibits much better generalization performance across different problem sizes on synthetic and benchmark instances, respectively."
SP:e5c8680d8da9e7548fcb9bb5c073848eb80e1dd0,"This paper presents a method to estimate the exact Bayes error of generative models using normalizing flows. The method relies on the fact that the Bayesian error is invariant under the invertible transformation of the normalizing flow. The authors then use this invariance result to compute the exact error of the learned flow models by computing it for Gaussian base distributions, which can be done efficiently using Holmes - Diaconis - Ross integration. Moreover, the authors show that by varying the temperature of the trained flow models, they can generate synthetic datasets that closely resemble standard benchmark datasets, but with almost any desired Bayes errors. They use their approach to conduct a thorough investigation of state - of - the - art classification models, and find that in some — but not all — cases, these models are capable of obtaining accuracy very near optimal. Finally, they use their method to evaluate the intrinsic "" hardness "" of standard benchmark dataset, and ii ) hardness caused by the internal data distribution p."
SP:2896679f0472522bc3334178cd7574494cf12b7b,"This paper proposes a new initialization method for neural networks based on gradient - based initialization. The method is based on a simple heuristic that adjusts the norm of each network layer so that a single step of SGD or Adam with prescribed hyperparameters results in the smallest possible loss value. This adjustment is done by introducing a scalar multiplier variable in front of each parameter block, and then optimizing these variables using a simple numerical scheme. The authors show that the proposed method accelerates the convergence and test performance of many convolutional architectures, both with or without skip connections, and even without normalization layers. It also improves the stability of the original Transformer architecture for machine translation, enabling training it without learning rate warmup using either Adam or SGD under a wide range of learning rates and momentum coefficients."
SP:f69731403592fa5bdd4ca327708582d615aa131c,"This paper proposes a new approach to predict biomarker trajectories for Alzheimer's disease using longitudinal data. The proposed approach is based on Riemannian manifold embedding, where the data is embedded in a central geodesic and the trajectories are estimated using a diffeomorphism of the Euclidean metric. The authors propose to learn the metric as the push - forward of a kernel - based basis function. The method is evaluated on a synthetic dataset and a real - world ADNI dataset. The results show that the proposed method outperforms other methods on the ADNI datasets."
SP:438e906f52c4c0538956b51a2270b3ac498b27a8,"This paper proposes a routing - by - memory mechanism for existing CNN architectures. In each stage of the network, they introduce parallel Procedural Units ( PUs ). A PU consists of a memory head and a procedure. The memory head maintains a summary of a type of features. For an intermediate feature, we search its closest memory and forward it to the corresponding procedure in both training and testing. In this way, different procedures are tailored to different features and therefore tackle them better."
SP:d240173080cd3647dbaa5173a6422396f226775b,"This paper studies the equivariance properties of functions that are invariant to translation, rotation, reflection, boost, and other symmetries of physical laws. The authors show that it is simple to parameterize equivariant functions in terms of scalar products and scalar contractions of the scalar, vector, and tensor inputs. They also provide numerical experiments to support their theoretical results.   The authors also provide some numerical examples to show the effectiveness of their method."
SP:72c0f47566904deb27d8157da30807ec1d6b5685,"This paper proposes a generalization of the Intersection over Union ( IoU ) loss to a new family of power IoU losses with a single power parameter, called the α - IoU loss. The authors analyze the order preservingness and the loss / gradient reweighting properties of the proposed loss function and show that it can improve the bbox regression accuracy through up - weighting the loss and gradient of high IoU objects. Experiments on multiple detection models and benchmark datasets demonstrate that the proposed method outperforms existing IoU - based losses, especially at the high APs."
SP:397125177d7007316d67194ec00d5dc57b44ac79,"This paper proposes Distributionally Robust Imitation Learning ( DROIL ), a method for imitation learning where the reward function is not given, but demonstrations from experts are available. The authors show that DROIL can be seen as a framework that maximizes a generalized concept of entropy. They develop a novel approach to transform the objective function into a convex optimization problem over a polynomial number of variables for a class of loss functions that are additive over state and action spaces. Their approach lets us optimize both stationary and non - stationary policies and, unlike prevalent previous methods, it does not require repeatedly solving an inner reinforcement learning problem. They show the significant benefits of DROIL ’s new optimization method on synthetic data and a highway driving environment."
SP:58f220bbbed8d3e0633b408fca3b6838c4ad323d,"This paper proposes post - processing algorithms for individual fairness ( IF ), where the learner only has access to the predictions of the original model and a similarity graph between individuals guiding the desired fairness constraints. The authors cast the IF postprocessing problem as a graph smoothing problem corresponding to graph Laplacian regularization that preserves the desired “ treat similar individuals similarly ” interpretation. Theoretical results demonstrate the connection of the new objective function to a local relaxation of the individual fairness. Empirically, the proposed algorithms correct individual biases in large - scale NLP models such as BERT while preserving accuracy."
SP:ef791aa29decd839e7e583c9d1f71e8309ca87ef,"This paper proposes a structure - aware Dual Graph Aggregation Network ( SADGA ) for the cross - domain Text - to - SQL task. The authors adopt the graph structure to provide a unified encoding model for both the natural language question and database schema. Based on the proposed unified modeling, the authors further devise a structure-aware aggregation method to learn the mapping between the question - graph and the database - graph. The proposed method is featured with Global Graph Linking, Local Graph linking and DualGraph Aggregation Mechanism. The experimental results show that the proposed method achieves 3rd place on the challenging Text-to - SQL benchmark Spider."
SP:a2fa25a4539a38af61a0993f65ecc14339f26c2e,"This paper studies the problem of learning complex stochastic computations graphs with multiple discrete components. The authors show that it is challenging to optimize the parameters of these models, mainly due to small gradients and local minima. They then propose two new strategies to overcome these challenges. First, they show that increasing the scale parameter of the Gumbel noise perturbations during training improves the learning behavior. Second, they propose dropout residual connections specifically tailored to stochastically, discrete - continuous computation graphs. With an extensive set of experiments, the authors can train complex discrete - continuous models which one can not train with standard stochiastic softmax tricks."
SP:bb3ec363e90269db4a2ba99d8107cb56f86e68f0,"This paper studies the robustness of Bayesian neural networks ( BNNs ) to covariate shift. The authors show that BNN with Hamiltonian Monte Carlo ( HMC ) with Bayesian model average ( BMA ) does not generalize well under covariate shifts. They also show that the same issue does not affect other approximate inference procedures, or classical maximum a - posteriori ( MAP ) training. Finally, the authors propose novel priors that improve robustness to many sources of covariances shift."
SP:f86ec7042e9b73ae071704a6d3ed17d7e3da1b75,"In this paper, the authors categorize meta few - shot learning evaluation into two settings : in - distribution and out - of - distribution ( OOD ). In the ID setting, meta - learning methods that perform better on existing OOD datasets may perform significantly worse in the OOD setting. The authors identify that most existing FSL benchmarks instead reflect OOD evaluation, as they use disjoint sets of train ( base ) and test ( novel ) classes for task generation. This discrepancy is problematic because — as the authors show on numerous benchmarks — meta - learners that perform well on OOD data may perform worse on the ID data. In addition, the paper highlights concerns in 1 ) reliably performing model selection for a given meta learning method and 2 ) consistently comparing the performance of different methods. To address these concerns, they provide suggestions on how to construct FSL benchmark to allow for ID evaluation as well as more reliable OOD evaluations."
SP:371f77148b4f00a929f7c118b1bb7c5a6238d264,"This paper revisits the difference between KB - based and LM - based rule induction methods for rule generation. The authors argue that the KB method inducts rules by discovering data commonalities, while the LM method is "" learning rules from rules "", which limits these methods to only produce “ canned ” rules whose patterns are constrained by the annotated rules, while discarding the rich expressive power of LMs for free text. Therefore, the authors propose the open rule induction problem, which aims to induce open rules utilizing the knowledge in LMs. Besides, they propose the Orion system to automatically mine open rules from LMs without supervision. They conducted extensive experiments to verify the quality and quantity of the inducted open rules. Surprisingly, when applying the open rules in downstream tasks ( i.e., relation extraction ), these automatically inducted rules even outperformed the manually annotated rule."
SP:8be2e0ea4a83fe32a4859f456007a829e5e9270a,"This paper proposes Implicit Constraint Q - learning ( ICQ ), an offline RL algorithm for multi - agent off - policy reinforcement learning with finite data. The main idea of ICQ is to only trust the state - action pairs given in the dataset for value estimation. The authors extend ICQ to multi - agents tasks by decomposing the joint - policy under the implicit constraint. Experimental results show that ICQ can control the extrapolation error within a reasonable range under any number of agents and learn from complex multi -agent datasets."
SP:1939b24b68970c33ca16ce238deed257f76d009e,"This paper proposes a new adversarial perturbation method to improve the robustness of machine learning models against adversarial attacks. The main idea is to use non - uniform perturbations to generate adversarial examples that can better represent the feature dependencies during adversarial training. The authors propose using characteristics of the empirical data distribution, both on correlations between the features and the importance of the features themselves. They show that their approach is more robust to real - world attacks using experimental datasets for malware classification, credit risk prediction, and spam detection."
SP:417b30930b245667d777e5d90ee80dd41546760e,"This paper extends Tikhonov regularization to generalized self - concordant loss functions ( GSCs ), which contain the logistic loss. The main contribution of this paper is to show that the iterated Tikhanov ( IT ) regularization scheme, which is related to the proximal point method in optimization, overcomes the limitation of the classical Tikh on the difficulty of the learning task.   The main result is a probabilistic upper bound on the excess risk which is optimal given usual source and capacity conditions assumptions on the task. The paper also provides sufficient conditions to compute the estimator which is nontrivial by its sequential nature."
SP:1caeee4f00b52fe356ff4e5dd004d0203e838370,"This paper introduces a new kind of linear transform ( Deformable butterfly ) that generalizes the conventional butterfly matrices and can be adapted to various input - output dimensions. It inherits the fine - to - coarse - grained learnable hierarchy of traditional butterflies and when deployed to neural networks, the prominent structures and sparsity in a DeBut layer constitutes a new way for network compression. The authors apply DeBut as a drop - in replacement of standard fully connected and convolutional layers and demonstrate its superiority in homogenizing a neural network and rendering it favorable properties such as light weight and low inference complexity, without compromising accuracy. The natural complexity - accuracy tradeoff arising from the myriad deformations of a Debut layer also opens up new rooms for analytical and practical research."
SP:d345ce1d7afc367ee1a9fb68d50ff1b2219f02cb,"This paper proposes MetA Reusable Knowledge ( MARK ), a method to address the problem of catastrophic forgetting ( CF ) in continual learning. The proposed method is based on the construction and query of a Knowledge Base ( KB ) that uses metalearning to incrementally accumulate relevant knowledge from different tasks. The experiments show that the use of the KB is the crucial factor to mitigate CF. The authors also conduct ablation study to verify the effectiveness of the proposed method."
SP:722c52467e384058f8fdffa254d0e8db47440a64,"This paper proposes a data - driven framework for scheduling primal heuristics in a MIP solver such that the primal performance is optimized. Central to the approach is a novel formulation of the learning task as a scheduling problem, an efficient data collection procedure, and a fast, effective heuristic for solving the learning problem on a training dataset. A comprehensive experimental evaluation shows that the approach consistently learns heuristic schedules with better primal performance than SCIP’s default settings."
SP:5a21f0a49731dcb1d68deb06a75138e8e9d514d5,"This paper studies the problem of reinforcement learning in which the learner receives binary feedback only once at the end of an episode. The authors study the case where trajectory labels are generated by an unknown parametric model, and provide a statistically and computationally efficient algorithm that achieves sublinear regret.   The main contributions of the paper are :    1. The paper provides a theoretical analysis of the problem. 2. The algorithm is computationally and statistically efficient. 3. Under an explorability assumption, the authors prove that the algorithm can be computationally cost - efficient. 4. The algorithms are tested on synthetic data."
SP:e66bd9582058ba0f6091bb1042ce2ecfdaae1515,"This paper proposes a novel edge representation learning framework based on Dual Hypergraph Transformation ( DHT ), which transforms the edges of a graph into the nodes of a hypergraph. This dual hypergraph construction allows us to apply message - passing techniques for node representations to edges. After obtaining edge representations from the hypergraphs, we then cluster or drop edges to obtain holistic graph - level edge representations. The proposed method is evaluated on several graph reconstruction, generation, and classification tasks, showing its effectiveness over relevant baselines."
SP:e398873e29b05176e1d52dc6f86a59a4f405e6fd,"This paper studies the sufficiency of a state representation for learning and representing the optimal policy in the context of mutual information maximization ( MI ) in reinforcement learning. The paper provides a theoretical analysis of two popular MI objectives : 1 ) Mutual Information Maximization ( MIM ), where the objective is to maximise the mutual information between the agent and the MDP, and 2 ) mutual Information Minimization ( MNM ), which is to learn a representation of the state space of the agent. The theoretical analysis shows that these two objectives can yield insufficient representations given mild and common assumptions on the structure of MDPs. The experimental results corroborate the theoretical findings and demonstrate that the suiciency of a representation can have a substantial impact on the performance of an RL agent that uses that representation."
SP:50181f740910195d3a50dd7d7f8cbb1c476d730b,"This paper proposes Sparse Steerable Convolution ( SS - Conv ) for 3D object semantic analysis. The main idea is to use steerable convolution with sparse tensors, which preserves the property of SE(3)-equivariance. The authors propose a general pipeline for precise estimation of object poses, wherein a key design is a Feature - Steering module that takes the full advantage of SE - equivariance and is able to conduct an efficient pose refinement. Experiments on three tasks of 3D Object semantic analysis, including instance - level 6D pose estimation, category - level pose and size estimation, and category level 6d pose tracking, show the effectiveness of the proposed method."
SP:d746bfb200577c980d92727bb0b1a3c23e7bfdc5,"This paper proposes a dynamic token sparsification framework to prune redundant tokens progressively and dynamically based on the input. Specifically, they devise a lightweight prediction module to estimate the importance score of each token given the current features. The module is added to different layers to pruning redundant tokens hierarchically. To optimize the prediction module in an end - to - end manner, they propose an attention masking strategy to differentiably prune a token by blocking its interactions with other tokens. Benefiting from the nature of self - attention, the unstructured sparse tokens are still hardware friendly, which makes our framework easy to achieve actual speed - up. By hierarchically pruning 66% of the input tokens, our method greatly reduces 31% ∼ 37% FLOPs and improves the throughput by over 40 % while the drop of accuracy is within 0.5 % for various vision transformers."
SP:d0b6cde42b1cba5e6e3c7c5131426fd84adbd3d7,"This paper studies the problem of inference on the conditional mean E [ Y | X ], where the features X are continuously distributed. The authors consider the case where the feature X is finite in size, and the setting where X takes only a small number of possible values. In the finite setting, the authors show that any confidence interval for E [ X ] must have non - vanishing width, even as sample size tends to infinity. In contrast, in the continuous setting, they show that the vanishing - width confidence intervals are achievable if and only if the effective support size of the distribution of X is smaller than the square of the sample size. They also show that there are several distinct regimes in between the finite case and the continuous case, where vanishing width confidence interval is achievable if   support size is less than   $ \ell_2 $ square.   The authors also study the problem in settings in between these two extremes, where inference on E [ x ] is trivial to achieve."
SP:123952325765c040c3078fc7dca2b6d370e55590,"This paper proposes Representation Neutralization for Fairness ( RNF ), a method to reduce the discrimination of DNN models by only debiasing the classification head, even with biased representations as inputs. The key idea of RNF is to discourage the classification heads from capturing undesirable correlation between fairness sensitive information in encoder representations with specific class labels. To address low - resource settings with no access to sensitive attribute annotations, the authors leverage a bias - amplified model to generate proxy annotations for sensitive attributes. Experimental results over several benchmark datasets demonstrate the effectiveness of our RNF framework."
SP:210eb2c811f966bb1ac53932cacabbad9bb608fe,"This paper proposes a new type of convolutional layer that takes advantage of Bessel functions, well known in physics, to build Bessel - CNNs ( B - CNN ) that are invariant to all the continuous set of possible rotation angles by design. The authors define the problem of rotational invariance in CNNs and provide the necessary notations. Next, Section 3 presents the related works on bringing rotational    invariance into CNNs. The method, B -CNN, is then introduced in Section 4. Experiments are described and discussed in Section 5."
SP:ee51ecbd476d5b65903c942a62be89ff5d91698b,"This paper proposes a new large - scale solver for kernel ridge regression. The proposed method combines partitioning with random projections and iterative optimization to reduce space and time complexity while provably maintaining the same statistical accuracy. In particular, constructing suitable partitions directly in the feature space rather than in the input space, the authors promote orthogonality between the local estimators, thus ensuring that key quantities such as local effective dimension and bias remain under control. The authors characterize the statistical - computational tradeoff of our model, and demonstrate the effectiveness of our method by numerical experiments on large scale datasets."
SP:1f096d6fabd5b1fde43d06c552d46d87cd35cb4a,"This paper proposes a method to communicate among agents via discrete tokens. The authors use word embedding techniques from natural language processing to embed the tokens into a continuous space, which is then used to communicate with other agents. They show that their approach outperforms the standard one - hot communication strategy, which uses a single vector to communicate. They also provide a decision theoretic analysis of the value of such an approach. Finally, they demonstrate that agents using their method can effectively respond to novel human communication and that humans can understand unlabeled agent communication."
SP:8630ccc627534f9033bced04e2137a897ffef701,"This paper proposes to combine the strengths from both convolutional and transformer networks to create a new model called CoAtNet. The main idea is to combine depthwise convolution and self - attention layers in a principled way to improve the generalization, capacity and efficiency of the model. Experiments show that the proposed CoAtNets achieve state - of - the - art performance under different resource constraints across various datasets."
SP:d3ecbeeffa5ab365743ba8653c6739f24742ee31,"This paper presents a new second - order oracle bound for the expected risk of a weighted majority vote. The bound is based on a novel parametric form of the Chebyshev - Cantelli inequality, which is amenable to efficient minimization. The authors also derive a new concentration of measure inequality which combines PAC - Bayesian bounding with Bennett's inequality. The empirical evaluation shows that the new bounds can improve on the work of Masegosa et al. [ 2020 ]."
SP:5bac542a6532d43cf100e085398b4a4783719814,"This paper proposes a weakly - supervised audio - visual video parsing framework that leverages cross - video and cross - modality supervisory signals to facilitate weakly supervised video parsing. The proposed method exploits both the common and diverse event semantics across videos to identify audio or visual events. In addition, the proposed method explores event co - occurrence across audio, visual, and audio - video streams. Experiments on the benchmark dataset demonstrate that the proposed framework performs favorably against the state - of - the - arts in various settings."
SP:8fd6a03c1794afa524328d45f4232eacf6f86693,"This paper proposes a new federated learning algorithm called QuPeD for learning quantized and personalized models. The authors propose an alternating proximal gradient update for solving the compressed personalization problem, which allows clients to learn compressed personalized models with different quantization parameters and model dimensions/structures. In addition, the authors also formulate a compressed personalisation framework by introducing knowledge distillation loss for local client objectives collaborating through a global model. Numerically, the proposed algorithm outperforms competing personalized FL methods, FedAvg, and local training of clients in various heterogeneous settings."
SP:fca8b4f1e765cf1724a37f0ae9a7dac1cb79c8b1,This paper proposes a new framework for constrained clustering based on variational auto - encoder ( VAE ). The key idea is to use the prior clustering preferences to guide the clustering process towards a desirable partition of the data by indicating which samples should or should not belong to the same cluster. The proposed method is trained in the framework of stochastic gradient variational inference. The authors provide extensive experiments to demonstrate that DC - GMM shows superior clustering performances and robustness compared to other state - of - the - art deep clustering methods on a wide range of data sets.
SP:84379c0c881b7390ecc22fb398edfaf66d1af1ff,This paper proposes a method to speed up the learning of the Neural Tangent Kernel ( NTK ) and the convolutional NTK ( CNTK ). The main idea is to approximate the NTK matrix by sketching the polynomial expansion of the arc - cosine kernels. The sketching algorithm is based on the leverage score sampling. The authors also provide a spectral approximation guarantee for NTK. The proposed method is evaluated on CIFAR-10 and Cifar-100 datasets. The results show that the proposed method outperforms the original NTK and CNTKT.
SP:fa2668083ff3bb592c29a4c6822ae96ff54d0dbe,"This paper proposes a multi - range Transformers model for long - term 3D motion trajectory prediction. The proposed model consists of a local - range encoder for individual motion and a global - range decoder for social interactions. The decoder takes a pose as a query which attends to both local and global range features of the encoder. The model is evaluated on several datasets including CMU - Mocap, MuPoTS - 3D, 3DPW, and Panoptic datasets. The results show that the proposed model outperforms other state - of - the - art methods on long term motion prediction."
SP:0a0e07af37c8fe8580639b1df62d27b6f63f8dee,"This paper proposes a new approach, model predictive program synthesis ( MPPS ), that uses program synthesis to automatically generate the guiding programs for long - horizon planning problems. MPPS trains a generative model to predict the unobserved portions of the world, and then synthesizes a program based on samples from this model in a way that is robust to its uncertainty. Experimental results show that MPPS outperforms non - program - guided approaches on a set of challenging benchmarks, including a 2D Minecraft - inspired environment where the agent must complete a complex sequence of subtasks to achieve its goal."
SP:5bb42b178b0d27da271bfa60e633fdac718638c4,"This paper studies the problem of causal imitation learning in sequential settings, where the imitator must make multiple decisions per episode. The authors develop a graphical criterion that is necessary and sufficient for determining the feasibility of causal imitation learning. They provide an efficient algorithm to determine imitability and to find the policy for each action that leads to proper imitation. They prove that the proposed criterion is complete ( i.e., both necessary and necessary ). Finally, they verify that their approach compares favorably with existing methods in contexts where a demonstrator has access to latent variables through simulations."
SP:85bd81f0c5b6ccbc421ebbaf6f5c72164bc70b7f,"This paper presents a slot - wise, object - based transition model that decomposes a scene into objects, aligns them ( with respect to a slotwise object memory ) to maintain a consistent order across time, and predicts how those objects evolve over successive frames. The model is trained end - to - end without supervision using transition losses at the level of the object - structured representation rather than pixels. Thanks to the introduction of the novel alignment module, the model deals properly with two issues that are not handled satisfactorily by other transition models : object persistence and object identity. The authors show that the combination of an objectlevel loss and correct object alignment over time enables the model to outperform a state - of - the - art baseline, and allows it to deal well with object occlusion and re -appearance in partially observable environments."
SP:f32eddbb5c33a8422c075579ff08aa9833338d44,"This paper studies the problem of using adaptively collected data to minimize the average of a loss function over a hypothesis class in Empirical Risk Minimization ( ERM ). The authors propose a generic importance sampling weighted ERM algorithm, which uses the importance sampling structure to obtain rates with the good dependence on the exploration rate in the data. For regression, the authors provide fast rates that leverage the strong convexity of squared - error loss. For policy learning, they provide regret guarantees that close an open gap in the existing literature whenever exploration decays to zero, as is the case for bandit - collected data."
SP:f549a0c231b71bae0acbed6e3afb41890ee89cd9,"This paper proposes a novel and coherent scheme for kernel - reweighted regression by reparametrizing the sample weights using a doubly non - negative matrix. When the weighting matrix is confined in an uncertainty set using either the log - determinant divergence or the Bures - Wasserstein distance, the paper shows that the adversarially reweighting estimate can be solved efficiently using first - order methods. Numerical experiments show that the proposed re - weighting strategy delivers promising results on numerous datasets."
SP:fe12e13602925b9400fd596a987755beb10aa3d1,This paper proposes a method for training gradient estimators in the categorical setting. The method is based on importance sampling and statistical couplings. The main idea is to reparameterize the problem with a sequence of binary variables and perform Rao - Blackwellization. Experiments show that the proposed method outperforms RLOO in a variety of tasks.
SP:e16fdf963ec2f9c0d79fa404e47e7862a5d6e922,"This paper proposes a new predictor - based NAS framework that progressively shrinks the sampling space, by learning a series of weak predictors that can connect towards the best architectures. By co - evolving the sampling stage and learning stage, the proposed method can progressively evolve to sample towards the subspace of best architectures, thus greatly simplifying the learning task of each predictor. Extensive experiments on popular NAS benchmarks prove that the proposed framework is both sample - efficient and robust to various combinations of predictors and architecture encoding means. However, WeakNAS is still limited by the human - designed encoding of neural architectures."
SP:8f74abb04037ba2e59dcf8320dc555b149f68ed8,"This paper proposes a new intrinsic control method based on the Entropic Desired Dynamics for Intrinsic ConTrol ( EDDICT ). The key idea is to use a globally consistent coordinate system in the latent space of the agent to allow it to reach more states in the long term while still optimizing a local objective. The proposed method assumes a fixed additive latent dynamics, which results in tractable learning and an interpretable latent space. Compared to prior methods, the proposed method has improved state coverage and improved unsupervised performance on hard exploration games such as Montezuma ’s Revenge."
SP:c731a78c3e7f98ccd0253b51a0d42bf8deeb71f9,"This paper proposes a novel approach to generate chemically realistic and pharmacochemically acceptable molecules for drug design. The authors propose a fragment - based generative RL with Explorative Experience Replay for Drug design ( FREED ), which constrains the generated molecules to a realistic and qualified chemical space and effectively explores the space to find drugs by coupling our fragment-based generation method and a novel error - prioritized experience replay ( PER ). They also show that their model performs well on both de novo and scaffold - based schemes. Their model produces molecules of higher quality compared to existing methods while achieving state - of - the - art performance on two of three targets in terms of the docking scores."
SP:b938bca513e7de1231212064caf8877a78d8b612,"This paper studies the problem of learning directed acyclic graphical models from observational data in general settings without specific distributional assumptions. The approach is information - theoretic and uses a local Markov boundary search procedure in order to recursively construct ancestral sets in the underlying graphical model. The authors show that for certain graph ensembles, a simple forward greedy search algorithm ( i.e., without a backward pruning phase ) suffices to learn the Markov boundaries of each node. This substantially improves the sample complexity, which is at most polynomial in the number of nodes. This is then applied to learning the entire graph under a novel identifiability condition that generalizes existing conditions from the literature. As a matter of independent interest, the authors establish finite - sample guarantees for the problems of recovering Markov Boundaries from data. Moreover, they apply their results to the special case of polytrees, for which the assumptions simplify, and provide explicit conditions under which polytree are identifiable and learnable in polynuously time."
SP:af08109d4c45dc9401efb0e63c22167e9da28adb,"This paper studies the problem of learning with differential privacy ( DP ) in the setting where each user has a single sample and the privacy protection is enforced at the level of each user ’s data. In this setting, the authors show that, as long as each user receives sufficiently many samples, we can learn any privately learnable class via an (, )DP algorithm using only O(log(1/\sqrt{d } / ) users ). The authors also show that this is the case even in the local model, where d is the probabilistic representation dimension. In both cases, they show a nearly - matching lower bound on the number of users required. A crucial component of their results is a generalization of global stability [ BLM20 ] that allows the use of public randomness. Under this relaxed notion, they employ a correlated sampling strategy to show that the global stability can be boosted to be arbitrarily close to one, at a polynomial expense."
SP:da4f21d107a7f442c4d3e3ec13bdb44b041e07cf,"This paper provides a theoretical analysis of the properties of end - to - end model - based value iteration networks ( VINs ) in the context of reinforcement learning. In particular, the authors consider the case where the value function is parameterized by an implicit parameterization of a linear function. The authors show that, for a linear parametrization, gradient descent converges to global optima despite non - linearity and non - convexity introduced by the implicit representation. Furthermore, they derive convergence rates for both cases which allow them to identify conditions under which stochastic gradient descent ( SGD ) with this implicit representation converges substantially faster than its explicit counterpart. Finally, they provide empirical results in some simple domains that illustrate the theoretical findings."
SP:992aa07d4f815d1c81f967374590eece933833b1,"This paper proposes an approach to clean up the noise in Knowledge Graphs ( KGs ) through KG refinement task. The authors propose to use PSL - KGI to clean KGs and KG embeddings such as ComplEx and ConvE which do not make use of the ontological information to improve the quality of predictions, and also the power of KGs to perform longer chains of reasoning. The proposed approach, called IterefinE, operates in a co - training mode and results in explicit type - supervised embedding of the refined KG from PSL-KGI which they call as TypeE - X. The experiments over a range of KG benchmarks show that the embedding that they produce are able to reject noisy facts from KG and at the same time infer higher quality new facts."
SP:676fc4a3041af22e8f20ccba7daa2a0b1f5d6af5,"This paper proposes a new benchmark for knowledge base completion ( KB ). The authors argue that the current ranking - based evaluation paradigm for KB does not reflect the actual KBC quality, and propose a novel evaluation paradigm, designed to provide more transparent model selection criteria for a realistic scenario. They construct the data set FB14k - QAQ with an alternative evaluation data structure : instead of single facts, they use KB queries, i.e., facts where one entity is replaced with a variable, and construct corresponding sets of entities that are correct answers. This way, they can explicitly measure a model ’s ability to handle queries that have more correct answers in the real world than in the KB, including the special case of queries without any valid answer. They evaluate a number of state - of - the - art KB embeddings models on our new benchmark."
SP:83fe0a496a79bcf97ccba1c6d34b7d11e7d5c330,"This paper proposes a simple, general, and effective framework : Alternating Roles Dialog Model ( ARDM ). ARDM models each speaker separately and takes advantage of the large pretrained language model. It requires no supervision from human annotations such as belief states or dialog acts to achieve effective conversations. It outperforms or is on par with state - of - the - art methods on two popular task - oriented dialog datasets : CamRest676 and MultiWOZ. Moreover, it can generalize ARDM to more challenging, non - collaborative tasks such as persuasion."
SP:b11c06b7c4ef1aa43c59f808a679425e302d158e,"This paper proposes a new confidence measure for predicting the top k-1 or top k - 5 uncertainty for image classification. The authors use the notion of implied loss and prove that if an uncertainty measure is an implied loss, then low uncertainty means high probability of correct ( or in the Top k ) classification on the test set. They demonstrate empirically that these values can be used to measure the confidence that the classification is correct. Their method is simple to use on existing networks : they proposed confidence measures for Top k which can be evaluated by binning values on the Test set. For methods which are already quite accurate, as is the case for top 1 or top 5 uncertainty in image classification, the proposed method can be easily used."
SP:ab9666e15f2a0113d96cb4b47b1cbb30fa1f7982,"This paper studies the generalization properties of wide neural networks at large depth. The authors use the Neural Tangent Kernel ( NTK ) to show that in the large depth limit the spectrum of the NTK simplifies in much the same way as that of the NNGP kernel. By analyzing this spectrum, the authors arrive at a precise characterization of trainability and a necessary condition for generalization across a range of architectures including Fully Connected Networks ( FCNs ) and Convolutional Neural Networks ( CNNs ). In particular, they find that there are large regions of hyperparameter space where networks can only memorize the training set in the sense they reach perfect training accuracy but completely fail to generalize outside the training data. By comparing CNNs with and without - global average pooling, they show that CNNs without averaging pooling have very nearly identical learning dynamics to FCNs and convolutional neural networks."
SP:d3470c35aae48bf92439a55fdb98ccf07100e567,"This paper presents Graph Convolutional Networks ( GCN ) for protein quality assessment ( QA ). GCN is a graph - based method to estimate the quality of protein models. The authors show that GCN can capture the benefits of previous QA methods including representation learning, geometric invariance, explicit modeling of sequential and 3D structure, simultaneous local and global scoring, and computational efficiency. Through extensive experiments, they show significant improvements over the state - of - the - art, and offer informative qualitative and quantitative analyses."
SP:5188280131b58a35d3deda126a0754aea8fa6e58,"This paper studies the loss landscape of linear neural networks with different loss functions and different parameterizations. In particular, the authors study the critical locus of the loss function of a neural network is determined by the geometry of the functional space and by the parameterization of this space by the network ’s weights. They introduce a natural distinction between pure critical points, which only depend on the function space, and spurious critical points which arise from the parameterisation. They apply this perspective to revisit and extend the literature on the loss functions of linear networks. For this type of network, they use geometric properties of determinantal varieties to derive new results on the landscape. Their analysis clearly illustrates that the absence of “ bad ” local minima in the loss landscapes of linear linear networks is due to two distinct phenomena that apply in different settings : it is true for arbitrary smooth convex losses in the case of architectures that can express all linear maps ( “ filling architectures ” ) but it holds only for the quadratic loss when the functional spaces is a determinantial variety ( non - filling architectures ). Without any assumption on the architecture, smooth conveX losses may lead to landscapes with many bad minima."
SP:ee71597ceab23eb4db1d6608f15f80ad51f7ff6d,"This paper proposes a framework SEED ( Sampling, Encoding, and Embedding Distributions ) for inductive and unsupervised representation learning on graph structured objects. Instead of directly dealing with the computational challenges raised by graph similarity evaluation, given an input graph, the SEED framework samples a number of subgraphs whose reconstruction errors could be efficiently evaluated, encodes the subgraph samples into a collection of subGraph vectors, and employs the embedding of the subGraph vector distribution as the output vector representation for the input graph. By theoretical analysis, the authors demonstrate the close connection between SEED and graph isomorphism. The experimental results show that the proposed framework is effective, and achieves state - of - the - art predictive performance on public benchmark datasets."
SP:d9406fdf0a180a5efc6f15ba8739524665f0f9d2,This paper proposes a new Counterfactual regret minimization ( CFR ) algorithm that avoids traversing the whole game tree in each round. The authors prove that the regret of Lazy - CFR is almost the same as that of the vanilla CFR and only needs to visit a small portion of the game tree. They also show that the same idea can also be applied to CFR+ and the resulting algorithm can be directly applied to Lazy-CFR+. Experiments on Leduc Hold’em and heads - up flop hold ’em poker show the effectiveness of the proposed algorithm.
SP:023aa3dca1cf7992b22993a7088e8a74c92bb47e,"This paper proposes a method for Unsupervised Domain Adaptation ( UDA ) where the feature distribution of the source and target data is modeled as Gaussian mixture distributions. The authors propose two new domain discrepancy losses based on the Gaussian component distributions of the deep features called Gaussian Component Mean Matching ( GCMM ) and Pseudo Distribution Matching, which minimizes the negative log likelihood of generating the target features from the source feature distribution. Extensive experiments on Digits Image transfer tasks and synthetic - to - real image transfer task demonstrate the effectiveness of the proposed method."
SP:40be996e8bb86e887077b762b87c7c34a786ac98,"This paper proposes InfoCNF, an efficient conditional continuous normalizing flow ( CNF ) model that partitions the latent space into a class - specific supervised code and an unsupervised code that is shared among all classes for efficient use of labeled information. Since the partitioning strategy ( slightly ) increases the number of function evaluations ( NFEs ), the authors also employ gating networks to learn the error tolerances of its ordinary differential equation ( ODE ) solvers for better speed and performance. The authors show empirically that InfoC NF improves the test accuracy over the baseline while yielding comparable likelihood scores and reducing the N FEs on CIFAR10."
SP:97764e3393216106ff2ac3f550845acf4636119f,"This paper studies the convergence properties of the TD learning algorithm for value function approximation in reinforcement learning with non - linear functions. The authors consider the problem under a certain scaling of the approximating function, leading to a regime called lazy training. In this regime the parameters of the model vary only slightly during the learning process, a feature that has recently been observed in the training of neural networks, where the scaling arises naturally, implicit in the initialization of their parameters. Both in the under and over - parametrized frameworks, the authors prove exponential convergence to local, respectively global minimizers of the above algorithm in the lazy training regime. They then give examples of such convergence results in the case of models that diverge if trained with non-lazy TD learning."
SP:c518e4030f12b0f59ad1d7c0fc0ebd313c68ef95,"This paper presents a method to train an agent that can generate observations that can help predict whether a hypothesis about the dynamics of the world is true or false. The method is based on the observation that agents trained end - to - end with the reward fail to learn to solve this problem. To address this problem, the authors propose to use a triplet structure in the majority of hypotheses that can be formulated as triplets ( pre - condition, action sequence, post - condition ). Once the agents have been pretrained to verify hypotheses with this structure, they can be fine - tuned to verify more general hypotheses."
SP:6fa2f842b1bc993ed8024a3ce13dbd91529c61be,"This paper studies the feasibility of performing complex reasoning for mathematical formulas in a fixed ( 1024 dimensional ) dimensional embedding space. The authors train a neural network to map mathematical formulas into a latent space of fixed dimension by predicting whether a given rewrite is going to succeed ( i.e., returns with a new formula ). For successful rewrites, the authors also predict the latent representation of the resulting formula. The experiments show that graph neural networks can make non - trivial predictions about the rewrite - success of statements, even when they propagate predicted latent representations for several steps."
SP:a77ab500a5e7d4ea8430871d1e603941e92974fd,"This paper proposes a method to learn depth estimation from images. The method is inspired by natural agents, who interact with the environment via visual and haptic feedback. The authors propose a global - local network architecture to learn the depth from images and very sparse ground truth measurements. The proposed method is evaluated on several synthetic and real - world datasets. The results show that the proposed method outperforms the state - of - the - art methods."
SP:2afba5e24478da4e9d493887c7cf00e288cc0deb,"This paper proposes to use a Transformer - based model for the task of hashed word embedding. The proposed method is based on the idea of word pieces in natural language models. The key idea is to apply hash functions to map each id to multiple hash tokens in a much smaller space, similarly to a Bloom filter. The authors show that by applying a multi - layer Transformer to these Bloom filter digests, they are able to obtain models with high accuracy. They outperform models of a similar size without hashing and, to a large degree, models of larger size trained using sampled softmax with the same computational budget."
SP:745dd86d7f7bba79a02d27922003b764b620f83e,"This paper proposes a method for zero - shot 3D shape part discovery for objects in unseen categories. The proposed method is based on a learning based agglomerative clustering framework, which learns a grouping policy to progressively group small part proposals into bigger ones in a bottom - up fashion. The key idea is to restrict the local context for extracting part - level features, which encourages the generalizability to unseen categories, and to transfer the geometry prior of parts learned from 3 training categories to 21 unseen testing categories without seeing any annotated samples. Experiments on the PartNet dataset show that the proposed method achieves the state - of - the - art performance."
SP:868fc6df740b04963442d5abcfe2f4845585cfc8,"This paper proposes a technique called "" neuron editing "" that learns how neurons encode an edit for a particular transformation in a latent space. The authors use an autoencoder to decompose the variation within the dataset into activations of different neurons and generate transformed data by defining an editing transformation on those neurons. By performing the transformation in the latent space, the authors encode fairly complex and non - linear transformations to the data with much simpler distribution shifts to the neuron ’s activations. This technique has the advantage of being generally applicable to a wide variety of data domains, modalities, and applications.   The authors first demonstrate it on image transformations and then move to two main applications in biology : removal of batch artifacts representing unwanted noise and modeling the effect of drug treatments to predict synergy between drugs."
SP:6dee6932e64fe47bb44dd42fc242fa9d89b8d89c,"This paper proposes a method to learn the initializations for deep neural networks for few - shot image segmentation tasks. The authors propose a method based on first - order meta - learning, where a neural network is first trained on a large dataset and then used to learn a new initialization for a new task. The proposed method is based on the FOMAML algorithm, which is a model - agnostic approach. The paper also proposes a new neural network architecture for parameter efficiency and fast learning, called EfficientLab, and a new benchmark dataset, FP - k, for the empirical study of how the proposed method performs in both few-shot and many - shot settings. Experimental results show that the proposed approach outperforms random and ImageNet - trained initializations."
SP:ec6f390f6d45fb79c33ae5d9c8a24cadb96fbd60,"This paper proposes a new method for semi - supervised few - shot learning ( SS - FSL ) based on Prototypical Networks ( PN ). The proposed method is based on the notion of prototypical random walk ( PRW ), which is used in PN. The authors show that PRW can be used to learn representations that are compact and well - separated. They also show that it is robust to distractors, unlabeled data that does not belong to any of the training classes, and hence reflects robustness to labelled / unlabelled class distribution mismatch."
SP:d12e687bd2ee9fa60554312e644bb0a6487974f1,"This paper proposes Contrastive Sensor Fusion ( CSF ), a new self - supervised training objective to learn fused representations of multiple overhead image sources. CSF uses a contrastive loss to train an encoder that can produce a shared representation from any subset of available channels across multiple sensors. Using a dataset of 47 million unlabeled coterminous image triplets, CSF is trained to produce semantically meaningful representations from any possible combination of channels from the input sensors. Experiments show that CSF outperforms fully - supervised ImageNet weights on a remote sensing classification task and improve as more sensors are fused."
SP:4d8e054f07006b4f896721b5c24da805727d2c22,"This paper proposes weight rewinding, an alternative to the standard fine - tuning method for neural network pruning. The authors argue that weight reweighing can be used to train the network to completion, remove unwanted structure, compress the network, and then retrain the remaining structure to recover the accuracy. They compare their method with several state - of - the - art pruning techniques, including fine - tuned, weight rewind, and learning rate reweIGHING. They show that their method outperforms the other methods in accuracy and compression ratio."
SP:3bb1c79f9482e09828eda45fbb2e654f37219365,"This paper studies the relationship between output margin and generalization in deep neural networks. The authors propose to analyze the notion of margin, which they call the "" all - layer margin "", and show that it has a clear and direct relationship with generalization for deep models. They then propose a training algorithm that encourages a larger all -layer margin and demonstrate that it improves empirical performance over strong baselines. They apply their regularizer to WideResNet models ( Zagoruyko and Komodakis, 2016 ) trained on CIFAR datasets and demonstrate improved generalization performance for both clean and adversarially robust classification."
SP:3d44f27468087280e85dfb1fc7291db05179fe6d,"This paper proposes to use knowledge - grounded dialogues as training data for dialogue generation. The authors propose a disentangled response decoder to isolate the parameters that depend on knowledge - grounded dialogues from the entire generation model. The key idea is to use unstructured dialogues and documents to train the decoder. The proposed method is evaluated on two benchmarks. The results show that with only 1/8 training data, the model can achieve the state - of - the - art performance and generalize well on out - of domain knowledge."
SP:9b555f7fe743f5effdbdc8701ed519ce3159c4b0,"This paper proposes the mirror - generative NMT ( MGNMT ), a single unified architecture that simultaneously integrates the source to target translation model, the target to source translation model and two language models. The main idea is that the translation models and language models share the same latent semantic space, therefore both translation directions can learn from non - parallel corpora more effectively. The paper conducts extensive experiments on a variety of language pairs and scenarios, including resource - rich and low - resource situations. The results show that the proposed model achieves competitive performance on parallel bilingual data, while it does advance training on non - parallel data."
SP:d7a530a0ec4112095a58cef4cda9646f8ca6449d,"This paper investigates the role of the entropy term in the performance of the Soft Actor Critic ( SAC ) algorithm on Mujoco tasks. The authors show that the entropy is the primary contribution of the SAC algorithm to maintain satisfactory exploration in the presence of bounded action spaces. Based on this insight, the authors propose a new algorithm that does not employ entropy maximization but nevertheless matches the sampling efficiency and robustness performance of SAC for the Mujococo benchmarks. The experimental results demonstrate a need to revisit the benefits of entropy regularization in DRL."
SP:545e8da553fcb47d84eaa044d8a4947d3cd3230e,"This paper studies the vulnerability of copyright detection systems to adversarial attacks. The authors propose a simple method to generate adversarial perturbations that can be used to fool the system. The method is based on a well - known music identification method that uses a neural network to generate the perturbation, which is then fed to the system using gradient methods. The paper shows that this method is particularly vulnerable to attacks, especially for neural network based systems. It also shows that attacks on this model can transfer well to online systems."
SP:b511822850da3bf1079a36ed6f5ad4db80fbc424,"This paper proposes a new metric learning framework that uses point - to - point activation maps between two images to provide a visual explanation for deep metric learning and its applications. The proposed method is based on cosine similarity, which is a well - known metric in metric learning. The authors show that the proposed framework can be directly deployed to a large range of metric learning applications and provides valuable information for understanding the model. The experiments show its effectiveness on two potential applications, i.e. cross - view pattern discovery and interactive retrieval."
SP:67bf71219fe6bedec5f5525200e734638e4a6ca2,"This paper proposes a new algorithm, AOP, that combines model - based planning and model - free policy learning to improve the performance of a continual learning agent in the online lifelong learning setting. The main idea of AOP is to use the planner to estimate the current state of the environment, and the policy to adapt based on this information. AOP uses the planner as a model to predict the future performance of the policy, while the policy is learned using the planner. The paper also proposes an evaluation environment to evaluate the effectiveness of the proposed algorithm. Experiments show that AOP outperforms the state - of - the - art in the task of continual learning."
SP:11159cb878a436a5d4fc6edb4132f2cc3c1b3f72,"This paper proposes to replace the traditional softmax attention mechanism in image captioning models by two alternative sparsity - promoting transformations : sparsemax and TVMAX. With sparsemax, we obtain sparse attention weights, selecting relevant features. With TVMAX, we select relevant features by selecting relevant groups of features. The experimental results show that TVMAX outperforms the other compared attention mechanisms in terms of humanrated caption quality and attention relevance."
SP:fb0c3ce3db6ad674ddc615bdc6203cdcbe42c804,"This paper proposes a model to predict the evolution of dynamic graphs. The authors use a graph neural network and recurrent architecture to capture the temporal evolution patterns of dynamic graph. Then, they employ a generative model which predicts the topology of the graph at the next time step and constructs a graph instance that corresponds to that topology. They evaluate the proposed model on several artificial datasets following common network evolving dynamics, as well as on real - world datasets."
SP:ff722957a1765c0568426ed88dd910a6b74054ef,"This paper proposes Generative Imputation and Stochastic Prediction ( GI ) as a novel approach to impute missing values and to measure class uncertainties arising from the distribution of missing values. The proposed method is based on neural networks trained using an adversarial objective function. Specifically, a generator network is trained to generate imputations that a discriminator network is tasked to distinguish. Following this, a predictor is trained using the imputed samples from the generator network to capture the classification uncertainties and make predictions accordingly. The experimental results show the effectiveness of the proposed method in generating imputations as well as providing estimates for the class uncertainties in a classification task when faced with missing data."
SP:c051b0fe779d9e4131016970b7ba469b596f3009,"This paper proposes a new method for long - horizon off - policy estimation. The main idea is to use RKHSs to estimate the importance ratio of a fixed point of a "" backward flow "" operator. The proposed method is evaluated on a synthetic dataset and a real - world dataset. The paper shows that the proposed method outperforms the baselines in terms of importance ratio and finite sample generalization."
SP:065c900843011a71b70ed35357a2f71fe83872a7,"This paper proposes a method to model the Gaussian mixture model ( GMM ), which is a probabilistic framework that allows us to define a dataset containing K different Gaussians. In the GMM framework, it is possible to compute the conditional likelihood p(x|k, \tilde{x }, \theta ) which describes the distribution index corresponding to the data. However, the Euclidean distances between the data do not allow them to form mixtures naturally, and it is not feasible to compute p(k|x, \ta ) explicitly, making GMM unable to apply. To solve this problem, this paper proposes to use the GAN framework to compute these probabilities at the data ’s latent space z instead of x, where z is the corresponding latent representation of the data, through an additional classification network which is trained with GAN in an “ end - to - end ” fashion. Experiments show that the proposed method surpasses previous baselines in terms of the image generation performance with only minor growth on the size of the network."
SP:2da1608209058d214f8671062cc9eb0833ba4831,"This paper proposes a method to train large capacity neural networks with improved accuracy and lower dynamic computational cost by gating the deep - learning architecture on a fine - grained - level. Individual convolutional maps are turned on/off conditionally on features in the network. To achieve this, the authors introduce a new residual block architecture that gates convolutionsal channels in a fine-grained manner. They also introduce a generally applicable tool batch - shaping that matches the marginal aggregate posteriors of features in a neural network to a pre - specified prior distribution. They use this novel technique to force gates to be more conditional on the data. They present results on CIFAR-10 and ImageNet datasets for image classification, and Cityscapes for semantic segmentation. Their results show that their method can slim down large architectures conditionally, such that the average computational cost on data is on par with a smaller architecture but with higher accuracy."
SP:f90e9f0eb53f92601bdfa3f7bf86f71d037aad30,"This paper proposes a probabilistic importance inference approach for pruning DNNs. Specifically, they test the significance of the relevance of a connection in a DNN to the DNN ’s outputs using a nonparemetric scoring test and keep only those significant ones. Experimental results show that the proposed approach achieves better lossless compression rates than existing techniques."
SP:64cbbb6a2f6847ef71cd5a23ba3e4cc5c815a56e,"This paper proposes a method to learn hierarchical representations of actions by iteratively compressing action trajectories to learn nested behavioral hierarchies of arbitrary depth, with actions of arbitrary length. The proposed method is inspired by the Nevill - Manning algorithm, which computes the minimum - description - length codes of sequences of actions through iterative convolutional sparse coding and compression, with structure similar to classic string compression methods. The authors demonstrate the relevance of this approach for tasks with non - trivial hierarchical structure and show that the approach can be used to accelerate learning in recursively more complex tasks through transfer."
SP:e1ccfb3a684aef8a0fb36194eb16af1667811e81,"This paper proposes a new generative model, the Hierarchical Bayes Autoencoder ( HBAE ), which uses an energy - based model ( EBM ) instead of the commonly adopted unimodal Gaussian distribution for the decoder. The proposed model is trained using variational inference, similar to a VAE, to recover latent codes conditioned on inputs. The decoder is also trained using an adversarial approximation where a conditional generator is trained to match the EBM distribution. The paper shows that the proposed model can generate plausible variations consistent with the input data, and generates realistic unconditional samples. In addition, the paper proposes an extension to model sets of inputs, allowing a finer degree of semantic control over sampling behavior, and a new method for few - shot classification of sets."
SP:1130a391afa30d1e0fddadedd2a3aaa70a4cb751,"This paper proposes a new normalization technique for off - policy temporal difference ( TD ) algorithms. The proposed normalization is based on a mixture of on - policy and off policy transitions, which the authors call cross - normalization. The authors show that the proposed method improves the performance of DDPG and TD3 on a range of MuJoCo benchmark tasks.   The authors also evaluate the effect of normalization in the context of linear function approximators."
SP:f9cafaa5131176290fa069e6d24046c079cd9eea,"This paper proposes a bias - resilient neural network ( BR - Net ) to learn discriminative features unbiased and invariant to the confounder(s ) in the data. The main idea is to use adversarial training strategy to learn features that are not correlated with the bias or confounding variables in the study. The proposed method is evaluated on synthetic data, medical images, and a gender classification dataset. The results show that the learned features by the method not only result in superior prediction performance but also are uncorrelated with the biases or confounders variables."
SP:783049ff463edd1283c058c6106a3e1f9a033df4,"This paper proposes a lightweight Transformer - based model for character - level language modeling. The authors propose a lightweight model, called GroupTransformer, that factorizes the calculation paths by grouped embedding operators. Additionally, Group - Transformer employs inter - group linear operators to prevent performance degradation from the group strategy. Extensive experiments on two benchmark datasets, enwik8 and text8, show the effectiveness of the proposed model."
SP:946c26d371297c88d0ac246257104099b4585edc,"This paper proposes a novel objective function for training generative models with deep hierarchies of latent variables using Optimal Transport ( OT ). The objective function is based on the Wasserstein distance as the regularisation divergence, allowing the stacking of WAEs for arbitrarily deep - latent hierarchies. The authors show that this approach enables the learning of smooth latent distributions even in deep latent hierarchies, which otherwise requires extensive model design and tweaking of the optimisation procedure to train. They also show that their approach is significantly more effective at learning smooth hierarchical latents than the standard WAE."
SP:309b47441d227ffa33f96f9f16f2addc607e5bb0,"This paper presents an autoregressive video generation model based on a three - dimensional self - attention mechanism. The proposed method is based on block - local attention ( BLEU ), which can be implemented efficiently on TPUs. The authors show that the proposed method can achieve state - of - the - art results across a range of video generation benchmarks, while the scalability of the approach enables the authors to make an initial attempt at modeling videos of unusually high complexity and diversity as found in the Kinetics dataset."
SP:ad8fcdbc47a50dd2bf58aba2bc6cfe199e84dd4d,This paper proposes an adversarial generative model for the generalized zero - shot learning on multi - label text classification. The proposed method is based on the hierarchical structure of ICD codes to generate semantically meaningful features for zero shot codes without any labeled data. The paper also proposes a novel pseudo cycle generation architecture to guarantee the semantic consistency between the synthetic and real features by reconstructing the relevant keywords in input documents. Extensive experiments demonstrate the effectiveness of the proposed method on the public MIMIC - III dataset.
SP:3ce82ae297e5759ab957babe9927062e7a71b0ba,"This paper proposes a forward prediction objective for simultaneously learning embeddings of states and action sequences to improve sample efficiency in reinforcement learning ( RL ). The key idea is to learn a representation of the dynamics of the state space, which is then used to predict the action sequence. The action sequence embedding is learned by using the learned embedding of the action sequences, and the state embedding by learning the action embedding from pixel observations. The proposed method is evaluated on a simple family of goal - conditioned 2D control tasks. The results show that the proposed method improves the sample efficiency of model - free RL on control from low - dimensional states."
SP:11ce1616e721340eea9e80dad7460c77355ac7d1,"This paper proposes an automated relational meta - learning ( ARML ) framework that automatically extracts the cross - task relations and constructs the meta - knowledge graph. When a new task arrives, it can quickly find the most relevant structure and tailor the learned structure knowledge to the meta-learner. The proposed framework not only addresses the challenge of task heterogeneity by a learned meta-knowledge graph, but also increases the model interpretability. The experiments demonstrate the effectiveness of the proposed algorithm."
SP:37c209cd1c628b5c2f2b282fbeaf4bbf437c7670,This paper proposes a plug and play language model ( PPLM ) that combines a pretrained LM with one or more simple attribute classifiers that guide text generation without any further training of the LM. The authors propose a forward and backward pass in which gradients from the attribute model push the LM ’s hidden activations and thus guide the generation. The experimental results show that the proposed method can control a range of topics and sentiment styles and extensive automated and human annotated evaluations show attribute alignment and fluency.
SP:12d0980bfea2de880905a0b87b40856969bb1c58,"This paper proposes a novel unsupervised representation learning method based on denoising autoencoder ( DAE ). In contrast to conventional DAE, the corrupted data input to the proposed DAE is produced with the aid of a Laplacian pyramid. By adding corruptions to randomly chosen levels in the pyramid, the resulting data corruptions spans multiple scales across the original data space. From this, the network is forced to learn to represent underlying data structures across multiple scales. Experiments on several visual benchmarks demonstrate that better representations can be learned with the proposed approach, compared to its counterpart with single - scale corruption. Furthermore, the learned representations perform well when transferring to other vision tasks."
SP:12afc1b259e51a31cbeb72366d2b93fbee1aafaa,This paper addresses the problem of under - sensitivity of neural networks in natural language inference. The authors propose to use interval bound propagation ( IBP ) to verify the robustness of the decomposable attention model ( DMA ) in the context of NLI. The main idea of the paper is to use IBP to verify that the model does not become more confident in its predictions as input text is deleted. The proposed method is evaluated on the SNLI and MNLI datasets and compared with standard training methods.
SP:14257af9fe83522c6e5b5d6b0d68945b944e30fb,"This paper studies the problem of model - free off - policy deep reinforcement learning with replay memory. The authors show that the replay memory only holds a finite number of transitions, and link its structure to soft divergence. To address this issue, the authors construct a simple Markov Decision Process ( MDP ) for which exact Q - values can be computed efficiently as more data comes in, resulting in a QGRAPH. The Q - value for each transition in the simplified MDP is a lower bound of the Q -value in the original continuous Q - learning problem. By using these lower bounds in TD learning, the proposed method is less prone to soft divergences and exhibits increased sample efficiency while being more robust to hyperparameters."
SP:c92c97e47d8b218dfd009bbf61f5b3547b395f91,"This paper studies the effect of the embedding complexity of multilayer neural networks ( MLNs ) on the performance of unsupervised domain adaptation ( UDA ). In particular, the authors analyze the impact of the complexity of the encoder and decoder layers on the risk of UDA in the target domain. The authors find that the complexity tradeoff between the two layers depends on the number of layers in the layers. The paper further proposes a strategy that mitigates the sensitivity of the layers to the complexity. Empirical results show that the proposed strategy outperforms the baselines in most cases."
SP:f3f3c6fbae757836551b3f1ee54a7d1e040132b8,"This paper studies generalization bounds for stochastic gradient Langevin dynamics ( SGLD ) and several other noisy gradient methods ( e.g., with momentum, mini - batch and acceleration, Entropy - SGD ). The authors develop a new framework, termed Bayes - Stability, for proving algorithm - dependent generalization error bounds. The new framework combines ideas from both the PAC - Bayesian theory and the notion of algorithmic stability. They obtain new data - dependent bounds for several noisy Langevin methods. Their result recovers ( and is typically tighter than ) a recent result in Mou et al. ( 2018 ) and improves upon the results in Pensia et al ( 2018). Their experiments demonstrate that their new bounds can distinguish randomly labelled data from normal data."
SP:a82fcd1d3196ddf078cfe8f4bc6f445d9d2bdc11,"This paper investigates the role of the hippocampus in continual learning in the context of continual learning of two different spatial navigation strategies. The authors use a modified principal component analysis ( dPCA ) method to analyze the population - level activity of hippocampal CA1 neurons of rodents learning to perform allocentric and egocentric spatial tasks. The results show that hippocampal neurons encode relevant task variables such as decisions, navigational strategies and reward location. They also compare this hippocampal features with standard reinforcement learning algorithms, highlighting similarities and differences. Finally, they demonstrate that a standard deep reinforcement learning model achieves similar average performance when compared to animal learning, but fails to mimic animals during task switching."
SP:51acf1f8108683dce543a1fb4a61fbd593f9b4cc,"This paper proposes a tree search based policy optimization method for continuous environments. The main idea is to use a pre - trained policy to bootstrap the MCTS tree search with a few action samples from the policy distribution. The authors also propose a new loss function based on the trajectories ’ mean and standard deviation. Experimental results show that the proposed method significantly improves the performance of the baseline policy optimization algorithm, PPO."
SP:1ce3bc4d31712886f7dcada5b5ae67c3c376819a,"This paper studies the lottery ticket hypothesis, which argues that neural networks contain sparse subnetworks, which, if appropriately initialized, are capable of matching the accuracy of the full network when trained in isolation. However, the properties of winning tickets are not well understood, especially the importance of supervision in the generating process. In this paper, the authors aim to answer the following open questions : can we find winning tickets with few data samples or few labels? can we even obtain “ good ” tickets without supervision? They find that winning tickets found in these scenarios are, perhaps surprisingly, competitive with winning tickets generated on the full ImageNet dataset when evaluated on ImageNet classification task."
SP:dbcebe5b73486885d9f4478b258047c02f8481a2,"This paper focuses on the problem of "" prediction undersensitivity "" in the context of reading comprehension models. The authors propose a noisy adversarial attack that searches among semantic variations of comprehension questions for which a model still erroneously produces the same answer as the original question – and with an even higher probability – and show that, despite comprising unanswerable questions, SQuAD2.0 and NewsQA models are vulnerable to this attack and commit a substantial fraction of errors on adversarially generated questions. This indicates that current models — even where they can correctly predict the answer —rely on spurious surface patterns and are not necessarily aware of all information provided in a given comprehension question. Developing this further, the authors experiment with both data augmentation and adversarial training as defense strategies : both are able to substantially decrease a model ’s vulnerability to undersensitivity attacks on held out evaluation data. Finally, they demonstrate that adversarial robust models generalise better in a biased data setting with a train / evaluation distribution mismatch."
SP:5da870060778de460c1abe91562d6f3e707efef4,"This paper proposes a model - based approach to safety that allows the agent to look into the future and be aware of the future consequences of its actions. They learn the transition dynamics of the environment and generate a directed graph called the imaginative module. This graph encapsulates all possible trajectories that can be followed by the agent, allowing the agent    to efficiently traverse through the imagined environment without ever taking any action in reality. A baseline state, which can either represent a safe or an unsafe state ( based on whichever is easier to define ) is taken as a human input. The imaginative module is used to predict whether the current actions of the agent can cause it to end up in dangerous states in the future. They run experiments to confirm that their proposed method improves safety throughout learning and at convergence."
SP:c2796f28fb067138303df8d424d646f4ada31558,"This paper proposes a novel architecture, Physics - aware Difference Graph Networks ( PA - DGN ), which exploits neighboring information to learn finite differences inspired by physics equations. The proposed architecture leverages data - driven end - to - end learning to discover underlying dynamical relations between the spatial and temporal differences in given sequential observations. The authors demonstrate the superiority of PA - DAGN in the approximation of directional derivatives and the prediction of graph signals on the synthetic data and the real - world climate observations from weather stations."
SP:db8ed4f4fc3967f5dd4d208d5d029730eb99e840,"This paper proposes a proximal - type stochastic gradient descent ( ProxSGD ) algorithm for the problem of training structured neural networks with nonsmooth regularization and constraints. The authors formulate the problem as a constrained nonconvex optimization problem, and propose a convergent proximal gradient descent algorithm with momentum. They show that under properly selected learning rates, with probability 1, every limit point of the sequence generated by the proposed Prox SGD algorithm is a stationary point. They also show by extensive numerical tests how the proposed algorithm can be used to train either sparse or binary neural networks."
SP:2ca1f4da9faee79768764cda5d09d949cc942acc,"This paper proposes an end - to - end differentiable differentiable compression framework for lossy image compression. The authors propose a relative entropy coding algorithm to achieve bits - back efficiency. The decoder maps the input image to a distribution in continuous space from which a sample can be encoded with expected code length being the relative entropy to the encoding distribution, i.e., it is bit - back efficient. The method is trained using standard gradient - based optimizers. Experiments on the CLIC 2018 dataset show that the rate - distortion curve of the proposed method is competitive with the state - of - the - art on the Kodak dataset."
SP:788fd2b6956dd69bf7752d39ea21883947128c8a,"This paper proposes a method to generate high - quality super - resolution images from C - JPG images. The method is based on two components : ( 1 ) a functional sub - model to recover information from low - quality images, and ( 2 ) a cycle loss to improve the consistency. The proposed method is evaluated on a variety of SISR tasks and compared with other state - of - the - art methods."
SP:18dd92f2f55020be4f5a089b3b251327e47886f4,"This paper presents a deep neural network architecture that is able to estimate a full surface of pass probabilities from single - location labels derived from high frequency spatio - temporal data of professional soccer matches. The network learns a feature hierarchy that produces predictions at different sampling levels that are merged together to preserve both coarse and fine detail. The approach presents an extreme case of weakly supervised learning where there is just a single pixel correspondence between ground - truth outcomes and the predicted probability map. By providing not just an accurate evaluation of observed events but also a visual interpretation of the results of other potential actions, the approach opens the door for spatiotemporal decision - making analysis, an as - yet little - explored area in sports. The proposed deep learning architecture can be easily adapted to solve many other related problems in sports analytics."
SP:1ae31baf383fc520687b255d9cac14c3b040e253,"This paper proposes an inductive matrix completion model without using side information. The proposed method is based on a graph neural network ( GNN ) based on 1 - hop subgraphs around ( user, item ) pairs generated from the rating matrix. It achieves highly competitive performance with state - of - the - art transductive baselines. In addition, IGMC is inductive – it can generalize to users / items unseen during the training and can even transfer to new tasks. The transfer learning experiments show that a model trained out of the MovieLens dataset can be directly used to predict Douban movie ratings with surprisingly good performance."
SP:c5cb1b50e17a69e88d5ae28848e265215162da1e,"This paper considers the problem of unconstrained minimization of a smooth objective function in R in the setting where only function evaluations are possible. The authors propose and analyze stochastic zeroth - order method with heavy ball momentum. In particular, they propose SMTP, a momentum version of three - point method ( STP ). They show new complexity results for non - convex, convex and strongly convex functions. They test their method on a collection of learning to continuous control tasks on several MuJoCo environments with varying difficulty and compare against STP, other state - of - the - art derivative - free optimization algorithms and against policy gradient methods."
SP:a216cfc29937eb398ea98cb1aea3481c9aed8240,"This paper proposes Action Semantics Network ( ASN ), a neural network architecture for multi - agent reinforcement learning ( MAS ). The main idea of the paper is to model the influence of actions between two agents in the context of MAS. The proposed ASN can be easily combined with existing DRL algorithms to boost the learning performance. Experimental results on StarCraft II micromanagement and Neural MMO show ASN significantly improves the performance of state - of - the - art DRL approaches compared with several network architectures."
SP:efaf3a440dc17e05177832083ffbc23760ed7c97,"This paper proposes to exploit the underlying structures of the state - action value function, i.e., Q function, for both planning and deep RL. Specifically, the authors investigate the lowrank structure, which widely exists for big data matrices, and verify empirically the existence of low - rank Q functions in the context of control and deep reinforcement learning tasks. By leveraging Matrix Estimation ( ME ) techniques, the paper proposes a general framework to exploit low rank structure in Q functions. This leads to a more efficient planning procedure for classical control, and additionally, a simple scheme that can be applied to value - based RL techniques to consistently achieve better performance on “low - rank ” tasks. Extensive experiments on control tasks and Atari games confirm the efficacy of the approach."
SP:430336893b247b7bd45687d78b0d0511a7369e87,"This paper proposes a new algorithm, Best - Action Imitation Learning ( BAIL ), for batch reinforcement learning. BAIL first selects from the batch the actions it believes to be high - performing actions for their corresponding states ; it then uses those state - action pairs to train a policy network using imitation learning. Although BAIL is simple, it achieves state - of - the - art performance on the Mujoco benchmark."
SP:94078964876667e8a5d9ae7728d779d5b91a576e,"This paper proposes DeepXML, an algorithm to jointly learn word embeddings and classifiers for extreme multilabel learning on short text documents. The authors propose a novel architecture that splits training of head and tail labels by learning word embedding on head labels and transferring them through a novel residual connection to data impoverished tail labels. They also increase the amount of negative training data by extending state - of - the - art negative sub - sampling techniques and re - ranking the set of predicted labels to eliminate the hardest negatives for the original classifier. All of these contributions are implemented efficiently by extending the highly scalable Slice algorithm for pretrained embedding to learn the proposed deepXML architecture. The proposed algorithm could efficiently scale to problems involving millions of labels and could be more than 10x faster at training than XML - CNN and AttentionXML."
SP:b1b1252d82fa1bea18309e0b0b894e0f28f48bc9,"This paper proposes an end - to - end trainable variational hashing - based collaborative filtering method, which optimizes hash codes using a novel modification to the Hamming distance, which the authors call self - masking. The method first creates a modified item hash code, by applying an AND operation between the user and item hash codes, before computing the hamming distance. Intuitively, this can be seen as ignoring user - specified bits, corresponding to applying a binary importance weight to each bit, but without using more storage and only a very marginal runtime overhead. The authors verified experimentally that their model outperforms state - of - the - art baselines by up to 12 % in NDCG at different cutoffs, across 4 widely used datasets."
SP:80898d0f2b2c8dc3388fa9164e529eae36aa1b21,"This paper investigates the mode collapse issue of GANs. The authors propose two simple yet effective methods to calibrate the GAN learned distribution, i.e., latent space reshaping via Gaussian mixture models and importance sampling. They are observed to alleviate mode collapse without re - touching the training data, nor even needing any access to model parameters."
SP:e5b5dda2f024cfda10526e744aa035e0165af58a,"This paper studies the training of over - parametrized neural networks that are beyond the NTK regime yet still governed by the Taylor expansion of the network. The authors introduce the idea of randomizing the neural networks, which allows them to escape their NTK and couple with quadratic models. They show that the optimization landscape of randomized two - layer networks are nice and amenable to escaping - saddle algorithms. They prove concrete generalization and expressivity results on these randomized networks. They also demonstrate that their randomization technique can be generalized systematically beyond the quadratically case, by using it to find networks with higher - order terms in their Taylor series."
SP:cef7ea513eb3e42be4edf40e4ee1701a969bcbea,"This paper proposes an assessment tool, Graph Filter Discriminant Score ( GFD Score ), to evaluate the effectiveness of graph convolutional filters for a given graph in terms of node classification. The authors find that there is no single filter as a “ silver bullet ” that performs the best on all possible graphs, and graphs with different properties are in favor of different graph filters. Based on these findings, the authors develop Adaptive Filter Graph Neural Network ( AFGNN ), a simple but powerful model that can adaptively learn data - specific filters. Experiments show that the proposed model can find better filters and achieve better performance compared to existing GNNs, on both real - word and newly created benchmark datasets."
SP:3c5ec9dbcf914c8901e4e35f3c2a7df4707422ab,"This paper studies the problem of distributionally robust optimization ( DRO ) for overparameterized neural networks. The authors propose a new stochastic optimizer for group DRO that is stable and scales to large models and datasets. They show that the proposed method can be applied to overparametrized neural networks with vanishing average training loss and vanishing worst - case training loss. They also provide convergence guarantees for their algorithm in the convex case and empirically show that it behaves well in the non - convex models. Finally, they show that regularization is important for worst - group generalization in the over parameterized regime."
SP:eb1ee2e0f7d8466a04b58508ecb3da7b667eecdf,"This paper presents a simple but effective mask predictor to provide local explanations for black box classifiers. Specifically, the authors introduce the concept of distribution controller on relevance scores, and integrate it with a trainable mask generator to directly guide the relevance scores. In addition, the proposed predictor is optimized under the classification loss, aiming to better mimic the classifier. The experimental results demonstrate that the proposed method outperforms others in terms of faithfulness and explainability."
SP:32ea7cbc47cbdb1f703f4e07c31ce90abe083424,"This paper proposes a framework for image reconstruction and classification problems that involve detection of multiple object instances, without any supervision regarding their whereabouts. The network learns to extract the most significant patches, and feeds these patches to a task - specific network – e.g., auto - encoder or classifier – to solve a domain specific problem. The challenge in training such a network is the non - differentiable top - K selection process. To address this issue, the authors lift the training optimization problem by treating the result of top - k selection as a slack variable, resulting in a simple, yet effective, multi - stage training. The method is able to learn to detect recurring structures in the training dataset by learning to reconstruct images. It can also learn to localize structures when only knowledge on the occurrence of the object is provided, and in doing so it outperforms the state - of - the - art without any location supervision."
SP:da1c5f6351d531482e90b86c3cceb52850c520de,"This paper presents a neural program synthesis algorithm, AutoAssemblet, for generating a segment of assembly code to execute state change in the CPU and RAM. The authors propose a self - learning strategy suitable for code generation learned via reinforcement learning. They adapt policy networks and value networks to reduce the breadth and depth of the Monte Carlo Tree Search. They also propose an effective multi - entropy policy sampling technique to alleviate online update correlations. Experimental results show that the proposed method outperforms several baselines."
SP:0d4687fc36c02e27d1b95d532a3947589f92b1da,This paper studies the impact of model architecture on the speed of training in the context of gradient descent optimization. The authors use the ideas from prior work that shows gradient descent can be modeled as a first - order ODE and use ODE ’s coefficient matrix H to characterize the convergence rate. They introduce a simple analysis technique that enumerates H in terms of all possible “ paths ” in the network. They show that changes in model architecture parameters reflect as changes in the number of paths and the properties of each path. They believe their analysis technique is useful in reasoning about more complex model architecture modifications.
SP:3e3bc8f617df742a395e7d315ec3810a42071294,"This paper studies the connection between strongly overparametrized neural networks ( NNs ) and interpolating kernel methods. The authors prove that fully connected wide ReLU - NNs trained with squared loss are essentially a sum of two parts : the first is the minimum complexity solution of an interpolating kernels method, while the second contributes to the test error only and depends heavily on the initialization. This decomposition has two consequences : ( 1 ) the second part becomes negligible in the regime of small initialization variance, which allows the authors to transfer generalization bounds from minimum complexity interpolation kernel methods to NNs ; ( 2 ) in the opposite regime, the test errors of wide NNs increases significantly with the initialization variance while still interpolating the training data perfectly."
SP:b15ea009a36a0a76728dfc103d668d6781a8a99a,"This paper proposes a method to improve the depth estimation of stereo - based 3D object detection in autonomous vehicles without expensive LiDAR sensors. The authors propose a depthpropagation algorithm, guided by the initial depth estimates, to diffuse these few exact measurements across the entire depth map. They also propose a novel graph propagation algorithm that integrates the two data modalities and propagates the sparse yet accurate depth estimates using two sparse matrix solvers. The resulting system, PSEUDO - LIDAR ++ ( SDN + GDC ), performs almost on par with 64 - beam LiDar systems for $75,000 but only requires 4 beams and 2 commodity cameras."
SP:983d84502264633f3385d426c1d4601a0744ea9a,"This paper proposes a principled adversarial example detection method that can withstand norm - constrained white - box attacks. Inspired by one - versus - the - rest classification, in a K class classification problem, they train K base detectors where the i - th detector is trained to discriminate natural data of class i from adversarial examples perturbed from other classes. At inference time, they first get the predicted label ( say k ) of the input, and then use the k - fourth detector to identify whether the input is a natural sample ( of class k ) or an adversarial sample ( perturbed from other class ). They further devise a generative approach to detecting / classifying adversarial samples by interpreting each base detector as an unnormalized density model of the classconditional data. They provide comprehensive evaluation of the above adversarial detection / classification methods, and demonstrate their competitive performances and compelling properties."
SP:461e9308d050bc3dc7b35233452668bb31f5d491,"This paper proposes a novel intrinsic reward for exploration in sparse reward environments. The proposed reward is based on the change in the state representation produced by the agent's action. The authors propose to use the Euclidean distance between the predicted next state representation and the actual next state representations as the intrinsic reward. They compare their method with other state - of - the - art intrinsic reward methods on singleton environments with high - dimensional observations, as well as on hard - exploration tasks in procedurally generated grid - world environments. Their experiments show that RIDE outperforms other intrinsic rewards methods."
SP:c002c20b5e8696588e029c0f65e88860418826c4,"This paper presents a comprehensive study on the embedding - based retrieval models for large - scale query - document retrieval. The retrieval phase consists of two steps : the retrieval phase first reduces the solution space, returns a subset of candidate documents, and the scoring phase re - ranks the documents. The authors show that the two - tower retrieval model with random initialization ( No Pretraining ) or the unsuitable token - level pretraining task ( MLM ) are no better than the robust IR baseline BM-25 in most cases. With properly designed paragraph - level pre - training tasks inlcuding ICT, BFS, Wiki Link Prediction, and WLP, the two-tower Transformer models can considerably improve over the widely used BM - 25 algorithm."
SP:4e161e08a624f87633dfb49dfd46bd1665e15189,"This paper proposes a new type of graph neural network architecture, called BiGraphNet, that splits the graph into two parts : an input and an out graph. The input and out graph are parameterized by a bipartite graph convolution operation, which is a parameterized transformation between different input and output graphs. The authors show that the proposed architecture is general enough to subsume conventional graph convolutions and pooling as its special cases and supports multi - graph aggregation leading to a class of flexible and adaptable network architectures, termed Bi GraphNet.   The authors also show that their architecture provides the modeling flexibility to build efficient architectures such as graph skip connections, and graph autoencoders."
SP:9b9b6ee9014e5538442ba76d6059ed01f59ec8fb,"This paper proposes to use feature - wise transformation layers for augmenting the image features using affine transforms to simulate various feature distributions under different domains in the training stage. The authors further apply a learning - to - learn approach to search for the hyper - parameters of the feature -wise transformation layers to further improve the performance of metric - based few - shot classification models. The proposed method is applicable to various metric-based models, and provides consistent improvements on the few-shot classification performance under domain shift."
SP:df46627cb984a56bba36d510bfc52e00751e9107,"This paper proposes a new continuous convolutional network for fluid simulation. The authors use spatial convolutions as the main differentiable operation that relates particles to their neighbors in the continuous domain. They show that their network architecture can simulate different materials, generalizes to arbitrary collision geometries, and can be used for inverse problems. Experimental results indicate that the presented approach outperforms a state - of - the - art graph - based framework ( Li et al. )."
SP:3e17f333cf07183969c02bb66afdd3ccbf25bb19,"This paper proposes BatchEnsemble, an ensemble method to improve the accuracy and predictive uncertainty of single neural networks. The method is parallelizable across devices, where one device trains one member, and parallelizable within a device, where multiple ensemble members are updated simultaneously for a given mini - batch. The speedup at test time is 3X and memory reduction is 3x at an ensemble of size 4. The proposed method is applied to CIFAR-10/100 classification with ResNet32 and WMT14 EN - DE/EN - FR machine translation with Transformer. It is also applied to lifelong learning and scale up to 100 sequential learning tasks."
SP:a123a425ef3eb6188833d5a42e851bc3fa59df65,"This paper proposes a neural network - based solver for solving PDEs. The solver is grid free, mesh free and shape free, and the solution is approximated by neural network. The network is trained to minimize deviations of the learned function from the strong PDE solution and satisfy the boundary conditions. The resulting solution in turn is an explicit smooth differentiable function with a known analytical form. Unlike other numerical methods such as finite differences and finite elements, the derivatives of the desired function can be analytically calculated to any order. This framework enables the solution of high order non - linear PDES. The proposed algorithm is a unified formulation of both forward and inverse problems where the optimized loss function consists of few elements : fidelity terms of L2 and L∞ norms that unlike previous methods promote a strong solution. This setting is flexible in the sense that regularizers can be tailored to specific problems. The authors demonstrate their method on several free shape 2D second order systems with application to Electrical Impedance Tomography ( EIT ), diffusion and wave equations."
SP:973d0ad0faadcf7298300f2758de9154205e7113,"This paper studies the design choices of BNNs and how they affect the performance of logic - based reasoners, focusing on the individual neuron and block levels. The authors propose a modified training procedure that makes the resulting network easier for SAT solvers, like SAT solver or approximate model counting solvers to reason about. They demonstrate that their approach scales to larger deep neural networks compared to existing work for existential and probabilistic queries, leading to significant speed ups on all tested datasets."
SP:ca985e758f195bd04fb9f24b290a83974d6d308b,"This paper studies the expressive power of graph neural networks ( GNNs ) within the message - passing framework. Two results are presented. First, GNNnmp are shown to be Turing universal under sufficient conditions on their depth, width, node attributes, and layer expressiveness. Second, it is discovered that GNNmp can lose a significant portion of their power when their depth and width is restricted. The proposed impossibility statements stem from a new technique that enables the repurposing of seminal results from distributed computing and leads to lower bounds for an array of decision, optimization, and estimation problems involving graphs. Strikingly, several of these problems are deemed impossible unless the product of a GNNp ’s depth andwidth exceeds a polynomial of the graph size. This dependence remains significant even for tasks that appear simple or when considering approximation."
SP:a98ae70a91850bbe624c307ba61d3daeb2494b82,"This paper proposes a localised generative flow ( LGF ) method for density estimation. The authors argue that flow - based density models based on continuous bijections are limited in their ability to learn target distributions with complicated topologies, and propose LGFs to address this problem. LGFs are composed of stacked continuous mixtures of bijection, which enables each bijection to learn a local region of the target rather than its entirety. The method is a generalisation of existing flow-based methods, which can be used without modification as the basis for an LGF model. Unlike normalising flows, LGFs do not permit exact computation of log likelihoods, but they propose a simple variational scheme that performs well in practice. The experiments show that LGFs yield improved performance across a variety of density estimation tasks."
SP:3adc341dece170f428195e4dccadfb5f5daddf2d,"This paper studies the performance gap between seen and unseen environments widely observed in vision - and - language navigation tasks. By designing the diagnosis experiments of environment re - splitting and feature replacement, the authors find the environment bias to be in the low - level visual appearance. The authors further discuss how to eliminate this bias by using advanced high - level semantic features which are more rational for the VLN domain. The experimental results show that all of these semantic features significantly reduce the environment biases in multiple datasets and also achieve strong results in testing unseen environments."
SP:298e0043e99f586d314fbd9d16fdc6ae885e1ebb,"This paper proposes to use human feedback as an auxiliary reward function in deep reinforcement learning to accelerate and optimize the training of a DRL algorithm. The idea is that a human observer is placed on the agent to observe the agent's behavior, and the human's intrinsic reactions to the agent ’s behavior is sensed as implicit feedback by placing electrodes on the human scalp and monitoring what are known as event - related electric potentials. The implicit feedback is then used to augment the agent’s learning in the RL tasks. The authors develop a system to obtain and accurately decode the implicit human feedback ( specifically error - related event potentials ) for state - action pairs in an Atari - type environment. They show that the definition of error - potential is generalizable across different environments, and show that error -potentials of an observer can be learned for a specific game and the definition can be used as - is for another game without requiring re - learning of the error - Potentials. They propose two different frameworks to combine recent advances in DRL into an error - based feedback system in a sample - efficient manner, allowing humans to provide implicit feedback while training in the loop, or prior to training of the RL agent."
SP:a8395f8b877e1eebaef9ff2e8b4e488d55a74ef4,"This paper proposes a method to compare the performance of diverse image classifiers in terms of the amount of information required in individual test images to maintain correct classification. Given a classifier and a test image, the authors compute an approximate minimal - entropy positive image for which the classifier provides a correct classification, becoming incorrect upon any further reduction. The notion of entropy offers a unifying metric that allows to combine and compare the effects of various types of reductions ( e.g., crop, colour reduction, resolution reduction ) on classification performance, in turn generalising similar methods explored in previous works. The authors find that machine classifiers are more sensitive entropy - wise to reduced resolution (versus cropping or reduced colour for machines, as well as reduced resolution for humans ), supporting recent results suggesting a texture bias in the ILSVRC - trained models used. They also find, in the evaluated setting, that humans classify the minimal entropy positive images of machine models with higher precision than machines classify those of humans."
SP:81cec8f907d8fa0653b5bc08af1f59bfefd49619,"This paper studies the robustness of input perturbation defenses for convolutional neural networks. In particular, the paper focuses on the instability assumption that the adversarial examples are not robust and small perturbations to the attacking input often recover the desired prediction. The paper identifies a family of defense techniques that are based on instability assumption. The defenses include deterministic lossy compression algorithms and randomized perturbant to the input that all lead to similar gains in robustness.   The paper presents a comprehensive experimental analysis of when and why perturbative defenses work and potential mechanisms that could explain their effectiveness ( or ineffectiveness ) in different settings. The experiments suggest that all the perturbated based defenses are vulnerable to the same types of attack strategies."
SP:a136b98e0ed478144ce9dd26e2b6d611543124e8,"This paper proposes a neural 3D mapping network that takes as input 2.5D ( color and depth ) video streams captured by a moving camera, and lift them to stable 3D feature maps of the scene, by disentangling the scene content from the motion of the camera. The model also projects its feature maps to novel viewpoints, to predict and match against target views, and propose contrastive prediction losses to replace the standard color regression loss, and show that this leads to better performance on complex photorealistic data. The proposed model learns visual representations useful for ( 1 ) semi - supervised learning of 3D object detectors, and ( 2 ) unsupervised learning for 3D moving object detectors. To the best of the knowledge, this is the first work that empirically shows view prediction to be a scalable self - supervised task beneficial to 3d object detection."
SP:6fd61604a2eeb8a2cbbda6c40807cebef6d40f2f,"This paper studies the problem of unsupervised domain translation ( UDT ), where the goal is to find meaningful correspondences between two pairs of samples without explicit pairings between them. The paper proposes to cast UDT into an Optimal Transport ( OT ) framework by making the implicit bias explicit. This allows to provide theoretical guarantees for existing methods, and also to solve UDT problems where previous methods fail. Theoretical results show that CycleGAN - like models are biased towards low energy transformations, leading to the use of OT to solve the UDT problem."
SP:8bb3ce11ad773685f6e41d90db3e7a5481e5ba47,"This paper proposes a novel regularization method, RotationOut, for neural networks. The proposed method is different from Dropout that handles each neuron / channel independently, and instead it regards its input layer as an entire vector and introduces regularization by randomly rotating the vector. It can also be used in convolutional layers and recurrent layers with small modifications. The authors further use a noise analysis method to interpret the difference between R rotationOut and Dropout in co - adaptation reduction. Extensive experiments in vision and language tasks are conducted to show the effectiveness of the proposed method."
SP:37620ae8dc5683eb2843792e0aa4cbe6cba366f7,"This paper proposes a method to create universal adversarial perturbations ( UAPs ) for a given CNN in a data - free manner. The key idea is to find the first singular vector of the linearly approximated neural network. The approximation is being enabled by optimizing with the proposed dilate loss. Extensive experiments demonstrate that our method not only has theoretical support, but achieves higher fooling rate than the existing data free work."
SP:2fd7d5507a8727db743dc89379a6f021d31ed39a,"This paper proposes a method for transfer learning in neural architecture search ( NAS ). The main idea is to use meta - learning to learn a meta - architecture that can adapt to a new task easily and quickly through a few gradient steps, which is more flexible than the existing NAS methods. The authors also propose an efficient first - order approximation algorithm to optimize the whole search network. Extensive experiments show that T - NAS achieves state - of - the - art performance in few - shot learning and comparable performance in supervised learning but with 50x less searching cost."
SP:1314a79ba12474adb33ff31b3cb22bed25b94fb7,"This paper proposes a simple and effective stochastic neural network architecture for discriminative learning by directly modeling activation uncertainty and encouraging high activation variability. Compared to existing SNNs, the proposed SE - SNN is simpler to implement and faster to train, and produces state - of - the - art results on network compression by pruning, adversarial defense and learning with label noise."
SP:bd4935d4fcf33f60f22e0f2fd9f7dc8ddfab6d17,"This paper proposes a new meta - learning algorithm for generating curious behavior in reinforcement learning agents. The algorithm is based on the idea that curiosity is a mechanism found by evolution that encourages meaningful exploration early in an agent ’s life in order to expose it to experiences that enable it to obtain high rewards over the course of its lifetime. The authors formulate the problem of generating curiosity behavior as one of meta learning : an outer loop will search over a space of curiosity mechanisms that dynamically adapt the agent’s reward signal, and an inner loop will perform standard reinforcement learning using the adapted reward signal. The inner loop is composed of two parts : a reward - adaptive inner loop and a reward adaptive outer loop. The outer loop computes the reward signal and the inner loop uses it to perform reinforcement learning on the outer loop to generate curious behavior.    The authors show that by transferring programs, they can generalize between tasks much more varied than previously possible in meta - RL, even between those with different input or output spaces. They demonstrate the effectiveness of the approach empirically, finding two novel curiosity algorithms that perform on par or better than human - designed published curiosity algorithms in domains as disparate as grid navigation, acrobot, lunar lander, ant and hopper."
SP:6dff0f3a84809ae0ba9f58f36303597f1ba6dcc5,"This paper proposes a structural language modeling ( SLM ) approach for the problem of code generation. The main idea is to model a code snippet as a tree, where the tree is represented by an abstract syntax tree ( AST ). The AST is represented as a conditional probability distribution over all paths leading to a given AST node. The authors propose a neural model that computes the conditional probabilities of the AST by considering all AST paths. The proposed approach is evaluated on CIFAR-10/100 and C++ code generation benchmarks. The results show that the proposed approach outperforms the state - of - the - art."
SP:7fc60d6fd1cfcc135c34f9664d172d3fd1c0ae0a,"In this paper, the authors study the problem of learning large - scale neural networks ( NNs ) using gradient descent methods. They show that the objective functions in learning NNs are convex in the canonical model space. They further elucidate that the gradients between the original NN model space and the canonical space are related by a pointwise linear transformation, which is represented by the so - called disparity matrix. Furthermore, they show that gradient descent algorithms surely converge to a global minimum of zero loss provided that the disparity matrices maintain full rank. If this full - rank condition holds, the learning of NNs behaves in the same way as normal convex optimization."
SP:78a536138570fe9b5d88350e4b16d598a7db1fe0,"This paper proposes a graph - based multi - label segmentation method for image data. The proposed method is based on a discrete Potts model and a class - aware integer linear programming ( ILP ) formulation that ensures global optimum. The method can take RGB, or utilize the feature maps from any DCNN, whether trained on the target dataset or not, as input. The authors show competitive semantic ( and panoptic ) segmentation results on the PASCAL VOC 2012 and Cityscapes dataset given initial scribbles. They also demonstrate that their interactive approach can reach 90.6% mIoU on VOC validation set with an overhead of just 3 correction scribbles with an interactive approach."
SP:2eb90879ddbc39b6b5c05152784d6044d1940513,"This paper proposes to use a learned saliency model to detect adversarial perturbations in images. The authors argue that gradient - based adversarial tools are ineffective as an adversarial defense because of the shift in saliency due to the perturbation. To remedy this, the authors propose to use learnt saliency models to capture the shifts in the salient features of an image. The proposed method uses a CNN that distinguishes between adversarial images and natural images using salient pixels as its input. The method is tested on MNIST, CIFAR-10, and ASSIRA."
SP:fe5510d05ff091a5f133f2dbcd1b23d8d58d2c3e,"This paper studies the problem of estimating the robustness of neural networks to adversarial perturbations. The authors use the exact local robustness method of Huang et al. ( 2017 ) and the concentration inequalities of Goodfellow et al ( 2014 ) to estimate the global robustness. They also use FGSM to approximate the exact robustness properties of local neural networks. Finally, the authors show the convergence rate of the upper bound of the bound on the global adversarial robustness, which is upper - bounded by."
SP:8f5616a1480b68c04b496ed498d237d5a7e87794,This paper studies the problem of robust Reinforcement Learning with Wasserstein constraint. The authors propose a robust Advantage Actor - Critic algorithm according to the moderated robust Bellman equation. The proposed algorithm is evaluated on the Cart - Pole environment. The experimental results show the effectiveness and robustness of the proposed approaches.
SP:d85963f5f0f6b20cf08f2a7c169ae33a45db7de2,"This paper proposes a method to approximate mixed strategy Nash equilibria in multi - player continuous games, which always exist and include the pure ones as a special case. The main idea is to use the pushforward measure technique to represent a mixed strategy in continuous spaces. This allows to generalize the Gradient - based Nikaido - Isoda ( GNI ) function to measure the distance between the players ’ joint strategy profile and a Nash equilibrium. The gradient descent algorithm is shown to converge to a stationary Nash equilibrium under the convexity assumption on payoff functions, the same popular setting as in previous studies. In numerical experiments, the method consistently and significantly outperforms recent works on approximating Nash equilibrium for quadratic games, general blotto games, and GAMUT games."
SP:280d85cd8164a268f9d496ae5f17189c50f30dc1,"This paper proposes a novel Neural Execution Tree ( NExT ) framework to augment training data for text classification using Natural Language Explanations ( NL explanations ). The authors propose to use NL explanations for augmenting training data by transforming NL explanations into executable logical forms by semantic parsing. The proposed method generalizes different types of actions specified by the logical forms for labeling data instances, which substantially increases the coverage of each NL explanation. Experiments on two NLP tasks (relation extraction and sentiment analysis ) demonstrate its superiority over baseline methods. Its extension to multi - hop question answering achieves performance gain with light annotation effort."
SP:a9b5f7257dedd719cfe341fca275776734af1d98,"This paper extends the applicability of verified training to recurrent neural network architectures and complex specifications that go beyond simple adversarial robustness, particularly specifications that capture temporal properties, such as requiring that a robot periodically visits a charging station or that a language model always produces sentences of bounded length. Experiments show that while models trained using standard training often violate desired specifications, our verified training method produces models that both perform well ( in terms of test error or reward ) and can be shown to be provably consistent with specifications. This is significantly easier to guarantee than those trained adversarially or with data augmentation."
SP:3903680e07b676409e3cf6a1044b67291fe38630,"This paper studies the problem of generalization to visually diverse environments in deep reinforcement learning. The authors formalize the problem, illustrated the inefficiencies of standard domain randomization, and proposed a theoretically grounded method that leads to robust, low - variance policies that generalize well. They conducted several experiments in different environments of differing complexities using both on - policy and off - policy algorithms to support their claims."
SP:c79046dc56b9ee9c926f87386046422ea134ae8d,"This paper proposes a DRO framework for deep metric learning ( DML ). The authors cast DML as a simple pairwise binary classification problem that classifies a pair of examples as similar or dissimilar. The key to this framework is to define a robust loss for all pairs over a mini - batch of data, which is formulated by distributionally robust optimization. The flexibility in constructing the uncertainty decision set of the dual variable allows us to recover state - of - the - art complicated losses and also to induce novel variants. Empirical studies on several benchmark data sets demonstrate that the simple and effective method outperforms the SOTA results."
SP:38420928e40ef80c0136ad607b9275f9ab1e0769,"This paper studies the problem of finding a local minimum in non - convex finite - sum minimization in the stochastic trust region ( STR ) setting. The main contributions of this paper are :   1. The authors prove that the trust region method with inexact gradient and Hessian estimation can achieve a convergence rate of order O(1/k ) as long as those differential estimations are sufficiently accurate. 2. Combining such result with a novel Hessian estimator, the authors propose a sample - efficient algorithm that finds an approximate local minimum within Ú( \sqrt{n/\varepsilon } ) stochastically Hessian oracle queries. This improves the state - of - the - art result by a factor of O(n ). 3.   The authors also develop Hessian - free STR algorithms that achieve the lowest runtime complexity."
SP:28a35b70b5e6915af28cacebc4ea50690c9534af,"This paper proposes a new training method called Farkas layers that ensures that at least one neuron is active at a given layer. The method is based on the interaction of the geometry of the weights with the data : by simply adding one linearly dependent row to the weight matrix, we ensure that no neurons are dead. The authors demonstrate the effectiveness of the proposed method on the task of image classification."
SP:1d325b148e3efe407241c1f1cbe8d17400499741,"This paper studies the problem of certifying the robustness of deep neural networks to adversarial perturbations. In particular, the authors consider the case where the curvature of the neural network is bounded. The authors show that if the eigenvalues of the Hessian of the network are bounded, they can compute a robustness certificate in the l2 norm efficiently using convex optimization. In addition, they derive a computationally efficient differentiable upper bound on the curvatures of a deep network. Finally, they also use curvature bound as a regularization term during the training of the networks to boost its certified robustness against adversarial examples."
SP:33f6f5aa0d4655e5d75fe612e0eff05e579d45c5,"This paper proposes a novel method for compressed sensing recovery using untrained deep generative models. The method is based on the recently proposed Deep Image Prior ( DIP ), wherein the convolutional weights of the network are optimized to match the observed measurements. The authors show that this approach can be applied to solve any differentiable linear inverse problem, outperforming previous unlearned methods. Unlike various learned approaches based on generative model, this method does not require pre - training over large datasets. The proposed method also incorporates a novel learned regularization technique, which incorporates prior information on the network weights. This reduces reconstruction error, especially for noisy measurements."
SP:23c0f621e6041003b59bf0532130760694cf6a4a,"This paper proposes TAIC, a method for learning temporal abstraction from action sequences. The authors formulate the temporal abstraction problem as learning latent representations of action sequences and present a novel approach of regularizing the latent space by adding information - theoretic constraints. Specifically, they maximize the mutual information between the latent variables and the state changes. Experiments show that TAIC learns an effective abstraction of the long action sequences, which allows us to learn new tasks on higher level more efficiently."
SP:4e54c9196ba1eb2b6a0b0eee41e4a6f3a9de72dd,"This paper proposes a novel layer - wise sampling strategy, which samples the nodes layer by layer conditionally based on the factors of the bi - directional diffusion between layers. In this way, they potentially restrict the time complexity linear to the number of layers, and construct a mini - batch of nodes with high local bi - directional influence ( correlation ). Further, they apply the self - attention mechanism to flexibly learn suitable weights for the sampled nodes, which allows the model to be able to incorporate both the first - order and higher - order proximities during a single layer propagation process. Extensive experiments on three large benchmark graphs demonstrate the effectiveness and efficiency of the proposed model."
SP:bb0af9c011ef982c34fcadb545f6b5771818e7fa,"This paper proposes a new state - space model for unsupervised video modeling and planning. The proposed model is a combination of an image - based model and a dynamics model. The dynamics model is based on the AIR model, while the image model uses the dynamics model to model the position and velocity of the objects in the video. The authors show that the proposed model can be used to predict videos with convincing physical behavior over thousands of timesteps. They also show that it can also be used for sample efficient model - based control."
SP:e67b463bc0aec2345925d609fa521ea49df57fd9,"This paper proposes a new variational autoencoding model that incorporates the best properties of VAE and GAN. The authors propose to use an implicit likelihood to train the VAE model with an adversarially trained discriminator. The proposed method is called Implicit $ \lambda$-Jeffreys Autoencoder ( IAE ).   The authors provide a theoretical analysis of the objective and show that it is equivalent to the Jeffreys divergence. In experiments, the authors show that the proposed method achieves the state - of - the - art trade - off between generation and reconstruction quality."
SP:87056d0147ddcaf5d78f6888b05161fbdbb3346c,"This paper studies the problem of adversarial attacks on CNN classifiers. The authors show that the Bayes - optimal classifier is vulnerable to adversarial examples for certain class distributions, while for others it is robust to such attacks. They present analytical results showing conditions on the data distribution under which all points can be made arbitrarily close to the optimal decision boundary, and show that this can happen even when the classes are easy to separate, when the ideal classifier has a smooth decision surface, and when the data lies in low dimensions. They introduce new datasets of realistic images of faces and digits where the Bayesian classifier can be calculated efficiently. They show that for some of these datasets the optimal classifiers is robust and for others, the adversarial attack can be performed on them. They find that standard CNN training consistently finds a vulnerable classifier on these datasets, while large - margin methods often find a robust classifier with the exact same training data."
SP:a7b3a35e6a79084bdfd1e4a963dfa081279cd8bb,This paper presents an analysis of the impact of class sparsity on the performance of neural network pruning. The authors find that certain classes and images are systematically more impacted by the introduction of sparsity than other classes. They also find that pruning identified exemplars ( PIEs ) are more sensitive to sparsity. They find that removing PIE images from the test - set greatly improves top - 1 accuracy for both sparse and non - sparse models. Their findings provide important insights about when pruned models are qualified to make decisions on real world inputs.
SP:4b17edaa7ec6201891433320d85f9a415656b763,"This paper presents KG - A2C, a reinforcement learning agent for interactive fiction games. The agent uses a combination of knowledge graph - based state space and template - based action space. The knowledge graph is used to understand the current state of the game, while the action space is used for generating actions. Experiments show that the proposed method outperforms TDQN, an existing state - of - the - art action space - based RL agent."
SP:b1784ecbb8f36eef9cae33d61ce60d80c2f9c38d,"This paper proposes a data - dependent Gaussian prior ( D2GPo ) to augment the current MLE training with an extra Kullback - Leibler divergence loss term to alleviate the issue of negative diversity ignorance. The proposed method is poles apart from the commonly adopted L2 regularization for the purpose of smoothing the training of MLE. Experimental results show that the proposed method makes effective use of a more detailed prior in the data and has improved performance in typical language generation tasks, including supervised and unsupervised machine translation, text summarization, and storytelling, and image captioning."
SP:7c29cb5a32b14e1392408dc5daba4cd35848bea9,"This paper proposes to replace the widely used cross - entropy loss with focal loss to improve the calibration of neural networks. The proposed method is based on the idea of focal loss, which aims to regularize the weights of a network during training, reducing NLL overfitting and thereby improving calibration. The authors provide a thorough analysis of the factors causing miscalibration, and use the insights to theoretically justify the empirically excellent performance. Extensive experiments on a variety of computer vision ( CIFAR-10/100 ) and NLP ( SST, 20 Newsgroups / SST ) datasets show that focal loss achieves state - of - the - art accuracy and calibration."
SP:cd6b8417ec8bcb773c78cff677bb0a76d6b3f6f3,"This paper introduces LiPopt, a polynomial optimization framework for computing increasingly tighter upper bounds on the Lipschitz constant of neural networks. The main idea is to use the sparse connectivity of a network, to significantly reduce the complexity of computation. This is specially useful for convolutional as well as pruned neural networks, and the authors conduct experiments on networks with random weights and networks trained on MNIST, showing that in the particular case of the $ \ell_\infty$-Lipshitz constant, the proposed approach yields superior estimates, compared to baselines available in the literature."
SP:31c9dc0dd8806daddc9cb48c56ec819577fe46cd,"This paper proposes a self - supervised learning approach for video features. The proposed method extends the BERT model for text sequences to the case of sequences of real - valued feature vectors, by replacing the softmax loss with noise contrastive estimation ( NCE ). The authors also show how to learn representations from sequences of visual features and sequences of words derived from ASR ( automatic speech recognition ), and show that such cross - modal training ( when possible ) helps even more. Finally, the authors demonstrated that their method learns features that are far more useful than existing self - supervised methods for a variety of downstream video tasks."
SP:0f24424d10f1201dd25e8c56354e10afc9b2b11c,This paper proposes an approach to reduce the amount of data that needs to be transferred between servers and clients during the inference phase of a neural network. The authors propose a framework that automatically learns to select the relevant parts of the input data for a given neural network and its task. The selection masks are trained jointly with the corresponding neural network during the training phase. The experiments show that it is often possible to achieve a good accuracy with significantly less input data needed to be transfer.
SP:aa4fcf5b2cae05c5c6a903c24e4992b56655dee2,"This paper proposes a method for simultaneous classification and out - of - distribution detection. The proposed loss function includes two regularization terms where the first minimizes the l1 norm between the output distribution of the softmax layer of a DNN and the uniform distribution, while the second minimizes Euclidean distance between the training accuracy and its average confidence in its predictions on the training set. Experiments show that the proposed method can be combined with Mahalanobis distance - based classifier ( Lee et al., 2018b ) and achieves SOTA results in the OOD detection task."
SP:89bc528ef801182365ac279e8963803afccb391d,"This paper proposes an end - to - end deep learning model, called E2Efold, for RNA secondary structure prediction which can effectively take into account the inherent constraints in the problem. The key idea is to directly predict the RNA base - pairing matrix, and use an unrolled algorithm for constrained programming as the template for deep architectures to enforce constraints. With comprehensive experiments on benchmark datasets, the authors demonstrate the superior performance of the proposed method. It predicts significantly better structures compared to previous SOTA ( especially for pseudoknotted structures ) while being as efficient as the fastest algorithms in terms of inference time."
SP:b68560cce8c64ebe0ca5e6534b3732c775d36452,This paper proposes a method to improve the performance of agents by training a collective policy on simulated environments. The idea is to train the collective policy by visiting the simulated environments of each agent individually. This is done by having agents take turns to visit the simulated episodes and interact with their own biased representations of the environment. The authors show that the proposed method outperforms the best individually trained policies in terms of performance.
SP:bd1dc08b4fd9a5cc78d26d7eb7f05dbb4a629ab1,"This paper proposes a novel dialog generation model that learns a semantic latent space. The latent space is learned by maximizing the correlation between the features extracted from prompt and responses. An additional autoencoder is trained, for recovering the full sentence from the latent space from the prompt. Experimental results show that the proposed model eliminates the generic response problem, while achieving comparable or better coherence compared to baselines."
SP:ef0d5fd333ed60feb3946d24002e9a90642aea66,"This paper proposes a simple yet effective salient explanation method called Gaussian light and shadow ( GLAS ), which estimates the spatial impact of deep models by the feature perturbation inspired by light & shadow in nature. GLAS provides a useful coarseto - fine control benefiting from scalability of Gaussian mask. The authors also devised the ability to identify multiple instances through recursive GLAS. They prove the effectiveness of GLAS for fine - grained classification using the fine - grain classification dataset. They also illustrate that GLAS has state - of - the - art performance at high speed via the ImageNet Large Scale Visual Recognition Challenge."
SP:d17ca20cc527c28ab7358cb5b14954e5fb56409f,"This paper proposes a method to remove pixel - wise and channel - wise correlations in convolutional neural networks ( CNNs ). The method is inspired by the center - round structure found in biological neurons in the visual regions of the brain. The proposed method is shown to improve the optimization efficiency over standard batch normalization. Extensive experiments show that the network deconvolution operation is able to deliver performance improvement in all cases on the Cifar-10, CIFAR-100, MNIST, Fashion-MNIST, Cityscapes and ImageNet datasets."
SP:e1b0de9a36bf8359df368b7a55a7f23e99d88db7,"This paper proposes a novel quantization method for GANs based on EM algorithms, named as QGAN. The authors conduct an extensive study on the effectiveness of quantization methods which are widely used in CNNs. They observe that none of them generates samples with reasonable quality because of the underrepresentation of quantized weights in models, and the generator and discriminator networks show different sensitivities upon the quantization precision. Motivated by these observations, the authors develop a novel QGAN method for quantization. The experiments on various GAN models and different datasets show that QGAN can generate samples in a comparable quality in cases using even only 1 - bit or 2 - bit representations."
SP:58c4905f59f04a50b30d27c99521126a6455d38a,This paper studies the convergence of the Hamiltonian gradient descent ( HGD ) algorithm to the Nash equilibrium in the nonconvex - nonconcave setting. The authors show that HGD converges to the NE of the Dirac - GAN when the second - order derivatives of the objective are sufficiently bilinear. They also prove convergence rates for stochastic HGD and for some parameter settings of Consensus Optimization algorithm of Mescheder et al. ( 2017 ).
SP:d8556b52272321a1415ac2d85bb12e88b51ee73a,"This paper studies the stability of the forward / backward process of ResNet. Specifically, the authors provide a non - asymptotic analysis on the forward and backward stability for ResNet block hl = 1 / \sqrt{L}$, where L is the number of residual blocks and $ \tau$ is a scalar. They show that for standard initialization used in practice, $ \mathbb{R}(L)$ is sharp value in characterizing the stability. The authors also show that if ResNet is properly over - parameterized, gradient descent is guaranteed to find the global minima 1, which significantly enlarges the range of $ 1 / L$ that admits global convergence in previous work. They also demonstrate that the over - parameterization requirement of Res net only weakly depends on the depth, which corroborates the advantage of Resnet over vanilla feedforward network. Empirically, with $ 1/ L$, deep ResNet can be easily trained."
SP:cf70dc496825ece2f28fdf4f1a6f4316c69e0e48,"This paper proposes RigL, a method to train sparse neural networks with a fixed parameter count and a fixed computational cost throughout training, without sacrificing accuracy relative to existing dense - to - sparse training methods. RigL updates the topology of the network during training by using parameter magnitudes and infrequent gradient calculations. The authors show that this approach requires fewer floating - point operations ( FLOPs ) to achieve a given level of accuracy compared to prior techniques. They demonstrate state - of - the - art sparse training results with ResNet-50, MobileNet v1 and MobileNet V2 on the ImageNet-2012 dataset, WideResNets on the CIFAR-10 dataset and RNNs on the WikiText-103 dataset."
SP:d2d2b892518d54d0e63e26a056f2298be3be2610,"This paper proposes a method to control the generative process of GANs by finding meaningful directions in the latent space of any generative model along which we can move to control specific properties of the generated image like the position or scale of the object in the image. The proposed method does not require human annotations and is particularly well suited for the search of directions encoding simple transformations such as translation, zoom or color variations. The authors demonstrate the effectiveness of their method qualitatively and quantitatively, both for GAN models and variational auto - encoders."
SP:1c63389e972d4652fac831e9d11609cd3c3c371a,"This paper proposes a physics - as - inverse - graphics approach to learn physical parameters of systems from video. The key idea is to use a coordinate - consistent decoder to reconstruct the image from the differential equations governing the scene dynamics. The decoder is then used to learn the dynamics of an actuated system, which can then be used to perform vision - based model - predictive control. The paper shows that the proposed method outperforms other unsupervised methods in long - term future frame prediction of systems with interacting objects ( such as ball - spring or 3 - body gravitational systems ), due to its ability to build dynamics into the model as an inductive bias. It also shows the value of this tight vision - physics integration by demonstrating data - efficient learning of vision - actuated model - based control for a pendulum system."
SP:c6b8b682bf3087a65cb2379700b8a0183853c2af,"This paper proposes a new method for learning a classifier from noisy labels when a few clean labeled examples are given. The structure of clean and noisy data is modeled by a graph per class and Graph Convolutional Networks ( GCN ) are used to predict class relevance of noisy examples. The GCN is treated as a binary classifier learning to discriminate clean from noisy examples using a weighted binary cross - entropy loss function and then the GCN - inferred “ clean ” probability is exploited as a relevance measure. The proposed method outperforms the transductive approach ( Douze et al., 2018 ) that is using the same additional data without labels."
SP:dd9c9a5dccbba5dd15b03ca6b314a9e153e95548,"This paper proposes a new GNN architecture that maximizes the mutual information between edge features and message passing channels. The MI is reformulated as a differentiable objective via a variational approach. The authors show that the newly introduced objective enables the model to preserve edge information, and empirically corroborate the enhanced performance of MI - maximized models across a broad range of learning tasks including regression on molecular graphs and relation prediction in knowledge graphs. The paper also conducts attribution analysis to understand how our EIGNN reduces the regression error."
SP:f1cf63d728da51b4f83eb50ef69e3788b3a5ed74,"This paper proposes a method to verify the properties of generative neural networks. The method is based on the idea of non - convexity in the latent space of a generative model. The main idea is to relax the parameters of the generative models to allow for more robustness to different head rotations. The proposed method, called Propexline, is a combination of two existing methods. The first method is a deterministic method, where the output of the neural network is sampled from a latent space. The second one is a probabilistic method, in which the outputs of the network are drawn from a set of latent variables. The authors show that the proposed method is faster and more precise than previous methods for the same networks."
SP:2b0887dcf09249e8cee30d38163aeb9ef1e92b27,"This paper studies the problem of "" suspended animation "" in graph neural networks ( GCN ), where the model depth reaches a limit and the model becomes not respond to the training data any more and becomes not learnable. To address this problem, this paper introduces the GRESNET ( Graph Residual Network ) framework, which creates extensively connected highways to involve nodes ’ raw features or intermediate representations throughout the graph for all the model layers. The experiments show the effectiveness of the introduced new graph residual terms from the norm preservation perspective, which will avoid dramatic changes to the node ’s representations between sequential layers."
SP:dc436ade4d04072de35a90e5e4a1bfebfddb04e9,"This paper proposes an adversarial training method for face reconstruction from unlabeled and labeled images. The proposed method is based on 3D morphable models ( 3DMM ), which is a non - linear parametric model. The authors train their model with adversarial loss in a semi - supervised manner on a hybrid batch of unlabelled and labeled face images. A novel center loss is introduced to make sure that different facial images from the same person have the same identity shape and albedo. Besides, the proposed model disentangles identity, expression, pose, and lighting representations, which improves the overall reconstruction performance and facilitates facial editing applications, e.g., expression transfer. Extensive experiments show that the model achieves state - of - the - art performance in face reconstruction."
SP:f7bc06697b09e2d59ec06b2cbcf3c0828ece32ae,"This paper introduces the Expert Induced Markov Decision Process ( eMDP ) model as a formulation of solving imitation problems using Reinforcement Learning ( RL ) when only partial knowledge about the transition kernel is available. The idea is to replace the unknown transition kernel with a synthetic kernel that: 1 ) simulate the transition of state components for which the transition model is known, and 2 ) extract from demonstrations the state components that the kernel is unknown. The next state is then stitched from the two components : s = { SR, su }. The authors describe in detail the recipe for building an e - MDP and analyze the errors caused by its synthetic kernel. The experiments include imitation tasks in multiplayer games where the agent has to imitate one expert in the presence of other experts for whom we can not provide a transition model. They show that combining a policy gradient algorithm with our model achieves superior performance compared to the simulation - free alternative."
SP:82cce92821e8168ab4a6fd67573b66c1d17673b8,"This paper proposes a new self - supervised reinforcement learning method, called MISC, for learning to control states of interest without any external reward function. The authors formulate the intrinsic objective as rewarding the skills that maximize the mutual information between the context states and the states of the object. They evaluate the method on two robotic manipulation tasks from OpenAI Gym and a navigation task in the Gazebo simulator. They show that their method is able to learn to manipulate the object, such as pushing and picking up, purely based on the intrinsic mutual information rewards. Furthermore, the pre - trained policy and mutual information discriminator can be used to accelerate learning to achieve high task rewards."
SP:5db63d39cfd8132bec832ab64b8fbd403b3b8df0,"This paper proposes a trojan - based attack method for the neural network ( NN ) trojaning attack. The authors propose to insert the trojan into the ImageNet model and attack the victim model for the two smaller datasets. The attack is programmable that the malicious misclassification target is not fixed and can be generated on demand even after the victim ’s deployment. Compared to existing NN trojan methods, the proposed trojan supports dynamic and out scope target classes, which makes it broadly applicable. The trojan can be inserted into large - scale models, which provides well - learned general features. Further analyses show that the proposed attack is difficult to be detected or removed for existing defense methods."
SP:35ea626ee4dd1a7a368a660eb852192924966b7f,"This paper proposes a new few - shot regression ( FSR ) algorithm for the task of drug discovery. The proposed method is based on the idea of deep kernel learning, where a neural network is used in combination with a kernel function and a differentiable kernel algorithm. The choice of kernel is critical, and the proposed method learns to find the appropriate kernel for each task during inference. Experiments on synthetic and real - world datasets show that the proposed algorithm outperforms existing FSR algorithms."
SP:91ca4c3ee07617356250bae9f4ef9799b3b134ff,"This paper proposes a framework to characterize which reasoning tasks a neural network can learn well, by studying how well its computation structure aligns with the algorithmic structure of the relevant reasoning process. The authors formally define this algorithmic alignment and derive a sample complexity bound that decreases with better alignment. This framework offers an explanation for the empirical success of popular reasoning models, and suggests their limitations. On four categories of reasoning tasks with increasingly complex structure, the authors apply their framework to analyze which tasks some popular neural networks such as MLP, GNNs, and DP can generalize better than others."
SP:a52aee8da5cf5acd2baf3c2a62cb679e13b18bd5,"This paper proposes a new metric called Fréchet Joint Distance ( FJD ), which is able to implicitly assess image quality, conditional consistency, and intra - conditioning diversity within a single metric. The proposed metric is based on the idea of joint distributions of images and conditioning, which allows it to implicitly capture the aforementioned properties. The authors conduct proof - of - concept experiments on a controllable synthetic dataset, which consistently highlight the benefits of FJD when compared to currently established metrics. Moreover, they use the newly introduced metric to compare existing cGAN - based models for a variety of conditioning modalities ( e.g. class labels, object masks, bounding boxes, images, and text captions ). They show that FJD can be used as a promising single metric for cGAN benchmarking and model selection."
SP:fa822e8472efae17c7dfde8258057898383ecbbb,"This paper proposes a novel approach to identify decision states in a task - agnostic manner. The authors use the VIC framework ( Gregor et al., 2016 ), which maximizes an agent ’s ‘ empowerment ’, i.e., the ability to reliably reach a diverse set of states, and formulate a sandwich bound on the empowerment objective that allows identification of decision states. The decision states are discovered without extrinsic rewards – simply by interacting with the world.   The authors show that their approach yields decision states that align with human intuition across environments, and aid directed exploration on external - reward tasks and subsequently lead to better success rate and sample complexity in novel environments."
SP:a19a51df7e28a5d3380be4fba13842efbfe3efec,"This paper proposes a method for classifying time series with irregularly sampled and unaligned measurements, focusing on high scalability and data efficiency. The method SEFT ( Set Functions for Time Series ) is based on recent advances in differentiable set function learning, extremely parallelizable, and scales well to very large datasets and online monitoring scenarios. The authors extensively compare their method to competitors on multiple healthcare time series datasets and show that it performs competitively whilst significantly reducing runtime."
SP:4ae89d64460b08749acc192004545c1fa8b7553b,"This paper proposes an operation called Harmonic Convolution to model audio signals by explicitly utilizing the harmonic structure in convolutional kernels. The authors show that current network architectures for audio processing do not show strong evidence in capturing such priors, and propose an operation that helps deep networks model priors in audio signals. This is done by engineering the kernels to be supported by sets of harmonic series, instead of by local neighborhoods as convolutionsal kernels as in previous works. The experiments show that networks using Harmonic convolution can reliably model audio priors and achieve high performance on unsupervised audio restoration tasks and achieve better generalization performance for supervised musical source separation."
SP:c81a2b3fd1c56b9b18e4a358e3ff8b40aea5256a,"This paper proposes to use data echoing to reduce the total computation used by earlier pipeline stages and speed up training whenever computation upstream from accelerators dominates the training time. Data echoing reuses ( or “ echoes ” ) intermediate outputs from previous pipeline stages in order to reclaim idle capacity. The authors investigate the behavior of different data echoing algorithms on various workloads, for various amounts of echoing, and for various batch sizes. They find that in all settings, at least one data echoing algorithm can match the baseline ’s predictive performance using less upstream computation."
SP:b4cf56d3fa7d65cacde33f17cd04bd5bbc52dd71,"This paper proposes Variational Intrinsic Successor FeatuRes ( VISR ), a novel algorithm that learns controllable features that can be leveraged to provide enhanced generalization and fast task inference through the successor features framework. The proposed method combines behavioral mutual information ( BMI ) with successor features ( SF ) to learn features that maximize the features required by SF. Experiments on the full Atari suite demonstrate the effectiveness of the proposed method."
SP:83500230586a9134f910ad067b7233dc563dc1ba,"This paper studies the generalization properties of overparameterized FC ReLu networks. The authors show that the smoothness of the functional approximation, combined with a flat initial approximation, explains why massively overparametrized networks continue to generalize well. In particular, the global, rather than local, impact of breakpoints and delta - slopes helps regularize the approximating function in the large gaps between training data, resulting in their smoothness. This paper also shows that curvature - based parametrization of the approximations helps preserve ( i ) and regularize via ( ii )."
SP:7225825e353b711a7d023f706fafe5e17e4e2fb2,"This paper proposes a GAN - based method for image - to - image translation. The proposed method is based on the attention mechanism of the discriminator in GANs. The discriminator uses an attention mechanism to estimate the probability that the input is real, and the generator uses it to produce more realistic images. The method is evaluated on a number of image transfer tasks. The experimental results show that the proposed method outperforms the baselines."
SP:41c089ba65393174dae1dc136f79030a0a4fc532,"This paper investigates the role of multiplicative interaction layers in a variety of classical and modern neural network architectural motifs, such as gating, attention layers, hypernetworks, and dynamic convolutions. The authors show that such layers strictly enrich the representable function classes of neural networks. They conjecture that multiplicative interactions offer a particularly powerful inductive bias when fusing multiple streams of information or when conditional computation is required. They argue that they should be considered in many situation where multiple compute or information paths need to be combined, in place of the simple and oft - used concatenation operation. Finally, they back up their claims and demonstrate the potential of such layers by applying them in large - scale complex RL and sequence modelling tasks, where their use allows them to deliver state - of - the - art results."
SP:5144391584e6d3825e12684b7c053e4e282cff2b,"This paper proposes a new algorithm for batch active learning with deep neural network models. The algorithm, called BADGE, samples groups of points that are disparate and high magnitude when represented in a hallucinated gradient space. The authors show that BADGE incorporates both predictive uncertainty and sample diversity into every selected batch. Crucially, BADGE trades off between uncertainty and diversity without requiring any hand - tuned hyperparameters. While other approaches sometimes succeed for particular batch sizes or architectures, the BADGE consistently performs as well or better."
SP:ce6023b1e6bf45b071a6f5457b2575425ae03366,"This paper proposes a novel feature - level architecture to improve the interpretability of deep neural networks ( DNNs ). The main idea is to use the GLM layer in the DNN to isolate the low - level features from the high - level ones. The proposed method is based on the idea of feature leveling, which is a popular technique in deep learning. The paper presents a toy example to show the effect of the mixture effect of features in hidden layers. The experiments show that the proposed method outperforms the state - of - the - art DNN models on MNIST and CIFAR-10."
SP:b70ceead1bf6c7dc684c74501716e7012b891022,"This paper proposes a method for training a classifier over a large number of classes, known as ‘ extreme classification ’. The method is based on a scalable approximation to the softmax loss function via a generalized form of negative sampling. By generating adversarial negative samples from an auxiliary model, the authors prove that they maximize the signal - to - noise ratio of the stochastic gradient estimate. They also show that, while the auxiliary model introduces a bias, they can remove the bias at test time."
SP:29b52fee83309268d9864f3b1fc3617948577d41,"This paper proposes a new exploration method that leverages a low - dimensional encoding of the environment learned with a combination of model - based and model - free objectives. The proposed method uses intrinsic rewards that are based on a weighted distance of nearest neighbors in the low dimensional representational space to gauge novelty, and then leverage these intrinsic rewards for sample - efficient exploration with planning routines in representational spaces. One key element of the approach is that we perform more gradient steps in - between every environment step in order to ensure the model accuracy is high ( and hence ensure an accurate novelty heuristic ). Through this training scheme, our agent is also able to learn a meaningful representation of its state space in an extremely sample efficient manner."
SP:257c98dc1a9f3efcbf9544d9ee2ff524b000543d,"This paper studies the problem of out - of - distribution ( OOD ) detection in the few - shot classification setting. The authors propose two new methods for OOD detection : - MinDist and LCBO. The first method, MinDist, is based on the existing confidence scores developed in the supervised setting ( i.e., setting with a fixed number of classes ). The second method, LCBO, builds on the MinDist method to provide a new confidence score for out of distribution detection. The two methods are evaluated on four popular few shot classification datasets. Results show that MinDist outperforms the baselines on both OOD and OOD tasks."
SP:a3632b773143dfb3a8f104c6b658dfa1167d155b,"This paper proposes a generalized model of sequence generation that unifies decoding in directed and undirected models. The proposed framework models the process of generation rather than a resulting sequence, and under this framework, the authors derive various neural sequence models as special cases, such as autoregressive, semi - auto - regressive, and refinement - based non - Autoregressive models. This unification enables the authors to adapt decoding algorithms originally developed for directed sequence models to the unsupervised setting. The authors demonstrate this by evaluating various decoding strategies for a cross - lingual masked translation model ( Lample and Conneau, 2019 )."
SP:eca5e2be9831dfb79c4f5e633cbfadcfd2e00eb1,"This paper proposes a two - stage approach for the recognition of mathematical expressions ( MEs ). In the first stage, the proposed method uses object detection algorithm to detect the math symbols of the input image by YOLOv3, and in the second stage, it uses seq2seq model equipped with attention mechanism to translate math symbols with position information into LaTeX sequences. The proposed method significantly outperforms the end - to - end method. The ExpRate(expression recognition rate ) of our model is 74.1 % higher than that of the end-to - end model on the test data that does not come from the same source as training data."
SP:923fee8623da1569a7f54a57b4b326f29440b4c0,"This paper proposes a vector quantization method to reduce the memory footprint of convolutional neural networks. The proposed method is based on Product Quantization ( PQ ), which aims at preserving the quality of the reconstruction of the network outputs rather than its weights. The method only requires a set of unlabelled data at quantization time and allows for efficient inference on CPU by using bytealigned codebooks to store the compressed weights. Experiments show that applying the proposed method to the semi - supervised ResNet-50 of Yalniz et al. ( YalNiz et. al., 2019 ) leads to a 5 MB memory footprint and a 76.1 % top - 1 accuracy on ImageNet object classification."
SP:74850ad70241948f93fed95ba1f0ac11360437c1,"This paper presents a transformer - based model that uses Tensor - product representations to encode structural relations between cells in the Transformer architecture. Specifically, the paper proposes a new attention mechanism, called TP - Attention, which explicitly encodes the relations between each Transformer cell and the other cells from which values have been retrieved by attention. The paper shows that the proposed TP - attention can resolve the ambiguity introduced by multiple layers of standard attention, and it is shown theoretically how it avoids such ambiguity ( Sec.2 )."
SP:d319df820c6630c409fab32097652a083e8f53ea,"This paper studies the problem of generalization in deep neural networks. The authors propose to use the information distance between the training and test sets as a metric for generalization, which is defined as the difference between training error and inference error. The paper derives a necessary and sufficient condition for this metric based on the Kolmogorov complexity. Then, the authors formulate an optimization problem to learn a more general classification function. To achieve this, they use channel codes on the input features as a systematic way to improve the degree to which the training sets are representative of the empirical sample set. Experiments demonstrate that a model trained on arbitrarily encoded input features is more robust to common corruptions and adversarial perturbations and that using more encodings may be beneficial to minimize the generalization error."
SP:b8e86f5e89330d81ba4967a7ed2dbfb56375d8a0,"This paper proposes a new graph pooling operation based on compressive Haar transforms, called HaarPooling. The proposed method is computed by following a chain of sequential clusterings of the input graph. The input of each pooling layer is transformed by the compressed Haar basis of the corresponding clustering. The Haar pooling operates in the frequency domain by the synthesis of nodes in the same cluster and filters out fine detail information by compressive haar transforms. Such transforms provide an effective characterization of the data and preserve the structure information. By the sparsity of the Haar based, the computation of Haarpooling is of linear complexity. The experimental results on benchmark graph classification tasks compared with existing Graph pooling methods."
SP:17bea301d6718ef5f28864dd2445552b3cf65eeb,"This paper proposes a new point cloud decoder architecture based on a sampling - based approach. The proposed architecture is based on the PointNet encoder, which is a fully connected network that maps shape representations to a fixed number of output points. In contrast, the proposed architecture uses a sample - based decoder that maps a shape representation to a point feature distribution, allowing an arbitrary number of sampled features to be transformed into individual output points, which are then fed into the decoder network. The authors evaluate the performance of the proposed architectures on CIFAR-10/100 and ImageNet and compare their performance to feedforward architectures and show their improved effectiveness."
SP:51d826ead5d1d9cb89d493ce4c39728651bbc57b,"This paper presents a benchmark of real - world noisy labels at 10 controlled noise levels. The authors conduct a large - scale study across a variety of noise levels and types, architectures, methods, and training settings. The results show that : ( 1 ) Deep Neural Networks ( DNNs ) generalize much better on real world noise than synthetic noise. ( 2 ) When networks are fine - tuned, ImageNet architectures generalize well on noisy data. ( 3 ) Real - world noise appears to be less harmful, yet it is more difficult for robust DNN methods to improve. ( 4 ) Robust learning methods that work well on synthetic noise may not work as well on real-world noise."
SP:9873f78fb2821afdbb5551700e6ab6a0e8bcb9f0,"This paper proposes a new method for learning from human supervision. The authors propose a rule - exemplar method to combine the efficiency of rules with the quality of instance labels. The supervision is coupled such that it is both natural for humans and synergistic for learning. They propose a training algorithm that jointly denoises rules via latent coverage variables, and trains the model through a soft implication loss over the coverage and label variables. The denoised rules and trained model are used jointly for inference. Empirical evaluation on five different tasks shows that their algorithm is more accurate than several existing methods of learning from a mix of clean and noisy supervision."
SP:6f2c656dbb7629f652a4291d6971625184d8118b,This paper proposes an efficient memory layer for GNNs that can jointly learn node representations and coarsen the graph. It also introduces two new networks based on this layer : memory - based GNN ( MemGNN ) and graph memory network ( GMN ) that can learn hierarchical graph representations. The experimental results show that the proposed models achieve state - of - the - art results in eight out of nine graph classification and regression benchmarks. The paper also shows that the learned representations could correspond to chemical features in the molecule data.
SP:81bc52d734c86975d741b6482d65ca71a9d81620,"This paper studies the effect of initialization in deep linear networks on the convergence time of gradient descent. The authors provide a proof that drawing the initial weights from the orthogonal group speeds up convergence relative to the standard Gaussian initialization with iid weights. They show that for deep networks, the width needed for efficient convergence to a global minimum is independent of the depth. They also show that Gaussian initialization leads to exponentially long convergence time if the width is too small compared with the depth, whereas the width needs to be at least as large as the depth in the case of iid initialization."
SP:9f5d95fc89c2f0d59d04838aa180f3db67997dfa,"This paper proposes a new quantization method to compress the weights and activations of deep neural networks. The main idea is to apply uniform scalar quantization to quantize the activations and weights separately. The quantizer stepsize is individually chosen for each layer ’s weights and activation. The authors also incorporate a dead zone into the quantizers for weights. Experimental results show that the proposed method can compress deep CNNs ( e.g., ResNet-50 ) down to 2 bits and the accuracy loss is less than 0.7%."
SP:7191d7b217a12b1bf9c47d790896a8227c14cc3d,"This paper proposes a novel inference WGAN ( iWGAN ) model, which is a principled framework to fuse auto - encoders and Wasserstein GANs.   The proposed method jointly learns an encoder network and a generative network using an iterative primal dual optimization process. The authors also provide a rigorous probabilistic interpretation of their model under the framework of maximum likelihood estimation. The iWAGN, with a clear stopping criteria, has many advantages over other autoencoder GANS. The empirical experiments show that the proposed method mitigates the symptom of mode collapse, speeds up the convergence, and is able to provide a measurement of quality check for each individual sample."
SP:cca6ae14fd0dd12352855e594acf7f3263bb1f24,"This paper extends the mention pair model of anaphoric annotation ( MPA ) of Paun et al. ( 2018b ) with hierarchical communities of annotators. Specifically, the authors use a nonparametric partially pooled structure ( based on a stick breaking process ) to alleviate the effects of sparsity inherent in some crowdsourcing environments. The authors show, using a recently published large - scale crowdsourced anaphora dataset, that the proposed model performs better than its unpooled counterpart in conditions of Sparsity, and on par when enough observations are available. The model is thus more resilient to different crowdsourcing setups, and, further provides insights into the community of workers."
SP:4295cae4a56a02eb21c486408c1bf37a7483cb49,"This paper proposes a hierarchical agent SID that schedules between following extrinsic and intrinsic drives to accelerate exploration and stabilize learning. The intrinsic reward is based on the successor feature control ( SFC ), which takes into account statistics over complete trajectories and thus differs from previous methods that only use local information to evaluate intrinsic motivation. The proposed intrinsic reward SFC and the hierarchical exploration framework SID are without any task - specific components, and can be incorporated into existing DRL methods with minimal computation overhead. The experimental results show a substantially improved exploration efficiency with SFC."
SP:9fa22eb03a79bce0fc1c8e84ae8640e010701eca,"This paper proposes a method for weakly - supervised video moment retrieval based on word - by - word word interaction and word - conditioned visual graph ( WCVG ). Specifically, the proposed method uses a multi - level attention mechanism to learn richer multimodal representations. The proposed method is evaluated on two datasets : DiDeMo and Charades - STA, where it outperforms the state - of - the - art weakly supervised method by a significant margin."
SP:27ac670353f34ee7a23bb7622f80c1dfbc0985e0,This paper proposes an image - guided rendering method that combines image - based rendering and GAN - based image synthesis. The main idea is to train an object - specific deep neural network to synthesize the view - dependent appearance of an object using an RGB video of the object. The proposed method is evaluated on synthetic and real - world datasets.
SP:257d124367b1da9a595dc11a9df750d6bade298e,"This paper presents a sparse representation of model uncertainty for deep neural networks ( DNNs ) that relies on an inverse formulation of Multivariate Normal Distribution ( MND ) : an information form. The paper shows that the model uncertainty can be estimated in this form using a scalable Laplace Approximation scheme, which involves a diagonal correction of the Kronecker - factorized eigenbasis. As this makes the inversion of the information matrix intractable an operation that is required for a full Bayesian analysis, the paper further devise a novel low - rank approximation of this eigenbais that exploits spectral sparsity of DNN. Methods to realize this sparsification are provided that develops into a memory - wise tractable sampling computations. Both theoretical analysis and empirical evaluations over various benchmarks show the superiority of our approach over existing methods."
SP:2e03ceba4004b82f86f8349352a8ee4520e9c35d,"This paper proposes a load - balanced hashing method to improve the performance of One Permutation Hashing ( OPH ) and densification strategies in MinHash. The main idea is to balance the load of the bins ( the number of elements in a bin ) in OPH to reduce the empty bins in advance. The proposed method is evaluated on two benchmark datasets and compared with OPH and OPH. The results show that the proposed method outperforms the state - of - the - art OOPH in similarity estimating, large - scale learning and fast near neighbour searching."
SP:d73827ab98b0ff6bd92abfefea43a5f88ea40de2,This paper proposes a method for analyzing periodic data by adding a graph structure to each data point and constructing a machine learning model according to the characters of the graph structure and the original data. The proposed method performs a cyclic permutation to a graph neural network to ensure that the results account for phase shift of the periodic measurements. The paper demonstrates that adding a certain structure to data is shown to be very effective for feature extraction.
SP:0df5ad333eb4ff9cca7f2d117909e2ce533a65d8,"This paper proposes a confidence - oriented decoder for neural conditional text generation. The key idea is to use a variational Bayes objective to learn a confidence score for each target position, which is then used to calibrate the decoder at inference time. Experiments on a structured data - to - text dataset show that the proposed method is more faithful to the source than existing state - of - the - art approaches, according to both automatic metrics and human evaluation."
SP:03307deac29173b2968fbd08f95fc77eb1f82410,"This paper proposes a novel lookahead pruning ( LAP ) scheme to reduce the Frobenius distortion of a single - layer operation incurred by magnitude - based pruning. LAP is motivated from linear networks, and extends to nonlinear networks which indeed minimizes the root mean square lookahead distortion assuming i.i.d. activations. The authors empirically show its effectiveness on networks with nonlinear activation functions and test the algorithm on various network architectures including VGG, ResNet and WRN, where LAP consistently performs better than MP."
SP:dc80fdc75bc14ae19fe4ba9b85c35ce00b12856f,"This paper proposes Moniqua, a decentralized stochastic gradient descent algorithm that uses quantized communication. The authors prove in theory that it can communicate a provably bounded number of bits per iteration, while converging at the same asymptotic rate as the original algorithm does with full - precision communication. In addition, the authors show empirically that the proposed algorithm converges faster with respect to wall clock time than other quantized decentralized algorithms."
SP:86c61a658d07ab86e2d84cef7e480bf7a06e4ddb,"This paper proposes a modification to the partial model in reinforcement learning to make it more robust to policy changes. The modification is based on the idea that partial models can be incorrect if they are confounded by the observations they don’t model, and can therefore lead to incorrect planning. To address this, the authors introduce a general family of partial models that are provably correct, yet remain fast because they do not need to fully model future observations. The proposed modifications address the correctness of the model against policy changes, but not the correctness / robustness against other types of intervention in the environment. The experiments show the effectiveness of the modifications."
SP:c70479b2096a52584b242de58272ca8d8565feea,"This paper proposes a variational autoencoder ( VAE ) model that learns a succinct common representation of two correlated data variables for conditional and joint generation tasks. The proposed model is based on two information theoretic problems -- distributed simulation and channel synthesis -- in which Wyner ’s common information arises as the fundamental limit of the succinctness of the common representation. The Wyner VAE decomposes a pair of correlated variables into their common representation and local representations that capture the remaining randomness ( e.g., texture and style ) in respective data variables by imposing the mutual information between the data variables and common representation as a regularization term. The utility of the proposed approach is demonstrated through experiments for joint and conditional generation with and without style control using synthetic data and real images. Experimental results show that the proposed model outperforms existing VAE variants and the information bottleneck method."
