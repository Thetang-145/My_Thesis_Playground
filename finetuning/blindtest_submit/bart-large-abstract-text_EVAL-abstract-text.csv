paper_id,summary
SP:b19df5243359791fbaad005d6f13d7e9fdb0ff63,"This paper proposes a method for multi-agent role-based learning. The proposed method first decomposes joint action spaces into restricted role action spaces by clustering actions according to their effects on the environment and other agents. Then, the role selector searches in a smaller role space and at a lower temporal resolution, while role policies learn in significantly reduced primitive action-observation spaces. The authors further integrate information about action effects into the role policies to boost learning efficiency and policy generalization. "
SP:7deb61890d97422a0fe141ca807f968c70ab239a,"This paper studies the behavior of the stochastic subgradient descent (SSGD) method applied to over-parameterized nonsmooth optimization problems that satisfy an interpolation condition. The authors prove that SSGD converges, respectively, with rates O(1/ ) and O(log(1)$ for convex and strongly-convex objectives when interpolation holds. These rates coincide with established rates for SGD. "
SP:c7e0b3fedc0d0409d662dd612b529fdacad2b03e,"This paper proposes to use non-linear ""reservoir"" layers to improve the performance of transformer-based machine translation and language modelling. In particular, the authors propose to use a variety of nonlinear “reserveoir” layers interspersed with regular transformer layers, and show improvements in wall-clock compute time until convergence, as well as overall performance, on various machine translation tasks. "
SP:ba9f1d4738ec67a440346f3ac6c4cf35f7232077,This paper studies the group representation theory of steerable CNN. The authors show that kernel constructed by filter transform can also be interpreted in the group representations theory. They show that filter transformed kernels can be used to convolve input/output features in different group representation. They also provide a simple approach to implement steerable convolution operators. 
SP:c1116fbb4d058eb6be195b5d13d19a55ba86b602,"This paper proposes an optimal neural synthesis approach where the goal is to find a program that satisfies user-provided constraints while also maximizing the program’s score with respect to a neural model. Specifically, the authors focus on multimodal synthesis tasks in which the user intent is expressed using combination of natural language (NL) and input-output examples. At the core of the method is a top-down recurrent neural model that places distributions over abstract syntax trees conditioned on the NL input. This model not only allows for efficient search over the space of syntactically valid programs, but it also allows to leverage automated program analysis techniques for pruning the search space based on infeasibility of partial programs. "
SP:55e02d79146bbb42f1ab6d4fafa2db5ddbe599b0,"This paper proposes a protein graph convolutional neural network (PGCN) to predict the specificity of a protease enzyme. The proposed method is based on a structure-based molecular interaction graph generated using the Rosetta energy function, which describes the topology and energetic features, to determine the substrate specificity. The PGCN is used to recapitulate and predict the specific specificity of the NS3/4 protease from the Hepatitic C virus. "
SP:7727eeb7b17ad94ddfa0cf24e64a9626d83a8876,"This paper studies the underestimation bias in double Q-learning, which is a classical method for reducing overestimation bias. The authors show that under an approximate Bellman operator, the proposed method converges to non-optimal stationary solutions. To address this issue, the authors propose a simple but effective approach as a partial fix for the underestimating bias. "
SP:1d630b69f95392a5ef3d7d580b523e077a3555a8,"This paper proposes a two-step training framework for deep generative models (DGMs) of high-dimensional natural images. First, it generates images in low-frequency bands by training a sampler in the wavelet domain. Then, it super-resolves these images back to the pixel-space with a novel wavelet super-resolution decoder network. The proposed method preserves more structural information than pixel-based methods, leading to significantly better generative quality of the low-resolution sampler (e.g., 64×64). Since the sampler and decoder can be trained in parallel and operate on much lower dimensional spaces than end-to-end models, the training cost is substantially reduced."
SP:b943a73b1ec34867371325748dc3a91ff4011947,"This paper studies the problem of self-supervised few-shot learning (FSL). The authors first summarized the supervised FSL methods and explained why SSL is suitable for FSL. Then, they further analyzed the main difference between supervised training and self-self-training on FSL and obtained the bound for the gap between self-Supervised loss and supervised loss. Finally, the authors proposed potential ways to improve the test accuracy under the setting of Self-Self-Training. "
SP:bd552f98e6a447cefa6b1a9bbdf40bc6539fb643,"This paper studies the convergence of two-layer teacher-student neural networks with finite width. The authors prove that under the most basic settings, all student neurons must align with the teacher neuron at any local minima. The proof is extended to more general cases, where the proof can be reduced to analyzing the properties of a special class of functions that they call Angular Distance (AD) function. Finally, they demonstrate that these properties can be easily verified numerically. "
SP:0f62846913ec10b44ed32845770da0565479dc75,This paper proposes a framework for learning representations for deep neural networks that incorporate user-provided formal knowledge to improve learning from data. The proposed method is based on the idea of adaptive semantic logic (DASL). The authors provide formal semantics that demonstrate that their knowledge representation captures all of first order logic and that finite sampling from infinite domains converges to correct truth values. They illustrate DASL through a toy problem in which they add structure to an image classification task and demonstrate that knowledge of that structure reduces data requirements by a factor of 1000. 
SP:2f19259d65fab904c1b771244da3dcb2f8aa0c26,"This paper studies the convergence of feedforward residual neural networks (ResNets) to iterative solutions. The authors define three indices of iterative convergence, and introduce regularizations to encourage iterative convergent computation and test whether this provides a useful inductive bias for ResNets.   The authors show that, even though ResNs can express iterative solution, they do not learn them when trained conventionally on computer vision tasks. To make the networks more iterative, they manipulate the degree of weight sharing across layers using soft gradient coupling, and impose a Lipschitz constraint on the residual functions using spectral normalization."
SP:6c14506b8b2b06043409d912e6bf877651aaa665,"This paper presents two normalization methods, SelfNorm and CrossNorm, to promote OOD generalization. SelfNorm uses attention to recalibrate statistics (channel-wise mean and variance), while CrossNorm exchanges the statistics between feature maps. Extensive experiments on different domains (vision and language), tasks (classification and segmentation), and settings (supervised and semi-supervised) show their effectiveness."
SP:2774abdc11917321dd4994af0f0da1ff824bea03,This paper proposes to augment the attention module in the convolutional encoder of an RL agent with a simple attention module to improve the sample efficiency and final performance of the agents. The proposed method is evaluated on the DeepMind Control Suite environments.  
SP:31a7051d08d19c01e11f1fac2f3041ed2fa28f15,"This paper proposes an extension to GradNorm, a widely used gradient-based approach for training multi-task neural networks, by dynamically homogenizing not only the gradient magnitudes but also their directions across tasks. Specifically, the authors propose to add a layer of task-specific rotation matrices that aligns all the task gradients. The authors provide theoretical guarantees on the algorithm stability and convergence. The experiments on several real-world datasets and network architectures show that Rotograd outperforms previous approaches for multitask learning."
SP:ac9ebd027b92527d9a87b13ad11d002d99a2b0f6,"This paper proposes a novel I2I translation constraint, called Minimal Geometry-Distortion Constraint (MGC), which promotes the consistency of geometry structures and reduce the unwanted distortions in translation by reducing the randomness of color transformation in the translation process. To facilitate estimation and maximization of MGC, the authors propose an approximate representation of mutual information called relative Squared-loss Mutual Information (rSMI) that can be efficiently estimated analytically. The authors demonstrate the effectiveness of their MGC by providing quantitative and qualitative comparisons with the state-of-the-art methods. "
SP:92a38d7d18f07f68b8f93c61180e2cc1dddd21de,"This paper studies the effect of point sampling patterns in point cloud GANs. The authors propose a sampling spectrum to depict the different sampling sensitivities of discriminators. They further study how different evaluation metrics weigh the sampling pattern against the geometry and propose several perceptual metrics. They discover a middle-point sampling-aware baseline discriminator, PointNet-Mix, which improves all existing point cloud generators by a large margin on sampling-related metrics. "
SP:16c4be3eb162bc81cb3343c2fc115eb8e926a5b5,"This paper investigates the adversarial robustness of CapsNets. The authors show that adversarial examples misled the votes from primary capsules by manipulating the votes of primary capsules. They propose a novel vote attack where they attack votes of capsules directly. The vote attack is not only effective but also efficient by circumventing the routing process. Furthermore, they integrate their vote attack into the detection-aware attack paradigm, which can successfully bypass the class-conditional reconstruction based detection method. "
SP:dbd093dff7a38ba8882bb8119c34623ddaaf4cc6,"This paper proposes a new algorithm for meta-reinforcement learning. The key idea is to use privileged information in the form of a task descriptor at train time to improve the learning of recurrent policies. The proposed method learns an informed policy (i.e., a policy receiving as input the description of the current task) that is used to both construct task embeddings from the descriptors, and to regularize the training of the recurrent policy through parameters sharing and an auxiliary objective. The authors evaluate their algorithm in a variety of environments that require sophisticated exploration/exploitation strategies and show that it outperforms vanilla RNNs, Thompson sampling and the task-inference approaches to meta reinforcement learning."
SP:bd89d254fbf31db61db237d08ab42981e27c52df,"This paper proposes a new paradigm to learn an RL policy from offline data in the real-world sequential recommendation system (SRS). Instead of increasing the fidelity of models for policy learning, the proposed method learns to adapt to diverse simulators generated by the offline dataset. The authors show that the method overcomes the distortion problem and produces robust recommendations in the unseen real world. "
SP:1a166b28cf684e0d5759bd629f6a53370d2bf11c,"This paper proposes a method for learning goal-reaching policies from scratch. The method is based on imitation learning, where an agent continually relabels and imitates the trajectories it generates to progressively learn goal reaching behaviors. Each iteration, the agent collects new trajectories using the latest policy, and maximizes the likelihood of the actions along these trajectories under the goal that was actually reached, so as to improve the policy. The authors show that this iterated supervised learning procedure optimizes a bound on the RL objective and derive performance bounds of the learned policy."
SP:c306530164d677e670554eeba8203c66bb3d9f7a,"This paper proposes a new non-autoregressive text to speech (TTS) model, FastSpeech 2, which improves the one-to-many mapping problem in TTS by directly training the model with ground-truth target instead of the simplified output from teacher, and introducing more variation information of speech (e.g., pitch, energy and more accurate duration) as conditional inputs. The proposed model is trained with a 3x training speed-up over the existing fastSpeech model. The authors also propose two variants of the proposed model, which is the first attempt to directly generate speech waveform from text in parallel, enjoying the benefit of fully end-to end inference. "
SP:79e9fb20d383816f54738ce70d137131ebc10290,"This paper studies the unsupervised dimension reduction problem (UDR) in the language of tempered distributions, i.e. as a problem of approximating an empirical probability density function pemp(x) by another tempered distribution q(x), whose support is in a k-dimensional subspace. The authors reformulate the problem to the minimization of the distance between q and pemp, D(q, pemp), over a pertinent set of generalized functions. In particular, the authors introduce a nonnegative penalty function R(f) that “forces” the support of f to be k-diminishing. Then the authors propose an algorithm for minimization I(f + λR(f), based on the idea of two-step iterative computation, briefly described as a) an adaptation to real data and to fake data sampled around a k dimensional subspace found at a previous iteration, b) calculation of a new k-dimension subspace, and c) a new SDR. "
SP:93e54522e6c2b805905d21fc968fc40866f2898b,"This paper proposes a new method for feature contrastive learning, called Feature Contrastive Learning (FCL), that encourages the model to be more sensitive to the features that have higher contextual utility. The proposed method is based on the idea of contextual feature utility and contextual feature sensitivity. Experiments show that FCL achieves a better balance of robustness and sensitivity in the presence of noise. "
SP:f03c50f15022c4f56ac2b3085354ffed38ad1145,"This paper proposes a new method for imitation learning. The proposed method is based on adversarial learning with a latent representation inside the discriminator network, which is regularized through mutual information constraints to incentivize learning only features that encode information about the completion levels of the task being demonstrated. Empirical results show the effectiveness of the proposed method. "
SP:ef18f4188426bc01be309633b486884b0e7a81a4,"The paper studies the generalization properties of a pruned neural network. The authors show that the convex region near a desirable model with guaranteed generalization enlarges as the neural network model is pruned, indicating the structural importance of a winning ticket. The paper also shows that the number of samples required for achieving zero generalization error is proportional to the number number of the non-pruned weights in the hidden layer. "
SP:eed6cb2f8caed39f8295f4aeb6e044c2ac981c4d,"This paper proposes AutoLabel to automatically learn the labels for augmented data, based on the distance between the clean distribution and augmented distribution. AutoLabel is built on label smoothing and is guided by the calibration-performance over a hold-out validation set. Experiments show that AutoLabel can improve models’ accuracy and calibration performance, especially under distributional shift. Additionally, it can help adversarial training by bridging the gap between clean accuracy and adversarial robustness."
SP:0d5017e1a405bf86e3bac40e6e59886d4bf48450,"This paper proposes a new self-supervised objective, Representation Learning via Invariant Causal Mechanisms (RELIC), that enforces invariant prediction of proxy targets across augmentations through an invariance regularizer which yields improved generalization guarantees. RELIC significantly outperforms competing methods in terms of robustness and out-of-distribution generalization on ImageNet, while also significantly outperforming these methods on Atari achieving above human-level performance. "
SP:8f80a6f79f78c6421857f392c9a5e98061d7eb60,"This paper proposes a visual transformer network for object goal navigation. The proposed method is based on the Transformer architecture. The key idea is to learn a spatial-aware representation of the scene, which can be used to learn directional navigation signals. The authors also propose a pre-training scheme to associate the visual representations with navigation signals, and thus facilitate navigation policy learning. Experiments on the artificial environment AI2-Thor demonstrate the effectiveness of the proposed method. "
SP:3e7cbe3dff592ef371e48dd86be7719fc5343f17,This paper proposes a communication-computation efficient secure aggregation method for federated learning. The key idea is to design the topology of the secret-sharing nodes (denoted by the assignment graph G) as sparse random graphs instead of the complete graph corresponding to the existing solution. Theoretical guarantees on the reliability/privacy of the proposed scheme are provided. 
SP:00fae41e0eca0a1575cd7b2dcfabf0dc5c9c8b8a,"This paper proposes a new method for solving the auction design problem. The main idea is to use a time-independent Lagrangian instead of a hyper-parameter search to find the optimal auction. The proposed method is based on the recent work of Duetting et al. (2019), which proposes an inner maximization loop to compute optimal misreports. The authors show that the proposed method improves the performance of their method. "
SP:a0e8061beb5e9a6c631419861559d22b8d645cb4,"This paper proposes a new method for fine-tuning pre-trained models for downstream tasks. The proposed method, called Bi-Tuning, consists of two heads: a classifier head with an improved contrastive cross-entropy loss to better leverage the label information in an instancecontrast way, and a projector head with a newly-designed categorical contrastive learning loss to fully exploit the intrinsic structure of data in a category-consistent way. Experimental results show that the proposed method achieves state-of-the-art results on CUB in low-data regime."
SP:87e5b552c13d73bd85249062a152c6c140e594a9,This paper proposes a new measure for the robustness of classifiers called genuine adversarial accuracy. It can measure the adversarial robustness without trading off accuracy on clean data and accuracy on the adversarially perturbed samples. The authors prove that a single nearest neighbor (1-NN) classifier is the most robust classifier according to the genuine robust accuracy for given data and a norm-based distance metric when the class for each data point is unique. 
SP:2fda410b9281c5e253d385bc4382ec168bc161f3,"This paper studies the problem of disparate impact on graph-structured data. Specifically, the authors focus on dyadic fairness, which articulates a fairness concept that a predictive relationship between two instances should be independent of the sensitive attributes. Based on this, they theoretically relate the graph connections to Dyadic fairness on link predictive scores in learning graph neural networks, and propose a fair adjacency matrix with proper graph structural constraints for fair link prediction, and in the meanwhile preserve predictive accuracy as much as possible. Empirical validation demonstrates that their method delivers effective dyadic fair in terms of various statistics, and at the same time enjoys a favorable fairness-utility tradeoff."
SP:b614e9fbec58e9efa7722d2ec4a60fc93d210f92,"This paper proposes a new method for disentanglement-based generative autoencoders. Specifically, the authors propose a disentangled representation and regularization to guarantee the validity of exploration in latent space and achieve controllable synthesis. The encoder of DEAE first turns the input sample into a disenangled latent code, then explores the latent code space through directed interpolation. To aid the interpolated latent code in successfully outputting a meaningful sample, after the decoder, they regularize the output by ’reusing’ the encoder to force the obtained latent representation to maintain perfect disentangling. Experiments demonstrate that DEAE can improve the performance of downstream tasks by synthesizing attribute-controllable augmented samples. "
SP:c934adb14926a00ef9c73c9773cb0b3a2669921e,"This paper proposes a new Bayesian memory allocation scheme that bridges the gap between episodic and semantic memory via a hierarchical latent variable model. The authors extend the idea of locally contiguous memory to the Kanerva Machine, enabling a novel differentiable block allocated latent memory.  The authors demonstrate that this allocation scheme improves performance in memory conditional image generation, resulting in new state-of-the-art conditional likelihood values. "
SP:e63d7d8c581019e17585fb9c0eac33d6836e187d,"This paper studies the sample complexity and loss landscape of attention-based neural networks. The authors show that, under mild assumptions, every local minimum of the attention model has low prediction error, and attention models require lower sample complexity than models without attention. Experiments on various datasets validate the theoretical findings. "
SP:f739d199fdee26f09994e3f9487aec1eab0f2e89,"This paper proposes a method for learning a prior preference from experts. The authors extend the concept of expected free energy (EFE), which is a core quantity in active inference, and claim that EFE can be treated as a negative value function. The proposed method can be interpreted using reinforcement learning (RL) algorithms and find a theoretical connection between them. "
SP:5592b79e49eba95c15103a3348f2bde57b60f2ab,"This paper proposes a data augmentation method to improve generalization in both adversarial and standard learning by using out-of-distribution (OOD) data that are devoid of the abovementioned issues. The authors show how to improve theoretical theoretically using OOD data in each learning scenario and complement their theoretical analysis with experiments on CIFAR-10, CifAR-100, and a subset of ImageNet. The results indicate that undesirable features are shared even among image data that seem to have little correlation from a human point of view. "
SP:3cac7a2c310165ed0de46d8e5546c3bfbd639158,"This paper proposes a new meta-RL method called Fast Linearized Adaptive Policy (FLAP), which is able to extrapolate well to out-of-distribution tasks without the need to reuse data from training, and adapt almost instantaneously with the need of only a few samples during testing. FLAP builds upon the idea of learning a shared linear representation of the policy so that when adapting to a new task, it suffices to predict a set of linear weights. A separate adapter network is trained simultaneously with the policy such that during adaptation, it can directly use the adapter network to predict these linear weights instead of updating a meta-policy via gradient descent. The application of the separate feed-forward network not only speeds up the adaptation run-time significantly, but also generalizes extremely well to very different tasks that prior MetaRL methods fail to generalize to. "
SP:21a1bd4ada0723c96c0dbf7a142a2faf5defa4e3,"This paper proposes a federated kernel k-means algorithm for the optimization problem of kernel k means. The authors propose a distributed stochastic proximal gradient descent (DSPGD) algorithm to determine an approximate solution to the optimization of kernelk means. In addition, a communication efficient mech anism (CEM) is designed to reduce the communication cost. Theoretical analysis shows that DSPGD with CEM converges with an O(1/T) rate, where T is the number of iterations. "
SP:be568dd3fea51ce33a6d1e4b07dda5aee6342395,"The paper proposes a new once-for-all training method, CompOFA, to reduce the search space and hence the training budget by constraining search to models close to the accuracy-latency Pareto frontier. The proposed method is based on compound relationships between model dimensions to build a design space smaller by several orders of magnitude. The authors demonstrate that even with simple heuristics we can achieve a 2x reduction in training time1 and 216x speedup in model search/extraction time compared to the state of the art, without loss of Pareta optimality."
SP:04b84d26cf282dbb753cbf27f14c334f65d3f8ec,"This paper proposes a new meta-learning algorithm, ADML (ADversarial Meta-Learner), which leverages clean and adversarial samples to optimize the initialization of a learning model in an adversarial manner. The proposed method is tested on two widely used image datasets, MiniImageNet and CIFAR100, in terms of both accuracy and robustness. "
SP:dfbaa6b53c4e8328d52666ad4641fc917bf0c0b3,This paper proposes a data-driven framework for permutation selection combining domain knowledge with machine learning concepts such as node embedding and self-attention. The proposed method is shown to improve the bit error rate of Bose Chaudhuri Hocquenghem (BCH) code as compared to the baseline decoders. 
SP:c860a7b0952d708e7851c9bc4b63d246f64d1cba,"This paper proposes to perform an unsupervised classification task prior to fine-tuning BERT for a target text classification task. Specifically, as such an intermediate task, the authors perform un-supervised clustering, training BERT on predicting the cluster labels. They test this hypothesis on various data sets and show that this additional classification step can significantly reduce the demand for labeled examples mainly for topical classification tasks."
SP:ea37f5882fd98dd4ce233077bb3069517d4ed4ea,"This paper presents an empirical study of the performance of generative models using a random shooting agent. The authors show that the mixture density nets outperform all other models by a large margin. They also show that heteroscedasticity at training time, perhaps acting as a regularizer, improves predictions at longer horizons. "
SP:4e25ba3714d78ba59a0d8efbb65e0ef5201702f8,"This paper proposes a GAN-based method for disentangling affine transformations in a self-supervised and rigorous manner. The proposed method is inspired by InfoGAN, where an additional affine regularizer acts as the inductive bias. The authors decompose the affine matrix into separate transformation matrices and inferring the transformation parameters by maximum likelihood estimation. Experiments on MNIST, CelebA, and dSprites demonstrate the effectiveness of the proposed method."
SP:121f8420cfb49c6d80b5ebb4051e85947182594a,"This paper proposes a new contrastive learning method for instance discrimination-based contrastive training. The proposed method is based on the idea of minimizing the distribution divergence between the weakly and strongly augmented images over the representation bank to supervise the retrieval of strongly augmented queries from a pool of candidates. The authors show that the proposed method achieves top-1 accuracy of 76.2% on ImageNet with a standard ResNet-50 architecture with a single-layer classifier fine-tuned. Moreover, it outperforms the previous self-supervised and supervised methods on both the transfer learning and object detection tasks."
SP:af54e542223097c315ecd677d0b968e9a0b2a1d4,"This paper proposes a new class of MRI de-identification techniques that remodel privacy-sensitive facial features as opposed to removing them. To accomplish this, the authors propose a conditional, multi-scale, 3D GAN architecture that takes a patient’s MRI scan as input and generates a 3D volume in which the brain is not modified but the face has been de-identified. The proposed method preserves privacy more reliably without adversely affecting downstream medical analyses on the brain, including segmentation and age prediction."
SP:0ac3964bd2320341488476d60f57b75d2a79f92c,"The paper proposes a multi-head attention based global pooling layer that captures the interaction between nodes according to their structural dependencies. The proposed method satisfies both injectiveness and permutation invariance, such that it is at most as powerful as the Weisfeiler-Lehman graph isomorphism test. The experimental results show that the proposed method significantly outperforms state-of-the-art graph pooling methods on graph classification benchmarks with high memory and time efficiency. "
SP:76848e7ac3e6709e92f6a6db60269cb5177495d1,"This paper proposes a new explanation for the over-squashing problem in GNNs. The authors show that the bottleneck hinders popular GNN models from fitting long-range signals in the training data; they further show that GNN that absorb incoming edges equally, such as GCN and GIN, are more susceptible to over-Squashing than GAT and GGNN; finally, they show that prior work, which extensively tuned GNN model of long range problems, suffer from over-splashing, and that breaking the bottleneck improves their state-of-the-art results without any tuning. "
SP:90d8fa381446923902e42b259392e5e975e6caa1,This paper proposes a domain adaptation method for sentiment analysis. The proposed method induces large margins between different classes in an embedding space based on the notion of prototypical distribution. The authors show that the proposed method reduces the effect of “domain shift” on the performance of a trained classifier in the target domain.
SP:893fd7440b82f5da0d4c0944928810322eaee2f0,"This paper proposes a new evaluation method for detecting gender-bias in NLI models. The proposed method is based on a challenge task, which is designed to test whether a model is biased towards gender-specific hypotheses. The authors evaluate three models (BERT, RoBERTa, BART) trained on MNLI and SNLI data-sets are significantly prone to gender-induced prediction errors. They also find that debiasing techniques such as augmenting the training dataset to ensure a gender-balanced dataset can help reduce such bias."
SP:a32ab755bd249c393b70938036ce8e810c0c439f,"This paper studies variational intrinsic control (VIC), an unsupervised reinforcement learning method for finding the largest set of intrinsic options available to an agent. In the original work by Gregor et al. (2016), two VIC algorithms were proposed: one that represents the options explicitly, and the other that does it implicitly. The authors show that the intrinsic reward used in the latter is subject to bias in stochastic environments, causing convergence to suboptimal solutions. To correct this behavior and achieve the maximal empowerment, they propose two methods respectively based on the transitional probability model and Gaussian mixture model. "
SP:b4df2c4627a6d46c5100133e38c4bea20b296dd8,This paper studies the problem of learning from small datasets. The authors propose to use an ensemble of relatively small deep neural networks to improve sample efficiency in the low data regime. They compare different ensemble configurations to their deeper and wider competitors given a total fixed computational budget and provide empirical evidence of their advantage. 
SP:4a0ee01f4897efa81659f37ef0468ee8195bbc4f,"This paper proposes a method to improve the compression factor of binary neural networks (BNNs) by using positive 0/1 binary weights, instead of the -1/+1 weights used by state-of-the-art binary networks. The authors show that the proposed method is able to achieve a high compression factor and reduces the number of operations and parameters at inference time. Experiments are conducted on linear and convolutional networks."
SP:5be8539ad02595ad3c7a2d7afe8cbb3e9924467d,"This paper proposes a post hoc calibration method for predicting the predictive uncertainty of a machine learning model. The proposed method uses outlier exposure to properly calibrate the model probabilities. The calibration error is the difference between predicted error rates and actual error rates, as measured by collecting data into bins based on pmax = maxi p softmax i bins.  "
SP:ea503f67e38fce7dee9cc4996b55b8959911f030,"This paper studies the expressive power of graph neural networks and graph kernels from an empirical perspective. Specifically, the authors compare the graph representations and similarities produced by these algorithms against those generated by a well-accepted but intractable graph similarity function. The authors also investigate the impact of node attributes on the performance of the different models and kernels."
SP:0cf7b7d929f50e0b7f4fda5e1f68e5ade2f7c29b,"This paper proposes a method to regularize self-supervised image animation by using the top-k percent occlusion pixels of the foreground to regularise image animation. The proposed method, named PriorityCut, is based on the existing CutMix method. The main contribution of the proposed method is to use the occlusions of foreground pixels to improve the performance of the inpainting. The method is evaluated on a variety of image datasets. "
SP:60b535fc6cbc1a7a26ad53f706ebb17de346dc4f,"This paper proposes a method for learning disentangled causal mechanisms (ICM), which are independent causal mechanisms that directly model multiple data generation processes (mechanisms) in a coarse granularity. The authors outline sufficient conditions under which the mechanisms can be learned using a single self-supervised generative model with an unconventional mixture prior, simplifying previous methods. Moreover, the authors prove the identifiability of the model w.r.t. the mechanisms in the self supervised scenario. "
SP:44d4e24428d043a69b40013919cda0e8e7bff99c,"This paper proposes a self-labeling approach for predicting chemical compound graphs from 2D images. The proposed approach is based on graph aligning, where a fully mediating layer is represented using the planar embedding of the chemical graph structure we are predicting. The authors show that the proposed approach achieves up to 4x improvement of performance after domain adaptation to target domain compared to pretrained model only on the source domain."
SP:ad906dd9a176cffd283593321ff6b9ad19595528,"This paper proposes a domain knowledge based deep learning framework to solve the chiller plants energy optimization problems. Specifically, the energy consumption estimation of most chillers can be physically viewed as an input-output monotonic problem. To tackle the small sample size problem, this paper considers domain knowledge in the structure and loss design of deep network to build a nonlinear model with lower redundancy function space. Experimental results show the superiority of the proposed method in energy optimization compared to the existing ones. "
SP:6cb65ee5d2926858570601eeeade24fe86c7f32f,"This paper proposes a collaborative causal spatio-temporal fusion transformer, named CausalTrans, to establish the collaborative causal effects of predictors on multiple forecasting targets, such as supply and demand in ride-sharing platforms. Specifically, the authors integrate the causal attention with the Conditional Average Treatment Effect (CATE) estimation method in causal inference, and propose a novel and fast multi-head attention evolved from Taylor’s expansion instead of softmax, reducing the time complexity from O(V) to O(v) where V is the number of nodes in a graph. The authors conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various model components, and the time efficiency of the proposed method."
SP:223980a1954d626d90ff54d8dc61b5d85a6b349c,"This paper proposes a method for jointly identifying a mixture of discrete and continuous factors of variability. The method is based on a multi-agent VAE framework, where multiple interacting autoencoding agents are trained on augmented copies of training samples to learn mixture representations, while being encouraged to reach consensus on the categorical assignments. The proposed method is evaluated on MNIST and dSprites."
SP:c982610ad28662c3bd13132abe1f7307d1a61b68,"This paper studies the group equivariant convolutional networks (GCNNs) with G-steerable kernels. The authors provide a general characterization of steerable kernel spaces for the practically relevant case of G being any compact group. In particular, they show that steerable kernels are fully understood and parameterized in terms of 1) generalized reduced matrix elements, 2) ClebschGordan coefficients, and 3) harmonic basis functions on homogeneous spaces. In addition, they generalize the famous Wigner-Eckart theorem for spherical tensor operators. "
SP:7b2ea39069277ad0f4f79476a77ef84587a804d9,"This paper studies the effect of selective classification on the accuracy of a classifier in the presence of spurious correlations. Specifically, the authors study the margin distribution, which captures the model’s confidences over all predictions. They show that selective classification monotonically improves or worsens accuracy is fully determined by the accuracy at full coverage (i.e., without any abstentions) and whether the distribution satisfies a property we call left-log-concavity. The authors also show that increasing abstention can even decrease accuracies on some groups. Motivated by their analysis, they train distributionally-robust models that achieve similar full-coverage accuracies across groups."
SP:f1d57ee27e901daf7e4e2b84139019e945818911,"This paper proposes a new hierarchical nonnegative CANDECOMP/PARAFAC decomposition (hierarchical NCPD) model and a training method, Neural NCPD, for performing hierarchical topic modeling on multi-modal tensor data. The proposed method utilizes a neural network architecture and backpropagation to mitigate error propagation."
SP:b6ddc3a560aa7155e7e927bf5360bedc36586597,"This paper proposes a new adversarial robustness certificate that computes the number of predictions that are simultaneously guaranteed to remain stable under perturbation, i.e. cannot be attacked. The authors leverage the locality property of Graph Neural Networks and leverage their locality property to fuse multiple single-node certificates into a drastically stronger collective certificate. "
SP:cc93dd2f68e415e2457166e78627865dc1b44697,"This paper proposes Quantile Regression GAN (QRGAN) to improve the performance of GANs by minimizing the 1-Wasserstein distance between real and generated data distribution as a novel approach in modification of loss functions for improvement of GGANs. The proposed method is based on quantile regression, which minimizes the Wasserstein distances between the generated and real data distributions. The method is evaluated on the Frechet Inception Distance (FID) for generation performance assessment. "
SP:4ddb47ee77c374ae6c3e419412d92ca77260692e,"This paper investigates relevance metrics that can provide reasonable explanations to users. Specifically, the authors adopted three tests to evaluate whether the relevance metrics satisfy the minimal requirements for similarity-based explanation. They showed that cosine similarity of the gradients of the loss performs best, which would be a recommended choice in practice. In addition, they showed that some metrics perform poorly in our tests and analyzed the reasons of their failure. "
SP:6c2cbf2bc0f6dabe974e80ec1e82d2d12189906e,"This paper proposes adding a low-rank global attention (LRGA) module to Graph Neural Networks (GNNs) for improving their generalization power. The authors show that augmenting GNNs with LRGA provides algorithmic alignment to a powerful graph isomorphism test, namely the 2-Folklore Weisfeiler-Lehman (2-FWL) algorithm. They also show that adding the LRGA module improves the sample complexity of the kernel’s feature map when learned with a randomly initialized two-layer MLP. "
SP:b4abdd28504b4c1de239eabd4e0e27d370efee71,This paper proposes an adaptive label smoothing method to improve the calibration performance of convolutional neural networks (CNNs). The proposed method is based on the idea of objectness measures and labels smoothing during training. The authors show qualitative results using class activation maps and quantitative results using classification and transfer learning tasks. 
SP:5254658923e594294b69d124a8d004166852822a,"This paper proposes a convex duality framework that makes a two-layer fully-convolutional ReLU denoising network amenable to convex optimization. In particular, it implies training neural networks with weight decay regularization induces path sparsity while the prediction is piecewise linear filtering. Experiments on MNIST and fastMRI datasets confirm the efficacy of the dual network optimization problem."
SP:085cad6bc143c8713580bddfaa71f06496dac314,"This paper proposes an end-to-end speech synthesis model that learns to synthesise speech from normalised text or phonemes. The proposed model is feed-forward and thus efficient for both training and inference, using a differentiable alignment scheme based on token length prediction. It learns to produce high fidelity audio through a combination of adversarial feedback and prediction losses constraining the generated audio to roughly match the ground truth in terms of its total duration and mel-spectrogram. To allow the model to capture temporal variation, the authors employ soft dynamic time warping in the spectrogram-based prediction loss. The resulting model achieves a mean opinion score exceeding 4 on a 5 point scale. "
SP:01148cea55db606aa78d27e900818684a8bce9ab,This paper proposes a non-parametric representation learning framework to mitigate the missing attributes problem in attributed graphs. The proposed method is based on Wasserstein graph diffusion to smooth the distribution representations of nodes with information from their local neighborhoods. The authors also propose two algorithms based on it for node classification (with missing attributes) and matrix completion respectively. 
SP:aeeb5909f7123ef631f569b469af9715205c881f,"This paper proposes a method for learning a goal-conditioned policy in the absence of extrinsic rewards. The teacher is a goal generating agent that proposes Adversarially Motivated Intrinsic GOals (AMIGO). The teacher learns to propose increasingly challenging and achievable goals that allow the student to learn general skills for acting in a new environment, independent of the task to be solved. The authors show that AMIGO generates a natural curriculum of self-proposed goals which ultimately allows the agent to solve challenging procedurally-generated tasks where other forms of intrinsic motivation and state-of-the-art RL methods fail. "
SP:3d05bc7dca97681cb582298e318b9b973841eed3,This paper studies the problem of private information retrieval from a dataset of files stored on a single server under both a user distortion and a user privacy constraint. The authors propose a data-driven framework by leveraging recent advancements in generative adversarial models which allows a user to learn efficient schemes in terms of download rate from the data itself.  The authors show that the optimal rate-distortion-leakage tradeoff is convex and that in the limit of large file sizes this allows for a concise information-theoretical formulation. 
SP:3f9e2db00fc3dcd7a40588adcb638503ec10dc09,"This paper proposes a new greedy learning method for GNNs. The proposed method decouples the GNN into smaller modules and associates each module with greedy auxiliary objectives. This allows GNN layers to be updated during the training process without waiting for feedback from successor layers, thus making parallel GNN training possible. The authors also propose a lazy update scheme during training to further improve its efficiency. "
SP:5ecb1b288f7fc02aead4493f81640867bc349290,"This paper proposes a framework for answering complex queries on incomplete Knowledge Graphs. The authors translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. They then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. They show that the proposed approach produces more accurate results than state-of-the-art methods trained on millions of generated queries. "
SP:f04a522fd04c503754fdb8c52da68646d31271a4,"This paper proposes a method for verifying the robustness of a feed-forward neural network with piecewise-linear activation functions. The method is based on a geometric projection of the input space into a set of convex polyhedral regions in which the network’s behavior is linear; hence, a systematic search for decision boundaries within the regions around a given input is sufficient for assessing robustness. Empirically, the proposed method is far more precise than many approximate verification approaches, while at the same time performing multiple orders of magnitude faster than complete verifiers."
SP:5297651ff873f97c07b9c47ed3eff52251661844,"This paper proposes an approach for learning an embedding of objects in an affordance space, in which each dimension corresponds to an aspect of meaning shared by many actions, using text corpora. This embedding makes it possible to predict which verbs will be applicable to a given object, as captured in human judgments of affordance, better than a variety of alternative approaches. Furthermore, the dimensions learned are interpretable, and that they correspond to typical patterns of interaction with objects. "
SP:72b4f3b40c6c6fa2eb53e95ed9a10a4077ffa049,"This paper proposes a method for the emergence of individuality in multi-agent reinforcement learning (MARL). The proposed method learns a probabilistic classifier that predicts a probability distribution over agents given their observation and gives each agent an intrinsic reward of being correctly predicted by the classifier. The intrinsic reward encourages the agents to visit their own familiar observations, and learning by such observations makes the intrinsic reward signals stronger and in turn makes the agents more identifiable. Two regularizers are proposed to increase the discriminability of the classifiers. Empirically, the proposed method is shown to outperform existing methods in a variety of MARL scenarios. "
SP:112509d6d3573a9d495d182fdfae6ec0327cddf5,This paper proposes a Smoothed WEighted Ensembling (SWEEN) scheme to improve the performance of randomized smoothed classifiers. The authors show the ensembling generality that SWEEN can help achieve optimal certified robustness. They also develop an adaptive prediction algorithm to reduce the prediction and certification cost. Extensive experiments are conducted to demonstrate the effectiveness of the proposed method.
SP:ea892e3d199ed6121279b20061a87f43afae8796,This paper proposes a method to learn the subtask hierarchy by learning from demonstration. The method is based on the inductive bias and proposes Ordered Memory Policy Network (OMPN) to discover subtask hierarchies. The proposed method can be used to perform task decomposition. Experiments on Craft and Dial demonstrate the effectiveness of the proposed method. 
SP:cc6aa977ce561a2493ae74bb694205cd67c8d890,"This paper proposes a causal semantic generative model (CSG) for out-of-distribution (OOD) examples. The authors show that under certain conditions, CSG can identify the semantic factor by fitting training data, and this semantic-identification guarantees the boundedness of OOD generalization error and the success of adaptation. Empirical study shows improved OOD performance over prevailing baselines."
SP:be3f34a59e5e61dcdbc7cb085f031ba4a5a5b758,"This paper studies the problem of robustness to adversarially corrupted rewards in online learning. In particular, the authors consider the setting where an online algorithm makes a prediction at each time step, and receives a stochastic reward from the environment that can be arbitrarily corrupted with probability $\mathcal{O}(0,12)$ with probability $p(x,y)$, where $p$ is the noise rate of the adversary. The authors propose to design robust online algorithms with near optimal regret in three different scenarios: multi-armed bandits, linear contextual bandits, and Markov Decision Processes (MDPs). The authors provide empirical evidence on synthetic and real datasets. "
SP:6d62a80aaebb2988df3953d4d7164e5a2fa1aa6d,"This paper proposes Rewriter-Evaluator, a framework to improve the performance of neural machine translation (NMT) models with multiple passes of decoding. It consists of a rewriter and an evaluator. At every pass, the rewriter produces a new translation and evaluates the quality of the past translation to decide whether to terminate the rewriting process. The authors also propose a prioritized gradient descent (PGD) method that facilitates training the Rewriter and the Evaluator jointly. Experiments are conducted on two translation tasks, Chinese-English and English-German, and show that the proposed framework notably improves the performances of NMT models. "
SP:9761fca8848868dfc9cacdab2537f8276ca76e0f,"This paper proposes a method for learning a multimodal predictive distribution, where the empirical frequency of the sampled predictions closely reflects that of the corresponding labels in the training set. To this end, the authors propose a novel two-stage, cascaded strategy for calibrated adversarial refinement. In the first stage, they explicitly model the data with a categorical likelihood, and then train an adversarial network to sample from it an arbitrary number of coherent predictions. The model can be used independently or integrated into any black-box segmentation framework to facilitate learning of calibrated stochastic mappings. The authors demonstrate the utility and versatility of the approach by attaining state-of-the-art results on the multigrader LIDC dataset and a modified Cityscapes dataset."
SP:ce965758f1b795a56c02f45d6a8d06cb8bdf29cb,"This paper proposes a new and theoretically and practically better alternative to EF for dealing with contractive compressors. In particular, the authors propose a construction which can transform any contractive compressor into an induced unbiased compressor. They show that their approach leads to vast improvements over EF, including reduced memory requirements, better communication complexity guarantees and fewer assumptions. "
SP:4fd702490293e481c79614852ba27dd3ce9215a4,"This paper proposes a new framework for hyperparameter transfer across adjustments (HT-AA) for machine learning. The authors provide four simple HT-AA baseline algorithms and eight benchmarks changing various aspects of ML algorithms, including the hyperparameters, the search space, and the neural architectures used. They show that the best baseline, on average and depending on the budgets for the old and new HPO, reaches a given performance 1.2–3.6x faster than a prominent HPO algorithm without transfer. "
SP:e8f99bae5853de525450fcb8facd23cf973fc161,"This paper investigates the role of label representation in the training of image classification models. The authors show that high dimensional, high entropy label representations are generally more useful because they provide a stronger error signal. In addition, they show that the features learned through their label representations exhibit more robustness under various adversarial attacks and better effectiveness with a limited amount of training data. "
SP:4e8d924cba7367af0999b30d79250b4dc40413e1,"This paper proposes a method to improve the robustness and uncertainty performance of ensemble neural networks by using a single model’s capacity to train multiple subnetworks that independently learn the task at hand. The authors show that, using a multi-input multi-output (MIMO) configuration, the benefits of using multiple predictions can be achieved ‘for free’ under a single models’ forward pass. By ensembling the predictions made by the subnetwork, the authors improve model robustness without increasing compute."
SP:d2f1c23b67c6744101034dc5e1c70765a733b169,"This paper proposes a method to transfer intermediate knowledge obtained from one Convolutional Neural Network (CNN) to another by utilizing sparse representation learning. The proposed method first extracts sparse representations of the hidden features of the teacher CNN, which are then used to generate both pixellevel and image-level labels for training intermediate feature maps of the student network. The authors formulate SRM as a neural processing block, which can be efficiently optimized using stochastic gradient descent and integrated into any CNN in a plugand-play manner. The experiments demonstrate that SRM is robust to architectural differences between the teacher and student networks, and outperforms other KD techniques across several datasets."
SP:e8c0f43bd5debf6544f588cd3442dc3dd62d0eee,"This paper proposes a new metric for measuring behavioral similarity between states. The proposed metric is motivated by the sequential structure in reinforcement learning, which is orthogonal to recent approaches, which rarely exploit this structure explicitly. The authors also present a contrastive representation learning procedure to embed any state similarity metric, which they instantiate with PSM to obtain policy similarity embeddings (PSEs1). They demonstrate that PSEs improve generalization on diverse benchmarks, including LQR with spurious correlations, a jumping task from pixels, and Distracting DM Control Suite."
SP:92f3b4942da9075440dda618f561a85f8fde5a5c,"This paper studies the problem of disentangling affine transformations in the latent space of a deep learning model. The authors show that a popular approach to disentangle natural factors of variation in data (e.g. object shape vs pose) introduces topological defects (i.e. discontinuities in the encoder) for a broad family of transformations such as rotations and translations. To address this problem, the authors propose a distributed equivariant operator that can act on the entire latent space. "
SP:ef0f58c462bc5dd1c7b78f562c42a4e17f0f252b,"The paper proposes a method to estimate the temporal dynamics of interaction between neurons in the Hawkes process. The proposed method is based on augmenting the auxiliary latent variables with Gaussian form, which allows for a simple iterative algorithm with analytical updates. The method is evaluated on synthetic and real-world data. "
SP:1156d3deac022829bda930ffcb081947609d972b,"This paper studies the gradient descent (GD) algorithm for training two-layer neural network models. It shows that there are two distinctive phases in the GD dynamics in the under-parameterized regime: An early phase in which the gradient dynamics follows closely that of the corresponding random feature model, followed by a late phase where the neurons are divided into two groups: a group of a few (maybe none) “activated” neurons that dominate the dynamics and a group that support the continued activation and deactivation process. The quenching process seems to provide a clear mechanism for “implicit regularization”. "
SP:9e81401a6f30c70d870a12cce0cf600557f92b80,"This paper proposes a method to solve constrained Markov decision process (CMDP) problems by decomposing the CMDP into a pair of MDPs; reconnaissance MDP (R-MDP) and planning MDP. In R-MPD, the agent has access to the generative model which provides us with a next state sample for any given state-action pair, and proposes a model to solve a CMDP problem by decompose the problem into a two-stage MDP: reconnaissance and planning. In the reconnaissance stage, the threat function, the Q-function analogue of danger that can determine whether a given state is safe or not, is used to determine the safeness of each action. In planning stage, a reward-seeking policy is trained while using a fixed threat function to determine safety. The authors also present an efficient approximation method for the threat functions that can greatly reduce the difficulty of solving R-mDP. "
SP:f1d4ac7d5516dd0df742e224c8c09c721d0d0886,"This paper studies the effect of the square loss on the performance of neural networks trained with cross-entropy and square losses. The authors show that the square losses outperform the cross losses on a range of NLP, ASR, and computer vision tasks. They also show that training with square losses is less sensitive to the randomness in initialization. "
SP:915f1f0fc4850507c28c1d609239b41775863ebe,"This paper proposes a self-supervised reinforcement learning method that combines future prediction and data augmentation to improve sample-efficient deep RL from pixels. The proposed method, Self-Predictive Representations (SPR), trains an agent to predict its own latent state representations multiple steps into the future using an exponential moving average of the agent's parameters and a learned transition model. The authors show that the proposed method achieves a median human-normalized score of 0.415 on Atari in a setting limited to 100k steps of environment interaction."
SP:983f01c170909c8c67fd3be25f121bd61bdd8307,This paper proposes an efficient method for generating single-node representations using local PageRank computations. The authors theoretically prove that their method produces globally consistent representations in sublinear time. They demonstrate this empirically by conducting extensive experiments on real-world datasets with over a billion edges. 
SP:d11037b8fe2b10aee672ba82f69410b40181f0f9,"This paper proposes a new method for graph coarsening. The proposed method is based on the recent progress of deep learning on graph neural networks. The authors propose a framework for measuring the quality of the proposed method and show that depending on the goal, we need to carefully choose the Laplace operator on the coarse graph and associated projection/lift operators. Motivated by the observation that the current choice of edge weight for the coarse graphs may be suboptimal, the authors parametrize the weight assignment map with the graph neural network and train it to improve the quality in an unsupervised way. Experiments on both synthetic and real-world datasets show that the proposed methods significantly improves common graph Coarsening methods under various metrics, reduction ratios, graph sizes, and graph types. "
SP:0d680213339f0e2aedb0be4aeed51423706b8bf6,This paper presents a geometric deep learning algorithm for estimating the acoustic properties of 3D objects at interactive rates. The proposed method is based on discrete-laplacian and implicit encoders to compute these characteristics. The authors show that the proposed method can accurately estimate these acoustic properties for arbitrary topologies and takes less than 1ms per object on a NVIDIA GeForce RTX 2080 Ti GPU. 
SP:afc33a782c43e3d4c5c4fbf047d0b1108bc30bae,"This paper proposes Risk Extrapolation (REx), a method to reduce the variance of the training risk across training domains, which is a form of robust optimization over a perturbation set of extrapolated domains (MMREx) and propose a penalty on variance of training risks (V-REx). The authors prove that variants of REx can recover the causal mechanisms of the targets, while also providing some robustness to changes in the input distribution (“covariate shift”). The proposed method is able to outperform Invariant Risk Minimization in situations where these types of shift co-occur."
SP:411d5bcf7698d534ad60f581d479ff74849ba4de,"This paper proposes a new neural operator for partial differential equations (PDEs) by parameterizing the integral kernel directly in Fourier space, allowing for an expressive and efficient architecture. The Fourier neural operator is the first ML-based method to successfully model turbulent flows with zero-shot super-resolution. It is up to three orders of magnitude faster compared to traditional PDE solvers."
SP:41d268d0eac9b4c84baa156fb641aa6d3060b5a4,"This paper studies the implicit bias of gradient flow (i.e., gradient descent with infinitesimal step size) on linear neural network training. The authors propose a tensor formulation of neural networks that includes fully-connected, diagonal, and convolutional networks as special cases, and investigate the linear version of the formulation called linear tensor networks.  The authors show that gradient flow on separable classification finds a stationary point of the `2/L max-margin problem in a “transformed” input space defined by the network.  For underdetermined regression, the authors prove a global minimum which minimizes a norm-like function that interpolates between weighted `1 and `2 norms.  "
SP:e27907ef4a4e6e0f5841618fcaa7e7e0db443f91,"This paper proposes a method for optimizing the width-multipliers across different layers of a slimmable neural network. The proposed method is based on a multiobjective optimization lens, which allows for optimizing both the shared weights and the width multipliers for the sub-networks. The method is evaluated with 15 network and dataset combinations and two types of cost objectives, i.e., FLOPs and memory footprint, to demonstrate the effectiveness of the proposed method."
SP:cf59403abb6ca89ccee4f8e77e9a33d99e6a00f5,"This paper studies the problem of federated semi-supervised learning (FSSL), where the private data at each client may be either partly labeled, or completely unlabeled with labeled data being available only at the server. The authors propose a novel method to tackle the problems, which they refer to as Federated Matching (FedMatch). FedMatch improves upon naive combinations of federate learning and semi-Supervised learning approaches with a new inter-client consistency loss and decomposition of the parameters for disjoint learning on labeled and unlabeling data. The experimental validation of FedMatch shows that the proposed method outperforms both local semi supervised learning and baselines. "
SP:9457b6d430a2cd864d526d7e90bf3e1ab13d6df4,"This paper proposes a new self-supervised learning method CoLES for discrete event sequences. CoLES is based on contrastive learning, which is used for audio and computer vision domains. The proposed method is evaluated on several public datasets and showed that CoLES representations consistently outperform other methods on different downstream tasks. "
SP:385942a5bcee7384bb722a1669b541f2fac0cd36,"This paper proposes a new unsupervised parsing framework that can jointly generate constituency tree and dependency graph. The proposed framework is based on the StructFormer model, which can induce dependency and constituency structure at the same time. The authors integrate the induced dependency relations into transformer, in a differentiable manner, through a novel dependency-constrained self-attention mechanism. Experimental results show that the proposed framework can achieve strong results on un-supervised constituency parsing, un-unsupervised dependency parsing and masked language modeling. "
SP:078966ff62775bba6031e47d374bda95f4a7dde3,This paper proposes a method for learning the mapping between scene graph nodes and visual objects under weak supervision. The proposed method learns a metric among visual objects and scene graphs by incorporating information from both object features and relational features. Extensive experiments on Visual Genome and Visual Relation Detection (VRD) datasets verify that the proposed method post an improvement on scene graph grounding task over current state-of-the-art approaches. 
SP:4644dbf7466b6234d8abf69995fdfb357efcc119,"This paper proposes a new relational discrepancy, named spherical sliced fused Gromov Wasserstein (SSFG), that can find an important area of projections characterized by a von Mises-Fisher distribution. The authors also introduce two variants of SSFG to improve its performance.  "
SP:5ae2c0af82cac89a65f1cc38c43e2d05ea298901,"This paper proposes a method to speed up training for a particular kind of deep networks which contain repeated structures, such as the transformer module. The authors first train such a deep network with the weights shared across all the repeated layers till some point. Then, they stop weight sharing and continue training until convergence. The untying point is automatically determined by monitoring gradient statistics. Empirical results show that the proposed method is able to reduce the training time of BERT by 50%."
SP:a51710551142316b67e2fccd969fea1ece35ba39,"This paper studies the adversarial transferability and the interaction inside adversarial perturbations. The authors show that the negative correlation between the transferability of adversarial attacks and adversarial interactions can be regarded as a unified perspective to understand current transferability-boosting methods. Based on this, the authors propose to directly penalize interactions during the attacking process, which significantly improves the robustness against adversarial attack. "
SP:f1565319075c1442c2cb52d96443facb492c06c2,"This paper studies the forgetting problem in deep learning. The authors show that deeper layers are disproportionately responsible for forgetting, with sequential training resulting in an erasure of earlier task representational subspaces. They also provide an analytic argument and empirical picture relating forgetting to task semantic similarity, where maximal forgetting occurs for task sequences with intermediate similarity. "
SP:30d7532cdcf420bff3be6b92eea3d93bce59e6bd,"This paper proposes a new training algorithm for BERT, called EarlyBERT, which is inspired by the early-bird lottery tickets recently studied for computer vision tasks. In particular, the authors propose to reduce the self-attention and fully-connected sub-layers inside a transformer, which are the first to identify structured winning tickets in the early stage of BERT training. The authors apply those tickets to efficient BERT pre-training and fine-tuning, and conduct comprehensive pre-testing and downstream experiments on GLUE and SQuAD downstream tasks. "
SP:c547f23ff6caaf5e9f35d258490b86ae0ac8ed03,"This paper studies the robustness of f-divergence measures when label noise presents. The authors derive a nice decoupling property for a family of f divergences, where the divergence is shown to be a linear combination of the variational difference defined on the clean distribution and a bias term introduced due to the noise.  The authors also propose fixes to make them robust. "
SP:841888179dcdac901889c8d62cb5234311fe28f1,This paper proposes an ensemble-based weighted Bellman backup method for off-policy deep RL. The proposed method re-weights the target Q-values based on uncertainty estimates from a Q-ensemble. The authors show that the proposed method stabilizes and improves learning on both continuous and discrete control benchmarks on both low-dimensional and high-dimensional environments. 
SP:afc08f203562b841180811aef943bfb63a1659ea,This paper proposes a method for predicting uncertainty in a few-shot classification framework. The method is based on the distributional mismatch between support and query sets via class-wise similarities. The proposed method is algorithm-agnostic and readily expanded to include a range of meta-learning models. Experiments show that the proposed method helps the model avoid being indiscriminately confident.
SP:12ae325ea3bce1e60195afac7d85895d2d20c29c,"This paper proposes a generative model for learning video-text representations. The authors argue that noise contrastive learning is too strict, enforcing dissimilar representations even for samples that are semantically related. To alleviate this problem, the authors propose a novel method to naturally push these related samples together: each sample’s caption must be reconstructed as a weighted combination of other support samples’ visual representations. This simple idea ensures that representations are not overly-specialized to individual samples, are reusable across the dataset, and results in representations that explicitly encode semantics shared between samples. The proposed method outperforms others by a large margin on MSR-VTT, VATEX, ActivityNet, and MSVD for video-to-text and text-tovideo retrieval. "
SP:8a71d8fad25a126aff01431cacf348c05de75667,"This paper proposes a novel method, seg tok, to form the vocabulary of Chinese BERT, with the help of Chinese word segmentation (CWS) and subword tokenization. The authors also propose three versions of multi-vocabulary pretraining (MVP) to improve the models expressiveness. Experiments show that the proposed method improves the performances of Chinese PLMs on sentence level tasks, it can also improve efficiency; and it can improve PLMs’ downstream performance. "
SP:b93ec7bc02b48068073ffe705f71d2643e663d51,"This paper proposes a new GCN training method, called BDS-GCN, that adopts unbiased boundary sampling strategy to enable efficient and scalable distributed GCNs training while maintaining the full-graph accuracy. Empirical evaluations and ablation studies validate the effectiveness of the proposed method. "
SP:2d4ba873d11e969ebd1fc31f9b5ab450c964d154,"This paper proposes a graph neural network (GNN) for quantum chemistry simulations. The GNN is based on graph neural networks, and is able to estimate per-atom forces in 3D space, which is a central capability for performing atomic simulations. In particular, the authors propose a message passing architecture, expressive message passing, appropriate choice of basis and non-linear activation functions, and model scaling in terms of network depth and width. Experiments show that the proposed GNN can achieve 4x higher success rate than existing ML models. "
SP:8bdcf4fe6abf4739d4732b7ea8538513135dcccc,"This paper studies the problem of fine-tuning neural networks. The authors provide a neural network generalisation bound based on Rademacher complexity that uses the distance the weights have moved from their initial values. They also propose a simple yet effective method that constrains the hypothesis class to a small sphere centred on the initial pre-trained weights, thus obtaining provably better generalisation performance than conventional transfer learning. "
SP:3a3249e97ef2345ea2264de5ed8287e16687838e,"This paper investigates the phenomenon of decoupling the hyperparameters for mask discovery (Hfind) and mask evaluation (Heval) in unstructured magnitude pruning on vision classification tasks. The authors show that different Hfind values yield masks with materially different layerwise pruning ratios and that the decoupled find-eval phenomenon is causally mediated by these ratios. They show that this phenomenon holds across a number of models, datasets, configurations, and also for one-shot structured pruning. "
SP:2d6f5d72b21675f74ff4cde4d16bfb36abd5795f,"The paper proposes a new metric, called m-coherence, to study the alignment of per-example gradients during training. The metric is inspired by gradient diversity, a quantity previously used in some theoretical bounds. The authors show that compared to other commonly used metrics, m-Coherence is more interpretable, cheaper to compute (O(m) instead of O(m)) and mathematically cleaner. "
SP:e7c5de9a475d0ba71bc79580e8436024fb2c6f59,The paper proposes a method for generating summary statistics for implicit generative models where the evaluation of the likelihood function is intractable but sampling data from the model is possible. The method is based on the idea of learning mutual information maximizing representations of the data with the help of deep neural networks. The authors apply their method to both approximate Bayesian computation and recent neural likelihood methods.
SP:c5997bf2348e94949684f45fbd418661e85220c1,This paper proposes a new image-to-image translation model (TUNIT) that simultaneously learns to separate image domains and translate input images into the estimated domains. TUNIT achieves comparable or even better performance than the set-level supervised model trained with full labels. 
SP:0cd97e64e638cabbeea0fdef3e9c5b33f4000f72,"This paper studies the problem of gradient descent training of wide neural networks and the corresponding implicit bias in function space. The authors show that the solution of training a width-n shallow ReLU network is within n−1/2 of the function which fits the training data and whose difference from initialization has smallest 2-norm of the weighted second derivative with respect to the input. The curvature penalty function 1/ζ is expressed in terms of the probability distribution that is utilized to initialize the network parameters, and the authors compute it explicitly for various common initialization procedures. "
SP:8b885142facbb3b8db41ec9d83822cee81324694,"This paper studies the problem of weight decay for adaptive gradient methods. The authors show that the L2 regularization is unstable for all optimizers that use Momentum, such as stochastic gradient descent (SGD) and Adam, and that decoupled weight decay is highly unstable. They propose the stable weight decay (SWD) method to fix the unstable weight decay problem from a dynamical perspective. "
SP:a3206dc71e32ba1830895bf442d3840f3331a532,"This paper proposes a novel method to combine the strengths of both translation memory (TM) and neural machine translation (NMT). The authors treat the matched sentence pair of TM as the additional signal and apply one encoder enhanced by the pre-trained language model (PLM) to encode the TM information and source sentence together. The authors extend the sentence level retrieval method to the n-gram retrieval method that doesn’t need to calculate the similarity score. Further, the authors explore new methods to manipulate the information flow from TM to the NMT decoder. Experiments demonstrate that the proposed methods can significantly improve the translation quality and show strong adaptation for an unknown or new domain."
SP:72b43991a242872b2ceb1861e8ffbdf26c9f4818,"This paper studies the problem of learning a deep convolutional neural network. The authors show that the basic iterative gradient ascent scheme for maximizing the rate reduction of learned features naturally leads to a deep network, one iteration per layer. Moreover, all linear operators of the so-derived network naturally become multi-channel convolutions when we enforce classification to be rigorously shift invariant. "
SP:f8b02cf1b918b0956761829ec6ef9127596071ec,"This paper studies the implicit acceleration of gradient flow in over-parameterized two-layer linear models. The authors show that implicit acceleration emerges from a conservation law that constrains the dynamics to follow certain trajectories. More precisely, gradient flow preserves the difference of the Gramian matrices of the input and output weights and the amount of acceleration depends on both the magnitude of that difference (which is fixed at initialization) and the spectrum of the data. "
SP:e5f086c806be88d50e461a782b5b00124f4656fb,"This paper proposes a new framework CLIME, which is based on uniform sampling of user-defined subspaces. This allows the end-user the flexibility to delineate the precise subspace of the input domain to be explained. The proposed framework can be applied to any ML model, and extensive experiments demonstrate its versatility on real-world problems. "
SP:b1d5ef15772e192eb8c8a0e65b3c21ee7c794295,"This paper proposes a novel pre-trained language model, AMBERT (A Multi-grained BERT), on the basis of both fine and coarse tokenizations. The proposed model takes both the sequence of words (finegrained tokens) and the sequences of phrases as input after tokenization, and employs one encoder for processing the words and the other encoder to process the sequences. The authors also develop a version of AMBERTs which performs equally well as AMBERt but uses about half of its inference time. The experiments are conducted on benchmark datasets for CLUE, GLUE, SQuAD and RACE."
SP:fd1cfe80343d3789227d99d836a5674374a234f5,"This paper proposes a new Transformer architecture for semantic parsing. The main idea is to incorporate Long Short-Term Memory (LSTM) into the Self-Attention mechanism of the original Transformer to capture more local context of phrases. Experimental results show that the proposed model captures the detailed meaning better than Transformer, raises local context awareness and achieves strong competitive performance on Geo, MSParS datasets."
SP:2056a65a7500d79465685af883083cd706277c1f,"This paper proposes a new adversarial training method for adversarial robustness. The proposed method, called CAT, is based on the idea of combining adversarial perturbations. The authors show that the proposed method is able to improve the robustness of DNNs against the compositions of pixel and spatial transformations, while incurring limited impact on clean inputs."
SP:006e5b9ac9a8eb7223843731488bfefbd8eb09bd,"This paper proposes a method for learning abstract rules directly from high-dimensional sensory data. The method is based on a recurrent network augmented with an external memory that enables a form of variable-binding and indirection. This binding mechanism allows symbol-like representations to emerge through the learning process without the need to explicitly incorporate symbol-processing machinery, enabling the ESBN to learn rules in a manner that is abstracted away from the particular entities to which those rules apply. Experiments show that the proposed method is able to generalize to novel entities given only a limited number of training examples."
SP:4171ce45966ac499f51450a19fb233934c0847f0,"This paper proposes a new framework, Translation between Augmented Natural Languages (TANL), to solve many structured prediction language tasks including joint entity and relation extraction, nested named entity recognition, relation classification, semantic role labeling, event extraction, coreference resolution, and dialogue state tracking. The authors frame the problem as a translation task between augmented natural languages, from which the task-relevant information can be easily extracted. The proposed framework can match or outperform task-specific models on all tasks, and in particular, achieves new state-of-the-art results on joint entity extraction (CoNLL04, ADE, NYT, and ACE2005 datasets), relation classification (FewRel and TACRED), and semantic roles labeling (Co-NLL-2005 and CoNLL2012). "
SP:8f1b2fc6829e0bdfcc981020b0dcf3e63a947910,"This paper proposes a new method to address the problem of unlabeled entity recognition (NER) in NER models. The key idea is to use negative sampling that, to a large extent, avoids training NER model with unlabelled entities. Experiments on synthetic datasets and real-world datasets show the effectiveness of the proposed method. "
SP:dd76ece8d92a8a230a8b43033d8cb2368c677a94,"This paper proposes a novel acoustic word embedding called Acoustic Neighbor Embeddings where speech or text of arbitrary length are mapped to a vector space of fixed, reduced dimensions by adapting stochastic neighbor embedding (SNE) to sequential inputs. The Euclidean distance between coordinates in the embedding space reflects the phonetic confusability between their corresponding sequences. Two encoder neural networks are trained: an acoustic encoder that accepts speech signals in the form of frame-wise subword posterior probabilities obtained from an acoustic model and a text encoder, which accepts text transcriptions. The proposed method is shown to have more effective gradients for neural network training. "
SP:9142189126b8612ac0acee6fe18a0cfcb70b6545,This paper studies the problem of learning a pair of mean-field states and a stationary policy in a game where the goal is to reach the Nash equilibrium. The authors propose a fictitious play algorithm that alternates between gradient descent and proximal policy optimization. They show that their algorithm converges to the Nash equilibria at a sublinear rate. 
SP:c498f8a199da1818fe64ed88b0825c5aad688aec,"This paper studies the problem of probabilistic inference on the joint distribution defined by a normalizing flow model. Given a pre-trained flow model p(x), the authors propose a new generative model with the property that its composition with the given model approximates the target conditional distribution. By parametrizing this new distribution as another flow model, the authors can efficiently train it using variational inference and also handle conditioning under arbitrary differentiable transformations. The authors provide extensive empirical evidence showcasing the flexibility of their method on a variety of inference tasks with applications to inverse problems."
SP:1d0f27f61c9d32911b8bd15d6b82ef5eec644f0f,"This paper proposes a new evaluation criterion called Perceptual Hausdorff Distance (PHD) to measure the quality of cell membrane segmentation results. The paper first introduces an ultra-high resolution Image Segmentation dataset for the Cell membrane, called U-RISC, the largest annotated Electron Microscopy (EM) dataset with multiple iterative annotations and uncompressed high-resolution raw data. Then, the paper proposes to resolve the inconsistency of the current popular segmentation evaluation criteria are inconsistent with human perception. "
SP:8ca7aff87c82be69c9542550c814f52c9419ab0a,"This paper proposes a new benchmark for continual learning (CL) based on a modular architecture and learning algorithm. The modular architecture consists of atomic skills that can be composed to perform a certain task. The learning algorithm leverages a task-driven prior over the exponential search space of all possible ways to combine modules, enabling efficient learning on long streams of tasks. The experiments show that the proposed method performs competitively on widely used CL benchmarks while yielding superior performance on the more challenging benchmarks."
SP:cc819c61f408e88f247eb87946187ccec3dad32e,"This paper proposes a generative model-based unsupervised meta-learning method for few-shot classification tasks. The proposed method is based on the LAtent Space Interpolation Unsupervised Meta-learning (LASIUM) framework. The authors propose to generate pairs of in-class and out-of-class samples from the latent space in a principled way, allowing them to create synthetic classes forming the training and validation data of a meta-task. The experimental results show that the proposed method outperforms or is competitive with the baselines. "
SP:b25771e5c214a352f74ba6196fbd88bca6c43c98,"This paper studies the injectivity of fully connected and convolutional ReLU layers and networks. The authors show that global injectivity with iid Gaussian matrices, a commonly used tractable model, requires larger expansivity between 3.4 and 10.5. They also characterize the stability of inverting an injective network via worst-case Lipschitz constants of the inverse. Finally, they show that an end-to-end—rather than layerwise—doubling of the dimension suffices for injectivity. "
SP:a95a153d3fe9bcf535ebf8514f51d00df483f210,"This paper proposes a continuous conditional generative adversarial network (CcGAN) for image generation conditional on continuous, scalar conditions (termed regression labels). Existing conditional GANs (cGANs) are mainly designed for categorical conditions (e.g., class labels); conditioning on regression labels is mathematically distinct and raises two fundamental problems: (P1) Since there may be very few (even zero) real images for some regression labels, minimizing existing empirical versions of cGAN losses (a.k.a. empirical cGAN loss) often fails in practice; (P2) Since regression labels are scalar and infinitely many, conventional label input methods are not applicable. The proposed CcGAN solves the above problems by (S1) reformulating existing empirical CGAN losses to be appropriate for the continuous scenario; and (S2) proposing a novel method to incorporate regression labels into the generator and the discriminator. "
SP:10dd09ab315870631d1451d200f2c87a023f8226,"This paper proposes an active learning algorithm for semi-supervised learning (SSL) and active learning (AL). The authors argue that the annotation efficiency brought by AL algorithms that seek diversity on labeled samples can be improved upon when using SSL as the training scheme. To this end, the authors propose an AL algorithm that instead focuses on controlling the convergence rate of a classification network by actively querying instances to improve the rate of convergence upon inclusion to the labeled set. The authors show that a deep neural network trained using a combination of CRC and a recently proposed SSL algorithm can quickly achieve high performance using far less labeled samples than SL. "
SP:7f3947c3fa5b09674507d8f3e10d9280376ecb94,"This paper proposes a federated learning method for training neural network models. The proposed method is based on a dynamic regularizer for each device at each round, so that in the limit the global and device solutions are aligned. The authors demonstrate both through empirical results on real and synthetic data as well as analytical results that their scheme leads to efficient training, in both convex and non-convex settings. "
SP:a3fbb073b0e2371b20d5d9df6ab829673f90354f,"This paper proposes a method for accelerating contrastive learning algorithms with little or even no loss of accuracy. The main idea is to truncate the back-propagation and updates only a part of the parameters for each gradient descent update. The proposed method is based on the observation that the similarity on the intermediate layers is a good surrogate of the final similarity. The authors exploit this observation by introducing additional intermediate contrastive losses. Additionally, they do selection based on intermediate losses to filter easy regions for each image, which further reduces the computational cost."
SP:5b5e705ea1ee1b857e17e64d560a39052804949d,"This paper studies the global convergence and global optimality of actor-critic, one of the most popular families of reinforcement learning algorithms. The authors focus on the more practical single-timescale setting, where the actor and critic are updated simultaneously. Specifically, in each iteration, the critic update is obtained by applying the Bellman evaluation operator only once while the actor is updated in the policy gradient direction computed using the critic. For both cases, the authors prove that the actor sequence converges to a globally optimal policy at a sublinear O(K−1/2) rate, where K is the number of iterations. Moreover, under the broader scope of policy optimization with nonlinear function approximation, they prove that actorcritic with deep neural network finds the global optimal policy for the first time."
SP:26705a4dc305cce336f657c5937d1f5b4209548a,"This paper proposes to represent log data at a few levels of abstraction including field level, log level, and log sequence level. The authors use a version of Transformer Networks (TNs) to encode numerical and textual information that is suitable for log embeddings. They show how a number of log processing applications can be readily solved with their representation. "
SP:165c51a16f17fb8726e968f8b34742b62011d60e,"This paper proposes a new wavelet decomposition method for deep convolutional neural networks (CNNs) that is motivated by the similarities between trained CNN kernels and oriented Gabor filters for addressing the lack of a mathematical understanding of their properties. The proposed method is based on the separable wavelet packet transform while the other two methods implement the 2D dual-tree real and complex wavelet transform. The experiments show that the proposed method achieves the accuracy rate of standard AlexNet, but with a significantly lower number of parameters. "
SP:d0a284da462584724ba6a3a48c9e986d391233f6,"The paper proposes a coach-player framework to solve the problem of multi-agent particle physics. The proposed framework is based on a variational objective to regularize learning, and an adaptive communication method to let the coach decide when to communicate with different players. The authors demonstrate zero-shot generalization to new team compositions with varying numbers of heterogeneous agents. The performance of the proposed method is comparable or even better than the setting where all players have a full view of the environment, but no coach."
SP:4eb662b527d556758aaa1a0b589495fcc337fad0,"This paper studies the influence function in deep learning with non-convex loss functions. The authors provide a comprehensive and large-scale empirical study of successes and failures of influence functions in neural network models trained on datasets such as Iris, MNIST, CIFAR-10 and ImageNet. They show that the network architecture, its depth and width, as well as the extent of model parameterization and regularization techniques have strong effects in the accuracy of influence function. They also show that for certain network architectures and datasets, training with weight-decay regularization is important to get high-quality influence estimates."
SP:5fea74a2031d097a99dacf613bedcb054b0c3831,"This paper studies the connection between the pretraining task of next word prediction and text classification. The authors hypothesize, and verify empirically, that classification tasks of interest can be reformulated as sentence completion tasks, thus making language modeling a meaningful pre-training task. They also show that language models that are -optimal in crossentropy (log-perplexity) learn features that can linearly solve such classification tasks with O( √ ) error, thus demonstrating that doing well on language modeling can be beneficial for downstream tasks. "
SP:a67da438e9821010284416170c3699ae7ff96c99,"This paper proposes a new membership inference attack (MIA) method that uses the reconstruction error to detect if data samples were used to train a neural network model. The proposed method is based on a novel difficulty score that can be computed for each image, and its computation does not require a training set. The method is shown to achieve high MIA accuracy on an extensive number of benchmarks."
SP:6fe23ebe09f2a4e42a21598f8e9c79edeca99863,"This paper proposes a differentiable architecture search method by formulating it into a distribution learning problem. Specifically, the authors treat the continuously relaxed architecture mixing weight as random variables, modeled by Dirichlet distribution. The authors propose a simple yet effective progressive learning scheme that enables searching directly on large-scale tasks, eliminating the gap between search and evaluation phases. Experiments demonstrate the effectiveness of the proposed method."
SP:c590d0ed2487b42480b53fc077546a4a0bc27a78,"This paper proposes a new class of function approximators for low-dimensional but complex functions. The proposed method, multiplicative filter networks, simply multiply together (linear functions of) sinusoidal or Gabor wavelet functions applied to the input. This representation has the notable advantage that the entire function can simply be viewed as a linear function approximation over an exponential number of Fourier basis functions, respectively. Experiments show that the proposed method largely outperforms or matches the performance of these approaches on the domains highlighted in these past works. "
SP:f5be855300f63c185a006834302bd4b033b56258,"The paper proposes a teacher-student scheme to enable the gradient-based meta-learning algorithms to explore long horizons by the inner loop. The key idea is to employ a student network to adequately explore the search space of task-specific models (e.g., by more than ten steps), and a teacher then takes a “leap” toward the regions probed by the student. The teacher not only arrives at a high-quality model but also defines a lightweight computation graph for meta-gradients. The proposed method is generic; it performs well when applied to four meta learning algorithms over three tasks: few-shot learning, long-tailed classification, meta-attack."
SP:0361e02d56b7d121cb5ede1cb582284cc18fc599,"This paper proposes a new algorithm for offline reinforcement learning. The algorithm is based on the behavior regularization, which constraints the learned policy within the support set of the dataset. To prevent catastrophic performance degradation due to rare out-of-distribution actions, the authors add a gradient penalty term to the policy evaluation objective to penalize the gradient of the Q value w.r.t. the out of distribution actions. The authors also employ state-dependent Lagrange multipliers for the regularization term to avoid distributing KL divergence penalty across all states of the sampled batch."
SP:b2cfb380aa2a21f72f508b453cf5949257a5b4ec,This paper proposes a new training method called Adjoined Networks (AN) that can regularize and compress any CNN-based neural architecture. The main idea is to train both the original and the smaller networks together. The parameters of the smaller network are shared across both the architectures. The authors prove strong theoretical guarantees on the regularization behavior of the adjoint training paradigm. Experiments are conducted on Imagenet and CIFAR-100.
SP:dba40073f79143e5355d194aa16db9eee0267a5d,"This paper proposes a new greedy exploration algorithm that retains the simplicity of -greedy while reducing dithering. The main limitation of greedy exploration is its lack of temporal persistence, which limits its ability to escape local optima. The authors propose a temporally extended form of greedy that simply repeats the sampled action for a random duration. "
SP:5efb581a368ace3bd085d48801a899559d6a43ef,"This paper studies the implicit regularization of gradient flow with infinitesimal initialization in matrix factorization. The authors provide theoretical and empirical evidence that for depth-2 matrix factorisation, gradient flow is mathematically equivalent to a simple heuristic rank minimization algorithm, Greedy Low-Rank Learning, under some reasonable assumptions. They also extend the results to the case where depth ≥ 3, and show that the benefit of being deeper is that the above convergence has a much weaker dependence over initialization magnitude. "
SP:7f997cf7a63a7330fc12fd525516080c91a3cb9b,"This paper proposes a two-stage framework for improving robustness of classifiers. The first stage is model patching, which first models subgroup features within a class and learns semantic transformations between them, and then trains a classifier with data augmentations that deliberately manipulate subgroups features. The second stage is a regularizer that balances subgroup performance using a theoretically-motivated subgroup consistency regularizer, accompanied by a new robust objective. Experiments on 3 benchmark datasets demonstrate the effectiveness of the proposed method."
SP:de6cea1e35a0555175e17546a93422e9a96a511e,"This paper proposes a new classifier, named Rulebased Representation Learner (RRL), that automatically learns interpretable nonfuzzy rules for data representation. To train the non-differentiable RRL effectively, the authors project it to a continuous space and propose a novel training method, called Gradient Grafting, that can directly optimize the discrete model using gradient descent. An improved design of logical activation functions is also devised to increase the scalability of RRL and enable it to discretize the continuous features end-to-end. "
SP:e36388a9452e557dd51bf0170bf2f9da22271a49,"This paper proposes a new regret minimization (RGM) algorithm and its extension for structured environments. RGM builds from invariant risk minimisation (IRM) by recasting simultaneous optimality condition in terms of predictive regret, finding a representation that enables the predictor to compete against an oracle with hindsight access to held-out environments. The structured extension adaptively highlights variation due to complex environments via specialized domain perturbations. The experiments show that RGM significantly outperforms previous state-of-the-art baselines. "
SP:cad3ed2fba57faf17a3e8899dc5a744d5358aa68,"This paper proposes a novel architecture for cross-probe BERT. The proposed architecture is based on a combination of text and vision probes, and the cross-modal attentions are conducted on text and image probes. It takes lightweight computation cost, and meanwhile effectively exploits crossmodal attention. Experiments on two public benchmarks demonstrate state-of-the-art effectiveness and efficiency."
SP:51fd82de525fcb738fdeaeeae20fbb2cdf975f0c,"This paper proposes a new type of Actor, named forward-looking Actor or FORK for short, for Actor-Critic algorithms. The proposed method can be easily integrated into a model-free ActorCritic algorithm. Experiments on six Box2D and MuJoCo environments with continuous state and action spaces demonstrate significant performance improvement for the proposed method."
SP:6e730239e6e8b43c4988dd61dca30f15dc039ef7,This paper proposes a new aggregation method for federated learning. The proposed method is based on Bayesian inference. The authors show that the proposed method can be used to aggregate local models into a global model. 
SP:3ac5f437fc349a33810d0645664d1c448528af74,This paper presents a double-blind review of the BERT models. The authors provide a detailed explanation of the proposed method. 
SP:efa2343ead47263a0d09e1c17f9aa044605b9650,This paper studies the problem of finite-time convergence of deep neural networks. The authors propose a Lyapunov-based analysis of the loss function to derive an a priori upper bound on the settling time of the deep neural network. The upper bound is derived under the assumption of boundedness of the input.  The authors also provide a bound for the robustness against input perturbations. 
SP:7a0ded4b3b2d08d43765ff7b722da9b9863aabd6,The paper proposes a method to improve the disentanglement of latent variables in GINs by using mutual information between each learned latent variable and the auxiliary variable to correctly identify informative latent variables. The proposed method is based on the nonlinear independent component analysis theory. The method is tested on synthetic and real-world datasets. 
SP:0d9ba12bbf47b13a46c2225f9dc06878418daaea,"The paper proposes a new pooling method for convolutional neural networks. The proposed method is based on the classical Lifting scheme from signal processing. The main idea is to decompose a feature map into various downsized sub-bands, each of which contains information with different frequencies. By performing LiftDownPool backward, a corresponding up-pooling layer LiftUpPool is able to generate a refined upsampled feature map using the downscaled feature map. Experiments show the proposed method achieves better results on image classification and semantic segmentation, using various backbones. Moreover, it is better robust to input corruptions and perturbations."
SP:147239edceb17bade6ea5d3dca44e3a59998aa47,"This paper proposes a fast, distance-preserving, binary embedding algorithm to transform a high-dimensional dataset T ⊆ R into binary sequences in the cube {±1}. When T consists of well-spread (i.e., non-sparse) vectors, the proposed method applies a stable noise-shaping quantization scheme to Ax where A ∈ Rm×n is a sparse Gaussian random matrix. The authors show that Euclidean distances among the elements of T are approximated by the `1 norm under a fast linear transformation. Further, they prove that the method is accurate and its associated error is comparable to that of a continuous valued Johnson-Lindenstrauss embedding plus a quantization error that admits a polynomial decay as the embedding dimension m increases. "
SP:f65e229bca3904095743e7a501b1083cc60f1e22,This paper proposes a method for learning plasticity rules for recurrent neural networks (RNNs) that can be used as proxies for Gradient Descent (GD) to improve the robustness and generalization of artificial neural nets (ANNs). The method is based on a genetic setting where natural selection of a numerical parameter over a sequence of generations provably simulates a simple variant of GD. The authors provide both empirical and theoretical evidence for this hypothesis. 
SP:f435530146fa975cb27cd375a857df9bcbd87682,"This paper proposes a novel learning paradigm for visual question generation (VQG) that combines answer-awareness and region-reference. The authors propose a new double-hints guided Graph-to-Sequence learning framework that first models them as a dynamic graph and learns the implicit topology, and then utilizes a graph to sequence model to generate the questions with double hints. To this end, they develop a simple methodology to self-learn the visual hints without introducing any additional human annotations. The experiments on VQA2.0 and COCO-QA datasets demonstrate that the proposed model on this new setting can significantly outperform existing state-of-the-art baselines by a large margin. "
SP:53a26ce11647866d3f6ba8b84ca9f13106197a8d,"This paper studies the double descent phenomenon in linear regression. The authors prove that for certain linear regression models with isotropic data distribution, optimally-tuned `2 regularization achieves monotonic test performance as we grow either the sample size or the model size.  The authors also demonstrate empirically that optimally tuned `2-regularization can mitigate double descent for more general models. "
SP:c193ccc74b987beaf8d53a29a8529a0af5e87742,"This paper proposes a spatial dependency network (SDN) to improve the generative modeling by better exploiting spatial regularities and coherence in images. The spatial dependency networks are computed in a spatially coherent way, using a sequential gating-based mechanism that distributes contextual information across 2-D space. The authors show that augmenting the decoder of a hierarchical VAE by spatial dependency layers considerably improves density estimation over baseline convolutional architectures and the state-of-the-art among the models within the same class. In a vanilla VAE setting, a powerful SDN decoder also improves learning disentangled representations. "
SP:db91512a90e75675af03c2f197751c8526d6f5e9,"This paper proposes a simplified version of BCQ (Fujimoto et al., 2018a) that removes a heuristic design choice and naturally restrict extracted policies to remain exactly within the support of a given behavior policy. The authors derive this simplified algorithm through the introduction of a novel backup operator, Expected-Max Q-Learning (EMaQ), which is more closely related to the resulting practical algorithm. Specifically, in addition to the distribution support, EMaQ explicitly considers the number of samples and the proposal distribution, allowing the authors to derive new sub-optimality bounds which can serve as a novel measure of complexity for offline RL problems. In the offline RL setting – the main focus of this work – EMaq matches and outperforms prior state-of-the-art in the D4RL benchmarks. "
SP:e2b80adeaa9208e0667a64a3f24661f77b48e487,"This paper proposes a batch selection algorithm for improving model fairness. The proposed algorithm is based on bilevel optimization, where the outer optimizer is an inner optimizer, and the inner problem is to select minibatch sizes for the purpose of improving the fairness of the model. The authors show that the proposed method is compatible with existing batch selection techniques intended for different purposes, such as faster convergence, thus gracefully achieving multiple purposes. "
SP:72f26b850bb2258223c0fc71598e35ad07d690e6,"This paper studies the bounds on the Lipschitz constant of deep equilibrium (DEQ) models. The authors show that monotone DEQ models, a recently-proposed subclass of DEQs, have a simple function of the strong monotonicity parameter of the network. They derive simple-yet-tight bounds on both the input-output mapping and the weight-output maps defined by these networks, and demonstrate that they are small relative to those for comparable standard DNNs. They also highlight how to use these bounds to develop PAC-Bayes generalization bounds."
SP:bcfd4d7fd4590e3bc248a0a5422ce4b67db74a74,"This paper proposes a new method for imitation learning and goal-conditioned reinforcement learning. The key idea is to use density estimation to learn to reach a given state or set of states. The authors show that the method can be applied to both goal conditioned and imitation learning settings. In imitation learning, the proposed method can learn from extremely sparse amounts of expert data and achieves state-of-the-art results on a common benchmark. In goal conditioned RL, the authors show it can circumvent the problem of sparse rewards while addressing hindsight bias."
SP:d57550b2f323b356d7e609acc35ee33039f376b4,"This paper proposes a variational multi-task learning framework for learning multi-tasks with limited training data. The proposed framework is based on variational Bayesian inference, which enables task relatedness to be explored in a principled way by specifying priors. The authors introduce Gumbel-softmax priors to condition the prior of each task on related tasks. The posteriors over representations and classifiers are inferred jointly for all tasks and individual tasks are able to improve their performance by using the shared inductive bias. Experimental results demonstrate that the proposed method achieves state-of-the-art performance on four benchmark datasets consistently surpassing previous methods."
SP:3ccdf8322f16c8a7bef82e32fad4c03969a510d1,"This paper proposes a systematic and unified benchmark, Long-Range Arena, specifically focused on evaluating model quality under long-context scenarios. The proposed benchmark is a suite of tasks consisting of sequences ranging from 1K to 16K tokens, encompassing a wide range of data types and modalities such as text, natural, synthetic images, and mathematical expressions requiring similarity, structural, and visual-spatial reasoning. The authors systematically evaluate ten well-established long-range Transformer models (Reformers, Linformer, Linear Transformers, Sinkhorn Transformers, Performers, Synthesizers, Sparse Transformers, and Longformers) on the newly proposed benchmark suite. "
SP:e12e410c3335b76133ceda4c865b244fbbab8580,"This paper proposes a multilingual code summarization model, which jointly learns on Context and Structure of source code. The authors show that jointly training on non-parallel data from multiple programming languages improves results on all individual languages, where the strongest gains are on low-resource languages. "
SP:f46e98d48f90071831f1c0069bf74a7993be6db8,"This paper proposes a reinforcement learning approach for audio-visual navigation. The proposed approach is based on the idea of waypoints that are dynamically set and learned end-to-end within the navigation policy, and an acoustic memory that provides a structured, spatially grounded record of what the agent has heard as it moves. The authors demonstrate the effectiveness of their approach on two challenging datasets, Replica and Matterport3D."
SP:23bfe317dcef00a91ea92389b3f39d9b93972454,"This paper studies the effect of weight initialization on the convergence rate of small convolutional networks trained to predict n steps of the two-dimensional cellular automaton Conway’s Game of Life. The authors find that networks of this architecture trained on this task rarely converge. Rather, networks require substantially more parameters to consistently converge. Furthermore, the initialization parameters that gradient descent converges to a solution are sensitive to small perturbations, such as a single sign change. Finally, the authors observe a critical value d0 such that training minimal networks with examples in which cells are alive with probability d0 dramatically increases the chance of convergence. "
SP:1b5ba618d3e28d48f9205c0780f8288a08fa5392,"This paper proposes a new algorithm for semi-supervised learning (SSL) that considers not only the perturbed inputs but also the similarity among the inputs having the same label. The proposed algorithm, RankingMatch, is based on a new objective function, dubbed BatchMean Triplet loss, which has the advantage of computational efficiency while taking into account all input samples. The authors also perform an ablation study to prove the efficacy of the proposed algorithm. "
SP:f3abccf4a2566ffbc821aba209fab15058639ad4,"This paper studies the problem of few-shot meta-learning, where the goal is to learn a new task from a small number of examples, by meta-training across static data from a set of previous tasks. The authors extend previous meta learning algorithms to handle the variable-shot settings that naturally arise in sequential learning: from many-shot learning at the start, to zero-shot training towards the end. They show that meta learning solves the full task set with fewer overall labels and achieves greater cumulative performance, compared to standard supervised methods."
SP:95cb420d92ec42e12a4bbb0e66224f1c498a7161,"This paper presents a series of experiments to test the sensitivity of Transformer representations to several kinds of structure in sentences. The experiments are based on the notion of representational invariance, which is a general class of interventional, input perturbation-based analyses of representations from Transformer networks pretrained with self-supervision.  The experiments include three different perturbations: (1) random permutations of n-grams of varying width; (2) swapping of two spans which do or do not form a syntactic phrase, to test sensitivity to global phrase structure; and (3) swapping pairs of adjacent words which do not break apart a phrase.  Experiments show that Transformer models build sensitivity to larger parts of the sentence along their layers, and that hierarchical phrase structure plays a role in this process. The authors also connect their probe results to the Transformer architecture by relating the attention mechanism to syntactic distance between two words. "
SP:cb27b27a6fefc192ad1c2bd083d13eb9e51a5c44,This paper proposes a new GAN architecture for few-shot image synthesis. The architecture consists of a skip-layer channel-wise excitation module and a self-supervised discriminator trained as a feature-encoder. The authors show that the proposed architecture can achieve better performance than the state-of-the-art StyleGAN2.
SP:c0dbeb5d94b2388595cf7ad9675c55df0bac7f8e,This paper proposes a new dual algorithm for neural network bounding. The proposed algorithm is based on a tighter linear relaxation for piecewise linear activations. The authors show that the proposed algorithm recovers the strengths of the new relaxation in the dual space: tightness and a linear separation oracle. 
SP:56e3837417dbcce0d65338dc3aac4e1a20eb0df8,This paper proposes a generative and contrastive pre-training framework for improving the commonsense reasoning ability of a pre-trained text-to-text transformer (PTLM). The generative objective is based on the concept-aware language model (CALM) and the contrastive objective is a combination of the two. The authors show that the proposed method can improve the performance of a PTLM on both NLU and NLG tasks.
SP:7ec69bdee021af506293c87a3b75bce1c40a03d7,"This paper proposes a method for unsupervised physical object discovery. The method is based on a multi-scale pixel-based and physical motion-based model. The model is trained to segment observable and partially occluded objects of varying sizes, and infer properties of those objects. The proposed method is tested on both synthetic and real scenes. "
SP:66997bc19a3ba6548fcf21f114e748bea95cad1c,"This paper proposes a method to improve the robustness of deep neural networks against adversarial attacks. The proposed method increases the margins of training samples by moving the decision boundaries of the DNN model far away from the training samples to improve robustness. The method is evaluated on six publicly available datasets (including a COVID-19 CT image dataset) under strong 100-PGD white-box adversarial attack, and the proposed method significantly improved classification accuracy on noisy data while keeping a relatively high accuracy on clean data. "
SP:276ffd59fbf49e3ee02756da8920218102214917,"This paper proposes a new knowledge distillation method called ProKT, which is a model-agnostic method by projecting the supervision signals of a teacher model into the student's parameter space. The proposed method is implemented by decomposing the training objective into local intermediate targets with approximate mirror descent technique. Experiments on both image and text datasets show that the proposed ProKT consistently achieves the state-of-the-art performance comparing to all existing knowledge distilling methods. "
SP:906dc21d6988953fcf57d63bbdd12973e5818d16,"This paper proposes a new channel pruning method to solve the problem of compression and acceleration of Convolutional Neural Networks (CNNs). The proposed method uses a hyper-structure network to generate the architecture of the main network. The authors use a regularization term to specify the computational resource of the compact network. To address this issue, they further introduce learnable layer-wise scaling factors to balance the gradients from different terms, and they can be optimized by hyper-gradient descent. Extensive experimental results on CIFAR-10 and ImageNet show that the proposed method is competitive with state-of-the-art methods. "
SP:890fd9454596c051b0e9535baf73b1dd1fae67ca,"This paper proposes a method for learning a theorem prover for higher-order logic theorem proving in the presence of a large knowledge base of potential premises without learning from human proofs. The main idea is to augment the exploration of premises based on a simple tf-idf (term frequency-inverse document frequency) based lookup in a deep reinforcement learning scenario. The experiments show that the proposed method outperforms a prover trained with no human proofs, dubbed DeepHOL Zero. "
SP:88209417a8ad07e6103084e41709be900303ce5f,"This paper proposes an automated data augmentation approach called MODALS (Modalityagnostic Automated Data Augmentation in the Latent Space) to augment data for any modality in a generic way. The proposed method is based on four universal data transformation operations in the latent space to adapt the transform to data of different modalities. Experiments on multiple datasets for text, tabular, time-series and image modalities demonstrate the effectiveness of the proposed method. "
SP:6d84670d321b0d584b097c630574bd748e85c9a2,"This paper studies the optimization efficiency of multilayer neural networks in the mean field regime, where the width tends to infinity and the learning dynamics tends to a nonlinear and nontrivial dynamical limit. The authors first develop a rigorous framework to establish a mean field limit of three-layer networks under stochastic gradient descent training. Then, they prove a global convergence result for unregularized feedforward feedforward neural networks under suitable regularity and convergence mode assumptions, which does not rely critically on convexity. Finally, they propose a neuronal embedding, which comprises of a fixed probability space that encapsulates neural networks of arbitrary sizes. "
SP:b90f893f927db9c439595fd119a565cf43c971f4,"This paper proposes a method for learning explanations of expert decisions by modeling their reward function in terms of preferences with respect to “what if” outcomes: Given the current history of observations, what would happen if we took a particular action? To learn these costbenefit tradeoffs associated with the expert’s actions, the authors integrate counterfactual reasoning into batch inverse reinforcement learning. The authors demonstrate the effectiveness of their method in both real and simulated medical environments. "
SP:c92916780418bfa7f0796fd9766b6d28b9eea5ef,"This paper presents a series of ablations on existing methods that show that morphological information encoded in the graph does not improve their performance. Motivated by the hypothesis that any benefits GNNs extract from the graph structure are outweighed by difficulties they create for message passing, the authors propose AMORPHEUS, a transformer-based approach. "
SP:2cf58f5cac20dccdc2034ef60e8e46b7988ebd7d,"This paper proposes a method for visual counting, which aims to predict the number of occurrences given a natural image and a query (e.g. a question or a category). Unlike most prior works that use explicit, symbolic models which can be computationally expensive and limited in generalization, this work proposes a simple and effective alternative by revisiting modulated convolutions that fuse the query and the image locally. The proposed method MoVie, short for Modulated conVolutional bottlenecks, uses a residual bottleneck, and only needs a single forward-pass during inference. "
SP:c64e77507e562f236cb69361b22fb1a7951ffb22,"This paper proposes a model-targeted poisoning attack that can target a desired model based on online convex optimization. The authors provide a lower bound on the minimum number of poisoning points needed to achieve a given target classifier. In addition, as an online attack, the authors can incrementally determine nearly optimal poisoning points. "
SP:a526023ec4cb839b83c574d31f59a9a67bc7af00,"This paper proposes a new binarization method for real-time point cloud applications that run on edge devices. The proposed method, BiPointNet, introduces Entropy-Maximizing Aggregation (EMA) to modulate the distribution before aggregation for the maximum information entropy, and Layer-wise Scale Recovery (LSR) to efficiently restore feature representation capacity. Extensive experiments show that BiPointNets outperforms existing binarized models by convincing margins, at the level even comparable with the full precision counterpart. Moreover, biPointNet gives an impressive 14.7x speedup and 18.9x storage saving on real-world resource-constrained devices. "
SP:825b4d1db0c537a607655bb5b4bf221ec672c8af,"This paper proposes three modifications to the self-attention architecture of Transformer: adding memory tokens to store non-local representations, creating memory bottleneck for the global information, and controlling memory update with dedicated layer. Experiments show that the proposed modifications improve the model performance for machine translation and language modelling tasks."
SP:f0fa1b7684bc605f6edd4813c44be20988fe8b4c,"This paper presents Prototypical Contrastive Learning (PCL), an unsupervised representation learning method that bridges contrastive learning with clustering. Specifically, prototypes are introduced as latent variables to help find the maximum-likelihood estimation of the network parameters in an Expectation-Maximization framework. The authors propose ProtoNCE loss, which encourages representations to be closer to their assigned prototypes.  "
SP:5342a5e1d87fd17b1a2efed967dbbfeafa440ee7,"This paper proposes a new block to defend against adversarial attacks. The proposed block is orthogonal to each other, and the parameters of these paths are required to be orthogonally with each other. The authors show that the proposed block can defend against both white-box and black-box attacks. "
SP:776df66274ed12449fde8dcef873a593980f397c,"This paper proposes a self-supervised graph attention network (SuperGAT) for noisy graphs. SuperGAT learns more expressive attention in distinguishing mislinked neighbors. Specifically, it exploits two attention forms compatible with a self supervised task to predict edges, whose presence and absence contain the inherent information about the importance of the relationships between nodes. Experiments on 17 real-world datasets demonstrates that the proposed method generalizes across 15 datasets of them. "
SP:80a05296d6b1e4c6e9e2df01938c73029ff8487d,"This paper proposes a novel DSMAD agent, INS-DS (Introspective Diagnosis System) comprising of two separate yet cooperative modules, i.e., an inquiry module for proposing symptom-inquiries and an introspective module for deciding when to inform a disease. The proposed method is inspired by the introspective decision-making process of human, where the inquiry module first proposes the most valuable symptom inquiry, then the introspection module intervenes the potential responses of this inquiry and decides to inquire only if the diagnoses of these interventions vary. The authors also propose two evaluation metrics to validate the reliability and robustness of DSMAD methods. Extensive experimental results demonstrate the new state-of-the-art under various experimental settings."
SP:10ae09d90d465125433a9b4f15b1405ab017920d,"This paper proposes a batch-wise regularization based on the proposed Batch Confusion Norm (BCN) to flexibly address the natural world distribution which usually involves fine-grained and long-tailed properties at the same time. The BCN term can alleviate possible overfitting due to exploring image features of fine details. More importantly, the BCN can learn to exert proper distribution of confusion strength over tailed and head categories to improve classification performance. "
SP:90f1e0fe1e9678d1e9a4dcb519d4e8fd61098ce0,"This paper proposes a new method for inverse reinforcement learning. The proposed method is based on variational imitation learning, where the posterior distribution over the reward is learned jointly with an appropriate policy in a completely offline manner through a variational approach to said latent reward. Experiments are conducted on real medical data and classic control simulations. "
SP:ccd251d95c0a2d8dc5ad2a148ec29955e105e71e,This paper proposes a method for learning a counterfactual belief for partially observable environments. The proposed method is based on the idea of learning an approximate auto-regressive belief that is learned as a supervised task. The method is evaluated on the Hanabi benchmark. 
SP:db408e6bfe69a9b3984f3b27ca92b802aa37af42,"This paper proposes a new method to control the bias-variance trade-off between the depth and breadth of the search. The proposed method, Shoot Tree Search (STS), is an interpolation between two celebrated search mechanisms: MCTS and random shooting. The authors show that STS can get the best of both worlds consistently achieving higher scores. "
SP:5efc271ccc555fd9aa542548838170bd4c98e957,This paper proposes a new pre-training method for inductive bias learning in neural networks. The proposed method is based on the idea that inductive biases can be encoded in the form of datasets. The authors design three synthetic tasks that are intended to require the model to have these three abilities. They specifically design these synthetic tasks in a way that they are devoid of mathematical knowledge to ensure that only the fundamental reasoning biases of the model can be learned from these tasks. Experiments on three large mathematical reasoning benchmarks demonstrate the effectiveness of the proposed method.
SP:bb8e0b554d3b3314fa343c902d9e60f1a141ea30,"This paper studies the inductive bias of gradient descent for weight normalized smooth homogeneous neural nets, when trained on exponential or cross-entropy loss. Specifically, the authors show that the gradient flow path with EWN is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. The authors also demonstrate their results on synthetic data sets and architectures."
SP:c71f9d2a602516865a0b103028186e83b52e5f00,"This paper proposes a new training procedure for GANs. The proposed method is based on the observation that the mode collapse of the generator is driven by the discriminator’s inability to maintain classification accuracy on previously seen samples, a phenomenon called Catastrophic Forgetting in continual learning. The authors propose to dynamically generate additional discriminators to remember previous modes of generation. Experiments show that the proposed method can be plugged-in to existing GAN frameworks to mitigate mode collapse."
SP:52c48198c95826e042f9e5a512ef3265daaff882,"This paper proposes a new regularization method for BERT, called AUBER, that leverages reinforcement learning to automatically prune attention heads from BERT. Instead of relying on heuristics or rule-based policies, the proposed method learns a pruning policy that determines which attention heads should or should not be pruned for regularization. Experiments on ablation study demonstrate the effectiveness of the proposed methods."
SP:abcbbad146f1b0d5d579c215952c95e5499a378a,"This paper proposes a method for learning correspondence between two domains, i.e., sim-to-real and real-world, by learning dynamics cycles that align dynamic robot behavior across two domains using a cycle-consistency constraint. The authors show that the proposed method is able to align uncalibrated monocular video of a real robot arm to dynamic state-action trajectories of a simulated arm without paired data. "
SP:006434d56992836ab9420d7d4215bc70664de304,"This paper studies the problem of explainability in the context of machine learning. The authors argue that the Shapley framework for explainability attributes a model’s predictions to its input features in a mathematically principled and model-agnostic way. However, general implementations of Shapley explainability make an untenable assumption: that the model's features are uncorrelated. To address this problem, the authors propose two solutions to Shapley-based explainability: one is based on generative modelling, and the other is directly learned from the value function. "
SP:7cda6bccf08887c7cef66d0ac3ccefdea8f5d7c8,"This paper proposes a new method for opponent modelling. The proposed method is based on variational autoencoders, which are trained to reconstruct the local actions and observations of the opponent based on embeddings which depend only on the local observations. The authors provide a comprehensive evaluation and ablation study in diverse multi-agent tasks, showing that the proposed method achieves comparable performance to an ideal baseline which has full access to opponent’s information, and significantly higher returns than a baseline method which does not use the learned embedding."
SP:c239bc531bcf7293032748af29a1b786e9d893dd,"This paper proposes a new contrastive learning method, Consistent Contrast (CO2), which is inspired by consistency regularization in semi-supervised learning on unlabeled data. CO2 takes the corresponding similarity of a positive crop as a pseudo label, and encourages consistency between these two similarities. Empirically, CO2 improves Momentum Contrast (MoCo) by 2.8% and 1.9% top-1 accuracy on ImageNet linear protocol, 3.1% and 5.1 percent top-5 accuracy on PASCAL VOC. "
SP:d18bab21790713e2facb053c47298fc9079ab783,"This paper studies the last-iterate convergence of Optimistic Gradient Descent Ascent (OGDA) and Optimistic Multiplicative Weights Update (OMWU) for bilinear games over the probability simplex. In particular, the authors show that when the equilibrium is unique, linear last iterate convergence is achieved with a learning rate whose value is set to a universal constant, improving the result of (Daskalakis & Panageas, 2019b) under the same assumption. The authors also extend the results to more general objectives and feasible sets for the projected OGDA algorithm. "
SP:bbc7f77308b298c332a39747f693bc396f00a89f,"This paper proposes a federated user verification (UV) framework for private and secure training of UV models in federated setup, where the conventional loss functions are not applicable due to the constraints that each user has access to the data of only one class and user embeddings cannot be shared with the server or other users. In FedUV, users jointly learn a set of vectors and maximize the correlation of their instance embedding with a secret user-defined linear combination of those vectors. The authors show that choosing the linear combinations from the codewords of an error-correcting code allows users to collaboratively train the model without revealing their embedding vectors. "
SP:40fa47cc0928e2925ef5ce6d808073f368ca2cd4,"The paper proposes a method to estimate the effective dimension of class manifolds (CMs) by computing their intersection with random affine subspaces of varying dimension. The authors provide a theory for the technique and verify that their theoretical predictions agree with measurements on real neural networks. The experiments show that well-performing, robust models have higher dimensional CMs than worse performing models. "
SP:09bce202ac7a750c3700a8ef3cd92cfe8ed00c39,The paper proposes a curiosity-aware entropy temperature for Soft Actor-Critic (SAC) for reinforcement learning. The curiosity is added to the target entropy to increase the entropy temperature of unfamiliar states and decrease the entropy for familiar states. The proposed method is evaluated on the MuJoCo benchmark.
SP:dce5eb20581a21c5de0a9fc07a8a79a1fbb28c71,"This paper proposes a meta-reinforcement learning algorithm that is both efficient and extrapolates well when faced with out-of-distribution tasks at test time. The proposed method is based on a simple insight: dynamics models can be adapted efficiently and consistently with off-policy data, more easily than policies and value functions.  The authors propose model identification and experience relabeling (MIER) to identify the dynamics models that can be used to generate synthetic experience for the new task without using meta-learning at all. "
SP:34d78aa11f9d50baf75a9646a6f9128318c3389a,This paper proposes two meta-learning methods for the few-shot learning (FSL) problem. The first is Eigen-Reptile (ER) that updates the meta-parameters with the main direction of historical taskspecific parameters to alleviate gradient noise. The second is Introspective Self-paced Learning (ISPL) that constructs a plurality of prior models to determine which sample should be abandoned. The experiments show that the proposed methods outperform or achieve highly competitive performance compared with the state-of-the-art methods with or without noisy labels. 
SP:a571bff9ffe4edafd7bc064c4d10609e6b981ce3,"This paper proposes a new adversarial training method for image classification. The proposed method, Adversarial Batch Normalization (AdvBN), improves the performance of ResNet-50 on ImageNet-C (+8.1%), Stylized-ImageNet (+6.7%), and ImageNetInstagram (+3.9%) over standard training practices. In addition, AdvBN can also improve generalization on semantic segmentation."
SP:6a9c46bd3cf854299f360bff136e1d79d3edb2e4,This paper proposes a new metric for detecting outliers in the data distribution. The metric is called Variance of Gradients (VoG) and is based on the observation that high VoG scores are far more difficult for the model to learn and over-index on corrupted or memorized examples. The authors provide quantitative and qualitative support that VoG is a meaningful way to rank data by difficulty and to surface a tractable subset of the most challenging examples for human-in-the-loop auditing.
SP:074bfacc75837bb19049be8a2890e10de073dd8e,"The paper proposes a new method to improve the quality of generated samples. The method is based on the gradient flow of entropy-regularized f-divergences between the real and the generated data distributions. The gradient flow takes the form of a non-linear Fokker-Plank equation, which can be easily simulated by sampling from the equivalent McKean-Vlasov process. The proposed method can be applied to GANs with vector-valued critics and even other deep generative models such as VAEs and Normalizing Flows. Empirical results on multiple synthetic, image, and text datasets demonstrate the effectiveness of the proposed method. "
SP:74ecbc5a6d464bfa49337da9e0dd6a0fe714d4bb,"This paper presents a variable encoder-decoder (VECO) pre-training approach to unify the two mainstreams in both model architectures and pretraining tasks. VECO splits the standard Transformer block into several sub-modules trained with both innersequence and cross-sequence masked language modeling, and correspondingly reorganizes certain submodules for understanding and generation tasks during inference. The proposed method achieves new state-of-the-art results on various cross-lingual understanding tasks of the XTREME benchmark covering text classification, sequence labeling, question answering, and sentence retrieval. "
SP:3d177ad50727d1a2619b68ab8a897b79d8652beb,"This paper proposes a novel intrinsic motivation for Reinforcement Learning (RL) that encourages the agent to understand the causal effect of its actions through auditory event prediction. The authors first conduct an in-depth analysis of their module using a set of Atari games. Then, they apply their model to audio-visual exploration using the Habitat simulator and active learning using the ThreeDWorld (TDW) simulator. "
SP:014f6118ebe55ece6be23c3a10f12e4591e444b1,"This paper proposes a framework to jointly learn a reliable representation and assign clusters to unlabelled data. To avoid overfitting the learnt embedding to labelled data, the authors take inspiration from self-supervised representation learning by noise-contrastive estimation and extend it to jointly handle labelled and unlabelling data. In particular, they proposed using category discrimination on labelled data and cross-modal discrimination on multi-modAL data to augment instance discrimination used in conventional contrastive learning approaches. They further employ Winner-Take-All (WTA) hashing algorithm on the shared representation space to generate pairwise pseudo labels to better predict cluster assignments. "
SP:4df640f502e88ddba2d7e183625231d70b083e82,"This paper proposes a universal weakly supervised segmentation method. The proposed method is based on a semi-supervised metric learning problem, where pixels of the same semantics need to be mapped to the same (distinctive) features. The authors propose 4 types of contrastive relationships between pixels and segments in the feature space, capturing low-level image similarity, semantic annotation, co-occurrence, and feature affinity. They also propose a conditional random field to propagate sparse labels to the entire image. "
SP:f7d6099adb40a0ce2f8a3563dbd5207cf1fdea0f,"This paper proposes a simple but effective distillation strategy for unsupervised learning. The proposed method, BINGO, is short for Bag of InstaNces aGgregatiOn, targets at transferring the relationship learned by the teacher to the student. The main idea is to aggregate compact representations over the student with respect to instances in a bag. "
SP:328866aad6544c81ded8980934df31dc4472435f,"This paper proposes GATSBI, a generative adversarial approach to simulation-based inference (SBI) for high-dimensional simulators. The authors reformulate the variational objective in an adversarial setting to learn implicit posterior distributions. The proposed method is amortized across observations, works in high-dimension posterior spaces, and supports implicit priors. Experiments are conducted on two SBI benchmark problems and on two high dimensional simulators to demonstrate the effectiveness of the proposed method. "
SP:2915e82097eae4eb8546dc500f32b3ec37e3766f,"This paper proposes a generative model for the identification and estimation of treatment effects (TEs) under limited overlap when subjects with certain features belong to a single treatment group. Specifically, the authors use a latent variable to model a prognostic score which is widely used in biostatistics and sufficient for TEs. The model is then learned as β-Intact-VAE––a new type of variational autoencoder (VAE). The authors derive the TE error bounds that enable representations balanced for treatment groups conditioned on individualized features. "
SP:ca358c9f36aac6e58ed1b3949c349d210c49a48e,"This paper proposes a framework for Autonomous Reinforcement Learning (ARL) where the agent not only learns through its own experience, but also contends with lack of human supervision to reset between trials. The authors introduce a simulated benchmark EARL1 around this framework, containing a set of diverse and challenging simulated tasks reflective of the hurdles introduced to learning when only a minimal reliance on extrinsic intervention can be assumed. "
SP:abe51d4a9817c08f0abde5da0bb8e6ca4e02e7cf,This paper investigates the reasoning capabilities of GNN-based QA systems. The authors analyze the reasoning capability of existing GNN modules for QA and analyze their reasoning capability. They show that existing knowledge-aware GNNs may only carry out some simple reasoning such as counting. They also show that even a very simple graph neural counter can outperform all the existing QA modules on CommonsenseQA and OpenBookQA. 
SP:3ea5a38e7fcd9111dcd299ad039b634e2781685f,"This paper proposes a three-stage framework to enable DNN inference with near-optimal compression and much better performance during inference runtime. The key insight of the proposed method leverages the concept of Succinct Data Structures, which supports fast queries directly on compressed representation without decompression. The proposed method first transforms DNN models as our proposed formulations in either Element-wise or Block-wise manner, so that Sucinct Data structures can take advantage of. Then, the proposed framework compresses transformed DNN model using Succucinct DataStructures. Finally, the method exploits our specialized execution pipelines for different model formulations, to retrieve relevant data for Dnn inference. The experimental results show that, our method achieves at least 8.7X/11.5X speedup on AlexNet/VGG-16 inference, compared with Huffman Coding. "
SP:94c395afc794a9cc163e362078769ff83f3d20d0,"This paper proposes a new training method for improving the performance of tiny neural networks. The proposed method, called Network Augmentation (NetAug), augments the network (reverse dropout) instead of inserting noise into the dataset or the network. The authors argue that training tiny models are different from large models: rather than augmenting the data, we should augment the model, since tiny models tend to suffer from under-fitting rather than over-fitting due to limited capacity.  The authors demonstrate the effectiveness of NetAug on image classification and object detection. "
SP:9c24549b980e415616f818acbf4cf680ef8edb52,"This paper proposes a super-resolution generative adversarial network (GAN) for dynamic point cloud sequences without requiring point correspondence annotation. The proposed method, Temporal Point cloud Upsampling GAN (TPU-GAN), can implicitly learn the underlying temporal coherence from point cloud sequence, which in turn guides the generator to produce temporally coherent output. In addition, a learnable masking module is proposed to adapt upsampling ratio according to the point distribution. Experiments are conducted on two different domains: particles in the fluid dynamical system and human action scanned data."
SP:67efe60ad37807505369b7852bc0abed29ffdda8,"This paper proposes a new method for fully pre-training an encoder-only transformer and smoothly finetunes it for object detection via a task adapter. The proposed method is inspired by the success of textual prompts in NLP, which treat query positional embeddings as visual prompts to help the model attend to the target area (prompting) and recognize the object. To this end, the authors propose the task adapter which leverages self-attention to model the contextual relation between object query embedding. Experiments on the challenging COCO dataset demonstrate that the proposed method achieves competitive performance. "
SP:a1f9897496303984fc7ad469222106b14b4a6233,"This paper proposes a new federated learning algorithm, FedPAGE, which is able to reduce the communication complexity by utilizing the recent optimal PAGE method (Li et al., 2021). The proposed algorithm uses much fewer communication rounds than previous local methods for both federated convex and nonconvex optimization. In the convex setting, the number of communication rounds is O(3/4 S), improving the best-known result O( N S ) by a factor of N, where N is the total number of clients, S is the sampled subset of clients in each communication round, and is the target error. The authors also show that in the non-convolutional case, the communication cost for each round is the same for both FedPPAGE and SCAFFOLD."
SP:81e74765abc6524edd8fdf9a3ba107d7bddaa04b,"This paper studies the decision boundary geometry of ANN classifiers by utilizing adversarial perturbations. Specifically, the authors define adversarial subspaces, which are spanned by orthogonal directions of minimal perturbation from any given input sample. The authors conduct analysis to characterize the geometry of the boundary, which is more curved within the adversarial subspace than within a random subspace of equal dimensionality. "
SP:af5c25ecf38c5c3f3387720bdc80c2c54c5699fe,This paper proposes a weakly supervised contrastive learning approach to learn representations for unlabeled data. The proposed approach is based on the idea that the auxiliary information can be used to improve the performance of self-supervised representation learning. The main contribution of this paper is to propose a two-stage weakly supervised learning approach. The first stage is to cluster data according to its auxiliary information. The second stage is learning similar representations within the same cluster and dissimilar representations for data from different clusters. Experiments show that the proposed approach performs better than other baseline representation learning methods.
SP:0a92fcc52970201de4a66b1e76c93dbea9dfd3f1,"This paper proposes a method to learn algorithms automatically from data. The method is based on unrolling a classic path-following algorithm, with some components being more flexible and learnable. The authors theoretically show the improved recovery accuracy achievable by PLISA. Furthermore, they analyze the empirical Rademacher complexity of PLISA to characterize its generalization ability to solve new problems outside the training set. "
SP:5064eda9ba27060af15e81b2b317b2e4558b0ac4,This paper proposes a method for learning a compact and decodable latent representation space for the discrete-continuous hybrid action space. The proposed method is based on an embedding table and conditional variational auto-encoder (VAE) to learn the dependence between discrete action and continuous parameter. The authors evaluate the proposed method on a variety of environments. 
SP:5128bf712f6b197de113c7a371b4bec36f978eca,"This paper proposes SGEM, Stochastic Gradient with Energy and Momentum to solve a large class of general non-convex stochastic optimization problems, based on the AEGD method that originated in the work [AEGD: Adaptive Gradient Descent with Energy. The authors show that SGEM features an unconditional energy stability property, and derive energy-dependent convergence rates in the general nonconvolutional setting, as well as a regret bound in the online convex setting. "
SP:11f49b0a975be87769be29e85d7e3924699cf2c9,"This paper proposes a conditional masked language model with correction (CMLMC) to improve the performance of Transformer-based autoregressive (AR) machine translation models. The proposed CMLMC is based on the Conditional Masked Language Model with Correction (CMM) framework. CMM is trained on raw data without distillation and approaches AR performance on multiple datasets, a first for NAR models. "
SP:96f8ac3c6163e56d8ae1954a162bae01e6b58a0a,"This paper proposes a new neural network architecture inspired by the WaveNet architecture. The proposed architecture is based on spiking neural dynamics, which is a natural alternative to dilated temporal convolutions. The authors demonstrate the effectiveness of the proposed architecture on several datasets for keyword-spotting. "
SP:7f20a2e4e95f857140b87b0730360b3ff2f371f4,"This paper proposes a class of algorithms, called Shifty algorithms, that provide high-confidence behavioral guarantees that hold under demographic shift. The proposed algorithm, Shifty, is based on the idea that if certain subgroups of the population become more or less probable in deployment (a phenomenon called demographic shift), prior work’s fairness assurances are often invalid. The authors show that the proposed algorithm is an effective tool for training models that are fair when demographic shift occurs. They evaluate Shifty using a real-world dataset of university entrance exams and subsequent student success."
SP:94f097921bee5fdc10ec2e7c901b2ddb876d9d41,"This paper proposes a neural Stochastic Dual Dynamic Programming (ν-SDDP) method for solving multi-stage stochastic optimization problems. The proposed method learns to map problem instances to a piece-wise linear value function within intrinsic low-dimension space, which is architected specifically to interact with a base SDDP solver, so that it can accelerate optimization performance on new instances. The authors demonstrate that the proposed method can significantly reduce problem solving cost without sacrificing solution quality."
SP:3d9f5132f9ec3807dbca78462a459fd123a09b24,"This paper proposes a protocol for private next-token prediction for language models that were fine-tuned on a private corpus after pre-training on a public corpus. The proposed method, called SUBMIX, is based on the idea of group differentially private prediction. The authors show that the proposed method is able to prevent the leakage of information that is unique to any individual user in the private corpus via a relaxation of group differential private prediction, which allows it to thwart existing data-extraction attacks. "
SP:7f524d186ea939309c7eeb843c62b6a4b4cfbc8a,"This paper proposes an unsupervised method to detect out-of-distribution (OOD) samples using a k-NN density estimate with respect to a classification model’s intermediate activations on indistribution samples. The authors leverage a recent insight about label smoothing, which they call the Label Smoothed Embedding Hypothesis, and show that the k-nn density estimator performs better as an OOD detection method both theoretically and empirically. "
SP:aafbd6ada14cc59a272fe4bf95fac71fa18e57ab,"This paper proposes a diffusion-based representation learning method for semi-supervised image classification. The proposed method is based on a new formulation of the denoising score matching objective, which encodes information needed for denoizing. The authors show that the proposed method can improve the performance of existing GANs and VAEs. "
SP:8cfc837d5c10d539bbd098df7134c42e4830ba25,This paper proposes a method for goal-conditioned reinforcement learning. The main idea is to use planning at training time to automatically generate a curriculum of intermediate states. The proposed method is more sample efficient that prior methods.
SP:ef3193842e06d4a6edb8a6a86ea5bc97ee5eaa4a,"This paper extends mixup to k-mixup by perturbing k-batches of training data in the direction of other randomly-chosen instances in the training set using displacement interpolation, i.e. interpolation under the Wasserstein metric. The authors demonstrate theoretically and in simulations that the proposed method preserves cluster and manifold structures, and extend theory studying the efficacy of standard mixup. The experiments show that training with k-Mixup further improves generalization and robustness across several network architectures and benchmark datasets of differing modalities. "
SP:0fe6a9848026e5f6436a380199e27a9ad26cffed,This paper proposes a nonlinear kernelized classification layer for deep networks to tackle the problem of embedding learning. The authors theoretically show that their classification layer optimizes over all possible radial kernel functions on the space of embeddings to learn an optimal nonlinear classifier. They then demonstrate the usefulness of this layer in learning more model-efficient classifiers in a number of computer vision and natural language processing tasks.
SP:01ee8ec81619784788eb0ce9785098e437d17a7c,"This paper studies the issue of bias in node representations obtained by Graph Neural Networks (GNNs) in the context of graph contrastive learning. In particular, the authors theoretically explain the sources of bias of GNNs and graph structure. Based on the analysis, fairness-aware data augmentation frameworks are developed to reduce the intrinsic bias. Extensive experiments on node classification and link prediction are carried out over real networks. "
SP:7739dc9e37f7f1384f87d2e60281e5bb27fece99,"This paper proposes a confounder balanced IV regression (CB-IV) algorithm to jointly remove the bias from the unmeasured confounders with IV regression and achieve better bias-variance trade-off in imbalanced treatment distributions. The proposed algorithm consists of three main modules: (1) treatment regression: regressing the treatment with IVs and confounds like previous nonlinear IV methods for removing the confounding from unmmeasureable confounds; (2) confounding: learning a balanced representation of confounds to eliminate the bias induced by the observed confoundings; and (3) outcome regression. Extensive experiments demonstrate that CB-IV algorithm outperforms the state-of-the-art methods, including IV regression methods, for treatment effect estimation. "
SP:fdb68c39fce254b73310a3101b2fe97ba47e69fe,"This paper studies the problem of model-agnostic meta-learning (MAML) in a linear regression setting where hardness is related to the rate that gradient descent converges on the task. Specifically, the authors prove that in order for MAML to achieve substantial gain over NAL, (i) there must be some discrepancy in hardness among the tasks, and (ii) the optimal solutions of the hard tasks must be closely packed with the center far from the center of the easy tasks optimal solutions. The authors also give numerical and analytical results suggesting that these insights apply to two-layer neural networks. "
SP:e8143c7880c16ee9ce7a544e0fd80f001b1b4f9f,"This paper proposes a new method for sparse blind source separation (BSS) based on an unrolled version of the Proximal Alternating Linearized Minimization (PALM) algorithm. The proposed method, called Learned PALM (LPALM), leverages the data-driven knowledge stemming from realistic simulations or ground-truth data by learning both PALM hyperparameters and variables. In contrast to most existing unrolled algorithms, which assume a fixed known dictionary during the training and testing phases, this paper further emphasizes on the ability to deal with variable mixing matrices (a.k.a. dictionaries). The proposed LPALM algorithm thus enables to perform semi-blind source separation, which is key to increase the generalization of the learnt model in real-world applications. "
SP:7716315001949ab88c8a216302fe51bae872fc87,"This paper proposes a new attention module called implicit self-attention and a Legendre Memory Unit based model to improve the performance of transformers on the task of language modeling. The authors show that for the same amount of training, the proposed model improves the loss over transformers about as much as transformers improve over LSTMs. "
SP:832f422b3554e89702e13c8c5690ee26f2289e3b,"The paper proposes a two-stage GAN-based method for image generation. The first stage is trained on the classical GAN objective with internal conditioning on a set of space keypoints. The second stage is used to re-arrange the generated images by re-positioning and exchanging keypoint embeddings, such as generating portraits by combining the eyes, and mouth from different images. The keypoints have associated appearance embedding that respectively control the position and style of the generated objects and their parts. "
SP:9206ae6e31077569313838504ef6daa89ad3b59c,This paper studies the effect of layer normalization on the signal propagation of fully connected neural networks. The authors show that increasing the depth leads to gradient explosion or to another undesirable phenomenon called representation shrinkage. They also show that many popular normalization techniques fail to mitigate these problems. 
SP:2177be818b5843c580c787f1b2d725154846feb6,"This paper proposes a line search method for finding optimal step sizes for stochastic gradient descent automatically. The proposed method is based on the observation that the full-batch loss behaves locally parabolically in the direction of noisy update step directions. By exploiting these findings, the authors propose a line-search method that approximates the full batch loss with a parabola estimated over several mini-batches. Learning rates are derived from such parabolas during training. The experiments show that the proposed method outperforms SGD tuned with a piece-wise constant learning rate schedule and other line search approaches for Deep Learning across models, datasets, and batch sizes on validation and test accuracy."
SP:62233782f9046c85617d9ccfe8427eae7d1c9da7,"This paper studies the problem of noise-contrastive estimation (NCE) when the noise distribution is inappropriate. The authors prove that the problem arises due to an ill-behaved (more precisely, flat) loss landscape. To address this, the authors introduce a variant of NCE called eNCE which uses an exponential loss and for which normalized gradient descent addresses the landscape issues provably when the target and noise distributions are in a given exponential family."
SP:ceba6c1421b2d03863007fdaf029b8b946519c1b,"This paper studies the convergence of distributed SGD under Byzantine faults. The authors first observe that the integration of standard practices in DP and BR is not straightforward. To circumvent this shortcoming, they revisit the theory of (α, f)-BR to obtain an approximate convergence guarantee. Then, they propose to improve this guarantee through hyperparameter optimization."
SP:bc783f0c829f90931535e63687d13172879631b3,This paper proposes a novel method for code editing with few exemplars. The proposed method combines edit representations extracted from support exemplars and compositionally generalizes them to the query code snippet editing via multi-extent similarities ensemble. The authors evaluate the proposed method on C# and Python datasets and show up to 8.6% absolute accuracy improvements compared to non-composition baselines.
SP:ca0c4bdb02f7d939fb6de38b6b446ced4b5984a0,"This paper proposes a generative model based on relational constraints between different subcomponents of an example (e.g., lines of a poem or measures of music). The proposed model has two parts: (i) one model to generate a realistic set of relational constraints, and (ii) a second model that generates realistic data satisfying these constraints. For model (i), the authors propose a program synthesis algorithm that infers the relational constraints present in the training data, and then learn a generator based on the resulting constraint data. "
SP:692ae0c583a1585eff1a7d9c0d3b51b7879611cc,"This paper proposes a new method for set-to-hypergraph prediction. The main contribution is to change the asymptotic memory scaling from exponential to linear. The authors also introduce a training method that encourages iterative refinement of the predicted hypergraph, which allows us to skip iterations in the backward pass for improved efficiency and constant memory usage. Finally, the authors combine both contributions in a single set to hypergraph model that enables us to address problems with larger input set sizes."
SP:e3481fb6d8d1aa45d6ed4a454e781f5a2c30c57e,"This paper proposes a post-processing method to mitigate bias of state-of-the-art models. It consists in learning a shallow neural network, called the Ethical Module, which transforms the deep embeddings of a pre-trained model to give more representation power to the discriminated subgroups. The proposed method is supervised by the von Mises-Fisher loss, whose hyperparameters allow to control the space allocated to each subgroup in the latent space. Besides being very simple, the resulting methodology is more stable and faster than most current methods of bias mitigation. "
SP:3fb5dcc8b8fb731e09c14b16480cada1c7ccfaa7,"This paper proposes a new method for knowledge distillation in class-incremental learning (CIL). The proposed method is based on placebo data chosen from a free image stream (e.g., Google Images), which is both simple and surprisingly effective even when there is no class overlap between the placebos and the old data. The authors use an evaluation function to quickly judge the quality of candidate images (good or bad placebos) and collect good ones. For training this function, they sample pseudo CIL tasks from the data in the 0-th phase and design a reinforcement learning algorithm."
SP:506e0a888c03a955b708464eed3670c04baf4912,"This paper proposes a path auxiliary algorithm for sampling from discrete distributions. The proposed algorithm uses a composition of local moves to efficiently explore large neighborhoods. The authors also give a fast version of their algorithm that only queries the evaluation of energy function twice for each proposal via linearization of the energy function. Empirically, they show that their path auxiliary algorithms considerably outperform other generic samplers on various discrete models for sampling, inference, and learning. "
SP:4b466277aa5561a80c48d5e72559de4ce95f228b,"This paper presents Variational Predictive Routing (VPR), a neural probabilistic inference system that organizes latent representations of video features in a temporal hierarchy, based on their rates of change, thus modeling continuous data as a hierarchical renewal process. By employing an event detection mechanism that relies solely on the system's latent representations (without the need of a separate model), VPR is able to dynamically adjust its internal state following changes in the observed features, promoting an optimal organisation of representations across the levels of the model’s latent hierarchy. Experiments on several video datasets demonstrate the effectiveness of the proposed method."
SP:459ef2e6bd7638020955dbb4d8ae1098619f7b95,"This paper proposes a unified global and attention-based Local Features Retrieval method (UGALR), which is an end-to-end and single-stage pipeline. The proposed method accelerates extraction speed and reduces memory consumption by removing the re-ranking process and learning local feature matching with convolutional neural networks instead of RANSAC algorithm. Experiments on Revisited Oxford and Paris datasets validate the effectiveness of the proposed method. "
SP:487cc308a1e8ee078c54b2158bcae47e920e73f8,"This paper proposes a new method for multi-task learning, called RotoGrad, that jointly homogenizes gradient magnitudes and directions, while ensuring training convergence. The method is based on the Pytorch algorithm. The authors show that the proposed method outperforms existing methods in multi-label classification in CelebA and computer vision tasks. "
SP:050cd8319d84a1bd8c2ccb930ba69b33c8fb6e60,"This paper proposes a new model fusion framework, CLAFusion, to fuse neural networks with a different number of layers, which the authors refer to as heterogeneous neural networks, via cross-layer alignment. The cross layer alignment problem, which is an unbalanced assignment problem, can be solved efficiently using dynamic programming. The proposed framework balances the number of layer of neural networks before applying layer-wise model fusion. Experiments on CIFAR-10 show that the proposed framework achieves a more favorable performance compared to the individual networks trained on heterogeneous data without the need for any retraining. "
SP:f764eae15cd083fdb4eb2af09ac64c2d878a454f,"This paper studies the implicit regularization effect of SGD in the offline deep RL setting, leading to poor generalization and degenerate feature representations. The authors derive the form of this implicit regularizer and, inspired by this derivation, propose a simple and effective explicit regularizer, called DR3, that counteracts the undesirable effects of this implicitly regularizer. Experiments are conducted on Atari 2600 games, D4RL domains and robotic manipulation from images. "
SP:6fd793b27123bf80504e2ad5957455b7ec311612,"This paper proposes a probabilistic hypermodel-based exploration method HyperDQN to address the limitations of randomized least square value iteration (RLSVI) in deep RL. The proposed method is based on a non-linear neural network (i.e., base model) that predicts Q-values, which outputs the parameter of the base model. The hypermodel is trained to approximate Q-value functions. The authors show that the hypermodel can generate approximate posterior samples regarding the parameter and the changing feature does not affect the efficiency of RLSVI. "
SP:b428383660928374c953f659ea1e05852dbdcd6e,This paper proposes a method to learn causal representations from observational data by regularizing the learning procedure with mutual information measures according to a hypothetical causal graph. The authors prove a theoretical guarantee that the causality-inspired learning is with reduced sample complexity and better generalization ability. Extensive experiments show that the models trained on causal representations learned by their approach is robust under adversarial attacks and distribution shift.
SP:1258c05a80a17949b50e6dae13deea1d2235f456,"The paper proposes ProgFed, a progressive training framework for efficient and effective federated learning. The proposed framework is based on gradient compression and distillation. The authors theoretically prove that Progfed converges at the same asymptotic rate as standard training on full models.   The authors also show that their approach is also complimentary to prior work on compression, showing reduced communication of up to 50x at only 0.1% loss in utility. "
SP:8cdaa6e0dafd750ebdb5d7a4c1987a042400662f,This paper studies the generalization of adversarial training through the lens of the adversarial Rademacher complexity of deep neural networks. The authors provide a method to overcome this issue and provide upper bounds of the upper bounds. The upper bounds also include the product of weight norms. They provide experiments to show that the adversarially trained weight norms are larger than the standard trained weight norm. 
SP:925d6bb051e9b384669fb695085b678c11f7c11a,"This paper proposes a differentiable kernel-based estimator of differential entropy. The proposed estimator is parameterized by a kernel. The authors show that the estimator can be used to estimate both conditional and continuous differential entropy, as well as mutual information. Experiments on a variety of tasks demonstrate the effectiveness of the proposed method. "
SP:d2f3beac855f0d72c13552fecb2bdb9d42195df3,"This paper proposes a new soft-greedy operator, called resmax, that takes actions proportionally to their suboptimality gap: the residual to the estimated maximal value. The authors show that resmax is a non-expansion for any fixed exploration hyperparameter, unlike the softmax policy which requires a state-action specific temperature to obtain a nonexpansion (called mellowmax). "
SP:792ae8808aa6902758146aef1548c975492b833c,This paper proposes a new method to control the model's learnability on a specific dataset with a special key. The proposed method leverages class-wise perturbation that applies a universal transformation function on data samples of the same label. This ensures that the learnability can be easily restored with a simple inverse transformation while remaining difficult to be detected or reverse-engineered. The authors empirically demonstrate the success and practicability of the proposed method on visual classification tasks. 
SP:9af10703605e620e563241e2602a50b629f3d37a,"This paper proposes a new method for handling missing features in graph machine learning applications. The proposed method is based on minimization of the Dirichlet energy and leads to a diffusion-type differential equation on the graph. The discretization of this equation produces a simple, fast and scalable algorithm which is called Feature Propagation. The authors show that the proposed method outperforms previous methods on seven common node-classification benchmarks and can withstand surprisingly high rates of missing features. Moreover, it takes only 10 seconds to run on a graph with ∼2.5M nodes and ∼123M edges."
SP:cbaa3f1379fa99159899d79ccb479c0187403aca,This paper proposes an integer optimization problem for selecting a core set that minimizes the discrete Wasserstein distance from the unlabeled data pool to label. The core set is selected by using high-quality latent features that can be obtained by unsupervised learning on the unlabelled pool. The authors demonstrate that this problem can be tractably solved with a Generalized Benders Decomposition algorithm. Numerical results on several data sets show that the optimization approach is competitive with baselines and particularly outperforms them in the low budget regime. 
SP:4c72923f78ca6590dc11e10d1a2403076a583718,"This paper proposes a method to solve the de novo genome assembly problem by applying geometric deep learning to the central part of the genome assembly. A graph convolutional network is trained on a dataset generated from human genomic data to reconstruct the genome by finding a path through the assembly graph. The authors show that their model can compute scores from the lengths of the overlaps between the sequences and the graph topology which, when traversed with a greedy search algorithm, outperforms the greedy search over the overlap lengths only. Moreover, their method reconstructs the correct path in the fraction of time required for the state-of-the-art de-novo assemblers. "
SP:24de906e4289c9073b6c55c747b0913b8df5e053,"This paper proposes to use experience replay (ER) in meta-learning to improve continual learning representations by integrating ER also into meta-training. The authors propose to store the samples’ representations, instead of the samples themselves, into the replay buffer. This ensures the batch nature of ER does not conflict with the online-aware nature of OML. Moreover, the authors introduce a meta-learned Predictive Sample Selection to replace the widely used reservoir sampling. Experimental results on a number of real-world meta-continual learning benchmark data sets demonstrate that the proposed method outperforms the state-of-the-art. "
SP:3c78454f053f74930979a8054cd7c8a34b6fe63d,"This paper proposes a new method for multi-agent joint Q-learning based on centralized training with Decentralized Execution (CTDE) where each agent gives its suggestion about how to weight individual Q-values to explicitly maximize the joint Q value, besides guaranteeing the Bellman optimality. The authors formulate an explicit credit assignment problem and formulate a gradient ascent solution for this problem. Empirically, the authors show that ECAQ achieves interpretable credit assignment and superior performance compared to several advanced baselines."
SP:0d2b225ac697679d10df25f371b2a718d4949b42,"This paper studies the problem of adversarial robustness in the context of transductive learning. The authors formulate and analyze threat models for adversarial learning based defenses, and point out important subtleties. They propose the principle of attacking model space for solving bilevel attack objectives, and present Greedy Model Space Attack (GMSA), an attack framework that can serve as a new baseline for evaluating adversarial based defenses. They show that GMSA, even with weak instantiations, can break previous Transductive-learning based defenses which were resilient to previous attacks, such as AutoAttack. On the positive side, they report a somewhat surprising empirical result of “transductive adversarial training”: Adversarially retraining the model using fresh randomness at the test time gives a significant increase in robustness against attacks we consider. "
SP:e7024cae196fc5eb6a62d289a95d76b532b6a36c,"This paper studies the problem of batch normalization, which is an approximation of the limiting case where the entire dataset is normalized jointly, and explore other ways to approximate the gradient from this limiting case. The authors propose an approximation that removes the need to keep more than one example in memory at any given time, at the cost of a small factor increase in the training step computation, as well as a fully per-example training procedure. They further use their insights to improve batch renormalization for very small minibatches. "
SP:4aa42984fcb0fd66936d668477b2719ef5c427d4,This paper proposes a low-rank adaptation method to reduce the number of trainable parameters for downstream tasks. The proposed method freezes the pretrained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture. The authors show that the proposed method performs on-par or better than finetuning in model quality on RoBERTa. 
SP:b77a00beb0802f47810b03d3c4aa24d92781414f,"The paper proposes a new linear-chain conditional random field (CRF) that can enforce a broad class of constraints, including nonlocal ones, by specifying the space of possible output structures as a regular language L. The resulting regular-constrained CRF (RegCCRF) has the same formal properties as a standard CRF, but assigns zero probability to all label sequences not in L. Moreover, RegCCRF can incorporate their constraints during training, while related models only enforce constraints during decoding. The authors prove that constrained training is never worse than constrained decoding, and show empirically that it can be substantially better in practice. "
SP:74c186a96c12adff178264aa84ace8d04dc7d725,"This paper proposes two neural models for camera-based physiological measurement called EfficientPhys that remove the need for face detection, segmentation, normalization, color space transformation or any other preprocessing steps. The proposed models achieve state-of-the-art accuracy on three public datasets. "
SP:3003bab6e3f7e2e21cd6cf27ee7d483d877d9fb3,"This paper proposes Hardware-Aware Latency Pruning (HALP) that formulates structural pruning as a global resource allocation optimization problem, aiming at maximizing the accuracy while constraining latency under a predefined budget. The proposed method leverages latency lookup table to track latency reduction potential and global saliency score to gauge accuracy drop. The paper also proposes an augmented knapsack solver, enabling HALP to surpass prior work in pruning efficacy and accuracy-efficiency trade-off."
SP:c44d676c09c8e5a70d73b21b507b41a422fec809,"This paper proposes a molecular graph generation method via energy-based models (EBMs) for permutation invariant and multi-objective molecule generation. The authors propose to learn the energy function by contrastive divergence and generate samples by Langevin dynamics. In addition, to generate molecules with a specific desirable property, the authors propose a simple yet effective learning strategy, which pushes down energies with flexible degrees according to the properties of corresponding molecules. The experimental results demonstrate the effectiveness of the proposed method. "
SP:70e60fa5deef3e3ba77d05d0c3e0e7fbf396aa1d,"This paper proposes a neural model to learn a bottom-up search policy for program synthesis, instead of relying on a combinatorial search algorithm. The proposed method, called CROSSBEAM, learns to combine previously explored programs into new programs, taking into account the search history and partial program executions. The method is trained on-policy using data extracted from its own top-up searches on training tasks. The experiments show that the method learns to search efficiently, exploring much smaller portions of the program space compared to the state-of-the-art."
SP:daa044ffefe80bae16b014f60061d941ed8c2ba6,This paper proposes a method to replace the standard squared Bellman error with a functional regularizer. The proposed method is based on the idea of using up-to-date parameters as well as control the regularization. The method is evaluated on a range of Atari environments. 
SP:dd174014d056a7d2bc86ee99119841eafa62ed52,"This paper proposes a new perspective on designing powerful Graph Neural Networks (GNNs). In a nutshell, this enables a general solution to inject structural properties of graphs into a message-passing aggregation scheme of GNNs. The authors develop a new hierarchy of local isomorphism on neighborhood subgraphs. Then, they theoretically characterize how message passing GNN can be designed to be more expressive than the Weisfeiler Lehman test in distinguishing graph structures. To elaborate this characterization, they propose a novel neural model, called GraphSNN, and prove that this model is strictly more expressive. "
SP:beb9ba0261e176bfc50e9bf5bed2b6169d388285,"This paper proposes a novel prediction interval (PI) method for uncertainty quantification. The proposed method is based on linear combinations of three NNs, each of which is independently trained using the standard mean squared error loss. The coefficients of the linear combinations are computed using root-finding algorithms to ensure tight PIs for a given confidence level. The authors theoretically prove that PI3NN can calculate PIs without retraining NNs and it completely avoids the crossing issue. Furthermore, the authors propose an initialization scheme which provides reasonably larger PIs of the OOD samples than those of the in-distribution samples. "
SP:4b44a834e2212bacb4c2d9408a81f1efc76a670b,"This paper proposes a meta-learning method for online learning. The proposed method is based on the idea of metalearning, where the model is trained on a set of tasks, and then used to adapt to new tasks. The authors show that the proposed method outperforms the baselines on Rainbow-MNIST and CIFAR-100 datasets. "
SP:fbae35cb171b3a3eb7c5d4bc83881ed7c4a70aae,This paper proposes a differentiable scaffolding tree (DST) to convert discrete chemical structures to locally differentiable ones. The DST enables a gradient-based optimization on a chemical graph structure by back-propagating the derivatives from the target properties through a graph neural network (GNN). The empirical studies show the gradient based molecular optimizations are both effective and sample efficient. 
SP:61b59899cf6ae442d9f8f5226e79708a4280cfb2,This paper proposes a knowledge-augmented approach to predict patients' response for a target lab result. The proposed approach is based on a graph-based model of drug-lab interactions and diagnosis-lab interaction as graphs. The authors also take into consideration patients' past lab responses to personalize the prediction. Experiments on real-world datasets demonstrate the effectiveness of the proposed solution.
SP:8623cebb515c4a736427449b46ad2cdf8b806b77,"This paper proposes a new single-domain generalization (SDG) problem, where the target domain includes unseen categories out of the source label space. The authors propose a CrossMatch approach to improve the performance of SDG methods on identifying unknown classes by leveraging a multi-binary classifier. The CrossMatch generates auxiliary samples out of source domain space by using an adversarial data augmentation strategy.  The authors also adopt a consistency regularization on generated auxiliary samples between multibinary classifiers and the model trained by SDG. "
SP:126f8ffb855aa22eda4d681a499953879ed3679e,"This paper proposes two natural extensions of trust-region methods based on Kullback-Leibler divergence, namely Wasserstein policy optimization and Sinkhorn policy optimization (SPO). WPO and SPO directly optimize the policy distribution and derive their close-form policy updates based on the Lagrangian duality. Theoretically, the authors show that WPO guarantees a monotonic performance improvement, while SPO provably converges to WPO as the entropic regularizer diminishes. Experiments across tabular domains and robotic locomotion tasks further demonstrate the performance improvement of both approaches, more robustness of WPO to sample insufficiency, and faster convergence of SPO."
SP:999eacf6500c87205584a3256d7ca45b3016fb1c,"This paper proposes a forgetting-and-relearn framework for shaping the learning trajectories of artificial neural networks. The forgetting step selectively removes undesirable information from the model, and the relearning step reinforces features that are consistently useful under different conditions. The proposed forgetting and relearning framework unifies many existing iterative training algorithms in the image classification and language emergence literature, and allows us to understand the success of these algorithms in terms of the disproportionate forgetting of undesirable information. "
SP:2789859517b6624730b14a7e010444a72d3dd3ed,"This paper proposes an offline-online setting for batch RL, where the agent has access to a batch of data to train on but is also allowed to learn during the evaluation phase in an online manner. This is an extension to batch RL and allows the agent to adapt to new situations without having to precommit to a policy. The experiments show that standard RL agents trained in an offline and online manner can outperform agents trained only offline or online."
SP:76625a25e770415599a34122110d61cb3b7e614c,"This paper studies the problem of domain generalization (DG) via learning to reduce domain shift with an episodic training procedure. In particular, the authors propose a PAC-style generalization bound for discrepancyoptimal meta-learning and further make comparisons with other DG bounds including ERM and domain-invariant learning. The theoretical analyses show that there is a tradeoff between classification performance and computational complexity for discrepancy-optimal Meta-learning. Empirically, the proposed method achieves state-of-the-art results on two DG benchmarks. "
SP:6421a9759c766641fd8c128a249f1a9c5699d19c,"This paper studies the effect of the policy and value networks in DNN-based best-first search on the Sokoban domain. The authors show that the policy network is a powerful heuristic guiding the search, which can lead to left heavy tails with polynomial scaling by avoiding exploring exponentially sized sub-trees. To further understand the phenomena, the authors studied the cost distribution of the search algorithms and found that the heavy-tailed runtime distributions are both on the left and right-hand sides. "
SP:84c415bc0f120d1997289f91661ff74e7297d3bd,This paper presents a method for meta-imitation learning by watching video demonstrations from humans. The method is able to translate human videos into practical robot demonstrations and train the meta-policy with adaptive loss based on the quality of the translated data. Experiments show that the method achieves comparable performance to the baseline on fast learning a set of vision-based tasks through watching a single video demonstration. 
SP:fedf5c75e83d6ab41ef9d5daa9054ffe4e424ec2,"This paper studies the problem of over-parameterized deep neural networks trained using gradient-based optimizers. The authors argue that adaptive optimizers are prone to making output scores (logits) and network weights large, causing training loss to become too small and the network to lose its adaptivity (ability to move around and escape regions of poor generalization) in the weight space. "
SP:819df8d847a99f13ed5efdcabae8b464c12b464b,"This paper proposes a family of equivariant convolutional neural networks (G-CNNs) that can learn partial and full equivariances from data at every layer end-to-end. The authors claim that the proposed method is applicable to discrete groups, continuous groups and combinations thereof.   The authors show that the partial G-CNN is able to retain full equivariance whenever beneficial, e.g., for rotated MNIST, but are able to restrict it whenever it becomes harmful. "
SP:0c0ca9df96f1fa2eb8b83a47d0d5964590fef290,"This paper proposes the amortized Langevin dynamics (ALD), which replaces the datapoint-wise MCMC iterations with updates of an inference model that maps observations into latent variables. The authors prove that ALD has the target posterior as a stationary distribution under some assumptions. ALD can be extended to sampling from an unconditional distribution such as an energy-based model, enabling more flexible generative modeling by applying it to the prior distribution of the latent variable. Based on ALD, the authors construct a new deep latent variable model named the Langevin autoencoder (LAE). LAE uses ALD for autoencoders-like posterior inference and sampling from the latent space EBM. "
SP:5631097031c7e599bdeae64366ffa6e4558837c6,"This paper proposes a neural network for hypergraph reasoning. The proposed model is based on the grounding of relationships such as parent and grandparent tensors as sparse tensors and uses neural networks and finite-domain quantification operations to infer new facts. To enable training on large-scale graphs such as real-world knowledge graphs, the proposed model makes training and inference-time sub-sampling of the input graphs. To remedy the information loss in sampled sub-graphs, the authors propose a novel sampling and label calibration paradigm based on an information-theoretic measure information sufficiency. "
SP:9657121b01c51f78c00d06b47d3e8d678dd85d54,"This paper proposes a new family of differentiable top-k cross-entropy classification losses. The authors relax the assumption that k is a positive integer, and propose to draw k from a probability distribution for training. They find that relaxing k does not only produce better top-5 accuracies, but also makes models more robust, which leads to top-1 accuracy improvements."
SP:cb3188f435c54a365890e20e4d582c250d919833,"This paper proposes a new method for solving large-scale optimal transport (OT) problems at an unprecedented combination of speed and accuracy. The proposed method tackles the original OT problem directly instead of solving an approximate regularized problem, as many state-of-the-art techniques do. The algorithm has the same cost per iteration as the popular Sinkhorn method, and each iteration can be executed efficiently, in parallel. In addition, the authors establish a linear convergence rate for the formulation of the OT problem. "
SP:9a087cc734a3e7f3ab848bef5e2eff37fe40f303,This paper proposes a framework for disentangling performance gaps in federated learning. The framework is based on the idea that the performance gap should be separated from unseen client data (out-of-sample gap) from performance gaps from unseen clients distributions (participation gap). The authors propose a semantic synthesis strategy that enables realistic simulation without naturally-partitioned data. 
SP:da0e8c89f343abfe500eb4c1968e418c2fb52ef6,"This paper studies the few-shot setting of pre-trained language models (PLMs) with self-supervised finetuning. The authors show that a simple Multi-Null Prompting (without manually/automatically created prompts) strategy can yield very promising results on a few widely-used datasets, e.g., IMDB, Amazon, and GLUE. "
SP:9817dccb1a121058b23a2ef825ed339cf8b53674,This paper proposes a method to improve the alignment of the attention mechanism. The proposed method is based on a sharpener module. The sharpener is used to align the relevant parts of the encoded image with the target output. The method is evaluated on synthetic handwritten handwritten 8 digit as well as real-world scene text recognition datasets.
SP:3913ed3b3cf6494368e3be6cacb637ff85f80ee6,This paper proposes a method for learning a complete tour plan from scratch while respecting an apriori fixed number of available vehicles. The proposed method is based on a supervised deep learning framework. The authors show that their method is faster and easier to train and achieves competitive results. 
SP:594a813c0d0baa66738b9c8331370f861ad3c416,"This paper proposes a novel link prediction method that enhances graph learning by counterfactual inference. The proposed method uses causal models considering the information of the node pair (i.e., learned graph representations) as context, global graph structural properties as treatment, and link existence as outcome. Experiments on benchmark datasets show that the proposed method achieves state-of-the-art performance on link prediction."
SP:48a7e50451b887f55be17b2662aa11ce18791cc1,"This paper proposes a two-stage unsupervised feature selection via knowledge contrastive disTillation (SOFT) model that incorporates the second-order covariance matrix with the first-order data matrix. In the first stage, the authors learn a sparse attention matrix that can represent second order relations between features, and perform graph segmentation for feature selection. Experimental results on 12 public datasets show that SOFT outperforms classical and recent state-of-the-art methods. "
SP:14bcae11aeede63f28d1b80c05ed18a01d3e3f3c,"This paper proposes a new multimodal variational autoencoder (VAE) that combines information from different modalities implicitly through mutual supervision. The proposed method is based on semisupervised VAEs, which can be used to combine information between modalities. The authors show that the proposed method outperforms baselines on both partial and complete observation schemes on the MNIST-SVHN (image–image) and CUB (image-text) datasets. "
SP:e834a52cadebe5f125ce491273b4ad1146beae3f,"This paper proposes Deep Explore Options, an extension of Explore Options to tackle complex visual problems. The authors propose a new transitionselection algorithm based on the interest of multiple agents. They also propose to consider intrinsic reward learning as an auxiliary task, with a resulting architecture achieving 50% faster wall-clock speed and building a stronger, shared representation. "
SP:41578dd1a4bdb043b3d68afa5f9cebb3e14f3907,"This paper proposes a new method for learning Hamiltonian dynamical systems from data. The method is based on a stiffness-aware index, which is a simple, yet effective metric to quantify the stiffness of the dynamical system. The authors also propose a resampling technique to apply different time integration strategies such as step size adaptation to better capture the dynamic characteristics of the Hamiltonian vector fields."
SP:bfb0a059eeb6f40a18fbd20c0eec5037a64ca09e,"This paper proposes a method for training Transformer-based language models to perform multi-step computations. The method is based on scratchpad training, where the model is asked to emit intermediate computation steps into a “scratchpad”. The authors show that the scratchpad improves the performance of the model on a number of tasks. "
SP:e6c1a8b4bba287455dc9cf145b6bd1f04e2148a9,"This paper proposes a novel method for generating adversarial perturbations that are interpretable, universal to any source image, and physically-realizable. The proposed method is based on deep image generators and a novel optimization objective. The authors show that they are versatile and use them to generate targeted feature-level attacks at the ImageNet scale that are simultaneously interpretable. They also show that these attacks can also reveal spurious, semantically-describable feature/class associations that can be exploited by novel combinations of natural objects."
SP:873618263dc4246a39c44d0abfecfb5f688817e3,"This paper proposes a new method for simulated annealing (SA) based on reinforcement learning. The proposed method is based on a learned proposal distribution, which can be optimised for higher solution quality given a fixed computational budget. The authors show that the proposed method outperforms baselines with hand-selected parameters on Rosenbrock's function, the Knapsack problem, the Bin Packing problem, and the Travelling Salesperson problem. "
SP:cae31f7436920eb3946e3f5bca0ac88a73d7c3ec,"This paper proposes a new metric for measuring the non-stationarity of a policy sequence, which can be bounded by the KL-divergence of consecutive joint policies. The proposed metric is based on message passing, and the authors propose a trust-region decomposition network (TRD-Net) to estimate the joint policy divergence more accurately. Experiments show that the proposed metric can improve the performance of MAMT."
SP:989b58167a15ae4fafbe27ff534d327991b6c4d7,"This paper proposes a self-supervised representation learning framework for audio-visual speech, which masks multi-stream video input and predicts automatically discovered and iteratively refined multimodal hidden units. On the largest public lip-reading benchmark LRS3 (433 hours), AV-HuBERT achieves 32.5% WER with only 30 hours of labeled data, outperforming the former state-of-the-art approach (33.6%) trained with a thousand times more transcribed video data. "
SP:7c9eb8aa4a4dcb5965157d860e812d81654e3aa7,"This paper proposes ECORD, an RL algorithm for combinatorial optimisation on graphs. The main idea is to restrict the GNN to a single pre-processing step, before entering a fast-acting exploratory phase directed by a recurrent unit. Experiments show that ECORD achieves a new SOTA for RL algorithms on the Maximum Cut problem, while also providing orders of magnitude improvement in speed and scalability."
SP:f741d980c9c560a21298e947f1605dcbab7ceeac,"This paper proposes a new method for training VAEs with discrete latents. The proposed method is based on a variational variational autoencoder (VAE) with truncated posteriors. The authors show that the proposed method can be used to train VAEs without sampling-based approximation, reparameterization trick and amortization.  The authors also show that direct optimization can be efficiently scalable to hundreds of latent variables using smaller networks.  "
SP:deb189d37bd51b92762ce259a106d9a9e9d81ea4,"This paper proposes a new method to identify controllable aspects of the environment. The method is based on counterfactual measures of blame to identify effects on the environment controlled by the agent. The proposed method is evaluated in a wide range of environments showing that it can accurately identify controlled effects. Moreover, it is integrated into the state-of-the-art exploration method, achieving substantially better performance than action-prediction models."
SP:ea18d57904e25fd09ed0f6c9972029d78779a8a6,"This paper proposes structure-regularized pruning (SRP), which imposes regularization on the pruned structure to make sure the locations of pruned filters are aligned across different layers. To transfer the expressive power in the unimportant filters to the rest of the network, the authors employ L2 regularization to drive the weights towards zero so that eventually their absence will cause minimal performance degradation. The authors apply SRP to train efficient image SR networks, resulting in a lightweight network SRPN-L and a very deep one SRPN. "
SP:0dee45001ae9600f485614dfe6874a516ac01db5,"This paper proposes a framework for few-shot learning. The proposed framework trains a feature extracting backbone with the contrastive loss on the base category data and a masking module to select relevant features that are more suited to target domain classification. Finally, a classifier is fine-tuned along with the backbone such that the backbone produces features similar to the relevant ones. Experimental results demonstrate that the proposed framework outperforms all meta-learning approaches and produces competitive results against recent cross-domain methods. "
SP:92aa611d71a8da597358330d84fddbb90de2cf4f,"This paper studies the generalization properties of infinite width networks trained by Bayesian inference and finite width neural network trained by gradient descent. The authors show that while typical networks that fit the training data already generalise fairly well, gradient descent can further improve generalisation by selecting networks with a large margin. They also show that test performance can be substantially improved by selecting a function with much larger margin than is typical under the NNGP posterior. "
SP:a0e3cf719a95bbc5aad2f663ba5a3169c316ee9b,"This paper proposes a cross-lingual manifold mixup (X-Mixup) method, which adaptively calibrates the representation discrepancy and gives compromised representations for target languages. Experiments on the XTREME benchmark show 1.8% performance gains on multiple text understanding tasks, compared with strong baselines. "
SP:19f8cd8f0c274b6141ba097d2ebb6d18af0986fd,"This paper studies the problem of Byzantine robust distributed or federated learning, where a central server wants to train a machine learning model over data distributed across multiple workers. The authors propose a simple bucketing scheme that adapts existing robust algorithms to heterogeneous datasets at a negligible computational cost. They also theoretically and experimentally validate their approach. "
SP:4d63513b9a1b9b9fc44a69b3d5679a8f48eb95e7,This paper studies the relationship between disentanglement and multi-task learning based on hard parameter sharing. The authors perform a thorough empirical study of the representations obtained by neural networks trained on automatically generated supervised tasks.   
SP:9851adb72e2918780f661f83f7da06eb866787be,"This paper proposes a framework for certifying robust policies for reinforcement learning against adversarial state perturbations. The authors propose two types of robustness certification criteria: robustness of per-state actions and lower bound of cumulative rewards. Specifically, the authors propose a local smoothing algorithm that uses a policy derived from Q-functions smoothed with Gaussian noise over each encountered state to guarantee the robustness for actions taken along this trajectory. They also propose a global smoothing approach that makes use of adaptive search in order to obtain tight certification bounds for the reward. "
SP:78da3c97182ec1baf6a131740bf7c91a9afb2fd2,"This paper proposes a new approach to conformal prediction, which aims to output a precise set of promising prediction candidates that is guaranteed to contain a limited number of incorrect answers. The authors propose to trade coverage for precision by enforcing that the presence of incorrect candidates in the predicted conformal sets (i.e., the total number of false positives) is bounded according to a user-specified tolerance. The proposed algorithm then optimizes for a generalized notion of set coverage, which allows for any number of true answers for a given query (including zero)."
SP:b126d2f3c397633745c8833e22ace93a2470e963,"This paper studies the length distortion of ReLU networks with random initialization. The authors show that the expected length distortion does not grow with depth, and indeed shrinks slightly, for ReLU network with standard random initialization, and generalize this result by proving upper bounds both for higher moments of the distortion and for the distortion of higher-dimensional volumes. "
SP:b3b6d0512edfca461ea295ee8665f7f226c45d57,"This paper proposes SAFEty skill pRiors (SAFER), a behavioral prior learning algorithm that accelerates policy learning on complex control tasks, under safety constraints. SAFER learns to extract a safety variable from offline data that encodes safety requirements, as well as the safe primitive skills over abstract actions in different scenarios. In the inference stage, SAFER composes a safe and successful policy from the safety skills according to the inferred safety variable and abstract action. The authors demonstrate its effectiveness on several complex safety-critical robotic grasping tasks inspired by the game Operation,1."
SP:a5dadb3ecc3caed3b9d9a68eda0d48a53c2d1ce2,"This paper proposes a multi-branch restoration model inspired from the Human Visual System (i.e., Retinal Ganglion Cells) which can achieve multiple restoration tasks in a general framework. The experiments show that the proposed model, called CMFNet, has competitive performance results on four datasets, including image dehazing, deraindrop, and deblurring, which are very common applications for autonomous cars. "
SP:263b386beee44b0b45b6f6dc3cf80d020500be62,"This paper proposes a new federated learning setup, Inference-time PFL (IT-PFL), where a model trained on a set of clients, needs to be later evaluated on novel unlabeled clients at inference time. The proposed method is based on a hypernetwork module and an encoder module. The authors show that it generalizes better than current FL and PFL methods, especially when the novel client has a large domain shift. "
SP:960d0a63a82593f6e72275b65f0501f0469d1924,This paper presents a new method to visualize representations learned with self-supervised models. The method is based on a conditional diffusion based generative model (RCDM) and is trained to generate images from a set of data augmentation data. The authors show that SSL (backbone) representation are not invariant to many data augumentation they were trained on.  The authors also demonstrate that SSL representations are more robust to small adversarial perturbation of their inputs. 
SP:398899e6c86b4a2a17dfa5c2f4478811f4331c1d,"This paper studies the problem of differentially private frequency moments estimation. The authors prove that Fp sketch, a well-celebrated streaming algorithm for frequency moments, is differentially privacy as is when p ∈ (0, 1). The authors also provide an evaluation of the algorithm. "
SP:3253b13851b5a3b5e3c8c6e24891db05903a4e57,"This paper proposes a reward-switching policy optimization (RSPO) method to discover diverse strategies in complex RL environments by iteratively finding novel policies that are both locally optimal and sufficiently different from existing ones. To encourage the learning policy to consistently converge towards a previously undiscovered local optimum, RSPO switches between extrinsic and intrinsic rewards via a trajectory-based novelty measurement during the optimization process. Experiments show that the proposed method is able to discover a wide spectrum of strategies in a variety of domains. "
SP:e3ab3aa87ab023bd9949b99a17d4b6e26c1473c0,This paper proposes a new sampling method for diffusion models. The main idea is to use gradient descent to improve the sample quality of the diffusion model. The method is based on differentiable diffusion Sampler Search (DDSS) and is compatible with any pre-trained diffusion model without fine-tuning or re-training required. The authors show that optimizing the degrees of freedom of GGDM samplers by maximizing sample quality scores via gradient descent leads to improved sample quality. 
SP:7a7506f2b5500a573c0cfb8b0822e5ea725c886a,This paper proposes a lightweight model called P-Adapters that sits between the embedding layer and first attention layer of LLMs. The P-Adapter takes LLM embeddings as input and output continuous prompts that are used to query the LLM. The authors also investigate Mixture of Experts (MoE) models that learn a set of continuous prompts (“experts”) and select one to query. 
SP:35cdf71f027cc5168b55cc34c64bfb2f3087d6f5,"This paper proposes a continuous classification of time series (CCTS) method. The authors define CCTS as a continual learning task with the unclear distribution division. In order to overcome two main problems, the authors propose a novel Adaptive model training policy ACCTS. Instead of the fixed rules and the prior knowledge, ACCTS extracts data distributions adaptive to the time series evolution and the model change. ACCTS only replays the important samples. Experiments on four real-world datasets show that ACCTS can classify more accurately than all baselines at every time. "
SP:d9b74b749aa465496763d3a3a9bf3a53e800587e,"This paper proposes a memory-based language model that can read and memorize new data at inference time, thus acquiring new knowledge immediately. The authors show that an approximate kNN lookup into the memory improves language modeling across various benchmarks and tasks, including generic webtext (C4), math papers (arXiv), books (PG-19), code (Github), and formal theorems (Isabelle). "
SP:7a1bbf86c3fdb8738aa826ca330493e857d050ba,"The paper proposes a sampling scheme based on the Metropolis–Hastings Monte Carlo algorithm to generate samples from the masked language modeling (MLM) objective. The proposed sampling scheme is based on two energy parametrizations derivable from the trained MLMs. The authors show that the proposed sampling algorithm yields a Markov chain whose stationary distribution is that of the target distribution, and their approach generates higher quality samples than other recently proposed undirected generation approaches. "
SP:011626ba4fafee13d4a30e3f13c1df5b7071a7f1,"The paper proposes a learning-based data augmentation method to improve the performance of deep neural networks for NLP tasks. The proposed method is based on the idea that a good augmentation should construct more diverse and challenging samples for providing informative training signals, while avoiding the risk of losing the semantics of original samples. The authors propose a novel reward function for updating the augmentation policy to construct difficult but not too different samples (DND) while training the model, to construct the augmented samples with low confidence but a high semantic similarity with original ones. In addition, the authors introduce a sample re-weighting scheme to focus on difficult augmented samples after the original ones are learned confidently for more effective learning from the augmented ones. The method is more effective on the challenging low-data and class-imbalanced regimes."
SP:69d41a862ea189f72d4e8af2854e27b95a91fa41,"This paper proposes a new meta-learning framework for offline reinforcement learning. The proposed framework is based on the FOCAL framework, which is an extension of the SOTA algorithm. The key idea is to use intra-task attention mechanism and inter-task contrastive learning objectives to improve task representation learning against sparse reward and distribution shift. Theoretical analysis and experiments are presented to demonstrate the superior performance and robustness of the proposed framework. "
SP:ed86c60850d5c8302dcf1c2167db303e778fe681,"This paper proposes a method to improve the accuracy of the belief model at test time. The method is based on the idea of parametric sequential generative modeling, where the model parameters at each time step are approximate dynamic programming in the form of fine-tuning. The authors demonstrate the effectiveness of the method on the Hanabi game. "
SP:6150725599c10f0e26f0d7cb1fc04b5b227a4456,"This paper proposes a new method for training neural networks with sparse inputs. The proposed method, Pixelated Butterfly, uses a simple fixed sparsity pattern based on flat block butterfly and low-rank matrices to sparsify most network layers (e.g., attention, MLP). The authors show that the proposed method is 3x faster than butterfly and speeds up training to achieve favorable accuracy–efficiency tradeoffs."
SP:136e31054a55abca840f6478491972023c2296cb,"This paper proposes a conditional diffusion probabilistic model for image generation. The proposed method is inspired by the class clustering phenomenon. The authors propose to model the class center in the forward and reverse process, and make an elegant modification to the original formulation, which enables controllable generation and gets interpretability. Experiments are conducted on CIFAR-10 and ImageNet to verify the effectiveness of the proposed method. "
SP:fc2196f1f4ecd864398fed6640ff3f8b19870763,"This paper proposes a new domain generalization (DG) method, LASSO, that explores diverse latent subspaces and learns individual hypotheses on those sub-spaces. The proposed method is based on the LAtent Sub-Space Orientation (LASSO) method. The authors show that the latent sub-space is formed by the label-informative features captured in source domains, which allows the model to project target examples onto appropriate sub-subspaces while preserving crucial label information for the label prediction task. "
SP:6e8e5bdeb77e3cafe1975da8411fb65118955d14,"This paper studies the problem of kernel thinning (KT) in a reproducing kernel Hilbert space (RKHS). The authors show that KT applied directly to the target RKHS yields tighter, dimension-free guarantees for any kernel, any distribution, and any fixed function. They also show that, for analytic kernels like Gaussian, inverse multiquadric, and sinc, target KT admits maximum mean discrepancy (MMD) guarantees comparable to or better than those of square-root KT without making explicit use of a less smooth squareroot kernel. Finally, they establish that a sum of the target and power kernels (a procedure called KT+) simultaneously inherits the improved MMD guarantees of power KT and the tighter individual function guarantees of target KT."
SP:645c3f1864aa843d4899fc2406f694b5aab8460d,"This paper presents a benchmark suite for the NP-hard MAXIMUM INDEPENDENT SET problem, in both its weighted and unweighted variants. The suite offers a unified interface to various state-of-the-art traditional and machine learning-based solvers. The authors also conduct an in-depth analysis of the popular guided tree search algorithm by Li et al. (Li et al., 2018). The authors re-implementing their algorithm with a focus on code quality and extensibility, and show that the graph convolution network used in the tree search does not learn a meaningful representation of the solution structure, and can in fact be replaced by random values. "
SP:155ecd17d264a084b014abdfd0362146d8fb07e0,"This paper proposes Wavelet Compressed Convolution (WCC), a novel approach for activation maps compression for 1 × 1 convolutions (the workhorse of modern CNNs). WCC achieves compression ratios and computational savings that are equivalent to low bit quantization rates at a relatively minimal loss of accuracy. To this end, the authors use a hardware-friendly Haar-wavelet transform, known for its effectiveness in image compression, and define the convolution on the compressed activation map. By combining WCC with light quantization, they achieve compression rates equal to 2-bit and 1-bit with minimal degradation in image-to-image tasks. "
SP:004865e6affad32403b7965493a53c8a7ffdda0a,"This paper studies the problem of learning in extensive-form correlated equilibrium (EFCE) in multiplayer general-sum imperfect-information extensive form games. The authors propose a faster no-regret learning dynamics for EFCE in the context of correlated and coarse correlated equilibria in normal-form games, which can capture sequential and simultaneous moves, as well as imperfect information. The proposed algorithm is based on a refined perturbation analysis of a structured Markov chain, which may be of independent interest. Experiments on standard benchmarks corroborate the findings."
SP:ee545ff83df4d7ff256ac61fbe0eb0765f52f1d5,"This paper proposes a method to learn a discretization of continuous action spaces by leveraging the priors of demonstrations. By discretizing the action space, the proposed method can apply any discrete action deep RL algorithm to the continuous control problem. The proposed method is evaluated on three different setups: RL with demonstrations, RL with play data and imitation learning. "
SP:4b39279b98d6aa311bb49dd1384925f9d6f66c2d,"This paper proposes a novel adversarial style augmentation (AdvStyle) approach for domain generalization in semantic segmentation. AdvStyle is based on the idea that the image style variation can largely influence the model’s performance and the style features can be well represented by the channelwise mean and standard deviation of images. Specifically, AdvStyle regards the style feature as a learnable parameter and updates it by adversarial training. Experiments on two synthetic-to-real semantic segmentations benchmarks demonstrate that AdvStyle can significantly improve the model performance on unseen real domains and show that it can achieve the state of the art. "
SP:4a2e6d70b383e4941e0bc44e7e82972b22e26792,"This paper proposes a novel approach for mid-air gesture recognition. The proposed approach consists of an event-based guided variational autoencoder (VAE) and an encoder component. The VAE encodes the event based data sensed by a Dynamic Vision Sensor (DVS) into a latent space representation suitable to compute the similarity of midair gesture data. The authors show that the Hybrid GuidedVAE achieves 87% classification accuracy on the DVSGesture dataset and it can encode the sparse, noisy inputs into an interpretable latent space representations, visualized through T-SNE plots. "
SP:2e66468a6b94177e54b0052b97713ee63902c278,This paper proposes a Hierarchical Table Ensemble (S-HTE) for tabular data. The proposed method is based on ferns (oblivious decision trees) and uses an annealing mechanism to reduce the number of neurons in the network. The authors show that the proposed method can be used for classification and regression tasks. 
SP:b238db9252d83a13438bb747d70e635bb9945958,"This paper studies the problem of learning value functions from undirected state-only experience (state transitions without action labels). The authors first theoretically characterize the applicability of tabular Q-learning in discrete Markov decision processes (MDPs) learns the same value function under any arbitrary refinement of the action space. This theoretical result motivates the design of Latent Action Q-Learning or LAQ, an offline RL method that can learn effective value function from state- only experience. The authors show that LAQ can recover value functions that have high correlation with value functions learned using ground truth actions. "
SP:108ebe9045a9e2b8b5aba8352733782462db8a81,"This paper proposes SWARM Parallelism, a model-parallel training algorithm designed for swarms of poorly connected, heterogeneous unreliable devices. SWARM creates temporary randomized pipelines between available nodes that are rebalanced in case of failure. To further reduce the network usage of SWARM, the authors develop several compression-aware architecture modifications and evaluate their tradeoffs. Finally, they combine their insights to train a large Transformer language model with 1.1B shared parameters on a swarm of preemptible T4 GPUs with less than 400Mb/s network throughput. "
SP:91d2f094d5481651b554f58aecc2a6207057a47c,"This paper proposes an online transition correction (OTC) method for offline decentralized multi-agent reinforcement learning. The proposed method is based on two types of distances, i.e., embedding-based and value-based distance, to measure the similarity between transitions, and further propose an adaptive rank-based prioritization to sample transitions according to the transition similarity. Empirically, the proposed method outperforms baselines in a variety of tasks."
SP:d0e650d568214481b07a0452ec606ccbf6d05410,"This paper proposes a logarithmic unbiased quantization (LUQ) method to quantize both the forward and backward phase to 4-bit, achieving state-of-the-art results in quantized neural network training. The authors also propose a method that exploits the low precision format by avoiding multiplications during two-thirds of the training process."
SP:f2862d1f987164ed6c3c375cd8962e57c369373b,"This paper proposes a self-attention feature selection mechanism to improve the performance of attentional classifiers in the presence of task-irrelevant features. Specifically, the proposed method is based on the idea that the classifier should be able to learn a classifier that is polythetic by default. The authors show that threshold meta-learners, such as Prototypical Networks, require an embedding dimension that is exponential in the number of task relevant features to emulate these functions. In contrast, attentional classes are polythetic by default and able to solve these problems with a linear embedding.  The authors also show that the attentional models are susceptible to misclassification. To address this challenge, the authors propose to adaptively dilute non-discriminative features."
SP:e1e513fef25d29e17cdadd1b36d932a8ad8897cd,"This paper proposes a multi-agent reinforcement learning framework to study emergent communication between agents with a continuous communication channel trained through reinforcement learning. The proposed framework is based on a simple messaging environment where a speaker agent needs to convey a concept to a ""listener"" agent, and the listener needs to map the continuous signal to the concept. The speaker is equipped with a vocoder that maps symbols to a continuous waveform, this is passed over a lossy continuous channel. The authors show that noise is essential in the communication channel when conveying unseen concept combinations. They show that basic compositionality emerges in the learned language representations. "
SP:0e6ff65ba4a3df35947d1b6f4d438612088d90a0,This paper proposes a backdoor attack against pre-trained NLP models. The key feature of the attack is that the adversary does not need prior information about the downstream tasks when implanting the backdoor to the pre-training model. The authors further design a simple yet effective strategy to bypass a state-of-the-art defense. Experimental results indicate that the proposed backdoor attack can compromise a wide range of downstream NLP tasks in an effective and stealthy way. 
SP:58d3ecb4a1906251e79ad883aa97cc2502642658,"This paper proposes a new framework for skill discovery, where skills are learned one after another in an incremental fashion. This framework allows newly learned skills to adapt to new environment or agent dynamics, while the fixed old skills ensure the agent doesn’t forget a learned skill. Experiments are conducted on both evolving and static environments. "
SP:2c6595408f5ec95537eaf555e5fe3d992b58c222,"This paper proposes a novel log-polar space convolution (LPSC) layer, where the convolution kernel is elliptical and adaptively divides its local receptive field into different regions according to the relative directions and logarithmic distances. The proposed LPSC not only naturally encodes local spatial structures, but also greatly increases the single-layer receptive field while maintaining the number of parameters. Experiments on different tasks and datasets demonstrate the effectiveness of the proposed LPsC. "
SP:7791f96b1eef277a9133975507a750d9e7c6b8ff,"The paper proposes an algorithm for the efficient approximation of the information bottleneck on the trade-off between accuracy and information complexity of NNs. The authors show that the compression of information stored in weights (IIW) is proved to play a key role in NNs generalization based on the PAC-Bayes theorem. Then, the authors build an IIW-based information bottleneck based on PIB, which satisfies the potential of IIW in enhancing NNs in practice. "
SP:a733847ade77ffbf38760fc79da17893dea8d53f,"This paper studies the problem of data poisoning attacks, which add imperceptible perturbations to training data to maximize the test error. The authors show that the perturbation of advanced attacks are almost linear separable when assigned with the target labels of the corresponding samples. They also show that linear separability is indeed the workhorse for recent attacks. "
SP:7b50be406138ad01db3ee112899f622637896fe9,This paper proposes a new algorithm for offline policy evaluation. The proposed algorithm is based on importance sampling and its variants. The authors provide theoretical justification of the proposed algorithm through a better per-state-neighborhood normalization condition and show the limitation of previous attempts to this approach through an illustrative example. They further test their proposed method in a healthcare-inspired simulator and a logged dataset collected from real hospitals.
SP:c976752a55b9ff47dc63c95a9fd7b51a81e8a42e,"This paper presents CoLLIE, a method for continual learning of how language is grounded in vision. The method is based on a pre-trained multimodal embedding model, where language and images are projected in the same semantic space (in this case CLIP by OpenAI). The method learns a transformation function that adjusts the language embeddings when needed to accommodate new language use. The authors verify the model’s performance on two different tasks of continual learning."
SP:d3371b322acfc321ee79a2e1b438d82644872fa4,"This paper proposes a novel object captioning model, VLAF2, for learning Visual-Linguistic Adequacy, Fidelity, and Fluency, which utilizes linguistics observed from captions for describing visual information of images with novel objects. The authors provide an insight into the relationship between the above properties and existing visual/language models. The proposed method is evaluated on the nocaps dataset. "
SP:9f3b6486662d80350d77a4b060d4a5b8b22a6130,"This paper studies the transfer learning problem in few-shot learning. The authors provide an explanation for the phenomenon that the features learned by overparameterized classification networks show an interesting clustering property, called neural collapse. They demonstrate both theoretically and empirically that neural collapse generalizes to new samples from the training classes, and – more importantly – to new classes as well, allowing foundation models to provide feature maps that work well in transfer learning and, specifically, in the few shot setting. "
SP:624c95d9ce1ee4b66274e858e2da22bef6b052c7,"This paper proposes a deep point cloud reconstruction network consisting of two stages: 1) a 3D sparse stacked-hourglass network as for the initial densification and denoising, 2) a refinement via transformers converting the discrete voxels into 3D points. In particular, the authors further improve the performance of transformer by a newly proposed module called amplified positional encoding. This module has been designed to differently amplify the magnitude of positional encoding vectors based on the points’ distances for adaptive refinements. Extensive experiments demonstrate that the proposed network achieves state-of-the-art performance among the recent studies in the ScanNet, ICL-NUIM, and ShapeNetPart datasets. "
SP:34a81ca65131576d4c14332a4e9eb3a4c344cab7,"The paper proposes a new method for GCN training, called PipeGCN, which is based on the idea of pipelining inter-partition communication. The authors show that the convergence rate of the proposed method is close to that of the vanilla distributed GCN with staleness. The paper also proposes a smoothing method to further improve the convergence. "
SP:8302d49558ee0f16392d623d4e604e92db10d041,"This paper proposes a method for test time adaptation. The method is based on minimizing the entropy of the model’s average, or marginal, output distribution across the augmentations. The proposed method can be applied to any test setting where the model is probabilistic and adaptable: when presented with a test example, perform different data augmentations on the data point, and then adapt (all of) the model parameters. The experiments show the effectiveness of the proposed method."
SP:a985de5e940ff3a4160b378201b8c02f68d1914a,"This paper proposes a new objective for jointly training the model and the policy, such that updates to either component increase a lower bound on expected return. The proposed algorithm (MnM) is conceptually similar to a GAN: a classifier distinguishes between real and fake transitions, the model is updated to produce transitions that look realistic, and the policies are updated to avoid states where the model predictions are unrealistic. "
SP:a469fbcdc20b11dff4085b6fbc384e77f33cd37d,"This paper proposes a method to combine behavioral cloning from observation history and single observation cloning from single observation. The method is inspired by human decision making. The authors first compute a coarse action based on the instantaneous observation, and then refine it into a final action using historical information. The proposed method is evaluated on CARLA autonomous driving from images and various MuJoCo continuous control tasks. "
SP:95c4533b5d1a865c4cc6a54615e7ad6357bdaad1,"This paper proposes a model-based meta-learning method called DyAd which can generalize across heterogeneous domains by partitioning them into different tasks. DyAd has two parts: an encoder which infers the time-invariant hidden features of the task with weak supervision, and a forecaster which learns the shared dynamics of the entire domain. The encoder adapts and controls the forecaster during inference using adaptive instance normalization and adaptive padding. Theoretically, the generalization error of such procedure is related to the task relatedness in the source domain, as well as the domain differences between source and target. "
SP:ec70553cb0c27e5349c1b8cce6bcaa96a83bf050,"This paper proposes a method for weakly supervised monocular 3D object detection. The proposed method first detects 2D boxes on the image. Then, a network is trained to predict 3D boxes which can tightly align with associated RoI LiDAR points. The method obtains 16.47 AP in KITTI, which even outperforms many prior fully supervised methods."
SP:34217c6a8ca43b8eeb9ddc83d6f1f0af05918984,"This paper proposes a soft gradient-based subword tokenization module (GBST) that automatically learns latent subword representations from characters in a data-driven fashion. GBST enumerates candidate subword blocks and learns to score them in a position-wise fashion using a block scoring network. The authors also introduce CHARFORMER, a deep Transformer model that integrates GBST and operates on the byte level. "
SP:d26d25f2ef23a89a2c139d0dd87c4c86fddcff5e,"This paper studies the black-box hard-label backdoor detection problem where the DNN is fully black box and only its final output label is accessible. The authors show that the objective of backdoor detection is bounded by an adversarial objective, and show that a singularity is often observed in the adversarial map of a backdoorinfected example, which they call adversarial singularity phenomenon. Based on this observation, the authors propose a new adversarial extreme value analysis (AEVA) to detect backdoor attacks. AEVA is based on the monte-carlo gradient estimation. "
SP:c6dbca0ed0799b7fec21777606f6f809eb2d8c48,"This paper proposes a new uncertainty measure, Kullback-Leibler divergence (KLoS), for jointly quantifying in-distribution and out of distribution (OOD) uncertainties. The proposed KLoS is a class-wise divergence measure built from in-sample and out-of-sample samples and does not require OOD training data, in contrast to current second-order uncertainty measures. The authors further design an auxiliary neural network, KLoSeNet, to learn a refined criterion directly aligned with the evidential training objective. Experiments show that KLoSE outperforms first-order and second- order uncertainty measures to simultaneously detect misclassifications and OOD samples. "
SP:8b4f3916dca4e627931558e14836749bd4a6792f,"This paper studies the problem of semi-supervised learning of convolutional neural networks. Specifically, the authors consider the case where the distribution of patches in the input images has low-dimensional structure (e.g., when the patches are sampled from a low dimensional manifold). The authors show that the dependence of their algorithm on the dimension of the patch distribution is essentially optimal."
SP:7f2f354d5cc1030bd97bd716aea8fe1d3af86b25,"The paper proposes a novel algorithm for face clustering based on graph convolutional networks (GCN). The proposed method Ada-NETS aims to construct clean graphs for GCNs to cluster faces by constructing clean graphs by constructing a new structure space, which is transformed to a new face structure space by considering face features of the neighbour images. Then, an adaptive neighbour discovery strategy is proposed to determine a proper number of edges connecting to each face image. Experiments on multiple public clustering datasets show that the proposed method significantly outperforms current state-of-the-art methods. "
SP:a3bc8e26f55e78f07de081ca85865afd52b6ae4a,"This paper proposes a new distributionally robust optimization (DRO) method for learning robust models that are able to perform well on a collection of possible data distributions (the “uncertainty set”) without demographics. The proposed method, Unit DRO, minimizes the loss over a reweighted dataset where important samples (i.e., samples on which models perform poorly) will be upweighted and others will be downweighted. The authors show that the proposed method achieves superior performance on large-scale DG ReID and cross-domain ReID benchmarks compared to standard baselines. "
SP:62c1f734b7f6c6e7d5114da6f37c9e3cdda73a23,This paper proposes a method to improve the training of GNNs by adding noise to the input graph. The proposed method is based on the idea of noise correcting node-level loss. The authors show that the noise correction loss helps ameliorate oversmoothing by encouraging diverse node latents. They also demonstrate the effectiveness of Noisy Nodes with non-spatial architectures on Open Graph Benchmark. 
SP:24a1b44f37f8eedbab2047fb84600a322d289f3b,"This paper proposes a new approach to the set2vec problem. The key idea is to use the maximum-a-posterior (MAP) estimate of the mixture distribution, which is approximately attained by a few ExpectationMaximization (EM) steps. The proposed approach is differentiable and can be seen as a special case of the optimal transport kernel embedding (OTKE). The proposed method is evaluated on various tasks. "
SP:b4f7b660b84fe7702fbcc8a96c192abc3a64f045,"The paper proposes a contrastive analysis (CA) method for unsupervised feature selection in the biomedical data analysis setting. The proposed method, CFS (Contrastive Feature Selection), is based on the contrastive feature selection (CFS) framework. The authors show that CFS outperforms previous state-of-the-art methods on a semi-synthetic dataset and four real-world biomedical datasets."
SP:bc4f69f23aba2034cbf14cb31bdc7a991806bbf6,This paper studies the problem of early stopping in linear regression models. The authors show that the optimal early stopping time corresponds to the training process of deep neural network. They also provide theoretical results to reveal the relationship between the model dimension as well as sample size of the dataset for linear regression model. 
SP:ede87b50cd9c4a6533f17e3e5ddfaaeaaac71dcf,"This paper proposes a quasi-Newton method for the policy gradient algorithm with entropy regularization. In the case of Shannon entropy, the resulting algorithm reproduces the natural policy gradient (NPG) algorithm. For other entropy functions, this method results in brand new policy gradient algorithms. The authors provide a simple proof that all these algorithms enjoy the Newton-type quadratic convergence near the optimal policy. "
SP:3535504f7599b1f39239f7cd8e09acd40fa8fdf0,"This paper proposes a generalization method for text-based games (TBG). The main idea is to use case-based reasoning to train agents and generalize out of the training distribution. The method is inspired by case reasoning, where the agent collects instances of positive experiences from the agent’s interaction with the world in the past and later reuses the collected experiences to act efficiently. The proposed method can be applied in conjunction with any existing on-policy neural agent in the literature for TBGs. The experiments show that the proposed method consistently improves existing methods."
SP:9a5dd0148a15dc5b4d2bc6762dfe8a8991f8866c,This paper proposes a two-stage method to distill multiple word senses from a pre-trained language model (BERT) by using attention over the senses of a word in a context and transferring this sense information to fit multi-sense embeddings in a skip-gram-like framework. The authors demonstrate an effective approach to training the sense disambiguation mechanism in their model with a distribution over word senses extracted from the output layer of BERT. 
SP:e4cdba0fc7cd7f440d4436219f3959d8d5e2ad28,"This paper proposes a method to transfer 2D model architectures and weights to understand 3D point-clouds, by inflating 2D convolutional filters to 3D convolutions and finetuning the inflated imagepretrained models (FIP). The method is evaluated on few-shot classification and speed-up training of point cloud models. The authors show that the method can achieve competitive performance on 3D Point-cloud classification, beating a wide range of point-Cloud models that adopt task-specific architectures and use a variety of tricks."
SP:dc99c307931ae9c5d4a1b998dc94cfc6ac78d11f,"This paper proposes a method for training the autoregressive generative model that takes advantage of a well-designed energy-based learning objective. The authors show that their method is capable of alleviating the exposure bias problem and increase temporal coherence by imposing a constraint which fits joint distributions at each time step. Besides, the authors estimate energy scores based on the underlying auto-regressive network itself, which does not require any extra network. Finally, thanks to importance sampling, the proposed method can train the entire model efficiently without requiring an MCMC process."
SP:51e748c55bd4134047098559577fa3f37aa7433a,"This paper proposes a unified framework that connects Wasserstein distributional robustness with current state-of-the-art adversarial training (AT) methods. Specifically, the authors introduce a new Wasserstein cost function and a new series of risk functions, with which they show that standard AT methods are special cases of their counterparts in their framework. This connection leads to an intuitive relaxation and generalization of existing AT methods and facilitates the development of a new family of distributional adversarial robustness AT-based algorithms. Extensive experiments show that the proposed framework robustify further their standard AT counterparts in various settings."
SP:f192046ea8ad61bfc8e05a0ddb90a8bd15b4640b,"This paper proposes a new unsupervised representation learning framework for multivariate time series, namely Bilinear Temporal-Spectral Fusion (BTSF). BTSF uses instance-level augmentation by simply applying dropout on the entire time series for better preserving global context and capturing long-term dependencies. Also, an iterative bilinear temporal-spectral fusion module is devised to explicitly encode the affinities of abundant time-frequency pairs and iteratively refine representations of time series through cross-domain interactions with Spectrum-to-Time (S2T) and Timeto-Spectrum (T2S) Aggregation modules. Extensive experiments are conducted on three major practical tasks for time series such as classification, forecasting and anomaly detection, which is the first to evaluate on all three tasks. "
SP:ef54840009afb095c67bbbc29a7824c20a375ee8,"This paper proposes a method for automatically adjusting the learning rate during gradient descent. The method is based on the line-search method. The authors formulate first and second-order gradients with respect to learning rate as functions of consecutive weight gradients, leading to a cost-effective implementation. Extensive experimental evaluation is conducted, validating the effectiveness of the proposed method."
SP:263c787361cd6d4443ce516d389c694d0fe44b28,"This paper proposes a method for continual meta-learning in sequential multi-task learning. The authors propose a new method, continual meta policy search (CoMPS), that removes this limitation by meta-training in an incremental fashion, over each task in a sequence, without revisiting prior tasks. CoMPS continuously repeats two subroutines: learning a new task using RL and using the experience from RL to perform completely offline meta learning to prepare for subsequent task learning. Experiments are conducted on several continuous control tasks."
SP:2bd729b7aa045bf74e31229c9e76e57af36e804b,"This paper proposes a new threat model for poisoned classifier, where one without knowledge of the original trigger, would want to control the poisoning classifier. Under this threat model, the authors propose a test-time, human-in-the-loop attack method to generate multiple effective alternative triggers without access to the initial backdoor and the training data. They construct these alternative triggers by first generating adversarial examples for a smoothed version of the classifier with a procedure called Denoised Smoothing, and then extracting colors or cropped portions of smoothed adversarial images with human interaction. The authors demonstrate the effectiveness of their attack through extensive experiments on ImageNet and TrojAI."
SP:e58ab0e3cff6b18013145a1a99cfa9da0a3d872f,"This paper proposes a new method for distilling unconditional GANs. The proposed method is based on the idea that the main challenge of unconditional GGAN distillation lies in the output discrepancy issue, where the teacher and student model yield different outputs given the same input latent code. The authors conduct thorough analysis about the reasons and effects of this discrepancy issue and identify that the style module plays a vital role in determining semantic information of generated images. Based on this finding, the authors propose a novel initialization strategy for the student model, which can ensure the output consistency to the maximum extent. To further enhance the semantic consistency, the author proposes a latent-direction-based distillation loss that preserves the semantic relations in latent space. Extensive experiments demonstrate the effectiveness of the proposed method."
SP:2c2231743fa33b95828c6615263954ce1c05f95d,This paper proposes a method for generating online approximations of offline algorithms. The method is based on the idea of learning a multi-task learning model to simultaneously detect behavioral structures which have already occurred and predict those that may come next. The authors demonstrate the method on both synthetic data and historical stock market data.
SP:ee3a21d2fb8a073099aa200129a53c31f3b6561d,"This paper proposes a method to amortize the computation of the inducing points locations, as well as the parameters of the variational posterior approximation q. The method is based on a neural network that receives the observed data as an input and outputs the induced points locations and parameters of q.  The authors show that their method is able to reduce the number of inducing points to O(M) per iteration. "
SP:f20c99b441545047a16ae524cc2e317b2c3787a2,"This paper proposes a protocol for secure (Byzantinetolerant) decentralized training that emphasizes communication efficiency. The authors provide theoretical bounds for its resistance against Byzantine and Sybil attacks and show that it has a marginal communication overhead. To demonstrate its practical effectiveness, they conduct large-scale experiments on image classification and language modeling in presence of Byzantine attackers."
SP:93894f20ab2593e5237b6972fef9fe63e96af89a,"The paper proposes a physics-informed learning method for smoothed particle hydrodynamics (SPH), which is a mesh-free Lagrangian method for obtaining approximate numerical solutions of the equations of fluid dynamics, which has been widely applied to weaklyand strongly compressible turbulence in astrophysics and engineering applications. The authors propose a learnable hierarchy of parameterized and “physics-explainable” SPH informed fluid simulators using both physics based parameters and Neural Networks as universal function approximators. The learning algorithm develops a mixed mode approach, mixing forward and reverse mode automatic differentiation with forward and adjoint based sensitivity analyses to efficiently perform gradient based optimization.  The authors show that their physics informed learning method is capable of solving inverse problems over the physically interpretable parameter space, as well as over the space of Neural Network parameters. "
SP:d11b81f9ab414fcf430a03cd70c2d3246b678474,"This paper proposes Mix-MaxEnt, a method to regularize a single deterministic neural network to obtain improved accuracy and reliable uncertainty estimates. The method is based on generating between-cluster samples via the convex combination of two images from different classes and maximizing the entropy on these samples. The proposed method is tested on real-world datasets (CIFAR-10 and CIFAR100) using ResNet and Wide-ResNet architectures. "
SP:365490b872464f00634dc7a50d024fceaf0a61ee,"This paper proposes a self-supervised auto-encoder-based method for animating images. The key idea is to learn a set of orthogonal motion directions simultaneously, and use their linear combination, in order to represent any displacement in the latent space. The proposed method is evaluated on three datasets: VoxCeleb, Taichi, and TED-talk. "
SP:86f9f89f84e117c86478b9afaf087f65524f5472,"This paper proposes a new meta-learning method, called task interpolation (MLTI), to generate additional tasks by randomly sampling a pair of tasks and interpolating the corresponding features and labels. The proposed method can be applied to both gradient-based and metric-based meta-training settings. The theoretical analysis shows that MLTI corresponds to a data-adaptive meta-regularization and further improves the generalization. Empirically, the proposed method is shown to be compatible with representative meta learning algorithms and consistently outperforms other state-of-the-art strategies. "
SP:73d577e9c4f4af5e11a9e5bdb583ee0f50a315f5,"This paper proposes a new method for fair representation learning. The proposed method, called Fair Normalizing Flows (FNF), is based on the idea of normalizing flows, which is to model the encoder as a normalizing flow trained to minimize the statistical distance between the latent representations of different groups. The main advantage of FNF is that its exact likelihood computation allows us to obtain guarantees on the maximum unfairness of any potentially adversarial downstream predictor. Experiments are conducted on a variety of real-world datasets."
SP:404d5643327f60f0f06f820033a56081f9e01900,"The paper proposes a novel GNN called COUNT-GNN for subgraph isomorphism counting. The key idea is to learn a low-dimensional representation for both the query and the input graph, which can be adapted to each query individually to improve their matching. At the edge level, the proposed method uses an edge-centric message passing scheme, where messages on edges are propagated and aggregated based on the edge adjacency. The proposed method is evaluated on a number of benchmark datasets. "
SP:5a94f18156ab2949c86de45fcf0de2e16977eebb,"This paper proposes a new method for federated learning, called SimFed, which is based on similarity matching and kernel factorization (SimFed). SimFed measures task-level similarity based on locally learned knowledge and matches the relevant ones for personalized knowledge reflection. SimFed also factorizes the model parameters into two basis vectors and the highly sparse masks to significantly reduce the dimensionlaity of parameter space for alleviating knowledge collapse and information loss when reflecting the heterogeneous knowledge. The paper studies two essential challenges of the agnostic personalized federated setting: label heterogeneity where local clients learn from the same single domain but labeling schemes are not synchronized with others and domain heterogeneity where the clients learns from the different datasets which can be semantically similar or dissimilar to each other. "
SP:97f30bea31eccef6c770fbce1e14fd6d2493a178,"This paper proposes an object dynamics distillation network (ODDN) that distills explicit object dynamic representations (e.g., velocity) from raw video input. The proposed ODDDN is based on a relation module that calculates object-pair interactions and applies it to the corresponding dynamic representations of objects. The authors verify the effectiveness of the proposed method on tasks of video events reasoning and video prediction. "
SP:ba8e50d1fa9cb824fa3f76c0c691997cd151d760,"The paper proposes a new GNN layer called PEG for positional encoding (PE) that allows using positional features of nodes given by positional encoding techniques such as Laplacian Eigenmap, Deepwalk, etc.. GNNs with PE often get criticized because they are not generalizable to unseen graphs (inductive) or stable. The paper studies these issues in a principled way and proposes a provable solution, a class of GNN layers termed PEG with rigorous mathematical analysis. PEG imposes permutation equivariance w.r.t. the original node features and rotation equivariant w.rt. the positional features simultaneously. Extensive link prediction experiments over 8 real-world networks demonstrate the advantages of PEG in generalization and scalability. "
SP:cf448479f68c3194c1a9e11729bf70d7cc2ae8fd,"The paper proposes LaMer, a novel text style transfer framework based on large-scale language models. LaMer first mines the roughly parallel expressions in the non-parallel datasets with scene graphs, and then employs MLE training, followed by imitation learning refinement, to leverage the intrinsic parallelism within the data. On two benchmark tasks (sentiment & formality transfer) and a newly proposed challenging task (political stance transfer), LaMer achieves qualitative advances in transfer accuracy, content preservation, and fluency. "
SP:8f7b2d1020d9e527118b8fb816760c13b0d0bfcb,"This paper studies the problem of multi-hop logical reasoning on hyper-relational knowledge graphs (KGs). In particular, the authors propose a method to answer queries that are based on a query embedding and a query answering method. The proposed method is based on Graph Neural Networks (GNNs) and query embeddings. The authors show that the proposed method can answer queries in a more complex setting. "
SP:5f8b58424a1a8eeb72217e75189d6f773a298a7a,This paper proposes a new method for multi-budget hyperparameter optimization. The method is based on a new surrogate for Gaussian Processes that embeds the learning curve dynamics and a new acquisition function that incorporates multi-budget information. The authors show that the proposed method outperforms the state-of-the-art baselines. 
SP:99d3d94e3af5d2dc7b92c00ac1345d1d2dd0d15b,"This paper proposes a method to improve the performance of learned image compression. The proposed method is based on the post-training quantization and makes the model inference integer-arithmetic-only, which is much simpler than presently existing training and fine-tuning based approaches. The authors also improve the discretization of the entropy parameters and extend the deterministic inference to fit Gaussian mixture models. "
SP:85d0df515e9e555f3ea1c21d607304dfaeae69c0,"This paper proposes a fully unsupervised noise reconstruction and removal network for denoising scanning electron microscopy images. The network is inspired by gated recurrent units, reconstructs and removes the noise by synthesizing the sequential data. The authors provide detailed performance analysis using numerical as well as empirical metrics."
SP:e6275b0b103fa90dcebcdd3d3c14c830c3402972,"This paper studies the stochastic label trick in GNNs. The authors show that under certain simplifying assumptions, the label trick can be reduced to an interpretable, deterministic training objective composed of two factors. The first is a data-fitting term that naturally resolves potential label leakage issues, while the second serves as a regularization factor conditioned on graph structure that adapts to graph size and connectivity. "
SP:b6cbc3661f9c440687c3dd01ee35a118c87db377,"The paper proposes to model machine theory of mind in a more flexible and symmetric scenario; a multiagent environment SymmToM where all agents can speak, listen, see other agents, and move freely through a grid world. The authors show that multi-agent deep reinforcement learning models that model the mental states of other agents achieve significant performance improvements over agents with no such ToM model. "
SP:f8ce83805eee46c6c196e8477bf10d8d7f7e0f46,"This paper proposes a zero-shot object detection method for indoor scenes. The proposed method is based on unsupervised learning, and it aims to detect novel objects in the image with the knowledge learned from and only from seen objects. The method is evaluated on the YCB Video Dataset, which contains 21 objects in various categories. "
SP:aa1dcd9217270010f16a00004facede942efea17,This paper proposes a method to generate high-fidelity and high-resolution videos by training an autoregressive latent video prediction model with minimal modification to existing models. The proposed method is based on a VQ-GAN with a causal transformer model and a top-k sampling and data augmentation to further improve video prediction quality. The method achieves competitive performance to state-of-the-art approaches on standard video prediction benchmarks with fewer parameters and enables high resolution video prediction on complex and large-scale datasets.
SP:7f57896afd63bc869d2db6ddf7abbeaa71daae11,"This paper proposes a generative adversarial network (GAN) based on Vision Transformers (ViTs) for image generation. The proposed GAN is based on the ViT architecture. The main contribution of the paper is to introduce several novel regularization techniques for training GANs with ViTs.   The proposed method is evaluated on three datasets: CIFAR-10, CelebA, and LSUN. "
SP:bbae3afcaea0a2e54904cb8daaed7df4fe37da6e,"This paper proposes to decompose the task of image generative modeling into two steps: first prioritize the modeling of visually perceptible information to achieve good sample quality, and then subsequently model the imperceptible information—the bulk of the likelihood signal—to achieve good likelihoods. The authors argue that the nature of high-dimensional image data distributions poses an intrinsic challenge. "
SP:bfed56018134ec66cde9a7e958df964d4cca3164,"This paper proposes a training-free inference framework that estimates the analytic forms of the variance and KL divergence using the Monte Carlo method and a pretrained score-based model. The authors show that both the optimal reverse variance and the corresponding optimal KL divergence of a DPM have analytic forms w.r.t. its score function. To correct the potential bias caused by the score based model, the authors derive both lower and upper bounds of the optimal variance and clip the estimate for a better result. Empirically, the analytic-DPM improves the log-likelihood of various DPMs, produces high-quality samples, and meanwhile enjoys a 20x to 80x speed up."
SP:3f935ba5784c3e86db72421426bc479061af1a4b,"This paper proposes to use vision transformers (ViTs) for medical image classification. The authors conduct a series of experiments on several standard medical image benchmark datasets and tasks. They show that, while CNNs perform better if trained from scratch, ViTs can perform on par with CNNs when pretrained on ImageNet. "
SP:a64e0535f268901e38fd51e027c612ebcdbae1a4,"This paper studies the problem of pretraining neural language models (NLMs) over a large corpus. The authors show that the pretrained NLM can model much stronger dependencies between text segments that appeared in the same training example, than it can between different training examples. This theoretically motivated degree of freedom for “pretraining example design” indicates new training schemes for self-improving representations. "
SP:59066956fa2e423d5f2d2ea4f91c4ddf6afd4683,"This paper proposes a new symbolic representation and analysis framework for learning to optimize (L2O) models. The proposed framework is based on symbolic regression, which can be used to improve interpretability and scalability of existing L2O models. In addition, the proposed framework can be applied to learnable optimizers. "
SP:54dfeb363beee9959aecc9e0853ff06e43bd94e4,"This paper studies the problem of provable adversarial robustness for deep neural networks (DNNs) in the context of reinforcement learning (RL). The main contribution is to prove an adaptive version of the Neyman-Pearson Lemma for smoothing based defenses, where the adversarial perturbation at a particular time can be a stochastic function of current and previous observations and states as well as previous actions. The authors then propose a method to defend against an adaptive RL adversary by adding a Gaussian noise to its observation at each time-step before passing it through the policy function. The robustness certificates guarantee that the final total reward obtained by policy smoothing remains above a certain threshold, even though the actions at intermediate time-steps may change under the attack. "
SP:e0f9add5fde18eaab0eeb2b10b14928acc8ec5b8,"The paper proposes a new method for predicting the target domain accuracy using only labeled source data and unlabeled target data. The method is based on the average threshold on the model's confidence, predicting accuracy as the fraction of unlabeling examples for which model confidence exceeds that threshold. The proposed method outperforms previous methods across several model architectures, types of distribution shifts (e.g., synthetic corruptions, dataset reproduction, or novel subpopulations), and datasets (WILDS, ImageNet, BREEDS, CIFAR, and MNIST). "
SP:e748bf6ee653087cae825df32a8546f9ccebfcf1,"This paper studies the partial distribution matching (PDM) problem, where point sets are regarded as discrete distributions, and the goal is to partially match them. To handle large point sets, the authors propose a method for large scale PDM problem by utilizing the partial Wasserstein-1 (PW) discrepancy, which can be efficiently optimized. The authors theoretically derive the Kantorovich–Rubinstein duality for the PW discrepancy, and show its gradient can be explicitly computed. Based on these theoretical results, they propose a PWAN, which approximates the PW discrepancies by a neural network, and learns the transformation adversarially with the network. "
SP:f94f77696d100b2638fa2a6d82c8df47db3b6a36,This paper proposes a novel Deep Kernel Gaussian Process surrogate with Landmark Meta-features (DKLM) that can be jointly meta-trained on a set of source tasks and then transferred efficiently on a new (unseen) target task. The DKLM is designed to capture the similarity between hyperparameter configurations with an end-to-end meta-feature network that embeds the set of evaluated configurations and their respective performance. Experiments on a wide range of HPO meta-datasets from OpenML and demonstrate the empirical superiority of the proposed method against a series of stateof-the-art baselines. 
SP:e3c57f3589e8ab674644d900c14b3473cd71a23f,"This paper proposes a new method for deep generative models to be fingerprinted. The key idea is to generate a large number of models with distinct fingerprints, which can then be used for deep fake detection and attribution. The method is based on the idea of using a 128-bit fingerprinting mechanism to generate more than 10 identifiable models. Experiments show that the proposed method is effective in detecting deep fakes. "
SP:73bffd1a0856b80d29f7a2b2b68be57882531f07,"This paper proposes a new form of explanation for black box models that output similarity between two inputs. Specifically, the authors propose a method that provides feature attributions to explain the similarity between a pair of inputs as determined by a black box similarity learner. The authors also propose an analogy objective function to identify diverse analogous pairs of examples that share the same level of similarity as the input pair and provide insight into (latent) factors underlying the model’s prediction. Experiments are conducted on tabular and text data. "
SP:6a3c4ae05d582f8896840483b08c735ced2976bc,"This paper studies the certified robustness of ensemble ML models. The authors first prove that diversified gradient and large confidence margin are sufficient and necessary conditions for certifiably robust ensemble models under the model-smoothness assumption. Then, the authors propose the Diversity Regularized Training (DRT) to train certified ensemble models. Extensive experiments show that the DRT enhanced ensembles can consistently achieve higher certified L2-robustness. "
SP:3002b29c27709780238876d8c3f81bbd6a0f8112,"The paper proposes a new recursive pooling technique of local neighborhoods that allows different tradeoffs of computational cost and expressive power. The authors prove that this model can count subgraphs of size k, and thereby overcomes a known limitation of low-order GNNs. They also provide a (near) matching information-theoretic lower bound for counting subgraph with graph representations that pool over representations of derived (sub-)graphs. "
SP:5d0cbd84336caf5f31e1f98e11f6733230e4d792,This paper studies the knowledge integration (KI) process in an information-theoretic view and shows that KI could be interpreted using a graph convolution operation. The authors propose a simple probe model called Graph Convolution Simulator (GCS) for interpreting knowledge-enhanced LMs and exposing what kind of knowledge is integrated into these models. They conduct experiments to verify that GCS model can indeed be used to correctly interpret the KI process. 
SP:7e73948421e98307fceb69a316d8a4e7c4926cda,"This paper studies the effect of the adaptation learning rate in meta-learning with mixed linear regression. The authors propose a principled way to estimate optimal adaptation learning rates that minimize the population risk of MAML. Then, the authors interpret the underlying dependence between the optimal adaptive learning rate and the input data. Finally, they prove that compared with empirical risk minimization (ERM), the initialization with a smaller average distance to the task optima, consistent with previous practical findings."
SP:effbc85d89b1197d9c2abcaf5ff13864135dd6e1,"This paper proposes a method for source-free domain adaptation (SFDA) where a model trained on labelled data in a source domain is adapted to unlabelled data in the target domain without access to the source-domain data during adaptation. The proposed method, Feature Restoration (FR), aims to extract features with the same semantics from the target domains as were previously extracted from the source, rather than extracting new ones. The authors also propose a bottom-up training scheme for FR which boosts performance by preserving learnt structure in the later layers of a network. "
SP:7d63034ec7e6a4f178681ff2a49feb485cd47116,"This paper proposes a method to propagate adversarial robustness among federated learning (FL) users. The proposed method is based on batch normalization, which is a simple yet effective propagation approach that transfers robustness through carefully designed batch-normalization statistics. Experiments show that the proposed method improves the robustness of FL models even when only a small portion of users afford AT during learning."
SP:42c7a79e58b6a9f776fa6ae928bd89c194f9303f,"This paper proposes a transformer-based method for learning the network structure of a game. The proposed method is based on the transformer-like architecture, which correctly accounts for the symmetries of the problem and learns a mapping from the equilibrium actions to the network structures of the game without explicit knowledge of the utility function. The method is tested on three different types of network games using both synthetic and real-world data. "
SP:1c7b9157cf8c06ca771da78895fc3af969b0fb85,"This paper proposes a method for relation prediction in heterogeneous graphs. The method is based on analogy subgraph embedding learning (ANalogy SubGraph Embedding Learning), which predicts relations between each node pair by checking whether the subgraphs containing the pair are similar to other subgraph containing the considered relation. The proposed method is evaluated on heterogeneous graph based recommendation as well as knowledge graph completion."
SP:26ed25a7b42da2cf11b76a727102d8aa36d76657,This paper proposes a few-shot learning method for histology images. The method combines contrastive learning (CL) with latent augmentation (LA) to build a model that can learn useful representations without manual labels. Experiments show that the proposed method generalizes better than supervised learning in terms of generalization. 
SP:badbe687258cd5c282ca167b1f6fbfc6b5400dbf,"This paper proposes a new RNN-based model, called Mixed-Memory-RNNs (mmRNN), that can be used to model irregularly-sampled time series with long-term dependencies. The authors show that similar to standard RNNs, the underlying reason for this issue is the vanishing or exploding of the gradient during training. They provide a solution by equipping arbitrary continuous-time networks with a memory compartment separated from its timecontinuous state. This way, they encode a continuous time dynamical flow within the RNN, allowing it to respond to inputs arriving at arbitrary time-lags while ensuring a constant error propagation through the memory path. "
SP:4efd22f9122fa5856a9f4302eb6875fa0c414912,"This paper proposes BiBERT, an accurate fully binarized BERT, to eliminate the performance bottlenecks. The proposed method uses an efficient Bi-Attention structure for maximizing representation information statistically and a DirectionMatching Distillation (DMD) scheme to optimize the full binarization of BERT accurately. Extensive experiments show that the proposed method outperforms both the straightforward baseline and existing state-of-the-art quantized models with ultra-low bit activations."
SP:619bd742e92bea6241852f5a9d2b7bacf13b393a,"This paper proposes a new method to solve keypoint detection and instance association by using Transformer. Specifically, the self-attention in Transformer measures dependencies between any pair of locations, which can provide association information for keypoints grouping. To address it, the authors propose a novel approach of supervising self-Attention to be instance-aware. The proposed method is tested on the COCO multi-person keypoints detection challenge and person instance segmentation task."
SP:14750819593136fc9ef4efd032ab6f94dc5f6a02,"This paper proposes a method for learning mean-variance (MV) trade-off policies that achieve Pareto efficiency. The main idea is to train an agent to maximize the expected quadratic utility function, in which the maximizer corresponds to the optimal policy. The proposed method does not suffer from the computational difficulties because it does not include gradient estimation of the variance. The experiments show the effectiveness of the proposed method. "
SP:f675b564b3a9c8626ce7944d752fa3e0d868428e,"This paper proposes a method for test-time domain adaptation for a generatively-modeled channel model and an autoencoder system. The proposed method utilizes feature transformations at the decoder to compensate for changes in the channel distribution, and effectively present to the encoder samples close to the source distribution. Experimental evaluation on simulated datasets and real mmWave wireless channels demonstrate that the proposed method can adapt the MDN channel using very limited number of samples, and improve or maintain the error rate of the auto-encoder under changing channel conditions."
SP:77dc92137ea490d3e1b4b8ee1630dbe2ee0bddfa,"This paper proposes a new model for the abductive natural language inference task (αNLI). The authors argue that it is unnecessary to distinguish the reasoning abilities among correct hypotheses; and similarly, all wrong hypotheses contribute the same when explaining the reasons of the observations. Therefore, they propose to group instead of ranking the hypotheses and design a structural loss called “joint softmax focal loss” in this paper. The experimental results show that the proposed IMSL has achieved the highest performance on the RoBERTa-large pretrained model, with ACC and AUC results increased by about 1% and 5% respectively. "
SP:17cd72df5fc19398f582d27516fd742b073f79e3,This paper proposes a method to detect out-of-distribution (OOD) data. The proposed method combines a certifiable OOD detector with a standard classifier from first principles into an OOD aware classifier. The authors show that the proposed method provably avoids the asymptotic overconfidence problem of standard neural networks.
SP:9c3756f13932236aff3e8104f4fa193dcc8fde2f,"This paper proposes a new generalized transferable attack (GTA) problem where the attacker has a set of surrogate models trained on different datasets (with different label sets and image sizes), and none of them is equal to the dataset used by the victim model. The authors then propose a novel method called Image Classification Eraser (ICE) to erase classification information for any encountered images from arbitrary dataset. Extensive experiments on CIFAR-10, Cifar-100, and TieredImageNet demonstrate the effectiveness of the proposed ICE on the GTA problem. "
SP:2e0447c741a3f09be1095633d870200355211260,"This paper proposes a method for training discriminative pre-trained language models (PrLMs) on false negative samples. The authors define the false negative issue as the problem where training is carried out on wrong data and leads to less efficiency and less robustness in the resulting PrLMs. To address this issue, the authors propose to use counter-false-negative pre-training methods to counteract the harmful gradient updates subject to false negative predictions. Experimental results on GLUE and SQuAD benchmarks show that the proposed method achieves better performance together with stronger robustness. "
SP:281bc59d639aa76d84921b3ec4ce1ee8f1ba5b51,This paper proposes a novel open-world semi-supervised learning setting where novel classes may appear in the unlabeled test data. The authors propose an end-to-end approach that assigns instances to previously seen classes or forms novel classes by grouping similar instances without assuming any prior knowledge. The key idea in ORCA is to utilize uncertainty adaptive margin to circumvent the bias towards seen classes caused by learning seen classes faster than the novel classes. Experiments on image classification datasets and a single-cell dataset demonstrate that ORCA consistently outperforms alternative baselines.
SP:6c572c4c21b01a0cf3fd9ef97fbb348ef4e405ae,"The paper proposes a second-order method for training large-scale deep neural networks (DNNs). The proposed method, SLIM-QN, uses the BFGS update rule that directly approximates the Hessian inverse using past parameters and gradients, without explicitly constructing Hessian matrix and then computing its inverse. To achieve stable convergence, the authors introduce momentum in Hessian updates together with an adaptive damping mechanism. The authors provide rigorous theoretical results on the convergence of SLIM. "
SP:4bffce00ebb02d2e676eec897647ac14c3344deb,This paper proposes a systematic method called Locality Sensitive Pruning (LSP) for graph pruning based on Locality-Sensitive Hashing. LSP aims to sparsify a graph so that similar local environments of the original graph result in similar environments in the resulting sparsified graph. Extensive experiments on synthetic and real-world datasets demonstrate the superiority of LSP.
SP:c5e024f4e2079586298519ca868630efd7579eca,"This paper proposes a simple adversarial augmentation method that can modify training data to be hard positives/negatives without distorting the key information about their original identities. In particular, the authors decompose a sample x to be its variational auto-encoder (VAE) reconstruction G(x) plus the residual R(x), where the residual is the information-distinctive information due to an information-theoretic interpretation of the VAE objective. The authors then adversarially perturb G(X) in the bottleneck space and adds it back to the original R(y) as an augmentation, which is therefore sufficiently challenging for contrastive learning and meanwhile preserves the sample identity intact. The proposed method is applied to different self-supervised learning methods. "
SP:0991bc5f213bd8ab7572e2fed309e1b57a35835b,This paper proposes a new method for detecting distribution shifts in machine learning models. The proposed method is based on time-uniform confidence sequences (TUCS). The authors show that TUCS can detect harmful shifts while ignoring benign ones. The authors also demonstrate the effectiveness of the proposed method on simulated and real datasets. 
SP:1c7b954273e3a9cda333385b15a3e8ed3bf8178a,"This paper proposes to combine neural implicit representations for appearance modeling with neural ordinary differential equations (ODEs) in order to obtain interpretable physical models directly from visual observations. The proposed model combines several unique advantages: (i) Contrary to existing approaches that require large training datasets, the proposed method is able to identify physical parameters from only a single video (ii) The use of neural implicit representation enables the processing of high-resolution videos and the synthesis of photo-realistic imagery. (iii) The embedded neural ODE has a known parametric form that allows for the identification of interpretability physical parameters, and (iv) long-term prediction in state space. (v) Furthermore, the photo realistic rendering of novel scenes with modified physical parameters becomes possible."
SP:51efd1451343f4994d857daa5490e299b812bc2d,"The paper considers the context-dependent RL setting, where there is an unknown finite number of not directly observable contexts, abrupt (discontinuous) context changes occurring during an episode, and Markovian context evolution. The authors propose a context distillation procedure, which identifies and removes spurious contexts in an unsupervised fashion. They then find the representation of the optimal policy enabling efficient policy learning using off-the-shelf RL algorithms. "
SP:ea167b126212b2092bc1190d7f8376bf7c54a888,"This paper presents a framework to pretrain knowledge based multilingual language models (KMLMs) by generating a large amount of code-switched synthetic sentences and reasoning-based multilingual training data using the Wikidata knowledge graphs. Then based on the intra and inter-sentence structures of the generated data, the authors design pretraining tasks to facilitate knowledge learning, which allows the language models to not only memorize the factual knowledge but also learn useful logical patterns. The pretrained KMLMs demonstrate significant performance improvements on a wide range of knowledge-intensive cross-lingual NLP tasks. "
SP:6c11cf29c90f923346372ba6f11452c36e69ad6d,This paper proposes an unsupervised agent that learns to increase the choices another agent has by preferring to maximize the number of states that the other agent can reach in its future. The agent is trained to act altruistically towards other agents by giving them more choice and thereby allowing them to better achieve their goals. The authors evaluate their approach on three different multi-agent environments where another agent's success depends on the altruistic agent’s behaviour. 
SP:5dbc54201ba184266c5054f0d2944bd197bc307a,"This paper studies the double descent phenomenon in finite-width neural networks. The authors derive bounds for the population loss and its lower bound, while imposing minimal assumptions on the form of the parametric model. The bounds bear an intimate connection with the spectrum of the Hessian at the optimum, and importantly, exhibit a double descent behaviour at the interpolation threshold. "
SP:b485114712055f39a7afb951dbc3db482ff523fd,"This paper studies the exponential decay of the GNTK in deep GCNs. The authors show that the gradient descent of the deep GCN suffers from an exponential decay in the optimization process. To overcome this issue, the authors propose Critical DropEdge, a connectivity-aware and graph-adaptive sampling method, inspired by the theoretical insights on trainability. Experimental results show the effectiveness of the proposed method."
SP:25a92b3583afdc6892e59f1e769125d52c8011af,This paper proposes a method for estimating the second derivative of the cardiac pulse. The method is based on the observation that the second derivatives of the input frames and the target vital sign signals can be used to estimate the left ventricle ejection time (LVET) intervals. The authors show that the proposed method is able to estimate LVET intervals better than other methods. 
SP:0a88d2fcbdfab3e196bf6b9c75adb1006ab87536,"The paper proposes a symbolic mapping method for multi-agent language learning. The method is inspired by the theory that language may evolve from simple tasks to difficult tasks. The authors show that symbolic mapping learned in simple referential games can notably promote language learning in difficult tasks and show that with the help of symbolic mapping, agents can easily learn to use new symbols when the environment becomes more complex. "
SP:89575be04cb33b41d7a0a7b62f9496c2838a1317,"The paper proposes a hierarchical modular approach to learn agents that navigate and manipulate objects in a divide-andconquer manner for the diverse nature of the entailing tasks. Specifically, the authors first infer a sequence of subgoals to be executed based on language instructions by high-level policy composition controller (PCC). Then discriminatively control the agent’s navigation by a master policy by alternating between navigation policy and various independent interaction policies. Finally, they infer manipulation actions with the corresponding object masks using the appropriate interaction policy. The proposed method achieves the state-of-the-art performance on the challenging ALFRED benchmark. "
SP:e2c8efe00db7baba2368f4f6a37815809b9e235e,"This paper proposes Nuisance-Randomized Distillation (NURD), a method for training models that perform well regardless of the nuisance-label relationship. NURD is based on the notion of nuisance-varying family, which is a set of distributions that differ only in the nuisance and label relationship. Under this definition, the authors define the set of representations such that conditioning on any member of this family is independent. The authors show that the representations in this set always perform better than chance, while representations outside of this set may not. "
SP:c75998b76f4e0510fc719d25959a10fc07db1c40,"This paper proposes OTTER (Optimal TransporT distillation for Efficient zero-shot Recognition), which uses online entropic optimal transport to find a soft image-text match as labels for contrastive learning. Compared with InfoNCE loss, label smoothing, and knowledge distillation, OTTER consistently outperforms these baselines. "
SP:e83cd70377542b5d187998e2e4a7ac070f453ed6,"This paper presents Pix2Seq, a simple and generic framework for object detection. Unlike existing approaches that explicitly integrate prior knowledge about the task, this paper casts object detection as a language modeling task conditioned on the observed pixel inputs. The neural network perceives an image and generates a sequence of tokens that correspond to bounding boxes and class labels. The proposed method achieves competitive results on the challenging COCO dataset."
SP:abc9315f61929cc1c54dfef8ff83d7eac56ec2f2,"This paper proposes a symbolic distillation method for visual reinforcement learning. The proposed method is based on a policy regression algorithm called RoundTourMix, which distills the CNN policy network knowledge into the symbolic policy. The symbolic policy can be treated as discrete and abstracted representations of the policy network, but are found to be more interpretable, robust and transferable. The method is experimentally demonstrated to maintain the performance and “denoise” the CNN policies."
SP:04e7e181aeb1244ae1c4837ad416aef93ea3ea32,"This paper proposes a new method for image-to-image translation, called PIVQGAN, which aims to disentangle the coarse-level object arrangements (posture) and the fine-grained level styling (identity) of the generated image from two exemplar sources. The authors propose a Vector-Quantized Spatial Normalization (VQSN) module for the generator for better pose-identity disentanglement, and a joint-training scheme with self-supervision methods for the GANInversion encoder and the generator. The VQSN module automatically learns to encode the shaping and composition information from the commonly shared objects inside the training-set images. The joint training scheme ensures that the pose-related representations are learned by the generator and the VQN module. The proposed method is evaluated on various datasets."
SP:e51a7f45493064972585109f203a867e9828eb15,"This paper proposes a multi-layer perceptron (MLP) architecture for extracting information from speech signals. The model splits feature channels into non-overlapped chunks and processes each chunk individually. By setting different numbers of chunks and focusing on different contextual window sizes, speech-MLP learns multiscale local temporal dependency. The proposed model is successfully evaluated on two tasks: keyword spotting and speech enhancement."
SP:d708d3886f4abd4552d8ccb2096df7361c803b13,This paper studies the problem of transfer learning in binary classification. The authors derive a new lower bound on the generalization error that can be achieved by any transfer learning algorithm (regardless of its computational complexity) as a function of the amount of source and target samples. The lower bound depends on a natural notion of distance that is easily computed on real world data sets.  The authors also consider a more general setting where there are more than one source domains for knowledge transfer to the target task and develop new bounds on generalization errors in this setting.
SP:f7511ba9ccad03233b34b1bf41bbac7361d20a57,"This paper proposes a probabilistic shape completion method extended to the continuous geometry of large-scale 3D scenes. The proposed method is based on the generative Cellular Automata (GCA) framework. The authors derive the variational lower bound of the complete shape distribution and therefore their progressive generation constitutes a valid generative model. Experiments show that their model successfully generates diverse plausible scenes faithful to the input, especially when the input suffers from a significant amount of missing data. "
SP:d22d8f074adbe8fb0f25fb8f8d96201b3159bf6b,"This paper proposes a temporal priors framework to guide exploration in reinforcement learning. The proposed framework is based on the idea of temporal consistency, which is a non-Markovian generalization of behavioral priors. The authors show that the proposed method can accelerate off-policy reinforcement learning in unseen downstream tasks. "
SP:25e06c022ae8b3cbbb8db413d7b534a1a5c92391,"This paper proposes a new learning rate scheduling method, called Graph-Network-based Scheduler (GNS), for training deep neural networks. GNS learns a directed graph for the underlying neural network of the target problem, encodes current dynamics with a graph message passing network and trains an agent to control the learning rate accordingly via reinforcement learning. The proposed method can capture the intermediate layer information while being able to generalize to problems of varying scales. Besides, an efficient reward collection procedure is leveraged to speed up training."
SP:d73cb0471c1770607ad3e4621cfc5f170683dd8e,"This paper proposes a method for object-centric learning from a point cloud. The method is based on the Chamfer Mixture Loss, which is a variational loss that can be used to model the spatial mixture model on point clouds. The authors also propose an object-specification scheme that describes each object’s location relative to its local voxel grid cell. The proposed method is evaluated on the task of unsupervised scene decomposition."
SP:3c57e921c1bf23e482551ceb71702931a7f07439,"This paper proposes a method for grounding high-level tasks, expressed in natural language, to a chosen set of actionable steps (i.e. “make breakfast”), to a given set of actions. The method is based on a procedure that conditions on existing demonstrations and semantically translates the plans to admissible actions. Experiments show that the proposed method substantially improves executability over the LLM baseline. "
SP:e0159d1c9df2e657892a3a0c77549df4698d9a1a,"This paper proposes a geometrical interpretation of the Variational Autoencoder framework. In particular, it proposes a new way to generate samples consisting in sampling from the uniform distribution deriving intrinsically from the Riemannian manifold learned by a VAE. The proposed method is tested on four benchmark datasets. "
SP:b4b8e1727f8617894f10f20365cb68de79f0e650,"This paper proposes a new transformer architecture that replaces redundant heads in transformers with a mixture of Gaussian keys at each head. The key is a Gaussian mixture model and allows each attention head to focus on different parts of the input sequence efficiently. Compared to its conventional transformer counterpart, Transformer-MGK accelerates training and inference, has fewer parameters, and requires less FLOPs to compute while achieving comparable or better accuracy across tasks. "
SP:82731dcce233e748f63382e09b6224a513fe9689,"The paper proposes a new two-dimensional continuous environment for spatial navigation. The proposed method is based on a direct-inverse model of environment dynamics to fuse image and action related signals, allowing reconstruction of the action relating the two successive images, as well as prediction of the new image from its current value and the action. The authors propose a minimalistic recurrent architecture, called Resetting Path Integrator (RPI), that can easily and reliably be trained to keep track of its position relative to its starting point during a sequence of movements. RPI updates its internal state using the (possibly noisy) self-motion signal, and occasionally resets it when the image signal is present."
SP:1a27c397d1e73def5e724c5c6f25548975ba50fa,"This paper studies the problem of learning representations of the input data with effective features for prediction. The authors prove that neural networks trained by gradient descent can succeed on these problems. The success relies on the emergence and improvement of effective features, which are learned among exponentially many candidates efficiently by exploiting the data (in particular, the structure of the distribution). In contrast, no linear models on data-independent features of polynomial sizes can learn to as good errors. "
SP:8ada73ed7eade9ebdeef376485e849c42575bc5f,"This paper studies the robustness of fixed feature extractors to adversarial examples generated by test-time adversaries. The authors provide bounds on how robust any classifier trained on top of it can be, when a data distribution and attacker constraints are specified. The tightness of these bounds relies on the effectiveness of the method used to find collisions between pairs of perturbed examples at deeper layers. For linear feature extractor, the authors provide closed-form expressions for collision finding while for arbitrary feature extractsors, they propose a bespoke algorithm based on the iterative solution of a convex program that provably finds collisions. "
SP:874b5fa51924cbcceed490d98a0ea80f74586b32,"This paper proposes a new offline RL method called Value-based Episodic Memory (VEM). VEM learns the V-function instead of the Q-function to naturally keep the learning procedure within the offline dataset. To enable effective generalization while maintaining proper conservatism in offline learning, the authors propose Expectile V-Learning (EVL), which smoothly interpolates between the optimal value learning and behavior cloning. Further, implicit planning along offline trajectories to enhance learned V-values and accelerate convergence. "
SP:34f08d92681504490c2f739b0d08f79f9764b2f5,"This paper proposes a new adversarial training framework that learns to reweight the loss associated with individual training samples based on a notion of class-conditioned margin, with the goal of improving robust generalization. Inspired by MAML-based approaches, the proposed method is formulated as a bilevel optimization problem where the upper-level task corresponds to learning a robust classifier, and the lower-level tasks corresponds to learn a parametric function that maps from a sample’s multi-class margin to an importance weight. Extensive experiments demonstrate that the proposed approach improves both clean and robust accuracy compared to related techniques and state-of-the-art baselines."
SP:3ad36be6b6900aabe43da043461cf178ce977082,"This paper proposes a new type of equivariant graph neural network called Steerable E(3) Equivariant Graph Neural Networks (SEGNNs) that generalise equivariants graph networks, such that node and edge attributes are not restricted to invariant scalars, but can contain covariant information, such as vectors or tensors. This model, composed of steerable MLPs, is able to incorporate geometric and physical information in both the message and update functions. The authors provide a new class of activation functions for general use with steerable feature fields. "
SP:8928aa83f7ebd4e310f4fe1d01ff0eb0c96e4d2b,"This paper proposes a new differentiable physics model for composite materials such as cloths. The authors propose several differentiable forces, whose counterparts in empirical physics are indifferentiable, to facilitate gradient-based learning. Experiments are conducted to demonstrate the effectiveness of the proposed method."
SP:2c8358c095b10981d3015b9f6c75765419a9480d,"The paper proposes a method for learning a new task from a set of base tasks. The method is based on logical composition in reinforcement learning. The authors provide bounds on the performance of the transferred policy on the new task, and the necessary and sufficient number of tasks that need to be learned throughout an agent’s lifetime to generalise over a distribution. They also demonstrate that as a side effect of the proposed method, an agent can produce an interpretable Boolean expression of its understanding of the current task. "
SP:c85d71d05164d019cc32bf423e4c4fe20c169f41,"This paper proposes a new method for multivariate time series classification (MTSC) based on random convolutional kernels. The proposed method is based on wavelet scattering transformation of the time series and distributed feature selection, which is fast both during training and inference. The authors show that the proposed method achieves speedup ranging from 9x to 65x compared to ROCKET during inference on an edge device, on datasets with comparable accuracy. "
SP:db43614ca016280a79448f44a97c81c8ff5ba981,"This paper presents a new framework AMOS that pretrains text encoders with an Adversarial learning curriculum via a Mixture of Signals from multiple auxiliary generators. The main encoder is trained as a discriminator to detect replaced tokens generated by auxiliary masked language models (MLMs). Different from ELECTRA which trains one MLM as the generator, the authors jointly train multiple MLMs of different sizes to provide training signals at various levels of difficulty. To push the discriminator with challenging replaced tokens, they learn mixture weights over the auxiliary MLMs’ outputs to maximize the discrimator loss by backpropagating the gradient from the main discriminator via Gumbel-Softmax. For better pretraining efficiency, they propose a unified auxiliary model. "
SP:db3825633ab5d0671340390b23ab655838cc38b2,This paper proposes an adaptive fine-tuning method for relational fact extraction. The authors propose to use a pre-trained language model on the standard fill-mask task using a small training dataset of existing facts from a knowledge graph. The proposed method is evaluated on a variety of datasets and compared to a number of baselines. 
SP:ae25d32714b2b9f7e02cc20f4a36252e20e78e4f,"This paper proposes to learn the knowledge base embeddings in different geometric spaces and apply manifold alignment to align the shared entities. The proposed method is evaluated on the out-of-taxonomy entity typing task, where we aim to predict the types of the entities from the knowledge graph. "
SP:9ab3bc525ee4a9c96518c43e4c43082655a7674f,"This paper proposes a one-shot learning framework for link prediction in temporal knowledge graphs. The proposed method employs a self-attention mechanism to effectively encode temporal interactions between entities, and a network to compute a similarity score between a given query and a (one-shot) example. The experiments show that the proposed algorithm outperforms the state of the art baselines for two well-studied benchmarks."
SP:91f92a40e12afd0702f07ae7f4175ecce57b7007,This paper proposes a method to learn a neural module for solving a set of visual reasoning tasks. The proposed method is based on the idea of learning a neural network that calls existing modules (solvers for simpler tasks) in a functional program-like manner. The model learns to query existing modules and composes their outputs in order to produce its own output. Experiments show that the proposed method outperforms an attention-based baseline. 
SP:de33b02e7f2faec5bcae9a5516721aa1ef190572,"This paper proposes a method to improve the parameter efficiency of deep convolutional neural networks with bottlenecks. In particular, the authors propose Selective Convolutional Unit (SCU), a widely-applicable architectural unit that improves parameter efficiency for various modern CNNs with bottleneck structures. SCU gradually learns the channel-selectivity on-the-fly via the alternative usage of pruning unimportant channels, and rewiring the pruned parameters to important channels. Experiments show that the SCU-based models without any postprocessing generally achieve both model compression and accuracy improvement compared to the baselines."
SP:2d80fa4bc440061be2234b5070503d3fa056baed,"This paper proposes a method to partially identify the classifier. The proposed method learns a scoring function that preserves the order induced by the class posterior under mild assumptions, which can be used as a classifier by setting an appropriate threshold. Experiments show that the proposed method outperforms previous methods for PU learning. "
SP:5f312626b0613d2e07c59214c5f00db208a98717,The paper proposes an adaptive weighting method to detect when an auxiliary loss is helpful to the main loss. The proposed method is based on the cosine similarity between gradients of tasks. The authors show that their approach is guaranteed to converge to critical points of the main task and demonstrate the practical usefulness of the proposed algorithm in a few domains. 
SP:e270ae3eeb7ab4fa91ba37d4d68ce10f2fa0a3b5,"The paper proposes a geometric framework to analyze the high-dimensional geometry of adversarial examples. In particular, the authors highlight the importance of codimension: for low-dimensional data manifolds embedded in high dimensional space there are many directions off the manifold in which to construct adversarial example. The authors prove (1) a tradeoff between robustness under different norms, (2) that adversarial training in balls around the data is sample inefficient, and (3) sufficient sampling conditions under which nearest neighbor classifiers and ball-based adversarial learning are robust. "
SP:e07d948a79d478ecd23a0a4406d4ddd3ac5e3be3,"This paper proposes a new representation learning framework for time series. The proposed framework is based on interpretable discrete dimensionality reduction and deep generative modeling. The authors introduce a new way to overcome the non-differentiability in discrete representation learning and present a gradient-based version of the traditional self-organizing map algorithm that is more performant than the original. Furthermore, to allow for a probabilistic interpretation of the proposed method, the authors integrate a Markov model in the representation space. "
SP:5915ee71ea58dbdbafa31c1ad291d1e5940a0cf4,"This paper studies the properties of multidimensional probability distributions in the context of latent space prior distributions of implicit generative models. The authors show that there is a trade-off between the interpolation being linear, and the latent distribution having even the most basic properties required for stable training, such as finite mean. They show that the distribution mismatch can be eliminated completely by a proper choice of the latent probability distribution or using non-linear interpolations. "
SP:19b63ca635712f1509ca6e0141303c192f2709e0,"This paper proposes a method for learning the parameters of shallow networks in hyperbolic space. The main idea is to use the geometry of embedding of object representations to compute the ubiquitous attention mechanisms for different neural networks architectures without increasing the number of parameters of the model. The proposed method shows improvements in generalization on neural machine translation on WMT’14 (English to German), learning on graphs (both on synthetic and real-world graph tasks) and visual question answering (CLEVR) tasks. "
SP:f6049e9f80a63c9306c1cebcb6b229aa6da44ddc,"This paper presents an analysis of DNN fingerprinting attacks that exploit cache side-channels. The authors define the threat model for these attacks: an adversary does not need the ability to query the victim model; instead, she runs a co-located process on the host machine where the victim's deep learning (DL) system is running and passively monitors the accesses of the target functions in the shared framework. Once the attacker observes function invocations that map directly to architecture attributes of the victim network, the attacker can reconstruct the victim’s entire network architecture. Based on the extracted architecture attributes, the authors also demonstrate that an attacker can build a meta-model that accurately fingerprints the architecture and family of the pretrained model in a transfer learning setting. "
SP:6a3dd89db6c24a1f98e8866ef0a4c1c2c1ec6635,"This paper proposes a hierarchical network model for predicting future video frames. The model is inspired by the feedforward, feedback and lateral recurrent circuits in the mammalian hierarchical visual system. The feedforward path computes and encodes spatiotemporal features of successive complexity and a feedback path projects interpretation from a higher level to the level below. The network learns by comparing the incoming signals with its prediction, updating its internal model of the world by minimizing the prediction errors at each level of the hierarchy in the style of predictive self-supervised learning. "
SP:fb74e57f35666742caf651e6da33b5defcf259a8,"This paper proposes a method to compute continuous embeddings for RNA-seq data, in a reference-free fashion. The proposed method captures information of both DNA sequence similarity as well as DNA sequence abundance in the embedding latent space. The authors confirm the quality of these vectors by comparing them to known gene sub-structures and report that the latent space recovers exon information from raw RNA-Seq data. "
SP:03aca6ff6a7f0ad2d5ccbcb15ed9536e305a9880,"This paper proposes a new method for model compression. The proposed method is based on the architecture space. The authors first encode the network and then perform gradient descent in continuous space to optimize a compression objective function that maximizes accuracy and minimizes parameter count. The final continuous feature is then mapped to a discrete architecture using the decoder. Experiments are conducted on visual recognition tasks such as CIFAR-10/100, FMNIST and SVHN."
SP:0511b5d10a90e3fe814e2d35208b4a987894ea62,"This paper proposes a framework for planning online and learning offline, where an agent, with an internal model, needs to continually act and learn in the world. The proposed framework is based on the synergistic relationship between local model-based control, global value function learning, and exploration. The authors study how local trajectory optimization can cope with approximation errors in the value function, and can stabilize and accelerate value functions learning. Finally, they also demonstrate how trajectories can be used to perform temporally coordinated exploration in conjunction with estimating uncertainty in value function approximation."
SP:771494fda4702cd8c7efbf225b19028f91b449b9,"This paper proposes a new method for zero-shot and dual learning for neural machine translation (NMT). The proposed method is based on the LSTM-based unsupervised NMT system proposed in (Lample et al., 2018b), and is trained on English-French and English-Spanish. Experiments on the UN corpus show that the proposed method outperforms the standard NMT systems. "
SP:1558dc03f99670f9ddccdca9c223a2baf962d438,"This paper proposes a new adversarial framework for information retrieval. The proposed framework is based on the framework for Information-Retrieval (IR), which is a framework for modeling the correct conditional probability distribution p(d|q) over the documents (d), given the query (q). The authors claim that optimizing their minimax loss function will result in a generator which can learn the distribution, but their setup and baseline term steer the model away from an exact adversarial formulation, and this work attempts to point out certain inaccuracies in their formulation. The authors propose a co-training like setup where two models are trained in a cooperative rather than an adversarial fashion. "
SP:6a13dda852ab075a3c0fb691476d6dc57919c729,This paper proposes a method to model sparsity in the latent space of a variational auto-encoder (VAE) with a Spike and Slab prior distribution. The authors derive the evidence lower bound using a discrete mixture recognition function thereby making approximate posterior inference as computational efficient as in the standard VAE case. They show that the proposed method is able to infer truly sparse representations with generally intractable non-linear probabilistic models. 
SP:06a22143186fa2948fbe324ccae96a62ff12064e,"This paper proposes a non-adversarial feature matching-based approach to train generative models. The proposed approach, Generative Feature Matching Networks (GFMN), leverages pretrained neural networks such as autoencoders and ConvNet classifiers to perform feature extraction. The experimental results demonstrate that the proposed method can achieve state-of-the-art results for challenging benchmarks such as CIFAR10 and STL10. "
SP:2d7cf2f07a27d6c8e304a1b47c25387ad2e4432d,"This paper studies the expressive power of GNNs to capture different graph structures. The authors provide theoretical analysis of the discriminative power of popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, and show that they cannot learn to distinguish certain simple graphs structures. They then develop a simple architecture that is provably the most expressive among the class of Gnns and is as powerful as the WeisfeilerLehman graph isomorphism test. "
SP:51126f2dd37ce57d2614c9044ede1e43627f0829,"This paper proposes a framework for interpretable continual learning (ICL) based on the variational continual learning framework. The authors propose to use saliency maps to provide explanations of previously performed tasks and propose a new metric to assess their quality. Experiments show that ICL achieves state-of-the-art results in terms of overall continual learning performance as measured by average classification accuracy, and also in its explanations, which are assessed qualitatively and quantitatively. "
SP:27a565b3e5442b93d208652784051e640b0c1bfe,"This paper proposes a new evaluation framework for adversarial attacks on seq2seq models taking meaning preservation into account and demonstrate that existing methods may not preserve meaning in general. The authors also propose new constraints for attacks on word-based MT systems and show, via human and automatic evaluation, that they produce more semantically similar adversarial inputs. Furthermore, they show that performing adversarial training with meaning-preserving attacks is beneficial to the model in terms of adversarial robustness without hurting test performance. "
SP:54ddd8132bf9e4259d2c2d72b348d2bb5f9e227c,"This paper proposes a new approach to improve the performance of reinforcement learning algorithms by combining the policies using original rewards and inverse (negative) rewards. The proposed approach is based on deep Q-learning, double Q-Learning, and on-policy actor-critic. The authors prove the convergence of the inverse policies. The experiments for some games in OpenAI gym show that the hybrid polices obtained the rewards up to 63.8% more than the original algorithms. "
SP:89a732b57934d08b937c93560f391b7758e54f8a,"This paper proposes a method to learn a hierarchical, disentangled object representation and a dynamics model for object parts from unlabeled videos. The method is based on a layered image representation, a structural descriptor that composes low-level concepts into a hierarchical structure, and a dynamic model that predicts the system dynamics by predicting the future. Experiments on multiple real and synthetic datasets demonstrate that the proposed method works well on all three tasks: segmenting object parts, building their hierarchical structure and capturing their motion distributions. "
SP:bb2a655d67bed9da43f0b8ec7d888b89c217d12e,"This paper proposes a novel inference method, Deep Determinantal Generative Classifier (DDGC), which can obtain a more robust decision boundary under any softmax neural classifier pre-trained on noisy datasets. The proposed method is based on estimating the parameters of generative classifier using the minimum covariance determinant estimator, with neither re-training of the deep model nor changing its architectures. Experimental results demonstrate the superiority of DDGC given different learning models optimized by various training techniques to handle noisy labels or adversarial samples. "
SP:0fa525cc708470b757a60117cb608bb2feaa2c50,"This paper proposes a method for learning subgoals in Hierarchical Reinforcement Learning (HRL). The method is based on incremental unsupervised learning over a small memory of the most recent experiences of the agent. In addition, the method is combined with an intrinsic motivation learning mechanism. The proposed method is evaluated on two RL problems with sparse delayed feedback."
SP:e5861538bc8bb9165cb33299bbf12dd875abf976,"This paper proposes a neural framework for solving the Circuit Satisfiability problem. The framework is built upon two fundamental contributions: a rich embedding architecture that encodes the problem structure, and an end-to-end differentiable training procedure that mimics Reinforcement Learning. The experimental results show the superior out-of-sample generalization performance compared to the recently developed NeuroSAT method."
SP:ff3e5d44619df3825632b0b1a943add081364861,"This paper proposes a combination of two existing methods for deep reinforcement learning, namely cross-entropy method (CEM) and Twin Delayed Deep Deterministic policy gradient (TD3), to improve the sample efficiency of off-policy deep RL algorithms. The proposed method, CEM-RL, is based on the simple cross entropy method and TD3, which is a variant of DDPG. The authors evaluate the proposed method on a set of benchmarks classically used in deep RL. "
SP:78b2eb326695da0b0cc4ba39a9206d11644a5e32,"This paper proposes a multi-variable LSTM recurrent neural network (IMV-LSTM) for predicting and interpreting multi-variate time series. The proposed model is equipped with hidden state matrix and update process, so as to learn variableswise hidden states. The authors also propose a mixture attention mechanism and associated summarization methods to quantify the temporal and variable importance in data. Extensive experiments using real datasets demonstrate the prediction performance and interpretability of the proposed model. "
SP:1c26660569b579f060f7b4a31e321c6d2356b928,"The paper proposes a data augmentation method for adversarial defense against adversarial attacks. The proposed method is based on feature smoothing, which is an interpolation of features from a pair of samples, with the new label remaining the same as the dominant data point. The method is tested on MNIST and CIFAR10 datasets. "
SP:88d652f9e411dd3a2e9ad651d9011e579653c6aa,"This paper proposes a theoretical framework for deep and locally connected nonlinear networks with ReLU nonlinearity. The framework is built upon teacher-student setting, by projecting the student's forward/backward pass onto the teacher's computational graph. The proposed framework bridges data distribution with gradient descent rules, favors disentangled representations and is compatible with common regularization techniques such as Batch Norm. "
SP:7842bbe0e2324cfd732db8745550733ccc3dfcdc,This paper proposes a modular architecture of neural networks with a Behavioral Module (BM) and corresponding end-to-end training strategy. The proposed method allows separation of main task’s objectives and behaviors between different BMs. The experiments also show network extendability through independent learning of new behavior patterns. 
SP:300c391ff644b6889cd9ae27cf0d162dfcdd4451,This paper proposes a differentiable formulation for the neuromodulation of plasticity. The authors show that this formulation can be used to train neural networks with gradient descent. Experiments show that the proposed formulation improves the performance of neural networks on both reinforcement learning and supervised learning tasks. 
SP:1ab5d94d31e99351433436c026799c8aa597bf73,"This paper proposes a new quantization method to reduce the inference latency and memory consumption. The proposed method is based on re-training the full precision model, followed by directly optimizing the corresponding binary model. The quantization training process takes no longer than the original training process. The authors also propose a new loss function to regularize the weights, resulting in reduced quantization error. "
SP:0876b1d9a6d664808ca1ab15865679fbf638267e,"This paper proposes a method for style transfer onto open-ended content. The method is based on a variational autoencoder (VAE) and a style encoder. The VAE reconstruction loss is inadequate to ensure a decomposition of the latent representation into style and content. To this end, the authors propose an auxiliary loss, leakage filtering, which ensures that no style information remaining in the content representation is used for reconstruction and vice versa. The authors demonstrate the effectiveness of their method on few-shot learning tasks."
SP:d37e15cde7765fca87595a242f0a4511b3346d46,"This paper proposes a new method to speed up deep RL training for problems that have the property of state-action permissibility (SAP). Two types of states are defined under SAP. The first type says that after an action at is performed in a state st and the agent reaches the new state st+1, the agent can decide whether the action is permissible or not permissible in state st. The second type is that even without performing the action at in st, the agents can already decide whether at is permitted or not in st.  The authors incorporate the proposed SAP property into two state-of-the-art deep RL algorithms to guide their state-actions exploration. "
SP:20015d8b60e13300586b67c281858cbe28825c48,"This paper studies the behavior of weight-tied multilayer vanilla autoencoders under the assumption of random weights. It provides quantitative answers and insights to three questions that were yet fully understood in the literature. The authors provide an exact characterization in the limit of large dimensions, which reveals interesting phase transition phenomena when the depth becomes large. Secondly, they show that deep autoencoder display a higher degree of sensitivity to perturbations in the parameters, distinct from the shallow counterparts. Thirdly, they obtain insights on pitfalls in training initialization practice, and demonstrate experimentally that it is possible to train a deep auto-encoder with the tanh activation and a depth as large as 200 layers, without resorting to layer-wise pre-training or batch normalization. "
SP:91764f80dbe2401ade38b35a8253ba05f0f86386,The paper proposes a new adversarial black-box adversarial attack method based on the discrete cosine transform (DCT) algorithm. The proposed method can be used for both targeted and untargeted attacks. The authors show that the proposed method is able to generate adversarial ImageNet images with a median of 600 model queries (ResNet-50) and achieves a cost of only $3 per image.
SP:fc20ae0fbf57a1ce489c04b85c7c2f4c93dc2450,This paper proposes a new method for option discovery in hierarchical reinforcement learning. The method is based on the idea of discovering “landmark” sub-goals which are prototypical states of well connected regions. The authors propose a new model called Successor options that leverages Successor representations to achieve the same.  The authors also design a novel pseudo-reward for learning the intra-option policies. Experiments are conducted on a collection of grid worlds and on complex high dimensional environments.
SP:12a172c1e2892d016b37932acfc48dcb56874a89,"This paper studies the problem of domain division which aims to segment instances drawn from different probabilistic distributions. The authors propose a domain division algorithm to split the testing instances into known, unknown and uncertain domains, and then conduct recognition tasks in each domain. Two statistical tools, namely, bootstrapping and KolmogorovSmirnov (K-S) Test, for the first time, are introduced to uncover and fine-tune the decision boundary of each domain, and the uncertain domain is newly introduced in the framework to adopt those instances whose domain labels cannot be predicted confidently. Extensive experiments demonstrate the state-of-the-art performance on OSL and G-ZSL benchmarks."
SP:28bcf7c6a4673e9ec2b4ebed09839d85188e0b2a,"This paper proposes a neural network for classification and regression, without the need to learn layout structures in the output space. The structure is defined by polar prototypes, points on the hypersphere of the output. For classification, each class is described by a single polar prototype and they are a priori distributed with maximal separation and equal shares. For regression, the training can be performed as a polar interpolation between two prototypes, arriving at a regression with higher-dimensional outputs.  "
SP:d1034342785d133cf8372b8624897963cc2ee83a,This paper proposes a method for learning a policy for reinforcement learning. The key idea is to use the information from the initial state of the environment to infer both side effects that should be avoided as well as preferences for how the environment should be organized. The method is based on Maximum Causal Entropy IRL and is evaluated in a suite of proof-of-concept environments. 
SP:417a4e0acee699b3e004ad30d0ecf533a9ed987e,"The paper proposes a method for learning the dependency structure between latent variables in deep latent variable models. The proposed method combines the complementary strengths of deep generative models and probabilistic graphical models. In particular, the model is expressed in terms of a Bayesian network with a learned, flexible dependency structure. The network parameters, variational parameters as well as the latent topology are optimized simultaneously with a single objective. Inference is formulated via a sampling procedure that produces expectations over latent variable structures and incorporates top-down and bottom-up reasoning. "
SP:976dedab53e69610692a563382ada1dbb82c1e9d,"This paper presents a dynamical neural network for solving the 1-minimizing dictionary learning problem. The authors show that by combining ideas of top-down feedback and contrastive learning, a new dynamical network can be constructed, and the true gradients for learning are provably computable by individual neurons. They also provide a learning process, its rigorous mathematical analysis, and numerical results on several dictionary learning problems. "
SP:f45117a6beaeb86a70b1380b4fac3cfba37fb892,This paper proposes a novel network for lane detection. The proposed network consists of multiple encoder-decoders module in end-to-end ways and show the promising results for the lane detection task. The authors also propose to rethink the evaluation methods of the popular methods based on IoU.
SP:68b0a10ca06df74612d0753cc3f3ddddde806035,"This paper proposes a new method for batch contextual bandit learning. The proposed method, Maximum Likelihood Inverse Propensity Scoring (MLIPS), estimates a maximum likelihood surrogate policy based on the logged action-context pairs, and then uses this surrogate policy as the proposal. The authors prove that MLIPS is asymptotically unbiased, and moreover, has a smaller nonasymptotic mean squared error than IPS. "
SP:8e0ed65c5dded23b34798499b2436b24422fd729,"This paper proposes a meta-learning method for few-shot classification. The proposed method uses a kernel generator as meta-learner to learn to construct individualized feature embedding for query images. The kernel generator acquires meta-knowledge of generating adequate convolutional kernels for different query images during training, which can generalize to unseen categories without fine-tuning. Experiments on Omniglot and miniImageNet demonstrate the effectiveness of the proposed method."
SP:faa3f7ffdcfb6e3b8ec0421193dae3d9987b015c,"This paper proposes a population-based genetic algorithm (GA) for training deep neural networks. The authors show that the GA can evolve the weights of a DNN with a simple, gradient-free, population based genetic algorithm and it performs well on hard deep RL problems, including Atari and humanoid locomotion. The GA is faster than ES, A3C, and DQN (it can train Atari in ∼4 hours on one workstation or ∼1 hour distributed on 720 cores), and enables a state-of-the-art, up to 10,000-fold compact encoding technique. "
SP:dfdbe3267a8160f24746884cdf5297993e424231,"This paper proposes a curiosity method that uses episodic memory to form the novelty bonus. To determine the bonus, the current observation is compared with the observations in memory. The novelty bonus is summed up with the real task reward, making it possible for RL algorithms to learn from the combined reward. Experiments are conducted on VizDoom, DMLab and MuJoCo. "
SP:1e58a1c5344d1b5b7c8a40210a243700bd933d65,"This paper proposes a method for modeling transition models in complex uncertain domains using relational rules. For any action, a rule selects a set of relevant objects and computes a distribution over properties of just those objects in the resulting state given their properties in the previous state. Feed-forward neural networks are used to learn the transition distribution on the relevant objects’ properties. The method is demonstrated to be both more versatile and more sample efficient than learning a monolithic transition model in a simulated domain."
SP:8ce00a3fedbf54a7f2c1ff414511cbb7d59b4597,"This paper proposes a new instance-wise feature selection method, which is termed INVASE. INVASE consists of 3 neural networks, a selector network, a predictor network and a baseline network which are used to train the selector network using the actor-critic methodology. The authors demonstrate through a mixture of synthetic and real data experiments that INVASE significantly outperforms state-of-the-art benchmarks."
SP:b91d6c33349df0bb6cb7e1c5e9433f0d4744b4da,"This paper proposes a domain adaptation method to adapt the source data to the unlabeled target domain. To this end, the authors propose to learn discriminative feature representations of patches based on label histograms in the source domain, through the construction of a disentangled space. The authors then use an adversarial learning scheme to push the feature representations in target patches to the closer distributions in source ones. Extensive ablation studies and experiments are conducted on numerous benchmark datasets with various settings, such as synthetic-to-real and cross-city scenarios."
SP:00922af13a21464cbc4cd7b34c196dd4f86c9247,"This paper proposes two algorithms for online learning, AMSGrad and Adam. The algorithms are based on the observation that mini-batch of stochastic gradients in consecutive iterations do not change drastically and consequently may be predictable. The authors combine the idea of momentum method, adaptive gradient method, and algorithms in OPTIMISTIC ONLINE LEARNING."
SP:52228b48f2776d57dd422edb33b82e247f056b75,"This paper proposes a new benchmark for image classifier robustness. The proposed benchmark, IMAGENET-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. The authors also propose a new dataset called IMAGenet-P which enables researchers to benchmark a classifier’s robustness to common perturbations. "
SP:20358ea0f769e6ea9222d8e35159d711ee1b20b2,"This paper studies the problem of estimating the MAP of a conditional language model. The authors show theoretically that dropout training can be understood as performing MAP estimation concurrently for an entire family of conditional models whose objectives are themselves lower bounded by the usual dropout objective. The family includes models that compute a power mean over the sampled dropout masks, and their less stochastic subvariants with tighter and higher lower bounds than the fully stochiastic dropout objectives. The deterministic subvariant’s bound is equal to its objective, and the highest amongst these models. "
SP:ac1b950ad29429ae045bb5e53279014a6a0b9d2b,"This paper proposes a cumulative saliency based soft filter pruning (GSFP) scheme to prune redundant filters of Convolutional Neural Networks (CNNs). Specifically, the GSFP adopts a robust pruning method, which measures the global redundancy of the filter in the whole model by using the soft pruning strategy. The authors also propose a reasonable normalization formula to prevent certain layers of filters in the network from being completely clipped due to excessive pruning rate. Experiments show that GSFP is effective on many classic CNN architectures and different data sets. "
SP:621e41d4199e333ec7f9d0936d4e34c918f39c11,"The paper proposes a cross-lingual document classification framework (CACO) between related language pairs. CACO uses a character-based embedder and a word-based classifier. The embedder derives vector representations for input words from their written forms, and the classifier makes predictions based on the word vectors. The authors also propose a multi-task objective that can further improve the model if additional cross or monolingual resources are available."
SP:544e421f9c747640d949f433e3091763508b7237,"This paper proposes a new method for weakly-supervised temporal action localization. The proposed method is based on the marginalized average attentional network (MAAN), which is trained to suppress the dominant response of the most salient regions in a principled manner. The MAAN employs a novel marginalized average aggregation (MAA) module and learns a set of latent discriminative probabilities in an end-to-end fashion. Extensive experiments on two large-scale video datasets show that the proposed method achieves a superior performance on weakly supervised temporal actions localization. "
SP:9f98c9bac99003741dd14e093b54d692c0b0e8d8,"This paper proposes a new representation for language models that is based on reduced representation. The proposed representation is a combination of two existing representations, one that is composed of word-level and chunk-level embeddings, and the other that is a mixture of word and chunk representations. The authors show that the proposed representation can be used as a compositional representation, and that it is able to discover crude linguistic roles, which roughly resembles a classic division between syntax and semantics."
SP:5908b6acfed0e7c51e203c72eba907e6635e6c60,"This paper proposes a greedy strategy for observation selection in partially observable Markov decision processes (POMDPs). In particular, the authors propose a point-based value iteration algorithm that incorporates the greedy strategy to achieve near-optimal uncertainty reduction for sampled belief points. The authors also propose a solver to efficiently approximate the reachable subspace of belief simplex by essentially separating computations related to perception from planning. The proposed solver is evaluated on a range of robotic scenarios where the robot simultaneously performs active perception and planning."
SP:0adec4abec17b3aab0c6eb69d11925dc20544950,"This paper proposes a curriculum loss that consists of two parts: a) an adaptive weight that mitigates large early punishment; b) an additional representation loss for low weighted samples. The adaptive weight assigns small values to hard examples, reducing the influence of noisy gradients. On the other hand, the less-weighted hard sample receives the proposed representation loss. The proposed curriculum loss is easy to combine with existing stochastic algorithms like SGD. Experimental result shows consistent improvement over several benchmark datasets. "
SP:8b555b9f24044bc68c204169d6a37e262361d706,"The paper proposes a model for learning heuristics for combinatorial optimization problems. The proposed model is based on attention layers with benefits over the Pointer Network and is trained using REINFORCE with a simple baseline based on a deterministic greedy rollout, which is more efficient than using a value function. The authors show that the proposed model can learn strong heuristic for two variants of the Vehicle Routing Problem (VRP), the Orienteering Problem (OP) and (a stochastic variant of) the Prize Collecting TSP."
SP:efb76bcf1dbd9a9cf6b5db74b5d4256a9f9e9e73,This paper proposes a differentiable neural architecture search (DNAS) framework to efficiently explore its exponential search space with gradient-based optimization. Experiments show the effectiveness of the proposed method on CIFAR-10 and ImageNet.
SP:ea4173f8265bc50296de51c4ee7ecb6b8f78bec0,"This paper proposes a new attention architecture called Posterior Attention Models (PAM), which is based on a principled factorization of the joint distribution of the attention and output variables. The authors show that the current attention architectures do not adequately model the dependence among the attention, output and output tokens across a predicted sequence. To address this issue, the authors propose two major changes. First, the position where attention is marginalized is changed from the input to the output. Second, the attention propagated to the next decoding stage is a posterior attention distribution conditioned on the input. Empirically, the proposed posterior attention models yield better BLEU score and alignment accuracy than existing attention models."
SP:987e2c14abc091d4d3ef9b48fb2046408eb1f59e,"The paper proposes a method to learn bi-directional translations between the source and the target domains. The proposed method, called HarmonicGAN, uses a smoothness term over the sample graph to attain harmonic functions to enforce consistent mappings during the translation. The authors demonstrate the effectiveness of the proposed method in a number of applications including medical imaging, object transfiguration, and semantic labeling. "
SP:885a69003bad0e79cb2872a4e5c772191ad7e34f,"This paper studies the exploding and vanishing gradient problem (EVGP) in recurrent neural networks. The authors show that when the LSTM weights are large, the gradient components through the linear path (cell state) in the computational graph get suppressed. Based on the hypothesis that these components carry information about long term dependencies (which they show empirically), their suppression can prevent LSTMs from capturing them. To address this problem, the authors propose a simple stochastic algorithm (h-detach) that is specific to recurrent neural network optimization and targeted towards addressing this problem. "
SP:9aaff3777321347d1194884af5690b0b5185eff9,"This paper proposes a method for training binary weight networks without layer-wise or filter-wise scaling factors. The proposed method, named as SnapQuant, has two intriguing features: (1) The posterior distribution is parameterized as a policy network trained with a reinforcement learning scheme. (2) The policy network, which has a nested parameter structure consisting of layer, filter, and kernel-wise parameter sharing designs, is applicable to any neural network architecture. The performance of SnapQuant is evaluated with several visual recognition tasks including ImageNet."
SP:29d1f6d0661a51e56c59bbb106da56700fc22d9a,"This paper proposes a Bayesian nonparametric framework for federated learning with neural networks. Each data server is assumed to train local neural network weights, which are modeled through the framework. The authors then develop an inference approach that allows them to synthesize a more expressive global network without additional supervision or data pooling. "
SP:ab1f2bd216635d63450688866c729a501bd7e9d0,This paper proposes a new algorithm for learning with Opponent-Learning Awareness (LOLA) that interpolates between LOLA and a stable variant named LookAhead. The authors show that the proposed algorithm converges locally to equilibria and avoids strict saddles in all differentiable games. They also show that LOLA agents can exhibit ‘arrogant’ behaviour directly at odds with convergence.
SP:bdafb5fca09a775a8c92d2826d5dc977d28091c2,"This paper proposes an alarm system to set off alarms when the segmentation result is possibly unsatisfactory. The alarm system is based on shape feature which is a strong prior information shared among different data, so it is capable to predict the qualities of segmentation results given different segmentation algorithms on different datasets. The VAE is trained using only the ground truth masks, therefore the bad segmentation with bad shapes become the rare events for VAE and will result in large loss value. Finally, the representation in the one-dimensional feature space is learned by learning the classifiers/regressors in the feature space. "
SP:60738395d9efe2b3fe3a00c542ebb4261e54386c,"This paper proposes an untrained simple image model, called the deep decoder, which is a deep neural network that can generate natural images from very few weight parameters. The proposed model is simple in the sense that each layer has an identical structure that consists of only one upsampling unit, pixel-wise linear combination of channels, ReLU activation, and channelwise normalization. The authors show that underparameterization enables the proposed model to compress images into a concise set of network weights, which they show is on par with wavelet-based thresholding. "
SP:1c9bad3bd4d670172f65aa0304e9837ecafc6b3d,"This paper presents an end-to-end neural network architecture for program synthesis from natural language (NL) specifications. The proposed architecture relies exclusively on neural components, and is trained on abstract syntax trees, combined with a pretrained word embedding and a bi-directional multi-layer LSTM for processing of word sequences. The decoder features a doubly-recurrent LSTMs, for which the authors propose novel signal propagation schemes and soft attention mechanism. "
SP:d2ec231bb6153a303e5110e671dea14c2721e636,"This paper studies the problem of adversarial robustness to adversarial perturbations on MNIST. The authors propose a novel robust classification model that performs analysis by synthesis using learned class-conditional data distributions. They derive bounds on the robustness and go to great length to empirically evaluate their model using maximally effective adversarial attacks by (a) applying decision based, score-based, gradient-based and transfer-based attacks for several different Lp norms, (b) by designing a new attack that exploits the structure of the defended model and (c) by devising a novel decision-based attack that seeks to minimize the number of perturbed pixels (L0). The results suggest that the proposed method yields state-of-the-art robustness on the MNIST against L0, L2 and L∞ adversarial examples. "
SP:91a24e7f4b952c37441feab4a7e8555014c856a4,"This paper proposes a new framework for training GANs, which allows more flexible spectrum control (e.g., making the weight matrices of the discriminator have slow singular value decays). Specifically, the authors propose a new reparameterization approach for the loss matrices, and use various regularizers and constraints, without intensively computing singular value decompositions. Experiments on CIFAR-10, STL-10 and ImgaeNet datasets confirm that compared to other methods, the proposed method is capable of generating images with competitive quality by utilizing spectral normalization and encouraging the slow singular values decay. "
SP:8115fd9b681198d62100c36794926fb57dc0a4f5,"This paper proposes an accelerated value iteration algorithm for reinforcement learning. The authors introduce the Anderson acceleration technique into the value iteration, which they call Anderson Accelerated Value Iteration (A2VI). The authors further apply their method to the Deep Q-learning algorithm, resulting in the Deep Anderson-Accelerated Q-Learning (DA2Q) algorithm. The theoretical analysis and empirical results show the effectiveness of the proposed algorithm. "
SP:bd79b0c0af778a36008a0c0cf2fb6393fd2789d4,"This paper proposes a new method, SupportNet, to solve the catastrophic forgetting problem in the class incremental learning scenario. The proposed method combines the strength of deep learning and support vector machine (SVM), where SVM is used to identify the support data from the old data, which are fed to the deep learning model together with the new data for further training. Two powerful consolidation regularizers are applied to stabilize the learned representation and ensure the robustness of the learned model. "
SP:d228d213f79716774043cea253305fecece659ec,"This paper presents a comparison of four different measures of unit selectivity on AlexNet, namely, localist selectivity Bowers et al. (2014), precision (Zhou et al., 2015), class-conditional mean activity selectivity CCMAS, and a new measure called top-class selectivity. The authors show that the precision and CCMAS measures provide a much higher level of selectivity than is warranted, with the most selective hidden units only responding strongly to a small minority of images from within a category. The interpretable images in the hidden layers were not associated with highly selective units. "
SP:b9deae0392e0160b400d76c549d382e235196f8c,"This paper proposes a novel family of Graph Neural Networks (GNNs) for solving community detection problems in a supervised learning setting. In particular, the authors propose to augment GNNs with the non-backtracking operator defined on the line graph of edge adjacencies. The authors show that, in a data-driven manner and without access to the underlying generative models, they can match or even surpass the performance of the belief propagation algorithm on binary and multiclass stochastic block models, which is believed to reach the computational threshold in these cases. "
SP:a9ed31090e55f6152fc31c7512af5d634cc7225a,"This paper studies the problem of dictionary learning, where the goal is to model the given data as a linear combination of a few columns of a matrix known as a dictionary, and the sparse weights forming the linear combination are known as coefficients. Since the dictionary and coefficients, parameterizing the linear model are unknown, the corresponding optimization is inherently non-convex. This paper proposes a simple Neurally plausible alternating Optimization-based Online Dictionary Learning algorithm, which recovers both the dictionary (i.e., the coefficients) and dictionary (the dictionary) exactly at a geometric rate, when initialized appropriately. The proposed algorithm is scalable and amenable for large scale distributed implementations in neural architectures, by which it only involves simple linear and non-linear operations. "
SP:85232b72a2643d6dc81cf952ccbb95192032b7c5,"This paper proposes a new loss function and training scheme for learning binary hash codes with any differentiable model and similarity function. The proposed loss function improves over prior methods by using log likelihood loss on top of an accurate approximation for the probability that two inputs fall within a Hamming distance target. The training scheme obtains a good estimate of the true gradient by better sampling inputs and evaluating loss terms between all pairs of inputs in each minibatch. To fully leverage the resulting hashes, the authors use multi-indexing."
SP:3bd4ccff7f48380d2db8dff2c4ca515894a7f1db,"This paper proposes a new method for neural architecture search, called Graph HyperNetwork (GHN). The proposed method is based on a graph neural network, which generates the weights by running inference on graph neural networks. The authors show that GHN is faster than other random search methods on CIFAR-10 and ImageNet and can find networks with better speed-accuracy tradeoff than the state-of-the-art manual designs. "
SP:65ccf43cd4e033d22239069057f5200d49f33724,This paper proposes a method to improve generative adversarial imitation learning by using additional information from non-expert demonstrations which are easier to obtain. The key idea of the method is to perform multiclass classification to learn discriminator functions where non-experts are regarded as being drawn from an extra class. Experiments in continuous control tasks demonstrate that the proposed method learns better policies when the number of expert demonstrations is small. 
SP:e8427949a98effbd37ce7604fa11f240e2342196,"In this paper, the authors propose a new class of neural networks, called Invertible Neural Networks (INNs), to solve the ambiguous inverse problem. In particular, the INNs focus on learning the forward process, using additional latent output variables to capture the information otherwise lost. The authors prove theoretically and verify experimentally, on artificial data and real-world problems from medicine and astrophysics, that INNs are a powerful analysis tool to find multi-modalities in parameter space, uncover parameter correlations, and identify unrecoverable parameters. "
SP:75c9bb53bac29bdb390f9ba5707caee4ab1f5925,"This paper proposes a new ensemble method for estimating uncertainty of deep neural networks. The proposed method replaces the fixed mixing weights by an adaptive, input-dependent distribution (specifying the probability of each component) represented by an NN, and by considering uncountably many mixture components. The authors empirically show that the proposed model results in better uncertainty estimates and is more robust to adversarial examples than previous approaches. "
SP:e1e38289285c1b8fdb318e4f6d37a198a08787a2,"This paper proposes a new compression method for neural networks. The proposed method is based on the classical bits-back argument, where the weights are encoded using a random sample, and the Kullback-Leibler divergence between the sampled variational distribution and the encoding distribution. The authors show that the proposed method achieves the best compression rates for a fixed memory budget, and vice versa, it achieves the highest compression rates in a Pareto sense. "
SP:ad70d8cf3a4558aab0d3b7155594464a3debd912,This paper proposes ProxylessNAS that can directly learn the architectures for large-scale target tasks and target hardware platforms. The main contribution of the paper is to address the memory consumption issue of differentiable NAS and reduce the computational cost (GPU hours and GPU memory) to the same level of regular training while still allowing a large candidate set. The paper also proposes to specialize neural architectures for hardware with direct hardware metrics. Experiments on CIFAR-10 and ImageNet demonstrate the effectiveness of directness and specialization. 
SP:e5b70d43d301d1980fae02623ea711976b429c14,"This paper proposes to modify the linear penalties to second-order ones, which allows for a more practical training procedure in non-convex, large-data settings. The authors also derive a method for efficiently computing the gradients associated with the second order penalties in stochastic mini-batch settings. "
SP:e4720b8e4efdb222c45eafd47fd8a7fbf15d881d,The paper proposes a reweighted wake-sleep (RWS) algorithm for learning discrete latent variable models. The proposed method is based on the reweighting of the wake state of a weighted autoencoder. The authors show that the proposed method outperforms the existing state-of-the-art methods in the discrete latent-variable learning setting. 
SP:7459ae5b1d886e68930c4c9e21df508bc8ab3c9a,"This paper proposes to use truncated randomized search in the reward function to train structured prediction energy networks (SPENs), which provide efficient test-time inference using gradient-based search on a smooth, learned representation of the score landscape, and have previously yielded state-of-the-art results in structured prediction. In particular, the authors show that truncated random search yields previously unknown local improvements, providing effective supervision to SPENs."
SP:638c1bc09992029b78bd83f0127594dcccb96c06,"This paper proposes an active learning based framework, EffAcTS, to select model parameters for Robust Policy Search (RPS). The proposed method is based on active learning, where the goal is to collect only as much data as necessary to select such a subset. The authors apply this framework to an existing method, namely EPOpt, and experimentally validate the gains in sample efficiency and the performance of the proposed method on standard continuous control tasks. "
SP:491c239713a6489f0b1790ca26db54a1813c67ae,"This paper proposes a two-timescale network (TTN) architecture that enables linear methods to be used to learn values, with a nonlinear representation learned at a slower timescale. The authors prove convergence for TTNs, with particular care given to ensure convergence of the fast linear component under potentially dependent features provided by the learned representation.  The authors empirically demonstrate the benefits of TTNs compared to other nonlinear value function approximation algorithms, both for policy evaluation and control. "
SP:327d606cf3813b00a009a7785e08ef9e11f89493,"This paper proposes a hybrid model-based and model-free approach, LEArning and Planning with Semantics (LEAPS), consisting of a multi-target sub-policy that acts on visual inputs and a Bayesian model over semantic structures. When placed in an unseen environment, the agent plans with the semantic model to make high-level decisions, proposes the next sub-target to execute, and updates the semantic models based on new observations. LEAPS outperforms strong baselines that do not explicitly plan using the semantic content. "
SP:d7c26f43bc68d160095b1f50447528843d79edbd,This paper proposes a multi-task perception-related basic knowledge and driving knowledge stepwisely. Specifically segmentation map and depth map (pixel level understanding of images) were considered as what & where and how far knowledge for tackling easier drivingrelated perception problems before generating final control commands for difficult driving task. The results of experiments demonstrated the effectiveness of multitask perception knowledge for better generalization and accident explanation ability. 
SP:b6bd98cc70fab97e1245cbb63a42ef89ab7e7ed5,This paper studies the trade-off between adversarial robustness and standard generalization. The authors show that there exists an inherent tension between the goal of adversarial generalization and that of standard accuracy. They also argue that this phenomenon is a consequence of robust classifiers learning fundamentally different feature representations than standard classifiers. 
SP:9c9275d75cd95b1b82e0cbb1421e3d3ade1ce33a,"This paper proposes a new method for gradient-based training of neural networks that uses only local learning rules and, crucially, does not rely on neurons having a mechanism for back-propagating an error gradient. The proposed method is called Initialized Equilibrium Propagation, which trains a feedforward network to initialize the iterative inference procedure for Equilibrium propagation. After training, we can simply use this initializing network for inference. The experiments show that this network appears to work as well or better than the original version of equilibrium propagation while requiring fewer steps to converge. "
SP:ac9ea91eb465517de495477cf67bc94d5ed1b0cb,"This paper proposes a new zeroth-order stochastic optimization algorithm, ZO-signSGD, which enjoys dual advantages of gradient-free operations and signSGD. The authors show that under some mild conditions, the convergence rate is O(\sqrt{d/\epsilon}/T) for the proposed algorithm. In addition, the authors analyze the effects of different types of gradient estimators on the convergence of ZO and propose several variants of the algorithm. "
SP:5f79b11777f6ef1d70c85418bfc2e4616dd7d960,"This paper proposes a new optimization method to reduce the computation efforts of convolutional neural networks. The proposed method is based on multiply-accumulate (MAC) operations. The authors propose to set a checkpoint in the MAC process to determine whether a filter could terminate early based on the intermediate result. Furthermore, a fine-tuning process is conducted to recover the accuracy drop due to the applied checkpoints. The experimental results show that the proposed method can save approximately 50% MAC operations with less than 1% accuracy drop for CIFAR-10 example model and Network in Network on the cifar-10 and CifAR-100 datasets. "
SP:7801e9c854ad7d960c0d24fda15597af6994c23f,This paper investigates the use of temporal dependency in audio data to improve the robustness of automatic speech recognition (ASR) models against adversarial attacks. The authors show that input transformation developed from image adversarial defense provides limited robustness improvement and is subtle to advanced attacks; temporal dependency can be exploited to gain discriminative power against audio adversarial examples and is resistant to adaptive attacks considered in the experiments. 
SP:51830b811a8e39b4f0a5b7609df719e026fac6a1,"This paper proposes a generative model that learns to generate images by means of composition. Specifically, the generator learns to identify and disentangle information corresponding to different objects at a representational level. Experiments on several multi-object image datasets show that the proposed method is better at generating images that are faithful to the reference distribution."
SP:fb59990b8da0e95d8202383478a456667de60449,"This paper proposes a method for learning disentangled representations from unlabeled images. The method is based on a variational autoencoder, where the only supervision comes from an auxiliary “reference set” that contains images where the factors of interest are constant. During training, the variational inference framework is used to minimize the objective function. Experiments are conducted on three tasks: feature learning, conditional image generation and attribute transfer."
SP:dbc1983d9b9d72aa14f8e8515d793d2bbde26c9c,"This paper proposes a method for continual online learning from an incoming stream of data, using deep neural network models. The method uses stochastic gradient descent to update model parameters, and an expectation maximization algorithm with a Chinese restaurant process prior to develop and maintain a mixture of models to handle non-stationary task distributions. This allows for all models to be adapted as necessary, with new models instantiated for task changes and old models recalled when previously seen tasks are encountered again."
SP:5665e5f006f84927beb0440e145f476e02538077,"This paper proposes a method for training a distributed RL agent from experience replay. The method is based on a single network architecture and fixed set of hyperparameters. The authors study the effects of parameter lag resulting in representational drift and recurrent state staleness and empirically derive an improved training strategy. The resulting agent, Recurrent Replay Distributed DQN, quadruples the previous state-of-the-art on Atari-57, and matches the state of the art on DMLab-30."
SP:47ace37f31a46d5ee85c283e62ddb71a12f2c5c4,"This paper proposes a hierarchical generative model for multi-agent basketball. The proposed model is inspired by recent work on leveraging programmatically produced weak labels, which extends to the spatiotemporal regime. The authors show how to instantiate their framework to effectively model complex interactions between basketball players and generate realistic multi-Agent trajectories of basketball gameplay over long time periods. "
SP:1a90cdf028068528b0559e7d44bf26dda20310bd,"This paper presents a method to integrate temporal information, from a learned dynamics model, with ambiguous visual information, in the context of interacting agents. The method is based on a graph-structured variational recurrent neural network (Graph-VRNN), which is trained end-to-end to infer the current state of the (partially observed) world, as well as to forecast future states. The authors show that their method outperforms various baselines on two sports datasets, one based on real basketball trajectories and one generated by a soccer game engine."
SP:8392f04b7265f665ba6d44d297bca245d44b4708,"This paper proposes a method for end-to-end training of a base neural network that integrates calls to existing blackbox functions. The base network is trained with a differentiable neural network in a way that drives the base network to comply with the black-box function interface during the optimization process. At inference time, the differentiable estimator is replaced with its external blackbox non-differentiable counterpart such that the base model output matches the input arguments of the black box function. The authors show that by leveraging the existing precise black box functions during inference, the integrated model generalizes better than a fully differentiable model, and learns more efficiently compared to RL-based methods. "
SP:13fb86de763a0b34ac6fa34ea9dfbd1c476ce43e,The paper proposes a new method for learning-to-learn (LTL) based on a mixture of hierarchical Bayesian models over the parameters of an arbitrary function approximator such as a neural network. The authors propose a stochastic expectation maximization procedure to jointly estimate parameter initializations for gradient descent as well as a latent assignment of tasks to initializations. They further derive a novel and scalable non-parametric variant of their method that captures the evolution of a task distribution over time as demonstrated on a set of few-shot regression tasks. 
SP:a410144dbe19713a06c63da87d9fb58b999a7492,"This paper proposes a meta auxiliary learning method for image classification, where the auxiliary task is hierarchical sub-class image classification. The proposed method, Meta Auxiliary Learning (MAXL), is self-supervised and general, and is competitive even with a human-defined auxiliary learning methods. The meta learner is a multi-task evaluator, which is trained to determine sub-classes target labels to improve the generalisation performance on the principal task. Experiments on three different CIFAR datasets show the effectiveness of the proposed method. "
SP:76248e1c914c60ce69de244fe7ec62488d01e161,"This paper presents a neural network based representation for addressing the open set recognition problem. In this representation instances from the same class are close to each other while instances from different classes are further apart, resulting in statistically significant improvement when compared to other approaches. "
SP:d4ee856bbf2dfb6390e5247086fec2e52dcb6858,"This paper proposes a method to reduce the number of iterations required by stochastic gradient descent to achieve a given training error. The method is based on the observation that gradient noise due to quantization during training increases with reduced precision, and seek ways to overcome this noise. To this end, the authors propose to start with pretrained fp32 precision baseline networks and fine-tuning, and use larger batches along with matched learning rate annealing. The authors also demonstrate that the weights of the low-precision networks are very close to the corresponding baseline networks, making training from scratch unnecessary."
SP:6bfdc37b346e6ddfa049e0414647f4beda8ede3f,"This paper proposes a method to model surface properties governing bounces in everyday scenes. The proposed method is based on a physics-based model, Bounce and Learn, which learns end-to-end, starting from sensor inputs, to predict post-bounce trajectories and infer two underlying physical properties that govern bouncing restitution and effective collision normals. To achieve this, the authors introduce the Bounce Dataset comprising 5K RGB-D videos of bouncing trajectories of a foam ball to probe surfaces of varying shapes and materials. The model learns from the collected dataset of real-world bounces and is bootstrapped with additional information from simple physics simulations."
SP:010bd055310c363d3cb0fbe0e11546de58220e15,"This paper studies the adversarial vulnerability of deep neural networks. The authors show that adversarial vulnerabilities increase with the gradients of the training objective when viewed as a function of the inputs. For most current network architectures, they prove that the `1-norm of these gradients grows as the square root of the input size. "
SP:5fa3ae057e55be6b71cc94a7dbfe31e54e1c536f,"This paper proposes an interactive agent modeling scheme enabled by encouraging an agent to learn to probe. In particular, the probing agent learns to interact with the environment and with a target agent (i.e., a demonstrator) to maximize the change in the observed behaviors of that agent. The proposed method consists of two learning processes: i) imitation learning for an approximated agent model and ii) pure curiosity-driven reinforcement learning to discover new behaviors that otherwise can not be observed. The experimental results suggest that the agent model learned by the proposed method generalizes better in novel scenarios than the ones learned by passive observation, random probing, and other curiositydriven approaches do, and can be used for enhancing performance in multiple applications including distilling optimal planning to a policy net, collaboration, and competition."
SP:3af184a5529d6ec2a0862efd1af80ef5b50d2952,"This paper proposes a modification to traditional Artificial Neural Networks (ANNs), which provides the ANNs with new aptitudes motivated by biological neurons. The modification connects a new type of ANN nodes, which mimic the function of biological neuromodulators and are termed modulators, to enable other traditional ANN nodes to adjust their activation sensitivities in run-time based on their input patterns. In this manner, the slope of the activation function to be context dependent. This modification produces statistically significant improvements in the context of Convolutional Neural Networks and Long Short-Term Memory networks."
SP:287a577834fd2820a939a1113b39146a22727491,"This paper proposes a neural analysis and synthesis (NANSY) framework that can manipulate voice, pitch, and speed of an arbitrary speech signal. NANSY does not require any labels associated with speech data such as text and speaker information, but rather uses a new set of analysis features, i.e., wav2vec feature and newly proposed pitch feature, Yingram, which allows for fully self-supervised training. The experiments show that the proposed method can achieve significant improvement in several applications such as zero-shot voice conversion, pitch shift, and time-scale modification 1."
SP:90f35ad1ec0c38b0817f5678ee2a5c4f0e08fb38,This paper studies the generalization properties of the bilevel programming framework. The authors provide an expectation bound w.r.t. the validation set based on uniform stability. They also show that gradient-based algorithms can be better than cross-validation under certain conditions in theoretical perspective.
SP:42f52aec3a776d87daa5fd72b8e6325d12c88d63,"This paper proposes a knowledge distillation approach to facilitate the transfer of dark knowledge from a teacher to a student. The proposed method learns the teacher models that are friendly to students and, consequently, more appropriate for knowledge transfer. The authors show that the proposed method can improve the performance of diverse student models in terms of accuracy and convergence speed. "
SP:e15a1c21229233fd97dc1dfa0a4ef48b69dc9f95,"This paper studies the problem of generalization to out-of-distribution (OOD) data. In particular, the authors introduce a new concept of expansion function, which characterizes to what extent the variance is amplified in the test domains over the training domains, and therefore give a quantitative meaning of invariant features. The authors prove OOD generalization error bounds. Extensive experiments on benchmark OOD datasets demonstrate that their model selection criterion has a significant advantage over baselines."
SP:37b04b9068d39bcf0a581eb8181d13cf1a8926bf,"This paper proposes a variational Continual Bayesian Meta-Learning (VC-BML) algorithm for online learning. The proposed algorithm is based on a Dynamic Gaussian Mixture Model for meta-parameters, with the number of component distributions determined by a Chinese Restaurant Process. To infer the posteriors of model parameters, compared to the previously used point estimation method, the proposed method uses structured variational inference for the sake of avoiding forgetting knowledge. Experiments on tasks from non-stationary distributions show that the proposed algorithm can transfer knowledge among diverse tasks and alleviating catastrophic forgetting in an online setting. "
SP:776d5b02b8d3a8bbcc1f52706f3887c384cb149e,"This paper proposes a fast algorithm for the probabilistic solution of boundary value problems (BVPs), which are ordinary differential equations subject to boundary conditions. The authors propose a Gauss–Markov prior and tailor it specifically to BVPs, which allows computing a posterior distribution over the solution in linear time, at a quality and cost comparable to that of wellestablished, non-probabilistic methods. The proposed method is compatible with other parts of the statistical modelling tool-chain. "
SP:86aac0c6b75fdc12f84bba342934865616f866d4,"This paper studies the problem of learning a near optimal policy in a reward-mixingMarkov decision process (MDP). In this MDP, a reward function is drawn from one of multiple possible reward models at the beginning of every episode, but the identity of the chosen reward model is not revealed to the agent. The authors provide the first polynomial-time algorithm that finds an optimal policy after exploring Õ(poly(H, −1)·S2A2) episodes, where H is time-horizon and S,A are the number of states and actions respectively. "
SP:1a3c70ae9cf2a806d603f4b9e7ca6e10b720a956,This paper proposes a new method for conditional average treatment effect estimation. The proposed method is based on single-cause perturbation. The method is agnostic to the exact choice of algorithm in either step. Experiments are conducted on synthetic and semi-synthetic data. 
SP:247bc6675cce89d51558537daf63dadb0c4307f8,This paper proposes a multi-wavelet-based neural operator learning scheme that compresses the associated operator’s kernel using fine-grained wavelets. The projected kernel is trained at multiple scales derived from using repeated computation of multiwavelet transform. The proposed method shows significantly higher accuracy and achieves state-of-the-art in a range of datasets. 
SP:1153785e6a016cfee2644952a772aa08927299b6,"This paper proposes to use frequency domain approximation (FDA) to estimate the gradient of sign function in the Fourier frequency domain using the combination of sine functions for training BNNs. The proposed method does not affect the low-frequency information of the original sign function which occupies most of the overall energy, and high-frequency coefficients will be ignored to avoid the huge computational overhead. The experiments on several benchmark datasets and neural architectures illustrate that the binary network learned using the proposed method achieves the state-of-the-art accuracy. "
SP:33b95ea8da4d30b8e8f9d3fe3acca023d4b8d831,"This paper studies the problem of multi-area computation in the context of recurrent neural networks (RNNs) trained on neuroscience-based tasks. In particular, the authors show that incorporating multiple areas and Dale's Law is critical for biasing the networks to learn biologically plausible solutions. The authors also show that output-relevant information is preferentially propagated between areas. "
SP:db3ced65d67e3373fb3936ec50f41c8ef010bbbe,"This paper proposes structured attention graphs (SAGs), which compactly represent sets of attention maps for an image by visualizing how different combinations of image regions impact the confidence of a classifier. The proposed method is based on a beam search algorithm to systematically search for multiple explanations for each image. The authors conduct a user study comparing the use of SAGs to traditional saliency maps for answering comparative counterfactual questions about image classifications."
SP:f2b385bfd9ada0e26aa8829214b424f58582d9f7,"This paper studies how the choice of training objective affects the transferability of the hidden representations of convolutional neural networks trained on ImageNet. The authors show that many objectives lead to statistically significant improvements in ImageNet accuracy over vanilla softmax cross-entropy, but the resulting fixed feature extractors transfer substantially worse to downstream tasks. They also show that different objectives and hyperparameter combinations lead to dramatically different levels of class separation. "
SP:b66b5e24f68563e2e200eda660f0dbaff53efeff,"This paper proposes a method for learning a deep generative model of latent dynamics from data in which the set of observed variables changes at each time step. The method is based on selective backpropagation through time (SBTT). The authors show that it is able to obtain spatio-temporal super-resolution in neuronal time series by exploiting relationships among neurons, embedded in latent low-dimensional population dynamics. The authors test SBTT applied to sequential autoencoders and demonstrate more efficient and higher-fidelity characterization of neural population dynamics in electrophysiological and calcium imaging data. "
SP:3513a83806e71006b86d60b779d8bd6bb87c3546,"This paper proposes a hierarchical approach to sequence-to-sequence learning with quasi-synchronous grammars. The source and target trees are treated as latent and induced during training. The authors develop a neural parameterization of the grammar which enables parameter sharing over the combinatorial space of derivation rules without the need for manual feature engineering.  The authors apply this latent neural grammar to various domains—a diagnostic language navigation task designed to test for compositional generalization, style transfer, and small-scale machine translation."
SP:d06fc251f2a9287f7a2236a188349628d8f39d9a,"This paper proposes a new algorithm to perform Group Elastic Net with application to function-on-scalar feature selection, where a functional response is modeled against a very large number of potential scalar predictors. The proposed algorithm exploits the sparsity structure of the Augmented Lagrangian to greatly reduce computational burden. The authors also extend the proposed algorithm to the function on-scaled regression framework. "
SP:e0b53f76f3a6b756fedd09926f9cf034f89f4a5a,"The paper proposes a mixture model of multi-level marked point processes for identifying potential heterogeneity in the observed data. Specifically, the authors study a matrix whose entries are marked log-Gaussian Cox processes and cluster rows of such a matrix. An efficient semi-parametric Expectation-Solution (ES) algorithm combined with functional principal component analysis (FPCA) is proposed for model estimation. The effectiveness of the proposed framework is demonstrated through simulation studies and real data analyses."
SP:3aa213076f3e9f9838ac654517df2fe1fca33499,"This paper proposes an online multi-task learning approach for adaptive nonlinear control, which is called Online Meta-Adaptive Control (OMAC). The goal is to control a nonlinear system subject to adversarial disturbance and unknown environmentdependent nonlinear dynamics, under the assumption that the environmentdependent dynamics can be well captured with some shared representation. The authors provide instantiations of their approach under varying conditions, leading to the first non-asymptotic end-to-end convergence guarantee for multi-Task non-linear control. Experiments show that OMAC significantly outperforms conventional adaptive control approaches which do not learn the shared representation, in inverted pendulum and 6-DoF drone control tasks. "
SP:cb274c93a169b199ea09120ca02105a3f16b31c5,This paper proposes a new method for certified robust training. The method is based on interval bound propagation (IBP) and CROWN-IBP. The main contributions are: 1) The authors derive a new weight initialization method for IBP training; 2) They propose to fully add Batch Normalization (BN) to each layer in the model; 3) They also design regularization to explicitly tighten certified bounds and balance ReLU activation states during wamrup. 
SP:18ffeb199a670fb2b1f4417b8653479001944dab,"This paper studies the problem of change point detection. The authors propose a new detection boundary that is a function of the contamination proportion ε and is the first time shown in the literature. They also derive the minimax-rate optimal localisation error rate, quantifying the cost of accuracy in terms of contamination proportion. Extensive numerical experiments are conducted with comparisons to existing robust change point detectors. "
SP:d03617b5fc446768809cf015c9234b0c9386a690,"This paper studies the power of learning via mini-batch stochastic gradient descent (SGD) and batch Gradient Descent (GD) on the empirical loss of a differentiable model or neural network. The authors show that SGD and GD can always simulate learning with statistical queries (SQ), but their ability to go beyond that depends on the precision ρ of the gradient calculations relative to the minibatch size b and sample size m. In particular, when bρ is small enough, SGD can go beyond SQ learning and simulate any sample-based learning algorithm and thus its learning power is equivalent to that of PAC learning; this extends prior work that achieved this result for b = 1. "
SP:1de2864fe2f53e25596a9bd2c61e2048e79296f6,This paper studies the convergence of the Wasserstein distance minimization problem in the non-convex case where the unknowns are the positions of the atoms. The authors provide an upper bound on the convergence rate of the proposed method. The upper bound is based on a modified Poliak-Łojasiewicz inequality. The lower bound is derived for the corresponding gradient descent. 
SP:c3d364aeee55230a436c3ce4e8dc8310ee73959e,This paper proposes a relational self-attention (RSA) method for video action recognition. The proposed method is based on the idea of generating relational kernels and aggregating relational contexts. The authors show that the proposed method significantly outperforms the existing methods on the standard motion-centric benchmarks. 
SP:2c2530069d5cab485629090243da464d107feadd,"This paper studies the mean field theory of multilayer neural networks. The authors derive a system of dynamical equations, called the second-order mean field limit, that captures the limiting fluctuation distribution. They demonstrate through the framework the stochasticity with cross-layer dependency and the nonlinear time evolution inherent in the limit. They apply the result to show a stability property of gradient descent mean field training."
SP:a3d927854d9d7fd39b8d05a79666810d585d5062,"This paper proposes a novel parameterization of dissipative brackets from metriplectic dynamical systems for learning irreversible dynamics with unknown a priori model form. The proposed method learns generalized Casimirs for energy and entropy guaranteed to be conserved and nondecreasing, respectively. Furthermore, for the case of added thermal noise, the authors guarantee exact preservation of a fluctuation-dissipation theorem, ensuring thermodynamic consistency. The authors provide benchmarks for dissipative systems demonstrating learned dynamics are more robust and generalize better than either ""black-box"" or penalty-based approaches."
SP:32e8e83e06b1e9a4dad761334d5947c91bfd1853,This paper proposes a sample selection-based algorithm for fair and robust training. The proposed algorithm is based on the combinatorial optimization problem for the unbiased selection of samples in the presence of data corruption. Experiments show that the proposed algorithm obtains fairness and robustness that are better than or comparable to the state-of-the-art technique. 
SP:991127729bf067fe27fdd7ed360aab39e4df5921,"This paper proposes periodic activation functions for Bayesian neural networks. The authors show that the activation function is a connection between the prior on the network weights and translation-invariant, stationary Gaussian process priors. They also show that this link goes beyond sinusoidal (Fourier) activations by also covering triangular wave and periodic ReLU activation functions. "
SP:d61a2aecfea4612c473b4e6fd41f3dc2fcbb04a1,"This paper proposes a method for providing feedback to interactive programs. The proposed method is based on a cooperative objective between an agent and an autoregressive model, where the agent is able to sample differential trajectories from the input MDP that allows a classifier to determine membership: Play to Grade. The method is evaluated on a dataset of 711,274 anonymized student submissions to a single assignment with hand-coded bug labels. "
SP:daf99ad91613d6e11b13315ccbd1bbe25094ae4b,The paper proposes a representation and mimic tree (RAMi) framework for interpretable deep reinforcement learning models. The proposed method is based on the information bottleneck (IB) principle. The authors propose a Monte Carlo Regression Tree Search (MCRTS) algorithm that explores different splits to find the IB-optimal mimic tree. Experiments show that the method achieves strong approximation performance with significantly fewer nodes than baseline models.
SP:84560de78af979354fff83d1370d8675c1e9191f,"This paper proposes a Bayesian framework for modeling the structure of dynamic predictions over time. The proposed framework is based on the Gaussian latent information martingale, which is inferred from historical data. The authors show that the proposed framework preserves important properties of probability paths such as the martingales structure and appropriate amount of volatility and better quantifies future uncertainties around probability paths. "
SP:0c4bfb44e0a353256692d5e5ae96f65c1a14363d,"This paper studies the problem of active pure exploration with fixed confidence in generic stochastic bandit environments. The goal of the learner is to answer a query about the environment with a given level of certainty while minimizing her sampling budget. For this problem, instance-specific lower bounds on the expected sample complexity reveal the optimal proportions of arm draws an Oracle algorithm would apply. The authors propose Frank-Wolfe-based Sampling (FWS), a simple algorithm whose sample complexity matches the lower bounds for a wide class of pure exploration problems. The algorithm is computationally efficient as, to learn and track the optimal proportion of arms draws, it relies on a single iteration of Frank-wolfe algorithm applied to the lower-bound optimization problem. "
SP:0947a0f08fba53d3c8af9b78dd64e6e10fc73e32,This paper proposes a new method for combinatorial optimization. The main idea is to use a structure-coupled kernel that explicitly integrates the structural information from decoded structures with the learned latent space representation for better surrogate modeling. Experiments on real-world benchmarks show that LADDER significantly improves over the BO over latent space method. 
SP:37adabdc6615c5199a481553c8ccc06d57363614,"This paper studies the role of the representation of state-action value functions in regret minimization in finite-horizon Markov Decision Processes (MDPs) with linear structure. The authors derive a necessary condition on the representation, called universally spanning optimal features (UNISOFT), to achieve constant regret in any MDP with linear reward function. They then demonstrate that this condition is also sufficient for these classes of problems by deriving a constant regret bound for two optimistic algorithms (LSVI-UCB and ELEANOR). Finally, they propose an algorithm for representation selection and prove that it achieves constant regret when one of the given representations, or a suitable combination of them, satisfies the UNISOFT condition."
SP:92566b664ab2f6ee9b73f29327aeef85d14ecf60,"This paper proposes a differentiable contact model, which can capture contact mechanics: frictionless/frictional, as well as elastic/inelastic. The proposed contact model extends the scope of Lagrangian and Hamiltonian neural networks by allowing simultaneous learning of contact and system properties.  The proposed method is evaluated on a series of challenging 2D and 3D physical systems. "
SP:82d59a3609dfd458f90f23d4e477c8b497e9dc18,"This paper studies the Benevolent Training Hypothesis (BTH) which argues that the complexity of the function a deep neural network (NN) is learning can be deduced by its training dynamics. The authors first observe that the Lipschitz constant close to the training data affects various aspects of the parameter trajectory, with more complex networks having a longer trajectory, bigger variance, and often veering further from their initialization. They then show that NNs whose 1st layer bias is trained more steadily (i.e., slowly and with little variation) have bounded complexity even in regions of the input space that are far from any training point. Finally, they find that steady training with Dropout implies a training and datadependent generalization bound that grows poly-logarithmically with the number of parameters. "
SP:9b329c915fa8d4045c167c9df37a49ee314d190e,"This paper studies the problem of distribution-independent PAC learning of halfspaces in the Massart noise model with strongly polynomial sample complexity, i.e., independent of the bit complexity of the examples. The authors show that any distribution can be efficiently decomposed as a disjoint mixture of few distributions for which a Forster transform exists and can be computed efficiently. "
SP:e5229305af00067ae2dbabd903e585964aec8928,"This paper proposes a Bayesian optimisation-based adversarial attack method for graph classification models. The proposed method is black-box, query-efficient and parsimonious with respect to the perturbation applied. The authors empirically validate the effectiveness and flexibility of the proposed method on a wide range of graph classification tasks involving varying graph properties, constraints and modes of attack. "
SP:4999e5664383066fdacd14be6242c7b83f85f3dd,"This paper studies the problem of label shift adaptation in the online setting, where the test-time label distribution is continually changing and the model must dynamically adapt to it without observing the true label. The authors propose adaptation algorithms inspired by classical online learning techniques such as Follow The Leader (FTL) and Online Gradient Descent (OGD) and derive their regret bounds. They empirically verify their findings under both simulated and real world label distribution shifts and show that OGD is particularly effective and robust to a variety of challenging label shift scenarios."
SP:806515ae07fb1c9d02773592005d53d4158ef102,"This paper studies the detection and localization of gradual changes in the distribution of a sequence of time-ordered observations. The authors propose a general method for detecting and localizing gradual changes that does not require a specific data generating model, a particular data type, or prior knowledge about which features of the distribution are subject to change. Despite relaxed assumptions, the proposed method possesses proven theoretical guarantees for both detecting and localization."
SP:7a3c8a7b17ecab19361d36e1d3d73fa35b71214c,"The paper proposes an algorithm for blind source separation (BSS) problems. The proposed algorithm is based on the idea of independent component analysis (ICA). The authors propose a novel objective function for ICA from which they derive a biologically plausible NN, including both the neural architecture and the synaptic learning rules. The authors show that the proposed algorithm relies on modulating synaptic plasticity by the total activity of the output neurons. "
SP:22f8b517a3df65144412938f5891c463d7bae0ab,"This paper studies the space of solutions associated with various tasks. The authors first study a simple two-neuron network on a task that leads to multiple solutions. They trace the nature of the final solution back to the network’s initial connectivity and identify discrete dynamical regimes that underlie this diversity. They then examine three neuroscience-inspired tasks: Delayed discrimination, Interval discrimination, and Time reproduction. For each task, they find a rich set of solutions."
SP:9b08a0f547ead3b59077a43b1052c6d46a0730f6,"This paper proposes a new method, Arbitrary Conditioning with Energy (ACE), that can simultaneously estimate the distribution p(xu | xo) for all possible subsets of unobserved features xu and observed features xo. ACE is designed to avoid unnecessary bias and complexity and reduce the problem to only learning one-dimensional conditionals (from which more complex distributions can be recovered during inference). This results in an approach that is both simpler and higher-performing than prior methods. "
SP:f2b14f5854e6aa6922795d1d2051b7402486cef6,"This paper proposes a new adaptive weighted loss for SISR to train deep networks focusing on challenging situations such as textured and edge pixels with high uncertainty. Specifically, the authors introduce variance estimation characterizing the uncertainty on a pixel-by-pixel basis into SisR solutions so the targeted pixels in a high-resolution image (mean) and their corresponding uncertainty (variance) can be learned simultaneously. Moreover, uncertainty estimation allows the authors to leverage conventional wisdom such as sparsity prior for regularizing SISRs solutions. Experimental results show that the proposed uncertainty-driven loss achieves better PSNR performance than traditional loss functions without any increased computation during testing."
SP:9997583f40fa648adf57bb4fc34228f357be0cf1,"The paper proposes a general PAC-Bayesian generalization bound for adversarial robustness. The main contribution of the paper is to derive a worst-case analysis of the risk of a hypothesis over all the possible perturbations, and to use the PACBayesian framework to bound the averaged risk on the perturbation for majority votes (over the whole class of hypotheses). The paper provides general bounds that are valid for any kind of attacks (i.e., the adversarial attacks), and are tight thanks to the PAC-bayesian framework. "
SP:90b72e8dc41584e38f25dff9fb2853f5b11dc8fa,"This paper proposes a probabilistic entity representation model (PERM) to encode entities as a Multivariate Gaussian density with mean and covariance parameters to capture its semantic position and smooth decision boundary, respectively. PERM also defines the closed logical operations of projection, intersection, and union that can be aggregated using an end-to-end objective function. On the logical query reasoning problem, PERM significantly outperforms the state-of-the-art methods on various public benchmark KG datasets on standard evaluation metrics. "
SP:b6184c9732dbb7eba7c20cae8869d975c428efe4,"This paper proposes a new gradient-based hyperparameter optimization method for few-shot meta-learning. The proposed method is based on forward-mode differentiation with sharing (FDS), which tackles memory scaling issues and gradient degradation issues by sharing hyperparameters that are contiguous in time. The authors provide theoretical guarantees about the noise reduction properties of FDS, and demonstrate its efficiency empirically by differentiating through ∼ 10 gradient steps of unrolled optimization. "
SP:9c3a326e5ee4e862923d3bf9415f32a077db8534,"This paper proposes a method to improve the coherence and accuracy of neural sequence models by adding System 2-inspired logical reasoning. The proposed method is based on a symbolic reasoning module, which can either accept or reject the generations from a neural sequence model. Experiments show that the proposed method can improve the accuracy and coherence of neurally-based generations. "
SP:d77d046095e4c8336c0c76ac48cb046923230753,This paper proposes a method for off-policy evaluation (OPE) in continuous treatment settings. The method is based on deep learning and multiscale change point detection. The proposed method can be applied to discrete treatments as well as continuous treatments. 
SP:4d085e57286fdd36143108a002d16914222c239a,"This paper proposes a variational inference method for continuous time-series data. The proposed method is based on a Markov jump process modulating a subordinated diffusion process. The authors provide the exact evolution equations for the prior and posterior marginal densities, the direct solutions of which are computationally intractable. They also provide a new continuous-time variational approximation on the diffusion level. "
SP:d1f396e691f9d331adfb7b694a99c50e8004331f,This paper studies the effect of the spectrum of sensing matrices on the difficulty of recovering x from y. The authors define a notion for the spikiness of spectrum of A and show the importance of this measure in the performance of the expectation propagation algorithm (EP). The authors also define certain quantities based on the function f that enables to describe the impact of the Spiky spectrum on EP recovery. 
SP:ee66604d4da9fd04826e90ccbb94f0499eba4c63,"This paper proposes a new method for zero-shot learning in GZSL. The proposed method, Dual Progressive Prototype Network (DPPN), constructs two types of prototypes that record prototypical visual patterns for attributes and categories, respectively. With attribute prototypes, DPPN alternately searches attribute-related local regions and updates corresponding attribute prototypes to progressively explore accurate attribute-region correspondence. Besides, along with progressive attribute localization, the proposed method also projects category prototypes into multiple spaces to progressively repel visual representations from different categories, which boosts category discriminability. Experiments on four benchmarks demonstrate the effectiveness of the method."
SP:61eb6297568c3f6869fbb03eaf6a21260de5466c,"This paper presents an end-to-end deep learning approach for removing defocus blur from a single image, so as to have an all-in-focus image for consequent vision tasks. First, a pixel-wise Gaussian kernel mixture (GKM) model is proposed for representing spatially variant defocus blurring kernels in an efficient linear parametric form, with higher accuracy than existing models. Then, a deep neural network is developed by unrolling a fixed-point iteration of the GKM-based deblurring. Finally, a scale-recurrent attention module is proposed to estimate the mixing coefficients in GKKM for estimating the mixing coefficient. Extensive experiments show the effectiveness of the proposed method."
SP:18bf447c90935c373e5ec4cdfbbf8f2a273d2edb,"This paper proposes a new self-supervised video representation learning (SSVRL) method. The proposed method is based on a cross guidance contrastive learning algorithm, where motion vectors can take supervision signals from RGB frames and vice versa. The authors also propose a multi-instance InfoNCE loss to enhance the representation ability of the motion vectors, hence the effectiveness of the proposed method. "
SP:8c7b1d976d9758cd534c565ec31a23f97892e503,"This paper studies the problem of asymptotic overconfidence in ReLU Bayesian neural networks (BNNs) with infinite ReLU features. In particular, the authors show that the output variance of a BNN with finitely many features is quadratic in the distance from the data region. To mitigate this issue, they propose a Gaussian process (GP) with a variance that grows cubically so that no overconfidence can occur. The authors also extend finite ReLU BNNs with infinite reLU features via the GP and show the resulting model is maximally uncertain far away from data while the BNN’s predictive power is unaffected near the data. "
SP:e77276f61626e896f6a985296f1d832129242cdf,This paper considers the problem of selecting a formula for identifying a causal quantity of interest among a set of available formulas. The authors assume an sequential setting in which the investigator may alter the data collection mechanism in a data-dependent way with the aim of identifying the formula with lowest asymptotic variance in as few samples as possible. They formalize this setting by using the bestarm-identification bandit framework where the standard goal is replaced with the goal of learning the arm that will produce the best estimate.  The authors introduce new tools for constructing finite-sample confidence bounds on estimates of the variance that account for the estimation of potentially complex nuisance functions. They validate their method by providing upper bounds on the sample complexity and an empirical study on artificially generated data.
SP:471361588bfc6c6033631509d1e43e77fd9721ce,"This paper studies the problem of variance reduction for stochastic gradient descent. The authors show that adding the previous step’s compression error, as done in existing work, does not fully compensate the compression error. Instead, the authors propose ErrorCompensatedX, which uses the compression errors from the previous two steps. The paper provides a unified theoretical analysis framework for this class of variance reduced algorithms, with or without error compensation. "
SP:3b7ff0dc668cac2191d95fcc4dc6e0335dec3206,"This paper proposes a method for generating multi-grained explanations for graph neural networks. The method is based on the pre-training and fine-tuning idea. The authors propose to use the contrastivity among different classes, so as to highlight the class-wise characteristics from a global view, and adapts the explanations in the local context. Experiments on both synthetic and real-world datasets show the superiority of the proposed method. "
SP:9b5a62d3a2b27bc60da28980e9fb0ecdff1215c0,This paper proposes a method to generate counterfactual explanations on GNNs by explicitly modelling the common decision logic of GNN on similar input graphs. The proposed method is robust to noise and aligns well with human intuition. Experimental results demonstrate the superior performance of the proposed method. 
SP:4edb870786c9cea2c6075359cb4e79b02a8e2f5f,This paper proposes a self-supervised representation learning method for voice conversion. The key idea is to decompose the content and voice style from the source speech. The proposed method is based on a novel information bottleneck and adversarial feedback. The experimental results show the superiority of the proposed method. 
SP:9fbb0c6beb3f8f88972f13dcf0e1fe7db03233c7,"This paper proposes a Siamese voxel-to-BEV tracker, which can significantly improve the tracking performance in sparse 3D point clouds. The proposed method consists of two components. First, it first performs template feature embedding to embed the template’s feature into the potential target and then generate a dense 3D shape to characterize the shape information of the target. Second, it regresses the 2D center and the z-axis center from the dense bird's eye view (BEV) feature map in an anchor-free manner. Extensive evaluation on the KITTI and nuScenes datasets shows that the proposed method significantly outperforms the current state-of-the-art methods by a large margin. "
SP:8b788c78680a54c453a04f4551436763ee57585e,"This paper proposes a novel positional encoding method based on learnable Fourier features. The proposed method is based on a multi-layer perceptron, modulated with a learnable feature mapping. The authors show that the proposed method outperforms existing methods on several public benchmark tasks. "
SP:d2ac1b6381315bce4449f09bd519f33a2a42d714,"This paper proposes a recursive constraint-based method for learning the causal MAG of a system from observational data in the presence of latent variables and selection bias. The key idea is that at each iteration a specific type of variable is identified and removed. This allows us to learn the structure efficiently and recursively, as this technique reduces both the number of required conditional independence (CI) tests and the size of the conditioning sets. The upper bound of the proposed approach and the lower bound at most differ by a factor equal to number of variables in the worst case. "
SP:49a4912ce457f5f5ec62c44fa10444af8075fabf,This paper proposes a batch Thompson Sampling framework for two canonical online decision making problems: stochastic multi-arm bandit and linear contextual bandit with finitely many arms. The proposed framework dynamically determines the duration of each batch in order to balance the exploration-exploitation trade-off. The authors also demonstrate experimentally that dynamic batch allocation dramatically outperforms natural baselines such as static batch allocations. 
SP:653a519e3c799c25e0d0b4240322642040b121a3,"This paper studies the problem of domain adaptation (DA) and domain generalization (DG) in the multi-source DA setting. In particular, the authors develop novel upper-bounds for the target general loss which appeal to define two kinds of domain-invariant representations. They further study the pros and cons as well as the trade-offs of enforcing learning each domain invariant representation. Finally, they conduct experiments to inspect the tradeoff of these representations for offering practical hints regarding how to use them in practice. "
SP:2a7bee950cd07494d59dfee60ac2e86cc0e481b1,"This paper proposes aligned structured sparsity learning (ASSL), which introduces a weight normalization layer and applies L2 regularization to the scale parameters for sparsity. To align the pruned filter locations across different layers, the authors propose a sparsity structure alignment penalty term, which minimizes the norm of soft mask gram matrix. The proposed method is applied to train efficient image SR network with smaller model size and lower computation than state-of-the-art methods. "
SP:e9830bb9e7d3ddc3bd1c2994590fdb5d8f3668be,"This paper proposes a novel exploration method for cooperative multi-agent reinforcement learning. The authors leverage an insight of factorized MARL algorithms that the ""induced"" individual Q-values, i.e., the individual utility functions used for local execution, are the embeddings of local actionobservation histories, and can capture the interaction between agents due to reward backpropagation during centralized training. Therefore, the authors use prediction errors of individual Q values as intrinsic rewards for coordinated exploration and utilize episodic memory to exploit explored informative experience to boost policy training. "
SP:c7e33d479575c88e22282ee6fd4f978bcd3c06ed,"This paper studies the problem of list-decodable linear regression, where an adversary can corrupt a majority of the examples. The main result is a Statistical Query (SQ) lower bound of d for this problem. "
SP:7b258252a9063514348f5fa8d9c85afd85748747,This paper proposes a latent hybridisation model (LHM) that integrates a system of expert-designed ODEs with machine-learned Neural ODE models to fully describe the dynamics of the system and to link the expert and latent variables to observable quantities. LHM is evaluated on synthetic data as well as real-world intensive care data of COVID-19 patients. 
SP:3ea9e86e5755ef84d28e3163c60531ace5d62e3a,"This paper studies the problem of few-shot meta-learning, where the goal is to learn a representation for a given task. The authors provide a theoretical framework for analyzing a MAML-like algorithm, assuming all available tasks require approximately the same representation. They then provide risk bounds on predictors found by finetuning via gradient descent, demonstrating that the method provably leverages the shared structure. In contrast, they establish settings where learning one representation for all tasks (i.e. using a frozen representation) fails."
SP:8ba5a2ac80f7c53f81ad008e96c033ecad14ac0d,"This paper presents Grammar-Based Grounded Lexicon Learning (G2L2), a lexicalist approach to learn a compositional and grounded meaning representation of language from grounded data. The proposed method is based on a collection of lexicon entries, which map each word to a tuple of a syntactic type and a neuro-symbolic semantic program. The authors propose a joint parsing and expected execution algorithm, which does local marginalization over derivations to reduce the training time. Experiments are conducted on two domains: visual reasoning and language-driven navigation."
SP:16c458651815813efdcbe8ba1205bbddbe3e4e68,"The paper proposes a stochastic Newton algorithm for homogeneous distributed convex optimization, where each machine can calculate stochiastic gradients of the same population objective, as well as stochastically Hessian-vector products (products of an independent unbiased estimator of the Hessian of the population objective with arbitrary vectors). The authors show that their method can reduce the number, and frequency, of required communication rounds compared to existing methods without hurting performance, by proving convergence guarantees for quasi-self-concordant objectives. "
SP:d7e479d59f82d4c55372a68ca7b4516f2871f346,The paper proposes a new similarity measure named Density-aware Chamfer Distance (DCD) for measuring the similarity between two point sets. It is derived from CD and benefits from several desirable properties: 1) it can detect disparity of density distributions and is thus a more intensive measure of similarity compared to CD; 2) it is stricter with detailed structures and significantly more computationally efficient than EMD; 3) the bounded value range encourages a more stable and reasonable evaluation over the whole test set. The paper adopts DCD to evaluate the point cloud completion task and shows that DCD pays attention to both the overall structure and local geometric details and provides a more reliable evaluation even when CD and EMD contradict each other. 
SP:e4b302009520770814ff2c096020b779a9fc38fe,"This paper studies the problem of knowledge distillation, which is a popular technique for training a small student network to emulate a larger teacher model, such as an ensemble of networks. The authors show that while the proposed method can improve student generalization, it does not typically work as it is commonly understood: there often remains a surprisingly large discrepancy between the predictive distributions of the teacher and the student, even in cases when the student has the capacity to perfectly match the teacher. They also show how the details of the dataset used for distillation play a role in how closely the student matches the teacher — and that more closely matching the teacher paradoxically does not always lead to better student generalisation."
SP:895c7e03f9e4dadb94be1f39d61bf0b5e1533f4f,"The paper proposes a coreset for k-decision trees. The coreset is a small summarization of the loss of the decision tree for a given matrix D of N entries (labels) where each rectangle is assigned a real label. The authors provide the first algorithm that outputs such a (k, ε)-coreset for every such matrix D. The size |C| is polynomial in k log(N)/ε, and its construction takes O(Nk) time. Experimental results on sklearn and lightGBM show that applying the coresets on real-world data-sets significantly improves the computation time of random forests and their parameter tuning. "
SP:f3ece96b15ec06d703925df2061ed9694ec3bca5,"This paper studies the problem of the identification of m arms with largest means under a fixed error rate δ (fixed-confidence Top-m identification), for misspecified linear bandit models. The authors first derive a tractable lower bound on the sample complexity of any δ-correct algorithm for the general Top-M identification problem. They then describe the first algorithm for this setting, which is both practical and adapts to the amount of misspecification. Finally, they evaluate their algorithm on both synthetic and real-world data, showing competitive performance with respect to existing baselines. "
SP:e71c5e39b8d8d1640d6de2352ac51ddd52eea89d,"This paper proposes a contrastive learning method for learning disentangled graph-level representations with self-supervised learning. The proposed method first identifies the latent factors of the input graph and derive its factorized representations. Then, the authors propose a novel factor-wise discrimination objective in a contrastively learning manner, which can force the factorized representation to independently reflect the expressive information from different latent factors. Extensive experiments on both synthetic and real-world datasets demonstrate the superiority of the proposed method. "
SP:0a7edbbdabab11273689c40c517001eb46491113,This paper proposes a method for estimating the robustness of a trained network to input uncertainties with a stochastic simulation inspired by the field of Statistical Reliability Engineering. The method is based on an Importance Splitting simulation generating samples of rare events. The robustness assessment is cast as a statistical hypothesis test: the network is deemed as locally robust if the estimated probability of failure is lower than a critical level. 
SP:c1db485ff1ff9573daa421e167225654babb55ac,"This paper proposes a general framework, called CoPE, that enables a polynomial expansion of two input variables and captures their auto-and cross-correlations. CoPE is evaluated in five tasks (class-conditional generation, inverse problems, edges-to-image translation, image-to image translation, attribute guided generation, and attribute guided image generation) involving eight datasets. "
SP:5a75bc7a3ea0ce971cfceebbc1c2434e3aa2584d,"This paper proposes a new neural tangent kernel (NTK) based MMD statistic. The proposed NTK-MMD statistic is based on the connection between NTK and the maximum mean discrepancy (MMD) statistic. This connection enables the authors to develop a computationally efficient and memory-efficient approach to compute the MMD and perform NTK based two-sample tests towards addressing the long-standing challenge of memory and computational complexity of MMD. Theoretically, such a connection allows us to understand the NTK test statistic properties, such as the Type-I error and testing power for performing the two sample test. Numerical experiments on synthetic and real-world datasets validate the theory and demonstrate the effectiveness of the proposed method. "
SP:1df2ffbbe56b8018067820980b93af2a8b57f891,"This paper proposes a class-disentanglement method to extract the minimum necessary information required by a neural net D(·) from an image x to accurately predict its class. The proposed method is based on a variational autoencoder G(·), where the former competes with the latter in decomposing x so the latter retains only necessary information for classification in x − G(x). The authors apply it to both clean images and their adversarial images and discover that the perturbations generated by adversarial attacks mainly lie in the class-dependent part x-G(x), which provides novel interpretations to classification and attack models. "
SP:2789874561620ba7894c4672f935056bb911e919,"This paper proposes a federated Thompson sampling (FTS) algorithm for Bayesian optimization (BO) with differential privacy (DP). The proposed algorithm is based on a general framework for adding DP to iterative algorithms. The authors also leverage the ability of this general DP framework to handle different parameter vectors, as well as the technique of local modeling for BO, to further improve the utility of the algorithm through distributed exploration (DE). The resulting differentially private FTS with DE (DP-FTS-DE) algorithm is endowed with theoretical guarantees for both the privacy and utility and is amenable to interesting theoretical insights about the privacy-utility trade-off. "
SP:be7d6b81736a2c3f89abd8771b41b18802e88832,The paper proposes a multi-label active learning (ML-AL) framework that combines Gaussian Process-Bayesian Bernoulli Mixture model (GP-BM) to accurately quantify a data sample’s overall contribution to a correlated label space and choose the most informative samples for cost-effective annotation. The BM is integrated with a predictive GP to connect data features as an effective inductive bias and achieve a feature-component-label mapping. The model also outputs a predictive distribution that provides both the label prediction and their correlations in the form of a label covariance matrix. A novel auxiliary variable based variational inference algorithm is developed to tackle the non-conjugacy introduced along with the mapping process for efficient end-to-end posterior inference. Experiments demonstrate the state-of-the-art AL performance of the proposed model. 
SP:2b7270b0370c193300bcbbb5fb0a4101b3329d99,This paper proposes a new method to improve the performance of the current state-of-the-art LIDAR methods. The proposed method is based on a polar coordinate system. The authors propose to use multi-scale padding from neighboring sectors to increase the spatial context. They also improve the core polar convolutional architecture by introducing feature undistortion and range stratified convolutions. Experimental results on the nuScenes dataset show significant improvements over other streaming based methods. 
SP:7ae2c5b7d9c8a6c8f4a353606aa419929c47f31b,"This paper proposes a method for learning a structured latent variable. The authors extend the Gumbel-Max trick to define distributions over structured domains. In particular, they highlight a family of recursive algorithms with a common feature we call stochastic invariant. They avoid the differentiable surrogates by leveraging the score function estimators for optimization. "
SP:415d363c66a6967c1daca9dc02001b85bf7f0752,"This paper proposes a new method for image denoising, called GainTuning. The method is based on a multiplicative scaling parameter (Gain) of each channel in the convolutional layers of the CNN. To avoid overfitting, the proposed method optimizes a single multiplicative scale parameter (the ""Gain"" parameter) for each channel. The proposed method is evaluated on standard image-denoising benchmarks. "
SP:90afa1102683b456bc72a54abef466326827546a,This paper proposes a new architecture for panoptic segmentation. The proposed architecture consists of a convolutional neural network and an asymmetric multi-way cut problem solver. The latter solves a combinatorial optimization problem that elegantly incorporates semantic and boundary predictions to produce a panoptical labeling. Experiments are conducted on Cityscapes and COCO datasets.
SP:1952e174d9ec7b83ad1d394ece7fe77ea1f6d78d,"This paper proposes Recursive Bayesian Networks (RBNs), which generalize and unify PCFGs and dynamic Bayesian networks (DBNs) by combining their strengths and containing both as special cases. The authors provide two solutions: 1) for arbitrary RBNs, they generalise inside and outside probabilities from PCFG to the mixed discrete-continuous case, which allows for maximum posterior estimates of the continuous latent variables via gradient descent, while marginalising over network structures. 2) for Gaussian RBN, they additionally derive an analytic approximation of the marginal data likelihood (evidence) and marginal posterior distribution, allowing for robust parameter optimisation and Bayesian inference. "
SP:5f29b169d3e4bbaeeec85e1aeebe2094fae4be6e,"The paper proposes a constrained backpropagation (CBP) algorithm based on the pseudo-Lagrange multiplier method to obtain the optimal set of weights that satisfy a given set of constraints. The proposed algorithm is the utilization of a Lagrangian function (loss function plus constraint function) as its objective function. The authors considered various types of constraints — binary, ternary, one-bit shift, and two-bit shifts weight constraints. "
SP:3ddf8e2e108fb261bb23aec8a27a25aba7523dc1,"This paper studies active learning with Gaussian process classification (GPC). The authors propose a new active learning algorithm for GPC. The main contribution of the paper is to derive the joint predictive distribution of label pairs as a one-dimensional integral, as a result of which the computation of the acquisition function avoids retraining the GPC for each query, remarkably reducing the computational overhead. The authors also derive the gradient chain rule to efficiently calculate the gradient of acquisition function. The proposed algorithm is evaluated on both synthetic and real-world datasets."
SP:fa1fac04cd4ccb1f3eaf80807db09f9683ce6b50,"This paper studies the effect of unbounded gradients on the regularization of a broad class of autoencoder-based architectures, including VAE models, as applied to data lying on or near a low-dimensional manifold (e.g., natural images). The main finding is that, if the ultimate goal is to simultaneously avoid over-regularization (high reconstruction errors, sometimes referred to as posterior collapse) and underregularisation (excessive latent dimensions are not pruned from the model), then an autoencoders-based energy function with infinite gradients around optimal representations is provably required per a certain technical sense which we carefully detail. Given that both overand under-regularisation can directly lead to poor generated sample quality or suboptimal feature selection, this result suggests that heuristic modifications to or constraints on the VAE energy function may at times be ill-advised."
SP:2611cfd6e0696a57d061687993cef1fe5c95999d,"This paper studies the bandit problem with graph feedback. The authors propose the notions of the fractional weak domination number δ∗ and the k-packing independence number Ω, which capture upper bound and lower bound for the regret respectively. They show that the two notions are inherently connected via aligning them with the linear program of the weakly dominating set and its dual, and show that a general regret upper bound O(\delta^3/\epsilon^3) can be obtained. Moreover, they show that for several special families of graphs, they can get rid of the (log |V |) 1 3 factor and establish optimal regret."
SP:e50dec57af337839cbde4b65fb7b431785fda44d,"The paper proposes to use neighbourhood reference distributions to improve the interpretability of Shapley values for model agnostic feature attributions by simulating feature absence under a global population distribution. The authors show that the Nadaraya-Watson estimator, a well-studied kernel regressor, can be expressed as a self-normalised importance sampling estimator. Empirically, they observe that Neighbourhood Shapley value identify meaningful sparse feature relevance attributions that provide insight into local model behaviour, complimenting conventional Shapley analysis. "
SP:35bdeb78f9fe74e754177fb54b48e7399dc8590d,"This paper proposes a novel method, called PlayVirtual, which augments cycle-consistent virtual trajectories to enhance the data efficiency for RL feature representation learning. Specifically, PlayVirtual predicts future states in a latent space based on the current state and action by a dynamics model and then predicts the previous states by a backward dynamics model, which forms a trajectory cycle. Based on this, the authors augment the actions to generate a large amount of virtual state-action trajectories. The authors validate the effectiveness of their designs on the Atari and DeepMind Control Suite benchmarks."
SP:ca09e472cbcf2ac8c8c9b192a87df2ed59218210,"This paper proposes a framework for measuring the robustness of a neural network to noisy labels. The framework is based on the notion of predictive power in its representations, which is the test performance of a linear model trained on the learned representations using a small set of clean labels. In particular, the authors show that a network is more robust if its architecture is more aligned with the target function than the noise. The authors provide both theoretical and empirical evidence to support their hypothesis."
SP:903727fe028684623a8ccadec210e641ecffc685,"This paper proposes a new method for learning a reward function from examples of successful outcomes. The proposed method is based on a data-driven Bellman equation, where examples take the place of the typical reward function term. The authors derive a control algorithm that maximizes the future probability of these successful outcome examples. Experiments show that their approach outperforms prior methods that learn explicit reward functions."
SP:39ccbd5909a1d7ed212fe92d8d6843c2c70dfe1f,"This paper studies differentially private stochastic optimization in convex and non-convex settings. For the convex case, the authors focus on the family of non-smooth generalized linear losses (GLLs). The authors provide the first nearly dimension independent rate, Õ ( log d (nε)1/3 ) in linear time. The authors also provide a linear-time algorithm for the constrained l2-case with smooth losses. "
SP:99a476f71e6901aefe281f11fb72ff78265a5b6e,"This paper studies the cooperative bandit problem under stochastic time-varying networks, instantaneous reward sharing over a network with random delays, and adversarially corrupted rewards. The authors propose decentralized algorithms that achieve competitive performance, along with near-optimal guarantees on the incurred group regret as well. "
SP:d3e896a65470f2439bc7753b4f66e152306b2d6f,"This paper proposes a post-training quantization algorithm for reducing the memory storage and computational costs of vision transformers. To preserve the functionality of the attention mechanism, the authors introduce a ranking loss into the conventional quantization objective that aims to keep the relative order of the self-attention results after quantization. Moreover, they thoroughly analyze the relationship between quantization loss of different layers and the feature diversity, and explore a mixedprecision quantization scheme by exploiting the nuclear norm of each attention map and output feature. The effectiveness of the proposed method is verified on several benchmark models and datasets. "
SP:aa6b1328585b5916267a3ff4f9119e7aa4ce2bb5,"This paper studies the convergence of double Q-learning with a constant learning rate. The authors show that synchronous double Q learning attains an accurate global optimum with a time complexity of $\epsilon$-accurate global optimum, and the asynchronous algorithm achieves a time-consistency complexity of $L$-accelerated global optimum. In addition, the authors provide new analytical tools that improve the existing convergence rate by orders of magnitude. "
SP:04fd4d83717c4f7e1a4b5651a59200151f33411d,This paper studies semi-supervised OOD detection. The authors introduce a new technique called Structure-Keep Unzipping (STU) to improve the detection performance. The STU method learns a new representation space in which OOD samples could be separated well. An efficient optimization algorithm is derived to solve the objective. 
SP:6bf8b94483b26033795b0eda9649518027f5e1c2,"This paper proposes a transformer-based framework for visual grounding tasks. Specifically, two modalities are fused in a visual-lingual encoder. In the decoder, the model learns to generate contextualized lingual queries which are then decoded and used to directly regress the bounding box and produce a segmentation mask for the corresponding referred regions. Extensive experiments and ablations illustrate that the model benefits greatly from contextualized information and multi-task training."
SP:29b552b36696c9bda72f3ab4f31605d98880fd6b,"This paper studies the problem of multiclass boosting with a possibly large number of classes or categories. In particular, the weak learner is assumed to belong to an easy-to-learn base class, and the booster is an agnostic PAC learner for that class with respect to the standard classification loss. The authors study the resources required for boosting, especially how they depend on the number of class k, for both the booster and weak learners. They also prove a trade-off between number of oracle calls and the resource required of the weak learners, meaning that the fewer calls to the weaker learner the more that is demanded on each call."
SP:f63b050773871338c48b778c362172e4b72477a4,"This paper proposes an embedding-based approach for unsupervised object segmentation and interpretable object-centric scene generation. The proposed method is based on a stochastic stick-breaking process, where the embeddings of pixels are clustered in a differentiable fashion using a Stochastic Stick-breaking Process (SSP). The method is used to develop a new model, GENESIS-V2, which can infer a variable number of object representations without using RNNs or iterative refinement. Experiments on synthetic and real-world datasets demonstrate the effectiveness of the proposed method."
SP:408deb9e5577ee7118b836fee77135df641fe545,This paper proposes an adaptive conformal inference method for online prediction sets where the data generating distribution is allowed to vary over time in an unknown fashion. The authors propose to model the distribution shift as a learning problem in a single parameter whose optimal value is varying over time and must be continuously re-estimated. The adaptive approach provably achieves the desired coverage frequency over long-time intervals irrespective of the true data generating process. 
SP:e6e5b1e2428abcf1a163ec1cce15cd299f9a544f,"This paper proposes a Pose-level Inference Network (PINet) that is free of bounding box detection and keypoint grouping. PINet first applies the Part-based Pose Generation (PPG) to infer multiple coarse poses for each person from his/her body parts. Those coarse poses are refined by the Pose Refinement module through incorporating pose priors, and finally are fused in the Pose Fusion module. Experiments on several crowded scenes pose estimation benchmarks demonstrate the superiority of PINet."
SP:e76f048c3dccffcb8bcc6a66f6165fc19d175610,"This paper proposes a fast, exact algorithm for computing the Bellman operator for S-rectangular robust Markov decision processes with L∞-constrained rectangular ambiguity sets. The algorithm combines a novel homotopy continuation method with a bisection method to solve S-Rectangular ambiguity in quasi-linear time in the number of states and actions. The proposed algorithm improves on the cubic time required by leading general linear programming methods. "
SP:c4af66a64a5c2bd58ca2e29dbc4b27d5bf4b63b8,This paper studies the online knapsack problem with very weak predictions: in the form of knowing an upper and lower bound for the number of items of each value. The authors systematically derive online algorithms that attain the best possible competitive ratio for any fixed prediction. 
SP:1d478d4fa3f5df0ded963ef164325667fd744dbb,"This paper proposes a new model-based episodic memory of trajectories addressing current limitations of episodic control. The memory estimates trajectory values, guiding the agent towards good policies. The authors also construct a complementary learning model via a dynamic hybrid control. Experiments demonstrate that the proposed model allows significantly faster and better learning than other strong reinforcement learning agents across a variety of environments including stochastic and non-Markovian settings. "
SP:551174c1266b5f4b6aaf5432a4c713386f90898c,"This paper proposes a semi-supervised learning method called DP-SSL that adopts an innovative data programming (DP) scheme to generate probabilistic labels for unlabeled data. Different from existing DP methods that rely on human experts to provide initial labeling functions (LFs), the proposed method uses multiple-choice learning (MCL) based approach to automatically generate LFs from scratch in SSL style. With the noisy labels produced by the LFs, the authors design a label model to resolve the conflict and overlap among the labeled labels, and finally infer probablistic labels. Extensive experiments on four standard SSL benchmarks show that DP- SSL can provide reliable labels and achieve better classification performance on test sets than existing SSL methods."
SP:d1d6a40a8bde62a21da4fc18a076e344c84ab0d0,This paper proposes a multi-view Pose Transformer (MvP) for estimating multi-person 3D poses from multiple-view images. The proposed method is based on a hierarchical scheme to concisely represent query embeddings of multiple-person skeleton joints and introduces an input-dependent query adaptation approach. MvP also introduces a RayConv operation to integrate the view-dependent camera geometry into the feature representations for augmenting the projective attention. Experiments show that the proposed method outperforms the state-of-the-art methods on several benchmarks. 
SP:2e147bd5321e25bb27d2531fd58c46460a1e5320,"This paper studies the problem of support recovery and approximate recovery in the context of 1-bit compressed sensing. The main contribution of the paper is to prove the existence of learning algorithms for the first problem which work without any assumptions. Under a mild structural assumption on the unknown vectors, the authors also show the existence for the second problem and rigorously analyze their query complexity."
SP:e3388e479a825be429f3a878e2c4d8b05903ff10,"This paper studies the changepoint detection problem, where sensing actions (or sensors) are sequentially chosen, and only measurements corresponding to chosen actions are observed. The authors derive an information-theoretic lower bound on the detection delay for a general class of finitely parameterized probability distributions. They then propose a computationally efficient online sensing scheme, which seamlessly balances the need for exploration of different sensing options with exploitation of querying informative actions. Experiments on synthetic and real datasets demonstrate the effectiveness of the proposed method. "
SP:268260e9452ba2bc57e50a6b7b3328233137ac9b,"This paper proposes a new method for solving stochastic nested optimization problems. The main idea is to combine several SGD-type updates (potentially on multiple variables) into a single SGD approach that is called ALternating Stochastic Gradient dEscenT (ALSET) method. By leveraging the hidden smoothness of the problem, this paper presents a tighter analysis of ALSET for solving the nested problems. Under the new analysis, to achieve an -stationary point of the nested problem, it requires O( −2) samples in total. Under certain regularity conditions, applying the proposed method to stochiastic compositional, min-max, and reinforcement learning problems either improves or matches the best-known sample complexity in the respective cases."
SP:82ad52361bc5b2c421f1dc6b76e1a5520570fc6c,"This paper proposes a Siamese Sampling and Reasoning (SiaSamRea) approach, which consists of a siamese sampling mechanism to generate sparse and similar clips from the same video, and a novel reasoning strategy for integrating the interdependent knowledge between contextual clips into the network. The reasoning strategy consists of two modules: (1) siamesed knowledge generation to learn the inter-relationship among clips; (2) Siameses knowledge reasoning to produce the refined soft label by propagating the weights of inter-relation to the predicted candidates of all clips. Extensive experiments demonstrate the effectiveness of the proposed method."
SP:160022e2cd61159da92f92e85520b7062a337a8d,"This paper proposes a method to reduce the computational and memory complexity of a large class of structured models. The proposed method is based on a matrix-vector product and uses a low-rank constraint to trade off model expressivity and speed via the rank. Experiments are conducted on language modeling, polyphonic music modeling, unsupervised grammar induction, and video modeling."
SP:238592ad73927194cdf0c0cf9ae2e48ca86e182c,"This paper proposes a new uncertainty measure for contextual bandits. The proposed measure, Sample Average Uncertainty (SAU), is a frequentist approach that directly estimates the uncertainty of the outcomes based on the value predictions. The authors show theoretically that the uncertainty measure estimated by SAU asymptotically matches the uncertainty provided by Thompson Sampling, as well as its regret bounds. Experimental results show that SAU-based exploration outperforms current state-of-the-art deep Bayesian bandit methods. "
SP:ffc5b18f7e18607b2934e5aa199e7542005d79f4,"This paper proposes a new method for learning behavioral embeddings from unlabeled, multi-view, high-resolution behavioral videos across different animals and multiple sessions. The key idea is to disentangle the dynamic behavioral factors (pose) from time-invariant, non-behavioral nuisance factors (context) in a deep autoencoder, and exploit the temporal structures of pose dynamics. The authors further combine DBE with a stochastic temporal model to propose Variational Disentangled Behavior Embedding (VDBE), an end-to-end approach that learns meaningful discrete behavior representations and generates interpretable behavioral videos. "
SP:bf78a450e4aad6b87fdeb8ec0d68adaaff7b595b,This paper proposes a deep 3D conditional generative model that can synthesize high-resolution 3D shapes using simple user guides such as coarse voxels. It marries the merits of implicit and explicit 3D representations by leveraging a novel hybrid 3D representation. The core of DMTET includes a deformable tetrahedral grid that encodes a discretized signed distance function and a differentiable marching tetrahedra layer that converts the implicit signed distance representation to the explicit surface mesh representation. This combination allows joint optimization of the surface geometry and topology as well as generation of the hierarchy of subdivisions using reconstruction and adversarial losses defined explicitly on the surface mesh. 
SP:2bc0bd6aa2a12691b16145f0d23542c4c86e3a44,"This paper proposes sliced mutual information (SMI) as a surrogate measure of statistical dependence. SMI is defined as an average of MI terms between one-dimensional random projections. The authors show that it preserves many of the structural properties of classic MI, while gaining scalable computation and efficient estimation from samples. Furthermore, and in contrast to classic MI can grow as a result of deterministic transformations. "
SP:e220b348901b476c2afd95f97630fb5400582f40,"This paper proposes a computationally efficient two-step lookahead constrained Bayesian optimization acquisition function (2-OPT-C) supporting both sequential and batch settings. To enable fast acquisition function optimization, the authors develop a likelihoodratio-based unbiased estimator of the gradient of the optimal acquisition function that does not use the reparameterization trick. In numerical experiments, the proposed method improves query efficiency by 2x or more over previous methods."
SP:51fbd861422647912f275b48861ea3c4812afdc8,"This paper proposes Multi-Dimensional Distributional DQN (MD3QN), which extends distributional RL to model the joint return distribution from multiple reward sources. The authors prove the convergence for the joint distributional Bellman operator and build an empirical algorithm by minimizing the Maximum Mean Discrepancy between joint return distributions and its Bellman target. In experiments, the authors show that the proposed method accurately models the joint returns in environments with richly correlated reward functions, and outperforms previous RL methods utilizing multi-dimensional reward functions in the control setting."
SP:1f85c93d6bbfd65bf497c92c9cd534d799753097,"This paper proposes a new geometric deep learning model, called CorticalFlow, that learns to deform a reference template towards a targeted object. To conserve the template mesh’s topological properties, the model is trained over a set of diffeomorphic transformations. To reduce topological errors introduced by its discrete resolution, the authors derive numeric conditions which improve the manifoldness of the predicted triangle mesh.   "
SP:2f31d9cf4ad17ad08344439ca0aef7ec91944545,"This paper proposes a general reduction from deletion guarantees against adaptive sequences to deletion guarantees for non-adaptive sequences, using differential privacy and its connection to max information. The authors show in theory how prior work for nonconvex models fails against adaptive deletion sequences, and use this intuition to design a practical attack against the SISA algorithm of Bourtoule et al. "
SP:7150006590e268ab732c9be6c9048f67a377f956,This paper studies the problem of risk-averse Bayes-adaptive reinforcement learning. The authors propose a two-player stochastic game and propose an approximate algorithm based on Monte Carlo tree search and Bayesian optimisation. The experiments demonstrate that their approach significantly outperforms baseline approaches for this problem.
SP:a94f39406f73d7483ddd744ed2f03c78b8bc5d44,"This paper studies the behavior of shallow ReLU networks trained with the logistic loss via gradient descent on binary classification data where the underlying data distribution is general, and the (optimal) Bayes risk is not necessarily zero. In this setting, it is shown that gradient descent with early stopping achieves population risk arbitrarily close to optimal in terms of not just logistic and misclassification losses, but also in terms calibration, meaning the sigmoid mapping of its outputs approximates the true underlying conditional distribution arbitrarily finely. Moreover, the necessary iteration, sample, and architectural complexities of this analysis all scale naturally with a certain complexity measure of the true conditional model. "
SP:a9c786cbb61e1f10f3542161b13e43a1a68ab34d,"This paper proposes a method for coordinated group detection on social media. The proposed method combines neural temporal point process with prior knowledge such as temporal logic or pre-defined filtering functions. Specifically, the authors jointly learn a Gibbs distribution of group assignment based on how consistent an assignment is to the account embedding space and the prior knowledge. To address the challenge that the distribution is hard to be efficiently computed and sampled from, they design a theoretically guaranteed variational inference approach to learn a mean-field approximation for it. Experimental results on a real-world dataset show the effectiveness of the proposed method compared to state-of-the-art model in both unsupervised and semi-supervised settings."
SP:b5c6e967a26a02861db2ecd620e9061db0c03e59,"The paper studies the problem of binary classification with non-linear data. The authors show that when the network depth is large relative to certain geometric properties that set the difficulty of the problem and the network width and number of samples are polynomial in the depth, randomly-initialized gradient descent quickly learns to correctly classify all points on the two curves with high probability. The paper also shows that the NTK can be locally approximated by a translationally invariant operator on the manifolds and stably inverted over smooth functions. "
SP:8f6bee3be43df6b6e80804974014caaafe08c49e,"This paper proposes a new auxiliary classifier GAN, called ReACGAN, for conditional GANs. The main idea is to replace the softmax cross-entropy loss in ACGAN with a data-to-data cross entropy loss. The authors show that the proposed method can achieve state-of-the-art generation results on CIFAR10, Tiny-ImageNet, CUB200, and ImageNet datasets. "
SP:080e80746a87228b156408ff649ab7a17f44e92d,"This paper proposes an extensive-form double oracle algorithm for two-player zero-sum games that is guaranteed to converge to an approximate Nash equilibrium linearly in the number of infostates. The authors also introduce Neural XDO, where the best response is learned through deep RL. Experiments on a modified Leduc poker game and Oshi-Zumo show that tabular XDO achieves a lower exploitability than CFR with the same amount of computation. "
SP:bda04facef4f34679fc4e17b8ea1aae74c3d649f,"This paper proposes a permutation-invariant variational autoencoder for graph structured data. The proposed model indirectly learns to match the node order of input and output graph, without imposing a particular node order or performing expensive graph matching. The authors demonstrate the effectiveness of the proposed model for graph reconstruction, generation and interpolation."
SP:e17ea6aeba78c9dfc25596d8b35a2a4f1f1f6763,"This paper proposes to decouple the depth and scope of GNNs to generate representation of a target entity (i.e., a node or an edge), and then apply a GNN of arbitrary depth on top of the subgraph. The authors claim that the proposed method improves the expressive power from the perspectives of graph signal processing (GCN), function approximation (GraphSAGE) and topological learning (GIN). Empirically, on seven graphs (with up to 110M nodes) and six backbone GNN architectures, the authors achieve significant accuracy improvement with orders of magnitude reduction in computation and hardware cost. "
SP:4890f251db559a0a572afc66e0c1f899b577d9ff,"This paper studies the universal approximation of affine-coupling normalizing flows. In particular, the authors show that any log-concave distribution can be approximated using well-conditioned affine coupling flows. The authors also provide theoretical evidence for the benefits of Gaussian padding when training affine flows. "
SP:5ffa81488ed1092deb89bd5e150fa146325057ce,"This paper proposes a budget constrained offline reinforcement learning and evaluation with λ-generalization (BCORLE(λ)) framework. The proposed method can help enterprises develop a coupons allocation policy which greatly improves users’ retention rate on the platform while ensuring the cost does not exceed the budget. Specifically, the proposed method is proposed to lead the policy learning process can be executed according to different λ values adaptively, avoiding re-learning new polices from scratch. "
SP:6b04cc7b4e45b9e65a1d34c15e3f75a2ef27d601,"This paper proposes a method for domain adaptation (DA) where the source pretrained model is adapted to the target domain in the absence of source data. The proposed method is based on the observation that target data, which might no longer align with the source domain classifier, still forms clear clusters. To capture this intrinsic structure, the authors define local affinity of the target data and encourage label consistency among data with high local affinity. The authors observe that higher affinity should be assigned to reciprocal neighbors, and propose a self regularization loss to decrease the negative impact of noisy neighbors. Furthermore, to aggregate information with more context, they consider expanded neighborhoods with small affinity values. "
SP:ac1bf04ff782e5892a0bc5fe5949848ca8e731c2,"This paper proposes a new pooling mechanism for learning representations from set-structured data. The proposed method is based on an end-to-end trainable Euclidean embedding for sliced-Wasserstein distance. The method is evaluated on a wide variety of set-based data, including point-cloud, graph, and image classification tasks. "
SP:6cb2f0cbc076f8680cb00411790629f8e1478053,"This paper proposes a family of RNNs called SBO-RNNs that can be formulated using stochastic bilevel optimization (SBO). With the help of SGD, the authors convert the SBO problem into an RNN where the feedforward and backpropagation solve the lower and upper-level optimization for learning hidden states and their hyperparameters, respectively. The authors prove that under mild conditions there is no vanishing or exploding gradient in training SBO. "
SP:d3a4300e21ca215334f256f0467a428470548fe4,This paper studies the online problem of minimizing power consumption in systems with multiple power-saving states. The authors propose a learning-augmented online algorithm that makes decisions based on (potentially inaccurate) predicted lengths of the idle periods. The algorithm’s performance is near-optimal when predictions are accurate and degrades gracefully with increasing prediction error. 
SP:22aba6284123af0ecd6605ee4e89b351bd7e10a3,"This paper proposes a mathematical framework for quantifying the transferability in multi-source transfer learning problems, with both the task similarities and the sample complexity of learning models taken into account. In particular, the authors consider the setup where the models learned from different tasks are linearly combined for learning the target task, and use the optimal combining coefficients to measure the quantifiable transferability. Then, they demonstrate the analytical expression of this transferability measure, characterized by the sample sizes, model complexity, and the similarities between source and target tasks, which provides fundamental insights of the knowledge transferring mechanism and the guidance for algorithm designs. "
SP:0fb8dcf15e0d43547d566fdba7bc70b3bb600005,"The paper proposes a method for visual search. The method is based on the observation that there is an asymmetry in visual search in humans, where finding a target A among distractors B can be easier than finding B among A. The authors argue that this phenomenon is due to the fact that humans have experience with the natural environment. To this end, the authors propose a model that takes a target and a search image as inputs and produces a sequence of eye movements until the target is found. The model integrates eccentricity-dependent visual recognition with target-dependent top-down cues. Experiments are conducted on augmented versions of ImageNet where the biases of natural images were either removed or reversed. "
SP:f0cc968ea9da4884dcdaf6d0c75ea9f1511bdfc3,This paper studies the problem of training certifiably robust models against adversarial examples. The authors identify another key factor that influences the performance of certifiable training: smoothness of the loss landscape. They propose a new method with the desired properties. 
SP:a158f8772a9dada059ffd1d6d7838ed40d8483da,This paper studies the problem of online linear regression in the stochastic setting. The authors derive high probability regret bounds for online ridge regression and the forward algorithm. They also provide numerical experiments to illustrate their results and endorse their intuitions. 
SP:17ff9a2133aebf2d1b1787e8efc49d709389c0e7,This paper proposes a two-time-scale variant of the extragradient (EG) method for nonconvex-nonconcave problems. The main idea is to use an anchoring technique to speed up the convergence of the SGD. The authors show that the proposed method has a fast O(1/k) rate on the squared gradient norm. 
SP:4e38973033de24fc183c6112e1146f8eef0ddaea,"This paper studies the problem of uniformity testing for statistical data that consists of rankings over m items, where the alternative class is restricted to Mallows models. The authors show that uniform distribution can be distinguished from Mallows model with O(m 1/2) samples based on simple pairwise statistics, which allows us to test uniformity using only two samples, if m is large enough. In addition, the authors propose a central DP algorithm that requires O(max{1/✏0, 1/ p m}), where ✏0 is the privacy budget parameter. "
SP:99a835191a3ba8372e391b6d3316e9b68e543295,"This paper studies a general greedy score-based algorithm for learning directed acyclic graphs. Unlike edge-greedy algorithms such as the popular GES and hill-climbing algorithms, this algorithm is vertex greedy and requires at most a polynomial number of score evaluations. The authors provide new score functions and optimality conditions based on the duality between Bregman divergences and exponential families, which they explore in detail. They also show how recent polynomially-time algorithms for learning DAG models are a special case of this algorithm. Finally, they provide extensive experiments suggesting that this algorithm indeed optimizes the score in a variety of settings."
SP:b60989706296b963b6671c01f22384978a334be1,"This paper proposes a neural architecture dilation algorithm to improve the adversarial robustness of the backbone CNNs that have a satisfactory accuracy. Under a minimal computational overhead, the proposed dilation architecture is expected to be friendly with the standard performance of backbone CNN while pursuing adversarial adaptation. Experimental results on real-world datasets and benchmark neural networks demonstrate the effectiveness of the proposed algorithm to balance the accuracy and adversarial attacks. "
SP:77ed765e911a4e5f2bfba13cbd2403500a5d05e6,"This paper studies the problem of reward-free reinforcement learning with linear function approximation for episodic Markov decision processes (MDPs). In this setting, the agent interacts with the environment and collects samples without the reward. The authors propose a new provably efficient algorithm, called UCRL-RFE under the Linear Mixture MDP assumption, where the transition probability kernel of the MDP can be parameterized by a linear function over certain feature mappings defined on the triplet of state, action, and next state.  The authors show that to obtain an $\epsilon$-optimal policy for arbitrary reward function, UCRL -RFE needs to sample at most Õ(H5d2ε−2) episodes during the exploration phase. By constructing a special class of linear Mixtures MDPs, the authors also prove that for any reward-based algorithm, it needs to samples at least Ω̃(H2dε−1) episodes to achieve an ε optimal policy.  "
SP:28563ba0975f56ddb662cd46e85de78bb6024d36,"This paper proposes a method for forecasting taxi-ride counts information between departure and destination locations. The proposed method is based on shifting seasonal matrix factorization (SSMF), which can adaptively learn multiple seasonal patterns (called regimes), as well as switching between them. The method has the following properties: (a) it accurately forecasts future events by detecting regime shifts in seasonal patterns as the data stream evolves; (b) it works in an online setting, i.e., processes each observation in constant time and memory; (c) it effectively realizes regime shifts without human intervention by using a lossless data compression scheme; and (d) it is able to accurately forecast upcoming events on three real-world data streams. "
SP:e4bb07033001be4d04695ef058f426d49fe440be,"This paper proposes a neural network architecture for solving the non-linear assignment problem. The proposed architecture is based on the feature weaving layer, which is stacked to model frequent communication between elements in a parameter-efficient way. The experimental results show its impressive performance among the learning-based baselines. "
SP:8a559e21d45661eef427b310e5fe8488d5749137,"This paper studies the impact of various self-supervised learning proxy tasks on different architectures and threat models for 3D point clouds with adversarial training. Specifically, the authors study MLP-based (PointNet), convolution-based, and transformer-based 3D architectures. The authors show that local feature learning is desirable for adversarial robustness in point clouds since it limits the adversarial propagation between the point-level input perturbations and the model's final output. "
SP:657c5a1114c0d054b9e767d85990bbbb0492912d,The paper considers the problem of computing projections of close-by points over widely-prevalent submodular base polytopes B(f). The authors propose a toolkit to speed up the computation of projections using both discrete and continuous perspectives. They also adapt the away-step Frank-Wolfe algorithm to use this information and enable early termination. The theoretical results show orders of magnitude reduction in runtime.
SP:8dae43d6b5cebb7ef6c39437d997b390c2380536,"The paper considers the problem of learning the natural parameters of a k-parameter minimal exponential family from i.i.d. samples in a computationally and statistically efficient manner. The authors provide finite sample guarantees to achieve an (`2) error of α in the parameter estimation with sample complexity O(poly(k/α)) and computational complexity O(\sqrt{k})$. The authors also show that, at the population level, the proposed method can be viewed as the maximum likelihood estimation of a reparameterized distribution belonging to the same class of exponential family."
SP:4f9ddb697e86356fb293ef34a69ca3702c4e8164,This paper proposes a hybrid differentiable renderer that combines rasterization and ray-tracing for inverse graphics. The main idea is to combine the advantages of rasterisation and ray tracing to improve the performance of the renderer. The proposed method is evaluated on synthetic and real-world datasets. 
SP:6ac1c8556e7131939cc582f513bc9921470e1b09,This paper proposes a differentiable training method for the soft-argmax operation. The proposed method is based on a continuous formulation of the output distribution and develops a sampling process to approximate the expectation of the localization error. Experiments are conducted to demonstrate the effectiveness of the proposed method. 
SP:478c05c90090f9d80b72ac352c488073b45a5d8b,This paper proposes a directed graph data augmentation method called Laplacian perturbation and theoretically analyzes how it provides contrastive information without changing the directed graph structure. The proposed method is trained using multi-task curriculum learning to progressively learn from multiple easy-to-difficult contrastive views. Experiments on various benchmarks demonstrate the effectiveness of the proposed method.
SP:85b383d2f722f7bff438840e423f5cb4c67d5980,"This paper proposes a new benchmark for language grounding, called Symbolic Interactive Language Grounding (SILG), which unifies a collection of diverse grounded language learning environments under a common interface. The proposed benchmark consists of grid-world environments that require generalization to new dynamics, entities, and partially observed worlds (RTFM, Messenger, NetHack), as well as symbolic counterparts of visual worlds that require interpreting rich natural language with respect to complex scenes (ALFWorld, Touchdown). The authors propose the first shared model architecture for RL on these environments, and evaluate recent advances such as egocentric local convolution, recurrent state-tracking, entity-centric attention, and pretrained LM using SILG. "
SP:23c8db56f59f778fe812a5dd161f7a1f21c3cdba,"This paper proposes a sparse version of the Vision Transformer (V-MoE) that is scalable and competitive with the largest dense networks. The authors propose an extension to the routing algorithm that can prioritize subsets of each input across the entire batch, leading to adaptive per-image compute. The proposed method is applied to image recognition, where it matches the performance of state-of-the-art networks while requiring as little as half of the compute at inference time. "
SP:c5235f41dfb8b5cc478f11c5d5e0ab0b8676871e,"This paper studies the problem of training a 1-hidden-layer neural network with fewer than n (sample size) neurons when the activation is smooth. The authors prove that as long as the width m ≥ 2n/d (where d is the input dimension), its expressivity is strong, i.e., there exists at least one global minimizer with zero training loss. They also identify a nice local region with no local-min or saddle points, and prove that every KKT point is a nearly global optimizer. Finally, they show that projected gradient methods on this constrained formulation significantly outperform SGD for training narrow neural nets."
SP:0be529f5254afd59dcfa6b34a359c7037e7a8323,"This paper proposes a continuous mean-Covariance Bandit (CMCB) model to explicitly take into account option correlation. Specifically, in CMCB, there is a learner who sequentially chooses weight vectors on given options and observes random feedback according to the decisions. The agent's objective is to achieve the best trade-off between reward and risk, measured with option covariance. The authors propose novel algorithms with optimal regret (within logarithmic factors), and provide matching lower bounds to validate their optimalities. The experimental results also demonstrate the superiority of the proposed algorithms. "
SP:472a90bb175b0286765c5a47b040e1a58f594a05,"This paper proposes a non-commutative extension of Lee-Seung's Multiplicative Update (MMU) algorithm for computing positive semidefinite (PSD) factorization of a data matrix. The MMU algorithm ensures that updates remain PSD by congruence scaling with the matrix geometric mean of appropriate PSD matrices, and it retains the simplicity of implementation that the multiplicative update algorithm for nonnegative matrix factorization (NMF) enjoys. The authors show that under their update scheme the squared loss objective is non-increasing and fixed points correspond to critical points. "
SP:83abd6d149d88cc6e96cbc4d488e4fe9dc2a4fcb,"This paper proposes a meta-domain specific-domain invariant (mDSDI) framework for domain generalization (DG) that extends beyond the invariance view to further capture the usefulness of domain-specific information. Specifically, the authors propose to disentangle features in the latent space while jointly learning both domain-invariant and domainspecific features in a unified framework.  The authors empirically show that mDSDI provides competitive results with state-of-the-art techniques in DG. "
SP:4191474c75e2fedf514f0f3001a67a047eb74c30,This paper presents a method to improve the quality of image synthesis using diffusion models. The method is based on ablations. The authors show that the ablations can improve the FID of the diffusion model on unconditional image synthesis and conditional image synthesis. They also show that classifier guidance can help improve the sample quality. 
SP:fe3cab08596cde4c14ecf6fca8d0f95b02bab229,"This paper proposes a method to leverage out-of-distribution samples for improving few-shot learning. The proposed method is simple to implement, agnostic to feature extractors, lightweight without any additional cost for pre-training, and applicable to both inductive and transductive settings. Extensive experiments on various standard benchmarks demonstrate the proposed method consistently improves the performance of pretrained networks with different architectures."
SP:b1f65724926f136979829b7a6c870bc31f38f591,"This paper proposes two new algorithms for prioritized sampling, ReMERN and ReMERT, which are based on the regret minimization objective. The main idea is to use the Bellman update to optimize the return of the policy. The authors also provide theoretical justifications for previous criteria, and propose two new methods to compute the prioritization weight. The experiments on MuJoCo, Atari and Meta-World demonstrate the effectiveness of the proposed algorithms."
SP:601ebf30b3c6aa35fcef49633aa8eb0acd0f2c66,"This paper studies the problem of sequential prediction with expert advice in a nonstationary environment with long-term memory guarantees in the sense of Bousquet and Warmuth [4]. The authors propose a linear-time algorithm that improves on the best known regret bounds [27]. This algorithm incorporates a relative entropy projection step in linear time, which may be of independent interest."
SP:b2439973063e827b3cbe92306a2fdee3286b6b44,"This paper studies the contextual linear bandits problem. The authors consider the setting where the learner has access to a set of possible actions, and the goal is to learn a hidden d-dimensional value w∗. In this setting, the authors propose two algorithms for solving the problem: 1) a cutting-plane algorithm with O(d log T) regret, and 2) a list size poly(d) algorithm. "
SP:abe83c7e0bcf4829742609d709637e2f84d8a4d9,"This paper introduces a small set of orthogonal combinators for composing machine learning operators into pipelines. It describes a translation scheme from pipelines and associated hyperparameter schemas to search spaces for AutoML optimizers. The paper also presents Lale, an open-source sklearn-compatible AutoML library."
SP:0d7f1cae577ed598048b64617e85ca6bd5c6d7fa,"This paper studies the effect of sparse gradient descent (SGD) on the generalization performance of meta-learning. The authors show that SGD can improve the performance of few-shot and continual learning problems by allowing the learning algorithm to decide which weights to change, i.e., by learning where to learn. They show that patterned sparsity emerges from this process, with the pattern of sparsity varying on a problem-by-problem basis. They also show that sparse learning also emerges in a more expressive model where learning rates are meta-learned."
SP:05037e1850003a725a466b64d3e32aa2aed458fb,"This paper proposes a new method for multi-view learning, called Shared Independent Component Analysis (ShICA) that models each view as a linear transform of shared independent components contaminated by additive Gaussian noise. The authors show that this model is identifiable if the components are either non-Gaussian or have enough diversity in noise variances. To solve this problem, the authors propose to use joint diagonalization after Multiset CCA, leading to a new approach called ShICA-J. The proposed method is based on second-order statistics, which is both more accurate and more costly. "
SP:44dd1faa1813c433fd7581d05cae3df440bfb93e,"This paper proposes a novel multi-agent reinforcement learning method called Fictitious Co-Play (FCP) to improve the generalization of agents to new human co-players. The proposed method is based on a two-player collaborative cooking simulator that has recently been proposed as a challenge problem for coordination with humans. The authors argue that the crux of the problem is to produce a diverse set of training partners. They train our agent partner as the best response to a population of self-play agents and their past checkpoints taken throughout training, a method they call FICTITIOUS CO-PLAY. They find that FCP agents score significantly higher than SP, PP, and BCP when paired with novel agent and human partners. "
SP:21c84bd720b1e90ea0f88fbf8fd24dbcb49b547c,"This paper proposes a new multi-agent actor-critic method, called FACMAC, which combines per-agent utilities into the joint action-value function via a non-linear monotonic function, as in QMIX. The authors also employ a nonmonotonic factorisation and empirically demonstrate that its increased representational capacity allows it to solve some tasks that cannot be solved with monolithic, or monotonically factored critics. In addition, FACMAC uses a centralised policy gradient estimator that optimises over the entire joint action space, rather than optimising over each agent's action space separately as in MADDPG."
SP:1c8351b8a6cdf1212840388e19a596729b3bfda4,"This paper proposes a biologically plausible model of long-term memory. The authors propose a key-value memory that stores inputs using a combination of biologically plausible three-factor plasticity rules. The proposed model performs on par with classical Hopfield networks on auto-associative memory tasks and can be naturally extended to continual recall, hetero-association memory, and sequence learning. "
SP:7ad6da2c63859d64970e9b35326e9ceab48add47,"This paper studies the problem of pairwise learning. The authors propose stochastic and online gradient descent methods for the problem. The main contribution of the paper is to develop novel stability results, optimization, and generalization error bounds for both convex and nonconvex problems. They also extend their algorithms and stability analysis to develop differentially private SGD algorithms for the pairwise setting. "
SP:cb11dacc930d71a616ee2fbe4acfae030f9dca59,"This paper proposes a new method to reconstruct the Dynamic Objects from RGBD or calibrated videos. The proposed method is based on a canonical 4D implicit function which is pixel-aligned with aggregated temporal visual cues, and a 4D transformation module which captures object dynamics to support temporal propagation and aggregation. The method is evaluated on synthetic RGBD video datasets SAIL-VOS 3D and DeformingThings4D++, and on real-world video data 3DPW."
SP:8ae97752e74b4395774575009031abcb6ba5cea7,"This paper provides a non-asymptotic analysis of linear stochastic approximation (LSA) algorithms with fixed stepsize. The authors derive high probability bounds on the performance of LSA under weaker conditions on the sequence {(An,bn) : n 2 N⇤} than previous works. In particular, the authors provide polynomial concentration bounds with order depending on the stepsize and the number of iterations. "
SP:86c1e937755e35efafecc09dfe2606ffb1653a41,"This paper extends the options framework for temporal abstraction in reinforcement learning from discounted Markov decision processes (MDPs) to average-reward MDPs. The authors provide general convergent off-policy inter-option learning algorithms, intra-option algorithms for learning values and models, as well as sample-based planning variants of their learning algorithms. They show the efficacy of the proposed algorithms with experiments on a continuing version of the Four-Room domain."
SP:7e4e1e20e7c253d02c6ae58457fb30029f130f0c,"This paper studies the robustness of visual transformers (VTs) in a small training set regime. The authors show that, despite having comparable accuracy when trained on ImageNet, their performance on smaller datasets can be largely different. They propose an auxiliary self-supervised task which can extract additional information from images with only a negligible computational overhead. The proposed task is used jointly with the standard (supervised) training and it does not depend on specific architectural choices, thus it can be easily plugged in the existing VTs. "
SP:0132ef17585e293b23e9dc45189c0989d829b52a,"This paper proposes a new method for label-free alignment of hierarchical datasets. The proposed method is based on the Riemannian geometry of the Lorentz model of hyperbolic space. The authors analyze the proposed method, its theoretical properties, stability and computational efficiency are demonstrated in simulations. "
SP:3580ac64f09e3021de5d4c92411bcc0f3c5d10f3,"This paper studies the trade-off between accuracy for a population of interest (sum query) and accuracy for its component sub-populations (point queries). Compared to differentially private query answering systems that are not required to produce microdata, accuracy can degrade by a logarithmic factor. The authors present lower bounds for pure, approximate, and concentrated differential privacy. They propose mitigation strategies and create a collection of benchmark datasets. "
SP:c0e64dc8acfaed3e4d7745af12fd34003d0e5017,"The paper proposes a method for learning a curriculum of tree-structured sub-tasks for goal-conditioned reinforcement learning (RL) and planning. The method is based on a top-down decomposition of a long-horizon task to a tree of sub-task sequences, and a bottom-up traversal of the tree is used to train the planner and the RL agent. The RL agent is trained to minimize the planner’s cost of completing the sequence in each layer from top to bottom layers, which gradually increases the sub-to-hard curriculum for the planner. The authors show that the method improves the success rate and sample efficiency. "
SP:9911693a04a300b5a93634fb0267ef83e5489d77,"This paper proposes a Bayesian framework for generating local explanations along with their associated uncertainty. The framework is instantiated to obtain Bayesian versions of LIME and KernelSHAP which output credible intervals for the feature importances. The authors carry out a detailed theoretical analysis that leverages the aforementioned uncertainty to estimate how many perturbations to sample, and how to sample for faster convergence. Experimental evaluation with multiple real world datasets and user studies demonstrate the efficacy of the proposed framework. "
SP:5efb4b81bd37c70640e8768e9dfb5bba14a0cfb8,"This paper studies the problem of heavy tails in Adder neural networks (ANNs). The authors show that unordered heavy tails are the key component which prevents ANNs from achieving superior classification performance since fatter tails tend to overlap in feature space. To alleviate this problem, the authors propose a novel method for tackling existing heavy tails with only a modification of classifier where ANN features are clustered with their tails wellformulated through proposed angle-based constraint on the distribution parameters to encourage high diversity of tails. Experiments on several benchmarks and comparison with other distributions demonstrate the effectiveness of proposed approach for boosting the performance of ANNs."
SP:cbccb65457564992d534504c0d060da44cafce8c,"This paper studies the phenomenon of gradient starvation in over-parameterized neural networks. In particular, the authors identify simple properties of learning dynamics during gradient descent that lead to this imbalance, and prove that such a situation can be expected given certain statistical structure in training data. The authors then develop a novel but simple regularization method aimed at decoupling feature learning dynamics, improving accuracy and robustness in cases hindered by gradient starvation. "
SP:8f6fe37cb0a332b66e10cc00261a44622841c8c6,"This paper presents a single-blind evaluation of teams of humans and AI agents in the cooperative card game Hanabi, with both rule-based and learning-based agents. In addition to the game score, the authors also quantify subjective measures of the human’s perceived performance, teamwork, interpretability, trust, and overall preference of AI teammate. The authors find that humans have a clear preference toward a rule based AI teammate (SmartBot) over a state-of-the-art learning based agent (Other-Play) across nearly all subjective metrics, despite no statistical difference in the game scores. "
SP:2a05e333fc1a14057515ef3addde9a40152373db,"This paper proposes a novel learning approach for visual question generation (VQG) by leveraging double visual and answer hints, which can be cast as a weakly supervised learning problem with noises. The key rationale is that the salient visual regions of interest can be viewed as a constraint to improve the generation procedure for producing high-quality questions. The proposed method is based on estimating the probability of being ground-truth questions, which in turn implicitly measures the quality of predicted visual hints. Experimental results on two benchmark datasets show that the proposed method outperforms the state-of-the-art approaches by a large margin on a variety of metrics. "
SP:15756d6ef47b39ded404acea2135c93bd5ee1062,"This paper proposes a method to mitigate label noise and class imbalance by manipulating gradients at the class level. Specifically, GDW unrolls the loss gradient to class-level gradients by the chain rule and reweights the flow of each gradient separately. The proposed method achieves remarkable performance improvement on both issues. "
SP:7a8f56a01bec51ebf70d9ff689005a62cccfe5c6,"This paper proposes a new task to learn spatio-temporal language grounding for embodied agents. The task is to learn the meaning of spatio temporal descriptions of behavioral traces of an embodied agent. The descriptions involve time-extended predicates in past and present tense as well as spatiotemporal references to objects in the scene. The authors train several models including multimodal Transformer architectures, and the latter implement different attention computations between words and objects across space and time. They test models on two classes of generalization: 1) generalization to randomly held-out sentences; 2) generalisation to grammar primitives. "
SP:3d4a9d439bc84c3b0e6600f6985a23bdf95cd67f,"This paper proposes Prototypical Cross-Attention Network (PCAN) for multiple object tracking and segmentation. PCAN first distills a space-time memory into a set of prototypes and then employs cross-attention to retrieve rich information from the past frames. To segment each object, PCAN adopts a prototypical appearance module to learn the contrastive foreground and background prototypes, which are then propagated over time. Extensive experiments demonstrate that PCAN outperforms current video instance tracking methods on both Youtube-VIS and BDD100K datasets. "
SP:1175ad16382b349ab1a39895150172d266abe571,"This paper studies the approximation of gradient descent to the initial value problem of gradient flow. The authors first show that the degree of approximation depends on the curvature around the gradient flow trajectory. They then show that over deep neural networks with homogeneous activations, gradient flow trajectories enjoy favorable curvature, suggesting they are well approximated by gradient descent. Finally, they show that gradient descent efficiently converges to global minimum almost surely under random initialization. "
SP:b8412e9ce82ce92125fe7cd3aff7bea8b906d16e,"The paper considers a stochastic multi-armed bandit problem with delayed impact of actions. In this setting, actions taken in the past impact the arm rewards in the subsequent future. The authors generalize the bandit setting to encode the dependency of this “bias” due to the action history during learning. They propose an algorithm that achieves a regret of Õ(KT 2/3) and show a matching regret lower bound of ⌦(KT2/3)."
SP:9c1d678dff5f609197dc3cfb67b841827f4a439a,"This paper proposes an end-to-end solution for video instance segmentation (VIS) based on transformers. Specifically, the authors propose Inter-frame Communication Transformers (IFC), which significantly reduces the overhead for information-passing between frames by efficiently encoding the context within the input clip. The authors propose to utilize concise memory tokens as a means of conveying information as well as summarizing each frame scene. The features of each frame are enriched and correlated with other frames through exchange of information between the precisely encoded memory tokens.  The authors validate their method on the latest benchmark sets and achieved state-of-the-art performance. "
SP:6c922eaa358f6fb9771690b1240e4f6f08a35b69,"This paper proposes a new method for graph embedding based on random walks. The proposed method, called residual2vec, debiases various structural biases in graphs by using random graphs. The authors show that this debiasing not only improves link prediction and clustering performance but also allows us to explicitly model salient structural properties in graph representation learning. "
SP:851eac96135b577a5014166edcb43db6a190cf4b,"This paper studies the problem of estimating non-linear functionals of discrete distributions in the context of local differential privacy. The authors show that the quadratic risk for estimating the power sum functional Fγ = ∑K k=1 p γ k, γ > 0 as a function of K, n and α. They also show two plug-in type estimators of Fγ, for all $\epsilon$ > 0."
SP:a0408b54f88a26479f33f36bb27e0a675f637ccd,"This paper studies the problem of online multiclass classification in a setting where the learner’s feedback is determined by an arbitrary directed graph. The authors prove surrogate regret bounds that hold, both in expectation and with high probability, for a large class of surrogate losses. In the full information case, they show that GAPPLETRON achieves a constant surrogate regret of order BK. They also prove a general lower bound of order max { BK, √ T} showing that their upper bounds are not significantly improvable. Experiments on synthetic data show that for various feedback graphs our algorithm is competitive against known baselines. "
SP:490262589efce6fb10b913431ec6db8d4e5b2dec,"This paper studies the problem of explainable clustering in the setting first formalized by Dasgupta, Frost, Moshkovitz, and Rashtchian (ICML 2020). A k-clustering is said to be explainable if it is given by a decision tree where each internal node splits data points with a threshold cut in a single dimension (feature), and each of the k leaves corresponds to a cluster. The authors give an algorithm that outputs an explainable cluster that loses at most a factor of O(log k) compared to an optimal (not necessarily explainable) clustering for the k-medians objective, and a factor for k-means objective. The algorithm is remarkably simple."
SP:6a9e47be710ddaf386bffc54d003d7dc2b67fdc3,"This paper proposes a multilingual language model (PrLM) that supports both explicit universal dependency parsing and implicit language modeling. Syntax in terms of universal dependency parse serves as not only pre-training objective but also learned representation in the model, which brings unprecedented PrLM interpretability and convenience in downstream task use. The proposed model outperforms two popular multilingual PrLM, multilingual-BERT and XLM-R, on cross-lingual natural language understanding (NLU) benchmarks and linguistic structure parsing datasets."
SP:94f4b65214a648cbc84f13beba45a825e2e9901a,"This paper proposes a dual-aspect Collaborative Transformer (DACT) to learn embeddings for the node and positional features separately, instead of fusing them together as done in existing ones, so as to avoid potential noises and incompatible correlations. Moreover, the positional features are embedded through a cyclic positional encoding (CPE) method to allow Transformer to effectively capture the circularity and symmetry of VRP solutions. The authors train DACT using Proximal Policy Optimization and design a curriculum learning strategy for better sample efficiency. The experiments show that DACT outperforms existing Transformer based improvement models and exhibits much better generalization performance across different problem sizes on synthetic and benchmark instances, respectively. "
SP:e5c8680d8da9e7548fcb9bb5c073848eb80e1dd0,"The paper proposes a method to compute the exact Bayes error of generative models learned using normalizing flows. The method relies on a fundamental result, which states that the Bayes errors are invariant under invertible transformation. The authors also show that by varying the temperature of the learned flow models, they can generate synthetic datasets that closely resemble standard benchmark datasets. Finally, the authors use their method to evaluate the intrinsic ""hardness"" of standard benchmark dataset. "
SP:2896679f0472522bc3334178cd7574494cf12b7b,"This paper proposes GradInit, an automated and architecture agnostic method for initializing neural networks. GradInit is based on a simple heuristic; the norm of each network layer is adjusted so that a single step of SGD or Adam with prescribed hyperparameters results in the smallest possible loss value. This adjustment is done by introducing a scalar multiplier variable in front of each parameter block, and then optimizing these variables using a simple numerical scheme. The proposed method accelerates the convergence and test performance of many convolutional architectures, both with or without skip connections, and even without normalization layers. "
SP:f69731403592fa5bdd4ca327708582d615aa131c,"This paper proposes a new method for estimating disease progression using longitudinal data. The proposed method is based on learning the metric from the data. Specifically, the authors learn the metric as the push-forward of the Euclidean metric by a diffeomorphism, which is estimated iteratively as the composition of radial basis functions belonging to a reproducible kernel Hilbert space. The metric update allows the authors to improve the forecasting of imaging and clinical biomarkers in the Alzheimer’s Disease Neuroimaging Initiative (ADNI) cohort. "
SP:438e906f52c4c0538956b51a2270b3ac498b27a8,"This paper proposes a routing-by-memory mechanism for existing CNN architectures. Specifically, it proposes parallel Procedural Units (PUs). A PU consists of a memory head and a procedure. The memory head maintains a summary of a type of features. For an intermediate feature, it searches its closest memory and forward it to the corresponding procedure in both training and testing. Experimental results show that the proposed method improves VGGNet, ResNet, and EfficientNet’s accuracies on Tiny ImageNet, ImageNet and CIFAR-100 benchmarks with negligible extra computational cost."
SP:d240173080cd3647dbaa5173a6422396f226775b,"This paper studies the equivariance property of polynomials under the symmetry of physical laws. The authors show that it is simple to parameterize universally approximating polynomial functions that are equivariant under these symmetries, or under the Euclidean, Lorentz, and Poincaré groups, at any dimensionality d. The key observation is that nonlinear O(d)-equivariant functions can be universally expressed in terms of a lightweight collection of scalars—scalar products and scalar contractions of the scalar, vector, and tensor inputs. "
SP:72c0f47566904deb27d8157da30807ec1d6b5685,"This paper proposes a new family of loss functions for bbox regression. The main idea is to generalize existing IoU-based losses to a power IoU term and an additional power regularization term with a single power parameter α. The authors analyze properties such as order preservingness and loss/gradient reweighting. Experiments on multiple object detection benchmarks and models demonstrate that α-IoU losses, 1) can surpass the IoU loss by a noticeable performance margin; 2) offer detectors more flexibility in achieving different levels of bbox accuracy by modulating α; and 3) are more robust to small datasets and noisy bboxes. "
SP:397125177d7007316d67194ec00d5dc57b44ac79,This paper studies distributionally robust imitation learning (DROIL) and establishes a close connection between DROIL and Maximum Entropy Inverse Reinforcement Learning. The authors develop a novel approach to transform the objective function into a convex optimization problem over a polynomial number of variables for a class of loss functions that are additive over state and action spaces.  The authors show that DROIL can be seen as a framework that maximizes a generalized concept of entropy. 
SP:58f220bbbed8d3e0633b408fca3b6838c4ad323d,"This paper proposes a general post-processing algorithm for individual fairness (IF) in algorithmic fairness, where the learner only has access to the predictions of the original model and a similarity graph between individuals guiding the desired fairness constraints. The authors cast the problem as a graph smoothing problem corresponding to graph Laplacian regularization that preserves the desired “treat similar individuals similarly” interpretation. The theoretical results demonstrate the connection of the new objective function to a local relaxation of the individual fairness. Empirically, the proposed algorithm correct individual biases in large-scale NLP models such as BERT. "
SP:ef791aa29decd839e7e583c9d1f71e8309ca87ef,"The paper proposes a structure-aware Dual Graph Aggregation Network (SADGA) for cross-domain Text-to-SQL. SADGA uses the graph structure to provide a unified encoding model for both the natural language question and database schema. Based on the proposed unified modeling, the authors further devise a structure aware aggregation method to learn the mapping between the question-graph and schema-graph. The proposed method is featured with global graph linking, local graph linking and DualGraph Aggregation Mechanism. "
SP:a2fa25a4539a38af61a0993f65ecc14339f26c2e,"This paper studies the problem of learning a stochastic computation graph with multiple sequential discrete components. The authors show that it is challenging to optimize the parameters of these models, mainly due to small gradients and local minima. To overcome these challenges, the authors propose two new strategies to overcome the challenges. First, increasing the scale parameter of the Gumbel noise perturbations during training improves the learning behavior. Second, they propose dropout residual connections to improve the learning performance. "
SP:bb3ec363e90269db4a2ba99d8107cb56f86e68f0,"This paper studies the problem of covariate shift in Bayesian inference. The authors show that Bayesian neural networks (BNNs) with high-fidelity approximate inference via full-batch Hamiltonian Monte Carlo achieve poor generalization under covariate shifts, even underperforming classical estimation. They also show why the same issue does not affect many approximate inference procedures, or classical maximum a-posteriori (MAP) training. "
SP:f86ec7042e9b73ae071704a6d3ed17d7e3da1b75,"This paper proposes a new meta-learning evaluation framework for few-shot classification. The proposed framework is based on the idea of out-of-distribution (OOD) evaluation. The authors show that most existing few shot classification benchmarks instead reflect OOD evaluation, as they use disjoint sets of train (base) and test (novel) classes for task generation.  The authors also show that in the OOD setting, even though current FSL benchmarks seem befitting, the authors highlight concerns in 1) reliably performing model selection, and 2) consistently comparing the performance of different methods. "
SP:371f77148b4f00a929f7c118b1bb7c5a6238d264,"This paper proposes an open rule induction problem, which aims to induce open rules utilizing the knowledge in LMs. The authors argue that, while KB-based methods inducted rules by discovering data commonalities, the current LM-based method are “learning rules from rules”. They propose the Orion (open rule induction) system to automatically mine open rules from LMs without supervision of annotated rules. They conducted extensive experiments to verify the quality and quantity of the inducted open rules. "
SP:8be2e0ea4a83fe32a4859f456007a829e5e9270a,This paper proposes an implicit constraint Q-learning (ICQ) algorithm for offline multi-agent RL. The main idea is to only trust the state-action pairs given in the dataset for value estimation. Experimental results demonstrate that the extrapolation error is controlled within a reasonable range and insensitive to the number of agents. 
SP:1939b24b68970c33ca16ce238deed257f76d009e,"This paper proposes a method to improve the robustness of machine learning models against adversarial attacks. The key idea is to enable non-uniform perturbations that can adequately represent these feature dependencies during adversarial training. The method is based on characteristics of the empirical data distribution, both on correlations between the features and the importance of the features themselves. Experiments show that the proposed method is more robust to real-world attacks. "
SP:417b30930b245667d777e5d90ee80dd41546760e,"This paper extends the theory of Tikhonov regularization to generalized self concordant loss functions (GSC), which contain, e.g., the logistic loss. The authors show that fast and optimal rates can be achieved for GSC by using the iterated Tikhonic regularization scheme, which is intrinsically related to the proximal point method in optimization."
SP:1caeee4f00b52fe356ff4e5dd004d0203e838370,"This paper introduces a new kind of linear transform named Deformable Butterfly (DeBut) that generalizes the conventional butterfly matrices and can be adapted to various input-output dimensions. DeBut is a drop-in replacement of standard fully connected and convolutional layers, and demonstrates its superiority in homogenizing a neural network and rendering it favorable properties such as light weight and low inference complexity, without compromising accuracy. The natural complexity-accuracy tradeoff arising from the myriad deformations of a DeBut layer also opens up new rooms for analytical and practical research. "
SP:d345ce1d7afc367ee1a9fb68d50ff1b2219f02cb,"This paper proposes a method to address the problem of catastrophic forgetting. The proposed method, called MetA Reusable Knowledge (MARK), keeps a set of shared weights among tasks. The shared weights are used as a common Knowledge Base (KB) that is not only used to learn new tasks, but also enriched with new knowledge as the model learns new tasks. A metalearning approach provides the key mechanism to incrementally enrich the KB with new information and to foster weight reusability. A set of trainable masks is used to selectively choose from the KB relevant weights to solve each task. Experiments show that the proposed method achieves state-of-the-art results in several popular benchmarks."
SP:722c52467e384058f8fdffa254d0e8db47440a64,This paper proposes a data-driven framework for scheduling primal heuristics in an exact MIP solver. The proposed framework learns a problem-specific schedule of primal heuristic that collectively finds many solutions at minimal cost. The authors formalize the learning task and propose an efficient algorithm for computing such a schedule. 
SP:5a21f0a49731dcb1d68deb06a75138e8e9d514d5,"This paper studies the problem of learning in a setting where the learner receives binary feedback only once at the end of an episode. This is an extreme test case for theory, but it is also arguably more representative of real-world applications than the traditional requirement in RL practice. The authors study the case where trajectory labels are generated by an unknown parametric model and provide a statistically and computationally efficient algorithm that achieves sublinear regret."
SP:e66bd9582058ba0f6091bb1042ce2ecfdaae1515,"This paper proposes a novel edge representation learning framework based on Dual Hypergraph Transformation (DHT), which transforms the edges of a graph into the nodes of a hypergraph. This dual hypergraph construction allows us to apply message-passing techniques for node representations to edges. After obtaining edge representations from the hypergraphs, we then cluster or drop edges to obtain holistic graph-level edge representations. Experiments are conducted on diverse graph datasets for graph representation and generation performance. "
SP:e398873e29b05176e1d52dc6f86a59a4f405e6fd,"This paper studies the sufficiency of a state representation for learning and representing the optimal policy, and study several popular MI based objectives through this lens. The authors find that two of these objectives can yield insufficient representations given mild and common assumptions on the structure of the MDP. They corroborate their theoretical results with empirical experiments on a simulated game environment. "
SP:50181f740910195d3a50dd7d7f8cbb1c476d730b,"This paper proposes a new steerable convolution method for 3D object semantic analysis. The proposed method is based on sparse tensors. The authors claim that the proposed method improves the performance of existing methods on three tasks: instance-level 6D pose estimation, category-level segmentation and size estimation, and category level pose tracking. "
SP:d746bfb200577c980d92727bb0b1a3c23e7bfdc5,"This paper proposes a dynamic token sparsification framework to prune redundant tokens progressively and dynamically based on the input. Specifically, a lightweight prediction module to estimate the importance score of each token given the current features. To optimize the prediction module in an end-to-end manner, an attention masking strategy to differentiably prune a token by blocking its interactions with other tokens. By hierarchically pruning 66% of the input tokens, the proposed method greatly reduces 31% ∼ 37% FLOPs and improves the throughput by over 40% while the drop of accuracy is within 0.5% for various vision transformers. "
SP:d0b6cde42b1cba5e6e3c7c5131426fd84adbd3d7,"This paper studies the problem of inference on the conditional mean E [Y |X], where the features X are continuously distributed. The authors show that any confidence interval for E [y |X] must have non-vanishing width, even as sample size tends to infinity. They also show that there are several distinct regimes in between the finite setting and the continuous setting, where the effective support size of the distribution of X is smaller than the square of the sample size. "
SP:123952325765c040c3078fc7dca2b6d370e55590,"This paper proposes Representation Neutralization for Fairness (RNF), a new bias mitigation method for DNN models. The proposed method is based on the idea of representation neutralization for fairness. The key idea of RNF is to discourage the classification head from capturing undesirable correlation between fairness sensitive information in encoder representations with specific class labels. To this end, the authors leverage samples with the same ground-truth label but different sensitive attributes, and use their neutralized representations to train the classification heads of the DNN model. The authors also leverage a bias-amplified model to generate proxy annotations for sensitive attributes. Experimental results over several benchmark datasets demonstrate the effectiveness of the proposed method."
SP:210eb2c811f966bb1ac53932cacabbad9bb608fe,"This paper proposes a new convolutional layer that takes advantage of Bessel functions, well known in physics, to build Bessel-CNNs (B-CNN) that are invariant to all the continuous set of possible rotation angles by design. The proposed B-CNN can be used for image classification and medical imaging applications. "
SP:ee51ecbd476d5b65903c942a62be89ff5d91698b,This paper proposes a new method for kernel ridge regression. The proposed method combines partitioning with random projections and iterative optimization to reduce space and time complexity while provably maintaining the same statistical accuracy. The authors also characterize the statistical-computational tradeoff of the proposed method.
SP:1f096d6fabd5b1fde43d06c552d46d87cd35cb4a,"This paper proposes a method for learning to communicate among agents via discrete tokens. The key idea is to use word embedding techniques from natural language processing, which enables them to communicate with discrete tokens derived from a learned, continuous space. The authors show in a decision theoretic framework that their method optimizes communication over a wide range of scenarios, whereas one-hot tokens are only optimal under restrictive assumptions. In self-play experiments, they validate that their trained agents learn to cluster tokens in semantically meaningful ways, allowing them communicate in noisy environments where other techniques fail. "
SP:8630ccc627534f9033bced04e2137a897ffef701,"This paper proposes CoAtNets, a family of hybrid models built from two key insights: (1) depthwise convolution and self-attention can be naturally unified via simple relative attention; (2) vertically stacking convolution layers and attention layers in a principled way is surprisingly effective in improving generalization, capacity and efficiency. Experiments show that CoAtNet achieves state-of-the-art performance under different resource constraints across various datasets. "
SP:d3ecbeeffa5ab365743ba8653c6739f24742ee31,"This paper proposes a new second-order oracle bound for the expected risk of a weighted majority vote. The bound is based on a novel parametric form of the Chebyshev-Cantelli inequality (a.k.a. one-sided Chebysheshv’s), which is amenable to efficient minimization. The authors also derive a new concentration of measure inequality, which they name PAC-Bayes-Bennett, and use it for empirical estimation of the oracle bounds. "
SP:5bac542a6532d43cf100e085398b4a4783719814,"This paper proposes a method for weakly supervised audio-visual video parsing. The proposed method exploits both the common and diverse event semantics across videos to identify audio or visual events. In addition, the proposed method explores event co-occurrence across audio, visual, and audio-video streams. The discovered supervisory signals across different videos and modalities can greatly facilitate the training with only video-level annotations."
SP:8fd6a03c1794afa524328d45f4232eacf6f86693,"This paper proposes a quantized and personalized federated learning algorithm QuPeD that facilitates collective (personalized model compression) training via knowledge distillation (KD) among clients who have access to heterogeneous data and resources. The authors propose an algorithm for learning quantized models through a relaxed optimization problem, where quantization values are also optimized over. For personalization, the authors propose a compressed personalization framework by introducing local client objectives collaborating through a global model. Experiments are conducted to validate the effectiveness of the proposed algorithm. "
SP:fca8b4f1e765cf1724a37f0ae9a7dac1cb79c8b1,"This paper proposes a new framework for constrained clustering. The proposed framework is based on the framework of stochastic gradient variational inference (SGVI). The authors propose to use a probabilistic framework to learn the underlying distribution of data conditioned on prior clustering preferences, expressed as pairwise constraints. The authors provide extensive experiments to demonstrate the effectiveness of the proposed framework. "
SP:84379c0c881b7390ecc22fb398edfaf66d1af1ff,"The paper proposes a near-input-sparsity time approximation algorithm for NTK, by sketching the polynomial expansions of arc-cosine kernels. The proposed method can transform any image using a linear runtime in the number of pixels. The authors also prove a spectral approximation guarantee for the NTK matrix, by combining random features (based on leverage score sampling) with a sketching algorithm. "
SP:fa2668083ff3bb592c29a4c6822ae96ff54d0dbe,"This paper proposes a multi-range Transformers model for 3D motion trajectory prediction. The model consists of a local-range encoder for individual motion and a global-range decoder for social interactions. The Transformer decoder then performs prediction for each person by taking a corresponding pose as a query which attends to both local and global-ranging encoder features. The proposed model not only outperforms state-of-the-art methods on long-term 3D-motion prediction, but also generates diverse social interactions by automatically dividing the persons into different interaction groups."
SP:0a0e07af37c8fe8580639b1df62d27b6f63f8dee,"This paper proposes a method to generate program synthesis for long-horizon planning problems. The method uses a generative model to predict the unobserved portions of the world, and then synthesizes a program based on samples from this model in a way that is robust to its uncertainty. The authors show that their method can obtain the benefits of program-guided reinforcement learning without requiring the user to provide a new guiding program for every new task. "
SP:5bb42b178b0d27da271bfa60e633fdac718638c4,"This paper studies the problem of causal imitation learning in sequential settings, where the imitator must make multiple decisions per episode. The authors develop a graphical criterion that is necessary and sufficient for determining the feasibility of causal imitability, providing conditions when an imitators can match a demonstrator's performance despite differing capabilities. Finally, the authors provide an efficient algorithm for determining imitability and corroborate their theory with simulations."
SP:85bd81f0c5b6ccbc421ebbaf6f5c72164bc70b7f,"This paper presents a slot-wise, object-based transition model that decomposes a scene into objects, aligns them (with respect to a slotwise object memory) to maintain a consistent order across time, and predicts how those objects evolve over successive frames. The model is trained end-to-end without supervision using transition losses at the level of the object-structured representation rather than pixels. The authors show that the combination of an objectlevel loss and correct object alignment over time enables the model to outperform a state-of-the-art baseline, and allows it to deal well with object occlusion and re-appearance."
SP:f32eddbb5c33a8422c075579ff08aa9833338d44,This paper studies the problem of learning a risk minimization algorithm for adaptive data. The authors propose a generic importance sampling weighted ERM algorithm for using adaptively collected data to minimize the average of a loss function over a hypothesis class and provide first-of-their-kind generalization guarantees and fast convergence rates. The main contribution is a new maximal inequality that carefully leverages the importance sampling structure to obtain rates with the good dependence on the exploration rate in the data.
SP:f549a0c231b71bae0acbed6e3afb41890ee89cd9,"This paper proposes a novel and coherent scheme for kernel-reweighted regression by reparametrizing the sample weights using a doubly non-negative matrix. When the weighting matrix is confined in an uncertainty set using either the log-determinant divergence or the Bures-Wasserstein distance, the adversarially reweighted estimate can be solved efficiently using first-order methods. Numerical experiments show that the reweighting strategy delivers promising results on numerous datasets. "
SP:fe12e13602925b9400fd596a987755beb10aa3d1,The paper proposes a new gradient estimator based on importance sampling and statistical couplings for categorical variables. The authors show that the proposed estimator outperforms the existing gradient estimators. The main contributions are: (1) The authors introduce a novel derivation of their estimator using importance sampling. (2) The proposed estimators are based on reparameterizing categorical variable as sequences of binary variables and Rao-Blackwellization. (3) They show that their estimators provide state-of-the-art performance.
SP:e16fdf963ec2f9c0d79fa404e47e7862a5d6e922,This paper proposes a new method for neural architecture search (NAS) based on weak predictor-based NAS. The proposed method is called WeakNAS. WeakNAS is based on the idea that weak predictors are more likely to sample better architectures than strong predictors. The authors show that the proposed method outperforms the state-of-the-art SOTA methods on NAS-Bench-101. 
SP:8f74abb04037ba2e59dcf8320dc555b149f68ed8,"This paper proposes a new method for learning a global coordinate system for learning an agent that is able to reach more states in the long term while still optimizing a local objective. The proposed method, Entropic Desired Dynamics for Intrinsic ConTrol (EDDICT), assumes fixed additive latent dynamics, which results in tractable learning and an interpretable latent space. The authors show that EDDICT's globally consistent codes allow it to be far more exploratory, as demonstrated by improved state coverage and increased unsupervised performance on hard exploration games such as Montezuma's Revenge."
SP:c731a78c3e7f98ccd0253b51a0d42bf8deeb71f9,This paper proposes a new method for generating molecules with large docking scores. The method is based on fragment-based generative RL with Explorative Experience Replay for Drug design (FREED) which constrains the generated molecules to a realistic and qualified chemical space and effectively explores the space to find drugs by coupling the fragment generation method and a novel error-prioritized experience replay (PER). The authors also show that their model performs well on both de novo and scaffold-based schemes. 
SP:b938bca513e7de1231212064caf8877a78d8b612,"This paper studies the problem of learning directed acyclic graphical models from observational data in general settings without specific distributional assumptions. The authors propose a local Markov boundary search procedure in order to recursively construct ancestral sets in the underlying graphical model. This substantially improves the sample complexity, which is at most polynomial in the number of nodes. "
SP:af08109d4c45dc9401efb0e63c22167e9da28adb,"This paper studies the problem of differential privacy (DP) in the setting where each user holds m samples and the privacy protection is enforced at the level of each user’s data. In this setting, the authors show that, as long as each user receives sufficiently many samples, we can learn any privately learnable class via an ("", )DP algorithm using only O(log(1/ )/"") users. For the local model, they show that they can learn using O""(d) users even in the probabilistic representation dimension. "
SP:da4f21d107a7f442c4d3e3ec13bdb44b041e07cf,"This paper studies the convergence rate of stochastic gradient descent (SGD) with implicit representations of value functions via theory and focused experimentation. The authors prove that, for a linear parametrization, gradient descent converges to global optima despite nonlinearity and non-convexity introduced by the implicit representation. Furthermore, they derive convergence rates for both cases which allow them to identify conditions under which SGD with this implicit representation converges substantially faster than its explicit counterpart. Finally, they provide empirical results in some simple domains that illustrate the theoretical findings."
SP:992aa07d4f815d1c81f967374590eece933833b1,"This paper proposes a method to improve the performance of knowledge graph (KG) refinement tasks. The proposed method is based on a combination of two existing methods, namely PSL-KGI and ConvE. The main contribution of the paper is that it combines the two methods in a co-training mode, which is called IterefinE.  The method is evaluated on a range of KG benchmarks and shows that it is able to reject noisy facts from KG and infer higher quality new facts. "
SP:676fc4a3041af22e8f20ccba7daa2a0b1f5d6af5,"The paper proposes a new benchmark for knowledge base completion (KBC) based on a novel evaluation data structure, FB14k-QAQ, where instead of single facts, the authors use KB queries, i.e., facts where one entity is replaced with a variable, and construct corresponding sets of entities that are correct answers. The authors randomly remove some of these correct answers from the data set, simulating the realistic scenario of real-world entities missing from a knowledge base (KB). The authors also propose a simple variant of TransE that encourages thresholding and achieves a significant improvement in classification F1 score relative to the original TransE. "
SP:83fe0a496a79bcf97ccba1c6d34b7d11e7d5c330,"This paper proposes a new dialog model called Alternating Roles Dialog Model (ARDM), which is based on a pre-trained language model. ARDM models each speaker separately and takes advantage of the large pretrained language model to generate human-like responses to persuasion tasks. It requires no supervision from human annotations such as belief states or dialog acts to achieve effective conversations. The proposed model outperforms or is on par with state-of-the-art methods on two popular task-oriented dialog datasets: CamRest676 and MultiWOZ. "
SP:b11c06b7c4ef1aa43c59f808a679425e302d158e,"The paper proposes a method to estimate the probability that the classification predicted by a deep neural network is correct (or in the Top 5) using the softmax values of the network. The authors define the notion of implied loss and prove that if an uncertainty measure is an implied loss, then low uncertainty means high probability of correct classification on the test set. The method is simple to use on existing networks: they proposed confidence measures for Top k which can be evaluated by binning values on the Test set. "
SP:ab9666e15f2a0113d96cb4b47b1cbb30fa1f7982,"This paper studies the generalization properties of deep neural networks at large depth. The authors first show that in the wide network limit, random networks before training are Gaussian processes governed by a kernel known as the Neural Network Gaussian Process (NNGP) kernel, and that at large depths the spectrum of the NNGP kernel simplifies considerably and becomes “weakly data-dependent”. Then, the authors show that gradient descent training of wide neural networks is described by the Neural Tangent Kernel (NTK) that is related to the NNNGP kernel. Finally, they perform a thorough empirical investigation of these theoretical results and finding excellent agreement on real datasets."
SP:d3470c35aae48bf92439a55fdb98ccf07100e567,"This paper proposes a graph-based method to estimate the quality of protein models. The proposed method, GRAPHQA, is based on the graph neural network (GNN) architecture. The main contributions of the proposed method are: 1. It is able to model both sequential and 3D structure, 2. It can be applied to both hand-engineered and representation-learning approaches, and 3. It shows significant improvements over the state-of-the-art."
SP:5188280131b58a35d3deda126a0754aea8fa6e58,"This paper studies the critical locus of the loss function of a linear neural network, which is determined by the geometry of the functional space and by the parameterization of this space by the network’s weights. The authors introduce a natural distinction between pure critical points and spurious critical points, which arise from the parameterisation. They use geometric properties of determinantal varieties to derive new results on the landscape of linear networks with different loss functions and different parameterizations. The analysis clearly illustrates that the absence of “bad” local minima in the loss landscape is due to two distinct phenomena that apply in different settings. "
SP:ee71597ceab23eb4db1d6608f15f80ad51f7ff6d,"This paper proposes a general framework SEED (Sampling, Encoding, and Embedding Distributions) for inductive and unsupervised representation learning on graph structured objects. The proposed framework samples a number of subgraphs whose reconstruction errors could be efficiently evaluated, encodes the subgraph samples into a collection of subGraph vectors, and employs the embedding of the subGraph vector distribution as the output vector representation for the input graph. By theoretical analysis, the authors demonstrate the close connection between SEED and graph isomorphism. "
SP:d9406fdf0a180a5efc6f15ba8739524665f0f9d2,"This paper proposes a new counterfactual regret minimization (CFR) algorithm, called Lazy-CFR, which adopts a lazy update strategy to avoid traversing the whole game tree in each round. The authors prove that the regret of Lazy CFR is almost the same as the vanilla CFR and only needs to visit a small portion of the game tree. Empirical results consistently show that LazyCFR is fast in practice."
SP:023aa3dca1cf7992b22993a7088e8a74c92bb47e,"This paper proposes a new unsupervised domain adaptation (UDA) method, called Distribution Matching Prototypical Network (DMPN) to model the deep features from each domain as Gaussian mixture distributions. The authors propose two new domain discrepancy losses with probabilistic interpretations. To learn both discriminative and domain invariant features, DMPN is trained by minimizing the classification loss on the labeled source data and the domain discrepancy loss together. Extensive experiments are conducted over two UDA tasks. "
SP:40be996e8bb86e887077b762b87c7c34a786ac98,This paper proposes a conditional continuous normalizing flow (CNF) model that partitions the latent space into a class-specific supervised code and an unsupervised code that is shared among all classes for efficient use of labeled information. The authors also propose a gating network to learn the error tolerances of its ordinary differential equation (ODE) solvers for better speed and performance. Experiments on CIFAR-10 show that the proposed model improves the test accuracy over the baseline while yielding comparable likelihood scores and reducing the NFEs.
SP:97764e3393216106ff2ac3f550845acf4636119f,"This paper studies the approximation of the value function for infinite-horizon discounted Markov Reward Processes (MRP) with nonlinear functions trained with the Temporal-Difference (TD) learning algorithm. The authors consider this problem under a certain scaling of the approximating function, leading to a regime called lazy training. In this regime the parameters of the model vary only slightly during the learning process, a feature that has recently been observed in the training of neural networks, where the scaling arises naturally, implicit in the initialization of their parameters. Both in the underand over-parametrized frameworks, the authors prove exponential convergence to local, respectively global minimizers of the above algorithm in the lazy training regime. "
SP:c518e4030f12b0f59ad1d7c0fc0ebd313c68ef95,"This paper proposes a method to train an agent to verify hypotheses about the dynamics of the world by generating observations to generate observations which can help predict whether the hypothesis is true or false. The authors use the underlying structure in the majority of hypotheses – they can be formulated as triplets (pre-condition, action sequence, post-condition). Once the agents have been pretrained to verify the hypotheses with this structure, they can fine-tuned to verify more general hypotheses. "
SP:6fa2f842b1bc993ed8024a3ce13dbd91529c61be,"This paper proposes a simple experiment to study whether neural networks can perform several steps of approximate reasoning in a fixed dimensional latent space. Specifically, the authors perform sequences of rewrite steps both in formula space and in latent space, and compare the quality of embeddings of the resulting formulas to their predicted latent representations. The experiments show that graph neural networks are able to make non-trivial predictions about the rewrite-success of statements, even when they propagate predicted latent representation for several steps. "
SP:a77ab500a5e7d4ea8430871d1e603941e92974fd,"This paper proposes a method for learning depth from images and very sparse depth measurements, just a few pixels per image. To learn from such extremely sparse supervision, the authors introduce an appropriate inductive bias by designing a specialized global-local network architecture. Experiments on several datasets show that the proposed method can learn monocular dense depth estimation when trained with very sparse ground truth, even a single pixel. Moreover, the global parameters extracted by the network are predictive of the metric agent motion."
SP:2afba5e24478da4e9d493887c7cf00e288cc0deb,"This paper extends the idea of word pieces in natural language models to machine learning tasks on opaque ids. This is achieved by applying hash functions to map each id to multiple hash tokens in a much smaller space, similarly to a Bloom filter. The authors show that by applying a multi-layer Transformer to these Bloom filter digests, they are able to obtain models with high accuracy. "
SP:745dd86d7f7bba79a02d27922003b764b620f83e,This paper proposes a learning-based agglomerative clustering framework for learning 3D parts for objects in unseen categories. The proposed method learns a grouping policy to progressively group small part proposals into bigger ones in a bottom-up fashion. Experiments show that the proposed method can transfer knowledge of parts learned from 3 training categories to 21 unseen testing categories without seeing any annotated samples.
SP:868fc6df740b04963442d5abcfe2f4845585cfc8,"This paper proposes a method for generating new samples outside of the manifold of the data that they are trained on. The method is based on the idea of neuron editing, which is a technique that learns how neurons encode an edit for a particular transformation in a latent space. The authors use an autoencoder to decompose the variation within the dataset into activations of different neurons and generate transformed data by defining an editing transformation on those neurons. By performing the transformation in the latent trained space, they encode fairly complex and non-linear transformations to the data with much simpler distribution shifts to the neuron’s activations. "
SP:6dee6932e64fe47bb44dd42fc242fa9d89b8d89c,"This paper studies the problem of few-shot image segmentation, where the goal is to produce dense, structured predictions given an arbitrary amount of training data for a new task. The authors extend the FOMAML and Reptile meta-learning algorithms (including FomAML, Reptile, and FOMMAML+) to image segmentations, and propose a novel neural network architecture built for parameter efficiency and fast learning which they call EfficientLab. They show that their network, with an empirically estimated optimal update procedure yields state-of-the-art results on the FSS-1000 dataset, while only requiring one forward pass through a single model at evaluation time. "
SP:ec6f390f6d45fb79c33ae5d9c8a24cadb96fbd60,"This paper proposes a new semi-supervised few-shot learning method, Prototypical Random Walk Networks (PRWN). The proposed method is built on top of Prototypesical Networks (PN) (Ren et al., 2018) and is able to learn representations that are compact and well-separated. The authors also show that their model is resistant to distractors, unlabeled data that does not belong to any of the training classes, and hence reflecting robustness to labelled/unlabelled class distribution mismatch. "
SP:d12e687bd2ee9fa60554312e644bb0a6487974f1,"This paper proposes a self-supervised training objective, Contrastive Sensor Fusion (CSF), which exploits coterminous data from multiple sources to learn useful representations of every possible combination of those sources. The proposed method uses information common across multiple sensors and bands by training a single model to produce a representation that remains similar when any subset of its input channels is used. Experiments show that CSF outperforms fully supervised ImageNet weights on a remote sensing classification task and improve as more sensors are fused."
SP:4d8e054f07006b4f896721b5c24da805727d2c22,This paper proposes a network-agnostic rewinding method for neural network pruning. The proposed method rewinds unpruned weights to their values from earlier in training and retrains them from there using the original training schedule using the same learning rate schedule. The authors compare the performance of the proposed method with the standard fine-tuning and weight-rewinding methods. 
SP:3bb1c79f9482e09828eda45fbb2e654f37219365,"This paper proposes a new notion of margin, called the ""all-layer margin"", for deep models. The authors show that the all-layer margins have a clear and direct relationship with generalization for deep model, and propose a theoretically inspired training algorithm for increasing the margin.   The authors also provide tighter generalization bounds for neural nets which depend on Jacobian and hidden layer norms and remove the exponential dependency on depth.  The proposed algorithm improves both clean and adversarially robust test performance over strong baselines. "
SP:3d44f27468087280e85dfb1fc7291db05179fe6d,This paper proposes a disentangled response decoder for knowledge-grounded dialogue generation. The key idea is to isolate parameters that depend on knowledge-based dialogues from the entire generation model. The proposed method is evaluated on two benchmark datasets. 
SP:9b555f7fe743f5effdbdc8701ed519ce3159c4b0,"This paper proposes a mirror-generative neural machine translation model (MGNMT) that simultaneously integrates the source to target translation model, the target to source translation model and two language models. The authors claim that the proposed MGNMT can learn from non-parallel data more effectively. Experiments show the effectiveness of the proposed model. "
SP:d7a530a0ec4112095a58cef4cda9646f8ca6449d,"This paper studies the effect of the entropy term in Soft Actor Critic (SAC) on the performance of maximum entropy reinforcement learning algorithms. The authors first show that SAC has a bounded nature of the action spaces. Then, the authors propose a simple non-uniform sampling method for selecting transitions from the replay buffer during training. The proposed method outperforms SAC and achieves state-of-the-art performance on challenging continuous control tasks."
SP:545e8da553fcb47d84eaa044d8a4947d3cd3230e,This paper studies the problem of adversarial attacks against industrial copyright detection systems. The authors propose to use a well-known music identification method and implement this system in the form of a neural net. They then attack this system using simple gradient methods. 
SP:b511822850da3bf1079a36ed6f5ad4db80fbc424,This paper proposes a new method for visual explanation of deep metric learning. The method is based on decomposing the final activation map of each image by decomposing it into a point-to-point activation intensity. The authors show that the proposed method can be directly deployed to a large range of metric learning applications and provides valuable information for understanding the model. 
SP:67bf71219fe6bedec5f5525200e734638e4a6ca2,"This paper studies the problem of learning control in an online lifelong learning scenario, where mistakes can compound catastrophically into the future and the underlying dynamics of the environment may change. The authors propose a new algorithm, Adaptive Online Planning (AOP), that achieves strong performance in this setting by combining model-based planning with model-free learning. AOP is able to call upon more extensive planning only when necessary, leading to reduced computation times. "
SP:11159cb878a436a5d4fc6edb4132f2cc3c1b3f72,"This paper proposes a new attention mechanism for image captioning. The proposed method, called TVMAX, replaces the softmax attention mechanism by two alternative sparsity-promoting transformations: sparsemax and total-variation Sparse Attention (TVMAX). With sparsemax, the authors obtain sparse attention weights, selecting relevant features. By selecting relevant groups of features, the TVMAX transformation improves interpretability. "
SP:fb0c3ce3db6ad674ddc615bdc6203cdcbe42c804,This paper proposes a model for predicting the evolution of dynamic graphs. The model is based on a graph neural network along with a recurrent architecture. The proposed model predicts the topology of the graph at the next time step and constructs a graph instance that corresponds to that topology. The authors evaluate the proposed model on several artificial datasets following common network evolving dynamics.
SP:ff722957a1765c0568426ed88dd910a6b74054ef,"This paper proposes a method for imputing missing features and estimating the distribution of target assignments given incomplete data. The method consists of a generator network to generate imputations that a discriminator network is tasked to distinguish. Then, a predictor network is trained using the imputed samples to capture the classification uncertainties and make predictions accordingly. The proposed method is evaluated on CIFAR-10 image dataset as well as three real-world tabular classification datasets."
SP:c051b0fe779d9e4131016970b7ba469b596f3009,This paper proposes a new method for estimating the importance ratio of stationary distributions. The method is based on reproducing kernel Hilbert spaces (RKHSs) and is shown to have asymptotic consistency and finite-sample generalization. Experiments on benchmarks verify the effectiveness of the method.
SP:065c900843011a71b70ed35357a2f71fe83872a7,"This paper proposes a modification of the Gaussian mixture model (MM) framework, where each of the modes is associated with a Gaussian distribution. The authors propose to compute the conditional likelihood p(x|k, θ) and the responsibility probability p(k|x, \tilde{k}) for each mode in the GMM framework, and to compute these probabilities at the data’s latent space z instead of x. They also propose a modified GAN to allow them to define the distribution using p(z|k) where z is the corresponding latent representation of x, as well as p(pk|z, \ta) through an additional classification network which is trained with the GAN in an “end-to-end” fashion. "
SP:2da1608209058d214f8671062cc9eb0833ba4831,"This paper proposes a method for training large capacity neural networks with significantly improved accuracy and lower dynamic computational cost. The method is based on a new residual block architecture that gates convolutional channels in a fine-grained manner. The authors also introduce a generally applicable tool batch-shaping that matches the marginal aggregate posteriors of features in a neural network to a pre-specified prior distribution. Experiments show that the proposed method can slim down large architectures conditionally, such that the average computational cost on the data is on par with smaller architecture, but with higher accuracy."
SP:f90e9f0eb53f92601bdfa3f7bf86f71d037aad30,"This paper proposes a probabilistic importance inference approach for pruning DNNs. Specifically, the authors test the significance of a connection in a DNN to the DNN’s outputs using a nonparemetric scoring test and keep only those significant ones. Experimental results show that the proposed approach achieves better lossless compression rates than existing techniques. "
SP:64cbbb6a2f6847ef71cd5a23ba3e4cc5c815a56e,"This paper proposes a method for learning a sequence of actions that can be compressed to yield a compact code of action trajectories. The proposed method is based on identifying behavioral ‘motifs’, which can be used to learn nested behavioral hierarchies of arbitrary depth, with actions of arbitrary length. The learned temporally extended actions provide new action primitives that can participate in deeper hierarchies as the agent learns. "
SP:e1ccfb3a684aef8a0fb36194eb16af1667811e81,"This paper proposes a probabilistic autoencoder for image generation. The proposed method is based on the Hierarchical Bayes Autoencoders (HBAE) framework, which is a variational inference framework. The main idea is to use an energy-based model (EBM) for the decoder and a conditional generator for the generator. The authors show that the proposed method can generate complex image sets. "
SP:1130a391afa30d1e0fddadedd2a3aaa70a4cb751,"This paper proposes a new normalization technique for off-policy temporal difference (TD) algorithms. The proposed technique is based on a mixture of on-policy transitions, which is called cross-normalization. It can be regarded as an extension of batch normalization that re-centers data for two different distributions. Experiments show that the proposed technique improves over the state-of-the-art across a range of MuJoCo benchmark tasks."
SP:f9cafaa5131176290fa069e6d24046c079cd9eea,"This paper proposes a new adversarial training strategy to learn discriminative features unbiased and invariant to the confounder(s). The proposed method is based on the adversarial loss function that encourages a vanished correlation between the bias and learned features. The authors apply their method to synthetic data, medical images, and a gender classification (Gender Shades Pilot Parliaments Benchmark) dataset. The results show that the learned features by the proposed method not only result in superior prediction performance but also are uncorrelated with the bias or confounders variables."
SP:783049ff463edd1283c058c6106a3e1f9a033df4,"This paper proposes a lightweight model for character-level language modeling based on Transformer. The proposed model, called GroupTransformer, is based on grouped embedding operators, which factorizes the calculation paths by grouped operators. Additionally, Group-Transformer employs inter-group linear operators to prevent performance degradation from the group strategy. The experimental results show that the proposed model has better performance on two benchmark tasks, enwik8 and text8. "
SP:946c26d371297c88d0ac246257104099b4585edc,"This paper proposes Optimal Transport, a method for training generative models with hierarchical-latent-variable structures. The method is based on a variational autoencoder with Maximum Mean Discrepancy divergence. The authors show that the proposed method enables the generative model to fully leverage its deep-latents hierarchy, and that in-so-doing, it is more effective than the original Wasserstein Autoencoders. "
SP:309b47441d227ffa33f96f9f16f2addc607e5bb0,"This paper presents an autoregressive video generation model based on a three-dimensional self-attention mechanism. The proposed model achieves competitive results across multiple metrics on popular benchmark datasets, for which they produce continuations of high fidelity and realism. The authors also present results on Kinetics, a large scale action recognition dataset."
SP:ad8fcdbc47a50dd2bf58aba2bc6cfe199e84dd4d,"This paper proposes a latent feature generation framework for generalized zero-shot ICD coding, where the goal is to improve the prediction on codes that have no labeled data without compromising the performance on seen codes. The proposed framework generates semantically meaningful features by exploiting ICD code hierarchical structure and a novel cycle architecture that reconstructs the relevant keywords. Extensive experiments demonstrate the effectiveness of the proposed method."
SP:3ce82ae297e5759ab957babe9927062e7a71b0ba,This paper proposes a self-supervised representation learning method to improve sample efficiency in reinforcement learning (RL). The authors propose a forward prediction objective for simultaneously learning embeddings of states and action sequences. The proposed method is shown to improve the sample efficiency and peak performance of model-free RL on control from low-dimensional states.
SP:11ce1616e721340eea9e80dad7460c77355ac7d1,"This paper proposes an automated relational meta-learning (ARML) framework that automatically extracts the cross-task relations and constructs the meta-knowledge graph. When a new task arrives, it can quickly find the most relevant structure and tailor the learned structure knowledge to the meta learner. The proposed framework is evaluated on toy regression and few-shot image classification tasks. "
SP:37c209cd1c628b5c2f2b282fbeaf4bbf437c7670,"This paper proposes a plug-and-play language model (PPLM) for controllable language generation, which combines a pretrained LM with one or more simple attribute classifiers that guide text generation without any further training of the LM. In the canonical scenario, the attribute models are simple classifiers consisting of a user-specified bag of words or a single learned layer with 100,000 times fewer parameters than the LM, and are used to guide the generation. Sampling entails a forward and backward pass in which gradients from the attribute model push the LM’s hidden activations and thus guide the generated text generation. Model samples demonstrate control over a range of topics and sentiment styles. "
SP:12d0980bfea2de880905a0b87b40856969bb1c58,"This paper proposes a new unsupervised learning framework for learning robust representations with unlabeled data. The proposed method is based on denoising autoencoder, where the noisy input data is generated by corrupting clean data in the gradient domain. In this way, the agent learns more robust representations that exploits the underlying data structures across multiple scales. Experiments on several visual benchmarks demonstrate that better representations can be learned with the proposed approach compared to its counterpart with single-scale corruption. "
SP:12afc1b259e51a31cbeb72366d2b93fbee1aafaa,This paper proposes a method to verify the under-sensitivity of neural networks. The proposed method is based on the interval bound propagation (IBP) approach. The method is evaluated on the SNLI and MNLI datasets. 
SP:14257af9fe83522c6e5b5d6b0d68945b944e30fb,"This paper proposes to use a data graph to represent transitions in a Markov Decision Process (MDP) for off-policy deep RL. The authors show that the Q-value for each transition in the simplified MDP is a lower bound of the Q value for the same transition in a continuous Q-learning problem. By using these lower bounds in TD learning, their method is less prone to soft divergence and exhibits increased sample efficiency while being more robust to hyperparameters. "
SP:c92c97e47d8b218dfd009bbf61f5b3547b395f91,"This paper studies the effect of the embedding complexity on the generalization to the target domain. The authors show that the complexity affects an upper bound on the target risk, and empirically demonstrate the effectiveness of the proposed method. "
SP:f3f3c6fbae757836551b3f1ee54a7d1e040132b8,"This paper studies the generalization error of stochastic gradient Langevin dynamics (SGLD) and several other noisy gradient methods (e.g., with momentum, mini-batch and acceleration, Entropy-SGD). The authors develop a new framework, termed Bayes-Stability, for proving algorithm-dependent generalisation error bounds. The new framework combines ideas from both the PAC-Bayesian theory and the notion of algorithmic stability. The authors also study the setting where the total loss is the sum of a bounded loss and an additional `2 regularization term."
SP:a82fcd1d3196ddf078cfe8f4bc6f445d9d2bdc11,"This paper studies the role of hippocampal neurons in continual learning of two different spatial navigation strategies. The authors analyse population level activity of 612 hippocampal CA1 neurons of rodents learning to perform allocentric and egocentric spatial tasks. The components uncovered using dPCA from the firing activity reveal that hippocampal networks encode relevant task variables such as decisions, navigational strategies and reward location. They compare this hippocampal features with standard reinforcement learning algorithms, highlighting similarities and differences. Finally, a standard deep reinforcement learning model achieves similar average performance when compared to animal learning, but fails to mimic animals during task switching. "
SP:51acf1f8108683dce543a1fb4a61fbd593f9b4cc,"This paper proposes a new method for continuous MCTS, called TPO, which is based on a tree search based policy optimization method. The main idea is to limit the tree search branching factor by drawing only a few action samples from the policy distribution and defining a new loss function based on the trajectories’ mean and standard deviations. The proposed method is evaluated on a variety of continuous environments. "
SP:1ce3bc4d31712886f7dcada5b5ae67c3c376819a,"This paper studies the lottery ticket hypothesis, which claims that neural networks contain sparse subnetworks, which, if appropriately initialized (the winning tickets), are capable of matching the accuracy of the full network when trained in isolation. The paper investigates the following open questions: can we find winning tickets with few data samples or few labels? can we even obtain “good” tickets without supervision? The authors find that winning tickets found in these scenarios are, perhaps surprisingly, competitive with winning tickets generated on the full ImageNet dataset when evaluated on ImageNet classification task. "
SP:dbcebe5b73486885d9f4478b258047c02f8481a2,"This paper studies the problem of excessive prediction undersensitivity, where the input text is meaningfully changed, and the model’s prediction does not change when it should. The authors formulate a noisy adversarial attack which searches among semantic variations of comprehension questions for which a model still erroneously produces the same answer as the original question – and with an even higher probability. They show that SQuAD2.0 and NewsQA models are vulnerable to this attack and commit a substantial fraction of errors on adversarially generated questions. They also show that adversarial training is able to substantially decrease a model's vulnerability to undersensitivity attacks on held out evaluation data."
SP:5da870060778de460c1abe91562d6f3e707efef4,"This paper proposes a model-based approach to ensuring the safety of the agent while making sure that the agent does not cause any unnecessary disruptions to its environment. The proposed approach learns the transition dynamics of the environment and generate a directed graph called the imaginative module. A baseline state, which can either represent a safe or an unsafe state (based on whichever is easier to define) is taken as a human input, and the imagination module is used to predict whether the current actions of the agents can cause it to end up in dangerous states in the future. Experiments on two gridworld environments and a self-driving car simulator demonstrate that the proposed approach to safety visits unsafe states significantly less frequently than a baseline. "
SP:c2796f28fb067138303df8d424d646f4ada31558,"This paper proposes a novel architecture, Physics-aware Difference Graph Networks (PA-DGN), which leverages neighboring information to learn finite differences inspired by physics equations. The proposed architecture leverages data-driven end-to-end learning to discover underlying dynamical relations between the spatial and temporal differences in given sequential observations. The experiments demonstrate the superiority of the proposed architecture."
SP:db8ed4f4fc3967f5dd4d208d5d029730eb99e840,"This paper studies the problem of training structured neural networks (NN) with nonsmooth regularization (e.g. `1-norm) and constraints. The authors formulate the problem as a constrained nonconvex optimization problem, and propose a convergent proximal-type stochastic gradient descent (ProxSGD) algorithm.  The authors show that under properly selected learning rates, with probability 1, every limit point of the sequence generated by the proposed ProXSGD algorithm is a stationary point. Finally, to support the theoretical analysis and demonstrate the flexibility of ProExSGD, the authors show by extensive numerical tests how ProxGSD can be used to train either sparse or binary neural networks through an adequate selection of the regularization function and constraint set. "
SP:2ca1f4da9faee79768764cda5d09d949cc942acc,"This paper proposes a differentiable compression framework for lossy image compression. The main idea is to use a non-deterministic compression codec to circumvent the quantization step by relying on a probabilistic gradient-based optimizer. The proposed method is a principled, end-to-end differentiable framework that can be straight-forwardly trained using standard gradient based optimizers. Experiments on the CLIC 2018 dataset demonstrate the efficiency of the proposed method."
SP:788fd2b6956dd69bf7752d39ea21883947128c8a,"This paper proposes a new super resolution (SR) method for C-JPG images. The proposed method is based on a novel SR structure with two specifically designed components, as well as a cycle loss. The first component is a functional sub-model to recover information from C-jPG images, instead of the perspective of noise elimination in traditional SR approaches. The second component is an integrated cycle loss to improve the SR generation. Experiments show that the proposed method achieves outstanding performance among state-of-the-art methods."
SP:18dd92f2f55020be4f5a089b3b251327e47886f4,This paper presents a fully convolutional network architecture that is able to estimate a full surface of pass probabilities from single-location labels derived from high frequency spatio-temporal data of professional soccer matches. The network is trained by learning a feature hierarchy that produces predictions at different sampling levels that are merged together to preserve both coarse and fine detail. The proposed method can be easily adapted to solve many other related problems in sports analytics.
SP:1ae31baf383fc520687b255d9cac14c3b040e253,"This paper proposes an inductive matrix completion model without using side information. The authors train a graph neural network (GNN) based purely on 1-hop subgraphs around (user, item) pairs generated from the rating matrix. The proposed method achieves competitive performance with state-of-the-art transductive baselines. "
SP:c5cb1b50e17a69e88d5ae28848e265215162da1e,"This paper studies the problem of unconstrained minimization of a smooth objective function in R in setting where only function evaluations are possible. The authors propose and analyze stochastic zeroth-order method with heavy ball momentum. They provide convergence analysis of this method for non-convex, convex and strongly convex objectives. "
SP:a216cfc29937eb398ea98cb1aea3481c9aed8240,"This paper proposes a novel network architecture, named Action Semantics Network (ASN), that explicitly represents such action semantics between agents. ASN characterizes different actions’ influence on other agents using neural networks based on the action semantics. Experiments on StarCraft II micromanagement and Neural MMO show ASN significantly improves the performance of state-of-the-art DRL approaches compared with several network architectures. "
SP:efaf3a440dc17e05177832083ffbc23760ed7c97,"This paper proposes a method to exploit the underlying structures of the state-action value function, i.e., Q function, for both planning and deep RL. Specifically, the authors investigate the low-rank structure, which widely exists for big data matrices, and propose a general framework to exploit this structure in Q functions. Experiments on control tasks and Atari games confirm the efficacy of the proposed method. "
SP:430336893b247b7bd45687d78b0d0511a7369e87,"This paper proposes a new algorithm, Best-Action Imitation Learning (BAIL), for batch reinforcement learning. BAIL first selects from the batch the actions it believes to be high-performing actions for their corresponding states; it then uses those state-action pairs to train a policy network using imitation learning. Experimental results show that BAIL achieves state of the art performance on the Mujoco benchmark. "
SP:94078964876667e8a5d9ae7728d779d5b91a576e,"The paper proposes a new deep extreme multi-label learning method, called DeepXML, that splits training of head and tail labels. The proposed method is able to scale to problems involving millions of labels that were beyond the pale of state-of-the-art deep extreme classifiers as it could be more than 10x faster at training than XML-CNN and AttentionXML.   The method is based on the Slice algorithm for pretrained embeddings to learn the proposed deepXML architecture. "
SP:b1b1252d82fa1bea18309e0b0b894e0f28f48bc9,"This paper proposes an end-to-end trainable variational hashing-based collaborative filtering approach that uses the novel concept of self-masking: the user hash code acts as a mask on the items (using the Boolean AND operation), such that it learns to encode which bits are important to the user, rather than the user’s preference towards the underlying item property that the bits represent. This allows a binary user-level importance weighting of each item without the need to store additional weights for each user. The proposed method is evaluated on 4 datasets and achieves significant gains in NDCG. "
SP:80898d0f2b2c8dc3388fa9164e529eae36aa1b21,"This paper proposes a set of statistical tools for quantitatively measuring the mode collapse of GANs. The main contribution of the paper is a new metric for quantifying mode collapse, which is based on a combination of two existing metrics: low-level perceptual quality and high-level mode collapse. The authors also propose two simple yet effective methods to calibrate the GAN learned distribution, without accessing either model parameters or the original training data. The experimental results show that the proposed metric consistently shows strong mode collapse on several state-of-the-art GAN models."
SP:e5b5dda2f024cfda10526e744aa035e0165af58a,"This paper studies the training of over-parametrized neural networks that are beyond the NTK regime yet still governed by the Taylor expansion of the network. The authors introduce the idea of randomizing the neural networks, which allows them to escape their NTK and couple with quadratic models. They show that the optimization landscape of randomized two-layer networks are nice and amenable to escaping-saddle algorithms. They prove concrete generalization and expressivity results on these randomized networks. "
SP:cef7ea513eb3e42be4edf40e4ee1701a969bcbea,"The paper proposes a new method for evaluating the effectiveness of graph convolutional filters for semi-supervised node classification. The method is based on the idea that there is no single filter as a “silver bullet” that performs the best on all possible graphs, and graphs with different properties are in favor of different graph convolutionsal filters. The authors propose a novel assessment tool, called Graph Filter Discriminant Score (GFD), to evaluate whether there exists an optimal filter for all graph data, which graph properties should be considered for finding the optimal graph filter; and how to design appropriate filters that adapt to a given graph. Based on these findings, the authors propose Adaptive Filter Graph Neural Network (AFGNN), a simple but powerful model that can adaptively learn data-specific filters. "
SP:3c5ec9dbcf914c8901e4e35f3c2a7df4707422ab,"This paper proposes a distributionally robust optimization (DRO) method for overparameterized neural networks. The main idea is to learn models that instead minimize the worst-case training loss over a set of pre-defined groups. The authors show that naively applying group DRO to overparametrized neural networks fails: these models can perfectly fit the training data, and any model with vanishing average training loss also already has vanishing worst case training loss. To address this issue, the authors introduce a stochastic optimization algorithm, with convergence guarantees, to efficiently train group-DRO models. "
SP:eb1ee2e0f7d8466a04b58508ecb3da7b667eecdf,This paper proposes a new local explanation method for black-box classifiers. The proposed method is based on distribution controllers and integrates it with a neural network to directly guide the distribution of relevance scores. The authors also introduce the classification loss to optimize the proposed predictor. The experimental results demonstrate that the proposed method also outperforms others in terms of faithfulness and explainability. 
SP:32ea7cbc47cbdb1f703f4e07c31ce90abe083424,"This paper proposes a method for image reconstruction and classification problems that involve detection of multiple object instances, without any supervision regarding their whereabouts. The method is based on top-k selection, where the network learns to extract the most significant K patches, and feeds these patches to a task-specific network – e.g., auto-encoder or classifier – to solve a domain specific problem. The proposed method is able to learn to detect recurring structures in the training dataset by learning to reconstruct images. It can also learn to localize structures when only knowledge on the occurrence of the object is provided."
SP:da1c5f6351d531482e90b86c3cceb52850c520de,"This paper proposes a neural program synthesis algorithm, AutoAssemblet, which learns to generate a chunk of assembly code that can be executed to match a state change inside the CPU and RAM. The authors use self-learning reinforcement learning to reduce the breadth and depth of the Monte Carlo Tree Search, resulting in better synthesis performance. They also propose an effective multi-entropy policy sampling technique to alleviate online update correlations. "
SP:0d4687fc36c02e27d1b95d532a3947589f92b1da,This paper studies the effect of model architecture on the speed of training in the context of gradient descent optimization. The authors use the ideas from prior work that shows gradient descent can be modeled as a first-order ODE and use ODE’s coefficient matrix H to characterize the convergence rate. They introduce a simple analysis technique that enumerates H in terms of all possible “paths” in the network. 
SP:3e3bc8f617df742a395e7d315ec3810a42071294,"This paper studies the initialization bias of strongly overparametrized neural networks under gradient descent. The authors prove that fully connected wide ReLU-NNs trained with squared loss are essentially a sum of two parts: The first is the minimum complexity solution of an interpolating kernel method, while the second contributes to the test error only and depends heavily on the initialization. This decomposition has two consequences: (a) the second part becomes negligible in the regime of small initialization variance, which allows us to transfer generalization bounds from minimum complexity interpolating kernels methods to NNs; (b) in the opposite regime, the test errors of wide NNs increases significantly with the initialization variance. "
SP:b15ea009a36a0a76728dfc103d668d6781a8a99a,"This paper proposes a new pseudo-LiDAR framework for 3D object detection. The proposed method is based on the pseudo-Lidar framework. The main contribution of the paper is to adapt the stereo network architecture and loss function to be more aligned with accurate depth estimation of faraway objects, which is currently the primary weakness of the current state-of-the-art. The authors also propose a depthpropagation algorithm, guided by the initial depth estimates, to diffuse these few exact measurements across the entire depth map. "
SP:983d84502264633f3385d426c1d4601a0744ea9a,"This paper proposes a principled adversarial example detection method that can withstand norm-constrained white-box attacks. Inspired by one-versus-the-rest classification, in a K class classification problem, the authors train K base detectors where the i-th detector is trained to discriminate natural data of class i from adversarial examples perturbed from other classes. At inference time, they first get the predicted label (say k) of the input, and then use the k-th detectors to identify whether the input is a natural sample (of class k) or an adversarial attack. "
SP:461e9308d050bc3dc7b35233452668bb31f5d491,"This paper proposes a novel type of intrinsic reward that encourages the agent to take actions that lead to significant changes in its learned state representation. The intrinsic reward does not diminish during the course of training and it rewards the agent substantially more for interacting with objects that it can control. The experiments demonstrate that this approach is more sample efficient than existing exploration methods, particularly for procedurally-generated MiniGrid environments. "
SP:c002c20b5e8696588e029c0f65e88860418826c4,"This paper studies the retrieval of documents from a large document corpus. The authors propose a new retrieval method based on embedding-based Transformer models. The proposed method is based on a combination of BM-25 (token matching + TF-IDF weights) and Transformer-based models.  The authors show that the key ingredient of learning a strong embedding based Transformer model is the set of pre-training tasks. They show that with adequately designed paragraph-level pretraining tasks, the proposed method can significantly improve over the widely-used BM25 as well as embedding models without Transformers. "
SP:4e161e08a624f87633dfb49dfd46bd1665e15189,"This paper proposes a new graph convolutional network architecture, called BiGraphNet, which subsumes conventional graph convolutions and pooling as its special cases and supports multi-graph aggregation leading to a class of flexible and adaptable network architectures. The authors propose a new bipartite graph neural network operation, a parameterized transformation between different input and output graphs. The proposed method is general enough to subsume conventional Graph Convolution and Pooling and can be used to build efficient architectures such as graph skip connections, and graph autoencoders. "
SP:9b9b6ee9014e5538442ba76d6059ed01f59ec8fb,This paper proposes a new few-shot classification method for metric-based methods. The proposed method uses feature-wise transformation layers for augmenting the image features using affine transforms to simulate various feature distributions under different domains in the training stage. The authors conduct extensive experiments and ablation studies under the domain generalization setting.
SP:df46627cb984a56bba36d510bfc52e00751e9107,This paper proposes a new convolutional neural network architecture for Lagrangian fluid simulation. The proposed architecture is based on the N-D convolution. The authors show that the proposed architecture can be extended to the continuous domain. 
SP:3e17f333cf07183969c02bb66afdd3ccbf25bb19,"This paper proposes a new ensemble method, BatchEnsemble, that can be used to reduce the computational and memory cost of ensemble training. The proposed method is parallelizable across devices, where one device trains one member, but also parallelizable within a device, where multiple ensemble members are updated simultaneously for a given mini-batch. The authors show that the speedup at test time is 3x and memory reduction is 3X at an ensemble of size 4. "
SP:a123a425ef3eb6188833d5a42e851bc3fa59df65,This paper proposes a neural network-based partial differential equations solver for forward and inverse problems. The network is trained to minimize deviations of the learned function from the strong PDE solution and satisfy the boundary conditions. The resulting solution in turn is an explicit smooth differentiable function with a known analytical form. The proposed algorithm is a unified formulation of both forward/inverse problems where the optimized loss function consists of few elements: fidelity terms of L2 and L∞ norms. 
SP:973d0ad0faadcf7298300f2758de9154205e7113,This paper proposes a method to improve the performance of logic-based reasoning tools for SAT solvers. The method is based on the Binarized Neural Network (BNN) architecture and the training procedure. The main contribution of the paper is to analyze the architectural design choices of BNNs and discuss how they affect the performance. The authors propose changes to the BNN architecture and training procedure to get a simpler network for the SAT solver without sacrificing accuracy on the primary task. 
SP:ca985e758f195bd04fb9f24b290a83974d6d308b,"This paper studies the expressive power of graph neural networks falling within the message-passing framework (GNNmp). Two results are presented. First, GNNmp are shown to be Turing universal under sufficient conditions on their depth, width, node attributes, and layer expressiveness. Second, it is discovered that GNNMP can lose a significant portion of their power when their depth and width is restricted. "
SP:a98ae70a91850bbe624c307ba61d3daeb2494b82,"This paper proposes a generative flow-based density model based on continuous bijections that can be used to learn target distributions with complicated topologies. The proposed method, called localised generative flows (LGFs), is composed of stacked continuous mixtures of bijection, which enables each bijection to learn a local region of the target rather than its entirety. The authors show empirically that LGFs yield improved performance across a variety of density estimation tasks. "
SP:3adc341dece170f428195e4dccadfb5f5daddf2d,"This paper studies the problem of vision-and-language navigation (VLN) where the agent is trained to follow naturallanguage instructions, explore the given environments, and reach the desired target locations. The authors propose a novel method for environment re-splitting and feature replacement to improve the performance of VLN models on unseen environments. The proposed method is based on the observation that the low-level visual appearance conveyed by ResNet features directly affects the agent model and contributes to this environment bias in results. The experiments show that the proposed method can significantly decrease the performance gap between seen and unseen on multiple datasets. "
SP:298e0043e99f586d314fbd9d16fdc6ae885e1ebb,"This paper proposes an approach to use implicit human feedback to accelerate and optimize the training of a DRL algorithm. The human's intrinsic reactions to the agent's behavior is sensed as implicit feedback by placing electrodes on the human scalp and monitoring what are known as event-related electric potentials. The implicit feedback is then used to augment the agent’s learning in the RL tasks. The authors demonstrate the feasibility of capturing error-potentials of a human observer watching an agent learning to play several different Atari-games using an electroencephalogram (EEG) cap, and then decoding the signals appropriately and using them as an auxiliary reward function to accelerate its learning of the game.   "
SP:a8395f8b877e1eebaef9ff2e8b4e488d55a74ef4,"This paper proposes a new method for laconic classification, which aims to minimize the amount of information (aka. entropy) required in individual test images to maintain correct classification. The authors propose two complementary frameworks for computing the minimal-entropy positive images of both human and machine classifiers, in experiments over the ILSVRC test-set. The proposed method is able to combine and compare the effects of various types of reductions (e.g., crop, colour reduction, resolution reduction) on classification performance, in turn generalising similar methods explored in previous works. "
SP:81cec8f907d8fa0653b5bc08af1f59bfefd49619,This paper studies the effect of perturbation attacks on the robustness of convolutional neural networks. The authors identify a family of defense techniques that are based on the instability assumption. They show that deterministic lossy compression algorithms and randomized perturbations to the input that all lead to similar gains in robustness. They also provide a comprehensive experimental analysis of when and why these defenses work and potential mechanisms. 
SP:a136b98e0ed478144ce9dd26e2b6d611543124e8,"This paper proposes a method for view prediction for 3D object detection. The method is based on a neural 3D mapping network, which takes as input 2.5D video streams captured by a moving camera, and lifts them to stable 3D feature maps of the scene, by disentangling the scene content from the motion of the camera. The model also projects its 3D features maps to novel viewpoints, to predict and match against target views. Experiments show that the proposed model learns visual representations useful for semi-supervised learning of 3D moving object detectors, and unsupervised learn of moving object detector. "
SP:6fd61604a2eeb8a2cbbda6c40807cebef6d40f2f,"This paper studies the problem of unsupervised domain translation (UDT), where the goal is to find meaningful correspondences between two domains, without access to explicit pairings between them. The authors show that existing methods are biased towards low energy transformations, leading them to cast UDT into an Optimal Transport (OT) framework by making this implicit bias explicit. They then propose a simple approach to solve UDT, and illustrate its properties in two distinct settings. "
SP:8bb3ce11ad773685f6e41d90db3e7a5481e5ba47,"This paper proposes a new regularization method, RotationOut, for neural networks. Unlike Dropout, which handles each neuron/channel independently, the proposed method considers its input layer as an entire vector and introduces regularization by randomly rotating the vector. The proposed method can also be used in convolutional layers and recurrent layers with small modifications. Extensive experiments in vision and language tasks are conducted to show its effectiveness. "
SP:37620ae8dc5683eb2843792e0aa4cbe6cba366f7,"This paper proposes a method to create Universal Adversarial Perturbations (UAP) for a given CNN in a data-free manner. The proposed method is based on a sequential optimization of the adversarial perturbation with the proposed dilate loss. By doing so, the authors constrains the ReLU activation function at every layer to act roughly linear for data points and thus eliminate the dependency on data for crafting UAPs. Extensive experiments demonstrate that the proposed method not only has theoretical support, but achieves higher fooling rate than the existing data free work."
SP:2fd7d5507a8727db743dc89379a6f021d31ed39a,"This paper proposes a transferable neural architecture search method based on meta-learning. The proposed method learns a meta-architecture that is able to adapt to a new task quickly through a few gradient steps, which makes the transferred architecture suitable for the specific task. Extensive experiments show the effectiveness of the proposed method."
SP:1314a79ba12474adb33ff31b3cb22bed25b94fb7,"This paper proposes a simple and effective stochastic neural network (SE-SNN) architecture for discriminative learning by directly modeling activation uncertainty and encouraging high activation variability. Compared to existing SNNs, the proposed SE is simpler to implement and faster to train, and produces state of the art results on network compression by pruning, adversarial defense and learning with label noise."
SP:bd4935d4fcf33f60f22e0f2fd9f7dc8ddfab6d17,"This paper proposes a meta-RL method for generating curious behavior. The authors formulate the problem of generating curiosity as one of meta-learning: an outer loop will search over a space of curiosity mechanisms that dynamically adapt the agent’s reward signal, and an inner loop will perform standard reinforcement learning using the adapted reward signal. To broaden the generalization, the authors instead propose to meta-learn algorithms: pieces of code similar to those designed by humans in ML papers.  The authors demonstrate the effectiveness of the proposed curiosity algorithms in domains as disparate as grid navigation with image inputs, acrobot, lunar lander, ant and hopper. "
SP:6dff0f3a84809ae0ba9f58f36303597f1ba6dcc5,This paper proposes a new approach for any-code-to-code generation (AnyC2C) that leverages the strict syntax of programming languages to model a code snippet as a tree. The proposed approach is based on structural language modeling (SLM). The proposed method estimates the probability of the program’s abstract syntax tree (AST) by decomposing it into a product of conditional probabilities over its nodes. The authors present a neural model that computes these conditional probabilities by considering all AST paths leading to a target node. 
SP:7fc60d6fd1cfcc135c34f9664d172d3fd1c0ae0a,"This paper studies the problem of non-convex optimization in learning large-scale neural networks (NN). The authors prove that the objective functions in learning NNs are convex in the canonical model space. They further elucidate that the gradients between the original NN model space and the canonical space are related by a pointwise linear transformation, which is represented by the so-called disparity matrix. Finally, they show that gradient descent methods surely converge to a global minimum of zero loss provided that the disparity matrices maintain full rank. "
SP:78a536138570fe9b5d88350e4b16d598a7db1fe0,"This paper proposes an interactive graph-based segmentation algorithm that enforce connectivity. The proposed method is based on instance-aware heuristic of a discrete Potts model, and a class-aware Integer Linear Programming (ILP) formulation that ensures global optimum. The authors show competitive semantic (and panoptic) segmentation results on the PASCAL VOC 2012 and Cityscapes dataset given initial scribbles. "
SP:2eb90879ddbc39b6b5c05152784d6044d1940513,"This paper proposes a new adversarial defense based on a learned saliency model. The proposed method is based on the idea that the saliency map can capture the shifts in saliency due to adversarial perturbations, while also having a low computational cost. This allows saliency models to be used effectively as a real-time defense. Experiments on MNIST, CIFAR-10, and ASSIRA demonstrate the effectiveness of the proposed method."
SP:fe5510d05ff091a5f133f2dbcd1b23d8d58d2c3e,"This paper studies the problem of estimating the probability that the prediction at any point sampled from the (unknown) input distribution is susceptible to adversarial attacks. Specifically, given a trained model, the authors consider the problem to compute the probability of computing the global adversarial robustness with estimation error upper-bounded by $\epsilon$ for any > 0 selected a priori. The authors show how concentration inequalities can be employed to compute global robustness. They also provide statistically sound analysis of the robustness/accuracy trade-off for a variety of neural networks architectures and training methods. "
SP:8f5616a1480b68c04b496ed498d237d5a7e87794,"This paper proposes a new method for robust reinforcement learning. The method is based on the Wasserstein distance between the transition kernel and the reference transition kernel. The authors show that the transition-kernel disturbance can be connected to the state disturbance, which allows to reduce the infinite-dimensional optimization problem to a finite-dimensional risk-aware problem. Then, the authors derive the optimal Bellman equation and propose a novel robust learning algorithm. The proposed method is tested on the Cart-Pole environment."
SP:d85963f5f0f6b20cf08f2a7c169ae33a45db7de2,"This paper proposes a new method to approximate mixed strategy Nash equilibria in multi-player continuous games, which always exist and include the pure ones as a special case. The proposed method adopts the pushforward measure technique to represent a mixed strategy in continuous spaces. In numerical experiments, the proposed method consistently and significantly outperforms recent works on approximating Nash equilibrium for quadratic games, general blotto games, and GAMUT games. "
SP:280d85cd8164a268f9d496ae5f17189c50f30dc1,"This paper proposes a neural execution tree (NExT) framework to augment training data for text classification using NL explanations. NExT transforms NL explanations into executable logical forms by semantic parsing, and generalizes different types of actions specified by the logical forms for labeling data instances. Experiments on two NLP tasks (relation extraction and sentiment analysis) demonstrate its superiority over baseline methods. "
SP:a9b5f7257dedd719cfe341fca275776734af1d98,"The paper proposes a method for verifying the robustness of machine learning models to perturbations of the input features. The method is based on the idea of verifying the accuracy of a neural network trained on the input data. The authors extend the verification procedure to recurrent neural network architectures and (2) complex specifications that go beyond simple adversarial robustness, such as requiring that a robot periodically visits a charging station or that a language model always produces sentences of bounded length. Experiments show that while models trained using standard training often violate desired specifications, the proposed method produces models that both perform well (in terms of test error or reward) and can be shown to be provably consistent with specifications."
SP:3903680e07b676409e3cf6a1044b67291fe38630,"This paper proposes a new method for visual domain randomization, where the agent is only trained on one variation of the environment, and its learned state representations are regularized during training to minimize the Lipschitz constant. The authors show that minimizing the policy’s variance with respect to the randomization parameters leads to low variance in the learned policies. "
SP:c79046dc56b9ee9c926f87386046422ea134ae8d,"This paper proposes a new loss function for deep metric learning (DML) based on a pairwise binary classification problem that classifies a pair of examples as similar or dissimilar. The key to this framework is to define a robust loss for all pairs over a mini-batch of data, which is formulated by distributionally robust optimization. The authors show that the proposed loss can recover state-of-the-art complicated losses and also to induce novel variants. Empirical studies on several benchmark data sets demonstrate the effectiveness of the proposed method. "
SP:38420928e40ef80c0136ad607b9275f9ab1e0769,"This paper studies the problem of finding a local minimum in non-convex finite-sum minimization. The authors prove that the trust region method with inexact gradient and Hessian estimation can achieve a convergence rate of order O(1/k) as long as those differential estimations are sufficiently accurate. Then, the authors propose a sample-efficient stochastic trust region (STR) algorithm which finds an approximate local minimum within Õ(\sqrt{n}/\epsilon). Finally, they also develop Hessian-free STR algorithms which achieve the lowest runtime complexity. "
SP:28a35b70b5e6915af28cacebc4ea50690c9534af,This paper proposes a new method for training deep neural networks without batch normalization or weight initialization. The proposed method is based on linear programming. The authors show that the proposed method improves the training capacity in the absence of batch normalisation or methods of initialization across a broad range of network sizes. 
SP:1d325b148e3efe407241c1f1cbe8d17400499741,"This paper studies the problem of computing exact robustness certificates for deep classifiers with differentiable activation functions in two steps. The authors show that if the eigenvalues of the Hessian of the network (curvatures of the networks) are bounded, they can compute a robustness certificate in the l2 norm efficiently using convex optimization. They also derive a computationally efficient differentiable upper bound on the curvature of a deep network. Finally, they propose a regularization term to boost the certified robustness against adversarial examples. "
SP:33f6f5aa0d4655e5d75fe612e0eff05e579d45c5,"This paper proposes a method for compressed sensing recovery using untrained deep generative models. The method is based on the recently proposed Deep Image Prior (DIP), wherein the convolutional weights of the network are optimized to match the observed measurements. The authors show that this approach can be applied to solve any differentiable linear inverse problem, outperforming previous unlearned methods. "
SP:23c0f621e6041003b59bf0532130760694cf6a4a,This paper proposes a temporal abstraction method for hierarchical reinforcement learning. The authors formulate the temporal abstraction problem as learning latent representations of action sequences and present a novel approach of regularizing the latent space by adding information-theoretic constraints. The proposed method is shown to achieve a significant speedup in convergence over benchmark learning problems. 
SP:4e54c9196ba1eb2b6a0b0eee41e4a6f3a9de72dd,This paper proposes a new sampling strategy for GCN-like models. The sampling strategy is based on the factors of the bi-directional diffusion between layers. The authors also propose a self-attention mechanism to flexibly learn suitable weights for the sampled nodes. Experiments on three large benchmark graphs demonstrate the effectiveness and efficiency of the proposed model. 
SP:bb0af9c011ef982c34fcadb545f6b5771818e7fa,"This paper presents a new unsupervised video prediction model, called STOVE. The model is composed of an image model and a dynamics model in compositional manner and improves on previous work by reusing the dynamics model for inference, accelerating and regularizing training. The proposed model predicts videos with convincing physical behavior over thousands of timesteps, outperforms previous unsupervision models, and even approaches the performance of supervised baselines. The authors further demonstrate the strength of the model as a simulator for sample efficient model-based control in a task with heavily interacting objects."
SP:e67b463bc0aec2345925d609fa521ea49df57fd9,This paper proposes a variational autoencoding model that incorporates the best properties of variational auto-encoders (VAE) and generative adversarial networks (GAN). It is known that GAN can produce very realistic samples while VAE does not suffer from mode collapsing problem. The authors propose a novel approach to train the VAE model with an implicit likelihood by an adversarially trained discriminator. The proposed model optimizes λ-Jeffreys divergence between the model distribution and the true data distribution. 
SP:87056d0147ddcaf5d78f6888b05161fbdbb3346c,"This paper studies adversarial attacks against the Bayes-Optimal classifier for certain class distributions, while for others the optimal classifier is robust to such attacks. The authors present analytical results showing conditions on the data distribution under which all points can be made arbitrarily close to the optimal decision boundary and show that this can happen even when the classes are easy to separate, when the ideal classifier has a smooth decision surface and when the data lies in low dimensions. "
SP:a7b3a35e6a79084bdfd1e4a963dfa081279cd8bb,"This paper studies the effect of pruning identified exemplars (PIEs) on the top-1 accuracy of neural network models. PIEs are hard-to-generalize-to images that are mislabelled, of lower image quality, entail abstract representations, atypical examples or require fine-grained classification. The authors find that certain examples, which are pruning-identified exemplars, and classes are systematically more impacted by the introduction of sparsity. They also show that removing PIE images from the test-set greatly improves top accuracy for both sparse and non-sparse models."
SP:4b17edaa7ec6201891433320d85f9a415656b763,This paper presents a novel method for learning a dynamic knowledge graph for interactive fiction games. The key idea is to use the knowledge graph to reason about game state and to constrain natural language generation in combinatorially large text-based action spaces. Experiments show that the proposed method outperforms existing methods. 
SP:b1784ecbb8f36eef9cae33d61ce60d80c2f9c38d,This paper proposes a data-dependent Gaussian prior (D2GPo) for maximum likelihood estimation (MLE) for language generation. The proposed method is based on the Kullback-Leibler divergence (KL2 divergence) term derived by comparing the training prediction and the detailed training prediction. The authors show that the proposed method makes effective use of a more detailed prior in the data and has improved performance in typical language generation tasks. 
SP:7c29cb5a32b14e1392408dc5daba4cd35848bea9,"This paper proposes a new calibration method for deep neural networks. The proposed method, focal loss, replaces the widely used cross-entropy loss with focal loss. The authors provide a thorough analysis of the factors causing miscalibration, and use the insights from this to theoretically justify the empirically excellent performance of the proposed method. Experiments are conducted on a variety of computer vision (CIFAR-10/100) and NLP (SST, 20 Newsgroup) datasets."
SP:cd6b8417ec8bcb773c78cff677bb0a76d6b3f6f3,"This paper proposes a polynomial optimization framework for computing increasingly tighter upper bounds on the Lipschitz constant of neural networks. The authors show how to use the sparse connectivity of a network, to significantly reduce the complexity of computation. They conduct experiments on networks with random weights as well as networks trained on MNIST. "
SP:31c9dc0dd8806daddc9cb48c56ec819577fe46cd,"This paper proposes a self-supervised learning approach for video features that results in significantly improved performance on downstream tasks (such as video classification, captioning and segmentation). The proposed method extends the BERT model for text sequences to the case of sequences of real-valued feature vectors, by replacing the softmax loss with noise contrastive estimation (NCE). The authors also show how to learn representations from sequences of visual features and sequences of words derived from ASR (automatic speech recognition). "
SP:0f24424d10f1201dd25e8c56354e10afc9b2b11c,"This paper proposes a new method to reduce the amount of data needed to be transferred between servers and clients during the inference phase of a neural network. The method is based on a simple yet effective framework that allows to select certain parts of the input data needed for the subsequent application of a given neural network, which is trained simultaneously such that a good model performance is achieved while, at the same time, only a minimal amount of the data is selected. Experiments show that the proposed method significantly reduces the number of data transferred between the server and the client."
SP:aa4fcf5b2cae05c5c6a903c24e4992b56655dee2,"This paper proposes a method to detect out-of-distribution (OOD) examples without compromising much of its classification accuracy on the test examples from known classes. Based on the Outlier Exposure (OE) technique, the authors propose a novel loss function for OOD detection with OE both on image and text classification tasks. Experiments show that the combination of the proposed method with the Mahalanobis distance-based classifier achieves state-of the art results in the OOD classification task. "
SP:89bc528ef801182365ac279e8963803afccb391d,"This paper proposes an end-to-end deep learning model for RNA secondary structure prediction which can effectively take into account the inherent constraints in the problem. The key idea of E2Efold is to directly predict the RNA base-pairing matrix, and use an unrolled algorithm for constrained programming as the template for deep architectures to enforce constraints. With comprehensive experiments on benchmark datasets, the authors demonstrate the superior performance compared to previous SOTA."
SP:b68560cce8c64ebe0ca5e6534b3732c775d36452,"This paper proposes a method for learning a collective policy for the problem of learning from simulated data. The method is based on the idea that each agent has different biases, and the goal is to learn a policy that can be applied to the real-world environment. The key idea is to let agents imagine together; make them take turns to host virtual episodes within which all agents participate and interact with their own biased representations. The authors show that the proposed method can achieve significantly higher returns than the best individually trained policies. "
SP:bd1dc08b4fd9a5cc78d26d7eb7f05dbb4a629ab1,"This paper proposes a dialog generation model that learns a semantic latent space, on which representations of semantically related sentences are close to each other. The latent space is learned by maximizing correlation between the features extracted from prompt and responses. An additional autoencoder is trained, for recovering the full sentence from the latent space. Experimental results show that the proposed model eliminates the generic response problem while achieving comparable or better coherence compared to baselines."
SP:ef0d5fd333ed60feb3946d24002e9a90642aea66,This paper proposes a Gaussian light and shadow (GLAS) method to estimate the spatial impact of deep models by the feature perturbation inspired by light and shadows in nature. GLAS provides a useful coarseto-fine control benefiting from scalability of Gaussian mask. The authors also devised the ability to identify multiple instances through recursive GLAS. 
SP:d17ca20cc527c28ab7358cb5b14954e5fb56409f,"This paper proposes a method to remove pixel-wise and channel-wise correlations before the data is fed into each layer of a convolutional neural network. The proposed method is called network deconvolution. The authors show that the proposed method can be efficiently calculated at a fraction of the computational cost of a conventional convolution layer. Experiments are conducted on CIFAR-10, Cifar-100, MNIST, Fashion-MNIST, Cityscapes, and ImageNet."
SP:e1b0de9a36bf8359df368b7a55a7f23e99d88db7,"This paper proposes a novel quantization method for GANs based on EM algorithms, named QGAN. The proposed method is based on applying existing successful CNN quantization methods to quantize GAN models to extreme low bits. Experiments on CIFAR-10 and CelebA show that QGAN can quantize weights in GAN to even 1-bit or 2-bit representations with results of quality comparable to original models. "
SP:58c4905f59f04a50b30d27c99521126a6455d38a,"This paper studies the convergence of the Hamiltonian gradient descent (HGD) algorithm for convex-concave min-max optimization. The authors show that the HGD algorithm achieves linear convergence in a variety of more general settings, including a novel “sufficiently bilinear” condition. They also prove convergence rates for stochastic HGD and for some parameter settings of the Consensus Optimization algorithm of Mescheder et al."
SP:d8556b52272321a1415ac2d85bb12e88b51ee73a,"This paper studies the stability of learning ResNet. The authors show that for standard initialization used in practice, τ = 1/\�( √ L) is a sharp value in characterizing the stability for forward/backward process of ResNet, where L is the number of residual blocks. Moreover, if ResNet is properly over-parameterized, gradient descent is guaranteed to find the global minima 1, which significantly enlarges the range of τ ≤ 1/Ω̃(L). "
SP:cf70dc496825ece2f28fdf4f1a6f4316c69e0e48,"This paper proposes a method to train sparse neural networks with a fixed parameter count and a fixed computational cost throughout training, without sacrificing accuracy relative to existing dense-to-sparse training methods. The method updates the topology of the network during training by using parameter magnitudes and infrequent gradient calculations. The authors show that this approach requires fewer floating-point operations (FLOPs) to achieve a given level of accuracy compared to prior techniques."
SP:d2d2b892518d54d0e63e26a056f2298be3be2610,"This paper proposes a new method to find meaningful directions in the latent space of any generative model along which we can move to control precisely specific properties of the generated image like the position or scale of the object in the image. The proposed method does not require human annotations and is particularly well suited for the search of directions encoding simple transformations of generated image, such as translation, zoom or color variations. Experiments show the effectiveness of the proposed method qualitatively and quantitatively. "
SP:1c63389e972d4652fac831e9d11609cd3c3c371a,"This paper proposes a physics-as-inverse-graphics approach to perform unsupervised physical parameter estimation of systems from video, where the differential equations governing the scene dynamics are known, but labeled states or objects are not available. The proposed method is based on a physics as inverse-GPS framework, which is able to perform long-term extrapolative video prediction, as well as vision-based model-predictive control. The authors also show that the controller’s interpretability provides unique capabilities in goal-driven control and physical reasoning."
SP:c6b8b682bf3087a65cb2379700b8a0183853c2af,"This paper proposes a method for learning a classifier from noisy labels when a few clean labeled examples are given. The proposed method is based on graph convolutional networks (GCN). The GCN is treated as a binary classifier learning to discriminate clean from noisy examples using a weighted binary cross-entropy loss function, and then the GCN-inferred “clean” probability is exploited as a relevance measure. The method is evaluated on an extended version of a few-shot learning problem where the few clean examples of novel classes are supplemented with additional noisy data."
SP:dd9c9a5dccbba5dd15b03ca6b314a9e153e95548,"The paper proposes a new objective for graph neural networks that maximizes the mutual information (MI) between edge features and message passing channels. The proposed objective is reformulated as a differentiable objective via a variational approach. The paper theoretically shows that the proposed objective enables the model to preserve edge information, and empirically corroborates the enhanced performance of MI-maximized models across a broad range of learning tasks. "
SP:f1cf63d728da51b4f83eb50ef69e3788b3a5ed74,"This paper proposes a new method for verifying the non-trivial properties of generative models. The method is based on the idea of using the latent space of a generative model to verify non-convexity of the output of the model. The proposed method, called APPROXLINE, performs both deterministic and probabilistic abstract interpretation and captures infinite sets of outputs of the generative networks. "
SP:2b0887dcf09249e8cee30d38163aeb9ef1e92b27,"This paper studies the problem of ""suspended animation"" in GNNs, where the model depth reaches the suspended animation limit, and the model will not respond to the training data any more and become not learnable. To resolve the problem, the authors introduce the GRESNET (Graph Residual Network) framework in this paper, which creates extensively connected highways to involve nodes’ raw features or intermediate representations throughout the graph for all the model layers. The authors prove the effectiveness of the introduced new graph residual terms from the norm preservation perspective, which will help avoid dramatic changes to the node’s representations between sequential layers. "
SP:dc436ade4d04072de35a90e5e4a1bfebfddb04e9,"This paper proposes a semi-supervised face reconstruction method. The proposed method is based on the adversarial loss, which is used to train a convolutional neural network (CNN) to regress the face shape and texture directly. A novel center loss is introduced to make sure that different facial images from the same person have the same identity shape and albedo. Besides, the proposed method disentangles identity, expression, pose, and lighting representations, which improves the overall reconstruction performance and facilitates facial editing applications."
SP:f7bc06697b09e2d59ec06b2cbcf3c0828ece32ae,"This paper proposes a method for imitation learning with partial knowledge of the transition kernel. In particular, the authors propose to replace the unknown transition kernel with a synthetic kernel that simulates the transition of state components for which the kernel is known (sr) and extract from demonstrations the next state for the unknown kernel (su). The next state is then stitched from the two components: s = {sr, su}. The authors analyze the errors caused by its synthetic kernel. "
SP:82cce92821e8168ab4a6fd67573b66c1d17673b8,"This paper proposes a self-supervised reinforcement learning approach for learning to control states of interest without any external reward function. The authors formulate the intrinsic objective as rewarding the skills that maximize the mutual information between the context states and the states of interests. They evaluate their approach for different simulated robotic manipulation tasks from OpenAI Gym and a navigation task in the Gazebo simulator. They show that their method is able to learn to manipulate the object, such as pushing and picking up, purely based on the intrinsic mutual information rewards."
SP:5db63d39cfd8132bec832ab64b8fbd403b3b8df0,"This paper proposes a new trojan attack method for large models, which outperforms existing studies in capability, generality, and stealthiness. The proposed method is programmable that the malicious misclassification target is not fixed and can be generated on demand even after the victim’s deployment. Moreover, the trojan shows no biased behavior for different target classes, which makes it more difficult to defend. "
SP:35ea626ee4dd1a7a368a660eb852192924966b7f,"This paper proposes a new few-shot regression (FSR) algorithm for drug discovery. The proposed algorithm consists of learning a deep network in combination with a kernel function and a differentiable kernel algorithm. The choice of kernel is critical, and the proposed algorithm learns to find the appropriate kernel for each task during inference. The authors also introduce novel benchmarks derived from biological assays."
SP:91ca4c3ee07617356250bae9f4ef9799b3b134ff,"This paper proposes a framework to characterize which reasoning tasks a neural network can learn well, by studying how well its computation structure aligns with the algorithmic structure of the relevant reasoning process. The authors derive a sample complexity bound that decreases with better alignment. They show that GNNs align with DP and thus are expected to solve these tasks. "
SP:a52aee8da5cf5acd2baf3c2a62cb679e13b18bd5,"The paper proposes a new metric called Fréchet Joint Distance (FJD), which is defined as the joint distribution between joint distributions of images and conditioning, allowing it to implicitly capture the aforementioned properties in a single metric. The authors conduct experiments on a controllable synthetic dataset, which consistently highlight the benefits of FJD when compared to currently established metrics. "
SP:fa822e8472efae17c7dfde8258057898383ecbbb,"This paper proposes a method for learning to identify decision states, which are the parsimonious set of states where decisions meaningfully affect the future states an agent can reach in an environment. The method is based on the VIC framework (Gregor et al., 2016), which maximizes an agent’s ‘empowerment’, i.e., the ability to reliably reach a diverse set of state. The authors show that their decision states are often interpretable, and lead to better exploration on downstream goal-driven tasks. "
SP:a19a51df7e28a5d3380be4fba13842efbfe3efec,"This paper proposes a method for classifying irregularly sampled time series with unaligned measurements, focusing on high scalability and data efficiency. The method SEFT (Set Functions for Time Series) is based on recent advances in differentiable set function learning, extremely parallelizable, and scales well to very large datasets and online monitoring scenarios. The authors extensively compare their method to competitors on multiple healthcare time series datasets and show that it performs competitively whilst significantly reducing runtime."
SP:4ae89d64460b08749acc192004545c1fa8b7553b,"This paper proposes a new method for training deep neural networks for audio processing. The proposed method is based on the idea of harmonic convolutional kernels, which is inspired by the harmonic structure of the audio signal. The method is tested on unsupervised audio restoration and supervised musical source separation. "
SP:c81a2b3fd1c56b9b18e4a358e3ff8b40aea5256a,"This paper proposes a data echoing algorithm to reduce the total computation used by earlier pipeline stages and speeds up training whenever computation upstream from accelerators dominates the training time. The authors investigate the behavior of different data echoing algorithms on various workloads, for various amounts of echoing, and for various batch sizes. "
SP:b4cf56d3fa7d65cacde33f17cd04bd5bbc52dd71,This paper proposes a new method for improving the generalization of Markov Decision Processes (MDPs). The proposed method is inspired by the successor features framework. The key idea is to learn controllable features that can be leveraged to provide enhanced generalization and fast task inference. Experiments on the Atari suite demonstrate the effectiveness of the proposed method. 
SP:83500230586a9134f910ad067b7233dc563dc1ba,"This paper studies the generalization properties of deep neural networks. The authors show that the smoothness of the functional approximation, combined with a flat initial approximation, explains why massively overparameterized networks continue to generalize well. "
SP:7225825e353b711a7d023f706fafe5e17e4e2fb2,"This paper proposes a GAN-based method for image-to-image translation. The proposed method is based on an attention mechanism, where the discriminator estimates the probability that its input is real, and the generator creates an attention map that highlights the critical features for such prediction. Experiments are conducted on a number of image transfer tasks."
SP:41c089ba65393174dae1dc136f79030a0a4fc532,"This paper studies the role of multiplicative interaction layers in neural network architectures. The authors show that such layers strictly enrich the representable function classes of neural networks. They conjecture that multiplicative interactions offer a particularly powerful inductive bias when fusing multiple streams of information or when conditional computation is required. They also argue that they should be considered in many situation where multiple compute or information paths need to be combined, in place of the simple and oft-used concatenation operation. Finally, they back up their claims by applying them in large-scale complex RL and sequence modelling tasks."
SP:5144391584e6d3825e12684b7c053e4e282cff2b,"The paper proposes a new active learning algorithm for batch active learning with deep neural network models. The proposed algorithm, Batch Active learning by Diverse Gradient Embeddings (BADGE), samples groups of points that are disparate and high magnitude when represented in a hallucinated gradient space, a strategy designed to incorporate both predictive uncertainty and sample diversity into every selected batch. The authors show that BADGE consistently performs as well or better than other active learning methods."
SP:ce6023b1e6bf45b071a6f5457b2575425ae03366,"This paper proposes a novel feature leveling architecture for self-explaining deep neural networks. The proposed method is based on the idea that existing deep architectures are hard to interpret because each hidden layer carries a mix of low level features and high level features. As a solution, the proposed method isolates low level and high-level features on a per-layer basis to better utilize the GLM layer in the proposed architecture for interpretation. Experimental results show that the modified models are able to achieve competitive results comparing to main-stream architectures on standard datasets. "
SP:b70ceead1bf6c7dc684c74501716e7012b891022,This paper proposes an adversarial training method for drastically enhancing the gradient signal by drawing negative samples from the adversarial model that mimics the data distribution. The authors provide a mathematical proof that this adversarial sampling minimizes the gradient variance while any bias due to non-uniform sampling can be removed. Experiments on large scale data sets demonstrate the effectiveness of the proposed method.
SP:29b52fee83309268d9864f3b1fc3617948577d41,This paper proposes a new method for efficient exploration that leverages a low dimensional encoding of the environment learned with a combination of model-based and model-free objectives. The proposed method is based on intrinsic rewards that are based on a weighted distance of nearest neighbors in the low dimensional representational space to gauge novelty. The method is tested on a number of maze tasks as well as a control problem and shows that it is more sample-efficient compared to strong baselines. 
SP:257c98dc1a9f3efcbf9544d9ee2ff524b000543d,This paper proposes two new methods for out-of-distribution detection in the few-shot setting and establish benchmark datasets. The proposed methods are evaluated using standard metrics on new benchmark datasets and show improved results with the proposed methods.
SP:a3632b773143dfb3a8f104c6b658dfa1167d155b,"This paper proposes a generalized model of sequence generation that unifies decoding in directed and undirected models. The proposed framework models the process of generation rather than a resulting sequence, and under this framework, the authors derive various neural sequence models as special cases, such as autoregressive, semi-autoregressive and refinement-based non-autorgressive models. This unification enables the authors to adapt decoding algorithms originally developed for directed sequence models to interpret decoding in undirectized models. Experiments are conducted on WMT’14 English-German translation."
SP:eca5e2be9831dfb79c4f5e633cbfadcfd2e00eb1,"This paper proposes a novel two-stage approach for mathematical expressions recognition. In the first stage, this method locates and recognizes the math symbols of input image by object detection algorithm. The second stage, it translates math symbols with position information into LaTeX sequences by seq2seq model equipped with attention mechanism. The experimental results show that the two stage method significantly outperforms the end-to-end method. "
SP:923fee8623da1569a7f54a57b4b326f29440b4c0,This paper proposes a vector quantization method that aims at preserving the quality of the reconstruction of the network outputs rather than its weights. The proposed method only requires a set of unlabelled data at quantization time and allows for efficient inference on CPU by using bytealigned codebooks to store the compressed weights.  The authors validate their approach by quantizing a high performing ResNet-50 model to a memory size of 5 MB (20× compression factor) while preserving a top-1 accuracy of 76.1% on ImageNet object classification. 
SP:74850ad70241948f93fed95ba1f0ac11360437c1,"This paper proposes a new transformer architecture for the Mathematics Dataset. The architecture is based on the TensorProduct Transformer (TP-Transformer) architecture. The main contribution is a novel attention mechanism, called TP-Attention, which explicitly encodes the relations between each Transformer cell and the other cells from which values have been retrieved by attention. The attention maps are used to resolve ambiguities introduced by multiple layers of standard attention. "
SP:d319df820c6630c409fab32097652a083e8f53ea,"The paper proposes a method to improve the generalization of deep neural networks by using channel codes on the input features. Specifically, the authors reformulate a learning algorithm as a procedure for searching for a source code that maps input features to classes, and then train the classifier on the extended features. The authors derive a necessary and sufficient condition for generalization using a universal cognitive similarity metric, namely information distance, based on Kolmogorov complexity, and formulate an optimization problem to learn a more general classification function. Experiments are conducted to demonstrate the effectiveness of the proposed method."
SP:b8e86f5e89330d81ba4967a7ed2dbfb56375d8a0,This paper proposes a new graph pooling operation based on compressive Haar transforms. The proposed method is based on following a chain of sequential clusterings of the input graph. The input of each pooling layer is transformed by the compressed Haar basis of the corresponding clustering. The authors show that the proposed method achieves state-of-the-art performance on diverse graph classification problems. 
SP:17bea301d6718ef5f28864dd2445552b3cf65eeb,"This paper proposes a sample-based point-cloud decoder architecture that maps a shape representation to a point feature distribution, allowing an arbitrary number of sampled features to be transformed into individual output points. The proposed architecture is based on a fully-connected network that maps shape representations to a fixed number of output points, while the learned distributions are used to learn the output transformation. The experimental results show the effectiveness of the proposed method. "
SP:51d826ead5d1d9cb89d493ce4c39728651bbc57b,"This paper presents a benchmark of real-world noisy labels at 10 controlled noise levels. The authors conduct a large-scale study across a variety of noise levels and types, architectures, methods, and training settings. The results show that: (1) Deep Neural Networks (DNNs) generalize much better on real world noise, and vice versa. (2) DNNs may not learn patterns first on noisy data, and thus it is more difficult for robust DNN methods to improve. (3) When networks are fine-tuned, ImageNet architectures generalize well on noisy images. "
SP:9873f78fb2821afdbb5551700e6ab6a0e8bcb9f0,"This paper proposes a rule-exemplar method for collecting human supervision to combine the efficiency of rules with the quality of instance labels. The supervision is coupled such that it is both natural for humans and synergistic for learning. The proposed method jointly denoises rules via latent coverage variables, and trains the model through a soft implication loss over the coverage and label variables. Empirical evaluation on five different tasks shows that the proposed method is more accurate than several existing methods of learning from a mix of clean and noisy supervision, and is effective in denoising rules."
SP:6f2c656dbb7629f652a4291d6971625184d8118b,This paper proposes a memory-based GNN and a graph memory network for graph classification and regression tasks. The memory layer is used to jointly learn node representations and coarsen the graph. Experiments show that the proposed models achieve state-of-the-art results in eight out of nine graph classification tasks. 
SP:81bc52d734c86975d741b6482d65ca71a9d81620,"This paper studies the effect of initialization in deep linear networks and provides for the first time a rigorous proof that drawing the initial weights from the orthogonal group speeds up convergence relative to the standard Gaussian initialization with iid weights. The authors show that for deep networks, the width needed for efficient convergence to a global minimum is independent of the depth and scales linearly in the depth. Moreover, the authors demonstrate how the benefits of a good initialization can persist throughout learning. "
SP:9f5d95fc89c2f0d59d04838aa180f3db67997dfa,"This paper studies the problem of how to optimize the bit allocation of weights and activations for deep CNNs compression. The authors first explore the additivity of output error caused by quantization and find that additivity property holds for deep neural networks which are continuously differentiable in the layers. Based on this observation, the authors formulate the optimal bit allocation problem of weights/activations in a joint framework and propose a very efficient method to solve the optimization problem via Lagrangian Formulation. The method obtains excellent results on deep CNN ResNet-50 with only 0.7% accuracy loss."
SP:7191d7b217a12b1bf9c47d790896a8227c14cc3d,"The paper proposes a novel inference WGAN (iWGAN) model, which is a principled framework to fuse auto-encoders and WGANs. The iWGAN jointly learns an encoder network and a generative network using an iterative primal dual optimization process. The authors establish the generalization error bound of iWAGN under the framework of maximum likelihood estimation. The empirical experiments show that the proposed model greatly mitigates the symptom of mode collapse, speeds up the convergence, and is able to provide a measurement of quality check for each individual sample."
SP:cca6ae14fd0dd12352855e594acf7f3263bb1f24,"This paper proposes an extension of the mention pair model of anaphoric annotation (MPA) to alleviate the effects of sparsity inherent in some crowdsourcing environments. Specifically, the authors use a nonparametric partially pooled structure (based on a stick breaking process), fitting jointly with the ability of the annotators hierarchical community profiles. The proposed model is tested on a recently published large-scale crowdsourced anaphora dataset, and on par when enough observations are available. "
SP:4295cae4a56a02eb21c486408c1bf37a7483cb49,"This paper proposes a new type of intrinsic reward, successor feature control (SFC), which is general and not task-specific. The intrinsic reward is based on statistics over complete trajectories and thus differs from previous methods that only use local information to evaluate intrinsic motivation. The proposed method is evaluated on three different environments with pure visual inputs: VizDoom, DeepMind Lab and DeepMind Control Suite. The results show a substantially improved exploration efficiency with SFC and hierarchical usage of the intrinsic drives."
SP:9fa22eb03a79bce0fc1c8e84ae8640e010701eca,"This paper proposes a method for weakly supervised video moment retrieval. The proposed method is based on a multi-level co-attention mechanism to learn richer multimodal representations. Specifically, the proposed method consists of a Frame-By-Word interaction module as well as a Word-Conditioned Visual Graph (WCVG) to learn visual-semantic representations that contain contextual information of their relative positions in the temporal sequence through iterative message-passing.   The method is evaluated on the DiDeMo and Charades-STA datasets. "
SP:27ac670353f34ee7a23bb7622f80c1dfbc0985e0,"This paper proposes a learned image-guided rendering technique that combines the benefits of image-based rendering and GAN-based image synthesis. Specifically, an object-specific deep neural network is trained to synthesize the view-dependent appearance of an object. In the target view, the pipeline reinserts the new views. To composite multiple reprojected images to a final output, the authors learn a composition network that outputs photo-realistic results. The authors demonstrate the effectiveness of their approach both qualitatively and quantitatively on synthetic as well as on real data."
SP:257d124367b1da9a595dc11a9df750d6bade298e,"This paper proposes a sparse representation of model uncertainty for deep neural networks (DNNs) that relies on an inverse formulation of Multivariate Normal Distribution (MND): an information form. The authors show that the model uncertainty can be estimated in this form using a scalable Laplace Approximation scheme, which involves a diagonal correction of the Kronecker-factored eigenbasis. They further devise a novel low-rank approximation of this eigenbais that exploits spectral sparsity of DNNs. "
SP:2e03ceba4004b82f86f8349352a8ee4520e9c35d,"This paper proposes a load-balanced hashing method, called Amortization Hashing (AHash), which can generate as few empty bins as possible. The main idea is to balance the load of the bins (the number of elements in a bin) so as to reduce the empty bins in advance. The authors claim that AHash is more load balanced and accurate without hurting runtime efficiency compared with OPH and densification strategies. The experiments on real datasets validate the claim. "
SP:d73827ab98b0ff6bd92abfefea43a5f88ea40de2,This paper proposes a method for extracting features from phase shift data by adding a graph structure to each data point and constructing a suitable machine learning architecture for graph data with cyclic permutation. Simulation and experimental results illustrate its effectiveness. 
SP:0df5ad333eb4ff9cca7f2d117909e2ce533a65d8,"This paper proposes a new method for conditional text generation based on a variational Bayes objective. The key idea is to learn a confidence score for each target position, which can be used at inference time to promote more faithful generation. Experiments on a structured data-to-text dataset show the effectiveness of the proposed method. "
SP:03307deac29173b2968fbd08f95fc77eb1f82410,"This paper proposes a new pruning method, called lookahead pruning, which extends the magnitude-based pruning to a multi-layer optimization. The proposed method is evaluated on VGG and ResNet."
SP:dc80fdc75bc14ae19fe4ba9b85c35ce00b12856f,"This paper proposes Moniqua, a decentralized stochastic gradient descent algorithm that allows decentralized SGD to use quantized communication. The authors prove in theory that moniqua communicates a provably bounded number of bits per iteration, while converging at the same asymptotic rate as the original algorithm does with full-precision communication. In addition, the authors show empirically that the proposed algorithm converges faster with respect to wall clock time than other quantized decentralized algorithms. "
SP:86c61a658d07ab86e2d84cef7e480bf7a06e4ddb,"This paper proposes a new family of partial models that are provably correct, yet remain fast because they do not need to fully model future observations. The authors show that partial models can be causally incorrect: they are confounded by the observations they don’t model, and can therefore lead to incorrect planning. "
SP:c70479b2096a52584b242de58272ca8d8565feea,The paper proposes a new variational autoencoder (VAE) model that learns a succinct common representation of two correlated data variables for conditional and joint generation tasks. The proposed model is based on two information theoretic problems—distributed simulation and channel synthesis—in which Wyner's common information arises as the fundamental limit of the succinctness of the common representation. Experimental results show that the proposed model outperforms existing VAE variants and the variational information bottleneck method. 
