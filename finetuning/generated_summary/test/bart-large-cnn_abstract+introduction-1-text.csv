paper_id,summary
SP:b19df5243359791fbaad005d6f13d7e9fdb0ff63,"This paper proposes a method for multi-agent role-based learning that decomposes joint action spaces into restricted role action spaces by clustering actions according to their effects on the environment and other agents. The proposed method, called RODE, learns a role selector based on action effects and a role policy based on actions. The role selector searches in a smaller role space and at a lower temporal resolution, while the role policies learn in significantly reduced primitive action-observation spaces. RODE achieves state-of-the-art performance on the StarCraft II micromanagement benchmark and achieves rapid transfer to new environments with three times the number of agents."
SP:7deb61890d97422a0fe141ca807f968c70ab239a,"This paper studies the behavior of the stochastic subgradient descent (SSGD) method applied to over-parameterized nonsmooth optimization problems that satisfy an interpolation condition. By leveraging the composite structure of the empirical risk minimization problems, the authors prove that SSGD converges, respectively, with rates O(1/ ) and O(log(1-1/)) for convex and strongly-convex objectives when interpolation holds. These rates coincide with established rates for SGD and SSGD methods applied to smooth problems. The analysis provides a partial explanation for the empirical observation that sometimes SGD or SSGD behave similarly for training smooth and nonsmoothed machine learning models."
SP:c7e0b3fedc0d0409d662dd612b529fdacad2b03e,"This paper proposes to use non-linear ""reservoir"" layers to improve the performance of transformer-based machine translation and language modelling models. The proposed method is based on the idea of using random initialization of the reservoir layers, where some of the layers are randomly initialized and never updated. The experiments show that the proposed method improves the performance on a variety of machine translation tasks and language modeling tasks. "
SP:ba9f1d4738ec67a440346f3ac6c4cf35f7232077,This paper proposes a filter transform-based method for steerable CNNs. The proposed method is based on group representation theory. The authors show that filter transformed kernels can be used to convolve input/output features in different group representation. They also show that the kernel constructed by filter transform can also be interpreted in the group representations theory. This interpretation helps complete the puzzle of steerable kernel theory and provides a novel and simple approach to implement steerable convolution operators.
SP:c1116fbb4d058eb6be195b5d13d19a55ba86b602,"This paper proposes an optimal neural synthesis approach for multimodal program synthesis where the goal is to find a program that satisfies user-provided constraints while maximizing the program’s score with respect to a neural model. Specifically, the user intent is expressed using combination of natural language (NL) and input-output examples. At the core of the method is a top-down recurrent neural model that places distributions over abstract syntax trees conditioned on the NL input. The experimental results on STRUCTUREDREGEX dataset show that the proposed method substantially outperforms prior state-of-the-art techniques in terms of accuracy and explores fewer states during search."
SP:55e02d79146bbb42f1ab6d4fafa2db5ddbe599b0,"This paper proposes a protein graph convolutional neural network (PGCN) to predict the substrate specificity landscape of a protease enzyme, which is the set of all sequence motifs that are recognized/cut by the enzyme. The proposed method is based on a physically intuitive, structure-based molecular interaction graph generated using the Rosetta energy function that describes the topology and energetic features, to determine substrate specificity. The PGCN model also readily lends itself to the design of novel enzymes with tailored specificity against disease targets."
SP:7727eeb7b17ad94ddfa0cf24e64a9626d83a8876,"This paper studies the underestimation bias in double Q-learning, which is a classical method for reducing overestimation bias caused by taking maximum estimated values in the Bellman operation. The authors show that under the approximate Bellman operator, there are multiple non-optimal fixed points in the model. To address this issue, the authors propose a doubly bounded estimator that utilizes an abstracted dynamic programming as a lower bound estimation to rule out the potential non-optimality fixed points. The proposed method is evaluated on several Atari benchmark tasks and shows significant improvement over baseline algorithms."
SP:1d630b69f95392a5ef3d7d580b523e077a3555a8,"This paper proposes a two-step training framework for deep generative models (DGMs) of high-dimensional natural images. First, a sampler is trained to generate images in low-frequency bands by training a decoder in the wavelet domain. Then, the decoder is trained in the pixel-space with a novel wavelet super-resolution decoder network. The proposed method achieves a Fréchet Inception Distance (FID) of 10.59 – beating the baseline BigGAN model – at half the compute (256 TPU-v3 cores)."
SP:b943a73b1ec34867371325748dc3a91ff4011947,"This paper studies self-supervised few-shot learning (SSL) in the context of FSL. In particular, the authors provide a theoretical analysis of why SSL is suitable for FSL and the main difference between SSL and supervised training on FSL is the difference between the loss of SSL and MAML. The authors also provide the bound for the gap between SSL loss and supervised loss. Finally, they propose several ways to improve the test accuracy under the setting of SSL. "
SP:bd552f98e6a447cefa6b1a9bbdf40bc6539fb643,"This paper studies the convergence of two-layer teacher-student neural networks with finite widths. The authors show that the student neurons must align with the teacher neurons at any local minima of the teacher neuron. This shows that there might not be any local maxima near the initialization of the neural network. The paper extends this result to more general cases, where the proof can be reduced to analyzing the properties of a special class of functions that the authors call the angular distance (AD) function. "
SP:0f62846913ec10b44ed32845770da0565479dc75,"This paper proposes Deep Adaptive Semantic Logic (DASL), a novel framework for learning deep neural networks that incorporates user-provided formal knowledge to improve learning from data. The authors provide formal semantics that demonstrate that our knowledge representation captures all of first order logic and that finite sampling from infinite domains converges to correct truth values. DASL’s representation improves on prior neuro-symbolic work by avoiding vanishing gradients, allowing deeper logical structure, and enabling richer interactions between the knowledge and learning components. Experiments on a visual relationship detection task demonstrate that the addition of commonsense knowledge improves performance by 10.7% in conditions of data scarcity."
SP:2f19259d65fab904c1b771244da3dcb2f8aa0c26,"This paper proposes a regularization method for feedforward residual neural networks (ResNets) that aims to make them more iterative and convergent. The authors define three indices of iterative convergence and show that, even though ResNets can express iterative solutions, they do not learn them when trained conventionally on computer vision tasks. They then introduce regularizations to encourage iterative convergent computation and test whether this provides a useful inductive bias. Finally, the authors show that the proposed method does not improve classification accuracy on standard visual recognition tasks."
SP:6c14506b8b2b06043409d912e6bf877651aaa665,"This paper proposes two new normalization methods, SelfNorm and CrossNorm, to promote OOD generalization. SelfNorm uses attention to recalibrate statistics (channel-wise mean and variance), while CrossNorm exchanges statistics between feature maps. Extensive experiments on different domains (vision and language), tasks (classification and segmentation), and settings (supervised and semi-supervised) show the effectiveness of the proposed methods."
SP:2774abdc11917321dd4994af0f0da1ff824bea03,"This paper proposes to augment the convolutional encoder of an RL agent with a simple attention module. The proposed module is based on the attention mechanism of convolution. The authors show that the proposed module can extract interpretable task-relevant information such as agent locations and movements without the need for data augmentations or contrastive losses, and significantly improve the sample efficiency and final performance of the agents. The experiments are conducted on the DeepMind Control Suite environments."
SP:31a7051d08d19c01e11f1fac2f3041ed2fa28f15,"This paper proposes Rotograd, an extension of GradNorm, a widely used gradient-based approach for training multi-task neural networks. The main idea is to dynamically homogenize not only the gradient magnitudes but also their directions across tasks. To this end, the authors propose a task-specific rotation matrices that aligns all the task gradients. The authors also provide theoretical guarantees on the algorithm stability and convergence. Experiments on several real-world datasets and network architectures show that the proposed method outperforms previous approaches."
SP:ac9ebd027b92527d9a87b13ad11d002d99a2b0f6,"This paper proposes a new constraint for unsupervised geometry-invariant image translation, called minimal geometry-distortion constraint (MGC), as a general I2I translation constraint to guarantee the consistency of geometry structure of source and translated images, and thus reduce translation mismatch in the translation process. The proposed MGC is based on the mutual information (MI)-based dependency measure that models the nonlinear relationships of pixel values in the source and translation images. To facilitate estimation and maximization of MGC, the authors propose an approximate representation of mutual information called relative Squared-loss Mutual Information (rSMI) that can be efficiently estimated in an analytic form. Experiments on several benchmark datasets demonstrate the effectiveness of the proposed constraint."
SP:92a38d7d18f07f68b8f93c61180e2cc1dddd21de,"This paper studies the effect of sampling patterns in point cloud GANs. The authors show that sampling-insensitive discriminators (e.g. PointNet-Max) produce shape point clouds with point clustering artifacts, while sampling-oversensitive discriminator fail to guide valid shape generation. They propose the concept of sampling spectrum to depict the different sampling sensitivities of discriminators. They further study how different evaluation metrics weigh the sampling pattern against the geometry and propose several perceptual metrics forming a sampling spectrum of metrics. Guided by the proposed sampling spectrum, they discover a middle-point sampling-aware baseline discriminator, which improves all existing point cloud generators by a large margin on sampling-related metrics."
SP:16c4be3eb162bc81cb3343c2fc115eb8e926a5b5,"This paper studies the adversarial robustness of Capsule Networks (CapsNets), a recently proposed class-conditional neural network (CNN). CapsNets have been shown to be more robust to white-box attacks than CNNs under popular attack protocols. In this paper, the authors investigate the inner workings of CapsNet when the output capsules are attacked. The first observation is that adversarial examples can manipulate the votes from primary capsules. The second observation is the high computational cost, when directly applying multi-step attack methods designed for CNNs to attack Caps-Nets, due to the computationally expensive routing mechanism. Motivated by these two observations, this paper proposes a novel vote attack where we attack votes of Caps-Net directly. The vote attack is not only effective but also efficient by circumventing the routing process. Extensive experiments demonstrate the superior attack performance of our vote attack on Caps-NETs."
SP:dbd093dff7a38ba8882bb8119c34623ddaaf4cc6,"This paper proposes a meta-reinforcement learning method for online adaptation where the agent must explore to identify its particular characteristics and then exploit this information for collecting reward within the same episode. The proposed method uses privileged information in the form of a task descriptor at train time to improve the learning of recurrent policies. The method learns an informed policy (i.e., a policy receiving as input the description of the current task) that is used to both construct task embeddings from the descriptors, and to regularize the training of the recurrent policy through parameters sharing and an auxiliary objective. This approach significantly reduces the learning sample complexity without altering the representational power of RNNs, by focusing on the relevant characteristics of the task and by exploiting them efficiently."
SP:bd89d254fbf31db61db237d08ab42981e27c52df,This paper proposes a method to learn an RL policy from offline data in the sequential recommendation system (SRS) setting. The proposed method is based on model learning to adapt to diverse simulators generated by the offline dataset. The method is evaluated on synthetic environments and a real-world ride-hailing platform. The results show that the method overcomes the distortion problem and produces robust recommendations in the unseen real world.
SP:1a166b28cf684e0d5759bd629f6a53370d2bf11c,"This paper proposes a method to learn goal-reaching policies from scratch without the need for expert demonstrations or a value function. The authors leverage the property that any trajectory is a successful demonstration for reaching the final state in that same trajectory. They propose a simple algorithm in which an agent continually relabels and imitates the trajectories it generates to progressively learn goal reaching behaviors from scratch. Each iteration, the agent collects new trajectories using the latest policy, and maximizes the likelihood of the actions along these trajectories under the goal that was actually reached, so as to improve the policy. They show that this iterated supervised learning procedure optimizes a bound on the RL objective, derive performance bounds of the learned policy and empirically demonstrate improved performance and robustness over current RL algorithms."
SP:c306530164d677e670554eeba8203c66bb3d9f7a,"This paper proposes a new non-autoregressive text-to-speech (TTS) model FastSpeech 2, which aims to solve the one-to many mapping problem in TTS by directly training the model with ground-truth target instead of the simplified output from teacher, and introducing more variation information of speech (e.g., pitch, energy and more accurate duration) as conditional inputs in training and use predicted values in inference. In addition, this paper also proposes a method to directly generate speech waveform from text in parallel, enjoying the benefit of fully end to end inference. The experimental results show that the proposed method achieves a 3x training speed-up over the previous fastSpeech model and achieves even faster inference speed. "
SP:79e9fb20d383816f54738ce70d137131ebc10290,"This paper studies the unsupervised dimension reduction problem (UDR) in the language of tempered distributions, i.e., the problem of approximating an empirical density function pemp(x) by another tempered distribution q(x), whose support is in a k-dimensional subspace. The problem is reduced to the minimization of the distance between q and pemp, D(q, pemp), over a pertinent set of generalized functions. This infinite-dimensional formulation allows to establish a connection with another classical problem of data science — the sufficient dimension reduction (SDR) problem. The authors introduce a nonnegative penalty function R(f) that “forces” the support of f to be kdimensional. Then they propose an algorithm for minimization I(f + \�R(f), based on the idea of two-step iterative computation, which is an adaptation to real data and to fake data sampled around a k dimensional subspace found at a previous iteration. "
SP:93e54522e6c2b805905d21fc968fc40866f2898b,"This paper proposes a new method for feature contrastive learning (FCL) that encourages the model to be more sensitive to the features that have higher contextual utility. The proposed method is based on two notions: contextual feature utility and contextual feature sensitivity. The authors show that FCL achieves a better balance of robustness and sensitivity, leading to improved generalization in the presence of noise. "
SP:f03c50f15022c4f56ac2b3085354ffed38ad1145,"This paper proposes a new method for imitation learning based on adversarial imitation learning. The main idea is to learn a latent representation of a task using a discriminator network. This latent representation is regularized through mutual information constraints to incentivize learning only features that encode information about the completion levels of the task being demonstrated. This allows to obtain a shared feature space to perform imitation while disregarding the differences between the expert’s and the agent's domains. Empirically, the proposed method is able to efficiently imitate in a diverse range of control problems including balancing, manipulation, and locomotive tasks. "
SP:ef18f4188426bc01be309633b486884b0e7a81a4,"This paper studies the generalization performance of a pruned neural network trained on the lottery ticket hypothesis (LTH), which states that learning on a properly pruned network (the winning ticket) improves test accuracy over the original unpruned network. The paper shows that the convex region near a desirable model with guaranteed generalization enlarges as the neural network model is pruned, indicating the structural importance of a winning ticket. Theoretical results are obtained by analyzing the geometric structure of the objective function and the sample complexity to achieve zero generalization error. In particular, the authors show that the number of samples required for achieving zero generalisation error is proportional to number of the non-pruned weights in the hidden layer. "
SP:eed6cb2f8caed39f8295f4aeb6e044c2ac981c4d,"This paper proposes AutoLabel to automatically learn the labels for augmented data, based on the distance between the clean distribution and augmented distribution. The proposed method is built on label smoothing and is guided by the calibration-performance over a hold-out validation set. The authors show that AutoLabel is a generic framework that can be easily applied to existing data augmentation methods, including AugMix, mixup, and adversarial training. Experiments show that the proposed method can improve models’ accuracy and calibration performance, especially under distributional shift. "
SP:0d5017e1a405bf86e3bac40e6e59886d4bf48450,"This paper proposes a novel self-supervised representation learning method based on a causal framework that enforces invariant prediction of proxy targets across augmentations through an invariance regularizer which yields improved generalization guarantees. The authors also generalize contrastive learning using refinements and show that learning on refinements is a sufficient condition for learning useful representations; this provides an alternative explanation to MI for the success of contrastive methods. Empirically, RELIC significantly outperforms competing methods in terms of robustness and out-of-distribution generalization on ImageNet while also significantly outperforming these methods on Atari achieving above human-level performance on 51 out of 57 games."
SP:8f80a6f79f78c6421857f392c9a5e98061d7eb60,This paper proposes a visual transformer network (VTNet) for object goal navigation. The proposed method is based on the Transformer architecture. The main idea is to embed object and region features with their location cues as spatial-aware descriptors and then incorporate all the encoded descriptors through attention operations to achieve informative representation for navigation. Experiments show that the proposed method outperforms state-of-the-art methods in unseen testing environments.
SP:3e7cbe3dff592ef371e48dd86be7719fc5343f17,This paper proposes a communication-computation efficient secure aggregation method for federated learning. The key idea is to design the topology of the secret-sharing nodes (denoted by the assignment graph G) as sparse random graphs instead of the complete graph corresponding to the existing solution. The authors provide theoretical guarantees on the reliability/privacy of the proposed scheme and provide extensive real-world experiments to show that the proposed method can maintain the same levels of reliability and data privacy in practical federatedlearning systems.
SP:00fae41e0eca0a1575cd7b2dcfabf0dc5c9c8b8a,This paper studies the problem of finding an incentive compatible auction that maximizes expected revenue in a single-bidder setting. The authors propose a time-independent Lagrangian that can be used to compare the performance of two auctions. They also propose to use an inner maximization loop to compute optimal misreports. They demonstrate the effectiveness of their approach by learning competitive or strictly improved auctions compared to prior work.
SP:a0e8061beb5e9a6c631419861559d22b8d645cb4,"This paper proposes a new method for fine-tuning pre-trained representations for supervised and unsupervised tasks. The proposed method is based on integrating two heads: a classifier head with an improved contrastive cross-entropy loss to better leverage the label information in an instance-contrast way, and a projector head with a newly-designed categorical contrastive learning loss to fully exploit the intrinsic structure of data in a category-consistent way. The experimental results show that the proposed method achieves state-of-the-art results on CUB tasks."
SP:87e5b552c13d73bd85249062a152c6c140e594a9,"This paper proposes a new measure for adversarial robustness, called genuine adversarial accuracy, which measures the robustness of classifiers without trading off accuracy on clean data and accuracy on the adversarially perturbed samples. The proposed measure is based on the notion of invariance-based adversarial examples, samples whose predicted classes are unchanged even if the perceptual classes are changed. The authors prove that a single nearest neighbor (1-NN) classifier is the most robust classifier according to the proposed measure. "
SP:2fda410b9281c5e253d385bc4382ec168bc161f3,"This paper proposes a method to learn a fair adjacency matrix for link prediction in graph neural networks based on dyadic fairness. The proposed algorithm, FairAdj, is based on the idea that a fair link prediction should be independent of the sensitive attributes. The authors show that regulating weights on existing edges in a graph contributes to dyadic fairness conditionally. They empirically show that the proposed algorithm achieves better performance than existing methods in terms of fairness-utility tradeoff."
SP:b614e9fbec58e9efa7722d2ec4a60fc93d210f92,"This paper proposes a disentangled exploration autoencoder (DEAE) method for controllable image synthesis. The proposed method is based on disentanglement and regularization to guarantee the validity of exploration in latent space. The encoder of DEAE first turns the input sample into a disenangled latent code, then explores the latent code space through directed interpolation. After the decoder, the encoder is regularized to force the obtained latent representation to maintain perfect disentangling. Experiments demonstrate that DEAE can improve the performance of downstream tasks by synthesizing attribute-controllable augmented samples, and can help to eliminate dataset bias."
SP:c934adb14926a00ef9c73c9773cb0b3a2669921e,"This paper proposes a new Bayesian memory allocation scheme that bridges the gap between episodic and semantic memory via a hierarchical latent variable model. The authors extend the idea of locally contiguous memory to the Kanerva Machine, enabling a novel differentiable block allocated latent memory. The proposed K++ model infers a key distribution as a proxy to the pointers (Marlow et al., 2008) and is able to embed similar samples to an overlapping latent representation space, thus enabling it to be more efficient on compressing input distributions. Experiments show that K++ improves performance in memory conditional image generation."
SP:e63d7d8c581019e17585fb9c0eac33d6836e187d,"This paper studies the sample complexity and loss landscape of attention-based neural networks. The authors show that, under mild assumptions, every local minimum of the attention model has low prediction error, and attention models require lower sample complexity than models without attention. Besides revealing why popular self-attention works, the theoretical results also provide guidelines for designing future attention models."
SP:f739d199fdee26f09994e3f9487aec1eab0f2e89,"This paper extends the concept of expected free energy (EFE), which is a core quantity in active inference, to the inverse RL setting. The authors claim that EFE can be treated as a negative value function and extend it to the policy network setting. They also propose a novel inverse RL algorithm for designing EFE-based rewards, by learning a prior preference from expert demonstrations, which can be used to learn the prior preference given the observation to achieve a final goal. The experiments show that the proposed method can be applied to an inverse RL problem."
SP:5592b79e49eba95c15103a3348f2bde57b60f2ab,"This paper proposes a data augmentation method to improve generalization in both adversarial and standard learning by using out-of-distribution (OOD) data that are devoid of the abovementioned issues. Theoretical analysis and experiments on CIFAR-10, CifAR-100, and a subset of ImageNet demonstrate the effectiveness of the proposed method."
SP:3cac7a2c310165ed0de46d8e5546c3bfbd639158,"This paper proposes a new meta-RL method called Fast Linearized Adaptive Policy (FLAP) for adapting to out-of-distribution tasks. FLAP builds upon the idea of learning a shared linear representation of the policy so that when adapting to a new task, it suffices to predict a set of linear weights. A separate adapter network is trained simultaneously with the policy such that during adaptation, FLAP can directly use the adapter network to predict these linear weights instead of updating a meta-policy via gradient descent to obtain the new policy. Experiments on standard continuous-control metaRL benchmarks show FLAP presenting significantly stronger performance on out of distribution tasks with up to double the average return and up to 8X faster adaptation run-time speeds."
SP:21a1bd4ada0723c96c0dbf7a142a2faf5defa4e3,"This paper proposes a federated kernel k-means algorithm to solve the optimization problem of kernel k means under federated settings. The authors propose a distributed stochastic proximal gradient descent (DSPGD) algorithm and a communication efficient mech anism (CEM) algorithm to reduce the communication cost. The theoretical analysis shows that DSPGD with CEM converges with an O(1/T) rate, where T is the number of iterations. The experimental results show that the proposed algorithm achieves the highest clustering quality with the communication costs reduced by more than 60%. "
SP:be568dd3fea51ce33a6d1e4b07dda5aee6342395,"This paper proposes CompOFA, a method to reduce the training time and the search space of once-for-all (OFA) architectures by constraining search to models close to the accuracy-latency Pareto frontier. The authors propose to use compound relationships between model dimensions to build a design space smaller by several orders of magnitude. The proposed method achieves a 2x reduction in training time, and 216x speedup in model search/extraction time compared to the state-of-the-art. "
SP:04b84d26cf282dbb753cbf27f14c334f65d3f8ec,"This paper proposes an adversarial meta-learning algorithm, ADML (ADversarial Meta-Learner), which leverages clean and adversarial samples to optimize the initialization of a learning model in an adversarially adversarial manner. The proposed method is based on MAML (Finn et al., 2017) with adversarial training. The experimental results show the effectiveness and superiority of ADML in terms of both accuracy and robustness. "
SP:dfbaa6b53c4e8328d52666ad4641fc917bf0c0b3,"This paper proposes a data-driven framework for permutation selection to improve the decoding performance of the Bose Chaudhuri Hocquenghem (BCH) code. The proposed method is based on a self-attention model that embeds all the differentiated group permutations of a code in a word-independent manner, by extracting relevant features. Then, a trained NN accepts a corrupted word and the embedded permutations and predicts the probability for successful decoding for each permutation. Thereafter, a set of either one, five or ten most-probable-to-decode permutations are chosen, and decoding is carried out on the permuted channel words rather than decoding an arbitrary dataset with all permutations, and empirically choosing the best subset of them. The method is evaluated on the BCH code."
SP:c860a7b0952d708e7851c9bc4b63d246f64d1cba,This paper proposes to use clustering as an intermediate task for fine-tuning BERT for a target text classification task. The clustering is done by partitioning unlabeled training data into relatively homogeneous clusters of text instances and training BERT on predicting the cluster labels. The authors test this hypothesis on various data sets and show that this additional classification step can significantly reduce the demand for labeled examples mainly for topical classification tasks. 
SP:ea37f5882fd98dd4ce233077bb3069517d4ed4ea,"This paper presents an empirical study of model-based reinforcement learning (MBRL) on the Acrobot environment. The authors compare the performance of different generative models with a random shooting control agent. They find that the mixture density nets outperform all other models by a large margin. They also find that heteroscedasticity at training time, perhaps acting as a regularizer, improves predictions at longer horizons. "
SP:4e25ba3714d78ba59a0d8efbb65e0ef5201702f8,"This paper proposes an affine disentangled GAN (ADIS-GAN) that can explicitly disentangle affine transformations in a self-supervised and rigorous manner. The affine regularizer is derived by decomposing the affine matrix into separate transformation matrices and inferring the transformation parameters by maximum likelihood estimation. The results show that the learned representations are axis-aligned and scalable, where transformations such as rotation, horizontal zoom, horizontal skew, and vertical translation can be explicitly selected and learned."
SP:121f8420cfb49c6d80b5ebb4051e85947182594a,"This paper proposes CLSA, a self-supervised representation learning method that leverages stronger augmentations to improve the performance of instance discrimination-based contrastive learning. The main idea is to leverage the distribution divergence between the weakly and strongly augmented images over the representation bank to supervise the retrieval of strongly augmented queries from a pool of candidates. The proposed method achieves top-1 accuracy of 76.2% on ImageNet with a standard ResNet-50 architecture with a single-layer classifier fine-tuned. It also achieves the competitive performances on several downstream tasks."
SP:af54e542223097c315ecd677d0b968e9a0b2a1d4,"This paper proposes a method to de-identify a patient's face using MRI scans. The proposed method is based on a GAN architecture that takes a patient’s MRI scan as input and generates a 3D volume in which the brain is not modified but the face has been de-identified. Compared to the classical removal-based techniques, the proposed method preserves privacy more reliably without adversely affecting downstream medical analyses on the brain. "
SP:0ac3964bd2320341488476d60f57b75d2a79f92c,"This paper proposes a new graph pooling method based on a multi-head attention based global pooling layer that captures the interaction between nodes according to their structural dependencies. The proposed method, called GMT, is a graph multiset transformer (GMT) that maps a set of node representations into a compact form. It is shown that GMT satisfies both injectiveness and permutation invariance, such that it is at most as powerful as the Weisfeiler-Lehman graph isomorphism test. The experimental results show that GMT significantly outperforms state-of-the-art pooling methods on graph classification benchmarks with high memory and time efficiency, and obtains even larger performance gain on graph reconstruction and generation tasks."
SP:76848e7ac3e6709e92f6a6db60269cb5177495d1,"This paper studies the problem of over-squashing in graph neural networks (GNNs). In particular, the authors propose a new explanation for why GNNs struggle to propagate information between distant nodes in a long-range problem. The authors show that the bottleneck of the GNN is caused by the exponentially growing information into fixed-size vectors, which leads to the oversquashing of the information. The paper also shows that GIN, GCN and GGNN are more susceptible to this problem than GAT, GGNN and GIN. Finally, the paper shows that breaking the bottleneck improves the performance of these networks."
SP:90d8fa381446923902e42b259392e5e975e6caa1,This paper proposes a new method for cross-domain sentiment analysis based on the notion of prototypical distribution. The proposed method is based on learning prototypical distributions for the source domain and the target domain in an embedding space that is trained to be domain-agnostic by matching the data distributions across the domains. The authors show that the proposed method can reduce the effect of “domain shift” on the performance of a trained classifier in the target domains. 
SP:893fd7440b82f5da0d4c0944928810322eaee2f0,"This paper proposes an evaluation methodology to measure the gender bias in NLI models. The proposed evaluation is based on a challenge task that involves pairing gender neutral premise against gender-specific hypothesis. The authors evaluate three models (BERT, RoBERTa, BART) trained on MNLI and SNLI data-sets. They find that three models are significantly prone to gender-induced prediction errors. They also find that debiasing techniques such as augmenting the training dataset can help reduce the bias in certain cases."
SP:a32ab755bd249c393b70938036ce8e810c0c439f,"This paper studies variational intrinsic control (VIC), an unsupervised reinforcement learning method for finding the largest set of intrinsic options available to an agent. The authors show that the intrinsic reward used in implicit VIC is subject to bias in stochastic environments, causing convergence to suboptimal solutions, and propose two methods based on the transitional probability model and Gaussian mixture model to correct this behavior and achieve the maximal empowerment. "
SP:b4df2c4627a6d46c5100133e38c4bea20b296dd8,This paper studies the use of neural ensembles for small-scale image classification problems with a few labeled examples per class. The authors propose to use an ensemble of relatively small deep neural networks to improve sample efficiency in the low-data regime. They show that deep ensembling is a simple yet effective technique that outperforms current state-of-the-art approaches for learning from small datasets. They compare different ensemble configurations to their deeper and wider competitors given a total fixed computational budget and provide empirical evidence of their advantage.
SP:4a0ee01f4897efa81659f37ef0468ee8195bbc4f,"This paper proposes Sparse Binary Neural Networks (SBNNs), a method for quantized deep neural networks (DNNs) that uses positive 0/1 binary weights instead of the -1/1 weights used by state-of-the-art BNNs. The authors claim that SBNNs achieve a high compression factor and reduce the number of operations and parameters at inference time. Experiments on linear and convolutional networks over MNIST and CIFAR-10 datasets show the effectiveness of the proposed method."
SP:5be8539ad02595ad3c7a2d7afe8cbb3e9924467d,"This paper proposes a post hoc calibration method for predictive uncertainty estimation for OOD data. The proposed method uses outlier exposure to calibrate the model probabilities. The method is based on using the softmax probabilities of the model as a surrogate for class membership probabilities (Hendrycks & Gimpel, 2017) to estimate the predictive uncertainty. The results show that the proposed method outperforms the baseline method on corrupted data. "
SP:ea503f67e38fce7dee9cc4996b55b8959911f030,"This paper studies the expressive power of graph neural networks and graph kernels from an empirical perspective. Specifically, it compares the graph representations and similarities produced by these algorithms against those generated by a well-accepted, but intractable graph similarity function. The authors also investigate the impact of node attributes on the performance of the different models and kernels. The results reveal interesting findings. For instance, theoretically more powerful models do not necessarily yield higher-quality representations, while graph kernels are shown to be very competitive with GNNs."
SP:0cf7b7d929f50e0b7f4fda5e1f68e5ade2f7c29b,"This paper proposes a method for self-supervised image animation that generates a video of a source image following the motion of a driving video. The proposed method is based on a data augmentation technique called CutMix, which aims to regularize the discriminator predictions on inpainting. The authors propose a new method called PriorityCut, which uses the top-k percent occlusion pixels of the foreground to regularise image animation. The experimental results show that the proposed method outperforms state-of-the-art image animation approaches in pixel-wise difference, low-level similarity, keypoint distance, and feature embedding distance."
SP:60b535fc6cbc1a7a26ad53f706ebb17de346dc4f,"This paper proposes a method for learning disentangled representations of independent causal mechanisms (ICM) that directly model multiple data generation processes (mechanisms) in a coarse granularity. The authors propose to learn a model that disentangles each mechanism and approximates the groundtruth mechanisms from observational data. They outline sufficient conditions under which the mechanisms can be learned using a single self-supervised generative model with an unconventional mixture prior, simplifying previous methods. They also prove the identifiability of their model w.r.t. the mechanisms in the self supervised scenario. They compare their approach to disentangling representations on various downstream tasks."
SP:44d4e24428d043a69b40013919cda0e8e7bff99c,This paper proposes a self-labeling method for predicting chemical compound graphs from 2D images. The authors propose a graph aligning approach that generates rich or detailed labels given normal labels W in the target domain. The proposed method is evaluated on the Maybridge compound data set.  
SP:ad906dd9a176cffd283593321ff6b9ad19595528,This paper proposes a method to solve the energy optimization problem for chiller plants. The authors propose a monotonic neural network (MNN) which can constrain the input-output of the chiller power model to conform to physical laws and provide accurate function space about chiller plant. The proposed method is evaluated on a cooling system of a data center and shows the superiority of the proposed method in energy optimization.
SP:6cb65ee5d2926858570601eeeade24fe86c7f32f,"This paper proposes a causal spatio-temporal fusion transformer (CausalTrans) method for multi-head, multi-task and multi-target forecasting. CausalTrans aims to establish the collaborative causal effects of predictors on multiple forecasting targets, such as supply and demand in ride-sharing platforms. Specifically, the authors integrate the causal attention with the Conditional Average Treatment Effect (CATE) estimation method in causal inference. Moreover, they propose a novel Taylor expansion attention to replace softmax in multihead attention of Transformers (Vaswani et al., 2017) such that time complexity reduces from O(V2) to $O(V)$. "
SP:223980a1954d626d90ff54d8dc61b5d85a6b349c,"This paper proposes a method for jointly identifying a mixture of discrete and continuous factors of variability. The proposed method is based on a multi-agent VAE framework, where multiple agents are trained on augmented copies of training samples to learn mixture representations, while being encouraged to reach consensus on the categorical assignments. The method is evaluated on MNIST and dSprites datasets, achieving state-of-the-art categorical assignment while preserving interpretability of the continuous factors. It is also applied to a single cell gene expression dataset for a population of neurons."
SP:c982610ad28662c3bd13132abe1f7307d1a61b68,"This paper provides a general characterization of steerable kernel spaces for group equivariant convolutional networks (GCNNs) that satisfy a G-steerable kernel space. This characterization is motivated by a striking analogy between the constraints underlying steerable kernels on the one hand and spherical tensor operators from quantum mechanics on the other hand. By generalizing the famous Wigner-Eckart theorem for spherical tensors operators, the authors prove that steerable Kernel spaces are fully understood and parameterized in terms of 1) generalized reduced matrix elements, 2) Clebsch-Gordan coefficients, and 3) harmonic basis functions on homogeneous spaces. "
SP:7b2ea39069277ad0f4f79476a77ef84587a804d9,"This paper studies the effect of selective classification on the accuracy disparities between groups in the presence of spurious correlations. The authors show that selective classification can magnify existing accuracy disparities within a population. They show that increasing abstentions can even decrease accuracies on some groups. To better understand this phenomenon, they study the margin distribution, which captures the model’s confidences over all predictions. They prove that whether selective classification monotonically improves or worsens accuracy is fully determined by the accuracy at full coverage (i.e., without any abstention) and whether the distribution satisfies a property they call left-log-concavity property. "
SP:f1d57ee27e901daf7e4e2b84139019e945818911,"This paper proposes a hierarchical nonnegative CANDECOMP/PARAFAC (CP) decomposition (hierarchical NCPD) model and a training method, Neural NCPD, for performing hierarchical topic modeling on multi-modal tensor data. The neural NCPD utilizes a neural network architecture and backpropagation to mitigate error propagation through hierarchical NCPD. Experimental results on real and synthetic data demonstrate the effectiveness of the proposed method."
SP:b6ddc3a560aa7155e7e927bf5360bedc36586597,"This paper proposes a new adversarial robustness certificate for graph neural networks (GNNs) that is guaranteed to remain stable under adversarial perturbations. The authors leverage the locality property of GNNs to fuse multiple single-node certificates into a drastically stronger collective certificate. The proposed method can be applied to node classification, image segmentation, and named-entity recognition tasks. "
SP:cc93dd2f68e415e2457166e78627865dc1b44697,This paper proposes Quantile Regression GAN (QRGAN) to improve the performance of GANs. The proposed method is based on quantile regression to minimize the 1-Wasserstein distance between real and generated data distribution between the discriminator and the generator. Quantile regression is used to train a discriminator that can be used to guide the generator to generate the generated data. The method is evaluated on the mixture of gussian dataset and image generation experiments. 
SP:4ddb47ee77c374ae6c3e419412d92ca77260692e,"This paper investigates relevance metrics for similarity-based explanations for machine learning models. The authors propose to evaluate relevance metrics in terms of their appropriateness. The relevance metrics are defined as the similarity of the gradients of the output of the model to the input of the classifier. Three relevance metrics (cosine similarity of gradients, identical class test and identical subclass test) are used to evaluate whether the relevance metrics satisfy the minimal requirements for similarity based explanation. The experiments show that cosine similarity is the best metric to evaluate the relevance of a relevance metric. The results also show that some relevance metrics perform poorly in the tests and analyze the reasons of their failure."
SP:6c2cbf2bc0f6dabe974e80ec1e82d2d12189906e,"This paper proposes adding a low-rank global attention (LRGA) module to graph neural networks (GNNs) to improve their generalization power. The proposed LRGA module is a computation and memory efficient variant of the dot-product attention (Vaswani et al., 2017). The authors show that adding LRGA to GNNs improves the performance on several graph classification, regression, node labeling and link prediction tasks. "
SP:b4abdd28504b4c1de239eabd4e0e27d370efee71,This paper proposes a method to improve the calibration performance of convolutional neural networks (CNNs) by combining the ideas of objectness and label smoothing during training. The proposed method is based on a smoothing factor that is adaptive based on the relative object size within an image. The authors show that the proposed method can reduce the confidence of CNNs by an order of magnitude when trained on context-only images.
SP:5254658923e594294b69d124a8d004166852822a,"This paper proposes a two-layer fully-convolutional ReLU denoising network for image reconstruction. The proposed method is based on the duality of the dual network, which is a non-convex and convex dual network. The dual network is trained with weight decay regularization and piecewise linear filtering. Experiments on MNIST and fastMRI datasets confirm the efficacy of the proposed method. "
SP:085cad6bc143c8713580bddfaa71f06496dac314,"This paper proposes an end-to-end speech synthesis method that uses a combination of adversarial feedback and prediction losses to generate high-quality audio. The proposed method is based on a differentiable alignment scheme based on token length prediction. The authors also propose soft dynamic time warping in the spectrogram-based prediction loss to capture temporal variation in the generated audio. In the experiments, the proposed method achieves a mean opinion score exceeding 4 on a 5 point scale. "
SP:01148cea55db606aa78d27e900818684a8bce9ab,"This paper proposes a non-parametric method for node representation learning for attributed graphs with missing attributes. The proposed method is based on a decomposition of the attribute matrix into discrete distributions in a lower-dimensional space equipped with the Wasserstein metric. The authors propose to smooth the distribution representations of nodes with information from their local neighborhoods to reduce the distortion caused by missing attributes and obtain integrated representations expressing information of both topology structure and attributes. Two algorithms are proposed for node classification (with missing attributes) and matrix completion respectively, and demonstrate their effectiveness in experiments."
SP:aeeb5909f7123ef631f569b469af9715205c881f,"This paper proposes a meta-learning method for reinforcement learning in environments with sparse extrinsic rewards. The proposed method, AMIGO, trains a goal-conditioned policy in the absence of (or alongside) environment reward. The teacher learns to propose increasingly challenging, yet achievable, goals that allow the student to learn general skills for acting in a new environment, independent of the task to be solved. Experiments show that the proposed method gradually learns to interact with the environment and solve tasks in procedurally generated environments. "
SP:3d05bc7dca97681cb582298e318b9b973841eed3,"This paper studies the problem of information retrieval from a dataset of files stored on a single server under both a user distortion and a user privacy constraint. Specifically, a user requesting a file from the dataset should be able to reconstruct the requested file with a prescribed distortion, and in addition, the identity of requested file should be kept private from the server. The proposed model can be seen as an extension of the well-known concept of private information retrieval by allowing for distortion in the retrieval process and relaxing the perfect privacy requirement. The authors show that the optimal rate-distortion-leakage tradeoff is convex and that in the limit of large file sizes this allows for a concise information-theoretical formulation in terms of mutual information."
SP:3f9e2db00fc3dcd7a40588adcb638503ec10dc09,"This paper proposes a decoupled greedy learning method for graph neural networks (GNNs) that decouples the GNN into smaller modules and associates each module with greedy auxiliary objectives. This allows GNN layers to be updated during the training process without waiting for feedback from successor layers, thus making parallel GNN training possible. Further, a lazy update scheme is proposed to further improve the efficiency of the proposed method. The proposed method is evaluated on several benchmark datasets and shows superior efficiency while not sacrificing much performance."
SP:5ecb1b288f7fc02aead4493f81640867bc349290,"This paper proposes a framework for answering complex queries on incomplete Knowledge Graphs. Each query is converted into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. The proposed method is evaluated on a large set of complex queries, including queries using logical conjunctions, disjunctions, existential quantifiers, and missing edges. The results show that the proposed method outperforms the state-of-the-art black-box neural models."
SP:f04a522fd04c503754fdb8c52da68646d31271a4,"This paper proposes a method to check the local robustness of neural networks with piecewise linear activation functions. The proposed method is based on finding the decision boundaries within a set of convex polyhedral regions in which the network’s behavior is linear. The authors show how the regions around a point can be analyzed using simple geometric projections, thus admitting an efficient, highly-parallel GPU implementation that excels particularly for the `2 norm, where previous work has been less effective. Empirically, the method is shown to be far more precise than many approximate verification approaches, and scales to much deeper networks. "
SP:5297651ff873f97c07b9c47ed3eff52251661844,"This paper proposes an approach to embedding objects in an affordance space, in which each dimension corresponds to an aspect of meaning shared by many actions, using text corpora. This embedding makes it possible to predict which verbs will be applicable to a given object, as captured in human judgments of affordance, better than a variety of alternative approaches. The dimensions learned are interpretable, and correspond to typical patterns of interaction with objects. Finally, the dimensions can be used to predict a state-of-the-art representation derived purely from human judgements of object similarity."
SP:72b4f3b40c6c6fa2eb53e95ed9a10a4077ffa049,"This paper proposes a method for the emergence of individuality in multi-agent reinforcement learning (MARL) by learning a probabilistic classifier that predicts a probability distribution over agents given their observation and gives each agent an intrinsic reward of being correctly predicted by the classifier. The intrinsic reward encourages the agents to visit their own familiar observations, which makes the intrinsic reward signals stronger and in turn makes the agents more identifiable. Two regularizers are proposed to increase the discriminability of the classifiers. Empirical results show that EOI outperforms existing methods in a variety of multi agent cooperative scenarios."
SP:112509d6d3573a9d495d182fdfae6ec0327cddf5,"This paper proposes a randomized smoothing method to improve the certified robustness of randomized smoothed classifiers. The proposed method, SWEEN (Smoothed WEighted Ensembling (SWEEN)) is based on the ensembling generality of random smoothed models. Theoretical analysis shows that the optimal SWEen model can be obtained from training under mild assumptions. An adaptive prediction algorithm is also proposed to reduce the prediction and certification cost. Extensive experiments show that the proposed method outperforms the upper envelope of their corresponding candidate models by a large margin."
SP:ea892e3d199ed6121279b20061a87f43afae8796,"This paper proposes a method to decompose tasks into sub-tasks by learning the subtask hierarchy by learning from demonstration. The method is based on the idea of inductive bias. The authors propose to use a bottom-up recurrence and a top-down recurrence to implement horizontal update and vertical expansion respectively. Experiments on Craft and Dial demonstrate that the proposed method can achieve higher task decomposition performance under both unsupervised and weakly supervised settings, comparing with strong baselines. "
SP:cc6aa977ce561a2493ae74bb694205cd67c8d890,"This paper proposes a Causal Semantic Generative model (CSG) for out-of-distribution (OOD) prediction from a single training data set. The proposed method is based on the causal invariance principle, with a novel design in variational Bayes for both efficient learning and easy prediction. Theoretically, the authors prove that under certain conditions, CSG can identify the semantic factor by fitting training data, and this semantic-identification guarantees the boundedness of OOD generalization error and the success of adaptation. Empirical study shows improved OOD performance over prevailing baselines."
SP:be3f34a59e5e61dcdbc7cb085f031ba4a5a5b758,"This paper studies the problem of online learning with adversarially corrupted rewards in the setting of stochastic multi-armed bandits, linear contextual bandits, and Markov Decision Processes (MDPs). The authors propose a new algorithm, UCRL2, that maintains robust estimates of the estimated rewards and transition probabilities at each state-action pair. They show that the proposed algorithm achieves near optimal regret with respect to the true uncorrupted reward distribution. They also provide empirical evidence on synthetic and real datasets."
SP:6d62a80aaebb2988df3953d4d7164e5a2fa1aa6d,"This paper proposes Rewriter-Evaluator, a neural machine translation (NMT) framework that consists of a rewriter and an evaluator. At every pass, the rewriter produces a new translation to improve the past translation and the evaluators estimates the translation quality to decide whether to terminate the rewriting process. The authors also propose a prioritized gradient descent (PGD) method to train the re-writer and the evaluation jointly. Extensive experiments on two translation tasks, Chinese-English and English-German, show that the proposed framework significantly improves the performance of NMT models and significantly outperforms previous baselines."
SP:9761fca8848868dfc9cacdab2537f8276ca76e0f,"This paper proposes a method to learn a multimodal predictive distribution for semantic segmentation, where the empirical frequency of the sampled predictions closely reflects that of the corresponding labels in the training set. To this end, the authors propose a novel two-stage, cascaded strategy for calibrated adversarial refinement. In the first stage, they explicitly model the data with a categorical likelihood, and train an adversarial network to sample from it an arbitrary number of coherent predictions. The proposed method is evaluated on the multigrader LIDC dataset, a modified Cityscapes dataset, and a toy regression dataset."
SP:ce965758f1b795a56c02f45d6a8d06cb8bdf29cb,"This paper proposes a new method for dealing with contractive compressors in distributed stochastic optimization algorithms. The proposed method is based on the framework of compressed communication with error feedback (EF). EF is the only known technique that can deal with the error induced by contractive compressor which are not unbiased, such as Top-K or PowerSGD. In this paper, the authors propose a new and theoretically and practically better alternative to EF, which can transform any contractive compression method into an induced unbiased compressor. The authors also extend their results to federated learning with partial participation following an arbitrary distribution over the nodes, and demonstrate the benefits thereof."
SP:4fd702490293e481c79614852ba27dd3ce9215a4,"This paper proposes a new research framework for hyperparameter transfer across adjustments (HT-AA) that aims to leverage knowledge obtained from previous hyper-parameter optimization (HPO) steps to speed-up a new HPO. The authors provide four simple HT-AA baseline algorithms and eight benchmarks changing various aspects of ML algorithms, their hyperparameters search spaces, and the neural architectures used. They also provide a python package with an out-of-the-box usable implementation of their algorithms. "
SP:e8f99bae5853de525450fcb8facd23cf973fc161,"This paper studies the effect of label representation on the performance of deep neural networks. The authors propose to use audio labels as the supervised signal for image classification. They show that high-entropy label representations (i.e., high dimensional, high entropy labels) produce more robust and data-efficient neural networks, and low-dimensional labels with low entropy do not have these benefits and may even lead to worse performance. They also show that features learned through label representations exhibit more robustness under various adversarial attacks and better effectiveness with a limited amount of training data. "
SP:4e8d924cba7367af0999b30d79250b4dc40413e1,"This paper proposes a method for ensemble neural networks to improve model robustness and uncertainty performance. The method is based on a multi-input multi-output (MIMO) configuration, where a single model is used to train multiple subnetworks that independently learn the task at hand. By ensembling the predictions made by the sub-networks, the method is able to improve the performance of ensemble networks without increasing the computational cost. The proposed method is evaluated on CIFAR-10, ImageNet, and ImageNet-100 datasets."
SP:d2f1c23b67c6744101034dc5e1c70765a733b169,"This paper proposes a method to transfer intermediate knowledge obtained from one Convolutional Neural Network (CNN) to another by utilizing sparse representation learning (SRM). SRM first extracts sparse representations of the hidden features of the teacher CNN, which are then used to generate both pixel-level and image-level labels for training intermediate feature maps of the student network. The authors formulate SRM as a neural processing block, which can be efficiently optimized using stochastic gradient descent and integrated into any CNN in a plug-and-play manner. The experiments demonstrate that SRM is robust to architectural differences between the teacher and student networks and outperforms other KD techniques across several datasets."
SP:e8c0f43bd5debf6544f588cd3442dc3dd62d0eee,"This paper proposes a novel method for learning representations for reinforcement learning. The main idea is to use a state similarity metric (PSM) to measure behavioral similarity between states. The PSM is motivated by the fact that the optimal policies in those states as well as in future states are likely to be similar. The authors also propose a contrastive representation learning procedure to embed any state similarity metrics, which they instantiate with PSM to obtain policy similarity embeddings (PSEs1). Experiments show that PSEs improve generalization on diverse benchmarks."
SP:92f3b4942da9075440dda618f561a85f8fde5a5c,"This paper proposes a method to disentangle natural factors of variation in data (e.g. object shape vs pose) by learning to map each of these factors to distinct subspaces of a model’s latent representation. The authors show that this approach introduces discontinuities in the encoder for a broad family of affine transformations such as rotations and translations. They then propose an alternative, more flexible approach, which relies on distributed equivariant operators, potentially acting on the entire latent space, and theoretically and empirically demonstrate the effectiveness of their approach."
SP:ef0f58c462bc5dd1c7b78f562c42a4e17f0f252b,"This paper proposes to use the nonlinear Hawkes process (Hawkes process) to model the excitation-inhibition interaction among neurons in neural spike trains. The authors propose to use three auxiliary latent variables (Pólya-Gamma variables, latent marked Poisson processes and sparsity variables) to make functional connection weights in a Gaussian form, which allows for a simple iterative algorithm with analytical updates. The EM algorithm is derived to obtain the maximum a posteriori (MAP) estimate. Empirical results show that the EM algorithm can estimate the temporal dynamics of interaction and reveal the functional connectivity underlying neural spike train. "
SP:1156d3deac022829bda930ffcb081947609d972b,"This paper studies the dynamics of two-layer neural networks (2LNNs) trained with gradient descent (GD) algorithm for training two layer neural networks in the under-parameterized regime. It shows that there are two phases in the GD dynamics in this regime: an early phase in which the dynamics follows closely that of the corresponding random feature model, followed by a late phase where the neurons are divided into two groups: a group of a few (maybe none) “activated” neurons that dominate the dynamics and another group of “quenched’ neurons that support the continued activation and deactivation process. In particular, when the target function can be accurately approximated by a relatively small number of neurons, this quenching-activation process biases GD to picking sparse solutions. This neural network-like behavior is continued into the mildly over-parametrized regime, in which it undergoes a transition to a random featurelike behavior where the inner-layer parameters are effectively frozen during the training process. This is qualitatively different from the dynamics associated with the ""mean-field"" scaling where all neurons participate equally."
SP:9e81401a6f30c70d870a12cce0cf600557f92b80,"This paper proposes a method to solve constrained Markov decision process (CMDP) problems by decomposing the CMDPs into a pair of MDPs; reconnaissance MDP and planning MDP. In R-MDP, the agent trains the threat function, the Q-function analogue of danger that determines whether a given state-action pair is safe or not, and trains a reward-seeking policy while using a fixed threat function to determine the safeness of each action. The proposed method is able to solve other CMDP problems with different reward and different danger-constraint without the need to re-train the model. The authors also present an efficient approximation method for the threat functions that can greatly reduce the difficulty of solving R-RDPs."
SP:f1d4ac7d5516dd0df742e224c8c09c721d0d0886,"This paper studies the effect of different loss functions on the performance of modern neural networks trained with square loss and cross-entropy loss. The paper shows that square loss performs comparably or better when trained with the square loss, even after equalizing computational resources. It also shows that the cross entropy loss appears to have a slight edge on computer vision tasks. "
SP:915f1f0fc4850507c28c1d609239b41775863ebe,"This paper proposes a method for self-supervised reinforcement learning from pixels. The proposed method, called Self-Predictive Representations (SPR), trains an agent to predict its latent state representations multiple steps into the future using an encoder which is an exponential moving average of the agent’s parameters and makes predictions using a learned transition model. On its own, this future prediction objective outperforms prior methods for sample-efficient deep RL from pixels, and it further improves performance by adding data augmentation to the future prediction loss, which forces the agent's representations to be consistent across multiple views of an observation. "
SP:983f01c170909c8c67fd3be25f121bd61bdd8307,"This paper proposes InstantEmbedding, an efficient method for generating single-node representations using local PageRank computations. The authors theoretically prove that their approach produces globally consistent representations in sublinear time. They demonstrate this empirically by conducting extensive experiments on real-world datasets with over a billion edges. They also show that their method produces high quality representations that meet or exceed the state-of-the-art for unsupervised representation learning on tasks like node classification and link prediction."
SP:d11037b8fe2b10aee672ba82f69410b40181f0f9,"Graph coarsening is a popular technique to reduce the size of a graph while maintaining its essential properties. This paper proposes a framework for measuring the quality of coarsened algorithms and shows that depending on the goal, we need to carefully choose the Laplace operator on the coarse graph and associated projection/lift operators. Motivated by the observation that the current choice of edge weight for the coarse graphs may be suboptimal, the paper proposes to parametrize the weight assignment map with graph neural networks and train it to improve the graph-coarsening quality in an unsupervised way. Extensive experiments on both synthetic graphs and real networks demonstrate that the proposed method GOREN significantly improves common graph coarsens methods under different evaluation metrics, reduction ratios, graph sizes, and graph types."
SP:0d680213339f0e2aedb0be4aeed51423706b8bf6,"This paper proposes a method to estimate the scattering field of 3D objects based on discrete-laplacian and implicit encoders. The method is based on a point cloud approximation of each object, and each point is encoded in a high-dimensional latent space. The proposed method can accurately estimate these acoustic properties for arbitrary topologies and takes less than 1ms per object on a NVIDIA GeForce 2080 Ti GPU. The authors also prove that their learning method is permutation and rotation invariant and demonstrate high accuracy on objects that are quite different from the training data."
SP:afc33a782c43e3d4c5c4fbf047d0b1108bc30bae,"This paper proposes Risk Extrapolation (REx) as a method to reduce the variance of the training risk across training domains. The authors show that this reduces the model's sensitivity to a wide range of distributional shifts, including the distributional shift where the input contains both causal and anti-causal elements. They motivate this approach as a form of robust optimization over a perturbation set of extrapolated domains (MMREx), and propose a penalty on the training risks (V-REx as a simpler variant). They show that REx can recover the causal mechanisms of the targets, while also providing some robustness to changes in the input distribution."
SP:411d5bcf7698d534ad60f581d479ff74849ba4de,"This paper proposes a method for learning Fourier neural operators for solving PDEs with zero-shot super-resolution. The method is based on the Fourier transform of the integral kernel of the PDE, which is used to parameterize the operator directly in Fourier space, allowing for an expressive and efficient architecture. Experiments on Burgers’ equation, Darcy flow, and Navier-Stokes equation show that the proposed method is able to solve PDE solvers up to three orders of magnitude faster compared to traditional methods."
SP:41d268d0eac9b4c84baa156fb641aa6d3060b5a4,"This paper studies the implicit bias of gradient flow (i.e., gradient descent with infinitesimal step size) on linear neural network training. The authors propose a tensor formulation of neural networks that includes fully-connected, diagonal, and convolutional networks as special cases, and investigate the linear version of the formulation called linear tensor networks. With this formulation, the convergence direction of the network parameters are characterized as singular vectors of the tensor defined by the network. For separable classification, the authors show that gradient flow finds a stationary point of the `2/L max-margin problem in a “transformed input space”. For underdetermined regression, they prove that gradient flows find a global minimum which minimizes a norm-like function that interpolates between weighted `1 and `2 norms in the transformed input space. "
SP:e27907ef4a4e6e0f5841618fcaa7e7e0db443f91,This paper studies the problem of optimizing the width-multipliers of slimmable neural networks. The authors propose a method to jointly optimize the width multipliers for different layers and the shared weights in a network. The proposed method is based on stochastic gradient descent. The method is evaluated on the ImageNet dataset and MobileNetV2 dataset.
SP:cf59403abb6ca89ccee4f8e77e9a33d99e6a00f5,"This paper studies the problem of federated semi-supervised learning (FSSL) in the setting where clients have labeled and unlabeled data (labels-at-client) and the server has labeled data only available at the server. The proposed method, FedMatch, is based on federated learning (FL) with SSL, where the data is available at both client and server, and where the server only has access to the labeled data at the client. The authors show that FedMatch outperforms both local SSL and SSL with SSL algorithms under the conventional labels at-client scenario and the novel labels- at-server scenario. "
SP:9457b6d430a2cd864d526d7e90bf3e1ab13d6df4,"This paper proposes CoLES, a self-supervised learning method for discrete event sequences. CoLES is based on contrastive learning, which is an extension of Contrastive Learning (CL) to the discrete event sequence domain. The authors show that CoLES outperforms other methods on several downstream tasks. "
SP:385942a5bcee7384bb722a1669b541f2fac0cd36,"This paper proposes a method for unsupervised dependency parsing and constituency parsing in natural language. The proposed method is based on a transformer-based parsing framework that can jointly generate constituency tree and dependency graph. The authors propose a dependency-constrained self-attention mechanism to induce dependency and constituency structure at the same time. The experimental results show that the proposed method can achieve strong results on un-supervised constituency parsing, dependency parsing, and masked language modeling tasks. "
SP:078966ff62775bba6031e47d374bda95f4a7dde3,This paper proposes a method to learn the mapping between scene graph nodes and visual objects under weak supervision. The proposed method learns a metric among visual objects and scene graphs by incorporating information from both object features and relational features. Extensive experiments on Visual Genome (VG) and Visual Relation Detection (VRD) datasets verify that the proposed method post an improvement on scene graph grounding task over current state-of-the-art approaches. Further experiments verify the grounding found by the proposed model can reinforce the performance of the existing method.
SP:4644dbf7466b6234d8abf69995fdfb357efcc119,"This paper proposes two variants of sliced fused sliced fused Gromov Wasserstein (SFG) to reduce the inner discrepancy between the prior and aggregated posterior distributions. First, the authors propose a new relational discrepancy, named spherical sliced fused gromov wasserstein, that can find an important area of projections characterized by a von Mises-Fisher distribution. Second, they introduce two variants, MSSFG and PSSFG, that replace the vMF distribution by a power spherical distribution to improve the sampling time in high dimension settings. Finally, they apply the new discrepancies to the RAE framework to achieve its new variants. Experiments are conducted on image generation and reconstruction tasks."
SP:5ae2c0af82cac89a65f1cc38c43e2d05ea298901,"This paper proposes a method to reduce the training time of deep linear networks by stopping weight sharing during training and then continuing training until convergence. The method is based on a theoretical analysis of the convergence of linear networks. Theoretical analysis is done for linear networks with repeated layers, and the method is applied to linear models with multiple layers, where the weights are shared across all the repeated layers. Experiments show that the proposed method is able to reduce training time by 50% for BERT."
SP:a51710551142316b67e2fccd969fea1ece35ba39,"This paper studies the relationship between the adversarial transferability and the interaction inside adversarial perturbations. The authors show that there is a negative correlation between the transferability of the perturbation and the interactions inside the perturbed data. They then propose a new loss function to penalize the interaction during the attacking process. The proposed loss function penalizes interactions during the attack process, which is shown to significantly improve the adversary transferability. "
SP:f1565319075c1442c2cb52d96443facb492c06c2,"This paper studies the role of forgetting in deep neural networks. The authors find that deep layers are disproportionately responsible for forgetting, with sequential training resulting in an erasure of earlier task representational subspaces. To mitigate forgetting, the authors propose several methods to stabilize these deeper layers, but show diversity on precise effects, with some increasing feature reuse while others store task representations orthogonally, preventing interference. They also show that maximal forgetting occurs for task sequences with intermediate similarity."
SP:30d7532cdcf420bff3be6b92eea3d93bce59e6bd,"This paper proposes a method to reduce the training time of BERT, a very large language model. The proposed method is based on the idea of early bird ticketing, which is used to identify winning tickets in the early stage of training BERT. The method is applied to both pre-training and fine-tuning of large-scale language models and achieves comparable performance to standard BERT with 35-45% less training time. "
SP:c547f23ff6caaf5e9f35d258490b86ae0ac8ed03,"This paper studies the robustness of f-divergence measures in the context of learning with noisy labels. The authors derive a family of f divergences that are robust to label noise in the presence of label noise, where the divergence is a linear combination of the variational difference defined on the clean distribution and a bias term introduced due to the label noise. They show that when maximizing a properly defined f-Divergence measure with respect to a classifier’s predictions and the supervised labels is robust with label noise and the noise rate is small. They also propose fixes to make them more robust. "
SP:841888179dcdac901889c8d62cb5234311fe28f1,This paper proposes ensemble-based weighted Bellman backups for off-policy deep reinforcement learning. The proposed method re-weights the target Q-values based on uncertainty estimates from a Q-ensemble. The authors show that the proposed method stabilizes and improves learning on both continuous and discrete control tasks. They also investigate the signal-to-noise aspect by studying environments with noisy rewards.
SP:afc08f203562b841180811aef943bfb63a1659ea,"This paper proposes a method for estimating task uncertainty in few-shot classification problems. The method is based on the notion of distributional mismatch between support and query sets via class-wise similarities. The proposed method is algorithm-agnostic and readily expanded to include a range of meta-learning models. Experiments show that the proposed method helps the model avoid being indiscriminately confident, and thereby, produce calibrated classification results."
SP:12ae325ea3bce1e60195afac7d85895d2d20c29c,"This paper proposes a novel method for learning video-text representation learning. The authors propose to use a generative model to naturally push these related samples together. Each sample’s caption must be reconstructed as a weighted combination of other support samples’ visual representations. This simple idea ensures that representations are not overly-specialized to individual samples, are reusable across the dataset, and results in representations that explicitly encode semantics shared between samples. "
SP:8a71d8fad25a126aff01431cacf348c05de75667,"This paper proposes a method to pre-train a Chinese BERT model with a pre-trained vocabulary that is based on a Chinese word segmentation (CWS) and sub-word tokenization. The proposed method, called seg tok, is a variant of the pre-training method proposed by Bert Devlin et al. (2018), where the vocabulary is derived from Chinese characters. The authors also propose three methods to improve the performance of BERT on sentence-level tasks. "
SP:b93ec7bc02b48068073ffe705f71d2643e663d51,This paper proposes a method for distributed training of graph convolutional neural networks (GCNs) for graph-based learning. The proposed method is based on unbiased boundary sampling strategy to enable efficient and scalable distributed GCN training while maintaining the full-graph accuracy. Experiments and ablation studies validate the effectiveness of the proposed method in terms of training performance and achieved accuracy.
SP:2d4ba873d11e969ebd1fc31f9b5ab450c964d154,"This paper proposes a graph neural network (GNN) model for estimating per-atom forces in quantum chemistry simulations. The proposed model is based on graph neural networks and uses 3D molecular structure to estimate per-atomic forces in 3D space. The authors show that the proposed model reduces the estimation error of atomic forces by 30% compared to existing models, and generalizes well to out-of-distribution structures. Finally, the authors apply their model to the large-scale catalyst dataset, OC20, where the model is able to achieve 4x higher success rate than existing ML models."
SP:8bdcf4fe6abf4739d4732b7ea8538513135dcccc,"This paper proposes a new generalization bound for neural networks based on Rademacher complexity. The generalization bounds are based on the distance between the weights from their initial values. The authors show that this bound has no dependence on the number of weights and compares favourably to other bounds when applied to convolutional networks. Inspired by this, the authors develop a simple yet effective fine-tuning algorithm that constrains the hypothesis class to a small sphere centred on the initial pre-trained weights, thus obtaining provably better generalisation performance than conventional transfer learning. Empirical evaluation shows that their algorithm works well, corroborating the theoretical results."
SP:3a3249e97ef2345ea2264de5ed8287e16687838e,"This paper investigates the phenomenon of decoupling the hyperparameters for mask discovery (Hfind) and mask evaluation (Heval) in unstructured magnitude pruning on vision classification tasks. The authors show that different Hfind values yield masks with materially different layerwise pruning ratios and that the decoupled find-eval phenomenon is causally mediated by these ratios. They also show that this phenomenon holds across a number of models, datasets, configurations, and also for one-shot structured pruning. "
SP:2d6f5d72b21675f74ff4cde4d16bfb36abd5795f,"This paper proposes a metric called m-coherence to study the alignment of per-example gradients during training of ResNet and EfficientNet models on ImageNet and several variants with label noise. This metric is more interpretable, cheaper to compute, and mathematically cleaner than other commonly used metrics. The metric is closely connected to gradient diversity, a quantity previously used in some theoretical bounds. The authors show the evolution of alignment of gradients in ResNet, Efficientnet, and ImageNet models. "
SP:e7c5de9a475d0ba71bc79580e8436024fb2c6f59,"This paper studies the problem of generating summary statistics for implicit generative models where the evaluation of the likelihood function is intractable but sampling data from the model is possible. The authors frame the task of constructing sufficient statistics as learning mutual information maximizing representations of the data with the help of deep neural networks. They apply their approach to both approximate approximate Bayesian computation and recent neural likelihood methods, boosting their performance on a range of tasks. "
SP:c5997bf2348e94949684f45fbd418661e85220c1,"This paper proposes a fully unsupervised image-to-image translation model (TUNIT) that simultaneously learns to separate image domains and translate input images into the estimated domains. The proposed model achieves comparable or even better performance than the set-level supervised model trained with full labels, generalizes well on various datasets, and is robust against the choice of hyperparameters (e.g., pseudo domains)."
SP:0cd97e64e638cabbeea0fdef3e9c5b33f4000f72,"This paper studies the implicit bias of gradient descent training of wide neural networks and the corresponding implicit bias in function space for 1D regression. The authors show that the solution of training a width-n shallow ReLU network is within n-1/2 of the function which fits the training data and whose difference from initialization has smallest 2-norm of the weighted second derivative with respect to the input. The curvature penalty function 1/ζ is expressed in terms of the probability distribution that is utilized to initialize the network parameters, and the authors compute it explicitly for various common initialization procedures. "
SP:8b885142facbb3b8db41ec9d83822cee81324694,"This paper studies the problem of weight decay in deep neural networks. The authors find that the L2 regularization is unstable weight decay for all optimizers that use Momentum, such as stochastic gradient descent (SGD), and decoupled weight decay is highly unstable for all adaptive gradient methods. They propose the stable weight decay (SWD) method, which applies a bias correction factor on decoupling weight decay to make weight decay more stable during training. The proposed SWD method makes significant improvements over the existing Adam with L2 and AdamW regularization methods."
SP:a3206dc71e32ba1830895bf442d3840f3331a532,This paper proposes a novel method to combine the strengths of both Translation Memory (TM) and neural machine translation (NMT) to improve the translation quality of NMT. The authors treat the matched sentence pair of TM as the additional signal and apply one encoder enhanced by the pre-trained language model (PLM) to encode the TM information and source sentence together. They extend the sentence level retrieval method to the n-gram retrieval method and explore new methods to manipulate the information flow from TM to the NMT decoder. They validate their proposed methods on a mixed test set of multiple domains and show that the proposed methods can significantly improve NMT translation quality and show strong adaptation for an unknown domain.
SP:72b43991a242872b2ceb1861e8ffbdf26c9f4818,"This paper proposes a new convolutional neural network based on the principles of rate reduction and shift invariant classification. The authors show that the basic iterative gradient ascent scheme for maximizing the rate reduction of learned features naturally leads to a deep network, one iteration per layer. The architectures, operators (linear or nonlinear), and parameters of the network are all explicitly constructed layer-by-layer in a forward propagation fashion. All components of this “white box” network have precise optimization, statistical, and geometric interpretation. The experiments show that such a network can already learn a good discriminative deep representation without any back propagation training."
SP:f8b02cf1b918b0956761829ec6ef9127596071ec,"This paper studies the implicit acceleration of gradient flow in over-parameterized two-layer linear models. The authors show that implicit acceleration emerges from a conservation law that constrains the dynamics to follow certain trajectories. More precisely, gradient flow preserves the difference of the Gramian matrices of the input and output weights and the amount of acceleration depends on both the magnitude of that difference (which is fixed at initialization) and the spectrum of the data. "
SP:e5f086c806be88d50e461a782b5b00124f4656fb,"This paper proposes CLIME, a method for generating explainable explanations for opaque ML models. CLIME is based on uniform sampling of user-defined subspaces of the input domain. The authors show that CLIME can mitigate the problem of out-of-distribution (OOD) sampling and can be used to train a surrogate interpretable model to be locally faithful on perturbed instances. They also propose an efficient estimation algorithm to measure the true value of metrics such as fidelity up to any desired degree of accuracy, which can help in building trust in the generated explanations."
SP:b1d5ef15772e192eb8c8a0e65b3c21ee7c794295,"This paper proposes a novel pre-trained language model called AMBERT (A Multi-Grained BERT) that takes both fine-grained and coarse-graining tokenization as input after tokenization, employs one encoder for processing sequence of words and the other encoder to process the sequence of phrases, utilizes shared parameters between the two encoders, and finally creates a sequence of contextualized representations of the words and phrases. Experiments are conducted on benchmark datasets for Chinese and English, including CLUE, GLUE, SQuAD, RACE, and CLUE. The results show that the proposed model outperforms the existing best performing models in almost all cases, particularly the improvements are significant for Chinese."
SP:fd1cfe80343d3789227d99d836a5674374a234f5,"This paper proposes a Transformer-based model for semantic parsing. The main idea is to incorporate Long Short-Term Memory (LSTM) into the Self-Attention mechanism of the original Transformer to capture more local context of phrases. Experimental results show that the proposed model captures the detailed meaning better than Transformer, raises local context awareness and achieves strong competitive performance on semantic parsing datasets."
SP:2056a65a7500d79465685af883083cd706277c1f,"This paper proposes a new adversarial training method to improve the robustness of deep neural networks (DNNs) against combinations of multiple perturbations. The proposed method, called CAT, is based on the idea of compositing multiple adversarial perturbation models. The authors show that the proposed method outperforms existing methods by large margins in defending against compositions of pixel and spatial transformations, two major classes of adversarial attacks."
SP:006e5b9ac9a8eb7223843731488bfefbd8eb09bd,"This paper proposes a method for learning abstract rules from sensory data. The method is based on a recurrent network augmented with an external memory that enables a form of variable-binding and indirection. This binding mechanism allows symbol-like representations to emerge through the learning process without the need to explicitly incorporate symbol-processing machinery, enabling the ESBN to learn rules in a manner that is abstracted away from the particular entities to which those rules apply. The proposed method is evaluated on a suite of tasks involving relationships among images that are governed by abstract rules. The results show that the proposed method can generalize abstract rules to novel entities given only a limited number of training examples."
SP:4171ce45966ac499f51450a19fb233934c0847f0,"This paper proposes a new framework, Translation between Augmented Natural Languages (TANL), to solve many structured prediction language tasks including joint entity and relation extraction, nested named entity recognition, relation classification, semantic role labeling, event extraction, coreference resolution, and dialogue state tracking. Instead of tackling the problem by training task-specific discriminative classifiers, the authors frame it as a translation task between augmented natural languages, from which the task-relevant information can be easily extracted. The proposed method achieves new state-of-the-art results on joint entity extraction, relation extraction (CoNLL04, ADE, NYT, and ACE2005 datasets), relation classification (FewRel and TACRED), and semantic roles labeling (coNLL-2005 and CoNLL2012). The authors also show that the proposed method can also significantly improve the performance in a low-resource regime."
SP:8f1b2fc6829e0bdfcc981020b0dcf3e63a947910,"This paper studies the problem of unlabeled entity recognition, where the entities of a sentence may not be fully annotated. The authors identify two causes of performance degradation of NER models: 1) reducing the number of annotated entities and 2) treating unannotated entities as negative instances. Based on these observations, the authors propose a general approach, which can almost eliminate the misguidance brought by unlabeling entities. The key idea is to use negative sampling that, to a large extent, avoids training NER-based models with unlabelled entities. Experiments on synthetic datasets and real-world datasets show the effectiveness of the proposed approach."
SP:dd76ece8d92a8a230a8b43033d8cb2368c677a94,"This paper proposes a novel acoustic word embedding method based on stochastic neighbor embedding (SNE) that maps a sequence of words to a vector space of fixed, reduced dimensions. The Euclidean distance between coordinates in the embedding space reflects the phonetic confusability between their corresponding sequences. Two encoder neural networks are trained: an acoustic encoder that accepts speech signals in the form of frame-wise subword posterior probabilities obtained from an acoustic model and a text encoder which accepts text in the forms of subword transcriptions. Compared to a triplet loss criterion, the proposed method is shown to have more effective gradients for neural network training. It also gives more accurate results with low-dimensional embeddings."
SP:9142189126b8612ac0acee6fe18a0cfcb70b6545,"This paper proposes a play algorithm for stationary mean-field games, where the goal is to learn a pair of state and policy that constitute the Nash equilibrium. The algorithm is based on gradient descent and proximal policy optimization, respectively. The authors show that the algorithm converges to a Nash equilibrium at a sublinear rate. "
SP:c498f8a199da1818fe64ed88b0825c5aad688aec,"This paper studies the problem of probabilistic inference on the joint distribution defined by a normalizing flow model. Given a pre-trained flow model p(x), the authors propose a method to approximate the target conditional distribution by parametrizing this new distribution as another flow model using variational inference. The authors show that this task is computationally hard for a large class of flow models. Motivated by this hardness result, the proposed method trains a new generative model with the property that its composition with the given model approximates the conditional distribution. The proposed method is able to handle conditioning under arbitrary differentiable transformations. "
SP:1d0f27f61c9d32911b8bd15d6b82ef5eec644f0f,This paper proposes a new high-resolution image segmentation dataset for Electron Microscopy (EM) for cell membrane segmentation. The U-RISC dataset is the largest annotated EM dataset for the Cell membrane with multiple iterative annotations and uncompressed high resolution raw data. The authors also propose a new evaluation criterion called Perceptual Hausdorff Distance (PHD) to measure the quality of cell segmentation results. Experiments are conducted to verify the effectiveness of the proposed criteria.
SP:8ca7aff87c82be69c9542550c814f52c9419ab0a,"This paper proposes a new benchmark for continual learning (CL) based on short streams of tasks. The authors propose a new modular architecture, whose modules represent atomic skills that can be composed to perform a certain task. Learning a task reduces to figuring out which past modules to re-use, and which new modules to instantiate to solve the current task. The learning algorithm leverages a task-driven prior over the exponential search space of all possible ways to combine modules, enabling efficient learning on long stream of tasks, and achieves competitive performance on the new benchmark."
SP:cc819c61f408e88f247eb87946187ccec3dad32e,"This paper proposes a generative model-based unsupervised meta-learning method for few-shot classification tasks. The proposed method generates pairs of in-class and out-of-class samples from the latent space in a principled way, allowing us to create synthetic classes forming the training and validation data of a meta-task. The experimental results show that the proposed method outperforms or is competitive with current unsupervisory learning baselines on the most widely used benchmark datasets. "
SP:b25771e5c214a352f74ba6196fbd88bca6c43c98,"This paper studies injectivity of fully connected and convolutional ReLU layers and networks. The authors show that global injectivity with iid Gaussian matrices, a commonly used tractable model, requires larger expansivity between 3.4 and 10.5. They also characterize the stability of inverting an injective network via worst-case Lipschitz constants of the inverse. Finally, using an argument based on random projections, they show that an end-to-end-doubling of the dimension suffices for injectivity. "
SP:a95a153d3fe9bcf535ebf8514f51d00df483f210,"This paper proposes a continuous conditional generative adversarial network (CcGAN) for image generation conditional on continuous, scalar conditions (termed regression labels). Existing conditional GANs (cGANs) are mainly designed for categorical conditions (e.g., class labels); conditioning on regression labels is mathematically distinct and raises two fundamental problems: (1) Since there may be very few (even zero) real images for some regression labels, minimizing existing empirical versions of cGAN losses (a.k.a. empirical cGAN loss) often fails in practice; (2) Since regression labels are scalar and infinitely many, conventional label input methods are not applicable. The proposed CcGAN solves the above problems, respectively, by reformulating existing empirical losses to be appropriate for the continuous scenario; and proposing a novel method to incorporate regression labels into the generator and the discriminator. The empirical discriminator losses, termed the hard vicinal discriminator loss (HVDL) and the soft vicinal discriminate loss (SVDL), are derived under mild assumptions in this work. A new benchmark dataset, RC-49, is also proposed for generative image modeling conditional on regression label."
SP:10dd09ab315870631d1451d200f2c87a023f8226,"This paper proposes an active learning algorithm for semi-supervised learning (SSL) and active learning (AL) that aims to reduce the sample complexity by actively querying unlabeled instances to be annotated by a human-in-the-loop. The authors argue that AL algorithms that seek diversity on labeled samples can be improved upon when using SSL as the training scheme. To this end, the authors propose an algorithm that focuses on controlling the convergence rate of a classification network by querying instances to improve the rate of convergence upon inclusion to the labeled set. The proposed algorithm is based on the neural tangent kernel (NTK) and the authors show that the proposed algorithm can achieve the performance of SSL with far less labeled samples than SL."
SP:7f3947c3fa5b09674507d8f3e10d9280376ecb94,"This paper proposes a new method for federated learning, where the server orchestrates cooperation between a subset of randomly chosen devices in each round. The authors point out that the minima of the local-device level empirical loss are inconsistent with those of the global empirical loss, and propose a dynamic regularizer for each device at each round, so that in the limit the global and device solutions are aligned. They demonstrate both through empirical results on real and synthetic data as well as analytical results that their scheme leads to efficient training, in both convex and non-convex settings."
SP:a3fbb073b0e2371b20d5d9df6ab829673f90354f,"This paper proposes a method to speed up the training of self-supervised contrastive learning algorithms with little or no loss of accuracy. The main idea is to truncate the back-propagation and update only a part of the parameters for each gradient descent update. The proposed method is based on the observation that intermediate contrastive losses are a good surrogate of the final similarity between pairs of images, and thus can be used to further reduce the computational cost. Experiments show that the proposed method can save the training time with almost no loss on the final performance of the downstream tasks. "
SP:5b5e705ea1ee1b857e17e64d560a39052804949d,"This paper studies the global convergence and global optimality of actor-critic in the single-timescale setting, where the actor and critic are updated simultaneously. Specifically, in each iteration, the critic update is obtained by applying the Bellman evaluation operator only once while the actor is updated in the policy gradient direction computed using the critic. The authors also consider two function approximation settings, linear function approximation and deep neural networks, and prove that the actor sequence converges to a globally optimal policy at a sublinear O(K-1/2) rate. "
SP:26705a4dc305cce336f657c5937d1f5b4209548a,"This paper proposes to represent log files at three levels of abstraction: field level, log level, and sequence level. The representation for each level can be computed from the previous level. These representations are in vector format and serve as interfaces to downstream applications. The authors use a version of Transformer Networks (TNs) to encode numerical and textual information that is suitable for log embeddings. They show how a number of log processing applications can be solved with their representation."
SP:165c51a16f17fb8726e968f8b34742b62011d60e,"This paper proposes a method to decompose convolutional layers into a sequence of wavelet decompositions, which are modulated by mixture weights. The method is motivated by the similarities between trained CNN kernels and oriented Gabor filters for addressing this problem. The proposed method is evaluated on the AlexNet architecture for image classification as an example. "
SP:d0a284da462584724ba6a3a48c9e986d391233f6,"This paper proposes a coach-player framework for dynamic multi-agent teams with heterogeneous agents. The proposed framework assumes that the players only have a partial view of the environment, while the coach has a complete view. The coach coordinates the players by distributing individual strategies. Specifically, the authors propose an attention mechanism for both the players and the coach, incorporate a variational objective to regularize learning, and design an adaptive communication method to let the coach decide when to communicate with different players. Experiments on resource-collection tasks in the multi agent particle environment show that the proposed method achieves comparable or even better performance compared to methods where players have full observation but no coach."
SP:4eb662b527d556758aaa1a0b589495fcc337fad0,"This paper studies the effect of influence functions in deep neural networks on the accuracy of influence estimates. The authors provide extensive experiments on a variety of datasets, including Iris, MNIST, CIFAR-10, ImageNet, and ImageNet-10. They find that the influence estimates for deep networks are often erroneous for shallow networks, while for deeper networks the estimates are erroneous. They also find that for certain network architectures and datasets, training with weight-decay regularization is important to get high-quality influence estimates and the accuracy can vary significantly. "
SP:5fea74a2031d097a99dacf613bedcb054b0c3831,"This paper studies the connection between the pretraining task of next word prediction and text classification. The authors hypothesize and verify empirically that classification tasks of interest can be reformulated as sentence completion tasks, thus making language modeling a meaningful pre-training task. Theorems 4.1 and 4.2 show that -optimal language model (in cross-entropy) will do O(\sqrt{O}(\tilde{O})^2-well on such tasks. Theorem 4.3 shows a stronger result for low-dimensional softmax models by leveraging a new tool, conditional mean features. The usefulness of language model features themselves is demonstrated by arguing a weak linear relationship between them and conditional means features. Experiments verify the sentence completion reformulation idea and the good performance of conditional mean feature on standard benchmarks. "
SP:a67da438e9821010284416170c3699ae7ff96c99,"This paper proposes a new method for detecting membership inference attacks (MIA), which aims to detect if data samples were used to train a neural network model. Unlike the traditional MIA approaches, addressing classification models, this paper addresses conditional image generation models (e.g. image translation). Due to overfitting, reconstruction errors are typically lower for images used in training. This paper proposes to use a novel difficulty score that can be computed for each image, and its computation does not require a training set. The proposed method is shown to achieve high MIA accuracy on an extensive number of benchmarks."
SP:6fe23ebe09f2a4e42a21598f8e9c79edeca99863,"This paper proposes a differentiable architecture search method by formulating the neural architecture search problem into a distribution learning problem. The proposed method DrNAS treats the continuously relaxed architecture mixing weight as random variables, modeled by Dirichlet distribution, which can be optimized with gradient-based optimizer in an end-to-end manner. This formulation improves the generalization ability and induces stochasticity that naturally encourages exploration in the search space. Extensive experiments demonstrate the effectiveness of DrNAS."
SP:c590d0ed2487b42480b53fc077546a4a0bc27a78,"This paper proposes a new method for function approximators for low-dimensional but complex functions. The proposed method is based on multiplicative filter networks (MFNs), which simply multiply together sinusoidal or Gabor wavelet functions applied to the input. The authors show that the proposed method performs as well or better than SIREN or Fourier feature networks on a variety of tasks."
SP:f5be855300f63c185a006834302bd4b033b56258,"This paper proposes a teacher-student scheme to enable the gradient-based meta-learning algorithms to explore long horizons by the inner loop. The key idea is to employ a student network to adequately explore the search space of task-specific models (e.g., by more than ten steps), and a teacher then takes a “leap toward the regions probed by the student” to arrive at a high-quality model but also defines a lightweight computation graph for meta-gradients. The proposed method is evaluated on three tasks: few-shot learning, long-tailed classification, and meta-attack."
SP:0361e02d56b7d121cb5ede1cb582284cc18fc599,"This paper proposes a new algorithm for offline reinforcement learning based on behavior regularization. The main idea is to use an analytical upper bound on KL divergence as the behavior regularizor to reduce the variance associated with sample-based estimations. The authors also propose state-dependent Lagrange multipliers for the regularization term to avoid distributing distributing KL divergence penalty across all states of the sampled batch. Finally, the authors propose a gradient penalty term to the policy evaluation objective to penalize the gradient of the Q value w.r.t the out-of-distribution actions. The proposed algorithm BRAC+ outperforms existing model-free and model-based offline RL algorithms on the D4RL benchmark."
SP:b2cfb380aa2a21f72f508b453cf5949257a5b4ec,This paper proposes Adjoined networks as a training approach that can regularize and compress any CNN-based neural architecture. The proposed method trains both the original and the smaller networks together. The parameters of the smaller network are shared across both the architectures. The authors prove strong theoretical guarantees on the regularization behavior of the adjoint training paradigm. Empirical evaluation on Imagenet and CIFAR-100 shows that the proposed method can achieve a 99.7x reduction in the number of parameters and a 5x improvement in inference time.
SP:dba40073f79143e5355d194aa16db9eee0267a5d,"This paper proposes an extension of the greedy algorithm for reinforcement learning (RL) based on temporal persistence. In particular, the authors propose to replace actions with temporally extended sequences of actions, or options (Sutton, Precup, and Singh, 1999). The authors argue that temporal persistence is the main limitation of greedy exploration, which limits its ability to escape local optima. The authors propose a temporal extension of greedy that simply repeats the sampled action for a random duration, and show that this extension improves exploration on a large set of domains. They also show that a simple set of domain-agnostic options work surprisingly well across a variety of environments. "
SP:5efb581a368ace3bd085d48801a899559d6a43ef,"This paper shows that for depth-2 matrix factorization, gradient flow with infinitesimal initialization is mathematically equivalent to a heuristic rank minimization algorithm, Greedy Low-Rank Learning (GLRL) under some reasonable assumptions. This generalizes the rank minimisation view from previous works to a much broader setting and enables them to construct counter-examples to refute the conjecture from Gunasekar et al. (2017). They also extend the results to the case where depth is deeper than 3, and they show that the benefit of being deeper is that the above convergence has a much weaker dependence over initialization magnitude so that this rank-minimization is more likely to take effect for initialization with practical scale."
SP:7f997cf7a63a7330fc12fd525516080c91a3cb9b,"This paper proposes a two-stage model patching method to improve the robustness of classifiers. The first stage models subgroup features within a class and learns semantic transformations between them, and then trains a classifier with data augmentations that deliberately manipulate sub-group features. The second stage trains the classifier using a CycleGAN to learn intra-class, inter-subgroup augmentations, and balances subgroup performance using a theoretically-motivated subgroup consistency loss and robust objective. Experiments on three benchmark datasets demonstrate the effectiveness of the proposed method."
SP:de6cea1e35a0555175e17546a93422e9a96a511e,"This paper proposes a rule-based representation learning method for decision trees. The proposed method is based on the idea of learning non-differentiable non-fuzzy rules for data representation. To train the model, the authors propose a novel training method, Gradient Grafting, that can directly optimize the discrete model using gradient descent. An improved design of logical activation functions is also devised to increase the scalability of RRL and enable it to learn the continuous features end-to-end. Experiments on 9 small and 4 large data sets show the effectiveness of the proposed method."
SP:e36388a9452e557dd51bf0170bf2f9da22271a49,"This paper proposes a new regret minimization algorithm for molecular property prediction. The proposed algorithm is based on invariant risk minimization (IRM) and extends IRM to structured environments. The main idea of IRM is to find a representation that enables the predictor to compete against an oracle with hindsight access to held-out environments. To this end, the authors propose a new IRM-based algorithm, RGM, and extend IRM for structured environments by recasting simultaneous optimality condition in terms of predictive regret. Experiments show that RGM significantly outperforms previous state-of-the-art baselines. "
SP:cad3ed2fba57faf17a3e8899dc5a744d5358aa68,"This paper proposes a novel architecture, cross-probe BERT, for cross-modal text-vision retrieval. The proposed method is based on the two-tower architecture, where the vision probes and the image’s local features are concatenated and fed into the vision tower and generate the attended vision probes, and the text probes are fed to the text tower and generated by the attended text probes. The authors show that the proposed method outperforms the state-of-the-art methods on two public benchmarks. "
SP:51fd82de525fcb738fdeaeeae20fbb2cdf975f0c,"This paper proposes a model-free actor-critic algorithm named forward-looking actor (FORK) for Actor-Critic algorithms. The proposed FORK can be easily integrated into TD3, TD3-FORK, SAC, and Ant-v3. The experiments on six Box2D and MuJoCo environments with continuous state and action spaces demonstrate significant performance improvement for TD3 and SAC. A variation of FORK is further shown to solve BipedalWalkerHardcore in as few as four hours using a single GPU."
SP:6e730239e6e8b43c4988dd61dca30f15dc039ef7,"This paper proposes a new federated learning algorithm, FEDBE, which aggregates local models into a global model by sampling higher-quality global models and combining them via Bayesian model ensemble. The authors show that an effective model distribution can be constructed by simply fitting a Gaussian or Dirichlet distribution to the local models. The empirical studies validate FED BE’s superior performance, especially when users’ data are not i.i.d. and when the neural networks go deeper."
SP:3ac5f437fc349a33810d0645664d1c448528af74,This paper presents a method for analyzing the performance of BERT models under double-blindness. The paper is well-written and easy to follow. The authors provide a detailed description of their methodology for understanding the BERT model. They also provide an overview of related works in the literature. 
SP:efa2343ead47263a0d09e1c17f9aa044605b9650,"This paper presents a Lyapunov based analysis of the loss function of deep neural networks to derive an a priori upper bound on the settling time of neural networks. The authors formulate the supervised learning framework as a control problem where weights of the network are control inputs and learning translates into a tracking problem. An analytical formula for finite-time upper bounds on settling time is provided under the assumptions of boundedness of input. Finally, the authors prove that our loss function is robust against input perturbations."
SP:7a0ded4b3b2d08d43765ff7b722da9b9863aabd6,"This paper studies the problem of learning disentangled representations from synthetic data. The authors propose to use the mutual information between each learned latent variable and the auxiliary variable to correctly identify informative latent variables. They show that the method taken by GIN for informative latent variable selection is not theoretically supported and can be disproved by experiments. They further show the advantage of their method on various downstream tasks including classification, outlier detection and adversarial attack defence on both synthetic and real data."
SP:0d9ba12bbf47b13a46c2225f9dc06878418daaea,"This paper proposes a new pooling operation for convolutional neural networks. The proposed method, called LiftDownPool, decomposes a feature map into various downsized sub-bands, each of which contains information with different frequencies. By performing LiftUpPool backward, a corresponding up-pooling layer is able to generate a refined upsampling feature map. Experiments show that the proposed method achieves better results on image classification and semantic segmentation."
SP:147239edceb17bade6ea5d3dca44e3a59998aa47,"This paper proposes a fast, distance-preserving, binary embedding algorithm to transform a high-dimensional dataset T ⊆ R into binary sequences in the cube {±1}. When T consists of well-spread (i.e., non-sparse) vectors, the embedding method applies a stable noise-shaping quantization scheme to Ax where A is a sparse Gaussian random matrix. The authors show that Euclidean distances among the elements of T are approximated by the `1 norm on the images of T under a fast linear transformation. This contrasts with standard methods, where the Hamming distance is used instead. The proposed method is both fast and memory efficient."
SP:f65e229bca3904095743e7a501b1083cc60f1e22,"This paper proposes a method to learn plasticity rules for the weights of recurrent neural networks (RNNs) that can be used to improve the robustness and generalization of RNNs. The authors argue that the plasticity rule can be learned by gradient descent (GD) on the rule parameters of the RNN. They provide both empirical and theoretical evidence for this hypothesis. In the experiments, the authors show that learning plastic rules through GD recovers two classical supervised learning algorithms, the Perceptron algorithm and the Multiplicative Weights (or Winnow) algorithm. They also show that the classifiers learned using plastic rules exhibit surprising levels of tolerance to adversarial perturbations. "
SP:f435530146fa975cb27cd375a857df9bcbd87682,"This paper proposes a method for visual question generation (VQG) that aims to generate visual questions with answer-awareness and region-reference. The proposed method is based on a Graph-to-Sequence learning framework that first models the image as a dynamic graph and learns the implicit topology end to end, and then uses a graph to sequence model to generate the questions with double hints. Experiments on VQA2.0 and COCO-QA datasets demonstrate that the proposed method can significantly outperform existing state-of-the-art baselines."
SP:53a26ce11647866d3f6ba8b84ca9f13106197a8d,"This paper studies the effect of optimal regularization on the performance of linear regression models with isotropic data distribution. Theoretically, the authors prove that optimally-tuned `2 regularization achieves monotonic test performance as we grow either the sample size or the model size. Empirically, they show that optimizing the regularization can mitigate double descent for more general models, including neural networks. "
SP:c193ccc74b987beaf8d53a29a8529a0af5e87742,"This paper proposes a spatial dependency network (SDN) to improve generative modeling by better exploiting spatial regularities and coherence in images. The proposed SDN is based on spatial dependency networks (SDNs) that use a sequential gating-based mechanism to distribute contextual information across 2-D space. The authors show that SDN improves density estimation over baseline convolutional architectures and the state-of-the-art among the models within the same class. In addition, SDN can be applied to large images by synthesizing samples of high quality and high coherence. "
SP:db91512a90e75675af03c2f197751c8526d6f5e9,"This paper proposes EMaQ, an off-policy reinforcement learning algorithm for offline RL, which is based on BCQ (Fujimoto et al., 2018a). The main contribution of this paper is a simplification of BCQ, which removes a heuristic design choice and naturally restricts extracted policies to remain exactly within the support of a given behavior policy. Empirical results show that EMaq outperforms SAC in the offline RL setting and outperforms prior state-of-the-art in the D4RL benchmark tasks. In the online RL setting, it is competitive with Soft Actor Critic. "
SP:e2b80adeaa9208e0667a64a3f24661f77b48e487,"This paper proposes a batch selection algorithm to improve model fairness in machine learning. The proposed algorithm, called FairBatch, is based on bilevel optimization. The main idea of the algorithm is to use batch selection as an inner optimizer to select the minibatch size for the purpose of improving model fairness. The algorithm is evaluated on synthetic and real-world datasets. The results show that the proposed algorithm outperforms existing methods in terms of fairness."
SP:72f26b850bb2258223c0fc71598e35ad07d690e6,"This paper studies the bounds on the Lipschitz constant of monotone deep equilibrium (DEQ) models. The authors show that monDEQs are monotonicity-strongly connected, which means that the bounds can be bounded as a simple function of the strong monotonic parameter of the network. The bounds are shown to be tight on both the input-output mapping and the weight-output maps defined by these networks, and are comparable to those for comparable standard DNNs.  The authors also show that one can use these bounds to design monOTone DEQ models, even with e.g. multiscale convolutional structure, that still have constraints on the Lipshitz constant. "
SP:bcfd4d7fd4590e3bc248a0a5422ce4b67db74a74,"This paper proposes a method for imitation learning and goal-conditioned reinforcement learning. The main idea is to use density estimation to estimate the density of expert states that the agent is likely to visit and then use this density estimate to guide the agent towards those states. The paper shows that the proposed method can be applied to both imitation learning (i.i.d.) and goal conditioned reinforcement learning (VDI) settings. In the imitation learning setting, VDI is able to learn from extremely sparse amounts of expert data and achieves state-of-the-art results on a common benchmark. In goal conditioned setting, the paper demonstrates that VDI can circumvent the problem of sparse rewards while addressing hindsight bias."
SP:d57550b2f323b356d7e609acc35ee33039f376b4,"This paper proposes a variational multi-task learning (VMTL) framework for simultaneously learning multiple related tasks. The proposed VMTL is based on variational Bayesian inference, which enables task relatedness to be explored in a principled way by specifying Gumbel-softmax priors. Each prior is represented as a mixture of variational posteriors of other related tasks and the mixing weights are learned in a data-driven manner for each individual task. Experiments on four benchmark datasets demonstrate the effectiveness of the proposed method."
SP:3ccdf8322f16c8a7bef82e32fad4c03969a510d1,"This paper proposes a systematic and unified benchmark, Long-Range Arena, for evaluating long-range Transformer models under long-context scenarios. The benchmark is a suite of tasks consisting of sequences ranging from 1K to 16K tokens, encompassing a wide range of data types and modalities such as text, natural, synthetic images, and mathematical expressions requiring similarity, structural similarity, and visual-spatial reasoning. The paper systematically evaluates ten well-established long range Transformer model (Reformers, Linforms, Linear Transformers, Sinkhorn Transformers, Performers, Synthesizers, Sparse Transformers, and Longformers) on the benchmark suite."
SP:e12e410c3335b76133ceda4c865b244fbbab8580,"This paper proposes a multilingual code summarization model that jointly learns on Context and Structure of source code. The proposed model uses only language-agnostic features, i.e., source code and its parsed abstract syntax tree (AST; Structure) and features that can be computed directly from the AST. Besides obtaining state-of-the-art results on monolingual code summarisation on all five programming languages considered in this work, the proposed model also trains the first multilingual model on multiple programming languages substantially improves the performance on all languages."
SP:f46e98d48f90071831f1c0069bf74a7993be6db8,"This paper proposes a new method for audio-visual navigation in a 3D environment, where the goal is to find a sound source in an unmapped 3D space. The proposed method is based on an end-to-end reinforcement learning approach that learns to dynamically set the waypoints in the environment and uses an acoustic memory to store what the agent has heard as it moves through the environment. The method is evaluated on the Replica and Matterport3D environments. The results show that the proposed method outperforms the state-of-the-art in terms of the number of points in SPL on heard sounds and generalizes better to unseen sounds."
SP:23bfe317dcef00a91ea92389b3f39d9b93972454,"This paper investigates the effect of weight initializations on the convergence of small convolutional neural networks trained to predict n steps of Conway's Game of Life. The authors find that networks trained on this task rarely converge to a solution, and that networks require substantially more parameters to consistently converge. They also find that the initialization parameters are sensitive to small perturbations, such as a single sign change. "
SP:1b5ba618d3e28d48f9205c0780f8288a08fa5392,"This paper proposes a new algorithm for semi-supervised learning. The algorithm considers not only the perturbed inputs but also the similarity among the inputs having the same label. The authors introduce a new objective function, BatchMean Triplet loss, which has the advantage of computational efficiency while taking into account all input samples. The proposed algorithm achieves state-of-the-art performance across many standard SSL benchmarks with various labeled data amounts."
SP:f3abccf4a2566ffbc821aba209fab15058639ad4,"This paper studies the problem of few-shot meta-learning, where the goal is to learn a new task from a small number of examples from a set of previous tasks in a sequential learning setting. The authors propose a new algorithm that can adapt to variable amounts of data, and an online version of this algorithm that addresses the above problem setting of online incremental learning. The proposed algorithm is based on the idea of meta-training and meta-adaptation, and the authors show that the proposed algorithm can outperform empirical risk minimization and a previous online meta learning method (Finn et al., 2019) on two online image classification problems consisting of sequences of classification tasks and one online regression problem. "
SP:95cb420d92ec42e12a4bbb0e66224f1c498a7161,"This paper presents a series of probes to test the sensitivity of Transformer representations to sentence-level structure in sentences. The probes are designed to test several kinds of structure in the sentence. The authors compare the representations from perturbed sentences against the original sentence using three different perturbations: random permutations of n-grams of varying width, swapping of two spans which do or do not form a syntactic phrase, and swapping two adjacent words which either break apart or break apart syntactic phrases. They also connect their probe results to the Transformer architecture by relating the attention mechanism to syntactic distance between two words. "
SP:cb27b27a6fefc192ad1c2bd083d13eb9e51a5c44,"This paper studies the few-shot image synthesis task for GANs with minimum computing cost. The authors propose a skip-layer channel-wise excitation module and a self-supervised discriminator trained as a feature-encoder. They show that the proposed model converges from scratch with just a few hours of training on a single GPU, and has a consistent performance with less than 100 training samples. "
SP:c0dbeb5d94b2388595cf7ad9675c55df0bac7f8e,This paper proposes a novel dual dual algorithm for neural network bounding. The main idea of the proposed method is to use a linear relaxation of the activations of a neural network to obtain tight neural network bounds. The proposed method can be viewed as a specialised dual solver that operates on a small active set of dual variables. The authors show that the proposed dual algorithm recovers the strengths of the new relaxation in the dual space: tightness and a linear separation oracle. They also show that their method can achieve better bounds than off-the-shelf dual solvers in only a fraction of their running time. 
SP:56e3837417dbcce0d65338dc3aac4e1a20eb0df8,"This paper proposes a method to augment pre-trained language models with concept-centric commonsense knowledge. The authors propose both generative and contrastive objectives for learning common sense from the text, and use them as intermediate self-supervised learning tasks for incrementally pre-training PTLMs (before task-specific fine-tuning on downstream tasks). The proposed method, CALM, outperforms T5-base on four commonsense-related NLU datasets (i.e., COMMONSENSEQA, PEARL QA, PIQA and ANLI) and COMMONGEN, a commonsense related NLG dataset. "
SP:7ec69bdee021af506293c87a3b75bce1c40a03d7,"This paper proposes a method for unsupervised physical object discovery. The proposed method uses multi-scale pixel cues and physical motion cues to accurately segment observable and partially occluded objects of varying sizes, and infer properties of those objects. The model reliably segments objects on both synthetic and real scenes. The discovered object properties can also be used to reason about physical events. "
SP:66997bc19a3ba6548fcf21f114e748bea95cad1c,This paper proposes a method to improve the robustness of deep neural networks (DNNs) against adversarial attacks. The proposed method increases the margins of training samples by moving the decision boundaries of the DNN model far away from the training samples to improve robustness. The IMA method is evaluated on six publicly available datasets (including a COVID-19 CT image dataset) under strong 100-PGD white-box attacks and the results show that the proposed method significantly improved classification accuracy on noisy data while keeping a relatively high accuracy on clean data.
SP:276ffd59fbf49e3ee02756da8920218102214917,"This paper proposes ProKT, a new method for knowledge distillation. The proposed method is based on projecting the supervision signals of a teacher model into the student’s parameter space by decomposing the training objective into local intermediate targets with approximate mirror descent technique. Experiments on both image and text datasets show that the proposed ProKT method consistently achieves the state-of-the-art performance."
SP:906dc21d6988953fcf57d63bbdd12973e5818d16,"This paper proposes a channel pruning method to solve the problem of compression and acceleration of Convolutional Neural Networks (CNNs). The proposed method uses a hyper-structure network to generate the architecture of the main network, which can be optimized by regular backpropagation and regularization term to specify the computational resource of the compact network. The authors also introduce learnable layer-wise scaling factors to balance the gradients from different terms, and they can be optimize by hyper-gradient descent. Extensive experimental results on CIFAR-10 and ImageNet show that the proposed method is competitive with state-of-the-art methods."
SP:890fd9454596c051b0e9535baf73b1dd1fae67ca,"This paper proposes a method to train a theorem prover to prove a higher-order logic theorem in the presence of a large knowledge base of potential premises without learning from human proofs. This is achieved by augmenting the exploration of premises based on a simple tf-idf (term frequency-inverse document frequency) based lookup in a deep reinforcement learning scenario. The experiments show that the proposed method, dubbed DeepHOL Zero, outperforms provers that are trained only on human proofs, and approaches the performance of a prover trained by a combination of imitation and reinforcement learning."
SP:88209417a8ad07e6103084e41709be900303ce5f,"This paper proposes a data augmentation method called MODALS (Modalityagnostic Automated Data Augmentation in the Latent Space) to augment data for any modality in a generic way. The main idea is to fine-tune four universal data transformation operations in the latent space to adapt the transform to data of different modalities. Experiments on multiple datasets for text, tabular, time-series and image modalities demonstrate the effectiveness of the proposed method."
SP:6d84670d321b0d584b097c630574bd748e85c9a2,"This paper studies the mean field limit of three-layer neural networks under stochastic gradient descent training. The authors provide a global convergence result for unregularized feedforward three layer networks in the mean-field regime. They show that under suitable regularity and convergence mode assumptions, a universal approximation property, natural of neural networks, holds at any finite training time (not necessarily at convergence). "
SP:b90f893f927db9c439595fd119a565cf43c971f4,"This paper proposes a method for learning explanations of expert decisions by modeling their reward function in terms of preferences with respect to “what if” outcomes: Given the current history of observations, what would happen if we took a particular action? To learn these costbenefit tradeoffs associated with the expert’s actions, the authors integrate counterfactual reasoning into batch inverse reinforcement learning. This offers a principled way of defining reward functions and explaining expert behavior, and also satisfies the constraints of real-world decision-making where active experimentation is often impossible (e.g. in healthcare). "
SP:c92916780418bfa7f0796fd9766b6d28b9eea5ef,"This paper studies the problem of continuous control in graph neural networks (GNNs) in the context of multi-task reinforcement learning (MTRL). The authors propose a transformer-based approach AMORPHEUS, a GNN-based method for continuous MTRL. They show that GNNs do not improve the performance of the proposed method. They also show that the proposed approach is more sample efficient than existing methods that use morphological information to define the message-passing scheme."
SP:2cf58f5cac20dccdc2034ef60e8e46b7988ebd7d,"This paper proposes a method for visual counting, which aims to predict the number of occurrences given a natural image and a query (e.g. a question or a category). Unlike most prior works that use explicit, symbolic models which can be computationally expensive and limited in generalization, this work proposes a simple and effective alternative by revisiting modulated convolutions that fuse the query and the image locally. Following the design of residual bottleneck, the method is called MoVie, short for Modulated ConVolutional bottlenecks. The proposed method is shown to achieve state-of-the-art performance on counting-specific VQA tasks while being more efficient and outperforming prior-art on difficult benchmarks. "
SP:c64e77507e562f236cb69361b22fb1a7951ffb22,"This paper proposes a model-targeted poisoning attack that can target a desired model based on online convex optimization. The authors prove that the model induced by training on the original training data with these points added, converges to the target classifier as the number of poison points increases, given that the loss function is convex and proper regularization is adopted in training. They also provide a lower bound on the minimum number of poisoning points needed to reach the target model (Theorem 4.2), which can be used to estimate the optimality of the attack and indicate the intrinsic hardness of attacking different targets. The attack is also efficient in incremental poisoning scenario as it works in an online fashion and can incrementally find poisoning points that are nearly optimal."
SP:a526023ec4cb839b83c574d31f59a9a67bc7af00,"This paper proposes a method for efficient deep learning on point clouds. The proposed method is based on the PointNet model, which is a model binarized version of PointNet++ (Qi et al., 2017b), PointCNN, DGCNN, PointConv, and PointNet+ (Wang et al, 2019a). The main contributions of this paper are: 1. The authors propose a new method for point cloud binarization based on entropy-maximizing aggregation (EMA) and layer-wise scale recovery (LSR). 2. They show that aggregation-induced feature homogenization leads to a degradation of information entropy, and scale distortion hinders optimization and invalidates scale-sensitive structures. 3. They provide theoretical justifications and in-depth analysis for the proposed method. 4. They conduct extensive experiments on multiple tasks on the point cloud. "
SP:825b4d1db0c537a607655bb5b4bf221ec672c8af,This paper proposes to augment the Transformer-based Transformer model with memory tokens to selectively store global as well as local representations of a sequence. The proposed method is called Memory-augmented Neural Networks (MANNs) which extend traditional neural architectures with general-purpose memory for representations. Experiments are conducted on machine translation and language modelling tasks to show the effectiveness of the proposed method.
SP:f0fa1b7684bc605f6edd4813c44be20988fe8b4c,"This paper proposes Prototypical Contrastive Learning (PCL), an unsupervised representation learning method that bridges contrastive learning with clustering. PCL learns low-level features for instance discrimination, but more importantly, it encodes semantic structures discovered by clustering into the learned embedding space. Specifically, PCL introduces prototypes as latent variables to help find the maximum-likelihood estimation of the network parameters in an Expectation-Maximization framework. The authors iteratively perform E-step as finding the distribution of prototypes via clustering and M-Step as optimizing the network via contrastive Learning. "
SP:5342a5e1d87fd17b1a2efed967dbbfeafa440ee7,This paper proposes an orthogonal multi-path (OMP) block to improve the robustness of deep neural networks against adversarial attacks. The OMP block consists of a block containing multiple paths to learn robust features and the parameters of these paths are required to be orthogonality with each other. The proposed OMP blocks can be posed in any layer of a neural network and the neural networks learn features that are appropriate for all the paths and hence are expected to be robust. Experiments on white-box and black-box attacks demonstrate the effectiveness of the proposed method.
SP:776df66274ed12449fde8dcef873a593980f397c,"This paper proposes a self-supervised graph attention network (SuperGAT) for noisy graphs. SuperGAT learns more expressive attention in distinguishing mislinked neighbors by encoding edges, whose presence and absence contain the inherent information about the importance of the relationships between nodes. The authors analyze the classic attention forms GO and DP using label-agreement and link prediction tasks, and this analysis reveals that GO is better at label agreement and DP at link prediction. They propose recipes to design graph attention concerning homophily and average degree and confirm its validity through experiments on real-world datasets."
SP:80a05296d6b1e4c6e9e2df01938c73029ff8487d,"This paper proposes a new method for DSMAD (dialogue system for medical automatic diagnosis), which aims to learn an agent that mimics the behavior of a human doctor, i.e., inquiring symptoms and informing diseases. The proposed method, called INS-DS (Introspective Diagnosis System), consists of two separate yet cooperative modules: an inquiry module for proposing symptom-inquiries and an introspective module for deciding when to inform a disease. The authors also propose two evaluation metrics to validate the reliability and robustness of DSMAD methods."
SP:10ae09d90d465125433a9b4f15b1405ab017920d,This paper proposes a batch-wise regularization method for fine-grained visual classification (FGVC) based on the proposed Batch Confusion Norm (BCN) to address the long-tailed distribution of natural world distribution. The proposed method is able to deal with both the inter-class similarity and intra-class variations in the FGVC problem. The authors extend the existing confusion energy-based framework to account for long tailed scenario to improve the performance of FGVC model by the BCN technique. The experimental results show that the proposed BCN method is effective and can be consistently boosted by incorporating extra attention mechanism.
SP:90f1e0fe1e9678d1e9a4dcb519d4e8fd61098ce0,This paper proposes a method for approximate reward inference in inverse reinforcement learning and imitation learning. The proposed method is based on a variational posterior distribution over the reward that scales to arbitrarily complicated state spaces. This is achieved by jointly learning an approximate posterior distribution with an imitator policy in an auto-encoderesque manner. Experiments are conducted on real medical data and simulated control environments. 
SP:ccd251d95c0a2d8dc5ad2a148ec29955e105e71e,"This paper proposes a method for learning counterfactual belief distributions for partially observable environments. The method is based on an auto-regressive belief distribution that is learned as a supervised task. In the multi-agent settings, the method uses a novel public-private model architecture for underlying policies in order to efficiently evaluate these policies during rollouts. In Hanabi, the proposed method obtains more than 60% of the benefit of exact search while reducing compute requirements by up to 35x."
SP:db408e6bfe69a9b3984f3b27ca92b802aa37af42,"This paper proposes a new method to control the trade-off between depth and breadth of the search in state-space planning. The proposed method, called Shoot Tree Search (STS), is an interpolation between two celebrated search mechanisms: MCTS and random shooting. It also lets the user control the bias-variance tradeoff, akin to TD(n), but in the tree search context. In experiments on challenging domains, STS can get the best of both worlds consistently achieving higher scores."
SP:5efc271ccc555fd9aa542548838170bd4c98e957,"This paper proposes a method for learning inductive bias in neural networks. The method is based on the idea that deduction, induction, and abduction form an irreducible set of reasoning primitives, and the authors design three synthetic tasks that are intended to require the model to have these three abilities. These synthetic tasks are designed in a way that they are devoid of mathematical knowledge to ensure that only the fundamental reasoning biases can be learned from these tasks. This defines a new pre-training methodology called “LIME” (Learning Inductive bias for Mathematical rEasoning). The authors show that LIME significantly outperforms vanilla transformers on three very different large mathematical reasoning benchmarks."
SP:bb8e0b554d3b3314fa343c902d9e60f1a141ea30,"This paper studies the inductive bias of gradient descent for weight normalized smooth homogeneous neural nets, when trained on exponential or cross-entropy loss. The analysis focuses on exponential weight normalization (EWN), which encourages weight updates along the radial direction. This paper shows that the gradient flow path with EWN is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. These results can be extended to hold for gradient descent via an appropriate learning rate."
SP:c71f9d2a602516865a0b103028186e83b52e5f00,"This paper proposes a method to address the problem of mode collapse in generative adversarial networks (GANs), where the discriminator is unable to maintain classification accuracy on previously seen samples, a phenomenon called Catastrophic Forgetting in continual learning. Motivated by this observation, the authors introduce a novel training procedure that dynamically spawns additional discriminators to remember previous modes of generation. The proposed method can be plugged-in to existing GAN frameworks to mitigate mode collapse and improve standard metrics for GAN evaluation."
SP:52c48198c95826e042f9e5a512ef3265daaff882,"This paper proposes a method to regularize BERT using reinforcement learning to automatically prune attention heads from BERT. The proposed method, AUBER, learns a pruning policy that determines which attention heads should or should not be pruned for regularization. Experimental results show that the proposed method outperforms existing pruning methods by achieving up to 9.39% better accuracy. "
SP:abcbbad146f1b0d5d579c215952c95e5499a378a,"This paper proposes a method to learn correspondence between two domains, one in vision and the other in physics. The correspondence is learned using unpaired and randomly collected data from the two domains. The authors propose dynamics cycles that align dynamic robot behavior across two domains using a cycle-consistency constraint. Once this correspondence is found, they can directly transfer the policy trained on one domain to the other, without needing any additional fine-tuning on the second domain. "
SP:006434d56992836ab9420d7d4215bc70664de304,"This paper studies the Shapley framework for explainability, which attributes a model’s predictions to its input features in a mathematically principled and model-agnostic way. The authors show that the assumption that the features are uncorrelated is an untenable assumption and develop two solutions to Shapley explainability that respect the data manifold. One solution, based on generative modelling, provides flexible access to data imputations; the other one directly learns the value function. "
SP:7cda6bccf08887c7cef66d0ac3ccefdea8f5d7c8,"This paper proposes a new method for opponent modelling based on variational autoencoders to reconstruct the local actions and observations of the opponent based on only the local observations. The proposed method is evaluated in two benchmark environments, the multi-agent particle environment and level-based foraging (LBF) environments. The results show that the proposed method achieves comparable performance to an ideal baseline which has full access to opponent’s information, and significantly higher returns than a baseline method which does not use the learned embeddings."
SP:c239bc531bcf7293032748af29a1b786e9d893dd,"This paper proposes Consistent Contrast (CO2), a method for semi-supervised contrastive learning on unlabeled images. CO2 is inspired by consistency regularization in semi-Supervised learning, which aims to encourage consistency between crops from the same image and other crops from other images. To this end, the authors introduce a regularization term that takes the similarity of a query crop to other crops as a pseudo label, and encourages consistency between these two similarities. Experiments show that CO2 improves Momentum (MoCo) by 2.9% on ImageNet linear protocol, 3.8% and 1.1% top-5 accuracy on 1% and 10% labeled semi supervised settings, and transfer to image classification, object detection, and semantic segmentation tasks."
SP:d18bab21790713e2facb053c47298fc9079ab783,"This paper studies the convergence of Optimistic Gradient Descent Ascent (OGDA) and Optimistic Multiplicative Weights Update (OMWU) in bilinear games over the simplex. The authors show that when the equilibrium is unique, linear last-iterate convergence is achieved with a learning rate whose value is set to a universal constant, improving the result of (Daskalakis & Panageas, 2019) under the same assumption. They extend the results to more general objectives and feasible sets for the projected OGDA algorithm, by introducing a sufficient condition under which OGDA exhibits concrete last iterate convergence rates with a constant learning rates whose value only depends on the smoothness of the objective function. Finally, they provide experimental results to support their theory."
SP:bbc7f77308b298c332a39747f693bc396f00a89f,"This paper proposes FedUV, a federated training method for user verification models in federated federated settings, where each user has access to the data of only one class and user embeddings cannot be shared with the server or other users. The main idea is to jointly learn a set of vectors and maximize the correlation of their instance embedding with a secret user-defined linear combination of those vectors. The authors show that choosing the linear combinations from the codewords of an error-correcting code allows users to collaboratively train the model without revealing their embedding vectors. They show that FedUV is on par with existing approaches, while not sharing the embedding vector with other users or the server."
SP:40fa47cc0928e2925ef5ce6d808073f368ca2cd4,"This paper proposes a method to estimate the effective dimension of class manifolds (CMs) of deep neural network classifiers by computing their intersection with random affine subspaces of varying dimension. This is done by computing the intersection of multiple CMs of different classes. The method is then used to compute the effective dimensions of CMs as well as the boundaries between CMs. The authors provide a theory for the technique and verify that their theoretical predictions agree with measurements on real neural networks. Extensive experiments are conducted to show the connection between the geometry of the CMs, generalization, and robustness."
SP:09bce202ac7a750c3700a8ef3cd92cfe8ed00c39,"This paper proposes a method to improve the exploration-exploitation trade-off in Soft Actor-Critic (SAC) policies. The main idea is to use the curiosity mechanism to increase the entropy temperature for unfamiliar states and decrease the target entropy for familiar states. To model curiosity for feature inputs, the authors propose a new curiosity model, X-RND, optimized by contrastive self-supervised learning. Experimental results on MuJoCo benchmark show that the proposed method significantly improves the sample efficiency, outperforming the advanced model-based / model-free RL baselines."
SP:dce5eb20581a21c5de0a9fc07a8a79a1fbb28c71,"This paper proposes a meta-reinforcement learning algorithm that is both efficient and extrapolates well when faced with out-of-distribution tasks at test time. The proposed method is based on a simple insight that dynamics models can be adapted efficiently and consistently with off-policy data, more easily than policies and value functions. The authors propose a model identification and experience relabeling (MIER) algorithm that adapts the model with gradient descent, and leverage all data collected from other tasks during meta-training, by using the learned model to relabel the next state and reward on every previously seen transition, obtaining synthetic data to continue training the policy. This enables MIER to adapt to tasks outside of the meta-train distribution, outperforming prior methods in this setting."
SP:34d78aa11f9d50baf75a9646a6f9128318c3389a,"This paper studies the few-shot learning (FSL) problem with sampling and label noise in the context of meta-learning. The authors propose two methods to address these two challenges. The first method, Eigen-Reptile (ER) updates the meta-parameters with the main direction of historical tasks to alleviate gradient noise. The second method, ISPL (Introspective Self-paced Learning) constructs a plurality of prior models to determine which sample should be abandoned. Empirical results show the effectiveness of the proposed methods."
SP:a571bff9ffe4edafd7bc064c4d10609e6b981ce3,"This paper proposes Adversarial batch normalization (Adversarial Batch Normalization (AdvBN), a method to train deep neural networks that are robust to distributional shifts in the mean and variance of deep image features. The proposed method is based on adversarial training by adversarially perturbing these feature statistics, rather than image pixels, to produce models that are more robust to distributionsal shifts. Experiments show that AdvBN improves the performance of ResNet-50 on ImageNet-C, Stylized-ImageNet, and ImageNetInstagram over standard training practices."
SP:6a9c46bd3cf854299f360bff136e1d79d3edb2e4,This paper proposes Variance of Gradients (VoG) as a proxy metric for detecting outliers in the data distribution. The authors provide quantitative and qualitative support that VoG is a meaningful way to rank data by difficulty and to surface a tractable subset of the most challenging examples for human-in-the-loop auditing. Data points with high VoG scores are far more difficult for the model to learn and over-index on corrupted or memorized examples. VoG can be computed using checkpoints stored over the course of training and is model agnostic.
SP:074bfacc75837bb19049be8a2890e10de073dd8e,"This paper proposes a method to improve the sample quality of deep generative models. The proposed method, called Discriminator Gradient Gradient f low (DGf low), is based on the gradient flow of entropy-regularized f-divergences between the real and the generated data distributions. The gradient flow takes the form of a non-linear Fokker-Plank equation, which can be easily simulated by sampling from the equivalent McKean-Vlasov process. By refining inferior samples, the proposed method avoids wasteful sample rejection used by previous methods (DRS & MH-GAN). Experiments on synthetic, image (CIFAR10 & STL10), text (Billion Words) and text datasets demonstrate that DGf low leads to significant improvement in the quality of generated samples."
SP:74ecbc5a6d464bfa49337da9e0dd6a0fe714d4bb,"This paper proposes a new pre-training method for multilingual Transformer models. The proposed method splits the standard Transformer block into several sub-modules trained with both innersequence and cross-sequence masked language modeling, and reorganizes certain sub- modules for understanding and generation tasks during inference. The method achieves state-of-the-art results on various cross-lingual understanding tasks of the XTREME benchmark covering text classification, sequence labeling, question answering, and sentence retrieval. For generation tasks, VECO also outperforms all existing cross-Linguistic models and SOTA Transformer variants."
SP:3d177ad50727d1a2619b68ab8a897b79d8652beb,"This paper proposes a novel intrinsic reward for reinforcement learning that encourages the agent to understand the causal effect of its actions through auditory event prediction. First, the agent collects a small amount of acoustic data and uses K-means to discover underlying auditory event clusters and then trains a neural network to predict the auditory events and use the prediction errors as intrinsic rewards to guide RL exploration. The authors conduct an in-depth analysis of their module using a set of Atari games and apply their model to audio-visual exploration using the Habitat simulator and active learning using the ThreeDWorld (TDW) simulator. "
SP:014f6118ebe55ece6be23c3a10f12e4591e444b1,"This paper studies the problem of novel category discovery on single and multi-modal data with labels from different but relevant categories. The authors propose an end-to-end framework to jointly learn a reliable representation and assign clusters to unlabelled data. To avoid over-fitting the learnt embedding to labelled data, the authors extend the self-supervised representation learning by noise-contrastive estimation and extend it to jointly handle labelled and unlabeled data. In particular, the proposed method uses category discrimination on labelled data and crossmodal discrimination on multi- modal data to augment instance discrimination used in conventional contrastive learning approaches. They further employ Winner-Take-All (WTA) hashing algorithm on the shared representation space to generate pairwise pseudo labels to better predict cluster assignments. The proposed method outperforms existing methods by a significant margin."
SP:4df640f502e88ddba2d7e183625231d70b083e82,"This paper proposes a method for weakly supervised segmentation, where the task is to assign a label to every pixel based on training instances with partial annotations such as image-level tags, object bounding boxes, labeled points and scribbles. The authors propose 4 types of contrastive relationships between pixels and segments in the feature space, capturing low-level image similarity, semantic annotation, co-occurrence, and feature affinity, and pixel-wise feature can be learned from training images with any partial annotations in a data-driven fashion. Experiments on Pascal VOC and DensePose demonstrate consistent gains over the state-of-the-art (SOTA), and the gain is substantial especially for the sparsest keypoint supervision."
SP:f7d6099adb40a0ce2f8a3563dbd5207cf1fdea0f,"This paper proposes a distillation strategy for unsupervised self-supervised learning. The key idea is to aggregate compact representations over the student with respect to instances in a bag. The proposed method achieves state-of-the-art performance on small scale models, i.e., 65.5% and 68.9% top-1 accuracies. "
SP:328866aad6544c81ded8980934df31dc4472435f,"This paper proposes GATSBI (Generative Adversarial Training for Simulation-based Inference) to learn implicit posterior distributions for SBI. The authors reformulate the variational objective in an adversarial setting to learn the implicit posterior distribution, which is amortised across observations, works in high-dimensional posterior spaces, and supports implicit priors. The proposed method is evaluated on two SBI benchmark problems and on two high dimensional simulators. "
SP:2915e82097eae4eb8546dc500f32b3ec37e3766f,"This paper studies the identification and estimation of individualized individualized treatment effects (TEs) under limited overlap. The authors propose a generative prognostic model based on recovering prognostic scores from observed variables, and the model is then learned as a new type of variational autoencoder (VAE). The authors also derive the TE error bounds that enable representations balanced for treatment groups conditioned on individualized features. The proposed method is compared with recent methods using (semi-)synthetic datasets."
SP:ca358c9f36aac6e58ed1b3949c349d210c49a48e,"This paper proposes a framework for autonomous reinforcement learning (ARL) where the agent not only learns through its own experience, but also contends with a lack of human supervision to reset between trials. The authors propose a new benchmark for ARL, named EARL1, which consists of a set of challenging and challenging simulated tasks. They also provide a formal definition of ARL and provide a number of instantiations that describe how common ingredients, such as irreversible states, interventions, and other components, fit into the general framework. They show that standard approaches to episodic RL and existing approaches struggle as interventions are minimized. "
SP:abe51d4a9817c08f0abde5da0bb8e6ca4e02e7cf,"This paper investigates the reasoning capability of Graph Neural Networks (GNNs) in the context of knowledge-powered QA. The authors propose a simple graph neural counter that can outperform existing GNN modules on CommonsenseQA and OpenBookQA, two popular QA benchmark datasets which heavily rely on knowledge-aware reasoning. They show that existing knowledge aware GNNs may only carry out some simple reasoning such as counting. They also show that even a simple GNN module can perform reasoning over knowledge graphs."
SP:3ea5a38e7fcd9111dcd299ad039b634e2781685f,"This paper proposes a three-stage compression method for Deep Neural Network (DNN) inference. The main idea is to use the Succinct Data Structures (SDS) to compress the representation of DNNs. The proposed method first transforms DNN models as their proposed formulations in either Element-wise or Block-wise manner. Then, the proposed method compresses the DNN model using SDS. Finally, the method exploits the specialized execution pipelines for different model formulations, to retrieve relevant data for DNN inference. "
SP:94c395afc794a9cc163e362078769ff83f3d20d0,"This paper proposes a new training method for improving the performance of tiny neural networks by augmenting the model. The authors argue that training tiny models is different from training large models because tiny models tend to suffer from under-fitting rather than over-fitting due to limited capacity. To alleviate this issue, NetAug augments the network (reverse dropout) instead of inserting noise into the dataset or the network. It puts the tiny model into larger models and encourages it to work as a sub-model of larger models to get extra supervision. Extensive experiments on six image classification datasets (ImageNet, Food101, Flowers, Cars, Cub200, and Pets) show that NetAug is much more effective than regularization techniques for tiny neural network."
SP:9c24549b980e415616f818acbf4cf680ef8edb52,"This paper proposes a generative adversarial network (GAN) for dynamic point cloud sequences without requiring point correspondence annotation. The proposed method, Temporal Point cloud Upsampling GAN (TPU-GAN), can implicitly learn the underlying temporal coherence from point cloud sequence, which in turn guides the generator to produce temporally coherent output. In addition, a learnable masking module is proposed to adapt upsampling ratio according to the point distribution. The experimental results show the effectiveness of the proposed method."
SP:67efe60ad37807505369b7852bc0abed29ffdda8,"This paper proposes a method for fully pre-training encoder-only detection transformers (DETR) for object detection. The proposed method is based on the idea of using query positional embeddings as visual prompts to help the model attend to the target area (prompting) and recognize the object. To this end, the authors propose a task adapter which leverages the contextual relation between object query embedding and the query location. Experiments on the challenging COCO dataset demonstrate that the proposed method achieves competitive performance. "
SP:a1f9897496303984fc7ad469222106b14b4a6233,"This paper proposes FedPAGE, a new federated learning algorithm for convex and non-convex optimization. The main idea is to use the recent optimal PAGE method (Li et al., 2021) to further reduce the communication complexity of FedAvg/local-SGD (FedAvg, also known as LocalSGD) for federated convex learning. The authors show that the proposed algorithm can reduce the number of communication rounds to O(3/4 S) in convex setting and O(N^2/3 S+S^2) in non-Convex setting. In both settings, the communication cost for each round is the same."
SP:81e74765abc6524edd8fdf9a3ba107d7bddaa04b,"This paper studies the decision boundary geometry of ANN classifiers by utilizing adversarial perturbations. The authors define adversarial subspaces, which are spanned by orthogonal directions of minimal perturbation to the decision boundaries from any given input sample. They find that the boundary lies close to input samples in a large subspace, where the distance to the boundary grows smoothly and sub-linearly as one increases the dimensionality of the subspace. They also characterize the geometry of the boundary, which is more curved within the adversarial subsets than within a random subspace of equal dimensionality. "
SP:af5c25ecf38c5c3f3387720bdc80c2c54c5699fe,"This paper proposes a weakly-supervised contrastive learning method that uses auxiliary information to cluster data according to its auxiliary information. The auxiliary information comes from discrete attributes from three datasets: UT-zappos50K, CUB-200-2011, Wider Attribute, and ImageNet-100. The proposed method is based on a two-stage clustering-based learning approach, where the first stage clusters the data based on the auxiliary information, and the second stage learns similar representations within the same cluster and dissimilar representations for data from different clusters. Experiments show that the proposed method achieves better performance compared to the supervised representations. "
SP:0a92fcc52970201de4a66b1e76c93dbea9dfd3f1,"This paper proposes a method to recover sparse parameters from observational data by unrolling a path-following algorithm with some components that are more flexible and learnable. The proposed method, PLISA, is based on an iterative iterative recovery algorithm. Theoretical analysis is provided to show the improved recovery accuracy achievable by PLISA. The empirical Rademacher complexity of PLISA is also analyzed to characterize its generalization ability."
SP:5064eda9ba27060af15e81b2b317b2e4558b0ac4,"This paper proposes HyAR, a method to learn a compact and decodable latent representation space for discrete-continuous hybrid action spaces. HyAR constructs the latent space and embeds the embeddings between discrete action and continuous parameter via an embedding table and conditional Variational Auto-Encoder (VAE). To further improve the effectiveness, the action representation is trained to be semantically smooth through unsupervised environmental dynamics prediction. Finally, the agent learns its policy with conventional DRL algorithms in the learned representation space and interacts with the environment by decoding the hybrid action embedding to the original action space. The results demonstrate the superiority of HyAR when compared with previous baselines."
SP:5128bf712f6b197de113c7a371b4bec36f978eca,"This paper proposes SGEM, Stochastic Gradient with Energy and Momentum to solve a large class of general non-convex stochastic optimization problems, based on the AEGD method that originated in the work [AEGD: Adaptive Gradient Descent with Energy. arXiv: 2010.05109]. SGEM incorporates both energy and momentum at the same time so as to inherit their dual advantages. The authors show that SGEM features an unconditional energy stability property, and derive energy-dependent convergence rates in the general nonconveX stochastically setting, as well as a regret bound in the online convex setting. A lower threshold for the energy variable is also provided. "
SP:11f49b0a975be87769be29e85d7e3924699cf2c9,"This paper proposes a Conditional Masked Language Model with Correction (CMLMC) to improve the performance of Transformer-based autoregressive (AR) machine translation models. The proposed method is based on the CMLM architecture and addresses the indistinguishability of tokens, and mismatch between training and inference. Empirically, CMLMC achieves state-of-the-art NAR performance when trained on raw data without distillation."
SP:96f8ac3c6163e56d8ae1954a162bae01e6b58a0a,"This paper proposes to use spiking neural dynamics as a natural alternative to dilated temporal convolutions for local signal processing. The proposed method is inspired by the WaveNet architecture and uses simple neural dynamics, fixed time-constants and a simple feed-forward architecture. The results show that the proposed method can achieve state-of-the-art performance on several datasets for keyword-spotting. "
SP:7f20a2e4e95f857140b87b0730360b3ff2f371f4,"This paper proposes Shifty algorithms that provide high-confidence behavioral guarantees that hold under demographic shift. The proposed algorithm is based on the Shifty algorithm, which is a class of algorithms that provides high confidence behavioral guarantees. The algorithm is evaluated on a real-world dataset of university entrance exams and subsequent student success. The experiments demonstrate that the algorithm’s high confidence fairness guarantees are valid in practice."
SP:94f097921bee5fdc10ec2e7c901b2ddb876d9d41,"This paper proposes Neural Stochastic Dual Dynamic Programming (N-SDDP) for solving multi-stage stochastic dual dynamic programming (MSSO) problems. The proposed method extends SDDP by introducing a trainable neural model that learns to map problem instances to a piece-wise linear value function within intrinsic low-dimension space, which is architected specifically to interact with a base SDDP solver, so that can accelerate optimization performance on new instances. Experiments on synthetic and real-world MSSO problems demonstrate the effectiveness of the proposed method."
SP:3d9f5132f9ec3807dbca78462a459fd123a09b24,"This paper proposes a new protocol for next-token prediction, called SUBMIX, to prevent privacy violations by language models that were fine-tuned on a private corpus after pre-training on a public corpus. The proposed method is based on a relaxation of group differentially private prediction, which allows for a tight, data-dependent privacy accounting mechanism that allows it to thwart existing data-extraction attacks while maintaining the utility of the language model. The authors also show that the proposed method can effectively prevent existing data extraction attacks against GPT-2."
SP:7f524d186ea939309c7eeb843c62b6a4b4cfbc8a,"This paper proposes an unsupervised method to detect OOD samples using a k-NN density estimate with respect to a classification model’s intermediate activations on indistribution samples. The authors leverage a recent insight about label smoothing, which they call the Label Smoothed Embedding Hypothesis, and show that one of the implications is that the proposed method performs better as an OOD detection method both theoretically and empirically. The proposed method outperforms many OOD baselines and provides new finite-sample high-probability statistical results."
SP:aafbd6ada14cc59a272fe4bf95fac71fa18e57ab,"This paper proposes a new method to learn representations for non-adversarial GANs and VAEs. The proposed method is based on a new formulation of the denoising score matching objective, which allows for better representation learning without any supervised signal. The authors also propose to learn an infinite-dimensional latent code, which achieves improvements of state-of-the-art models on semi-supervised image classification. "
SP:8cfc837d5c10d539bbd098df7134c42e4830ba25,"This paper proposes a method for goal-conditioned reinforcement learning that uses graph planning to learn a curriculum of intermediate states to reach distant goal-reaching tasks. The proposed method, C-Planning, is based on the idea of expectation maximization, where the E-step is used to plan a sequence of waypoints using graph planning, and the M-step aims to learn the policy to reach those waypoints. Empirical results show that the proposed method is more sample efficient than prior methods and is able to solve long-range manipulation and navigation tasks."
SP:ef3193842e06d4a6edb8a6a86ea5bc97ee5eaa4a,"This paper extends mixup to k-mixup by perturbing k-batches of training data in the direction of other randomly-chosen instances in the training set using displacement interpolation, i.e. interpolation under the Wasserstein metric. The authors demonstrate theoretically and in simulations that k-Mixup preserves cluster and manifold structures, and extend theory studying the efficacy of standard mixup regularization to the k- mixup case. The empirical results show that training with k- Mixup further improves generalization and robustness across several network architectures and benchmark datasets of differing modalities."
SP:0fe6a9848026e5f6436a380199e27a9ad26cffed,This paper proposes a kernelized classification layer for deep networks to tackle the problem of nonlinearity in representation learning. The authors show that the proposed kernelized layer optimizes over all possible radial kernel functions on the space of embeddings to learn an optimal nonlinear classifier. The proposed method is empirically shown to be effective in learning more model-efficient classifiers in computer vision and natural language processing tasks.
SP:01ee8ec81619784788eb0ce9785098e437d17a7c,"This paper investigates the sources of bias in node representations obtained via graph neural networks (GNNs). The analysis reveals that both nodal features and graph structure lead to bias in the obtained representations. Based on the analysis, fairness-aware data augmentation frameworks are developed to reduce the intrinsic bias. Extensive experiments on node classification and link prediction are carried out over real networks in the context of graph contrastive learning. "
SP:7739dc9e37f7f1384f87d2e60281e5bb27fece99,"This paper proposes a confounder-balanced IV regression method to estimate treatment effect from observational data in the presence of unmeasured confounders. The proposed method consists of three main modules: (1) treatment regression: regressing the treatment with IVs and confoundeders in the first stage, and then regressing with the predicted treatment and the predicted outcome in the second stage.  (2) Confounder balancing: learning a balanced representation of confoundering variables to eliminate the bias induced by the observed observed confoundsers. (3) Outcome regression: Regressing the outcome with the prediction and the balanced representation for treatment effect estimation. (4) Experiments on both synthetic and real-world datasets demonstrate the effectiveness of the proposed algorithm. "
SP:fdb68c39fce254b73310a3101b2fe97ba47e69fe,"This paper analyzes the performance of MAML in a linear regression setting with a mixture of easy and hard tasks, where hardness is related to the rate that gradient descent converges on the task. Specifically, the authors show that in order to achieve substantial gain over NAL, there must be some discrepancy in hardness among the tasks, and the optimal solutions of the hard tasks must be closely packed with the center far from the center of the easy tasks optimal solutions. They also give numerical and analytical results suggesting that these insights apply to two-layer neural networks. "
SP:e8143c7880c16ee9ce7a544e0fd80f001b1b4f9f,"This paper proposes a method for sparse blind source separation (BSS) that unrolls the original PALM algorithm by learning both the hyperparameters and variables of the algorithm. The method is based on the idea of unfolding and unrolling, which allows to leverage the data-driven knowledge stemming from realistic simulations or ground-truth data. The proposed method, called Learned PALM (LPALM), is able to perform semi-blind source separation, which is key to increase the generalization of the learnt model in real-world applications. "
SP:7716315001949ab88c8a216302fe51bae872fc87,This paper proposes a Legendre Memory Unit-based model with implicit self-attention to improve the performance of transformers on the task of language modeling. The authors show that the proposed model exhibits a power-law relationship with respect to model size over 6 orders of magnitude. The proposed model is able to scale better than transformers with the same amount of training. 
SP:832f422b3554e89702e13c8c5690ee26f2289e3b,"This paper proposes LatentKeypointGAN, a two-stage GAN that is trained end-to-end on the classical GAN objective with internal conditioning on a set of space keypoints. These keypoints have associated appearance embeddings that respectively control the position and style of the generated objects and their parts. The authors demonstrate that the latent space provides an interpretable latent space that can be used to re-arrange the generated images by re-positioning and exchanging keypoint embedding. The explicit generation of keypoints and matching images enables a new, GAN-based method for unsupervised keypoint detection. "
SP:9206ae6e31077569313838504ef6daa89ad3b59c,"This paper studies the effect of depth in fully-connected neural networks with layer normalization using the mean field formalism. The authors demonstrate that increasing the depth leads to gradient explosion or representation shrinkage. They show that the appearance of these problems is not restricted to a specific initialization scheme or a choice of activation function, but rather is an inherent property of the fully connected architecture itself. They also show that many popular normalization techniques fail to mitigate these problems."
SP:2177be818b5843c580c787f1b2d725154846feb6,"This paper proposes a line search method to find optimal step sizes for stochastic gradient descent automatically. The proposed method is based on the observation that the full-batch loss behaves locally parabolically in the direction of noisy update step directions, and the trend of the optimal update step size changes slowly. Based on this observation, the proposed method approximates the full batch loss with a parabola estimated over several mini-batches. The learning rates are derived from such parabolas during training. Experiments are conducted on several datasets, models, and gradient noise levels. "
SP:62233782f9046c85617d9ccfe8427eae7d1c9da7,"This paper studies the problem of ill-behaved loss landscape in Noise-Contrastive Estimation (NCE) and proposes a new loss function called eNCE, which replaces the log loss in NCE with an exponential loss. The authors show that the resulting condition number is polynomial in the dimension and the parameter distance between P and Q when they belong to an exponential family. Theoretically, the authors prove that both NCE and e-NCE can potentially suffer from numerical issues during optimization when P $\infty$ and Q are far from each other. To address this, they propose a new algorithm called normalized gradient descent (NFD) to address the landscape issues provably. "
SP:ceba6c1421b2d03863007fdaf029b8b946519c1b,"This paper studies the convergence of distributed SGD under Byzantine and Byzantine attacks. In particular, the authors consider the case where a fraction of the workers are malicious, and the other fraction are honest, providing noisy information to the server to ensure differential privacy (DP). The authors show that the integration of standard practices in DP and Byzantine resilience is not straightforward. To circumvent this, they revisit the theory of Byzantine resilience (BR) to obtain an approximate convergence guarantee. They also provide some insights on how to improve this guarantee through hyperparameter optimization. "
SP:bc783f0c829f90931535e63687d13172879631b3,"This paper proposes a method for code editing with few exemplars. The proposed method is based on multi-extent similarities ensemble. The method is applied to both query and support exemplars, where the support exemplar contains the original and modified support code snippets, and the query exemplars contain the query code snippets. The results show that the proposed method outperforms the baseline methods by 8.0-10.9% in terms of absolute accuracy."
SP:ca0c4bdb02f7d939fb6de38b6b446ced4b5984a0,"This paper proposes a generative model based on relational constraints to generate high-level structure in sequence data. The authors propose a program synthesis algorithm that infers the relational constraints present in the training data, and then learns a model to generate the constraint data. They show that their approach significantly improves over state-of-the-art generative models in terms of capturing high level structure in the data. "
SP:692ae0c583a1585eff1a7d9c0d3b51b7879611cc,"This paper addresses the problem of set-to-hypergraph prediction, where the goal is to infer the set of relations for a given set of entities. The paper addresses two common scaling problems encountered in this task: the exponentially growing number of hyperedges and the run-time complexity, both leading to higher memory requirements. The authors propose to predict and supervise the positive edges only, which changes the asymptotic memory scaling from exponential to linear. They also introduce a training method that encourages iterative refinement of the predicted hypergraph, which allows us to skip iterations in the backward pass for improved efficiency and constant memory usage. Finally, the authors combine the efficient representation from the first contribution with the scalable training method from the second contribution in a recurrent model to improve the performance."
SP:e3481fb6d8d1aa45d6ed4a454e781f5a2c30c57e,"This paper proposes a post-processing method to mitigate bias of state-of-the-art models. It consists in learning a shallow neural network, called the Ethical Module, which transforms the deep embeddings of a pre-trained model to give more representation power to the discriminated subgroups. Its training is supervised by the von Mises-Fisher loss, whose hyperparameters allow to control the space allocated to each subgroup in the latent space. Besides, the resulting methodology is more stable and faster than most current methods of bias mitigation."
SP:3fb5dcc8b8fb731e09c14b16480cada1c7ccfaa7,"This paper proposes a new method for class-incremental learning (CIL) by distilling the knowledge of previous classes from the training data. The proposed method is based on placebos from a free image stream, where the placebos are unlabeled and can be used for both logit distillation and feature distillation. A reinforcement learning-based algorithm is proposed to learn a policy to produce phase-specific functions to evaluate the quality of placebos. Empirical results show that the proposed method outperforms the state-of-the-art KD-based methods on three CIL benchmarks."
SP:506e0a888c03a955b708464eed3670c04baf4912,"This paper proposes a new algorithm for sampling from discrete energy-based models (EBMs). The authors propose a path auxiliary algorithm that uses a composition of local moves to efficiently explore large neighborhoods. They also give a fast version of their algorithm that only queries the evaluation of energy function twice for each proposal via linearization of the energy function. Empirically, the authors show that their algorithm outperforms other generic samplers on various discrete models for sampling, inference, and learning."
SP:4b466277aa5561a80c48d5e72559de4ce95f228b,"This paper proposes a method for learning a hierarchical generative model that can dynamically adapt its latent representations in response to datasets with different temporal dynamics. The proposed method, called Variational Predictive Routing (VPR), is a neural probabilistic inference system that organizes latent representations of video features in a temporal hierarchy, based on their rates of change, thus modeling continuous data as a hierarchical renewal process. By employing an event detection mechanism that relies solely on the system’s latent representations (without the need of a separate model), VPR is able to dynamically adjust its internal state following changes in the observed features, promoting an optimal organisation of representations across the levels of the model's latent hierarchy. "
SP:459ef2e6bd7638020955dbb4d8ae1098619f7b95,This paper proposes an end-to-end and single-stage method for image retrieval that combines global and attention-based local feature matching with convolutional neural networks. The proposed method is evaluated on two image retrieval datasets and achieves state-of-the-art performance.   
SP:487cc308a1e8ee078c54b2158bcae47e920e73f8,"This paper proposes RotoGrad, a multi-task learning algorithm that jointly homogenizes gradient magnitudes and directions across tasks while ensuring training convergence. The proposed method is based on the idea of homogenizing the gradient magnitude and direction of the gradients across tasks. The authors show that the proposed method outperforms existing methods in multi-label classification and computer vision tasks. "
SP:050cd8319d84a1bd8c2ccb930ba69b33c8fb6e60,This paper proposes a method to fuse heterogeneous neural networks via cross-layer alignment and layer-wise model fusion. The proposed method is based on a dynamic programming-based algorithm to balance the number of layers between two networks. Experiments on CIFAR-10 show that the proposed method achieves better performance compared to the individual networks trained on heterogeneous data without retraining. 
SP:f764eae15cd083fdb4eb2af09ac64c2d878a454f,"This paper studies the implicit regularization effect of SGD in offline deep reinforcement learning. The authors show that implicit regularisation is harmful in the offline deep RL setting, leading to poor generalization and degenerate feature representations. To address this issue, the authors derive the form of this implicit regularizer and propose a simple and effective explicit regularizer, called DR3, which minimizes the feature similarity between state-action pairs appearing in a bootstrapping update. Empirically, DR3 improves performance and stability in Atari 2600 games, D4RL domains and robotic manipulation from images."
SP:6fd793b27123bf80504e2ad5957455b7ec311612,"This paper proposes HyperDQN, a deep RL algorithm that uses a probabilistic hypermodel to generate approximate posterior samples regarding the parameter of the Q-value function. The hypermodel is trained jointly with a non-linear neural network (i.e., base model) that predicts Q-values and a meta model that outputs the parameters of the base model. The proposed method is evaluated on the Atari suite and outperforms DQN with 200M frames in terms of the maximum human-normalized score. "
SP:b428383660928374c953f659ea1e05852dbdcd6e,"This paper proposes a method to learn causal representations from observational data by regularizing the learning procedure with mutual information measures according to a hypothetical causal graph. The proposed method is based on a counterfactual loss, and the authors show that the proposed method achieves better sample complexity and better generalization ability. Extensive experiments are conducted to show the effectiveness of the proposed methods."
SP:1258c05a80a17949b50e6dae13deea1d2235f456,"This paper proposes ProgFed, a progressive training framework for efficient and effective federated learning. It inherently reduces computation and two-way communication costs while maintaining the strong performance of the final models. Extensive experiments on various datasets (CIFAR-10/100, EMNIST and BraTS) and architectures (VGG-16/19, ResNet-18/152, ConvNets, 3D-Unet) and diverse tasks from simple classification to medical image segmentation show that the proposed method saves up to 20% computation and up to 63% communication costs for converged models without sacrificing performance. "
SP:8cdaa6e0dafd750ebdb5d7a4c1987a042400662f,This paper studies the generalization of adversarial training through the lens of the adversarial Rademacher complexity of deep neural networks. The main contribution of this paper is to provide an upper bound on the adversarially robustness of a deep neural network to adversarial attacks. The upper bound is based on the analysis of the weight norms of the trained model. The authors provide experiments to show that the weight norm of an adversarial trained model is larger than the standard trained weight norms. 
SP:925d6bb051e9b384669fb695085b678c11f7c11a,"This paper proposes a differentiable kernel-based differential entropy estimator (KNIFE) for differential entropy and mutual information (MI) estimation. The proposed estimator is based on the kernelized neural diferentially-ferential entropy (DE) estimator, which is a kernelized estimator of differential entropy that is differentiable and parameterized by a kernel. This estimator can be used for both discrete and continuous differential entropy, and can also be used to estimate mutual information. Experiments on synthetic data and real-world tasks demonstrate the effectiveness of the proposed method. "
SP:d2f3beac855f0d72c13552fecb2bdb9d42195df3,"This paper proposes a new soft-greedy operator, called resmax, that takes actions proportionally to their suboptimality gap: the residual to the estimated maximal value. It is simple to use and ensures coverage of the state-space, but focuses exploration more on potentially promising actions like softmax. It does not concentrate probability as quickly as softmax, and so better avoids overemphasizing sub-optimal actions that appear high-valued during learning. The authors prove that it is a non-expansion for any fixed exploration hyperparameter, unlike the softmax policy which requires a state-action specific temperature to obtain a nonexpansion (called mellowmax)."
SP:792ae8808aa6902758146aef1548c975492b833c,"This paper proposes a new method to attack the learnability of deep learning models. The proposed method is based on adversarial invertible transformation, which is a mapping from image to image, to slightly modify data samples so that they become “unlearnable” by machine learning models with negligible loss of visual features. The method can be easily restored with a simple inverse transformation while remaining difficult to be detected or reverse-engineered. Empirical results show that the proposed method works on common image datasets."
SP:9af10703605e620e563241e2602a50b629f3d37a,"This paper proposes a method for handling missing features in graph machine learning applications. The proposed method is based on minimization of the Dirichlet energy and leads to a diffusion-type differential equation on the graph. The discretization of this equation produces a simple, fast and scalable algorithm which the authors call Feature Propagation (FP). The proposed FP method outperforms previous methods on seven common node-classification benchmarks and can withstand surprisingly high rates of missing features. "
SP:cbaa3f1379fa99159899d79ccb479c0187403aca,This paper proposes a method for active learning by minimizing the discrete Wasserstein distance between the full data set and a subset of the unlabeled data set. The authors propose a Generalized Benders Decomposition algorithm to solve this problem. The proposed method is shown to outperform existing active learning methods in the low-budget regime where less than one percent of the data set is labeled. 
SP:4c72923f78ca6590dc11e10d1a2403076a583718,"This paper proposes a method for de-novo genome assembly using graph convolutional neural networks. The method is based on a dataset generated from human genomic data to reconstruct the genome by finding a path through the assembly graph. The authors show that their model can compute scores from the lengths of the overlaps between the sequences and the graph topology which, when traversed with a greedy search algorithm, outperforms the greedy search over the overlap lengths only. Moreover, their method reconstructs the correct path in the fraction of time required for the state-of-the-art de novo assemblers."
SP:24de906e4289c9073b6c55c747b0913b8df5e053,"This paper proposes a meta-learning method for continual learning that incorporates experience replay (ER) into the online-aware meta-training procedure of Javed & White (OML). The authors propose to store the samples’ representations, instead of the samples themselves, into the replay buffer. This ensures the batch nature of ER does not conflict with the online nature of OML. Moreover, the authors introduce a meta learning procedure to select samples that can best help overcome catastrophic forgetting. Experimental results on a number of real-world meta-continual learning benchmark data sets demonstrate that the proposed method outperforms the state-of-the-art."
SP:3c78454f053f74930979a8054cd7c8a34b6fe63d,"This paper proposes Explicit Credit Assignment Joint Q-Learning (ECAQ), a method for multi-agent joint Q-learning with explicit credit assignment. The authors propose a criterion to measure an assignment function so that we can find better assignments by explicitly optimizing this criterion. Theoretically, the authors give a gradient ascent solution for this problem. Empirically, ECAQ achieves interpretable credit assignment and superior performance compared to several advanced baselines."
SP:0d2b225ac697679d10df25f371b2a718d4949b42,This paper studies the adversarial robustness of transductive learning-based defenses. The authors propose a bilevel attack framework to attack the model space of the defense. They show that even weak instantiations of the proposed GMSA can break the defenses. They also show that adversarially training the model can reduce the robust accuracy to that of adversarial training alone. 
SP:e7024cae196fc5eb6a62d289a95d76b532b6a36c,"This paper proposes a per-example normalization method for batch normalization, which is an approximation of batch renormalization in the limiting case where the entire dataset is normalized jointly. The authors show that the proposed method can remove the need to keep more than one example in memory at any given time, at the cost of a small factor increase in the training step computation, and removes the extra computation at a small drop in the final model accuracy. They further use their insights to improve the performance of the method for very small minibatches. "
SP:4aa42984fcb0fd66936d668477b2719ef5c427d4,"This paper proposes a low-rank adaptation method to reduce the number of trainable parameters in a pre-trained language model. The proposed method, called Low-Rank Adaptation (LoRA), freezes the pretrained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture. The authors show that LoRA can reduce the total number of parameters by 10,000 times and the GPU memory requirement by 3 times compared to fine-tuning GPT-3 175B with Adam. "
SP:b77a00beb0802f47810b03d3c4aa24d92781414f,"This paper proposes a regular-constrained linear-chain conditional random field (CRF) model that can learn non-local dependencies in the output of a CRF. The authors propose to constrain the CRF to a regular language by specifying the space of possible output structures as a language L. The proposed method RegCCRF (RegCCRF) has the same formal properties as a standard CRF, but assigns zero probability to all label sequences that are not in L. Experiments on semantic role labeling show that the proposed method can achieve state-of-the-art results on a standard dataset."
SP:74c186a96c12adff178264aa84ace8d04dc7d725,"This paper proposes two neural architectures for camera-based physiological measurement that remove the need for face detection, segmentation, normalization, color space transformation or any other preprocessing steps. The proposed models achieve state-of-the-art accuracy on three public datasets. The authors also evaluate the latency of the proposed networks and show that their most light weight network achieves a 33% improvement in efficiency."
SP:3003bab6e3f7e2e21cd6cf27ee7d483d877d9fb3,"This paper proposes Hardware-Aware Latency Pruning (HALP), a method to perform structural pruning of neural networks. The proposed method is based on a global resource allocation optimization problem, aiming at maximizing the accuracy while constraining latency under a predefined budget. The method leverages latency lookup table to track the latency reduction potential and global saliency score to gauge the accuracy drop. The results on ImageNet and VOC datasets demonstrate the effectiveness of the proposed method."
SP:c44d676c09c8e5a70d73b21b507b41a422fec809,"This paper proposes GraphEBM, a molecular graph generation method via energy-based models (EBMs) to perform permutation invariant and multi-objective molecule generation. The authors propose to learn the energy function by contrastive divergence and generate samples by Langevin dynamics. To generate molecules with a specific desirable property, the authors propose a simple yet effective learning strategy, which pushes down energies with flexible degrees according to the properties of corresponding molecules. Empirical results show that the proposed method is effective on random, single objective, and multi objective generation tasks."
SP:70e60fa5deef3e3ba77d05d0c3e0e7fbf396aa1d,"This paper proposes a method for program synthesis that trains a neural model to learn a hands-on search policy for bottom-up synthesis, instead of relying on a combinatorial search algorithm. The proposed method, called CROSSBEAM, learns to combine previously-explored programs into new programs by taking into account the search history and partial program executions. The method is trained on-policy using data extracted from its own bottom up searches on training tasks. The results show that the proposed method achieves better performance than state-of-the-art methods in string manipulation and logic programming."
SP:daa044ffefe80bae16b014f60061d941ed8c2ba6,"This paper proposes to augment the squared Bellman error with a functional regularizer to improve the stability of deep reinforcement learning (DQL) methods. The proposed method is based on the idea of implicit regularization, where the target network is used to regularize the value function of the reward function. The authors show that the proposed method outperforms the standard target-network-based DQL methods in terms of sample efficiency and performance."
SP:dd174014d056a7d2bc86ee99119841eafa62ed52,"This paper proposes GraphSNN, a graph neural network (GNN) architecture that is more expressive than the Weisfeiler Lehman test in distinguishing graph structures. The main idea is to use a hierarchy of local isomorphism on neighborhood subgraphs to design a message-passing aggregation scheme of GNNs. The proposed method is shown to be more expressive and more efficient than the standard WLE test. Empirical results show the effectiveness of the proposed method. "
SP:beb9ba0261e176bfc50e9bf5bed2b6169d388285,"This paper proposes a novel prediction interval (PI) method for uncertainty quantification, which addresses three major issues with the state-of-the-art PI methods. First, existing PI methods require retraining of neural networks (NNs) for every given confidence level and suffer from the crossing issue in calculating multiple PIs. Second, they usually rely on customized loss functions with extra sensitive hyperparameters for which fine tuning is required to achieve a well-calibrated PI, leading to over-confident PIs, and third, they underestimate uncertainties of out of distribution (OOD) samples. The proposed PI3NN method calculates PIs from linear combinations of three NNs, each of which is independently trained using the standard mean squared error loss. The coefficients of the linear combinations are computed using root-finding algorithms to ensure tight PIs for a series of confidence levels without retraining NNs and it completely avoids the cross issue. Furthermore, the authors address OOD identification challenge by introducing an initialization scheme which provides reasonably larger PIs of the OOD samples than those of the in-distribution samples."
SP:4b44a834e2212bacb4c2d9408a81f1efc76a670b,"This paper proposes a fully online meta-learning method for continual online learning. The proposed method, FOML, updates the online parameters with each new datapoint or batch of data, while simultaneously performing meta-gradient updates on a separate set of meta-parameters using a buffer of previously seen data. The method does not require any ground truth knowledge about the task boundaries and stays fully online without resetting back to pretrained weights. Empirical results show that the proposed method is able to learn new tasks faster than the state-of-the-art online learning methods on Rainbow-MNIST, and CIFAR100 datasets."
SP:fbae35cb171b3a3eb7c5d4bc83881ed7c4a70aae,"This paper proposes a differentiable scaffolding tree (DST) that converts discrete chemical structures to locally differentiable ones. DST enables a gradient-based optimization on a chemical graph structure by back-propagating the derivatives from the target properties through a graph neural network (GNN). The empirical studies show that DST is both effective and sample efficient, and the learned graph parameters provide an explanation that helps domain experts understand the model output."
SP:61b59899cf6ae442d9f8f5226e79708a4280cfb2,This paper proposes a knowledge-augmented approach to predict patients’ lab test responses for a target lab result. The authors model drug-lab interaction and diagnosis-lab interactions as graphs and design a knowledge augmentation method to predict the response for the target lab test result. They also take into consideration past lab responses to personalize the prediction. Experiments on real-world datasets demonstrate the effectiveness of the proposed solution in reducing prediction errors by a significant margin.
SP:8623cebb515c4a736427449b46ad2cdf8b806b77,"This paper proposes CrossMatch, a method for open-set single domain generalization (OS-SDG) where the source and target domains do not have the same label space. CrossMatch generates auxiliary samples out of the source label space by using an adversarial data augmentation strategy. The authors also adopt a consistency regularization on generated auxiliary samples between multibinary classifiers and the model trained by SDG methods, to improve the model’s capability on unknown class identification."
SP:126f8ffb855aa22eda4d681a499953879ed3679e,"This paper studies Wasserstein policy optimization (WPO) and Sinkhorn trust region optimization (SPO), which are extensions of Kullback-Leibler divergence (KL divergence) methods for trust-region optimization. The authors derive the Lagrangian duality of WPO and SPO and show that WPO guarantees a monotonic performance improvement, while SPO provably converges to WPO as the entropic regularizer diminishes. Experiments on tabular domains and robotic locomotion tasks demonstrate the performance improvement of both approaches."
SP:999eacf6500c87205584a3256d7ca45b3016fb1c,"This paper proposes a forget-and-relearn framework that unifies many existing iterative training algorithms in the image classification and language emergence literature in terms of the disproportionate forgetting of undesirable information. The forgetting step selectively removes undesirable information from the model, and the relearning step reinforces features that are consistently useful under different conditions. The authors leverage this understanding to improve upon existing algorithms by designing more targeted forgetting operations. They show that existing algorithms have a forgetting step that disproportionately affects undesirable information for the given task."
SP:2789859517b6624730b14a7e010444a72d3dd3ed,"This paper investigates the offline-online setting of batch RL, where the agent has access to a batch of data to train on but is also allowed to learn during the evaluation phase in an online manner. This is an extension to batch RL that allows the agent to adapt to new situations without having to precommit to a policy. The authors find that standard RL agents trained in an offline-Online manner can outperform agents trained only offline or online, sometimes by a large margin, highlighting the potential of this new setting. They also find that larger datasets and a good policy can be critical to good results."
SP:76625a25e770415599a34122110d61cb3b7e614c,"This paper studies the problem of domain generalization (DG) via learning to reduce domain shift with an episodic training procedure. In particular, the authors learn to optimize Y-discrepancy between the unseen target domain and source domains only using source-domain samples. Theoretically, they give a PAC-style generalization bound for discrepancy-optimal meta-learning and further make comparisons with other DG bounds including ERM and domain-invariant learning. Empirically, the algorithm achieves state-of-the-art results on two DG benchmarks."
SP:6421a9759c766641fd8c128a249f1a9c5699d19c,"This paper studies the problem of best-first search for PSPACE-hard planning in the Sokoban domain. This is an NP-complete setting where the goal is to find a solution to a hard-to-solve PSPACE problem. The authors propose to use a DNN-based search algorithm to solve the problem. They show that the search space is exponential in the number of sub-trees, which leads to the existence of left heavy tails. They also propose a tree model that can explain the appearance of these tails.  "
SP:84c415bc0f120d1997289f91661ff74e7297d3bd,"This paper presents a method for meta-imitation learning by watching video demonstrations from humans. The method is able to translate human videos into practical robot demonstrations and train the meta-policy with adaptive loss based on the quality of the translated data. The approach relies only on human videos and does not require robot demonstration, which facilitates data collection and is more in line with human imitation behavior. The proposed method achieves comparable performance to the baseline on a set of vision-based tasks through watching a single video demonstration."
SP:fedf5c75e83d6ab41ef9d5daa9054ffe4e424ec2,"This paper studies the effect of large batch size on the generalization performance of deep neural networks trained with gradient-based optimizers (SGD). In particular, the authors argue that large batch sizes can lead to over-parameterization of the weights and output scores, which in turn leads to poor generalization. They argue that SGD-style optimizers are particularly affected by this issue. They also argue that small batch sizes yield better generalisation performance due to the noise of mini-batch gradients and large learning rate."
SP:819df8d847a99f13ed5efdcabae8b464c12b464b,"This paper proposes a method for learning group equivariant convolutional neural networks (G-CNNs) that are able to learn partial and full equivariance from data at every layer end-to-end. In particular, the authors propose a method to learn a group-equivariant G-CNN that is able to restrict the level of group equivariances at each layer. This allows the network to learn the optimal level of equivariancy. The proposed method is evaluated on MNIST, 6/9 classification, and natural image classification tasks. "
SP:0c0ca9df96f1fa2eb8b83a47d0d5964590fef290,"This paper proposes the amortized Langevin dynamics (ALD), which replaces the datapoint-wise MCMC iterations with updates of an inference model that maps observations into latent variables. ALD enables scalable inference from large-scale datasets. The authors prove that ALD has the target posterior as a stationary distribution under some assumptions. They also extend ALD to sampling from an unconditional distribution such as an energy-based model."
SP:5631097031c7e599bdeae64366ffa6e4558837c6,"This paper proposes a model for hypergraph reasoning based on sparse neural networks. The model is motivated by the observation that in logical reasoning, logical rules (e.g., my parent’s parent is my grandparent) usually apply locally, and sparsely across all pairs of people in the world. Inspired by these observations, the authors propose Sparse and Local Neural Logic Machines (SpaLoc) to leverage the sparsity in hypergraph neural networks, which represents the grounding of relationships such as parent and grandparent as sparse tensors and uses neural networks and finite-domain quantification operations to infer new facts based on the input. To enable training on large-scale graphs such as real-world knowledge graphs, SpaLoc makes training and inference-time sub-sampling of the input graphs. To remedy the information loss in sampled sub-graphs, a novel sampling and label calibration paradigm based on an information-theoretic measure information sufficiency is proposed to regularize the number of hyperedges in intermediate layers of a SpaLoc model. The proposed model shows superior accuracy and efficiency on synthetic datasets compared with prior art and achieves state-of-the-art performance on several real- world knowledge graph reasoning benchmarks."
SP:9657121b01c51f78c00d06b47d3e8d678dd85d54,"This paper proposes to relax the assumption that k is a positive integer, where k is either 1 or 5. The authors propose to draw k from a probability distribution for training and propose a new family of differentiable top-k cross-entropy classification losses. They find that relaxing k does not only produce better top-5 accuracies, but also makes models more robust, which leads to top-1 accuracy improvements. They achieve a new state-of-the-art on ImageNet for publicly available models with an 88.37% top 1 and a 98.68% top 5 accuracy."
SP:cb3188f435c54a365890e20e4d582c250d919833,"This paper proposes a new method for solving large-scale optimal transport (OT) problems at an unprecedented combination of speed and accuracy. The proposed method is based on the Douglas-Rachford splitting (DRF) technique, which allows to solve the original OT problem directly instead of solving an approximate regularized problem, as many state-of-the-art techniques do. This allows to provide sparse transport plans and avoid numerical issues of methods that use entropic regularization. The algorithm has the same cost per iteration as the popular Sinkhorn method, and each iteration can be executed efficiently, in parallel. The authors also establish a linear convergence rate for the formulation of the OT problem."
SP:9a087cc734a3e7f3ab848bef5e2eff37fe40f303,"This paper proposes a framework for disentangling performance gaps in federated learning from unseen client data (out-of-sample gap) and unseen client distributions (participation gap). The proposed framework disentangles the performance gap between clients and meta-distributions. The authors also propose a dataset synthesis strategy that enables realistic simulation without naturally-partitioned data.   The authors conduct a systematic study of generalization in FL across six tasks. They observe and explain differences in behavior across natural and synthetic federated datasets, indicating that dataset synthesis strategies can be important for realistic simulations. "
SP:da0e8c89f343abfe500eb4c1968e418c2fb52ef6,"This paper studies the few-shot setting of prompt-based language models (PLMs) for zero-shot tasks. PLMs are pre-trained with self-supervision objectives to improve the performance of the language model. The paper shows that PLMs can achieve good performance on a few widely-used datasets, e.g., IMDB, Amazon and GLUE. However, there are some limitations of PLMs under the few shot setting, particularly for the language understanding tasks. To address these limitations, the paper proposes two new strategies to adapt PLMs for the zero shot setting. "
SP:9817dccb1a121058b23a2ef825ed339cf8b53674,This paper proposes a method to improve the performance of the attention mechanism in image recognition tasks. The proposed method is based on a sharpener module that aims to align relevant parts of the encoded image with the target output. The sharpener aims to find the target in an image region and refines representation to be target-specific. Experiments on synthetic handwritten digits and real-world scene text recognition datasets show that the proposed method outperforms the existing methods. 
SP:3913ed3b3cf6494368e3be6cacb637ff85f80ee6,"This paper proposes a reinforcement learning-based method to solve the vehicle routing problem. The proposed method is based on deep reinforcement learning, where the goal is to construct a complete tour plan from scratch while respecting an apriori fixed number of available vehicles. The method is evaluated on a number of real-world vehicle routing problems. The results show that the proposed method outperforms the baselines in terms of the number of vehicles and the cost of vehicles."
SP:594a813c0d0baa66738b9c8331370f861ad3c416,"This paper proposes a method for link prediction based on counterfactual question answering. The proposed method is based on the idea of causal inference. The authors propose to learn the causal relationship between global graph structure and link existence by using the learned graph representations as context, global graph structural properties as treatment, and the link existence as outcome. The method is evaluated on several benchmark datasets."
SP:48a7e50451b887f55be17b2662aa11ce18791cc1,"This paper proposes a two-stage unsupervised feature selection method based on knowledge contrastive disTillation (SOFT) that incorporates the second-order covariance matrix with the first-order data matrix for feature selection. In the first stage, the authors learn a sparse attention matrix that can represent second order relations between features, and in the second stage, they build a relational graph based on the learned attention matrix and perform graph segmentation to select features. Experimental results on 12 public datasets show that SOFT outperforms classical and recent state-of-the-art methods."
SP:14bcae11aeede63f28d1b80c05ed18a01d3e3f3c,"This paper proposes a semi-supervised multi-modal VAE (MEME) that combines information between modalities implicitly through mutual supervision. This formulation naturally allows learning from partially-observed data where some modalities can be entirely missing, something that most existing approaches either cannot handle, or do so to a limited extent. Experiments on MNIST-SVHN and CUB datasets show that MEME outperforms prior work on both partial and complete data settings."
SP:e834a52cadebe5f125ce491273b4ad1146beae3f,"This paper proposes Deep Explore Options, a method for combining intrinsic and extrinsic rewards in deep reinforcement learning. The proposed method is based on the idea of exploring options, which is an extension of Explore Options in the tabular setting. The authors show that the proposed method can learn from multiple intrinsic rewards, ignore harmful intrinsic rewards and learn to balance exploration, but also isolate exploitative or exploratory behaviors. They also propose a new transition selection algorithm, called J-PER, to learn from intrinsic reward signals. The method is evaluated on 6 Atari environments, where it outperforms baselines in 4 of the 6 environments."
SP:41578dd1a4bdb043b3d68afa5f9cebb3e14f3907,"This paper proposes a new method for learning Hamiltonian dynamical systems from data. The method splits the training data into stiff and non-stiff portions based on a stiffness-aware index, a simple, yet effective metric to quantify the stiffness of the dynamical system. This classification along with a resampling technique allows to apply different time integration strategies such as step size adaptation to better capture the dynamic characteristics of the Hamiltonian vector fields. The proposed method is evaluated on complex physical systems including a three-body problem and billiard model."
SP:bfb0a059eeb6f40a18fbd20c0eec5037a64ca09e,"This paper presents a method to train a language model to perform multi-step computations. The main idea is to train the model to emit intermediate computation steps into a “scratchpad”, where intermediate computations are represented as a sequence of steps. The paper shows that the model is able to perform complex multistep computations, even in the few-shot regime, when asked to perform the operation “step by step”. "
SP:e6c1a8b4bba287455dc9cf145b6bd1f04e2148a9,"This paper proposes a novel adversarial perturbation method based on deep image generators and a novel optimization objective. The proposed method is able to generate targeted feature-level attacks at the ImageNet scale that are simultaneously interpretable, universal to any source image, and physically-realizable. These attacks can also reveal spurious, semantically-describable feature/class associations that can be exploited by novel combinations of natural objects. The authors also use these adversaries to guide the design of copy/paste attacks in which one natural image is pasted into another to induce an unrelated misclassification."
SP:873618263dc4246a39c44d0abfecfb5f688817e3,"This paper proposes a method for solving stochastic annealing (SA) problems by learning a policy that optimizes for higher solution quality given a fixed computational budget. The proposed method uses a neural network to learn the proposal distribution, which is then used to optimise the solution quality. The method is evaluated on a number of problems, including Rosenbrock’s function, the Knapsack problem, the Bin Packing problem, and the Travelling Salesperson problem. "
SP:cae31f7436920eb3946e3f5bca0ac88a73d7c3ec,"This paper proposes a new metric to measure the non-stationarity of a policy sequence in multi-agent reinforcement learning (MARL). The metric is based on the KL divergence of consecutive joint policies, which is bounded by the joint policy divergence. The authors propose a new algorithm to control the joint policies’ divergence by imposing the trust-region constraint. The proposed algorithm MAMT can approximately constrain the consecutive joint policy divergences to satisfy the metric. The algorithm is able to achieve better performance in multiple cooperative tasks."
SP:989b58167a15ae4fafbe27ff534d327991b6c4d7,"This paper proposes a self-supervised representation learning framework for audio-visual speech, which masks multi-stream video input and predicts automatically discovered and iteratively refined multimodal hidden units. The proposed method, AV-HuBERT, achieves 32.5% WER with only 30 hours of labeled data, outperforming the former state-of-the-art approach (33.6%) trained with a thousand times more transcribed video data (31K hours) trained on 31,000 hours of transcribed videos (Makino et al., 2019). The lip-reading WER is further reduced to 26.9% when using all the labeled data from LRS3 (433 hours)."
SP:7c9eb8aa4a4dcb5965157d860e812d81654e3aa7,"This paper proposes ECORD, an RL algorithm for combinatorial optimisation on graphs. The main idea of ECORD is to restrict the GNN to a single pre-processing step before entering a fast-acting exploratory phase directed by a recurrent unit. ECORD achieves a new SOTA for RL algorithms on the Maximum Cut problem, while also providing orders of magnitude improvement in speed and scalability."
SP:f741d980c9c560a21298e947f1605dcbab7ceeac,"This paper proposes a method to train VAEs with discrete latents by directly optimizing the encoder and decoder of the VAE. The proposed method is based on a variational variational approximation of the latent variables. The authors show that the proposed method can be used to train a VAE without sampling approximation, reparameterization trick, and amortization. The method is shown to be more efficient than amortized training, and can be applied to small neural networks. "
SP:deb189d37bd51b92762ce259a106d9a9e9d81ea4,"This paper proposes an unsupervised method based on counterfactual measures of blame to identify effects on the environment controlled by the agent. The proposed method, Controlled Effect Network (CEN), is evaluated in a wide range of environments showing that it can accurately identify controlled effects. Moreover, CEN is evaluated as an intrinsic motivator by integrating it in the state-of-the-art exploration method, achieving substantially better performance than action-prediction models."
SP:ea18d57904e25fd09ed0f6c9972029d78779a8a6,"This paper proposes a structure-regularized pruning (SRP) method for lightweight image super-resolution (SR) networks. SRP imposes regularization on the pruned structure to make sure the locations of pruned filters are aligned across different layers. To transfer the expressive power in the unimportant filters to the rest of the network, the authors employ L2 regularization to drive the weights towards zero so that eventually their absence will cause minimal performance degradation. The proposed method achieves superior performance gains on both lightweight and large image SR networks."
SP:0dee45001ae9600f485614dfe6874a516ac01db5,This paper proposes a method for few-shot learning that trains a feature extracting backbone with the contrastive loss on the base category data and then fine-tunes the backbone with a masking module to select relevant features that are more suited to target domain classification. The proposed method is evaluated on the CDFSL benchmark and shows competitive performance. 
SP:92aa611d71a8da597358330d84fddbb90de2cf4f,This paper studies the effect of gradient descent on the generalization performance of neural networks trained by Bayesian inference and finite width networks trained with gradient descent. The authors show that gradient descent can select networks with a large margin that generalize better than the typical neural network-Gaussian process (NNGP) posterior. They also propose a theoretical tool to estimate the average test error of the NNGP posterior on a given holdout set. 
SP:a0e3cf719a95bbc5aad2f663ba5a3169c316ee9b,"This paper proposes a new method for cross-lingual transfer based on the manifold mixup (X-Mixup) method, which adaptively calibrates the representation discrepancy and gives compromised representations for target languages. Experiments on the XTREME benchmark show that the proposed method achieves 1.8% performance gains on multiple text understanding tasks, compared with strong baselines, and reduces the crosslingual representation discrepancy significantly."
SP:19f8cd8f0c274b6141ba097d2ebb6d18af0986fd,"This paper studies the Byzantine robust distributed federated learning problem, where a fraction of the workers may deviate from the prescribed algorithm and send arbitrary messages to the server. The authors propose a new Byzantine robust algorithm, called bucketing, that adapts existing robust algorithms to heterogeneous datasets at a negligible computational cost. They also theoretically and experimentally validate their approach, showing that it is effective against challenging attacks. "
SP:4d63513b9a1b9b9fc44a69b3d5679a8f48eb95e7,This paper studies the relationship between disentanglement and multi-task learning based on hard-parameter sharing. The authors show that disentangled representations appear naturally during the process of multi- task neural network training. They verify their hypotheses by training multiple models in single- and multiple-task settings and investigating the level of disentangling achieved in their latent representations. 
SP:9851adb72e2918780f661f83f7da06eb866787be,"This paper proposes a framework of certifying robust policies (CROP) for reinforcement learning against adversarial state perturbations. CROP defines two types of robustness criteria: robustness of per-state actions and lower bound of cumulative rewards. The authors propose a local smoothing algorithm that uses a policy derived from Q-functions smoothed with Gaussian noise over each encountered state to guarantee state-level robustness. They also propose a global smoothing method for certifying the robustness for cumulative rewards under adversarial attacks. Finally, the authors evaluate the proposed CROP framework on three Atari games, including RegPGD, RegCVX, and RadialRL."
SP:78da3c97182ec1baf6a131740bf7c91a9afb2fd2,"This paper proposes a new approach to conformal prediction, which aims to output a precise set of promising prediction candidates that is guaranteed to contain a limited number of incorrect answers with high probability. Conformal prediction provides the ability to adapt to model uncertainty by constructing a calibrated candidate set in place of a single prediction. This paper proposes to trade coverage for precision by enforcing that the presence of incorrect candidates in the predicted conformal sets (i.e., the total number of false positives) is bounded according to a user-specified tolerance. Subject to this constraint, the proposed algorithm optimizes for a generalized notion of set coverage (the true positive rate) that allows for any number of true answers for a given query (including zero). The proposed algorithm is evaluated on several classification tasks in natural language processing, computer vision, and computational chemistry."
SP:b126d2f3c397633745c8833e22ace93a2470e963,"This paper studies the effect of depth on the expected length distortion of a ReLU network. The authors show that the length distortion does not grow with depth, and indeed shrinks slightly, for ReLU networks with standard random initialization. They also generalize this result by proving upper bounds for higher moments of the distortion and for the distortion of higher-dimensional volumes. The theoretical results are corroborated by experiments. "
SP:b3b6d0512edfca461ea295ee8665f7f226c45d57,"This paper proposes SAFER, a behavioral prior learning algorithm that learns to extract safety skills from offline data that encodes safety requirements, as well as the safety skills over abstract actions in different scenarios. In the inference stage, SAFER composes a safe and successful policy from safety skills according to the inferred safety variable and abstract action. The proposed method is evaluated on several complex robotic grasping tasks inspired by the game Operation,1 in which SAFER outperforms baseline methods in learning successful policies and enforcing safety requirements."
SP:a5dadb3ecc3caed3b9d9a68eda0d48a53c2d1ce2,"This paper proposes a multi-branch image restoration model inspired by Retinal Ganglion Cells (RGC) that can achieve multiple restoration tasks in a general framework. The experiments show that the proposed architecture, called CMFNet, has competitive performance results on four datasets, including image dehazing, deraindrop, and deblurring. "
SP:263b386beee44b0b45b6f6dc3cf80d020500be62,"This paper proposes a method for federated learning with novel clients at inference time, where a model trained on a set of clients needs to be later evaluated on novel clients with unlabeled data. The proposed method, IT-PFL-HN, is based on a hypernetwork module and an encoder module that learns a representation for a client given its unlabeling data. This client representation is fed to a hyper network that generates a personalized model for that client. Experiments show that the proposed method generalizes better than current FL and PFL methods, especially when the novel client has a large domain shift. "
SP:960d0a63a82593f6e72275b65f0501f0469d1924,"This paper proposes a new method to visualize representations learned with self-supervised models. The method is based on a conditional diffusion based generative model (RCDM) that is trained on a pre-trained representation of the input image. The authors show that SSL-trained representations are not invariant to many data augmentation tasks like classifications, and SSL representations are more robust to adversarial perturbations than supervised representations. They also demonstrate that SSL representations retain more detailed information on the content of the background and object style, while supervised representations appear oblivious to these."
SP:398899e6c86b4a2a17dfa5c2f4478811f4331c1d,"This paper studies the Fp sketch, a well-celebrated streaming algorithm for frequency moments estimation, and shows that it is differentially private as is when p \in (0, 1). The authors also propose a new sensitivity definition called pure multiplicative sensitivity, which shows that the pure multiplier sensitivity is approximately max-22p-2, 22p+2p when p = 1 and p = 0, 1. They also show that Fp is exponentially better than existing DP baselines and only worse than the optimal non-private baseline by a logarithmic factor. "
SP:3253b13851b5a3b5e3c8c6e24891db05903a4e57,"This paper proposes a reward-switching policy optimization (RSPO) method to find novel policies that are both locally optimal and sufficiently different from existing ones. To encourage the learning policy to consistently converge towards a previously undiscovered local optimum, RSPO switches between extrinsic and intrinsic rewards via a trajectory-based novelty measurement during the optimization process. Experiments show that the proposed method can discover a wide spectrum of strategies in a variety of domains, ranging from single-agent particle-world tasks and MuJoCo continuous control to multi-agent stag-hunt games and StarCraftII challenges."
SP:e3ab3aa87ab023bd9949b99a17d4b6e26c1473c0,"This paper proposes a method to find fast diffusion model samplers for diffusion models by differentiating through sample quality scores. The proposed method is based on the Generalized Gaussian Diffusion Model (GGDM), a family of non-Markovian diffusion models. The authors show that optimizing the degrees of freedom of the diffusion model via gradient descent leads to improved sample quality. They show that the proposed method achieves state-of-the-art results on unconditional image generation across various datasets."
SP:7a7506f2b5500a573c0cfb8b0822e5ea725c886a,This paper proposes a method to improve the accuracy of large language models (LLMs) by taking LLM embeddings as input and output continuous prompts that are used to query the LLM. The method is based on a mixture of experts (MoE) model that learns a set of continuous prompts (experts) and selects one of them to query. The P-Adapters are lightweight models that sit between the embedding layer and first attention layer of LLMs. The authors show that the proposed method outperforms the more complex MoE models in extracting factual information from BERT and RoBERTa while eliminating the need for additional annotations.
SP:35cdf71f027cc5168b55cc34c64bfb2f3087d6f5,"This paper proposes a method for continuous classification of time series (CCTS) that aims to classify time series at every time. The main idea is to model multiple distributions simultaneously, which is hard to achieve due to their independent identically distributed premise. Two main problems are the catastrophic forgetting and the overfitting. To overcome these problems, the authors propose a novel Adaptive model training policy ACCTS. ACCTS extracts data distributions adaptive to the time series evolution and the model change. The authors also propose an importance-based replay policy that only replays the important samples."
SP:d9b74b749aa465496763d3a3a9bf3a53e800587e,"This paper proposes a method to extend language models with the ability to memorize the internal representations of past inputs in order to acquire new knowledge. The proposed method is based on the idea of kNN lookup into the memory of a language model, which allows the model to simply read and memorize new data at inference time, thus acquiring new knowledge immediately. The authors show that the performance steadily improves when the size of external memory is increased to 131k tokens. They also find that the model is capable of making use of newly defined functions and theorems during test time."
SP:7a1bbf86c3fdb8738aa826ca330493e857d050ba,"This paper proposes a sampling method to generate sequences from pre-trained masked language modeling (MLM) models. The authors interpret MLMs as energy-based sequence models and propose two energy parametrizations derived from the trained MLMs. A sampling scheme based on the Metropolis-Hastings Monte Carlo algorithm is proposed to sample from these models, and samples are proposed from the same masked conditionals used for training the masked language models and are accepted or rejected based on their energy values according to the target distribution. Experiments are conducted on open-ended unconditional generation and a conditional generation task of machine translation. "
SP:011626ba4fafee13d4a30e3f13c1df5b7071a7f1,This paper studies the problem of data augmentation in NLP tasks. The authors propose a learning-based augmentation policy learning method to find the best augmentation strategy for each task. They propose a sample re-weighting scheme to focus on difficult augmented samples after the original ones are learned confidently for more effective learning from the augmented ones. The proposed method outperforms the recent state-of-the-art augmentation schemes on various text classification tasks and GLUE benchmark.
SP:69d41a862ea189f72d4e8af2854e27b95a91fa41,"This paper proposes a meta-RL algorithm for offline reinforcement learning with sparse reward and distribution shift. The proposed algorithm is based on the FOCAL algorithm, which is a model-free offline RL algorithm. The authors propose to use intra-task attention mechanism and inter-task contrastive learning objectives to achieve robust task inference. Theoretical analysis and experiments are presented to demonstrate the superior performance and robustness of the proposed algorithm. "
SP:ed86c60850d5c8302dcf1c2167db303e778fe681,"This paper proposes a method for estimating the belief state of a partially observable Markov system, given sample-access to its dynamics model. The proposed method is based on the belief fine-tuning (BFT) framework, which leverages approximate dynamic programming to determine the model parameters at each time step. BFT can improve the accuracy of the belief model at test time because it specializes the capacity of the model to the space of local observations. The method is applied to the Hanabi game, where the number of possible information states is too large to track tabularly. "
SP:6150725599c10f0e26f0d7cb1fc04b5b227a4456,"This paper proposes a new method for training sparse neural networks. The proposed method, Pixelfly, uses a fixed sparsity pattern based on flat block and low-rank matrices to sparsify most of the network layers (e.g., attention, MLP, and MLP-Mixer) to speed up the training of neural networks without loss of accuracy. The method is evaluated on ImageNet classification and WikiText-103 language modeling tasks, and achieves 2.3x training time speedup compared to dense ViT models."
SP:136e31054a55abca840f6478491972023c2296cb,"This paper proposes a score-based generative model for conditional image generation. The proposed method is inspired by the class clustering phenomenon of Markov chain diffusion probabilistic models. The authors propose to explicitly model the class center in the forward and reverse process of the forward process, and make an elegant modification to the original formulation, which enables controllable generation and gets interpretability. They also provide another direction for faster sampling and more analysis of their method, and conduct extensive experiments on multiple tasks."
SP:fc2196f1f4ecd864398fed6640ff3f8b19870763,"This paper proposes a method for domain generalization (DG) based on latent sub-spaces. The proposed method is based on the idea of LASSO, where the latent subspaces are formed by the label-informative features captured in source domains. The authors propose to learn individual hypotheses for each sub-space and use them to project target examples onto appropriate sub-SPaces while preserving crucial label informative feature for the label prediction task. The method is evaluated on several well-known DG benchmarks and achieves state-of-the-art results. "
SP:6e8e5bdeb77e3cafe1975da8411fb65118955d14,"This paper studies the kernel thinning (KT) algorithm of Dwivedi and Mackey (2021) which compresses a probability distribution more effectively than independent sampling by targeting a reproducing kernel Hilbert space (RKHS) and leveraging a less smooth squareroot kernel. The authors show that KT applied directly to the target RKHS yields tighter, dimension-free guarantees for any kernel, any distribution, and any fixed function in the RkHS. They also show that, for analytic kernels like Gaussian, inverse multiquadric, and sinc, target KT admits maximum mean discrepancy (MMD) guarantees comparable to or better than those of square-root KT without making explicit use of a square root kernel. Finally, they prove that KT with a fractional power kernel yields better-than-Monte-Carlo MMD guarantees for non-smooth kernels, like Laplace and Matérn."
SP:645c3f1864aa843d4899fc2406f694b5aab8460d,"This paper presents an open-source benchmark suite for the NP-hard Maximum inDEPENDENT SET problem, in both its weighted and unweighted variants. The suite offers a unified interface to various state-of-the-art traditional and machine learning-based solvers. The authors also conduct an in-depth analysis of the popular guided tree search algorithm by Li et al [NeurIPS 2018], testing various configurations on small and large synthetic and real-world graphs. The analysis shows that the graph convolution network used in the tree search does not learn meaningful representation of the solution structure, and can in fact be replaced by random values. The results from the original publication are not reproducible."
SP:155ecd17d264a084b014abdfd0362146d8fb07e0,"This paper proposes Wavelet Compressed Convolution (WCC), a method to compress convolutional neural networks (CNNs) with 1-bit quantization. The method is based on the Haar-wavelet transform (HWT), which can be applied to any 1-1 convolution network. The authors show that WCC achieves compression ratios and computational savings that are equivalent to low bit quantization rates at a relatively minimal loss of accuracy. The proposed method is evaluated on three image-to-image tasks."
SP:004865e6affad32403b7965493a53c8a7ffdda0a,"This paper studies the problem of learning extensive-form correlated equilibrium (EFCE) in multiplayer general-sum imperfect-information extensive form games. The main contribution of this paper is the development of a faster no-regret learning dynamics for EFCE in multiplayer games. This is achieved by using a modified version of the Ellipsoid algorithm, which is a variant of the CFR algorithm. The authors show that this algorithm converges to a correlated distribution of play that is O(T 3/4)-approximate of the original correlated equilibrium, which significantly improves over the best prior rate of $O(T 1/2)$. The authors also provide a theoretical analysis of the stability of fixed strategies through a refined perturbation analysis of a structured Markov chain."
SP:ee545ff83df4d7ff256ac61fbe0eb0765f52f1d5,"This paper proposes a method to learn a discretization of continuous action spaces by leveraging the priors of demonstrations. By discretizing the action space we can apply any discrete action deep RL algorithm to the continuous control problem. The proposed method AQuaDem can learn a state-dependent discretisation of a continuous action space using demonstrations, enabling the use of discrete-action deep RL methods by virtue of this learned discretized action space. Empirical results show that the proposed method outperforms state-of-the-art continuous control methods, both in terms of performance and sample efficiency."
SP:4b39279b98d6aa311bb49dd1384925f9d6f66c2d,"This paper studies the problem of domain generalization in semantic segmentation. The authors propose a novel adversarial style augmentation (AdvStyle) approach to dynamically generate hard stylized images during training and thus can effectively prevent the model from overfitting on the source domain. Specifically, AdvStyle regards the style feature as a learnable parameter and updates it by adversarial training. Experiments show that AdvStyle can significantly improve the model performance on unseen real domains and show that it can achieve the state-of-the-art."
SP:4a2e6d70b383e4941e0bc44e7e82972b22e26792,"This paper proposes a novel mid-air gesture recognition system that encodes event-based gesture data at high temporal resolution into a latent space representation. The proposed method is based on the Hybrid Guided Variational Autoencoder (GuidedVAE), which is a hybrid VAE-VAE architecture that uses a dynamic vision sensor (DVS) to capture the event of a gesture. The authors show that the proposed method achieves 87% classification accuracy on the DVSGesture dataset and it can encode the sparse, noisy inputs into an interpretable latent representation, visualized through T-SNE plots. "
SP:2e66468a6b94177e54b0052b97713ee63902c278,"This paper proposes a method for sparse hierarchical table ensembles (S-HTE) for deep learning for tabular data. The method is based on the idea of sparse hierarchical decision trees (SHTEs), where the decision trees are composed of ferns (oblivious decision trees) and the weights of each fern are computed by a sparse Hierarchical Table Ensemble (HTE). The S-HTEs are trained with dense weights at the beginning of the training process and gradually become sparse using an annealing mechanism, leading to an efficient final predictor. Experiments show that the proposed method is able to achieve comparable performance to SHTEs while having an order of magnitude lower computational complexity. "
SP:b238db9252d83a13438bb747d70e635bb9945958,"This paper proposes Latent Action Q-learning (LAQ), an offline RL method for learning value functions from undirected state-only experience (state transitions without action labels i.e. s, s′, r) tuples. The proposed method is based on tabular Q learning (Q-learning) in discrete Markov decision processes (MDPs) with discrete latent actions obtained through a latent-variable future prediction model. The authors show that the proposed method can recover value functions that have high correlation with value functions learned using ground truth actions. The experimental results show that LAQ outperforms existing methods that learn from observation-only data. "
SP:108ebe9045a9e2b8b5aba8352733782462db8a81,"This paper proposes SWARM, a model-parallel training algorithm designed for swarms of poorly connected, heterogeneous unreliable devices that are rebalanced in case of failure. To further reduce the network usage of the approach, the authors develop several compression-aware architecture modifications and evaluate their tradeoffs. Finally, they combine their insights to train a large Transformer language model with 1.1B shared parameters on a swarm of preemptible T4 GPUs with less than 400Mb/s network throughput."
SP:91d2f094d5481651b554f58aecc2a6207057a47c,"This paper proposes a method to bridge offline training and online tuning in decentralized multi-agent reinforcement learning (D4RL). The authors propose to use both offline and online experiences to tune the policies of agents by modifying sampling probabilities. They design two types of distances, i.e., i.i.d. embedding-based and value-based distances, to measure the similarity between transitions, and propose an adaptive rank-based prioritization to sample transitions according to the transition similarity. Experimental results show that OTC outperforms baselines in a variety of tasks."
SP:d0e650d568214481b07a0452ec606ccbf6d05410,"This paper proposes a new quantization method to reduce the computational cost of training deep neural networks to 4-bit training. The proposed method is based on a logarithmic unbiased quantization (LUQ) method to quantize both the forward and backward phase of the training process to 4 bits. The method achieves state-of-the-art results on ResNet50 on ImageNet. The authors also propose a method that exploits the low precision format by avoiding multiplications during two-thirds of training process, thus reducing the area used by the multiplier."
SP:f2862d1f987164ed6c3c375cd8962e57c369373b,"This paper studies the problem of learning polythetic classifiers in the presence of task-irrelevant features. The authors show that threshold meta-learners, such as Prototypical Networks, require an embedding dimension that is exponential in the number of task relevant features to emulate these functions. In contrast, attentional classifiers such as Matching Networks, which are linear embeddings, are able to solve these problems with a linear embedding dimensions. To address this challenge, the authors propose a self-attention feature-selection mechanism that adaptively dilutes non-discriminative features. Experiments on synthetic and real-world few-shot learning tasks demonstrate the effectiveness of the proposed method."
SP:e1e513fef25d29e17cdadd1b36d932a8ad8897cd,"This paper proposes a multi-agent reinforcement learning framework to explore emergent communication between agents with a continuous communication channel trained through reinforcement learning. The authors use a simple messaging environment where a “speaker” agent needs to convey a concept to a listener and the listener needs to map the continuous signal to the concept. The speaker is equipped with a vocoder that maps symbols to a continuous waveform, while the listener is trained with deep Q-learning. They show that basic compositionality emerges in the learned language representations. They also show that noise is essential in the communication channel when conveying unseen concept combinations. "
SP:0e6ff65ba4a3df35947d1b6f4d438612088d90a0,"This paper proposes a novel backdoor attack against pre-trained NLP models. The proposed method, called BadPre, is a task-agnostic backdoor attack that can be applied to a wide range of downstream NLP tasks. The authors propose a two-stage attack to backdoor downstream language models. In the first stage, the attacker reconstructs the pre-training data by poisoning public corpus and fine-tune a clean foundation model with the poisoned data. The backdoored foundation model will be released to the public for users to train downstream models. At the second stage, to trigger the backdoors in a downstream model, the attackers can inject triggers to the input text and attack the target model. Experimental results show that BadPre can achieve performance drop for up to 100% on 10 different downstream tasks."
SP:58d3ecb4a1906251e79ad883aa97cc2502642658,"This paper proposes an incremental skill discovery method that learns skills one after another in an incremental fashion in an unsupervised manner. The proposed method, called DISk, is able to learn a diverse set of controllable skills in both dynamic and static environments. Experiments show that the proposed method outperforms state-of-the-art skill discovery methods on both skill quality and the ability to solve downstream tasks. "
SP:2c6595408f5ec95537eaf555e5fe3d992b58c222,"This paper proposes a new convolution method called log-polar space convolution (LPSC) where the convolution kernel is elliptical and adaptively divides its local receptive field into different regions according to the relative directions and logarithmic distances. The proposed LPSC not only naturally encodes local spatial structures, but also greatly increases the single-layer receptive field while maintaining the number of parameters. Experiments on different tasks and datasets demonstrate the effectiveness of the proposed method."
SP:7791f96b1eef277a9133975507a750d9e7c6b8ff,"This paper studies the generalization ability of neural networks (NNs) in terms of the information-theoretic information bottleneck (IIW). The authors propose a new information bottleneck, PAC-Bayes Information Bottleneck (PIB), which is based on the trade-off between accuracy and information complexity of NNs. The authors also propose a Bayesian inference algorithm for sampling from the optimal weight posterior specified by PIB. Finally, the authors empirically identify the fitting to compressing phase transition during NNs’ training and the connection between the IIW compression and generalization."
SP:a733847ade77ffbf38760fc79da17893dea8d53f,"This paper studies the data poisoning attacks, which add imperceptible perturbations to training data to maximize the test error. The authors find that the perturbation of advanced attacks are almost linear separable when assigned with the target labels of the corresponding samples. They further confirm that linear separability is indeed the workhorse for recent attacks. The synthetic data are as powerful as the deliberately crafted attacks. "
SP:7b50be406138ad01db3ee112899f622637896fe9,"This paper proposes POELA, a new algorithm for offline policy evaluation based on importance sampling. The main idea is to constrain the potential action set to the set of observed actions with similar states to prevent improper avoidance to lower-reward initial states. The authors provide a theoretical justification of the proposed algorithm through a better per-state-neighborhood normalization condition and show the limitation of previous attempts to this approach through an illustrative example. The experiments show the proposed method with less overfitting and better test performance compared with state-of-the-art batch reinforcement learning algorithms."
SP:c976752a55b9ff47dc63c95a9fd7b51a81e8a42e,"This paper presents CoLLIE, a model for continual learning of how language is grounded in vision. The model uses a pre-trained multimodal embedding model, where language and images are projected in the same semantic space (CLIP by OpenAI), to learn a transformation function that adjusts the language embeddings when needed to accommodate new language use. The authors show that the model can efficiently learn and generalize from only a few examples, with little interference with the model’s original zero-shot performance. "
SP:d3371b322acfc321ee79a2e1b438d82644872fa4,"This paper proposes VLAF2, a novel method for learning novel object captioning models for novel images. The proposed method is based on visual-linguistic adequacy, fidelity, and adequacy, which is a combination of BERT and CLIP. The method is evaluated on the nocaps dataset, where it is shown to achieve state-of-the-art results in terms of fidelity, fluency, and fluency. "
SP:9f3b6486662d80350d77a4b060d4a5b8b22a6130,"This paper studies the phenomenon of neural collapse, which is a clustering property of over-parameterized classification networks that allows them to learn representations that are transferable to new, unseen classes. The authors show that neural collapse generalizes to new samples from the training classes, and – more importantly – to new classes as well, allowing foundation models to provide feature maps that work well in transfer learning and, specifically, in the few-shot setting.  The authors provide a theoretical explanation for this behavior based on the recently observed phenomenon that the features learned by overparametrized classification networks show an interesting clustering properties. "
SP:624c95d9ce1ee4b66274e858e2da22bef6b052c7,"This paper proposes a deep point cloud reconstruction method based on 3D sparse stacked-hourglass network for densification and denoising, and a refinement via transformers converting the discrete voxels into 3D points. The proposed method achieves state-of-the-art performance among the recent studies in the ScanNet, ICL-NUIM, and ShapeNetPart datasets. Extensive experiments demonstrate the effectiveness of the proposed method. "
SP:34a81ca65131576d4c14332a4e9eb3a4c344cab7,"This paper proposes PipeGCN, a new method for distributed GCN training. The main idea is to use intra-partition computation to hide the communication overhead of communicating node features and feature gradients among partitions for every GCN layer in each training iteration. The paper also provides a theoretical convergence guarantee that shows the convergence rate of the proposed method is close to that of the vanilla distributed GCNs training without stale features and stale gradients. Extensive empirical and ablation studies show the effectiveness of the method. "
SP:8302d49558ee0f16392d623d4e604e92db10d041,"This paper studies the problem of test-time robustification, i.e., using the test input to improve model robustness. The authors propose a simple approach that can be used in any test setting where the model is probabilistic and adaptable: when presented with a test example, perform different data augmentations on the data point, and then adapt (all of) the model parameters by minimizing the entropy of the model’s average, or marginal distribution across the augmentations, to encourage the model to make the same prediction across different augmentations. The proposed method is called marginal entropy minimization with ensembled augmentations (MEME), and this is the primary contribution of the work. The empirical results show that MEME consistently improves the performance of ResNet and vision transformer models on several challenging ImageNet distribution shift benchmarks, achieving new state-of-the-art results for these models in the setting in which only one test point is available."
SP:a985de5e940ff3a4160b378201b8c02f68d1914a,"This paper proposes a model-based reinforcement learning algorithm, Mismatched No More (MnM), that jointly trains the model and the policy to increase the expected return on the reward function. This is achieved by jointly optimizing the policy and the model using the same objective, which is a global lower bound on the expected reward. The authors show that MnM is tight under certain assumptions. The proposed algorithm is tested on a variety of RL tasks, and is shown to be competitive with existing methods. "
SP:a469fbcdc20b11dff4085b6fbc384e77f33cd37d,"This paper proposes an imitation learning method that combines the advantages of behavioral cloning (BC-OH) and behavioral cloning from observation history. The main idea is to first compute a coarse action based on the instantaneous observation, and then refine it into a final action using historical information. Experiments show that the proposed method outperforms all baselines on CARLA autonomous driving from images and various MuJoCo continuous control tasks."
SP:95c4533b5d1a865c4cc6a54615e7ad6357bdaad1,"This paper proposes a model-based meta-learning method called DyAd that can generalize across heterogeneous domains by partitioning them into different tasks. DyAd has two parts: an encoder which infers the time-invariant hidden features of the task with weak supervision, and a forecaster which learns the shared dynamics of the entire domain. The encoder adapts and controls the forecaster during inference using adaptive instance normalization and adaptive padding. Theoretically, the generalization error of such procedure is related to the task relatedness in the source domain, as well as the domain differences between source and target. The experimental results show that DyAd outperforms state-of-the-art approaches on both turbulent flow and real-world ocean data forecasting tasks."
SP:ec70553cb0c27e5349c1b8cce6bcaa96a83bf050,"This paper proposes a method for weakly supervised monocular 3D object detection. The proposed method first generates 2D boxes on the image, and then selects corresponding RoI LiDAR points as the weak supervision. A network is trained to predict 3D boxes which can tightly align with associated RoI points. Experiments on the KITTI benchmark show the effectiveness of the proposed method."
SP:34217c6a8ca43b8eeb9ddc83d6f1f0af05918984,"This paper proposes a soft gradient-based subword tokenization module (GBST) that automatically learns latent subword representations from characters in a data-driven fashion. GBST enumerates candidate subword blocks and learns to score them in a position-wise fashion using a block scoring network. The authors also introduce a deep Transformer model that integrates GBST and operates on the byte level. Experiments on English GLUE, multilingual, and noisy text datasets show that the proposed method is more efficient compared to byte-level and subword-based models."
SP:d26d25f2ef23a89a2c139d0dd87c4c86fddcff5e,"This paper proposes an adversarial extreme value analysis (AEVA) method to detect backdoor attacks in black-box deep neural networks. AEVA is based on the observation that the adversarial map of a backdoor-infected example has a singularity phenomenon, which can be used to define the objective function of AEVA. The proposed AEVA method is evaluated on three tasks and backdoor attacks and is shown to be effective in detecting backdoor attacks."
SP:c6dbca0ed0799b7fec21777606f6f809eb2d8c48,"This paper proposes a new uncertainty measure, KLoS, that captures both in-distribution and OOD uncertainty in a single score. The proposed measure is a Kullback-Leibler divergence (KL) divergence between the predicted Dirichlet distribution and a class-wise prototype Dirichlets distribution, which is based on the second-order uncertainty representation provided by evidential models. The paper also proposes an auxiliary neural network to learn a refined criterion directly aligned with the evidential training objective for training samples and to improve uncertainty estimation. Extensive experiments show the effectiveness of the proposed measure. "
SP:8b4f3916dca4e627931558e14836749bd4a6792f,"This paper studies the problem of learning convolutional networks (CNNs) from unlabeled images with low-dimensional patches. The authors propose a semi-supervised algorithm that learns a linear classifier over the features of the image. They show that the algorithm can learn CNNs when the distribution of patches in the input images has low-dimension structure (e.g., when the patches are sampled from a low dimensional manifold). They also provide a lower bound that shows that the dependence of the algorithm on the dimension of the patch distribution is essentially optimal. "
SP:7f2f354d5cc1030bd97bd716aea8fe1d3af86b25,"This paper proposes Ada-NETS to cluster faces by constructing clean graphs for graph convolutional neural networks (GCNs) based on kNN relations in the feature space. In particular, the paper proposes to transform the face into a new structure space by considering the face features of the neighbour images. Then, an adaptive neighbour discovery strategy is proposed to determine a proper number of edges connecting to each face image. Experiments on multiple public clustering datasets show that the proposed method significantly outperforms current state-of-the-art methods."
SP:a3bc8e26f55e78f07de081ca85865afd52b6ae4a,"This paper proposes a new method for generalizable person re-identification (DG ReID) that uses distributionally robust optimization (DRO) to learn robust models that are able to perform well on a collection of possible data distributions (the “uncertainty set”) without demographics. The authors argue that the convex condition of KL DRO may not hold for over-parameterized neural networks and applying KLDRO fails to generalize under distribution shifts in real scenarios. Instead, the authors propose a simple yet efficient approach, Unit DRO, that minimizes the loss over a reweighted dataset where important samples (i.e., samples on which models perform poorly) will be upweighted and others will be downweighted. Empirical results show that the proposed method achieves superior performance on large-scale DG ReID and cross-domain ReID benchmarks compared to standard baselines."
SP:62c1f734b7f6c6e7d5114da6f37c9e3cdda73a23,"This paper proposes a method to improve the performance of graph neural networks (GNNs) by adding noise to the input graph. Specifically, the paper proposes to corrupt the graph with noise and add a noise correcting node-level loss. The noise correction loss helps ameliorate oversmoothing by encouraging diverse node latents. Experimental results show that the proposed method can improve GNN performance on three 3D molecular property prediction tasks. "
SP:24a1b44f37f8eedbab2047fb84600a322d289f3b,"This paper proposes a new method for set2vec embedding based on self-attention. The proposed method is based on the maximum-a-posterior (MAP-EM) steps, which are differentiable operations with a fixed number of mixture parameters, allowing efficient auto-diff backpropagation for any given downstream task. The authors show that the proposed method can be seen as a special case of OTKE, which is a single-step EM with extra balanced assignment constraints. "
SP:b4f7b660b84fe7702fbcc8a96c192abc3a64f045,"This paper proposes a method for unsupervised feature selection in contrastive analysis (CA) setting, where the goal is to select a small number of informative features for use in unknown downstream tasks. The proposed method, CFS (Contrastive Feature Selection), is based on the idea of contrastive contrastive learning. The method is evaluated on a semi-synthetic dataset and four real-world biomedical datasets. The results show that the proposed method outperforms existing methods. "
SP:bc4f69f23aba2034cbf14cb31bdc7a991806bbf6,"This paper studies the relationship between optimal early stopping time and model dimension and sample size for linear regression models. Theoretical results show that the optimal stopping time depends on the model dimension as well as the sample size of the dataset. In particular, the authors show that when the model size exceeds the number of features, early stopping can help mitigate double descent. "
SP:ede87b50cd9c4a6533f17e3e5ddfaaeaaac71dcf,"This paper proposes a quasi-Newton method for the policy gradient algorithm with entropy regularization. The proposed algorithm is based on the natural policy gradient (NPG) algorithm with Shannon entropy. The authors show that the proposed algorithm converges in single-digit iterations, often orders of magnitude faster than other state-of-the-art algorithms. They also provide a simple proof that all these algorithms enjoy Newton-type quadratic convergence near the optimal policy."
SP:3535504f7599b1f39239f7cd8e09acd40fa8fdf0,"This paper proposes a case-based reasoning (CBR) method for text-based games (TBGs) to improve the generalization performance of existing deep RL methods for TBGs. The proposed method is based on the idea that the agent is trained with a set of positive experiences from the past and reuses the collected experiences to act efficiently. The method can be applied in conjunction with any existing on-policy neural agent in the literature for TBG. The experiments show that the proposed approach consistently improves existing methods, obtains good out-of-distribution generalization, and achieves new state of-the-art results on widely used environments."
SP:9a5dd0148a15dc5b4d2bc6762dfe8a8991f8866c,"This paper proposes a two-stage method to distill multiple word senses from a pre-trained language model (BERT) by using attention over the senses of a word in a context and transferring this sense information to fit multi-sense embeddings in a skip-gram-like framework. The proposed method is evaluated on the contextual word similarity and sense induction tasks, and experiments with an embedding-based topic model (ETM) demonstrates the benefits of the proposed method in a downstream application."
SP:e4cdba0fc7cd7f440d4436219f3959d8d5e2ad28,"This paper presents a method to transfer a 2D image-pretrained model to a 3D point-cloud model by inflating 2D convolutional filters to 3D filters and finetuning the inflated image pretrained models (FIP). The method is evaluated on few-shot classification and point cloud classification tasks. The results show that FIP can achieve competitive performance on 3D points cloud classification, beating a wide range of point cloud models. "
SP:dc99c307931ae9c5d4a1b998dc94cfc6ac78d11f,"This paper proposes a method for training an autoregressive generative model that takes advantage of a well-designed energy-based learning objective. The proposed method is capable of alleviating the exposure bias problem and increase temporal coherence by imposing a constraint which fits joint distributions at each time step. Besides, the proposed method estimates the energy scores based on the underlying auto-regressive network itself, which does not require any extra network. Finally, thanks to importance sampling, the authors can train the entire model efficiently without MCMC process."
SP:51e748c55bd4134047098559577fa3f37aa7433a,"This paper presents a unified framework that connects Wasserstein distributional robustness with current state-of-the-art AT methods. Theoretically, the authors show that standard AT methods are special cases of their counterparts in the proposed framework. This leads to an intuitive relaxation and generalization of existing AT methods and facilitates the development of a new family of distributional AT-based algorithms. Extensive experiments show that the proposed algorithms robustify further their standard AT counterparts in various settings."
SP:f192046ea8ad61bfc8e05a0ddb90a8bd15b4640b,"This paper proposes a novel unsupervised representation learning method for multivariate time series. The proposed method is based on the idea of bilinear temporal-spectral fusion (BTSF) to incorporate spectral information and temporal relations in feature representation. BTSF augments the segment-level augmentation by simply applying dropout on the entire time series for better preserving global context and capturing long-term dependencies. Extensive experiments are conducted on three major practical tasks for time series such as classification, forecasting and anomaly detection to demonstrate the effectiveness of the proposed method. "
SP:ef54840009afb095c67bbbc29a7824c20a375ee8,"This paper proposes an algorithm for automatically adjusting the learning rate of deep neural networks during gradient descent. The learning rate is optimized via a simple extra gradient descent step, justified by an analysis that exploits the structure of neural networks. The authors formulate first and second-order gradients with respect to learning rate as functions of consecutive weight gradients, leading to a cost-effective implementation. Extensive experimental evaluation is conducted, validating the effectiveness of the proposed method for a plethora of different settings."
SP:263c787361cd6d4443ce516d389c694d0fe44b28,"This paper proposes a continual meta-learning method for sequential multi-task learning, where the goal is to achieve high reward over any sequence of tasks quickly. The proposed method, called CoMPS, is based on meta-training in an incremental fashion, over each task in a sequence, without revisiting prior tasks during training. The method consists of two subroutines: learning a new task using RL and using the experience from RL to prepare for subsequent task learning. The experiments show that the proposed method achieves a higher average reward with fewer samples on average over each of the tasks in the sequence."
SP:2bd729b7aa045bf74e31229c9e76e57af36e804b,"This paper proposes a new threat model for poisoned classifiers, where one without knowledge of the original trigger, would want to control the poisoned classifier. The authors propose a test-time, human-in-the-loop attack method to generate multiple effective alternative triggers without access to the initial backdoor and the training data. They construct these alternative triggers by first generating adversarial examples for a smoothed version of the classifier, created with a procedure called Denoised Smoothing, and then extracting colors or cropped portions of smoothed adversarial images with human interaction. They demonstrate the effectiveness of their attack through extensive experiments on high-resolution datasets."
SP:e58ab0e3cff6b18013145a1a99cfa9da0a3d872f,"This paper proposes a new method for unconditional GAN distillation, specifically for the StyleGAN2 architecture. The main contribution of this paper lies in the analysis of the output discrepancy issue, where the teacher and student model yield different outputs given the same input latent code. The authors identify that the style module plays a vital role in determining semantic information of generated images, and propose a novel initialization strategy for the student model, which can ensure the output consistency to the maximum extent. To further enhance the semantic consistency, the authors propose a latent-direction-based distillation loss that preserves the semantic relations in latent space. Extensive experiments demonstrate the effectiveness of the proposed method. "
SP:2c2231743fa33b95828c6615263954ce1c05f95d,"This paper proposes a method for approximating offline algorithms in online settings by encoding the behavior of offline algorithms into graphs. The authors train a multi-task learning model to simultaneously detect behavioral structures which have already occurred and predict those that may come next. They demonstrate the methodology on both synthetic data and historical stock market data, where the contrast between explanation and prediction is particularly stark."
SP:ee3a21d2fb8a073099aa200129a53c31f3b6561d,"This paper proposes a method to reduce the number of inducing points in Gaussian Processes (GPs) by amortizing the parameters of an approximate posterior distribution. The inducing points are learned by considering them as parameters of a variational posterior approximation of the posterior distribution of the Gaussian process. A neural network is used to compute the inducing points for each potential data point. The proposed method is evaluated on MNIST, CIFAR-10, and MNIST-100 datasets."
SP:f20c99b441545047a16ae524cc2e317b2c3787a2,"This paper proposes a protocol for decentralized training in the presence of Byzantine attackers. The proposed protocol is based on the ResNet-18 protocol, which is a distributed training algorithm with Byzantine tolerance. The authors provide theoretical bounds for the robustness of the proposed protocol to Byzantine and Sybil attacks. They also conduct experiments on image classification and language modeling in presence of the Byzantine attackers to verify the effectiveness of their algorithm. "
SP:93894f20ab2593e5237b6972fef9fe63e96af89a,"This paper proposes a method to learn a physics-explainable SPH-based model for learning Lagrangian models of turbulence using parameterized and learn-able physics-based parameters and Neural Networks as universal function approximators. The authors propose a mixed mode approach, mixing forward and reverse mode automatic differentiation with forward and adjoint based sensitivity analyses to efficiently perform gradient based optimization. They show that their method is capable of solving inverse problems over the physically interpretable parameter space, as well as over the space of Neural Network parameters. They also show improved interpretability, generalizability (over larger ranges of time scales and Reynolds numbers), preservation of physical symmetries and requires less training data."
SP:d11b81f9ab414fcf430a03cd70c2d3246b678474,"This paper proposes Mix-Max-Ent, a method to regularize a single deterministic neural network to obtain improved accuracy and reliable uncertainty estimates. The proposed method is based on a data-dependent regularizer corresponding to the predictive distribution in the regions of the embedding space between the class clusters. This is achieved by synthetically generating between-cluster samples via the convex combination of two images from different classes and maximizing the entropy on these samples. Extensive experiments on real-world datasets (CIFAR-10 and CIFAR100) using ResNet and Wide-ResNet architectures demonstrate that the proposed method consistently provides much improved classification accuracy, better calibrated probabilities for in-distribution data, and better uncertainty estimates when exposed to situations involving domain-shift and out-of- distribution samples."
SP:365490b872464f00634dc7a50d024fceaf0a61ee,"This paper proposes a self-supervised auto-encoder-based method for image-to-image motion transfer from a source image to a still image. The proposed method, Latent Image Animator (LIA), is motivated by the observation that the latent space of a GAN can be viewed as a set of directions in the latent code of an image animator that induces high-level transformations in the space of the animator. To this end, the authors propose to learn a linear combination of orthogonal motion directions simultaneously, and use their linear combination to represent any displacement in latent space. Extensive quantitative and qualitative analysis shows that the proposed method outperforms state-of-the-art methods on VoxCeleb, Taichi and TED-talk datasets w.r.t. generated quality."
SP:86f9f89f84e117c86478b9afaf087f65524f5472,"This paper proposes a meta-learning method called task interpolation (MLTI) to augment the task set through interpolation. The proposed method randomly samples a pair of tasks and interpolates the corresponding features and labels. Theoretical analysis shows that MLTI corresponds to a data-adaptive meta-regularization and further improves the generalization. Empirically, MLTI outperforms six prior metalearning regularization methods on eight real-world datasets from various domains."
SP:73d577e9c4f4af5e11a9e5bdb583ee0f50a315f5,"This paper proposes a new fair representation learning method, called Fair Normalizing Flows (FNF), which is based on the idea of normalizing flows to minimize the statistical distance between the latent representations of different groups. The main advantage of FNF is that its exact likelihood computation allows us to obtain guarantees on the maximum unfairness of any potentially adversarial downstream predictor. Experiments are conducted on a variety of datasets to demonstrate the effectiveness of the proposed method."
SP:404d5643327f60f0f06f820033a56081f9e01900,"This paper proposes a graph neural network (GNN) based method for subgraph isomorphism counting. The proposed method is based on edge-centric message passing, where messages on edges are propagated and aggregated based on the edge adjacency. The method is able to preserve fine-grained structural information, given that an edge is an atomic unit of encoding graph structures. Extensive experiments on several benchmark datasets demonstrate the effectiveness and efficiency of the proposed method COUNT-GNN."
SP:5a94f18156ab2949c86de45fcf0de2e16977eebb,"This paper proposes a federated learning method for federated settings where each client can have their own personalized labels, which might not be compatible with others (even for the same class), and can be also possibly from a variety of multiple domains. In this setting, the proposed method measures task-level similarity based on locally learned knowledge and matches the relevant ones for personalized knowledge reflection. The authors also factorize the model parameters into two basis vectors and the highly sparse masks to significantly reduce the dimensionlaity of parameter space for alleviating knowledge collapse and information loss when reflecting the heterogeneous knowledge. The proposed method outperforms the current state-of-the-art baselines."
SP:97f30bea31eccef6c770fbce1e14fd6d2493a178,"This paper proposes a method to learn object-centric representations of scenes with multiple objects by distilling explicit object dynamic representations (e.g., velocity) from raw video input. The method is based on a relation module that calculates object-pair interactions and applies it to the corresponding dynamic representations of objects. The proposed method is evaluated on tasks of video events reasoning and video prediction, which are two important evaluations for video understanding. "
SP:ba8e50d1fa9cb824fa3f76c0c691997cd151d760,"This paper studies the problem of link prediction in graph neural networks (GNNs) that allow using positional features of nodes given by positional encoding (PE) techniques such as Laplacian Eigenmap, Deepwalk, etc.. GNNs with PE often get criticized because they are not generalizable to unseen graphs (inductive) or stable. This paper studies these issues in a principled way and proposes a provable solution, a class of GNN layers termed PEG with rigorous mathematical analysis. Extensive link prediction experiments over 8 real-world networks demonstrate the advantages of PEG in generalization and scalability."
SP:cf448479f68c3194c1a9e11729bf70d7cc2ae8fd,"This paper proposes LaMer, a novel text style transfer framework based on large-scale language models. LaMer first mines the roughly parallel expressions in the non-parallel datasets with scene graphs, and then employs MLE training, followed by imitation learning refinement, to leverage the intrinsic parallelism within the data. On two benchmark tasks (sentiment & formality transfer and a newly proposed challenging task (political stance transfer), LaMer achieves qualitative advances in transfer accuracy, content preservation, and fluency. "
SP:8f7b2d1020d9e527118b8fb816760c13b0d0bfcb,This paper extends the multi-hop logical reasoning problem to hyper-relational knowledge graphs (KGs) and proposes a method to answer conjunctive queries in latent space. The proposed method is based on Graph Neural Networks (GNNs) and query embedding techniques. The method is validated on a variety of query patterns and is shown to be able to answer more complex queries.
SP:5f8b58424a1a8eeb72217e75189d6f773a298a7a,This paper proposes a new method for hyperparameter optimization for deep neural networks. The proposed method is based on Bayesian optimization for a gray-box setup. The authors propose a new surrogate for Gaussian Processes that embeds the learning curve dynamics and a new acquisition function that incorporates multi-budget information. The experimental results show that the proposed method outperforms the state-of-the-art methods on a variety of datasets.
SP:99d3d94e3af5d2dc7b92c00ac1345d1d2dd0d15b,"This paper proposes a new method to improve the performance of learned image compression. The proposed method is based on post-training quantization and makes the model inference integer-arithmetic-only, which is much simpler than the existing training and fine-tuning based approaches. The authors further improve the discretization of the entropy parameters and extend the deterministic inference to fit Gaussian mixture models. "
SP:85d0df515e9e555f3ea1c21d607304dfaeae69c0,"This paper proposes an unsupervised noise reconstruction and removal network for denoising scanning electron microscopy images. The architecture is inspired by gated recurrent units, which reconstructs and removes the noise by synthesizing the sequential data. The noise reconstruction module is trained with soft attention and signal boosting, that upon deployment on large images (more than 24M pixels) remove the noise, and a neural network architecture design using our noise reconstruction modules with detailed performance analysis, and an updated Noise2Noise loss function specifically designed for the denoised FIB-SEM data sets."
SP:e6275b0b103fa90dcebcdd3d3c14c830c3402972,"This paper studies the label trick for graph neural networks (GNNs) and label propagation. The authors propose to use a randomly-selected portion of the training labels as GNN inputs, concatenated with the original node features for making predictions on the remaining labels. This so-called label trick accommodates the parallel use of features and labels, and is foundational to many of the top-ranking submissions on the Open Graph Benchmark (OGB) leaderboard. This paper shows that under certain simplifying assumptions, the stochastic label trick can be reduced to an interpretable, deterministic training objective composed of two factors. The first is a data-fitting term that naturally resolves potential label leakage issues, while the second serves as a regularization factor conditioned on graph structure that adapts to graph size and connectivity. "
SP:b6cbc3661f9c440687c3dd01ee35a118c87db377,"This paper proposes a new multi-agent multi-agents task, called SymmToM, where agents can speak, listen, see other agents, and move freely through a grid world in a symmetric environment. The goal of the task is to test the ability of agents to develop a theory of mind (ToM) to understand the other agents’ internal states. The authors show that agents with no ToM model fail to achieve performance comparable to agents with access to the gold-standard mental state of other agents. In addition, they show that the problem of solving the task requires developing a model that models the mental states of all agents. "
SP:f8ce83805eee46c6c196e8477bf10d8d7f7e0f46,"This paper proposes a novel method for zero-shot object detection based on YOLOv5. The proposed method is based on the YCB Video dataset, which contains 21 objects in various categories. The authors propose to split the dataset by seen and unseen objects, which can be used for both gZSD and gZSL research that related to daily objects. They also propose a novel attribute labelling method for objects in YCB video dataset."
SP:aa1dcd9217270010f16a00004facede942efea17,"This paper proposes a video prediction method based on an autoregressive latent video prediction model. The proposed method is based on a high-fidelity image generator (VQ-GAN) with a causal transformer model (HARP) to generate high-resolution (256x256) videos. The authors show that the proposed method achieves competitive performance to state-of-the-art approaches on standard video prediction benchmarks with fewer parameters, and enables high resolution video prediction on complex and large-scale datasets. "
SP:7f57896afd63bc869d2db6ddf7abbeaa71daae11,"This paper proposes to use ViTs to train GANs with ViTs for image generation. Specifically, the ViT discriminators are used to train the GAN discriminator. The proposed method, ViTGAN, achieves comparable performance to the best-performing CNN-based GAN models on CIFAR-10, CelebA, LSUN bedroom, and CelebA datasets. "
SP:bbae3afcaea0a2e54904cb8daaed7df4fe37da6e,"This paper proposes a two-stage training process to improve the ELBO performance of variational autoencoders. The first stage trains a low-rate model on top of a high-rate one, and the second stage trains an additional model to model the visually imperceptible bits. The authors show that the low rate model has much worse ELBOs than the high rate model due to the poor modeling of the visually perceptible bits, and propose a two stage training process that trains a secondary model on the top of the first one. The secondary model is able to improve ELBO significantly with minimal impact on the sample quality achieved by the initial one."
SP:bfed56018134ec66cde9a7e958df964d4cca3164,"This paper proposes a score-based model for estimating the variance and KL divergence of the reverse process of a DPM. The authors show that both the optimal reverse variance and the corresponding optimal KL divergence have analytic forms w.r.t. the score function of the DPM, and derive lower and upper bounds of the optimal variance and optimal divergence, respectively. Then, the authors propose a training-free inference framework that estimates the analytic forms of the inverse variance and divergence using the Monte Carlo method and a pretrained score based model. Empirically, the proposed method improves the log-likelihood of various DPMs, produces high-quality samples, and enjoys a 20x to 40x speed up."
SP:3f935ba5784c3e86db72421426bc479061af1a4b,"This paper proposes to use vision transformers (ViTs) to replace CNNs for medical image classification tasks. The authors conduct a series of experiments on several standard medical image benchmark datasets and tasks and show that ViTs perform better than CNNs when pretrained on ImageNet, both in a supervised and self-supervised setting. They also show that the proposed ViTs can be used in medical image analysis."
SP:a64e0535f268901e38fd51e027c612ebcdbae1a4,"This paper studies the problem of pretraining neural language models (NLMs) over a large corpus. The authors show that the pretrained NLM can model much stronger dependencies between text segments that appeared in the same training example, than it can between different training examples. They also show that pretraining NLMs can improve the performance of natural language understanding tasks. "
SP:59066956fa2e423d5f2d2ea4f91c4ddf6afd4683,This paper proposes a new method for learning to optimize (L2O) based on symbolic regression. The main contribution of this paper is the introduction of symbolic regression to the L2O framework. The proposed method is shown to be able to be trained on large-scale problems and outperforms human-designed and tuned optimizers.   
SP:54dfeb363beee9959aecc9e0853ff06e43bd94e4,"This paper studies the problem of adversarial robustness of deep neural networks (DNNs) in the context of reinforcement learning (RL). In this setting, the adversary can infer the defense strategy used by the victim agent by observing the states, actions, etc. from previous time-steps and adapt itself to produce stronger attacks in future steps (e.g., by focusing more on states critical to the agent’s performance). To defend against an adaptive RL adversary that can directly certify the total reward without requiring the policy to be robust at each time-step, the authors propose policy smoothing where the agent adds a Gaussian noise to its observation at every time step before passing it through the policy function. The authors show that their method can yield meaningful robustness guarantees in practice."
SP:e0f9add5fde18eaab0eeb2b10b14928acc8ec5b8,"This paper proposes a method for predicting the target domain accuracy using only labeled source data and unlabeled target data. The proposed method, ATC, learns a threshold on the model’s confidence, predicting accuracy as the fraction of unlabeling examples for which model confidence exceeds that threshold. ATC outperforms previous methods across several model architectures, types of distribution shifts (e.g., due to synthetic corruptions, dataset reproduction, or novel subpopulations), and datasets (WILDS, ImageNet, BREEDS, CIFAR, and MNIST). "
SP:e748bf6ee653087cae825df32a8546f9ccebfcf1,"This paper studies the problem of point set registration, where the goal is to recover a transformation that matches one set to the other. The authors formulate the registration problem as a partial distribution matching (PDM) problem, where point sets are regarded as discrete distributions, and the goal of the registration is to partially match them. To handle large point sets, the authors propose a method for large scale PDM problem by utilizing the partial Wasserstein-1 (PW) discrepancy, which they show can be efficiently optimized. They theoretically derive the Kantorovich-Rubinstein duality for the PW discrepancy, and show its gradient can be explicitly computed. Based on these theoretical results, they propose a neural network, which approximates the partial PW discrepancy by a neural networks, and learns the transformation adversarially with the network, and incorporates an efficient coherence regularizer for non-rigid transformations to avoid unrealistic deformations. "
SP:f94f77696d100b2638fa2a6d82c8df47db3b6a36,This paper proposes a transfer learning method for hyperparameter optimization (HPO) that can be jointly trained on a set of source tasks and then transferred efficiently on a new (unseen) target task. The proposed method is based on Deep Kernel Gaussian Process surrogate with Landmark Meta-features (DKLM). The DKLM captures the similarity between hyper-parameter configurations with an end-to-end meta-feature network that embeds the set of evaluated configurations and their respective performance. Experiments validate the performance of DKLM in a wide range of HPO meta-datasets from OpenML.
SP:e3c57f3589e8ab674644d900c14b3473cd71a23f,This paper proposes a new method for fingerprinting GANs for deep fake detection and attribution. The proposed method is based on the concept of fingerprinting for generative models that enables a responsible disclosure of state-of-the-art GAN models with distinct fingerprints. The key idea is to use a 128-bit fingerprinting mechanism to generate a large population of models that can be used to identify the source of the generated samples. The authors show that the proposed method can be applied to a wide range of GAN-based deep fakes and achieves good performance.
SP:73bffd1a0856b80d29f7a2b2b68be57882531f07,"This paper proposes a method to provide post-hoc explanations for model agnostic local explanations for black box similarity learners. The method is based on two steps: (1) derive feature attributions to explain the similarity between a pair of inputs as determined by a black-box similarity learner, and (2) propose analogies as a new form of explanation in machine learning to identify diverse analogous pairs of examples that share the same level of similarity as the input pair and provide insight into (latent) factors underlying the model’s prediction. The proposed method is applied to tabular and text data, to explain similarities between i) sentences from the Semantic Textual Similarity (STS) dataset, ii) patients in terms of their healthcare utilization using Medical Expenditure Panel Survey (MEPS) data, and iii) iris species (IRIS). The proposed methods outperform feature-and exemplar-based baselines in both the quantitative evaluation and human user study."
SP:6a3c4ae05d582f8896840483b08c735ced2976bc,"This paper studies the certified robustness of ensemble ML models under the model-smoothness assumption. The authors show that ensemble models are more robust than a single model empirically, but the standard ensemble models only achieve marginal improvement compared to single models. To address this issue, the authors propose the lightweight Diversity Regularized Training (DRT) to train ensemble models. Extensive experiments show that the DRT enhanced ensembles can consistently achieve higher certified L2-robustness than existing single ML models. "
SP:3002b29c27709780238876d8c3f81bbd6a0f8112,"This paper studies the expressive power of low-order graph neural networks (GNNs) in the context of graph representation learning. In particular, the authors propose a new pooling technique of local neighborhoods that allows different tradeoffs of computational cost and expressive power. First, they prove that this model can count subgraphs of size k, and thereby overcomes a known limitation of low order GNNs. Second, they show how recursive pooling can exploit sparsity to reduce the computational complexity compared to the existing higher-order GNN. More generally, they provide a (near) matching information-theoretic lower bound for counting sub-graphs with graph representations that pool over representations of derived (sub-)graphs. "
SP:5d0cbd84336caf5f31e1f98e11f6733230e4d792,This paper revisits the KI process in an information-theoretic view and shows that KI could be interpreted using a graph convolution operation. The authors propose a simple probe model called Graph Convolution Simulator (GCS) for interpreting KI methods and expose what kind of knowledge is integrated into these models. They find that only a small amount of factual knowledge is captured in these models during integration. They conduct experiments to verify that our GCS model can indeed be used to correctly interpret KI processes and analyze two typical knowledge-enhanced LMs: K-Adapter and ERNIE.
SP:7e73948421e98307fceb69a316d8a4e7c4926cda,"This paper studies the effect of the adaptation learning rate in meta-learning with mixed linear regression. The authors propose a principled way to estimate optimal adaptation learning rates that minimize the population risk of MAML. They also prove that compared with empirical risk minimization (ERM), MAMM produces an initialization with a smaller average distance to the task optima. "
SP:effbc85d89b1197d9c2abcaf5ff13864135dd6e1,"This paper proposes a method for source-free domain adaptation (SFDA) that aims to adapt a model trained on labelled data in a source domain to unlabelled data in the target domain without access to source-domain data during adaptation. The authors propose to restore the source features by storing a lightweight and flexible approximation of the feature distribution under the source data. In the source domain, they adapt the feature-extractor such that the approximate feature distribution is preserved on the target data. They also propose a bottom-up training scheme for FR that boosts performance by preserving learnt structure in the later layers of a network. "
SP:7d63034ec7e6a4f178681ff2a49feb485cd47116,"This paper proposes FedRBN, a method for federated learning to propagate adversarial robustness among non-iid users. The proposed method is based on batch normalization (BN) statistics, which are used to train two separate BNs for clean and adversarial data. The authors show that the proposed method can propagate robustness from high-resource users that can afford AT, to those low resource users that cannot afford it, during the FL process. Experiments are conducted on MNIST, CIFAR-10, and ImageNet datasets."
SP:42c7a79e58b6a9f776fa6ae928bd89c194f9303f,"This paper proposes a method to infer the network structure from observed game outcomes (equilibrium actions) without knowing the utility function associated with the game. The proposed method is based on a transformer-like architecture that correctly accounts for the symmetries of the problem and learns a mapping from the equilibrium actions to the network structures of the game without explicit knowledge of the utility functions. The method is tested on three different types of network games using both synthetic and real-world data, and shows superior performance over existing methods. "
SP:1c7b9157cf8c06ca771da78895fc3af969b0fb85,"This paper proposes GraphANGEL, a novel relation prediction framework that predicts relations between each node pair by checking whether the subgraphs containing the pair are similar to other subgraph containing the considered relation. Each graph pattern explicitly represents a specific logical rule, which contributes to an inductive bias that facilitates generalization to unseen relation types and leads to more explainable predictive models. The proposed method outperforms existing models in terms of heterogeneous graph based recommendation as well as knowledge graph completion tasks."
SP:26ed25a7b42da2cf11b76a727102d8aa36d76657,"This paper studies few-shot learning in histology images. The authors propose to combine contrastive learning (CL) with latent augmentation (LA) to build a few shot system. CL learns useful representations without manual labels, while LA transfers semantic variations of the base dataset in an unsupervised way. The experimental results show that CL learned models generalize better than supervised learning for histological images in unseen classes, unseen classes and unseen classes. "
SP:badbe687258cd5c282ca167b1f6fbfc6b5400dbf,"This paper proposes a continuous-time recurrent model for learning long-term dependencies of irregularly-sampled time series. The proposed model is based on a memory compartment separated from its time-continuous state, which encodes a continuous time dynamical flow within the RNN, allowing it to respond to inputs arriving at arbitrary time-lags while ensuring a constant error propagation through the memory path. The authors prove that similar to standard RNNs, the underlying reason for this issue is the vanishing or exploding of the gradient during training. This phenomenon is expressed by the ordinary differential equation (ODE) representation of the hidden state, regardless of the ODE solver’s choice. The paper shows that learning ODE-RNNs by the adjoint method (Chen et al., 2018) does not help with this problem."
SP:4efd22f9122fa5856a9f4302eb6875fa0c414912,"This paper proposes a new method for fully binarized BERT to reduce the computational and memory cost of the BERT model. The proposed method, BiBERT, is based on the binarization of BERT with a 1-bit weight, embedding, and activation. The authors show that the performance drop can be mainly attributed to the information degradation and optimization direction mismatch respectively in the forward and backward propagation. To address this issue, the authors propose an efficient DMD scheme to optimize the full BERT accurately. Extensive experiments show the effectiveness of the proposed method. "
SP:619bd742e92bea6241852f5a9d2b7bacf13b393a,"This paper proposes a method to solve keypoint detection and instance association by using Transformer for multi-person pose estimation. The key idea is to supervise self-attention in Transformer to be instance-aware and assign the detected keypoints to their instances based on the pairwise attention scores, without using pre-defined offset vector fields or embedding like CNN-based bottom-up models. The proposed method is evaluated on the COCO challenge and the person instance segmentation task. "
SP:14750819593136fc9ef4efd032ab6f94dc5f6a02,"This paper studies the problem of Pareto-efficient reinforcement learning for sequential decision-making under uncertainty. In particular, the authors propose a method to train an agent to maximize the expected quadratic utility function, where the expected utility function is defined as the expected variance of the policy. The authors show that the proposed method is more computationally efficient than existing methods, which do not include gradient estimation of the variance. The proposed method can be seen as an extension of existing methods that consider the mean-variance (MV) trade-off."
SP:f675b564b3a9c8626ce7944d752fa3e0d868428e,"This paper studies the problem of test-time domain adaptation for an autoencoder system whose channel is generatively-modeled using a mixture density network (MDN). Different from the setting of conventional training-time (unsupervised or semi-supervised) domain adaptation, the authors propose a fast and sample-efficient method for adapting the channel model without modifying the encoder and decoder neural networks, and adapting only the MDN channel model. The method utilizes feature transformations at the decoder to compensate for changes in the channel distribution, and effectively present to the target samples close to the source distribution. Experimental evaluation on simulated datasets and real mmWave wireless channels demonstrate that the proposed method can adapt the channel using very limited number of samples, and improve or maintain the error rate of the autoencoders."
SP:77dc92137ea490d3e1b4b8ee1630dbe2ee0bddfa,"This paper studies the abductive natural language inference task (αNLI) where the goal is to infer the most plausible explanation between the cause and the event. The authors propose to group the hypotheses and design a structural loss called “joint softmax focal loss” to penalize the inference network uniformly. Based on the observation that the hypotheses are generally semantically related, the authors have designed a novel interactive language model aiming at exploiting the rich interaction among competing hypotheses. The experimental results show that the proposed IMSL achieves the highest performance on the RoBERTa-large pretrained model, with ACC and AUC results increased by about 1% and 5% respectively."
SP:17cd72df5fc19398f582d27516fd742b073f79e3,"This paper proposes a method for adversarially robust out-of-distribution (OOD) detection and OOD detection. The method combines a certifiable OOD detector with a standard classifier from first principles into an OOD aware classifier. The proposed method achieves the best of two worlds: certifiably robust detection, even for OOD samples close to the in-dist distribution, without loss in either prediction accuracy or detection performance for non-manipulated OOD data. Moreover, the proposed method avoids the asymptotic overconfidence problem of standard neural networks."
SP:9c3756f13932236aff3e8104f4fa193dcc8fde2f,"This paper proposes a generalized transferable transferable attack (GTA) problem where the attacker has a set of surrogate models trained on different datasets (with different label sets and image sizes), and none of them is equal to the dataset used by the victim model. The paper then proposes a novel method called Image Classification Eraser (ICE) to erase classification information for any encountered images from arbitrary dataset. Extensive experiments on Cifar-10, CifAR-100, and TieredImageNet demonstrate the effectiveness of the proposed ICE on the GTA problem. "
SP:2e0447c741a3f09be1095633d870200355211260,"This paper studies the problem of false negative predictions in discriminative pre-trained language models (PrLMs). The authors propose two pre-training objectives: soft regularization by minimizing the semantic distances between the prediction and the original one to smooth the rough cross-entropy, and hard correction to shield the gradient propagation of the false negative samples to avoid training with false negatives. The proposed methods are tested on GLUE and SQuAD benchmark tasks and show better performance compared to the baselines."
SP:281bc59d639aa76d84921b3ec4ce1ee8f1ba5b51,"This paper proposes a novel open-world semi-supervised learning (SSL) setting where novel classes may appear in unlabeled test data. The authors propose ORCA, an end-to-end approach that assigns instances to previously seen classes or forms novel classes by grouping similar instances without assuming any prior knowledge. ORCA gradually increases the discriminability of the model during the training and reduces the gap between intra-class variance of seen with respect to novel classes. Experiments on image classification datasets and a single-cell dataset demonstrate that ORCA consistently outperforms alternative baselines."
SP:6c572c4c21b01a0cf3fd9ef97fbb348ef4e405ae,"This paper proposes SLIM-QN, a light stochastic quasi-Newton optimizer for training large-scale deep neural networks (DNNs). The proposed method addresses two key barriers in existing second-order methods: 1) the high computational cost of obtaining the Hessian matrix and its inverse in every iteration (e.g. KFAC); 2) convergence instability due to stochastically training. To tackle the first challenge, the proposed method uses the BFGS update rule that directly approximates the inverse using past parameters and gradients. To achieve stable convergence, the authors introduce momentum in Hessian updates together with an adaptive damping mechanism. Experiments on various datasets and network architectures show that the proposed algorithm achieves faster convergence compared to SGD."
SP:4bffce00ebb02d2e676eec897647ac14c3344deb,"This paper proposes a systematic method for graph pruning based on Locality Sensitive Hashing (LSH) to remove redundant components from large graphs without compromising the performance too much. The proposed method is based on the observation that large graphs often involve redundant components that can be removed without compromising performance. The authors argue that sparsification based on local properties of a graph is more in-line with the prevailing methodology of GCNs, as opposed to approaches that rely on global topologies, such as spectral methods. Extensive experiments on synthetic and real-world datasets demonstrate the superiority of the proposed method."
SP:c5e024f4e2079586298519ca868630efd7579eca,"This paper proposes a data augmentation method for contrastive self-supervised learning (SSL) that can modify training data to be hard positives/negatives without distorting the key information about their original identities. In particular, the authors decompose a sample x to be its variational auto-encoder (VAE) reconstruction G(x) plus the residual R(x), where R retains most identitydistinctive information due to an information-theoretic interpretation of the VAE objective. They then add it back to the original VAE’s bottleneck space and add it as an augmentation, which preserves the sample identity intact. They apply this “identity-disentangled adversarial augmentation (IDAA)” to different SSL methods, and on multiple benchmark datasets, IDAA consistently improves both their efficiency and generalization performance."
SP:0991bc5f213bd8ab7572e2fed309e1b57a35835b,"This paper proposes a method to detect distribution shifts in training data. The proposed method is based on the Brier score, which measures the difference between the training distribution and the test distribution. The authors argue that the proposed method can detect harmful shifts while ignoring benign ones, and allow continuous monitoring of model performance without increasing the false alarm rate. The method is evaluated on both simulated and real data."
SP:1c7b954273e3a9cda333385b15a3e8ed3bf8178a,This paper proposes a method to reconstruct the physical parameters of pendulum motion from a single video frame using neural ODEs. The method is based on neural implicit representations for appearance modeling with neural ordinary differential equations (ODEs) to obtain interpretable physical models directly from visual observations. The proposed method is able to recover the metric length of the pendulum from the monocular video (relative error to true length is less than 2.5%) and can synthesize high-resolution and photo-realistic imagery. 
SP:51efd1451343f4994d857daa5490e299b812bc2d,"This paper studies the problem of context-dependent reinforcement learning in the setting of Markovian Markov Decision Processes (MDPs) where there are a finite number of not-observable contexts and abrupt (discontinuous) context changes occurring during an episode. The authors propose a context distillation procedure, which identifies and removes spurious contexts in an unsupervised fashion. The proposed method is based on the Hierarchical Dirichlet Process (HDP) prior for model learning, which is arguably best-suited for Markov process modeling. Experiments on autonomous car left turn and drone take-off tasks demonstrate the effectiveness of the proposed method. "
SP:ea167b126212b2092bc1190d7f8376bf7c54a888,"This paper proposes a pretraining framework to train knowledge-based multilingual language models (KMLMs) for knowledge-intensive cross-lingual NLP tasks. The pretrained KMLMs generate synthetic sentences and reasoning-based training data using the Wikidata knowledge graphs. Then based on the intra-and inter-sentence structures of the generated data, the authors design pretraining tasks to facilitate knowledge learning, which allows the language models to not only memorize the factual knowledge but also learn useful logical patterns. The proposed KMLM achieves significant performance improvements on a wide range of tasks, including named entity recognition, factual knowledge retrieval, relation classification, and logic reasoning."
SP:6c11cf29c90f923346372ba6f11452c36e69ad6d,This paper proposes an unsupervised method to learn to act altruistically towards other agents by increasing the number of states that the other agent can reach in its future. The proposed method is based on an agent that learns to increase the choices another agent has by preferring to reach more states. The method is evaluated on three multi-agent environments where another agent's success depends on the altruistic agent’s behaviour. The results show that the proposed method outperforms the baselines.
SP:5dbc54201ba184266c5054f0d2944bd197bc307a,"This paper studies the phenomenon of double descent in neural networks. The authors derive a lower bound for the Hessian of the population loss of a neural network under the assumption that the network is under- or over-parameterized. The lower bound is based on the influence functions of the neural network, and the authors show how the choice of the loss function affects the double descent behavior of the network at the interpolation threshold. They also show that the Hessians of neural networks exhibit double descent behaviour at interpolation thresholds."
SP:b485114712055f39a7afb951dbc3db482ff523fd,"This paper proposes a theoretical framework for deep GCNs based on the graph neural tangent kernel (GNTK) to study the exponential decay of trainability of GCNs in the large-depth setting. Theoretical results show that the GNTK behaves asymptotically in the infinite-width setting, and the authors propose a sampling method to overcome this exponential decay problem. The proposed method, called Critical DropEdge, is a connectivity-aware and graph-adaptive sampling method. Experimental results show the effectiveness of the proposed method. "
SP:25a92b3583afdc6892e59f1e769125d52c8011af,This paper proposes a method to estimate the second derivative of the second-order waveform of a cardiac pulse. The second derivative can be used as an indicator of blood pressure and arterial disease. The method is based on a neural network that estimates the waveform from the first-order dynamics. The authors show that the proposed method is able to estimate left ventricle ejection time (LVET) intervals better than other methods.   
SP:0a88d2fcbdfab3e196bf6b9c75adb1006ab87536,"This paper proposes a symbolic mapping method to help agents learn a compositional and symmetric language in complex settings like dialog games. The proposed method is inspired by the theory that human language evolved from simple tasks to difficult tasks. The authors propose a novel architecture called symbolic mapping as a basic component of the communication system of agent. They find that symbolic mapping learned in simple referential games can notably promote language learning in difficult tasks and explore vocabulary expansion, and show that agents can easily learn to use new symbols when the environment becomes more complex."
SP:89575be04cb33b41d7a0a7b62f9496c2838a1317,"This paper proposes a hierarchical modular approach to learn agents that navigate and manipulate objects in a divide-and-conquer manner for the diverse nature of the entailing tasks. Specifically, the policy operates at three levels of hierarchy. First, it infer a sequence of subgoals to be executed based on language instructions by high-level policy composition controller (PCC), then discriminatively control the agent’s navigation by a master policy by alternating between navigation policy and various independent interaction policies. Finally, the agent infer manipulation actions with the corresponding object masks using the appropriate interaction policy. The proposed agent achieves state-of-the-art performance on the ALFRED benchmark."
SP:e2c8efe00db7baba2368f4f6a37815809b9e235e,"This paper proposes Nuisance-randomized distillation (NURD), a method for training predictive models that perform well regardless of the nuisance-label relationship. The authors define a family of distributions that differ only in the nuisance and label relationship. NURD uses the family to train a model that performs well on every member of the family regardless of nuisance- label relationship in that member. The main contribution of the paper is the introduction of a new family called nuisance-varying family, where the nuisance variable is independent of the label variable. This family is defined as a set of distributions where the label and the nuisance are independent of each other, and the authors show that the representations in this set always perform better than chance, while representations outside of this set may not. The proposed method is evaluated on several tasks including class-conditional Gaussians, labeling colored MNIST images (Arjovsky et al., 2019), detecting waterbirds, and classifying chest X-rays."
SP:c75998b76f4e0510fc719d25959a10fc07db1c40,"This paper proposes OTTER (Optimal TransporT distillation for Efficient Zero-shot Recognition), which uses online entropic optimal transport to find a soft image-text match as labels for contrastive learning. The proposed method is based on pre-trained image and text encoders, pretrained image-to-text models, and pretrained zero-shot models on the Conceptual Captions (CC), (subset of) Wikipedia-based Image Text (Srinivasan et al., 2021), and YFCC 15M datasets, which contain 3M, 5M, and 15M image-caption pairs, respectively. Compared with InfoNCE loss, label smoothing, and knowledge distillation, OTTER consistently outperforms these baselines in zero shot evaluation on Google Open Images (19,958 classes) and multi-labeled ImageNet 10K (10032 classes) from Tencent ML-Images."
SP:e83cd70377542b5d187998e2e4a7ac070f453ed6,"This paper proposes Pix2Seq, a framework for object detection that casts object detection as a language modeling task conditioned on the observed pixel inputs. Object descriptions (e.g., bounding boxes and class labels) are expressed as sequences of discrete tokens, and we train a neural net to perceive the image and generate the desired sequence. The proposed method is task-agnostic and can incorporate task-specific prior knowledge with a sequence augmentation technique, proposed below, that alters both input and target sequences during training. Experiments on the COCO dataset show that the proposed method can achieve competitive results compared to highly customized, well-established approaches."
SP:abc9315f61929cc1c54dfef8ff83d7eac56ec2f2,"This paper proposes a symbolic distillation method for visual reinforcement learning. The proposed method distills the learned policy into a symbolic policy, composed from geometric and numerical symbols and operators. The symbolic policy can be treated as discrete and abstracted representations of the policy network, but are found to be more interpretable, robust and transferable. A policy regression algorithm called RoundTourMix is proposed to distill the symbolic rules as teacher-student. Experiments show that the proposed method achieves comparable or even stronger performance in seven visual RL environments."
SP:04e7e181aeb1244ae1c4837ad416aef93ea3ea32,"This paper proposes a method for image-to-image translation that disentangles the coarse-level object arrangements (posture) and the fine-grained level styling (identity) of the generated image from two exemplar sources. The proposed method is based on StyleGAN2, which is a GAN-based method that uses self-supervision for image generation and image synthesis. The authors propose a VQSN module for the generator for better pose-identity disentanglement and a joint-training scheme for the GANInversion encoder and the generator. Experiments on various datasets show that the proposed method achieves better synthesis image quality and disentangling scores of the proposed model."
SP:e51a7f45493064972585109f203a867e9828eb15,"This paper proposes a multi-layer perceptron (MLP) architecture for extracting information from speech signals. The proposed model splits feature channels into non-overlapped chunks and processes each chunk individually. These chunks are then merged together and further processed to consolidate the output. By setting different numbers of chunks and focusing on different contextual window sizes, speech-MLP learns multiscale local temporal dependency. Experiments on keyword spotting and speech enhancement tasks show that the proposed model can achieve comparable performance with less parameters and inference time."
SP:d708d3886f4abd4552d8ccb2096df7361c803b13,This paper proposes a lower bound on the generalization error of transfer learning algorithms for binary classification problems. The lower bound is based on a notion of distance that can be easily computed on real world data sets. The authors also consider a more general setting where there are more than one source domains for knowledge transfer to the target task and develop new bounds on generalization errors in this setting. The experiments on real image classification and action recognition data sets corroborate the theoretical findings.
SP:f7511ba9ccad03233b34b1bf41bbac7361d20a57,"This paper proposes a probabilistic shape completion method extended to the continuous geometry of large-scale 3D scenes. The local continuous shape is incrementally generated as a sparse voxel embedding, which contains the latent code for each occupied cell. Experiments show that the proposed method outperforms deterministic models even in less ambiguous cases with a small amount of missing data on input scans exhibiting any levels of completeness."
SP:d22d8f074adbe8fb0f25fb8f8d96201b3159bf6b,This paper proposes temporal priors as a non-Markovian generalization of behavioral priors for guiding exploration in reinforcement learning. The authors propose to use a probabilistic mixture of policy and temporal prior to guide off-policy reinforcement learning in unseen downstream tasks. They provide empirical evidence that their approach improves upon strong baselines in long-horizon continuous control tasks under sparse reward settings.
SP:25e06c022ae8b3cbbb8db413d7b534a1a5c92391,"This paper proposes a learning-to-learn method for learning rate scheduling in deep neural networks. The proposed method is based on a graph-network-based scheduling mechanism, where the underlying neural network of the target problem is represented as a directed graph, and a graph message passing network is used to control the learning rate via reinforcement learning. The method is evaluated on image classification and language understanding tasks, and the proposed method achieves better performance than baselines. "
SP:d73cb0471c1770607ad3e4621cfc5f170683dd8e,"This paper proposes a method to decompose a 3D point cloud into a spatial mixture model where each component corresponds to one object. The method is based on the Chamfer Mixture Loss, which is used to train a mixture model on point clouds. The authors also introduce an object-specification scheme that describes each object’s location relative to its local voxel grid cell. The proposed method is evaluated on the task of scene decomposition. "
SP:3c57e921c1bf23e482551ceb71702931a7f07439,"This paper investigates the problem of grounding high-level tasks, expressed in natural language, to a chosen set of actionable steps (i.e. “open fridge”) in an interactive environment. The authors find that if pre-trained LMs are large enough and prompted appropriately, they can effectively decompose high level tasks into low-level plans without any further training. However, the plans produced naively by LLMs often cannot map precisely to admissible actions. To address this issue, the authors propose a procedure that conditions on existing demonstrations and semantically translates the plans to actionable actions. The proposed method substantially improves executability over the LLM baseline in the recent VirtualHome environment."
SP:e0159d1c9df2e657892a3a0c77549df4698d9a1a,"This paper proposes a geometrical interpretation of the Variational Autoencoder (VAE) framework. The authors show that VAEs naturally unveil a Riemannian structure of the learned latent space, and propose a new method to generate samples from the uniform distribution deriving intrinsically from the manifold learned by a VAE. The proposed method is shown to be more robust in the low data regime than the vanilla VAE and can compete with more advanced VAE models on four benchmark datasets."
SP:b4b8e1727f8617894f10f20365cb68de79f0e650,"This paper proposes Transformer with a Mixture of Gaussian Keys (Transformer-MGK), a novel transformer architecture that replaces redundant heads in transformers with a mixture of keys at each head. These mixtures of keys follow a Gaussian mixture model and allow each attention head to focus on different parts of the input sequence efficiently. Compared to the conventional transformer counterpart, the proposed model accelerates training and inference, has fewer parameters, and requires less FLOPs to compute while achieving comparable or better accuracy across tasks."
SP:82731dcce233e748f63382e09b6224a513fe9689,"This paper proposes a new two-dimensional continuous environment for spatial navigation. The authors propose to fuse image and action related signals, allowing reconstruction of the action relating the two successive images, as well as prediction of the new image from its current value and the action. They propose a minimalistic recurrent architecture, called Resetting Path Integrator (RPI), that can easily and reliably be trained to keep track of its position relative to its starting point during a sequence of movements. RPI updates its internal state using the (possibly noisy) self-motion signal, and occasionally resets it when the image signal is present. The proposed architecture is compared to off-the-shelf LSTM networks on identical tasks and consistently shows better performance while also offering more interpretable internal dynamics and higher-quality representations."
SP:1a27c397d1e73def5e724c5c6f25548975ba50fa,"This paper studies the effect of input structure on the success of feature learning in neural networks. In particular, the authors consider the setting where the labels are determined by a set of class relevant patterns and the inputs are generated from these along with some background patterns. They prove that neural networks trained by gradient descent can succeed on these problems. The success relies on the emergence and improvement of effective features, which are learned among exponentially many candidates efficiently by exploiting the data (in particular the structure of the input distribution). In contrast, no linear models on data-independent features of polynomial sizes can learn to as good errors. Furthermore, if the specific input structure is removed, then no polynomials algorithm can learn even weakly. "
SP:8ada73ed7eade9ebdeef376485e849c42575bc5f,This paper studies the robustness of feature extractors to adversarial examples generated by test-time adversaries. The main contribution of this paper is to provide lower bounds on the classifier-agnostic robustness for any classifier trained on top of a fixed feature extractor. The lower bounds depend on the effectiveness of the method used to find collisions between pairs of perturbed examples at deeper layers. The authors provide closed-form expressions for collision finding and propose a bespoke algorithm based on the iterative solution of a convex program that provably finds collisions. The bounds are then used to identify the layers of robustly trained models that contribute the most to a lack of robustness.
SP:874b5fa51924cbcceed490d98a0ea80f74586b32,"This paper proposes a value-based offline reinforcement learning (VEM) method that learns the V-function instead of the Q-function to naturally keep the learning procedure within the offline dataset. The authors propose Expectile V-Learning (EVL), which smoothly interpolates between the optimal value learning and behavior cloning, and introduce implicit planning along offline trajectories to enhance learned V-values and accelerate convergence. Empirical results on the D4RL benchmark show that VEM achieves superior performance in most tasks, particularly in sparse-reward tasks."
SP:34f08d92681504490c2f739b0d08f79f9764b2f5,"This paper proposes a novel adversarial training framework that learns to reweight the loss associated with individual training samples based on a notion of class-conditioned margin, with the goal of improving robust generalization. Inspired by MAML-based approaches, the authors formulate weighted adversarial learning as a bilevel optimization problem where the upper-level task corresponds to learning a robust classifier, and the lower-level tasks corresponds to learn a parametric function that maps from a sample’s multi-class margin to an importance weight. Extensive experiments demonstrate that the proposed method improves clean and robust accuracy compared to related techniques and state-of-the-art baselines."
SP:3ad36be6b6900aabe43da043461cf178ce977082,"This paper proposes a method for equivariant graph neural networks (SEGNNs) that incorporate geometric and physical information in both the message and update functions. Specifically, the authors define steerable node attributes (e.g., position, force, velocity, spin, etc.) and introduce steerable MLPs, which provide a new class of activation functions for general use with steerable feature fields. Experiments on several tasks in computational physics and chemistry demonstrate the effectiveness of the proposed method."
SP:8928aa83f7ebd4e310f4fe1d01ff0eb0c96e4d2b,"This paper proposes a new differentiable physics model for differentiable fabrics for composite materials such as cloths. The authors propose several differentiable forces, whose counterparts in empirical physics are indifferentiable, to facilitate gradient-based learning. The experiments show that the proposed model is more explicable, has higher data efficiency, generates more accurate predictions and is fast in control learning."
SP:2c8358c095b10981d3015b9f6c75765419a9480d,"This paper proposes a method for transfer learning based on logical composition in reinforcement learning. In particular, the proposed method allows an agent to determine whether a new task with possibly many desirable goals can be immediately solved using its existing abilities, or whether a task-specific skill should be learned. The proposed method also enables the agent to learn the new task faster by generating an estimate of the optimal policy. The authors provide bounds on the performance of the transferred policy on new task, and the necessary and sufficient number of tasks that need to be learned throughout an agent’s lifetime to generalise over a distribution. "
SP:c85d71d05164d019cc32bf423e4c4fe20c169f41,"This paper proposes a distributed solution for multivariate time series classification (MTSC) based on a wavelet scattering transformation of the time series and distributed feature selection. The proposed method, called LightWaveS, employs just 2,5% of the ROCKET features, while achieving accuracy comparable to recent deep learning solutions. The method also scales well with more nodes and large numbers of channels. In addition, it can significantly reduce the input size and provide insight to an MTSC problem by keeping only the most useful channels."
SP:db43614ca016280a79448f44a97c81c8ff5ba981,"This paper presents a pretraining method for text encoders with adversarial learning curriculum via a Mixture Of Signals from multiple auxiliary generators. The main encoder is trained as a discriminator to detect replaced tokens generated by auxiliary masked language models (MLMs). Different from ELECTRA which trains one MLM as the generator, this paper jointly trains multiple MLMs of different sizes to provide training signals at various levels of difficulty. The discriminator is trained with mixture weights over the auxiliary MLMs’ outputs to maximize the discriminator loss by backpropagating the gradient from the discriminators via Gumbel-Softmax."
SP:db3825633ab5d0671340390b23ab655838cc38b2,"This paper proposes an adaptive fine-tuning method for relational fact extraction from a pre-trained language model on the standard fill-mask task using a small training dataset of existing facts from a knowledge graph. The authors show that the proposed method outperforms all baselines, even by using significantly fewer training facts. They also analyze the transfer learning capabilities of this adapted language model by training on a restricted set of relations to show that even fewer training relations are needed to achieve high knowledge extraction quality."
SP:ae25d32714b2b9f7e02cc20f4a36252e20e78e4f,"This paper proposes to learn knowledge base embeddings in different geometric spaces and apply manifold alignment to align the shared entities. The hyperbolic space characterizes the transitivity naturally because of its tree-like properties. The proposed method is evaluated on the out-of-taxonomy entity typing task, where the authors aim to predict the types of the entities from the knowledge graph. Experimental results on two datasets based on YAGO3 demonstrate that the proposed method has significantly good performances."
SP:9ab3bc525ee4a9c96518c43e4c43082655a7674f,"This paper proposes a one-shot learning framework for link prediction in temporal knowledge graphs. The proposed method employs a self-attention mechanism to effectively encode temporal interactions between entities, and a network to compute a similarity score between a given query and a (one-shot example) example. The experiments show that the proposed algorithm outperforms the state of the art baselines for two well-studied benchmarks while achieving significantly better performance for sparse relations."
SP:91f92a40e12afd0702f07ae7f4175ecce57b7007,"This paper proposes a method to learn visual reasoning tasks by learning a sequence of neural modules. Each module represents a solver for each task as a neural module that calls existing modules (solvers for simpler tasks) in a functional program-like manner. Lower modules are a black box to the calling module, and communicate only via a query and an output. A module for a new task learns to query existing modules and composes their outputs in order to produce its own output. The proposed method is tested on a set of visual reasoning task and shows improved performance in all tasks by progressively learning progressively."
SP:de33b02e7f2faec5bcae9a5516721aa1ef190572,"This paper proposes a method to improve the performance of deep convolutional neural networks (DNNs) by pruning unimportant channels and rewiring the pruned parameters to important channels during training. The proposed method is based on the idea of channel-selectivity, i.e., redistributing the computations of important channels to the important channels. To achieve this, the authors propose the Selective Convolutional Unit (SCU), a widely-applicable architectural unit that improves parameter efficiency of various modern CNNs with bottlenecks. During training, SCU gradually learns the channel selectivity on-the-fly via the alternative usage of (a) pruning the unimportant channel, and (b) reweighing the parameters to the most important channel. The experimental results demonstrate that the SCU-based models without any postprocessing generally achieve both model compression and accuracy improvement compared to the baselines, consistently for all tested architectures."
SP:2d80fa4bc440061be2234b5070503d3fa056baed,"This paper studies the problem of learning a binary classifier only from positive data and unlabeled data (PU learning). The authors propose a method to partially identify the classifier. The proposed algorithm learns a scoring function that preserves the order induced by the class posterior under mild assumptions, which can be used as a classifier by setting an appropriate threshold. The experiments show that the proposed method outperforms previous methods for PU learning on various real-world datasets."
SP:5f312626b0613d2e07c59214c5f00db208a98717,"This paper proposes to use cosine similarity between gradients of tasks as an adaptive weight to detect when an auxiliary loss is helpful to the main loss. The authors show that their approach is guaranteed to converge to critical points of the main task and demonstrate the practical usefulness of the proposed algorithm in a few domains: multi-task supervised learning on subsets of ImageNet, reinforcement learning on gridworld and Atari games."
SP:e270ae3eeb7ab4fa91ba37d4d68ce10f2fa0a3b5,"This paper proposes a geometric framework to analyze the high-dimensional geometry of adversarial examples. The proposed framework is based on the manifold reconstruction literature. The authors highlight the importance of codimension for low-dimensional data manifolds embedded in high dimensional space. They show that the choice of norm to restrict an adversary is important in that there exists a tradeoff between being robust to different norms. They also show that adversarial training in balls around the data is sample inefficient, and that nearest neighbor classifiers and ball-based adversarial learning are robust. "
SP:e07d948a79d478ecd23a0a4406d4ddd3ac5e3be3,"This paper proposes a new representation learning method for time series data. The proposed method is based on discrete dimensionality reduction and deep generative modeling. The authors propose a gradient-based method to overcome the non-differentiability in discrete representation learning. They also integrate a Markov model in the representation space, which improves clustering performance and provides additional explanatory insights. "
SP:5915ee71ea58dbdbafa31c1ad291d1e5940a0cf4,"This paper studies the properties of multidimensional probability distributions in the context of latent space prior distributions of implicit generative models. The authors show that the distribution mismatch can be eliminated completely by the proper choice of the latent probability distribution or using non-linear interpolations. They also show that there is a trade-off between the interpolation being linear, and the latent distribution having even the most basic properties required for stable training, such as finite mean. "
SP:19b63ca635712f1509ca6e0141303c192f2709e0,"This paper proposes a method to learn the parameters of deep neural networks in hyperbolic space. The proposed method is motivated by the observation that the number of objects can grow exponentially for any semantic distance from the query. The authors propose to impose hyper-bolic geometry on the embeddings used to compute the ubiquitous attention mechanisms for different neural networks architectures. By only changing the geometry of embedding of object representations, the proposed method can use the embedding space more efficiently. The method shows improvements in generalization on neural machine translation on WMT'14 (English to German), learning on graphs (both on synthetic and real-world graph tasks) and visual question answering (CLEVR) tasks while keeping the neural representations compact."
SP:f6049e9f80a63c9306c1cebcb6b229aa6da44ddc,"This paper studies the problem of deep neural network (DNN) fingerprinting attacks that exploit cache side-channels. The authors define the threat model for these attacks: the adversary runs a co-located process on the host machine where the victim’s deep learning (DL) system is running and passively monitors the accesses of the target functions in the shared framework. They introduce DeepRecon, an attack that reconstructs the architecture of the victim network using the internal information extracted via Flush+Reload, a cache side channel technique. Based on the extracted architecture attributes, they also demonstrate that an attacker can build a meta-model that accurately fingerprints the architecture and family of the pretrained model in a transfer learning setting. Finally, they propose and evaluate new framework-level defense techniques that obfuscate our attacker's observations."
SP:6a3dd89db6c24a1f98e8866ef0a4c1c2c1ec6635,"This paper proposes a hierarchical network model for long-range video prediction. The model is inspired by the feedforward, feedback and lateral recurrent circuits in the mammalian hierarchical visual system. It assumes that spatiotemporal memories are encoded in the recurrent connections within each level and between different levels of the hierarchy. The network processes data in blocks of video frames rather than a frame-to-frame basis. This allows it to learn relationships among movement patterns, yielding state-of-the-art performance in long range video sequence predictions in benchmark datasets. The authors also provide neurophysiological evidence, showing that neurons in the early visual cortex of awake monkeys exhibit very similar sensitivity and behaviors."
SP:fb74e57f35666742caf651e6da33b5defcf259a8,"This paper proposes a method to compute continuous embeddings from raw RNA-seq data, in a reference-free fashion. The authors report that their model captures information of both DNA sequence similarity as well as DNA sequence abundance in the embedding latent space. They confirm the quality of these vectors by comparing them to known gene sub-structures and report that the latent space recovers exon information from raw R-Seq data from acute myeloid leukemia patients."
SP:03aca6ff6a7f0ad2d5ccbcb15ed9536e305a9880,"This paper proposes a method for model compression that operates on the architecture space, where the encoder/decoder is trained to learn a mapping from discrete architecture space to a continuous embedding and back. During the compression phase, they first encode the network and then perform gradient descent in continuous space to optimize a compression objective function that maximizes accuracy and minimizes parameter count. The final continuous feature is then mapped to a discrete architecture using the decoder. They demonstrate the effectiveness of their approach on several visual learning tasks and show 5-20x compression on architectures."
SP:0511b5d10a90e3fe814e2d35208b4a987894ea62,"This paper proposes a framework for planning online and learning offline, where an agent with an internal model needs to continually act and learn in the world. The proposed framework builds on the synergistic relationship between local model-based control, global value function learning, and exploration. The authors show that local trajectory optimization can cope with approximation errors in the value function, and can stabilize and accelerate global learning. They also show how approximate value functions can help reduce the planning horizon and allow for better policies beyond local solutions. Finally, trajectory optimization is used to perform temporally coordinated exploration in conjunction with estimating uncertainty in value function approximation. "
SP:771494fda4702cd8c7efbf225b19028f91b449b9,"This paper proposes a zero-shot dual neural machine translation method for low-resource languages. The proposed method is based on reinforcement learning, where the model is trained on monolingual data for the target language pair. The method is evaluated on the UN corpus on English-French and English-Spanish. The results show that the proposed method outperforms the LSTM-based and Transformers-based unsupervised NMT systems."
SP:1558dc03f99670f9ddccdca9c223a2baf962d438,"This paper studies the problem of estimating the conditional probability distribution p(d|q) over the documents (d,q) given the query (q). The authors propose a generative adversarial network (GAN) based on the framework for Information-Retrieval (IR) to solve this problem. The authors point out inaccuracies in the minimax loss function used in IRGANs and propose a co-training method to improve the performance of the proposed GAN. "
SP:6a13dda852ab075a3c0fb691476d6dc57919c729,This paper proposes a method to model sparsity in the latent space of a variational auto-encoder (VAE) with a Spike and Slab prior distribution. The proposed method is based on combining ideas from sparse coding and sparse coding. The authors derive the evidence lower bound using a discrete mixture recognition function to make approximate posterior inference as computational efficient as in the standard VAE case. The method is able to infer truly sparse representations with generally intractable non-linear probabilistic models on two benchmark classification tasks (MNIST and Fashion-MNIST) by demonstrating improved classification accuracy and significantly increased robustness to the number of latent dimensions.
SP:06a22143186fa2948fbe324ccae96a62ff12064e,"This paper proposes a non-adversarial feature matching-based approach to train generative models. The proposed method, Generative Feature Matching Networks (GFMN), leverages pretrained neural networks such as autoencoders and ConvNet classifiers to perform feature extraction. The experimental results demonstrate that, due to the expressiveness of the features from pretrained ImageNet classifier, even by just matching first order statistics, our approach can achieve state-of-the-art results for challenging benchmarks such as CIFAR10 and STL10."
SP:2d7cf2f07a27d6c8e304a1b47c25387ad2e4432d,"This paper studies the expressive power of graph neural networks (GNNs) for graph classification and node classification tasks. In particular, the authors propose a theoretical framework for analyzing the expressivity of GNNs to capture different graph structures. They show that the discriminative power of popular GNN variants, such as Graph Convolutional Networks (GCN) and GraphSAGE, cannot learn to distinguish certain simple graph structures, and then develop a simple architecture that is provably the most expressive among the class of Graph Neural Networks and is as powerful as the WeisfeilerLehman graph isomorphism test. They empirically validate their theoretical findings on a number of graph classification benchmarks, and demonstrate that the proposed model achieves state-of-the-art performance."
SP:51126f2dd37ce57d2614c9044ede1e43627f0829,This paper proposes a framework for interpretable continual learning (ICL) based on the variational continual learning framework. The main idea of ICL is to generate a saliency map of a task and use it to guide the attention of the learner during the next task. The saliency maps are then used to generate explanations of previously performed tasks and a new metric is proposed to assess the quality of the explanations. Experiments on three datasets show that ICL achieves state-of-the-art results in terms of overall continual learning performance and explanations.
SP:27a565b3e5442b93d208652784051e640b0c1bfe,"This paper proposes a new evaluation framework for adversarial attacks on neural sequence-to-sequence (seq2seq) models taking meaning preservation into account and demonstrate that existing methods may not preserve meaning in general. Based on these findings, the authors propose new constraints for attacks on word-based MT systems and show, via human and automatic evaluation, that they produce more semantically similar adversarial inputs. The experiments are designed to answer several questions about meaning preservation in seq2seq models."
SP:54ddd8132bf9e4259d2c2d72b348d2bb5f9e227c,"This paper proposes a method to improve the performance of reinforcement learning algorithms by combining the policies using original rewards and inverse (negative) rewards. The proposed method is based on deep Q-learning, double-Q learning, and on-policy actor-critic. The authors show that the proposed method can achieve better performance than the original policies and is more stable than the existing methods. The paper also provides a convergence analysis for the proposed methods."
SP:89a732b57934d08b937c93560f391b7758e54f8a,"This paper proposes a method to learn a hierarchical, disentangled object representation and a dynamics model for object parts from unlabeled videos. The method is based on a layered image representation, a structural descriptor that composes low-level concepts into a hierarchical structure, and predicts the system dynamics by predicting the future. Experiments on multiple real and synthetic datasets demonstrate that the proposed method works well on all three tasks: segmenting object parts, building their hierarchical structure and capturing their motion distributions. "
SP:bb2a655d67bed9da43f0b8ec7d888b89c217d12e,This paper proposes Deep Determinantal Generative Classifier (DDGC) to improve the classification performance of deep neural networks trained on noisy datasets. The main idea of DDGC is to estimate the parameters of the generative classifier using the minimum covariance determinant estimator (MCDE) and then use it to train a generative model on top of the discriminative deep model. Experiments on CIFAR-10 and SVHN datasets show that DDGC can improve the performance of DenseNet and ResNet trained on the noisy dataset. The proposed method is also shown to be robust against adversarial perturbations. 
SP:0fa525cc708470b757a60117cb608bb2feaa2c50,This paper proposes a model-free method for subgoal discovery in hierarchical reinforcement learning (HRL) with sparse delayed feedback. The method is based on incremental unsupervised learning over a small memory of the agent's most recent experiences in the environment. The authors propose an intrinsic motivation learning mechanism to learn subgoals and skills together. The proposed method is evaluated on two tasks: a variant of the rooms environment and a classic ATARI 2600 game. 
SP:e5861538bc8bb9165cb33299bbf12dd875abf976,"This paper proposes a neural framework for learning to solve the Circuit Satisfiability problem. The proposed method is based on a rich embedding architecture that encodes the problem structure, and an end-to-end differentiable training procedure that mimics Reinforcement Learning and trains the model directly toward solving the SAT problem. Experimental results show the superior performance of the proposed method compared to the recently developed NeuroSAT method."
SP:ff3e5d44619df3825632b0b1a943add081364861,"This paper proposes to combine the cross-entropy method (CEM) with DDPG or TD3, an off-policy deep RL algorithm, to improve sample efficiency in deep RL. CEM-RL is a combination of CEM and TD3. The authors evaluate the proposed method on a set of benchmarks for deep RL and show that it outperforms the existing methods in terms of sample efficiency."
SP:78b2eb326695da0b0cc4ba39a9206d11644a5e32,This paper proposes a multi-variable LSTM recurrent neural network (IMV-LSTM) model for multi-variate time series forecasting. The proposed model is equipped with hidden state matrix and update process to learn variables-wise hidden states and a mixture attention mechanism to quantify the temporal and variable importance in data. Extensive experiments using real datasets demonstrate the prediction performance and interpretability of the proposed model. 
SP:1c26660569b579f060f7b4a31e321c6d2356b928,"This paper proposes feature smoothing, a data augmentation method that trains a neural network on virtual training data as an interpolation of features from a pair of samples, with the new label remaining the same as the dominant data point. The intuition is to generate virtual data points as close as adversarial examples, and to avoid the computational burden of generating data during training. The experiments on MNIST and CIFAR10 datasets explore different combinations of known regularization and data augmentation methods and show that the proposed method with logit squeezing performs best for both adversarial and clean accuracy. "
SP:88d652f9e411dd3a2e9ad651d9011e579653c6aa,"This paper proposes a theoretical framework for deep convolutional neural networks with ReLU nonlinearity. The framework is built upon teacher-student setting, by projecting the student's forward/backward pass onto the teacher's computational graph. The proposed framework bridges data distribution with gradient descent rules, favors disentangled representations and is compatible with common regularization techniques such as Batch Norm. "
SP:7842bbe0e2324cfd732db8745550733ccc3dfcdc,"This paper proposes a modular architecture of neural networks with a Behavioral Module (BM) and corresponding end-to-end training strategy. This approach allows efficient learning of behaviors and preferences representation, which is particularly useful for user modeling (as for dialog agents) and recommendation tasks, as allows learning personalized representations of different user states. The experiments show that the proposed method allows separation of main task’s objectives and behaviors between different BMs. Moreover, the experiments also show network extendability through independent learning of new behavior patterns."
SP:300c391ff644b6889cd9ae27cf0d162dfcdd4451,This paper proposes a differentiable formulation for the neuromodulation of plasticity that can be used to train neural networks with gradient descent. This formulation is based on the differentiable Hebbian plasticity framework. The paper shows that this formulation improves the performance of neural networks on both reinforcement learning and supervised learning tasks. The experimental results show that the proposed method outperforms non-plastic and non-modulated plastic networks.
SP:1ab5d94d31e99351433436c026799c8aa597bf73,"This paper proposes a non-intrusive quantization technique to reduce the inference latency/memory consumption of deep neural networks. The proposed method is based on re-training the full precision model, followed by directly optimizing the corresponding binary model. The quantization training process takes no longer than the original training process. The authors also propose a new loss function to regularize the weights, resulting in reduced quantization error. Combining both help them achieve full precision accuracy on CIFAR dataset using binary quantization. They also achieve full accuracy on WikiText-2 using 2-bit quantization, and achieve performance comparable to ImageNet."
SP:0876b1d9a6d664808ca1ab15865679fbf638267e,"This paper proposes a method for open-ended recombination of style and content from one image with the content of another. The method is based on a VAE-based style encoder paired with a content encoder. The VAE reconstruction loss alone is inadequate to ensure a decomposition of the latent representation into style-content representation and content-style representation. An auxiliary loss, leakage filtering, is proposed to ensure that no style information remaining in the content representation is used for reconstruction and vice versa. The proposed method achieves state-of-the-art performance on few-shot learning tasks."
SP:d37e15cde7765fca87595a242f0a4511b3346d46,"This paper proposes a method to speed up deep RL training for problems that have the property of state-action permissibility (SAP). Two types of SAP are defined: (1) after an action at is performed in a state st and the agent reaches the new state st+1, the agent can decide whether the action at at is permissible or not permissible in state st; (2) even without performing the action in st, an agent can already decide whether at is permitted or not in st. The authors incorporate the proposed SAP property into two state-of-the-art deep RL algorithms to guide the agent to decide whether an action is permissible in st or not. They also propose a novel approach to using the SAP property, i.e., building a binary predictive model to predict if an action in state is permissible ahead of time. Experimental results show that the proposed approach can result in a huge speedup in RL training."
SP:20015d8b60e13300586b67c281858cbe28825c48,"This paper studies the behavior of weight-tied multilayer vanilla autoencoders under the assumption of random weights. The analysis reveals interesting phase transition phenomena when the depth becomes large. This provides quantitative answers and insights to three questions that were yet fully understood in the literature. The paper also provides insights on pitfalls in training initialization practice, and demonstrates experimentally that it is possible to train a deep autoencoder without resorting to pre-training or batch normalization."
SP:91764f80dbe2401ade38b35a8253ba05f0f86386,This paper proposes a simple black-box adversarial image attack algorithm based on the discrete cosine transform (DCT) algorithm. The key idea is to randomly pick a low frequency component of the DCT and either add or subtract it to the target image. The proposed algorithm can be used for both targeted and untargeted attacks. The authors show that the proposed algorithm is query efficient in both settings. 
SP:fc20ae0fbf57a1ce489c04b85c7c2f4c93dc2450,"This paper proposes a new method for option discovery in Hierarchical Reinforcement Learning (HRL) based on the idea of ""landmark sub-goals"" which are prototypical states of well connected regions. The authors propose a new model called Successor options that leverages Successor representations to achieve the same. They also design a novel pseudo-reward for learning the intra-option policies and describe an incremental approach that alternates between exploration and option construction to navigate the state space in tasks with a fixed horizon setup where primitive actions fail to explore fully."
SP:12a172c1e2892d016b37932acfc48dcb56874a89,"This paper studies the problem of domain division, which aims to segment instances drawn from different probabilistic distributions. In particular, the authors propose a domain division algorithm to split the testing instances into known, unknown and uncertain domains, and then conduct recognition tasks in each domain. Two statistical tools, namely, bootstrapping and Kolmogorov-smirnov (K-S) Test, are introduced to uncover and fine-tune the decision boundary of each domain for the first time. Extensive experiments demonstrate that the proposed algorithm achieves the state-of-the-art performance on OSL and G-ZSL benchmarks."
SP:28bcf7c6a4673e9ec2b4ebed09839d85188e0b2a,"This paper proposes a neural network for classification and regression tasks that explicitly states the layout structures in the output space, i.e., the layout, of the output. The structure is defined by polar prototypes, points on the hypersphere of output space. For classification, each class is described by a single polar prototype and they are a priori distributed with maximal separation and equal shares. For regression, they show that training can be performed as a polar interpolation between two prototypes, arriving at a regression with higher-dimensional outputs. "
SP:d1034342785d133cf8372b8624897963cc2ee83a,This paper proposes a reward learning algorithm based on Maximum Causal Entropy IRL (MCE) that uses the initial state of the world at initialization as a source of information about human preferences to learn implicit preferences. The algorithm is evaluated on a suite of proof-of-concept environments designed to show the properties of the MCE algorithm. The results show that the RLSP algorithm can be used to infer both side effects that should be avoided as well as preferences for how the environment should be organized.
SP:417a4e0acee699b3e004ad30d0ecf533a9ed987e,"This paper proposes a method for learning the dependency structure between latent variables in deep latent variable models. The proposed method combines the complementary strengths of deep generative models and probabilistic graphical models. Inference is formulated via a sampling procedure that produces expectations over latent variables structures and incorporates top-down and bottom-up reasoning over latent variable values. Experiments on MNIST, Omniglot, and CIFAR-10 show that the proposed method outperforms several predefined latent dependency structures."
SP:976dedab53e69610692a563382ada1dbb82c1e9d,"This paper proposes a dynamical network for solving the dictionary learning problem. The proposed method is based on top-down feedback and contrastive learning. The authors show that the proposed method can be used to solve the problem of 1-minimizing dictionary learning, and the true gradients for learning are provably computable by individual neurons. They also show the difference in states after a long enough evolution, called limiting states in short, is shown to hold gradient information of a dictionary learning objective function which the network minimizes, as well as gradient information for the network to maintain weight dependency."
SP:f45117a6beaeb86a70b1380b4fac3cfba37fb892,This paper proposes an encoder-decoder network for semantic image segmentation and lane detection task. The proposed method is based on a single spatial pyramid structure and uses multiple encoder and decoder modules in end-to-end ways. The experimental results show that the proposed method achieves better results than existing methods. 
SP:68b0a10ca06df74612d0753cc3f3ddddde806035,"This paper proposes a new method for batch contextual bandit learning from logged bandit feedback. The proposed method, Maximum Likelihood Inverse Propensity Scoring (MLIPS), estimates a maximum likelihood surrogate policy based on the logged action-context pairs, and then uses this surrogate policy as the proposal distribution in the off-policy estimator to obtain the inverse propensity weights in the estimator. The authors prove that MLIPS is asymptotically unbiased, and moreover, has a smaller nonasymptotic mean squared error than IPS estimator, which is somewhat surprising as the estimated surrogate policy is less accurate than the given historical policy. Experiments on multi-label classification problems and a large-scale ad placement dataset demonstrate the empirical effectiveness of MLIPS. "
SP:8e0ed65c5dded23b34798499b2436b24422fd729,"This paper proposes a meta-learning method for few-shot image classification. The authors propose to learn how to create an individualized feature embedding specific to a given query image for better classifying. Specifically, they introduce a kernel generator as meta-learner to learn to construct feature embeddings for query images. The kernel generator acquires meta-knowledge of generating adequate convolutional kernels for different query images during training, which can generalize to unseen categories without fine-tuning. The proposed method achieves competitive performance on two standard few shot classification data sets."
SP:faa3f7ffdcfb6e3b8ec0421193dae3d9987b015c,"This paper proposes a non-gradient-based evolutionary algorithm for deep neural networks (DNNs). The proposed algorithm is based on population-based genetic algorithm (GA). The authors show that the proposed algorithm can evolve the weights of a DNN with a simple, gradient-free, population based genetic algorithm and it performs well on hard deep RL problems, including Atari and humanoid locomotion. The authors also demonstrate that combining DNNs with novelty search, which encourages exploration on tasks with deceptive or sparse reward functions, can solve a high-dimensional problem on which reward-maximizing algorithms (e.g., DQN, A3C, ES, and the GA) fail."
SP:dfdbe3267a8160f24746884cdf5297993e424231,"This paper proposes a new curiosity method for reinforcement learning that uses episodic memory to form the novelty bonus. To determine the bonus, the current observation is compared with the observations in memory. Crucially, the comparison is done based on how many environment steps it takes to reach current observation from those in memory — which incorporates rich information about environment dynamics. This allows us to overcome the known “couch-potato” issues of prior work — when the agent finds a way to instantly gratify itself by exploiting actions which lead to hardly predictable consequences. The proposed method outperforms the state-of-the-art curiosity method ICM in VizDoom, DMLab, and MuJoCo."
SP:1e58a1c5344d1b5b7c8a40210a243700bd933d65,"This paper proposes a method to learn sparse relational rules for describing transition models in uncertain domains using relational rules. For any action, a rule selects a set of relevant objects and computes a distribution over properties of just those objects in the resulting state given their properties in the previous state. An iterative greedy algorithm is used to construct deictic references that determine which objects are relevant in any given state. Feed-forward neural networks are used to learn the transition distribution on the relevant objects’ properties. This strategy is demonstrated to be more versatile and more sample efficient than learning a monolithic transition model in a simulated domain in which a robot pushes stacks of objects on a cluttered table."
SP:8ce00a3fedbf54a7f2c1ff414511cbb7d59b4597,"This paper proposes a novel instance-wise feature selection method called INVASE. The proposed method consists of 3 neural networks, a selector network, a predictor network, and a baseline network, which are used to train the selector network using the actor-critic methodology. Using this methodology, INVASE is capable of flexibly discovering feature subsets of a different size for each instance, which is a key limitation of existing state-of-the-art methods. Experiments on synthetic and real-word data show that INVASE significantly outperforms other state of the art methods."
SP:b91d6c33349df0bb6cb7e1c5e9433f0d4744b4da,"This paper proposes a domain adaptation method for semantic segmentation. The authors propose to learn discriminative feature representations of patches based on label histograms in the source domain, through the construction of a disentangled space, and then use an adversarial learning scheme to push the feature representations in target patches to the closer distributions in source ones. Extensive ablation studies and experiments are conducted on numerous benchmark datasets with various settings, such as synthetic-to-real and cross-city scenarios. The proposed method achieves state-of-the-art performance on semantic segmentations."
SP:00922af13a21464cbc4cd7b34c196dd4f86c9247,"This paper proposes two optimistic algorithms for online learning algorithms for AMSGrad and Adam. The algorithms are based on the observation that mini-batch of stochastic gradients in consecutive iterations do not change drastically and consequently may be predictable. The authors combine the idea of momentum method, adaptive gradient method, and algorithms in OPTIMISTIC ONLINE LEARNING, which leads to speed up in training deep neural nets in practice. Experiments show that the proposed algorithms are faster than the baselines."
SP:52228b48f2776d57dd422edb33b82e247f056b75,This paper introduces a new benchmark for image classifier robustness. The benchmark is based on image classifiers trained with adversarial perturbation and corruption perturbations. The authors also introduce a new dataset called IMAGENET-P to evaluate the robustness of classifiers to common perturbed images. They show that there are negligible changes in relative corruption robustness from AlexNet classifier to ResNet classifiers. They also show that a bypassed adversarial defense can improve robustness to adversarial examples. 
SP:20358ea0f769e6ea9222d8e35159d711ee1b20b2,"This paper shows that dropout training can be understood as performing MAP estimation concurrently for an entire family of conditional models whose objectives are lower bounded by the dropout objective. This discovery allows them to pick any model from this family after training, which leads to a substantial improvement on regularisation-heavy language modelling. The family includes models that compute a power mean over the sampled dropout masks, and their less stochastic subvariants with tighter and higher lower bounds than the fully stochastically dropout objectives. The deterministic subvariant’s bound is equal to its objective, and the highest amongst these models. It also exhibits the best model fit in the experiments."
SP:ac1b950ad29429ae045bb5e53279014a6a0b9d2b,"This paper proposes a global soft filter pruning (GSFP) method to prune redundant filters of convolutional neural networks (CNNs). The proposed method is based on cumulative saliency based soft pruning, which measures the global redundancy of the filter in the whole model by using the soft-pruning strategy. In addition, in the model recovery process, the proposed method uses the cumulative-saliency strategy to improve the accuracy of pruning. The experimental results show that GSFP is effective on many classic CNN architectures and different data sets. "
SP:621e41d4199e333ec7f9d0936d4e34c918f39c11,"This paper proposes a cross-lingual document classification framework (CACO) between related language pairs. CACO jointly trains a character-based embedder and a word-based classifier. The embedder derives vector representations for input words from their written forms, and the classifier makes predictions based on the word vectors. Experiments on CLDC show the effectiveness of the proposed method."
SP:544e421f9c747640d949f433e3091763508b7237,This paper proposes a method for weakly-supervised temporal action localization. The authors propose a marginalized average attentional network (MAAN) to suppress the dominant response of the most salient regions in a principled manner. The MAAN employs a novel marginalized average aggregation (MAA) module and learns a set of latent discriminative probabilities in an end-to-end fashion. Extensive experiments on THUMOS14 and ActivityNet1.3 show that the proposed method achieves a superior performance on the task of weakly supervised video localization. 
SP:9f98c9bac99003741dd14e093b54d692c0b0e8d8,"This paper proposes a method to use Holographic Reduced Representation (HRR) to construct word-level and chunk-level representations for natural language processing (NLP) tasks. The proposed method is based on the VSA framework, where the word and chunk embeddings are reduced to a single image. The authors show that the proposed method can be used as a compositional representation for both word level and chunk level representations, and that it is able to discover crude linguistic roles, which roughly resembles a classic division between syntax and semantics."
SP:5908b6acfed0e7c51e203c72eba907e6635e6c60,This paper proposes a method for learning a POMDP model with a greedy strategy for observation selection that aims to minimize the uncertainty in state. The proposed method is based on a point-based value iteration algorithm that incorporates the greedy strategy to achieve near-optimal uncertainty reduction for sampled belief points. The method is evaluated on a range of robotic scenarios where the robot simultaneously performs active perception and planning. 
SP:0adec4abec17b3aab0c6eb69d11925dc20544950,"This paper proposes a curriculum loss for training deep neural networks. The main idea is to train the network on ""good"" samples to reduce large shifting, and encourage ""bad samples"" to learn from ""good samples"". The proposed curriculum loss consists of two parts: a) an adaptive weight that mitigates large early punishment; b) an additional representation loss for low-weighted samples. Experiments on MNIST, Cifar-10, and CIFAR-100 show that the proposed method can improve the performance of the network."
SP:8b555b9f24044bc68c204169d6a37e262361d706,"This paper presents a method to learn heuristics for combinatorial optimization problems. The authors propose a model based on attention layers with benefits over the Pointer Network and train this model using REINFORCE with a simple baseline based on a deterministic greedy rollout, which they find is more efficient than using a value function. The proposed method is tested on the Travelling Salesman Problem (TSP), the Vehicle Routing Problem (VRP), the Orienteering Problem (OP) and the Prize Collecting TSP (PCTSP), outperforming a wide range of baselines and getting results close to highly optimized and specialized algorithms."
SP:efb76bcf1dbd9a9cf6b5db74b5d4256a9f9e9e73,"This paper proposes a neural architecture search (DNAS) method for quantizing different layers of neural networks with different bit-widths. The main idea is to construct a super-net, where the number of layers, filter size of each layer, etc., is the same as the target network, but the size of the super net is differentiable. The proposed method is based on gradient-based optimization. Experiments on CIFAR-10 and ImageNet show that the proposed method outperforms the state-of-the-art compression of ResNet on ImageNet."
SP:ea4173f8265bc50296de51c4ee7ecb6b8f78bec0,This paper proposes a new attention model based on posterior attention. The proposed posterior attention model is based on the joint distribution of the attention and output variables. The posterior attention distribution is conditioned on the output of the decoding stage. The authors show that the posterior distribution is much lower than the entropy of the soft-attention model. The running time overhead of posterior attention is only 40% over existing soft attention models. 
SP:987e2c14abc091d4d3ef9b48fb2046408eb1f59e,"This paper proposes a new method for image-to-image translation, called HarmonicGAN. The proposed method is based on the idea of using a smoothness term over the sample graph to enforce consistent mappings between the source and the target domains. The method is evaluated on a variety of tasks, including medical imaging, object transfiguration, semantic labeling, and semantic labeling. "
SP:885a69003bad0e79cb2872a4e5c772191ad7e34f,"This paper studies the exploding and vanishing gradient problem (EVGP) in recurrent neural networks (LSTMs) and proposes a simple stochastic algorithm (h-detach) to address this problem. The authors show that when the LSTM weights are large, the gradient components through the linear path (cell state) in the computational graph get suppressed. Based on the hypothesis that these components carry information about long term dependencies (which the authors show empirically), their suppression can prevent LSTMs from capturing them. "
SP:9aaff3777321347d1194884af5690b0b5185eff9,"This paper proposes SnapQuant, a method for training real binary weight networks without layer-wise or filter-wise scaling factors from scratch under the Bayesian deep learning perspective. The posterior distribution is parameterized as a policy network trained with a reinforcement learning scheme. During the training phase, the binary weights are generated on-the-fly since what we actually maintain is the policy network, and all the binary weight are used in a burn-after-reading style. At the testing phase, we can sample binary weight instances for a given recognition architecture from the learnt policy network. The performance of SnapQuant is evaluated with several visual recognition tasks including ImageNet."
SP:29d1f6d0661a51e56c59bbb106da56700fc22d9a,"This paper proposes a Bayesian nonparametric framework for federated learning with neural networks. Each data server is assumed to train local neural network weights, which are modeled through the framework. An inference approach is developed to synthesize a more expressive global network without additional supervision or data pooling. Experiments are conducted on two popular image classification datasets."
SP:ab1f2bd216635d63450688866c729a501bd7e9d0,"This paper studies the problem of learning in differentiable games, where the goal is to learn an objective function that maximizes the mutual information between the agent and the opponent. The authors propose a new algorithm, SOS, which is based on Opponent Shaping (SOS) and a stable variant named LookAhead (LookAhead). Theoretical results show that SOS converges to equilibria and avoids strict saddles in all games, while also shaping the learning of opponents and consistently either matching or outperforming LOLA. Experiments are conducted on the IPD game and the GAN game."
SP:bdafb5fca09a775a8c92d2826d5dc977d28091c2,"This paper proposes an alarm system to set off alarms when the segmentation result is possibly unsatisfactory. The idea is to project segmentation results into a low dimensional feature space, and then learn classifiers/regressors in the feature space to predict the qualities of segmentations results. The feature space is formed using shape feature, which is a strong prior information shared among different data, so it is capable to predict segmentation performance given different segmentation algorithms on different datasets. The shape feature is captured using the value of loss function when the result is tested using a VAE. The VAE is trained using only the ground truth masks, therefore the bad segmentations result with bad shapes become the rare events for VAE and will result in large loss value."
SP:60738395d9efe2b3fe3a00c542ebb4261e54386c,"This paper proposes a simple deep decoder, which is a deep neural network that can generate natural images from very few weight parameters. The proposed method is simple in the sense that each layer has an identical structure that consists of only one upsampling unit, pixel-wise linear combination of channels, ReLU activation, and channelwise normalization. This simplicity makes the network amenable to theoretical analysis, and it sheds light on the aspects of neural networks that enable them to form effective signal representations. The results show that the proposed method can achieve state-of-the-art performance for denoising."
SP:1c9bad3bd4d670172f65aa0304e9837ecafc6b3d,"This paper presents an end-to-end neural network-based method for program synthesis from natural language (NL) specifications. The proposed method is trained on abstract syntax trees, combined with a pretrained word embedding and a bi-directional multi-layer LSTM for processing of word sequences. The decoder features a doubly-recurrent LSTMs and novel signal propagation schemes and soft attention mechanism. Experiments show that the proposed method performs on par with or better than the method proposed in a previous study."
SP:d2ec231bb6153a303e5110e671dea14c2721e636,"This paper proposes a novel adversarial defense method for deep neural networks. The proposed method is based on the idea of learning class-conditional data distributions for adversarial perturbations. The authors show that the proposed method outperforms the state-of-the-art in terms of adversarial robustness on MNIST against L0, L2, and L∞ perturbation. They also show that even the most successful L0 robustness method (Madry et al.) has lower L0-robustness than undefended networks and is still highly susceptible to L2-perturbed images. "
SP:91a24e7f4b952c37441feab4a7e8555014c856a4,"This paper proposes a method to control the spectra of the weight matrices of the discriminator in GANs. The main idea is to reparameterize the spectral norm of the matrices to encourage the slow singular value decay. The proposed method is based on the idea of spectral normalization, which is an extension of the work of (Brock et al., 2016) and (Miyato et. al., 2018). The authors show that the proposed method can control the spectral decay of the spectral matrices without computing the singular value decompositions. The method is evaluated on CIFAR-10, STL-10 and ImgaeNet datasets and compared to other methods."
SP:8115fd9b681198d62100c36794926fb57dc0a4f5,"This paper proposes a value iteration algorithm for reinforcement learning based on Anderson accelerated value iteration (A2VI). A2VI can be viewed as an approximation of the policy evaluation by interpolating on historical data and is more efficient than the modified policy iteration, which is a classical approximate method for policy evaluation. The proposed method is applied to the deep Q-learning algorithm, resulting in the Deep Anderson Accelerated Q-Learning (DA2Q) algorithm. The theoretical analysis of the convergence of the method is provided. Empirical results on toy problems and Atari games show the effectiveness of the proposed method."
SP:bd79b0c0af778a36008a0c0cf2fb6393fd2789d4,"This paper proposes a novel method to solve the catastrophic forgetting problem in the class incremental learning scenario. The proposed method combines the strength of deep learning and support vector machine (SVM), where SVM is used to identify the support data from the old data, which are fed to the deep learning model together with the new data for further training so that the model can review the essential information of old data when learning the new information. Two powerful consolidation regularizers are applied to stabilize the learned representation and ensure the robustness of the learned model. The experimental results show that the proposed method significantly outperforms the state-of-the-art incremental learning methods."
SP:d228d213f79716774043cea253305fecece659ec,"This paper conducts a comprehensive study of unit selectivity measures on the AlexNet network. The authors compare four measures of selectivity on AlexNet, namely precision, class-conditional mean activity selectivity, CCMAS, and a new measure called top-class selectivity. They show that the precision and CCMAS measures provide a much higher level of selectiveivity than is warranted, with the most selective hidden units only responding strongly to a small minority of images from within a category. They also generate activation maximization (AM) images that maximally activated individual units and found that under (5%) of units in fc6 and conv5 produced interpretable images of objects, whereas fc8 produced over 50% interpretable image."
SP:b9deae0392e0160b400d76c549d382e235196f8c,"This paper studies the problem of community detection in graphs from a learning perspective. The authors propose a novel family of Graph Neural Networks (GNNs) for solving community detection problems in a supervised learning setting. They show that GNNs can match or even surpass the performance of the belief propagation algorithm on binary and multiclass stochastic block models, which is believed to reach the computational threshold in these cases. They also provide an upper bound on the energy gap controlling the energy difference between local and global minima (or minimum) of a given graph distribution. "
SP:a9ed31090e55f6152fc31c7512af5d634cc7225a,"This paper studies the problem of online dictionary learning, where the goal is to model the given data as a linear combination of a few columns of a matrix known as a dictionary, and the sparse weights forming the linear combination are known as coefficients. Since the dictionary and coefficients, parameterizing the linear model are unknown, the corresponding optimization is inherently non-convex. This was a major challenge until recently, when provable algorithms for dictionary learning were proposed. However, these provide guarantees only on the recovery of the dictionary, without explicit recovery guarantees on the coefficients. This potentially limits the utility of existing provable dictionary learning methods in applications where coefficient recovery is of interest. To this end, this paper proposes a simple Neurally plausible alternating Optimization-based Online Dictionary Learning algorithm, which recovers both the Dictionary and coefficients exactly at a geometric rate, when initialized appropriately. The algorithm is also scalable and amenable for large scale distributed implementations in neural architectures. "
SP:85232b72a2643d6dc81cf952ccbb95192032b7c5,"This paper proposes a new loss function and training scheme for learning binary hash codes with any differentiable model and similarity function. The proposed loss function improves over prior methods by using log likelihood loss on top of an accurate approximation for the probability that two inputs fall within a Hamming distance target. A novel training scheme obtains a good estimate of the true gradient by better sampling inputs and evaluating loss terms between all pairs of inputs in each minibatch. To fully leverage the resulting hash codes, the proposed method uses multi-indexing. The authors demonstrate that these techniques provide large improvements to the similarity search tasks."
SP:3bd4ccff7f48380d2db8dff2c4ca515894a7f1db,"This paper proposes Graph HyperNetwork (GHN) for neural architecture search (NAS) to amortize the search cost. Given an architecture, GHN directly generates the weights by running inference on a graph neural network. GHNs model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, the authors randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHN is fast – it can search nearly 10x faster than other random search methods on CIFAR-10 and ImageNet."
SP:65ccf43cd4e033d22239069057f5200d49f33724,This paper proposes a method to improve the performance of GAIL by using additional information from non-expert demonstrations which are easier to obtain. The key idea of the proposed method is to perform multiclass classification to learn discriminator functions where the expert demonstrations are regarded as being drawn from an extra class. Experiments in continuous control tasks demonstrate that the method learns better policies than the GAIL baseline when the number of expert demonstrations is small.
SP:e8427949a98effbd37ce7604fa11f240e2342196,"This paper proposes a method to learn the inverse of the forward process of a neural network (INN) that can be used to determine the posterior distribution of the parameters of the inverse process. The INN is based on the notion of invertibility, which means that the latent variables of the INN can be learned implicitly. The authors show that the INNs are able to provide the full posterior distribution over parameter space, which is then used to learn a model of the corresponding inverse process, which can then be used for the inverse problem. The proposed method is evaluated on synthetic and real-world problems, and compared with Bayesian computation (ABC) and conditional VAEs."
SP:75c9bb53bac29bdb390f9ba5707caee4ab1f5925,"This paper proposes a new method for quantifying the uncertainty of deep neural networks (NNs). The method is based on the ensemble of NNs trained with a proper scoring rule. The ensemble method can be understood as finite mixture model with uniform mixing weights. The proposed method replaces the fixed mixing weights by an adaptive, input-dependent distribution (specifying the probability of each component) represented by an NN, and considers uncountably many mixture components. The resulting model can be seen as the continuous counterpart to mixture density networks and is therefore referred to as compound density networks (CDNs)."
SP:e1e38289285c1b8fdb318e4f6d37a198a08787a2,"This paper proposes a method to reduce the size of neural networks by using a full variational distribution over weights, which allows for more efficient coding schemes and consequently higher compression rates. In particular, following the classical bits-back argument, the authors encode the network weights using a random sample, requiring only a number of bits corresponding to the KullbackLeibler divergence between the sampled variational distributions and the encoding distribution. The proposed method sets new state-of-the-art in neural network compression, as it strictly dominates previous approaches in a Pareto sense."
SP:ad70d8cf3a4558aab0d3b7155594464a3debd912,"This paper proposes ProxylessNAS, a proxy-based NAS algorithm that directly learns the architectures for large-scale target tasks and hardware platforms. The main contribution of this paper is to address the high memory consumption issue of differentiable NAS and reduce the computational cost (GPU hours and GPU memory) to the same level of regular training while still allowing a large candidate set. Experiments on CIFAR-10 and ImageNet demonstrate the effectiveness of directness and specialization. "
SP:e5b70d43d301d1980fae02623ea711976b429c14,"This paper proposes to modify the Lagrangian dual with additive linear penalties to second-order ones. The authors argue that this results in a more practical training procedure in non-convex, large-data settings. In particular, the use of second order penalties allows training the penalized objective with a fixed value of the penalty coefficient, thus avoiding the instability and potential lack of convergence associated with two-player min-max games. In addition, the authors derive a method for efficiently computing the gradients associated with the second order penalty in stochastic mini-batch settings."
SP:e4720b8e4efdb222c45eafd47fd8a7fbf15d881d,"This paper presents a reweighted wake-sleep (RWS) algorithm for learning discrete latent-variable models with discrete latent variables. The authors show that RWS outperforms existing state-of-the-art methods in learning the discrete latent variable models. They also show that the RWS algorithm learns better models and inference networks with increasing numbers of particles, and extend to continuous latent variables as well."
SP:7459ae5b1d886e68930c4c9e21df508bc8ab3c9a,"This paper proposes a method to train structured prediction energy networks (SPENs) for structured output prediction tasks. SPENs are trained using gradient-based search on a smooth, learned representation of the score landscape, and have previously yielded state-of-the-art results in structured prediction. In particular, this truncated randomized search in the reward function yields previously unknown local improvements, providing effective supervision to SPENS, avoiding their traditional need for labeled training data. "
SP:638c1bc09992029b78bd83f0127594dcccb96c06,"This paper studies the problem of robust policy search, i.e., learning policies that do not degrade in performance when subject to unseen environment model parameters. The authors propose an active learning based framework, EffAcTS, to selectively choose model parameters for this purpose so as to collect only as much data as necessary to select such a subset. They apply this framework to an existing method, namely EPOpt, and experimentally validate the gains in sample efficiency and the performance of their approach on standard continuous control tasks. "
SP:491c239713a6489f0b1790ca26db54a1813c67ae,"This paper proposes a two-timescale network (TTN) architecture that enables linear methods to be used to learn values, with a nonlinear representation learned at a slower timescale. The approach facilitates the use of algorithms developed for the linear setting, such as data-efficient least-squares methods, eligibility traces and the myriad of recently developed linear policy evaluation algorithms, to provide nonlinear value estimates. The authors prove convergence for TTNs, with particular care given to ensure convergence of the fast linear component under potentially dependent features provided by the learned representation."
SP:327d606cf3813b00a009a7785e08ef9e11f89493,"This paper proposes a model-based and model-free approach to planning and planning with semantic regularities for visual navigation in House3D, a 3D environment that contains diverse human-designed indoor scenes with real-world objects. The proposed method, LEAPS, consists of a multi-target sub-policy that acts on visual inputs, and a Bayesian model over semantic structures. When placed in an unseen environment, the agent plans with the semantic model to make high-level decisions, proposes the next sub-target to execute, and updates the semantic models based on new observations. The experimental results show that the proposed method outperforms strong baselines that do not explicitly plan using the semantic content."
SP:d7c26f43bc68d160095b1f50447528843d79edbd,"This paper proposes a multi-task perception-related basic knowledge and driving knowledge stepwise training strategy to tackle the generalization and accident explanation problems of end-to-end deep learning driving models. The proposed model consists of two modules: perception module and driving module as in Fig. 1. The perception module is used for learning easier driving-related perception knowledge, which is able of pixel level understanding of input including what & where and how far knowledge. After the perception module was trained to have pixel-level understanding of its image input, the driving module was freezed and trained with driving dataset. The results of experiments demonstrated the effectiveness of multitask perception knowledge for better generalization generalization, generalization ability, and crash explanation ability."
SP:b6bd98cc70fab97e1245cbb63a42ef89ab7e7ed5,This paper studies the trade-off between adversarial robustness and standard generalization in adversarial training. The authors show that robust models are more resource-consuming and lead to a reduction in standard accuracy. They also show that adversarially robust learning tends to equip the resulting models with invariances that we would expect to be also present in human vision. 
SP:9c9275d75cd95b1b82e0cbb1421e3d3ade1ce33a,"This paper proposes a new method for gradient-based training of neural networks that does not rely on neurons having a mechanism for back-propagating an error gradient. The proposed method is based on the Equilibrium Propagation method proposed by Scellier & Bengio (2017), which uses only local learning rules to approximate the state of the fixed-point using a local learning rule. The authors propose a feedforward network to initialize the iterative inference procedure for Equilibrium propagation. After training, they can simply use this initializing network for inference, resulting in a learned feed-forward network. "
SP:ac9ea91eb465517de495477cf67bc94d5ed1b0cb,"This paper proposes a zeroth-order (ZO) stochastic optimization algorithm, ZO-signSGD, which combines the advantages of gradient-free operations and signSGD. The main idea is to use the sign information of gradient estimates of gradient estimators to speed up the convergence of the algorithm. The convergence rate is shown to be O(d/\sqrt{d/T}) under some mild conditions, where d is the number of optimization variables, and T is number of iterations. In addition, the authors analyze the effects of different types of gradient estimation methods and propose several variants of the ZO algorithm to improve the convergence rate. Empirical evaluations on image classification datasets MNIST and CIFAR-10 demonstrate the effectiveness of the proposed algorithm."
SP:5f79b11777f6ef1d70c85418bfc2e4616dd7d960,This paper proposes a method to reduce the computation efforts of convolutional neural networks by pruning the output of some convolution operations. The authors propose to set a checkpoint in the multiply-accumulate (MAC) operations to determine whether a filter could terminate early based on the intermediate result. A fine-tuning process is conducted to recover the accuracy drop due to the applied checkpoints. The experimental results show that the proposed method can save approximately 50% MAC operations with less than 1% accuracy drop for CIFAR-10 example model and Network in Network.
SP:7801e9c854ad7d960c0d24fda15597af6994c23f,This paper investigates the use of temporal dependency in audio data to improve the adversarial robustness of ASR systems. The authors show that temporal dependency can be exploited to gain discriminative power against audio adversarial examples and is resistant to adaptive attacks considered in the experiments. They also show that the input transformation developed from image adversarial defense provides limited robustness improvement and is subtle to advanced attacks. The results also show promising insights in exploiting domain-specific data properties to mitigate the negative effects of adversarial attacks.
SP:51830b811a8e39b4f0a5b7609df719e026fac6a1,This paper proposes a method to learn a generative model for multi-object images by composing individual objects and background. The proposed method is based on the Wasserstein and non-saturating generative models (Wasserstein GANs). The authors show that the proposed method can generate images that are more faithful to the reference distribution. The method is evaluated on several image datasets and shows that it is able to disentangle information corresponding to different objects at a representational level. 
SP:fb59990b8da0e95d8202383478a456667de60449,"This paper proposes a method for learning disentangled representations from unlabeled images, where the only supervision comes from an auxiliary “reference set” that contains images where the factors of interest are constant. To alleviate the annotation cost, the authors propose a novel deep generative model designed to exploit the weak supervisory signal provided by the reference set. During training, they use the variational inference framework where adversarial learning is used to minimize the objective function. They validate the ability of the proposed model to learn disentangling representations from minimal supervision."
SP:dbc1983d9b9d72aa14f8e8515d793d2bbde26c9c,"This paper proposes a meta-learning method for continual online learning of deep neural network models. The proposed method uses expectation maximization and a Chinese restaurant process to learn a mixture of models to handle non-stationary task distributions. This allows for all models to be adapted as necessary, with new models instantiated for task changes and old models recalled when previously seen tasks are encountered again. Empirical results show that the proposed method is able to adapt to out-of-distribution tasks, and can recognize and revert back to prior tasks."
SP:5665e5f006f84927beb0440e145f476e02538077,"This paper studies the effect of parameter lag and recurrent state staleness in distributed training of RNN-based RL agents with experience replay. The authors show that parameter lag can lead to representational drift and recurrent staleness, and propose an improved training strategy to mitigate these issues. The proposed method, called Recurrent Replay Distributed DQN (R2D2), achieves state-of-the-art performance on Atari-57 and DMLab-30 games."
SP:47ace37f31a46d5ee85c283e62ddb71a12f2c5c4,"This paper proposes a hierarchical generative model for modeling multi-agent trajectories in basketball. The authors propose a hierarchical framework that can capture long-term coordination using intermediate variables. The proposed method is inspired by recent work on leveraging programmatically produced weak labels, which they extend to the spatiotemporal regime. They show how to instantiate their framework to effectively model complex interactions between basketball players and generate realistic multi agent trajectories of basketball gameplay over long time periods."
SP:1a90cdf028068528b0559e7d44bf26dda20310bd,"This paper proposes a graph-structured variational recurrent neural network (Graph-VRNN) to infer the current state of the (partially observed) world, as well as to forecast future states. The proposed method is trained end-to-end to integrate temporal information, from a learned dynamics model, with ambiguous visual information, with a learned vision model, in the context of interacting agents. The results show that the proposed method outperforms various baselines on two sports datasets, one based on real basketball trajectories, and one generated by a soccer game engine."
SP:8392f04b7265f665ba6d44d297bca245d44b4708,"This paper proposes a method for end-to-end training of a base neural network that integrates calls to existing black-box functions. The method is motivated by the fact that there is a vast amount of existing functions that programmatically solve different tasks in a precise manner eliminating the need for training. The proposed method approximates the functions with a differentiable neural network in a way that drives the base network to comply with the function interface during the inference process. The experiments show that the integrated model generalizes better than a fully differentiable model, and learns more efficiently compared to RL-based methods."
SP:13fb86de763a0b34ac6fa34ea9dfbd1c476ce43e,"This paper proposes a method for meta-learning based on hierarchical Bayesian models over the parameters of an arbitrary function approximator such as a neural network. The method is based on the model-agnostic metalearning (MAML) algorithm (Finn et al., 2017) to jointly estimate parameter initializations for gradient descent as well as a latent assignment of tasks to initializations. This approach better captures the diversity of training tasks as opposed to consolidating inductive biases into a single set of hyperparameters. The proposed method achieves better generalization performance on the standard mini-ImageNet benchmark for 1-shot classification."
SP:a410144dbe19713a06c63da87d9fb58b999a7492,"This paper proposes a meta-augmentation method for image classification, where the auxiliary task is hierarchical sub-class image classification. The proposed method, called Meta Auxiliary Learning (MAXL), trains a multi-task evaluator to determine sub-task target labels to train a meta learner to improve the generalization performance on the principal task. The experiments show that the proposed method outperforms baseline auxiliary learning methods, and is competitive even with a method which uses human-defined sub class hierarchies."
SP:76248e1c914c60ce69de244fe7ec62488d01e161,This paper proposes a neural network based representation for open set recognition. The proposed method is based on the idea that instances from the same class are close to each other while instances from different classes are further apart. The authors propose a loss function that enables them to use the same distance function both when training and when computing an outlier score. Experiments on three datasets from two different domains show that the proposed method achieves statistically significant improvement over existing methods.
SP:d4ee856bbf2dfb6390e5247086fec2e52dcb6858,"This paper presents a series of experiments on low-precision networks for image classification on ImageNet. The authors show that, at 8-bit precision, the proposed methods can match or exceed the accuracy of the full precision baseline networks after one epoch of fine-tuning. They also show that the weights of the low precision networks are very close (in cosine similarity) to the corresponding baseline networks, making training from unnecessary unnecessary. They find that gradient noise due to quantization during training increases with reduced precision, and seek ways to overcome this noise. "
SP:6bfdc37b346e6ddfa049e0414647f4beda8ede3f,"This paper proposes an end-to-end model to predict post-bounce trajectories and infer two underlying physical properties that govern bouncing restitution and effective collision normals. The proposed model, Bounce and Learn, comprises two modules – a Physics Inference Module (PIM) and a Visual Inference module (VIM). VIM learns to infer physical parameters for locations in a scene given a single still image, while PIM is used to model physical interactions for the prediction task given physical parameters and observed pre-collision 3D trajectories. To achieve the results, the authors introduce the Bounce Dataset comprising 5K RGB-D videos of bouncing trajectories of a foam ball to probe surfaces of varying shapes and materials in everyday scenes including homes and offices. "
SP:010bd055310c363d3cb0fbe0e11546de58220e15,"This paper studies the relationship between the adversarial vulnerability of neural networks and the gradients of the training objective when viewed as a function of the inputs. The authors show that for most current network architectures, the gradient norm of these gradients grows as the square root of the input size. They also show that CNNs and feed-forward networks exhibit increasingly large gradients with input dimension d, almost independently of their architecture. "
SP:5fa3ae057e55be6b71cc94a7dbfe31e54e1c536f,"This paper proposes an interactive agent modeling scheme that encourages an agent to learn to probe. The probing agent learns to interact with the environment and with a target agent (i.e., a demonstrator) to maximize the change in the observed behaviors of that agent. Through probing, rich behaviors can be observed and are used for enhancing the agent modeling to learn a more accurate mind model of the target agent. The proposed framework consists of two learning processes: i) imitation learning for an approximated agent model and ii) pure curiosity-driven reinforcement learning to learn an efficient probing policy to discover new behaviors that otherwise can not be observed. The experimental results show that the agent model learned by the proposed method generalizes better in novel scenarios than the ones learned by passive observation, random probing, and other curiosity driven approaches do, and can be used to enhance performance in multiple applications including distilling optimal planning to a policy net, collaboration, and competition."
SP:3af184a5529d6ec2a0862efd1af80ef5b50d2952,"This paper proposes a modification to ANNs that modulates the activations of the ANNs in a way that mimics biological neuromodulators. Specifically, the authors introduce a new type of ANN nodes, called modulators, that are able to adjust their activation sensitivities in run-time based on their input patterns. The authors show that the modulators can improve the performance of ANNs compared to the baseline ANNs. "
SP:287a577834fd2820a939a1113b39146a22727491,"This paper presents a neural analysis and synthesis (NANSY) framework that can manipulate voice, pitch, and speed of an arbitrary speech signal. NANSY uses a novel training strategy based on information perturbation. The idea is to perturb information in the original input signal (e.g., formant, pitch and frequency response), thereby letting synthesis networks selectively take essential attributes to reconstruct the input signal. Experiments on zero-shot voice conversion, pitch shift, and time-scale modification demonstrate the effectiveness of the proposed method."
SP:90f35ad1ec0c38b0817f5678ee2a5c4f0e08fb38,"This paper studies the generalization properties of gradient-based bilevel programming (BVP) algorithms for hyperparameter optimization. In particular, the authors provide an expectation bound on the validation set based on uniform stability. They also provide a bound for the classical cross-validation algorithm under certain conditions. Finally, they show that regularization terms in both the outer and inner levels can relieve the overfitting problem in BVP algorithms. "
SP:42f52aec3a776d87daa5fd72b8e6325d12c88d63,"This paper proposes a knowledge distillation method to transfer knowledge from a teacher to a student. The main idea is to learn the teacher models that are friendly to students and, consequently, more appropriate for knowledge transfer. The proposed method learns the student branches jointly to obtain student-friendly representations. The experimental results demonstrate the effectiveness of the proposed method. "
SP:e15a1c21229233fd97dc1dfa0a4ef48b69dc9f95,"This paper studies generalization to out-of-distribution (OOD) data. In particular, the authors define what is OOD and what does it mean by saying an OOD problem is learnable. They also introduce a new concept of expansion function, which characterizes to what extent the variance is amplified in the test domains over the training domains, and therefore give a quantitative meaning of invariant features. Based on these, they prove that OOD generalization largely depends on the expansion function and model selection. Extensive experiments on benchmark OOD datasets demonstrate that their model selection criterion has a significant advantage over baselines."
SP:37b04b9068d39bcf0a581eb8181d13cf1a8926bf,"This paper proposes a Variational Continual Bayesian Meta-Learning (VC-BML) algorithm for online tasks with non-stationary task distributions. The proposed algorithm is based on a Dynamic Gaussian Mixture Model (DGMM) for meta-parameters, which is a mixture of dynamically updated distributions, each component of which is associated with a cluster of similar tasks. This allows the algorithm to adapt to diverse and dissimilar tasks due to a larger parameter space, alleviating the negative knowledge transfer problem. To infer the posteriors of model parameters, the authors develop a more robust posterior approximation method – structured variational inference method – for the sake of avoiding forgetting knowledge. Empirical results show that the proposed algorithm can alleviate negative transfer and catastrophic forgetting for streaming low-resource tasks."
SP:776d5b02b8d3a8bbcc1f52706f3887c384cb149e,"This paper proposes a probabilistic solution of boundary value problems (BVPs), which are ordinary differential equations subject to boundary conditions. In contrast to previous work, this paper introduces a Gauss–Markov prior and tailor it specifically to BVPs, which allows computing a posterior distribution over the solution in linear time, at a quality and cost comparable to that of well-established, non-probabilistic methods. The proposed method is compatible with other parts of the statistical modelling tool-chain. "
SP:86aac0c6b75fdc12f84bba342934865616f866d4,"This paper studies the problem of learning a near optimal policy for two reward-mixing Markov decision processes (MDPs), where the reward function is drawn from one of multiple possible reward models at the beginning of every episode, but the identity of the chosen reward model is not revealed to the agent. The latent state space, for which the dynamics are Markovian, is not given to the agents. The authors provide the first polynomial-time algorithm that finds an optimal policy after exploring two episodes, where H is the time horizon and S is the number of states and actions respectively. This is the first efficient algorithm that does not require any assumptions in partially observed environments."
SP:1a3c70ae9cf2a806d603f4b9e7ca6e10b720a956,"This paper proposes Single-cause perturbation (SCP) to estimate the multi-cause treatment effect in the context of conditional average treatment effect estimation (CATE). The proposed method is based on augmenting observational data with the estimated potential outcomes under single-cause interventions, and then performs covariate adjustment on the augmented dataset to obtain the estimator. The empirical results demonstrate the performance gain of SCP on extensive synthetic and semi-synthetic experiments."
SP:247bc6675cce89d51558537daf63dadb0c4307f8,"This paper proposes a multi-wavelet-based neural operator learning scheme that compresses the associated operator’s kernel using fine-grained wavelets. By explicitly embedding the inverse multiwavelet filters, the proposed method can learn the projection of the kernel onto fixed multi wavelet polynomial bases. This allows learning the complex dependencies at various scales and results in a resolution-independent scheme. The proposed method is evaluated on the Korteweg-de Vries (KdV) equation, Burgers’ equation, Darcy Flow, and Navier-Stokes equation, and achieves state-of-the-art accuracy."
SP:1153785e6a016cfee2644952a772aa08927299b6,"This paper proposes frequency domain approximation (FDA) for training binary neural networks (BNNs) in the Fourier frequency domain. The proposed method is based on the combination of sine functions for training BNNs, namely FDA-BNN. This method does not affect the low-frequency information of the original sign function which occupies most of the overall energy, and high-frequency coefficients will be ignored to avoid the huge computational overhead. The experiments on several benchmark datasets and neural architectures illustrate that the binary network learned using our method achieves the state-of-the-art accuracy."
SP:33b95ea8da4d30b8e8f9d3fe3acca023d4b8d831,This paper proposes to use multi-area RNNs with neuroscience-inspired architecture constraints to learn biologically plausible solutions to a perceptual decision-making task (Checkerboard Task). The authors show that incorporating multiple areas and Dale’s Law is critical for biasing the networks and that output-relevant information is preferentially propagated between areas. The results suggest that cortex uses modular computation to generate minimal sufficient representations of task information.
SP:db3ced65d67e3373fb3936ec50f41c8ef010bbbe,"This paper proposes a method to search for multiple saliency maps for image classification. The authors argue that a single saliency map provides an incomplete understanding since there are often many other maps that can explain a classification equally well. They propose structured attention graphs (SAGs), which compactly represent sets of sets of attention maps for an image by visualizing how different combinations of image regions impact the confidence of a classifier. They conduct a user study comparing the use of SAGs to traditional saliency mapping baselines."
SP:f2b385bfd9ada0e26aa8829214b424f58582d9f7,"This paper studies how the choice of training objective affects the transferability of the hidden representations of convolutional neural networks trained on ImageNet. The authors show that many objectives lead to statistically significant improvements in ImageNet accuracy over vanilla softmax cross-entropy, but the resulting fixed feature extractors transfer substantially worse to downstream tasks. The choice of loss has little effect when networks are fully fine-tuned on the new tasks, and differences among loss functions are apparent only in the last few layers of the network."
SP:b66b5e24f68563e2e200eda660f0dbaff53efeff,"This paper proposes selective backpropagation through time (SBTT) to learn a deep generative model of latent dynamics from data in which the set of observed variables changes at each time step. The proposed method is applied to sequential autoencoders and is able to obtain spatio-temporal super-resolution in neuronal time series by exploiting relationships among neurons, embedded in latent low-dimensional population dynamics. Experiments on electrophysiological and calcium imaging data demonstrate the effectiveness of SBTT."
SP:3513a83806e71006b86d60b779d8bd6bb87c3546,"This paper proposes a hierarchical approach to sequence-to-sequence learning with quasi-synchronous grammars, where each node in target tree is transduced by a node in the source tree. Both the source and target trees are treated as latent and induced during training. A neural parameterization of the grammar is developed which enables parameter sharing over the combinatorial space of derivation rules without the need for manual feature engineering. The proposed method is applied to various domains, including SCAN, style transfer, and small-scale machine translation, and finds that it performs respectably compared to baseline approaches."
SP:d06fc251f2a9287f7a2236a188349628d8f39d9a,"This paper proposes a new algorithm to perform Group Elastic Net for feature selection and functional data analysis. The algorithm is based on the Augmented Lagrangian (AGL) algorithm, which exploits the sparsity structure of the AGL to reduce the computational burden. The authors also extend the algorithm to the function-on-scalar regression framework and show that the proposed algorithm can achieve better performance than existing methods. "
SP:e0b53f76f3a6b756fedd09926f9cf034f89f4a5a,"This paper proposes a method to cluster repeatedly observed marked point processes to identify potential heterogeneity in the observed data. Specifically, the authors propose a mixture model of multi-level marked point process for identifying potential heterogeneity. The proposed method is based on a matrix whose entries are marked log-Gaussian Cox processes and cluster rows of such a matrix. An efficient semi-parametric Expectation-Solution (ES) algorithm combined with functional principal component analysis (FPCA) is proposed for model estimation. "
SP:3aa213076f3e9f9838ac654517df2fe1fca33499,"This paper proposes an online multi-task learning approach for adaptive nonlinear control, called Online Meta-Adaptive Control (OMAC), which is motivated by robot control, where a robotic system encounters a sequence of new environmental conditions that it must quickly adapt to. A key emphasis is to integrate online representation learning with established methods from control theory, in order to arrive at a unified framework that yields both control-theoretic and learning-theoric guarantees. The authors provide instantiations of their approach under varying conditions, leading to the first non-asymptotic end-to-end convergence guarantee for multi- task non-linear control. Experiments show that OMAC significantly outperforms conventional adaptive control approaches which do not learn the shared representation."
SP:cb274c93a169b199ea09120ca02105a3f16b31c5,"This paper proposes a method for training neural networks with certifiable robustness guarantees. The method is based on interval bound propagation (IBP) and CROWN-IBP. The authors identify two important issues in existing methods, namely exploded bounds at initialization, and the imbalance in ReLU activation states and improve IBP training. To mitigate these issues and conduct faster certified training with shorter warmup, the authors propose three improvements based on IBP-based training: 1) derive a new weight initialization method for IBP, 2) propose to fully add Batch Normalization (BN) to each layer in the model, 3) design regularization to explicitly tighten certified bounds and balance ReLU activations states during wamrup. The proposed method is able to efficiently train certifiably robust models that outperform previous SOTA performance in significantly shorter training epochs."
SP:18ffeb199a670fb2b1f4417b8653479001944dab,"This paper proposes a change point detection method that is robust against adversarial attacks. The proposed method is based on the Huber-contamination framework, which allows the contamination distributions to be different at each time point. The authors derive the minimax-rate optimal localisation error rate, quantifying the cost of accuracy in terms of the contamination proportion. They also propose a computationally-feasible method, matching the lower bound under certain conditions, saving for logarithmic factors. Extensive numerical experiments are conducted with comparisons to existing robust change point detectors methods."
SP:d03617b5fc446768809cf015c9234b0c9386a690,"This paper studies the power of learning via mini-batch stochastic gradient descent (SGD) and batch Gradient Descent (GD) on the empirical loss of a differentiable model or neural network. The authors show that SGD and GD can always simulate learning with statistical queries (SQ), but their ability to go beyond that depends on the precision of the gradient calculations relative to the minibatch size b and sample size m (for GD). With fine enough precision, SGD can go beyond SQ learning and simulate any sample-based learning algorithm and thus its learning power is equivalent to that of PAC learning. On the other hand, with low precision (high ρ, i.e. only a few bits of precision, which is frequently the case when training deep networks), the mini batch size b plays an important role, and simulating arbitrary sample based methods is provably not possible using fbGD, or with bSGD with a minibatch size that is too large, namely b = ω(log(n)/ρ2). "
SP:1de2864fe2f53e25596a9bd2c61e2048e79296f6,"This paper studies the problem of optimal uniform quantization, which is a non-convex minimization problem where the unknowns are the positions of atoms. The authors show that a suitably adjusted version of Lloyd’s algorithm, in which Voronoi cells are replaced by Power cells, leads to configurations with small Wasserstein error. This is surprising because, again, of the non-Convex nature of the problem, as well as the existence of spurious critical points, they provide explicit estimates for the convergence of this Lloyd-type algorithm, starting from a cloud of points that are sufficiently far from each other in the ambient space."
SP:c3d364aeee55230a436c3ce4e8dc8310ee73959e,This paper proposes a dynamic self-attention method for video understanding. The proposed method leverages spatio-temporal relations in videos by dynamically generating relational kernels and aggregating relational contexts. Experiments show that the proposed method outperforms the state-of-the-art on standard motion-centric benchmarks. 
SP:2c2530069d5cab485629090243da464d107feadd,"This paper studies the fluctuation of the learning dynamics of multilayer neural networks in terms of the second order mean field limit. The authors derive a system of dynamical equations that captures the limiting fluctuation distribution of neurons in this second order limit. They demonstrate through the framework the complex interaction among neurons, the stochasticity with cross-layer dependency, and the nonlinear time evolution inherent in this limit, that this limit is related quantitatively to the limit of large-width networks. They apply the result to show a stability property of gradient descent mean field training: along the training trajectory, the learned output function progressively biases towards a solution with minimal fluctuation, even after the network has been initialized at or has converged to a global optimum. "
SP:a3d927854d9d7fd39b8d05a79666810d585d5062,"This paper proposes a method to model a metriplectic dynamical system with learnable dynamics with unknown a priori model form. The proposed method learns generalized Casimirs for energy and entropy guaranteed to be conserved and nondecreasing, respectively. For the case of added thermal noise, the proposed method guarantees exact preservation of a fluctuation-dissipation theorem, ensuring thermodynamic consistency. Experiments show that the learned dynamics are more robust and generalize better than either ""black-box"" or penalty-based approaches."
SP:32e8e83e06b1e9a4dad761334d5947c91bfd1853,This paper proposes a sample selection-based algorithm for fair and robust training in the presence of data corruption. The authors formulate a combinatorial optimization problem for the unbiased selection of samples and propose a greedy algorithm that is efficient and effective in practice. Experiments show that the proposed algorithm obtains fairness and robustness that are better than or comparable to the state-of-the-art technique. 
SP:991127729bf067fe27fdd7ed360aab39e4df5921,"This paper proposes periodic activation functions for Bayesian neural networks (BNNs) that establish a connection between the prior on the network weights and translation-invariant, stationary Gaussian process priors. The authors show that this connection goes beyond sinusoidal (Fourier) activations by also covering triangular wave and periodic ReLU activation functions. In a series of experiments, they show that periodic activation function obtain comparable performance for in-domain data and capture sensitivity to perturbed inputs in deep neural networks for out-of-domain detection. "
SP:d61a2aecfea4612c473b4e6fd41f3dc2fcbb04a1,"This paper proposes a method to provide feedback to interactive programs as a task of classifying Markov Decision Processes (MDPs). Each student’s program fully specifies an MDP where the agent needs to operate and decide, under reasonable generalization, if the dynamics and reward model of the input MDP should be categorized as correct or broken. The authors demonstrate that by designing a cooperative objective between an agent and an autoregressive model, they can use the agent to sample differential trajectories that allow a classifier to determine membership: play to grade. The method enables an automatic feedback system for interactive code assignments."
SP:daf99ad91613d6e11b13315ccbd1bbe25094ae4b,"This paper proposes a method to explain deep reinforcement learning (DRL) models by visualizing the importance of low-level input features with superpixels, attentions, or saliency maps. The proposed method is based on disentangling the high-level latent object features derived from a disentangled representation and a mimic tree that extracts the causal impact of the latent features on DRL action values. To jointly optimize both the fidelity and the simplicity of the mimic tree, the authors derive a novel Minimum Description Length (MDL) objective based on the Information Bottleneck (IB) principle. Experiments show that the proposed method achieves strong approximation performance with significantly fewer nodes than baseline models."
SP:84560de78af979354fff83d1370d8675c1e9191f,"This paper proposes a Bayesian framework to model the structure of dynamic predictions over time. The proposed method is based on the Gaussian latent information martingale (GLIM) framework, which is used to estimate the posterior probability distributions of future probability paths. The authors propose to model these trajectories by assuming predictions update according to a latent process of information flow which is inferred from historical data. The method is evaluated on three different metrics to evaluate the performance of the proposed method."
SP:0c4bfb44e0a353256692d5e5ae96f65c1a14363d,"This paper studies the problem of active pure exploration with fixed confidence in stochastic bandits. The goal is to answer a query about the environment with a given level of certainty while minimizing her sampling budget. For this problem, instance-specific lower bounds on the expected sample complexity reveal the optimal proportions of arm draws an Oracle algorithm would apply. The authors devise Frank-Wolfe-based Sampling (FWS), a simple algorithm whose sample complexity matches the lower bounds for a wide class of pure exploration problems. They apply FWS to various pure exploration tasks, including best arm identification in unstructured, thresholded, linear, and Lipschitz bandits."
SP:0947a0f08fba53d3c8af9b78dd64e6e10fc73e32,"This paper proposes LADDER, a Bayesian optimization method for black-box combinatorial spaces. The proposed method is based on deep generative models (DGMs) that learn a latent representation of structures using continuous spaces. However, the surrogate model over the latent space only uses the information learned by the DGM, which may not have the desired inductive bias to approximate the target black box function. To overcome this drawback, this paper proposes a novel structure-coupled kernel that explicitly integrates the structural information from decoded structures with the learned latent space representation for better surrogate modeling. Experiments on real-world benchmarks show the efficacy of the proposed method over prior methods in the problem setting."
SP:37adabdc6615c5199a481553c8ccc06d57363614,"This paper studies the role of representation of state-action value functions in regret minimization in finite-horizon Markov Decision Processes (MDPs) with linear structure. The authors derive a necessary condition on the representation, called universally spanning optimal features (UNISOFT), to achieve constant regret in any MDP with linear reward function. They then demonstrate that this condition is also sufficient for these classes of problems by deriving a constant regret bound for two optimistic algorithms (LSVI-UCB and ELEANOR). Finally, they propose an algorithm for representation selection and prove that it achieves constant regret when one of the given representations, or a suitable combination of them, satisfies the UNISOFT condition."
SP:92566b664ab2f6ee9b73f29327aeef85d14ecf60,"This paper proposes a differentiable contact model that can capture contact mechanics: frictionless/frictional, as well as elastic/inelastic. The proposed contact model extends the scope of Lagrangian and Hamiltonian neural networks by allowing simultaneous learning of contact and system properties. Experiments on a series of challenging 2D and 3D physical systems with different coefficients of restitution and friction show the effectiveness of the proposed method."
SP:82d59a3609dfd458f90f23d4e477c8b497e9dc18,"This paper studies the Benevolent training Hypothesis (BTH) which argues that the complexity of the function a deep neural network (NN) is learning can be deduced by its training dynamics. The paper shows that the Lipschitz constant close to the training data affects various aspects of the parameter trajectory, with more complex networks having a longer trajectory, bigger variance, and often veering further from their initialization. They also show that NNs whose 1st layer bias is trained more steadily (i.e., slowly and with little variation) have bounded complexity even in regions of the input space that are far from any training point. Finally, they find that steady training with Dropout implies a training with dropout."
SP:9b329c915fa8d4045c167c9df37a49ee314d190e,"This paper studies the problem of distribution independent PAC learning of halfspaces in the Massart noise model with strongly polynomial sample complexity, i.e., independent of the bit complexity of the examples. The authors show that any distribution can be efficiently decomposed as a disjoint mixture of few distributions for which a Forster transform exists and can be computed efficiently. The main application of this result is to obtain the first polynomially-time algorithm for distribution-independent PAC learning in the half-spaces setting. The algorithm requires n = poly(d, b, 1/b) labeled examples, runs in time poly(n, b) and achieves misclassification error $\�+$."
SP:e5229305af00067ae2dbabd903e585964aec8928,"This paper proposes a Bayesian optimisation-based adversarial attack method for graph classification models. The proposed method is black-box, query-efficient and parsimonious with respect to the perturbation applied. It can be easily adapted to perform various modes of attacks such as deleting or rewiring edges and node injection. The authors also investigate the topological properties of the successful adversarial examples found by their method and offer valuable insights on the graph topology change and the model robustness."
SP:4999e5664383066fdacd14be6242c7b83f85f3dd,"This paper studies the problem of online label shift adaptation in the online setting, where the test-time label distribution is continually changing and the model must dynamically adapt to it without observing the true label. The authors propose two adaptation algorithms inspired by classical online learning techniques such as Follow The Leader (FTL) and Online Gradient Descent (OGD) and derive their regret bounds. They empirically verify their findings under both simulated and real world label distribution shifts and show that OGD is particularly effective and robust to a variety of label shift scenarios."
SP:806515ae07fb1c9d02773592005d53d4158ef102,"This paper proposes a method for detecting and localizing gradual changes in the distribution of a sequence of time-ordered observations. The proposed method requires no prior domain knowledge, and it offers theoretical guarantees on both detection (false positive rate, power) and localization (consistency). "
SP:7a3c8a7b17ecab19361d36e1d3d73fa35b71214c,This paper proposes an online blind source separation (BSS) algorithm based on independent component analysis (ICA) neural networks (NNs). The proposed algorithm is based on a single-layer NN that can separate independent sources without pre-processing. The authors also propose a novel objective function for ICA that relies on modulating synaptic plasticity by the total output activity of the output neurons. The proposed method can be seen as an extension of Hebbian learning rules.
SP:22f8b517a3df65144412938f5891c463d7bae0ab,"This paper studies the behavior of two-neuron recurrent neural networks (RNNs) on three tasks: interval reproduction, delayed discrimination, and interval discrimination. The authors show that different networks with identical hyperparameters find qualitatively different solutions for each task. They find one layer of variability within the neural activity in response to stimuli from the training set, which is akin to multiple realizability. An additional layer is uncovered by testing the trained networks’ ability to extrapolate, as a perturbation to a system often reveals hidden structure. Furthermore, they relate extrapolation patterns to specific dynamical objects and effective algorithms."
SP:9b08a0f547ead3b59077a43b1052c6d46a0730f6,"This paper proposes a new method for arbitrary conditional density estimation. The proposed method, called Arbitrary Conditioning with Energy (ACE), can simultaneously estimate the distribution p(xu | xo) for all possible subsets of unobserved features xu and observed features xo. ACE is designed to avoid unnecessary bias and complexity — it specifies densities with a highly expressive energy function and reduce the problem to only learning one-dimensional conditionals (from which more complex distributions can be recovered during inference). Empirical results show that ACE achieves state-of-the-art results for arbitrary likelihood estimation and data imputation."
SP:f2b14f5854e6aa6922795d1d2051b7402486cef6,"This paper proposes an uncertainty-driven loss function for single image super-resolution (SISR) to train deep networks focusing on challenging situations such as textured and edge pixels with high uncertainty. Specifically, it introduces variance estimation characterizing the uncertainty on a pixel-by-pixel basis into SISR solutions so the targeted pixels in a high-resolution image (mean) and their corresponding uncertainty (variance) can be learned simultaneously. Experimental results show that the proposed method achieves better PSNR performance than traditional MSE or L1 loss functions without any increased computation during testing."
SP:9997583f40fa648adf57bb4fc34228f357be0cf1,"This paper proposes the first general PAC-Bayesian generalization bounds for adversarial robustness, that estimate, at test time, how much a model will be invariant to imperceptible perturbations in the input. Instead of deriving a worst-case analysis of the risk of a hypothesis over all the possible perturbation, the authors leverage the PACBayesian framework to bound the averaged risk for majority votes (over the whole class of hypotheses). The theoretically founded analysis has the advantage to provide general bounds that are valid for any kind of attacks (i.e., the adversarial attacks), that are tight thanks to the PAC-bayesian framework, and that can be directly minimized during the learning phase to obtain a robust model on different attacks at the test time."
SP:90b72e8dc41584e38f25dff9fb2853f5b11dc8fa,"This paper proposes a probabilistic entity representation model (PERM) for logical reasoning over Knowledge Graphs (KGs). PERM encodes entities as a multivariate Gaussian density with mean and covariance parameters to capture its semantic position and smooth decision boundary, respectively. PERM also defines the closed logical operations of projection, intersection, and union that can be aggregated using an end-to-end objective function. The experimental results show that PERM significantly outperforms the state-of-the-art methods on various public benchmark KG datasets on standard evaluation metrics. "
SP:b6184c9732dbb7eba7c20cae8869d975c428efe4,"This paper proposes a new method for learning hyperparameters for gradient-based hyperparameter optimization (HPO) in few-shot meta-learning. The proposed method is based on forward-mode differentiation with sharing (FDS), a simple and efficient algorithm which tackles memory scaling and gradient degradation issues. The authors provide theoretical guarantees about the noise reduction properties of their algorithm, and demonstrate its efficiency empirically by differentiating through 10 gradient steps of unrolled optimization on CIFAR-10. "
SP:9c3a326e5ee4e862923d3bf9415f32a077db8534,"This paper proposes a method to improve neural sequence models by adding logical reasoning. The proposed method is based on the dual-system model, where a symbolic reasoning module can either accept or reject the generations of a neural sequence model. The method is tested on the gSCAN grounded compositional challenge and instruction-following tasks. The results show that the proposed method can improve the consistency and coherence of text generations. "
SP:d77d046095e4c8336c0c76ac48cb046923230753,"This paper studies off-policy evaluation (OPE) in continuous treatment settings, where the goal is to estimate the mean outcome under a new treatment decision rule using historical data generated by a different decision rule. To handle continuous treatments, the authors develop a novel estimation method for OPE using deep jump learning. The key ingredient of their method lies in adaptively discretizing the treatment space using deep discretization, by leveraging deep learning and multiscale change point detection. Their method is further justified by theoretical results, simulations, and a real application to warfarin dosing."
SP:4d085e57286fdd36143108a002d16914222c239a,"This paper proposes a continuous-time variational inference algorithm for Markov Jump Processes (MJPs) that combines a Gaussian process approximation on the diffusion level with posterior inference for continuous time Markov jump processes. The authors provide the exact evolution equations for the prior and posterior marginal densities, the direct solutions of which are computationally intractable. Therefore, the authors propose to use a variational estimation method to approximate the exact posteriors by minimizing the path-wise Kullback-Leibler divergence. The proposed method is able to obtain Bayesian latent state estimates for arbitrary points on the real axis and point estimates of unknown system parameters. "
SP:d1f396e691f9d331adfb7b694a99c50e8004331f,"This paper studies the effect of the spectrum of the sensing matrices on the performance of expectation propagation (EP) algorithms. The authors define a notion for the spikiness of A and show the importance of this measure in the performance. Based on this notion, the authors show that matrices with spikier spectrums are better for EP, while less spiky (flatter) spectrums offer better recoveries. "
SP:ee66604d4da9fd04826e90ccbb94f0499eba4c63,"This paper proposes a new method for generalized zero-shot learning (GZSL) to address the problem of domain shift. The proposed method is based on the idea of progressive prototype networks (DPPNs) that construct prototypes for both attributes and categories to improve cross-domain transferability and category discriminability of visual representations. Specifically, DPPN alternately searches attribute-related local regions and updates corresponding attribute prototypes to progressively explore accurate attribute-region correspondence. Experiments on four benchmarks demonstrate that the proposed method achieves state-of-the-art performance."
SP:61eb6297568c3f6869fbb03eaf6a21260de5466c,"This paper presents an end-to-end deep learning approach for removing defocus blur from a single image, so as to have an all-in-focus image for consequent vision tasks. First, a pixel-wise Gaussian kernel mixture (GKM) model is proposed for representing spatially variant defocus kernels in an efficient linear parametric form, with higher accuracy than existing models. Then, a deep neural network is developed by unrolling a fixed-point iteration of the GKM-based deblurring. Extensive experiments show that the proposed method outperforms existing defocus debluring methods, but also has its advantages in terms of model complexity and computational efficiency."
SP:18bf447c90935c373e5ec4cdfbbf8f2a273d2edb,"This paper proposes a new method for self-supervised video representation learning (SSVRL) based on motion vectors from compressed videos. The proposed method is based on a cross-guidance contrastive learning algorithm, where the motion vectors can take supervision signals from RGB frames and vice versa. The method is evaluated on action recognition and action retrieval tasks and achieves state-of-the-art performance."
SP:8c7b1d976d9758cd534c565ec31a23f97892e503,"This paper proposes a method to mitigate overconfidence in ReLU nets around the training data, but far away from them, ReLU Bayesian neural networks (BNNs) can still underestimate uncertainty and thus be asymptotically overconfident. This issue arises since the output variance of a BNN with finitely many features is quadratic in the distance from the data region. Meanwhile, Bayesian linear models with ReLU features converge, in the infinite-width limit, to a particular Gaussian process (GP) with a variance that grows cubically so that no overconfidence can occur. This paper extends finite ReLU BNNs with infinite ReLU feature via the infinite GP and show that the resulting model is maximally uncertain far away, while the BNN’s predictive power is unaffected near the data."
SP:e77276f61626e896f6a985296f1d832129242cdf,"This paper considers the problem of identifying the best estimate of a causal quantity of interest among a set of available formulas in a sequential setting, where the investigator may alter the data collection mechanism in a data-dependent way with the aim to identify the formula with the lowest asymptotic variance in as few samples as possible. The authors formalize this setting by using the best-arm-identification bandit framework where the standard goal of learning the arm with lowest loss is replaced with the goal of finding the arm that will produce the best estimates. They introduce new tools for constructing finite-sample confidence bounds on estimates of the asymPTotic variance that account for the estimation of potentially complex nuisance functions, and adapt the best arm identification algorithms of LUCB and Successive Elimination to use these bounds. They validate their method by providing upper bounds on the sample complexity and an empirical study on artificially generated data."
SP:471361588bfc6c6033631509d1e43e77fd9721ce,"This paper studies the convergence of variance-reduced stochastic gradient descent algorithms for distributed learning. The authors show that adding back the previous step’s compression error does not fully compensate the compression error, and propose ErrorCompensatedX, which uses the previous two steps’ compression error to achieve the same asymptotic convergence rate with the training without compression. They also provide a unified theoretical analysis framework for this class of variance reduced algorithms, with or without error compensation. "
SP:3b7ff0dc668cac2191d95fcc4dc6e0335dec3206,"This paper proposes a method for explaining graph neural networks (GNNs). The proposed method, called ReFine, is based on the idea of pre-training and fine-tuning. In particular, ReFine first trains a GNN on a synthetic graph and then fine-tunes it on a real-world graph. The authors show that ReFine is able to explain a large fraction of the input graph, which is important for explaining the decision making process of GNNs. They also show that the proposed method is better at explaining graph classification than existing methods."
SP:9b5a62d3a2b27bc60da28980e9fb0ecdff1215c0,This paper proposes a method to generate counterfactual explanations for graph neural networks (GNNs) that are robust to noise and align well with human intuition. The main idea is to model the common decision logic of GNNs on similar input graphs and generate explanations that are naturally robust to the noise because they are produced from common decision boundaries of a GNN that govern the predictions of many similar input graph. The authors conduct extensive experiments on several public datasets to demonstrate the superior performance of the proposed method.
SP:4edb870786c9cea2c6075359cb4e79b02a8e2f5f,This paper proposes a self-supervised representation learning method for voice style transfer. The proposed method is based on the idea of information bottleneck and adversarial feedback to decompose content and style from the source speech. The discriminator is decomposed into a content discriminator and a style discriminator. Experiments show that the proposed method achieves better transfer performance than other baselines in both many-to-many and zero-shot style transfer scenarios. 
SP:9fbb0c6beb3f8f88972f13dcf0e1fe7db03233c7,This paper proposes a Siamese voxel-to-BEV tracker for 3D object tracking in sparse point clouds. The proposed method consists of a shape-aware feature learning network and a target localization network to capture 3D shape information of the object to learn the discriminative features. Extensive evaluation on the KITTI and nuScenes datasets shows that the proposed method significantly outperforms the current state-of-the-art methods by a large margin.
SP:8b788c78680a54c453a04f4551436763ee57585e,"This paper proposes a positional encoding method based on learnable learnable Fourier features for multi-dimensional position encoding. The proposed method is based on a multi-layer perceptron, which is modulated with a learnable feature mapping. The method is parameter-efficient and can handle test samples with arbitrary length. Experiments show that the proposed method outperforms existing methods by both improving the accuracy and allowing faster convergence."
SP:d2ac1b6381315bce4449f09bd519f33a2a42d714,"This paper studies the problem of learning the causal MAG of a system from observational data in the presence of latent variables and selection bias. The authors propose a computationally efficient recursive constraint-based method that is sound and complete. The key idea of their approach is that at each iteration a specific type of variable is identified and removed. This allows us to learn the structure efficiently and recursively, as this technique reduces both the number of required conditional independence (CI) tests and the size of the conditioning sets. The former substantially reduces the computational complexity, while the latter results in more reliable CI tests."
SP:49a4912ce457f5f5ec62c44fa10444af8075fabf,"This paper proposes a batch Thompson Sampling algorithm for stochastic multi-arm bandit and linear contextual bandit problems. The algorithm is based on Thompson sampling, which is a Thompson sampling algorithm that uses Thompson sampling to sample from a batch of Thompson samples. The authors show that the algorithm can achieve near-optimal regret guarantees while reducing the number of sequential interactions with the environment from T to O(log T). The algorithm uses a dynamic batch allocation mechanism that determines the duration of each batch based on an offline estimation of the regret accumulated during that phase."
SP:653a519e3c799c25e0d0b4240322642040b121a3,"This paper studies the problem of learning domain-invariant representations in multiple source domain adaptation (MSDA) and domain generalization (DG) settings. The main contribution of this paper is a theoretical analysis of the trade-off of learning representation learning in MSDA and DG. Theoretical bounds for the target general loss are provided for two kinds of representation learning: one for source DA and one for target DA. Theorems 1 and 3 are developed for the source DA setting and Theorem 8 is developed for target DG setting. Experiments on MNIST, CIFAR-10, and ImageNet show the effectiveness of the proposed method. "
SP:2a7bee950cd07494d59dfee60ac2e86cc0e481b1,"This paper proposes an aligned structured sparsity learning (ASSL) method for lightweight image super-resolution (SR) networks. The authors propose a weight normalization layer and L2 regularization to the scale parameters for sparsity. To align the pruned filter locations across different layers, they propose a sparsity structure alignment penalty term, which minimizes the norm of soft mask gram matrix. The proposed method achieves superior performance gains over SOTA lightweight image SR methods."
SP:e9830bb9e7d3ddc3bd1c2994590fdb5d8f3668be,"This paper proposes an intrinsic reward for multi-agent reinforcement learning based on the observation that individual Q-values are the embeddings of local action-observation histories and can capture the interaction between agents due to reward backpropagation during centralized training. The authors propose to use prediction errors as intrinsic rewards for coordinated exploration and utilize episodic memory to exploit explored informative experience to boost policy training. Empirical results show that the proposed intrinsic reward can guide agents’ policies to novel or promising states, thus enabling effectively coordinated exploration."
SP:c7e33d479575c88e22282ee6fd4f978bcd3c06ed,"This paper studies the problem of list-decodable linear regression, where an adversary can corrupt a majority of the examples. The goal is to output a small list of hypothesis vectors such that at least one of them is close to the target regression vector. The main result is a Statistical Query (SQ) lower bound of d for this problem. The SQ lower bound qualitatively matches the performance of previously developed algorithms, providing evidence that current upper bounds for this task are nearly best possible."
SP:7b258252a9063514348f5fa8d9c85afd85748747,"This paper proposes a hybrid model for predicting patient health status and disease progression over time, where a wealth of domain knowledge is available from pharmacology. The model is based on a pharmacological model that describes the dynamics of carefully-chosen medically meaningful variables in terms of systems of Ordinary Differential Equations (ODEs). However, these models only describe a limited collection of variables, and these variables are often not observable in clinical environments. To close this gap, the authors propose the latent hybridisation model (LHM) that integrates a system of expert-designed ODEs with machine-learned Neural ODE models. The proposed method is evaluated on synthetic data as well as real-world intensive care data of COVID-19 patients, where it consistently outperforms previous works."
SP:3ea9e86e5755ef84d28e3163c60531ace5d62e3a,"This paper presents a theoretical framework for analyzing a MAML-like algorithm, assuming all available tasks require approximately the same representation. The authors provide risk bounds on predictors found by finetuning via gradient descent, demonstrating that the method provably leverages the shared structure. In contrast, the authors establish settings where learning one representation for all tasks (i.e. using a “frozen representation” objective) fails."
SP:8ba5a2ac80f7c53f81ad008e96c033ecad14ac0d,"This paper presents Grammar-based Grounded Lexicon Learning (G2L2), a lexicalist approach to learn a compositional and grounded meaning representation of language from grounded data, such as paired images and texts. At the core of the approach is a collection of lexicon entries, which map each word to a syntactic type and a neuro-symbolic semantic program. To facilitate learning in an exponentially growing compositional space, the authors introduce a joint parsing and expected execution algorithm, which does local marginalization over derivations to reduce the training time. The proposed method is evaluated on two domains: visual reasoning and language-driven navigation."
SP:16c458651815813efdcbe8ba1205bbddbe3e4e68,"This paper proposes a stochastic Newton algorithm for homogeneous distributed stochastically convex optimization, where each machine can calculate the same population objective. The authors provide convergence guarantees for quasi-self-concordant objectives (e.g., logistic regression) and show that their method can reduce the number, and frequency, of required communication rounds compared to existing methods without hurting performance. They also provide empirical evidence to support their claims."
SP:d7e479d59f82d4c55372a68ca7b4516f2871f346,"This paper proposes Density-aware Chamfer Distance (DCD) to evaluate point cloud completion tasks. The proposed metric is based on Chamfer distance (CD) and Earth Mover’s Distance (EMD) which are two widely used metrics for measuring the similarity between two point sets. However, CD is usually insensitive to mismatched local density, and EMD is usually dominated by global distribution while overlooks the fidelity of detailed structures. To tackle these problems, the authors propose a new similarity measure named D density-aware (Density-Aware Chamfer distance) which is derived from CD and benefits from several desirable properties: 1) it can detect disparity of density distributions and is thus a more intensive measure of similarity compared to CD; 2) it is stricter with detailed structures and significantly more computationally efficient than EMD; 3) the bounded value range encourages a more stable and reasonable evaluation over the whole test set; 4) a novel point discriminator module that estimates the priority for another guided downsampling step, and it achieves noticeable improvements under DCD together with competitive results for both CD and E MD."
SP:e4b302009520770814ff2c096020b779a9fc38fe,"This paper studies the problem of knowledge distillation, which is a popular technique for training a small student network to emulate a larger teacher model, such as an ensemble of networks, to improve student generalization. The authors show that there often remains a surprisingly large discrepancy between the predictive distributions of the teacher and the student, even in cases when the student has the capacity to perfectly match the teacher. They identify difficulties in optimization as a key reason for why the student is unable to match the teachers. They also show how the details of the dataset used for distillation play a role in how closely the student matches the teacher — and that more closely matching the teacher paradoxically does not always lead to better student generalisation."
SP:895c7e03f9e4dadb94be1f39d61bf0b5e1533f4f,"This paper studies the problem of learning a k-decision tree, which is a recursive partition of a matrix (2D-signal) into k-1 block matrices (axis-parallel rectangles, leaves) where each rectangle is assigned a real label. Given an error parameter $\� \in 0, 1$ and a (k,\varepsilon)-coreset C of D, the authors show that the optimal k-tree of C is a (1 + \�)-approximation to the optimal decision tree of D up to a multiplicative factor of 1/\epsilon. The authors also show that applying their coresets on real-world data-sets boosts the computation time of random forests and their parameter tuning by up to x10, while keeping similar accuracy. "
SP:f3ece96b15ec06d703925df2061ed9694ec3bca5,"This paper studies the problem of best-arm identification for linear bandit models with misspecified linear models under a fixed error rate $\delta$. The authors derive a tractable lower bound on the sample complexity of any $d$-correct algorithm for the general Top-m identification problem. They show that knowing the scale of the deviation from linearity is necessary to exploit the structure of the problem. The authors then describe the first algorithm for this setting, which is both practical and adapts to the amount of misspecification. They also derive an upper bound to its sample complexity which confirms this adaptivity and matches the lower bound when $\d = 0$. Finally, they evaluate their algorithm on both synthetic and real-world data, showing competitive performance with respect to existing baselines."
SP:e71c5e39b8d8d1640d6de2352ac51ddd52eea89d,"This paper proposes a method for learning disentangled graph representations with self-supervised learning. The proposed method is based on the idea of factorized representation learning, where the representation of the input graph is determined by the latent factors of the graph. The authors propose a novel factor-wise discrimination objective in a contrastive learning manner to force the factorized representations to independently reflect the expressive information from different latent factors. Extensive experiments on both synthetic and real-world datasets demonstrate the superiority of the proposed method."
SP:0a7edbbdabab11273689c40c517001eb46491113,This paper proposes a method to assess the robustness of a trained network to input uncertainties with a stochastic simulation inspired by the field of Statistical Reliability Engineering. The robustness assessment is cast as a statistical hypothesis test: the network is deemed as locally robust if the estimated probability of failure is lower than a critical level. The procedure is based on an Importance Splitting simulation generating samples of rare events. Theoretical guarantees are derived that are nonasymptotic w.r.t. sample size. Experiments tackling large scale networks outline the efficiency of the method making a low number of calls to the network function.
SP:c1db485ff1ff9573daa421e167225654babb55ac,"This paper proposes CoPE, a polynomial neural network (PNN) architecture for conditional image generation. CoPE is based on polynomials of two input variables, i.e., the noise variable and the conditional variable. The authors show how CoPE can be trivially augmented to accept an arbitrary number of input variables. They evaluate CoPE on five tasks (class-conditional generation, inverse problems, edges to image translation, image-to-image translation, and attributeguided generation) on eight datasets. They show that CoPE outperforms single-variable PNNs on all tasks."
SP:5a75bc7a3ea0ce971cfceebbc1c2434e3aa2584d,"This paper proposes a neural tangent kernel (NTK) based method to compute the MMD statistic and perform NTK based two-sample tests. Theoretical analysis is provided to understand the NTK test statistic properties, such as the Type-I error and testing power for performing the two- sample test, by adapting existing theories for kernel MMD. Experiments on synthetic and real-world datasets validate the theory and demonstrate the effectiveness of the proposed NTK-MMD statistic."
SP:1df2ffbbe56b8018067820980b93af2a8b57f891,"This paper proposes a class-disentanglement method to extract the minimum necessary information required by a neural net D(·) from an image x to accurately predict its class. The proposed method trains a variational autoencoder to extract this class-dependent information via a trade-off between reconstructing x by G(x) and classifying x by D(x-G(x)), where the former competes with the latter in decomposing x so that the latter retains only necessary information for classification in x-g(x). They apply it to both clean images and their adversarial images and discover that the perturbations generated by adversarial attacks mainly lie in the class-dependent part of x. They also provide novel interpretations to classification and attack models, and propose to conduct adversarial detection and adversarial defense respectively on x."
SP:2789874561620ba7894c4672f935056bb911e919,This paper proposes a differentially private federated Thompson sampling (FTS) algorithm with distributed exploration (DE) for Bayesian optimization (BO) in the federated learning setting. The proposed algorithm is the first algorithm with a rigorous guarantee on the user-level privacy in the FBO setting. This paper provides theoretical guarantees for both the privacy-utility trade-off and empirically shows that DP-FTS-DE achieves high utility (competitive performance) with a strong privacy guarantee (small privacy loss). 
SP:be7d6b81736a2c3f89abd8771b41b18802e88832,"This paper proposes a method for multi-label active learning (ML-AL) based on Gaussian process-Bayesian Bernoulli Mixture model (GP-BM) to quantify a data sample’s overall contribution to a correlated label space and choose the most informative samples for cost-effective annotation. In particular, the BM encodes label correlations using a Bayesian mixture of label clusters, where each mixture component corresponds to a global pattern of label correlations. A novel auxiliary variable based variational inference algorithm is developed to tackle the non-conjugacy introduced along with the mapping process for efficient end-to-end posterior inference. A principled sampling function is designed accordingly to capture both the feature uncertainty (through GP) and label covariance (through BM) for effective data sampling. Extensive experiments on both synthetic and real-world datasets demonstrate the state-of-the-art AL performance of the proposed model."
SP:2b7270b0370c193300bcbbb5fb0a4101b3329d99,This paper proposes to use a polar coordinate system to improve the end-to-end latency of lidar perception models. The proposed method uses a multi-scale padding method to increase the spatial context by using neighboring sectors from the current scan and/or the following sector from the past scan. The authors also improve the core polar convolutional architecture by introducing feature undistortion and range stratified convolutions. Experimental results on the nuScenes dataset show significant improvements over other streaming based methods. 
SP:7ae2c5b7d9c8a6c8f4a353606aa419929c47f31b,"This paper extends the Gumbel-Max trick to define distributions over structured domains by leveraging the score function estimators for optimization. In particular, they highlight a family of recursive algorithms with a common feature we call stochastic invariant. The feature allows us to construct reliable gradient estimates and control variates without additional constraints on the model. In the experiments, they consider various structured latent variable models and achieve results competitive with relaxation-based counterparts."
SP:415d363c66a6967c1daca9dc02001b85bf7f0752,"This paper proposes GainTuning, a method for adapting CNN denoisers trained on large datasets to a single test image. To avoid overfitting, the proposed method optimizes a single multiplicative scaling parameter (the “GainTuning”) of each channel in the convolutional layers of the CNN. The proposed method is evaluated on standard image-denoising benchmarks, boosting their denoising performance on nearly every image in a held-out test set. Empirical results demonstrate the effectiveness of the method."
SP:90afa1102683b456bc72a54abef466326827546a,This paper proposes a differentiable architecture for semantic and instance segmentation (a.k.a. panoptic segmentation) consisting of a convolutional neural network and an asymmetric multi-way cut problem solver. The latter solves a combinatorial optimization problem that elegantly incorporates semantic and boundary predictions to produce a pan-optic labeling. The formulation allows to directly maximize a smooth surrogate of the quality metric by backpropagating the gradient through the optimization problem. Experimental results on Cityscapes and COCO datasets show the effectiveness of the proposed method.
SP:1952e174d9ec7b83ad1d394ece7fe77ea1f6d78d,"This paper proposes Recursive Bayesian Networks (RBNs), which generalize and unify PCFGs and DBNs, combining their strengths and containing both as special cases. The main challenge lies in performing joint inference over the joint distribution over the marginal data likelihood (evidence) and marginal posterior distribution, allowing for robust parameter optimisation and Bayesian inference. The RBNs can be applied to continuous latent variables and also to nested hierarchical dependency structure. The proposed method is evaluated on synthetic data and an application to hierarchical music analysis. "
SP:5f29b169d3e4bbaeeec85e1aeebe2094fae4be6e,"This paper proposes a constrained backpropagation (CBP) algorithm based on the pseudo-Lagrange multiplier method to obtain the optimal set of weights that satisfy a given set of constraints. The proposed algorithm is the utilization of a Lagrangian function (loss function plus constraint function) as its objective function. The authors considered various types of constraints — binary, ternary, one-bit shift, one bit shift, and two bit shift weight constraints. Experiments show that the proposed algorithm outperforms the state-of-the-art methods on ImageNet."
SP:3ddf8e2e108fb261bb23aec8a27a25aba7523dc1,"This paper studies active learning for Gaussian Process Classification (GPC) in the setting of query synthesis. In this setting, the goal of active learning is to select the best instance for labeling by optimizing an acquisition function to enhance data/label efficiency. The selection can be either from a discrete instance set (pool-based scenario) or a continuous instance space (query synthesis scenario). The main contribution of this paper is to develop efficient algorithms for EER-based active learning with GPC. The authors derive the joint predictive distribution of label pairs as a one-dimensional integral, as a result of which the computation of the acquisition function avoids retraining the GPC for each query, remarkably reducing the computational overhead. They also derive the gradient chain rule to efficiently calculate the gradient of acquisition function, which leads to the first query synthesis active learning algorithm."
SP:fa1fac04cd4ccb1f3eaf80807db09f9683ce6b50,"This paper studies the effect of unbounded gradients in continuous variational autoencoder (VAE) models on the regularization of VAE-based architectures, including VAE models, as applied to data lying on or near a low-dimensional manifold (e.g., natural images). The main finding is that, if the ultimate goal is to simultaneously avoid over-regularization (excessive latent dimensions are not pruned from the model) and under-regularized latent dimensions, then the energy function with infinite gradients around optimal representations is provably required per a certain technical sense. This result suggests that heuristic modifications to or constraints on the VAE energy function may at times be ill-advised, and large gradients should be accommodated to the extent possible."
SP:2611cfd6e0696a57d061687993cef1fe5c95999d,"This paper studies the min-max regret of the bandit problem with graph feedback. The authors propose two notions of the fractional weak domination number and the k-packing independence number capturing upper bound and lower bound for the regret respectively. They show that the two notions are inherently connected via aligning them with the linear program of the weakly dominating set and its dual. Based on this connection, they prove a general regret upper bound O(\delta_1/\varepsilon) and a lower bound $\tilde{O}(\delta_{\textrm{k}(k)}(k))$ for graphs with bounded integrality gap. They also show that for several special families of graphs, they can get rid of the (log |V |) 1 3 factor and establish optimal regret."
SP:e50dec57af337839cbde4b65fb7b431785fda44d,"This paper proposes to use neighbourhood reference distributions to improve the local interpretability of Shapley values for model agnostic feature attributions for model outcome at a particular instance by simulating feature absence under a global population distribution. The authors show that the Nadaraya-Watson estimator, a well-studied kernel regressor, can be expressed as a self-normalised importance sampling estimator. Empirically, the Neighbourhood Shapley Values identify meaningful sparse feature relevance attributions that provide insight into local model behaviour, complimenting conventional Shapley analysis. They also increase on-manifold explainability and robustness to the construction of adversarial classifiers."
SP:35bdeb78f9fe74e754177fb54b48e7399dc8590d,"This paper proposes PlayVirtual, which augments cycle-consistent virtual trajectories to enhance the data efficiency for RL feature representation learning. Specifically, PlayVirtual predicts future states in a latent space based on the current state and action by a dynamics model and then predicts the previous states by a backward dynamics model, which forms a trajectory cycle. Based on this, the authors augment the actions to generate a large amount of virtual state-action trajectories. The proposed method achieves the state-of-the-art performance on the Atari and DMControl Suite benchmarks."
SP:ca09e472cbcf2ac8c8c9b192a87df2ed59218210,"This paper studies the relationship between network architecture and robustness to noisy labels. The authors propose a framework to connect the robustness of a network to the alignments between its architecture and target/noise functions. They provide both theoretical and empirical evidence across various neural network architectures and different domains to support their hypothesis. They also find that when the network is well-aligned with the target function, its predictive power in representations could improve upon state-of-the-art (SOTA) noisy-label-training methods in terms of test accuracy."
SP:903727fe028684623a8ccadec210e641ecffc685,"This paper proposes an algorithm for off-policy example-based control that learns to predict whether the task will be solved in the future via classification, without using separate reward learning and policy search procedures. The key idea is to directly learn a value function from transitions and successful outcomes, without learning this intermediate reward function. The authors show that their method satisfies a new data-driven Bellman equation, where examples take the place of the typical reward function term. Empirically, their method significantly outperforms state-of-the-art imitation learning methods (AIRL, DAC, and SQIL) and recent methods that learn reward functions (ORIL, PURL, and VICE)."
SP:39ccbd5909a1d7ed212fe92d8d6843c2c70dfe1f,"This paper studies differentially private stochastic optimization in convex and non-convex settings. For the convex case, the algorithm achieves optimal excess population risk in near-linear time, while the best known algorithms for general convex losses run in super- linear time. The algorithm for the l1-case with smooth losses and polyhedral constraint has nearly-optimal excess risk, and circumvents the dimension dependent lower bound of [AFKT21] for general non-smooth convex loss. In the l2-case, the authors provide the first nearly-dimension independent rate, which matches the best existing non-private algorithm when d = O(\sqrt{n})$. "
SP:99a476f71e6901aefe281f11fb72ff78265a5b6e,"This paper studies the cooperative bandit learning problem with stochastic time-varying networks, message-passing with adversarial corruptions, and instantaneous reward-sharing over a network with random delays, and adversarially corrupted rewards. The authors propose decentralized algorithms that achieve competitive performance, along with near-optimal guarantees on the incurred group regret as well. The proposed algorithms are straightforward to implement and obtain competitive empirical performance. "
SP:d3e896a65470f2439bc7753b4f66e152306b2d6f,"This paper proposes a post-training quantization algorithm for vision transformers to reduce the memory storage and computational costs. To preserve the functionality of the attention mechanism, the authors introduce a ranking loss into the conventional quantization objective that aims to keep the relative order of the self-attention results after quantization. The authors also analyze the relationship between quantization loss of different layers and the feature diversity, and explore a mixed-precision quantization scheme by exploiting the nuclear norm of each attention map and output feature. The proposed method is verified on several benchmark models and datasets, which outperforms the state-of-the-art post training quantization algorithms."
SP:aa6b1328585b5916267a3ff4f9119e7aa4ce2bb5,"This paper studies the convergence rate of double-Q-learning in the case of constant learning rate. The authors show that synchronous double Q-learning attains an accurate global optimum with a time complexity of $\tilde{O}(\sqrt{L}(1-\gamma^{-7})$, where L is the cardinality of the state-action space, $\gamma$ is the discount factor, and $L$ is a parameter related to the sampling strategy for asynchronous double Q learning. They also show that the synchronous algorithm attains a global optimum of $O(1/L^2)$ with a complexity of $L_1$ (1-L^7)$, and the asynchronous algorithm achieves a complexity $L_{1/2}$ with $L^{-1}$ complexity. The convergence rate is improved by an order of magnitude."
SP:04fd4d83717c4f7e1a4b5651a59200151f33411d,"This paper proposes a method for semi-supervised OOD detection, where the goal is to detect out-of-distribution (OOD) samples from an unknown distribution. The proposed method, called STEP, is based on the structure-keep-unzipping (STU) algorithm, which learns a new representation space in which OOD samples could be separated well. Experiments show that STEP outperforms other methods by a large margin and achieves remarkable detection performance on several benchmarks."
SP:6bf8b94483b26033795b0eda9649518027f5e1c2,"This paper proposes a simple one-stage multi-task framework for visual grounding tasks for referring expression comprehension and segmentation. The proposed method is based on a transformer architecture, where two modalities are fused in a visual-lingual encoder. In the decoder, the model learns to generate contextualized lingual queries which are then decoded and used to directly regress the bounding box and produce a segmentation mask for the corresponding referred regions. Experiments show that the proposed method outperforms state-of-the-art methods on both REC and RES tasks."
SP:29b552b36696c9bda72f3ab4f31605d98880fd6b,"This paper studies the problem of multiclass boosting, where the weak learner is assumed to belong to an easy-to-learn base class and the weak learners are an agnostic PAC learner for that class with respect to the standard classification loss. The goal of the overall boosting algorithm is then to learn a combination of weak hypotheses by repeatedly calling the weakLearner repeatedly. The authors prove that the number of samples required by a weak-learner is at least polynomial in k, exponentially more than the number needed by the booster. They also prove a tradeoff between number of oracle calls and the resources required of the weak Learner."
SP:f63b050773871338c48b778c362172e4b72477a4,"This paper proposes a method for unsupervised object segmentation and object-centric scene generation. The proposed method is based on embedding-based clustering, where embeddings of pixels are clustered in a differentiable fashion using a stochastic stick-breaking process. Similar to iterative refinement, this clustering procedure also leads to randomly ordered object representations, but without the need of initialising a fixed number of clusters a priori. This is used to develop a new model, GENESIS-V2, which can infer a variable number of object representations without using RNNs. The experimental results show that the proposed method outperforms recent baselines in terms of image segmentation, image generation, and scene generation on both synthetic and real-world datasets."
SP:408deb9e5577ee7118b836fee77135df641fe545,This paper proposes a method for forming prediction sets in an online setting where the data generating distribution is allowed to vary over time in an unknown fashion. The distribution shift is modeled as a learning problem in a single parameter whose optimal value is varying over time and must be continuously re-estimated. This paper builds on ideas from conformal inference to provide a general wrapper that can be combined with any black box method that produces point predictions of the unseen label or estimated quantiles of its distribution. The proposed method is tested on two real world datasets and finds that its predictions are robust to visible and significant distribution shifts.
SP:e6e5b1e2428abcf1a163ec1cce15cd299f9a544f,"This paper proposes a Pose-level Inference Network (PINet) for multi-person pose estimation in crowded scenes. PINet first applies the Part-based Pose Generation (PPG) to infer multiple coarse poses for each person from his/her body parts. Those coarse poses are refined by the Pose Refinement module through incorporating pose priors, and finally are fused in the Pose Fusion module. Experiments on several crowded scenes pose estimation benchmarks demonstrate the superiority of PINet."
SP:e76f048c3dccffcb8bcc6a66f6165fc19d175610,This paper proposes an exact algorithm for computing the Bellman operator for S-rectangular robust Markov decision processes with L-constrained rectangular ambiguity sets. The algorithm combines a novel homotopy continuation method with a bisection method to solve the ambiguity in quasi-linear time in the number of states and actions. The proposed algorithm improves on the cubic time required by leading general linear programming methods by several orders of magnitude. 
SP:c4af66a64a5c2bd58ca2e29dbc4b27d5bf4b63b8,This paper studies the online knapsack problem with very weak predictions. The authors derive online algorithms that attain the best possible competitive ratio for any fixed prediction. They also extend the results to more general settings such as generalized one-way trading and two-stage onlineknapsack. 
SP:1d478d4fa3f5df0ded963ef164325667fd744dbb,"This paper proposes a model-based episodic memory of trajectories to address the limitations of episodic control. The memory estimates trajectory values, guiding the agent towards good policies. A complementary learning model via a dynamic hybrid control is also proposed. Experiments demonstrate that the proposed model allows significantly faster and better learning than other strong reinforcement learning agents across a variety of environments."
SP:551174c1266b5f4b6aaf5432a4c713386f90898c,"This paper proposes a new semi-supervised learning method for unlabeled data. The proposed method, DP-SSL, is based on a data programming scheme to generate probabilistic labels for unlabelled data. In particular, the authors propose a multiple-choice learning (MCL) based approach to automatically generate LFs from scratch in SSL style. The noisy labels produced by the LFs are used to design a label model to resolve the conflict and overlap among the noisy labels. Extensive experiments on four standard SSL benchmarks show that the proposed method achieves better classification performance than existing SSL methods, especially when only a small number of labeled samples are available."
SP:d1d6a40a8bde62a21da4fc18a076e344c84ab0d0,"This paper proposes a multi-view pose transformer (MVPT) model for estimating multi-person 3D poses from multiple views. The proposed MVPT is a direct regression model that directly regresses the 3D joint locations from the multi-views images. To improve the accuracy of the proposed model, the authors propose a hierarchical scheme to represent query embeddings of multi-people skeleton joints and introduce an input-dependent query adaptation approach to improve the performance. Experiments on the Panoptic dataset show that the proposed method outperforms the state-of-the-art methods."
SP:2e147bd5321e25bb27d2531fd58c46460a1e5320,"This paper studies the problem of learning the supports of unknown sparse vectors from a family of sparse vectors, where each vector has at most k non-zero elements. In the first problem, the authors use a sequence of noisy responses to learn the support of all the vectors from the family. The support recovery problem is a generalization of support recovery and approximate recovery problems, well-studied under the framework of 1-bit compressed sensing. The authors also show the existence of learning algorithms for the second problem and analyze their query complexity. "
SP:e3388e479a825be429f3a878e2c4d8b05903ff10,"This paper proposes a method to detect abrupt changes in temporal behavior patterns. The proposed method is motivated by the bandit quickest changepoint detection problem, where sensing actions (or sensors) are sequentially chosen, and only measurements corresponding to chosen actions are observed. The authors derive an information-theoretic lower bound on the detection delay for a general class of finitely parameterized probability distributions. They then propose a computationally efficient online sensing scheme, which seamlessly balances the need for exploration of different sensing options with exploitation of querying informative actions. They derive expected delay bounds for the proposed scheme and show that these bounds match the lower bounds at low false alarm rates. "
SP:268260e9452ba2bc57e50a6b7b3328233137ac9b,"This paper proposes a new algorithm for solving stochastic nested nested optimization problems. The algorithm is based on alternating SGD updates on multiple variables. The main contribution of this paper is to provide a tighter analysis of the convergence rate of the proposed algorithm, ALSET, for solving nested nested problems. In particular, the paper shows that under certain regularity conditions, the proposed method can achieve a convergence rate that matches the best-known sample complexity in the nested problem setting."
SP:82ad52361bc5b2c421f1dc6b76e1a5520570fc6c,"This paper proposes a Siamese Sampling and Reasoning (SiaSamRea) method for video question answering (VQA) task. The proposed method consists of a siamese sampling mechanism to generate sparse and similar clips from the same video, and a reasoning strategy to integrate the interdependent knowledge between contextual clips into the network inference. Extensive experiments demonstrate the effectiveness of the proposed method. "
SP:160022e2cd61159da92f92e85520b7062a337a8d,"This paper proposes a method to reduce the computational and memory complexity of a large class of structured models by using a low-rank constraint. The main idea is to view the central inference step as a matrix-vector product and use a low rank constraint to trade off model expressivity and speed via the rank. Experiments on language modeling, polyphonic music modeling, unsupervised grammar induction, and video modeling show that the proposed method matches the accuracy of standard models while providing practical speedups."
SP:238592ad73927194cdf0c0cf9ae2e48ca86e182c,"This paper proposes Sample Average Uncertainty (SAU), a simple and efficient uncertainty measure for deep contextual bandits. The proposed SAU is a frequentist approach that directly estimates the uncertainty of the outcomes based on the value predictions. The authors show theoretically that the uncertainty measure estimated by SAU matches the uncertainty provided by Thompson Sampling, as well as its regret bounds. Empirically, the authors show that SAU-based exploration outperforms current state-of-the-art deep Bayesian bandit methods on several real-world datasets at modest computation cost."
SP:ffc5b18f7e18607b2934e5aa199e7542005d79f4,"This paper proposes a method to learn behavioral embeddings from video data. The method is based on disentangling the dynamic behavioral factors (pose) from time-invariant, non-behavioral nuisance factors (context) in a deep autoencoder, and exploit the temporal structures of pose dynamics. The proposed method is applied to both continuous and discrete latent representations for simultaneous embedding and segmentation within the same model. "
SP:bf78a450e4aad6b87fdeb8ec0d68adaaff7b595b,"This paper proposes DMTET, a deep 3D conditional generative model that can synthesize high-resolution 3D shapes using simple user guides such as coarse voxels. It marries the merits of implicit and explicit 3D representations by leveraging a novel hybrid 3D representation. Compared to the current implicit approaches, which are trained to regress the signed distance values, the proposed method directly optimizes for the reconstructed surface, which enables us to synthesize finer geometric details with fewer artifacts. The core of the proposed model is a deformable tetrahedral grid that encodes a discretized signed distance function and a differentiable marching tetrahedra layer that converts the implicit signed distance representation to the explicit surface mesh representation. "
SP:2bc0bd6aa2a12691b16145f0d23542c4c86e3a44,"This paper proposes sliced mutual information (SMI) as a surrogate measure of dependence. SMI is defined as an average of MI terms between one-dimensional random projections. The authors show that SMI preserves many of the structural properties of classic MI, while gaining scalable computation and efficient estimation from samples. This enables leveraging SMI for feature extraction by optimizing it over processing functions of raw data to identify useful representations thereof."
SP:e220b348901b476c2afd95f97630fb5400582f40,"This paper proposes a two-step constrained Bayesian optimization acquisition function (2-OPT-C) for non-myopic acquisition functions. The proposed method is based on a likelihood-ratio-based unbiased estimator of the gradient of the two step optimal acquisition function that does not use the reparameterization trick. In numerical experiments, the proposed method improves query efficiency by 2x or more over previous methods. "
SP:51fbd861422647912f275b48861ea3c4812afdc8,"This paper proposes Multi-Dimensional Distributional Distributional DQN (MD3QN), which extends distributional RL to model the joint return distribution from multiple reward sources. The proposed method can capture not only the randomness in returns for each source of reward, but also the rich reward correlation between the randoms of different sources. In experiments, the proposed method outperforms previous RL methods utilizing multi-dimensional reward functions in the control setting."
SP:1f85c93d6bbfd65bf497c92c9cd534d799753097,"This paper proposes a method for 3D surface reconstruction from 3D images. The proposed method is based on a flow-based method for generating 3D shapes from a 3D image, where the model is trained to deform a reference template towards a target object. To reduce the topological errors introduced by its discrete resolution, the authors derive numeric conditions to improve the manifoldness of the predicted triangle mesh. The method is evaluated on the task of brain cortical surface reconstruction. "
SP:2f31d9cf4ad17ad08344439ca0aef7ec91944545,"This paper studies the problem of data deletion in the non-convex setting. In particular, the authors consider the case where a user deletes a data point as a function of the published model and then updates the model with the deleted data points. The authors provide a general reduction from deletion guarantees against adaptive sequences to deletion guarantees for non-adaptive sequences. They also provide a new algorithm that is able to handle arbitrary model classes and training methodologies. "
SP:7150006590e268ab732c9be6c9048f67a377f956,This paper studies the problem of optimising the conditional value at risk (CVaR) of the total return in Bayes-adaptive Markov decision processes (MDPs). The authors show that a policy optimising CVaR in this setting is risk-averse to both the epistemic uncertainty due to the prior distribution over MDPs and the aleatoric uncertainty. The authors reformulate the problem as a two-player stochastic game and propose an approximate algorithm based on Monte Carlo tree search and Bayesian optimisation. The experiments demonstrate that the proposed algorithm significantly outperforms baseline approaches for this problem.
SP:a94f39406f73d7483ddd744ed2f03c78b8bc5d44,"This paper studies the behavior of deep networks trained with the logistic loss via gradient descent on binary classification data where the underlying data distribution is general, and the (optimal) Bayes risk is not necessarily zero. In this setting, it is shown that gradient descent with early stopping achieves population risk arbitrarily close to optimal in terms of not just logistic and misclassification losses, but also the sigmoid mapping of its outputs approximates the true underlying conditional distribution arbitrarily finely. Moreover, the necessary iteration, sample, and architectural complexities of this analysis all scale naturally with a certain complexity measure of the true conditional model. Finally, any univariate classifier satisfying a local interpolation property is inconsistent."
SP:a9c786cbb61e1f10f3542161b13e43a1a68ab34d,"This paper proposes a method for coordinated group detection on social media based on neural temporal point process with prior knowledge. Specifically, the authors jointly learn a Gibbs distribution of group assignment based on how consistent an assignment is to the account embedding space and the prior knowledge, and use a theoretically guaranteed variational inference approach to learn a mean-field approximation of the observed data likelihood. Experimental results on a real-world dataset show the effectiveness of the proposed method compared to state-of-the-art model in both unsupervised and semi-supervised settings. The detection result suggests presence of suspicious coordinated efforts on spreading misinformation about COVID-19 vaccines."
SP:b5c6e967a26a02861db2ecd620e9061db0c03e59,"This paper studies the problem of binary classification in a neural tangent kernel (NTK) regime, where the network depth plays the role of a fitting resource in solving the classification problem. The authors show that when the depth of the network is sufficiently large relative to intrinsic properties of the data, the NTK can be locally approximated by a translationally invariant operator on the manifolds and stably inverted over smooth functions, which guarantees convergence and generalization. This is the first generalization guarantee for deep networks with nonlinear data that depends only on intrinsic data properties. "
SP:8f6bee3be43df6b6e80804974014caaafe08c49e,"This paper proposes ReACGAN, an extension of the Conditional Generative Adversarial Networks (cGAN) architecture that incorporates class information into GANs. The main contribution of this paper is two-fold. First, the authors identify that gradient exploding in the classifier can cause an undesirable collapse in early training, and projecting input vectors onto a unit hypersphere can resolve the problem. Second, they propose the Data-to-Data Cross-Entropy loss (D2D-CE) to exploit relational information in the data-labeled dataset. The experimental results on CIFAR-10, Tiny-ImageNet, CUB200, and ImageNet datasets show the effectiveness of the proposed method. "
SP:080e80746a87228b156408ff649ab7a17f44e92d,"This paper proposes an extensive form double oracle (XDO) algorithm for two-player zero-sum games that is guaranteed to converge to an approximate Nash equilibrium linearly in the number of infostates. Unlike PSRO, which mixes best responses at the root of the game, XDO mixes best response at every infostate. The authors also introduce Neural XDO (NXDO), where the best response is learned through deep RL. Experiments on a modified Leduc poker game and Oshi-Zumo show that XDO achieves a lower exploitability than CFR with the same amount of computation."
SP:bda04facef4f34679fc4e17b8ea1aae74c3d649f,"This paper proposes a permutation-invariant variational autoencoder for graph structured data. The proposed model indirectly learns to match the node order of input and output graph, without imposing a particular node order or performing expensive graph matching. The authors demonstrate the effectiveness of their proposed model for graph reconstruction, generation and interpolation and evaluate the expressive power of extracted representations for graph-level classification and regression."
SP:e17ea6aeba78c9dfc25596d8b35a2a4f1f1f6763,"This paper proposes to decouple the depth and scope of GNNs by first extracting a localized subgraph as the bounded-size scope, and then applying a GNN of arbitrary depth on top of the subgraph. The proposed method achieves significant accuracy improvement with orders of magnitude reduction in computation and hardware cost. Empirically, on seven graphs (with up to 110M nodes) and six backbone GNN architectures, the proposed SHADOW-GNN achieves significant performance gains. "
SP:4890f251db559a0a572afc66e0c1f899b577d9ff,"This paper studies the problem of approximating log-concave distributions with affine-coupling normalizing flows (affine-Coupling Flows). The authors show that any distribution can be approximated by affine coupling flows with a well-conditioned affine coupling flow. The authors also provide a theoretical analysis of the connection between affine flows and underdamped Langevin dynamics, Hénon maps, and stochastic differential equations. "
SP:5ffa81488ed1092deb89bd5e150fa146325057ce,"This paper proposes a method to solve the problem of coupons allocation in an online e-commerce market, where the goal is to allocate coupons within a fixed budget while maximizing users’ retention on the platform. The authors propose a budget constrained offline reinforcement learning and evaluation with λ-generalization (BCORLE(λ)) framework. Specifically, the proposed method can help enterprises develop a coupons allocation policy which greatly improves users' retention rate while ensuring the cost does not exceed the budget. The proposed method is based on the Lagrangian problem formulation of the proposed algorithm BCORLE, which is a combination of BCQ and batch-constrained Q-learning. "
SP:6b04cc7b4e45b9e65a1d34c15e3f75a2ef27d601,"This paper proposes a method for source-free domain adaptation (SFDA) where the source pretrained model is adapted to the target domain in the absence of source data. The method is based on the observation that target data, which might no longer align with the source domain classifier, still forms clear clusters. To capture this intrinsic structure, the authors define local affinity of the target data and encourage label consistency among data with high local affinity. They observe that higher affinity should be assigned to reciprocal neighbors, and propose a self-regularization loss to decrease the negative impact of noisy neighbors. The experiments show that the proposed method achieves state-of-the-art performance on several 2D image and 3D point cloud recognition datasets."
SP:ac1bf04ff782e5892a0bc5fe5949848ca8e731c2,"This paper proposes a method for learning representations from set-structured data by pooling a set of features into a fixed-dimensional representation. The proposed method, Pooling by Sliced-Wasserstein Embedding (PSWE), provides an exact Euclidean embedding for the (generalized) sliced-wasserstein (SW) distance between sets of samples based on the SW distance. Experiments on point cloud classification, graph classification, and image recognition tasks demonstrate the effectiveness of the proposed method. "
SP:6cb2f0cbc076f8680cb00411790629f8e1478053,"This paper proposes a family of RNNs that can be formulated using stochastic bilevel optimization (SBO) to solve the lower and upper-level optimization for learning hidden states and their hyperparameters, respectively. The authors prove that under mild conditions there is no vanishing or exploding gradient in training SBO-RNN. Empirically, the proposed method achieves better performance with fewer parameters, less training data, and much faster convergence. "
SP:d3a4300e21ca215334f256f0467a428470548fe4,"This paper proposes a learning-augmented online algorithm that makes decisions based on (potentially inaccurate) predicted lengths of the idle periods. The algorithm’s performance is near-optimal when predictions are accurate and degrades gracefully with increasing prediction error. A key ingredient in the algorithm is a new algorithm for the online ski rental problem in the learning augmented setting with tight dependence on the prediction error, and the theoretical findings are supported with experiments. "
SP:22aba6284123af0ecd6605ee4e89b351bd7e10a3,"This paper proposes a transferability measure for multi-source transfer learning problems that takes into account both the task similarities and the sample complexity of learning models taken into account. In particular, the authors consider the setting where the models learned from different tasks are linearly combined for learning the target task, and use the optimal combining coefficients to measure the transferability. Then, they demonstrate the analytical expression of this transferable measure, characterized by the sample sizes, model complexity, and the similarities between source and target tasks, which provides fundamental insights of the knowledge transferring mechanism and the guidance for algorithm designs. "
SP:0fb8dcf15e0d43547d566fdba7bc70b3bb600005,"This paper proposes a method for visual search based on visual asymmetry. The proposed method, called eccNET, takes a target and a search image as inputs and produces a sequence of eye movements until the target is found. The model integrates eccentricity-dependent visual recognition with target-dependent top-down cues. It is trained on augmented versions of ImageNet where the biases of natural images were either removed or reversed. The empirical results show that the proposed method can spontaneously reveal visual search asymmetry and qualitatively match the polarity of human behavior."
SP:f0cc968ea9da4884dcdaf6d0c75ea9f1511bdfc3,This paper studies the problem of training certifiable robust models against adversarial examples. The authors propose a new method for certifiable training with tighter bounds on the worst-case loss and smoothness of the loss landscape. They show that linear relaxation-based methods often have a landscape with favorable optimization properties. The proposed method achieves a decent performance under a wide range of perturbations. 
SP:a158f8772a9dada059ffd1d6d7838ed40d8483da,This paper studies the problem of online linear regression in the stochastic bandit setting. The main contribution of this paper is to derive regret bounds for online ridge regression and the forward algorithm. The regret bounds are based on the analysis of the expected regret of a linear regression algorithm with linear function approximations. The authors show that the proposed forward algorithm is more robust to the regularization parameter than the ridge algorithm. They also provide numerical experiments to illustrate their results. 
SP:17ff9a2133aebf2d1b1787e8efc49d709389c0e7,"This paper proposes two variants of the extragradient (EG) method for nonconvex-nonconcave problems. First, a two-time-scale variant of the EG method named EG+ is proposed under a smooth structured nonConvex nonConcave setting, with a slow O(1/k) rate on the squared gradient norm, where k denotes the number of iterations. Second, another variant of EG with an anchoring technique, named extra anchored gradient (EAG), is studied under smooth convex-concaves setting, yielding a fast $O(\sqrt{k}/k}$ rate on squared gradients. This paper further develops its backtracking line-search version, named FEG-A, for the case where the problem parameters are not available. The stochastic analysis of FEG is also provided. "
SP:4e38973033de24fc183c6112e1146f8eef0ddaea,"This paper studies the problem of uniformity testing for ranking data that consists of rankings over m items, where the alternative class is restricted to Mallows models. The authors show that uniform distribution can be distinguished from Mallows model with O(m 1/2) samples based on simple pairwise statistics, which allows us to test uniformity using only two samples, if m is large enough. They also consider uniformity test with central and local differential privacy (DP) constraints. "
SP:99a835191a3ba8372e391b6d3316e9b68e543295,"This paper proposes a score-based algorithm for learning directed acyclic graphs (DAGs), which is a general greedy algorithm that requires at most a polynomial number of score evaluations. The authors show that this algorithm is a special case of recent polynomials-time algorithms for learning DAGs, which can be interpreted as order-based algorithms. They also provide extensive experiments to show that the proposed algorithm indeed optimizes the score in a variety of settings. "
SP:b60989706296b963b6671c01f22384978a334be1,"This paper proposes a neural architecture dilation for adversarial robustness (NADAR) algorithm to improve the robustness of backbone convolutional neural networks (CNNs) that have a satisfactory accuracy over the natural data. The authors propose a dilation architecture to pursue a maximal robustness gain while preserving a minimal accuracy drop. They also apply a FLOPs-aware approach to optimize the architecture, which can prevent the architecture from increasing the computation cost of the network too much. Experimental results on real-world datasets and benchmark neural networks demonstrate the effectiveness of the proposed algorithm to balance the accuracy and robustness."
SP:77ed765e911a4e5f2bfba13cbd2403500a5d05e6,"This paper studies reward-free reinforcement learning with linear function approximation for episodic Markov decision processes (MDPs). In the exploration phase, the agent interacts with the environment and collects samples without the reward. In the planning phase, an agent is given a specific reward function and uses samples collected from the Exploration phase to learn a good policy. The authors propose a new provably efficient algorithm, UCRL-RFE under the Linear Mixture MDP assumption, where the transition probability kernel of the MDP can be parameterized by a linear function over certain feature mappings defined on the triplet of state, action, and next state. They show that to obtain an $\�-optimal policy for arbitrary reward function, the algorithm needs to sample at most $\tilde{O}(\Hd(H + d)episodes))$, where H is the length of the episode and d is the dimension of the feature mapping. They also propose a Bernstein-type bonus to further improve the efficiency. "
SP:28563ba0975f56ddb662cd46e85de78bb6024d36,"This paper proposes a method for forecasting future events based on seasonal patterns in real-world data streams. The proposed method is based on the Shifting Seasonal Matrix Factorization (SSMF) algorithm, which can adaptively learn multiple seasonal patterns (called regimes) as well as switching between them. The method works in an online setting, i.e., processes each observation in constant time and memory, and realizes regime shifts without human intervention by using a lossless data compression scheme. The results show that the proposed method can accurately forecast future events by detecting regime shifts in seasonal patterns as the data stream evolves, and it works in the online setting."
SP:e4bb07033001be4d04695ef058f426d49fe440be,"This paper proposes a neural network architecture for solving assignment problems. The proposed method is based on a feature-weaving layer, which is stacked to model frequent communication between elements in a parameter-efficient way for solving the combinatorial problem of assignment. The experimental results show its impressive performance among the learning-based baselines and achieves better or comparative performance to the state-of-the-art algorithmic method."
SP:8a559e21d45661eef427b310e5fe8488d5749137,"This paper studies the impact of various self-supervised learning proxy tasks on different architectures and threat models for 3D point clouds with adversarial training. Specifically, the authors study MLP-based, convolution-based and transformer-based 3D architectures. They demonstrate that appropriate applications of these proxy tasks can significantly enhance the robustness of 3D deep learning models against adversarial attacks. They further leverage two simple yet powerful ensemble methods to boost the adversarial robustness by a substantial margin."
SP:657c5a1114c0d054b9e767d85990bbbb0492912d,"This paper proposes a method for computing iterative projections of close-by points over submodular base polytopes. The main idea is to use the away-step Frank-Wolfe algorithm to use this information and enable early termination. The proposed method is based on the FISTA algorithm, which has been shown to have near-optimal regret bounds and convergence rates, but suffers from a computational bottleneck of computing “projections” in potentially each iteration (e.g., O(T) regret of online mirror descent). Motivated by this trade-off in runtime v/s convergence rate, the authors propose a method to speed up the computation of projections using both discrete and continuous perspectives. The theoretical results show orders of magnitude reduction in runtime in preliminary computational experiments. "
SP:8dae43d6b5cebb7ef6c39437d997b390c2380536,"This paper studies the problem of learning the natural parameters of a k-parameter minimal exponential family from i.i.d. samples in a computationally and statistically efficient manner. The authors propose a method that is consistent as well as asymptotically normal under mild conditions. They provide finite sample guarantees to achieve an (`2) error of α in the parameter estimation with sample complexity O(poly(k/alpha)) and computational complexity $O(poly\mathcal{O}(\sqrt{k}/alpha)$, where $k$ is the number of samples. "
SP:4f9ddb697e86356fb293ef34a69ca3702c4e8164,"This paper proposes a differentiable renderer for inverse graphics that combines the advantages of rasterization and ray-tracing. The renderer is based on a combination of two differentiable methods: (1) a physics-based renderer based on path tracing, and (2) a ray tracing based renderer. The proposed method is evaluated on synthetic and real images. The results show that the proposed method achieves better results than the baselines. "
SP:6ac1c8556e7131939cc582f513bc9921470e1b09,"This paper proposes sampling-argmax, a differentiable training method that imposes implicit constraints to the shape of the probability map by minimizing the expectation of the localization error. The expectation can be approximated by calculating the average error of all samples drawn from the output distribution. The proposed method is shown to be effective on various localization tasks."
SP:478c05c90090f9d80b72ac352c488073b45a5d8b,"This paper proposes a directed graph data augmentation method called Laplacian perturbation (DiGCL) for graph contrastive learning. DiGCL dynamically learns from all possible contrastive views generated by the proposed method, and trains it using multi-task curriculum learning to progressively learn from multiple easy-to-difficult contrastive view. The proposed method outperforms the state-of-the-art in both unsupervised and supervised learning settings. "
SP:85b383d2f722f7bff438840e423f5cb4c67d5980,"This paper proposes a multi-environment Symbolic Interactive Language Grounding benchmark (SILG), which unifies a collection of diverse grounded language learning environments under a common interface. SILG consists of grid-world environments that require generalization to new dynamics, entities, and partially observed worlds (RTFM, Messenger, NetHack), as well as symbolic counterparts of visual worlds that require interpreting rich natural language with respect to complex scenes (ALFWorld, Touchdown). The authors also propose the first shared model architecture for RL on these environments, and evaluate recent advances such as egocentric local convolution, recurrent state-tracking, entity-centric attention, and pretrained LM using SILG."
SP:23c8db56f59f778fe812a5dd161f7a1f21c3cdba,"This paper proposes a sparse version of the Vision Mixture of experts network (MoE) for image recognition. The proposed method is based on sparsely-activated Mixture-of-Experts networks (MoEs) and is able to be trained with up to 32 experts per layer and almost 15B parameters. The authors also propose an extension to the routing algorithm that can prioritize subsets of each input across the entire batch, leading to adaptive per-image compute. This allows V-MoE to trade-off performance and compute smoothly at test-time. "
SP:c5235f41dfb8b5cc478f11c5d5e0ab0b8676871e,"This paper studies the problem of training narrow neural networks with fewer than n neurons. The authors show that as long as the width m > 2n/d (where d is the input dimension), the expressivity is strong, i.e., there exists at least one global minimizer with zero training loss. They also identify a nice local region with no local-min or saddle points, and prove that every KKT point is a nearly global minimiser. Finally, they show that projected gradient methods on this constrained formulation significantly outperform SGD for training narrow networks."
SP:0be529f5254afd59dcfa6b34a359c7037e7a8323,"This paper proposes a continuous mean-covariance bandit (CMCB) model to explicitly take into account option correlation in online risk-aware multi-armed bandit problems. The proposed CMCB model is based on a continuous learner who sequentially chooses weight vectors on given options and observes random feedback according to the decisions. The agent’s objective is to achieve the best trade-off between reward and risk, measured with option covariance. To capture different reward observation scenarios in practice, the authors consider three feedback settings, i.e., full-information, semi-bandit and full bandit feedback. They propose novel algorithms with optimal regrets (within logarithmic factors), and provide matching lower bounds to validate their optimalities. The experimental results also demonstrate the superiority of their algorithms."
SP:472a90bb175b0286765c5a47b040e1a58f594a05,"This paper proposes an extension of the Multiplicative Update (MMU) algorithm to the PSD factorization problem, which is a generalization of the nonnegative matrix factorization (NMF) problem. In particular, the authors propose a non-commutative extension of Lee-Seung’s algorithm, which ensures that updates remain PSD by congruence scaling with the matrix geometric mean of appropriate PSD matrices, and it retains the simplicity of implementation that the multiplicative update algorithm for NMF enjoys. The authors also show that the MMU algorithm can be also used as a primitive to calculate blockdiagonal and tensor PSD factors. The proposed method is evaluated on real and synthetic data. "
SP:83abd6d149d88cc6e96cbc4d488e4fe9dc2a4fcb,"This paper proposes a meta-learning framework for domain generalization (DG) based on domain-invariant and domain-specific information. Specifically, the proposed method aims to disentangle features in the latent space while jointly learning both domain invariant and domainspecific features in a unified framework. The proposed method is evaluated on several benchmark datasets, including Colored MNIST, Rotated-MNIST, VLCS, PACS, Office-Home, Terra Incognita, DomainNet, and a newly created dataset, Background-Colored- MNIST."
SP:4191474c75e2fedf514f0f3001a67a047eb74c30,"This paper presents a method to improve the FID of diffusion models on unconditional image synthesis tasks. The method is based on a series of ablations, where a diffusion model is first trained to generate the image, and then a classifier is used to guide the diffusion model during sampling. The results show that the proposed method can achieve better FID than the state-of-the-art GAN-based methods. The proposed method is also shown to improve FID on conditional image synthesis."
SP:fe3cab08596cde4c14ecf6fca8d0f95b02bab229,"This paper proposes to leverage out-of-distribution samples, i.e., unlabeled samples coming from outside target classes, to improve few-shot learning. Specifically, the proposed method exploits the easily available out of distribution samples (e.g., from base classes) to drive the classifier to avoid irrelevant features by maximizing the distance from prototypes to out of distribution samples while minimizing that to in-dist distribution samples. The proposed method is simple to implement, agnostic to feature extractors, lightweight without any additional cost for pre-training, and applicable to both inductive and transductive settings. Extensive experiments on various standard benchmarks demonstrate that the proposed methods consistently improves the performance of pretrained networks with different architectures."
SP:b1f65724926f136979829b7a6c870bc31f38f591,"This paper proposes ReMERN and ReMERT, two algorithms for prioritized sampling in off-policy reinforcement learning. The main idea is to use hindsight TD error as a metric for prioritization in the Bellman update. Theoretical analysis is provided to show that with high TD error, better on-policiness and more accurate Q value should be assigned with higher weights during sampling. The authors also propose two new methods to compute the prioritization weight. Experiments on MuJoCo, Atari and Meta-World show the effectiveness of the proposed algorithms. "
SP:601ebf30b3c6aa35fcef49633aa8eb0acd0f2c66,This paper studies the problem of sequential prediction with expert advice in a nonstationary environment with long-term memory guarantees in the sense of Bousquet and Warmuth [4]. The authors give a linear-time algorithm that improves on the best known regret bounds [27]. This algorithm incorporates a relative entropy projection step. This projection is advantageous over previous weight-sharing approaches in that weight updates may come with implicit costs as in for example portfolio optimization. The authors also give an algorithm to compute this projection step in linear time.
SP:b2439973063e827b3cbe92306a2fdee3286b6b44,"This paper studies the problem of contextual linear bandits motivated by routing applications in navigational engines and recommendation systems. In this problem, the learner is presented with a subset Xt ⊆ R of possible actions, and the goal is to learn a hidden d-dimensional value w∗. Every round, we are presented with Xt, and if we choose (i.e., recommend to the user) action xt, we obtain utility 〈xt, w\�〉 but only learn the identity of the best action arg maxx∈Xt〈x,w,w〉. The authors design algorithms for this problem which achieve regret O(d log T) and exp(O(dlog d)). To accomplish this, they design novel cutting-plane algorithms with low “regret” – the total distance between the true point w.∗ and the hyperplanes the separation oracle returns. "
SP:abe83c7e0bcf4829742609d709637e2f84d8a4d9,"This paper proposes Lale, an open-source sklearn-compatible AutoML library. Lale uses a small set of orthogonal combinators for composing machine learning operators into pipelines. It describes a translation scheme from pipelines and associated hyperparameter schemas to search spaces for AutoML optimizers. The proposed Lale is more expressive than the high-level interfaces of prior AutoML tools. "
SP:0d7f1cae577ed598048b64617e85ca6bd5c6d7fa,"This paper studies the problem of meta-learning, where the goal is to learn a weight initialization such that a small number of weight changes results in low generalization error. The authors show that this form of meta learning can be improved by letting the learning algorithm decide which weights to change, i.e., by learning where to learn. They find that patterned sparsity emerges from this process, with the pattern of sparsity varying on a problem-by-problem basis. This selective sparsity results in better generalization and less interference in a range of few-shot and continual learning problems. Moreover, sparse learning also emerges in a more expressive model where learning rates are meta-learned."
SP:05037e1850003a725a466b64d3e32aa2aed458fb,"This paper proposes a new method for multi-view learning based on additive Gaussian noise. The proposed method, called ShICA-J, is based on the notion of shared independent component analysis (ShICA) that models each view as a linear transform of independent components contaminated by additive Gaussians. The authors show that this model is identifiable if the components are either non-Gaussian or have enough diversity in noise variances. They also show that in some cases multi-set canonical correlation analysis can recover the correct unmixing matrices, but that even a small amount of sampling noise makes Multiset CCA fail. To solve this problem, the authors propose to use joint diagonalization after multiset correlation analysis (MCA) to solve the problem. Experiments on fMRI and MEG datasets demonstrate the effectiveness of the proposed method."
SP:44dd1faa1813c433fd7581d05cae3df440bfb93e,This paper studies the problem of multi-agent reinforcement learning with human co-players in a two-player collaborative cooking simulator. The authors propose a new method called Fictitious Co-Play (FCP) to train agents that collaborate well with human partners without using human data. They show that FCP outperforms the state-of-the-art in task score and in human partner preference (Section 5.2).
SP:21c84bd720b1e90ea0f88fbf8fd24dbcb49b547c,"This paper proposes a new method for cooperative multi-agent reinforcement learning in both discrete and continuous action spaces. The proposed method uses a centralised but factored critic, which combines per-agent utilities into the joint action-value function via a non-linear monotonic function. This allows for more coordinated policy changes and fully reaps the benefits of the centralised critic. Empirical results demonstrate that the proposed method achieves better performance than MADDPG and other baselines."
SP:1c8351b8a6cdf1212840388e19a596729b3bfda4,"This paper proposes a biologically plausible model of long-term memory based on Hebbian and non-Hebbian plasticity rules. The proposed model is based on a Hopfield network with a key-value mechanism to store and read out memories in a single step. The authors show that the proposed model can be extended to continual recall, hetero-associative memory, sequence learning, and sequence learning tasks. "
SP:7ad6da2c63859d64970e9b35326e9ceab48add47,"This paper studies the problem of pairwise learning, where the loss function depends on a pair of instances. The authors propose stochastic and online gradient descent (SGD) algorithms for the problem. The proposed algorithms are based on the SGD algorithm for convex and non-convex problems. Theoretical results on the generalization bounds, optimization error bounds, and stability analysis are provided. Experimental results show that the proposed algorithms perform better than existing algorithms."
SP:cb11dacc930d71a616ee2fbe4acfae030f9dca59,"This paper proposes REDO, a class-agnostic framework to reconstruct the Dynamic Objects from RGBD or calibrated videos. REDO aims to handle different object dynamics including rigid motion, non-rigid motion, and articulation. To address these challenges, the authors develop two novel modules. First, a canonical 4D implicit function which is pixel-aligned with aggregated temporal visual cues. Second, a 4D transformation module captures object dynamics to support temporal propagation and aggregation. RedO achieves state-of-the-art results on various benchmarks (SAIL-VOS 3D, DeformingThings4D++, and 3DPW)."
SP:8ae97752e74b4395774575009031abcb6ba5cea7,This paper provides a non-asymptotic analysis of linear stochastic approximation (LSA) algorithms with fixed stepsize. The analysis is based on new results regarding moments and high probability bounds for products of matrices which are shown to be tight. The authors also establish polynomial concentration bounds with order depending on the stepsize and the number of iterations. 
SP:86c1e937755e35efafecc09dfe2606ffb1653a41,"This paper extends the options framework for temporal abstraction in reinforcement learning from discounted Markov decision processes (MDPs) to average-reward MDPs. The authors propose general convergent off-policy inter-option learning algorithms, intra-option algorithms for learning values and models, as well as sample-based planning variants of their learning algorithms. They also extend the notion of option-interrupting behavior from the discounted to the average reward formulation. They show the efficacy of the proposed algorithms with experiments on a continuing version of the Four-Room domain."
SP:7e4e1e20e7c253d02c6ae58457fb30029f130f0c,"This paper proposes a self-supervised training method for visual transformers (VTs), which is an architectural paradigm alternative to convolutional networks (CNNs). The authors compare the performance of different VTs on ImageNet and ImageNet with respect to their performance on smaller datasets. The authors also propose an auxiliary task that can extract additional information from images with only a negligible computational overhead. The proposed task is used jointly with the standard (supervised) training and it does not depend on specific architectural choices, thus it can be easily plugged in the existing VTs."
SP:0132ef17585e293b23e9dc45189c0989d829b52a,"This paper proposes a label-free hyperbolic Procrustes analysis (HPA) method for hierarchical data alignment. The proposed method is based on the Riemannian geometry of the Lorentz model, which is used to define three components: translation, scaling, and rotation. The authors provide theoretical analysis and justification of the alignment method based on new derivations of Riemanian geometry operations in the Lorendz model. The efficacy of HPA, its theoretical properties, stability and computational efficiency are demonstrated in simulations. "
SP:3580ac64f09e3021de5d4c92411bcc0f3c5d10f3,"This paper studies the problem of differentially private query answering in the context of microdata generation. The authors show that the uncertainty principle governs the trade-off between accuracy for a population of interest (“sum query”) vs. accuracy for its component sub-populations (‘point queries’). Compared to query answering systems that are not required to produce microdata, the accuracy can degrade by a logarithmic factor. To mitigate this, the authors propose mitigation strategies and create a collection of benchmark datasets that can be used for public study."
SP:c0e64dc8acfaed3e4d7745af12fd34003d0e5017,"This paper proposes a method to train a planner and an RL agent to jointly learn from each other on a curriculum of tree-structured sub-tasks. The planner decomposes a long-horizon task to a tree of sub tasks in a top-down manner, whose layers construct coarse-to-fine sub-task sequences as plans to complete the original task. The planning policy is trained to minimize the RL agent’s cost of completing the sequence in each layer from top to bottom layers. The bottom-up traversal of the tree trains the planner from easier sub tasks with denser rewards on the bottom layers to harder ones on the top layers and collects its cost on each sub task in the next episode. The RL agent and planner are fully optimized to facilitate each other's training. The method is evaluated on navigation and continuous control tasks."
SP:9911693a04a300b5a93634fb0267ef83e5489d77,"This paper proposes a Bayesian framework for generating explanations for black box black box explanations. The proposed framework is based on Bayesian versions of LIME and KernelSHAP, which output credible intervals for the feature importances, capturing the associated uncertainty. The authors also provide a detailed theoretical analysis that leverages the aforementioned uncertainty to estimate how many perturbations to sample, and how to sample for faster convergence. Experimental evaluation with multiple real world datasets and user studies demonstrate the efficacy of the proposed framework. "
SP:5efb4b81bd37c70640e8768e9dfb5bba14a0cfb8,"This paper proposes a method to improve the performance of Adder neural networks (ANNs) by pre-defining the feature distributions in order to model the heavy-tailedness in ANNs. The authors show that unordered heavy tails could be the key component which prevents ANNs from achieving superior classification performance since fatter tails tend to overlap in feature space. To solve this problem, the authors propose to use a mixture of multivariate Skew Laplace Distributions (MSPD) to embed this mixture of skew Laplace into the loss function through substituting the distribution parameters for the classifier head. The proposed method improves the classification accuracy by 0.7% on both CIFAR-100 and ImageNet with ResNet-18 compared to vanilla ANN."
SP:cbccb65457564992d534504c0d060da44cafce8c,"This paper studies the phenomenon of gradient starvation in neural networks. Gradient starvation is a phenomenon that occurs when cross-entropy loss is minimized by capturing only a subset of features relevant for the task, despite the presence of other predictive features that fail to be discovered. This paper provides a theoretical explanation for the emergence of such feature imbalances in over-parameterized neural networks and identifies simple properties of learning dynamics during gradient descent that lead to this imbalance, and prove that such a situation can be expected given certain statistical structure in training data. Based on the proposed formalism, the authors develop a novel regularization method aimed at decoupling feature learning dynamics, improving accuracy and robustness in cases hindered by gradient starvation."
SP:8f6fe37cb0a332b66e10cc00261a44622841c8c6,"This paper evaluates the performance of rule-based and learning-based AI agents in Hanabi, a cooperative game of cooperative card games with human and AI players. The paper also evaluates the human-AI teaming performance on a variety of metrics, including trust, teamwork, interpretability, and overall preference of AI teammates. The authors find that humans prefer rule based AI agents (SmartBot) over learning based agents (Other-Play) across nearly all subjective metrics, and generally view the learning based agent negatively, despite no statistical difference in the game score."
SP:2a05e333fc1a14057515ef3addde9a40152373db,"This paper proposes a new method for visual question generation (VQG) based on visual hints. The proposed method combines a visual hints predictor with a cross-modal reasoning module to determine the salient visual regions associated to the corresponding question, and a question generation module with predicted visual hints and textual answer hints. A discriminator is to distinguish whether a sample triplet (i.e., the image, answer, and question) is generated from the generator or ground-truth. Experimental results on two benchmark datasets show that the proposed method outperforms the state-of-the-art approaches by a large margin."
SP:15756d6ef47b39ded404acea2135c93bd5ee1062,"This paper proposes Generalized Data Weighting (GDW) to mitigate label noise and class imbalance by manipulating gradients at the class level. GDW unrolls the loss gradient to class-level gradients by the chain rule and reweights the flow of each gradient separately. In this way, GDW achieves remarkable performance improvement on both issues. Extensive experiments in various settings demonstrate the effectiveness of GDW."
SP:7a8f56a01bec51ebf70d9ff689005a62cccfe5c6,"This paper proposes a new task to learn spatio-temporal language grounding, where the goal is to learn the meaning of spatiotemporal descriptions of behavioral traces of an embodied agent. This is achieved by training a truth function that predicts if a description matches a given history of observations. The descriptions involve time-extended predicates in past and present tense as well as spatio temporal references to objects in the scene. To study the role of architectural biases in this task, the authors train several models including multimodal Transformer architectures; the latter implement different attention computations between words and objects across space and time. The results show that maintaining object identity in the attention computation of our Transformers is instrumental to achieving good performance on generalization overall."
SP:3d4a9d439bc84c3b0e6600f6985a23bdf95cd67f,"This paper proposes Prototypical Cross-Attention Network (PCAN) for online multiple object tracking and segmentation. PCAN first distills a space-time memory into a set of prototypes and then employs cross-attention to retrieve rich information from the past frames. To segment each object, PCAN adopts a prototypical appearance module to learn contrastive foreground and background prototypes, which are propagated over time. Extensive experiments demonstrate that PCAN outperforms current video instance tracking methods on both Youtube-VIS and BDD100K datasets. "
SP:1175ad16382b349ab1a39895150172d266abe571,"This paper provides a theoretical analysis of gradient flow as an approximate numerical solution to the initial value problem of gradient descent. The authors show that the degree of approximation depends on the curvature around the gradient flow trajectory. They show that over deep neural networks with homogeneous activations, gradient flow trajectories enjoy favorable curvature, suggesting that gradient descent is well approximated by gradient flow. This finding allows them to translate an analysis of gradients flow over deep linear neural networks into a guarantee that gradient flow efficiently converges to global minimum almost under random initialization."
SP:b8412e9ce82ce92125fe7cd3aff7bea8b906d16e,"This paper studies the problem of multi-armed bandit learning with delayed impact of actions in the context of stochastic bandits, where actions taken in the past impact the arm rewards in the subsequent future. The authors generalize the bandit setting to encode the dependency of this “bias” due to the action history during learning. The goal is to maximize the collected utilities over time while taking into account the dynamics created by the delayed impacts of historical actions. They propose an algorithm that achieves a regret of KT(KT 2/3) and show a matching regret lower bound of KT2/3. "
SP:9c1d678dff5f609197dc3cfb67b841827f4a439a,"This paper proposes an end-to-end solution for video instance segmentation (VIS) based on transformers. In particular, the authors propose Inter-frame Communication Transformers (IFC), which significantly reduces the overhead for information-passing between frames by efficiently encoding the context within the input clip. Specifically, they propose to utilize concise memory tokens as a means of conveying information as well as summarizing each frame scene. The features of each frame are enriched and correlated with other frames through exchange of information between the precisely encoded memory tokens. They validate their method on the latest benchmark sets and achieve state-of-the-art performance (AP 42.6 on YouTube-VIS 2019) while having a considerably fast runtime (89.4 FPS). "
SP:6c922eaa358f6fb9771690b1240e4f6f08a35b69,"This paper proposes a general graph embedding method that can debias various structural biases in graphs by using random graphs. The proposed method, called residual2vec, is based on random walks, which are biased by the degree of each node, where a node is sampled proportionally to its degree. The authors show that word2vec by itself has an implicit bias arising from the optimization algorithm—skip-gram negative sampling (SGNS), which happens to negate the bias due to the friendship paradox. To leverage this debiasing feature further, the authors propose a more general framework that can also compensate for other systematic biases in random walks. "
SP:851eac96135b577a5014166edcb43db6a190cf4b,"This paper studies the problem of estimating non-linear functionals of discrete distributions in the context of local differential privacy. In this setting, the initial data x1, xn are supposed i.i.d. and distributed according to an unknown discrete distribution p = p = (p1,..., pK). Only α-locally differentially private (LDP) samples z1,..., zn are publicly available, where the term ‘local’ means that each zi is produced using one individual attribute xi. The paper studies two types of algorithms for estimating the power sum functional Fγ of the discrete distribution K, n and α. In the non-interactive case, they study two plug-in type estimators of Fγ that are similar to the MLE analyzed by Jiao et al. in the multinomial model. They show lower bounds over all α-LDP mechanisms and all estimators using the private samples. They also introduce a two-step procedure which attains the parametric rate (nα2)−1/2 when \� < 2."
SP:a0408b54f88a26479f33f36bb27e0a675f637ccd,"This paper studies the problem of online multiclass classification in the setting where the learner’s feedback is determined by an arbitrary directed graph. The proposed algorithm GAPPLETRON achieves a constant surrogate regret of order BK, where BK is the diameter of the prediction space, K is the number of classes, T is the time horizon, and ρ is the domination number (a graph-theoretic parameter affecting the amount of exploration). In the full information case, the authors also prove a general lower bound of order max {BK, T}. Experiments on synthetic data show that for various feedback graphs our algorithm is competitive against known baselines."
SP:490262589efce6fb10b913431ec6db8d4e5b2dec,"This paper studies the problem of explainable clustering in the setting first formalized by Dasgupta, Frost, Moshkovitz, and Rashtchian (ICML 2020). A k-clustering is said to be explainable if it is given by a decision tree where each internal node splits data points with a threshold cut in a single dimension (feature), and each of the k leaves corresponds to a cluster. The authors give an algorithm that outputs an explainable cluster that loses at most a factor of O(log k) compared to an optimal (not necessarily explainable) clustering for the k-medians objective, and a factor O(k log k) for k-means objective. The algorithm is remarkably simple and runs in time O(dk log k), independent of the number of data points n."
SP:6a9e47be710ddaf386bffc54d003d7dc2b67fdc3,"This paper proposes a multilingual pre-trained language model (PrLM) that supports both explicit universal dependency parsing and implicit language modeling. Syntax in terms of universal dependency parse serves as not only pre-training objective but also learned representation in the model, which brings unprecedented PrLM interpretability and convenience in downstream task use. The model outperforms two popular multilingual PrLM, multilingual-BERT and XLM-R, on cross-lingual NLU benchmarks and linguistic structure parsing datasets."
SP:94f4b65214a648cbc84f13beba45a825e2e9901a,"This paper proposes a new Transformer-based method for solving vehicle routing problems (VRPs). The proposed method is based on the Dual-Aspect Collaborative Transformer (DACT) architecture. DACT learns embeddings for node and positional features separately, instead of fusing them together as done in existing ones, so as to avoid potential noises and incompatible correlations. Moreover, the positional features are embedded through a novel cyclic positional encoding (CPE) method to capture the circularity and symmetry of VRP solutions (i.e., cyclic sequences). The authors train DACT using Proximal Policy Optimization and design a curriculum learning strategy for better sample efficiency."
SP:e5c8680d8da9e7548fcb9bb5c073848eb80e1dd0,"This paper proposes a method to compute the exact Bayes error of generative models learned using normalizing flows. The method relies on a fundamental result, which states that the Bayesian error is invariant under invertible transformation, and can be computed for Gaussian base distributions, which can be done efficiently using Holmes-Diaconis-Ross integration. The authors also show that by varying the temperature of the learned flow models, they can generate synthetic datasets that closely resemble standard benchmark datasets, but with almost any desired Bayes errors. They also conduct a thorough investigation of state-of-the-art classification models and find that in some — but not all — cases, these models are capable of obtaining accuracy very near optimal."
SP:2896679f0472522bc3334178cd7574494cf12b7b,"This paper proposes Grad Init, a method for initializing neural networks. Grad Init is based on a simple heuristic: the norm of each network layer is adjusted so that a single step of SGD or Adam with prescribed hyperparameters results in the smallest possible loss value. This adjustment is done by introducing a scalar multiplier variable in front of each parameter block, and then optimizing these variables using a simple numerical scheme.  Grad Init accelerates the convergence and test performance of many convolutional architectures, both with or without skip connections, and even without normalization layers. It also improves the stability of the original Transformer architecture for machine translation. "
SP:f69731403592fa5bdd4ca327708582d615aa131c,"This paper proposes a method to predict biomarker progression for Alzheimer's disease using longitudinal data. The proposed method is based on linear mixed-effect models that embed the data in a Riemannian manifold and learn patient-specific trajectories distributed around a central geodesic. A few interpretable parameters characterize subject trajectories at the cost of a prior choice of the metric, which determines the shape of the trajectories. The authors extend this approach by learning the metric from the data allowing more flexibility while keeping the interpretability. Specifically, they learn the metric as the push-forward of the Euclidean metric by a diffeomorphism iteratively as the composition of radial basis functions belonging to a reproducible kernel Hilbert space."
SP:438e906f52c4c0538956b51a2270b3ac498b27a8,"This paper proposes a routing-by-memory mechanism for existing CNN architectures. In each stage of the network, they introduce parallel Procedural Units (PUs). A PU consists of a memory head and a procedure. The memory head maintains a summary of a type of features. For an intermediate feature, we search its closest memory and forward it to the corresponding procedure. In this way, different procedures are tailored to different features and therefore tackle them better. The proposed mechanism can be trained efficiently using a four-step training strategy. "
SP:d240173080cd3647dbaa5173a6422396f226775b,"This paper studies the equivariance properties of polynomial functions that are equivariant to translation, rotation, reflection, boost, and permutations. The authors show that polynomials can be expressed in terms of a lightweight collection of scalars, scalar products and scalar contractions of the scalar, vector, tensor, and tensor inputs. The scalar-based method is simple, efficient, and scalable. The paper also shows that the symmetries considered in this work are all global symmetry, as they act on all points in the same way. "
SP:72c0f47566904deb27d8157da30807ec1d6b5685,This paper proposes a new loss function for bounding box regression based on the Intersection over Union (IoU) loss and its variants. The main idea is to generalize existing IoU-based losses to a new family of power IoU losses with a single power parameter. The proposed loss function is based on a combination of the IoU loss and a power regularization term. The authors analyze properties such as order preservingness and loss/gradient reweighting. Experiments on multiple object detection benchmarks and models and models demonstrate that the proposed loss can surpass IoU based losses by a noticeable performance margin. 
SP:397125177d7007316d67194ec00d5dc57b44ac79,"This paper studies Distributionally Robust Imitation Learning (DROIL) for imitation learning in Markov Decision Process (MDP) settings where the reward function is not given, but demonstrations from experts are available. The authors show that DROIL can be seen as a framework that maximizes a generalized concept of entropy. They develop a novel approach to transform the objective function into a convex optimization problem over a polynomial number of variables for a class of loss functions that are additive over state and action spaces. They extend the formulation to stationary policies, which enables them to experimentally show the benefits of DROIL in a highway driving simulation."
SP:58f220bbbed8d3e0633b408fca3b6838c4ad323d,"This paper proposes a general post-processing algorithm for individual fairness (IF) based on graph Laplacian smoothing. The authors show that the proposed algorithm can be viewed as a graph smoothing problem that preserves the desired “treat similar individuals similarly” interpretation. The proposed algorithm is shown to be computationally and empirically more efficient than the baselines. Empirically, the proposed algorithms correct individual biases in large-scale NLP models such as BERT while preserving accuracy."
SP:ef791aa29decd839e7e583c9d1f71e8309ca87ef,"This paper proposes a structure-aware Dual Graph Aggregation Network (SADGA) for the cross-domain Text-to-SQL task. SADGA is based on the graph structure to provide a unified encoding model for both the natural language question and the database schema, and the question-schema linking method to learn the mapping between words in the question and tables/columns in the database schemas. Extensive experiments are conducted to demonstrate the effectiveness of the proposed method."
SP:a2fa25a4539a38af61a0993f65ecc14339f26c2e,"This paper studies the problem of training stochastic computation graphs with multiple discrete components. The authors show that it is challenging to optimize the parameters of these models, mainly due to small gradients and local minima. They propose two strategies to overcome these challenges. First, increasing the scale parameter of the Gumbel noise perturbations during training improves the learning behavior. Second, they propose dropout residual connections for discrete-continuous computation graphs in Section 2.2."
SP:bb3ec363e90269db4a2ba99d8107cb56f86e68f0,"This paper studies the effect of covariate shift in Bayesian neural networks (BNNs) on the performance of approximate Bayesian inference. The authors show that BNNs with Hamiltonian Monte Carlo (HMC) approximate inference achieve poor generalization under covariate shifts. They also show that the same issue does not affect many approximate inference procedures, or classical maximum a-posteriori (MAP) training. Finally, the authors propose novel priors that improve the robustness of BNN to many sources of covariates shift."
SP:f86ec7042e9b73ae071704a6d3ed17d7e3da1b75,"This paper categorizes few-shot meta-learning evaluation into two settings: in-distribution (ID) and out of distribution (OOD). In the ID setting, the train and test tasks are sampled iid from the same underlying task distribution, and in the OOD setting, they are sampled from different sets of train (base) and test (novel) classes. The authors identify that most existing FSL benchmarks do not reflect OOD evaluation, as they use disjoint sets of base and test classes for task generation. This discrepancy is problematic because it is difficult to compare the performance of different methods in the ID and OOD settings.  The authors also highlight the importance and distinction of ID vs. OOD evaluations, as well as the subtleties of current benchmarks. "
SP:371f77148b4f00a929f7c118b1bb7c5a6238d264,"This paper proposes an open rule induction method for rule induction based on LM-based rule generation. The proposed method is based on the idea of open rules, which are open rules that can be found in the knowledge base (KB) of a language model (LM). The authors argue that the current methods are ""learning rules from rules"", which limits the expressive power of the LM to only produce “canned” rules whose patterns are constrained by the annotated rules. To this end, the authors propose the Orion (open rule induction) system to automatically induct open rules from LMs without supervision. The authors conduct extensive experiments to verify the quality and quantity of the inducted open rules. "
SP:8be2e0ea4a83fe32a4859f456007a829e5e9270a,"This paper proposes Implicit Constraint Q-learning (ICQ), a novel offline RL algorithm for multi-agent offline RL. ICQ is based on the idea of implicit constraint learning, which aims to reduce the extrapolation error of the agent in the offline learning setting. The proposed method is evaluated on the StarCraft II offline tasks. The results show that ICQ achieves the state-of-the-art performance in StarCraft tasks. "
SP:1939b24b68970c33ca16ce238deed257f76d009e,"This paper proposes a method to generate adversarial examples that are more robust to real-world attacks than uniform norm-bounded perturbations. The method is motivated by the fact that features typically have some semantically meaningful dependencies. The authors propose to use non-uniform perturbation bounds that can represent these feature dependencies during adversarial training. The proposed method is tested on a variety of applications, including malware classification, credit risk prediction, credit card default prediction, and spam detection."
SP:417b30930b245667d777e5d90ee80dd41546760e,"This paper extends the Tikhonov regularization theory to generalized self-concordant loss functions (GSC), which contain the logistic loss. The main contribution of this paper is to derive the iterated regularization scheme for GSCs, which is related to the proximal point method in optimization. The authors show that the iterate regularization can be used to improve the convergence rate of the excess risk of the learning rate of GSC functions.  "
SP:1caeee4f00b52fe356ff4e5dd004d0203e838370,"This paper proposes a new linear transform called Deformable butterfly (DeBut) that generalizes the conventional butterfly matrices and can be adapted to various input-output dimensions. It inherits the fine-to-coarse-grained learnable hierarchy of traditional butterflies and when deployed to neural networks, the prominent structures and sparsity in a DeBut layer constitutes a new way for network compression. Experiments show that DeBut can be used as a drop-in replacement of standard fully connected and convolutional layers, and demonstrate its superiority in homogenizing a neural network and rendering it favorable properties such as light weight and low inference complexity, without compromising accuracy."
SP:d345ce1d7afc367ee1a9fb68d50ff1b2219f02cb,"This paper proposes MetA Reusable Knowledge (MARK), a method to address the problem of catastrophic forgetting (CF) in deep neural networks. The proposed method is based on the idea that the weights of a network are overwritten during the training of a new task, which causes forgetting of old information. To address this issue, the proposed method keeps a set of shared weights among tasks and uses these weights as a common knowledge base (KB) that is used to learn new tasks, but also enriched with new knowledge as the model learns new tasks. A metalearning approach is proposed to incrementally enrich the KB with knowledge and to foster weight reusability among tasks. Experiments show that Mark achieves state-of-the-art results in several popular benchmarks."
SP:722c52467e384058f8fdffa254d0e8db47440a64,This paper proposes a data-driven framework for scheduling primal heuristics in exact MIP solvers. The proposed method is based on learning from data describing the performance of primal heuristic in a specific MIP setting. The method is able to reduce the average primal integral by up to 49% on two classes of challenging instances. 
SP:5a21f0a49731dcb1d68deb06a75138e8e9d514d5,"This paper studies the setting where the learner receives binary feedback only once at the end of an episode. In this setting, the trajectory labels are generated by an unknown parametric model. The authors propose an algorithm that achieves sublinear regret in this setting. The algorithm is computationally efficient. "
SP:e66bd9582058ba0f6091bb1042ce2ecfdaae1515,"This paper proposes a novel edge representation learning framework based on Dual Hypergraph Transformation (DHT), which transforms the edges of a graph into the nodes of a hypergraph. This dual hypergraph construction allows the authors to apply message-passing techniques for node representations to edges. The authors validate their method with hypergraphs on diverse graph datasets for graph representation and generation performance, on which their method largely outperforms existing graph representation learning methods. "
SP:e398873e29b05176e1d52dc6f86a59a4f405e6fd,"This paper studies the sufficiency of a state representation for learning and representing the optimal policy in the context of reinforcement learning. The authors consider the problem of estimating mutual information (MI) maximization from samples of high-dimensional observations, and study several popular MI based objectives through this lens. They find that two of these objectives can yield insufficient representations given mild and common assumptions on the structure of the MDP. They corroborate their theoretical results with empirical experiments on a simulated game environment with visual observations."
SP:50181f740910195d3a50dd7d7f8cbb1c476d730b,"This paper proposes a steerable convolution (SS-Conv) method for 3D object semantic analysis. The main idea is to use sparse tensors to improve the performance of the convolutional layers. The proposed method is based on the SE(3)-equivariant deep feature learning (SE(3-equivariance) framework. The method is evaluated on 3 tasks: instance-level 6D pose estimation, 6D size estimation, and 6D category level 6D tracking. "
SP:d746bfb200577c980d92727bb0b1a3c23e7bfdc5,"This paper proposes a dynamic token sparsification framework to prune redundant tokens progressively and dynamically based on the input. Specifically, a lightweight prediction module is proposed to estimate the importance score of each token given the current features. To optimize the prediction module in an end-to-end manner, an attention masking strategy to differentiably prune a token by blocking its interactions with other tokens is proposed. The experimental results demonstrate the competitive trade-off between speed and accuracy. "
SP:d0b6cde42b1cba5e6e3c7c5131426fd84adbd3d7,"This paper studies the problem of distribution-free inference for regression functions. In particular, the authors consider the case where the underlying regression function is continuous and the data distribution is finite. The authors show that any confidence interval for the conditional mean E [Y |X] must have non-vanishing width, even as sample size tends to infinity. At the other extreme, if X takes only a small number of possible values, then inference on E is trivial to achieve. "
SP:123952325765c040c3078fc7dca2b6d370e55590,"This paper proposes Representation Neutralization for Fairness (RNF), a method to reduce the discrimination of DNN models by only debiasing the classification head, even with biased representations as inputs. To address low-resource settings with no access to sensitive attribute annotations, the authors leverage a bias-amplified model to generate proxy annotations for sensitive attributes. Experimental results on several benchmark datasets demonstrate the effectiveness of the proposed method."
SP:210eb2c811f966bb1ac53932cacabbad9bb608fe,"This paper proposes a new convolutional layer for CNNs that is invariant to rotational rotations. The proposed method is based on Bessel functions, which are well-known in physics and can be used to build Bessel CNNs (B-CNNs) that are rotational invariant for any continuous set of possible rotations by design. The authors propose to use the Bessel function in the convolution layer of CNNs to make the CNNs invariant with respect to all possible rotational angles. The method is shown to be effective for image classification tasks."
SP:ee51ecbd476d5b65903c942a62be89ff5d91698b,"This paper proposes a new large-scale solver for kernel ridge regression, which combines partitioning with random projections and iterative optimization to reduce space and time complexity while provably maintaining the same statistical accuracy. In particular, constructing suitable partitions directly in the feature space rather than in the input space promotes orthogonality between the local estimators, thus ensuring that key quantities such as local effective dimension and bias remain under control. The authors also characterize the statistical-computational tradeoff of our model, and demonstrate the effectiveness of our method by numerical experiments on large scale datasets."
SP:1f096d6fabd5b1fde43d06c552d46d87cd35cb4a,This paper proposes a method to learn discrete communication tokens for emergent communication in reinforcement learning. The proposed method is based on word embedding techniques from natural language processing. The authors show that the proposed method outperforms the one-hot communication method in a variety of scenarios. They also provide a decision-theoretic analysis of the performance of their proposed method. 
SP:8630ccc627534f9033bced04e2137a897ffef701,"This paper proposes CoAtNets (pronounced “coat” nets), a family of hybrid models built from two key insights: (1) depthwise convolution and self-attention can be naturally unified via simple relative attention; (2) vertically stacking convolution layers and attention layers in a principled way is surprisingly effective in improving generalization, capacity and efficiency. Experiments show that CoAtNet achieves state-of-the-art performance under different resource constraints across various datasets."
SP:d3ecbeeffa5ab365743ba8653c6739f24742ee31,"This paper presents a new second-order oracle bound for the expected risk of a weighted majority vote. The bound is based on a novel parametric form of the Chebyshev-Cantelli inequality, which is amenable to efficient minimization. The authors also derive a new concentration of measure inequality that combines PAC-Bayesian bounding with Bennett’s inequality. The empirical evaluation shows that the new bounds can improve on the work of Masegosa et al [2020]."
SP:5bac542a6532d43cf100e085398b4a4783719814,"This paper proposes a method for weakly supervised audio-visual video parsing. The proposed method exploits both the common and diverse event semantics across videos to identify audio or visual events. In addition, the method explores event co-occurrence across audio, visual, and audio- visual streams. The discovered supervisory signals across different videos and modalities can greatly facilitate the training with only video-level annotations."
SP:8fd6a03c1794afa524328d45f4232eacf6f86693,"This paper proposes a quantized and personalized FL algorithm QuPeD for federated learning with knowledge distillation (KD) that allows clients to learn compressed personalized models with different quantization parameters and model dimensions/structures. The authors propose an algorithm for learning quantized models through a relaxed optimization problem, where quantization values are also optimized over. In addition, they formulate a compressed personalization framework by introducing distillation loss for local client objectives collaborating through a global model. Numerically, the proposed algorithm outperforms FedAvg, FedAvg+ and local training of clients in various heterogeneous settings."
SP:fca8b4f1e765cf1724a37f0ae9a7dac1cb79c8b1,"This paper proposes a novel framework for constrained clustering that is intuitive, interpretable, and can be trained efficiently in the framework of stochastic gradient variational inference. By explicitly integrating domain knowledge in the form of probabilistic relations, the proposed model (DC-GMM) uncovers the underlying distribution of data conditioned on prior clustering preferences, expressed as pairwise constraints. These constraints guide the clustering process towards a desirable partition of the data by indicating which samples should or should not belong to the same cluster. Extensive experiments are provided to demonstrate the effectiveness of the proposed method."
SP:84379c0c881b7390ecc22fb398edfaf66d1af1ff,"This paper proposes a near-input-sparsity approximation algorithm for NTK, by sketching the polynomial expansions of arc-cosine kernels. The sketch for convolutional counterpart of NTK (CNTK) can transform any image using a linear runtime in the number of pixels. Furthermore, the authors prove a spectral approximation guarantee for the NTK matrix, by combining random features (based on leverage score sampling) of the arc-Cosine kernels with a sketching algorithm. The authors benchmark their methods on various large-scale regression and classification tasks and show that a linear regressor trained on our CNTK features matches the accuracy of exact NTK."
SP:fa2668083ff3bb592c29a4c6822ae96ff54d0dbe,"This paper proposes a multi-range Transformers model for long-term 3D motion trajectory prediction for multi-person motion prediction. The proposed model consists of a local-range encoder for individual motion and a global-range decoder for social interactions. The model is evaluated on multiple datasets including CMU-Mocap, MuPoTS-3D, 3DPW, and Panoptic datasets. The results show that the proposed method outperforms the state-of-the-art methods on long term motion prediction, but also generates diverse social interactions by automatically dividing people into different interaction groups."
SP:0a0e07af37c8fe8580639b1df62d27b6f63f8dee,"This paper proposes a new approach to program synthesis for long-horizon planning problems. The proposed approach trains a generative model to predict the unobserved portions of the world, and then synthesizes a program based on samples from this model in a way that is robust to its uncertainty. Experiments show that the proposed approach outperforms non-program-guided approaches on a set of challenging benchmarks, including a 2D Minecraft-inspired environment."
SP:5bb42b178b0d27da271bfa60e633fdac718638c4,"This paper studies the problem of causal imitation learning in sequential settings, where the imitator must make multiple decisions per episode. The authors provide a graphical criterion for determining whether imitability is feasible in sequential setting based on a causal graph encoding the domain’s causal structure. They also propose an efficient algorithm to determine imitability and to find the policy for each action that leads to proper imitation. Finally, they verify the proposed algorithm with simulations."
SP:85bd81f0c5b6ccbc421ebbaf6f5c72164bc70b7f,"This paper presents a slot-wise, object-based transition model that decomposes a scene into objects, aligns them (with respect to a slotwise object memory) to maintain a consistent order across time, and predicts how those objects evolve over successive frames. The model is trained end-to-end without supervision using transition losses at the level of the object-structured representation rather than pixels. The authors show that the combination of an objectlevel loss and correct object alignment over time enables the model to outperform a state-of-the-art baseline, and allows it to deal well with object occlusion and re-appearance in partially observable environments."
SP:f32eddbb5c33a8422c075579ff08aa9833338d44,"This paper studies the importance sampling weighted ERM algorithm for using adaptively collected data to minimize the average of a loss function over a hypothesis class and provides first-of-their-kind generalization guarantees and fast convergence rates based on a new maximal inequality that leverages importance sampling structure to obtain rates with the good dependence on the exploration rate in the data. For regression, the authors provide fast rates that leverage the strong convexity of squared-error loss. For policy learning, they provide regret guarantees that close an open gap in the existing literature whenever exploration goes to zero, as is the case for bandit-collected data."
SP:f549a0c231b71bae0acbed6e3afb41890ee89cd9,"This paper proposes a reweighting strategy for kernel-reweighted regression by reparametrizing the sample weights using a doubly non-negative matrix. When the weighting matrix is confined in an uncertainty set using either the log-determinant divergence or the Bures-Wasserstein distance, the adversarially reweighted estimate can be solved efficiently using first-order methods. Numerical experiments show that the proposed method achieves promising results on numerous datasets."
SP:fe12e13602925b9400fd596a987755beb10aa3d1,"This paper proposes a categorical gradient estimator based on importance sampling and statistical couplings for the categorical setting. The authors extend the work of Dong et al. (2020) and Yin et al., (2020), who proposed a performant estimator that does not rely on continuous relaxations; however, it is limited to binary random variables. They extend their estimator to categorical variables by reparameterizing categorical variable as sequences of binary variables and Rao-Blackwellization. They show that their proposed estimators provide state-of-the-art performance and outperform existing estimators. "
SP:e16fdf963ec2f9c0d79fa404e47e7862a5d6e922,"This paper proposes a new predictor-based neural architecture search method, called WeakNAS. The proposed method is based on learning a set of weak predictors for each architecture-performance pair in the search space. These predictors are then used to guide the search towards the high-performance sub-space through a search path through a series of weaker predictors. The main idea is to sample a few well-performed architectures guided by the previously learned predictor and estimate a new better weak predictor to gradually refine the ranking of the sampling space. Experiments on NAS-Bench-101 and NAS-bench-201 show the effectiveness of the proposed method."
SP:8f74abb04037ba2e59dcf8320dc555b149f68ed8,"This paper proposes a method to learn a global coordinate system of latent codes that can be used to learn to reach more states in the long term while still optimizing a local objective. The method is based on the idea of Entropic Desired Dynamics for Intrinsic ConTrol (EDDICT), which assumes fixed additive latent dynamics, which results in tractable learning and an interpretable latent space. Compared to prior methods, EDDICT’s globally consistent codes allow it to be far more exploratory, as demonstrated by improved state coverage and increased unsupervised performance on hard exploration games such as Montezuma's Revenge."
SP:c731a78c3e7f98ccd0253b51a0d42bf8deeb71f9,This paper proposes a fragment-based generative RL framework to generate pharmacochemically acceptable molecules with large docking scores for drug design. The proposed method is based on fragment based generation method and a novel error-based experience replay (PER) algorithm. The experimental results show that the proposed method produces molecules of higher quality compared to existing methods while achieving state-of-the-art performance on two of three targets.
SP:b938bca513e7de1231212064caf8877a78d8b612,"This paper studies the problem of learning directed acyclic graphical models from observational data in general settings without specific distributional assumptions. The proposed approach is information-theoretic and uses a local Markov boundary search procedure in order to recursively construct ancestral sets in the underlying graphical model. The authors show that for certain graph ensembles, a simple forward greedy search algorithm (i.e. without a backward pruning phase) suffices to learn the Markov boundaries of each node. This substantially improves the sample complexity, which is at most polynomial in the number of nodes. This is then applied to the entire graph under a novel identifiability condition that generalizes existing conditions from the literature. "
SP:af08109d4c45dc9401efb0e63c22167e9da28adb,"This paper considers the setting where each user holds m samples and the privacy protection is enforced at the level of each user’s data. In this setting, the authors show that, as long as each user receives sufficiently many samples, we can learn any privately learnable class via an ("", )DP algorithm using only O(log(1/\sqrt{O}(d) users) users, where d is the probabilistic representation dimension. In both cases, they show a nearly-matching lower bound on the number of users required. "
SP:da4f21d107a7f442c4d3e3ec13bdb44b041e07cf,"This paper studies implicit representation of value functions via theory and focused experimentation. The authors prove that, for a linear parametrization, stochastic gradient descent with implicit parameterization converges to global optima despite nonlinearity and non-convexity introduced by the implicit representation. They also provide empirical results in some simple domains that illustrate the theoretical findings. "
SP:992aa07d4f815d1c81f967374590eece933833b1,This paper proposes a KG refinement framework called IterefinE which iteratively combines the two techniques of PSL-KGI and MLN to improve the performance of KG embeddings for knowledge graph refinement tasks. The proposed method is able to exploit not only the ontological information but also the power of KGs to perform longer chains of reasoning. Experiments show that the proposed method can reject noisy facts from KG and infer higher quality new facts. 
SP:676fc4a3041af22e8f20ccba7daa2a0b1f5d6af5,"This paper proposes a novel evaluation framework for knowledge base completion (KBC) based on binary predictions. The authors construct a data set FB14k-QAQ with an alternative evaluation data structure: instead of single facts, they use KB queries, i.e., facts where one entity is replaced with a variable, and construct corresponding sets of entities that are correct answers. They randomly remove some of these correct answers from the data set, simulating the realistic scenario of real-world entities missing from a KB. They evaluate a number of state-of-the-art KB embeddings models on the new benchmark."
SP:83fe0a496a79bcf97ccba1c6d34b7d11e7d5c330,"This paper proposes a new method for task-oriented dialog generation using pre-trained language models. The proposed method, Alternating Roles Dialog Model (ARDM), is based on BERT-2 and GPT-2 pre-training. ARDM models each speaker separately and takes advantage of the large pretrained language model. It requires no supervision from human annotations such as belief states or dialog acts to achieve effective conversations. Experiments show that ARDM outperforms or is on par with state-of-the-art methods on two popular tasks: CamRest and Multi-WOZ datasets. "
SP:b11c06b7c4ef1aa43c59f808a679425e302d158e,"This paper proposes a method to measure the confidence of a deep neural network (DNN) for predicting the top-k classification on the test set. The authors define the notion of implied loss and prove that if an uncertainty measure is an implied loss, then low uncertainty means high probability of correct (or top k) classification. The proposed method is simple to use on existing networks and can be evaluated by binning values on test set for methods which are already quite accurate. "
SP:ab9666e15f2a0113d96cb4b47b1cbb30fa1f7982,"This paper studies the generalization properties of wide neural networks at large depths. The authors show that in the wide network limit, random networks before training are Gaussian processes governed by a kernel known as the Neural Network Gaussian Process (NNGP) kernel, and that at large depth the spectrum of the NNGP kernel simplifies considerably and becomes “weakly data-dependent”. They also show that gradient descent training of wide networks is described by a neural tangent kernel (NTK) that is related to the Neural Tangent Kernel (NTP) kernel. They show that NTK simplifies in much the same way as that of the NTGP kernel. "
SP:d3470c35aae48bf92439a55fdb98ccf07100e567,"This paper proposes Graph Convolutional Networks (GRAPHQA), a graph-based method to estimate the quality of protein models. The method is based on graph convolutional networks (GCNNs), which are graph neural networks (GNNs) that can be used to model both sequential and 3D structures of proteins. The authors show that the proposed method outperforms the state-of-the-art for both hand-engineered and representation-learning approaches, as well as carefully evaluating the individual contributions of GRAPHA components. "
SP:5188280131b58a35d3deda126a0754aea8fa6e58,"This paper studies the loss landscape of linear networks with different loss functions and different parameterizations. The authors show that the absence of “bad” local minima is due to two distinct phenomena that apply in different settings: it is true for arbitrary smooth convex losses in the case of architectures that can express all linear maps (filling architectures), but it holds only for the quadratic loss when the functional space is a determinantal variety (non-filling architecture). "
SP:ee71597ceab23eb4db1d6608f15f80ad51f7ff6d,"This paper proposes a general framework SEED (Sampling, Encoding, and Embedding Distributions) for inductive and unsupervised representation learning on graph structured objects. Given an input graph, the proposed framework samples a number of subgraphs whose reconstruction errors could be efficiently evaluated, encodes the subgraph samples into a collection of sub-graph vectors, and uses the embedding of the sub graph vector distribution as the output vector representation for the input graph. The proposed method is able to achieve up to 10% improvement, compared with competitive baseline methods."
SP:d9406fdf0a180a5efc6f15ba8739524665f0f9d2,"This paper proposes Lazy-CFR, a counterfactual regret minimization (CFR) algorithm that avoids traversing the whole game tree in each round, which is time-consuming in large-scale games. The authors prove that the regret of the proposed algorithm is almost the same as that of the vanilla CFR and only needs to visit a small portion of the game tree. Empirical results show that the proposed method is provably faster than the vanilla one."
SP:023aa3dca1cf7992b22993a7088e8a74c92bb47e,"This paper proposes a method for Unsupervised Domain Adaptation (UDA) where the goal is to learn transferable features by minimizing the feature distribution discrepancy between the source and target domains. The proposed method, Distribution Matching Prototypical Network (DMPN), uses explicit feature distribution modeling to model the deep features from each domain as Gaussian mixture distributions. To learn both discriminative and domain invariant features, DMPN fine-tune the network to minimize the cross-entropy loss on the labeled source data and domain discrepancy losses. Extensive experiments on Digits Image transfer tasks and synthetic-to-real image transfer task demonstrate the proposed method can provide superior results than state-of-the-art approaches."
SP:40be996e8bb86e887077b762b87c7c34a786ac98,"This paper proposes a conditional conditional continuous normalizing flow (CNF) model that partitions the latent space into a class-specific supervised code and an unsupervised code that is shared among all classes for efficient use of labeled information. Since the partitioning strategy (slightly) increases the number of function evaluations (NFEs), the proposed method also employs gating networks to learn the error tolerances of its ordinary differential equation (ODE) solvers for better speed and performance. Empirical results on CIFAR-10 and time-series data demonstrate the effectiveness of the proposed approach."
SP:97764e3393216106ff2ac3f550845acf4636119f,"This paper studies the convergence of TD learning for value approximation in infinite-horizon discounted Markov Reward Processes (MRP) with nonlinear functions trained with the Temporal-Difference (TD) learning algorithm. In particular, the authors consider the setting where the parameters of the model vary only slightly during the training process, leading to a regime called lazy training. The authors prove exponential convergence to local and global minima of the TD learning algorithm in both the under- and over-parametrized regime, respectively, of a natural, weighted error function (the projected TD error), and illustrate such convergence properties through numerical examples. "
SP:c518e4030f12b0f59ad1d7c0fc0ebd313c68ef95,"This paper presents a method to train a reinforcement learning agent to generate observations that can be used to verify a hypothesis about the dynamics of the world. The agent is trained end-to-end with the reward. The authors show that agents trained with reward alone fail to learn to solve the problem of hypothesis verification. To solve this problem, the authors propose to train the agents as triplets (pre-condition, action sequence, post-condition). Once the agents have been pretrained to verify hypotheses with this structure, they can be fine-tuned to verify more general hypotheses. "
SP:6fa2f842b1bc993ed8024a3ce13dbd91529c61be,"This paper studies the problem of approximate reasoning in a fixed dimensional latent space, where the goal is to predict whether a statement can be rewritten by other theorems. The paper proposes to train a neural network to map mathematical formulas into a latent space of fixed dimension. The network is trained by predicting – based on the latent representation being trained – whether a given rewrite is going to succeed (i.e. returns with a new formula). For successful rewrites we also predict the latent representations of the resulting formula. For multi-step reasoning beyond two steps, we predict the future latent representations based on previous latent representation only - without seeing the intermediate formula. The experiments show that even after nine steps of reasoning, neural networks show non-trivial reasoning capabilities, despite not being trained on this task directly."
SP:a77ab500a5e7d4ea8430871d1e603941e92974fd,"This paper proposes a method to learn depth estimation from images with very sparse ground truth. The method is inspired by natural agents, who interact with the environment via visual and haptic feedback. The authors propose a global-local network architecture to learn from such sparse supervision. Experiments on several datasets show that the proposed model can learn monocular dense depth estimation when trained with sparse groundtruth, even a single pixel per image. "
SP:2afba5e24478da4e9d493887c7cf00e288cc0deb,"This paper extends the idea of word pieces in natural language models to machine learning tasks on opaque ids. This is achieved by applying hash functions to map each id to multiple hash tokens in a much smaller space, similarly to a Bloom filter. The authors show that by applying a multi-layer Transformer to these Bloom filter digests, they are able to obtain models with high accuracy. They outperform models of a similar size without hashing. "
SP:745dd86d7f7bba79a02d27922003b764b620f83e,"This paper proposes a learning-based agglomerative clustering framework to learn a grouping policy to progressively group small part proposals into bigger ones in a bottom-up fashion to restrict the local context for extracting part-level features, which encourages the generalizability to unseen categories. The proposed method is evaluated on PartNet, a large fine-grained 3D part dataset. The results show that the proposed method can transfer knowledge of parts learned from 3 training categories to 21 unseen testing categories without seeing any annotated samples."
SP:868fc6df740b04963442d5abcfe2f4845585cfc8,"This paper proposes a technique called ""neuron editing"" that learns how neurons encode an edit for a particular transformation in a latent space to generate transformed data by defining an editing transformation on those neurons. By performing the transformation in the latent space, the proposed method is able to perform fairly complex and non-linear transformations to the data with much simpler distribution shifts to the neuron’s activations. The proposed method has the advantage of being generally applicable to a wide variety of data domains, modalities, and applications. "
SP:6dee6932e64fe47bb44dd42fc242fa9d89b8d89c,"This paper studies the problem of few-shot image segmentation, where the goal is to learn a model that can generalize well to many-shot tasks. The authors propose a method to learn initializations for deep neural networks that must produce dense, structured predictions given an arbitrary amount of training data for a new task. The proposed method is based on first-order meta-learning of initialization for neural network initializations. The method is tested on the FSS-1000 dataset and the FP-k dataset. The results show that the proposed method outperforms random and ImageNet-trained initializations on both the few shot and many shot tasks."
SP:ec6f390f6d45fb79c33ae5d9c8a24cadb96fbd60,This paper proposes a method for semi-supervised few-shot learning based on Prototypical Networks (PN) to learn representations that are compact and well-separated. The proposed method is based on a random walk loss that encourages prototypical magnetization of the learning representation. Experiments show that the proposed method outperforms the state-of-the-art methods on a variety of benchmark datasets.
SP:d12e687bd2ee9fa60554312e644bb0a6487974f1,"This paper proposes a method for self-supervised learning of multi-sensor representations for remote sensing. The proposed method, Contrastive Sensor Fusion (SSF), trains a single encoder to produce representations from any possible combination of channels from the input sensors. The method is trained on a dataset of 47 million unlabeled images from 47 million scenes, each consisting of four bands for each of three different sensors over that scene. The results show that the proposed method outperforms the baselines on a remote sensing classification task. "
SP:4d8e054f07006b4f896721b5c24da805727d2c22,This paper proposes a new method for fine-tuning neural networks that trains the unpruned weights from their final trained values using a small fixed learning rate. The proposed method rewinds the weights to their values from earlier in training and retrains them from there using the original training schedule. The authors compare the proposed rewinding method with several other state-of-the-art network-specific pruning methods and show that the proposed method outperforms the other methods.
SP:3bb1c79f9482e09828eda45fbb2e654f37219365,"This paper studies the relationship between output margin and generalization in deep neural networks. The authors propose a new notion of margin, called the all-layer margin, which they call the “all-layer” margin. They show that it has a clear and direct relationship with generalization for deep models. They provide tighter generalization bounds for neural nets that depend on Jacobian and hidden layer norms and remove the exponential dependency on depth. They also present a theoretically inspired training algorithm for increasing the all layer margin. "
SP:3d44f27468087280e85dfb1fc7291db05179fe6d,"This paper proposes a knowledge-grounded dialogue generation model with a disentangled decoder to isolate parameters that depend on knowledge-based dialogues from the entire generation model. The main idea is to pre-train the model with ungrounded dialogues and unstructured documents, while the remaining small parameters can be well fitted using the limited training examples. Empirical results on two benchmarks indicate that with only 1/8 training data, the proposed model can achieve the state-of-the-art performance and generalize well on out of domain knowledge."
SP:9b555f7fe743f5effdbdc8701ed519ce3159c4b0,"This paper proposes a mirror-generative neural machine translation model (MGNMT) that integrates the source to target translation model, the target to source translation model and two language models into a single unified architecture. The proposed MGNMT achieves competitive performance on parallel bilingual data, while it does advance training on non-parallel data. Experiments show that the proposed method outperforms existing approaches in a variety of language pairs and scenarios, including resource-rich and low-resource situations."
SP:d7a530a0ec4112095a58cef4cda9646f8ca6449d,"This paper studies the effect of the entropy term in the Soft Actor Critic (SAC) algorithm on the performance of maximum entropy RL algorithms on Mujoco tasks. The authors show that the SAC algorithm has a bounded action space, and propose a new algorithm that does not use entropy maximization. They also propose a simple non-uniform sampling method for selecting transitions from the replay buffer during training. The proposed algorithm is shown to outperform SAC and achieves state-of-the-art performance on continuous control tasks."
SP:545e8da553fcb47d84eaa044d8a4947d3cd3230e,"This paper studies the vulnerability of industrial copyright detection systems to adversarial attacks. The authors propose an adversarial attack method based on a well-known music identification method and implement this system in the form of a neural net. They then attack this system using simple gradient methods to fool industrial systems, including the AudioTag copyright detector and YouTube’s Content ID system. "
SP:b511822850da3bf1079a36ed6f5ad4db80fbc424,"This paper proposes a method to decompose the final activation map of a metric learning model into a point-to-point intensity map, which can be used to show the relationship between two images. The proposed method can be applied to a wide range of metric learning applications and provides valuable information for understanding the model. The method is evaluated on two applications, i.e. cross-view pattern discovery and interactive retrieval. "
SP:67bf71219fe6bedec5f5525200e734638e4a6ca2,"This paper proposes a new algorithm for online lifelong learning that combines model-based planning with model-free learning. The proposed algorithm, AOP, is able to call upon more extensive planning only when necessary, leading to reduced computation times. Experiments show that AOP gracefully deals with novel situations, adapting behaviors and policies effectively in the face of unpredictable changes in the world."
SP:11159cb878a436a5d4fc6edb4132f2cc3c1b3f72,"This paper proposes to replace the traditional softmax attention mechanism by two alternative sparsity-promoting transformations: sparsemax and Total-variation Sparse Attention (TVMAX). With sparsemax, the authors obtain sparse attention weights, selecting relevant features, to encourage sparsity and encourage fusing of the related adjacent spatial locations. By selecting relevant groups of features, the TVMAX transformation improves interpretability. TVMAX outperforms the other compared attention mechanisms in terms of humanrated caption quality and attention relevance."
SP:fb0c3ce3db6ad674ddc615bdc6203cdcbe42c804,"This paper proposes a generative model for predicting the evolution of dynamic graphs. Specifically, the authors use a graph neural network along with a recurrent architecture to capture the temporal evolution patterns of dynamic graph topology. The proposed model predicts the topology of the graph at the next time step and constructs a graph instance that corresponds to that topology, which is then used to generate the graph instance. The authors evaluate the proposed model on several artificial datasets as well as real-world datasets."
SP:ff722957a1765c0568426ed88dd910a6b74054ef,"This paper proposes a method for imputing missing features and estimating the distribution of target assignments given incomplete data. The proposed method trains a simple and effective generator network to generate imputations that a discriminator network is tasked to distinguish. Following this, a predictor network is trained using the imputed samples to capture the classification uncertainties and make predictions accordingly. The method is evaluated on CIFAR-10 image dataset as well as three real-world tabular classification datasets under different missingness rates and structures."
SP:c051b0fe779d9e4131016970b7ba469b596f3009,"This paper proposes a new method for off-policy estimation for long-horizon problems. The proposed method is based on the RKHSs, a kernel-based estimator that computes importance ratios of stationary distributions, without knowing how the data are collected. The authors show that the proposed method outperforms the state-of-the-art importance-sampling-based methods. The method is evaluated on a number of synthetic and real-world datasets."
SP:065c900843011a71b70ed35357a2f71fe83872a7,"This paper proposes a method to compute the conditional likelihood and responsibility probability of a Gaussian mixture model (GMM), which is a probabilistic framework that allows us to define a dataset containing K different modes associated with Gaussian distributions. In a traditional GMM paradigm, it is straightforward to compute in closed-form, conditional likelihood p(x|k, \�), as well as responsibility probability p(k|x, θ) which describes the distribution index corresponds to the data. However, the Euclidean distances between the data do not allow them to form mixtures naturally, nor it’s feasible to compute responsibility distribution, making GMM unable to apply. To this end, the authors propose a modified GAN framework to compute these probabilities at the data's latent space z instead of x, where z is the corresponding latent representation of x. The proposed method is trained with the GAN in an end-to-end fashion. "
SP:2da1608209058d214f8671062cc9eb0833ba4831,"This paper proposes a method to train large capacity neural networks with significantly improved accuracy and lower dynamic computational cost by gating the deep-learning architecture on a fine-grained-level. Individual convolutional maps are turned on/off conditionally on features in the network. To achieve this, the authors introduce a new residual block architecture and a batch-shaping tool to match the marginal aggregate posteriors of features in a neural network to a pre-specified prior distribution to force gates to be more conditional on the data. The results show that the proposed method can slim down large architectures conditionally, such that the average computational cost is on par with a smaller architecture, but with higher accuracy."
SP:f90e9f0eb53f92601bdfa3f7bf86f71d037aad30,This paper proposes a probabilistic importance inference approach for pruning deep neural networks (DNNs) using a non-paremetric scoring test and keeping only those significant ones. The proposed method is based on the PCII method and algorithm and establishes theoretical properties for using the method to infer dependence between a network connection and the DNN output. The experimental results show that the proposed approach achieves better lossless compression rates than existing techniques.
SP:64cbbb6a2f6847ef71cd5a23ba3e4cc5c815a56e,"This paper proposes a method for hierarchical reinforcement learning based on identifying behavioral ‘motifs’—repeated action sequences that can be compressed to yield a compact code of action trajectories. The proposed method is based on iterative convolutional sparse coding and compression, with structure similar to classic string compression methods such as the Nevill-Manning algorithm. The learned temporally extended actions provide new action primitives that can participate in deeper hierarchies as the agent learns. Experiments show that the proposed method can be used to accelerate learning in recursively more complex tasks through transfer."
SP:e1ccfb3a684aef8a0fb36194eb16af1667811e81,"This paper proposes a Hierarchical Bayes Autoencoder (HBAE) for image generation. The HBAE uses a multi-modal energy-based model (EBM) for the decoder instead of the commonly adopted unimodal Gaussian distribution. The EBM is trained using variational inference to recover latent codes conditioned on inputs. The proposed method is also able to model sets by inferring a latent code for a set of examples, and sampling set members through the multimodal decoder."
SP:1130a391afa30d1e0fddadedd2a3aaa70a4cb751,"This paper proposes a new normalization technique called cross-normalization, which is an extension of batch normalization that re-centers data for two different distributions, as present in off-policy learning. The authors show that the proposed technique improves the performance of TD3 and DDPG on MuJoCo benchmark tasks. The paper also evaluates the stability of the proposed method in the context of linear function approximators."
SP:f9cafaa5131176290fa069e6d24046c079cd9eea,"This paper proposes an adversarial training strategy to learn discriminative features unbiased and invariant to confounder variables. The proposed method is based on adversarial loss function. The method is evaluated on synthetic data, medical images, and a gender classification dataset. The results show that the learned features by the proposed method are uncorrelated with the bias or confounders variables. "
SP:783049ff463edd1283c058c6106a3e1f9a033df4,"This paper proposes a lightweight Transformer-based model for character-level language modeling based on Transformer that factorizes the calculation paths by grouped embedding operators. The proposed Group-Transformer employs inter-group linear operators to prevent performance degradation from the group strategy. Extensive experiments on two benchmark datasets, enwik8 and text8, show the effectiveness of the proposed method."
SP:946c26d371297c88d0ac246257104099b4585edc,"This paper proposes a method for training hierarchical-latent-based generative models with deep latents based on Optimal Transport (OT). Optimal transport is an alternative, non-likelihood-based framework for training generative model with appealing theoretical properties, in principle allowing easier training convergence between distributions. The authors propose STACKEDWAE, a novel objective function based on OT, designed specifically for generative modelling with latent hierarchies, and show that it is able to fully leverage its hierarchy of latents. They also show that the proposed method is more effective than the original Wasserstein Autoencoder with Maximum Mean Discrepancy (MMD) divergence."
SP:309b47441d227ffa33f96f9f16f2addc607e5bb0,"This paper proposes an autoregressive video generation model based on a three-dimensional self-attention mechanism to generate high-quality video continuations. The proposed method is based on the three-D Self-Attention mechanism (SAT), which is an extension of the attention mechanism used in self-supervised video generation. The method is evaluated on the Kinetics dataset, a large scale action recognition dataset comprised of YouTube videos. The results show that the proposed method achieves competitive results across multiple metrics. "
SP:ad8fcdbc47a50dd2bf58aba2bc6cfe199e84dd4d,"This paper proposes an adversarial generative model for zero-shot ICD coding, where the goal is to improve the prediction on codes that have no labeled data without compromising the performance on seen codes. The proposed method, AGMC-HTS, generates semantically meaningful features by exploiting ICD code hierarchical structure and a novel cycle architecture that reconstructs the relevant keywords. Extensive experiments demonstrate the effectiveness of the proposed method on the MIMIC-III dataset."
SP:3ce82ae297e5759ab957babe9927062e7a71b0ba,"This paper proposes a method for self-supervised representation learning to improve sample efficiency in reinforcement learning (RL) from pixel observations. The authors propose a forward prediction objective for simultaneously learning embeddings of states and action sequences to capture the structure of the environment’s dynamics, enabling efficient policy learning. The proposed method achieves efficient learning of high-quality policies on goal-conditioned continuous control with pixel observations in only 1-2 million environment steps. The results show that the proposed method improves sample efficiency and peak performance of model-free RL on control from low-dimensional states."
SP:11ce1616e721340eea9e80dad7460c77355ac7d1,"This paper proposes a meta-learning framework that automatically extracts the cross-task relations and constructs the meta-knowledge graph, which can quickly find the most relevant structure and tailor the learned structure knowledge to the task-specific meta-learner. The proposed framework is motivated by the way of knowledge organization in knowledge bases, and is able to capture complex relations between tasks. Experiments on toy regression and few-shot image classification demonstrate the superiority of the proposed method over state-of-the-art baselines."
SP:37c209cd1c628b5c2f2b282fbeaf4bbf437c7670,"This paper proposes a method for controlling attributes of the generated language (e.g. switching topic or sentiment) without modifying the model architecture or fine-tuning on attribute-specific data. The method combines a pretrained LM with one or more simple attribute classifiers that guide text generation without any further training of the LM. In the canonical scenario, the attribute models are simple classifiers consisting of a user-specified bag of words or a single learned layer with 100,000 times fewer parameters than the LM and are trained with a forward and backward pass. The authors show that the PPLM approach can be used to detoxify instances where generation of toxic content is likely by following the negative gradient of a model trained to detect toxicity. "
SP:12d0980bfea2de880905a0b87b40856969bb1c58,"This paper proposes a novel unsupervised learning framework for learning representations with unlabeled data, where the noisy input data is generated by corrupting clean data in the gradient domain. The proposed method is based on denoising autoencoders (DAEs) and can be generalized to span multiple scales with a Laplacian pyramid representation of the input data. Experiments on several visual benchmarks demonstrate that better representations can be learned with the proposed approach, compared to its counterpart with single-scale corruption, and the learned representations perform well when transferring to other vision tasks."
SP:12afc1b259e51a31cbeb72366d2b93fbee1aafaa,This paper proposes a method to verify the robustness of neural networks to under-sensitivity in the context of natural language inference. The main idea is to use interval bound propagation (IBP) to verify whether a particular sample is free from the under-sensitive problem. The method is applied to the decomposable attention model and shows that the model is robust to small fractional deletions of the input text. The proposed method is tested on the SNLI and MNLI datasets. 
SP:14257af9fe83522c6e5b5d6b0d68945b944e30fb,"This paper studies the problem of deep Q-learning with a replay memory, where the replay memory is used to store past experience and derive all network updates in a continuous state-action space. The authors propose to represent these transitions in a data graph and link its structure to soft divergence. By selecting a subgraph with a favorable structure, the authors construct a simple Markov Decision Process (MDP) for which exact Q-values can be computed efficiently as more data comes in – resulting in a QGRAPH. They show that the Q-value for each transition in the simplified MDP is a lower bound of the Q value for the same transition in original continuous Q-Learning problem. By using these lower bounds in TD learning, their method is less prone to soft divergence and exhibits increased sample efficiency while being more robust to hyperparameters. "
SP:c92c97e47d8b218dfd009bbf61f5b3547b395f91,"This paper studies the effect of the embedding complexity on unsupervised domain adaptation (UDA) in the context of multilayer neural networks. In particular, the authors show that the complexity of the layer-dependent complexity tradeoff affects the upper bound on the risk of the target domain. The authors propose a strategy that mitigates sensitivity to the complexity and achieves performance on par with or better than the best layer-independent complexity trade-off. "
SP:f3f3c6fbae757836551b3f1ee54a7d1e040132b8,"This paper studies generalization error bounds for learning general non-convex objectives in stochastic Langevin dynamics (SGLD) and several other noisy gradient methods (e.g., momentum, mini-batch and acceleration, Entropy-SGD). The main contribution of this paper is to develop a new framework, termed Bayes-Stability, for proving algorithm-dependent generalisation error bounds. The new framework combines ideas from both the PAC-Bayesian theory and the notion of algorithmic stability. The authors show that the new bounds can distinguish randomly labelled data from normal data, which provides an explanation to the intriguing phenomena observed in Zhang et al (2017a)."
SP:a82fcd1d3196ddf078cfe8f4bc6f445d9d2bdc11,"This paper investigates the role of the hippocampus in continual learning in the context of continual learning of two different spatial navigation strategies. The authors analyse population-level activity of hippocampal CA1 neurons in the hippocampus of rodents learning to perform allocentric and egocentric spatial tasks. They find that hippocampal neurons encode relevant task variables such as decisions, navigational strategies and reward location. They compare this hippocampal features with standard reinforcement learning algorithms, highlighting similarities and differences. Finally, they demonstrate that a standard deep reinforcement learning model achieves similar performance when compared to animal learning, but fails to mimic animals during task switching."
SP:51acf1f8108683dce543a1fb4a61fbd593f9b4cc,"This paper proposes a tree search based policy optimization method for continuous environments. The proposed method, called TPO, is based on the MCTS tree search algorithm. The main contribution of this paper is to reduce the branching factor of the tree search by drawing only a few action samples from the policy distribution and defining a new loss function based on trajectories’ mean and standard deviations. Experimental results show that TPO significantly improves the performance of the baseline policy optimization algorithm PPO."
SP:1ce3bc4d31712886f7dcada5b5ae67c3c376819a,"This paper studies the lottery ticket hypothesis, which claims that neural networks contain sparse subnetworks, which, if appropriately initialized (the winning tickets), are capable of matching the accuracy of the full network when trained in isolation. This paper aims to answer the following open questions: can we find winning tickets with few data samples or few labels? Can we even obtain “good” tickets without supervision? The authors find that winning tickets found in these scenarios are, perhaps surprisingly, competitive with winning tickets generated on the full ImageNet dataset when evaluated on ImageNet classification task."
SP:dbcebe5b73486885d9f4478b258047c02f8481a2,This paper studies the problem of excessive prediction undersensitivity in neural reading comprehension models. The authors propose a noisy adversarial attack that searches among semantic variations of comprehension questions for which a model still erroneously produces the same answer as the original question – and with an even higher probability. They show that SQuAD2.0 and NewsQA models are vulnerable to this attack and commit a substantial fraction of errors on adversarially generated questions. They further propose a data augmentation and adversarial training as defence strategies that substantially decrease a model’s vulnerability to undersensitivity attacks on held out evaluation data. 
SP:5da870060778de460c1abe91562d6f3e707efef4,This paper proposes a model-based approach to safety that allows the agent to look into the future and be aware of the future consequences of its actions. The authors learn the transition dynamics of the environment and generate a directed graph called the imaginative module. The imagination module is used to predict whether the current actions of the agent can cause it to end up in dangerous states in the future. Experiments on two gridworld environments and a self-driving car simulator show that the proposed method improves safety throughout learning and at convergence.
SP:c2796f28fb067138303df8d424d646f4ada31558,"This paper proposes a novel method to learn finite differences inspired by physics equations. The method is based on a graph neural network (GNN) architecture, which leverages data-driven end-to-end learning to discover underlying dynamical relations between the spatial and temporal differences in given sequential observations. The proposed method is evaluated on synthetic data and real-world climate observations from weather stations. "
SP:db8ed4f4fc3967f5dd4d208d5d029730eb99e840,"This paper studies the problem of training structured neural networks with nonsmooth regularization (e.g. `1-norm) and constraints. The authors formulate training as a constrained nonconvex optimization problem and propose a convergent proximal-type stochastic gradient descent (ProxSGD) algorithm. They show that under properly selected learning rates, with probability 1, every limit point of the sequence generated by the proposed Prox SGD algorithm is a stationary point. Finally, they show by extensive numerical tests that the proposed algorithm can be used to train either sparse or binary neural networks. "
SP:2ca1f4da9faee79768764cda5d09d949cc942acc,"This paper proposes an end-to-end differentiable compression method for lossy image compression. The proposed method is based on a non-deterministic compression codec, which maps the input image to a distribution in continuous space from which a sample can be encoded with expected code length being the relative entropy to the encoding distribution, i.e. it is bits-back efficient. The method is trained using standard gradient-based optimizers and is shown to be competitive with the state-of-the-art on the Kodak dataset."
SP:788fd2b6956dd69bf7752d39ea21883947128c8a,"This paper proposes a new low-level computer vision (CV) model for super-resolution (SR) with compressed compressed JPG images. The proposed method is based on two components: a functional sub-model to recover information for C-JPG images, and a cycle loss to improve the performance of the SR model. Experiments show that the proposed method achieves better results than the state-of-the-art methods. "
SP:18dd92f2f55020be4f5a089b3b251327e47886f4,"This paper proposes a convolutional network architecture to estimate a full surface of pass probabilities from single-location labels derived from high frequency spatio-temporal data of professional soccer matches. The network is able to perform remarkably well from low-level inputs by learning a feature hierarchy that produces predictions at different sampling levels that are merged together to preserve both coarse and fine detail. The approach presents an extreme case of weakly supervised learning where there is just a single pixel correspondence between ground-truth outcomes and the predicted probability map. By providing not just an accurate evaluation of observed events but also a visual interpretation of the results of other potential actions, the approach opens the door to spatiotemporal decision-making analysis, an as-yet little-explored area in sports."
SP:1ae31baf383fc520687b255d9cac14c3b040e253,"This paper proposes IGMC, an inductive matrix completion method without using side information. IGMC trains a graph neural network (GNN) based purely on 1-hop subgraphs around (user, item) pairs generated from the rating matrix and maps them to their corresponding ratings. It achieves highly competitive performance with state-of-the-art transductive baselines. In addition, IGMC is inductive – it can generalize to users/items unseen during the training and can even transfer to new tasks. "
SP:c5cb1b50e17a69e88d5ae28848e265215162da1e,"This paper considers the problem of unconstrained minimization of a smooth objective function in R in the setting where only function evaluations are possible. The authors propose and analyze stochastic zeroth-order method with heavy ball momentum. They show new complexity results for non-convex, convex and strongly convex functions. They test their method on a collection of learning to continuous control tasks on several MuJoCo Todorov et al. environments."
SP:a216cfc29937eb398ea98cb1aea3481c9aed8240,"This paper proposes Action Semantics Network (ASN), a deep reinforcement learning (DRL) algorithm for multi-agent systems (MASs) that explicitly considers action semantics between agents. In particular, the proposed method characterizes different actions’ influence on other agents using neural networks based on the action semantics. The proposed method can be easily combined with existing DRL algorithms to boost its learning performance. Experimental results on StarCraft II micromanagement and Neural MMO show ASN significantly improves the performance of state-of-the-art DRL approaches compared with several network architectures."
SP:efaf3a440dc17e05177832083ffbc23760ed7c97,"This paper proposes to exploit the underlying structures of the state-action value function, i.e., Q function, for both planning and deep RL. Specifically, the authors investigate the low rank structure, which widely exists for big data matrices, and verify empirically the existence of low-rank Q functions in the context of control and deep reinforcement learning tasks. The authors propose a general framework to exploit this structure and extend it to value-based methods. Extensive experiments on control tasks and Atari games confirm the efficacy of the proposed method."
SP:430336893b247b7bd45687d78b0d0511a7369e87,"This paper proposes a new algorithm for off-policy deep reinforcement learning (DRL) in the batch setting. The proposed algorithm, called Best-Action Imitation Learning (BAIL), first selects from the batch the actions it believes to be high-performing actions for their corresponding states; it then uses those state-action pairs to train a policy network using imitation learning. Although BAIL is simple, it achieves state of the art performance on the Mujoco benchmark."
SP:94078964876667e8a5d9ae7728d779d5b91a576e,"This paper proposes DeepXML, a deep extreme multi-label learning method for short text documents. The proposed method splits training of head and tail labels into two parts: head-tail splits and tail-head splits. The head labels are learned by learning word embeddings on head labels and transferring them through a novel residual connection to data impoverished tail labels. The tail labels are also learned by extending the state-of-the-art negative sub-sampling techniques and re-ranking the set of predicted labels to eliminate the hardest negatives for the original classifier. "
SP:b1b1252d82fa1bea18309e0b0b894e0f28f48bc9,"This paper proposes an end-to-end trainable variational variational hashing-based collaborative filtering approach that uses the novel concept of self-masking: the user hash code acts as a mask on the items (using the Boolean AND operation), such that it learns to encode which bits are important to the user, rather than the user’s preference towards the underlying item property that the bits represent. This allows a binary user-level importance to be computed for each item without the need to store additional weights for each user. The proposed method outperforms state-of-the-art baselines on 4 datasets and achieves significant gains of up to 12% in NDCG."
SP:80898d0f2b2c8dc3388fa9164e529eae36aa1b21,"This paper studies the problem of mode collapse in GANs. The authors propose a new metric for quantitatively measuring the mode collapse of GAN images. The metric is based on a set of statistical tools that are broadly applicable to quantitatively measure mode collapse. The paper also proposes two methods to calibrate the GAN learned distribution, i.e., latent space reshaping via Gaussian mixture models, and importance sampling, to alleviate mode collapse without re-touching training data. "
SP:e5b5dda2f024cfda10526e744aa035e0165af58a,"This paper studies the training of over-parametrized neural networks that are beyond the NTK regime but are still governed by the Taylor expansion of the network. The authors propose the idea of randomizing the neural networks, which allows them to escape their NTK and couple with quadratic models. They show that the optimization landscape of randomized two-layer networks are nice and amenable to escaping-saddle algorithms. They also show that after randomization, the linear NTK f (1) is no longer the dominant term, and so the gradient dynamics of the neural net is not coupled with NTK. "
SP:cef7ea513eb3e42be4edf40e4ee1701a969bcbea,"This paper proposes a method to evaluate the effectiveness of graph convolutional filters for semi-supervised node classification tasks. The method is based on the Graph Filter Discriminant Score (GFD Score), which is a measure of how well a filter performs on a given graph in terms of node classification. The authors find that there is no single filter that performs the best on all possible graphs, and graphs with different properties are in favor of different graph convolutionsal filters. Based on these findings, the authors propose a method called Adaptive Filter Graph Neural Network (AFGNN) that can adaptively learn data-specific filters. AFGNN leverages graph filter assessment as an extra loss term and learns to combine a set of base filters. Experiments on both synthetic and real-world benchmark datasets demonstrate that the proposed model has the flexibility in learning an appropriate filter and consistently provides state-of-the-art performance across all datasets."
SP:3c5ec9dbcf914c8901e4e35f3c2a7df4707422ab,"This paper studies the problem of distributionally robust optimization (DRO) for over-parameterized neural networks. The authors show that applying group DRO to overparametrized neural networks fails: these models can perfectly fit the training data, and any model with vanishing average training loss also already has vanishing worst-case training loss. Instead, the poor worst case performance arises from poor generalization on some groups. To solve this problem, the authors propose a stochastic optimization algorithm, with convergence guarantees, to learn models that instead minimize the worst case training loss over a set of pre-defined groups. The proposed algorithm achieves substantially higher worst-group accuracies on a language inference task and two image tasks, while maintaining high average accuracies."
SP:eb1ee2e0f7d8466a04b58508ecb3da7b667eecdf,"This paper proposes a new local explanation method for black-box classifiers. The proposed method is based on the concept of distribution controllers and integrate it with a neural network to directly guide the distribution of relevance scores. Then, a classification loss is introduced to optimize the proposed predictor to enable discriminative scores over supporting features, and facilitate the setting of involved hyperparameters. The experimental results demonstrate that the proposed method also outperforms others in terms of faithfulness and explainability."
SP:32ea7cbc47cbdb1f703f4e07c31ce90abe083424,"This paper proposes a method to train a deep network for image reconstruction and classification problems that can be trained to detect multiple object instances, without any supervision regarding their whereabouts. The network learns to extract the most significant K patches, and feeds these patches to a task-specific network to solve a domain specific problem. The method is able to learn to detect recurring structures in the training dataset by learning to reconstruct images. It can also learn to localize structures when only knowledge on the occurrence of the object is provided, and in doing so it outperforms the state-of-the-art."
SP:da1c5f6351d531482e90b86c3cceb52850c520de,"This paper proposes a neural program synthesis algorithm, AutoAssemblet, that can generate assembly code that can be executed to match a state change inside the CPU and RAM. The algorithm is learned via self-learning reinforcement learning that explores the large code space efficiently. Policy networks and value networks are learned to reduce the breadth and depth of the Monte Carlo Tree Search, resulting in better synthesis performance. The authors also propose an effective multi-entropy policy sampling technique to alleviate online update correlations. "
SP:0d4687fc36c02e27d1b95d532a3947589f92b1da,This paper studies the effect of model architecture on the speed of training in the context of gradient descent optimization. The authors use the ideas from prior work that shows gradient descent can be modeled as a first-order ODE and use ODE’s coefficient matrix H to characterize the convergence rate. They introduce a simple analysis technique that enumerates H in terms of all possible “paths” in the network. They show that changes in model architecture parameters reflect as changes in the number of paths and the properties of each path.
SP:3e3bc8f617df742a395e7d315ec3810a42071294,"This paper studies the connection between strongly overparametrized neural networks (NNs) and interpolating kernel methods. The authors show that the test error of wide ReLU-NNs trained with squared loss are essentially a sum of two parts: the first is the minimum complexity solution of an interpolating kernels method, while the second contributes to the test errors only and depends heavily on the initialization. This decomposition has two consequences: (a) the second part becomes negligible in the regime of small initialization variance, which allows the authors to transfer generalization bounds from minimum complexity interpolation kernel methods to NNs; (b) in the opposite regime, the test-error of wide NNs increases significantly with the initialization variance."
SP:b15ea009a36a0a76728dfc103d668d6781a8a99a,"This paper proposes a new method for 3D object detection based on pseudo-LiDAR. The proposed method is based on a combination of two existing methods: 1) a depth-propagation algorithm to estimate the depth of a depth map, and 2) a loss function to estimate depth of faraway objects. The method is evaluated on the KITTI object detection benchmark, where the proposed method outperforms the previous state-of-the-art detection accuracy by 40%."
SP:983d84502264633f3385d426c1d4601a0744ea9a,"This paper proposes a principled adversarial example detection method that can withstand norm-constrained white-box attacks. The proposed method trains K base detectors where the i-th detector is trained to discriminate natural data of class i from adversarial examples perturbed from other classes. At inference time, the proposed method uses the predicted label (say k) of the input to identify whether the input is a natural sample (of class k) or an adversarial sample (perturbed from the other classes). The authors further devise a generative approach to detecting/classifying adversarial samples by interpreting each base detector as an unnormalized density model of the classconditional data. "
SP:461e9308d050bc3dc7b35233452668bb31f5d491,"This paper proposes Rewarding Impact-Driven Exploration (RIDE), a novel intrinsic reward for exploration in RL that encourages the agent to take actions which result in impactful changes to its representation of the environment state (see Figure 1 for an illustration). The proposed method is evaluated on multiple procedurally-generated tasks in MiniGrid, as well as on tasks with high-dimensional observations used in prior work. The experiments demonstrate that this approach is more sample efficient than existing exploration methods, particularly for procedurally generated MiniGrid environments. The authors also analyze the learned behavior and intrinsic reward received by the agent."
SP:c002c20b5e8696588e029c0f65e88860418826c4,"This paper studies the problem of large-scale query-document retrieval, where the goal is to return the set of relevant documents (e.g., paragraphs containing the answer) from a large document corpus. The retrieval phase first reduces the solution space, returns a subset of candidate documents, and then re-ranks the documents in the scoring phase. The authors propose a two-tower retrieval model to solve this problem. They show that the key ingredient of learning a strong embedding-based Transformer model is a set of paragraph-level pre-training tasks. The results show that with these tasks, the Transformer models can achieve better performance than the widely-used BM-25 embedding models."
SP:4e161e08a624f87633dfb49dfd46bd1665e15189,"This paper proposes a new graph convolution operation called bipartite graph convolutions (BGP) to replace graph pooling and non-parameterized pooling in graph neural networks (GNNs). In particular, the proposed BGP is a parametric graph-convolution operation that can be applied to both input and output graphs of the same graph. The authors show that the proposed method can be used to replace pooling layers in GNNs with a single parametric BGP operation. The proposed method is shown to be more flexible and adaptable than existing GNN architectures. "
SP:9b9b6ee9014e5538442ba76d6059ed01f59ec8fb,"This paper proposes to use feature-wise transformation layers for augmenting the image features using affine transforms to simulate various feature distributions under different domains in the training stage to improve the few-shot classification performance under domain shift. The proposed method is applied to several metric-based few shot classification methods, including MatchingNet (Vinyals et al., 2016), RelationNet (Sung et al. 2018), and Graph Neural Networks (Garcia & Bruna, 2018) with extensive experiments under the domain generalization setting. Experiments show that the proposed method can improve the performance of the proposed methods."
SP:df46627cb984a56bba36d510bfc52e00751e9107,"This paper proposes a continuous convolutional network for Lagrangian fluid simulation. The proposed method uses spatial convolutions as the main differentiable operation that relates particles to their neighbors. The authors show that the proposed method can simulate different materials, generalizes to arbitrary collision geometries, and can be used for inverse problems. "
SP:3e17f333cf07183969c02bb66afdd3ccbf25bb19,"This paper proposes BatchEnsemble, a new ensemble method for learning deep neural networks. The proposed method is based on the Hadamard product of a shared weight among all ensemble members and a rank-one matrix per member. The method is parallelizable across devices, where one device trains one member, and parallelizable within a device, where multiple ensemble members are updated simultaneously for a given mini-batch. The authors show that the proposed method can achieve comparable performance to progressive neural networks while having a much lower computational and memory costs. "
SP:a123a425ef3eb6188833d5a42e851bc3fa59df65,"This paper proposes a neural network-based PDE solver for forward and inverse problems. The solver is grid free, mesh free and shape free, and the solution is approximated by a neural networks. The network is trained to minimize deviations of the learned function from the strong PDE solution and satisfy the boundary conditions. The resulting solution is an explicit smooth differentiable function with a known analytical form. This framework enables the solution of high order non-linear PDEs. The proposed algorithm is a unified formulation of both forward and inverse problems. "
SP:973d0ad0faadcf7298300f2758de9154205e7113,"This paper studies the architecture of Binarized Neural Networks (BNNs), a class of neural networks that allow equivalent representation in Boolean logic and can be analyzed formally with logic-based reasoning tools like SAT solvers. The main bottleneck for all methods is their ability to reason about large BNNs efficiently. The authors analyze architectural design choices of BNN and discuss how they affect the performance of reasoning tools such as SAT solver. They propose changes to the BNN architecture and the training procedure to get a simpler network without sacrificing accuracy on the primary task. The experimental results demonstrate that their approach scales to larger deep neural networks compared to existing work for existential and probabilistic queries. "
SP:ca985e758f195bd04fb9f24b290a83974d6d308b,"This paper studies the expressive power of graph neural networks falling within the message-passing framework (GNNmp). Two results are presented. First, GNNmp are shown to be Turing universal under sufficient conditions on their depth, width, node attributes, and layer expressiveness. Second, it is discovered that GNNMP can lose a significant portion of their power when their depth and width is restricted. "
SP:a98ae70a91850bbe624c307ba61d3daeb2494b82,"This paper proposes localised generative flows (LGFs) to learn target distributions with complicated topologies. LGFs are composed of stacked continuous mixtures of bijections, which enables each bijection to learn a local region of the target rather than its entirety. The proposed method is a generalization of existing flow-based methods, which can be used without modification as the basis for an LGF model. Experiments show that LGFs yield improved performance across a variety of density estimation tasks."
SP:3adc341dece170f428195e4dccadfb5f5daddf2d,"This paper investigates the role of environment bias in vision-language navigation (VLN) in VLN. In particular, the authors propose to re-split the environment into two parts: the training environment and the test environment, and propose to replace the low-level visual features with high-level semantic features to reduce the environment bias. The proposed semantic features are based on ground-truth semantic views, ground truth semantic views and learned semantic view features. Experiments show that these semantic features significantly reduce the performance gap between seen and unseen environments on multiple datasets. "
SP:298e0043e99f586d314fbd9d16fdc6ae885e1ebb,This paper studies the problem of using implicit human feedback to accelerate and optimize the training of deep reinforcement learning (DRL) agents. Human observers are placed on the scalp of an RL agent and measure the event-related electric potentials (EEGs) of the agent. These EEGs are then used as an auxiliary reward function to augment the agent’s learning in the RL tasks. The paper proposes two ways to obtain and accurately decode the error-related event potentials for state-action pairs in an Atari-type environment. 
SP:a8395f8b877e1eebaef9ff2e8b4e488d55a74ef4,"This paper proposes a method to compute the minimal-entropy positive images of a classifier and a test image. The goal is to minimize the amount of information (aka. entropy) required in individual test images to maintain correct classification. The proposed method is based on the notion of entropy that allows to combine and compare the effects of various types of reductions (e.g., crop, colour reduction, resolution reduction) on classification performance, in turn generalising similar methods explored in previous works. The authors propose two complementary frameworks for computing the minimal entropy positive images for both human and machine classifiers, in experiments over the ILSVRC test-set. "
SP:81cec8f907d8fa0653b5bc08af1f59bfefd49619,This paper studies adversarial perturbation defenses for convolutional neural networks. The authors identify a family of defense techniques that are based on the instability assumption and show that deterministic lossy compression algorithms and randomized perturbations to the input that all lead to similar gains in robustness. They also provide a comprehensive experimental analysis of when and why these defenses work and potential mechanisms that could explain their effectiveness. 
SP:a136b98e0ed478144ce9dd26e2b6d611543124e8,This paper proposes a method to learn 3D feature maps of a scene from 2.5D color and depth video streams. The proposed method is based on a 3D mapping network that takes as input 2D video streams captured by a moving camera and disentangles the scene content from the motion of the camera. The method is applied to semi-supervised and unsupervised learning of 3D object detection tasks. 
SP:6fd61604a2eeb8a2cbbda6c40807cebef6d40f2f,"This paper studies the problem of unsupervised domain translation (UDT) from the perspective of Optimal Transport (OT) and CycleGAN. The authors define UDT in a rigorous, non-ambiguous manner, explore the implicit biases present in the approach and demonstrate the limits of the approaches and show that mappings produced by these methods are biased towards low energy transformations, leading us to cast UDT into an OT framework by making this implicit bias explicit. This allows them to provide theoretical guarantees for existing methods, and also to solve UDT problems where previous methods fail. Finally, the authors propose a simple approach to solve the UDT problem, and illustrate its properties in two settings: (1) learning a mapping from one domain to another, (2) linking these paired elements together."
SP:8bb3ce11ad773685f6e41d90db3e7a5481e5ba47,"This paper proposes a new regularization method, RotationOut, for convolutional layers and recurrent layers of deep neural networks. The proposed method is based on the idea that each layer of the network is treated as an entire vector and is regularized by randomly rotating the vector. The authors also propose a noise analysis method to interpret the difference between rotationOut and Dropout in co-adaptation reduction. Extensive experiments in vision and language tasks are conducted to show the effectiveness of the proposed method. "
SP:37620ae8dc5683eb2843792e0aa4cbe6cba366f7,"This paper proposes a method to create adversarial perturbations (UAPs) for CNNs in a data-free manner. The authors show that the adversary generation with full training data can be approximated to a formulation without data. This is achieved by a sequential optimization of the perturbation with the proposed dilate loss, which maximizes the Euclidean norm of the output before nonlinearity at any layer. Extensive experiments demonstrate that the proposed method achieves higher fooling rate than the existing methods."
SP:2fd7d5507a8727db743dc89379a6f021d31ed39a,This paper proposes a transferable neural architecture search (NAS) method based on meta-learning. The proposed method learns a meta-architecture that is able to adapt to a new task quickly through a few gradient steps. Extensive experiments show that T-NAS achieves state-of-the-art performance in few-shot learning and comparable performance in supervised learning.
SP:1314a79ba12474adb33ff31b3cb22bed25b94fb7,"This paper proposes a simple and effective stochastic neural network (SE-SNN) architecture for discriminative learning by directly modeling activation uncertainty and encouraging high activation variability. Compared to existing SNNs, the proposed method is simpler to implement and faster to train, and produces state-of-the-art results on network compression by pruning, adversarial defense and learning with label noise. "
SP:bd4935d4fcf33f60f22e0f2fd9f7dc8ddfab6d17,"This paper proposes a meta-RL algorithm for generating curious behavior. The algorithm is based on meta-learning: an outer loop will search over a space of curiosity mechanisms that dynamically adapt the agent’s reward signal, and an inner loop will perform standard reinforcement learning using the adapted reward signal. The proposed algorithm is evaluated on grid navigation, grid navigation with image inputs, acrobot, lunar lander, ant and hopper tasks. "
SP:6dff0f3a84809ae0ba9f58f36303597f1ba6dcc5,This paper proposes a new method for any-code-to-code generation (AnyC2C) that leverages the strict syntax of programming languages to model a code snippet as a tree – structural language modeling (SLM). SLM estimates the probability of the program’s abstract syntax tree (AST) by decomposing it into a product of conditional probabilities over its nodes. A neural model is proposed that computes these conditional probabilities by considering all AST paths leading to a target node. The proposed method can generate arbitrary expressions in any programming language. 
SP:7fc60d6fd1cfcc135c34f9664d172d3fd1c0ae0a,"This paper studies the convergence of gradient descent methods for learning large-scale neural networks (NNs) in the canonical model space. The authors prove that the objective functions in learning NNs are convex in this space, and that the gradients between the original NN model space and the canonical space are related by a pointwise linear transformation, which is represented by the so-called disparity matrix. They also show that gradient descent algorithms converge to a global minimum of zero loss provided that the disparity matrices maintain full rank. "
SP:78a536138570fe9b5d88350e4b16d598a7db1fe0,"This paper proposes interactive graph-based segmentation algorithms that enforce connectivity between pixels of the same label to be connected, which allows the annotator to better control over the final segmentation. The authors propose an instance-aware heuristic of a discrete Potts model, and a class-aware integer linear programming (ILP) formulation that ensures global optimum. Both algorithms can take RGB, or utilize the feature maps from any DCNN, whether trained on the target dataset or not, as input. They show competitive semantic (and panoptic) segmentation results on the PASCAL VOC 2012 and Cityscapes dataset given initial scribbles. "
SP:2eb90879ddbc39b6b5c05152784d6044d1940513,This paper proposes to use a learned saliency model to detect adversarial perturbations in an image classifier. The proposed method is based on the idea that the saliency map can capture the shifts in saliency due to the perturbation. This allows saliency models to be used effectively as a real-time defense. The authors also propose a novel defense: a CNN that distinguishes between adversarial images and natural images using salient pixels as its input.
SP:fe5510d05ff091a5f133f2dbcd1b23d8d58d2c3e,"This paper studies the problem of computing global adversarial robustness, i.e., the probability that the prediction at any point sampled from the (unknown) input distribution is susceptible to adversarial attacks. The authors consider the case where the model is trained to be robust to perturbations of the input distribution. They show that the global robustness is upper bounded by a concentration inequality, which is then used to compute the estimation error upper-bounded by an upper bound on the generalization error of the model. They also provide empirical results on MNIST, Fashion-MNIST, and CIFAR to show that robustness and accuracy tend to be negatively correlated for networks trained via stochastic gradient descent and with iterative pruning techniques."
SP:8f5616a1480b68c04b496ed498d237d5a7e87794,"This paper studies the problem of robust reinforcement learning, where the goal is to find the optimal policy with some extent of robustness to environmental dynamics. The authors propose to use Wasserstein distance to measure the disturbance to the reference transition kernel to connect the transition kernel disturbance to a finite-dimensional risk-aware problem. They show the existence of optimal robust policies, provide a sensitivity analysis for the perturbations, and then design a novel robust learning algorithm. The effectiveness of the proposed algorithm is verified in the Cart-Pole environment."
SP:d85963f5f0f6b20cf08f2a7c169ae33a45db7de2,"This paper proposes a method to approximate mixed strategy Nash equilibria in multi-player continuous games, which always exist and include the pure ones as a special case. The proposed method adopts the pushforward measure technique to represent a mixed strategy in continuous spaces. This allows them to generalize the Gradient-based Nikaido-Isoda (GNI) function to measure the distance between the players’ joint strategy profile and a Nash equilibrium. In numerical experiments, the proposed method consistently and significantly outperforms recent works on approximating Nash equilibrium for quadratic games, general blotto games, and GAMUT games."
SP:280d85cd8164a268f9d496ae5f17189c50f30dc1,"This paper proposes a neural execution tree (NExT) framework to augment training data for text classification using natural language explanations (NL explanations). NL explanations are unstructured and inherently compositional, which asks for a modularized model to represent their semantics, and NL explanations often have large numbers of linguistic variants, resulting in low recall and limited generalization ability. NExT generalizes different types of actions specified by the logical forms for labeling data instances, which substantially increases the coverage of each NL explanation. Experiments on two NLP tasks (relation extraction and sentiment analysis) demonstrate its superiority over baseline methods. The extension to multi-hop question answering achieves performance gain with light annotation effort."
SP:a9b5f7257dedd719cfe341fca275776734af1d98,"This paper extends the formal verification of adversarial robustness of recurrent neural networks (RNNs) to more complex specifications, such as requiring that a robot periodically visits a charging station or that a language model always produces sentences of bounded length. The authors propose a method to train RNNs to be robust to these specifications. The proposed method is based on the idea of training a RNN to be trained to be consistent with the specifications.  The authors show that the proposed method can be used to train models that are robust to the specifications and can be shown to be provably consistent with specifications."
SP:3903680e07b676409e3cf6a1044b67291fe38630,"This paper proposes a regularization method for visual domain randomization, where the agent is only trained on one variation of the environment, and its learned state representations are regularized during training to minimize the Lipschitz constant of the learned policy. The proposed method is evaluated on a toy gridworld environment, where it is shown to be more efficient and robust than the existing methods. "
SP:c79046dc56b9ee9c926f87386046422ea134ae8d,"This paper studies the problem of imbalanced data pairs in deep metric learning (DML). To tackle this issue, the authors propose a simple and effective framework to sample pairs in a batch of data for updating the model. The key to this framework is to define a robust loss for all pairs over a mini-batch of data, which is formulated by distributionally robust optimization (DRO). The flexibility in constructing the uncertainty decision set of the dual variable allows us to recover state-of-the-art complicated losses and also to induce novel variants. Experimental results show that the proposed variants of DRO framework outperform SOTA methods on several benchmark datasets."
SP:38420928e40ef80c0136ad607b9275f9ab1e0769,"This paper studies the problem of finding a local minimum in non-convex finite-sum minimization. The authors first prove that the trust region method with inexact gradient and Hessian estimation can achieve a convergence rate of order O(1/k) as long as those differential estimations are sufficiently accurate. Combining such result with a novel Hessian estimator, the authors propose a sample-efficient stochastic trust region (STR) algorithm which finds an approximate local minimum within $\Omega(n/\sqrt{n})$ stochastically Hessian oracle queries. This improves the state-of-the-art result by a factor of O(n). The authors also develop Hessian-free STR algorithms which achieve the lowest runtime complexity. Experiments verify theoretical conclusions and the efficiency of the proposed algorithms."
SP:28a35b70b5e6915af28cacebc4ea50690c9534af,This paper proposes a new method for training deep neural networks without batch normalization. The proposed method is based on linear programming. The authors propose to use Farkas layers to ensure that at least one neuron is active at a given layer in the network. The method is shown to improve the performance of deep networks with ReLU activations. 
SP:1d325b148e3efe407241c1f1cbe8d17400499741,"This paper studies the problem of computing exact robustness certificates for deep classifiers with differentiable activation functions. In particular, the authors provide computationally-efficient computationally efficient certifications in the l2 norm of the Hessian of the network (curvatures of the networks) using convex optimization. They also derive a computationally efficiently differentiable upper bound on the curvature of a deep network. Finally, they propose a regularization term during training to boost the network's certified robustness. "
SP:33f6f5aa0d4655e5d75fe612e0eff05e579d45c5,"This paper proposes a method for compressed sensing recovery using untrained deep generative models. The method is based on the recently proposed Deep Image Prior (DIP), wherein the convolutional weights of the network are optimized to match the observed measurements. The authors show that this approach can be applied to solve any differentiable linear inverse problem, outperforming previous unlearned methods, and does not require pre-training over large datasets. They also introduce a novel learned regularization technique, which incorporates prior information on the network weights, especially for noisy measurements. "
SP:23c0f621e6041003b59bf0532130760694cf6a4a,"This paper proposes a temporal abstraction method for hierarchical reinforcement learning (HRL) that learns the temporal abstraction from past experience or expert demonstrations without task-specific knowledge. The authors formulate the problem of temporal abstraction as learning latent representations of action sequences and present a novel approach of regularizing the latent space by adding information-theoretic constraints. Specifically, the authors maximize the mutual information between the latent variables and the state changes. The learned abstraction allows us to learn new tasks on higher level more efficiently."
SP:4e54c9196ba1eb2b6a0b0eee41e4a6f3a9de72dd,"This paper proposes a new layer-wise sampling strategy for graph convolutional networks (GCNs) to address the over-expansion of neighborhoods across layers. The proposed method samples the nodes layer by layer conditionally based on the factors of the bi-directional diffusion between layers. In this way, the authors restrict the time complexity linear to the number of layers, and construct a mini-batch of nodes with high local-local influence (correlation). Further, they apply the self-attention mechanism to flexibly learn suitable weights for the sampled nodes, which allows the model to incorporate both the first-order and higher-order proximities during a single layer propagation process without extra recursive propagation or skip connection. Extensive experiments on three large benchmark graphs demonstrate the effectiveness and efficiency of the proposed model."
SP:bb0af9c011ef982c34fcadb545f6b5771818e7fa,"This paper presents a state-space model for unsupervised video prediction. The model is a combination of a structured image model and a dynamics model, where the dynamics model is used for inference and the image model for training. The authors show that the model is able to predict videos with convincing physical behavior over thousands of timesteps, outperforms previous unsupervisory models, and even approaches the performance of supervised baselines. "
SP:e67b463bc0aec2345925d609fa521ea49df57fd9,This paper proposes a new variational autoencoding model that incorporates the best properties of VAE and GAN objectives. The main idea is to train the VAE model with an implicit likelihood by an adversarially trained discriminator. The proposed method achieves the state-of-the-art trade-off between generation and reconstruction quality on CIFAR-10 and TinyImagenet datasets. 
SP:87056d0147ddcaf5d78f6888b05161fbdbb3346c,"This paper shows that adversarial attacks can be used against the Bayes-Optimal classifier for certain class distributions, while for others the optimal classifier is robust to such attacks. The authors show that under certain conditions on the data distribution under which all points can be made arbitrarily close to the optimal decision boundary, and show that this can happen even when the classes are easy to separate, when the ideal classifier has a smooth decision surface, and when the data lies in low dimensions. They introduce new datasets of realistic images of faces and digits where the Bayesian optimality of the classifier can be calculated efficiently, and they show that for some of these datasets the optimal model is robust and for others it is vulnerable to adversarial examples. They find that standard CNN training consistently finds a vulnerable classifier even when optimal classifiers is robust while large-margin methods often find a robust classifier with the exact same training data."
SP:a7b3a35e6a79084bdfd1e4a963dfa081279cd8bb,"This paper studies the effect of sparsity in neural network pruning on different classes and images. They find that certain examples, which they term pruning identified exemplars (PIEs), and classes are systematically more impacted by sparsity. Removing PIE images from the test-set greatly improves top-1 accuracy for both sparse and non-sparse models. Their findings provide important insights about when pruned models are qualified to make decisions on real world inputs."
SP:4b17edaa7ec6201891433320d85f9a415656b763,"This paper proposes KG-A2C1, an agent that builds a dynamic knowledge graph while exploring and generates actions using a template-based action space. The authors argue that the dual uses of the knowledge graph to reason about game state and to constrain natural language generation are the keys to scalable exploration of combinatorially large natural language actions. The proposed agent achieves state-of-the-art performance on a large proportion of the games despite the exponential increase in action space size."
SP:b1784ecbb8f36eef9cae33d61ce60d80c2f9c38d,This paper addresses the problem of negative diversity ignorance in maximum likelihood estimation (MLE) for sequence prediction problems. The authors propose to augment the MLE loss by adding an extra Kullback-Leibler divergence term derived by comparing a data-dependent Gaussian prior and the detailed training prediction. Experimental results show that the proposed method makes effective use of a more detailed prior in the data and has improved performance in typical language generation tasks.
SP:7c29cb5a32b14e1392408dc5daba4cd35848bea9,"This paper proposes to replace the widely used cross-entropy loss with focal loss to calibrate deep neural networks (DNNs). The proposed focal loss is combined with temperature scaling to improve the calibration of DNNs. The proposed method achieves state-of-the-art accuracy and calibration in almost all cases. The authors provide a thorough analysis of the factors causing miscalibration, and theoretically justify the theoretically and empirically excellent performance of focal loss."
SP:cd6b8417ec8bcb773c78cff677bb0a76d6b3f6f3,"This paper proposes LiPopt, a polynomial optimization framework for computing increasingly tighter upper bounds on the Lipschitz constant of neural networks. The authors show how to use the sparse connectivity of a network, to significantly reduce the complexity of computation. This is specially useful for convolutional as well as pruned neural networks, and the authors conduct experiments on networks with random weights and networks trained on MNIST, showing that their approach yields superior estimates, compared to baselines available in the literature."
SP:31c9dc0dd8806daddc9cb48c56ec819577fe46cd,"This paper proposes a self-supervised learning approach for video features that results in significantly improved performance on downstream tasks (such as video classification, captioning and segmentation). The method extends the BERT model for text sequences to the case of sequences of real-valued feature vectors, by replacing the softmax loss with noise contrastive estimation (NCE). The authors also show how to learn representations from sequences of visual features and sequences of words derived from ASR (automatic speech recognition), and show that such cross-modal training (when possible) helps even more."
SP:0f24424d10f1201dd25e8c56354e10afc9b2b11c,"This paper proposes a framework to select parts of the input data needed for the subsequent application of a given neural network and its task. The selection masks are trained simultaneously so that a good model performance is achieved while, at the same time, only a minimal amount of data is selected. During the inference phase, only the parts selected by the masks have to be transferred between the server and the client. The experiments indicate that it is often possible to significantly reduce the amount of training data needed to transfer without affecting the model performance much."
SP:aa4fcf5b2cae05c5c6a903c24e4992b56655dee2,This paper proposes a method to detect out-of-distribution (OOD) examples in deep neural networks. The proposed method is based on the Outlier Exposure (OE) technique. The authors propose a novel loss function that achieves SOTA results in OOD detection with OE both on image and text classification tasks. The combination of the two methods outperforms the original Mahalanobis method in all of the experiments and to the best of the best-known results.
SP:89bc528ef801182365ac279e8963803afccb391d,"This paper proposes an end-to-end deep learning model, called E2Efold, for RNA secondary structure prediction which can take into account the inherent constraints in the problem. The key idea is to directly predict the RNA base-pairing matrix, and use an unrolled algorithm for constrained programming as the template for deep architectures to enforce constraints. Experiments on benchmark datasets show the superior performance of the proposed method."
SP:b68560cce8c64ebe0ca5e6534b3732c775d36452,"This paper proposes a method to train a collective policy that can be applied to real-world environments. The method is based on the idea that agents internalize their own predictive model of the environment and form a virtual simulation within which the agent plays trials of the episodes in entirety. Each agent takes turns to host virtual episodes within which all agents participate and interact with their own biased representations. Since agents’ biases vary, the collective policy developed while sequentially visiting the internal simulations complement one another’s shortcomings. The results show that the proposed method outperforms the best individually trained policies."
SP:bd1dc08b4fd9a5cc78d26d7eb7f05dbb4a629ab1,"This paper proposes a dialog generation model that learns a semantic latent space, on which representations of semantically related sentences are close to each other. This latent space is learned by maximizing correlation between the features extracted from prompt and responses. An additional autoencoder is trained, for recovering the full sentence from the latent space. Experimental results show that the proposed model eliminates the generic response problem, while achieving comparable or better coherence compared to baselines."
SP:ef0d5fd333ed60feb3946d24002e9a90642aea66,"This paper proposes a novel black-box explanation method for fine-grained classification. The proposed method is based on Gaussian lighting and shadowing (GLAS), which estimates the spatial impact of deep models by the feature perturbation inspired by light and shadow in nature. The method is able to identify multiple instances through recursive GLAS. The experimental results show the effectiveness of the proposed method. "
SP:d17ca20cc527c28ab7358cb5b14954e5fb56409f,"This paper proposes a method to remove pixel-wise and channel-wise correlations in convolutional neural networks (CNNs). The proposed method, called network deconvolution, removes pixel and channel correlations before the data is fed into each layer of a CNN. The method is shown to be computationally efficient at a fraction of the computational cost of a convolution layer. Empirical results show that the proposed method outperforms batch normalization on several image datasets."
SP:e1b0de9a36bf8359df368b7a55a7f23e99d88db7,"This paper proposes a quantization method for GANs based on EM algorithms to quantize the weights of GAN models to 1-bit or 2-bit representations. The authors conduct a sensitivity study on the sensitivity of the generator and discriminator networks to the quantization precision. Based on this sensitivity study, the authors propose a multi-precision quantization algorithm to find an appropriate quantized precision. The proposed method is evaluated on CIFAR-10 and CelebA datasets. The results show that the proposed method can quantize weights to 1/2 bit representations with results comparable to original models."
SP:58c4905f59f04a50b30d27c99521126a6455d38a,"This paper studies last-iterate convergence rates for convex-concave min-max optimization in non-convex-strongly concave settings. The authors show that the Hamiltonian gradient descent (HGD) algorithm achieves linear convergence in a variety of general settings that satisfy a novel “sufficiently bilinear” condition on the second-order derivatives of the objective g and show that this condition is sufficient for HGD to achieve linear convergence. The paper also shows that HGD can be viewed as a perturbation of the Consensus Optimization (CO) algorithm, which implies that for some parameter settings, HGD converges at the same rate as CO."
SP:d8556b52272321a1415ac2d85bb12e88b51ee73a,"This paper studies the stability of the forward/backward process of ResNet, where L is the number of residual blocks and $L$ is a scalar. The authors show that for standard initialization used in practice, $\tau$ = 1/\sqrt{L}$ is sharp value in characterizing the stability. They also show that if ResNet is properly over-parameterized, the global convergence of gradient descent is guaranteed to find the global minima 1, which significantly enlarges the range of $L$. Empirically, the authors demonstrate that with $\Tau$=1/L, deep ResNet can be easily trained even without normalization layer."
SP:cf70dc496825ece2f28fdf4f1a6f4316c69e0e48,"This paper proposes a method to train sparse neural networks with a fixed parameter count and a fixed computational cost throughout training, without sacrificing accuracy relative to existing dense-to-sparse training methods. The method updates the topology of the network during training by using parameter magnitudes and infrequent gradient calculations. The proposed method achieves state-of-the-art sparse training results on the ImageNet-2012 dataset, WideResNets on the CIFAR-10 dataset and RNNs on the WikiText-103 dataset."
SP:d2d2b892518d54d0e63e26a056f2298be3be2610,"This paper proposes a method to find meaningful directions in the latent space of any generative model along which we can move to control specific properties of the generated image like the position or scale of the object in the image. The proposed method does not require human annotations and is particularly well suited for the search of directions encoding simple transformations such as translation, zoom or color variations. The experimental results demonstrate the effectiveness of the method qualitatively and quantitatively, both for GANs and variational auto-encoders."
SP:1c63389e972d4652fac831e9d11609cd3c3c371a,"This paper proposes a physics-as-inverse-graphics-based model for unsupervised physical parameter estimation of systems from video, where the differential equations governing the scene dynamics are known, but labeled states or objects are not available. This framework allows the model to perform long term extrapolative video prediction, as well as vision based model-predictive control. The proposed method is evaluated on 4 datasets with different non-linear interactions and visual difficulty. The results show that the proposed method can learn physical parameters without object or state supervision, and can improve model performance in two tasks: long term video prediction and visual model predictive control."
SP:c6b8b682bf3087a65cb2379700b8a0183853c2af,"This paper proposes a method to learn a classifier from noisy labels when a few clean labeled examples are given. The proposed method is based on graph convolutional networks (GCN) to predict class relevance of noisy examples. For each class, the GCN is treated as a binary classifier learning to discriminate clean from noisy examples using a weighted binary cross-entropy loss function, and then the “clean” probability is exploited as a relevance measure. The method is evaluated on an extended version of a few-shot learning problem, where the few clean examples of novel classes are supplemented with additional noisy data. "
SP:dd9c9a5dccbba5dd15b03ca6b314a9e153e95548,This paper proposes a new objective function for graph neural networks (GNNs) that maximizes the mutual information between edge features and message passing channels. The proposed objective is based on a variational objective that can be expressed as a weighted sum of mutual information (MI) between edges and message-passing channels. It is shown that the proposed objective can preserve the edge information. Experiments are conducted on regression on molecular graphs and relation prediction in knowledge graphs. 
SP:f1cf63d728da51b4f83eb50ef69e3788b3a5ed74,"This paper proposes a method to certify non-trivial properties of generative networks. The method, called ProxLine, is able to verify the non-convexity and robustness of a generative model to different types of head rotations. ProxLINE is a combination of two existing methods, Prox-Net and ProxNet. The main idea of the method is to use the latent space of the generative network to verify that the output of a classifier is robust to different kinds of rotations (e.g., different amounts of ""moustache"" and ""bald"" rotations). The method is shown to be deterministic and probabilistic, and can be used to verify infinite sets of outputs of the network. "
SP:2b0887dcf09249e8cee30d38163aeb9ef1e92b27,"Graph neural networks (GNNs) based on the spectral graph convolutional operator have been criticized for its performance degradation, which is especially common for the models with deep architectures. In this paper, the authors further identify the suspended animation problem with the existing GNNs. Such a problem happens when the model depth reaches the suspended-animation limit, and the model will not respond to the training data any more and become not learnable. The authors introduce the GRESNET (Graph Residual Network) framework in this paper to resolve the problem, which creates extensively connected highways to involve nodes’ raw features or intermediate representations throughout the graph for all the model layers. Detailed studies about the GRENET framework for many existing graph neural networks, including GCN, GAT and LOOPYNET, will be reported in the paper with extensive empirical experiments on real-world benchmark datasets."
SP:dc436ade4d04072de35a90e5e4a1bfebfddb04e9,"This paper proposes a method for face reconstruction from unlabeled unlabelled images. The proposed method is based on a linear 3D morphable model (3DMM) that is trained on a dataset generated from a 3DMM dataset. The authors train the model with adversarial loss in a semi-supervised manner to exploit the value of large amounts of unlabelED face images from unconstrained photo collections. A novel center loss is introduced to make sure that different facial images from the same person have the same identity shape and albedo. Besides, the proposed model disentangles identity, expression, pose, and lighting representations, which improves the overall reconstruction performance and facilitates facial editing applications, e.g., expression transfer."
SP:f7bc06697b09e2d59ec06b2cbcf3c0828ece32ae,"This paper proposes a new model for imitation learning when the transition kernel is unknown. The model is based on the expert-induced Markov Decision Process (eMDP) model. The authors propose to replace the unknown transition kernel with a synthetic kernel that simulates the transition of state components for which the kernel is known. The next state is then stitched from the two components: s = s = {sr, su}. The authors show that the eMDP model achieves superior performance compared to the simulation-free alternative MDP model."
SP:82cce92821e8168ab4a6fd67573b66c1d17673b8,This paper proposes a self-supervised reinforcement learning method for learning to control states of interest in a robotic manipulation task. The proposed method is motivated by the mutual information between the context states and the state of interest. The method is evaluated on two robotic manipulation tasks from OpenAI Gym and a navigation task in the Gazebo simulator. The results show that the proposed method outperforms the baselines in both tasks. 
SP:5db63d39cfd8132bec832ab64b8fbd403b3b8df0,"This paper proposes a trojan-based attack method for large neural networks (NNs) that is programmable to generate a malicious misclassification target that is not fixed and can be generated on demand even after the victim’s deployment. The authors demonstrate their attack method under the scenario described in the retraining tutorial from Tensorflow and MXNet, which uses pre-trained ImageNet (Deng et al., 2009) models and replaces the FC layers for the Flower dataset and Caltech-256 dataset. The attack method outperforms existing studies in capability, generality, and stealthiness. "
SP:35ea626ee4dd1a7a368a660eb852192924966b7f,"This paper proposes a few-shot regression (FSR) algorithm based on deep kernel learning (DKL) and a differentiable kernel algorithm. DKL learns a deep network in combination with a kernel function and a kernel algorithm to find the appropriate kernel for each task during inference. The proposed algorithm outperforms existing FSR methods on both toy and novel, real-world benchmarks."
SP:91ca4c3ee07617356250bae9f4ef9799b3b134ff,"This paper proposes a framework to characterize which reasoning tasks a neural network can learn well, by studying how well its computation structure aligns with the algorithmic structure of the relevant reasoning process. The authors define this algorithmic alignment and derive a sample complexity bound that decreases with better alignment. This framework offers an explanation for the empirical success of popular reasoning models, and suggests their limitations. Experimental results confirm the theory."
SP:a52aee8da5cf5acd2baf3c2a62cb679e13b18bd5,"This paper proposes a new metric called Fréchet Joint Distance (FJD) for evaluating conditional generative adversarial networks (cGANs). FJD measures the distance between joint distributions of images and conditioning distributions, which allows it to implicitly capture image quality, conditional consistency, and intra-conditioning diversity. FJD can be used as a promising single metric for cGAN benchmarking and model selection and can be applied to any kind of conditioning (e.g., class, bounding box, mask, image, text, etc.). "
SP:fa822e8472efae17c7dfde8258057898383ecbbb,"This paper proposes a method to identify ‘decision states’, i.e., parsimonious set of states where decisions meaningfully affect the future states an agent can reach in an environment. The authors use the VIC framework, which maximizes an agent’s ‘empowerment’ and formulate a sandwich bound on the empowerment objective that allows identification of decision states. Unlike previous work (Goyal et al., 2019), the decision states are discovered without extrinsic rewards – simply by interacting with the world. The results show that the proposed method is transferable and leads to better exploration on downstream goal-driven tasks in partially observable environments."
SP:a19a51df7e28a5d3380be4fba13842efbfe3efec,"This paper proposes a method for irregularly sampled time series with unaligned measurements, focusing on high scalability and data efficiency. The method SEFT (Set Functions for Time Series) is based on recent advances in differentiable set function learning, extremely parallelizable, and scales well to very large datasets and online monitoring scenarios. The authors extensively compare their method to competitors on multiple healthcare time series datasets and show that it performs competitively while significantly reducing runtime."
SP:4ae89d64460b08749acc192004545c1fa8b7553b,"This paper proposes a method to model audio signal priors by explicitly utilizing the harmonic structure in convolutional neural networks. This is done by engineering the kernels to be supported by sets of harmonic series, instead of by local neighborhoods as convolutionsal kernels. Empirical results show that the proposed method can reliably model audio priors and achieve high performance on unsupervised audio restoration tasks. "
SP:c81a2b3fd1c56b9b18e4a358e3ff8b40aea5256a,"This paper proposes a data-augmentation technique called ""data echoing"" to reduce the total computation used by earlier stages of the training pipeline and speed up training whenever computation upstream from accelerators dominates the training time. Data echoing reuses (or “echoes”) intermediate outputs from earlier pipeline stages in order to reclaim idle capacity. The authors investigate the behavior of different data echoing algorithms on various workloads, for various amounts of echoing, and for various batch sizes. They find that in all settings, at least one data echoing algorithm can match the baseline performance using less upstream computation."
SP:b4cf56d3fa7d65cacde33f17cd04bd5bbc52dd71,"This paper proposes a method for learning a policy that is distinguishable from other policies in a Markov Decision Process (MDP) using successor features. Successor features (SF) enable fast transfer learning between tasks that differ only in their reward function, which is assumed to be linear in some features. The main contribution of this paper is to address this generalization and slow inference problem by making use of successor features (Barreto et al., 2017) and behavioral mutual information (BMI) maximization. The proposed method, Variational Intrinsic Successor FeatuRes (VISR), achieves human-level performance on 12 games and outperforms all baselines."
SP:83500230586a9134f910ad067b7233dc563dc1ba,"This paper studies the generalization properties of deep neural networks from a functional point of view. Theoretical and empirical results show that the smoothness of the approximating function increases with the number of units, which explains why massively over-parameterized networks generalize well. The authors show that generalization is due to three factors: (i) the very flat initialization, (ii) the curvature-based parametrization of approximating functions, and (iii) the role of gradient descent (GD) in preserving and regularizing functions. "
SP:7225825e353b711a7d023f706fafe5e17e4e2fb2,"This paper proposes a new GAN-based method for image-to-image translation. The proposed method is based on the attention mechanism of the discriminator. The discriminator is equipped with an attention mechanism that estimates the probability that its input is real, but also does it create an attention map that highlights the critical features for such prediction. This attention map then assists the generator to produce more plausible and realistic images. Experiments on a number of image transfer tasks demonstrate the superiority of the proposed method."
SP:41c089ba65393174dae1dc136f79030a0a4fc532,"This paper studies the role of multiplicative interaction layers as a unifying framework to describe a range of classical and modern neural network architectural motifs, such as gating, attention layers, hypernetworks, and dynamic convolutions. The authors argue that multiplicative interactions offer a particularly powerful inductive bias when fusing multiple streams of information or when conditional computation is required. They argue that they should be considered in many situation where multiple compute or information paths need to be combined, in place of the simple and oft-used concatenation operation. Finally, they back up their claims and demonstrate the potential of such layers in large-scale complex RL and sequence modelling tasks, where their use allows them to deliver state-of-the-art results."
SP:5144391584e6d3825e12684b7c053e4e282cff2b,"This paper proposes a new algorithm for batch active learning with deep neural network models. The algorithm, called BADGE, samples groups of points that are disparate and high magnitude when represented in a hallucinated gradient space. The authors show that BADGE is robust to architecture choice, batch size, and dataset, and generally performs as well as or better than the best baseline across various environmental conditions."
SP:ce6023b1e6bf45b071a6f5457b2575425ae03366,"This paper proposes a method for self-explaining deep neural networks (DNNs). The authors argue that existing DNNs are hard to interpret because each hidden layer carries a mix of low level features and high level features. To address this problem, the authors propose a novel feature leveling architecture that isolates low-level features from high-level ones on a per-layer basis to better utilize the GLM layer in the proposed architecture for interpretation. Experimental results show that the proposed method is able to achieve competitive results comparing to main-stream architectures on standard datasets while being more interpretable."
SP:b70ceead1bf6c7dc684c74501716e7012b891022,"This paper proposes a method to train a classifier for extreme classification. The proposed method is based on adversarial sampling, where the adversarial samples are drawn from an adversarial model that mimics the data distribution. The authors show that the proposed method can be used to reduce the training time by an order of magnitude relative to several competitive baselines. "
SP:29b52fee83309268d9864f3b1fc3617948577d41,"This paper proposes a method for efficient exploration that leverages a low dimensional encoding of the environment learned with a combination of model-based and model-free objectives. The intrinsic rewards are based on a weighted distance of nearest neighbors in the low dimensional representational space to gauge novelty. The authors leverage these intrinsic rewards for sample-efficient exploration with planning routines in representational spaces. The proposed method is tested on a number of maze tasks, as well as a control problem and shows that it is more sample efficient compared to strong baselines."
SP:257c98dc1a9f3efcbf9544d9ee2ff524b000543d,"This paper studies the problem of out-of-distribution detection in the few-shot setting. The authors propose a few new tasks for out of distribution detection and establish benchmark datasets, based on four popular few shot classification datasets. They also propose two new methods for this task and investigate their performance. "
SP:a3632b773143dfb3a8f104c6b658dfa1167d155b,"This paper proposes a generative model that unifies decoding in directed and undirected neural sequence models. The generative process is modeled as the process of generation rather than a resulting sequence, and the authors derive various neural sequence model as special cases, such as autoregressive, semi-autoregressive and non-autorgressive models. This unification enables them to adapt decoding algorithms originally developed for directed sequence models to the unsupervised setting. The experiments show that the proposed method is competitive with the state-of-the-art on WMT’14 English-German translation."
SP:eca5e2be9831dfb79c4f5e633cbfadcfd2e00eb1,"This paper proposes a two-stage method for MEs recognition. The first stage uses object detection to locate and recognize the math symbols of input image by object detection algorithm, and the second stage translates math symbols with position information into LaTeX sequences by seq2seq model equipped with attention mechanism. The proposed method significantly outperforms the end-to-end method on the test data."
SP:923fee8623da1569a7f54a57b4b326f29440b4c0,This paper proposes a vector quantization method to reduce the memory footprint of convolutional networks. The proposed method is based on the idea of quantizing the output of the network to preserve the quality of the reconstruction of the outputs rather than its weights. The method is validated on ImageNet object classification and Mask R-CNN with a memory size of 5 MB.
SP:74850ad70241948f93fed95ba1f0ac11360437c1,"This paper proposes a Tensor-product Transformer (TP-Transformer) that uses Tensor Product Representations (TP) to encode the relations between each Transformer cell and the other cells from which values have been retrieved by attention. The proposed TP-Attention goes beyond linear combination of retrieved values, strengthening representation-building and resolving ambiguities introduced by multiple layers of standard attention. This paper sets a new state-of-the-art on the recently introduced Mathematics Dataset containing 56 categories of free-form math wordproblems."
SP:d319df820c6630c409fab32097652a083e8f53ea,"This paper studies the problem of generalization in deep learning, where the training and test sets may not be sufficiently representative of the empirical sample set, which consists of real-world input samples. To address this problem, the authors reformulate a learning algorithm as a procedure for searching for a source code that maps input features to classes. They derive a necessary and sufficient condition for generalization using a universal cognitive similarity metric, namely information distance, based on Kolmogorov complexity. Then, they formulate an optimization problem to learn a more general classification function. To achieve this end, they extend the input features by concatenating encodings of them, and then train the classifier on the extended features, where we use channel codes on input features as a systematic way to improve the degree to which the training/test sets are representative of empirical sample sets. The experimental results show that the proposed method is more robust to common corruptions and adversarial perturbations than the model trained on uncoded input features."
SP:b8e86f5e89330d81ba4967a7ed2dbfb56375d8a0,"This paper proposes a new graph pooling operation based on compressive Haar transforms, called HaarPooling, for graph classification and graph-based regression tasks. The proposed method works by following a chain of sequential clusterings of the input graph. The input of each pooling layer is transformed by the Haar basis of the corresponding clustering. The experimental results show that the proposed method achieves state-of-the-art performance on diverse graph classification problems."
SP:17bea301d6718ef5f28864dd2445552b3cf65eeb,"This paper proposes a sample-based point cloud decoder that maps shape representation to a point feature distribution, allowing an arbitrary number of sampled features to be transformed into individual output points. The proposed method is based on the PointNet encoder, which maps shape representations to a fixed number of output points in a fully connected network. Three different decoder architectures are proposed, and the performance of the decoders are compared with feedforward architectures. The results show that the proposed method outperforms the feedforward methods."
SP:51d826ead5d1d9cb89d493ce4c39728651bbc57b,"This paper studies the effect of real-world noise on the performance of deep neural networks (DNNs) on noisy labels. The authors conduct a large-scale study across a variety of noise levels and types, architectures, methods, and training settings. They show that DNNs generalize much better on real world noise than synthetic noise. They also show that fine-tuned DNN architectures generalize well on noisy data. Finally, they show that adding noisy examples to a clean dataset may improve performance."
SP:9873f78fb2821afdbb5551700e6ab6a0e8bcb9f0,"This paper proposes a method to collect human supervision in the form of rule-exemplar supervision. The authors propose a training algorithm that jointly denoises rules via latent coverage variables, and trains the model through a soft implication loss over the coverage and label variables. The denoised rules and trained model are used jointly for inference. Empirical evaluation on five different tasks shows that the proposed method is more accurate than several existing methods of learning from a mix of clean and noisy supervision. "
SP:6f2c656dbb7629f652a4291d6971625184d8118b,Graph neural networks (GNNs) are a class of deep models that operate on data with arbitrary topology represented as graphs. This paper proposes an efficient memory layer for GNNs that can jointly learn node representations and coarsen the graph. It also introduces two new networks based on this layer: memory-based GNN (MemGNN) and graph memory network (GMN) that can learn hierarchical graph representations. The experimental results show that the proposed models achieve state-of-the-art results in eight out of nine graph classification and regression benchmarks. 
SP:81bc52d734c86975d741b6482d65ca71a9d81620,"This paper studies the effect of initialization in deep linear networks on the convergence of deep neural networks. The authors show that orthogonal initialization speeds up convergence relative to the standard Gaussian initialization with iid weights. They show that for deep networks, the width needed for efficient convergence to a global minimum is independent of the depth, whereas the width scales linearly in the depth. They also show that Gaussian initialization leads to exponentially long convergence time if the width is too small compared with the depth of the network."
SP:9f5d95fc89c2f0d59d04838aa180f3db67997dfa,This paper proposes a Lagrangian formulation method to optimize the bit allocation of weights and activations in deep neural networks for 2-bit quantization. The main contribution of this paper is to propose a method that can compress deep CNNs down to 2 bits with only 0.7% accuracy loss. This is the first paper that reports 2 bit results on deep networks without hurting the accuracy. 
SP:7191d7b217a12b1bf9c47d790896a8227c14cc3d,"This paper proposes a method to fuse variational auto-encoders (VAEs) and Wasserstein GANs (WGANs) in a principled way. The iWGAN jointly learns an encoder network and a generative network using an iterative primal dual optimization process. The authors provide the generalization error bound for the iwGANs and provide a rigorous probabilistic interpretation of the model under the framework of maximum likelihood estimation. The empirical experiments show that the proposed method is able to speed up the mode collapse, speeds up the convergence, and provides a measurement of quality check for each individual sample. "
SP:cca6ae14fd0dd12352855e594acf7f3263bb1f24,"This paper extends the mention pair model of anaphoric annotation (MPA) proposed by Paun et al. (2018b) with hierarchical communities of annotators. Specifically, the authors use a nonparametric partially pooled structure (based on a stick breaking process), fitting jointly with the ability of the annotators hierarchical community profiles. The authors conduct the evaluation on the Phrase Detectives 2 corpus, in various levels of sparsity, assessing the accuracy of the inferred mention pairs, the quality of the post-hoc constructed silver chains, and the viability of using silver chains as an alternative to expert-annotated chains when training a state-of-the-art coreference system. "
SP:4295cae4a56a02eb21c486408c1bf37a7483cb49,"This paper proposes a method for sparse reward reinforcement learning that combines intrinsic and extrinsic rewards. The intrinsic reward is defined as successor feature control (SFC), which is general and not task-specific. It is learned in a hierarchical fashion, and the intrinsic reward can be combined with a hierarchical exploration policy. The proposed method is evaluated on VizDoom, DeepMind Lab and DeepMind Control environments. "
SP:9fa22eb03a79bce0fc1c8e84ae8640e010701eca,"This paper proposes a method for weakly-supervised video moment retrieval, where the goal is to locate the video segment which is described by the sentence without having access to temporal annotations during training. The proposed method is based on a frame-by-word interaction module as well as a novel Word-Conditioned Visual Graph (WCVG) to learn visual-semantic representations that contain contextual information of their relative positions in the temporal sequence through iterative message-passing. Experiments on the DiDeMo and Charades-STA datasets demonstrate the effectiveness of the learned representations."
SP:27ac670353f34ee7a23bb7622f80c1dfbc0985e0,"This paper proposes an image-guided rendering technique that combines the benefits of image-based rendering and GAN-based image synthesis. Specifically, the authors train an object-specific deep neural network to synthesize the view-dependent appearance of an object using an RGB video of the object. The proposed method is able to generate photo-realistic re-renderings of reconstructed objects for virtual and augmented reality applications (e.g., virtual showrooms, virtual tours & sightseeing)."
SP:257d124367b1da9a595dc11a9df750d6bade298e,"This paper presents a sparse representation of model uncertainty for deep neural networks (DNNs) that relies on an inverse formulation of Multivariate Normal Distribution (MND): an information form. The paper shows that the model uncertainty can be estimated in this form using a scalable Laplace Approximation scheme, which involves a diagonal correction of the Kronecker-factored eigenbasis. As this makes the inversion of the information matrix intractable an operation that is required for a full Bayesian analysis, the paper devise a novel low-rank approximation of this eigenbais that exploits spectral sparsity of DNNs. "
SP:2e03ceba4004b82f86f8349352a8ee4520e9c35d,"This paper proposes a load-balanced hashing method for MinHash. MinHash is a fundamental method to compute set similarities and compact high-dimensional data for efficient learning and searching. One drawback of OPH is that the load of the bins (the number of elements in a bin) could be unbalanced, which leads to the existence of empty bins and false similarity computation. The proposed method AHash can generate as few empty bins as possible without hurting runtime efficiency compared with OPH and densification strategies. "
SP:d73827ab98b0ff6bd92abfefea43a5f88ea40de2,This paper proposes a method for extracting features from phase shift data by adding a graph structure to each data point and constructing a suitable machine learning architecture for graph data. The proposed method performs a cyclic permutation to a graph neural network to ensure that the results account for phase shift of the periodic measurements. Empirical results show the effectiveness of the proposed method.
SP:0df5ad333eb4ff9cca7f2d117909e2ce533a65d8,"This paper proposes a novel method for neural conditional text generation based on a confidence-based decoder that assigns a confidence score to each target position. This score is learned in training using a variational Bayes objective, and can be leveraged at inference time using a calibration technique to promote more faithful generation. Experiments on a structured data-to-text dataset show that the proposed method is more faithful to the source than existing state-of-the-art approaches, according to both automatic metrics and human evaluation."
SP:03307deac29173b2968fbd08f95fc77eb1f82410,"This paper proposes a new method for magnitude-based pruning of neural networks. The proposed method extends the single layer optimization to multi-layer optimization. The experimental results demonstrate that the proposed method consistently outperforms magnitude based pruning on various networks, including VGG and ResNet, particularly in the high-sparsity regime. "
SP:dc80fdc75bc14ae19fe4ba9b85c35ce00b12856f,"This paper proposes Moniqua, a decentralized decentralized stochastic gradient descent algorithm that uses quantized communication to communicate a provably bounded number of bits per iteration, while converging at the same asymptotic rate as the original algorithm does with full-precision communication. The authors prove in theory that the proposed algorithm can communicate a bound number of bit per iteration. They also show empirically that it converges faster with respect to wall clock time than other quantized decentralized algorithms. "
SP:86c61a658d07ab86e2d84cef7e480bf7a06e4ddb,"This paper studies the problem of learning partial models for reinforcement learning. The authors propose a family of partial models that are provably causally correct, yet fast because they do not need to fully model future observations. They show that partial models can be causally incorrect if they are confounded by the observations they don’t model, and can therefore lead to incorrect planning. To address this problem, the authors introduce a general family of models that is provably correct, but fast because it doesn't need to model all the observations. The proposed methods are tested on simple MDPs and 3D environments. "
SP:c70479b2096a52584b242de58272ca8d8565feea,This paper proposes a variational autoencoder (VAE) model that learns a succinct common representation of two correlated data variables for conditional and joint generation tasks. The proposed model is based on two information theoretic problems --distributed simulation and channel synthesis -- in which Wyner’s common information arises as the fundamental limit of the succinctness of the common representation. Experimental results show that the proposed model achieves better generative performance than existing VAE variants and the information bottleneck method.
