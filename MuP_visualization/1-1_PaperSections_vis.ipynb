{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1)Introduction\n",
      "['Hello world ', '1)Introduction']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello world \\r1)Introduction\"\n",
    "print(text)\n",
    "print(text.split(\"\\r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAWDATAFILES = {\n",
    "    \"train\": \"training_complete.jsonl\",\n",
    "    \"val\": \"validation_complete.jsonl\",\n",
    "    \"test\": \"testing_with_paper_release.jsonl\"\n",
    "}\n",
    "def print_progress(curr, full, desc='', bar_size=30):    \n",
    "    bar = int((curr+1)/full*bar_size)\n",
    "    sys.stdout.write(f\"\\r{desc}[{'='*bar}{' '*(bar_size-bar)}] {curr+1}/{full}\")\n",
    "    # sys.stdout.flush()\n",
    "    if curr+1==full: print()\n",
    "def load_data(data_split):\n",
    "    main_path = str((Path().absolute()).parents[0])    \n",
    "    filepath = f\"{main_path}/dataset_MuP/{RAWDATAFILES[data_split]}\"\n",
    "    with open(filepath, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "        col_name = [\"paper_id\", \"paper\",\"summary\"]\n",
    "    dataset = []\n",
    "    data_len = len(json_list)\n",
    "    for i, json_str in enumerate(json_list[:]):\n",
    "        result = json.loads(json_str)\n",
    "        dataset.append({\n",
    "            \"paper_id\": result[\"paper_id\"],\n",
    "            \"paper\": result[\"paper\"],\n",
    "            \"summary\": result[\"summary\"],\n",
    "        })\n",
    "        print_progress(i, data_len, bar_size=50)\n",
    "    return pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 18934/18934\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>paper</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>{'abstractText': 'We study the average CVloo s...</td>\n",
       "      <td>This paper investigates kernel ridge-less regr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:b80bc890180934092cde037b49d94d6e4e06fad9</td>\n",
       "      <td>{'abstractText': 'The use of episodic memories...</td>\n",
       "      <td>This paper presents a novel way of making full...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939</td>\n",
       "      <td>{'abstractText': 'Existing Multi-Task Learning...</td>\n",
       "      <td>This paper proposes a new framework that compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP:a1e2218e6943bf138aeb359e23628676b396ed66</td>\n",
       "      <td>{'abstractText': 'This paper deals with the fu...</td>\n",
       "      <td>This work proposes a deep reinforcement learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66</td>\n",
       "      <td>{'abstractText': 'Our work is concerned with t...</td>\n",
       "      <td>This paper proposes 3 deep generative models b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      paper_id  \\\n",
       "0  SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc   \n",
       "1  SP:b80bc890180934092cde037b49d94d6e4e06fad9   \n",
       "2  SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939   \n",
       "3  SP:a1e2218e6943bf138aeb359e23628676b396ed66   \n",
       "4  SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66   \n",
       "\n",
       "                                               paper  \\\n",
       "0  {'abstractText': 'We study the average CVloo s...   \n",
       "1  {'abstractText': 'The use of episodic memories...   \n",
       "2  {'abstractText': 'Existing Multi-Task Learning...   \n",
       "3  {'abstractText': 'This paper deals with the fu...   \n",
       "4  {'abstractText': 'Our work is concerned with t...   \n",
       "\n",
       "                                             summary  \n",
       "0  This paper investigates kernel ridge-less regr...  \n",
       "1  This paper presents a novel way of making full...  \n",
       "2  This paper proposes a new framework that compu...  \n",
       "3  This work proposes a deep reinforcement learni...  \n",
       "4  This paper proposes 3 deep generative models b...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = load_data(\"train\")\n",
    "# print(len(df_train))\n",
    "df_train.reset_index(inplace=True, drop=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop summary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>{'abstractText': 'We study the average CVloo s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:b80bc890180934092cde037b49d94d6e4e06fad9</td>\n",
       "      <td>{'abstractText': 'The use of episodic memories...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939</td>\n",
       "      <td>{'abstractText': 'Existing Multi-Task Learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP:a1e2218e6943bf138aeb359e23628676b396ed66</td>\n",
       "      <td>{'abstractText': 'This paper deals with the fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66</td>\n",
       "      <td>{'abstractText': 'Our work is concerned with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18929</th>\n",
       "      <td>SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695</td>\n",
       "      <td>{'abstractText': 'Discovering the underlying m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18930</th>\n",
       "      <td>SP:4706017e6f8b958c7d0825fed98b285ea2994b59</td>\n",
       "      <td>{'abstractText': 'Some conventional transforms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18931</th>\n",
       "      <td>SP:4706017e6f8b958c7d0825fed98b285ea2994b59</td>\n",
       "      <td>{'abstractText': 'Some conventional transforms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18932</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>{'abstractText': 'Thanks to graph neural netwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18933</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>{'abstractText': 'Thanks to graph neural netwo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18934 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          paper_id  \\\n",
       "0      SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc   \n",
       "1      SP:b80bc890180934092cde037b49d94d6e4e06fad9   \n",
       "2      SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939   \n",
       "3      SP:a1e2218e6943bf138aeb359e23628676b396ed66   \n",
       "4      SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66   \n",
       "...                                            ...   \n",
       "18929  SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695   \n",
       "18930  SP:4706017e6f8b958c7d0825fed98b285ea2994b59   \n",
       "18931  SP:4706017e6f8b958c7d0825fed98b285ea2994b59   \n",
       "18932  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb   \n",
       "18933  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb   \n",
       "\n",
       "                                                   paper  \n",
       "0      {'abstractText': 'We study the average CVloo s...  \n",
       "1      {'abstractText': 'The use of episodic memories...  \n",
       "2      {'abstractText': 'Existing Multi-Task Learning...  \n",
       "3      {'abstractText': 'This paper deals with the fu...  \n",
       "4      {'abstractText': 'Our work is concerned with t...  \n",
       "...                                                  ...  \n",
       "18929  {'abstractText': 'Discovering the underlying m...  \n",
       "18930  {'abstractText': 'Some conventional transforms...  \n",
       "18931  {'abstractText': 'Some conventional transforms...  \n",
       "18932  {'abstractText': 'Thanks to graph neural netwo...  \n",
       "18933  {'abstractText': 'Thanks to graph neural netwo...  \n",
       "\n",
       "[18934 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.drop(['summary'], axis=1, inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>{'abstractText': 'We study the average CVloo s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:b80bc890180934092cde037b49d94d6e4e06fad9</td>\n",
       "      <td>{'abstractText': 'The use of episodic memories...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939</td>\n",
       "      <td>{'abstractText': 'Existing Multi-Task Learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP:a1e2218e6943bf138aeb359e23628676b396ed66</td>\n",
       "      <td>{'abstractText': 'This paper deals with the fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66</td>\n",
       "      <td>{'abstractText': 'Our work is concerned with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18924</th>\n",
       "      <td>SP:77d59e1e726172184249bdfdd81011617dc9c208</td>\n",
       "      <td>{'abstractText': 'Quantum machine learning met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18926</th>\n",
       "      <td>SP:e58dc2d21175a62499405b7f4c3a03b135530838</td>\n",
       "      <td>{'abstractText': 'Trained generative models ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18928</th>\n",
       "      <td>SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695</td>\n",
       "      <td>{'abstractText': 'Discovering the underlying m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18930</th>\n",
       "      <td>SP:4706017e6f8b958c7d0825fed98b285ea2994b59</td>\n",
       "      <td>{'abstractText': 'Some conventional transforms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18932</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>{'abstractText': 'Thanks to graph neural netwo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8379 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          paper_id  \\\n",
       "0      SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc   \n",
       "1      SP:b80bc890180934092cde037b49d94d6e4e06fad9   \n",
       "2      SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939   \n",
       "3      SP:a1e2218e6943bf138aeb359e23628676b396ed66   \n",
       "4      SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66   \n",
       "...                                            ...   \n",
       "18924  SP:77d59e1e726172184249bdfdd81011617dc9c208   \n",
       "18926  SP:e58dc2d21175a62499405b7f4c3a03b135530838   \n",
       "18928  SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695   \n",
       "18930  SP:4706017e6f8b958c7d0825fed98b285ea2994b59   \n",
       "18932  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb   \n",
       "\n",
       "                                                   paper  \n",
       "0      {'abstractText': 'We study the average CVloo s...  \n",
       "1      {'abstractText': 'The use of episodic memories...  \n",
       "2      {'abstractText': 'Existing Multi-Task Learning...  \n",
       "3      {'abstractText': 'This paper deals with the fu...  \n",
       "4      {'abstractText': 'Our work is concerned with t...  \n",
       "...                                                  ...  \n",
       "18924  {'abstractText': 'Quantum machine learning met...  \n",
       "18926  {'abstractText': 'Trained generative models ha...  \n",
       "18928  {'abstractText': 'Discovering the underlying m...  \n",
       "18930  {'abstractText': 'Some conventional transforms...  \n",
       "18932  {'abstractText': 'Thanks to graph neural netwo...  \n",
       "\n",
       "[8379 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.drop_duplicates(subset=['paper_id'],inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>{'abstractText': 'We study the average CVloo s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:b80bc890180934092cde037b49d94d6e4e06fad9</td>\n",
       "      <td>{'abstractText': 'The use of episodic memories...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939</td>\n",
       "      <td>{'abstractText': 'Existing Multi-Task Learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP:a1e2218e6943bf138aeb359e23628676b396ed66</td>\n",
       "      <td>{'abstractText': 'This paper deals with the fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66</td>\n",
       "      <td>{'abstractText': 'Our work is concerned with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374</th>\n",
       "      <td>SP:77d59e1e726172184249bdfdd81011617dc9c208</td>\n",
       "      <td>{'abstractText': 'Quantum machine learning met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8375</th>\n",
       "      <td>SP:e58dc2d21175a62499405b7f4c3a03b135530838</td>\n",
       "      <td>{'abstractText': 'Trained generative models ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8376</th>\n",
       "      <td>SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695</td>\n",
       "      <td>{'abstractText': 'Discovering the underlying m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8377</th>\n",
       "      <td>SP:4706017e6f8b958c7d0825fed98b285ea2994b59</td>\n",
       "      <td>{'abstractText': 'Some conventional transforms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8378</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>{'abstractText': 'Thanks to graph neural netwo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8379 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         paper_id  \\\n",
       "0     SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc   \n",
       "1     SP:b80bc890180934092cde037b49d94d6e4e06fad9   \n",
       "2     SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939   \n",
       "3     SP:a1e2218e6943bf138aeb359e23628676b396ed66   \n",
       "4     SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66   \n",
       "...                                           ...   \n",
       "8374  SP:77d59e1e726172184249bdfdd81011617dc9c208   \n",
       "8375  SP:e58dc2d21175a62499405b7f4c3a03b135530838   \n",
       "8376  SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695   \n",
       "8377  SP:4706017e6f8b958c7d0825fed98b285ea2994b59   \n",
       "8378  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb   \n",
       "\n",
       "                                                  paper  \n",
       "0     {'abstractText': 'We study the average CVloo s...  \n",
       "1     {'abstractText': 'The use of episodic memories...  \n",
       "2     {'abstractText': 'Existing Multi-Task Learning...  \n",
       "3     {'abstractText': 'This paper deals with the fu...  \n",
       "4     {'abstractText': 'Our work is concerned with t...  \n",
       "...                                                 ...  \n",
       "8374  {'abstractText': 'Quantum machine learning met...  \n",
       "8375  {'abstractText': 'Trained generative models ha...  \n",
       "8376  {'abstractText': 'Discovering the underlying m...  \n",
       "8377  {'abstractText': 'Some conventional transforms...  \n",
       "8378  {'abstractText': 'Thanks to graph neural netwo...  \n",
       "\n",
       "[8379 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 INTRODUCTION\n",
      "2 STATISTICAL LEARNING AND EMPIRICAL RISK MINIMIZATION\n",
      "2.1 KERNEL LEAST SQUARES AND MINIMUM NORM SOLUTION\n",
      "3 ERROR BOUNDS VIA STABILITY\n",
      "4.1 KEY LEMMAS\n",
      "4.2 PROOF OF LEMMA 11\n",
      "5 REMARK AND RELATED WORK\n",
      "6 CONCLUSIONS\n",
      "A EXCESS RISK, GENERALIZATION, AND STABILITY\n",
      "====================================================================================================\n",
      "1 INTRODUCTION\n",
      "2 A NEW PERSPECTIVE OF REDUCING DIVERSITY OF GRADIENTS\n",
      "2.1 THE SOURCE OF GRADIENT DIVERSITY\n",
      "2.2 CONNECTING DEEP METRIC LEARNING TO CONTINUAL LEARNING\n",
      "3 DISCRIMINATIVE REPRESENTATION LOSS\n",
      "4 ONLINE MEMORY UPDATE AND BALANCED EXPERIENCE REPLAY\n",
      "5 EXPERIMENTS\n",
      "6 CONCLUSION\n",
      "A PROOF OF THEOREMS\n",
      "B ALGORITHMS OF ONLINE MEMORY UPDATE\n",
      "C DEFINITION OF PERFORMANCE MEASURES\n",
      "D RELATED METHODS FROM DML\n",
      "E ABLATION STUDY ON DRL\n",
      "F COMPARING DIFFERENT MEMORY SIZES\n",
      "G COMPARING DIFFERENT REPLAY STRATEGY\n",
      "H COMPARING TRAINING TIME\n",
      "I HYPER-PARAMETERS IN EXPERIMENTS\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    for sec in ((df_train['paper'][i])['sections']):\n",
    "        print((sec)['heading'])\n",
    "        # print(\">\"*10, sec['text'][:40])\n",
    "    print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sections extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def section_extraction(sec):\n",
    "    text = sec['text']\n",
    "    try:\n",
    "        # sec['heading']=sec['heading'].upper()\n",
    "        sec_split = ((sec)['heading'].upper()).split()\n",
    "        if len(sec_split)==1:\n",
    "            head_no = None\n",
    "            head_title = sec_split[0]\n",
    "        else:\n",
    "            head_no = sec_split[0]\n",
    "            head_title = \" \".join(sec_split[1:])\n",
    "    except:\n",
    "        head_no = None\n",
    "        head_title = None\n",
    "    return head_no, head_title, text\n",
    "\n",
    "def get_ext_section(df):\n",
    "    full_len = len(df)\n",
    "    sections_data = [] \n",
    "    one_section_papers = []\n",
    "    for ind, row in (df).iterrows():\n",
    "        sections = ((row['paper'])['sections'])\n",
    "        if len(sections)<=1: \n",
    "            one_section_papers.append(row['paper_id'])\n",
    "            continue\n",
    "        for sec in sections:\n",
    "            head_no, head_title, text = section_extraction(sec)\n",
    "            if head_no is not None:\n",
    "                while head_no[-1] in ['.','/',',',')']:\n",
    "                    head_no = head_no[:-1]\n",
    "            sections_data.append({\n",
    "                'paper_id': row['paper_id'],\n",
    "                'head_no': head_no,\n",
    "                'head_title': head_title,\n",
    "                'text': text,\n",
    "            })   \n",
    "        print_progress(ind, full_len, bar_size=50)\n",
    "    return pd.DataFrame(sections_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 8379/8379\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>head_no</th>\n",
       "      <th>head_title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>Statistical learning theory studies the learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>2</td>\n",
       "      <td>STATISTICAL LEARNING AND EMPIRICAL RISK MINIMI...</td>\n",
       "      <td>We begin by recalling the basic ideas in stati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>2.1</td>\n",
       "      <td>KERNEL LEAST SQUARES AND MINIMUM NORM SOLUTION</td>\n",
       "      <td>The focus in this paper is on the kernel least...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>3</td>\n",
       "      <td>ERROR BOUNDS VIA STABILITY</td>\n",
       "      <td>In this section, we recall basic results relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>4.1</td>\n",
       "      <td>KEY LEMMAS</td>\n",
       "      <td>In order to prove Theorem 7 we make use of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148542</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>B.4</td>\n",
       "      <td>ANALYZE FOR EPISTEMIC IN OOD DETECTION</td>\n",
       "      <td>In OOD detection, epistemic uncertainty perfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148543</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>C</td>\n",
       "      <td>DERIVATIONS FOR UNCERTAINTY MEASURES AND KL DI...</td>\n",
       "      <td>This appendix provides the derivations and sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148544</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>C.1</td>\n",
       "      <td>UNCERTAINTY MEASURES</td>\n",
       "      <td>Vacuity uncertainty of Bayesian Graph neural n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148545</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>C.2</td>\n",
       "      <td>JOINT PROBABILITY</td>\n",
       "      <td>At the test stage, we infer the joint probabil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148546</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>C.3</td>\n",
       "      <td>KL-DIVERGENCE</td>\n",
       "      <td>KL-divergence between Prob(y|r;β) and Prob(y|r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148547 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paper_id head_no  \\\n",
       "0       SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       1   \n",
       "1       SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       2   \n",
       "2       SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc     2.1   \n",
       "3       SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       3   \n",
       "4       SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc     4.1   \n",
       "...                                             ...     ...   \n",
       "148542  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb     B.4   \n",
       "148543  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb       C   \n",
       "148544  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb     C.1   \n",
       "148545  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb     C.2   \n",
       "148546  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb     C.3   \n",
       "\n",
       "                                               head_title  \\\n",
       "0                                            INTRODUCTION   \n",
       "1       STATISTICAL LEARNING AND EMPIRICAL RISK MINIMI...   \n",
       "2          KERNEL LEAST SQUARES AND MINIMUM NORM SOLUTION   \n",
       "3                              ERROR BOUNDS VIA STABILITY   \n",
       "4                                              KEY LEMMAS   \n",
       "...                                                   ...   \n",
       "148542             ANALYZE FOR EPISTEMIC IN OOD DETECTION   \n",
       "148543  DERIVATIONS FOR UNCERTAINTY MEASURES AND KL DI...   \n",
       "148544                               UNCERTAINTY MEASURES   \n",
       "148545                                  JOINT PROBABILITY   \n",
       "148546                                      KL-DIVERGENCE   \n",
       "\n",
       "                                                     text  \n",
       "0       Statistical learning theory studies the learni...  \n",
       "1       We begin by recalling the basic ideas in stati...  \n",
       "2       The focus in this paper is on the kernel least...  \n",
       "3       In this section, we recall basic results relat...  \n",
       "4       In order to prove Theorem 7 we make use of the...  \n",
       "...                                                   ...  \n",
       "148542  In OOD detection, epistemic uncertainty perfor...  \n",
       "148543  This appendix provides the derivations and sho...  \n",
       "148544  Vacuity uncertainty of Bayesian Graph neural n...  \n",
       "148545  At the test stage, we infer the joint probabil...  \n",
       "148546  KL-divergence between Prob(y|r;β) and Prob(y|r...  \n",
       "\n",
       "[148547 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paper = get_ext_section(df_train)\n",
    "df_paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file_dir = 'visualization_data\n",
    "# if not(Path(log_dir).exists()): os.system(f\"mkdir -p {log_dir}\")\n",
    "# df_paper.to_csv(f\"{file_dir}/paper_sections.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Extracted CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_paper = pd.read_csv(\"visualization_data/paper_sections.csv\", index_col=0)\n",
    "# df_paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepossing heading title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>head_no</th>\n",
       "      <th>head_title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>Statistical learning theory studies the learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>2</td>\n",
       "      <td>STATISTICAL LEARNING AND EMPIRICAL RISK MINIMI...</td>\n",
       "      <td>We begin by recalling the basic ideas in stati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>3</td>\n",
       "      <td>ERROR BOUNDS VIA STABILITY</td>\n",
       "      <td>In this section, we recall basic results relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>5</td>\n",
       "      <td>REMARK AND RELATED WORK</td>\n",
       "      <td>In the previous section we obtained bounds on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>6</td>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>In summary, minimizing a bound on cross valida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48456</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>2</td>\n",
       "      <td>RELATED WORK</td>\n",
       "      <td>Epistemic Uncertainty in Bayesian Deep Learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48457</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>3</td>\n",
       "      <td>PROPOSED APPROACH</td>\n",
       "      <td>Now we define the problem of uncertainty-aware...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48458</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>4</td>\n",
       "      <td>EXPERIMENTS</td>\n",
       "      <td>In this section, we describe our experimental ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48459</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>5</td>\n",
       "      <td>UNCERTAINTY EXPERIMENT AND ANALYSIS</td>\n",
       "      <td>In Section 4, we showed that our S-BGNN-T impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48460</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>6</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>In this work, we proposed a Subjective Bayesia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48461 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          paper_id head_no  \\\n",
       "0      SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       1   \n",
       "1      SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       2   \n",
       "2      SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       3   \n",
       "3      SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       5   \n",
       "4      SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       6   \n",
       "...                                            ...     ...   \n",
       "48456  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb       2   \n",
       "48457  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb       3   \n",
       "48458  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb       4   \n",
       "48459  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb       5   \n",
       "48460  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb       6   \n",
       "\n",
       "                                              head_title  \\\n",
       "0                                           INTRODUCTION   \n",
       "1      STATISTICAL LEARNING AND EMPIRICAL RISK MINIMI...   \n",
       "2                             ERROR BOUNDS VIA STABILITY   \n",
       "3                                REMARK AND RELATED WORK   \n",
       "4                                            CONCLUSIONS   \n",
       "...                                                  ...   \n",
       "48456                                       RELATED WORK   \n",
       "48457                                  PROPOSED APPROACH   \n",
       "48458                                        EXPERIMENTS   \n",
       "48459                UNCERTAINTY EXPERIMENT AND ANALYSIS   \n",
       "48460                                         CONCLUSION   \n",
       "\n",
       "                                                    text  \n",
       "0      Statistical learning theory studies the learni...  \n",
       "1      We begin by recalling the basic ideas in stati...  \n",
       "2      In this section, we recall basic results relat...  \n",
       "3      In the previous section we obtained bounds on ...  \n",
       "4      In summary, minimizing a bound on cross valida...  \n",
       "...                                                  ...  \n",
       "48456  Epistemic Uncertainty in Bayesian Deep Learnin...  \n",
       "48457  Now we define the problem of uncertainty-aware...  \n",
       "48458  In this section, we describe our experimental ...  \n",
       "48459  In Section 4, we showed that our S-BGNN-T impr...  \n",
       "48460  In this work, we proposed a Subjective Bayesia...  \n",
       "\n",
       "[48461 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no = list(str(i) for i in range(10))\n",
    "df_paper_main = df_paper[df_paper[\"head_no\"].isin(no)]\n",
    "df_paper_main.reset_index(drop=True, inplace=True)\n",
    "df_paper_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to set df_paper_main with all sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 144299 entries, 0 to 148546\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   paper_id    144299 non-null  object\n",
      " 1   head_no     144299 non-null  object\n",
      " 2   head_title  144299 non-null  object\n",
      " 3   text        144299 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 9.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_paper_main = df_paper[df_paper['head_title'].notna()]\n",
    "df_paper_main.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>head_no</th>\n",
       "      <th>head_title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>Statistical learning theory studies the learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>2</td>\n",
       "      <td>STATISTICAL LEARNING AND EMPIRICAL RISK MINIMI...</td>\n",
       "      <td>We begin by recalling the basic ideas in stati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>2.1</td>\n",
       "      <td>KERNEL LEAST SQUARES AND MINIMUM NORM SOLUTION</td>\n",
       "      <td>The focus in this paper is on the kernel least...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>3</td>\n",
       "      <td>ERROR BOUNDS VIA STABILITY</td>\n",
       "      <td>In this section, we recall basic results relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>4.1</td>\n",
       "      <td>KEY LEMMAS</td>\n",
       "      <td>In order to prove Theorem 7 we make use of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148542</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>B.4</td>\n",
       "      <td>ANALYZE FOR EPISTEMIC IN OOD DETECTION</td>\n",
       "      <td>In OOD detection, epistemic uncertainty perfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148543</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>C</td>\n",
       "      <td>DERIVATIONS FOR UNCERTAINTY MEASURES AND KL DI...</td>\n",
       "      <td>This appendix provides the derivations and sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148544</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>C.1</td>\n",
       "      <td>UNCERTAINTY MEASURES</td>\n",
       "      <td>Vacuity uncertainty of Bayesian Graph neural n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148545</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>C.2</td>\n",
       "      <td>JOINT PROBABILITY</td>\n",
       "      <td>At the test stage, we infer the joint probabil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148546</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>C.3</td>\n",
       "      <td>KL-DIVERGENCE</td>\n",
       "      <td>KL-divergence between Prob(y|r;β) and Prob(y|r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147065 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paper_id head_no  \\\n",
       "0       SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       1   \n",
       "1       SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       2   \n",
       "2       SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc     2.1   \n",
       "3       SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       3   \n",
       "4       SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc     4.1   \n",
       "...                                             ...     ...   \n",
       "148542  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb     B.4   \n",
       "148543  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb       C   \n",
       "148544  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb     C.1   \n",
       "148545  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb     C.2   \n",
       "148546  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb     C.3   \n",
       "\n",
       "                                               head_title  \\\n",
       "0                                            INTRODUCTION   \n",
       "1       STATISTICAL LEARNING AND EMPIRICAL RISK MINIMI...   \n",
       "2          KERNEL LEAST SQUARES AND MINIMUM NORM SOLUTION   \n",
       "3                              ERROR BOUNDS VIA STABILITY   \n",
       "4                                              KEY LEMMAS   \n",
       "...                                                   ...   \n",
       "148542             ANALYZE FOR EPISTEMIC IN OOD DETECTION   \n",
       "148543  DERIVATIONS FOR UNCERTAINTY MEASURES AND KL DI...   \n",
       "148544                               UNCERTAINTY MEASURES   \n",
       "148545                                  JOINT PROBABILITY   \n",
       "148546                                      KL-DIVERGENCE   \n",
       "\n",
       "                                                     text  \n",
       "0       Statistical learning theory studies the learni...  \n",
       "1       We begin by recalling the basic ideas in stati...  \n",
       "2       The focus in this paper is on the kernel least...  \n",
       "3       In this section, we recall basic results relat...  \n",
       "4       In order to prove Theorem 7 we make use of the...  \n",
       "...                                                   ...  \n",
       "148542  In OOD detection, epistemic uncertainty perfor...  \n",
       "148543  This appendix provides the derivations and sho...  \n",
       "148544  Vacuity uncertainty of Bayesian Graph neural n...  \n",
       "148545  At the test stage, we infer the joint probabil...  \n",
       "148546  KL-divergence between Prob(y|r;β) and Prob(y|r...  \n",
       "\n",
       "[147065 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paper_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1171467/3370833385.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_paper_main['head_title'] = prepro_list\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>head_no</th>\n",
       "      <th>head_title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>Statistical learning theory studies the learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>2</td>\n",
       "      <td>STATISTICAL LEARNING AND EMPIRICAL RISK MINIMI...</td>\n",
       "      <td>We begin by recalling the basic ideas in stati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>2.1</td>\n",
       "      <td>KERNEL LEAST SQUARES AND MINIMUM NORM SOLUTION</td>\n",
       "      <td>The focus in this paper is on the kernel least...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>3</td>\n",
       "      <td>ERROR BOUNDS VIA STABILITY</td>\n",
       "      <td>In this section, we recall basic results relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>4.1</td>\n",
       "      <td>KEY LEMMA</td>\n",
       "      <td>In order to prove Theorem 7 we make use of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>4.2</td>\n",
       "      <td>PROOF OF LEMMA 11</td>\n",
       "      <td>We can write any interpolating solution to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>5</td>\n",
       "      <td>REMARK AND RELATED WORK</td>\n",
       "      <td>In the previous section we obtained bounds on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>6</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>In summary, minimizing a bound on cross valida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>A</td>\n",
       "      <td>EXCESS RISK, GENERALIZATION, AND STABILITY</td>\n",
       "      <td>We use the same notation as introduced in Sect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SP:b80bc890180934092cde037b49d94d6e4e06fad9</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>In the real world, we are often faced with sit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      paper_id head_no  \\\n",
       "0  SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       1   \n",
       "1  SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       2   \n",
       "2  SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc     2.1   \n",
       "3  SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       3   \n",
       "4  SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc     4.1   \n",
       "5  SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc     4.2   \n",
       "6  SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       5   \n",
       "7  SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       6   \n",
       "8  SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       A   \n",
       "9  SP:b80bc890180934092cde037b49d94d6e4e06fad9       1   \n",
       "\n",
       "                                          head_title  \\\n",
       "0                                       INTRODUCTION   \n",
       "1  STATISTICAL LEARNING AND EMPIRICAL RISK MINIMI...   \n",
       "2     KERNEL LEAST SQUARES AND MINIMUM NORM SOLUTION   \n",
       "3                         ERROR BOUNDS VIA STABILITY   \n",
       "4                                          KEY LEMMA   \n",
       "5                                  PROOF OF LEMMA 11   \n",
       "6                            REMARK AND RELATED WORK   \n",
       "7                                         CONCLUSION   \n",
       "8         EXCESS RISK, GENERALIZATION, AND STABILITY   \n",
       "9                                       INTRODUCTION   \n",
       "\n",
       "                                                text  \n",
       "0  Statistical learning theory studies the learni...  \n",
       "1  We begin by recalling the basic ideas in stati...  \n",
       "2  The focus in this paper is on the kernel least...  \n",
       "3  In this section, we recall basic results relat...  \n",
       "4  In order to prove Theorem 7 we make use of the...  \n",
       "5  We can write any interpolating solution to the...  \n",
       "6  In the previous section we obtained bounds on ...  \n",
       "7  In summary, minimizing a bound on cross valida...  \n",
       "8  We use the same notation as introduced in Sect...  \n",
       "9  In the real world, we are often faced with sit...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = inflect.engine()\n",
    "prepro_list = [p.singular_noun(word) if p.singular_noun(word)!=False else word for word in df_paper_main['head_title']]\n",
    "df_paper_main['head_title'] = prepro_list\n",
    "df_paper_main[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head_title</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>7923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RELATED WORK</td>\n",
       "      <td>5533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>5453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXPERIMENT</td>\n",
       "      <td>4733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>APPENDIX</td>\n",
       "      <td>1559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79476</th>\n",
       "      <td>EXACT ANALYSI WITH TOY MODEL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79477</th>\n",
       "      <td>EX-POST DENSITY ESTIMATION</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79478</th>\n",
       "      <td>EWMA COMPARISON</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79479</th>\n",
       "      <td>EWC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79480</th>\n",
       "      <td>𝑓 ON TARGET DATA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79481 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         head_title  count\n",
       "0                      INTRODUCTION   7923\n",
       "1                      RELATED WORK   5533\n",
       "2                        CONCLUSION   5453\n",
       "3                        EXPERIMENT   4733\n",
       "4                          APPENDIX   1559\n",
       "...                             ...    ...\n",
       "79476  EXACT ANALYSI WITH TOY MODEL      1\n",
       "79477    EX-POST DENSITY ESTIMATION      1\n",
       "79478               EWMA COMPARISON      1\n",
       "79479                           EWC      1\n",
       "79480              𝑓 ON TARGET DATA      1\n",
       "\n",
       "[79481 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_heading = pd.DataFrame(df_paper_main.groupby(\"head_title\")[\"head_title\"].count())\n",
    "df_heading.columns = [\"count\"]\n",
    "df_heading.reset_index(inplace=True)\n",
    "df_heading.sort_values('count', ascending=False, inplace=True)\n",
    "df_heading.reset_index(drop=True, inplace=True)\n",
    "df_heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head_title</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EXPERIMENTAL SETUP</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SETUP</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>EXPERIMENT SETUP</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>PROBLEM SETUP</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>TRAINING SETUP</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78361</th>\n",
       "      <td>EXPERIEMNTAL SETUP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78391</th>\n",
       "      <td>EXPERIMEMT SETUP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78634</th>\n",
       "      <td>EXPERIMENT FOR OTHER SETUPS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78996</th>\n",
       "      <td>EVALUATION SETUP AND METRIC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79137</th>\n",
       "      <td>EVALUATION ON FULL SETUP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        head_title  count\n",
       "13              EXPERIMENTAL SETUP    801\n",
       "33                           SETUP    228\n",
       "47                EXPERIMENT SETUP    160\n",
       "56                   PROBLEM SETUP    137\n",
       "273                 TRAINING SETUP     19\n",
       "...                            ...    ...\n",
       "78361           EXPERIEMNTAL SETUP      1\n",
       "78391             EXPERIMEMT SETUP      1\n",
       "78634  EXPERIMENT FOR OTHER SETUPS      1\n",
       "78996  EVALUATION SETUP AND METRIC      1\n",
       "79137     EVALUATION ON FULL SETUP      1\n",
       "\n",
       "[480 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_heading[df_heading['head_title'].str.contains(r'SETUP*')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set section's keys adapted from *paper:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "section_keys = {\n",
    "    \"intro\":    [\"INTRODUCTION\", \"PROBLEM\", \"MOTIVATION\", \"PRELIMINARY\", \"OVERVIEW\"],\n",
    "    \"liture\":   [\"RELATED WORK\", \"BACKGROUND\", \"THEORY\", \"PREVIOUS WORK\", \"PRIOR WORK\", \"REVIEW\", \"BASELINE\"],\n",
    "    \"method\":   [\"APPROACH\", \"TECHNIQUE\", \"MODEL\", \"ALGORITHM\", \"METHOD\", \"DATASET\", \"SETUP\", \"SETTING\", \"FRAMEWORK\", \"ARCHITECTURE\", \"IMPLEMENTATION\", \"CONTRIBUTION\"],\n",
    "    \"result\":   [\"EXPERIMENT\", \"RESULT\", \"EVALUATION\", \"ABLATION STUDY\"],\n",
    "    \"discuss\":  [\"DISCUSSION\", \"LIMITATION\", \"ANALYS\"],\n",
    "    \"conclude\": [\"CONCLU\", \"FUTURE WORK\", \"APPLICATION\", \"SUMMARY\", \"IMPACT\"],\n",
    "    \"addition\": [\"NOTATION\", \"APPENDIX\", \"ACKNOWLEDGMENT\", \"ACKNOWLEDGEMENT\", \"EXTENSION\", \"REMARK\", \"MATERIAL\", \"ENVIRONMENT\"],\n",
    "}\n",
    "introduction_key = [\"INTRODUCTION\", \"PROBLEM\", \"MOTIVATION\", \"PRELIMINARY\", \"OVERVIEW\"]\n",
    "literature_key = [\"RELATED WORK\", \"BACKGROUND\", \"THEORY\", \"PREVIOUS WORK\", \"PRIOR WORK\", \"REVIEW\", \"BASELINE\"]\n",
    "method_key = [\"APPROACH\", \"TECHNIQUE\", \"MODEL\", \"ALGORITHM\", \"METHOD\", \"DATASET\", \"SETUP\", \"SETTING\", \"FRAMEWORK\", \"ARCHITECTURE\", \"IMPLEMENTATION\", \"CONTRIBUTION\"]\n",
    "result_key =[\"EXPERIMENT\", \"RESULT\", \"EVALUATION\", \"ABLATION STUDY\"]\n",
    "discuss_key = [\"DISCUSSION\", \"LIMITATION\", \"ANALYS\"]\n",
    "conclusion_key = [\"CONCLU\", \"FUTURE WORK\", \"APPLICATION\", \"SUMMARY\", \"IMPACT\"]\n",
    "additional_key = [\"NOTATION\", \"APPENDIX\", \"ACKNOWLEDGMENT\", \"ACKNOWLEDGEMENT\", \"EXTENSION\", \"REMARK\", \"MATERIAL\", \"ENVIRONMENT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# other = [\"REPRODUCIBILITY\", \"SIMULATION\", \"EXAMPLE\", \"FORMULATION\", \"LEARNING\", \"TASK\"]\n",
    "# pattern = r'CONCLU*|INTRODUCTION*|FUTURE*|WORK*|DISCUSSION*|ACKNOWLEDGMENT*|ACKNOWLEDGEMENT*|APPROACH*|MODEL*|ANALYSI*|ALGORITHM*|RELATED*|EXPERIMENT*|METHOD*|\\\n",
    "#     |PRELIMINARY*|BACKGROUND*|RESULT*|EVALUATION*|APPENDIX*|ABLATION STUDY*|LIMITATION*|PROBLEM*|STATEMENT*|\\\n",
    "#     |APPLICATION*|THEORY*|MOTIVATION*|IMPACT*|METHOD*|REPRODUCIBILITY*|SUMMARY*|DATASET*|STUDY*|SETUP*|\\\n",
    "#     |SIMULATION*|FRAMEWORK*|IMPLEMENTATION*|NOTATION*|SETTING*|ARCHITECTURE*|PREVIOUS WORK*|PRIOR WORK*|REVIEW*|LITERATURE*|\\\n",
    "#     |EXTENSION*|EXAMPLE*|FORMULATION*|OVERVIEW*|REMARK*|LEARNING*|ENVIRONMENT*|BASELINE*|CONTRIBUTION*|TASK*|MATERIAL*'\n",
    "# mask = df_heading['head_title'].str.contains(pattern)\n",
    "# n = 30*0\n",
    "# df_heading[~mask][n:n+30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pattern(keys):\n",
    "    pattern_str = r''\n",
    "    for key in keys:\n",
    "        pattern_str += key + \"*|\"\n",
    "    return pattern_str[:-1]\n",
    "\n",
    "def count_sec(keys, col_name):\n",
    "    mask = df_paper_main['head_title'].str.contains(pattern(keys))\n",
    "    df_count = pd.DataFrame(df_paper_main[mask].groupby(\"paper_id\")[\"paper_id\"].count())\n",
    "    df_count.columns = [col_name]\n",
    "    # intro_count.reset_index(inplace=True)\n",
    "    return df_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paper_id_main = list(df_paper_main['paper_id'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8038"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for k, v in section_keys.items():\n",
    "#     mask = df_paper_main['head_title'].str.contains(pattern(v))\n",
    "# df_tag = df_paper_main.copy()\n",
    "keys = section_keys[\"intro\"]\n",
    "mask = df_paper_main['head_title'].str.contains(pattern(keys))    \n",
    "df_intro = df_paper_main[mask]\n",
    "df_intro = df_intro[df_intro['text']!=''].reset_index(drop=True)\n",
    "paper_intro = list(set(df_intro['paper_id']))\n",
    "intro_idx = []\n",
    "i = 0\n",
    "for paper_id in paper_intro:\n",
    "    paper_df = df_intro[df_intro['paper_id']==paper_id]\n",
    "    intro_idx.append(paper_df.index[0])\n",
    "    # i += 1\n",
    "    # if i>3: break\n",
    "    # if len(paper_df)>1:\n",
    "    #     min_head_no = min(list(paper_df['head_no']))\n",
    "    #     intro_idx\n",
    "    #     print(paper_df.index[0])\n",
    "    #     # print(min_head_no)\n",
    "    #     break\n",
    "    # else:\n",
    "    #     intro_idx.append(0)\n",
    "    #     break\n",
    "len(intro_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'INTRODUCTION': 7889, 'INTRODUCTION AND MOTIVATION': 14, 'MOTIVATION': 12, 'PROBLEM SETUP': 2, 'THEORETICAL MOTIVATION: WHY TWO-TIME-SCALE MODELS?': 1, 'INTRODUCTION AND CONTRIBUTION': 1, 'INTRODUCTION:': 1, 'PRELIMINARY': 21, 'INTRODUCTION AND SETTING': 1, 'PROBLEM FORMULATION': 6, 'INTRODUCTION AND BACKGROUND': 6, 'INTRODUCTION AND LITERATURE REVIEW': 1, 'ARCHITECTURAL OVERVIEW': 1, 'LINEAR PROBLEM': 1, 'INTRODUCTION AND RELATED WORK': 25, 'INTRODUCTION: STATE OF THE ART': 1, 'BACKGROUND AND MOTIVATION': 4, 'BACKGROUND AND PROBLEM STATEMENT': 1, 'INTRODUCTION TO BANDIT MULTIPLE HYPOTHESIS TESTING': 1, 'PROBLEM STATEMENT': 4, 'BACKGROUND AND PRELIMINARY': 1, 'PRELIMINARIES AND PROBLEM DEFINITION': 1, 'GEOMOL HIGH-LEVEL OVERVIEW': 1, 'PRELIMINARIES: PLANNING IN PARTIALLY-REVEALED ENVIRONMENTS': 1, 'INTRODUCTION & MOTIVATION': 2, 'OVERVIEW OVER LOSS FUNCTIONS': 1, 'PROBLEM DEFINITION': 1, 'MOTIVATION AND CONTRIBUTION': 3, 'PRELIMINARY ON KNOWLEDGE DISTILLATION': 1, 'INTRODUCTION AND MAIN RESULT': 1, 'INTRODUCTION AND RELATION TO OTHER WORKS': 1, 'OVERVIEW': 4, 'INTRODUCTION & RELATED WORK': 2, 'PRELIMINARIES 99': 1, 'TWO DISTRIBUTED PROBLEMS: DETERMINISTIC AND STOCHASTIC': 1, 'PROBLEM SETTING': 3, 'INTRODUCTION: TAMING INSTABILITY WITH SMOOTHNESS': 1, 'OVERVIEW OF OUR APPROACH': 1, 'JUSTIFYING THE INTRODUCTION OF A META-HEAD': 1, 'DISCUSSION & OPEN PROBLEM': 1, 'THE BOLZA OPTIMISATION PROBLEM': 1, 'NOTATION AND PRELIMINARY': 1, 'MAIN RESULT AND OVERVIEW': 1, 'PRELIMINARY RESULT ON MNIST': 1, 'PROBLEMS AND MOVING FORWARD': 1, 'INTRODUCTION & BACKGROUND': 1, 'MOTIVATION AND RELATED WORK': 1, 'A PROBLEM FORMULATION FOR EVALUATING GENERALIZATION IN RL': 1, 'OVERVIEW AND MAIN RESULT': 1, 'FRAMEWORK OVERVIEW': 1, 'BACKPROPAGATION AND WEIGHT TRANSPORT PROBLEM': 1, 'THE OPTIMAL REWARD PROBLEM': 1, 'INTRODUCTION AND OVERVIEW': 1, 'CONTEXT AND MOTIVATION': 1, 'SOLVING THE CONTINUAL LEARNING PROBLEM': 1, 'PRELIMINARIES AND IRM': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>head_no</th>\n",
       "      <th>head_title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10219</th>\n",
       "      <td>SP:ed67cfd40308aa1fcadb6289553946a45da16473</td>\n",
       "      <td>1</td>\n",
       "      <td>MAIN RESULT AND OVERVIEW</td>\n",
       "      <td>Consider functions computed by a single ReLU l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          paper_id head_no  \\\n",
       "10219  SP:ed67cfd40308aa1fcadb6289553946a45da16473       1   \n",
       "\n",
       "                     head_title  \\\n",
       "10219  MAIN RESULT AND OVERVIEW   \n",
       "\n",
       "                                                    text  \n",
       "10219  Consider functions computed by a single ReLU l...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_intro_final = df_intro.iloc[intro_idx]\n",
    "head_title_intro_count = {}\n",
    "for head_title in df_intro_final['head_title']:\n",
    "    if head_title not in head_title_intro_count.keys():\n",
    "        head_title_intro_count[head_title] = 1\n",
    "    else:\n",
    "        head_title_intro_count[head_title] += 1\n",
    "print(head_title_intro_count)\n",
    "df_intro[df_intro['head_title']=='MAIN RESULT AND OVERVIEW']\n",
    "# df_paper_main[df_paper_main['paper_id']=='SP:c00f6a4198816665d335df1c8210dc612fa6443f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>head_no</th>\n",
       "      <th>head_title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>SP:0856c81319cd9dbbefc91f8357a04c664bd084b5</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>Neural architecture search (NAS) describes the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11391</th>\n",
       "      <td>SP:94d8eb827399e58de2a0aed1e5d3a1d629d7fcf7</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>Advances in Deep Reinforcement Learning (RL) h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237</th>\n",
       "      <td>SP:ee5f7316d51bcb8e09c19ee565498cc13f6349f3</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>In classification tasks, for input x, we appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>SP:d713225fa41061a2ad23a072786c21f066b2a777</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>Geometric deep learning refers to the developm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6410</th>\n",
       "      <td>SP:6efb95d8994e07d9c4482ca601df9019a0df93a6</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>Reinforcement learning (RL) for continuous act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6533</th>\n",
       "      <td>SP:6e0affde9a52c2dbc458ef3f877f5ffa2790f77b</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>Since the beginning of the recent wave of deep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>SP:f485de73661d59efd25025ddf9778652edb306c1</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>For robotic applications deployed in the real ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>SP:9bc80503d9771b780501b2dacac2cc37e4f5cd95</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>A molecule’s three-dimensional (3D) shape is c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>SP:09bbd1a342033a65e751a8878c23e3fa6facc636</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>One of the most important distinctions between...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>SP:223bbaf9169ba486cbfbc0d8c35d662ea211c358</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>Attention can be defined as the “allocation of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8038 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          paper_id head_no    head_title  \\\n",
       "3553   SP:0856c81319cd9dbbefc91f8357a04c664bd084b5       1  INTRODUCTION   \n",
       "11391  SP:94d8eb827399e58de2a0aed1e5d3a1d629d7fcf7       1  INTRODUCTION   \n",
       "5237   SP:ee5f7316d51bcb8e09c19ee565498cc13f6349f3       1  INTRODUCTION   \n",
       "2881   SP:d713225fa41061a2ad23a072786c21f066b2a777       1  INTRODUCTION   \n",
       "6410   SP:6efb95d8994e07d9c4482ca601df9019a0df93a6       1  INTRODUCTION   \n",
       "...                                            ...     ...           ...   \n",
       "6533   SP:6e0affde9a52c2dbc458ef3f877f5ffa2790f77b       1  INTRODUCTION   \n",
       "1284   SP:f485de73661d59efd25025ddf9778652edb306c1       1  INTRODUCTION   \n",
       "1487   SP:9bc80503d9771b780501b2dacac2cc37e4f5cd95       1  INTRODUCTION   \n",
       "251    SP:09bbd1a342033a65e751a8878c23e3fa6facc636       1  INTRODUCTION   \n",
       "1351   SP:223bbaf9169ba486cbfbc0d8c35d662ea211c358       1  INTRODUCTION   \n",
       "\n",
       "                                                    text  \n",
       "3553   Neural architecture search (NAS) describes the...  \n",
       "11391  Advances in Deep Reinforcement Learning (RL) h...  \n",
       "5237   In classification tasks, for input x, we appro...  \n",
       "2881   Geometric deep learning refers to the developm...  \n",
       "6410   Reinforcement learning (RL) for continuous act...  \n",
       "...                                                  ...  \n",
       "6533   Since the beginning of the recent wave of deep...  \n",
       "1284   For robotic applications deployed in the real ...  \n",
       "1487   A molecule’s three-dimensional (3D) shape is c...  \n",
       "251    One of the most important distinctions between...  \n",
       "1351   Attention can be defined as the “allocation of...  \n",
       "\n",
       "[8038 rows x 4 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_intro_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def len_paragraph(text):\n",
    "    return len(text.split(\"\\n\"))\n",
    "len_paragraph(df_intro_final.reset_index().iloc[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1171467/1065045391.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_intro_final[\"paragraphs\"] = df_intro_final[\"text\"].apply(len_paragraph)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>head_no</th>\n",
       "      <th>head_title</th>\n",
       "      <th>text</th>\n",
       "      <th>paragraphs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9717</th>\n",
       "      <td>SP:cbb2ef0a292693fffd77e7a95183e4725bf21dcd</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>Learning new concepts and skills from a small ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6237</th>\n",
       "      <td>SP:607bb2cfb36e19ba87c6d973da0d03b23eb1a445</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>Batch Normalization (BN) is an indispensable c...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6647</th>\n",
       "      <td>SP:119ec5a7b1bc981afd4d248e4643a0f0b3d49c3c</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>Consider the castle made out of toy blocks in ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>SP:6bfdc3596045227aaed04a50cd934e5d4bc1e9ad</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>Recent research has shown that deep neural net...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5575</th>\n",
       "      <td>SP:685bfac3b09438a4669b0d581a8eafdf73a81cc5</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>Learning a good representation for high-dimens...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6836</th>\n",
       "      <td>SP:452600e23747ac98ed7513304b5a008d8ee278bf</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>Neural networks are one of the most powerful m...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8460</th>\n",
       "      <td>SP:68815f20a6f2092c3ac14949d4295b9849fec002</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>Canonical correlation analysis (CCA) is a clas...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9271</th>\n",
       "      <td>SP:db15839ac53280a4ef57ee472565c137d975f52e</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>Animals play an important role in our everyday...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>SP:82c52fe144129e913a29248317952ac0fb520ffe</td>\n",
       "      <td>2</td>\n",
       "      <td>PRELIMINARIES AND IRM</td>\n",
       "      <td>Notations. We use lowercase (e.g., x), upperca...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>SP:2bd729b7aa045bf74e31229c9e76e57af36e804b</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>Backdoor attacks (Gu et al., 2017; Chen et al....</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8038 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         paper_id head_no  \\\n",
       "9717  SP:cbb2ef0a292693fffd77e7a95183e4725bf21dcd       1   \n",
       "6237  SP:607bb2cfb36e19ba87c6d973da0d03b23eb1a445       1   \n",
       "6647  SP:119ec5a7b1bc981afd4d248e4643a0f0b3d49c3c       1   \n",
       "2091  SP:6bfdc3596045227aaed04a50cd934e5d4bc1e9ad       1   \n",
       "5575  SP:685bfac3b09438a4669b0d581a8eafdf73a81cc5       1   \n",
       "...                                           ...     ...   \n",
       "6836  SP:452600e23747ac98ed7513304b5a008d8ee278bf       1   \n",
       "8460  SP:68815f20a6f2092c3ac14949d4295b9849fec002       1   \n",
       "9271  SP:db15839ac53280a4ef57ee472565c137d975f52e       1   \n",
       "2540  SP:82c52fe144129e913a29248317952ac0fb520ffe       2   \n",
       "2394  SP:2bd729b7aa045bf74e31229c9e76e57af36e804b       1   \n",
       "\n",
       "                 head_title  \\\n",
       "9717           INTRODUCTION   \n",
       "6237           INTRODUCTION   \n",
       "6647           INTRODUCTION   \n",
       "2091           INTRODUCTION   \n",
       "5575           INTRODUCTION   \n",
       "...                     ...   \n",
       "6836           INTRODUCTION   \n",
       "8460           INTRODUCTION   \n",
       "9271           INTRODUCTION   \n",
       "2540  PRELIMINARIES AND IRM   \n",
       "2394           INTRODUCTION   \n",
       "\n",
       "                                                   text  paragraphs  \n",
       "9717  Learning new concepts and skills from a small ...           5  \n",
       "6237  Batch Normalization (BN) is an indispensable c...           4  \n",
       "6647  Consider the castle made out of toy blocks in ...           5  \n",
       "2091  Recent research has shown that deep neural net...           7  \n",
       "5575  Learning a good representation for high-dimens...          10  \n",
       "...                                                 ...         ...  \n",
       "6836  Neural networks are one of the most powerful m...           8  \n",
       "8460  Canonical correlation analysis (CCA) is a clas...          14  \n",
       "9271  Animals play an important role in our everyday...           6  \n",
       "2540  Notations. We use lowercase (e.g., x), upperca...           7  \n",
       "2394  Backdoor attacks (Gu et al., 2017; Chen et al....           5  \n",
       "\n",
       "[8038 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_intro_final[\"paragraphs\"] = df_intro_final[\"text\"].apply(len_paragraph)\n",
    "df_intro_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count section catagories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intro</th>\n",
       "      <th>liture</th>\n",
       "      <th>method</th>\n",
       "      <th>result</th>\n",
       "      <th>discuss</th>\n",
       "      <th>conclude</th>\n",
       "      <th>addition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paper_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:b80bc890180934092cde037b49d94d6e4e06fad9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:a1e2218e6943bf138aeb359e23628676b396ed66</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:77d59e1e726172184249bdfdd81011617dc9c208</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:e58dc2d21175a62499405b7f4c3a03b135530838</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:4706017e6f8b958c7d0825fed98b285ea2994b59</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8232 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             intro  liture  method  result  \\\n",
       "paper_id                                                                     \n",
       "SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc    1.0     1.0     NaN     NaN   \n",
       "SP:b80bc890180934092cde037b49d94d6e4e06fad9    1.0     1.0     2.0     3.0   \n",
       "SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939    1.0     1.0     6.0     6.0   \n",
       "SP:a1e2218e6943bf138aeb359e23628676b396ed66    2.0     NaN     NaN     1.0   \n",
       "SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66    1.0     2.0     3.0     1.0   \n",
       "...                                            ...     ...     ...     ...   \n",
       "SP:77d59e1e726172184249bdfdd81011617dc9c208    2.0     NaN     3.0     NaN   \n",
       "SP:e58dc2d21175a62499405b7f4c3a03b135530838    2.0     NaN     2.0     3.0   \n",
       "SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695    1.0     1.0     1.0     1.0   \n",
       "SP:4706017e6f8b958c7d0825fed98b285ea2994b59    1.0     1.0     1.0     1.0   \n",
       "SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb    2.0     1.0     7.0     6.0   \n",
       "\n",
       "                                             discuss  conclude  addition  \n",
       "paper_id                                                                  \n",
       "SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc      NaN       1.0       1.0  \n",
       "SP:b80bc890180934092cde037b49d94d6e4e06fad9      NaN       1.0       NaN  \n",
       "SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939      NaN       1.0       1.0  \n",
       "SP:a1e2218e6943bf138aeb359e23628676b396ed66      2.0       1.0       1.0  \n",
       "SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66      NaN       1.0       1.0  \n",
       "...                                              ...       ...       ...  \n",
       "SP:77d59e1e726172184249bdfdd81011617dc9c208      NaN       NaN       NaN  \n",
       "SP:e58dc2d21175a62499405b7f4c3a03b135530838      2.0       1.0       NaN  \n",
       "SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695      1.0       1.0       NaN  \n",
       "SP:4706017e6f8b958c7d0825fed98b285ea2994b59      1.0       1.0       NaN  \n",
       "SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb      4.0       1.0       1.0  \n",
       "\n",
       "[8232 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_section_group = pd.DataFrame(index=paper_id_main)\n",
    "df_section_group.index.name='paper_id'\n",
    "\n",
    "for k, v in section_keys.items():\n",
    "    df_count = count_sec(v, k)\n",
    "    df_section_group = df_section_group.merge(df_count, on=\"paper_id\", how='outer', suffixes=('_1', '_2'))\n",
    "\n",
    "df_section_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>head_no</th>\n",
       "      <th>head_title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>Statistical learning theory studies the learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>2</td>\n",
       "      <td>STATISTICAL LEARNING AND EMPIRICAL RISK MINIMI...</td>\n",
       "      <td>We begin by recalling the basic ideas in stati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>2.1</td>\n",
       "      <td>KERNEL LEAST SQUARES AND MINIMUM NORM SOLUTION</td>\n",
       "      <td>The focus in this paper is on the kernel least...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>3</td>\n",
       "      <td>ERROR BOUNDS VIA STABILITY</td>\n",
       "      <td>In this section, we recall basic results relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>4.1</td>\n",
       "      <td>KEY LEMMA</td>\n",
       "      <td>In order to prove Theorem 7 we make use of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148542</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>B.4</td>\n",
       "      <td>ANALYZE FOR EPISTEMIC IN OOD DETECTION</td>\n",
       "      <td>In OOD detection, epistemic uncertainty perfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148543</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>C</td>\n",
       "      <td>DERIVATION FOR UNCERTAINTY MEASURES AND KL DIV...</td>\n",
       "      <td>This appendix provides the derivations and sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148544</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>C.1</td>\n",
       "      <td>UNCERTAINTY MEASURE</td>\n",
       "      <td>Vacuity uncertainty of Bayesian Graph neural n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148545</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>C.2</td>\n",
       "      <td>JOINT PROBABILITY</td>\n",
       "      <td>At the test stage, we infer the joint probabil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148546</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>C.3</td>\n",
       "      <td>KL-DIVERGENCE</td>\n",
       "      <td>KL-divergence between Prob(y|r;β) and Prob(y|r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147065 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paper_id head_no  \\\n",
       "0       SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       1   \n",
       "1       SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       2   \n",
       "2       SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc     2.1   \n",
       "3       SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       3   \n",
       "4       SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc     4.1   \n",
       "...                                             ...     ...   \n",
       "148542  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb     B.4   \n",
       "148543  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb       C   \n",
       "148544  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb     C.1   \n",
       "148545  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb     C.2   \n",
       "148546  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb     C.3   \n",
       "\n",
       "                                               head_title  \\\n",
       "0                                            INTRODUCTION   \n",
       "1       STATISTICAL LEARNING AND EMPIRICAL RISK MINIMI...   \n",
       "2          KERNEL LEAST SQUARES AND MINIMUM NORM SOLUTION   \n",
       "3                              ERROR BOUNDS VIA STABILITY   \n",
       "4                                               KEY LEMMA   \n",
       "...                                                   ...   \n",
       "148542             ANALYZE FOR EPISTEMIC IN OOD DETECTION   \n",
       "148543  DERIVATION FOR UNCERTAINTY MEASURES AND KL DIV...   \n",
       "148544                                UNCERTAINTY MEASURE   \n",
       "148545                                  JOINT PROBABILITY   \n",
       "148546                                      KL-DIVERGENCE   \n",
       "\n",
       "                                                     text  \n",
       "0       Statistical learning theory studies the learni...  \n",
       "1       We begin by recalling the basic ideas in stati...  \n",
       "2       The focus in this paper is on the kernel least...  \n",
       "3       In this section, we recall basic results relat...  \n",
       "4       In order to prove Theorem 7 we make use of the...  \n",
       "...                                                   ...  \n",
       "148542  In OOD detection, epistemic uncertainty perfor...  \n",
       "148543  This appendix provides the derivations and sho...  \n",
       "148544  Vacuity uncertainty of Bayesian Graph neural n...  \n",
       "148545  At the test stage, we infer the joint probabil...  \n",
       "148546  KL-divergence between Prob(y|r;β) and Prob(y|r...  \n",
       "\n",
       "[147065 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paper_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intro</th>\n",
       "      <th>liture</th>\n",
       "      <th>method</th>\n",
       "      <th>result</th>\n",
       "      <th>discuss</th>\n",
       "      <th>conclude</th>\n",
       "      <th>addition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paper_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SP:a20769de2c7acf390c7e3bece904a17df6a991bd</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:95ba9ad102adafaabf9671737e6549728d104629</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:797b07cd8142a35333037bb573db0dfe5dde65ac</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:72d1283f3602edc22896934271fcec5b03f25d9e</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:c83ecc74eb885df5f29e5a7080a8c60d1ee0a3b0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:7cd001a35175d8565c046093dcf070ba7fa988d6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:67c44f33dff59e4d218f753fdbc6296da62cdf62</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:62a75399aa97a61432385cf1dffabb674741a18a</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:76a052062e3e4bb707b24a8809c220c8ac1df83a</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SP:77d59e1e726172184249bdfdd81011617dc9c208</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             intro  liture  method  result  \\\n",
       "paper_id                                                                     \n",
       "SP:a20769de2c7acf390c7e3bece904a17df6a991bd    1.0     2.0     NaN     1.0   \n",
       "SP:95ba9ad102adafaabf9671737e6549728d104629    1.0     1.0     1.0     1.0   \n",
       "SP:797b07cd8142a35333037bb573db0dfe5dde65ac    1.0     NaN     3.0     7.0   \n",
       "SP:72d1283f3602edc22896934271fcec5b03f25d9e    2.0     NaN     1.0     5.0   \n",
       "SP:c83ecc74eb885df5f29e5a7080a8c60d1ee0a3b0    1.0     NaN     1.0     2.0   \n",
       "...                                            ...     ...     ...     ...   \n",
       "SP:7cd001a35175d8565c046093dcf070ba7fa988d6    2.0     NaN     4.0     3.0   \n",
       "SP:67c44f33dff59e4d218f753fdbc6296da62cdf62    2.0     3.0     5.0     1.0   \n",
       "SP:62a75399aa97a61432385cf1dffabb674741a18a    1.0     1.0     4.0     1.0   \n",
       "SP:76a052062e3e4bb707b24a8809c220c8ac1df83a    1.0     1.0     4.0     1.0   \n",
       "SP:77d59e1e726172184249bdfdd81011617dc9c208    2.0     NaN     3.0     NaN   \n",
       "\n",
       "                                             discuss  conclude  addition  \n",
       "paper_id                                                                  \n",
       "SP:a20769de2c7acf390c7e3bece904a17df6a991bd      1.0       NaN       1.0  \n",
       "SP:95ba9ad102adafaabf9671737e6549728d104629      1.0       NaN       NaN  \n",
       "SP:797b07cd8142a35333037bb573db0dfe5dde65ac      NaN       NaN       NaN  \n",
       "SP:72d1283f3602edc22896934271fcec5b03f25d9e      NaN       NaN       1.0  \n",
       "SP:c83ecc74eb885df5f29e5a7080a8c60d1ee0a3b0      1.0       NaN       1.0  \n",
       "...                                              ...       ...       ...  \n",
       "SP:7cd001a35175d8565c046093dcf070ba7fa988d6      1.0       NaN       2.0  \n",
       "SP:67c44f33dff59e4d218f753fdbc6296da62cdf62      1.0       NaN       2.0  \n",
       "SP:62a75399aa97a61432385cf1dffabb674741a18a      1.0       NaN       1.0  \n",
       "SP:76a052062e3e4bb707b24a8809c220c8ac1df83a      1.0       NaN       1.0  \n",
       "SP:77d59e1e726172184249bdfdd81011617dc9c208      NaN       NaN       NaN  \n",
       "\n",
       "[1115 rows x 7 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_section_group[df_section_group['conclude'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8232 entries, SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc to SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   intro     8058 non-null   float64\n",
      " 1   liture    7177 non-null   float64\n",
      " 2   method    7160 non-null   float64\n",
      " 3   result    7664 non-null   float64\n",
      " 4   discuss   4391 non-null   float64\n",
      " 5   conclude  7117 non-null   float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 450.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_section_group.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>head_no</th>\n",
       "      <th>head_title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>SP:a8bb14b514e474691be63b51582544a9befa7125</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>The majority of pruning algorithms for Deep Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>SP:a8bb14b514e474691be63b51582544a9befa7125</td>\n",
       "      <td>2</td>\n",
       "      <td>RELATED WORK</td>\n",
       "      <td>Pruning trained models Most of the pruning wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>SP:a8bb14b514e474691be63b51582544a9befa7125</td>\n",
       "      <td>3</td>\n",
       "      <td>PROBLEM FORMULATION: PRUNING AT INITIALIZATION</td>\n",
       "      <td>Given a dataset D = {(xi,yi)}ni=1, the trainin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>SP:a8bb14b514e474691be63b51582544a9befa7125</td>\n",
       "      <td>4</td>\n",
       "      <td>FORESIGHT CONNECTION SENSITIVITY</td>\n",
       "      <td>Since removing connections of a neural network...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>SP:a8bb14b514e474691be63b51582544a9befa7125</td>\n",
       "      <td>5</td>\n",
       "      <td>EXPERIMENTS</td>\n",
       "      <td>In the following we evaluate the efficacy of o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>SP:a8bb14b514e474691be63b51582544a9befa7125</td>\n",
       "      <td>5.1</td>\n",
       "      <td>RESULTS ON CIFAR-10</td>\n",
       "      <td>Fig 2 compares the accuracy of the described i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>SP:a8bb14b514e474691be63b51582544a9befa7125</td>\n",
       "      <td>5.2</td>\n",
       "      <td>RESULTS ON LARGER DATASETS</td>\n",
       "      <td>We now present experiments on large datasets. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>SP:a8bb14b514e474691be63b51582544a9befa7125</td>\n",
       "      <td>5.3</td>\n",
       "      <td>ANALYSIS</td>\n",
       "      <td>Saliency optimization To experimentally valida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>SP:a8bb14b514e474691be63b51582544a9befa7125</td>\n",
       "      <td>6</td>\n",
       "      <td>DISCUSSION</td>\n",
       "      <td>Pruning at initialization has become an active...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>SP:a8bb14b514e474691be63b51582544a9befa7125</td>\n",
       "      <td>None</td>\n",
       "      <td>ACKNOWLEDGMENTS</td>\n",
       "      <td>This work was supported by the Royal Academy o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>SP:a8bb14b514e474691be63b51582544a9befa7125</td>\n",
       "      <td>A</td>\n",
       "      <td>PRUNING IMPLEMENTATION DETAILS</td>\n",
       "      <td>We present experiments on CIFAR-10/100 (Krizhe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>SP:a8bb14b514e474691be63b51582544a9befa7125</td>\n",
       "      <td>B</td>\n",
       "      <td>ADDITIONAL ACCURACY-SPARSITY PLOTS</td>\n",
       "      <td>In the main text we show the complete range of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>SP:a8bb14b514e474691be63b51582544a9befa7125</td>\n",
       "      <td>C</td>\n",
       "      <td>FURTHER ANALYSIS OF PRUNING AT INITIALIZATION</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>SP:a8bb14b514e474691be63b51582544a9befa7125</td>\n",
       "      <td>C.1</td>\n",
       "      <td>SALIENCY VS T</td>\n",
       "      <td>In Fig 4 (left) we have seen that for higher s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>SP:a8bb14b514e474691be63b51582544a9befa7125</td>\n",
       "      <td>C.2</td>\n",
       "      <td>PRUNING VS SPARSIFICATION</td>\n",
       "      <td>FORCE algorithm is able to recover pruned weig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>SP:a8bb14b514e474691be63b51582544a9befa7125</td>\n",
       "      <td>C.3</td>\n",
       "      <td>NETWORK STRUCTURE AFTER PRUNING</td>\n",
       "      <td>In Fig 8 we visualize the structure of the net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>SP:a8bb14b514e474691be63b51582544a9befa7125</td>\n",
       "      <td>C.4</td>\n",
       "      <td>EVOLUTION OF PRUNING MASKS</td>\n",
       "      <td>As discussed in the main text, FORCE allows we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>SP:a8bb14b514e474691be63b51582544a9befa7125</td>\n",
       "      <td>C.5</td>\n",
       "      <td>COMPARISON WITH EARLY PRUNING</td>\n",
       "      <td>For fair comparison, we provided the same amou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>SP:a8bb14b514e474691be63b51582544a9befa7125</td>\n",
       "      <td>C.6</td>\n",
       "      <td>MOBILENET EXPERIMENTS</td>\n",
       "      <td>All our experiments were on overparameterized ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>SP:a8bb14b514e474691be63b51582544a9befa7125</td>\n",
       "      <td>D</td>\n",
       "      <td>LOCAL OPTIMAL MASKS</td>\n",
       "      <td>Definition 1 ((p, )-local optimal mask). Consi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>SP:a8bb14b514e474691be63b51582544a9befa7125</td>\n",
       "      <td>E.1</td>\n",
       "      <td>MAXIMIZING THE GRADIENT NORM USING THE GRADIEN...</td>\n",
       "      <td>In order to maximize the gradient norm after p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         paper_id head_no  \\\n",
       "1210  SP:a8bb14b514e474691be63b51582544a9befa7125       1   \n",
       "1211  SP:a8bb14b514e474691be63b51582544a9befa7125       2   \n",
       "1212  SP:a8bb14b514e474691be63b51582544a9befa7125       3   \n",
       "1213  SP:a8bb14b514e474691be63b51582544a9befa7125       4   \n",
       "1214  SP:a8bb14b514e474691be63b51582544a9befa7125       5   \n",
       "1215  SP:a8bb14b514e474691be63b51582544a9befa7125     5.1   \n",
       "1216  SP:a8bb14b514e474691be63b51582544a9befa7125     5.2   \n",
       "1217  SP:a8bb14b514e474691be63b51582544a9befa7125     5.3   \n",
       "1218  SP:a8bb14b514e474691be63b51582544a9befa7125       6   \n",
       "1219  SP:a8bb14b514e474691be63b51582544a9befa7125    None   \n",
       "1220  SP:a8bb14b514e474691be63b51582544a9befa7125       A   \n",
       "1221  SP:a8bb14b514e474691be63b51582544a9befa7125       B   \n",
       "1222  SP:a8bb14b514e474691be63b51582544a9befa7125       C   \n",
       "1223  SP:a8bb14b514e474691be63b51582544a9befa7125     C.1   \n",
       "1224  SP:a8bb14b514e474691be63b51582544a9befa7125     C.2   \n",
       "1225  SP:a8bb14b514e474691be63b51582544a9befa7125     C.3   \n",
       "1226  SP:a8bb14b514e474691be63b51582544a9befa7125     C.4   \n",
       "1227  SP:a8bb14b514e474691be63b51582544a9befa7125     C.5   \n",
       "1228  SP:a8bb14b514e474691be63b51582544a9befa7125     C.6   \n",
       "1229  SP:a8bb14b514e474691be63b51582544a9befa7125       D   \n",
       "1230  SP:a8bb14b514e474691be63b51582544a9befa7125     E.1   \n",
       "\n",
       "                                             head_title  \\\n",
       "1210                                       INTRODUCTION   \n",
       "1211                                       RELATED WORK   \n",
       "1212     PROBLEM FORMULATION: PRUNING AT INITIALIZATION   \n",
       "1213                   FORESIGHT CONNECTION SENSITIVITY   \n",
       "1214                                        EXPERIMENTS   \n",
       "1215                                RESULTS ON CIFAR-10   \n",
       "1216                         RESULTS ON LARGER DATASETS   \n",
       "1217                                           ANALYSIS   \n",
       "1218                                         DISCUSSION   \n",
       "1219                                    ACKNOWLEDGMENTS   \n",
       "1220                     PRUNING IMPLEMENTATION DETAILS   \n",
       "1221                 ADDITIONAL ACCURACY-SPARSITY PLOTS   \n",
       "1222      FURTHER ANALYSIS OF PRUNING AT INITIALIZATION   \n",
       "1223                                      SALIENCY VS T   \n",
       "1224                          PRUNING VS SPARSIFICATION   \n",
       "1225                    NETWORK STRUCTURE AFTER PRUNING   \n",
       "1226                         EVOLUTION OF PRUNING MASKS   \n",
       "1227                      COMPARISON WITH EARLY PRUNING   \n",
       "1228                              MOBILENET EXPERIMENTS   \n",
       "1229                                LOCAL OPTIMAL MASKS   \n",
       "1230  MAXIMIZING THE GRADIENT NORM USING THE GRADIEN...   \n",
       "\n",
       "                                                   text  \n",
       "1210  The majority of pruning algorithms for Deep Ne...  \n",
       "1211  Pruning trained models Most of the pruning wor...  \n",
       "1212  Given a dataset D = {(xi,yi)}ni=1, the trainin...  \n",
       "1213  Since removing connections of a neural network...  \n",
       "1214  In the following we evaluate the efficacy of o...  \n",
       "1215  Fig 2 compares the accuracy of the described i...  \n",
       "1216  We now present experiments on large datasets. ...  \n",
       "1217  Saliency optimization To experimentally valida...  \n",
       "1218  Pruning at initialization has become an active...  \n",
       "1219  This work was supported by the Royal Academy o...  \n",
       "1220  We present experiments on CIFAR-10/100 (Krizhe...  \n",
       "1221  In the main text we show the complete range of...  \n",
       "1222                                                     \n",
       "1223  In Fig 4 (left) we have seen that for higher s...  \n",
       "1224  FORCE algorithm is able to recover pruned weig...  \n",
       "1225  In Fig 8 we visualize the structure of the net...  \n",
       "1226  As discussed in the main text, FORCE allows we...  \n",
       "1227  For fair comparison, we provided the same amou...  \n",
       "1228  All our experiments were on overparameterized ...  \n",
       "1229  Definition 1 ((p, )-local optimal mask). Consi...  \n",
       "1230  In order to maximize the gradient norm after p...  "
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "No_sec_paper = list(df_section_group[df_section_group['conclude'].isna()].index)\n",
    "df_paper[df_paper['paper_id']==No_sec_paper[6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1194"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def no_section_info(section):\n",
    "    No_sec_paper = list(df_section_group[df_section_group[section].isna()].index)\n",
    "    return [list(df_paper[df_paper['paper_id']==paper]['head_title']) for paper in No_sec_paper]\n",
    "no_con = no_section_info('conclude')\n",
    "len(no_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "INTRODUCTION\n",
      "INFORMATION LATTICE: ABSTRACTIONS AND RULES OF A SIGNAL\n",
      "INFORMATION LATTICE LEARNING (ILL)\n",
      "PRACTICAL LATTICE CONSTRUCTION: TO START LIKE A BABY (PHASE I)\n",
      "PRACTICAL LATTICE LEARNING: TO LEARN LIKE A CHILD (PHASE II)\n",
      "ILL EXAMPLES\n",
      "DISCUSSION: LIMITATIONS AND CHALLENGES\n",
      "CONNECTION TO CONCEPT LATTICE\n",
      "MORE GENERALIZED FORMALISM FOR INFORMATION LATTICE\n",
      "MORE INSIGHTS ON THE SPECIAL LIFTING\n",
      "EXISTING WORK ON SUBLATTICE GENERATION\n",
      "MORE DETAILS ON THE CONSTRUCTION PHASE\n",
      "MORE ANALYSES IN THE LEARNING PHASE\n",
      "STUDIES ON ILL-BASED MUSIC APPLICATION\n",
      "CONCLUSION AND BROADER IMPACTS\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, NoneType found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[380], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, sections \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(no_con):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msections\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, NoneType found"
     ]
    }
   ],
   "source": [
    "for i, sections in enumerate(no_con):\n",
    "    print('='*50)\n",
    "    print(\"\\n\".join(sections))\n",
    "    if i>=20: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BACKGROUND',\n",
       " 'INFERENCE IN DLVMS AFFECTED BY MNAR',\n",
       " 'EXPERIMENT',\n",
       " 'CONCLUSION']"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_section_info('intro')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'intro_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# df_section_group_new = df_section_group.reset_index(drop=True)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# df_section_group_new = pd.concat([df_section_group, intro_count], axis=1, join='outer')\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df_section_group_new \u001b[38;5;241m=\u001b[39m df_section_group\u001b[38;5;241m.\u001b[39mmerge(\u001b[43mintro_count\u001b[49m, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaper_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m'\u001b[39m, suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_2\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      4\u001b[0m df_section_group_new[df_section_group_new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintro\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'intro_count' is not defined"
     ]
    }
   ],
   "source": [
    "# df_section_group_new = df_section_group.reset_index(drop=True)\n",
    "# df_section_group_new = pd.concat([df_section_group, intro_count], axis=1, join='outer')\n",
    "df_section_group_new = df_section_group.merge(intro_count, on=\"paper_id\", how='outer', suffixes=('_1', '_2'))\n",
    "df_section_group_new[df_section_group_new[\"intro\"]==None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8379 entries, SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc to SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   intro   7989 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 130.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_section_group_new.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Section identification for MuP dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reused function & lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAWDATAFILES = {\n",
    "    \"train\": \"training_complete.jsonl\",\n",
    "    \"val\": \"validation_complete.jsonl\",\n",
    "    \"test\": \"testing_with_paper_release.jsonl\"\n",
    "}\n",
    "def print_progress(curr, full, desc='', bar_size=30):    \n",
    "    bar = int((curr+1)/full*bar_size)\n",
    "    sys.stdout.write(f\"\\r{desc}[{'='*bar}{' '*(bar_size-bar)}] {curr+1}/{full}\")\n",
    "    # sys.stdout.flush()\n",
    "    if curr+1==full: print()\n",
    "def load_data(data_split):\n",
    "    main_path = str((Path().absolute()).parents[0])    \n",
    "    filepath = f\"{main_path}/dataset_MuP/{RAWDATAFILES[data_split]}\"\n",
    "    with open(filepath, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "        col_name = [\"paper_id\", \"paper\",\"summary\"]\n",
    "    dataset = []\n",
    "    data_len = len(json_list)\n",
    "    for i, json_str in enumerate(json_list[:]):\n",
    "        result = json.loads(json_str)\n",
    "        dataset.append({\n",
    "            \"paper_id\": result[\"paper_id\"],\n",
    "            \"paper\": result[\"paper\"],\n",
    "            \"summary\": result[\"summary\"],\n",
    "        })\n",
    "        print_progress(i, data_len, desc=f'Loading {data_split} data', bar_size=30)\n",
    "    return pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def section_extraction(sec):\n",
    "    text = sec['text']\n",
    "    try:\n",
    "        # sec['heading']=sec['heading'].upper()\n",
    "        sec_split = ((sec)['heading'].upper()).split()\n",
    "        if len(sec_split)==1:\n",
    "            head_no = None\n",
    "            head_title = sec_split[0]\n",
    "        else:\n",
    "            head_no = sec_split[0]\n",
    "            head_title = \" \".join(sec_split[1:])\n",
    "    except:\n",
    "        head_no = None\n",
    "        head_title = None\n",
    "    return head_no, head_title, text\n",
    "\n",
    "def get_ext_section(df):\n",
    "    full_len = len(df)\n",
    "    sections_data = [] \n",
    "    one_section_papers = []\n",
    "    for ind, row in (df).iterrows():\n",
    "        sections = ((row['paper'])['sections'])\n",
    "        if len(sections)<=1: \n",
    "            one_section_papers.append(row['paper_id'])\n",
    "            continue\n",
    "        for sec in sections:\n",
    "            head_no, head_title, text = section_extraction(sec)\n",
    "            if head_no is not None:\n",
    "                while head_no[-1] in ['.','/',',',')']:\n",
    "                    head_no = head_no[:-1]\n",
    "            sections_data.append({\n",
    "                'paper_id': row['paper_id'],\n",
    "                'head_no': head_no,\n",
    "                'head_title': head_title,\n",
    "                'text': text,\n",
    "            })   \n",
    "    return pd.DataFrame(sections_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "section_keys = {\n",
    "    \"introduction\": [\"INTRODUCTION\", \"PROBLEM\", \"MOTIVATION\", \"PRELIMINARY\", \"OVERVIEW\"],\n",
    "    \"literature\":   [\"LITERATURE\", \"RELATED WORK\", \"BACKGROUND\", \"THEORY\", \"PREVIOUS WORK\", \"PRIOR WORK\", \"REVIEW\", \"BASELINE\"],\n",
    "    \"method\":       [\"APPROACH\", \"TECHNIQUE\", \"MODEL\", \"ALGORITHM\", \"METHOD\", \"DATASET\", \"SETUP\", \"SETTING\", \"FRAMEWORK\", \"ARCHITECTURE\", \"IMPLEMENTATION\", \"CONTRIBUTION\"],\n",
    "    \"result\":       [\"EXPERIMENT\", \"RESULT\", \"EVALUATION\", \"ABLATION STUDY\"],\n",
    "    \"discussion\":   [\"DISCUSSION\", \"LIMITATION\", \"ANALYS\"],\n",
    "    \"conclusion\":   [\"CONCLU\", \"FUTURE WORK\", \"APPLICATION\", \"SUMMARY\", \"IMPACT\"],\n",
    "    \"addition\":     [\"NOTATION\", \"APPENDIX\", \"ACKNOWLEDGMENT\", \"ACKNOWLEDGEMENT\", \"EXTENSION\", \"REMARK\", \"MATERIAL\", \"ENVIRONMENT\"],\n",
    "}\n",
    "def pattern(keys):\n",
    "    pattern_str = r''\n",
    "    for key in keys:\n",
    "        pattern_str += key + \"*|\"\n",
    "    return pattern_str[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## New functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def section_processes(df_section):\n",
    "    # Remove Null 'head_title'\n",
    "    df_section = df_section[df_section['head_title'].notna()]\n",
    "    # Convert plural to singular noun\n",
    "    p = inflect.engine()\n",
    "    prepro_list = [p.singular_noun(word) if p.singular_noun(word)!=False else word for word in df_section['head_title']]\n",
    "    # df_section['head_title'] = prepro_list\n",
    "    df_section = df_section.drop(['head_title'], axis=1)\n",
    "    df_section = df_section.assign(head_title = prepro_list)    \n",
    "    return df_section\n",
    "\n",
    "def filter_sec(df_section, keys):\n",
    "    mask = df_section['head_title'].str.contains(pattern(keys))    \n",
    "    df_filter = df_section[mask]\n",
    "    df_filter = df_filter[df_filter['text']!=''].reset_index(drop=True)\n",
    "    paperId_filter = list(set(df_filter['paper_id']))\n",
    "    idx_filter = []\n",
    "    i = 0\n",
    "    for paper_id in paperId_filter:\n",
    "        paper_df = df_filter[df_filter['paper_id']==paper_id]\n",
    "        idx_filter.append(paper_df.index[0])\n",
    "    return df_filter.iloc[idx_filter]\n",
    "\n",
    "def export_data(data, output_dir, filename):\n",
    "    print(f\"Writing data to {output_dir+filename} file\")\n",
    "    if not(Path(output_dir).exists()): os.mkdir(output_dir)\n",
    "    with open(output_dir+filename, 'w', encoding='utf-8') as f:\n",
    "        for line in data:\n",
    "            json_record = json.dumps(line, ensure_ascii=False)\n",
    "            f.write(json_record + '\\n')\n",
    "    print(f'Wrote {len(data)} records to {output_dir}{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def all_processes(data_split, sec_catagory=[\"introduction\", 'conclusion'], export=False):\n",
    "    df_main = load_data(data_split)\n",
    "    df_paper = df_main.drop(['summary'], axis=1).drop_duplicates(subset=['paper_id'])\n",
    "    \n",
    "    print(\"Extracting section\")\n",
    "    df_section = get_ext_section(df_paper)\n",
    "    print(\"Processing with extracted sections\")\n",
    "    df_section = section_processes(df_section)\n",
    "    \n",
    "    # Extract text from desired catagory\n",
    "    df_cat_all = 0\n",
    "    for catagory in sec_catagory:\n",
    "        print(f\"Extracting \\\"{catagory}\\\" catagory\")\n",
    "        df_cat = filter_sec(df_section, keys=section_keys[catagory])\n",
    "        df_cat.rename(columns = {\n",
    "            'text': f'{catagory}',\n",
    "        }, inplace = True)\n",
    "        df_cat.drop(['head_no', 'head_title'], axis=1, inplace = True)\n",
    "        if isinstance(df_cat_all, int):\n",
    "            df_cat_all = df_cat.copy()\n",
    "        else:\n",
    "            df_cat_all = df_cat_all.merge(df_cat, on=\"paper_id\", how='outer')\n",
    "\n",
    "    \n",
    "    \n",
    "    abstract = []\n",
    "    for idx,row in df_paper.iterrows():\n",
    "        abstract.append({\n",
    "            'paper_id': row['paper_id'],\n",
    "            'abstract': row['paper']['abstractText'],\n",
    "        })\n",
    "        # print(row['paper']['abstractText'])\n",
    "    df_abs = pd.DataFrame(abstract)\n",
    "    df_final = df_abs.merge(df_cat_all, on=\"paper_id\", how='outer')\n",
    "    \n",
    "    # print(f\">>>Remove {len(df_paper)-len(df_final)}/{len(df_paper)} incorrect papers\")\n",
    "    null_allCat = True\n",
    "    for catagory in sec_catagory:\n",
    "        null_cat = df_final[catagory].isna()\n",
    "        null_allCat = null_allCat*null_cat\n",
    "        print(f\">>>There are {null_cat.sum()}/{len(df_final)} null value in {catagory} catagory\")\n",
    "    print(f\">>>There are {null_allCat.sum()}/{len(df_final)} null value in all catagories\")\n",
    "        \n",
    "        \n",
    "    if export:\n",
    "        dict_list = df_final.to_dict('records')\n",
    "        main_path = str((Path().absolute()).parents[0])\n",
    "        export_dir = f\"{main_path}/dataset_MuP/\"\n",
    "        export_data(\n",
    "            data=dict_list, \n",
    "            output_dir=export_dir, \n",
    "            filename=f'{data_split}_iden.jsonl',\n",
    "        )\n",
    "    \n",
    "\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** Processing with train data ******************************\n",
      "Loading train data[==============================] 18934/18934\n",
      "Extracting section\n",
      "Processing with extracted sections\n",
      "Extracting \"introduction\" catagory\n",
      "Extracting \"conclusion\" catagory\n",
      ">>>There are 341/8379 null value in introduction catagory\n",
      ">>>There are 1271/8379 null value in conclusion catagory\n",
      ">>>There are 219/8379 null value in all catagories\n",
      "Writing data to /home/nopphawann/My_Thesis_Playground/dataset_MuP/train_iden.jsonl file\n",
      "Wrote 8379 records to /home/nopphawann/My_Thesis_Playground/dataset_MuP/train_iden.jsonl\n",
      "****************************** Processing with val data ******************************\n",
      "Loading val data[==============================] 3604/3604\n",
      "Extracting section\n",
      "Processing with extracted sections\n",
      "Extracting \"introduction\" catagory\n",
      "Extracting \"conclusion\" catagory\n",
      ">>>There are 40/1060 null value in introduction catagory\n",
      ">>>There are 163/1060 null value in conclusion catagory\n",
      ">>>There are 21/1060 null value in all catagories\n",
      "Writing data to /home/nopphawann/My_Thesis_Playground/dataset_MuP/val_iden.jsonl file\n",
      "Wrote 1060 records to /home/nopphawann/My_Thesis_Playground/dataset_MuP/val_iden.jsonl\n",
      "****************************** Processing with test data ******************************\n",
      "Loading test data[==============================] 4611/4611\n",
      "Extracting section\n",
      "Processing with extracted sections\n",
      "Extracting \"introduction\" catagory\n",
      "Extracting \"conclusion\" catagory\n",
      ">>>There are 20/1052 null value in introduction catagory\n",
      ">>>There are 135/1052 null value in conclusion catagory\n",
      ">>>There are 8/1052 null value in all catagories\n",
      "Writing data to /home/nopphawann/My_Thesis_Playground/dataset_MuP/test_iden.jsonl file\n",
      "Wrote 1052 records to /home/nopphawann/My_Thesis_Playground/dataset_MuP/test_iden.jsonl\n"
     ]
    }
   ],
   "source": [
    "for data_split in RAWDATAFILES.keys():\n",
    "    print(f\"{'*'*30} Processing with {data_split} data {'*'*30}\")\n",
    "    df_cat_all = all_processes(\n",
    "        data_split, \n",
    "        export=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract', 'introduction']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section = \"abstract+introduction\"\n",
    "section = section.split(\"+\")\n",
    "section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paper_id': 'SP:b19df5243359791fbaad005d6f13d7e9fdb0ff63',\n",
       " 'abstract': 'Role-based learning holds the promise of achieving scalable multi-agent learning by decomposing complex tasks using roles. However, it is largely unclear how to efficiently discover such a set of roles. To solve this problem, we propose to first decompose joint action spaces into restricted role action spaces by clustering actions according to their effects on the environment and other agents. Learning a role selector based on action effects makes role discovery much easier because it forms a bi-level learning hierarchy: the role selector searches in a smaller role space and at a lower temporal resolution, while role policies learn in significantly reduced primitive action-observation spaces. We further integrate information about action effects into the role policies to boost learning efficiency and policy generalization. By virtue of these advances, our method (1) outperforms the current state-of-the-art MARL algorithms on 9 of the 14 scenarios that comprise the challenging StarCraft II micromanagement benchmark and (2) achieves rapid transfer to new environments with three times the number of agents. Demonstrative videos can be viewed at https:// sites.google.com/view/rode-marl.',\n",
       " 'introduction': 'Cooperative multi-agent problems are ubiquitous in real-world applications, such as crewless aerial vehicles (Pham et al., 2018; Xu et al., 2018) and sensor networks (Zhang & Lesser, 2013). However, learning control policies for such systems remains a major challenge. Joint action learning (Claus & Boutilier, 1998) learns centralized policies conditioned on the full state, but this global information is often unavailable during execution due to partial observability or communication constraints. Independent learning (Tan, 1993) avoids this problem by learning decentralized policies but suffers from non-stationarity during learning as it treats other learning agents as part of the environment.\\nThe framework of centralized training with decentralized execution (CTDE) (Foerster et al., 2016; Gupta et al., 2017; Rashid et al., 2018) combines the advantages of these two paradigms. Decentralized policies are learned in a centralized manner so that they can share information, parameters, etc., without restriction during training. Although CTDE algorithms can solve many multi-agent problems (Mahajan et al., 2019; Das et al., 2019; Wang et al., 2020d), during training they must search in the joint action-observation space, which grows exponentially with the number of agents. This makes it difficult to learn efficiently when the number of agents is large (Samvelyan et al., 2019).\\nHumans cooperate in a more effective way. When dealing with complex tasks, instead of directly conducting a collective search in the full action-observation space, they typically decompose the task and let sub-groups of individuals learn to solve different sub-tasks (Smith, 1937; Butler, 2012). Once the task is decomposed, the complexity of cooperative learning can be effectively reduced\\n∗Equal advising\\nbecause individuals can focus on restricted sub-problems, each of which often involves a smaller action-observation space. Such potential scalability motivates the use of roles in multi-agent tasks, in which each role is associated with a certain sub-task and a corresponding policy.\\nThe key question in realizing such scalable learning is how to come up with a set of roles to effectively decompose the task. Previous work typically predefines the task decomposition and roles (Pavón & Gómez-Sanz, 2003; Cossentino et al., 2005; Spanoudakis & Moraitis, 2010; Bonjean et al., 2014). However, this requires prior knowledge that might not be available in practice and may prevent the learning methods from transferring to different environments.\\nTherefore, to be practical, it is crucial for role-based methods to automatically learn an appropriate set of roles. However, learning roles from scratch might not be easier than learning without roles, as directly finding an optimal decomposition suffers from the same problem as other CTDE learning methods – searching in the large joint space with substantial exploration (Wang et al., 2020c).\\nTo solve this problem, we propose a novel framework for learning ROles to DEcompose (RODE) multi-agent tasks. Our key insight is that, instead of learning roles from scratch, role discovery is easier if we first decompose joint action spaces according to action functionality. Intuitively, when cooperating with other agents, only a subset of actions that can fulfill a certain functionality is needed under certain observations. For example, in football games, the player who does not possess the ball only needs to explore how to move or sprint when attacking. In practice, we propose to first learn effect-based action representations and cluster actions into role action spaces according to their effects on the environment and other agents. Then, with knowledge of effects of available actions, we train a role selector that determines corresponding role observation spaces.\\nThis design forms a bi-level learning framework. At the top level, a role selector coordinates role assignments in a smaller role space and at a lower temporal resolution. At the low level, role policies explore strategies in reduced primitive action-observation spaces. In this way, the learning complexity is significantly reduced by decomposing a multi-agent cooperation problem, both temporally and spatially, into several short-horizon learning problems with fewer agents. To further improve learning efficiency on the sub-problems, we condition role policies on the learned effect-based action representations, which improves generalizability of role policies across actions.\\nWe test RODE on StarCraft II micromanagement environments (Samvelyan et al., 2019). Results on this benchmark show that RODE establishes a new state of the art. Particularly, RODE has the best performance on 9 out of all 14 maps, including all 5 super hard maps and most hard maps. Visualizations of learned action representations, factored action spaces, and dynamics of role selections shed further light on the superior performance of RODE. We also demonstrate that conditioning the role selector and role policies on action representations enables learned RODE policies to be transferred to tasks with different numbers of actions and agents, including tasks with three times as many agents.',\n",
       " 'conclusion': 'Coming up with a set of roles that can effectively decompose the task is a long standing problem preventing role-based learning from realizing scalability. Instead of learning roles from scratch, in this paper, we find that role discovery becomes much easier if we first decompose joint action spaces according to action effects. With a specially designed hierarchical learning framework, we achieve efficient learning over these factored action spaces. We believe that the scalability and transferability provided by our method are crucial in building flexible and general-purpose multi-agent systems.'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_list = df_cat_all.to_dict('records')\n",
    "dict_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 NONE\n",
      "nan\n",
      "20 NONE\n",
      "nan\n",
      "44 NONE\n",
      "nan\n",
      "57 NONE\n",
      "nan\n",
      "61 NONE\n",
      "nan\n",
      "65 NONE\n",
      "nan\n",
      "68 NONE\n",
      "nan\n",
      "73 NONE\n",
      "nan\n",
      "76 NONE\n",
      "nan\n",
      "94 NONE\n",
      "nan\n",
      "100 NONE\n",
      "nan\n",
      "124 NONE\n",
      "nan\n",
      "141 NONE\n",
      "nan\n",
      "151 NONE\n",
      "nan\n",
      "159 NONE\n",
      "nan\n",
      "175 NONE\n",
      "nan\n",
      "176 NONE\n",
      "nan\n",
      "183 NONE\n",
      "nan\n",
      "188 NONE\n",
      "nan\n",
      "191 NONE\n",
      "nan\n",
      "193 NONE\n",
      "nan\n",
      "201 NONE\n",
      "nan\n",
      "202 NONE\n",
      "nan\n",
      "219 NONE\n",
      "nan\n",
      "223 NONE\n",
      "nan\n",
      "224 NONE\n",
      "nan\n",
      "236 NONE\n",
      "nan\n",
      "238 NONE\n",
      "nan\n",
      "249 NONE\n",
      "nan\n",
      "256 NONE\n",
      "nan\n",
      "264 NONE\n",
      "nan\n",
      "269 NONE\n",
      "nan\n",
      "278 NONE\n",
      "nan\n",
      "291 NONE\n",
      "nan\n",
      "296 NONE\n",
      "nan\n",
      "312 NONE\n",
      "nan\n",
      "321 NONE\n",
      "nan\n",
      "322 NONE\n",
      "nan\n",
      "324 NONE\n",
      "nan\n",
      "328 NONE\n",
      "nan\n",
      "332 NONE\n",
      "nan\n",
      "336 NONE\n",
      "nan\n",
      "337 NONE\n",
      "nan\n",
      "345 NONE\n",
      "nan\n",
      "373 NONE\n",
      "nan\n",
      "378 NONE\n",
      "nan\n",
      "390 NONE\n",
      "nan\n",
      "397 NONE\n",
      "nan\n",
      "403 NONE\n",
      "nan\n",
      "405 NONE\n",
      "nan\n",
      "431 NONE\n",
      "nan\n",
      "436 NONE\n",
      "nan\n",
      "441 NONE\n",
      "nan\n",
      "448 NONE\n",
      "nan\n",
      "450 NONE\n",
      "nan\n",
      "458 NONE\n",
      "nan\n",
      "471 NONE\n",
      "nan\n",
      "476 NONE\n",
      "nan\n",
      "481 NONE\n",
      "nan\n",
      "487 NONE\n",
      "nan\n",
      "496 NONE\n",
      "nan\n",
      "497 NONE\n",
      "nan\n",
      "535 NONE\n",
      "nan\n",
      "542 NONE\n",
      "nan\n",
      "554 NONE\n",
      "nan\n",
      "560 NONE\n",
      "nan\n",
      "567 NONE\n",
      "nan\n",
      "573 NONE\n",
      "nan\n",
      "576 NONE\n",
      "nan\n",
      "585 NONE\n",
      "nan\n",
      "600 NONE\n",
      "nan\n",
      "608 NONE\n",
      "nan\n",
      "614 NONE\n",
      "nan\n",
      "629 NONE\n",
      "nan\n",
      "640 NONE\n",
      "nan\n",
      "642 NONE\n",
      "nan\n",
      "658 NONE\n",
      "nan\n",
      "659 NONE\n",
      "nan\n",
      "666 NONE\n",
      "nan\n",
      "673 NONE\n",
      "nan\n",
      "685 NONE\n",
      "nan\n",
      "691 NONE\n",
      "nan\n",
      "693 NONE\n",
      "nan\n",
      "697 NONE\n",
      "nan\n",
      "710 NONE\n",
      "nan\n",
      "714 NONE\n",
      "nan\n",
      "730 NONE\n",
      "nan\n",
      "745 NONE\n",
      "nan\n",
      "755 NONE\n",
      "nan\n",
      "757 NONE\n",
      "nan\n",
      "762 NONE\n",
      "nan\n",
      "766 NONE\n",
      "nan\n",
      "768 NONE\n",
      "nan\n",
      "782 NONE\n",
      "nan\n",
      "783 NONE\n",
      "nan\n",
      "785 NONE\n",
      "nan\n",
      "787 NONE\n",
      "nan\n",
      "789 NONE\n",
      "nan\n",
      "806 NONE\n",
      "nan\n",
      "809 NONE\n",
      "nan\n",
      "810 NONE\n",
      "nan\n",
      "812 NONE\n",
      "nan\n",
      "819 NONE\n",
      "nan\n",
      "825 NONE\n",
      "nan\n",
      "834 NONE\n",
      "nan\n",
      "836 NONE\n",
      "nan\n",
      "837 NONE\n",
      "nan\n",
      "839 NONE\n",
      "nan\n",
      "843 NONE\n",
      "nan\n",
      "845 NONE\n",
      "nan\n",
      "847 NONE\n",
      "nan\n",
      "855 NONE\n",
      "nan\n",
      "875 NONE\n",
      "nan\n",
      "880 NONE\n",
      "nan\n",
      "881 NONE\n",
      "nan\n",
      "898 NONE\n",
      "nan\n",
      "899 NONE\n",
      "nan\n",
      "907 NONE\n",
      "nan\n",
      "914 NONE\n",
      "nan\n",
      "916 NONE\n",
      "nan\n",
      "917 NONE\n",
      "nan\n",
      "926 NONE\n",
      "nan\n",
      "940 NONE\n",
      "nan\n",
      "955 NONE\n",
      "nan\n",
      "965 NONE\n",
      "nan\n",
      "970 NONE\n",
      "nan\n",
      "983 NONE\n",
      "nan\n",
      "993 NONE\n",
      "nan\n",
      "1011 NONE\n",
      "nan\n",
      "1019 NONE\n",
      "nan\n",
      "1022 NONE\n",
      "nan\n",
      "1023 NONE\n",
      "nan\n",
      "1025 NONE\n",
      "nan\n",
      "1044 NONE\n",
      "nan\n",
      "1049 NONE\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "main_path = str((Path().absolute()).parents[0])\n",
    "filepath = f\"{main_path}/dataset_MuP/{data_split}_iden.jsonl\"\n",
    "with open(filepath, 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "dataset_list = []\n",
    "\n",
    "for i, json_str in enumerate(json_list):\n",
    "    data = json.loads(json_str)\n",
    "    # print(data[\"conclusion\"])\n",
    "    if not isinstance(data[\"conclusion\"], str): \n",
    "        print(i, \"NONE\")\n",
    "        print(data[\"conclusion\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#comment this if you are not using puffer?\n",
    "os.environ['http_proxy'] = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
    "\n",
    "from transformers import BartTokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_paragraph(text):\n",
    "    return len(text.split(\"\\n\"))\n",
    "def count_tokens(text):\n",
    "    tokens = tokenizer.encode(text, return_tensors='pt')\n",
    "    return tokens.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"We study the average CVloo stability of kernel ridge-less regression and derive corresponding risk bounds. We show that the interpolating solution with minimum norm minimizes a bound on CVloo stability, which in turn is controlled by the condition number of the empirical kernel matrix. The latter can be characterized in the asymptotic regime where both the dimension and cardinality of the data go to infinity. Under the assumption of random kernel matrices, the corresponding test error should be expected to follow a double descent curve.\"\n",
    "print(len(text.split(\" \")))\n",
    "count_tokens(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>introduction</th>\n",
       "      <th>conclusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>We study the average CVloo stability of kernel...</td>\n",
       "      <td>Statistical learning theory studies the learni...</td>\n",
       "      <td>In summary, minimizing a bound on cross valida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:b80bc890180934092cde037b49d94d6e4e06fad9</td>\n",
       "      <td>The use of episodic memories in continual lear...</td>\n",
       "      <td>In the real world, we are often faced with sit...</td>\n",
       "      <td>The two fundamental problems of continual lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939</td>\n",
       "      <td>Existing Multi-Task Learning(MTL) strategies l...</td>\n",
       "      <td>The process of Multi-Task Learning (MTL) on a ...</td>\n",
       "      <td>This work proposes a task-aware framework whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP:a1e2218e6943bf138aeb359e23628676b396ed66</td>\n",
       "      <td>This paper deals with the fuel optimization pr...</td>\n",
       "      <td>Hybrid electric vehicles powered by fuel cells...</td>\n",
       "      <td>In this paper, we have proposed a robust concu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66</td>\n",
       "      <td>Our work is concerned with the generation and ...</td>\n",
       "      <td>There is an increasing interest in developing ...</td>\n",
       "      <td>In this work we propose the first graph-based ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8155</th>\n",
       "      <td>SP:77d59e1e726172184249bdfdd81011617dc9c208</td>\n",
       "      <td>Quantum machine learning methods have the pote...</td>\n",
       "      <td>Data sets used for training machine learning m...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8156</th>\n",
       "      <td>SP:e58dc2d21175a62499405b7f4c3a03b135530838</td>\n",
       "      <td>Trained generative models have shown remarkabl...</td>\n",
       "      <td>Generative deep neural networks have shown rem...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8157</th>\n",
       "      <td>SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695</td>\n",
       "      <td>Discovering the underlying mathematical expres...</td>\n",
       "      <td>Understanding the mathematical relationships a...</td>\n",
       "      <td>We introduce an unconventional approach to sym...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8158</th>\n",
       "      <td>SP:4706017e6f8b958c7d0825fed98b285ea2994b59</td>\n",
       "      <td>Some conventional transforms such as Discrete ...</td>\n",
       "      <td>Large Convolutional Neural Networks (CNNs) (Kr...</td>\n",
       "      <td>We propose the new PC layers through conventio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8159</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>Thanks to graph neural networks (GNNs), semi-s...</td>\n",
       "      <td>Inherent uncertainties introduced by different...</td>\n",
       "      <td>In this work, we proposed a Subjective Bayesia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8160 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         paper_id  \\\n",
       "0     SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc   \n",
       "1     SP:b80bc890180934092cde037b49d94d6e4e06fad9   \n",
       "2     SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939   \n",
       "3     SP:a1e2218e6943bf138aeb359e23628676b396ed66   \n",
       "4     SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66   \n",
       "...                                           ...   \n",
       "8155  SP:77d59e1e726172184249bdfdd81011617dc9c208   \n",
       "8156  SP:e58dc2d21175a62499405b7f4c3a03b135530838   \n",
       "8157  SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695   \n",
       "8158  SP:4706017e6f8b958c7d0825fed98b285ea2994b59   \n",
       "8159  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb   \n",
       "\n",
       "                                               abstract  \\\n",
       "0     We study the average CVloo stability of kernel...   \n",
       "1     The use of episodic memories in continual lear...   \n",
       "2     Existing Multi-Task Learning(MTL) strategies l...   \n",
       "3     This paper deals with the fuel optimization pr...   \n",
       "4     Our work is concerned with the generation and ...   \n",
       "...                                                 ...   \n",
       "8155  Quantum machine learning methods have the pote...   \n",
       "8156  Trained generative models have shown remarkabl...   \n",
       "8157  Discovering the underlying mathematical expres...   \n",
       "8158  Some conventional transforms such as Discrete ...   \n",
       "8159  Thanks to graph neural networks (GNNs), semi-s...   \n",
       "\n",
       "                                           introduction  \\\n",
       "0     Statistical learning theory studies the learni...   \n",
       "1     In the real world, we are often faced with sit...   \n",
       "2     The process of Multi-Task Learning (MTL) on a ...   \n",
       "3     Hybrid electric vehicles powered by fuel cells...   \n",
       "4     There is an increasing interest in developing ...   \n",
       "...                                                 ...   \n",
       "8155  Data sets used for training machine learning m...   \n",
       "8156  Generative deep neural networks have shown rem...   \n",
       "8157  Understanding the mathematical relationships a...   \n",
       "8158  Large Convolutional Neural Networks (CNNs) (Kr...   \n",
       "8159  Inherent uncertainties introduced by different...   \n",
       "\n",
       "                                             conclusion  \n",
       "0     In summary, minimizing a bound on cross valida...  \n",
       "1     The two fundamental problems of continual lear...  \n",
       "2     This work proposes a task-aware framework whic...  \n",
       "3     In this paper, we have proposed a robust concu...  \n",
       "4     In this work we propose the first graph-based ...  \n",
       "...                                                 ...  \n",
       "8155                                                NaN  \n",
       "8156                                                NaN  \n",
       "8157  We introduce an unconventional approach to sym...  \n",
       "8158  We propose the new PC layers through conventio...  \n",
       "8159  In this work, we proposed a Subjective Bayesia...  \n",
       "\n",
       "[8160 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Primates perform well at generalization tasks. If presented with a single visual instance of an object, they often immediately can generalize and envision the object in different attributes, e.g., in different 3D pose (Logothetis et al., 1995). Primates can readily do so, as their previous knowledge allows them to be cognizant of attributes. Machines, by contrast, are most-commonly trained on sample features (e.g., pixels), not taking into consideration attributes that gave rise to those features.',\n",
       " 'To aid machine cognition of visual object attributes, a class of algorithms focuses on learning disentangled representations (Kingma & Welling, 2014; Higgins et al., 2017; Burgess et al., 2018; Kim & Mnih, 2018; Chen et al., 2018), which map visual samples onto a latent space that separates the information belonging to different attributes. These methods show disentanglement by interpolating between attribute values (e.g., interpolate pose, etc). However, these methods usually process one sample at a time, rather than contrasting or reasoning about a group of samples. We posit that semantic links across samples could lead to better learning.',\n",
       " 'We are motivated by the visual generalization of primates. We seek a method that can synthesize realistic images for arbitrary queries (e.g., a particular car, in a given pose, on a given background), which we refer to as controlled synthesis. We design a method that enforces semantic consistency of attributes, facilitating controlled synthesis by leveraging semantic links between samples. Our method maps samples onto a disentangled latent representation space that (i) consists of subspaces, each encoding one attribute (e.g., identity, pose, ...), and, (ii) is such that two visual samples that share an attribute value (e.g., both have identity “car”) have identical latent values in the shared attribute subspace (identity), even if other attribute values (e.g., pose) differ. To achieve this, we propose a general learning framework: Group Supervised Learning (GSL, Sec. 3), which provides a learner (e.g., neural network) with groups of semantically-related training examples, represented as multigraph. Given a query of attributes, GSL proposes groups of training examples with attribute combinations that are useful for synthesizing a test example satisfying the query (Fig. 1). This endows the network with an envisioning capability. In addition to applications in graphics, controlled synthesis can also augment training sets for better generalization on machine learning tasks (Sec. 6.3).',\n",
       " 'As an instantiation of GSL, we propose an encoder-decoder network for zero-shot synthesis: GroupSupervised Zero-Shot Synthesis Network (GZS-Net, Sec. 4). While learning (Sec. 4.2 & 4.3), we repeatedly draw a group of semantically-related examples, as informed by a multigraph created by GSL. GZS-Net encodes group examples, to obtain latent vectors, then swaps entries for one or more attributes in the latent space across examples, through multigraph edges, then decodes into an example within the group (Sec. 4.2).',\n",
       " 'Our contributions are: (i) We propose Group-Supervised Learning (GSL), explain how it casts its admissible datasets into a multigraph, and show how it can be used to express learning from semantically-related groups and to synthesize samples with controllable attributes; (ii) We show one instantiation of GSL: Group-supervised Zero-shot Synthesis Network (GZS-Net), trained on groups of examples and reconstruction objectives; (iii) We demonstrate that GZS-Net trained with GSL outperforms state-of-the-art alternatives for controllable image synthesis on existing datasets; (iv) We provide a new dataset, Fonts1, with its generating code. It contains 1.56 million images and their attributes. Its simplicity allows rapid idea prototyping for learning disentangled representations.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph = df_cat_all['introduction'].iloc[8].split(\"\\n\")\n",
    "print(len(paragraph))\n",
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8160 entries, 0 to 8159\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   paper_id           8160 non-null   object\n",
      " 1   introduction_text  8038 non-null   object\n",
      " 2   conclusion_text    7108 non-null   object\n",
      " 3   abstract           8160 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 318.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_cat_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat_all['intro_text'].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1052"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat_all['conclude_text'].isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section-based perspective extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>head_no</th>\n",
       "      <th>head_title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>Statistical learning theory studies the learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>2</td>\n",
       "      <td>STATISTICAL LEARNING AND EMPIRICAL RISK MINIMI...</td>\n",
       "      <td>We begin by recalling the basic ideas in stati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>2.1</td>\n",
       "      <td>KERNEL LEAST SQUARES AND MINIMUM NORM SOLUTION</td>\n",
       "      <td>The focus in this paper is on the kernel least...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>3</td>\n",
       "      <td>ERROR BOUNDS VIA STABILITY</td>\n",
       "      <td>In this section, we recall basic results relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>4.1</td>\n",
       "      <td>KEY LEMMA</td>\n",
       "      <td>In order to prove Theorem 7 we make use of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>4.2</td>\n",
       "      <td>PROOF OF LEMMA 11</td>\n",
       "      <td>We can write any interpolating solution to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>5</td>\n",
       "      <td>REMARK AND RELATED WORK</td>\n",
       "      <td>In the previous section we obtained bounds on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>6</td>\n",
       "      <td>CONCLUSION</td>\n",
       "      <td>In summary, minimizing a bound on cross valida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>A</td>\n",
       "      <td>EXCESS RISK, GENERALIZATION, AND STABILITY</td>\n",
       "      <td>We use the same notation as introduced in Sect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SP:b80bc890180934092cde037b49d94d6e4e06fad9</td>\n",
       "      <td>1</td>\n",
       "      <td>INTRODUCTION</td>\n",
       "      <td>In the real world, we are often faced with sit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      paper_id head_no  \\\n",
       "0  SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       1   \n",
       "1  SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       2   \n",
       "2  SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc     2.1   \n",
       "3  SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       3   \n",
       "4  SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc     4.1   \n",
       "5  SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc     4.2   \n",
       "6  SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       5   \n",
       "7  SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       6   \n",
       "8  SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc       A   \n",
       "9  SP:b80bc890180934092cde037b49d94d6e4e06fad9       1   \n",
       "\n",
       "                                          head_title  \\\n",
       "0                                       INTRODUCTION   \n",
       "1  STATISTICAL LEARNING AND EMPIRICAL RISK MINIMI...   \n",
       "2     KERNEL LEAST SQUARES AND MINIMUM NORM SOLUTION   \n",
       "3                         ERROR BOUNDS VIA STABILITY   \n",
       "4                                          KEY LEMMA   \n",
       "5                                  PROOF OF LEMMA 11   \n",
       "6                            REMARK AND RELATED WORK   \n",
       "7                                         CONCLUSION   \n",
       "8         EXCESS RISK, GENERALIZATION, AND STABILITY   \n",
       "9                                       INTRODUCTION   \n",
       "\n",
       "                                                text  \n",
       "0  Statistical learning theory studies the learni...  \n",
       "1  We begin by recalling the basic ideas in stati...  \n",
       "2  The focus in this paper is on the kernel least...  \n",
       "3  In this section, we recall basic results relat...  \n",
       "4  In order to prove Theorem 7 we make use of the...  \n",
       "5  We can write any interpolating solution to the...  \n",
       "6  In the previous section we obtained bounds on ...  \n",
       "7  In summary, minimizing a bound on cross valida...  \n",
       "8  We use the same notation as introduced in Sect...  \n",
       "9  In the real world, we are often faced with sit...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = inflect.engine()\n",
    "df_paper.dropna(inplace=True)\n",
    "prepro_list = [p.singular_noun(word) if p.singular_noun(word)!=False else word for word in df_paper['head_title']]\n",
    "df_paper['head_title'] = prepro_list\n",
    "df_paper[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective_keys = {\n",
    "    \"introduction\":  [\"INTRODUCTION\"],\n",
    "    \"research_gap\":  [\"LITERATURE\", \"RELATED WORK\", \"BACKGROUND\", \"PREVIOUS WORK\", \"PRIOR WORK\", \"REVIEW\", \"BASELINE\"],\n",
    "    \"model\":         [\"APPROACH\", \"TECHNIQUE\", \"MODEL\", \"ALGORITHM\", \"METHOD\", \"FRAMEWORK\", \"ARCHITECTURE\"],\n",
    "    \"experiment\":    [\"EXPERIMENT\", \"SETUP\", \"SETTING\", \"IMPLEMENTATION\", \"CONTRIBUTION\"],\n",
    "    \"result_discuss\":[\"RESULT\", \"EVALUATION\", \"ABLATION STUDY\", \"DISCUSSION\", \"LIMITATION\", \"ANALYS\"],\n",
    "    \"conclusion\":    [\"CONCLU\", \"FUTURE WORK\", \"APPLICATION\", \"SUMMARY\", \"IMPACT\"],\n",
    "    \"addition\":      [\"NOTATION\", \"APPENDIX\", \"ACKNOWLEDGMENT\", \"ACKNOWLEDGEMENT\", \"EXTENSION\", \"REMARK\", \"MATERIAL\", \"ENVIRONMENT\"],\n",
    "}\n",
    "def pattern(keys):\n",
    "    pattern_str = r''\n",
    "    for key in keys:\n",
    "        pattern_str += key + \"*|\"\n",
    "    return pattern_str[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped unclear sections: 5405/144299 (Remain 138894)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_paper_copy = df_paper.copy()\n",
    "for sec, keys in perspective_keys.items():\n",
    "    mask = (df_paper_copy['head_title'].str.contains(pattern(keys)))\n",
    "    df_paper_copy[sec] = mask.astype(int)\n",
    "sec_list = list(perspective_keys.keys())\n",
    "df_paper_copy['sum_sec'] = df_paper_copy[sec_list].sum(axis=1)\n",
    "drop_rows = (df_paper_copy[df_paper_copy['sum_sec']>1].index)\n",
    "# df_paper_copy = df_paper.copy()\n",
    "df_paper_copy.drop(drop_rows, inplace=True)\n",
    "print(f\"Dropped unclear sections: {len(drop_rows)}/{len(df_paper)} (Remain {len(df_paper_copy)})\")\n",
    "# for sec in sec_list:\n",
    "#     df_ = (df_paper_copy[df_paper_copy[sec]==1])\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paragraph splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_paragraph(text):\n",
    "    # pattern = r'(?<!:)\\n(?!•|\\s*[-*])'\n",
    "    pattern = r'(?:\\.|\\?)\\n(?!•|\\s*[-*]|[0-9]\\..+|[0-9].+|[a-z]\\..+|[a-z].+)'\n",
    "    split_text = re.split(pattern, text)\n",
    "    return [paragraph+'.' for paragraph in split_text[:-1]]+[split_text[-1]]\n",
    "\n",
    "def count_paragraph(text):\n",
    "    return len(split_paragraph(text))\n",
    "\n",
    "math_symbols = {'×', '÷', '√', '∛', 'ⁿ√', '⁄', '∝', '≥', '≤', '≠', '≈', '∧', '∨', '¬', '∩', '∪', '⊂', '⊃', '∅', '∫', '∞', '°', '⊥'}\n",
    "special_symbols = {'⏒', '⋥', '⋈', '∇', '⋒', '∋', '∌', '∟', '〈', '∦', '⋭', '⊘', '⋦', '∑', '⋠', '⋛', '∠', '⊙', '⏕', '⊛', '〉', '⋯', '⋏', '⋪', '⋬', '⋔', '∵', '⊉', '⋧', '⋓', '⋢', '⊈', '⋊', '⏚', '⊇', '⋟', '⊆', '⋉', '∀', '⊞', '⎱', '∈', '⋣', '⎰', '∥', '⊗', '⋩', '⏘', '⏙', '⏗', '⋨', '⊄', '∉', '⌋', '⋌', '⋆', '∃', '∴', '⊜', '∆', '⋱', '⋋', '∄', '⍟', '⌈', '⌉', '⋫', '⋚', '⏛', '⊖', '⏔', '⊡', '⋇', '⋙', '⍼', '⌊', '⊅', '⋘', '⌶', '≡', '⊟', '⋰', '⊕', '⏖', '⋮', '⊠', '⏑', '⊚', '⋤', '⋄', '⏓', '⋗', '⊝', '⋖'}\n",
    "lowercase_greek_symbols = {'α', 'β', 'γ', 'δ', 'ε', 'ζ', 'η', 'θ', 'ι', 'κ', 'λ', 'μ', 'ν', 'ξ', 'ο', 'π', 'ρ', 'σ', 'τ', 'υ', 'φ', 'χ', 'ψ', 'ω'}\n",
    "uppercase_greek_symbols = {'Α', 'Β', 'Γ', 'Δ', 'Ε', 'Ζ', 'Η', 'Θ', 'Ι', 'Κ', 'Λ', 'Μ', 'Ν', 'Ξ', 'Ο', 'Π', 'Ρ', 'Σ', 'Τ', 'Υ', 'Φ', 'Χ', 'Ψ', 'Ω'}\n",
    "\n",
    "def detect_math_expressions(text):\n",
    "    matched = set(text) & (math_symbols | special_symbols | lowercase_greek_symbols | uppercase_greek_symbols)\n",
    "    return len(matched)>0\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def split_sentence(text):\n",
    "    doc = nlp(text)\n",
    "    sentences = [re.sub(r'\\n', '', sent.text) for sent in doc.sents]\n",
    "    return sentences\n",
    "\n",
    "def remove_bullet(text):\n",
    "    pattern = r'^[\\(\\[\\{]?([a-zA-Z0-9])[\\.\\)\\]\\}\\s]+|^[\\(\\[\\{]?(?:[ivxlcdm]+)[\\.\\)\\]\\}\\s]+'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_intro = (df_paper_copy[df_paper_copy['introduction']==1]).drop(columns=sec_list+['sum_sec']).reset_index()\n",
    "# df_intro['paragraph'] = df_intro['text'].apply(count_paragraph)\n",
    "# df_intro\n",
    "\n",
    "# for i, paragraph in enumerate(split_text(text)):\n",
    "#     print('-'*50,i+1,'-'*50)\n",
    "#     print((paragraph))\n",
    "#     for sent in split_sentence(paragraph):\n",
    "#         print('-', remove_bullet(sent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = split_sentence(text)\n",
    "# for j, sentence in enumerate(sentences):\n",
    "#     print('-'*20,j+1,'-'*20)\n",
    "#     print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, paragraph in enumerate(split_text(text)):\n",
    "#     print('-'*50,i+1,'-'*50)\n",
    "#     # print(paragraph)\n",
    "#     sentences = split_sentence(paragraph)\n",
    "#     for j, sentence in enumerate(sentences):\n",
    "#         print('-'*20,j+1,'-'*20)\n",
    "#         print(is_sentence(sentence))\n",
    "#         print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# import string library function\n",
    "\t\n",
    "# Storing the sets of punctuation in variable result\n",
    "result = list(string.punctuation)\n",
    "\t\n",
    "# Printing the punctuation values\n",
    "print(result)\n",
    "print(type(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def is_sentence(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    # for w in doc:\n",
    "    #     print(w, type(w))\n",
    "    words = [(w) for w in doc if str(w) not in list(string.punctuation)]\n",
    "    print(len(words))\n",
    "    print(words)\n",
    "    \n",
    "def prepro_text(text, num_paragraph=None):\n",
    "    paragraphs = split_paragraph(text)\n",
    "    if num_paragraph!=None:\n",
    "        paragraphs = [paragraphs[num_paragraph]]\n",
    "    sentences = []\n",
    "    # print([split_sentence(paragraph) for paragraph in paragraphs])\n",
    "    sentences = [sentence for sentences in [split_sentence(paragraph) for paragraph in paragraphs] for sentence in sentences]\n",
    "    return sentences\n",
    "\n",
    "text = \"\"\"Paragraph number 1 is here.\n",
    "Paragraph number 2 is here. There are the contents:\n",
    "(1) The 1st bullet.\n",
    "(2) The 2nd bullet.\n",
    "(3) The 3rd bullet.\n",
    "Paragraph number 3 is here. This is the content.\n",
    "Paragraph number 4 is here. This is the content.\n",
    "Paragraph number 5 is here. This is the content.\"\"\"\n",
    "# prepro_text(\n",
    "#     text, \n",
    "    # num_paragraph=-1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[Paragraph, number, 3, is, here]\n"
     ]
    }
   ],
   "source": [
    "is_sentence(\"Paragraph number 3 is here.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical learning theory studies the learning properties of machine learning algorithms, and more fundamentally, the conditions under which learning from finite data is possible. In this context, classical learning theory focuses on the size of the hypothesis space in terms of different complexity measures, such as combinatorial dimensions, covering numbers and Rademacher/Gaussian complexities (Shalev-Shwartz & Ben-David, 2014; Boucheron et al., 2005). Another more recent approach is based on defining suitable notions of stability with respect to perturbation of the data (Bousquet & Elisseeff, 2001; Kutin & Niyogi, 2002). In this view, the continuity of the process that maps data to estimators is crucial, rather than the complexity of the hypothesis space. Different notions of stability can be considered, depending on the data perturbation and metric considered (Kutin & Niyogi, 2002). Interestingly, the stability and complexity approaches to characterizing the learnability of problems are not at odds with each other, and can be shown to be equivalent as shown in Poggio et al. (2004) and Shalev-Shwartz et al. (2010).\n",
      "In modern machine learning overparameterized models, with a larger number of parameters than the size of the training data, have become common. The ability of these models to generalize is well explained by classical statistical learning theory as long as some form of regularization is used in the training process (Bühlmann & Van De Geer, 2011; Steinwart & Christmann, 2008). However, it was recently shown - first for deep networks (Zhang et al., 2017), and more recently for kernel methods (Belkin et al., 2019) - that learning is possible in the absence of regularization, i.e., when perfectly fitting/interpolating the data. Much recent work in statistical learning theory has tried to find theoretical ground for this empirical finding. Since learning using models that interpolate is not exclusive to deep neural networks, we study generalization in the presence of interpolation in the case of kernel methods. We study both linear and kernel least squares problems in this paper.\n",
      "Our Contributions:\n",
      "• We characterize the generalization properties of interpolating solutions for linear and kernel least squares problems using a stability approach. While the (uniform) stability properties of regularized kernel methods are well known (Bousquet & Elisseeff, 2001), we study interpolating solutions of the unregularized (\"ridgeless\") regression problems.\n",
      "• We obtain an upper bound on the stability of interpolating solutions, and show that this upper bound is minimized by the minimum norm interpolating solution. This also means that among all interpolating solutions, the minimum norm solution has the best test error. In\n",
      "particular, the same conclusion is also true for gradient descent, since it converges to the minimum norm solution in the setting we consider, see e.g. Rosasco & Villa (2015). • Our stability bounds show that the average stability of the minimum norm solution is\n",
      "controlled by the condition number of the empirical kernel matrix. It is well known that the numerical stability of the least squares solution is governed by the condition number of the associated kernel matrix (see the discussion of why overparametrization is “good” in Poggio et al. (2019)). Our results show that the condition number also controls stability (and hence, test error) in a statistical sense.\n",
      "Organization: In section 2, we introduce basic ideas in statistical learning and empirical risk minimization, as well as the notation used in the rest of the paper. In section 3, we briefly recall some definitions of stability. In section 4, we study the stability of interpolating solutions to kernel least squares and show that the minimum norm solutions minimize an upper bound on the stability. In section 5 we discuss our results in the context of recent work on high dimensional regression. We conclude in section 6.\n"
     ]
    }
   ],
   "source": [
    "# df_section = {}\n",
    "\n",
    "    \n",
    "for sec in sec_list:\n",
    "    df_section = (df_paper_copy[df_paper_copy[sec]==1]).drop(columns=sec_list+['sum_sec']).reset_index(drop=True)\n",
    "    # df_section['processed_text'] = df_section['text'].apply(split_paragraph).apply\n",
    "    for idx, row in df_section.iterrows():\n",
    "        sec_text = row['text']\n",
    "    #     paragraphs = split_paragraph(sec_text)\n",
    "        break\n",
    "    break\n",
    "\n",
    "# prepro_text(\n",
    "#     sec_text, \n",
    "#     num_paragraph=-1\n",
    "# )\n",
    "print(sec_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Statistical learning theory studies the learning properties of machine learning algorithms, and more fundamentally, the conditions under which learning from finite data is possible.',\n",
       " 'In this context, classical learning theory focuses on the size of the hypothesis space in terms of different complexity measures, such as combinatorial dimensions, covering numbers and Rademacher/Gaussian complexities (Shalev-Shwartz & Ben-David, 2014; Boucheron et al., 2005).',\n",
       " 'Another more recent approach is based on defining suitable notions of stability with respect to perturbation of the data (Bousquet & Elisseeff, 2001; Kutin & Niyogi, 2002).',\n",
       " 'In this view, the continuity of the process that maps data to estimators is crucial, rather than the complexity of the hypothesis space.',\n",
       " 'Different notions of stability can be considered, depending on the data perturbation and metric considered (Kutin & Niyogi, 2002).',\n",
       " 'Interestingly, the stability and complexity approaches to characterizing the learnability of problems are not at odds with each other, and can be shown to be equivalent as shown in Poggio et al.',\n",
       " '(2004) and Shalev-Shwartz et al.',\n",
       " '(2010).',\n",
       " 'In modern machine learning overparameterized models, with a larger number of parameters than the size of the training data, have become common.',\n",
       " 'The ability of these models to generalize is well explained by classical statistical learning theory as long as some form of regularization is used in the training process (Bühlmann & Van De Geer, 2011; Steinwart & Christmann, 2008).',\n",
       " 'However, it was recently shown - first for deep networks (Zhang et al., 2017), and more recently for kernel methods (Belkin et al., 2019) - that learning is possible in the absence of regularization, i.e., when perfectly fitting/interpolating the data.',\n",
       " 'Much recent work in statistical learning theory has tried to find theoretical ground for this empirical finding.',\n",
       " 'Since learning using models that interpolate is not exclusive to deep neural networks, we study generalization in the presence of interpolation in the case of kernel methods.',\n",
       " 'We study both linear and kernel least squares problems in this paper.',\n",
       " 'Our Contributions:• We characterize the generalization properties of interpolating solutions for linear and kernel least squares problems using a stability approach.',\n",
       " 'While the (uniform) stability properties of regularized kernel methods are well known (Bousquet & Elisseeff, 2001), we study interpolating solutions of the unregularized (\"ridgeless\") regression problems.',\n",
       " '• We obtain an upper bound on the stability of interpolating solutions, and show that this upper bound is minimized by the minimum norm interpolating solution.',\n",
       " 'This also means that among all interpolating solutions, the minimum norm solution has the best test error.',\n",
       " 'Inparticular, the same conclusion is also true for gradient descent, since it converges to the minimum norm solution in the setting we consider, see e.g. Rosasco & Villa (2015).',\n",
       " '•',\n",
       " 'Our stability bounds show that the average stability of the minimum norm solution iscontrolled by the condition number of the empirical kernel matrix.',\n",
       " 'It is well known that the numerical stability of the least squares solution is governed by the condition number of the associated kernel matrix (see the discussion of why overparametrization is “good” in Poggio et al. (2019)).',\n",
       " 'Our results show that the condition number also controls stability (and hence, test error) in a statistical sense.',\n",
       " 'Organization:',\n",
       " 'In section 2, we introduce basic ideas in statistical learning and empirical risk minimization, as well as the notation used in the rest of the paper.',\n",
       " 'In section 3, we briefly recall some definitions of stability.',\n",
       " 'In section 4, we study the stability of interpolating solutions to kernel least squares and show that the minimum norm solutions minimize an upper bound on the stability.',\n",
       " 'In section 5 we discuss our results in the context of recent work on high dimensional regression.',\n",
       " 'We conclude in section 6.']"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepro_text(\n",
    "    sec_text, \n",
    "    # num_paragraph=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "c41a15a33a59f0eeae9566b7a824606ae2e90e5c5eb8240ec6145ee367642a6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
