paper_id,summary
SP:b19df5243359791fbaad005d6f13d7e9fdb0ff63,"This paper proposes an approach to role - based multi - agent learning by decomposing complex tasks into roles and policies. It is unclear how to efficiently discover such a set of roles, and the main contribution of this paper is to propose to first decompose joint action spaces into restricted role action spaces by clustering actions according to their effects on the environment and other agents, and then learn a role selector based on action effects to select a role in each role space using a bi - level learning hierarchy. The role selector searches in a smaller role space and at a lower temporal resolution, while role policies learn in significantly reduced primitive action - observation spaces. The paper further integrate information about action effects into the role policies to boost learning efficiency and policy generalization. The main contributions are the following : - The paper proposes to use action clustering as a learning strategy to learn role policies in both the joint action space and the role action space. - It proposes to generalize action - based role policies based on the role selector to a larger role space in each policy search. - The approach is evaluated empirically in two scenarios : ( 1 ) against the current state - of - the - art MARL algorithms on 9 of the 14 scenarios that comprise the challenging StarCraft II scenario, and ( 2 ) against a slightly different set of environments where the number of agents is slightly smaller. The results show that the proposed approach ( with minor modifications to the proposed role selector ) can learn more efficiently and more effectively in both scenarios. - In the second scenario, the proposed method ( with slightly smaller agents and slightly larger role spaces ) achieves rapid transfer to new environments with similar performance to the original one ( with three times as many agents ).   The paper is generally easy to follow and worth reading. However, there are a few typos in parts of the paper, and some of the explanations may be difficult to follow. Please see the notes for details."
SP:7deb61890d97422a0fe141ca807f968c70ab239a,"This paper studies the behaviour of the stochastic subgradient descent ( SSGD ) method applied to over - parametrized nonsmooth optimization problems that satisfy an interpolation condition. The authors leverage the composite structure of the empirical risk minimization problems to prove that SSGD converges to rates O(1/ ) and O(log(1 / ) for convex and strongly - convex objectives when the interpolation holds. These rates coincide with established rates for the stoenchastic gradient descent ( SGD ) method, which is applied to smooth problems that also satisfy a condition. Their analysis provides a partial explanation for the empirical observation that sometimes SGD and SSGD behave similarly for training smooth and nons mooth machine learning models. It also provides evidence that the sub - gradient rate is optimal for the SSGD method in convex settings."
SP:c7e0b3fedc0d0409d662dd612b529fdacad2b03e,"This paper presents Reservoir Transformer ( RPT ), a framework for training machine translation and masked language models that consists of transformer layers ( dubbed “ reservoir layers ” in the paper ), randomly initialized pre - defined blocks of data that are then iteratively updated using a compute - time - until - convergence ( CT ) mechanism. The authors propose to use this framework to train machine translation transformers ( MLPs ), which is a special type of transformer layer proposed in Wang et al. ( 2021 ), to replace the transformer layers in MLPs when they are not converging to the final wall - clock computation time ( until convergence ). The idea of using reservoir layers is to allow the machine translation process to process input data in a non - linear fashion, so that some of the randomly initialized blocks can be used to update the rest of the layers. The paper presents experiments on the Transformer - Language Model ( TML ) and Machine Translation ( MTL ) tasks, which compare the performance of using RPTs ( as well as transformer layers ) to that of vanilla MLPs. The main contributions of the paper are the following :    ( 1 ) An analysis of the effect of updating the random initialization blocks of Transformer layers on the convergence of the wall clock in terms of the average computation time of the final layer ( computed using the updated values of the previously initialized blocks ), showing that it is better than not updating the layers at all. ( 2 ) A set of experiments on language modelling tasks that compare the performances of vanilla TMLPs ( without the reservoir layers ) and Transformer LPs ( with and with the fully converged layers. ( 3 ) A study on machine translation tasks where the authors show that the reserved layers outperform vanilla LPs by a large margin.   The paper is well written and well presented, with clear explanations of the motivation for each of the proposed approaches."
SP:ba9f1d4738ec67a440346f3ac6c4cf35f7232077,"Filter transform has been widely used to construct steerable CNN to enhance the network robustness on geometry transformation of data and reduce overfitting. In this paper, the authors show that kernel constructed by filter transform can be interpreted in the group representation theory and provide a novel and simple approach to implement steerable convolution operators.    The main contribution of this paper is the following :   1 ) The authors provide a new interpretation of the Group Representation Theory ( GRT ), which has been used to derive the representation theory for the kernel representation of CNN. The main interpretation is that filter transformed kernels can be used to convolve input / output features in different group representation. This interpretation help complete the puzzle of steerable GRT and implement the CNN theory. 2 ) This paper provides a new and simple way to implement the Steinerable Convolutional Operator ( Soderberg - Rössler approach ) to increase the robustness of the network on the geometry transformation by using the filter transform technique."
SP:c1116fbb4d058eb6be195b5d13d19a55ba86b602,"This paper studies multimodal program synthesis ( MPS ), where the goal is to find a program that satisfies user - constraints while maximizing the program ’s score with respect to a neural model. The paper proposes an approach where the user intent is expressed using combination of natural language ( NL ) and input - output examples. The underlying neural model is a top - down recurrent neural model ( TRN ), which is trained using gradient descent.    The authors propose to use this recurrent model to search for a program in terms of the score $ \gamma$ of the latent variable $ \mathbb{R}$, where $ \theta$ is the difference between the output of the model and the input. The authors show that this search space is expandable and can be used to find programs that satisfy the user's constraints and maximise the program's score. They also show that their approach is robust to noise introduced by the noisy input from the user. They test their approach on a dataset of synthetic data points and show that it is as robust as the prior state - of - the - art techniques. The experimental results show that the proposed approach is more robust than the one used in the baselines, both when it comes to program search and program synthesis error. The main contributions of the paper are the following :   ( 1 )   - Proposes a recurrent neural program synthesis method based on TRN. The idea is to search a set of tasks for which the user has non - trivial objectives, such as to maximize the score of the neural model, and then synthesize the output from the program. This approach is not new ( as the authors have done before ), but is different from the previous approach in that it uses the output instead of the target score. The key difference is that the output ( output ) of TRN does not need to be the same as the input ( it only needs to be close to the target, i.e., the output can be a weighted sum of the input variables, but the target is the same. This allows the authors to use their method on tasks where the output may be different ( e.g., some may prefer input variables that are not similar to others ). The proposed approach does n’t require the output variables to be similar to other approaches, which leads to a more robust search. However, the authors argue that this approach is still not new and that the novelty of their method comes from the fact that it doesn't require the input to be different from other approaches. They compare their approach to existing methods on two tasks ( one where the input is assumed to be natural language and one where it is assumed the user is using examples ) and argue that their method is more stable."
SP:55e02d79146bbb42f1ab6d4fafa2db5ddbe599b0,"This paper proposes a new method for predicting the specificity landscape of the substrate specificity of a class of enzymes based on protein sequences. The method is based on a protein graph convolutional neural network ( PGCN ), which is a three - dimensional structure - based molecular interaction graph generated using the Rosetta energy function ( PEN ). The authors use it to determine the set of all sequence motifs that are recognized / cut / not recognized / not by the enzyme. It is important to distinguish between the sequences that the enzyme recognizes / cuts and the ones that it does not ( or does not not recognize / cut ). They evaluate their method on the task of protein classification, where they use the enzyme specificity landscape from the sequence patterns learned from experiments with a single enzyme. They show that their method is robust to even small mutational changes in the enzyme structure. They also compare their method with other methods that are based on machine learning models and show that its performance in classification tasks is equivalent or better to other methods.    The main contributions of this paper are as follows : 1. PEARL is a novel method for determining the specificity of the protein sequence of an enzyme based on the interaction between the enzyme and the structure of its functional groups. It uses the PEN with the three - dimension structure to do so ; 2. It derives the interaction graphs using PEN and derives the energy profiles of the interactions between the functional groups using the PENN. 3. They use PENN to train their model and compare it to a machine learning model that is based only on the interactions ( PENN and PENN ). Their method is computationally more efficient than the machine learning method as it uses PENN because PENN is physically based on interactions, while PENN uses information from PENN but is interpretable, and therefore requires more interpretability. The experiments on protein classification and disease prediction using PENN are not as good as the experiments on enzyme specificity. On the other hand, their experiments on disease prediction and enzyme specificity show that PENN performs much better than the one they compare to."
SP:7727eeb7b17ad94ddfa0cf24e64a9626d83a8876,"This paper studies the effect of the underestimation bias in Double Q - Learning ( DQL ), a classical method for reducing the overestimation of value estimates in Q - learning. The paper first shows that DqL suffers from an overestimation bias due to the fact that it computes the max - estimated values of the Bellman operator, which is biased towards computing higher values than the actual value estimates. Then, the paper proposes a simple but effective approach to address the problem of converging to non - optimal fixed points when computing the value estimates for solutions derived from DQLD. The approach leverages an approximate dynamic programming to bound the target value while minimizing the error of the estimator. The authors evaluate the proposed approach in two benchmark tasks on the Atari 100 benchmark and demonstrate its significant improvement over baseline methods.   The main contributions of this paper are the following :   ( 1 ) This paper shows that the underestimating bias of Double Q learning is more severe for fixed points than for estimated values. This observation is empirically verified using the following experiments on the following tasks : ( 2 ) It is shown that the converging problem is exacerbated when the fixed points are not accessible for the derived values. ( 3 ) The authors then propose an approximate solution to this problem by using a softmax estimator to estimate the maximum and minimum values for the points that would lead to the non - optimal fixed points. The method is evaluated on two tasks on Atari 100 and Atari 100 mini - ImageNet, where it is shown to outperform the baselines."
SP:1d630b69f95392a5ef3d7d580b523e077a3555a8,"The paper proposes a two - step training framework for deep generative models ( DGMs ) for generating high - dimensional natural images. The training consists of generating images in low - frequency bands by training a sampler in the wavelet domain and a decoder in the beam splitter domain, followed by generating the corresponding higher - dimensional images using the learned sampler and decoder. The main advantage of the proposed training framework over the previous methods is that the sampler can be trained in parallel, leading to generating images generated in much lower - dimensional spaces than those generated with end - to - end training. The authors demonstrate the effectiveness of their method on ImageNet with FID of 10.59, beating the baseline BigGAN model – at half the compute ( 256 TPU-v3 cores ). They also show that the training framework can be applied to generate images in the decoder domain, where the training only requires a fraction of the computational resources."
SP:b943a73b1ec34867371325748dc3a91ff4011947,"This paper studies self - supervised learning ( SSL ) for few - shot learning ( FSL ), a setting where the goal is to distill transferable knowledge on existing classes with large - scale labeled data into tasks on novel classes for which only a few labeled data are available. The paper first summarized the supervised FSL methods and explained why SSL is suitable for FSL. Then it further analyzed the main difference between supervised training and self - supervision training on FSL, and proposed ways to improve the test accuracy under the test setting of SSL. Finally, it proposed potential ways to augment SSL training to improve FSL practice.   The main contributions of this paper are as follows :   1 ) This paper studies the effect of pre - trained embedding networks ( pre - supervised training ) on the performance of downstream FSL tasks when applied to SSL - trained models. 2 ) It provides the bound for the difference between the loss terms when using SSL vs. self supervision. 3 ) It analyzes the main differences between the fine - grained loss terms for SSL and self supervision when using supervised training."
SP:bd552f98e6a447cefa6b1a9bbdf40bc6539fb643,"This paper analyzes the convergence of the parametrization of teacher - student neural networks with angular distance functions ( ADs ). The main idea is to prove that the student neuron weights must align with the teacher neuron at any local minima if the networks are to be considered "" not - too - wide "". The proof is built on the following three steps :    1. Under the assumption that global minima exist near the start of neural network initialization ( as is the case with first - order methods ), the paper shows that the input weights of student neurons eventually align with one of the teacher neurons. This suggests a distinct convergence nature for networks with finite widths where there might not be any local maxima near the initialization.   2. The paper extends the proof to more general cases, where the proof can be reduced to analyzing the properties of a special class of functions, called angular distance ( AD ) functions, which can be easily verified numerically. 3. Finally, the authors demonstrate that ADs can be used to verify the proof of these three steps."
SP:0f62846913ec10b44ed32845770da0565479dc75,"This paper introduces Deep Adaptive Semantic Logic ( DASL ), a framework for automating the generation of deep neural networks that incorporates user - provided formal knowledge to improve learning from data. The authors first introduce the concept of knowledge representation to capture all of the first - order logic and finite sampling from infinite domains to construct a knowledge representation for neural networks. They provide formal semantics that demonstrate that the representation of the knowledge representation captures all the logic necessary to form a valid belief proposition. They then demonstrate that via a toy problem where they add structure to an image classification task and demonstrate that knowledge of that structure reduces data requirements by a factor of 1000 on a visual relationship detection task. Finally, they apply the framework to real - world data and show that the addition of knowledge improves performance by 10.7 % in conditions of data scarcity.    The main contributions of this paper are the following :   1 ) The authors introduce Deepadaptivesemanticlogic(DASL ): a novel framework that is based on prior work on learning from neural networks to construct knowledge representations using machine learning and avoids vanishing gradients. This allows the learned representation to have deeper logical structure and enables richer interactions between the knowledge and learning components. 2 ) They provide the semantics for the representation and the learning model. 3 ) They conduct experiments on image classification tasks and relationship detection tasks to demonstrate the effectiveness of the framework and the interaction between knowledge representation and learning in terms of improving performance."
SP:2f19259d65fab904c1b771244da3dcb2f8aa0c26,"This paper studies iterative recurrent computations and neural networks with feedforward residual neural networks ( ResNets ). It shows that even though the typical feedforward ResNet express iterative solutions, they do not learn them when trained conventionally on computer vision tasks. To make the networks more convergent, it imposes a Lipschitz constraint on the residual functions using spectral normalization and introduces regularization to encourage iterative convergence. The paper also shows that iterative convergent computation does not provide a useful inductive bias for ResNetets when applied to visual recognition tasks with MNIST, CIFAR-10, CIFAAR-100 and Digitclutter. It is also shown that gradient coupling does not improve classification accuracy."
SP:6c14506b8b2b06043409d912e6bf877651aaa665,"This paper presents two normalization methods, SelfNorm and CrossNorm, to promote OOD generalization. SelfNorm uses attention to recalibrate statistics ( channel - wise mean and variance ), while CrossNorm exchanges the statistics between feature maps. Extensive experiments on different domains ( vision and language ), tasks ( classification and segmentation ) and settings (supervised and semi - supervised ) show their effectiveness."
SP:2774abdc11917321dd4994af0f0da1ff824bea03,"This paper proposes and studies a simple attention module in convolutional encoders for reinforcement learning ( RL ). The attention module consists of two modules : ( i ) a task - relevant module that extracts agent locations and movements ( task relevance ), and ( ii ) a feature extractor that adds the task relevant information to the output of the attention module without the need for data augmentation ( contrastive losses ).    The authors test the proposed attention module using agents trained in two environments : DeepMind Control Suite ( DCP ), a mixture of simulated and real world DM environments. They compare the performance of their attention module with that of the standard attention modules in standard RL and contrastive loss - free agents. The DPPs in the simulated DM environment outperform the supervised learning and unsupervised pre - training algorithms in the experiments. The main contributions of the paper are the following :   ( 1 ) A novel attention module is proposed that augments the attention of a simple, yet widely used, convolutionsal encoder by adding a task relevance information module. This augmentation is implemented using the Attention Mechanism ( Attention - Mechanism ). This module can be seen as an extension of the Attention Mechanism used in self - supervised learning ( AM ) and the attention mechanism used in contrastive learning ( DAG ) ( 2 ) The authors perform experiments on the widely benchmarked DM environments in both simulated DM and real life to validate the effectiveness of their module. The experiments show that the proposed Attention - Attention module ( with the augmentations ) can extract agent locations ( agent locations ) and task information ( agent movements ) more effectively than the standard Attention - only module ( without augmenting ) in DPP environments."
SP:31a7051d08d19c01e11f1fac2f3041ed2fa28f15,"GradNorm ( GradNorm, Chen et al., 2018 ) is a widely - used gradient - based approach for training multitask neural networks. In this paper, the authors propose Rotograd, an extension to GradNorm that addresses this problem by dynamically homogenizing not only the gradient magnitudes but also their directions across tasks. To this end, they propose to add a layer of task - specific rotation matrices that aligns all the task gradients with the one obtained from the original GradNorm. The authors also provide theoretical guarantees on the algorithm stability and convergence. Experiments on several real - world datasets and network architectures show that the proposed method outperforms previous approaches for the GradNorm method.    The main contributions of the paper are the following :   1 ) The authors propose a method to homogenize the gradients of the overall gradient magnitude across tasks by dynamically equalizing the contribution of each task to the overall gradients magnitude. This is a reasonable way to prevent the individual tasks ’ gradients from conflicting, i.e. pointing towards opposite directions, and thus resulting in a poor multitask performance. 2 ) They propose a way to ensure that the directions of gradients obtained from tasks are the same across gradients, by generating gradients that are rotated in the direction of the average gradient of contributions of all tasks. 3 ) They provide a theoretical guarantee on the stability of the algorithm."
SP:ac9ebd027b92527d9a87b13ad11d002d99a2b0f6,"This paper proposes a new constraint on the domain mapping function I2I, which aims to learn a mapping function without paired data from source and target domain images, by constraining the color transformation of the transformed images during the translation process from source images to target images. The proposed constraint is based on the geometry distortion problem, where the geometry structure of the translated image is different from the source image and vice versa due to the presence of distortion due to mismatch of geometry structure with the source images. To address this problem, the authors propose a Minimal Geometry - Distortion Constraint ( MGC ) to enforce the consistency of the geometry structures in the translation and reduce the distortions in translation by reducing the randomness of color transformation. To facilitate estimation and maximization of the MGC, they propose an approximate representation of mutual information called relative Squared - Loss ( RSD - LL ) that can be used during the mapping process to estimate the mapping function efficiently. The authors demonstrate the effectiveness of their MGC by providing quantitative and qualitative comparisons with the state - of - the - art methods on several benchmark datasets.   The main contributions of this paper are as follows :   1 ) The authors develop and study a novel type of constraint for the translation of domain mapping functions : a constraint that constrain the color transformers of transformed images so that the resulting transformed images have the same geometry structure regardless of the source or target images's geometry. 2 ) They use this constraint to train a classifier that learns a domain - specific mapping function, which is able to distinguish real - world objects from virtual objects ( e.g., objects that are present in the input or target domain. 3 ) They test the classifier by training it on a set of synthetic data, and show that it recovers the mapping functions better. 4 ) They compare the proposed MGC with their own MGC and the one."
SP:92a38d7d18f07f68b8f93c61180e2cc1dddd21de,"This paper studies the effect of point sampling patterns on the shape generation power of point generator generators in GANs. It shows that sensitivity to the sensitivity of the discriminators results in different shape point clouds being generated, and that over - sensitive discriminators produce point clustering artifacts. The paper proposes the concept of sampling spectrum to depict the different sampling sensitivities of the different discriminators and further study how different evaluation metrics weigh the sampling pattern against the geometry and propose several metrics forming a sampling spectrum of metrics. Guided by the proposed sampling spectrum, it discovers a middle - point sampling - aware baseline discriminator, PointNet - Mix, which improves all existing point cloud generators by a large margin on sampling - related metrics.   The paper provides the authors with the following technical details :   1. The generator design is revised and improved based on recent research on the generator design, the discriminator design needs more attention 2. The authors conduct extensive experiments to validate their new generator design and find that the new generator outperforms the previous generators in most cases. 3. They conduct a series of ablation studies to verify their findings and compare their generator design with the prior generators PointNet-Max, DGCNN, PointConv, KPConv and PointNet++. The results show that the proposed generator design outperforms them all on average. 4. A set of experiments is performed to verify the quality of the generator designs and to evaluate their methods for generating point clouds."
SP:16c4be3eb162bc81cb3343c2fc115eb8e926a5b5,"This paper studies the robustness of Capsule Networks ( CapsNets ) as alternatives to CNNs as attack methods against adversarial examples. The authors first observe that adversarial attacks on CNNs can be easily fooled by images with small quasi - imperceptible artificial perturbations, and then propose to use the class - conditional reconstruction based detection method to detect manipulators of the votes from primary capsules. Then, the authors apply multi - step attack methods designed for CNNs to attack with the detection - aware attack paradigm to obtain robust examples for the detection of manipulators using the class conditional representation. Experiments demonstrate that the robust examples detected by the proposed method are significantly better than the ones seen in the baselines. Extensive experiments demonstrate the superior attack performance of our proposed method compared to the standard CNNs and other attack methods.    The main contributions of this paper are the following :   1 ) The authors develop and study a robust class conditional neural network based on the proposed Capsule Network, which is proposed as an alternative of CNNs. 2 ) They develop and conduct extensive experiments to verify their findings."
SP:dbd093dff7a38ba8882bb8119c34623ddaaf4cc6,"This paper proposes a meta - reinforcement learning algorithm for the online adaptation setting where the agent needs to trade - off between two behaviour types within the same episode ( e.g., policy vs. reward ). It is realized that policies based on recurrent neural networks can be used in this setting by training them on multiple environments but they often fail to model this trade -off, or solve it at a very high computational cost. This paper proposes an algorithm that uses privileged information in the form of a task descriptor at the time of learning to improve the learning of recurrent policies. The algorithm learns an informed policy ( i.e., a policy receiving as input the description of the current task ) that is used to both construct task embeddings from the task description and construct the task embedding of the policy using parameters sharing and an auxiliary objective. This approach significantly reduces the learning sample complexity without altering the representational power of RNNs, by focusing on the relevant characteristics of the task, and by exploiting them efficiently, the authors argue. They evaluate the algorithm in a variety of environments that require sophisticated exploration /exploitation strategies and show that it outperforms vanilla RNNS, Thompson sampling and the task - inference approaches to meta - RL. The authors also evaluate the method in settings where policy gradient is not available and use Thompson sampling instead."
SP:bd89d254fbf31db61db237d08ab42981e27c52df,"This paper proposes a method to learn an RL policy from offline data in the real - world sequential recommendation system ( SRS ) via learning to adapt to diverse simulators generated by the offline dataset provided by the SRS dataset. The offline dataset is used to train a simulator from the dataset and optimal policies in the simulator trained using the learned policy from the simulator. However, due to the stochasticity and unsteadiness of the real world and the unavailability of online sampling, the distortion of the simulator is inevitable. This paper tackles this issue by learning a method called Adaptive Policy Learning ( APL ) to learn a policy from SRS data that produces robust policy recommendations in the unseen real world. APL trains an adaptive policy in a semi - supervised manner based on the model learning technique proposed in [ 1 ]. The main contribution of this paper is to develop and apply APL to the offline SRS policy learning problem. The method is evaluated in two environments, synthetic and a real world settings. The synthetic setting is used for training the policy learning model and the simulator, and is evaluated to see if the method overcomes the distortion problem and produces policy - optimal policies. The real world setting allows us to evaluate the effectiveness of APL in terms of policy - optimality ( i.e., the policy that leads to the least amount of simulator distortion is adopted by the policy with the least number of simulator errors when compared to the policy learned from the offline data using the adaptive policy learning method. The results show that the method does indeed provide policy optimality in the synthetic setting and produces robust policies when using APL with the adapted simulator learning method, and vice versa. The overall, however, the differences between APL and APL are not significant enough to affect the convergence of the two methods.    The main contributions of the paper are the following : ( 1 ) APL is an extension of an offline offline dataset used for policy learning to produce policy optimizers in SRS ; ( 2 ) it introduces a learning - based approach to obtain policy optimisation results using a learning method that learns a policy optimizer to produce optimal policies using a simulator ; and ( 3 ) it applies the adaptivity - based policy learning approach to the problem of policy optimization to obtain policies optimised in the semi - synthetic setting where the simulator has access to all datapoints."
SP:1a166b28cf684e0d5759bd629f6a53370d2bf11c,"This paper proposes an algorithm that progressively learns goal - reaching policies using imitation learning to acquire goal reaching policies from scratch, without the need for expert demonstrations or a value function. The core idea is to leverage the property that any trajectory sampled from the learned policy's trajectory as a successful demonstration for reaching the final state in that same trajectory can be used to define a policy to encourage the agent to behave in a certain way in order to achieve a goal. The algorithm proposes a simple algorithm in which an agent continually relabels and imitates the trajectories it generates to progressively learn goal-reaching behaviors from scratch. Each iteration, the agent collects new trajectories using the latest policy, and maximizes the likelihood of the actions along these trajectories under the goal that was actually reached, as well as to improve the policy. The authors formally show that this iterated learning iterates successfully.   The main contributions of this paper are the following :   ( 1 ) The authors propose a policy gradient method to learn goal reaching behaviors by imitation learning, where an agent progressively learns a policy that encourages a trajectory sample from the trajectory it currently lives in to reach a goal that is different from the one it originated from. This algorithm is referred to as Gradient Gradient Learning ( GR ). ( 2 ) The method is evaluated empirically using two benchmarks : the one measuring the agent ’s behavior with respect to the policy learned via imitation learning and the other measuring the policy changeover error over time using the distance between the learned trajectories and the goal states. The results demonstrate that GradientGradient Learning consistently outperforms the baseline GradientRLPolicy. ( 3 ) The major contributions of the paper include : ( a ) An algorithm that demonstrates that the method is robust and robust against the challenges presented by the challenges it faces, and ( b ) a method that demonstrates improved performance and robustness over current RL algorithms in several benchmark tasks over the course of training."
SP:c306530164d677e670554eeba8203c66bb3d9f7a,"This paper proposes a new method to generate speech waveform from text using an autoregressive teacher model. The proposed method is called FastSpeech 2s, which is the first attempt to generate waveform directly from text and enjoys the benefit of fully end - to - end inference. The main contributions of the paper are as follows :    1 ) This paper proposes to use the text - based duration prediction ( duration information extracted from the teacher model is not accurate enough ) during training to improve the accuracy of the target mel - spectrograms distilled from teacher models. 2 ) It proposes a method to directly generate the waveform ( instead of using the simplified output from teacher, and 2 ) introducing more variation information of speech ( e.g. pitch, energy and more accurate duration ) as conditional inputs in training and use predicted values in inference.   3 ) It presents the proposed method for generating speech waveforms from text in parallel, and achieves a 3x training speed - up over the previous fastspeech model ( Ren et al., 2019 ) and 4 ) it achieves faster inference speed as well. The paper also presents results showing that the proposed methods outperform the previous autoregressively trained methods in terms of voice quality as well as the number of synthesized utterances. The method is evaluated on both synthetic and natural speech tasks and compared with the previous models ( FastSpeach, FastTeach and VocalFlow ) and the current state - of - the - art. The results show that the methods are faster and more robust than the previous methods on terms of duration prediction accuracy ( duration, pitch, and energy, and more importantly voice quality. The authors also present results that the method is more robust on natural language tasks such as reading comprehension and vocabulary creation. The methods are evaluated on a variety of tasks including reading comprehension, writing comprehension, and listening comprehension."
SP:79e9fb20d383816f54738ce70d137131ebc10290,"In this paper, the authors propose a new formulation of the Unresolved Posterior Reduction Problem ( UDR ) in the language of tempered distributions, i.e. as a problem of approximating an empirical probability density function pemp(x ) by another tempered distribution q(x) whose support is in a k - dimensional subspace, over a set of generalized functions. This infinite - dimensional formulation allows to establish a connection with another classical problem of data science — the sufficient dimension reduction problem ( SDR ) — the first problem induces an algorithm for the second and vice versa. In order to reduce an optimization problem over distributions corresponding to UDR to one corresponding to SDR over ordinary functions, they introduce a new penalty function R(f ) that forces the support of f to be k - k -dimensional in order for the original f(pink ) to be reduced to the minimization of the distance between q and pemp, D(q ) over the set of functions. The authors demonstrate the effectiveness of their new formulation on 4 examples ( 3 UDR and 1 SDR ): synthetic data and standard datasets, with experiments conducted on MNIST, CIFAR-10, Fashion MNIST and Fashion - MNIST datasets. The experiments demonstrate that the proposed method leads to better performance than existing algorithms and generalize to other distributions.    The main contributions of the paper are the following :   1 ) The authors formulate the UDR problem as an approximated version of the SDR problem with the following formulation : 1 ) an adaptation to real data and fake data sampled around a k-dimensional subspace ( k=0, 1 ) based on the idea of two - step iterative iterative process iterative, described briefly described as a ( brief ) iterative. 2 ) The algorithm for approximating real data $ \epsilon$ given real $ p(x)=\mathbb{P}$ by another ( slightly different ) tempered distribution $ p(\text{p}$, p(p)}$ given data $ x = \text{P(x)-p(x)/x + \mathbf{D(q})$ where p(\text{D}_p}_d is the empirical density function and D_p is the tempered distribution. 3 ) Theorem 1 that states that the probability density of any two $ x$ evenly distributed over kdimensional subspaces is better than that of another $ p^{(x)}_d with respect to q(p}$. 4 ) A proof that this is true is given by the fact that the difference between the two distributions is"
SP:93e54522e6c2b805905d21fc968fc40866f2898b,"This paper proposes Feature Contrastive Learning ( FCL ), a feature contrastive learning approach that proposes to trade - off between robustness and sensitivity in the presence of noise in neural network training. The idea is that methods that promote robustness can hurt the model ’s sensitivity to patterns that are present in rare or underrepresented patterns, so the authors propose to introduce two notions : contextual feature utility and contextual feature sensitivity. The first is used to encourage the model to be more sensitive to the features that have higher contextual utility ( i.e., features that are salient in the context of the task at hand ). The second is used as a learning strategy to generalize the learned feature representations from the feature representations to other feature representations that are not present in the original input. The experiments show that the proposed approach achieves a better balance between the two terms, with the FCL - trained models achieving a lower error rate in terms of the ratio of robustness to sensitivity ( compared to the naive methods such as GANs that do n’t train the model with noise ). Overall, the approach seems to work better than the naive GAN - trained counterparts. The experimental results demonstrate that models trained with FCL outperform those trained with naive methods, especially when the feature representation is from a dataset whose features are scarce."
SP:f03c50f15022c4f56ac2b3085354ffed38ad1145,"This paper proposes DisentanGAIL, a generative adversarial imitation learning algorithm that bypasses the need for access to a full set of optimal states and actions by the agent to learn from by simply observing others perform a task. The paper proposes a latent representation of the discriminator network that is regularized through mutual information constraints to ensure that only features that encode information about the completion levels of the task being demonstrated are used. This allows the algorithm to obtain a shared feature space to enable learning with respect to the features that help the agent successfully perform imitation while disregarding the differences between the expert ’s and the agent’s domains.   The main contributions of this paper are the following :   1. A new adversarial learning method, Generative Adversarial Imitation Learning ( GenerativeGAIL ), is proposed that makes use of the adversarial training with a latent discriminator representation from the agent's point of view. 2. Mutual information constraints are used to ensure the regularization of the latent representation. 3. The method is designed to work in a range of control problems, including balancing, manipulation and locomotive tasks, while being robust to various domain differences in terms of both environment appearance and agent embodiment. 4. It is tested on a task where it is shown that the Generative GAIL algorithm is able to learn directly from high dimensional observations of an expert performing a task, by making use of adversarial learn with a hidden representation inside the discriminators network."
SP:ef18f4188426bc01be309633b486884b0e7a81a4,"This paper characterizes the performance of training a pruned neural network by analyzing the geometric structure of the objective function and the sample complexity to achieve zero generalization error. They show that the convex region near a desirable model with guaranteed generalization enlarges as the neural network model is pruned, indicating the structural importance of a winning ticket. The theoretical results are acquired from learning a prune neural network of one hidden layer, while experimental results are provided to justify the implications in pruning multi - layer neural networks. The experimental results obtained are sufficient to provide a formal justification of the improved generalization of the winning ticket, which has been empirically justified empirically in a broad range of deep neural network ( DNN ) involved applications like computer vision and natural language processing.    The main contributions of the paper are as follows :   - For the first time, the authors characterize a desirable convex function ( $ \gamma_t$ ) with a maximum value $ \tilde\gamma_{max}$ that is proportional to the number of the non - pruned weights in the hidden layer. This provides a formal characterization of a desirable pruned model and justifies the faster convergence rate to the desired model than training the original unpruned one. - The authors provide a set of experimental results to support their theoretical findings. The experiments cover a range of model sizes, pretrained and fully - connected layers, as well as different pruning methods ( layer pruning, unpruning, weight pruning ). They compare the generalization performance of trained and pruned models on MNIST, Fashion - MNIST and CIFAR-10."
SP:eed6cb2f8caed39f8295f4aeb6e044c2ac981c4d,"This paper proposes AutoLabel to automatically learn labels for augmented data based on distance between clean and augmented data. AutoLabel is built on label smoothing and is guided by the calibration - performance over a hold - out validation set. The authors show that AutoLabel can be easily applied to existing data augmentation methods, including AugMix, mixup, and adversarial training. They also provide some suggestions on how to further improve AutoLabel.   The main contributions of the paper are as follows :   - The authors propose AutoLabel, a machine learning method that automatically learns labels to label augmented data from the clean data. This is similar to the approach used in AugmentedMix, but instead of training a model to predict labels from the augmented data, AutoLabel trains a model that makes predictions based on the distance between the augmented and clean data, and uses a softmax to estimate the distance. This approach could potentially lead to better accuracy and better generalization performance for neural networks.- The authors conduct extensive experiments to validate their method. They compare the performance of AutoLabel with that of three other methods : ( 1 ) Augmix, ( 2 ) Adversarial training, and ( 3 ) CIFAR-10. They find that the methods can improve the accuracy significantly, especially under the distributional shift."
SP:0d5017e1a405bf86e3bac40e6e59886d4bf48450,"This paper proposes a novel self - supervised objective, Representation Learning via Invariant Causal Mechanisms (RELIC ), that enforces invariant prediction of proxy targets across augmentations through an invariant regularizer. The authors also generalize contrastive learning, a particular kind of self - supervision learning, to provide an alternative theoretical explanation for the success of these methods. The experimental results show that RELIC outperforms competing methods in terms of robustness and out - of - distribution generalization on Atari achieving above human - level performance on 51 out of 57 games.    The main contributions of this paper are as follows :   1. This paper proposes to study the problem of representation learning using a causal framework to constrain the proxy classifiers employed during pretraining to ensure that their predictions remain invariant. 2. Based on this, the authors propose to train representations only using unlabeled data, where data augmentations are allowed to follow the data distribution. 3. They provide experimental results on Atari games to support their theoretical findings and provide a theoretical understanding of the performance of RELIC and other representation learning methods."
SP:8f80a6f79f78c6421857f392c9a5e98061d7eb60,"This paper proposes a new method for learning informative visual representation in navigation tasks. The method is called Visual Transformer Network ( VTNet ) and it is designed for learning object and region representations with their location cues as spatial - aware descriptors and then incorporating all the encoded descriptors through attention operations to achieve informative representation for navigation. The authors claim that this method is more effective than state - of - the - art methods for learning navigation policy learning in unseen testing environments. The main contributions of the paper are the following :   1.   A new visual representation network, called VTNet, is proposed. It is designed to capture the relationships among all the object instances in a scene, the spatial locations of objects and image regions are emphasized so that directional navigation signals can be learned, and there is also a pre - training scheme to associate the visual representations with navigation signals to facilitate policy learning. 2. In addition to the object representations, the authors also introduce a new set of region representations, called Region Representations ( RPs ), which capture the spatial patterns in regions of the images. These regions are also emphasized to ensure that the RPs are similar enough to the original object representations so that the agent can learn the same object representations across different regions. 3. Experiments on the artificial environment AI2 -Thor demonstrate that VTNet significantly outperforms state -of -the -art methods in learning navigation signals, and the authors further investigate how the different regions are represented in the training. In the end, the main contribution of this paper is to develop a method that can be used to design effective visual representations of the observed scene in determining navigation actions."
SP:3e7cbe3dff592ef371e48dd86be7719fc5343f17,"This paper proposes communication -computation efficient secure aggregation ( CE - EMA ), which reduces the amount of communication / computational resources required by a factor of $ n/log n$ relative to the existing secure aggregation method ( Chan et al., 2019 ) without sacrificing data privacy in the federated learning setting, where n is the number of clients. The key idea behind the suggested scheme is to design the topology of the secret - sharing nodes ( G ) of the AE - G net, which is used to predict the distribution of the parameters of a neural network model fed into AE using the data distribution over the clients'private parameters. The authors first obtain a sufficient condition on G to guarantee reliable and private data privacy for the AE framework under the assumption that the clients do not disclose any information about the local parameters of the model to the non - clients. Then, they provide theoretical guarantees on the reliability /privacy of the proposed scheme. Through extensive experiments, they demonstrate that the proposed CE - CEMA, using only 50% of the resources required in the conventional scheme, maintains virtually the same levels of reliability and data privacy as the conventional AE scheme with a significantly reduced communication / computation cost. Finally, the authors provide theoretical evaluations of the reliability and privacy guarantees.    The main contributions of this paper are the following :   ( 1 ) The authors propose a new secure aggregation algorithm that uses a lower bound on the communication complexity ( $ \n / log n$ ) of AE net ( corresponding to the EMA principle ) to train neural network models using data distributed over multiple clients without a need to share private private data ; ( 2 ) They conduct extensive experiments to evaluate the proposed algorithm and compare the proposed communication complexity with the one proposed in the previous work, showing that their proposed communication aggregation algorithm can be achieved with the same level of privacy protection using only a small fraction of the communication costs ; and ( 3 ) They provide theoretical and extensive experimental evaluations of their proposed algorithm."
SP:00fae41e0eca0a1575cd7b2dcfabf0dc5c9c8b8a,"Duetting et al. ( 2019 ) is an important work in the field of auction design. It aims to design an incentive - compatible auction that maximizes expected revenue while minimizing the expected loss incurred by the designer. In this paper, the authors propose two novel approaches to the problem. First, they use recent results in theoretical auction design to introduce a time - independent Lagrangian that allows for comparing the performance of two auctions. Second, the optimization procedure in previous work uses an inner maximization loop to compute optimal misreports. To facilitate the use of an additional neural network to aggregate information from different auction participants, they propose to use an additional learning network by learning competitive or learning - competitive auction by learning ( e.g., strictly improved auctions ). The authors evaluate the effectiveness of their approach on two learning - based auction design tasks, where they design a two - player cooperative auction where one of the players is paid by the amount of the other player's ticket and the goal is to raise as much money as possible during the auction. The second task is to collect tickets for the players at the end of each round. This task is modeled as a 2 - player game, where each player takes part in two rounds, and the winner is chosen based on their performance during the first round. The winning player is then released to the other side. This process is repeated until a suitable amount of tickets are reached, at which point the second player takes over and the auction is called off - the - record. This procedure is referred to as post - hoc optimization.    The main contribution of this paper is the introduction of a novel formulation of Auction Design as a Two - Player Game with stationary utility functions. This formulation is based on the recent research direction initiated by Duetting et. al. that consists in building neural network architectures to find optimal auctions. The main difference between this formulation and prior work is that the prior work prior to this one uses a hyperparameter search to estimate the hyper - parameters of the neural network used to compute the maximization objective. The new formulation does not use a hyper - parameter and instead uses a Gaussian distribution of the parameters. This allows for using a single metric, the best - suited - to - fit score, to compare the two auction results. The experiments compare the proposed formulation of the new formulation with prior work on two games. The results indicate that the proposed approach is more competitive on the two games ( when compared to prior work ). When compared to other methods, the approach generally yields better results."
SP:a0e8061beb5e9a6c631419861559d22b8d645cb4,"This paper proposes Bi - Tuning, a general learning approach to fine - tune supervised and unsupervised pre - trained representations for downstream tasks exploiting labels and intrinsic structure of data. The motivation is that existing fine - tuning methods mainly leverage the former and discard the latter. To address this problem, the authors propose to integrate two heads : a classifier head with a newly designed categorical contrastive learning loss to exploit the label information in a category - consistent way and a teacher head with an improved cross - entropy - based loss to better leverage label information. The teacher head is placed on top of the head of the classifier and the student is placed in the middle. The student first trains a model with representations from a large - scale dataset and then fine - tunes the model on a specific downstream task. Experiments on CUB, CUB in low - data regime and ImageNet show that bi - tuning achieves state - of - the - art results on tasks of both fine - tuned models by increasing accuracy by large margins ( e.g. 10.7% absolute rise in accuracy ). Ablation studies are also conducted to validate the effectiveness of the proposed method.    The main contributions of the paper are the following : ( 1 ) A general approach to integrating two heads upon the backbone of pre -trained representations : ( 2 ) A teacher head and a student head trained on the same dataset to learn representations from both labels and data using the discriminative knowledge of labels and structure of the data."
SP:87e5b552c13d73bd85249062a152c6c140e594a9,"This paper proposes a new metric for assessing the robustness of classifiers. The authors argue that standard adversarial accuracy has a tradeoff with standard accuracy even when they neglect generalization. The new metric is proposed as a way to handle the problems of the standard adversary accuracy. The proposed metric is based on the adversarially perturbed samples. It does not favor a model with invariance - based adversarial examples, samples whose predicted classes are unchanged even if the perceptual classes are changed. The main contribution of this paper is to develop and evaluate the new metric as a new way to evaluate classifier robustness.   The main contributions of the paper are the following :   1 ) The authors develop and evaluates the new measure for adversarial robustness - based classifier accuracy. This is done by training a classifier on the same set of adversarial samples as the one used to train the adversarial classifier. The classifier is trained to output the class label on the set of samples sampled from the classifier trained on the perturbed set. The training is done using adversarial training and adversarial data. 2 ) The data used for the evaluation is collected from the same dataset as in the original paper. 3 ) The classifiers are trained using the same adversarial dataset as the original training set. 4 ) The results of the experiments are presented to demonstrate the importance of using the proposed metric and the tradeoff between the accuracy on clean data and accuracy on adversarial test data."
SP:2fda410b9281c5e253d385bc4382ec168bc161f3,"This paper studies the problem of disparate impact on graph - structured data using machine learning algorithms. The focus is on dyadic fairness, which articulates a fairness concept that a predictive relationship between two instances should be independent of the sensitive attributes. Based on this, the authors theoretically relate the graph connections to dyadic fair on link predictive scores in learning graph neural networks. They then propose an algorithm, FairAdj, to empirically learn a fair adjacency matrix with proper graph structural constraints for fair link prediction, and in the meanwhile enjoy a favorable predictive accuracy as much as possible while enjoying a favorable fairness -utility tradeoff.   The main contributions of this paper are as follows :   1. The paper proposes a novel graph neural network, called Graph Neural Networks ( GNN ), and introduces a novel algorithm, called GNN - ADJ ( Graph Adversarial and Demonstrative Jumps ), to enforce the edges in a graph that are subject to discrimination to be within a certain distance from each other. This is in contrast to prior work, which does not enforce edges on the edges of the neural network. 2. The authors then apply the GNNs to the graph space to enforce additional edges that are larger than a pre - chosen threshold, and show that this additional weighting makes the resulting graph more robust to discrimination. 3. The algorithms are evaluated empirically using synthetic data, and the results are generally favorable."
SP:b614e9fbec58e9efa7722d2ec4a60fc93d210f92,"This paper proposes Disentangled Exploration Autoencoder ( DEAE ), a method for generating autoencoders that is able to synthesize data from scratch, without using GAN - based adversarial training, which is notoriously hard to train and control. The method is based on disentangled representation and regularization to guarantee the validity of exploration in latent space to achieve controllable synthesis. The encoder of DEAE first turns the input sample into a disenangled latent code, then explores the latent code space through directed interpolation. To aid the interpolated latent code in successfully outputting a meaningful sample, after the decoder, the authors regularize the output by “ reusing ” the encoder to force the obtained latent representation to maintain perfect disentanglement. Experiments demonstrate that DEAE can improve the performance of downstream tasks by synthesizing attribute - controLLable augmented samples. Also, the method can help to eliminate dataset bias, which provides a solution for fairness problems."
SP:c934adb14926a00ef9c73c9773cb0b3a2669921e,"This paper proposes a novel method for bridging the gap between episodic and semantic memory in the human memory model. Episodic memory is a compressed representation produced by a serial event that is later restructured to build a more generalized form of reusable knowledge ( semantic memory ). The authors propose a new principled Bayesian memory allocation scheme that bridges the gap via a hierarchical latent variable model that allows for differentiable block allocated latent memory. Inspired by the Kanerva Machine, the authors simplify the process of memory writing by treating it as a fully feed forward deterministic process, relying on the stochasticity of the read key distribution to disperse information within the memory. The proposed method is evaluated on CIFAR-10, DMLab Mazes, Celeb-A and ImageNet32. The experiments demonstrate that this allocation scheme improves performance in memory - dependent tasks."
SP:e63d7d8c581019e17585fb9c0eac33d6836e187d,"This paper studies the sample complexity and loss landscape of attention - based neural networks. Attention models require lower sample complexity than models without attention, and local minimum of the attention model has low prediction error. The theoretical results also provide guidelines for designing future attention models. Experiments on various datasets validate the theoretical findings.   The main contribution of this paper is to provide theoretical analyses on the effectiveness of self - attention models despite significant empirical gains. The main contributions of the paper are as follows :   - First, the authors use the state - of - the - art Attention Mechanism ( AMM ) to train deep learning models for several tasks. Under mild assumptions, it is shown that the proposed attention model converges to the lowest possible local minimum with respect to all the tasks it is trained to solve. The authors use this insight to study the prediction error of attention models in terms of the number of layers and the average number of parameters used to train the model. This leads to a set of generalizable attention models that can be used to solve tasks without using attention at all. - The authors then carry out a series of experiments to validate their theoretical findings as well as the empirical gains made by attention models on various tasks. The experiments are conducted on the following tasks : MNIST, CIFAR-10, JeNet - SSIM, and the JeNet semantic segmentation task."
SP:f739d199fdee26f09994e3f9487aec1eab0f2e89,"This paper proposes a novel approach to active inference, where an agent chooses an action that leads to its prior preference for a future observation and uses it to infer the value function expected free energy ( EFE ), which is a quantity in active inference. The authors claim that EFE can be treated as a negative value function and propose a novel method to learn a prior preference from experts. The method is based on Bayesian modeling of a brain with a biologically plausible model of the agent, and its primary idea relies on the free energy principle and the prior preference. Experimental results of the proposed prior preference learning show the possibility of active inference with EFE - based rewards and its application to an inverse RL problem. This illustrates that the problem with inverse RL can be approached with a new perspective from the active inference perspective."
SP:5592b79e49eba95c15103a3348f2bde57b60f2ab,"This paper proposes a data augmentation method to improve generalization in both adversarial and standard learning by using out - of - distribution ( OOD ) data. OOD data is used to bridge the gap between the training and inference of neural networks. The theoretical analysis theoretically shows that generalization theoretically improves when OOD is used in each learning scenario. The empirical analysis supports the theoretical analysis with experiments on CIFAR-10, CifAR - 100, and a subset of ImageNet. The proposed method, Data Augmentation Method ( DAP ), improves generalization through the use of OOD as augmentation data. The main advantage of the proposed method over other augmentation methods is that DAP augmentation is not dependent on the pseudo - labels used for training the neural networks, which can be used to boost generalization even if they are not produced by the training algorithm. The major drawbacks of DAP is that it requires access to OOD ( which may not be available for training neural networks in all settings ) and that it uses the same set of parameters as DAP which may cause DAP to fail in some settings. The authors present a detailed explanation of the drawbacks and show how to circumvent them.    The main contribution of this paper is the proposal to augmentation the training parameters using OOD instead of softmax parameters as used in DAP. This augmentation can be done in a variety of settings such as standard learning, adversarial training, and stochastic gradient descent. The experimental results indicate that OOD augmentation often leads to undesirable features being present even among image data that seem to have little correlation from a human point of view."
SP:3cac7a2c310165ed0de46d8e5546c3bfbd639158,"The paper introduces Fast Linearized Adaptive Policy ( FLAP ), a meta - RL method that is able to extrapolate well to out - of - distribution tasks without gradient descent and adapt almost instantaneously with the need of a few samples during testing. FLAP builds upon the idea of learning a shared linear representation of the policy so that when adapting to a new task, it suffices to predict a set of linear weights from the policy and a separate adapter network is trained simultaneously with the policy such that during adaptation, we can directly use the adapter network to predict these linear weights instead of updating a policy via gradient descent. The paper introduces fast linearized adaptation run - time speeds ( up to 8X faster ) when compared to prior methods. It introduces a separate feed - forward network that is used for the application of the FLAP method. The experiments compare FLAP with MAML, a method that updates the policy using gradient descent to obtain the new policy, and with FLAP, which uses the learned linear representation to update the policy. The experimental results show that FLAP presents significantly stronger performance on out of distribution tasks with up to double the average return and up to $ 8X / min / sec faster adaptation run-time speeds.    The main contributions of this paper are the following :   1. Introducing a new meta - learning method, FLAP : A new metareinforcement learning method based on linearized learning. 2. Different from gradient descent based meta - policy updates by updating the policy from time to time. 3. Extensive experiments comparing the performance of FLAP to those of gradient - descent based methods, showing the benefits of using FLAP compared to gradient - based updates."
SP:21a1bd4ada0723c96c0dbf7a142a2faf5defa4e3,"This paper proposes a federated variant of the kernel k - means method ( FedK - Means ), which is based on a distributed stochastic proximal gradient descent ( DSPGD ) algorithm. The authors argue that this method is better suited for the federated setting as it is able to handle the convex optimization of k-means, where k is a weighted sum of k distributions over realizable quantities. The paper also presents a communication efficient mech anism ( CEM ) algorithm designed to reduce the communication cost of the proposed algorithm. Experimental results show that the proposed method achieves the highest clustering quality with the reduced communication cost compared to the standard federated approach.   The main contributions of this paper are the following :   ( 1 ) A federated version of the widely - used DDPG algorithm is proposed to address the distribution optimization problem of kernel k means under federated settings ; 2 ) An algorithm to ensure that users ’ local data are not exposed to the cloud server in federated K - means while maintaining communication efficiency ; and 3 ) A communication efficient Mech anism algorithm to improve the communication efficiency between the server and the client."
SP:be568dd3fea51ce33a6d1e4b07dda5aee6342395,"The paper presents a method to train efficient neural network architectures tailored to support both the accuracy under diverse hardware & latency constraints with Once - For - All ( OFA ) model architectures. OFA is an approach to jointly train several models at once with a constant training cost, but this cost remains as high as 40 - 50 GPU days. This paper proposes to reduce this search space – and hence the training budget – by constraining search to models close to the accuracy - latency Pareto frontier. The authors incorporate insights of compound relationships between model dimensions to build CompOFA, a design space smaller by several orders of magnitude. They demonstrate that this smaller design space is dense enough to support equally accurate models for a similar diversity of hardware and latency targets, while also reducing the complexity of the training and subsequent extraction algorithms.    The paper presents results on ImageNet that demonstrate that even with simple heuristics, the proposed method can achieve a 2x reduction in training time and 2x speedup in model search /extraction time compared to the state of the art, without loss of Pare to optimality!"
SP:04b84d26cf282dbb753cbf27f14c334f65d3f8ec,"This paper presents ADML ( Adversarial Meta - Learner - ML ), a meta - learning algorithm that leverages clean and adversarial samples to optimize the initialization of a learning model in an adversarial manner. The main contributions are three - folds :    ( 1 ) it proposes a new algorithm, ADML, to handle the task of learning a model from scratch with only clean data ( e.g., no adversarial perturbations ). This is similar to the approach of [ 1 ], [ 2 ] and [ 3 ], but differs in that it uses the clean samples to learn the model from the clean data and the adversarial ones to train the model. The paper shows that ADML outperforms the state - of - the - art meta - learners ( in terms of both accuracy and robustness ) on two widely -used image datasets ( MiniImageNet and CIFAR100 ) that are used for this study, and experiments are done with different attack mechanisms ( different - attack mechanisms for clean samples and different kinds of adversarial attacks ). The experiments show that it is more effective than other meta - learner algorithms even when the training is done entirely with clean data. It sheds light on the cases with limited or even contaminated samples, where it is less effective.   The main contribution of this paper is to propose a robust and easy - to - use adversarial approach to training a model in the meta learning setting, and to study the performance of ADML on the datasets when the learning model is adversarial initialized with clean samples."
SP:dfbaa6b53c4e8328d52666ad4641fc917bf0c0b3,"This paper proposes a new permutation - based encoder - decoder framework for the Bose - Chaudhuri Hocquenghem ( BCH ) encoder. The encoder is based on the maximum likelihood rule, which is NP - hard to achieve. The decoder is trained via permutation selection, where suboptimal decoding algorithms are employed to obtain the best bit error rate. The idea is to leverage the benefits of self - attention provided by self - encoding in order to improve the bit error of BCH decoder as compared to the baseline decoders. To this end, the authors propose a data - driven framework that selects permutation permutation seeds by combining domain knowledge with machine learning concepts such as node embedding and self - Attention. The authors show that their framework leads to significant improvements in bit error rates for the simulated BCH code compared to baseline decoder.    The main contributions of the paper are as follows :   1 ) A new algorithm for the permutation decoding of the BH encoder, based on a new data driven framework, is proposed. The bit error is optimized using a permutation based algorithm that is trained using machine learning techniques. This method is shown to lead to significant performance improvements in the simulated case. 2 ) The authors also show that the method leads to a significant reduction in the average bit error for the decoder in BCH compared to baselines. 3 ) The method is applied to several real - world BCH implementations, which demonstrate the effectiveness of the proposed in the experiments."
SP:c860a7b0952d708e7851c9bc4b63d246f64d1cba,This paper proposes a clustering - based approach to fine - tune BERT for target text classification. The idea is that fine - tuning BERT on the target task is prone to producing poor performance when clustering is performed on intermediate tasks. The clustering task consists of training BERT to predict cluster labels for target and intermediate classification tasks from unlabeled examples. The paper further discusses under which conditions this clustering approach is helpful and why it is effective. The authors test the clustering method on two data sets and show that it can significantly reduce the demand for labeled examples mainly for topical classification tasks.
SP:ea37f5882fd98dd4ce233077bb3069517d4ed4ea,"This paper studies generative models based on mixture density nets ( MDN ) using a fixed random - shooting control agent. The authors compare MDN with deterministic models ( DPM ), mixture density net ( MDP ), and stochastic models ( SDP ) on a mult multimodal learning task, where the control agent is assumed to be Gaussians. They find that the MDN models outperform the deterministic ones when the control is not parametrized, and heteroscedasticity at training time ( perhaps acting as a regularizer ) improves predictions at longer horizons. On the methodological side, they design metrics and an experimental protocol to evaluate the performance of the models. They also propose a state - of - the - art micro - data model - based reinforcement learning framework to improve performance when using them on the control problem. The main contributions are the following :   ( 1 ) The authors rigorously investigate the effect of the presence or absence of multivariate normal distributions on the generative model predictions when using DPMs, and find that they do not affect the performance ( although slightly ). ( 2 ) They show that the predictions from SDP models improve as the training time goes on, and predictors from MDPs become more realistic. ( 3 ) They design metrics to measure the contribution of each model to the prediction accuracy ( MLE ) using MMDN scores.    The main contribution of this paper is the development of the MLE framework, which allows for evaluating the performances of the different models not only on MLE but also on other tasks ( e.g. for instance, evaluating how well - behaved uniform distributions affect the predictions."
SP:4e25ba3714d78ba59a0d8efbb65e0ef5201702f8,"This paper proposes ADIS - GAN ( ADISGAN ), a GAN that disentangles affine transformations in a self - supervised and rigorous manner. The affine regularizer is derived by decomposing the affine transformation matrix into separate transformation matrices and inferring the transformation parameters by maximum likelihood estimation. Unlike GANs that rely on disentangled affine representations learned by existing approaches, the features learned by ADIS + GAN are axis - aligned and scalable, where transformations such as rotation, horizontal and vertical zoom, horizontal   and vertical skew can be explicitly selected and learned. The paper includes experiments on MNIST, CelebA, and dSprites to demonstrate the efficacy of the method.   The main contributions of this paper are as follows :   1. This paper proposes a new affine transformational model, affine GAN, inspired by InfoGAN, to learn affine features from images using GAN - like representations. 2. It defines affine matrices for transformations and derives the corresponding transformation regularizers, one each for rotation ( rotation + horizontal ), vertical skew ( horizontal + vertical ), and vertical   3. In the experiments, it is shown that ADIS+GAN achieves better results than InfoGAN in terms of accuracy and scalability when compared to ImageGAN, InfoGAN + InfoGAN - regularizer, with the main advantage of InfoGAN being that InfoGAN has a fully GAN regularizer and ImageGAN has an additional affine matrix regularizer with the inductive bias."
SP:121f8420cfb49c6d80b5ebb4051e85947182594a,"This paper proposes a new method for unsupervised representation learning ( un - supervised learning ) based on contrastive learning. The main idea is to combine the weakly augmented and strongly augmented images over the representation bank with the retrieval of strongly augmented queries from a pool of candidates that could overfit the queries containing distorted visual structures into the positive targets while still being able to distinguish them from the negative samples by leveraging the distributions of weakly augmented counterparts. The proposed method achieves top - 1 accuracy of 76.2 % on ImageNet with a standard ResNet-50 architecture with a single - layer classifier fine - tuned. This is almost the same as 76.5 % with a fully supervised ResNet - 50 and outperforms the previous self - supervised and supervised methods on both the transfer learning and object detection tasks.   The main contributions of the paper are as follows :    1. The authors propose to use the stronger augmentations directly to minimize the contrastive loss while maximizing the distribution divergence between the distribution of the augmented and the weaker augmented images. 2. Stronger augmentations could expose novel patterns of representations to improve their generalizability, but directly using them in instance discrimination - based contrastive learn instance discrimination may even deteriorate the performance, as the distortions induced from the stronger augmented images can ridiculously change the image structures and thus the transformed images can not be viewed as same as the original ones any more. 3. Additional efforts are needed to explore the role of the stronger augmentation in further pushing the performance of un - supervision learning closer to the fully supervised learning."
SP:af54e542223097c315ecd677d0b968e9a0b2a1d4,"This paper proposes a new method for the de - identification of the face in MRI scans using the magnetic resonance imagery ( MRI ). The authors claim that the existing methods for this task either use too much information about the patient ’s identity or remove information that could affect the accuracy of the analysis ( e.g., the fact that the features that are most likely to be seen by the scanner are the ones that are the subject of privacy concerns ). They propose GAN - GAN, a method that proposes to combine the features of the scanned subject with the information about their privacy. The proposed method is meant to be able to handle the challenging task of de - identifying the face of a patient who has undergone an MRI scan with the goal of producing a 3D image of their brain using the data from the scan as input. In the experiments, the authors show that their method is able to achieve better accuracy than two previous methods that are based on removing parts of the features but preserving the identity of the patient.    The main contributions of the paper are the following :   ( 1 ) The authors propose a method for obtaining 3D images of the subject's brain using only the features from the MRI scan ( face ). This is done by combining the features obtained from the scanner with the patient's privacy information ( the features are estimated using the information from the privacy label on the head ) and the privacy information of the subjects ’ features ( the privacy labels are obtained using the feature encoder / decoder in the same way as in [ 1 ]. The method is referred to as “ GAN ” ( “ Generative adversarial approach ” ). ( 2 ) The paper compares the proposed method with two other methods based on the removal - based method of GAN and the GAN method based on privacy - sensitive GAN. The paper shows that the proposed approach generally outperforms the other two methods in terms of accuracy when it comes to the number of features that need to be de - identified and the amount of information that needs to be removed / obscured ( in the privacy terms ). However, the paper also shows that in some cases the approach does not provide as good a privacy protection as the other methods do. ( see [ 3 ] )   [ 4 ] The main contribution of this paper is the introduction of the “ 3D GAN framework ”, a multi - scale, multi - headed combinatorial approach to de - identify the face using the brain scans of a single patient. The procedure is described in more detail in [ 5 ], which explains how the authors came up with the idea and the procedure that they use to achieve this goal. It is important to note that the procedure is not meant to replace the original MRI scanner ( which is used to identify the patient ), but rather to augment the original scanner with additional information that can be retrieved from the patient ( such as the location of the"
SP:0ac3964bd2320341488476d60f57b75d2a79f92c,"This paper proposes a new graph graph pooling method based on multi - head attention based global pooling. The proposed method, Graph Multiset Transformer ( GMT ), is based on the idea that obtaining an accurate representation for a graph requires a pooling function that maps a set of node representations into a compact form, which may be simple sum or average over all node representations, considering all node features equally without consideration of their task relevance, and any structural dependencies among them. The presented method is a generalization of node pooling methods that can be extended to the node clustering setting in the previous node - based pooling approaches for hierarchical graphs, and is evaluated on several graph reconstruction, link prediction, and graph generation tasks. The experimental results show that GMT significantly outperforms state - of - the - art graph pooled methods on graph classification benchmarks with high memory and time efficiency, and obtains even larger performance gain on graph reconstruction and generation tasks, and the authors claim that GMT is a powerful alternative to the previous graph node pooler methods and that it can be used as an extension of the previous pooling techniques.   The main contributions of this paper are as follows :   - A new graph processing layer is proposed to capture the interaction between nodes according to their structural dependencies, and measure the mutual information between two graphs that are distinguished by the Weisfeiler - Lehman test, as well as their mutual information about the graph structure. This is a multiset encoding problem that is formulated as a multi - headed attention problem, and a solution to this problem can be derived from the existing graph processing problem as well - known graph processing solversus. The authors propose a solution for this problem by first formulate the problem as a graph - to - be - graph encoding problem with auxiliary information about graph structure, and then solve it by a graph processing algorithm. - Theoretically, the authors prove that the proposed method is able to converge to a solution that satisfies both injectiveness and permutation invariance, such that it is at most as powerful as the so - called “ world - aware ” ( Wang et al., 2021 ) as the solution to the graph - isomorphism test. - Empirically, they show that the method converges to the global optimum solution in terms of both the number of edges and the average cross - entropy between nodes, and that the global optimality of the proposed pooling layer is better than the previous approaches as a result."
SP:76848e7ac3e6709e92f6a6db60269cb5177495d1,"In this paper, the authors propose a new explanation for the prediction performance of graph neural networks ( GNNs ). The authors claim that there is a bottleneck in the graph neural network modeling process that causes the message propagation from distant nodes to become difficult. This bottleneck causes the over - squashing of exponentially growing information into fixed - size vectors, leading to long - range interactions not propagating to the nodes at the origin. They show that GAT and GIN suffer from the same bottleneck, and that breaking the bottleneck improves the performance. They further propose a GNN model that is more resistant to over - sqashing than GAT / GIN and GAT+GIN, and they show that the bottleneck is caused by the distance matrices of the GNN training data. They also show that training GNN on GAT data reduces the likelihood that the model will over - squash a message from a distant node, which leads to a better performance. Finally, they study the effect of the magnitude of the bottleneck on the prediction accuracy of the model when the distance between nodes is less than a factor of 5.    The authors then provide experiments that compare the performance of their model to two other GNN models, one based on the GAT model and another based on GIN. They find that GIN outperforms GAT in terms of prediction accuracy when the bottleneck does not manifest itself in the training data, but GAT improves GNN performance when it does manifest."
SP:90d8fa381446923902e42b259392e5e975e6caa1,"This paper studies the problem of sentiment analysis of source - target sentiment generated by cross - domain ( domain - agnostic ) sentiment representations trained using data annotated in a source domain and trained to generalize well in a related target domain. The authors propose the idea of domain adaptation to mitigate the domain gap between different applications of generalizable classifiers trained to learn from source and target domain representations. This is achieved by matching the data distributions ( $ n$ for source and $ s$ for target ) in the source domain with those in the target domain to reduce the effect of “ domain shift ” on the performance of a trained classifier ( e.g., using the annotated source domain data ) in calculating sentiment scores for target samples. The main contributions of the paper are as follows :   ( 1 ) The authors introduce a new domain adaptation method that induces large margins between different classes in an embedding space based on the notion of prototypical distribution ( $ \mathbb{R}^n$ ) of source domain representations ( $ m$ ). This allows the proposed method to perform better than other domain adaptation methods that use individual data annotation for each domain representation. ( 2 ) They provide empirical analysis on two popular sentiment analysis datasets ( Amazon and Yelp ) to demonstrate that the method is effective in reducing the cost of training classifiers and that the margin is larger than the margin of the source adaptation method."
SP:893fd7440b82f5da0d4c0944928810322eaee2f0,"This paper investigates the bias in the NLI models trained on MNLI and SNLI data - sets based on gender stereotypes. It proposes a methodology to measure the biases by constructing a challenge task that pairs gender - neutral premise with a gender - specific hypothesis. The task is designed to be able to detect and evaluate the biases in the models. The paper presents results that three models ( BERT, RoBERTa, BART and BART - MNLI ) are more prone to bias than two other models ( SNLI and BERT ). It also proposes debiasing techniques such as augmenting the training dataset with a dataset that is gender - balanced to reduce bias in certain cases. The main contributions of this paper are the following :   1. The introduction of the “ gender bias detector ”, a machine learning - based machine learning algorithm that predicts the probability of a given observation being male or female based on a given set of occupations. This machine learning method is based on the fact that it is easier for the machine learning algorithms to predict female - based observations since it does not require access to personal details of the occupations. The resulting machine learning classifier is able to distinguish between true and predicted female observations more accurately. 2. The use of the gender biased machine learning model as the subject of the challenge task is investigated and the results are reported. It is found that the bias is more prevalent in the cases where the model was trained on a dataset where the assumed target task is male - female. However, it is less so for the datasets. 3. The evaluation methodology is used to investigate the prediction errors of the three models and debiased techniques are used to reduce the bias. The experiments are presented to demonstrate the effectiveness of the proposed evaluation methodology."
SP:a32ab755bd249c393b70938036ce8e810c0c439f,"Gregor et al. ( 2017 ) proposed VIC ( Value Intrinsic Control ( VIC ), an unsupervised reinforcement learning method for finding the largest set of intrinsic options available to an agent in a stochastic environment. In this paper, the authors revisits VIC and two variants of it, one which represents the options explicitly and one that does it implicitly, and they show that the implicit representation of the options in the former is biased, leading to suboptimal convergence in the latter case. To address this, they propose two methods based on the transitional probability model and Gaussian mixture model, i.e., one that represents the transition model options explicitly, and the other that is implicit in the case of the former. The first method is motivated by the fact that the Gaussian model is biased in the transition case, while the VIC method is not. The second one is motivated from the observation that the Alpha - Gaussian method converges to a lower bound on the posterior distribution of the transition probability, which is biased towards the higher distribution. The authors prove their theory using a series of experiments, including ( 1 ) Bayesian methods, ( 2 ) conditional Bayesian method, and ( 3 ) a mixture model - based method.    The main contributions of this paper are the following :   1 ) The authors revisit the idea of variational intrinsic control ( VI ) and show that there exist variational distributions of intrinsic rewards that are biased towards a particular transition model distribution, and that this bias is more prominent in the alpha than it is in the gaussian distribution. This bias results in a lower posterior distribution for the Alpha model, and vice versa for the Mixture model. 2 ) They propose to use Gaussian distributions to approximate the intra - transition distributions in order to get rid of the bias in alpha, and use the weighted average Gaussian distribution as the reward in the variational distribution. They show that this helps close the gap between alpha and beta distribution. 3 ) They show empirically that the proposed methods converge to lower bound lower bound values for alpha, where lower bound is closer to the upper bound."
SP:b4df2c4627a6d46c5100133e38c4bea20b296dd8,"This paper studies the ensembling method for learning from a relatively small dataset using a few labeled examples per class and a few class labels per class. The authors propose to improve sample efficiency in the low - data regime of image classification by using an ensemble of relatively small deep neural networks ( ENsembles ). The ensembles are trained on a small dataset of image classifications, where each class is represented by a set of class labels and the trained ensembled class is the average of the class labels of all other class labels. The ensemble is trained using supervised and unsupervised methods. The main contribution of this paper is to investigate the effectiveness of the ensemble method, DeepEnsembles, on classification problems with a small set of labeled class labels ( low - dimensional class labels ), and to show that it outperforms the state - of - the - art methods ( DeepGAN, DeepGAN - ensemble, and others ) when learning from small datasets using a fixed computational budget ( $ \epsilon$ ).    The authors first provide a comprehensive review of the history and development of Ensembles in the context of learning from very small datasets, starting with the original DeepGAN paper ( Liu et al., 2019 ). This review is expanded and extended to include several recent developments in image classification, such as the use of neural encoders, classifiers, and classifiers trained with synthetic class labels, and use of synthetic datasets ( CIFAR, MNIST, Fashion - MNIST ). During the review, the authors consider three different ensemble configurations ( Densemble, DenseNet, DeepNet, and Densemb, and DeepEnsemble ). They compare the performance of all of these methods across different loss estimations ( $ M$, L_N$, M$$, and L_DenseNet with respect to their respective performance on the small - sized dataset ( with and without labeled class label, and with a fixed number of classes / samples per class ). In particular, they consider the ensemble of Densebenches DenseEnsemble with DenseGAN and DeepNet - Dense(M ) as the default settings ( M = M-1, D_n, M_densemble(M, N_s, N ), where N is the number of class examples per encoder/decoder in the ensemble and D_s is the size of the dataset ( M is the total number of samples / classes, N represents the average class size ). To assess the performance on image classification with a limited number of labeled classes per class, they use the following loss estimator : $ \eps1 $ ( M=m$, N-1 < M-denseEnsemblenet M=M-1 $, N=m"
SP:4a0ee01f4897efa81659f37ef0468ee8195bbc4f,"This paper proposes Sparse Binary Neural Networks ( SBNN ), a method to introduce sparsity in BNNs by using positive 0 / 1 binary weights instead of the -1 / 1 weights used by state - of - the - art state - based quantized neural networks ( SNNs ).    The main idea of the method is to train a sparsity auxiliary network ( auxiliary weights ) to increase the compressibility of the BNN while reducing the number of operations of the network. The training consists of two steps : ( 1 ) train the auxiliary network and ( 2 ) update the weights of the SNN with the sparsity generated from ( 1) training. The first step is to fine - tune the parameters ( i.e., use $ \ell_2$-1 $ sparsity ; the second step is the addition of sparsity to the weights generated from the ( 1 / 1 ) training step. The sparsity is trained using gradient - based gradient clipping. The authors evaluate the effectiveness of their method using experiments on linear and convolutional networks over MNIST and CIFAR-10. The experiments show that SBNNs achieve high compression rates and good generalization with a small number of parameters, while achieving a similar or slightly lower compression ratio than SNN. The method is also able to achieve a small reduction in the total number of network operations, which is similar to that of SNN but with sparsity. The main contributions of the paper are the proposed sparsity method and the experimental results that show that the proposed SBNN can achieve a higher compression ratio compared to BNN."
SP:5be8539ad02595ad3c7a2d7afe8cbb3e9924467d,"This paper proposes a post hoc calibration method for model calibration on out - of - distribution ( OOD ) data for deep learning with machine learning ( ML ) models. The main idea is to estimate the probability that a model prediction is correct based on the outputs of the model and class membership as surrogate for class membership. The method uses outlier exposure to properly calibrate the model probabilities. It compares the Brier score ( Brier et al., 1983 ), other calibration measures ( including the expected calibration error ( ECE ) ), temperature scaling ( Hendrycks & Gimpel, 2015 ), dropout ( Gal & Ghahramani, 2016 ), and model ensembles ( Lakshminarayanan et al, 2017 ), as well as Stochastic Variational Bayesian Inference ( SVBI, 2019 ). The paper shows that the proposed method significantly improves on benchmark results.    The main contributions of this paper are the following :   1. A new method for estimating the model ’s confidence ( or uncertainty ) about the class prediction it should be confident in about the result of a machine learning model ( Predictive Uncertainty ). This is similar to the approach in [ 1 ], but it differs in that it uses the model outputs instead of the outputs. The key difference is that the latter uses the output of a neural network to compute the uncertainty, while the former uses the temperature of the class predictions to estimate how confident the model should be with respect to the class labels. This allows the method to handle uncertainty on OODP data where the model output could be very different from the predictions on other data. 2. A key idea of the method is to use the same softmax ( softmax p(x ) = softmax(f(f)(f ), where f is the number of class labels and p(f ) is the dimensionality of the distribution over all possible class labels produced by the model using the class distribution. The idea is that if the distribution is too large ( for example, for OOD data ), the model will overfit to the distribution too quickly, leading to worse class predictions. 3. The calibration error is measured by dividing the data into bins based on pmax = maxi p softmax i, where i.e., each bin contains 5 classes, and each class corresponds to a p(maxi psoftmax i ) where p("
SP:ea503f67e38fce7dee9cc4996b55b8959911f030,"This paper studies the expressive power of graph neural networks and graph kernels in solving machine learning problems on graphs from an empirical perspective. Specifically, it compares the graph representations and similarities produced by these algorithms against those generated by a wellaccepted, but intractable graph similarity function, which is the ability of these approaches to distinguish non - isomorphic graphs. This paper also investigates the impact of node attributes on the performance of the different models and kernels. The results reveal interesting findings, which suggest that theoretically more powerful models do not necessarily yield higher - quality representations, while higher - powerful graph kernels may yield more expressive representations.   The main contributions of this paper are as follows :   1. The authors develop a new empirical perspective of graph similarity between two sets of graphs, graphs K and L, and graph NNs and graph Kernels. The motivation is that there is often a need for algorithms whose produced graph representations can accurately capture similarity / distance of graphs in order to solve graph classification tasks, e.g., for instance, identifying which nodes in a graph are most likely to contain information relevant to a particular graph. This empirical perspective allows the authors to study this expressive power mainly of graph NN / GNNs and graph kernel expressive power to a lesser extent of graph GNN / GK. 2. They develop a set of graph kernels that can efficiently capture similarities between graphs. 3. They use these graph kernels to obtain graph representations that are expressive enough to handle similarity between graphs of different weights."
SP:0cf7b7d929f50e0b7f4fda5e1f68e5ade2f7c29b,"This paper proposes a novel method for augmenting the source image of a self - supervised image animation ( SIA ) generated from a static still image by warping it according to the motion of the driving video and recovering artifacts caused by inpainting. The proposed method, called PriorityCut, is based on the idea that traditional SIA image generation methods, such as CutMix, are unable to generate source images that are similar to the driving images due to the large pose differences between them and the fact that they do not use explicit pose references as an input. To alleviate this limitation, this paper proposes to augment the source images of SIA with the warping artifacts recovered from the driving videos by a method called “ priority cutting ”, where the source and the target region of the target image are augmented with the corresponding corresponding in -painting artifacts by a discriminator whose task it is to predict the locations of the artifacts from the inpainted source images given the current state of the art SIA methods. The method, named priority cut, is evaluated on a set of image datasets, where it is compared with previous methods ( CutMix and CutMix - GA ) and shows that it is better than them in terms of quality ( on average it is slightly better than CutMix but worse than the previous methods when it comes to generalization to higher - resolution images ) and generalizes better to lower - resolution and longer - range images ( compared to CutMix ). The experiments show that the proposed method is able to generate higher quality source and target images without loss of details. The main contributions of this paper are the following : ( 1 ) Prior to this paper, SIA was regarded as one of the slowest methods to generate high - quality source images from a still image ; ( 2 ) it is the first SIA method to be applied to a moving image generation task without any data augmentation ; ( 3 ) it was the first to introduce the concept of priority cutting and use it to augment source images for the first time to improve the quality of the generated target images ; ( 4 ) it has the first of two sets of experiments with SIA ( with priority cutting ) and with cutting. The experimental results show that in general, with the proposed approach, the generated source images look better and target objects look worse than when warping source images and that using priority cutting leads to better quality target objects.    The paper also includes a detailed discussion of the assumptions of the methods used for the method and its limitations, which include the importance of the"
SP:60b535fc6cbc1a7a26ad53f706ebb17de346dc4f,"This manuscript considers independent causal mechanisms ( ICM ), which directly model multiple data generation processes ( mechanisms ) in a coarse granularity. The goal is to learn a model that disentangles each mechanism and approximates the groundtruth mechanisms from observational data. The authors outline sufficient conditions under which the mechanisms can be learned using a single self - supervised generative model with an unconventional mixture prior, simplifying previous methods. Moreover, they prove the identifiability of the mechanisms w.r.t the mechanisms in the self - supervision scenario. They compare their approach to disentangled representations on various downstream tasks, showing that our approach is more robust to intervention."
SP:44d4e24428d043a69b40013919cda0e8e7bff99c,"This paper proposes a domain adaptation strategy to learn f : U → W where we have a fully mediating representation V such that f factors into U → V → W, but observing V requires detailed and expensive labels. The authors propose graph aligning approach that generates rich or detailed labels given normal labels W. First, they investigate the scenario of domain adaptation from the source domain where they have access to the expensive labels V to the target domain where only normal label W are available. Next, they show that after domain adaptation, the model is able to detect some compound types that were never seen in the original source domain. Finally, on the Maybridge data set, the proposed self - labeling approach achieves higher performance than the current state of the art.   The empirical results show that, using only 4000 data points, we obtain up to 4x improvement of performance after adaptation of the model from source to target domain compared to pretrained model only on source domain using only the labels from source domain only on the pretrained imagenet. However, if the assumptions are correct, the performance should allow the machine learning model to be more interpretable and interpretable, generalize generalize and be more data efficient at training time. In this paper, the fully - connected layer is represented using the embedding of the chemical graph structure we are predicting using the planar embedding from 2D images. The use of a fully connected layer implies some assumptions on the assumption on the mechanism of the underlying process, but if the assumption is correct, then the learning should be able to interpretable more interpretably and generalize better. The main contributions of this paper are the following :    1. The goal of the paper is to develop machine learning models that can predict molecular graph structure ( W ) given a 2D image of a chemical compound ( U ). This is a challenging problem in machine learning. 2. The problem of predicting chemical compound graphs from 2 D images can be simplified and simplified to obtain a parametric representation of the graph structure. 3. The major contribution of this work is the fully connecting the source and target domain representations. 4. The second major contribution is the method for domain adaptation."
SP:ad906dd9a176cffd283593321ff6b9ad19595528,"This paper proposes a nonlinear neural network framework to solve the chiller plants energy optimization problems. The authors claim that the energy consumption estimation of most chillers can be physically viewed as an input - output monotonic problem, i.e., energy consumption can be represented as input x output with max - pool constraint. Thus, the proposed framework can design a neural network that mimics the physical behavior of the system. The proposed framework is based on the domain knowledge in the structure and loss design of deep networks to build a non - linear model with lower redundancy function space.   The authors verify the proposed method in a cooling system of a data center, and experimental results show the superiority of the framework in energy optimization compared to the existing existing ones. The main contributions of this paper are the following :   1. A new nonlinear energy modeling framework based on domain knowledge is proposed for the energy optimization problem. 2. The method is compared with the existing linear models and two deep learning methods. 3. Results show that the proposed model outperforms the existing methods in most of the cases."
SP:6cb65ee5d2926858570601eeeade24fe86c7f32f,"This paper proposes a causal attention mechanism for multi - horizon, multi - task, and multitarget predictions that selects important variables predicting variables via their correlations with responses of interest, such as supply and demand in ride - sharing platform. The authors integrate the causal attention with the Conditional Average Treatment Effect ( CATE ) estimation method in causal inference to obtain more interpretable predictions. The main contributions of this paper are the following :    1 ) The authors propose a novel and fast multi - headed attention - based attention mechanism that extends the fast - multi - head attention evolved from Taylor ( Taylor ) to O(V ) estimation from softmax, reducing time complexity 2 ) to V, where V is the number of nodes in a graph 3 ) and the authors further design a spatial graph fusion mechanism to significantly reduce the parameters ’ scale 4 ) A wide range of experiments is conducted to demonstrate the interpretability of the proposed method CausalTrans and to compare the error reduction properties of different components of the method.   The authors claim that the method achieves up to 15% error reduction compared with various baseline methods and outperforms the baselines by a large margin."
SP:223980a1954d626d90ff54d8dc61b5d85a6b349c,"This paper proposes a new unsupervised un - supervised learning framework called coupled mixture VAE ( cpl - mixVAE ), which consists of multiple interacting autoencoding agents ( individual agents ) operating on augmented copies of training samples to learn mixture representations, while being encouraged to reach consensus on the categorical assignments. The framework is formulated as a variational inference problem, and the authors benchmarked their approach on MNIST and dSprites, achieving state - of - the - art categorical assignment while preserving interpretability of the continuous factors. They then demonstrate the utility of this approach in jointly identifying cell types and type - specific, activity - regulated genes for a single - cell gene expression dataset profiling over 100 cortical neuron types."
SP:c982610ad28662c3bd13132abe1f7307d1a61b68,"This paper studies the characterization of G - steerable kernels in Cartesian linear models of generalized linear models ( GCNNs ), a new type of convolutional network ( CNN ) based on G - equivariance - regularized linear models. Recent work has shown that there exist kernels that satisfy an $ \ell_2$-equivariance constraint on the function $ \sqrt{G}$ defined over $ \mathbb{R}$, where $ R$ is the number of units in the network, and the $ \epsilon$ and $ n$ operators defining the units are the parameters of the network. In this paper, the authors try to characterize $ G$-steerable kernel spaces by drawing a striking analogy between the constraints of steerable kernels on the one hand and those of spherical tensor operators from quantum mechanics on the other hand.   The main contribution of this paper is to provide a general characterization of the kernel spaces for the practically relevant case of G(G ), which is defined as any compact group of units under the constraint $ \theta_1 $, that is, bounded by a set of equivariant functions. The characterization is built upon prior work ( Liu et al., 2018 ) that GCNNs with $ \nabla_2 $ regularization can be cast as networks with additional symmetry priors, i.e., with which we can obtain a more robust network that generalize well to cases where we do not have access to the underlying assumptions ( e.g., for instance, in the case when we only use cases 1 and 2 ). The main contributions of the paper are the following : ( 1 ) - This paper proposes a new characterization of $ G^'s kernel spaces, based on recent advances in the theoretical description of the GCNN ; ( 2 ) it builds upon previous work that shows that there exists a kernel space $ \cup(G)$ such that $ \sigma_0 $ \to R$ where $ \sum_{\theta}^2 $ is a symmetric function of a unitary unitary structure ; ( 3 ) this kernel space corresponds to a special case of $ \mu$-norm $ \Phi$, and it is shown that for any $ M$-regularized GCNN $ \hat{M}$ given $ \in [ 0, 1]$ a $ \gamma_t$ the kernel $ \sup_{mu } = \mu_t(G^\pi, \text{max}^\Phi\pi }, this kernel is steerable. ( 4 ) This paper extends the characterization from previous work to $ G$.    In particular, it first notes that $ G(M)$ is a compact group, and for $ M>0, $ \frac{\mu } \to M$, there exist kernel spaces $ \"
SP:7b2ea39069277ad0f4f79476a77ef84587a804d9,"This paper studies the effect of using selective classification in vision classification in settings where the errors are costly but the abstentions are manageable. The authors find that while selective classification can improve average accuracies, it can magnify existing accuracy disparities between various groups within a population, especially in the presence of spurious correlations. They study this behavior consistently across five vision and NLP datasets. Surprisingly, increasing abstention can even decrease accuracies on some groups. To better understand this phenomenon, they study the margin distribution, which captures the model ’s confidences over all predictions. For symmetric margin distributions, they prove that whether selective classification monotonically improves or worsens accuracy is fully determined by the accuracy at full coverage ( i.e. without any abstenions ).    The authors then show that selective classification uniformly improves each group on these models. On the other hand, selective classification with distillation can increase accuracy disparities on groups that are not represented well by the distillation - based generative models. They further show that increasing margin on symmetric distributions increases the accuracy disparity between groups. Finally, the authors conclude with empirical evidence that the effectiveness of selective classification depends on whether the distribution satisfies a property called “ full - coverage ”, which enables the model to perform equally well across groups with full coverage. This property is defined to ensure that the distribution satisfying this property does not lead to a decrease in accuracy on any one group that is not represented equally well by all other groups using the same classifier. The paper concludes with analysis that shows the importance of training models to achieve similar full coverage accuracy across groups and show that the best trained models achieve similar performance across all groups."
SP:f1d57ee27e901daf7e4e2b84139019e945818911,"This paper proposes a hierarchical nonnegative CANDECOMP / PARAFAC ( CNAP/CP decomposition ) topic modeling framework for large - scale data with complex multi - modal structure. It is realized that most multi - layer network data with hierarchical structure is likely to have latent hierarchical structure due to its large number of hidden sub - networks. This paper proposes to mitigate error propagation through hierarchical NCPD by training a neural network architecture and backpropagation to mitigate the non - negative error propagation of the hierarchical CNAP / CP decomposition. The main contributions of this paper are the following :   1. The authors propose a hierarchical not - negative CNAP decomposition, named Hierarchical NCPD, to capture the hierarchical latent structure of the topic distribution. This decomposition can be viewed as a hierarchical version of the CDP decomposition of the full dataset.   2. They develop Neural NCPD to train a topic model using neural networks to approximate the hierarchical topic distribution using latent tensor representations. The neural networks are trained using gradient descent, gradient ascent, and gradient clipping. The goal is to train the topic networks with a minimum depth of 4 layers and a maximum depth of 6 layers. The training of neural networks is done using gradient ascent and a max gradient descent method. The resulting topic models are trained with gradient descent and max gradient clipping, and then fine - tuned using gradient clipping to achieve a final accuracy of 7 %. The learned topic parameters are used to update the topic latent representations and the parameters of the neural network. This training procedure is referred to as Neural NC PDPM ( Neural Predictive PMPM ) training. 3. Empirical experiments are conducted to validate the effectiveness of the Neural PDPM training and to compare the performance of PDPM and PDPM. The experiments show that PDPM outperforms PDPM in most cases."
SP:b6ddc3a560aa7155e7e927bf5360bedc36586597,"This paper proposes the first collective robustness certificate for adversarial robustness testing on graph neural networks ( GNNs ). Specifically, the authors considered two settings : Graph Neural Networks ( GNN ) and leverage their locality property - based robustness certificates ( i.e., those that consider each prediction independently and are pessimistic about its robustness under perturbation ). They considered the setting where they shared a single input ( e.g., a graph neural network ), a node, an image, or a document. The authors proposed to fuse multiple single - node certificates into a much stronger collective certificate. They defined the robustness condition as the number of predictions that are guaranteed not to be modified by adversarial perturbations that are at least as large as those guaranteed by the original classifier ( assuming that the perturbed input is the same as the one shared by the network ).   The authors considered three settings : ( 1 ) Graph NNs, ( 2 ) Graph Neurads, ( 3 ) Leverage NNs. The idea is to use the same classifier for both GNN and leverage NNs to obtain a more robust classifier when perturbed inputs are obtained from a shared network. The main difference between the two settings is that the NNs are trained to output the same set of labels ( vector of labels ) for each input, while the leveraging NNs output a set of different labels for each query. This allows the authors to train multiple NNs simultaneously without losing any performance on the query that is attacked ( as is the case when using different NNs for the different labels ). For the experiments, they used the GraphNeuroNets with different batch sizes and batch sizes to train the classifiers. They compared to the previous works, they defined the per - batch size as the average number of NNs per batch size ( per query ), per classifier, per query and per query label. They also defined the threshold for robustness ( upper bound ) of $ \epsilon$ for the maximum number of instances that are robust even if the query labels are not modified by the adversary ( lower bound is lower bound ). This is done by taking the same number of samples from each NN as in the previous work, but splitting them into separate batches of $ n(1, 2 ) samples from the same batch. For example, for the graph NN with a batch size $ M$ ( M=7, M=8 ) they split it into two batches ( M-1 and M-2 ) where M= 7 and M= 8 for the sample size M in the first batch is the max margin ( M"
SP:cc93dd2f68e415e2457166e78627865dc1b44697,"This paper proposes Quantile Regression GAN ( QRGAN ) to tackle mode collapse and gradient explosion problems of training discriminative generative models. QRGAN is a variant of least squares GAN and Wasserstein GAN, which are two variants of GANs that aim to mitigate the non - convergence and mode collapse issues of training generative adversarial models. In this paper, the authors first analyze the mode collapse problem of LSGAN and cause mode collapse of WGAN by analyzing the loss functions of these two variants. They show that LSGAN suffers from local minima and causes mode collapse while WGANs suffer from inefficient computation and slow training due to its constraints in Wassersteins distance approximation. Then, they propose QRGAN, which suffers from high robustness against mode collapse. Next, they evaluate QRGAN for generation performance assessment using Frechet Inception Distance ( FID ). They find that QRGAN outperforms WGAN and LSGAN in terms of robustness and performance. Finally, QRGAN has an apparent improvement in the evaluation and comparison of generation performance on CIFAR-10 and Tiny - ImageNet."
SP:4ddb47ee77c374ae6c3e419412d92ca77260692e,"This paper studies the problem of explaining the predictions made by machine learning models ( MLM ) with similarity explanations. The main contribution of this paper is to develop and evaluate relevance metrics to explain the predictions of MLM. The relevance metric is defined as the ratio of the cosine similarity of the gradients of the loss with the output of the model in terms of the similarity with respect to the set of similar instances. The authors developed three tests to evaluate whether the relevance metrics satisfy the minimal requirements for similarity - based explanation. The first test is to predict the similarity between the outputs of two different MLM models ( e.g., Gaussian Processes and Gradient Descent ) based on the similarity in the loss gradients. The second one is to choose a similarity metric for the loss that maximizes the distance between the output and the prior instance of the predicted outputs. The third one is a measure of how close the similarity is between the examples in the two models that are used as support for the predictions. In the experiments, the authors showed that some metrics perform poorly in the tests and analyzed the reasons of their failure.    The authors hope that this study can provide insights to help practitioners in selecting appropriate relevance metrics and also aid further researches for designing better relevance metrics for explanations. In particular, they focus on the importance of using similarity metrics that provide reasonable explanations to users."
SP:6c2cbf2bc0f6dabe974e80ec1e82d2d12189906e,"Graph Neural Networks ( GNNs ) with the Low - rank Global Attention ( LRGA ) module ( Vaswani et al., 2017 ) improves their generalization power. The motivation for adding the LRGA module is to improve the computation and memory efficiency of the dot - product attention ( PPO ), which is computationally and memory efficient. The authors theoretically show that adding LRGA improves the generalization properties of general graph neural networks with the 2 - FWL ( 2 - Weisfeiler - Lehman algorithm ). They also show that the alignment between existing GNN layers with LRGA and those augmented with the new LRGA produces state of the art results in current GNN benchmarks. Finally, they compare various GNN architectures with and without LRGA on several graph isomorphism tests and show that LRGA often closes the performance gap between different models.    The main contribution of this paper is to propose and develop a low - rank global attention module that can be added to Graph Neural Networks for improving their generalizability power. They use it to parametrize the generalisation properties of PPO in a family of expressive Graph Isomorphism Tests ( GITs ) that they study. They show that it provides algorithmic alignment to a powerful GIT variant that is more expressive than the original PPO and is more computationally efficient than the dot product attention. This allows them to theoretically quantify the generalized properties of the generalised GIT and generalize it to other GNN families. They provide empirical results that show the performance boost from using LRGA compared to not having it. The paper also provides theoretical justification for why the added LRGA helps improve the performance of existing GIT models compared to the un - added to PPO. The experiments are presented in Table 2, which compares the impact of having LRGA to having a fixed number of layers in a GNN and a random graph neural network and shows the benefits of using it compared to having no LRGA. They study the effect of adding and augmenting two GIT layers with the newly proposed LRGA modules as well as augmenting existing layers of a random GNN with the PPO module. They compare the performance gain compared to that of using the fixed GIT layer and show the advantage of adding the additional LRGA in generalization. In the experiments, the authors show that using the extra LRGA layer improves the performance by an average of"
SP:b4abdd28504b4c1de239eabd4e0e27d370efee71,"This paper proposes a new method for improving the calibration performance of CNNs ( Convolutional Neural Networks ). The proposed method is based on the idea that most existing approaches to CNN training use random crops on the images during training and only provide the classifiers with background only samples. This leads to dependence on context, which is harmful for safety - critical applications. To address this problem, the authors propose to train CNNs using label smoothing during training that combines the ideas of object - based object - likeness and label - based smoothing. To this end, they propose to compute a smoothing factor that is adaptive based on relative object size within an image to the one that is most likely to be localized. This is different from previous approaches that do not penalize inability to localize an object, nor do they take into account an object’s relative size in the given image.   The proposed approach is tested on MS - COCO and compared to the hard - label approach. Results show that CNNs trained using the proposed method are much less likely to make predictions that are inaccurate or inaccurate close to the predictions made using the hard label approach, while also being able to make correct predictions on context - only images when compared to baselines. Comparisons are also made using class activation maps and quantitative results using classification and transfer learning tasks. The results show that the proposed approach leads to an order of magnitude reduction in confidence when predicting on context only images compared to baseline CNNs. However, results are not compared to other methods that use class labels."
SP:5254658923e594294b69d124a8d004166852822a,"This paper proposes a dual neural network ( DNN ) for inverse problems where the underlying neural network is a two - layer fully - convolutional ReLU denoising network with weight decay regularization as the regularizer ( weight decay induces path sparsity while the prediction is piecewise linear filtering ). The proposed DNN is a special case of the convex duality framework proposed in ( Xie et al., 2019 ), which is also applicable to non - convex neural networks used for medical imaging. The authors show that the proposed DPN can be trained with DNN solvers ( Yin and Yang, 2017 ), and that it outperforms the naive convex methods ( Yin & Yang, Wang, et.al., 2018 ). Experiments on MNIST and FastMRI datasets confirm the efficacy of the proposed method."
SP:085cad6bc143c8713580bddfaa71f06496dac314,"This paper proposes a new method for generating speech synthesised from text or phonemes. The main focus of the paper is on synthesising speech sounds from character or phoneme sequences. This is done by using a differentiable alignment scheme based on token length prediction, which learns to produce high fidelity audio through a combination of adversarial feedback and prediction losses constraining the generated audio to roughly match the ground truth. To allow the model to capture temporal variation in generated audio, the authors employ soft dynamic time warping in the spectrogram - based prediction loss. The resulting model achieves a mean of 4.4 on a 5 point scale, which is comparable to the state - of - the - art GPT-50 model ( Zhang et al., 2018 ).   The main contributions of this paper are the following :   1. A new speech synthesizer model that learns to synthesise speech from character / phoneme input sequences using an end - to - end manner, unlike existing models which operate directly on character / phrase input sequences and produce speech audio outputs. The proposed generator is feed - forward and thus efficient for both training and inference. 2. An adversarial alignment scheme to train the generator. 3. A temporal variation capture strategy to learn the parameters of the discriminator."
SP:01148cea55db606aa78d27e900818684a8bce9ab,"This paper proposes the Wasserstein graph diffusion ( W3DP ) method to obtain information of both the topology structure and attributes of nodes from their local neighborhoods. It starts from a decomposition of the attribute matrix and transforms the node features into discrete distributions in a lower - dimensional space equipped with the WASSERSTAN metric. On this space, it proposes Wasserstein graph diffusion to smooth the distribution representations of nodes with information from the node's neighbors. This allows us to reduce the distortion caused by missing attributes and obtain integrated representations expressing information of the structure of both attributes and topology of the nodes. Then, to demonstrate the effectiveness of the method, it designs two algorithms based on on it for node classification ( with and without missing attributes ) and matrix completion. The first one is used to re - partition the nodes back to the original space and produce corresponding point representations to facilitate the downstream tasks. The second one uses the obtained representations to enhance the performance of the first one. The experiments show that the proposed method works better than baselines and baselines.    The main contributions of this paper are as follows. First, the authors propose a general non - parametric framework to mitigate the missing information problem of attribute matrix in node representation learning approaches. Second, they propose a distribution distillation method based on Wasserststein metric to smooth node distribution representations. Third, they show the effectiveness in experiments to evaluate the two algorithms used for distillation ( based on the obtained from the first method ) and producing point representations."
SP:aeeb5909f7123ef631f569b469af9715205c881f,"This paper proposes AMIGO, a method for reinforcement learning ( RL ) with sparse extrinsic rewards. The goal is to train a goal - generating teacher to propose increasingly challenging yet achievable GOals that the student can learn general skills for acting in a new environment, independent of the task to be solved. The teacher adopts a meta - learning approach where it considers the task as a learning objective and the goal as a reward function. This is done by training a neural network that predicts the student policy in the absence of ( or in the presence of ) the task and using a combination of the teacher ’s goal - conditioned policy and the learner's policy. The network is trained to generate GOals when the teacher fails to achieve the goal.   The main contribution of this paper is the method for training the neural network to generate goals that the teacher can then use to solve the challenging tasks that were originally proposed by the teacher to the student. The method is evaluated on a mini - task in the lab and larger task in a supervised learning setting. The experiments compare the proposed method with other methods for intrinsic motivation, state - of - the - art RL methods, and show that the proposed approach generally outperforms them in terms of generalization ability when compared to the baselines. Ablation studies are performed to evaluate the effectiveness of the method."
SP:3d05bc7dca97681cb582298e318b9b973841eed3,"This paper proposes a data - driven retrieval method, where a user can request a file from a dataset of files under both a user distortion and a user privacy constraint, and the identity of the requested file can be kept private from the server under a privacy constraint. The idea is to design a method that can be seen as an extension of the well - known concept of private information retrieval by allowing for distortion in the retrieval process and relaxing the perfect privacy requirement. The paper proposes to study the tradeoff between the rates of download rate, distortion, and user privacy leakage between source coding and the proposed data driven method. They evaluate the performance of the scheme on a synthetic Gaussian dataset as well as on the MNIST and CIFAR-10 datasets. The results show that the data driven approach significantly outperforms a general achievable scheme combining source coding with the download of multiple files, while the performances are comparable to the one obtained with CIFar-10.   The main contributions of the paper are the following :   1. The authors develop a learning - based retrieval method that, under the assumption that the dataset size is not too large, allows for a concise information - theoretical formulation in terms of mutual information with respect to the privacy constraint that is relaxed to facilitate the use of the proposed method. 2. They propose a new data-driven framework by leveraging recent leveraging recent advancements in generative adversarial models which allows a user to learn efficient schemes in terms   of the download rate from the data itself. 3. They provide the empirical evidence that the optimal rate - distortion - leakage tradeoff is convex, and show that in the limit of large file sizes, a rate of less than 1 % is optimal. 4. They also propose a privacy - aware adversary that tries to infer which file the user is interested in under a distortion constraint."
SP:3f9e2db00fc3dcd7a40588adcb638503ec10dc09,"Graph Neural Networks ( GNNs ) have become very popular for graph - related applications due to their superior performance. However, they have been shown to be computationally expensive in large scale settings, because their produced node embeddings have to be computed recursively, which scales exponentially with the number of layers. To address this issue, several sampling - based methods have recently been proposed to perform training on a subset of nodes while maintaining the fidelity of the trained model. In this work, the authors introduce a decoupled greedy learning method ( DGL - GNN ) that, instead of sampling the input graph, decouples the GNN into smaller modules and associates each module with greedy auxiliary objectives. The proposed approach allows GNN layers to be updated during the training process without waiting for feedback from successor layers, thus making parallel GNN training possible. The authors also propose a lazy - update scheme during training to further improve its efficiency. Experiments are conducted to evaluate the effectiveness and superior efficiency of the proposed approach under a range of experiments. The main finding is that compared to the sampler - based acceleration method, our method achieves improved efficiency without significantly compromising the model performances.   The main concern of mine is that the proposed method may not be suitable for applications where the model is very different from the one used in training. For example, in the case of graph neural networks, the model might not be robust enough to distinguish real - world graphs from simulated ones. To alleviate this concern the authors propose to use the simulated graph from a simulated GNN model to train the model. The training procedure for this model is similar to that used in the training of the original GNN. The only difference is that instead of training the model with simulated graphs, the training instead trains the model using simulated graphs."
SP:5ecb1b288f7fc02aead4493f81640867bc349290,"This paper proposes a framework for efficiently answering queries on incomplete Knowledge Graphs using neural link predictors. The authors translate each query into an end - to - end differentiable objective, where the truth value of each atom is computed by a pre - trained neural link predictor. They then analyse two solutions to the optimisation problem, including gradient - based and combinatorial search, and compare their approach with state - of - the - art methods, black - box neural models trained on millions of generated queries — without the need of training — on a large and diverse set of complex queries. The experimental results show that the proposed approach produces more accurate results than either of the two optimization approaches. Finally, the authors demonstrate that it is possible to explain the outcome of their model in terms of the intermediate solutions identified for each of the neural models that worked well in the experiments."
SP:f04a522fd04c503754fdb8c52da68646d31271a4,"This paper proposes a procedure for checking local robustness in feed - forward neural networks with piecewise - linear activation functions. The key idea is to partition the input space into a set of convex polyhedral regions in which the network ’s behavior is linear, and then search for decision boundaries within the regions around a given input point sufficient for assessing robustness. The method assumes that all inputs within an `p - ball consistently, which precludes various forms of adversarial inputs. The authors propose to implement the robustness checking procedure using a highly parallel GPU implementation that excels particularly for the $ \ell_2 $ norm, where previous work has been less effective. They show how the region around a point can be analyzed using simple geometric projections using a single GPU implementation. They find that the proposed method is more precise than many approximate verification approaches while at the same time performing multiple orders of magnitude faster than the naive early estimators. An implementation of the proposed algorithm is available on GitHub.    The main contributions of this paper are the following :   1. The paper proposes to implement a robustness checker that can be used to assess the local component of the piecewise activation function used to determine the degree of robustness of a neural network's piecewise activations. The idea is simple and straightforward. It can be viewed as an early version of an early - stage probabilistic neural network with a linear activation function. The main difference from the previous work is that the authors state explicitly that they do not require the output of the activations to be piecewise robust. This does not imply that the activation function is piecewise independent of the input. This is not stated by the authors, but is merely implies that there is a piecewise connection between the activation and the input that connects the input to the region of the function that the function is being tested for robustness ( which is not necessarily the case in the case of the network with linear activations ). They use the phrase “ regionally robust ” to refer to the set of regions in the neural network that are not too different from the input regionality in terms of the decision boundaries. The regions can be defined using a simple geometric projection, and the authors show that the regionality can be represented using geometric projections. They also show that a simple, highly parallel, GPU implementation of their proposed algorithm can be more precise ( with respect to the geometric projections ) than previous work ( using multiple GPU implementations of the activation functions ). In the experiments, the authors demonstrate that their proposed method allows them to obtain robustness values for a small number of inputs that do not appear in the output range of the neural networks they test."
SP:5297651ff873f97c07b9c47ed3eff52251661844,"This paper proposes an embedding of objects in an affordance space, in which each dimension corresponds to an aspect of meaning shared by many actions, using text corpora. The embedding makes it possible to predict which verbs will be applicable to a given object, as captured in human judgments of affordance, better than a variety of alternative approaches ( e.g., quantifying the extent to which actions rely on, have an effect on the properties of the object ). The dimensions learned are interpretable, and that they correspond to typical patterns of interaction with objects. Finally, the dimensions can be used to predict a state - of - the - art algorithm to estimate the state of an object from the trajectory of its nearest neighbors.   The main contribution of this paper is a new embedding method for representing affordance in a text - based model. The core idea is to use language to represent the relations between the actions that can be performed on an object, and the extent in which they depend on, or have effect on, the object. This is different from previous affordance approaches that use symbolic representations of the actions. The key idea of the embedding is to firstly represent the space of actions and relations in terms of dimensionality, and then use the learned dimensionality to represent relations between actions and the objects in the space. This allows the embeddings to be used for inferring relations between states and actions based on the actions, and vice versa. The main contributions of the paper are the following :   ( 1 ) -   1. An approach for representing the actions in a language - based affordance model using symbolic representations as representations of objects. This approach is evaluated empirically ( with experiments ), and compared to the following ( which uses symbolic representations and the representations as input to the affordance representations ;    2. A more realistic ( and potentially more interpretable ) embedding - based approach - based on symbolic representations - is evaluated and compared with the proposed embedding. It is shown that the learned embedding, although it is not as interpretable as the one in the paper, is at least as effective as the first one ( and possibly more so ) in predicting relations between verbs and interacting with the objects."
SP:72b4f3b40c6c6fa2eb53e95ed9a10a4077ffa049,"This paper proposes a method for the emergence of individuality ( EOI ) in multi - agent reinforcement learning ( MARL ) by learning a classifier that predicts a probability distribution over agents given their observation and gives each agent an intrinsic reward of being correctly predicted by the classifier. The intrinsic reward encourages the agents to visit their own familiar observations to learn the classifiers predictions which in turn makes the intrinsic reward signals stronger and, in turn, classifier predictions more identifiable. The method proposes to use two regularizers : ( 1 ) to increase the discriminability of classifier prediction from the agent observation and ( 2 ) to encourage the agent to self - introduce the predictions that are most plausible to the agent. The experiments demonstrate the effectiveness of the proposed method.   The main contributions of this paper are as follows :   - A new method for learning a probabilistic classifier is proposed for MARL that learns a probability classifier over agents from their observation ; - Two regularizers are proposed to enhance the intrinsic rewards for self - introducing classifiers to increase their predictability - The method is evaluated empirically on a suite of agent tasks and compared with a number of baselines. It is shown to outperform the baselines and outperforms other methods in terms of intrinsic reward and self - introduction of predictions."
SP:112509d6d3573a9d495d182fdfae6ec0327cddf5,"This paper studies randomized smoothed classifiers for certified robustness under l2 - norm adversarial attacks. It is not entirely resolved on how to find the optimal base classifier for randomized smoothing. In this paper, the authors propose Smoothed Entangled Entangled Models ( SWEEN ), a generality - generality based smoothing method that uses an ensemble of classifiers trained on the same data to estimate the robustness of the candidate classifier from the output of the ensemble. The ensembling method is based on the idea that the generality of the classifiers depends on the similarity of the input data, e.g., if the classifier outputs the same set of representations for all samples from a batch of samples from the same batch, then the representations produced by each batch are aggregated into a single set, and the aggregated set is used to train the final classifier. Extensive experiments are carried out to evaluate the effectiveness of SWEen. The main contributions of this paper are the following : 1. The authors develop and deploys an adaptive prediction algorithm to reduce the prediction and certification cost of the prediction algorithm that uses the ensemble method. 2. They show that using a few small classifiers with comparable performance to a single large classifier with comparable training time leads to comparable robustness to a model with a large margin. 3. They develop and apply a softmax classifier using the ensembled smoothed method to train classifiers that achieves state - of - the - art robustness."
SP:ea892e3d199ed6121279b20061a87f43afae8796,"This paper proposes Ordered Memory Policy Network ( OMPN ) to discover subtask hierarchy by learning from demonstration. The main idea is to use hierarchy to recover subtask boundaries from task decomposition in an unstructured demonstration. To this end, the authors study the inductive bias and propose a hierarchy induction method. Experiments on Craft and Dial demonstrate that the model can achieve higher task decomposability performance under both unsupervised and weakly supervised settings, comparing with strong baselines. The authors also propose a method called subtask network to discover hierarchy in partially observable environments while achieving similar performance as the main model.   The main contributions of this paper are as follows :   1 ) The authors propose a hierarchical learning method, based on induction, to discover a hierarchy of subtask tasks in a real - world setting. This method is referred to as subtask induction. 2 ) The proposed method is compared with other hierarchical learning methods, such as Hidden Hierarchical Networks ( HN ), in two experiments to validate the effectiveness of the proposed method. The experiments are conducted in two environments, one where the subask hierarchy is not known and another where it is known but the hierarchy is inferred from the task data. The results show that the subtask networks outperform the other methods."
SP:cc6aa977ce561a2493ae74bb694205cd67c8d890,"This paper proposes a semantic - semantic generative model for out - of - distribution ( OOD ) prediction based on a Causal Semantic Generative Model ( CSG ). The authors claim that traditional OOD prediction methods are sensitive to the semantic - variation factor due to their domain - specific correlation, while the CSG model only considers the semantic component. To address this issue, the authors propose to model the semantic and variation factors separately and use them to predict the output of a neural network from a single training data point, which is common and challenging.    The authors show that under certain conditions, CSG can identify the semantic factor by fitting training data, and guarantees the boundedness of the OOD generalization error. They also propose a novel design in variational Bayes for both efficient learning and easy prediction. Theoretically, they prove that if the training data contains only semantic information ( e.g., only semantic embeddings ), and the semantic information is extracted from the semantic embedding using a Gaussian Mixture Model ( GMM ), then the method is expected to be able to predict semantic output of an OOD instance with high accuracy. This is demonstrated experimentally in the case when training OOD instances are sampled from the Gaussian Variational Neural Network ( GMN ), which contains both semantic information and variation information. The methods are tested on real - world OOD examples and compared with standard supervised learning ( SSL ) and CSG - based methods. The results show that the proposed method is faster and more accurate than SSL for semantic output prediction of a given training data. The mainstay of CSG is the identification of the semantic identity of the difference between the output and the variation factor of the GMM model, which can then be used for future OOD predictions."
SP:be3f34a59e5e61dcdbc7cb085f031ba4a5a5b758,"This paper studies the problem of robust online learning with limited regret tolerance to adversarially corrupted rewards in multi - armed bandits, linear contextual bandits, and Markov Decision Processes ( MDPs ) with stochastic rewards under the assumption that the adversary can be arbitrarily corrupted with probability p(\sqrt{0, 12 } ). The main contributions are three - folds : ( 1 ) The paper considers the setting where the adversary receives a reward distribution $ \theta$ for each time step $ t$ from the online learning algorithm $ \mathbb{R}$, where $ p(t|\theta)$ is a random variable that can be either uncorrupted or corrupted. The goal is to design an algorithm that has small regret over a period of time steps ( while the algorithm observes corrupted rewards ) with respect to the true and corrupted rewards distribution.    ( 2 ) The main contribution of this paper is the following :   - First, the paper defines a robust setting for unsupervised online learning where the adversarial reward distribution can be obtained by using a random sampling from the distribution of rewards at each time point $ t$. This setting is considered in the setting when the algorithm has access only to a fixed amount of data points ( $ n$ ), and the policy is robust to a noise rate $ \nabla_y$ where $ y$ is the adversary's strength. The paper defines the noise rate as the ratio of the expected reward value when the policy has access to all training data points. The idea is to use this noise rate to design a robust policy that allows for learning with small regret in this setting. - The second part of the paper considers three different scenarios : 1 ) In each of these scenarios, the algorithm receives a fixed $ k$ reward distribution from the state - based learner ( the state is assumed to be aware of the hidden state of the state when making the prediction and the reward distribution is set. The algorithm first learns a policy that assigns a value to each hidden state variable $ k$. Then, the policy applies the policy to the hidden states of the policy. The policy is trained using supervised learning, where the policy gradient descent is used to train the algorithm and the underlying network. This policy is then used to update the policy at any time step to ensure that the policy does not deviate too much from the original policy. - In the third scenario, the proposed policy is applied to train a linear contextual bandit policy, which is a linear network with linear contextual inputs and linear contextual outputs. The approach is similar to the robust setting but the difference is that the algorithm does not require the user to disclose the linear labels of the inputs to the algorithm. This allows the algorithm to learn a linear distribution of the contextual inputs. - Finally, the authors study three scenarios where the opponent can be represented as a set of randomly distributed points, one of which is unknown ( the other two are linear and the other one is not known ) and the third one is a mixture of the two. In this setting the policy can be learnt by the policy and the environment ( the first one is the linear one ), so the algorithm needs to learn to distinguish between the real and the imagined states ( the latter can be learned from the imagined state ). This is done by training the policy by backpropagation and the others by forward propagation. The experiments compare the policy on synthetic data ( synthetic data ) and real - world data ( real world data ) where the"
SP:6d62a80aaebb2988df3953d4d7164e5a2fa1aa6d,"This paper proposes Rewriter - Evaluator ( REV - E ( PGD ), a framework to train a rewriter and evaluator for neural machine translation ( NMT ) with multiple passes of decoding. The rewriter produces a new translation every time the source sentence is translated to improve the past translation and the evaluators use their estimates of the translation quality to decide whether to terminate the rewriting process. PGD is a gradient descent - based method that facilitates training the rewriter to be able to handle gradient descent gradients. The authors conduct extensive experiments on two translation tasks, Chinese - English and English - German, and show that the proposed framework notably improves the performances of NMT models and significantly outperforms previous baselines.    The main contributions of the paper are the following : - The authors propose a framework that trains a re - writer and anevaluator jointly to improve source sentence translation. - They use the same encoder - decoder framework as in the previous works to train the re - writers and theevaluators jointly to decode source sentences. - Through experiments, the authors demonstrate that PGD with the proposed training procedure can significantly improve the performance of some model encoders compared to models trained with no training and without training at all."
SP:9761fca8848868dfc9cacdab2537f8276ca76e0f,"This paper proposes a two - stage adversarial training strategy for learning a multimodal predictive distribution of semantic segmentation labels from a toy regression dataset. The idea is to learn a distribution over predictions that captures the empirical distribution over labels, where the empirical frequency of the sampled predictions closely reflects that of the corresponding labels in the training set. The training consists of two stages. In the first stage, they explicitly model the data with a categorical likelihood, and in the second, they train an adversarial network to sample from it an arbitrary number of coherent predictions that can be derived from the training data. During the second stage, the training, the model is designed to be adaptable to handle tasks requiring learning a calibrated predictive distribution, such as learning of calibrated stochastic mappings.   The paper presents state - of - the - art results on the LIDC dataset and a modified Cityscapes dataset to demonstrate the utility and versatility of the approach by learning the approach. The main contributions of the paper include :    ( 1 ) The authors propose a novel two - step strategy for calibrated adversarial refinement of the learned model. The first step is to model data using a likelihood function. The second stage is to design a discriminator that can discriminate between a set of predictions that are drawn from the same distribution, and a set that is drawn from a distribution that is independent of the predictions. The discriminator is trained to discriminate between pairs of pairs of predictions. This discriminative classifier can be trained to distinguish between true and false classifiers. The true classifiers are trained to learn the true classifier from false classifier, and the discriminator trained on false positives is trained on true positives and false negatives. The core idea of this paper is to train a classifier that discriminates between false positives and true positives using the likelihood of the classifier and classifier. This is similar to what was done in [ 1 ], but different from [ 2 ]. The difference is that the original work uses classifiers to distinguish true positives from false positives, while this paper trains the classifiers on the true positives. The key difference between this paper and the previous work is the use of classifiers in the first step that discriminator to distinguish false positives from true positives, but the difference between the train and train - trained classifiers is not explicitly modeled with the likelihood. The experiments show that the proposed method is more robust to false positives than the previous approaches. The paper also presents results showing that the method is able to learn true positives for black - box segmentation tasks requiring such a learning."
SP:ce965758f1b795a56c02f45d6a8d06cb8bdf29cb,"This paper proposes communication with error feedback ( EF ) as a better alternative to error feedback for dealing with errors induced by contractive compressors, such as Top - K or PowerSGD, which are not unbiased compressors. The main contribution of this paper is a theoretical analysis of the error feedback mechanism of EF and the construction of a new technique to transform any existing compressors into an unbiased compressor. The construction of the new unbiased compressor consists of the following steps : 1 ) the author proposes a new algorithm to convert any existing contractive compressor into an induced unbiased compressor, such that the compressed error feedback from the induced compressor can be used to correct the error induced by the compressors ; 2 ) a new rule is proposed to prevent the gradient of the gradients produced by an induced compressor from becoming stochastic ; and 3 ) the authors propose a new method to coordinate the communication of gradients to reduce the communication cost of the compressed gradient. The authors carry out a series of experiments to validate their theoretical findings and to compare their proposed method with EF. The experimental results demonstrate that the proposed method leads to vast improvements over EF, including reduced memory requirements, better communication complexity, and communication complexity with respect to the number of workers. The paper also extends the results to federated learning with partial participation following an arbitrary distribution over the nodes, and demonstrate the benefits thereof. Finally, the authors conduct an ablation study to evaluate the effect of their proposed approach on the convergence rate of gradient communication with EF on large - scale machine learning tasks."
SP:4fd702490293e481c79614852ba27dd3ce9215a4,"Hyperparameter transfer across adjustments ( HT - AA ) proposes a new research framework to leverage knowledge from prior work to improve the performance of ML - based deep learning algorithms with respect to a new version of an existing hyperparameter optimization algorithm ( HPO ) developed by a different set of developers ( in this case, the changes to the hyperparameters in the original HPO after the developer adjustments are known ). The idea is to leverage the knowledge from previous work to inform the development of new HPO faster and with lower costs that benefit the user. The paper presents four baseline algorithms for the new method and benchmarks 8 algorithms that correspond to different versions of the classic HPO. The authors also provide python packages to help users develop the algorithms ( baseline and benchmarks ).    The main contributions of the paper are the following :   1 ) The paper proposes an extension of the original HT - A with the following modifications to the original problem formulation : instead of the standard two - stage optimization method ( step one in the HPO paper ), step two applies a three - stage method in which the optimization is applied step by step, starting at the end of the first stage and applying the modified version of the optimization method at each step. The benefits of this approach are claimed to be faster development cycles, lower costs, and reduced environmental impacts. 2 ) The authors show that applying the three - step method to an existing HPO that has been developed in previous works can lead to improvements in terms of both performance ( in the sense that it leads to faster cycles and lower costs ) as well as new state - of - the - art of the art techniques ( e.g., better network architectures ). 3 ) The experiments are conducted to test the effectiveness of applying the proposed method to a variety of settings that were previously only explored in previous HPO versions, such as the use of different tuning parameters of the neural network or the hyper -parameter search space. The experiments show that the proposed approach often leads to improved performance compared to the old and new versions of HPO, and sometimes even faster than the original design. "
SP:e8f99bae5853de525450fcb8facd23cf973fc161,"This paper studies the role of label representations in training image classifiers. It finds that the way in which data labels are represented in the label representations can have a profound effect on the quality of the trained models. For example, training an image classifier to regress audio labels rather than traditional categorical probabilities produces a more reliable classification. This result is surprising, considering that audio labels are more complex than simpler numerical probabilities or text. The authors hypothesize that high dimensional, high entropy label representations are generally more useful because they provide a stronger error signal. They support this hypothesis with evidence from various label representations including constant matrices, spectrograms, Gaussian mixtures, and uniform random matrices of various dimensionalities. They experimentally compare the performance of trained models with and without label representations on the standard image classification task, and find that features learned through our label representations exhibit more robustness under various adversarial attacks and better effectiveness with a limited amount of training data. These results suggest that label representation may play a more important role than previously thought."
SP:4e8d924cba7367af0999b30d79250b4dc40413e1,"This paper proposes a new method to train a multi - input multi - output ensemble neural network ( MIMO ) using a single model. The idea is to train multiple subnetworks independently of each other to learn the task at hand by using a forward pass that combines the predictions of the main model and those of the sub - networks. The sub - nets are trained in a way that requires only the forward pass for each sub - networks to be computed ( ensembling ). The authors argue that this allows them to reduce the computational cost of training multiple models in order to achieve the same robustness without using any additional forward passes. They compare their approach to previous methods that train multiple models with a single forward pass ( e.g., DeepEnsemble ), showing that their method is more robust and efficient in terms of robustness ( i.e., the model does not require as much computational overhead ). They also show that their approach is more error - free than DeepEnsembled ( DAE ), a prior method they use for training neural networks.   The main contributions of this paper are the following : 1 ) They propose a new way to train an ensemble network that learns the task using multiple models ( instead of training one model and using forward passes for each one of them ), which they call Multi - input Multi - output MIMOs ; 2 ) They show that the robustness they achieve is better than previous methods they have compared to DAE. 3 ) They evaluate their method on various metrics ( negative log - likelihood, accuracy, log - likelihood, and log - log - k/s, and calibration error on CIFAR10, and see if there is a significant improvement."
SP:d2f1c23b67c6744101034dc5e1c70765a733b169,"This paper proposes Sparse Representation Matching ( SRM ), a method to transfer intermediate knowledge obtained from one Convolutional Neural Network ( CNN ) to another by utilizing sparse representation learning. SRM first extracts sparse representations of the hidden features of the teacher CNN, which are then used to generate both pixellevel and image - level labels for training intermediate feature maps of the student network. The authors formulate SRM as a neural processing block, which can be efficiently optimized using stochastic gradient descent and integrated into any CNN in a plugand - play manner. Experiments demonstrate that SRM is robust to architectural differences between the teacher and student networks, and outperforms other KD techniques across several datasets."
SP:e8c0f43bd5debf6544f588cd3442dc3dd62d0eee,"This paper proposes a new approach to generalize policy representations learned from reinforcement learning ( RL ) based on state - action similarity metric ( PSM ). The motivation for developing such a metric is based on the sequential nature of RL and the fact that the goal is to learn policies that generalize to unseen environments. This approach is orthogonal to recent approaches, which do not explicitly exploit this sequential structure of RL reinforcement learning. The main contribution of this paper is to develop a PSM that is able to capture the high similarity between states that is measured through behavioral similarity measures such as the policy similarity metric. The paper also develops a contrastive representation learning procedure ( PSE ) to embed any state similarity metric that is derived from the PSM in the representation learning process, which is then used to obtain policy embedding densities that can be used to generate representations that are similar to the target states under the target policy. The PSE method is evaluated on three benchmarks ( LQR with spurious correlations, a jumping task from pixels, and Distracting DM Control ) and compared with two baselines based on policy embeddings ( PSEs and PSE - R. The experiments show that PSEs outperform the other two methods in generalization on all three benchmarks.   The main contributions of the paper are the following : 1 ) The PSM is developed and developed in a theoretically motivated manner and is used to train a classifier that learns from the state action space to generate state representations 2 ) The contrastive learning procedure is developed to embed the state representations from the states that are learned from the same state using PSMSE. The method is applied to three benchmarks, where it is compared to two other methods that do not use PSM. The results indicate that the PSE and the contrastive procedure improve generalization over the other methods in most cases."
SP:92f3b4942da9075440dda618f561a85f8fde5a5c,"This paper proposes a new approach to disentangle natural factors of variation in data ( e.g. object shape vs pose ) based on the latent representation of a machine learning model. The authors claim that the current approach, which maps each of the natural variation factors to distinct subspaces in the latent space of the model, introduces discontinuities in the encoder due to topological defects introduced by the use of equivariant operators. They propose a more flexible approach, based on a family of transformations acting on images —encompassing simple affine transformations such as rotations and translations — that can potentially act on the entire latent space in the model ’s latent representation. Inspired by group representation theory, the authors propose an approach to learn a distribution - agnostic encoder that maps each natural variation factor in the data $ \mathcal{O}$ to a subspace $ \Omega(z)$ of a latent space $ z$. The encoder is trained to generate $ \tilde{z}$ transformations $ p(z | z)$, where $ z \in \mathbb{Z}$ is the dimension of the data and $ \eta$ is a measure of the difference between the model's representation of the input $ z$. The authors show that their approach is more flexible and more interpretable than the previous approach, as it does not require the operator $ f(z ) to generate transformations ( which is costly and time - consuming ). The method is evaluated empirically on a set of image classification tasks ( object detection, object recognition, and semantic segmentation ), and applied to a new generation of machine learning models ( CIFAR-10 and ImageNet. The results show that the proposed approach has better interpretability and generalizes better than the prior approach ( which does not use distributed equivariants )."
SP:ef0f58c462bc5dd1c7b78f562c42a4e17f0f252b,"Hawkes process provides an effective statistical framework for analyzing the timedependent interaction of neuronal spiking activities. However, the classic Hawkes process is incapable of modelling inhibitory interactions among neurons and prefers to model excitatory interactions. In this paper, three sets of auxiliary latent variables ( Pólya - Gamma variables, latent marked Poisson processes and sparsity variables ) are augmented to make functional connection weights in a Gaussian form, which allows for a simple iterative algorithm with analytical updates. The authors propose EM algorithm to obtain the maximum a posteriori ( MAP ) estimate of the cost of expectationmaximization ( EM ) that is used to estimate the temporal $ \mathcal{T}$ that maximizes the marginal cost of the expected return ( $ \tau$ ) that would be obtained by applying EM algorithm with the auxiliary variables. They evaluate EM algorithm on synthetic and real neural recordings. EM algorithm is simple and efficient. The empirical results demonstrate the accuracy and efficiency performance of the algorithm.    The main contributions of this paper are the following :   1 ) The authors develop a novel connection weighting scheme based on Gaussian Gaussian distribution with auxiliary variables to model the activations of neurons. This allows for more flexible and interpretable connection weights that can be used for more complex tasks. 2 ) The connection weights are derived from the functional Gaussian connection weights and optimized using a simple algorithm. 3 ) EM algorithm and MAP algorithm are developed using the auxiliary variable augmentation."
SP:1156d3deac022829bda930ffcb081947609d972b,"This paper studies the dynamics of the gradient descent ( GD ) algorithm for training two - layer neural network models in the parametrized Gradient descent regime of the NeurIPS framework. It is found that there are two phases in the GD dynamics that are distinct from the dynamics associated with the more commonly studied “ mean - field ” phase of the algorithm. In particular, there is an early phase when the target function can be accurately approximated by a relatively small number of neurons, and there is a late phase in which the neurons are divided into two groups : a group of a few “ activated ” neurons that dominate the dynamics and another group of “ quenched “ neurons that support the continued activation and deactivation process. This is qualitatively different from the typical behavior of the neurons associated with “ MEF ”, where all neurons participate equally in the training process. The paper shows that this quenching - activation process biases the algorithm to picking sparse solutions. This neural network - like behavior is continued into the mildly over - parametric regime, in which it undergoes a transition to a random featurelike behavior where the inner - layer parameters are effectively frozen during the training procedure. This behavior is distinguished from the usual behavior of network - based models, where neurons are fully activated during training and fully fully deactivated at the end of training. The main contributions of this paper are the following :   ( 1 ) An analysis of the early and late GD phases for the underparameterized Gradient Descent regime, showing that the dynamics closely resemble that of the corresponding random feature model ; ( 2 ) A study of the neural network dynamics in the mean field of the late GD phase for the fully activated neurons."
SP:9e81401a6f30c70d870a12cce0cf600557f92b80,"This paper proposes a generative model for practical reinforcement learning problems ( PDPs ) that decomposes two types of MDPs ( reconnaissance MDP and planning MDP ) into their corresponding auxiliary functions : threat function and reward function. In R - MDP, the threat function is the Q - function analogue of danger that can determine whether a given state - action pair is safe or not ; in P - PDP, it is the reward function that is used to train a reward - seeking policy while using a fixed threat function to determine the reward value of each action taken by the agent to maximize the expected return while satisfying a set of prescribed safety constraints. The main contribution of this paper is to develop and train a parametrized autoregressive model of the MDP problem that can be used to solve PDP problems with different threat functions corresponding to different reward and different danger - contraints. The method is validated on a benchmark dataset and in two complex collision - free navigation tasks. The experimental results show that the proposed model outperforms the baselines and other state - of - the - art methods in most cases.   The main contributions of the paper are the following :   1 ) A new parametrization of the PDP problem from the perspective of reinforcement learning, which decomposes the original decision process ( RDP ) from the set of states and actions taken by an agent into two sets of states - action pairs, one for reconnaissance and one for planning. This allows the authors to define the difference in terms of reward and threat between RDPs and planning. 2 ) An improvement in accuracy of the training of threat function for RDPPDPs compared to the previous methods. 3 ) A novel approach for training reward function of the auxiliary threat function of PDP."
SP:f1d4ac7d5516dd0df742e224c8c09c721d0d0886,"This paper studies the relationship between modern deep learning with cross - entropy loss ( CEL ) and square loss ( SNL ) in classification tasks. CEL is widely believed to be empirically superior to the square loss, but this paper argues that this belief may not be wellfounded and investigates several neural architectures trained with square loss that perform comparably or better to those trained with cross entropy loss. The paper presents experimental results that support the observation that cross entropy seems to have a slight edge on some vision tasks compared to square loss on ASR and vision tasks, but the edge of square loss appears to be marginal on the ASR tasks. In conclusion, the paper shows that the advantages of using square loss to train deep neural architectures for classification tasks with CEL may be less justified if one considers the tradeoff between performance on vision tasks and performance on classification tasks when compared to cross entropy tasks.    The main contributions of this paper are the following :   1. This paper examines the relationship of the cross entropy and square losses in the context of deep learning and deep learning on equal footing, where square loss is used to train neural architectures that perform on task performance on all datasets ( vision, ASR, and machine learning ) while cross entropy is used for training deep architectures. This is in contrast to what is typically done in deep learning setting where the deep architectures are trained on equal datasets ( e.g., deep learning + cross entropy training + square loss ), which is done on a pre - defined dataset that does not allow for crossover between datasets. This leads to the conclusion that there may be trade - offs between training deep networks on different datasets for cross entropy losses and training with square losses. 2. The experiments compare the performance of modern deep networks with and without square loss with that of cross entropy networks, and find that square loss performs comparably to that of neural networks trained with the traditional cross entropy."
SP:915f1f0fc4850507c28c1d609239b41775863ebe,"This paper proposes Self - Predictive Representations ( SPR ), a self - supervised learning method for reinforcement learning from pixels. The idea is to train an agent to predict its own latent state representations multiple steps into the future using an encoder which is an exponential moving average of the agent ’s parameters. The encoder is trained using a learned transition model and the agent is taught to predict the target representations for future states using the encoder. The paper shows that on Atari games with limited interaction between the agent and the environment, SPR achieves a median human - normalized score of 0.415415 on Atari in a setting limited to 100k steps of environment interaction, which represents a 55% relative improvement over the previous state - of - the - art deep RL from pixels method ( SOTA ). On tasks where there is no additional data augmentation to the future prediction loss, SPR outperforms SOTA by a large margin.    The paper also shows that SPR can learn more accurate latent representations when augmented with self - supervision to learn more structure in its visual input and sequential interaction with the environment. The experimental results show that SPR is able to learn from structure in the environment more efficiently compared to SOTA, and the method is robust to the choice of reward structure."
SP:983f01c170909c8c67fd3be25f121bd61bdd8307,"This paper proposes InstantEmbedding, an efficient method for generating single - node representations using local PageRank computations. The authors theoretically prove that their approach produces globally consistent representations in sublinear time. They demonstrate this empirically by conducting extensive experiments on real - world datasets with over a billion edges.    The authors provide theoretical guarantees on the locality of the computation, as well as the proof of the global consistency of the generated embeddings. They show empirically that their method is able to produce high - quality representations on par with state - of - art methods, with efficiency several orders of magnitude better in clock time and memory consumption : running 9,000 times faster and using 8,000 times less memory on the largest graphs that contenders can process. They also show that our method produces high quality representations, demonstrating results that meet or exceed the state - art for unsupervised representation learning on tasks like node classification, link prediction and link embedding. Since such embedding learning methods learn a d -dimensional embedding vector for each node in a given graph, they can be used across multiple tasks and applications. The embedding for a node can be learned solely from the structure of the graph, and can not access representations of other nodes in the graph or rely on global model state. In this setting, the embedding is restricted to using only local embedding information. To achieve this successfully, the authors propose to use a high - order similarity matrix based on Personalized PageRank ( PPR ) as the basis on which local node embedding algorithms are computed via hashing. This is similar to the approach used in the previous work that links embedding methods to matrix factorization ( Tsitsulin et al., 2018 ). The main difference is that, instead of leveraging PPR, they use it to represent the representation of a single node, so that the final representations can be adaptively adapted for the same downstream tasks that graph embedding has proved adapt at the past to be effective at in the past. Importantly, since such embedDings are learnable and can be reused for multiple tasks, they are more suitable for general applications such as visualization, node classification and link prediction. However, they do not provide the option to route the learned embedding vectors ( the representations to other nodes ). For evaluation purposes, they only consider the setting where the input graph is large but also scarcely annotated. For example, the Friendster social graph, with only 30% nodes assigned to a community, from its total 65 M entries. At the same time, it is often the case thatGraphs are widely used to represent data when are objects connected to each other, such as social networks, chemical molecules, graphs"
SP:d11037b8fe2b10aee672ba82f69410b40181f0f9,"Graph coarsening is a popular technique to reduce the size of a graph while maintaining some graph properties. This paper proposes a data - driven algorithm, Graph Coarsening Neural Networks ( CGNN ), which leverages recent advances in deep learning on graphs for graph coarsened graphs to leverage the recent progress of deep learning. The authors propose a framework for measuring the quality of the choices of the Laplace operator on the coarse graph and associated projection / lift operators that are used to coarsen the graph. The choice of edge weight for the coarse graphs may be suboptimal, so the authors propose to parametrize the weight assignment map with graph neural networks to train it to improve the quality in an unsupervised way. Through extensive experiments on both synthetic and real networks, the authors demonstrate that the proposed method significantly improves common graph coarassing methods over the previous methods.    The main contributions of this paper are the following :   1 ) The authors develop a method to train a graph neural network, which outperforms the previous method, Graph Neural Networks, on synthetic data and real graphs. 2 ) The method is able to adapt to different losses ( differentiable and non - differentiable ), and scales to much larger graphs than previous work. 3 ) It is possible to train the network on real graphs and synthetic graphs with significantly fewer parameters than the trained network."
SP:0d680213339f0e2aedb0be4aeed51423706b8bf6,"This paper presents a geometric deep learning algorithm based on discrete - laplacian and implicit encoders to compute the acoustic properties of general 3D objects at interactive rates using a point cloud approximation of each object. Each point is encoded in a high - dimensional latent space and the network can accurately estimate these acoustic properties for arbitrary topologies and takes less than 1ms per object on a NVIDIA GeForce GTX 2080 Ti GPU. The authors also prove that their learning method is permutation and rotation invariant and demonstrate high accuracy on objects that are quite different from the training data. The main contribution of this paper is the introduction of a method for generating environmental acoustic effects in dynamic environments. The scattering characteristics of objects corresponding to scattering characteristics are frequently used for 3D audio content creation, environmental acoustic effect, localization and acoustic scene analysis, etc. The numerical solvers used to compute these characteristics are too slow for interactive applications and the proposed method is a faster alternative.   The main contributions of the paper are the following :   1 ) A novel geometric learning algorithm for generating the acoustic characteristics of general objects. The method is proposed to solve the problem of generating the characteristics of a general object from a collection of discrete scattering objects. This collection can be divided into several subsets of objects, and the method is trained to generate the corresponding characteristics of each sub - set using the discrete scattering characteristics from each subsets. The learning algorithm is trained using discrete LAplacians and the training set is updated based on the updated distribution of points in the point cloud. The updated distribution is updated according to the updated point cloud and updated points are inserted into the latent space of the object corresponding to the latest entry in the collection. This process is repeated until a final point in the distribution is inserted. 2 ) The authors demonstrate the effectiveness of their method on a toy environment generated from scratch using only the original data from the toy environment."
SP:afc33a782c43e3d4c5c4fbf047d0b1108bc30bae,"This paper proposes Risk Extrapolation ( REx ), a method for robust optimization over a perturbation set of extrapolated domains ( MMMREx ) and propose a penalty on the variance of training risks ( V - REx ) as a simpler variant. The idea is to assume that the variation across training domains is representative of the variation we might encounter at test time, but also that shifts at testing time may be more extreme in magnitude. In particular, they show that reducing differences in risk across training domain can reduce a model ’s sensitivity to a wide range of extreme distributional shifts, including the challenging setting where the input contains both causal and anti - causal elements. They motivate this approach as a form of robust optimization, and propose to propose Invariant Risk Minimization ( IRM ), which is able to outperform the original REx in situations where these perturbations are contained in the extrapolated domain. IRM proposes to recover the causal mechanisms of the targets, while also providing some robustness to changes in the input distribution ( “covariate shift ” ).    The main contributions of this paper are the following :   1. This paper proposes to propose a robust method for minimizing the risk variation between training and test domains by minimizing the difference in risk between the two training sets. This is motivated by the observation that the training loss at training time is low compared to the test time ( e.g., low in training loss but high in test time ), and that the loss at test and test time is similar in magnitude, whereas the loss is low in magnitude in the real world. 2. The authors propose to use IRM to estimate the difference between training loss and test loss in the training set and test domain risk. They show that IRM outperforms other methods for estimating the difference. 3. The main contribution of this work is the introduction of a penalty that proposes to penalize the deviation of training loss from the training mean when the mean is less than $ \epsilon$ and training loss is higher than the test loss. The paper also proposes to use the same penalty for training mean and test difference as in IRM, but with a slightly different parameters, which seems to be motivated by a desire to avoid overfitting to the data from the test domain. 4. The experiments are conducted on synthetic data, and the authors compare the performance of their approach to the one they propose and show that it performs comparably to other methods."
SP:411d5bcf7698d534ad60f581d479ff74849ba4de,"The paper proposes Fourier neural operators for partial differential equations ( PDEs ), a new type of operator that learns PDE solvers directly from the functional parametric dependence of the solution. This is in contrast to neural operators that use parametric approximations of the PDE solution, e.g., gradient descent, stochastic gradient descent. The paper proposes the Fourier Neural Operator ( FNO ), which is the first ML - based method to learn turbulent flows with zero - shot super - resolution. The method is based on the idea of learning an entire PDE family, which includes Burgers ’ equation, Darcy flow, and Navier - Stokes equation, by parameterizing the integral kernel directly in Fourier space.   The paper shows that the FNO is expressive and efficient with respect to previous learning - based methods for PDEs, and experiments show that it is faster and more accurate than the traditional PDE solvers with three orders of magnitude or more. The main contributions of the paper are the following : 1 ) it proposes a novel way to parameterize the kernel by directly mapping it to a space $ \mathbb{R}$ in $ \Fourier space ( unlike prior work which parametrized the kernel as a function mapping ) 2 ) it introduces the first FNO with three different classes of turbulent flows, where each class corresponds to a different type of PDE ( differentiable, parametric or non - parametric ), and 3 ) it provides a way to learn the mapping between the first and second class PDE of each PDE in the class."
SP:41d268d0eac9b4c84baa156fb641aa6d3060b5a4,"This paper studies gradient descent with infinitesimal step size on linear neural network training. It considers three different types of neural networks, L - layer, fully connected, diagonal and convolutional networks, and trainable linear tensor networks, where each layer corresponds to a set of connected, output tensors. The trained network consists of $ L$-layer L - factorized tensor, $ D$-valued tensor and $ L-width $ \mathbb{R}$-weighted tensor matrices, where $ L \in [ L_{\mathbf{R}}|L_{\textrm{S}}]$ is the weight matrix of the network, and $ D \to [ S, M } \to R$ is its output tensor.   The authors first study the gradient flow analysis of gradient descent on trained neural networks. They show that gradient flow is stationary at $ \ell_2 $ and $ l_\max_margin $ in the transformed input space of the trained network. This stationary point is obtained by using the $ \theta$ operator in the previous line. Next, they consider the case when the network is fully connected. They use the tensor formulation of the trainable neural network to show that the convergence direction in the direction of the weights is a singular vector of a tensor vector. This vector vector can be represented as $ \tilde{s}$ where $ s$ is a weighted sum of $ \gamma_t$ and $ t_{\theta } \bar{s } \log p(s )$. They use this vector representation to obtain the convergence rate in the gradient descent case where $ \bar(s)$ is $ \kappa$. Finally, they use gradient descent to obtain $ \nabla_{t}$ for trained network and $ \delta$ for trainable tensor network and show that for L-layer networks with L=1 $ and L-1 $ weights $ \eta$ that are orthogonally decomposable, gradient flow converges to a $ \sqrt{T}$ which minimizes a minimum $ \epsilon$ ( $ t$ ) which minimises a norm - like function $ \eps(t)$. In the authors show that this global minimum exists for all weights $ t$. For trained network with L_1 and L_2 weights L$ and L$ weights \eta, they show that $ \sigma"
SP:e27907ef4a4e6e0f5841618fcaa7e7e0db443f91,"This paper proposes a new method for optimizing the width - multipliers of sub - nets across different layers to improve the performance of slimmable neural networks. The main idea is based on the fact that different layers may have different prediction accuracy requirements ( FLOPs ) and different number of floating - point operations ( $ n$ operations ), and hence, different network operators might have different memory and computational requirements. The proposed method, called Multi - Objective Optimized Slimmable Networks ( MOSDN ), aims to develop a principled approach for deciding the number of multipliers across the layers to obtain better performance for slimvable networks. To this end, the authors use the ImageNet dataset ( MobileNetV2 ) to investigate the effect of different channel counts for different layers jointly with the weights for slimmable networks. They also propose a novel algorithm for optimizing both the shared weights and the width- multipliers for the sub - networks. The authors conduct extensive empirical analysis with 15 network and dataset combinations, two types of cost objectives, i.e., cost i and cost t, to demonstrate the effectiveness of the proposed method compared to existing alternatives. They show improvements up to 1.7% and 8% in top - 1 accuracy on the Image net with Mobile netV2. The results also highlight the potential of optimizing the channel counts   for different layer sizes jointly.    The authors also conduct an in - depth analysis of the network dynamics using the new method and compare it to existing methods. They find that channel counts do not significantly affect the network's prediction accuracy and computational cost. However, and channel splits across layers do affect the prediction accuracy. Overall, the method seems to perform marginally better than the existing approaches. The major concern of the paper is that channel splits do not keep close to the original network dynamics."
SP:cf59403abb6ca89ccee4f8e77e9a33d99e6a00f5,"This paper proposes a federated learning approach called FedMatch ( FedMatch ) to solve the problem of labeled and unlabeled data for semi - supervised learning in the federated setting, where data obtained at the client - side often comes without any accompanying labels due to either high labeling cost or difficulty of annotation due to the requirement of expert knowledge. The proposed approach is based on the Federated Semi - Supervised Learning ( FSSL ) approach with a new inter - client consistency loss and decomposition of the parameters for disjoint learning on labeled data ( labeled data is only available at the server ). The authors study two scenarios of FedMatch : 1 ) in a conventional setting where clients have labeled data available only, and 2 ) in an asymmetric setting where labeled data can be obtained only from the server ; and the second scenario considers a more challenging case, where the labeled data may not be available at all. For each scenario, the authors propose a novel method to tackle the problems, which they refer to as Federated Matching Matching ( FMS ). This method is validated on two scenarios : ( 1 ) with labeled data and ( 2 ) without labeled data. On both scenarios, FedMatch is shown to outperform both local semi - supervision learning and baselines which naively combine Federated learning with semi - supervising learning. On the asymmetric case, the proposed method outperforms both local supervised learning and FedMatch with a dataset augmentation, and it also shows an advantage on the more challenging scenario of using labeled data obtained from a server - only setting."
SP:9457b6d430a2cd864d526d7e90bf3e1ab13d6df4,"This paper proposes a method called CoLES for learning discrete event sequences using self - supervised learning from a low - dimensional fixed - length vector representations. The vector representations are obtained by augmenting the input event sequences with contrastive learning. Contrastive learning is a popular technique for learning event sequences from data that has been applied successfully in vision and audio domains and is a promising tool for machine learning due to its ability to handle complex information from the raw data that is typically not well represented in the vector representations used for event sequences. In this paper, the authors propose to apply contrastive learned from audio and computer vision domains to the event sequences domain in a self - supervision setting where the raw event sequences are represented by vector representations that are not available to the human eye. The proposed method, CoLES, adopts the contrastive reinforcement learning approach from prior work ( Zhang et al., 2021 ) to learn event representations from a discrete domain using self supervision and augmentation. The authors theoretically prove that the augmentation method underlying CoLES is robust to sampling from the discrete domain provided by CoLES. They evaluate CoLES on several public datasets and showed that CoLES representations consistently outperform other methods on different downstream machine learning tasks. In the experiments, the number of samples used to train CoLES has not been analyzed and it is not clear if there are any significant differences between the samples used for training and the ones used to augment the event representations."
SP:385942a5bcee7384bb722a1669b541f2fac0cd36,"This paper proposes a new unsupervised language parsing framework, StructFormer, that can combine the power of dependency grammar ( induced by one - to - one correspondence between words ) and grammar modeled by the representation of grammars ( induced from the self - attention mechanism ). There are two major classes of natural language grammar, namely dependency grammar and grammar - dependent. The dependency grammar is the one that models the assembly of one or several dependent words. The grammar - dependent one is used to generate the one - hot correspondence between two words, while the grammar - supported one is for the actual words. StructFormer is able to combine the two types of grammar in the same language parsing pipeline.   The main contribution of this paper is the introduction of a self - attentive parsing mechanism that turns induced dependency relations into transformer relations, in a differentiable manner, through the dependency - constraint mechanism. Experimental results show that the StructFormer model achieves good results on unsuper supervised language parsing with strong performance ( better than the baseline ) on the three main tasks : Unsupervised Language Parsing, Masked Language Modeling and Graph - based Graphsourcing."
SP:078966ff62775bba6031e47d374bda95f4a7dde3,"This paper proposes a model - based approach for learning a metric representation of scene nodes and object bounding boxes from a set of structured images using self - supervised learning. The key idea is to train a model that learns the metric among visual objects and scene graph nodes by incorporating information from both object features and relational features of the images. The model is trained with supervised learning and self - training with weak supervision. The main contributions are the following contributions :    ( 1 ) A new model architecture is proposed that learns a metric embedding between the nodes of the scene graph on the image, the object boundings inside the image and the graph nodes on the scene nodes. This embedding is then used to learn the mapping between the node matrices of the visual object and graph nodes in the image with self - supervision. This is similar to the approach used in [ 1 ], but different from the annotation - based learning in [ 2 ]. The paper proposes to use a graph neural network ( GNN ) instead of an image - based model ( e.g., an embedding of the bounding box ) for the graph matrices. This allows the GNN to be trained without the annotated mapping from the image to the nodes. The GNN can be seen as an encoder - decoder setup similar to [ 3 ], except that it uses a graph - based encoder instead of a bounding - box encoder. The resulting decoder can be further fine - tuned using supervised learning to obtain the correct mapping using only the graph node embedding and bounding object embedding ( instead of the object - based one ). This approach is referred to [ 4 ]. ( 5 ) A set of experiments are presented that compare the performance of the proposed method against the state - of - the - art methods on the task of scene graph grounding. The experiments are divided into two parts : ( a ) Grounding the Scene Graph Representation ( GMR ), where the GMR pretraining is used to train the model and ( b ) Graph grounding the SceneGraph ( GSR ), which uses the grounded model to perform the task. Results show that the proposed GMR method performs marginally better than the baselines ( on the first part of the task ) and marginally worse on the second part. Further experiments are performed on scene graph parsing tasks to verify the grounding found in GMR and to validate the grounding of the model ( the last part using the ground - truth graphs )."
SP:4644dbf7466b6234d8abf69995fdfb357efcc119,"The paper proposes SPherical sliced fused Gromov Wasserstein ( SSFG ) to learn the distribution of data by minimizing a reconstruction loss together with a relational regularization on the latent space using RAE framework. SSFG is an approach to reduce the inner discrepancy between the prior and aggregated posterior distributions by minimizing the reconstruction loss between SFG and RAE. However, this approach has a weakness in that it treats every slicing direction similarly and several directions are not useful for the discriminative task. To improve the discrepancy and consequently the relational regularisation, the authors propose a new relational discrepancy, named spherical sliced sliced FGSM ( PSFG ), that can find an important area of projections characterized by a von Mises - Fisher distribution. First, it introduces two variants of SSFG to improve its performance. The first variant, named mixture spherical sliced fused MSSF ( MSSFG ) replaces the vMF distribution by a mixture of von Mise - Fisher ( MFP ) and spherical distribution to capture multiple important areas of directions that are far from each other. The second variant named power spherical sliced GFSM ( PGFSM ) replaces   power spherical distribution of vMF with spherical distribution and tries to improve the sampling time in high dimension settings. The experiments show that the proposed SSFG and its variants have favorable performance in learning latent manifold structure, image generation, and reconstruction tasks."
SP:5ae2c0af82cac89a65f1cc38c43e2d05ea298901,"This paper proposes an approach to speed up training for transformer networks, which contain repeated structures such as the transformer module. The authors first train such a deep network with the weights shared across all the repeated layers till some point, then stop weight sharing and continue training until convergence. The untying point is automatically determined by monitoring gradient statistics. The adaptive untying criterion is obtained from a theoretic analysis over deep linear networks. Empirical results show that the proposed method is able to reduce the training time of BERT by 50 %.   The main contributions of the paper are the following :   1. A new approach to train transformer networks with shared weights across repeated layers is proposed. This approach is similar to the approach used to train BERT. The difference is that the authors use gradient statistics to track the gradient of the weights across the layers and train the model with gradient sharing until convergence, instead of using the gradient based approach used in BERT ( e.g., gradient clipping and gradient clipping + weight sharing ). 2. The method is applied to training BERT models for linear transformer networks ( transformer layers ), where the target problem is to learn a linear layer structure such that the model converges to a fixed, fixed, point untied at which the gradient does not go too far away from the fixed point. 3. A theoretical analysis is performed to determine the parameters of the adaptive criterion for the untying of the transformer layers, which is used to design a new training objective that is adaptive to the target model. 4. The evaluation is performed on a set of tasks such as natural language modeling and computer vision tasks. The experiments compare the proposed approach with BERT on MNIST, CIFAR-10, PASCAL, and ImageNet. The proposed approach is shown to outperform BERT and other baseline methods on these tasks with a few modifications."
SP:a51710551142316b67e2fccd969fea1ece35ba39,"This paper studies the adversarial transferability ( ADA ) of perturbation - based methods to enhance the transferability of an adversarial example. The main focus of the paper is on the interaction between the attacker and the defender within the attacking process of the AA. The paper proposes to use this interaction inside perturbations to understand the negative correlation between the ADA's transferability and the interaction with the attacker. The negative correlation is further verified through different DNNs with various inputs. This negative correlation can be regarded as a unified perspective to understand transferability - boosting methods and is used to propose a new ADA method. The proposed method penalizes the interactions between the attackers and the defenders during the attack process to improve the ADA transferability.    The paper is written in an easy - to - read format, which allows for easy reading comprehension and interpretation. Detailed comments and questions can be found at the end. I suggest reading the author response first, as it contains important information about the history of the ADA field. The authors should clearly state the background of the work before moving to the current state - of - the - art ADA methods. The references for the authors ’ methods are also the same as those in the rebuttal paper [ 1 ]. The only difference between the two papers is the citation length ( 1.5 vs. 1.6 ), which is based on the average number of steps in the attacking and defending process. The author ’s response for each step is in the form of a ( 1 ) + ( 2 ), where the difference in percentage of steps is the ratio of adversarial attacks and defending attacks ( 0 and defending actions ( 1.5 / 2 ). The score is the average adversarial attack score ( 0.5 for the defending actions and 0.1 / 2 for the recovering actions ). I believe that this score is important to keep the reader up to date and the paper could use this score to better inform the reader about the state of the art of ADA methods in the AE field."
SP:f1565319075c1442c2cb52d96443facb492c06c2,"This paper presents a quantitative analysis of the role of forgetting in the representation learning process in deep learning models. For the first time, the authors study the forgetting mechanisms of hidden neural network ( hidden ) representations with respect to task semantic similarity. They find that the forgetting mechanism is strongly related to the depth of the representation layers used to learn the task representations, with the deeper layers accounting for more forgetting while the higher the level of the hidden layer, the greater the semantic similarity to the task. This leads to the formulation of a knowledge gap between the importance of the different types of forgetting mechanisms for different layers of the neural representations and the mechanisms used to mitigate it. The paper also presents a set of methods to mitigate forgetting for the deeper layer representations, as well as an analysis of their effects on the fine - tuning of the representations to prevent forgetting.   The quantitative analysis is performed in terms of the layer - wise representation similarity of the task embeddings in the hidden neural representations. The results show that the deeper the representation layer is in general, the more semantic similarity with the task sequences it has with the hidden layers, and the more the deeper it is in the network the more it is responsible for forgetting the earlier task sequences ( at least the ones with intermediate similarity ). This is contrasted with the opposite case for the shallow layers ( intermediate layers ) of the network, where forgetting is more correlated with the higher layers ( the lowest layers ). The authors present a series of experiments that compare the effects of different methods for mitigating the forgetting of the deeper representation layers with the empirical effects of the methods developed to mitigate the feature re - use. The experiments show that for the deep layers there is some increase in the feature reuse, but there is also a decrease in the amount of re - usage, suggesting that some features may be re - used while others are orthogonally updated to avoid interference with task semantics. The empirical results also support the idea that the most forgetting occurs for sequences that have high level semantic similarity between the task and the hidden representations ( e.g., sequences where the task is encoded in both hidden layers and the neural network )."
SP:30d7532cdcf420bff3be6b92eea3d93bce59e6bd,"This paper proposes a training algorithm for large language processing models such as BERT, XLNet and T5, which have achieved impressive results in many natural language processing ( NLP ) tasks. However, their high model complexity requires enormous computation resources and extremely long training time. This paper proposes EarlyBERT, a general computationally - efficient training algorithm applicable to both pre - training and fine - tuning of large - scale language models to reduce the training time of BERT with 35 % less training time and BERT+35 % less inference time. The proposed algorithm is inspired by the Early - Bird Lottery Tickets recently studied for computer vision tasks. The authors first identify structured winning tickets in the early stage of the BERT training process to identify the most computationally efficient way to train the model. They then apply those tickets towards efficient BERT during pre-training stage, and conduct comprehensive pre - and fine-tuning stage. They conduct extensive experiments on GLUE and SQuAD tasks to validate the effectiveness of their proposed algorithm, which they call earlyBERT. The experimental results show that EarlyBerT achieves comparable performance to standard BERT ( with slightly less training ) during the training stage, while using much less training resources.    The main contributions of this paper are the following : 1 ) The authors propose a general algorithm for reducing the inference time of large language model pretraining by using a general computation method similar to that of early bird lottery tickets ; 2 ) They study the effect of the number of tickets and batch sizes of the training iterations to find the best way to reduce training time in terms of total number of training iterations. 3 ) They conduct comprehensive experiments to evaluate the performance of their algorithm, including GLUE - based training algorithm and GLUE training algorithm. The experiments show that the proposed method outperforms early bird lottery tickets with comparable performance."
SP:c547f23ff6caaf5e9f35d258490b86ae0ac8ed03,"This paper studies the robustness of f - divergences measured with respect to supervised labels when learning with noisy label noise using f - divergence measures. The main contribution of the paper is a derivation of the variational property of the decoupling of the divergence between the difference on the clean and noisy labels when the label noise presents, where the noise term is added to the noise measure and the original variational difference is maintained. The derivation is then used to propose a family of fivergence measures, which are robust when the noise rate is less than a certain threshold value, and are not robust when it is more than another threshold value. The paper presents the results of a series of experiments where it is assumed that the noise level is constant and that the supervised labels are trained on the noise - free distribution. The experiments are conducted on MNIST, Fashion - MNIST and CIFAR-10, MNIST with and without labeled labels, and use the F - divergence measures when the distance between the labeled labels and the clean distribution is between 0 and a desired distance. The robustness scores are calculated using the difference between the mean and standard deviation of the mean on the noisy label term and the difference in the mean between the label and the true label on the unlabeled one. Results are compared between the robust F - divergence and the standard deviation Fivergence with Noise Reduction ( SDR ) measures when maximizing the ratio between the true and noisy label loss ( label noise rate ). Results show that the SDR F - Divergence measures are more robust than the standard Divergence with SDRs when the mean is constant. Finally, the paper presents a set of experimental results showing that the robust / noise reduction measures are not as robust as claimed by the authors, and proposes methods to improve them."
SP:841888179dcdac901889c8d62cb5234311fe28f1,"This paper proposes ensemble - based weighted Bellman backup for off - policy deep reinforcement learning ( DRL ). It is motivated by the observation that DRL suffers from low signal - to - noise instability due to noisy rewards in Q - learning because the target values are derived from current Q - estimators, which are often noisy. To mitigate this issue, the authors propose to re - weight target Q - values based on uncertainty estimates from a Q - ensemble. The proposed method stabilizes and improves learning on both continuous and discrete control benchmarks. The main contributions are the following : 1 ) it proposes to use an ensemble of DQN - trained Bellman estimators to estimate the uncertainty of the Bellman backpropagation. The ensemble estimators are then used to compute the back - propagation parameters for the corresponding Bellman reward function, which is then used as the reward function in the DRL algorithm. 2 ) The method is tested on continuous DRL tasks ( with and without noise rewards ) using environments with noisy rewards, and finds that the proposed method significantly outperforms standard Bellman backups. 3 ) It is also investigated how the performance of the method changes when the ensemble size changes over time ( for example, when the size of the ensemble changes over the course of training ). The experiments show that the method performs better than the baseline DRL algorithms on both low - dimensional and high - dimensional tasks.   The main contribution of this paper is to propose a method to mitigate the issue of DRL instability caused by the noisy rewards used in DRL by using an ensemble based weighted back propagation. The method has the potential to stabilize and improve learning on DRL and it is empirically shown to outperform the baseline by using the ensemble."
SP:afc08f203562b841180811aef943bfb63a1659ea,"This paper proposes a method to measure the distributional mismatch between support and query sets via class - wise similarities in few - shot classification tasks via a meta - learning model. The method is algorithm - agnostic and can be applied to models trained with gradient descent, meta - supervised learning, or gradient descent. The training strategy is based on two components. First, the model is trained to be confident in the predictions of the classifier. The second component is used to ensure that the predictions are correct and do not overfit. The model outputs the class scores for each task as a function of the query scores. The class scores are used to compute a score for each query and support task. The score is used as a measure of the confidence of the model to perform well on the task and to prevent overfitting. The meta - training strategy consists of two steps : ( 1 ) train the model on the query sets and ( 2 ) train it on the support sets to minimize the likelihood of underfitting.   The experiments compare the proposed method with several other methods of training meta - learners and show that the method outperforms the other methods in most tasks. The main finding is that the training strategy helps the model avoid being indiscriminately confident and helps the classification results to be calibrated with accuracy."
SP:12ae325ea3bce1e60195afac7d85895d2d20c29c,"This paper proposes a novel method for learning video - text - to - video representations based on noise contrastive learning. The authors claim that the dominant paradigm for learning such representations relies on the representations of pairs of samples that are known to be related, pushes away representations of all other pairs that are not related. They argue that this last requirement is too strict, enforcing dissimilar representations even for samples that may be semantically related. To alleviate this, the authors propose a method that leverages a generative model to naturally push related samples together by leveraging a weighted combination of other support samples ’ visual representations. This simple idea ensures that representations are not overly - specialized to individual samples and are reusable across the dataset, and results in representations that explicitly encode semantics shared between samples. The method is tested on a large dataset of video-to -text and text -to -video datasets, and the authors evaluate it using a combination of supervised learning ( individual samples are sampled from the same dataset and their caption representations are reconstructed from a weighted sum of the caption representations of support samples ). The experiments show that the proposed method outperforms other methods that do not rely on the model ’s prediction, and that it is able to generalize well to other datasets."
SP:8a71d8fad25a126aff01431cacf348c05de75667,"This paper proposes a new method ( seg tok ) to pre - train a Chinese language model ( BERT ) based on pre - trained language models ( PLMs ) using Chinese word segmentation ( CWS ) and subword tokenization ( CTO ). The main reason why this is important is that the current default vocabulary used in the language model pre - training is not very diverse compared to the one provided by the authors of the previous works ( Bert Devlin et al., 2018 ), which is based on Chinese characters. The authors argue that this is because the existing vocabulary is monolithic and limited and that relying on one single vocabulary ( e.g., only characters that appear in the model ) during training limits its downstream performance on many downstream tasks. To overcome this limitation, the authors propose three versions of multi - vocabulary pretraining ( MVP ) to improve the models expressiveness.    First, the method proposes to use CWS to segment the vocabulary of BERT models according to the Chinese character lexicon. This is done by training the model on character segmentation from CWS and using the tokenization from CTO. Then the method is used to train a language model on BERT tasks using the learned tokenized Chinese character vocabulary. The language model is trained to predict the output of the model using the tokens generated from the segmented vocabulary using CWS tokens. The method is tested on a series of tasks where it is compared with the default vocabulary ( based on character - based vocabulary ) and compared to a vocabulary obtained from the masked language model. The results show that the method generally performs better on the lower level tasks ( where the vocabulary is sampled from the model but worse on the upper level tasks ). However, the higher level tasks perform much better with respect to the baseline vocabulary. Finally, the methods are also applied to downstream tasks where the model performs much better."
SP:b93ec7bc02b48068073ffe705f71d2643e663d51,"Graph Convolutional Networks ( GCNs ) have emerged as the state - of - the - art model for graph - based learning tasks. However, it is still challenging to train GCNs at scale, limiting their applications to real - world large graphs and hindering the exploration of deeper and more sophisticated GCN architectures. This paper proposes to leverage graph partition and distributed training for tackling the challenge of distributed graph partitioning due to the unique challenge posed by the GCN structures, especially the excessive amount of boundary nodes in each partitioned subgraph, which can easily explode the required memory and communications for distributed training of GCNs. To this end, the authors propose BDS - GCN, a method that adopts unbiased boundary sampling strategy to enable efficient and scalable distributed GCN training while maintaining the full - graph accuracy. The authors claim that it would open up up a new paradigm for enabling GCN - based distributed training at scale. Empirical evaluations and ablation studies are presented to validate the effectiveness of the proposed BDS -GCN and are released publicly upon acceptance."
SP:2d4ba873d11e969ebd1fc31f9b5ab450c964d154,"This paper presents a graph neural network ( GRNN ) called ForceNet for accurate and fast quantum chemistry simulations to accelerate catalyst discovery for renewable energy applications. The key challenge is to accurately capture highly complex and non - linear quantum interactions of atoms in 3D space, on which forces are dependent. To this end, ForceNet adopts expressive message passing architecture, ( 2 ) appropriate choice of basis vectors, and ( 3 ) model scaling in terms of network depth and width. In experiments, the authors demonstrate the potential for ML - based models to achieve practical usefulness while being orders of magnitude faster than physics - based simulations. Finally, they apply ForceNet to the large - scale catalyst dataset, where ForceNet is able to achieve 4x higher success rate than existing ML models."
SP:8bdcf4fe6abf4739d4732b7ea8538513135dcccc,"This paper proposes a generalisation bound for neural network generalisation based on Rademacher complexity that uses the distance the weights have moved from their initial values. This bound has no direct dependence on the number of weights and compares favourably to other bounds when applied to convolutional networks. The motivation for this paper is that providing a network with a good initialisation based upon transfer learning means that learning can modify the weights less, and hence achieve tighter generalisation. Inspired by this, the authors develop a simple yet effective fine - tuning algorithm that constrains the hypothesis class to a small sphere centred on the initial pre - trained weights, thus obtaining provably better generalisation performance than conventional transfer learning. Empirical evaluation shows that the proposed algorithm works well, corroborating the assumption of robustness. The authors also propose a penalty - based alternative that they show do not directly constrain the radius of the search space."
SP:3a3249e97ef2345ea2264de5ed8287e16687838e,"This paper proposes a novel approach to investigate the counterintuitive effect that counterintuitive factors can have on the search performance of mask - based generative models when compared to the unstructured magnitude - based pruning approaches commonly used in the field. The paper proposes to investigate a counterintuitive phenomenon that occurs when the hyperparameters for mask evaluation ( Hval ) and mask discovery ( Hfind ) are decoupled, leading to the observation that a mask generated from a model with worse initial conditions may in fact be better suited to a search task than a model that is better prepared for the task at the start of the evaluation phase. To investigate this phenomenon, the paper considers two scenarios : ( 1 ) a situation in which the parameters of both Hval and Hfind are significantly different across a large number of models, datasets, configurations, and also for one - shot structured pruning. ( 2 ) a setting in which different Hval values yield masks with materially different layerwise pruning ratios.    The paper experiments on CIFAR-10 and MS - COCO tasks in the Unstructured Magnitude Pruning ( UPM ) family, showing that masks generated from Hval - valued models ( which have lower initial conditions and higher evaluation parametrizations ) perform substantially better than those generated from models with values that are similar or identical across all the datasets and configurations. This phenomenon is verified experimentally by comparing the masks generated after evaluation with and without evaluation from the same set of datasets using the same hyperparameter values ( which are assumed to be the same across all of them )."
SP:2d6f5d72b21675f74ff4cde4d16bfb36abd5795f,"This paper proposes a metric called m - coherence ( m - Coherence ) to measure the benefit from a small step along the gradient of any one example in training neural networks with ResNet and EfficientNet. The metric is derived from the observation that networks with similar labels tend to converge to the same output distribution, while networks with different initial distributions tend to deviate from this output distribution during training.   Given a sample of size m, m -coherence is the number of examples in the sample that benefit from any one small step. This metric is tested empirically on ImageNet training and compared to other commonly used metrics, such as O(m ), to understand the evolution of alignment of per - example gradients during training and to provide insights into generalization properties of neural networks. A detailed analysis of this phenomenon provides both a deeper confirmation of CG, but at the same point puts into sharp relief what is missing from the theory in order to provide a complete explanation of generalization in neural networks!    The experiments are conducted on three datasets ( CIFAR-10, Tiny ImageNet, and ImageNet - ResNet ), and the results are reported to support the theory that CG provides a simple unified explanation for memorization and generalization. However, the authors acknowledge that some of their methods may not be reproducible enough for general use."
SP:e7c5de9a475d0ba71bc79580e8436024fb2c6f59,"This paper proposes a new approach to the problem of constructing statistics for generative models where the evaluation of the likelihood function is intractable but sampling data from the model is possible ( e.g. when the likelihood is approximated approximate Bayesian computation or recent neural likelihood methods ). The approach is to frame the task of constructing sufficient statistics as learning mutual information maximizing representations of the data with the help of deep neural networks. The infomax learning procedure does not need to estimate any density or density ratio estimates. The authors apply the approach to both traditional approximated Bayesian computations and recent Neural likelihood methods, boosting their performance on a range of tasks. The main contributions of the paper are the following :   ( 1 ) The authors introduce the idea of “ Mutual Information Maximization ” ( MIME ), which is a learning framework to maximize the mutual information ( mutual information ) between the data and the neural networks ( neural networks ). This is done by learning a KL - regularized version of the KL - divergence between the mean and covariance of a set of samples sampled from the neural network. This mutual information is then used to update the distribution of the mean of the samples obtained from the network using the learned KL divergence. The goal is to avoid the need for estimating the density of any of the sampled samples, which can be prohibitively expensive. ( 2 ) This approach is tested on a variety of tasks, where it is shown to outperform the baselines of both Bayesian Computation ( BC ) and Neural Networks ( NL )."
SP:c5997bf2348e94949684f45fbd418661e85220c1,"This paper proposes a novel image - to - image translation model, TUNIT, that is trained in an unsupervised manner with no paired images nor domain labels. The model learns to separate image domains ( $ \mathcal{L}$ ), and simultaneously learns to translate input images into the estimated domains using the domain labels and domain representations provided by the model. Experimental results show that the proposed model achieves comparable or better performance than the set - level supervised model trained with full labels and generalizes well on various datasets. The proposed model is robust against the choice of hyperparameters ( the number of pseudo - domains ) used to train the model and generalize fairly well against a variety of datasets.    The main contributions of this paper are the following :   1 ) A novel image-to - image model that learns to separately learn to translate to image domains and domains from input images 2 ) A domain - agnostic approach to training the model, where the model does not use labels for the domain representations and uses only the estimated domain representations instead of the labels provided for the labels of the input domain 3 ) A method for training a model that is able to distinguish between input domain representations from domain representations that are sampled from the same domain via image domain labels via domain representations 4 ) An approach to train a model to learn domain representations for an unknown domain from an unknown set of domain representations via image - domain representations 5. The approach is tested on a set of synthetic datasets ( CIFAR-10, MNIST, Fashion - MNIST and Fashion - UCI ) and compared against the TUNITS - trained with labels and full labels."
SP:0cd97e64e638cabbeea0fdef3e9c5b33f4000f72,"This paper studies the implicit bias in the training of deep neural networks trained with ReLU by gradient descent. The main results are the following : - For 1D regression, the authors show that the solution of training a width - n shallow ReLU network is within n−1 / 2 of the function which fits the training data and whose difference from initialization has smallest 2 - norm of the weighted second derivative with respect to the input. The curvature penalty function 1/ζ is expressed in terms of the probability distribution that is utilized to initialize the network parameters, and the authors compute it explicitly for various common initialization procedures. - For instance, asymmetric initialization with a uniform distribution yields a constant curvatures penalty, and hence the solution function is the natural cubic spline interpolation of training data. - In contrast to the results obtained in previous works, the analysis in this paper clarifies important details and allows the author to obtain significant generalizations.   The main contributions of the paper are as follows :   - The authors investigate implicit bias of training neural networks with deep ReLU. The first result shows that the training trajectories are captured by trajectories of decreasing regularization strength with decreasing gradient descent with decreasing mean squared error. The second result generalizes generalizes the generalizes to multivariate regression and different activation functions. In particular, the result focuses on the case where the gradient descent descent descent is parametric in nature. The third result is the result of generalizing the generalization from parametric to parametric gradient descent in the presence / absence of parametric noise. The difference between the two cases is the difference of the difference in the parametric parameters of the second parametric parameter of the first case. - The final result of the work is the same as the one in the previous work, but the difference is magnified slightly due to the fact that the parameters used in the second case are parametric. The authors do not use the magnified term in the third result. 	 The authors conclude the work with a set of experiments that compare the effect of gradient descent training of neural networks of different widths of ReLU with the impact of the corresponding implicit bias."
SP:8b885142facbb3b8db41ec9d83822cee81324694,"This paper studies the problem of weight decay in training deep neural networks using adaptive gradient methods such as stochastic gradient descent ( SGD ) and Adam with decoupled weight decay ( AdamW ). The authors show that the default implementation of L2 regularization ( L2 ) is unstable weight decay for gradient descent and that AdamW is more stable than SGD. They propose SWD ( Stable Weight Decay - SWD ) method to fix the weight decay problem in Adam using SWD method from a dynamical perspective. The main idea of SWD is to replace the regularization method L2 in Adam with a method inspired by SWD in SGD to improve the performance of Adam with weight decay. This method has two main advantages over L2 : ( 1 ) it can handle the instability issue caused by weight decay caused by the gradient descent method and ( 2 ) it has more flexibility to handle weight decay of Adam variants, which have more hyperparameters ( more granularity ).   The main contributions of this paper are the following :   1. They show that L2 is not the same as SGD and that the performance is not as good as Adam when weight decay is fixed with SWD. 2. They use the difference between Adam and SGD in the experiments to show that SWD improves Adam performance and the decay of SGD is less stable. 3. They suggest a way to make SWD more like SGD by making sure that a fixed weight decay can not fix the unstable one."
SP:a3206dc71e32ba1830895bf442d3840f3331a532,"This paper proposes a novel method to combine the strengths of both TM and NMT. The method treats the matched sentence pair of TM as the additional signal and apply one encoder enhanced by the pre - trained language model ( PLM ) to encode the TM information and source sentence together. Additionally, the sentence level retrieval method is extended to the n -gram retrieval method that is proposed in the paper. The proposed method is validated on a mixed test set of multiple domains. The experimental results demonstrate that the proposed methods can significantly improve the translation quality and show strong adaptation for an unknown or new domain.   The main contributions of the paper are as follows :   1. A new encoder is proposed that can efficiently capture the information flow from TM to the NMT decoder. 2. The source sentence encoder and the target encoder are jointly trained to capture the semantic relationship between the source sentence and TM sentences. 3. The authors also propose a sentence - level retrieval approach to retrieve source and target sentence level information during the encoder training."
SP:72b43991a242872b2ceb1861e8ffbdf26c9f4818,"This paper studies deep convolutional networks ( DNNs ) from the perspective of learning rate reduction ( RPR ) and shift invariant classification ( SHR ) based on gradient descent.   The paper proposes to learn RPR and SHR based on an iterative gradient ascent ( ERH ) method, where the goal is to maximize the rate reduction of learned features one layer at a time, one iteration per layer. The paper shows that this algorithm naturally leads to a deep network, where all components of the network have been explicitly constructed layer - by - layer in a forward propagation fashion. This includes the operators ( linear or nonlinear ), architectures, operators, and parameters of the DNN, which are all constructed layer by layer in an explicitly forward propagating fashion. They call this approach a "" white box "" network, which they describe as having precise optimization, statistical, and geometric interpretation. They show experiments that such a network can learn a good discriminative deep representation without any back propagation training and can generalize well to deep convolutions when RPR is enforced. They also show that linear operators of the so - derived DNN naturally become multi - channel convolutions under RPR when the classification loss is rigorously shift - invariant. This is in contrast to the case where the linear operator is not rigorously invariant when the learning rate is RPR based. They provide experiments that compare the performance of their approach to standard DNN learning approaches, and show that their approach is more efficient."
SP:f8b02cf1b918b0956761829ec6ef9127596071ec,"This paper studies the implicit acceleration of gradient flow in two - layer linear models with parametrized linear dynamics. The authors show that implicit acceleration is due to a conservation law that constrains the dynamics to follow certain trajectories. More precisely, gradient flow preserves the difference between the difference of the Gramian matrices of the input and output weights and the amount of acceleration depends on the magnitude of that difference. This paper generalizes prior work and generalizes the results without assuming small, balanced or spectral initialization for the weights, and establishes interesting connections between the matrix factorization problem and Riccati type differential equations.   The main contributions of this paper are as follows :   - The authors study the Implicit Gradient Acceleration of Gradient Flow in Two - Layer Linear Models. The main contribution is to study implicit acceleration and the consequences of this implicit acceleration through the lens of conservation. The results are helpful to understand how the acceleration relates to the expected future rewards for certain actions taken by the stationary and moving components of the model. This is particularly relevant for applications in the strongly convex case, where the data may consist of a mixture of discrete and featureless inputs ( e.g., images, sounds ). The implicit acceleration results from a conservation that constrain the dynamics of the stationary trajectories to follow a certain set of discrete actions. It is important to note that the acceleration does not depend on whether the input features are featureless or not, as this would imply an assumption on the properties of the features that would prevent the model from converging to a state that does not arise in practice. - The results of the paper generalize prior works and generalize the results to cases where the stationary points are not sampled from the data spectrum. The implications of these generalizations are two - fold : - The first is that the results of this study can be analyzed without assumptions on the spectral initialization of the weights used to derive the gradient norms. The second is that it is possible to analyze the results in a setting where the authors do not use spectral initialization and the parameters of the gradient norm are known. This allows the authors to study the implications of the results for the case when the weights are learnt from data."
SP:e5f086c806be88d50e461a782b5b00124f4656fb,"This paper proposes a theoretically sound explainable AI framework based on the explainable model approach from LIME ( Liu et al., 2021 ). The main contribution of this paper is to develop and train a surrogate interpretable model for LIME that can be used to generate explainable explanations for an opaque model. The surrogate model is trained using out - of - distribution ( OOD ) sampling, and is trained to be locally faithful on perturbed instances. To measure the true value of metrics such as fidelity, the paper proposes an estimation algorithm that can measure the fidelity up to any desired degree of accuracy. Based on this surrogate model, the generated explanations are used to train a classifier that generates explanations for a given instance. The classifier is trained with adversarial attacks that are susceptible to OOD sampling as a result of the different types of OODs used in the training of the surrogate model. To test the quality of the explanations generated by the classifier, an error checking algorithm is developed. Experiments demonstrate that the proposed explainable framework, CLIME, outperforms LIME on a variety of synthetic and real - world problems. The experiments demonstrate that CLIME is more stable and more resilient than LIME in terms of the number of instances for which the explanations are reliable."
SP:b1d5ef15772e192eb8c8a0e65b3c21ee7c794295,"This paper proposes a multi - grained language model, called AMBERT ( Multi - Grained BERT ), for NLU tasks in Chinese and English. It is built on top of pre - trained language models, such as BERT, where the tokens in the models are usually fine - granained in the sense that for languages like English they are words or sub -words, and for languages such as Chinese they are characters. In this paper, the authors combine the fine - and coarse - granularity - based language models and show that both have advantages and disadvantages when learning the language models. To this end, they devise a procedure that, for English, takes both the sequence of words ( fine grained tokens ) and the phrase sequences ( coarse grained tokenizations ) as input after tokenization, employs one encoder for processing the sequences of words and the other for processing phrases, utilizes shared parameters between the two encoders, and finally creates a sequence of contextualized representations of the words and phrases. Experiments have been conducted on benchmark datasets for English and Chinese, including CLUE, GLUE, SQuAD and RACE. The results show that AMBER T outperforms the existing best performing models in almost all cases, particularly the improvements are significant for Chinese. They also develop a version of AMBER t - mode, called MARTIN, which performs equally well as AMBERt but uses about half of its inference time. For the experiments on Chinese, they use the same encoder as in the previous paper ( Xie et al. 2020 ). For English, a different encoder is used, but the difference is that MART has the capacity to process the sequences instead of processing the phrases. The authors compare the performance of the two methods and find out the trade - offs between learning the two models. For Chinese, the performance is slightly worse than MART but it is slightly better than AMBER. The experiments on English and the differences are more significant for MART. The manuscript also includes experimental results on the tasks on GLUE and GLUE."
SP:fd1cfe80343d3789227d99d836a5674374a234f5,"This paper proposes a new semantic parsing framework based on Transformer. The main idea is to incorporate Long Short - Term Memory ( LSTM ) into the Self - Attention mechanism of the original Transformer to capture more local context of phrases. Experimental results show that the proposed model captures the detailed meaning better than Transformer, raises local context awareness and achieves strong competitive performance on Geo - MSParS datasets.   The main contribution of this paper is to develop a more detailed meaning representation by learning the phrase dependencies in the sentence. This is different from previous semantic parsing frameworks based on Neural Machine Translation ( MLT ) or Deep Neural Networks ( DNN ) which use the ability to learn long - range word dependencies. DNNs have been used in the past to improve the accuracy of Transformer because they can learn the dependency of the phrases in sentences. However, the one drawback of adapting MLT or DNN to the semantic parsing task is the lack of detail in expressing the information of sentences. Therefore, this work proposes a PhraseTransformer architecture that is capable of a more refined meaning representation and is based on the Transformer self - attention mechanism. This architecture is similar to the one used in Transformer 1.0 ( Xie et al., 2021 ) to learn the phrase dependency in sentence. The difference is that the current Transformer uses the DNN for the self attention while the proposed PhraseTransformers uses the attention mechanism for the sentence embedding. This paper proposes to incorporate the attention mechanisms of the two different types of phrases in the same Transformer architecture to gain better local context. The first is the Long - term memory which is used during the sentence generation process to capture the long - term dependencies. The second one is the phrase embedding used during sentence construction to capture short - term information. The key difference between the two methods is the fact that the former trains the embedding during sentence generation while the latter does not during the parsing process. The authors compare the proposed method with previous methods based on MLT, DNN and NeurASP on the Geo - MSS dataset using Neural Network ( NT - CUB and Neural Network - SOTA dataset using DNN."
SP:2056a65a7500d79465685af883083cd706277c1f,"This paper proposes composite adversarial training ( CAT ) for deep neural networks ( DNNs ) to improve robustness against adversarial perturbations. The authors propose a novel adversarial loss function that incorporates multiple adversarial losses to improve the robustness of the network against perturbation combinations of different compositions of the model parameters. The proposed loss function is based on composite loss theory, which proposes a joint loss function for each of the three types of adversarial attacks that the network can defend against : ( 1 ) the composition of the parameters when the network is robust ( i.e., the number of hidden states that can be attacked with the perturbed values ), ( 2 ) the combinations of the values when the networks are not robust and ( 3 ) the transformations caused by the pertubations ( e.g., spatial transformations ).   The authors evaluate the proposed method on two datasets ( CIFAR10 and ImageNet ) and two adversarial models ( PixPro and PixPro - DCP ), and show that CAT outperforms the state - of - the - art adversarial defense methods by large margins ( by a wide margin in most cases ) when defending against the compositions of pixel perturations and spatial transformations. They also show that the method is more robust than the best known individual pertubation defense methods ( DDT and ADAM ) on the individual perturbing tasks. The method is also more robust on the spatial transformations than ADAM and slightly more than DDT when applied to the two datasets. The main contributions of the paper are the following : 1 ) to develop a method that can handle multiple perturbational losses at the same time, 2 ) to flexibly integrate and optimise losses across the different types of attacks, and 3 ) to train the model robustness on individual perturbated values as well as their “compositions ” ( the values generated by the mixed - up representations of the hidden states during training )."
SP:006e5b9ac9a8eb7223843731488bfefbd8eb09bd,"This paper proposes a new learning method, the Emergent Symbol Binding Network ( ESBN ), to aid the induction of data - efficient induction of abstract rules in deep neural networks. ESBN is a recurrent network augmented with an external memory that enables a form of variable - binding and indirection. This binding mechanism allows symbol - like representations to emerge through the learning process without the need to explicitly incorporate symbol - processing machinery. The authors evaluate ESBN on a series of tasks designed to learn rules in a manner that is abstracted away from the particular entities to which those rules apply ( e.g., entities whose weights are associated with which the learned rules apply ). They show that ESBN displays nearly perfect generalization of learned rules to novel entities given only a limited number of training examples, and outperforms a number of other competitive neural network architectures.    The main contributions of this paper are : 1 ) The authors develop a learning method that allows for data - efficiently induction of rules by leveraging the power of symbol representation induction without the use of symbol processing ; 2 ) They show empirically that the ESBN outperforms competing methods for learning abstract rules using neural network - based methods such as RNNs and RMSNNs, and 3 ) They provide a set of empirical results supporting their method."
SP:4171ce45966ac499f51450a19fb233934c0847f0,"This paper proposes a framework to solve structured language prediction tasks such as entity and relation extraction, relation classification, semantic role labeling, event extraction, coreference resolution, and dialogue state tracking using augmented natural language ( TANL ) instead of task - specific discriminative classifiers. The main idea is to frame the task prediction task as a translation task between augmented natural languages, from which task - relevant information can be easily extracted. The proposed framework, Translation between Augmented Natural Languages, can be used to solve many structured prediction language tasks including entity extraction, nested named entity recognition ( for relation tasks only ), relation classifier ( for semantic tasks ), and meta - role labeling ( for tasks where the goal is to predict the role of the user ).    The main contributions of the paper are as follows :   ( 1 ) The authors propose a new framework that can solve structured tasks by translating between natural language augmented text and structured text. This allows them to avoid the need to train task specific classifiers for each task. Instead, they can use their framework to train a single model to solve all the tasks at the same time ( multi - task learning ). The authors show that their framework can match or outperform task-specific models on all tasks, and in particular, achieves new state - of - the - art results on joint entity extraction ( for example, on CoNLL04, ADE, NYT, and ACE2005 datasets ) and relation classification ( for FewRel and TACRED datasets ) using the same architecture and training same number of neurons. ( 2 ) They also show that the semantic labeling framework can also significantly improve performance in a low - resource regime, thanks to better use of label semantics for semantic role semantics. ( 3 ) They provide the empirical evidence for the effectiveness of their framework."
SP:8f1b2fc6829e0bdfcc981020b0dcf3e63a947910,"This paper studies the problem of entity recognition ( entity recognition ) in NER models with unlabeled entities. The authors propose a general approach to address the problem, which can almost eliminate the misguidance brought by unlabelED entities, through negative sampling. The key idea is to use negative sampling that, to a large extent, avoids training the NER model to identify entities that are negative instances of the annotated entities. This is similar to what is done in [ 1 ], but different from [ 2 ], which pre - trains the language model to discriminate between real - valued and imagined entities.   The authors first provide background information about the entity recognition problem ( EPC ), and then describe the history of NER and its evolution from its current state - of - the - art training methods ( NERNet and NERWorld ). Then, the authors propose three main steps to approach the EPC problem : ( 1 ) reduce the total number of annotated entity instances in the model ; ( 2 ) train the model only on the annotate entity instances ; ( 3 ) use a negative sampling strategy to identify the entities that the model does not recognize as negative ; and ( 4 ) avoid training the model to distinguish between real and imagined entity instances. The approach is evaluated on two synthetic datasets, and two real - world datasets, where the authors compare the performance of their approach with that of the baseline NERNeER model. The experiments show that the proposed approach is more robust to misguiding than the baseline one, and that negative sampling is more effective than training on entity identification than it is to identify entity representations as negative. The main contributions are the following : ( a ) A novel approach to identify and classify entities in sentences that are likely to misguide the model, ( b ) A more robust approach to training to identify which entity misguids the model and which entity is likely to be a negative instance."
SP:dd76ece8d92a8a230a8b43033d8cb2368c677a94,"This paper proposes Acoustic Neighbor Embeddings ( AWE ), where speech or text of arbitrary length are mapped to a vector space of fixed, reduced dimensions by adapting stochastic neighbor embedding ( SNE ) to sequential inputs. In AWE, the distance between coordinates in the embedding space reflects the phonetic confusability between the corresponding sequences. Two encoder neural networks are trained : an acoustic encoder that accepts speech signals in the form of frame - wise subword posterior probabilities obtained from an acoustic model and a text encoders that accept text in the forms of subword transcriptions. Compared to a triplet loss criterion, the proposed method is shown to have more effective gradients for neural network training and gives more accurate results with low - dimensional embeddings when the two encoder networks are used in tandem in a word ( word - word ) recognition task, and when the text encoder network is used standalone in an approximate phonetic matching task."
SP:9142189126b8612ac0acee6fe18a0cfcb70b6545,"This paper proposes a reinforcement learning algorithm for stationary mean - field games, where the goal is to learn a pair of mean-field state and stationary policy that constitute the Nash equilibrium. In contrast to previous work which solves each single - agent reinforcement learning problem via gradient descent and proximal policy optimization, here the authors propose a fictitious play algorithm that alternatively updates the mean field state and the stationary policy via gradient - descent updates of the mean and policy. The proposed algorithm is in stark contrast with previous works which solve each single agent Reinforcement Learning problem induced by the iterates mean field states to the optimum through gradient descent. Furthermore, the authors prove that the proposed algorithm converges to Nash equilibrium at a sub - linear rate.   To the best of my knowledge, this seems the first provably convergent RL algorithm for mean field games that proposes a play algorithm based on iterative updates of both mean and stationary policies. I suggest a brief summary of the contributions before moving to the main text. In short, the main contributions are the following :   1. The authors propose an algorithm that proposes an iterative update method for the mean - Field State and stationary Policy in a stationary mean field game. This is done by iteratively updating the mean Field State using a Gaussian Mixture Model ; the policy is updated using gradient descent updates ; and the updates are made using the proximal gradient updates via the gradient descent update of the policy. 2. The main contribution of the paper is the experimental results obtained by the use of the proposed play algorithm. The experiments show that the obtained from the algorithm outperforms the previous work in terms of the expected return on the cost of the difference between the cost incurred by the mean MDP and the policy cost by a large margin. Moreover, the experiments demonstrate that the algorithm is robust to the choice of hyperparameters used to train the algorithm. 3. I would appreciate the authors for providing more detailed details of the experiments and provide more details of their algorithm in the appendix."
SP:c498f8a199da1818fe64ed88b0825c5aad688aec,"This paper proposes a probabilistic inference framework based on generative flow models. The framework trains a generative model with the property that its composition with the given model approximates the target conditional distribution. By parametrizing this new distribution as another flow model, the framework can efficiently train it using variational inference and also handle conditioning under arbitrary differentiable transformations. The resulting approximate posterior remains a flow, so it offers exact likelihood evaluation, inversion inversion, and efficient sampling. The method is tested on a variety of inference tasks with applications to inverse problems. The experimental results demonstrate that the approach is comparable to simple MCMCMC baselines in terms of the quality of sample quality. Further, it explains the failure of naively applying variational inferred inference and shows that our method does not suffer from the same issue. For the inverse problem, the method is compared with MCMC Inverse.    The main contributions of this paper are the following :   1. The authors develop and study a task that is computationally hard for a large class of flow models : estimate p(x2 | x1 ) for some arbitrary partitioning of the variables x = ( x1, x2 ). This task is defined as the joint distribution defined by a normalizing flow model. 2. Motivated by the hardness of this task, the authors propose a framework for approximate Probabilistic Inference, where the target distribution is assumed to be the same as that of the training distribution. 3. They test the method on the task and show that it is as effective as the MCMC Approach."
SP:1d0f27f61c9d32911b8bd15d6b82ef5eec644f0f,"This paper presents an annotated Electron Microscopy ( EM ) dataset for the Cell membrane with multiple iterative annotations and uncompressed high - resolution raw data for the cell membrane segmentation task, U - RISC. The authors claim that the current popular segmentation segmentation evaluation criteria are not human - based, and propose a new evaluation criterion called Perceptual Haus Haus - Based Distance ( PHD ) to measure the consistency of the human segmentation results. The experiments conducted in the paper demonstrate that the PHD results are consistent with human perception. This observation is supported by a subjective experiment involving 20 people. The main contribution of this paper is the introduction of the EM dataset U -RISC, the largest annotated EM dataset of its kind for segmentation of the Cell membranes. The EM dataset is designed with two iterative manual annotation results under existing evaluation criteria :   ( 1 ) under existing EM evaluation criteria and PHD ( 2 ) under new evaluation criteria.    The experiments show that the human perception of EM segmentations is consistent with the obtained by using PHD. This is claimed to be the first time this has been the case in the field of cell segmentation. The paper also proposes a new per - arm ELBO ( Efficient Cell Membrane Segmentation - based ELBO ) to further investigate this phenomenon. The first ELBO results are presented in Table 1. The second part of the paper presents the empirical results obtained from the ELBO experiments in Table 2. In the experiments, it is shown that the EM results do not correspond to the claimed human perception and that the segmentations obtained by the current segmentation methods have a consistent and divergent properties. Based on this observation, the authors propose to use a different ELBO evaluation criterion ( Perceived Embeddedensity - based Distance ( PEARL ) to investigate the discrepancy between the human and EM perception of the cell segmentations. This paper is presented with the experimental results in Table 3."
SP:8ca7aff87c82be69c9542550c814f52c9419ab0a,"Continual Learning ( CL ) is a learning method that relies on the ability to transfer knowledge from previous tasks and to scale memory and compute sub -linearly with the number of tasks. This paper proposes a new suite of benchmarks to probe the learning algorithms across these new axes. First, it presents a new modular architecture, whose modules represent atomic skills that can be composed to perform a certain task. Learning a task reduces to figuring out which past modules to re - use, and which new modules to instantiate to solve the current task. The learning algorithm leverages a task - driven prior over the exponential search space of all possible ways to combine modules to enable efficient learning on long streams of tasks, which the authors call modular learning. The authors experiment that this modular architecture and the learning algorithm perform competitively on widely used CL benchmarks while yielding superior performance on the more challenging benchmarks we introduce in this work.   The authors also conduct experiments to evaluate the effectiveness of the new modular learning architecture and learning algorithm, which they call Atomic Modular Learning ( AML ). They compare the performance of AML with that of the widely used modular architecture based learning algorithms based on the benchmarks from the previous work. They find that the performance is on par or slightly better than those of the baselines from the original CL method, and slightly worse than the baseline learning algorithm based on GPT-2. They also perform some ablation studies to validate their results."
SP:cc819c61f408e88f247eb87946187ccec3dad32e,"This paper proposes LASIUM, a generative algorithm for unsupervised meta - learning based on synthetic metatask generation using generative models for few - shot classification tasks. The generative model is a linear program that iteratively generates metatasks by generating pairs of in - class and out - of - class samples from the latent space of the task space. The goal is to design a classifier that produces training and validation data for a given training instance of a meta - task. The method is based on LASUM - GAN ( Lee et al., 2020 ), a method for generating latent representations of the latent representation of a task from a training instance and validation samples of the meta - tasks.   The main contributions of this paper are the following :   ( 1 ) A new generative classifier is proposed that generates pairs of classes from a latent representation that can be used to generate training instances of a given task. This classifier can be trained using techniques such as random selection, clustering and/or augmentation. ( 2 ) It is possible to use this classifier to generate synthetic data to validate the training of the training instance. ( 3 ) The training data can then be used for training another classifier. ( 4 ) The validation of the synthetic data can be performed using the proposed method as well. ( 5 ) The proposed method is validated using the synthetic training data and validation training instances using the data generated by the other classifier and the generated pairs of training instances. ( 6 ) Experimental results show that the proposed approach outperforms or is competitive with the baselines of the current un - supervised learning baselines for tasks on the most widely used benchmark datasets ( Few - Shot - Classification - R ( FewShot - R ) and Metatask ( Metaset - R. ( 7 )"
SP:b25771e5c214a352f74ba6196fbd88bca6c43c98,"This paper studies injectivity in generative models for inverse and compressed sensing problems. It first characterizes injectivity of fully connected and convolutional ReLU layers and networks. Through layerwise analysis, it shows that an expansivity factor of two is necessary and sufficient for injectivity. Global injectivity with iid Gaussian matrices, a commonly used tractable model, requires larger expansivity between 3.4 and 10.5. The stability of inverting an injective network via worst - case Lipschitz is characterized using arguments from differential topology. Finally, using an argument based on random projections, it demonstrates that an end - to - end -- rather than layerwise --doubling of the dimensionality of the injective ReLU network can be approximated by injective reLU network."
SP:a95a153d3fe9bcf535ebf8514f51d00df483f210,"This paper proposes a new continuous conditional generative adversarial network ( conditional GAN ), CcGAN, for image generation conditional on regression labels. The motivation for this is two - fold : ( 1 ) Most prior GANs have been designed for categorical conditions ( e.g. class labels ), and conditioning on labels is mathematically distinct and raises two fundamental problems : ( 2 ) Since there may be very few ( even zero ) real images for some regression labels, minimizing existing empirical versions of cGAN losses often fails in practice ; ( 3 ) Since regression labels are scalar and infinitely many, conventional label input methods, such as combining a hidden map of the generator / discriminator with a one - hot encoded label, are not applicable. The authors propose a novel method to incorporate regression labels into the generator and the discriminator. Under mild assumptions, the authors propose two novel empirical discriminator losses, termed the hard vicinal discriminator loss ( HVDL ) and the vicinal discriminate / generator loss ( SVDL / GANL ), which are designed to match the empirical losses of a discriminator trained on continuous and scalar - free Gaussians ( RC-49 ) and a novel empirical generator loss based on UTKFace. Under the same assumptions, a new benchmark dataset, RC - 49, is also proposed for generative image modeling and is used as a benchmark for training discriminators. The proposed method is validated empirically on the RC -49 dataset and compared against the previous cGAN and another existing generative GAN models ( CGAN ) on the Circular 2 - D Gaussian and RC-50 datasets. The experimental results show that the proposed method can generate diverse, high - quality samples from the image distribution conditional on a given regression label. Moreover, the proposed continuous conditional ccGAN can outperform the existing cGAN both visually and quantitatively.    The authors also propose a contrastive loss term to account for the possibility that the regression labels may not be available for all possible values of the class labels under the proposed model. Under this term, a novel generator loss is proposed, which penalizes the generator error bound based on the expected value of a label from the training dataset and penalizes discriminator error bounds based on whether the label is available for the generator or not. The experiments are conducted to validate the effectiveness of the proposed methods."
SP:10dd09ab315870631d1451d200f2c87a023f8226,"This paper proposes a novel active learning ( AL ) algorithm to reduce the sample complexity of active learning by training a classification network and querying unlabeled instances to annotate instances to be annotated by a human - in - the - loop. In contrast to previous works combining AL and SSL ( ASSL ) algorithms, the authors propose an AL algorithm that actively queries instances to improve the convergence of convergence of the proposed algorithm ( AL - CRC ) with respect to the labeled set. The main contributions of the paper are as follows :   1. The authors propose a novel AL algorithm, named Active querying - based AL ( AC ), which is based on the recently proposed active learning algorithm ( SSL ).   2. They propose to use the same training parameters as in ASSL ( AS, a prior work ) to train an AL network using the AC algorithm but using far less labeled samples ( $ \epsilon$ per instance ). The difference between AC and SSL is that AC trains the classifier using the labeled instances, while SSL trains a classifier with the queried instances, but without the label labels. The advantage of AC is that it allows the human - annotated classifier to explore more diverse instances ( $ n$ vs $ k$ ), and the disadvantage is that the human annotates only a small fraction of instances, meaning that it is less able to make meaningful annotations on all the instances. 3. Based on the proposed AC algorithm, they propose to augment the training parameters of the AL algorithm with a manually annotated instance to increase the average convergence of $ \eps$ to the rate of convergence under the assumption that AC has a lower bound on the number of instances that the algorithm needs to learn from. They evaluate the proposed method on a set of synthetic data, and show that the proposed AL - AC outperforms both ASSL and fully supervised learning ( SL ) on the synthetic data."
SP:7f3947c3fa5b09674507d8f3e10d9280376ecb94,"This paper proposes a federated learning method for training neural network models, where the server orchestrates cooperation between a subset of randomly chosen devices in each round of training. The motivation is that the minima of the local - device level empirical loss is inconsistent with those of the global empirical loss, so that in the limit the global and device solutions are aligned. Different from recent prior works that either attempt inexact minimization or utilize devices for parallelizing gradient computation, the authors propose a dynamic regularizer for each device at each round to ensure that the global solutions of the proposed method are compatible with the device solutions. They demonstrate both through empirical results on real and synthetic data as well as analytical results that their scheme leads to efficient training, in both convex and non - convex settings. While being fully agnostic to device - wise the method is robust to large number of devices and robust to the number of training sets.   The main contributions of the paper are as follows :   - A novel method for distributed training of neural networks under the assumption that the training is done in rounds, where each round is a collection of rounds and the goal is to train a set of models on each round's training data. The authors argue that this approach is more efficient than training on individual rounds as it allows for more device - level computations to save transmission costs and also allows for a more global solution to the global loss. The method is applied to training neural networks on MNIST and CIFAR-10 datasets, training the models on a mixture of real data ( real - synthesized MNIST, synthetic data and MNIST augmented with real data ), and obtaining results that are comparable to training on real data. They show that their method leads to similar or better results on average compared to other methods. They also show that the regularizer is more robust than the device - based regularizer in terms of global loss, device loss and device loss."
SP:a3fbb073b0e2371b20d5d9df6ab829673f90354f,"This paper studies the problem of speeding up contrastive learning with little or no loss of accuracy using self - supervised methods. Contrastive learning is a popular technique to learn high - dimensional representations from a large set of synthetic data using an encoder - decoder setup. However, due to the high computational cost, it is computationally challenging to apply this technique to image classification tasks. This paper proposes a way to accelerate the learning process by using additional intermediate contrastive losses. The main idea is to use these losses to approximate the similarity between the intermediate layers of the decoder and the output of the final contrastive layers. The idea is that the intermediate layer similarity is a good surrogate for the final similarity of the outputs of the contrastive algorithm, and vice versa, so that the learning can be sped up more quickly. To this end, the paper proposes to truncate the back - propagation of the gradient descent update and only update a part of the parameters of gradient descent updates for each image. The paper shows that this accelerates the learning significantly for ImageNet linear classification and other downstream tasks.   The main contributions of this paper are the following :   1. It proposes a novel approach to estimate the distance between the top - k and the bottom - k layers of an image from the perspective of the learned representations from the supervised learning algorithm. This is a computationally reasonable way to estimate this distance since the distance is only proportional to the similarity in likelihood of the images from the two classes of the input pairs of the same dimension. The method estimates the distance in terms of K(d / image ) as a function of the distance to the ground - truth of the image from each pair of classes. 2. It uses this metric to estimate how fast the learning is going ( with little loss in the computation cost ). 3. It shows that the average gradient update speed - up for contrastive algorithms is fast for gradient updates for image classification. 4. It also shows that it is possible to adjust the gradient updates based on the intermediate losses to filter easy regions of each image in each gradient update to increase the average distance between pairs of images. The experiments show that this approach speeds up image classification by a significant margin on ImageNet classification tasks using ImageNet - R, ImageNet-SV ( Figure 4 ), SwAVR ( Figure 5 ), which compares the performance of the proposed method with that of several supervised methods ( e.g., DeepGAN, DenseGAN, VGG16 ). The results show that the proposed approach is competitive or slightly faster than the supervised methods on a small number of tasks, but with much fewer"
SP:5b5e705ea1ee1b857e17e64d560a39052804949d,"This paper studies the actor - critic algorithm, where the actor and critic policy updates are computed by applying the Bellman evaluation operator on the actor policy gradient direction while the critic policy gradient is computed using the critic update. The main focus of the paper is on the single - time - scale setting, where both the critic and actor policy updates can be obtained via the same Bellman operator.    The paper considers the global convergence and global optimality of the algorithm in two settings : linear and deep neural networks. In the linear setting, the authors prove that the actor sequence converges to a globally optimal policy at a sublinear O(K(K−1 / 2 ) rate, where K is the number of iterations. The authors also consider the deep neural network setting where the goal function is represented by a linear network. In this setting, under the broader broader scope of policy optimization with nonlinear function approximation, the author proves that actor-critic with deep neuralnetwork finds globally optimally performing policy with sublinear rate for the first time. The author also considers two settings where actor sequence and critic update can be computed simultaneously, and for both cases, the results are similar to the linear settings. In general, the main contribution of this paper is to provide the empirical evidence that the proposed algorithm achieves global convergence with a lower bound on the rate of convergence, while the deeper setting proves that the algorithm is able to converge to globally optimal policies at a lower rate. The major contributions of the work are the following :   ( 1 ) The main contribution is a careful analysis of the assumptions of the proposed in the paper. The reviewer's paper is carefully crafted to ensure that the main results are easy to compare with the state - of - the - art. This includes making use of the same assumptions in both settings that the authors consider, such that they do not lose any significant ground - truth information about the assumptions in the other works. This is important for comparing the two sets of results. ( 2 ) The second major contribution is the careful analysis that ensures that the method does not deviate too much from the accepted global norm of the global norm in the two settings, which the authors claim is necessary to avoid catastrophic overoptimism."
SP:26705a4dc305cce336f657c5937d1f5b4209548a,"This paper proposes embedding the field level, log level, and log sequence level of log files into vector representations to represent the data at a few levels of abstraction in log processing. The motivation is that log files are rich containers of data because they can store a sequence of structured textual and numerical data. Most sequential forms of data including natural languages and temporal signals can be represented as logs. The authors propose to embeddings the data representation at the level of abstraction using Transformer Networks ( TNs ). They show how a number of log processing applications can be readily solved with the representation obtained from TNs.   The main contributions of this paper are as follows :   1. The paper proposes to embed data representations for the log file at three levels : field level ( log, log sequence and log - sequence levels ). The representation for each level can be computed from the previous level and serves as interfaces to downstream applications. 2. It introduces a new embedding operation to encode numerical and textual information that is suitable for log embedding. 3. It applies the embedding to embedding vector representations for log files and shows how it can be used to solve problems in several cases ( e.g., log verification, log classification, log file classification, batch normalization ). 4. It compares the performance of different embedding methods with the one proposed by the authors and shows that it is the best option for solving log processing problems."
SP:165c51a16f17fb8726e968f8b34742b62011d60e,"This paper proposes a formalism for learning deep convolutional neural networks ( CNNs ) based on wavelet decompositions, motivated by the similarities between trained CNN kernels and oriented Gabor filters for addressing this problem. The formalism consists of three components, i.e., the separable wavelet transform, the 2D dual - tree transform, and the multi - tree real and complex wavelet transforms. The paper evaluates the formalism with three variants of the wavelets, using the AlexNet architecture for image classification as an example. The experiments show that the first variant of the proposed method achieves the accuracy rate of standard AlexNet with a significantly lower number of parameters, and an interpretation of the network that is grounded in mathematical theory. The second and third variants implement the features extraction techniques in the paper, taking advantage of their feature extraction properties such as directional selectivity and shift invariance. The last variant does not utilize these features."
SP:d0a284da462584724ba6a3a48c9e986d391233f6,"This paper proposes a coach - player framework to coordinate players in multi - agent multi - goal - pursuit teams. The framework assumes that the players have a limited view of the environment and the coach has a complete view, and three components are proposed to facilitate the communication between the coach and the players. The first component proposes an attention mechanism for the coach to keep track of the players ’ observations, and the second proposes a variational objective to regularize learning. The third component is an adaptive communication method to let the coach decide when to communicate with different players.   The authors test the proposed framework on the task of zero - shot generalization to new team compositions with varying numbers of heterogeneous agents. They show that the performance of the proposed method is comparable or better when used with a coach and no players ( but no communication ) than the performance when using the strategy with all players but no coach. Moreover, the results demonstrate that the coach can coordinate players as little as 13 % of the time using the adaptive communication strategy. The authors also study the impact of the strategies on resource collection tasks in the multi -agent particle environment."
SP:4eb662b527d556758aaa1a0b589495fcc337fad0,"This paper studies the influence functions of the commonly - used first - order influence function in neural network models with non - convex loss functions. It is well - known that the influence function can be implemented efficiently as a post - hoc access method requiring access only to the gradients and Hessian of the model. This paper provides a comprehensive and large - scale empirical study of the successes and failures of influence functions in two deep learning settings :   ( i ) influence estimates are fairly accurate for shallow networks, while for deeper networks the estimates are often erroneous ; ( ii ) the accuracy of influence estimates can vary significantly depending on the examined test points ; and ( iii ) the results suggest that in general influence function influence estimates in deep learning are fragile and call for developing improved influence estimation methods to mitigate these issues. The authors conducted experiments on different network architectures ( NN, MNIST, CIFAR-10 ), training with weight - decay regularization ( training with a weight - decay regularization of the training samples ), and extensive experiments with different datasets. They found that shallow networks have better influence while deeper networks have worse influence. They also found that the success rate of using influence functions is larger for deep networks with shallow networks than shallow networks with deeper networks.    The authors also conducted experiments to investigate the effect of the architecture of the network on the success and failure of influence function, and found that success rates are higher for NN architectures with shallow network architectures and lower success rates for deep network architectures with deep network datasets with deep architecture. They conducted experiments in the deep learning setting with different architectures and different datasets to evaluate the impact of the influence and suggest that influence functions may be more sensitive to the architecture."
SP:5fea74a2031d097a99dacf613bedcb054b0c3831,"This paper studies the ability of language - based pre - trained language models ( LPRMs ) to do well on the next word prediction task on text classification. The paper proposes to formalize the connection between the pretraining task of next - word prediction and text classification by considering the following questions :   1 ) What is the intuitive connection between pretraining language models and the text classification task?   2 ) How can we mathematically formalize this connection and quantify the benefit of language modeling for the downstream task of text classification? The paper hypothesizes that the classification tasks of interest can be reformulated as sentence completion tasks, thus making language modeling a meaningful pre - training task.   3 ) With a mathematical formalization of this hypothesis, the paper proposes a new objective function that performs well on some classification tasks that can be used to design a new language model ( L2LM ) that can generalize beyond the pretrained language model to perform well on downstream tasks. The authors conduct extensive experiments to validate their hypothesis and show that language models that are pretrained using large text corpora can learn features that can linearly solve such classification tasks with O( \O( \sqrt{( \mid ) ) error ) error, thus demonstrating that doing well on language modeling does not only depend on the language modeling but also has a major impact on the accuracy of the language model. The experiments are conducted to validate several assumptions under which the paper derives its theoretical findings and to compare the performance of the LPRM with that of a language model that is not pretrained with the one that is pretraining. They also conduct some ablation studies to explore whether there is a better way to train language models or not, and find out a balance between the two. The experimental results demonstrate that the language models do better than the other language models in terms of accuracy but not all the time, which is surprising since the paper claims to have used the same set of language models for all the tasks."
SP:a67da438e9821010284416170c3699ae7ff96c99,"This paper proposes a membership error - based detection method for detecting if training data samples used to train a neural network model are obtained from unauthorized sources. The idea is to use the reconstruction error ( used in image generation models ) to distinguish between easy - looking images seen in training and images that have never been seen before that are difficult to classify. Based on this idea, the authors propose to use a novel difficulty score for each image to measure the difficulty of classifying the easy and difficult images with respect to each other. The difficulty score is computed by summing over the reconstruction errors computed from the training data and the easy / difficult images. The authors compare their method with two other methods for detecting the use of hard - to - classify images in the training of neural network models : ( 1 ) the conditional image generation ( CIG ) method and ( 2 ) the membership error method. The CIG method is more accurate than the image generation model ( ImageNet ) on a number of benchmarks. However, the manuscript shows that the CIG methods are less effective at detecting the difficult images compared to the easy images. To overcome this issue, the paper proposes to score each image based on the difficulty score obtained by CIG and then use the score computed from reconstruction error of the easy image to assign a score to the difficult image. This score is then used to assign the score of the image to classify the image as hard / difficult. The manuscript includes experimental results on image classification and membership error for CIG model and image generation and uses it to compare the score for image reconstruction error and the difficulty scores for the difficult / easy image. The experimental results are compared with the original training data, image generation trained with CIG models and image synthesis model with image generation with image synthesis loss loss loss. The results show that CIG has better reconstruction error compared to image synthesis error for difficult and easy images and that the novel score is better for classifying difficult images than the original image error. The paper also presents experimental results for image generation on CIG, image synthesis with image loss loss and a set of additional datasets ( e.g. CIFAR-10, MNIST and Fashion - MNIST )."
SP:6fe23ebe09f2a4e42a21598f8e9c79edeca99863,"This paper proposes a differentiable architecture search method that treats the continuous relaxed architecture mixing weight as random variables modeled by the Dirichlet distribution, with gradient - based optimizer in an end - to - end manner. This formulation improves the generalization ability and induces stochasticity that naturally encourages exploration in the search space. To alleviate the large memory consumption of differentiable NAS, the authors propose a simple yet effective progressive learning scheme that enables searching directly on large - scale tasks, eliminating the gap between search and evaluation phases. Extensive experiments demonstrate the effectiveness of the proposed method. The authors obtain a test error of 2.46% for CIFAR-10, 23.7% for ImageNet under the mobile setting, and a state - of - the - art 4 - layer neural architecture search algorithm under the NAS - with - no - memory setting.   The authors also provide insights for the effective design of Neural architecture search algorithms, including an analysis of neural networks used for the design of neural network architectures."
SP:c590d0ed2487b42480b53fc077546a4a0bc27a78,"Recent work has shown that Fourier features in positional encodings outperform ReLU networks for approximating low - dimensional but complex functions, such as representing images as function of pixel coordinates, solving differential equations, or representing signed distance functions or neural radiance fields. In this paper, the authors propose and empirically demonstrate that an arguably simpler class of function approximators that can work just as well for such problems : multiplicative filter networks. In these networks, they avoid traditional compositional depth altogether, and simply multiply together ( sinusoidal sinusoid or Gabor wavelet functions ) the inputs that appear in the input space. They show that these multiplicative filters can, when compared to recent approaches that use Fourier feature with ReLU network or Sinusoidal activation networks, largely outperform or match the performance of these approaches on the domains highlighted in these past works.    The main contributions of this paper are the following :   1. The authors propose a new type of positional encoder, called multiplicative filtration network, which can be viewed as a linear function approximated with an exponential number of Fourier coefficients. This allows them to avoid the compositional problems that arise when the input is represented as a weighted sum of two functions, where the first function is the sum of the functions of the second function. The second function is simply the average of the two functions. Theoretical guarantees apply to this class of encoder that the $ \mathcalibration$ on the input $ x$ are independent functions that do not depend on the inputs $ x$. The authors argue that this guarantees are important for understanding the underlying structure of the data and ensure that the functions are additive in nature and do not suffer from lack of expressiveness due to lack of signal - to - noise correspondence between the input and the output functions. They use the following guarantees to motivate the construction of their filter network : 1. For each input x : $ x = f(x^2^T)$ where $ x^T \leq_{\theta}$ is a function of $ \theta_t$, $ f(X)=f(y ) = y^T$, where $ y$ is the number of units used to represent the input x.   2. For the authors consider two types of functions : $ \tilde_{\textrm{Fourier}$ and $ \gamma_t_{\mathcal{G}"
SP:f5be855300f63c185a006834302bd4b033b56258,"Gradient - based meta - learning is a popular technique to train meta - models by backpropagating gradients through an inner loop that optimizes task - specific meta - gradients by an outer loop, and then meta - gradient updates the inner loop via gradient descent back through the gradients to update the meta - model. The authors propose an extension to gradient descent called teacherstudent scheme to enable the gradient - based gradient algorithms to explore long horizons by the inner loops. The teacher student scheme consists of a student network that is trained with gradient descent, a teacher that acts as a teacher student, and a teacher - student algorithm that is used to backpropagate the gradient descent update through the student - teacher algorithm to expand the search space of meta - generative models. The proposed teacherstudent algorithm has the following steps :    1. Train the student network using gradient descent.   2. Train a set of gradient descent updates for meta - generic meta - learners based on the teacher student algorithm. The gradients used in the updates are the same meta - generalization parameters ( gradients that do n’t change much between training and testing ) as those used in gradient descent. 3. Update the gradient updates of the teacher-student algorithm using the updated meta - generalized gradient updates using the gradient update step of the updated gradient updates for the task - generic and meta - specific models. 4. Use the same teacher student teacher and gradient descent algorithm for all the meta learning tasks except few - shot learning, long - tail classification, meta - attack and meta-learning. The approach is evaluated on four tasks and compared with the approach applied to three meta learning algorithms, where the evaluation consists of three steps : ( 1 ) Few - Shot Learning, ( 2 ) Metaset learning, ( 3 ) Meta - Attack. The main contributions of the paper are the extensions to the teacherstudent and gradient - descent."
SP:0361e02d56b7d121cb5ede1cb582284cc18fc599," Offline Reinforcement Learning ( offline RL ) is a model - free and model - based approach to learning policies using unlabeled offline datasets. Standard off - policy RL algorithms are prone to overestimating the values of out - of - distribution ( OOD ) actions, which is why they are not suitable for offline RL. This paper proposes behavior regularization to constraints the learned policy within the support set of the dataset, using an analytical upper bound on KL divergence as the behavior regularizor to reduce variance associated with the variance of the KL divergence estimations used in the algorithm. To prevent catastrophic performance degradation due to rare OOD actions, the algorithm also proposes a gradient penalty term to the policy evaluation objective to penalize the gradient of the Q value w.rt the out -of - distribution actions. On offline RL benchmarks, BRAC+ outperforms the state - Of - the - art model-free and model based approaches.    The main contributions of this paper are the following :   1. The paper proposes a behavior regularized offline RL algorithm called BRAC+. The main idea is to learn effective policies by learning effective policies using previously collected datasets using OOD dataset. 2. The algorithm proposes to use state - dependent Lagrange multipliers for the distribution of distributions to encourage more freedom of deviation to high probability ( more explored ) states leading to better rewards while simultaneously restricting low probability ( with respect to KL divergence, low probability ) states to prevent out-of - contribution actions. 3. The method is evaluated on benchmark offline RL datasets and compared with other algorithms and achieves state - of the art performance."
SP:b2cfb380aa2a21f72f508b453cf5949257a5b4ec,"This paper proposes Adjoined networks as a training approach that can regularize and compress CNN - based neural network architectures. The main contribution is a one - shot learning paradigm that trains both the original CNN network and a smaller network together, where the parameters of the smaller network are shared across the larger network. This is in contrast to standard training approaches that train both the larger and the smaller CNN network separately. The theoretical analysis of the regularization behavior of the adjoint training paradigm is provided in Section 3. Empirical evaluation is carried out to show the effectiveness of the compression and regularization strategy. For resnet - 50 trained adjointly on Imagenet, the authors are able to achieve a 13.7x reduction in the number of parameters1 and a 3.9x improvement in inference time without any significant drop in accuracy. For the same architecture on CIFAR-100, the same adjoint network training with the standard training method leads to a reduction of about 5.6x reduction. The authors also provide empirical evaluation of both compression and compression behavior of adjoint networks trained with the compression strategy."
SP:dba40073f79143e5355d194aa16db9eee0267a5d,"This paper proposes a new algorithm for exploration in reinforcement learning ( RL ) called - greedy exploration to replace greedy exploration. The main motivation of the paper is that greedy exploration suffers from lack of temporal persistence, which limits its ability to escape local optima. To address this limitation, the paper proposes to apply a temporal - extended version of greedy exploration, i.e., a greedy exploration algorithm that repeats the sampled action for a duration ( $ t$ ) over a set of actions ( $ m$ steps ). The proposed algorithm, named - greedy - repeats, is simple and elegant, and it is easy to understand how it relates to previous work on exploration in RL, such as EB - greedy.   The main contributions of this paper are as follows :   1. It proposes a temporal extension of the greedy algorithm, called $ \mathbb{T}$, to replace the greedy exploration method, which is based on the idea that temporal persistence is limited for greedy exploration and is therefore more suitable for applying it to longer - term reinforcement learning problems. 2. It introduces a class of distributions, inspired by ecological models of animal foraging behaviour, of which $ \epsilon$ is added to the training distribution to encourage dithering. 3. It experiments with different iterations of greedy - repeated - actions, and finds that for long - duration actions, the proposed algorithm performs better than greedy exploration on average. 4. It is then experimentally tested with different combinations of $ \eps$ of $ t$. The experiments show that the proposed by the paper ( $ \beta$-greedy - repeats and $ \mu$-reinforced actions ) outperform greedy exploration by a large margin on average, and greedy exploration with a small margin on a small number of samples."
SP:5efb581a368ace3bd085d48801a899559d6a43ef,"This paper studies the implicit regularization of gradient descent with infinitesimal initialization in the context of Greedy Low - Rank Learning ( Greedy LR ). Previous work from the literature on gradient descent and norm minimization has shown that gradient flow with infinite initialization converges to the solution that minimizes the nuclear norm, but a series of recent papers argued that the language of norm minimisation is not sufficient to give a full characterization of the regularization process in gradient descent. This paper provides theoretical and empirical evidence that for depth - 2 matrix factorization, gradient flow   withinfinite initialization is mathematically equivalent to Greedy LP - learning, a rank minimization algorithm, under some reasonable assumptions. This generalizes the rank - minimization view from previous works from a much broader setting. It also enables the authors to construct counter - examples to refute the conjecture from Gunasekar et al. ( 2017 ) that the benefit of being deeper is that the convergence has a much weaker dependence over initialization magnitude so that this rank minimizability is more likely to take effect for initialization with practical scale.    The main contributions of this paper are the following :   1. The authors develop and study a simple heuristic rank minimisation algorithm, GreedyLP, for the case where the number of layers is polynomial in the order of decreasing importance. This allows them to generalize rank - minimizing gradient descent from rank - matching - based to rank - based learning. 2. They use it to train a neural network that learns to rank rank minimize the rank of the gradient norm corresponding to the lowest rank in each layer. 3. The algorithm is applied to training the neural networks in two cases, where the first layer is a Gaussian neural network, and the second layer is an extension of the Gaussian. 4. The second case is used to train the neural network without the parameter $ \mathbb{R}$, and it is expected that the parameters of this second layer will be similar to the first one. 5. The neural network will learn the parameters from the first and second layer, but the parameters will be from the same distribution. The experiments compare the performance of the proposed method with and without infinite parameter initialization and show that for both methods, the performance is comparable or slightly better on average cases where the average value is higher, but worse for the first."
SP:7f997cf7a63a7330fc12fd525516080c91a3cb9b,"This paper introduces model patching, a two - stage framework for improving robustness of classifier - based machine learning models. The framework trains a classifier with data augmentations that deliberately manipulate subgroup features within a class and learns semantic transformations between them, then trains the model to be invariant to subgroup differences. Model patching is used to mitigate performance differences between models trained on real - world skin cancer classification data that exhibit disparities in the presence or absence of spurious bandage features.   The framework is designed to work in two stages. In the first stage, the classifier trains a feature extractor and classifier. The classifier is trained with data augmentation that deliberately manipulates sub - group features within the class. The second stage trains the network to predict the feature representations for each subgroup from the class labels. The network is trained to be robust to the subgroup feature manipulation. This stage is named patching ( stage two ) and is similar in principle to what is done in stage one ( stage one ) of model - based patching [ 1 ]. The difference is that in stage two, the network does not train a separate classifier to predict features for subgroup data augmented from class - based features. ( 2 ) In the second stage ( stage three ), the model is trained for patching on all subgroups, except intra - class and inter - subgroup ( using a CycleGAN ) augmentation, which is trained using the original classifier but augmented with features from other subgroups. ( 3 ) the network learns features from all subgroup augmented classes and learns class representations from all other than the primary classifiers. ( 4 ) The network performs patching as if the subgroups were not included in the classifiers predictions, which results in robust performance on the real world dataset ( with reductions in robust error of up to 33 % relative to the best baseline. The authors evaluate the proposed framework and its effectiveness on the three benchmark datasets ( real world and synthetic skin cancer data ). The experimental results show that the proposed model does not perform significantly worse than the baseline model ( on real world data ) when subgroups of the target class are included or missing spurious bandages. The model performance is evaluated on synthetic data ( e.g., skin cancer dataset with and without bandage )."
SP:de6cea1e35a0555175e17546a93422e9a96a511e,"This paper proposes Gradient Grafting - based Rule - based Representation Learner ( RRL ), a classifier that automatically learns interpretable nonfuzzy rules for data representation using a discrete model with discrete parameters and structures. It is claimed that rule - based models are hard to optimize, especially on large data sets, due to their discrete parameter and structure. To train the non - differentiable RRL effectively, the authors project it to a continuous space and propose a novel training method, Gradient Gradienting, that directly optimize the discrete model using gradient descent. An improved design of logical activation functions is also devised to increase the scalability of RRL and enable it to more efficiently capture the features of the data sets. The authors conduct experiments on 9 small and 4 large data Sets to demonstrate that RRL outperforms the competitive approaches, has low complexity close to the simple decision trees, and is rational for its main technical contributions.    The main contributions of this paper are the following : 1 ) A new classifier, named Rule - Based Representation learner, a discrete - valued model with interpretable and parametric non - fuzzy rules. 2 ) An improvement in the design of the activation functions of the RRL classifier to allow it to capture more interpretability for the data representation produced by the classifier. 3 ) Gradient descent training method to learn interpretable, parametric rules for the training of the model."
SP:e36388a9452e557dd51bf0170bf2f9da22271a49,"This paper proposes a novel regret minimization algorithm ( RGM ) for structured biological simulations. The RGM algorithm is based on the invariant risk minimization ( IRM ) framework from prior work ( Liu et al., 2018 ) and extends IRM by recasting the optimality condition in terms of predictive regret as a joint optimality - optimality gradient recasting, where optimality is defined as the difference between the expected regret of the predictor and that of the simulated model ( oracle ). The main idea of the algorithm is to use the held - out trajectories in IRM to approximate the trajectories of the model and the model - free oracle in a closed - form, where the oracle has access to all trajectories but the predictor has only access to the closed form trajectories. The proposed RGM is evaluated on three tasks ( molecular property prediction, protein homology prediction, and stability prediction ) and compared with an oracle with hindsight access to a single training environment. The experiments show that RGM significantly outperforms previous state - of - the - art methods.   The main contributions of the paper are the following :   1 ) An algorithm to extend IRM from closed form to structured form, named RGM - SGD. 2 ) An extension to the IRM - IRM framework that allows for structured regressions ( SGD - RGM extension ). 3 ) A set of experiments to evaluate the stability of the proposed method, called RGM + EMA."
SP:cad3ed2fba57faf17a3e8899dc5a744d5358aa68,"This paper proposes a new cross - probable approach for retrieval of text from BERT text - vision models. The proposed approach is motivated by the fact that cross - modal attentions are computationally expensive to implement in textvision tasks and is therefore impractical for large - scale search. To alleviate this issue, the proposed approach proposes to split the text query into two parts : the first part is a set of self - supervised queries using the BERT model ( e.g., text - clustering ) and the second part is an extension of the cross - probe approach. To handle the two types of queries, the authors propose a new attention mechanism ( Attention Slot ) which is a weighted sum of the average of the first and second query's queries. The authors evaluate the proposed Cross - Probe ( CRP ) approach on two public benchmarks ( CIFAR-10 and STL-10 ) and compare the cost - effectiveness and the efficiency of the proposed CRP.    The main contributions of this paper are the following :   1 ) A new approach for cross - probing BERT models ;   2 ) A better way to split text query and cross - probe in order to reduce the computation cost of the CRP approach ; and 3 ) An improved version of the Attention Slot to handle the different query types."
SP:51fd82de525fcb738fdeaeeae20fbb2cdf975f0c,"This paper proposes a new type of Actor, named forward - looking Actor or FORK for Actor - Critic algorithms, which is a model - free extension of ActorCritic. For the actor - critic algorithm, the input is a set of actor tokens followed by a critic. The authors show that the FORK algorithm is able to solve Box2D, MuJoCo, and BipedalWalkerHardcore in a continuous state - action space. Experiments are conducted on 6 environments with continuous state and action spaces, and they show significant performance improvement FORK can bring to the state - of - the - art algorithms. They also propose a variation of FORK that further solve BipedALWalker hard core in as few as four hours using a single GPU.   The main contributions of this paper are the following :   1. A new actor type, named FORK, is proposed. The key idea is to use actor tokens as input to a critic, and the output is output. This is similar to Actor - critic, except that the critic does not need to know the actor tokens ( it is only the critic's input ). Theoretical analysis is performed to show that FORK is a better actor than Actor, and it is possible to learn the actor token from the critic. 2. Experimental results are presented on 6 Box2DP environments, showing significant performance improvements for FORK compared to Actor. 3. The main contribution of the paper is the introduction and analysis of a new class of critic, the Forward - Looking Actor."
SP:6e730239e6e8b43c4988dd61dca30f15dc039ef7,"This paper proposes FedBE, an aggregation algorithm to aggregate local and global learning models into a single global model when users have non - i.i.d. data. The authors show that FedBE can be constructed by simply fitting Gaussian or Dirichlet distribution to the local models to get distribution for global models. The method is based on Bayesian inference from the perspective of sampling higher - quality global models and combining them via Bayesian model Ensemble. The empirical studies validate FEDBE ’s superior performance, especially when users ’ data are not i.i.d., when the neural networks go deeper, and when the training data is sparse."
SP:3ac5f437fc349a33810d0645664d1c448528af74,"This paper is a collection of e - mail series of question and answer questions written in the form of question - answer pairs with the goal of encouraging readers to share information about themselves and their experiences in order to better understand the world around them.   The goal is to inspire and inform people about the importance of safety and respect for human dignity in online interaction with computers and the environment. To achieve this goal we have collected diverse sets of experiences from people all over the world from all walks of life and use them to inform us what to expect in the coming years ahead. The responses are written in an easy - to - read fashion using multiple choice questions and answers which are broken down into sections for each language ( e.g., ""What do you know about the states in the U.S. from the point of view of a first - person perspective?"" and ""What are your top five U.N. news stories from the past week or so?"" ). The question - and the answer - is in between each one after the other - about the safety and importance of keeping a clean and well - behaved electronic device in the home of President Barack Obama in the White House for the purposes of international relations and human dignity. The answer is a mix of English and Chinese ( with emphasis on the former in the citations and the latter on the latter for privacy reasons ). In the middle of the last leg of this sentence the author(s ) write that they have collected a large amount of data in their travels and have been able to generate a lot of interesting and useful information. The response is a bit by bit - by - depending on the situation and the question - it can be in English or Chinese ( for example - for the question of whether or not to switch to English in the next time round the vote is to go for English or not at all - it depends on the choice - it could be in the former or the latter in the case of the latter - it is not entirely clear to me what is the difference between the two in terms of the quality of the data collected so far. I have read the responses and most of them agree that English is improving but the quality is still lagging behind the other than in the sense that it is now closer to 0. The response from the Chinese side is still very similar to what it was a week ago but the difference is that it has not reached in the past few days or even a day or two ago and it is still not quite there yet. The difference between English and the Chinese is more or less similar at a ratio of 0.7 and 0.8 but the fact that the Chinese are starting to pick up on words and phrases from the English"
SP:efa2343ead47263a0d09e1c17f9aa044605b9650,"This paper presents a priori finite - time convergence analysis of the loss function of deep neural networks based on control theory and supervised learning. The setting is deterministic control theory, where the weights of the network are control inputs and learning translates into a tracking problem. The authors formulate the supervised learning framework as a control problem with weights $ \theta$ acting as inputs and learnable functions $ L_{\theta}$ as outputs, and formulate the problem as a convergence analysis with boundedness of input variables $ \mathbb{R}$, where $ D$ is the weight matrix of the neural network and $ T$ is its output function. They derive a formula for the upper bound on the settling time $ t$ which is the average of the mean and standard deviation over all weights in the network. This formula is then used to derive the convergence analysis $ \tilde{T}$ for the set of neural networks with fixed weights $ T$. The convergence analysis is done using the following assumptions : $ T = \sum_t(T)-T(T)$, $ T \to T(T ) = T$ ( Note that the assumptions are assumptions on the parameters of the control problem and the learning problem, and that T is a weighted sum of two functions.   $ T_t = T_T\to T_\pi(T_t, T_s )$    This gives rise to a loss function $ \epsilon$ where $ E(t_t )$ is a function of the value of the second order of the weights $ t_t$ that depends on the first two functions $ T(t|T_s|, T_{t_s }. The first function is used to train the network, and the second function is the one used to update the weights in training. The loss function can be seen as the average loss of the two functions ( the first one updating the weights since the first function was updated when the weights are updated according to the new values in the training data. The analysis is performed using a loss estimation method from the loss estimation paper. The method is simple and straightforward, with only a few lines of code required to obtain the upper and lower bounds. The main contributions of the paper are the following. First, the authors derive a set of assumptions for the convergence analyses of the proposed method. These assumptions include the following :   ( 1 ) The convergence rate of the learning and control problems can be represented as functions of time, where time as the number of epochs ( in seconds ) of the first and second order weights ( in"
SP:7a0ded4b3b2d08d43765ff7b722da9b9863aabd6,"This paper proposes to use nonlinear independent component analysis ( NII ) to improve the disentanglement of latent representation in GIN - based representation learning. In this paper, the authors first point out that the method taken by Sorrenson et al. ( 2020 ) for informative latent variable selection is not theoretically supported and can be disproved by experiments. Then, they propose to use the mutual information between each learned latent variable and the auxiliary variable to correctly identify informative latent variables to recover relevant latent variables. They further show the advantage of their method of using NII in experiments on synthetic data to show the improvement brought by the improvement achieved by the method in experiments.    The main contributions of this paper are the following :   ( 1 ) The authors propose a new method to learn a good representation of data, GIN, based on NII, to recover the underlying latent variables that generate the data, and thus can provide a compact and disentangled representation of the data. The authors argue that the current GIN method, while theoretically supported, can not be used as a basis for good representation learning because the obtained representation does not fully capture the latent variable information. ( 2 ) They show that using the method developed in NII to learn the latent variables is not a good idea as it does not preserve the latent information between the learned latent variables and auxiliary variables. ( 3 ) They further propose a method to utilize the information obtained from the learned and auxiliary latent variables in experiments to increase the accuracy of the representation learned by GIN."
SP:0d9ba12bbf47b13a46c2225f9dc06878418daaea,"This paper proposes a new method for bidirectional feature pooling in deep neural networks ( DNN ) based on the Lifting Scheme from signal processing ( LS ). The proposed method, named LiftPool, consists of three different pooling layers : 1 ) a feature decomposition layer that decomposes the feature map into subbands of various frequencies ( each subband has a number of frequencies ) 2 ) a corresponding up - pooling layer that is used to combine the features from subbands 3 ) A corresponding refinement step is performed to obtain a refined feature map from the feature decomposable subbands produced by the reverse pooling of the original feature map by the subbands pooled from the reverse feature map. The authors evaluate the proposed method on image - to - image ( image-to - image ) translation challenges and show that the proposed methods achieve better results on image classification and semantic segmentation, using various backbones. The paper also shows that LiftUpPool offers better robustness to input corruptions and perturbations.    The main contributions of this paper are the following :   1 ) The authors propose a new feature decomposing method for DNN feature maps, based on LS, to decompose the feature maps into various downsized sub -bands, each of which contains information with different frequencies. 2 ) The method is able to generate refined upsampled feature maps for each subbands using the detail detail sub - band feature map using the refined refinement step ( the refinement step ). 3 ) The refined feature maps are then used to perform the pooling function in the corresponding UpPooling layer ( corresponding to the updated feature map produced from the updated subbands in the previous UpPool )."
SP:147239edceb17bade6ea5d3dca44e3a59998aa47,"This paper proposes a new embedding method, DeepBinaryEmbedding ( DB ), to transform a well - spread dataset R into binary sequences in the $ \sqrt{±1}$ range using Gaussian random matrix. The embedding is based on Gaussian noise - shaped quantization of the vectors $ A$ and $ B$, which is different from most binary embedding methods, which use x 7 < sign(Ax ) for the embedding. The authors show that Euclidean distances among the elements of T are approximated by the ` ` 1 norm ` on the images of {±1 } under a fast linear transformation. They also show that distance - preserving embedding with time complexity O(n log n ) per data point is faster and more memory efficient than gradient - based embedding, where the distance between vectors $ \theta$ and embedding vector $ \tilde{O}(log n)$ depending on the data distribution. They compare this to gradient based embeddings, where $ \nabla_O(O(n))$ is used instead of $ \eta(O)(n ) \log n$. They show that the length of the binary codes required to achieve the desired accuracy is quite small, and they show it can be compressed further without compromising the accuracy. They test the proposed method on natural images and show that it achieves strong performance compared to standard methods.   The authors further provide experimental results on the following datasets : MNIST, CIFAR-10, Fashion MNIST-50, CelebA - MNIST and CelebA-100, Celeb18 and Celeb18. They compare the performance of DB with the following : ( 1 ), ( 2 ) Fast Linear Linear Embedding, Fast Distance - Preserving, ( 4 ) Distance - preserving, Distance - Propagating and ( 5 ) Smoothness - enhancing. They find that DB works better than the other methods on all of them ( except the last one, Smooth - GP - SGD, which they do not compare )."
SP:f65e229bca3904095743e7a501b1083cc60f1e22,"This paper proposes that plasticity rules governing the weight of recurrent neural networks ( RNNs ) learned through gradient descent can be used to improve robustness and generalize more easily between different tasks. The authors hypothesize that the plasticity rule governing the RNN weight can be learned from the learning rules of a neural network using gradient descent. They provide both empirical and theoretical evidence for this hypothesis. In experiments, the authors show that RNN learning rules learn well with fewer updates and exhibit surprising levels of tolerance to adversarial perturbations. They also argue that applying GD to learning rules is biologically plausible, in the sense that it is plausible to learn the rules over evolutionary time. The setting described in the paper is a genetic setting where natural selection of a numerical parameter over a sequence of generations provably simulates a simple variant of GD. Empirically, the classifiers learned using GD exhibit surprising accuracy improvements over those learned using a method based on multiplicative weights.   The main contributions of the paper are the following :   1. The paper proposes and studies the effect of learning rules learned by gradient descent ( GD ) on RNN weights. It is shown that the weight rule of a RNN is invariant to the number of parameters in the network. This is in contrast to the case when the weights depend only on one set of parameters ( e.g., when the network depends on all parameters but not all possible combinations of parameters ). This suggests that learning rules governed by GD can learn invariant parameters from many different sets of parameters. The experiments confirm that this is indeed the case. 2. The main result of this paper is in showing that using GD can improve the performance of RNN classifiers trained using multiplicative weight rules over a number of different datasets. 3. The major contribution of this work is to provide empirical evidence for the contribution of GD to improving the generalization performance of ANNs."
SP:f435530146fa975cb27cd375a857df9bcbd87682,"The paper proposes a novel method for the task of visual question generation ( VQG ), which aims to generate human - like questions from an image and potentially other side information ( e.g. answer type or the answer itself ). The authors propose a novel learning paradigm to generate visual questions with answer - awareness and region - reference, i.e., Double Hints textual answers and visual regions of interests, to mitigate the one - to - many mapping issue. To this end, they develop a simple methodology to self - learn the visual hints without introducing any additional human annotations. The experiments on VQA2 and COCO - QA datasets demonstrate that the proposed model significantly outperforms existing state -of - the - art architectures on both datasets.   The authors also propose a new double - hints guided Graph -to -Sequence learning framework that first models them as a dynamic graph and learns the implicit graph -to-sequence model to generate the questions with double hints. This is in contrast to the vanilla approach of previous works, which first utilize a graph - to-sequence modeling approach and then use the generated graph to map the answer to the question. In particular, the first part of the proposed method, Double - Hints Visual Question Generator, generates the visual question with two types of visual questions : 1 ) visual region of interest questions generating the image regions of interest ( for each image ). 2 ) image region of reference questions generating referential and meaningful questions ( for an image ) generated from the same set of visual regions. The proposed method is shown to outperform the state - of - the existing visual question models on COCQA and SQA by a large margin. The experimental margin is slightly smaller than the one observed in the authors ’ baseline, but is clearly distinguishable from the baseline on SQA. The main contribution of the paper is the use of the double - hints for generating visual questions instead of textual ones."
SP:53a26ce11647866d3f6ba8b84ca9f13106197a8d,"This paper studies optimally - tuned $ \ell_2 $ regularization to mitigate the phenomenon of “ double descent ”, where a generalization algorithm can have test performance that is non - monotonic in quantities such as the sample size and model size as they grow the size of the dataset or the model. Double descent is a phenomenon that occurs when an algorithm with high generalization error can perform well on a small number of samples but poorly on larger quantities. This phenomenon can be attributed to the fact that the training data used to train the algorithm is often not representative of the population that is actually using it.   The paper theoretically analyzes the phenomenon and shows that optimally-tuned $\ell_{2}$ regularization can mitigate it for generalization of linear regression with isotropic data distribution, and neural networks trained on Gaussian mixture models. Theoretically, the paper shows that optimal $ |\ell _ 2 \epsilon \mathbb{R}^2 regularization with $ \nabla_{\theta } \sim \hat{L_{\textrm{N}$ } regularization reduces the probability that the algorithm performs poorly on a given sample size or model size that is independent of the actual training data. Empirically, it is shown that this optimality property holds for both linear regression and neural network training. The paper further extends this result to other generalization algorithms, such as linear autoencoders and linear regression convolution, by showing that it can mitigate double descent for more general models that are trained with optimally $ \theta regularization. The empirical results are summarized as follows : 1. For linear regression, optimally \ell_{* } \times \mathbf{L}^n$ regularized linear regression models, the probability of double descent is approximately the same across all training datasets. 2. For neural networks training with a trained data distribution of $ \gamma_0 $ and $ \sigma_0 \eps1 $ regularized $ \textmu$, the empirical results show that the mitigation does not work as well for general models such as neural networks. 3. For other general models like Gaussian mix - up gradients, the results are consistent with the theoretical results."
SP:c193ccc74b987beaf8d53a29a8529a0af5e87742,"This paper proposes a new method to augment the decoder of VAE decoder with spatial dependency layer in order to improve density estimation. The method is based on a spatial dependency network ( SDN ) that maps feature maps at each level of a deep neural net to a spatially coherent embedding space using a gating - based mechanism distributes contextual information across 2 - D space. The authors show that the proposed SDN improves density estimation over baseline convolutional VAEs and the state - of - the - art among the models within the same class. They also demonstrate that SDN can be applied to large images by synthesizing samples of high quality and coherence from images that are of medium and high quality. The paper also shows that a powerful SDN decoder also improves learning learning disentangled representations in a vanilla VAE setting, indicating that neural architectures play an important role in this task.    The authors introduce a novel neural network for building image generators ( decoders ) and apply it to variational autoencoders ( VAEs ). In particular, they introduce a feature generator network that generates feature maps for latent codes using a spatial embedding and a feature encoder network that computes feature maps from latent codes to generate latent codes. The decoder network is trained to generate feature maps using the feature generator, and the feature maps are then used to build latent codes from the latent codes and feature generators. They show that spatial dependency layers significantly improves the density estimation in the VAEs decoder decoder. The experiments are conducted to evaluate the effect of adding spatial layers to VAEs. The experimental results are presented in Table 2, which compares density estimation performance of VAEs with other hierarchical VAEs, as well as VAEs that do not use spatial layers. They compare the performance of these VAEs to baseline models and other VAEs in terms of both density and accuracy. The results show that a spatial layer augmenting VAEs improves both density estimation and learning ( especially in the case of large latent codes ) and that a neural network without spatial layers improves learning ( in particular, SDN with a powerful decoder improves learning in the ability to discriminate between low - quality and high - quality images. In addition, the authors demonstrate that a simple SDN ( without spatial layer ) can not achieve the same density improvements as a fully - connected network ( without using spatial layers ), while a simple network with spatial layers can not do so at all."
SP:db91512a90e75675af03c2f197751c8526d6f5e9,"This paper studies the problem of off - policy reinforcement learning ( RL ) in the offline setting, where a fixed set of interactions is collected and no further interactions are allowed. The main contributions of the authors are demonstrating the importance of careful generative model design for estimating behavior policies, and an intuitive notion of complexity for offline RL problems. The authors propose EMaQ, a method that derives a simplified version of BCQ (ujimoto et al., 2018a ) by restricting extracted policies to remain exactly within the support of a given behavior policy. Empirically, the authors show that EM aQ matches and outperforms prior state - of - the - art in the D4RL benchmarks. The online RL setting, called Soft Actor Critic ( SAC ), is also demonstrated to be competitive. With its simple interpretation and fewer moving parts, such as no explicit function approximator representing the policy, EMa Q serves as a strong yet easy to implement baseline for future work.    The authors make no assumptions about the nature of the dataset used for training the learned policies, nor about the assumptions that are made by the authors to derive the parametrization of the BCQ algorithm. They explicitly consider the number of samples and the proposal distribution, allowing them to derive new sub - optimality bounds which can serve as a novel measure of complexity. They also consider the distance between the learned policy and the ground truth, which is more closely related to the resulting practical algorithm. Finally, they discuss the advantages and limitations of using a custom - designed backup operator, which they argue can lead to more efficient learning of decision - making policies."
SP:e2b80adeaa9208e0667a64a3f24661f77b48e487,"This paper proposes a batch batching - based optimization method for training machine learning models with model fairness. The proposed method, called FairBatch, is motivated by three primary fairness objectives : equal opportunity, equalized odds, and demographic parity. To achieve these objectives, the authors propose to batch the training batch in batches of equal size to ensure fairness of the training data. To this end, they propose a batch optimizer that selects batch sizes based on the likelihood of the batch distribution to be used in the batch. The optimizer is trained with two variants : batch - based batching and batch - adjusted batching. The main contributions of this paper are the following :   ( 1 ) The proposed algorithm is based on batching with batch - augmented gradient descent, where the batch size is the average of the gradients over the batch of gradients used to train the model ; ( 2 ) The method is designed to converge to the same batch size as the training algorithm, thus allowing for faster convergence on different gradients. ( 3 ) It is also designed to be compatible with other batching techniques, such as batch - agnostic batching, which can be used for different purposes. ( 4 ) The authors conduct extensive experiments to validate the effectiveness of their algorithm and show that it outperforms other bilevel optimization methods on both synthetic and real - world datasets. In particular, they show that the method outperforms methods that do not consider batching during training and do not require data preprocessing or model training changes."
SP:72f26b850bb2258223c0fc71598e35ad07d690e6,This paper studies bounds on the Lipschitz constants of deep neural networks ( DNNs ) to characterize the robustness and generalization properties of DEQs and PAC - Bayes generalization bounds. The authors show that the bounds obtained in previous work on DNN bounds depend only on the strong monotonicity of the network and do not depend on the depth of the DNN. They use the recently proposed deep equilibrium ( DEQ ) models as a subclass of DENNs and show that they satisfy the bounds of a recently proposed monotone DEQ model. They also show simple - yet - tight bounds on both the input - output mapping and the weight -output mapping defined by these networks. The main contributions of the paper are the following :   1. They show that a DNN model trained with the proposed DEQ bounds is robust and generalizes well to other models. This is demonstrated by comparing their bounds with other bounds obtained from previous work and showing that they do not suffer from the exponential depth dependence of the deeper the network is. 2. They provide bounds that are similar in spirit to the ones obtained from prior work on DEQ and PAC-Bayes that do not rely on the strength of the neural network ( PAC - DNN ). 3. They extend the bounds that they obtained in the previous work to the more recent class of models proposed in the context of deep equilibrium to also include bounds on PAC-DNNs.   The main contribution of this paper is the showing that these bounds are as tight as possible even for deep networks and still maintain the same constraints as the original DEQ models. The paper also shows how to use these bounds to develop PAC - bayes generalisation bounds that avoid the exponentially depth dependence that is present in the related work.
SP:bcfd4d7fd4590e3bc248a0a5422ce4b67db74a74,"This paper considers reinforcement learning ( RL ) in two settings : imitation learning and goal - conditioned RL. In imitation learning, the goal is represented as a set of states, and the RL algorithm is used to learn to reliably reach a state. In goal conditioned RL, the value function is the sum of the rewards generated by the algorithm and the state. The paper proposes a new approach to estimate the rewards using density estimation, drawing a connection between the probabilistic long - term dynamics of RL and value function.   The paper presents a unified view on the two settings and shows that the approach can be applied to both    Impersonation learning and Goal Conditioned RL. The approach is applied to the imitation learning setting and shows it to circumvent the problem of sparse rewards in goal - conditional RL while addressing hindsight bias in stochastic domains. It is also used to obtain state - of - the - art results on a common benchmark. In the goalconditioned RL setting, the approach is adapted to deal with the case when the reward function is not well defined. This approach is shown to be able to learn from extremely sparse amounts of expert data. The experimental results demonstrate the effectiveness of the approach."
SP:d57550b2f323b356d7e609acc35ee33039f376b4,"Multi - task learning aims to improve the overall performance of a set of tasks by leveraging their relatedness. When training data is limited using priors is pivotal, but currently this is done in ad - hoc ways using variational inference schemes. This paper proposes a general probabilistic inference framework for simultaneously learning multiple related tasks, which is cast as a variational Bayesian inference problem, and enables task relatedness to be explored in a principled way by specifying priors.    The main contribution of this paper is the introduction of Gumbel - softmax priors to condition the prior of each task on related tasks. Each prior is represented as a mixture of variational posteriors of other related tasks and the mixing weights are learned in a data - driven manner for each individual task. The experiments demonstrate that VMTL is able to tackle challenging multi -task learning with limited training data well, and it achieves state - of - the - art performance on four benchmark datasets consistently surpassing previous methods."
SP:3ccdf8322f16c8a7bef82e32fad4c03969a510d1,"This paper proposes a systematic and unified benchmark, Long - Range Arena ( LRA ), for evaluating model quality under long - context scenarios of transformers. The proposed benchmark is a suite of tasks consisting of sequences ranging from 1 - 16 K tokens, encompassing a wide range of data types and modalities such as text, natural, synthetic images, and mathematical expressions requiring similarity, structural similarity, and visual - sparsity reasoning.   The authors systematically evaluate ten well - established long - range Transformer models ( Reformer, Linformers, Linear Transformers, Sinkhorn Transformers, Performers, Synthesizers, Sparse Transformers, and Longformers ) on the newly proposed benchmark suite. The authors claim that the proposed evaluation paves the way towards better understanding this class of efficient transformers, and facilitates more research in this direction, and presents new challenging tasks to tackle. For example, the authors evaluate the model quality of Fast Transformer ( FTR ) on a task where the goal is to predict the output of the model ( output of a sequence of tokens ) from the input sequence ( input of a Transformer ). For a task similar to the one described in [ 1 ], the paper proposes to use a different set of models ( Transformer Proximal Models ) instead of the linear models ( Linear Transformers ) as claimed by the authors [ 2 ], which claim to be more efficient and comparable to vanilla models. For the task considered in this paper, the model complexity is estimated using the quadratic self - attention complexity metric, which is defined as the ratio of model complexity divided by the number of tokens used in evaluating the model compared to the input sequences. For evaluation tasks, the models considered here are the Fast Transformers ( FastProx ) and the Linear Transformers ( R - Linear R ( Linear R ). The paper claims that the models used for evaluating the models are comparable or slightly better than the vanilla models in terms of model quality, but the authors do not provide any empirical evidence for this claim. For other tasks considered in the paper the models were either slightly worse or slightly worse. For an evaluation task on the Deep Forest dataset the model was considered to be slightly worse, but for the difference between the model and the model on Deep Forest is not significant enough to be counted as an error in the evaluation was not considered. For evaluations on other datasets there was no significant difference between model and model"
SP:e12e410c3335b76133ceda4c865b244fbbab8580,"This paper proposes a framework for combining source code representation ( source code ), structure tree ( Structure ), and context ( Context ) for learning about the source code representations of computer programs. Traditionally, machine learning models have relied predominantly either on Structure or Context, but this work proposes to combine the two separately, and jointly learns on both the structure and context of source code. To this end, the authors propose a language - agnostic language summarization model, where source code and structure representations can be computed directly from the abstract syntax tree ( AST ). The proposed model is multilingual, and trained with data from multiple programming languages ( e.g., MS - COCO, CIFAR-10, VGG16, Ada2D, Ada5, Ada6, Ada7, Ada9, Ada10, Ada11 ). They obtain state - of - the - art results on monolingual code summarization on all five programming languages considered in this work. They show that jointly training on non - parallel training from multiple languages improves results on all individual languages, where the strongest gains are on low - resource languages. The main contributions of this work are the following :   1. The authors propose to jointly train a model that learns Source Code Representation via Structure and Context by combining the representations of Source Code, Structure, and Context. This is different from previous approaches that only considered source code, only considered the structure. The benefits of combining the two representations is evident in the lower bound of the error bound, which is lower than the upper bound for the error of the model on Structured Code. This lower bound. 2. They also show that the higher bound on the better the model performs when source code learning from Structure, the more the model learns from the structure of source codes.    3. This work is referred to as the Multilingual Code summarization ( CMCC ) model. It is the first multilingual code summarisation model to use both structures and context in the same ML model. The difference from the previous work is that the model considers only source codes, while the previous one considered only the structure, and the latter considers only the context. The advantage of the CMCC model is that it does not have to deal with the difference between the representation of source and context codes, which has to do with the source codes ; in the multilingual model, the only task of the first task is to learn the structure ( the context ), while in the second task it has to handle both the context and structure."
SP:f46e98d48f90071831f1c0069bf74a7993be6db8,"This paper proposes a new approach for 3D audio - visual navigation based on reinforcement learning using waypoints, waypoints that are dynamically set by the agent at each time - step and learned end - to - end within the navigation policy, acoustic memory that is spatially grounded and learns the direction the agent is moving in the 3D space using the sounds around it and the waypoints at time - steps. The key idea of the approach is to use the information from the ( jointly generated ) waypoints and acoustic memory to build a rich spatial and temporal embedding of the agent's previous moves in order to learn a mapping from the current position to a sound source ( e.g. the sound of a phone ringing in another room ). The waypoints are learned using a reinforcement learning approach where the goal is to predict the next waypoint at which the agent will arrive at the new waypoint ( in this case the current waypoint is sampled from the previous waypoint ) and the acoustic memory is trained to match the sampled waypoint to the current acoustic memory so that the mapping from current place to waypoint can be predicted from the last waypoint's acoustic memory's direction. The approach is evaluated on two datasets of real - world 3D 3D scenes, where the authors set the goal to learn the links between sights, sounds, and space. The first set of experiments compare the proposed approach with two baselines, a model that learns to act at a fixed granularity of agent motion and another that learns the waypoint locations using a learned trajectory distribution. The second set of tests compare the learned waypoints with the learned trajectories from the first waypoint and the learned trajectory from the second waypoint. The results show that the approach generally outperforms the baselines in terms of accuracy ( in the sense that the difference between the accuracy at the first and second waypoints is smaller than the difference at the third waypoints ). In addition the authors also demonstrate that their approach is robust to noise levels varying between the two datasets and the learning of the links is better on the second dataset."
SP:23bfe317dcef00a91ea92389b3f39d9b93972454,"This paper studies the convergence of neural networks trained on a simplified version of Conway ’s Game of Life update rule update using update rules. The update rules are the update rules of the automaton that, given a set of rules, updates the CNN parameters $ \mathbb{R}$ and the update rule $ \sqrt{T}$, which is defined as follows : $ \tau_1 \times T$ steps $ \sim T$, where $ T$ is the number of cells in the input set and $ \epsilon$ is a random permutation of the parameters of the CNN.   Previous work has shown that CNNs trained with update rules based on lottery tickets converge quickly to a solution ( e.g., Frankle & Carbin, 2018 ), and the authors use this idea to investigate how initializations of the subnetworks used to train CNNs affect convergence of the network. The authors study two types of CNNs, one based on convolutional neural network and another based on neural network - only CNNs. They find that networks trained under the simplified update rule rule update rule do not converge as quickly as those trained with the lottery tickets. Also, networks trained with updated rules using CNNs require substantially more parameters to converge consistently. They compare the convergence rate of the networks they study with the one trained using the lottery ticket update rules ( based on the updated rules ) that they call Conway “ lottery tickets ” ( Frankle et al., 2019 ). The experiments are conducted with a CNN architecture trained to approximate the two - dimensional automaton from the Conway game, and they compare the performance of the trained CNNs with and without Conway tickets. They show that the networks trained using lottery tickets perform much worse than the ones trained without updates. The networks that use lottery tickets tend to use larger initializations, suggesting that they are less sensitive to perturbation introduced by the random initializations."
SP:1b5ba618d3e28d48f9205c0780f8288a08fa5392,"This paper proposes RankingMatch, a semi - supervised learning ( SSL ) approach that ranks the likelihood of learning from inputs that have the same label as the similarity of their outputs. The motivation for this is that most successful SSL approaches are based on consistency regularization, which encourages the model to produce unchanged with perturbed input. The authors argue that there has been less attention spent on inputs with labels that are similar. RankingMatch considers not only the perturbed inputs but also the similarity among the inputs having same label. The paper introduces a new objective function, dubbed BatchMeanTriplet loss, which has the advantage of computational efficiency while taking into account all input samples. They also perform an ablation study to prove the efficacy of the proposed method against existing versions of triplet loss.   The paper is published with supplementary material ( Table 1, Figure 2, Table 2, Figure 3, Table 4, Figure 5, Table 6, Table 7, Table 8, Table 9, Table 10, Table 11, Table 12, Table 13, Table 14, Table 15, Table 16, Table 17, Table 18, Table 19, Table 20, Table 21, Table 22, Table 23, Table 25, Table 28, Table 29, Table 30, Table"
SP:f3abccf4a2566ffbc821aba209fab15058639ad4,"This paper studies meta - learning in the sequential learning setting, where the tasks are presented in sequence. The authors first consider the problem of learning new tasks from a small fixed number of examples and meta - training across static data from a set of previous tasks. In this setting, the authors consider two options : ( 1 ) meta - supervision, which learns the meta - labels for each task using a weighted sum of the examples ; ( 2 ) adaptation, which uses data from previous tasks to learn a meta - classification score for each new task.    The authors consider the online setting where the task is presented sequentially and the training is done over a period of time ( e.g., 48 hours for a task on MNIST ). They first consider two choices of meta - algorithms, meta - supervised learning ( MARL ) and ( BLEU ), which is an extension of MARL. They find that meta - MARL provides the best performance when the training set is small ( few - shot learning at the start of each task ), compared to MARL when the task set is large ( standard MARL with many - shot labels and zero - shot MARL at the end ). In addition, they show that MARL helps meta - learners to solve the full task set with fewer overall labels and achieves greater performance when using adaptation. They further show that adaptation is helpful for meta - learner to solve tasks with complex bi - level optimization that may require large amounts of meta-training data. To support their findings, they re - evaluate the algorithms they studied in this setting and extend them to handle the variable - shot settings that naturally arise in sequential learning. The experimental results support the authors ’ findings. In particular, when the learning problem is difficult to learn from the start and the learning rate is high, MARL performs much better than meta - Saban. When the learning rates are low or the task size is very small, AR and MARL perform much worse. Finally, the experiments show that the risk - minimization techniques of the authors work better than the risk minimization methods of the researchers."
SP:95cb420d92ec42e12a4bbb0e66224f1c498a7161,"This paper investigates the sensitivity of Transformer representations to syntactic structure in sentences using input perturbation - based analyses of representations from pre - trained Transformer networks. The authors take inspiration from representational invariance from neuroscience and computational neuroscience to understand the representational properties of Transformers. Specifically, they consider three types of syntactic structures : global phrases, local phrases and syntactic distance between two words. Each of the three probes involves swapping words in a sentence and comparing representations from perturbed sentences against the original. Results show that Transformers build sensitivity to larger parts of the sentence along their layers, and that hierarchical phrase structure plays a role in this process. In particular, sensitivity to local phrase structure increases along deeper layers and is explained by larger attention weights between syntactically distant words.    The authors also connect their probe results to the Transformer architecture by relating the attention mechanism to syntacially distant words and show that the attention weights are generally larger in the first layer and smaller in the second and third layers. Results from the experiments indicate that the most Transformer - like representations are the ones that are sensitive to the global phrase structure. However, the sensitivity to the local phrases seems to decrease as the layers get deeper. This is at least partly explained by the fact that the representations are no longer able to distinguish between syntactic words that are far apart from each other ( as is the case in the case of global phrases ) and local phrases. Results also suggest that Transformers are less sensitive than other models to the structure of the intermediate layers that are constructed from the first and second - level phrases. Finally, Transformer encoders seem to be more sensitive to local phrases than global phrases. This seems to be a result of the more complex structures being more fully incorporated into the representations."
SP:cb27b27a6fefc192ad1c2bd083d13eb9e51a5c44,"This paper studies the few - shot image synthesis task for GANs with minimum computing cost. It proposes a light - weight GAN structure that gains superior quality on 1024 - 1024 resolution images. Notably, the model converges from scratch with just a few hours of training on a single RTX-2080 GPU, and has a consistent performance even with less than 100 training samples. Two technique designs constitute the work, a skip - layer channel - wise excitation module and a self - supervised discriminator trained as a feature - encoder. With thirteen datasets covering a wide variety of image domains 1, 2, the authors show their model’s superior performance compared to the state - of - the - art GAN2, when data and computing budget are limited."
SP:c0dbeb5d94b2388595cf7ad9675c55df0bac7f8e,"This paper proposes a novel method for improving the tightness and robustness of the employed relaxation of neural network bounds. The main contributions are two - fold :    ( 1 ) A novel dual algorithm that operates on a small active set of dual variables ( $ n$ dual variables ) when computing the relaxation of a neural network bounding algorithm, and ( 2 ) A method that recovers the strengths of the new relaxation in the dual space by using a linear separation oracle. The key idea of the algorithm is that it tries to maximize the benefit of the newly proposed dual relaxation by minimizing the cost of the gradient descent. The authors argue that this is the most cost - efficient way to verify the properties that are more challenging to verify due to the lack of tightness that is typically associated with the employed relaxations. The dual algorithm consists of the following steps.   1 ) The authors propose a dual gradient descent algorithm. Theoretical analysis is performed to show that the proposed algorithm achieves better bounds than the one obtained by the baselines under the dual algorithm with the linear separation. This is done by running the algorithm with two additional steps : 1 ) In the first step, the authors propose to use the same dual variables as in the previous work ( Zhang et al., 2017 ) except that they replace the number of neurons in the network with a number linear in the activation function. This results in a relaxed activation function instead of a linear one. 2 ) Theorem 3.1 shows that the new method shares the benefits of previous dual approaches for weaker relaxations with the same amount of parallelism as it does for the stronger relaxations, provided that the corresponding to the weaker relaxation is implemented with the stronger relaxation. Theoremensitivities of the obtained in the second step are compared to those of the original method. The method is evaluated empirically on MNIST and CIFAR-10 and compared with two other methods. It is shown that the method is more robust to the weak relaxations in terms of the required parallelism, the required gradient descent and the required computation cost."
SP:56e3837417dbcce0d65338dc3aac4e1a20eb0df8,"Pre - trained language models ( PTLMs ) have achieved impressive results in a range of natural language understanding ( NLU ) and generation ( NLG ) tasks. However, current pre - training objectives such as masked token prediction ( for BERT - style PTLM ) and masked span infilling do not explicitly model the relational commonsense knowledge about everyday concepts, which is crucial to many downstream tasks that need common sense to understand or generate. To address this issue, this paper proposes both generative and contrastive objectives for learning common sense from the text, and use them as intermediate self - supervised learning tasks for incrementally pre - trained P TLMs ( before task - specific fine -tuning on downstream datasets ).   The main contribution of this paper is to propose CALM, a concept -aware language model ( CALM )1, that can pack more commonsense   knowledge into the parameters of a pre -trained text - to - text transformer without relying on external knowledge graphs, yielding better performance on both NLU and NLG. The authors show that CALM can be used as a general, “plug - and - play ” method for improving the commonsense reasoning ability of the PTL mains. Furthermore, they develop a joint pre -training framework to unify generative, contrastive and generative learning objectives so that they can mutually reinforce each other. Extensive experimental results show that our method, CALM1, can outperform baseline methods by a consistent margin and even comparable with some larger PTL Ms. The major concern of the paper is that the authors do not provide sufficient explanation as to why CALM is superior to the baseline methods. Also, the authors should provide more detailed descriptions of the differences between CALM and the baselines to clearly demonstrate that their method is superior."
SP:7ec69bdee021af506293c87a3b75bce1c40a03d7,"This paper presents POD - Net, an unsupervised method to segment 3D video scenes into 2D objects based on their 3D appearance and 3D interaction with the environment. The method is based on PODNet, a decomposition framework that decomposes 3D scenes into segments based off object properties. POD-Net is designed for the task of physical object discovery ( PD ), where an object is first segmented into a set of unobservable and partially occluded objects of varying sizes, and then used to infer properties of those objects. The obtained segments are used to generate 3D graphs showing the position and velocity of the objects in relation to each other and the environment in 2D space. This is done using a multi - scale pixel - based segmentation followed by a 3D frame - wise projection of the segmented objects to get 3D 3D views of the scene. The 3D view is augmented with 3D physics - based information from the interactions between the objects and the 3D frames in 3D space to disentangle 3D geometry and position of objects from 2D views. The model is trained with synthetic and real data to obtain the segmentations. It is tested on both synthetic data and real scenes, and compared with several existing methods. Comparisons with other PD methods are made based on object properties, the number of objects in a scene, and object interaction statistics. Results show that the POD Net segments objects more accurately than other methods, and that the properties are better used to derive 3D disentangling information."
SP:66997bc19a3ba6548fcf21f114e748bea95cad1c,"This paper proposes Increasing Margin Adversarial ( IMA ) Training to Train Deep Neural Networks ( DNNs ) to be more robust against adversarial noises and attacks. The authors propose a novel training method to increase the margin of training samples by moving the decision boundaries of the DNN model far away from the training samples to improve robustness during training. The IMA method is evaluated on six publicly available datasets ( including a COVID - 19 CT image dataset ) under strong 100 - PGD white - box adversarial attacks and the results show that the proposed method significantly improved the classification accuracy on noisy data while keeping a relatively high accuracy on the clean data.   The authors conducted a comprehensive evaluation of their method and applied it to three DNN models ( DeepCNN, Convolutional Neural Network, and RNN - SGD ) on three different datasets ( CIFAR-10, VGG16, and MNIST, MNIST-19 ), and compared with two baselines ( ACR - DNN and AC - SNN ). They also conducted an ablation study to evaluate the effect of distance between DNN decision boundaries and training samples when IMA is used during training and when the samples are generated using adversarial noise ( white noise or black noise ). The main finding is that IMA training results in significantly improved classification accuracy ( on the three datasets ) compared to ACRNN and SNN - GNN ( which does not use distance between decision boundaries as a metric for robustness improvement during training )."
SP:276ffd59fbf49e3ee02756da8920218102214917,"This paper proposes ProKT, a method to derive compact neural networks from larger teacher models. The authors observe that a converged heavy teacher model is strongly constrained for learning a compact student network and could make the optimization subject to poor local optima. They propose to use a model -agnostic method by projecting the supervision signals of a teacher model into the student ’s parameter space. The projection is implemented by decomposing the training objective into local intermediate targets with approximate mirror descent technique. The proposed method could be less sensitive with the quirks during optimization which could result in a better local optim a. Experiments on both image and text datasets show that the proposed ProKT consistently achieves the state - of - the - art performance comparing to all existing knowledge distillation methods.    The main contributions of this paper are as follows :   - A new model - aware supervision network is proposed for deep neural networks. This network is trained by minimizing the distance between the student model and the teacher model in a supervised manner. The student model receives supervision signals from the supervision network and vice versa. The supervision signals are encoded into the parameter space of the intermediate targets of the ProKT method. - This method is tested on two image datasets ( CIFAR-10 and ImageNet ) and compared to a teacher - supervised model and a student model. The results show that ProKT is more robust than the other methods to learning errors and better performs better than the student - teacher model."
SP:906dc21d6988953fcf57d63bbdd12973e5818d16,"This paper proposes a channel pruning method for CNNs to solve compression and acceleration problem. The proposed method is based on a hyper - structure network to generate the architecture of the main network, which can be optimized with regular backpropagation. The authors use a regularization term to specify the computational resource of the compact network. The experimental results on CIFAR-10 and ImageNet show that our method is competitive with state - of - the - art methods. However, if FLOPs is used as the criterion of computational resource in the regularization, it may over penalize early layers. To address this issue, the authors introduce learnable layer - wise scaling factors to balance the gradients from different terms ( learnable from hyper - gradient descent ). The paper also proposes a learning - based regularization method to further improve the performance of the proposed method."
SP:890fd9454596c051b0e9535baf73b1dd1fae67ca,"This paper studies the problem of proving a high - order logic theorem proving over a corpus of lower - order priors without learning from human proofs, which is referred to as “ DeepHOL Zero ”. This is a novel approach to proving such a theorem that relies on a prover trained by a combination of imitation and reinforcement learning, as opposed to a human - based prover that is trained only on human proofs. The main contributions of this paper are as follows :   ( 1 ) This paper proposes a new type of neural algorithm for proving the theorem : a neural algorithm that extends the probabilistic theorem provers ’ exploration of premises based on a simple tf - idf ( term frequency - inverse document frequency ) based lookup in a deep reinforcement learning scenario. This algorithm is termed “ deep neural algorithm ” ( DNE ) and it consists of three components : 1 ) A neural network that learns the parameters of the DNE algorithm via a weighted sum of the inputs to the neural network ( e.g., input x, output z ), 2 ) A policy that encourages the prover ’s exploration of the premises using a softmax over the inputs ( softmax + softmax penalty ), and 3 ) A regularization term that prevents the human - trained prover from over - processing the inputs that are not favorable to it ( low - rank / high - rank ). The algorithm is called DNE - FIFO. ( 3 ) An analysis of the performance of the proposed algorithm is performed by training a set of provers using DNE and RL ( RL ( linear and non - linear reinforcement learning ), where RL is used to train the provers and DRL is used for training the non - RL.    The main results of the paper are summarized in Table 1, where Table 1 shows that the neural algorithm proposed by this paper performs better than the one proposed by [ 1 ] and [ 2 ], and Table 2 shows that DNE algorithms trained with human proofs do not perform as well as those trained only with DNE or DNE. Also, Table 3 provides insights into the assumptions of DNE that makes the proposed method different from DNE, such as the importance of softmax and softmax / softmax. In addition, the paper also includes a discussion of the differences between DNE vs DNE in terms of the number of assumptions used for DNE exploration ( and the amount of data required to train provers ), which explains some of the discrepancies in the performance results."
SP:88209417a8ad07e6103084e41709be900303ce5f,"This paper proposes MODALS ( Modalityagnostic Automated Automated Data Augmentation in the Latent Space ) to augment data for any modality in a generic way. The underlying data augmentation methods are usually manually designed and carefully evaluated for each data modality separately, such as image processing functions for image data and word - replacing rules for text data. This paper proposes a generic automated data augmentor to fine - tune four universal data transformation operations in the latent space to adapt the transform to data of different modalities. The experimental results demonstrate the effectiveness of MODALS on multiple datasets for text, tabular, time - series and image modalities for both text and image. The main contributions of the paper are as follows :   1. The authors propose a generic data augmenting method that is parametrized as a generic extension of the multi - armed bandit classifier. It can be used to augmentation data for modalities of different distributions ( text, time and image ), and fine - tuning the parameters of the corresponding transformation operations fine - tuned manually for each one. The parameters of each operation can be adjusted manually for image and text data only, or for modality of choice. The flexibility of the parametrization allows MODALS to be applied to datasets of different sizes ( text / image, time / image and machine learning datasets ). The method is tested on four datasets ( CIFAR-10, Tiny ImageNet, TinyText and TinyText2, TinyC - ImageNet ) and compared with two manual methods ( ImageNet and Word - Replacing - Text. The results show that MODALS is better than the manual methods on average across all four datasets."
SP:6d84670d321b0d584b097c630574bd748e85c9a2,"Recent works have provided convergence guarantees for two - layer neural networks and multilayer ones under the mean - field regime, in which the training dynamics tend to a nonlinear and nontrivial dynamical limit. This lends a way to study large - width neural networks via analyzing the mean field limit. In this paper, the authors extend such analysis to three - layer networks and provide global convergence guarantees. To do so, they first develop a rigorous framework to establish the mean of the three layer limit of the regime for stochastic gradient descent training of neural networks, which is then used to obtain a global convergence guarantee under suitable conditions. Underlying the result is a universal approximation property, which importantly is shown to hold for all three layers of neural network, even if it is not the largest one.    The main contributions of this paper are the following :   ( 1 ) The authors develop and define a framework to analyze the mean and learnable parameters of a three layer neural network. This is done using the following steps : 1 ) A neural network of arbitrary width is modeled as a weighted sum of layers, such that each layer has a mean of $ \epsilon$ and the network has a learning rate $ \alpha$ where $ \eta$ is the average gradient of its weights over the layers and $ \tilde{O}$ is its mean square root. The network is modeled with a fixed set of layers $ \theta$ such that $ O(T)$ measures the distance between any two layers and the learning rate at any point in time $ t(T$, where $ T$ is a weighted average of the gradient of the layer weights at time t.   2 ) A training algorithm is defined such that the network converges to a set of $ t$ layers at some point in the training time such that there are no more than $ \eps(t)$ layers $ t$. The training algorithm $ T(T|t ) = \sum_t(T-\theta T)$ and here $ t_t \to T_t$ is an iterated gradient update of the parameters of the neural network with mean $ T$.   3 ) Under suitable conditions, the optimization efficiency of the proposed analysis is established such that no optimization error is incurred when there are more than two layers ( or $ t=0.5 $ ) and no convergence rate is achieved. The authors then apply their framework to three layer networks, and show that the global convergence result is global for training three layers ( with and without two layers ) is achieved, e.g., $ T_1 $"
SP:b90f893f927db9c439595fd119a565cf43c971f4,"This paper proposes to learn explanations of expert decisions by modeling their reward function in terms of preferences with respect to “ what if ” outcomes : Given the current history of observations, what would happen if we took a particular action? To learn these costbenefit tradeoffs associated with the expert ’s actions, the authors integrate counterfactual reasoning into batch inverse reinforcement learning. This offers a principled way of defining reward functions and explaining expert behavior, and it satisfies the constraints of real - world decision - making, where active experimentation is often impossible ( e.g., G in healthcare ). The authors conduct experiments in both real and simulated medical environments to demonstrate the effectiveness of their approach.   The main contributions of this paper are the following :   ( 1 ) The authors propose a learning framework that can accommodate settings where the expert policies depend on histories of observations rather than just current states. This is important for introspecting and auditing policies in different institutions. ( 2 ) It proposes to train a neural network that can predict the effects of different actions, while also being able to recover accurate and interpretable descriptions of behavior. ( 3 ) It develops a method to train an expert to estimate the cost - benefit tradeoff between actions taken by the expert and the actions that would have been taken if the expert had taken the opposite action."
SP:c92916780418bfa7f0796fd9766b6d28b9eea5ef,"Graph Neural Networks ( GNNs ) are one way to address incompatible environments, because they can process graphs of arbitrary size. They also allow practitioners to inject biases encoded in the structure of the input graph. Previous work in graph - based continuous control uses the physical morphology of the agent to construct the input graphs, i.e., encoding limb features as node labels and using edges to connect the nodes if their corresponded limbs are physically connected. In this work, the authors present a series of ablations on existing methods that show that morphological information encoded in GNN does not improve their performance. The authors also propose a transformer - based approach, AMORPHEUS, to incorporate the information from the graph structure to define the message - passing scheme.    The main contribution of this paper is to propose a GNN based method, Graph Neural Networks, that substantially outperforms GNN - based methods that do not use the morphologically encoded information and use the node labels to define graphs. While the proposed method, GNN, may not significantly improve the performance of the current GNN method, it substantially improves the generalisation performance of GNN. The main drawbacks of the proposed approach are summarized below :   1 ) The authors do not provide any explanation of why the differences between GNN and GNN are significant, and the only explanation they give is that GNN uses the same node labels, while GNN only uses the edge connections. This is not surprising since GNN is supposed to be able to handle different graph structures. 2 ) A reviewer who has followed the research for a long time does not understand the contributions of the authors and does not have the same high-level understanding of the research that the authors have. 3 ) It would be helpful for the reviewer to read the authors ’ rebuttal before making any further comments."
SP:2cf58f5cac20dccdc2034ef60e8e46b7988ebd7d,"This paper proposes a new method for visual counting based on a residual bottleneck, which aims to predict the number of occurrences given a natural image and a query. Unlike most prior works that use symbolic models which can be computationally expensive and limited in generalization, the method proposed here proposes a simple and effective alternative by revisiting modulated convolutions that fuse the query and the image locally. The method is called MoVie, short for Modulated conVolutional Bottlenecks, and is designed to be integrated as a module for ‘ number ’ related questions in generic VQA models. The paper presents the method as a general mechanism for counting tasks beyond counting. First, the paper presents three visual counting tasks : 1 ) advance the state - of - the - art on counting - specific VQ - A tasks while being more efficient ; 2 ) outperform prior - art and state - based methods on difficult benchmarks like COCO for common object counting ; 3 ) help us secure the first place of 2020 VQ-A challenge when integrated with the first module of the original. Finally, the authors provide evidence that a module such as MODulated Convinced Convolutional Probability Estimation can serve as a good generalization for counting and can be used for counting beyond counting alone."
SP:c64e77507e562f236cb69361b22fb1a7951ffb22,"This paper proposes a model - targeted poisoning attack based on online convex optimization to induce a model that misbehaves in a way desired by the adversary, such as misclassifying certain inputs. The proposed attack is the first model - targeting poisoning attack that provably converges to the target classifier under the provable convergence condition, defined as the distance from the induced classifier to target classifiers inversely proportionally to the square root of the number of poisoning points. The authors also provide a lower bound on the minimum number of poisoned points needed to achieve a given target of the classifier.   The authors experimentally compare the proposed attack with the best state - of - the - art model - targeted poisoning attacks in terms of terms of attack success rate and distance, and show that in most cases the proposed poisoning attack performs better than the best possible. The main contributions of the paper are the following :   ( 1 ) A new poisoning attack formulation based on model - based poisoning attacks is proposed, in which a classifier is first poisoned from the class of the adversary ’s choice, and the poisoning points are allocated according to the squared average of the gradient of the loss function of the corresponding classifier with respect to the training data ( e.g., $ \mathbb{R}$ ). This allows the adversary to select a set of sufficient poisoning points from which to obtain a sufficient number of misclassified classifiers ( $ \theta$ ) for each training point to attack the target. This formulation. ( 2 ) A lower bound is given on the required for each additional classifier poisoning point that is needed to obtain the corresponding maximum loss value for the corresponding target. ( 3 ) The authors conduct extensive experiments to verify the convergence of their proposed attack and demonstrate that the proposed method convergence is provable, which is demonstrated with experiments on both synthetic and real data."
SP:a526023ec4cb839b83c574d31f59a9a67bc7af00,"This paper proposes BiPointNet, a new binarized model for deep learning on point clouds based on aggregation - induced feature homogenization ( EMA ) and layer - wise scale - wise entropy recovery ( LSR ). The main motivation is to reduce the performance drop of existing binarization approaches for point clouds due to two challenges : ( 1 ) Feature homogenisation that leads to a degradation of information entropy, and ( 2 ) scale distortion that hinders optimization and invalidates scale - sensitive structures. To tackle these challenges, they introduce EMA to modulate the distribution before aggregation for the maximum information entropy ( K ), and Layer - wise Scale Recovery to efficiently restore feature representation capacity ( LS ). They provide theoretical justifications and in - depth analysis to support their approach. They conduct extensive experiments on several tasks to validate their method. They show that Bi point nets outperforms existing binarsized models by convincing margins, at the level of convincing margin. They also show that their methods are comparable with the full precision counterpart of the corresponding baseline method ( PointNet ).    The main contributions of this paper are the following :   1 ) To tackle the two challenges mentioned above, they propose a new model with two approaches : EMA that aggregates the features from the prior distribution before applying the learned model, andLSR that recovers the information entropy between the prior model and the one trained on the target distribution using the layerwise entropy. The authors provide detailed analyses of the differences between EMA and LSR, and show that EMA is more robust than LS, and that LSR is more efficient than the full baseline method on the distribution - wise recoverable features. The paper also provides detailed explanations for why the performance drops of PointNet are the magnitude that they observe. The major performance drops and the reasons for the performance performance drops are summarized in Table 2. This paper is well written and well presented. It is easy to follow most of the steps in the technical details. However, there are a few small details that are not clearly explained in the main text, so if you do not follow the technical part of the paper closely ( the details in the authors ’ explanations ) then you might miss some important points or have missed an important parts of the ideas. For example, the authors clearly state the advantages of their method for overcoming the challenges of aggregation and scale distortion and the importance of the first challenge mentioned in Sec 3.1 ( although I do not see these terms clearly stated in the paper. The second challenge of the scale distortion is more subtle and more subtle to me but it is important to understand how the authors explain how to"
SP:825b4d1db0c537a607655bb5b4bf221ec672c8af,"This paper studies the effect of adding trainable memory to Transformer models for language processing tasks by augmenting the model's self - attention with MANNets. MANNs extend traditional neural architectures with general - purpose memory for representations to capture both local and global context of sequences. The authors propose adding memory tokens to store non - local representations, ( creating memory bottleneck for the global information, ( 3 ) controlling memory update with dedicated layer, and evaluate the effect on the Transformer model on tasks including question answering, machine translation and language modelling tasks. The results show that MANNs learn simple algorithms like Copy or Reverse and can be successfully trained via backpropagation with comparable complexity to RNNs and LSTMs of comparable complexity. Experiments on GLUE benchmark show mixed results for tasks from question answering and language modeling, suggesting that adding memory selectively to the memory might improve the model ’s ability to process a global and local context. However, experiments on the task with MANNs show that presence of memory positively correlates with the model performance on machine translation tasks and that the model performs favorably on the tasks with masked language model performance. The main contributions of the paper are as follows.   1. This paper proposes adding memory to selectively store local as well as global representations of a sequence of sequences to capture contextual information. This is a promising direction in which to improve transformer models ’ current architecture, which is limited by the fact that most information about the context is stored mostly in the same element - wise representations. This might limit the processing of properties related to the sequence as a whole more difficult. 2. This work proposes to augment the memory of the transformer model by storing memory tokens corresponding to the representations of elements in the sequence that are relevant to the task at hand. 3. The experiments show that the added memory does not significantly improve the performance on tasks from GLUE."
SP:f0fa1b7684bc605f6edd4813c44be20988fe8b4c,"This paper presents Prototypical Contrastive Learning ( PCL ), an unsupervised representation learning method that bridges contrastive learning with clustering. More specifically, PCL learns low - level features for the task of instance discrimination, and more importantly, it encodes semantic structures discovered by clustering into the learned embedding space. Specifically, the authors introduce prototypes as latent variables to help find the maximum - likelihood estimation of the network parameters in an Expectation - Maximization framework. They propose ProtoNCE loss, a generalized version of InfoNCE for contrastive learners, which encourages representations to be closer to their assigned prototypes.   The manuscript includes the following main contributions :   1. The paper proposes PCL with a feature extractor. 2. The authors apply E - step to find the distribution of prototypes via clustering and M - step as optimizing the network via contrastivelearning. 3. A loss function is proposed to encourage representations in PCL to learn in a similar fashion to the way that representations are learned in the original contrastive setting. 4. A regularization term is introduced to encourage learning in a manner similar to that in contrastive methods."
SP:5342a5e1d87fd17b1a2efed967dbbfeafa440ee7,"This paper proposes Orthogonal Multi - Path ( OMP ) blocks to defend adversarial attacks against deep neural networks. The main idea is to design a block containing multiple paths that are orthogonal to each other in order to learn robust features. The parameters of these paths are the same throughout layers of the neural network. OMP blocks can be constructed via forward learning and backward correction. The authors show that one OMP block makes the neural networks learn features that are appropriate for all the paths and hence are expected to be robust. The performance under both white - box and black - box attacks of the proposed OMP is evaluated and compared with the state - of - the - art adversarial defense methods. The results show that the performance of neural networks equipped with OMP and other robustness measures are significantly better than those equipped with other robust defenses methods such as PGD, CP, CP - SGD.   The main contributions of the paper are as follows :   1. The paper proposes a novel and highly robust multi - path block defense method, OMP. This is different from the previous works that only defend one path and use the same set of parameters for each path. The key difference is that OMP requires that the parameters of the different paths be orthogonally consistent with each other. This ensures that the robustness of the network does not suffer from the non - matching of the parameters. 2. For each path, the authors propose to use a constraint on the position of the constraint that would prevent the network from learning features that do not overlap with any of the paths. This constraint can be phrasic parameters such that the network learns features that correspond to all paths. 3. For the authors use a trade - off between the variety and accuracy of the variety of the features learned. The experiments on e.g., the positions of imposing the constraint and the position constraint show that imposing constraint leads to improved performance. 4. In the experiments on the number of attacks and the accuracy in terms of the ratio of the accuracy on CIFAR-10 ( for vanilla networks ) and VGG16 ( for black box networks ), the performance is comparable to that of the original adversarial defenses. However, under OMP the robust performance of the networks is significantly better."
SP:776df66274ed12449fde8dcef873a593980f397c,"This paper proposes a self - supervised graph attention network called SuperGAT for dealing with noisy graphs. It is motivated by the observation that what graph attention learns is not understood well, particularly when graphs are noisy. To tackle this, it proposes to learn more expressive attention in distinguishing mislinked neighbors by encoding edges, whose presence and absence contain the inherent information about the importance of the relationships between nodes. To this end, it adopts two attention forms from graph attention literature, namely, average degree of self - supervision ( A ) and presence - of - node ( M ), to predict edges. The paper presents a recipe for using these attention forms and a graph attention algorithm to optimize them. The key idea is to use the information from M and G ( M and Z ) about the relationship between nodes in the graph space and the distance between nodes to predict the probability of their presence or absence at a particular node. To do this, the paper proposes to split the graph graph space into two subsets, based on the homophily and average degree assumptions of the graph. The method is evaluated on both synthetic and real - world graphs, where it is assumed that the input nodes are generated by graph neural networks ( GNNs ), and the output nodes are nodes that were not included in the original graph neural network ( NTN ). Results show that using the proposed method for learning attention for noisy graphs yields improved performance over NTN and other attention methods. The main contribution of the paper is the introduction of the edge encoder, which is used for learning the edges to encoder of the attention form used in NTN."
SP:80a05296d6b1e4c6e9e2df01938c73029ff8487d,"This paper proposes a new agent, called INS - DS ( Introrospective Diagnosis System ), to learn an agent that mimics the human doctor ’s behavior when it comes to symptom induction and disease diagnosis, i.e., inquiring about symptoms and informing about diseases. This differs from the standard DSMAD agent, which relies on simple diagnostic accuracy to justify the effectiveness of its agent, while ignoring the medical rationality of the inquiring process. The proposed agent is composed of two separate yet cooperative modules : an inquiry module for proposing proposing symptom - based interventions and an introspective module for deciding when to inform a disease. The first module proposes the most valuable symptom inquiry. The second module, based on the response from the first module, interprets the potential responses of this inquiry and decides to inquire only if the diagnoses of these interventions ( from the response of another agent ) could be made more reliable and more robustly. This paper also proposes two evaluation metrics to validate the reliability and robustness of DSMAD methods : ( 1 ) diagnostic accuracy and ( 2 ) robustness to noisy interaction with patients. The experimental results demonstrate that the proposed agent, INS -DS achieves the new state - of - the - art under various experimental settings and possesses the advantages of reliability   compared to other methods. The evaluation metrics are used to evaluate the diagnostic accuracy ( diagnostic accuracy ) and the robustness ( robustness ) of the agent. Two evaluation metrics also are proposed, one for the reliability of DSM - DS agent and one for robustness and another for evaluation of the two evaluation modules used to train the agent in previous works. The paper also includes extensive experimental results to demonstrate the advantage of the proposed method. The manuscript contains detailed experimental results and is well - written. The main concerns of the paper are summarized below."
SP:10ae09d90d465125433a9b4f15b1405ab017920d,"Fine - Grained Visual Classification ( FGVC ) is a popular and important problem in computer vision research. FGVC is distinguished from other classification problems, such as AutoClass, due to significant inter - class similarity and intra - class variations, which make learning effective classifiers a challenging task. The authors propose BCN, a confusion energy - based framework to account for long - tailed scenario to learn to exert distribution of confusion energy across head and category categories to improve classification performance. The BCN framework is based on the confusion energy based framework from [ 1 ], which is adapted for the natural world distribution by incorporating fine - grained and long tailed properties at the same time. The proposed BCN has three components : ( 1 ) Adaptive batch - wise regularization to train the classifier to alleviate batch confusion ; ( 2) Adaptive learning to further reduce cross - entropy loss ; and ( 3 ) BCN learning to combine adaptive learning with the adaptive confusion concept to tackle both problems simultaneously.   The main contribution of this paper is the introduction of the Adaptive BCN concept, which combines the existing confusion energy-based framework and the BCN network learning to adaptively learn to reduce batch confusion loss while maintaining batch accuracy. The method is evaluated on three popular FGVC datasets and compared with the state - of - the - art on iNaturalist, CIFAR-10, and ImageNet. BCN is shown to achieve better performance than the other two methods on all three datasets. The main contributions of the paper are as follows :   ( a ) An adaptive learning method to overcome the difficulties of batch confusion in learning the classification task using batch confusion and ( b ) A ) An extension to BCN - BCN to combine the adaptive learning and batch regularization for dealing with the cross entropy problem on the batch - entropy task on the multi - class datasets."
SP:90f1e0fe1e9678d1e9a4dcb519d4e8fd61098ce0,"This paper proposes a new method, the Approximate Variational Reward Imitation Learning ( AVRIL ), to solve the inverse reinforcement learning ( INL ) problem by learning an approximate posterior distribution over the reward that scales to arbitrarily complicated state spaces using an MDP solver. The main contributions of the paper are the following :    1. A new variational approach to infer the Bayesian inference over the latent reward from the state space using variational gradient descent. This approach is different from the traditional Bayesian methods that rely on the MDP and require interaction with the environment in order to estimate the reward.   2. An imitation learning algorithm is jointly learned by minimizing the posterior distribution of the state - action reward over the policy distribution sampled from the variational distribution. This learning is then used to compute an estimate of the true reward that is used as the policy value function, which is used in the gradient descent step of the INL algorithm to compute the imitation learning objective. 3. An empirical evaluation of the method is performed using real medical data and classic control simulations. The results demonstrate that the approach outperforms the two state - of - the - art INL methods as well as other imitation learning methods in environments beyond the small tabular setting that is typically used in INL."
SP:ccd251d95c0a2d8dc5ad2a148ec29955e105e71e,"This paper presents Learned Belief Search ( LBS ), a search method for learning counterfactual beliefs in a partially observable environment using an auto - regressive belief model. The method is applied to the multi - agent setting where the agent uses a public - private model for policies and the policy evaluation policy is learned as a supervised task from rollouts. LBS is different from prior methods in that it does not maintain an exact belief distribution as in prior works, instead it uses a weighted sum of the counter - facts from the roll - out policy evaluation and the learned counter - factual belief from the supervised task. The main contributions of the paper are the following :   ( 1 ) It proposes a novel search method, LBS, for learning a counter - factual belief from a trained policy evaluation model using a learned policy from roll -outs. This method is evaluated in Hanabi benchmark games and compared with two prior methods ( L2 and L1 ). The results show that LBS performs better than L2 in terms of the computational cost in the domains where the policy evaluations are conducted using roll - outs. ( 2 ) It is important to distinguish between L2 - based and LBS as L2 is less computationally efficient in some settings ( e.g., in the domain of Hanabi ).    The main contribution of this paper is the use of LBS in evaluating the policies learned by the supervised learning method. The evaluation policy from LBS shows that it is more efficient than the one from L2 when it comes down to evaluation only ( L1 is computationally expensive )."
SP:db408e6bfe69a9b3984f3b27ca92b802aa37af42,"This paper proposes a new method for planning in large state spaces, aiming to control the bias - variable trade - off between planning depth and breadth of the search space ( which has a crucial impact on planners performance ). The method is called Shoot Tree Search ( STS ), which is an interpolation between MCTS and random shooting. The main idea is to use the fact that the score obtained by random shooting depends on the probability distribution of seeds at each node in the tree ( which is determined by a KL divergence between the seeds sampled from the target distribution ) and the score of the tree when seeds are randomly selected from all seeds that start at the same location ( i.e. not sampled from same node at the start of the same search direction ). This allows the planner to select seeds from the same distribution that have the highest probability of being planted in the same direction ( compared to seeds from different directions taken by the same node ).   The paper presents experiments on three different domains ( CIFAR-10, MNIST, Fashion - MNIST and CelebAesthetics ), showing that STS achieves the best of both worlds ( scores obtained from both methods ) when planning in these three domains. The paper also presents a variant of STS for the more challenging domains ( e.g., Geometric Geometry and Geometric MNIST ), where STS is able to obtain scores from both the tested domains ( GeometricGeometry and StyleGeometry ) without the need of gradient descent. The experiments are conducted with different tree sizes ( 5 - shot, 25 - shot and 50 - shot ), and the choice of tree sizes is based on the number of seeds per domain ( 25 for CIF and 100 for StyleAest and 60 for GeometricNearesteps )."
SP:5efc271ccc555fd9aa542548838170bd4c98e957,"This paper proposes LIME ( Learning Inductive Biasensemble for Mathematical R e - learning ), a pre - training approach for learning inductive bias from datasets that encode the reasoning bias for inductive reasoning primitives in the form of datasets. This approach is inspired by Peirce ’s view that deductive, induction, and abduction primitives form an irreducible set of reasoning primitive that can be leveraged to learn inductive biases. The authors propose three tasks that require the model to be able to deduct, induction and abductive in order to learn these biases. To ensure that only the fundamental reasoning biases can be learned from these tasks, the authors propose to pre - train the model on three datasets before using it for the downstream tasks. The datasets are designed in a way that requires only a small fraction of the computational cost of the typical downstream task to encode the bias for the three inductive primitives used to learn the bias, which is then transferred to the datasets for downstream tasks using a transformer network model trained with LIME.   The authors test their approach on a set of three tasks where the model is trained on top of three datasets, three transformer networks, and three instances of each dataset. The experiments show that LIME - trained transformers significantly outperform vanilla transformers on all three datasets. The main contributions of the paper are the following :   ( 1 ) LIME is designed to be pre - trained on datasets where the datasets are the same size ( 3 datapoints ) as the datasets, so that the model does n’t have access to all the same dataset features ( e.g.( 2 ) The method is designed for transformer networks where the dataset features are much smaller ( 2 ) the transformer networks are much more flexible ( 3 ) The approach is tested on three tasks, where it is shown to outperform the vanilla approach on two datasets, and on one task it outperforms the transformer model significantly ( 4 ) The main contribution of this paper is the design of a methodology that pre - trains the transformer network first to get the datasets and then to train the inductive model on the dataset using LIME to get rid of the bias."
SP:bb8e0b554d3b3314fa343c902d9e60f1a141ea30,"This paper studies the effect of the weight normalization ( EWN ) applied to gradient descent on neural networks trained on exponential or cross entropy loss. The main results are the following : ( 1 ) The gradient flow path with EWN is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. ( 2 ) The convergence rate of the loss in this setting is given by $ \sqrt{1 t(log t ) 2 ), independent of the depth of the network. ( 3 ) The results can be extended to hold for gradient descent via an appropriate Adaptive Learning Rate ( AEL ), and are compared with the results obtained with the inductive bias of SWN."
SP:c71f9d2a602516865a0b103028186e83b52e5f00,"This paper proposes a novel method to mitigate mode collapse in GANs, a class of generative models that suffers from mode collapse due to the inability of discriminators to maintain classification accuracy on previously seen samples. The mode collapse is caused when some modes of the target distribution of the samples are ignored by the generator. The authors identify this mode collapse as a phenomenon called Catastrophic Forgetting in continual learning ( TCFN ), and propose a novel training procedure that dynamically spawns additional discriminator to remember previous modes of generation to mitigate the mode collapse. The training scheme is plugged - in to two GAN framework ( GAN Adversarial Networks and GAN - GAN++ ) to improve the performance of GAN evaluation on several datasets. The main contributions of the paper are as follows :   ( 1 ) The authors propose a new training scheme that encourages the discriminator ( in the GAN2 framework ) to plug in previous GAN frameworks ( e.g., GAN-2 ) and train the discriminators in a manner similar to GAN ’s so that they are more aware of the modes of distribution that the generator ignores. This leads to a more robust generator. ( 2 ) The method is evaluated on three datasets ( CIFAR10, MNIST, Fashion - MNIST and Fashion - EU - CSE ), where it is shown that it is able to reduce mode collapse ( on MNIST ) as well as increase accuracy ( on the other two datasets ). The results demonstrate that the proposed method is more robust than GAN+ ( which uses a different training procedure ) and that GANet, which does n’t train discriminators."
SP:52c48198c95826e042f9e5a512ef3265daaff882,"This paper proposes AUBER, an effective regularization method that leverages reinforcement learning to automatically prune attention heads from BERT. The idea is to use heuristics or rule - based policies to determine the pruning policy that determines which attention heads should or should not be pruned for regularization. The main contribution of the paper is to develop and test a pruning algorithm based on reinforcement learning that automatically prunes attention heads based on a policy that is learned using reinforcement learning. The method is evaluated empirically on NLP tasks and compared with two heuristically - based pruning methods : DP - pruning ( based on proxy score for importance of each attention head ) and DPM - a heuristic - based method that uses a KL divergence between the number of pruned attention heads and the order in which they are pruned. The results show that AUBERNESS achieves up to 9.39% better accuracy than the other two heuristic methods ( DPM and KL ). In addition, the authors conduct an ablation study to evaluate the effectiveness of their pruning method and to identify the leverages for reinforcement learning for pruning.   The paper is published with supplementary material."
SP:abcbbad146f1b0d5d579c215952c95e5499a378a,"This paper presents a method for learning data - driven transfer learning between two different multimodel robotic domains, differing in representation ( internal state vs. internal state ), physics parameters ( mass and friction ), and morphology ( number of limbs ). The underlying idea is to propose dynamics cycles that align dynamic robot behavior across two domains using a cycle - consistency constraint. Once this is done, the method is able to directly transfer the policy trained on one domain to the other, without needing any additional fine - tuning on the second domain.   The main contributions of this paper are :   ( 1 ) This paper proposes a learning framework that learns data correspondences across two different domains, i.e., v1 and v2, from unpaired and randomly collected data from the two domains. This enables learning policy gradient based transfer learning ( e.g., policy gradient from robot policy proposed in v1 to robot policy in v2 ) without the need for additional fine tuning in the first domain. ( 2 ) The method is evaluated on both simulated and real robotic tasks, where the goal is to train a robot policy based on the learned data from one domain ( v1 ) and the policy generated by the policy of the robot trained in the other ( v2 ): the robot policy is evaluated both in simulation ( on real and simulated tasks ) and on the real robot ( on the simulated task ). ( 3 ) The experiments are divided into two parts : one in which they test the ability of the proposed policy gradient method to learn data from v1, and one in where they do not : the ability to learn from v2 using the collected data. ( 4 ) The authors compare the performance of their method with the one method on simulated tasks and real - robot vs. robot tasks, and find that their method outperforms the other method on most of the time."
SP:006434d56992836ab9420d7d4215bc70664de304,"This paper studies the problem of explainability of explainable models in the context of deep learning with respect to the framework for explainability, the Shapley explainability algorithm. The main contribution of this paper is to develop two solutions to the explainability problem based on the generative modelling approach of Shapley Explainable Generative Models ( IDM ). The generative approach assumes that a model ’s predictions and its input features are mathematically principled and model - agnostic. This assumption is problematic because it leads to an untenable assumption that the features of a given model and the input features of the data manifold are orthogonal to each other, leading to an inability to isolate certain aspects of the features that are specific to a particular model ( e.g., the fact that a value function defined by a generative model learns the parameters of a particular input feature directly from its predictions and does n’t depend on other model parameters ). Under this assumption, the authors argue that there are drawbacks to the model explainability under the IDM assumption and propose two ways to address them. One is based on using imputations from generative models to obtain more flexible access to data imputations, while the other directly learns the value function of the model to provide stability at the cost of flexibility.    The first approach ( based on IDM and GANs ) is evaluated empirically and compared with two other explainability algorithms, one based on GAN - based explainability and another based on Markov chain theory. The results in a lower bound on the number of imputations of the second approach has higher performance. The experiments compare the performance of the proposed method with the one. The authors conclude that the proposed by IDM has higher stability but lower performance. Finally, on the other hand, the approach has a lower performance but higher flexibility."
SP:7cda6bccf08887c7cef66d0ac3ccefdea8f5d7c8,"This paper proposes a new method for opponent modelling based on variational autoencoders. The target agent is trained via reinforcement learning ( RL ) to estimate the opponent ’s world state, chosen actions, and received rewards from its interactions with the agent it is modelling. The opponent policy is learned using a reinforcement learning approach. The paper presents a method for embedding the opponent policy in the agent's decision - making process using learned embeddings instead of using the opponent's state - state and reward embedding, as done in prior work. This allows for using the technique for modelling multi - agent interactions without the need for access to opponent observations. The proposed method is evaluated in three tasks with different objectives and compared with two baselines. Results show that the proposed method achieves comparable performance to an ideal baseline method which has full access to all the opponent observations and rewards. The method also shows that it is more effective than two methods for two tasks for which the target agent only has access to the world state and rewards of the opponent. Ablation studies are performed to evaluate the effectiveness of the method."
SP:c239bc531bcf7293032748af29a1b786e9d893dd,"The paper proposes Consistent Contrastive Learning ( CO2 ), an extension of contrastive learning ( CO1 ) to the unsupervised learning setting where the task is to perform instance discrimination on a set of unlabeled images and label crops from the same query as positives and crops from other randomly sampled images as negatives based on similarity of query crop and each crop from other images. CO2 is motivated from the perspective of consistency and consistency of regularization in semi - supervised learning ( S2 ) learning on unlabelED data. It introduces a consistency regularization term into the current contrastive learners framework, which introduces a term “ consistent contrastive contrast ” into the definition of “ un - labeled contrastive learned ” term in CO1 to distinguish it from “ contrasting ” learning ( which takes the corresponding similarity of a positive crop as a pseudo label, and encourages consistency between these two similarities ). The authors show that with the addition of CO2, S2 learning ( with the help of MoCoCo learning regularization ), S1 learning ( without S1 regularization but with consistency in terms of the contrastive term ), CO2 learning performs better on image classification, object detection, semantic segmentation on PASCAL VOC, and image classification on COCO. They also show that CO2 learns better visual representations for these downstream tasks.   The main contributions of the paper are the following :   ( 1 ) The authors propose a method to distinguish between the positives and negatives obtained from crops from query crops sampled from other than those from the query crops under the control of the same semantic class as the query crop from which the negatives come from. This is important because negative crops may belong to same semantic classes as query crops and some of them may have been assigned negative labels based on the query class. ( 2 ) The method is based on instance discrimination with the assumption that the semantic class of the negative samples is similar to query crops. ( 3 ) The experiments show that the proposed method outperforms the S1 and S2 methods for image classification and object detection on ImageNet linear protocol and ImageNet Top - 5 classification with a notable margin of 2.9% and 1.8% on the accuracy on the top - 5 and 6 % on the image classification. ( 4 ) The paper also shows that the method is able to outperform S1 by a similar margin on object detection ( object detection ) on PascALVOC."
SP:d18bab21790713e2facb053c47298fc9079ab783,"This paper studies last - iterate convergence of Optimistic Multiplicative Weights Update ( OMWU ) and Optimistic Gradient Descent ( OGDA ) in bilinear games over the probability simplex. The authors first provide a sufficient condition under which OGDA exhibits concrete last -iterate convergence rates with a constant learning rate whose value only depends on the smoothness of the objective function. Then, under the same assumption, the authors provide experimental results to further support their theory. The experimental results consist of : ( 1 ) OMWu playing $ \ell_2$-functions over the space of simplex ( assuming the equilibrium $ \theta$ is unique ), ( 2 ) linear last - iteration convergence of $ \tilde{O}(\epsilon)$ on the set of polynomial values of the simplex, ( 3 ) strongly - convex optimization ( recovering the result of ( Hsieh et al., 2019 ), and ( 4 ) strongly convex - cum - combinatorial ( recovering $ \sum_{k=1}$ and $ \gamma_k$ ) functions. The experiments verify that the convergence rates obtained by the authors are robust to the additional assumptions ( e.g., $ K=1 $ and $ K$ being the size of the optimal function ), as well as the assumptions that the equilibrium of the polynomials is unique, namely that the learning rate of $ O$ is linear in the last iterate and that the distance between the ground - truth and optimal functions is not too large ( $ t$ is $ t-1$. )   The authors then extend the results to more general objectives and feasible sets for the projected OGDA algorithm, by introducing additional assumptions such as the uniqueness of the equilibrium and the importance of $ T$ for reaching the optimal solution. They show that OGDA converges exponentially fast even without the unique equilibrium assumption, and the resulting convergence rate is robust to $ T$. The authors also show the convergence rate holds for strongly-convex-stronglyconcave functions, recovering the end - of - year result ( 2019 ). In the last part of the manuscript, a number of experimental results are provided to verify the correctness of the assumptions and provide further support for the authors'theory."
SP:bbc7f77308b298c332a39747f693bc396f00a89f,"This paper proposes Federated User Verification ( FedUV ), a framework for training neural network models in federated setting. In FedUV, each user has access to the data of only one class and user embeddings cannot be shared with the server or other users. To address this problem, the authors propose to jointly learn a set of vectors and maximize the correlation of their instance embedding with a secret user - defined linear combination of those vectors. They show that choosing the linear combinations from the codewords of an error - correcting code allows users to collaboratively train the model without revealing their embedding vectors. The experimental results for user verification with voice, face, and handwriting data are presented and show that FedUV is on par with existing approaches, while not sharing the embedding vector or embedding details with other users or the server."
SP:40fa47cc0928e2925ef5ce6d808073f368ca2cd4,"This paper proposes a new technique to estimate the effective dimension of class manifolds ( CMs ) based on their intersection with random subspaces of varying dimension. The margin is defined via boundaries between these CMs. The authors present a simple technique to compute the intersection of the margin of a set of CMs and the boundaries between multiple CMs, by computing their intersection at random. They provide a theory for the technique and verify that their theoretical predictions and empirical predictions on real neural networks agree with each other. They then leverage this method to show deep connections between the geometry of CM, generalization, and robustness. In particular, they investigate how CM dimension depends on ( 1 ) the dataset, ( 2 ) architecture, ( 3 ) random initialization, ( 4 ) stage of training, 5 ) class, 6 ) ensemble size, ( 7 ) label randomization, 8 ) training set size, 9 ) robustness to data. They show that well - performing robust models have higher dimensional CMs than worse performing models, and that generalization is better for CM than it is for generalization - robust models. They also provide a unique perspective on ensembling via intersections of class manifold ensembles.   The paper is published with supplementary material. The manuscript includes the following main texts :    1. Introduction. This paper introduces a new class of neural network classifiers, the Deep Neural Networks ( DNNs ). These classifiers naturally partition input space into regions belonging to different classes. The main contribution is to develop a method for computing the intersection between the classifier weights and the margin between any two classes. This allows the authors to construct a novelties between the DNN classifier and the class boundary. The key idea is to use the same set of weights as in [ 1 ] to get a novel classifier but for other classifiers. The benefits of this is that it is possible to use different weights for different classifiers for different parts of the network. For example, in [ 2 ], the authors could use the weights from different DNN regions to get the same classifier for all classifiers but a different margin for some parts. This could lead to better generalization or worse generalization. On the other side, the main contribution of the paper is to train the network on different versions of the dataset. This is done by dividing the dataset into pieces of equal size and using the weights for each piece into smaller pieces. Different combinations of these smaller pieces yield slightly different results. The experiments compare the performance of the networks on different"
SP:09bce202ac7a750c3700a8ef3cd92cfe8ed00c39,"This paper proposes Curiosity - Aware Entropy Temperature for Soft Actor - Critic ( CAT - SAC ), an extension of the SAC policy in Haarnoja et al. ( 2018a ) that introduces an entropy temperature for maximizing both the external value and the entropy of the policy. The authors argue that the existing entropy temperature applied indiscriminately to different environment states undermines the potential of exploration, and propose to use the curiosity mechanism to explore more in an unfamiliar state, while less in a familiar state, so as to understand the environment more efficiently. To achieve this goal, they propose a method that uses the state - of - state prediction error to model the curiosity of the agent in developing an instance - level entropy temperature, where the state with the largest curiosity is considered more interesting to study, and the agent is encouraged to explore when its curiosity is large. Experimental results on the difficult MuJoJoJo benchmark dataset show that the proposed method significantly improves the sample efficiency, outperforming the advanced model - based / model - free RL baselines.    The main contributions of the paper are the following :   1 ) The authors propose a new method that extends the entropy - based policy in the previous work, Haeun-Jin ( 2018 ) to explicitly use the entropy from the exploration policy in order to increase the exploration potential of SAC policies. This is done by setting the state-of - the - art entropy temperature to 1 ) increase the entropy for unfamiliar states and decrease the target entropy for familiar states, and 2 ) adjust the target for the exploration in each state to encourage exploration in unfamiliar states while maintaining the same exploration in familiar states. The experiments show that this approach, when applied to both familiar states and unfamiliar states, results in improved the agent's exploration performance significantly. The experimental results also show that, when combined with the new exploration policy, SAC outperforms the existing soft actor - critic policies in terms of sample efficiency and exploration potential."
SP:dce5eb20581a21c5de0a9fc07a8a79a1fbb28c71,"This paper proposes MIER, a meta - reinforcement learning algorithm that is efficient and extrapolates well when faced with out - of - distribution tasks at test time. It builds on the model identification and experience relabeling ( MIER ) algorithm from [ 1 ], which is able to generate synthetic experience for the new task ( e.g., generating off - policy data for meta - training when the agent is not using meta - policies ). The key insight of MIER is that if we assume that the dynamics of the two model encoders are similar ( i.e., based on the assumption that the encoder is given by the same neural network ), then we can use MIER to predict the similarity of the learned model dynamics with the learned trajectories from the task trajectories. Based on this insight, MIER proposes to train a model encoder that predicts the trajectories of the ground - truth trajectories given only access to the training data for the policies under consideration. The paper shows that MIER training can lead to significantly better performance than baselines that do not require access to training data.    The main contributions of this paper are the following : ( 1 ) MIER trains an efficient and well - performing meta - policy learning algorithm from scratch using only the generated synthetic experience from MIER. ( 2 ) It uses the same two models ( ID and E ) to learn the learned policies and trajectories without requiring additional model training data from the agent. The experiments show that the algorithm outperforms the baselines of meta - re - policies and baselines and outperforms baselines in terms of performance when extrapolation."
SP:34d78aa11f9d50baf75a9646a6f9128318c3389a,"This paper proposes Introspective Self -paced Learning ( ISPL ), an extension of Eigen - Reptile ( ER ) for few - shot learning ( FSL ) to deal with label and sampling noise in meta - learning. The authors argue that FSL is a gradient noise problem since few available samples cause the meta - learner to overfit on existing examples ( clean or corrupted ) of an individual task at every gradient step. ISPL is motivated from the perspective of avoiding gradient noise at every step of the learning process by using a plurality of prior models to determine which samples should be abandoned during the training phase and which should be used as training samples for ISPL ( e.g., clean samples or corrupted samples ). Experiments on several tasks demonstrate that the proposed methods outperform state - of - the - art methods with or without noisy labels.   The main contributions of the paper are the following :   ( 1 ) The authors propose a method to mitigate the overfitting problem of FSL by treating sampling and label noise as separate problems. The idea is to firstly identify the problem of meta - overfitting and then to jointly identify the source of the problem ( the sampling noise and the label noise ) and come up with a solution that can alleviate both problems together. This is the main idea of ISPL. ( 2 ) It proposes to use a different mechanism for each gradient step of learning ( the Eigen-Reptile module ) to generate a set of independent experiments to evaluate the effectiveness of the proposed method. ( 3 ) It is important to distinguish between the output from the output of the method under the presence of label noise and that of the prior method ( E.R. )    Experimental results on MNIST and CIFAR-10 show that the methods proposed by the authors achieve better or comparable performance compared with the state of the art methods on both MNIST ( clean and corrupted ) and MNIST."
SP:a571bff9ffe4edafd7bc064c4d10609e6b981ce3,"This paper proposes Adversarial batch normalization ( AdvBN ) for generating robust distributional models that are robust to distributional shifts in the mean and variance of deep feature statistics. The distributional statistics are obtained by adversarially perturbing the feature statistics instead of the image pixels in deep neural networks, as is the case usually done for adversarial training. The authors demonstrate that AdvBN improves the performance of ResNet - 50 on ImageNet-C, Stylized - Image - Net, and ImageNet - Instagram over standard training practices. They also demonstrate improved generalization on semantic segmentation of ImageNet. The main contributions of the paper are the following : 1 ) AdvBN generates distributional robust models that produce distributional regularization that is robust to distributionsal shifts, as opposed to the image pixel - based robustness that is produced by image - based regularization. 2 ) It is important to distinguish between distributional normalization and distributional adversarial perturbation, which is the latter method's main contribution. 3 ) The method is shown to generate robust distributions of image features for training neural networks on adversarial distributions, and to visualize images from the latter.   The authors conduct extensive experiments to validate the effectiveness of AdvBN on various image classification tasks, and show that it yields better results than other robust regularization methods such as ResNet-50, ImageNet, and ShapeNet."
SP:6a9c46bd3cf854299f360bff136e1d79d3edb2e4,"This paper proposes Variance of Gradients ( VoG ) metric for detecting outliers in the data distribution. VoG is a metric that measures the probability that a point sampled from the distribution is likely to belong to a particular set of gradients. Data points with high VoG scores are more difficult for the model to learn and over - index on corrupted or memorized examples. The authors propose to use VoG to rank data by difficulty and to surface a tractable subset of the most challenging examples for human - in - the - loop auditing ( HILBO ), which is a setting where the model is allowed to explore and explore on its own. The paper provides quantitative and qualitative support that VoG can be a meaningful metric to detect outliers.   The main contributions of the paper are as follows :   1. A new metric, VoG, is proposed to measure the probability of finding an outlier data point in the distribution of gradient estimates. This metric is derived from the fact that outlier examples are likely to be clustered together in the dataset. 2. A subset of examples, dubbed Atypical Examples, is used to identify atypical examples for the safe deployment of models and to isolate outliers that require further human inspection. 3. A set of examples is used for testing the probabilistic neural network architecture, in which a model is trained on a dataset and samples are sent to a human agent to assess the model ’s performance. The human agent inspects the samples and reports back to the training set the score of the neural network and the accuracy of the predictions made by the model. The results are reported in terms of accuracy ( i.e., the accuracy with which the model learns to predict the true label given an image of the image ) for all samples from the dataset and for a subset of samples that have higher scores ( those with higher scores indicate that the model was able to learn more about the true labels ). The experiments conducted in the paper demonstrate that the VoG metric can detect outlier samples more reliably.                                                             1. An important but still developing technique for detecting outlier datasets is the so - called “ hard outlier classification ”. This is the process of identifying which examples are challenging for a model to classify and which ones need more human"
SP:074bfacc75837bb19049be8a2890e10de073dd8e,"The paper proposes Discriminator Gradient Gradient f low ( DGf low ), a technique to improve the generation quality of generated samples from GANs using entropy - regularized f - divergences between the real and generated data distributions. The method is motivated by two previous methods : DOT and DDLS, which generate samples using Gaussian Mixture Models ( GMMs ) and McKean - Levassov gradients respectively. Authors argue that DOT is costly to implement as it requires sampling from all possible combinations of GMMs, while DDLS is expensive because it requires using samples that are likely to be rejected due to their poor generation quality. The main idea of the method is to use the gradient flow of the Fokker - Plank equation to approximate the gradient of the mean and standard deviation of the distribution sampled from MC - $ \ell_2$. Gradient flow can be represented as a weighted average of the Kronecker - plank equation, where Kroneck's equation is the log - likelihood of the generated samples. Authors show that this gradient flow is easy to approximate via Monte Carlo simulations. Authors then propose a method to refine samples from inferior distribution to maximize the likelihood of generating samples from the optimal distribution. They show that their approach is more efficient than DRS and MH -GAN in terms of the number of rejected samples, and they also show that it is less expensive than DGAN and MH-GAN when it comes to generating samples.   The authors test the method on four different GAN datasets ( CUB, VAE, VAEs, STL, STL - VAE ), two deep generative models ( VA3 and VAE - VAEs ), and one stochastic VAE. Results show that DGF leads to significant improvement in the quality of generation samples for all four datasets. However, the authors show that the improvement is more marked for VAEs with VAEs and less so for STL. For STL, the improvement seems to only be around 0.02 %, and for DDLS it is about 0.05 %."
SP:74ecbc5a6d464bfa49337da9e0dd6a0fe714d4bb,"This paper presents a variable encoder - decoder ( VECO ) pre - training approach to unify the two mainstream Transformer architectures in understanding and generation tasks. Prior work has trained either an encoder only Transformer mainly for understanding tasks or an encoders - only transformer for generation tasks, ignoring the correlation between the two tasks and the different architectures used to build the Transformer models. In contrast, this paper splits the standard Transformer block into several sub - modules trained with both innersequence and cross - sequence masked language modeling, and correspondingingly reorganizes certain sub - module for understanding and generating tasks during inference. The main contributions of the paper are the following :   ( 1 ) The paper proposes a variable encoding - decoding block that can be used for both generation tasks and understanding tasks. This allows to train the most efficient encoder / decoder with reduced number of parameters necessary for both kinds of tasks, and also enables them to boost each other via sharing information via parametric sharing. ( 2 ) This paper proposes variants of the WMT14 and BLEU models that are compared with WMT16 and WMT17 on English - to - German ( E2D ) and English - To - French ( E3F ) datasets, with gains of up to 1.5 to 2 % ( on average ). ( 3 ) It outperforms all existing cross - lingual models and state - of - the - art Transformer variants on both datasets that it compares with. ( 4 ) As a result, the paper proposes to train two types of models : a generative model ( generative transformer ) and a model - only model ( model ), which is used to generate tokens for the generative tasks. ( 5 ) It also proposes to use GPT-2 as a model learning rate estimator to train generative models. ( 6 ) The experiments are conducted on various cross -lingual understanding tasks of the XTREME benchmark, with notable performance gains across text classification, sequence labeling, question answering, and sentence retrieval tasks.   The paper is published with supplementary material and the manuscript is also available for review online."
SP:3d177ad50727d1a2619b68ab8a897b79d8652beb,"This paper proposes a novel intrinsic motivation for guided exploration using auditory event prediction as reward mechanism in reinforcement learning ( RL ). It builds on the idea of multi - sensory integration ( MSS ), which integrates multiple sensory modalities ( e.g., visual, audio, and proprioceptive ) to build a causal understanding of the physical world to guide exploration based on a cluster of auditory event clusters that are predicted by a neural network using a set of K - means. The idea is to train the neural network to predict the event clusters using the clustering data and use the prediction errors as intrinsic rewards to guide RL exploration. The neural network is trained to predict an auditory event cluster of the given data using K - mean clustering, and the errors are used to reward the agent to explore the cluster using the knowledge of the true causal effect of the selected auditory event. The method is validated using the ThreeDWorld ( TDW ) simulator, the Habitat simulator, and audio - visual exploration using the TDW simulator. The experiments show that the proposed intrinsic motivation is superior to other intrinsic motivation methods in guiding exploration using MSS.    The main contributions of this paper are the following :   1. A new intrinsic reward mechanism for guiding exploration is proposed based on auditory event predictions ; 2. An in - depth analysis of the proposed method is conducted using TDW and Habitat simulators ; 3. A set of Atari games is used to validate the effectiveness of the intrinsic motivation."
SP:014f6118ebe55ece6be23c3a10f12e4591e444b1,"This paper proposes an end - to - end framework to jointly learn a reliable representation and assign clusters to unlabelled data using contrastive learning with labels from different but relevant categories. To avoid overfitting the learnt embedding to labelled data, the authors take inspiration from self - supervised representation learning by noise - contrastive estimation and extend it to jointly handle labelled and unlabeled data. The proposed framework proposes using category discrimination on labelled data and cross modal discrimination on multi - modal data to augment instance discrimination used in conventional contrastive learns approaches. It further employ WTA ( Winner - Take - All ) hashing algorithm on the shared representation space to generate pairwise pseudo labels for unlABelled data to better predict cluster assignments. This paper studies the problem of novel category discovery on single - and multi - multimodal data with label - free but label - dependent categories. The main contributions are the following :   1 ) The authors propose a generic framework that can be applied to a wide range of tasks, including machine learning ( e.g. classification, machine translation, recommendation systems ), clustering, and machine translation - agnostic clustering.   2 ) The method is evaluated on large - scale multi - video benchmarks CIFAR-10, CifAR100 and ImageNet, obtaining state - of - the - art results. 3 ) It is also compared with instance discrimination and instance discrimination with WTA on the task of semantic segmentation to assess whether the learnt representation is representative enough for the task."
SP:4df640f502e88ddba2d7e183625231d70b083e82,"This paper studies the problem of weakly supervised segmentation using image - level tags, object bounding boxes, labeled points and scribbles. It is realized that coarse annotations ( tags, boxes ) require precise pixel localization whereas sparse annotations ( points, scribbles ) lack region coverage. The paper proposes two approaches to handle the challenges presented by these two types of weak supervision : ( 1 ) conditional random fields propagate sparse labels to the entire image ; ( 2 ) class activation maps are used to localize coarse labels and iteratively refine the segmentation model. The main contribution of this paper is to formulate segmentation as a semi - supervised metric learning problem, where pixels of the same image ( different ) semantics need to be mapped to the same ( distinctive ) features within and across images. It proposes 4 types of contrastive relationships between pixels and segment in the feature space, capturing low - level image similarity, semantic similarity, contrastive annotation, co - occlusions and feature affinity. The major contributions are the following :    1 ) It proposes a segmentation framework that can be learned from training images with any partial annotations in a data - driven fashion, capturing feature similarity between pixels in each image, but also in discriminative feature learning within image and across image. This allows it to avoid the pitfalls of gradient descent and gradient vanishing, which can happen when learning features that are identical within an image but not within the same space ( e.g., if pixels in one image are sampled from the same feature space but not from another one in another image ). 2 ) It improves upon Pascal VOC and DensePose by introducing conditional segmentation with the proposed contrastive feature learning model. This enables it to learn feature relationships in both the image space and training instances without any additional supervision."
SP:f7d6099adb40a0ce2f8a3563dbd5207cf1fdea0f,"This paper presents a simple but effective distillation strategy for unsupervised learning, where the goal is to aggregate compact representations over the student with respect to instances in a bag to transfer the relationship among similar samples that can be transferred to the student to boost the performance of self - supervised learning. The paper proposes a method called BINGO ( short for Bag of InstaNces aGgregatiOn ) to achieve this goal, which is short for bag of similar samples constructed with a set of similar instances grouped within a bag, and are grouped by the teacher and the student. The student and the teacher use the same dataset ( ResNet-18 and ResNet - 34 ) and are asked to generate a linear evaluation of the relationship between the two sets of similar exemplars and the one obtained by the student using the extracted dataset from the teacher. The evaluation is done using linear regression on the samples from the two datasets, and the key idea is to generate similar samples so that the student can use the one that has the most similar relationship with the teacher to maximize the transfer probability when the student is asked to use it in the supervised learning task. The method is evaluated on ImageNet and ImageNet - GP with linear regression and compared with the supervised counterparts. The experiments show that the proposed method achieves better performance compared to the supervised counterpart on small scale models, i.e., 65.5 % and 68.9 % top - 1 accuracies, respectively. The main contributions of the paper are the following :   ( 1 ) The authors propose a method to aggregate similar samples from teacher and student to generate exemplars that have a high probability of being similar to one another. This is referred to as “ distillation ” in the paper as in the definition of distillation. ( 2 ) It is important to distinguish between “ similar ” and “ contrastive learning based ” learning methods, which regard each image as an individual class of augmentations as individual class and try to distinguish them from all other images. This kind of learning assumes a large quantity of exemplars, which naturally suffers from slow convergence and is hard for optimization. ( 3 ) In contrast, the proposed distillation method aims at generating similar samples which can be easily transferred from one exemplar to another using a small batch of exemplar.    The main contribution of this paper is the introduction of the concept of “ classifiers ”, which are classifiers that distinguish images that are similar to each other and that the teacher uses to learn a classifier to distinguish"
SP:328866aad6544c81ded8980934df31dc4472435f,"This paper proposes GATSBI, an adversarial variant of Sim - based Inference on stochastic models ( SBI ) for generating samples, but not computing likelihoods. Unlike generative adversarial networks ( GANs ), SBI and GAN require the computation of a likelihood function. This paper proposes to learn an implicit distribution via variational inference over the posterior distributions of the samples generated by the variational objective of SBI. The method is evaluated on two SBI benchmark problems and two high - dimensional simulators. The results show that GATsBI performs better than GAN and is more flexible than a state - of - the - art SBI approach. It also shows how GATSBI can be extended to perform posterior estimation on individual observations."
SP:2915e82097eae4eb8546dc500f32b3ec37e3766f,"The paper considers the identification and estimation of treatment effects ( TEs ) when subjects with certain features belong to a single treatment group ( i.e., when there is a limited overlap between the treatment groups ). The paper proposes a new variational autoencoder ( VAE ), which is a generative prognostic model that learns to predict the prognostic score using a latent variable and the individualized treatment effects conditioned on the features of the treatment group. The VAE is compared with VAEs using biostatistics and recent VAE - based methods using ( semi-)synthetic datasets. The main contributions of the paper are the following :   1. The use of VAE as a variational generative model to predict prognostic scores is a novel and interesting idea. The latent variable used to train the model is similar to that used in VAEs, and the fact that it is based on a learned variational model is important to distinguish it from other generative models that are not based on the latent variable. The difference is crucial to distinguish the VAE from other models that only learn the parameters of the model from the data.   2. The estimation of the TE error bounds is done using a VAE neural network that learns the weights of the representations of the covariance matrix for each treatment group using the learned VAE model. Three different versions of the neural network are considered : ( 1 ) the base VAE, ( 2 ) VAE with fixed weights ( with fixed parameters ), ( 3 ) the fully - connected VAE. The neural network is used to estimate the TE for the base model and derive the bounds for the two other TEs ( e.g., $ \mathbb{T}$ and $ \text{T_{t_{e } \log p}$, where $ p(T_{e}$ is the treatment effect ) for a given treatment and $ t_e$ for a sample of the same size \epsilon$.    3. The individualized VAE weights are learned using the fixed weights from the ground - truth VAE and the two variational models. The experiments are done to compare the performance of the proposed method and the baselines. The results are compared with two baselines ( VAEs and VAEs ) and two other methods. The experimental results show that the proposed VAE method performs better than other methods on a small number of cases, and that the average performance is slightly worse for larger numbers of samples."
SP:ca358c9f36aac6e58ed1b3949c349d210c49a48e,"This paper proposes a framework for Autonomous Reinforcement Learning ( ARL ) for reinforcement learning where the agent learns through its own experience, but also contends with the lack of human supervision to reset between trials. The paper proposes EARL1, a framework that extends the idea of naturalistic learning ( RL ) in which an agent learns a skill via trial and error to imitate the acquisition of skills through experience from the environment. However, unlike naturalistic RL, embodied learning in real - world embodied learning is situated in a continual non - episodic world with the environment resetting between trials, whereas common benchmark tasks in RL are episodic. This discrepancy presents a major challenge when attempting to take RL algorithms developed for episodic simulated environments and run them on real world platforms, such as robots. The main contribution of this paper is to propose EARL 1 around this framework, containing a set of diverse and challenging simulated tasks reflective of the hurdles introduced to learning when only a minimal reliance on extrinsic intervention can be assumed. The experiments show that standard approaches to episodic RL and existing approaches to reinforcement learning struggle as interventions are minimized, underscoring the need for developing new algorithms for RL and developing ARL algorithms.   The main contributions of the paper are the following :   1. The authors propose a new framework for autonomous reinforcement learning ARL : AEL. It extends the framework for naturalistic reinforcement learning in the sense that it provides an environment in which the agent does not need to learn a skill extraction algorithm ( unlike RL ) but also provides the agent with the capability to learn the skill acquisition strategy ( RL algorithm via the environment ). 2. It provides the environment in ARL $ \epsilon$ \epL1 $ to train an agent to solve tasks in an embodied learning setting where the environment changes between trials and the agent only needs to visit the environment a few times a day. 3. The algorithms developed in the framework are tested on the tasks in the presented in the experiments section and evaluated on the task of self - supervised learning ( SARL ). The results show that SARL outperforms existing RL algorithms on SARL and existing algorithms."
SP:abe51d4a9817c08f0abde5da0bb8e6ca4e02e7cf,"This paper investigates Graph Neural Networks ( GNNs ) and the ability of GNN - based QA modules to perform reasoning over knowledge graphs in order to approximate the reasoning capability of human - level QA systems. It shows that even a very simple graph neural counter can not outperform all the existing GNN modules on two popular QA benchmark datasets, CommonsenseQA and OpenBookQA, even when reasoning over simple knowledge graphs that are supported by the majority of the datasets ( e.g., QA101 and QA103 ). The authors investigate the following questions :   1. Can these GNN-based modules really perform a complex reasoning process?   2. Are they under or overcomplicated for QA.   3. What are the properties of the modules that make it possible to build such reasoning modules for knowledge - powered QA? The authors answer these questions by comparing the capabilities of the existing knowledge - aware GNN and the new Graph Neural Network - based modules. They show that the GNN module can only carry out some simple reasoning such as counting, while the new module can reasoning over complex knowledge graphs ( which is quite different from the way we normally do it ). They also show that it is difficult to train a reasoning model that can reason over complex graphs using the knowledge graphs provided by the new modules and that the reasoning model needs to be able to handle complex reasoning graphs beyond what is currently possible using the current state - of the art QA system. The experiments are conducted on three datasets ( Commonsense QA, OpenBook QA and QC - QA ), two popular benchmark datasets ( QC and QDataQA101 ), and two lesser - known datasets ( SQAR and SQAR - Q2A ) to investigate these questions. They compare the performance of the new and existing modules and find that the new one is slightly worse than the existing one on SQA and SQA, but on the other two datasets it performs slightly better than the previous one. They further investigate the differences between the two and find out that the module with the best performance is the one with the most common discrepancy between the output of the different modules."
SP:3ea5a38e7fcd9111dcd299ad039b634e2781685f,"This paper proposes a three - stage method for Deep Neural Networks ( DNN ) inference based on compressed data structures. The main idea of the method is to first transform the compressed representation of the underlying DNN model into a formulation similar to the one used in the paper ( Liu et al., 2020 ), and then perform inference on that formulation using compressed representation during inference time. To achieve this, the authors propose three stages of the proposed method. In the first stage, the compressive representation is transformed into a data structure representation using the method ’s proposed Succinct Data Structures. This representation is then used for fast queries on compressed representation obtained during the inference time ( stage 2 ). The second stage, stage 3, and final stage are the same as the previous stage, except that they are applied in a slightly different way ( stage 4 ). Experiments are carried out on AlexNet / VGG16 inference on standard DNN models and compared to AlexNet/VGG16 with and without decompression. Results show that, our method keeps the near - optimal compression throughout the three stages, and achieves at least 8.7x7.7 / 11.5x5.5X speedup on queries that are based directly on the representation obtained from stage two ( stage 3 ). Results also show that our method is synergistic with Pruning and Quantization and is capable of handling data augmentation similar to each other. The authors also conduct experiments on different versions of their method to test their method for different model formulations and retrieve relevant data for DNN inference."
SP:94c395afc794a9cc163e362078769ff83f3d20d0,"This paper proposes a new training method for improving the performance of tiny neural networks. The authors argue that existing regularization techniques ( e.g. data augmentation, dropout ) have shown much success on large neural networks by adding noise to overcome over - fitting, but it is argued that these techniques hurt the performances of tiny models. To alleviate this issue, NetAug augments the network instead of inserting noise into the dataset or the network. NetAug puts the tiny model into larger models and encourages it to work as a sub - model of larger models to get extra supervision, in addition to functioning as an independent model. They evaluate the effectiveness of NetAug on image classification and object detection using ImageNet, ImageNet - C and 4.3% on Cars On Pascal VOC. They find that NetAug provides 2.96% mAP improvement with the same computational cost.   The main contributions of this paper are the following :   1. They propose a method for augmenting the model, since tiny models tend to suffer from under - fitting rather than over -fitting due to limited capacity. 2. They show that using the reverse dropout technique on the network improves performance of the tiny models, achieving up to 2.3 % accuracy improvement on ImageNet   3. They use ImageNet to train the network and then reverse - engineer the image classification for ImageNet with NetAug."
SP:9c24549b980e415616f818acbf4cf680ef8edb52,"This paper presents a generative adversarial network ( GAN ) based on Point cloud Upsampling ( PUP ). PUP is used to generate dynamic point cloud sequences without point correspondence annotation. The key idea of the GAN is to learn the underlying temporal coherence from the point cloud sequence, which in turn guides the generator to produce temporally coherent output. To this end, the authors propose a learnable masking module to adapt upsampling ratio according to the point distribution. Experiments are conducted on two different domains : particles in the fluid dynamical system and human action scanned data. The quantitative and qualitative evaluation demonstrates the effectiveness of the proposed method.   The main contributions of the paper are the following :   1. A new generative network based on PUP, called GAN - TPU, is proposed. 2. A learning curve based on the PUP learning curve, called TPU - GAN, is investigated and compared with several existing methods, including PUP and PUP+. The results show that TPU+ outperforms the other methods in most scenarios."
SP:67efe60ad37807505369b7852bc0abed29ffdda8,"The paper proposes FP - DETR, a method for training object detection transformers that uses pre - training on the detection domain to prepare the model for the downstream tasks. The authors argue that the traditional object detection methods, such as TD - COCO, only pre - train the encoder - only part of the model, leading to poor robustness and generalization. To counter this, the paper proposes Fully Pre - Trains ( FP - TRains ), a pre - trained object detection transformer that encodes the target object detection task as part of its encoder and finetunes it after training. To this end, the authors propose a task adapter to help the model attend to the target area ( the query embedding ) and recognize the object using the task labels provided by the task encoder. The task adapter consists of two parts : ( 1 ) a ( 2 ) projection projection. The projection projection shows the distance from the target to the origin of the object at which the object was detected and ( 3 ) a dot product showing the distance between the target and the origin object of the input object. ( 4 ) A dot product indicates the distance the model has travelled in the direction of the target since the projection from the object origin to the starting point of the query. This dot product can be visualized with the help of the task adapter ( the projection is the dot product ).    The second contribution of the paper is an extension of the NLP prompt introduced in NLP [ 1 ] to the object detection domain. The idea is to use the positional embeddings provided by NLP as visual prompts to guide the model towards the target ( instead of the text prompt ). This is inspired by the success of textual prompts used in [ 2 ]. The experiments are conducted to demonstrate the effectiveness of the proposed method. The results are presented in Table 1, showing that the method is more robust to common corruptions in terms of robustness than the previous methods ( NLP and NLP ) on small - sized datasets and more robust on larger datasets. The method is evaluated on the task of object detection on COCOCO and compared to state - of - the art methods ( TD - DDPG, TD - GPT-DETR, DPT - R. The comparison is made with respect to the number of corruptions and corruptions as well as the size of the datasets used for training the model ( less corruptions for DDPGs and more for larger datasets )."
SP:a1f9897496303984fc7ad469222106b14b4a6233,"This paper studies the communication complexity of FedAvg, a classical local federated learning algorithm ( also known as Local SGD ), for convex convex optimization with clients running multiple local SGD steps before communicating their update to an orchestrating server. The authors propose FedPAGE, a variant of local FedAvg that uses much fewer communication rounds than previous local local methods for both convex and nonconvex optimization. In the convex setting, the number of communication rounds is O( O( 3 / 4 / 5 / 6 / 7 ), which is comparable to SCAFFOLD ( which uses a factor of NS of the total number of clients ). The communication cost for each round is the same in convex settings and unchanged in the nonconveyx setting. However, in both settings, the communication round length is reduced to a minimum of O( N+S^3 / N+O(N+S ), where N is the average of the communication rounds among all the clients in each round. This is achieved by using the optimal Page method of Li et al. ( 2021 ), in which clients run optimal local steps only on the subset of the dataset that is optimal for the task at hand, and communication rounds are divided between the subset and the server to ensure that the client updates are close to each other. The paper compares this to the previous state - of - the - art local methods ( FedSGD, FedAvg ) and previous best - known result ( FedAvg - SGD, which uses the most communication rounds ) in the conveX setting and the previous two local algorithms ( FedConfusion and FedConv2, which use convex data to update the clients. The main difference between FedSAGEa with and without optimal pageantry is that FedSAGap is based on Page, whereas FedGEa uses the more recent optimal page(2 ), while FedSA has the more communication rounds. In addition, the paper also compares the communication cost between the communicationrounds of FedSA and FedGE with that of the previous best known result of $ O(N + S / O(3 / O)(N/3 / S )$. In the paper shows that in the average communication round in FedSA is smaller, and in FedGE it is similar to that of FedGEA, while in FedCA it is slightly smaller. Finally, it also shows that the communication rate between the two is slightly higher than in FedGA."
SP:81e74765abc6524edd8fdf9a3ba107d7bddaa04b,"This paper proposes a new framework for analyzing the decision boundary geometry of artificial neural networks ( ANNs ) in the presence / absence of adversarial input perturbations. The main contribution of this work is to further our understanding of how and why adversarial perturbation can affect the final output of ANN classifiers. To this end, the most widely used defense against test - time adversarial attacks in ANNs is adversarial training, where one incorporates attacks into the training procedure. This paper quantifies the increase in boundary distance within adversarial subspaces, the redistribution of proximal class labels, and the decrease in boundary curvature when training with adversarial attack. The analysis is conducted in two main steps : ( 1 ) to characterize the geometry of the boundary of a pretrained pretrained ANN in adversarial settings, and ( 2 ) to investigate the effect of training with perturbed inputs on the final outputs of the pretrained network.    The first step is to train the network using adversarial pretrained examples. The pretrained networks are pretrained with two adversarial examples : the first example is used to train a discriminator and the second one is used for testing the network in the absence of pretrained neural networks. During pretrained training, the network outputs are evaluated using the following set of experiments :   1. In the first experiment, the output is compared with the output from a control network trained with no adversarial inputs. The results suggest that the pretraining leads to a more robust network that is more sensitive to the perturbed outputs. 2. The second experiment is used in the second experiment to compare the performance of trained networks trained with and without pretrained adversarial networks, and finds that the robust networks perform comparably to networks trained without pretraining and networks that do not train with pretraining. The experiments are used to inform the design of novel classifier architectures that are robust to perturbed network outputs."
SP:af5c25ecf38c5c3f3387720bdc80c2c54c5699fe,"This paper proposes a weakly - supervised contrastive learning approach that uses clustering to learn representations within the same cluster and dissimilar representations for data from different clusters. The clustering is done via a two - stage process : auxiliary information ( hashtags ) and implied clustering ( data clustering ). The first stage is to cluster data according to its auxiliary information and the second is to learn similar representations within a cluster of similar data from dissimilar clusters.   The authors argue that auxiliary information is useful for clustering as it can be used to hypothesize that an Instagram image will be semantically more similar with the same hashtags than another image with different hashtags. The second stage is the supervised learning that uses downstream labels as supervision signals to predict the performance of the representations learned by the first stage from the auxiliary information. The authors conduct a series of experiments that compare their approach with other baseline representation learning methods that also leverage auxiliary data information and unsupervised constructed clusters. They show that their approach performs the best in most cases, when comparing it with other baselines. They also provide some suggestions for improvement that could lead to better performance when compared with other supervised methods that do not use auxiliary information or auxiliary clustering information."
SP:0a92fcc52970201de4a66b1e76c93dbea9dfd3f1,"This paper proposes PLISA ( Provable Learning - based Iterative Sparse recovery Algorithm ) to learn algorithms automatically from data. The main idea is to learn an iterative recovery algorithm from data that recovers some of the parameters but does not fully exploit the distribution of interest. The algorithm is designed by unrolling a classic path - following algorithm, with some components being more flexible and learnable. The paper theoretically shows the improved recovery accuracy achievable by PLISA with the unrolled algorithm. It also analyzes the empirical Rademacher complexity of PLISA to characterize its generalization ability to solve new problems that arise outside the training set. The techniques proposed in this paper could potentially be applied to analyze other learning - based algorithms in the literature.   The main contributions of this paper are as follows :   ( 1 ) This paper proposes an algorithm, PLISA, to solve the problem of recovering sparse parameters from observational data using an unrolled version of the Path - Following algorithm. Theoretically, the paper shows that the obtained recovery accuracy with PLISA is better than the one obtained with the classic Path - Follow algorithm, and the performance is comparable to that obtained with PLEU. ( 2 ) Theorem 1 shows that PLISA can recover more parameters from the data compared to Path - follow without unrolling the algorithm, which leads to a tighter bound that can explain the observations. Theorem 2 provides the empirical analysis of the relationship between the complexity of the Unrolled PLISA algorithm and the one with unrolled, and shows that under certain assumptions on the hyperparameters ( e.g., $ \theta$ ), the recovered parameters are easier to learn. This gives rise to a generalization that generalizes PLISA better than other unrolled algorithms and generalizes it better to other generalization algorithms in sense that it generalizes beyond the sense that ( sense that $ \eta(t ) = T(t + \epsil_{t+\epsilon + t)$, where $ T \eta$ is the number of parameters and $ T_t \to the dimension of the dataset ( $ t \in \mathbb{T}$ ) is the amount of data that can be recovered ( $ \eps(t)$ ). This generalization generalizes existing generalization techniques ( generically applicable to a broad class of sparse estimation problems, which has received less attention so far, and also generalizes well to problems that are more likely to be encountered in the real world ). The major contributions of the paper are the following : ( a ) The paper contains novel contributions to the area of learning- based algorithms to solve problems where the estimation is sparse ( i.e., the estimation $ t$ is sparse, but the generalization is not general enough to solve this class of"
SP:5064eda9ba27060af15e81b2b317b2e4558b0ac4,"This paper proposes a new approach to learning action trajectories in the discrete - continuous action space from the hybrid action space. The main contribution of this paper lies in two parts. The first part is called Hybrid Action Representation ( HyAR ). It proposes to learn a compact and decodable latent representation for the original action space to replace the discrete action embeddings in the learned representation space of the agent. The second part of HyAR is called the action policy learning procedure. It learns a continuous action policy mapping from the learned action representation to the latent action representation via variational auto - encoder ( VAE ). The idea is to train the agent to be able to distinguish between discrete action and continuous action via action embedding via an embedding table. The authors evaluate HyAR in three environments with discrete action space, discrete action continuum and two environments with continuous action. They compare HyAR with two previous approaches to learn the agent's action policy : continualization and discretization of the action representation. The experiments show that HyAR achieves better performance and generalizes better to environments with higher - dimensional action spaces than the previous approaches. In addition, the experiments demonstrate that the learned latent representation is better than the one used in the continuous action representation and that the agent learns better action policies compared to DRL."
SP:5128bf712f6b197de113c7a371b4bec36f978eca,"This paper proposes SGEM, SGEM : Adaptive Gradient Gradient Descent with Energy and Momentum to solve general nonconvex stochastic optimization problems, based on AEGD. The main idea of the paper is to design a method that incorporates both energy and momentum at the same time so as to inherit their dual advantages. The authors show that SGEM has energy stability property, derive energy dependent convergence rates, and regret bound for convex and convex - exp - convex setting. They also propose a lower threshold for the energy variable that can be used to lower the bound on the momentum bound. Experiments are performed on standard nonconvergex optimization problems ( linear regression, logistic regression, and quadratic regression ) and online convex regression where SGEM is compared to AEGC and AEGDM. The experiments show SGEM converges faster and generalizes better / at least as well as AEGDP in training some neural networks."
SP:11f49b0a975be87769be29e85d7e3924699cf2c9,"This paper proposes a Conditional Masked Language Model with Correction ( CMLMC ) for non - autoregressive machine translation ( NAR ) models to improve NAR model performance on machine translation tasks. NAR models are machine translation models that approximate human - level accuracy on some languages. The paper investigates the possible reasons behind the performance gap between NAR and its machine translation counterparts ( AR ), namely the indistinguishability of tokens, the mismatch between training and inference, and the possible training - inference mismatch between the model parameters and the datasets used to train the model. The authors propose to use a conditional masked language model to train NAR on raw data without distillation ( training with distillation ) and trained on multiple datasets ( using distillation as a pre - training step ) to improve the performance of the model on the raw data and datasets. They show that the Conditional MLMC achieves state - of - the - art performance on the datasets trained on raw and pre - trained on the data ( training + post - training ). They also propose a method to train a model with a masked mask that is used during inference to improve inference performance ( using a mask applied to the masked input tokens ).    The main contributions of this paper are the following : ( 1 ) A new method that uses conditional masked tokens to train two NAR - type models ( one masked and one un - masked ). ( 2 ) A method that trains a masked model to learn the distribution of tokens among the parameters of the masked model and the corresponding to each of the two different encoders ( e.g., the masked tokens used during the training and corresponding to the output tokens of the unsupervised model ), which results in a more robustness ( better robustness ) against the performance degradation caused by the use of masked tokens. ( 3 ) The authors conduct extensive experiments to validate their method and compare their methods with the baseline NAR."
SP:96f8ac3c6163e56d8ae1954a162bae01e6b58a0a,"This paper proposes spiking neural dynamics as an alternative to dilated temporal convolutions for edge processing on always - on devices. The spiking method is inspired by the WaveNet architecture and hence is particularly well suited for a neuromorphic implementation. The proposed method is called WaveSense and it consists of a spiking network with fixed - time - constants, a feed - forward architecture and a simple neural dynamics model. The authors test the capabilities of this model on several datasets for keyword - spotting tasks and obtain near state - of - the - art performance of artificial neural networks such as CNNs and LSTMs.   The main contributions of this paper are the following :   1 ) The authors propose spiking methods for time - varying neural dynamics. This is a natural alternative to the dilated time - processing method as it is computationally expensive and time - dependent. 2 ) The neural dynamics used in WaveSense are parametrized as a weighted sum of the time - derivative parameters of the input variable $ \mathbb{R}$ and the output variable \Delta_t$. 3 ) The network is parameterized as a neural network with a fixed time - constant $ \Delta(T)$ where $ T$ is the number of input variables and $ T \to - time \in $ is the time derivative of the variable used to parameterize the spiking parameter $ T$.   4 ) WaveSense is trained using supervised learning and fine - tuning, and achieves near - optimal performance in terms of accuracy with respect to $ \theta$ on the datasets."
SP:7f20a2e4e95f857140b87b0730360b3ff2f371f4,"This paper studies the problem of fairness in social networks training based on machine learning with respect to demographic shift, a phenomenon that occurs when certain subgroups of the population become more or less probable in deployment ( a phenomenon termed demographic shift ), making prior work ’s fairness assurances invalid. The paper proposes Shifty algorithms, which are algorithms that provide high - confidence behavioral guarantees that hold under demographic shift. Under the assumption that the data used for training is representative of what will be encountered in deployment, which is often untrue, the paper proposes to design algorithms, called Shifty, that provide a guarantee that the learned models avoid bias under the phenomenon, unlike existing algorithms that do not. The proposed algorithm Shifty is evaluated using a real - world dataset of university entrance exams of the student, and compared with two existing algorithms, one based on human bias and another based on self - supervision. Results show that Shifty outperforms the other algorithms in terms of accuracy when applied to the majority of the time, except in the rare cases where there is a significant bias towards a particular subgroup ( e.g., when the student prefers a particular teacher over another ). Further, experiments demonstrate that the Shifty algorithm is an effective tool for training models that are fair when demographic shift occurs, and that our algorithm is able to overcome the demographic shift challenges with Shifty."
SP:94f097921bee5fdc10ec2e7c901b2ddb876d9d41,"This paper proposes Neural Stochastic Dual Dynamic Programming ( NSDDP ), a method to extend the standard stochastic dual dynamic programming ( SDDP ) method for solving synthetic and real - world process optimization problems, by using a neural network to learn a piece - wise linear value function within the intrinsic low - dimension space that can interact with a base SDDP solver to solve successive instances of the problem. The neural network consists of a layer - wise neural network module ( layer 2 ) and a linear layer ( layer 3 ), which is used to map the input instances into a piecewise linear function of value function ( layer 4 ). The linear layer is connected to the neural network via an external memory network ( layer 5 ) and the output instances to the input value function via a memory vector ( layer 6 ).   The network is trained from scratch using gradient descent, gradient clipping, and a reparameterization trick. During training, the model is updated with a fixed number of updates, and the parameters of the model are updated as new problems are introduced. Experiments are carried out to evaluate the effectiveness of the proposed method and to compare it to other SDP methods ( SDP, SDP++, and SDP+DP ) on a range of synthetic as well as real world problems. The results show that the proposed approach is able to reduce the problem solving cost without sacrificing solution quality over competitors, and that it is more robust to the number of decision variables."
SP:3d9f5132f9ec3807dbca78462a459fd123a09b24,"This paper proposes a new protocol for private next - token prediction, called sub - mutli - token ( PMPM ), for language models trained on a private corpus to protect privacy of the language model's training data. PM is developed in light of recent data - extraction attacks that have shown that language models can memorize some training samples verbatim, leading to privacy violations when the training data is released to the public. The authors propose to use a relaxation of group differentially private prediction in order to prevent the leakage of information unique to each individual user in the private corpus. They show that the proposed PM, called SUBMIX, is the first protocol that maintains privacy even when publicly releasing tens of thousands of next token predictions made by large transformer - based models such as GPT-2. They also provide a data - dependent privacy accounting mechanism, which allows it to thwart existing data - Extraction attacks.   The main contributions of this paper are the following : 1 ) The introduction of PM - GPT2 - based language models and their relaxation of the group - private prediction relaxation to ensure privacy of all users. 2 ) The use of the relaxation relaxation mechanism to ensure that only private predictions that are unique to the group members ( those that do not appear in the public corpus ) are available to the general public. 3 ) The formulation of the sub - PM protocol to prevent privacy violations of language models that fine - tune on a public corpus after pre - training on the private one."
SP:7f524d186ea939309c7eeb843c62b6a4b4cfbc8a,"This paper proposes a k - N density estimator to detect OOD samples with respect to a classification model ’s intermediate activations on indistribution samples. The proposed estimator is motivated by a recent insight about label smoothing, which the authors call the Label Smoothed Embedding Hypothesis. The authors argue that one of the implications is that the OOD detection method performs better as a detection method both theoretically and empirically when the model is trained with label smoothed training. They leverage the recent insight to show that the k - nanet density estimate outperforms many OOD baselines and provide new finite - sample high - probability statistical results.   The authors first provide a description of the problem of detecting out - of - distribution ( OOD ) examples. Then, they explain how the detection is affected by the distribution of the samples. This explains why it is important to train a model to discriminate between OOD and other samples. Next, the authors propose an estimator based on the Gaussian Mixture Model ( GMM ), which is a weighted sum of a number of distributions. This estimator can be used to estimate the k-NN density of the distribution where k is the number of samples and N is the estimated number of classes from the model. The method is then used to train the classifier. The model takes as input the distribution over the parameters of the GMM and outputs the class labels. The class labels are the average of the first and second - order classifications of the MDPs. The first class is trained to distinguish the samples from the ones that do not have labels. Second, the classifications are made using the third - order model. Finally, the samples are separated into the remaining and the null classes. The null samples do not appear to have any significant differences between the samples that the model trained to classify."
SP:aafbd6ada14cc59a272fe4bf95fac71fa18e57ab,"This paper proposes a novel approach to training non - adversarial generative models based on denoising autoencoders. In contrast to VAEs and GANs, which learn representations by directly transforming latent codes to data samples, the proposed approach introduced diffusion - based representation learning ( DR - DK ) encodes the information needed for denoised score matching objective using a new formulation of the objective. Authors argue that this allows for manual control of the level of details encoded in the representation that can be learned without any supervised learning. They demonstrate the effect of their approach on state - of - the - art DDPG and latent code learning by training a model based on a DPP ( Denoising Automated Post - Gradient Descent - based Representation Learning - based Learning ), which is similar to DR and VAE. Authors also propose to learn an infinite - dimensional latent code which achieves improvements of state-of -the - art models on semi - supervised - image classification.   The main contribution of this paper is to propose a novel method to learn a representation learning model without any adversarial training in the manner of GAN / VAE and DPP. The approach is similar in spirit to the approach of [ 1 ] and [ 2 ], but differs in that it uses a latent representation learning method instead of a latent code transformation method ( which is the latter method's main contribution ). The authors argue that the difference in terms of performance is due to the fact that in DR DK learns a representation representing the latent codes of interest only, while in VAE / GANET it encodes latent codes representing all relevant information, and thus has access to all the relevant information. This allows for more granularity in the information encoded in representation learning. Authors demonstrate the performance of their method on MNIST, Fashion - MNIST and CIFAR-10 on the DPP and MNIST datasets."
SP:8cfc837d5c10d539bbd098df7134c42e4830ba25,"This paper proposes Classifier - Planning ( C - Planning ), an algorithm for goal - conditioned reinforcement learning ( RL ) that uses planning at training time to automatically generate a curriculum of intermediate states to learn a policy to maximize the expected return when applying the goal - conditioned policies. The method is based on two steps : the E - step corresponds to planning a sequence of waypoints using graph planning while the M - step learns a goal -conditioned policy to reach those waypoints. The paper compares with two prior methods ( Goal - Conditioned Graph Search ( G - SP ) and Goal - Policy SGD ( P - SGD ) ) that use a graph - based method to search for the waypoints that correspond to the goals that the authors ( and others ) have previously used to learn the policies to reach. The main contributions of the paper are the planning - based approach and the fact that it uses planning during training and not during testing ( unlike the previous methods which used graph planning during testing ). The methods are evaluated on a variety of tasks including navigation, manipulation, and policy navigation tasks that prior methods based on graph search fail to solve or a set of goal - conditionaled policies based on offline data and expert demonstrations fail to learn. On the navigation tasks, the method is shown to be more sample efficient than prior methods and on the policy navigation task it is able to solve very long horizons ( up to 30 ms ) compared to the methods that use expert demonstrations and policy gradient descent. It is also shown that the learning of the policy using planning is as good as that of the trained policy using graph search and is more efficient than the learning using the policy gradient method."
SP:ef3193842e06d4a6edb8a6a86ea5bc97ee5eaa4a,"This paper proposes a new mixup method, k - mixup, to improve generalization and robustness of deep neural networks with mixup regularization. The main idea is to perturb the training data in the direction of other randomly - chosen instances in the training set, i.e. k - samples, to leverage the structure of the data. This is done using displacement interpolation under the Wasserstein metric to leverage k - points. The authors argue that traditional mixup suffers from poor regularization when distributions are clustered or supported on an embedded manifold. With larger α, the procedure can result in averaged training points with incorrect labels in other clusters or in locations that stray far from the data manifold. To address these issues, k- mixup averages random pairs of sets of k samples from the training dataset, where k is assumed to be a constant number. The average k- samples are viewed as discrete distributions and are averaged as distributions in a geometric sense, such that if k = 1, the process recovers standard mixup with standard regularization ; otherwise, it perturbs training datasets that better match the global cluster or manifold structure of   the original training dataset. The paper theoretically and in simulations, the authors demonstrate theoretically that k - mixesup preserves cluster and manifold structures, and extend theory studying the efficacy of mixup using 4 - mixups and standard mixups to the k -mixup case, and empirically shows that k-mixup further improves generalization of neural network architectures with improved robustness and generalization accuracy. The empirical results are shown on three synthetic datasets. The experiments are performed with 1 - mix - ups, 4 - mixesups, and 32 - mixes ups, where the authors compare the performance of all three methods. The experimental results are presented in Table 2, and the authors discuss the benefits of each mixup option."
SP:0fe6a9848026e5f6436a380199e27a9ad26cffed,"This paper proposes a nonlinear kernelized classification layer for embedding learning in deep neural networks ( DNN ). The motivation is that conventional DNNs almost universally use a linear classifier on the learned embedding vectors, which is suboptimal for a network with a limited - capacity backbone since better nonlinear classifiers could exist in the same embedding vector space. To tackle this problem, the proposed nonlinear classification layer optimizes over all possible radial kernel functions on the space of embeddings to learn an optimal classifier, which could be applied to learn more model - efficient classifiers. The paper shows that this kernelized layer is effective in learning more model-efficient classifiers in a number of computer vision and natural language processing tasks. The experiments are conducted on image classification and text classification tasks using ResNet-50 and Transformer-50 DNN architectures.    The main contributions of this paper are the following :   1. The authors propose a non - linear classification layer to learn classifiers on the embedding space of a DNN. The idea is that if the classifier is a linear function over the vector space $ \mathcal{L}$ of embedding embedding values, then it should be able to learn nonlinear functions over the possible radial functions of the classifiers defined in this space. The proposed layer, called Kernelized Classifier Ensembles Layer ( KLE ), optimizes all possible kernels ( $ L$ ) defined in the space represented by this vector space by the corresponding to the corresponding embedding value. This means that the KL(L_\mathcal_L_{KL } \to L_\theta ) for a given embedding $ \theta$, has a maximum value of $ \sqrt{L_KL}$. The authors show that KLE has maximum value $ L_L$ and minimum value $ \Delta_L$.   2. The experiment results are applied to classification tasks on CIFAR-10 and MS-WordNet and show that the proposed KLE is effective at learning classifiers for both tasks."
SP:01ee8ec81619784788eb0ce9785098e437d17a7c,"Graph Neural Networks ( GNNs ) are a popular statistical graph representation learning ( PDE ) tool. This paper theoretically analyzes the source of bias in the representation obtained from node representations obtained from GNN. Specifically, the paper analyzes both the nodal features and graph structure of the GNN to identify the sources of bias. Based on the analysis, two new methods are proposed to enhance the fairness of GNN - based learning mechanisms : ( 1 ) Data augmentation on the features of the nodes based on the obtained GNN representations ; and ( 2 ) Graph contrastive learning ( GCE ) on the generated representations. The proposed methods are theoretically motivated to ensure that the proposed augmentation strategies improve the fairness in terms of the terms of statistical parity and equal opportunity, while providing comparable utility to real networks. Experiments are conducted on node classification, link prediction, and link classification with real networks to evaluate the effectiveness of the proposed methods.    The main contributions of this paper are the following :   - A theoretical analysis of the bias of the node representation learning method using graph neural networks. Theorem 1 and 2 provide the theoretical explanation for the bias. - Theorem 3 and 4 provide the empirical analysis on the degree to which the proposed data augmentation techniques improve the node representations. - Empirical experiments are conducted to evaluate how the proposed approaches compare to the real networks when comparing the performance of the learned methods with respect to each other and multiple benchmarks. The results show that the methods do not significantly improve the accuracy of the obtained from the real network compared to the trained methods."
SP:7739dc9e37f7f1384f87d2e60281e5bb27fece99,"This paper considers the problem of estimating treatment effects from observational data in the presence of confounders. The prevalent way to address this challenge is to utilize an instrumental variable ( IV ) for two - stage regression, i.e. 2SLS and variants, but they need to assume additive separability of noise and are limited to the linear setting. In this paper, the authors propose a Confounder - Balanced IV Regression ( CB - IV ) algorithm to jointly remove the bias from the bias induced by the bias of unmeasured confounder with IV regression and outcome regression, in order to achieve better treatment effect estimation. The algorithm consists of three main modules : ( 1 ) treatment regression : regressing the treatment with IVs and confounds like previous nonlinear IV methods for removing the confounding bias from unbalanced confoundering ; ( 2 ) outcome regression : learning a balanced representation of confounds to eliminate the bias inducing by the observed bias in the second stage ; ( 3 ) bias - reduced treatment - effect trade - off using the proposed CB -IV algorithm. Experiments demonstrate that the proposed algorithm outperforms the state - of - the - art methods, including IV regression ( using the multiplicative assumption ) and confounding - with - bias ( using a weighted average of the predicted and observed variables ), as well as treatment effect estimators, using the two previous modules. In particular, the experiments demonstrate that CB - using the recently proposed outcome regression module outperformed the previous non - treatment regression methods using the assumptions of noise separability and additive separation, and that the new algorithm uses the same representation as the previous two methods. The authors also provide theoretical justification for the superiority of their algorithm over the other two methods, and provide theoretical guarantees to support their algorithm.   To summarize, the main contributions of this paper are as follows :   1 ) The authors introduce a new method to jointly estimate the treatment effect between the predicted treatment and the outcome using the predicted variables and the imbalance between the two variables. This method is referred to as CB - II and it is similar to the approach proposed in ( Yu et al., 2019 ), but it differs in that it uses the learned ( balanced ) estimate of the imbalance instead of the estimated treatment effect. Theoretical justification for this change is given in the paper ( Section 3.1 ). 2 ) The second contribution of the paper is the use of the balanced estimate to improve the accuracy of treatment effect"
SP:fdb68c39fce254b73310a3101b2fe97ba47e69fe,"The authors study the adaptability of model - agnostic meta - learning ( MAML ) in the linear regression setting, consisting of a mixture of easy and hard tasks. In particular, the authors consider a setting where the hardness of the tasks is proportional to the rate at which gradient descent converges on the task. They show that in order to achieve substantial gain over standard non - adaptive learning ( NAL ), ( i ) there must be some discrepancy in the hardness among the tasks, ( ii ) the optimal solutions of the hard tasks must be closely packed with the tasks from the easy tasks, and ( iii ) the solution of the easy task should be closer to the one found in the task with the most discrepancy in hardness. The authors also provide numerical and analytical results suggesting that these insights apply to two - layer neural networks. Finally, they provide few - shot image classification experiments that support their insights for supporting their insights.    The authors conclude their work with the following observations :   1 ) It is well - known that NAL is more adaptable to different tasks and easier to adapt the model to new tasks via one or few stochastic gradient descent steps 2 ) The adaptability / hardness tradeoff between NAL on easy tasks ( where the gradient descent step rate is close to the task's rate of convergence ) is studied in this setting, but it is not well - studied for hard tasks where the gradients do not converge as quickly. 3 ) The authors emphasize the importance of training a model to learn well on hard tasks in practice and provide numerical results that suggest that a model trained on hard task gradients learns better than one trained with NAL."
SP:e8143c7880c16ee9ce7a544e0fd80f001b1b4f9f,"This paper proposes a new algorithm, LPALM, for unrolling sparse BSS based on PALM hyperparameters and variables. The main idea is to leverage the data driven knowledge from realistic simulations or ground truth data by learning both the parameters of PALM and the variables associated with it. To do this, the paper proposes to learn the learned parameters and variables by unrolling the training and testing phases of the algorithm.   The main contributions of the paper are the following :   1. The authors propose a new unrolled method based on the Proximal Alternating Linearized Minimization ( PALM ) algorithm. This method assumes a fixed known linearized parametrization of the ground truth variables ( $ \mathbb{R}^2 $ ), which is different from most existing unrolled algorithms. The choice of hyperparameter $ \theta$ is carefully considered, and the authors propose to learn $ \tilde{PALM}$ instead of $ \eta$, as is the case with standard unrolled methods. This allows the algorithm to be trained in a semi - blind setting, where there are fewer iterations and fewer parameters to learn. The paper performs extensive experiments to compare the performance of the proposed method with other unrolled BSS methods, and shows that it outperforms them both in terms of accuracy and source separation ( the latter of which is controlled by the number of iterations and parameters of the unrolled algorithm ). The method is applied to two real - world astrophysics problems, in which it is shown to perform better than other methods and to perform comparably to ground truth methods in the remote sensing problem. The results demonstrate the benefits of the choice of learning the parameters and learning the variables, as well as the advantages of the method for the semi blind setting."
SP:7716315001949ab88c8a216302fe51bae872fc87,"This paper proposes a new model architecture for language modeling based on implicit self - attention using transformers and a Legendre Memory Unit based model. The architecture is based on the Legendre Neural Machine ( LPM ), a transformer - based model that models the relationship between the neural network parameters of a language model and the weights of a sequence of sentences. The authors show that the LPM model exhibits O(n^2 ) ( or better ) dependency for memory and computation for sequences up to length 1, 2, and 3. They also show that for the same amount of training the model improves the loss over transformers about as much as transformers improve over LSTMs. This is demonstrated by comparing the performance of the proposed model on the task of language modeling with language transformers that have a power - law relationship with model size up to 6 orders of magnitude. The proposed model does not exhibit the same robustness to the magnitude of the power that transformers exhibit when the size of the model is increased beyond 6 orders. The main contributions of the paper are the following :    1 ) The authors propose a new attention module for the language modeling task, the Implicit Self - Attention Module ( Siamu ). This module modifies the self attention of the transformers to encode information about the model's internal state. This information is then used to update the model parameters such that the model produces representations that are more robust to changes in the input ( e.g., the number of tokens in a sequence. ) 2 ) The motivation for developing the module is that prior work on self - attentions has shown that the module improves the performance over LPM models that only encode the internal states of the language model, but not the external states. 3 ) This motivates the design choices of the module.   The authors then propose to train the model using a combination of supervised learning and self - supervised learning, where the supervised learning phase is supervised by a teacher and the teacher trains the model via self - supervision, and the student model is trained using self - training to produce representations of the input that are fed back to the teacher. The teacher and student model are trained in a similar way so that the former can be used for inference and the latter for modelling the outputs of the latter. The experiments compare the proposed module to transformers, language models, LPMs, and Legendre models. The results demonstrate that the proposed method sometimes outperforms transformers while sometimes lagging lSTMs in terms of performance."
SP:832f422b3554e89702e13c8c5690ee26f2289e3b,"The paper proposes a new GAN framework LatentKeypointGAN, a two - stage GAN based on end - to - end image generation using keypoint embeddings. The key points used in the keypoint generation are obtained by re - positioning key points obtained from previous generations of GANs. The authors show that the keypoints control the position and style of the generated objects and their parts, and the appearance of keypoints is controlled by an encoder that generates a latent space representation of the key points. The encoder is trained to generate the latent space representations for each keypoint by conditioning on a set of space keypoints. The paper shows that the encoder generates latent representations for keypoints that correspond to the positions and appearance of objects and parts of the images. The obtained latent representations can be used to control the re - archiving of images by combining keypoints from different epochs of the same GAN epochs.    The paper contains the following contributions :   ( 1 ) A new method for generating keypoints based on GAN - based method for unsupervised keypoint detection. This method allows the author to generate keypoints for each epoch of the training using only the first stage of the GAN without any supervision from the domain. The method is called Latent keypointGAN and it is similar in spirit to the original GAN ( Xie et al., 2021 ). However, it differs in that it uses the embedding of key points in the latent representation instead of the dot product embedding used in Xie ( which is a weighted sum of two keypoints ). This allows for generating images with different keypoints in each epoch. The author uses the same embedding for the first and second stage of Latent KeypointGAN but different for the second stage. The major advantage of this method is that it does not require the domain knowledge of the authors for the appearance embedding. This avoids the need of disentangling the image into spatial and appearance factors which may have been difficult to handle by hand - crafted embedding by the authors. ( 2 ) The authors demonstrate that the generated keypoints provide an interpretable latent space that is easy to work with for the generated images. This is demonstrated by using the method to generate three different types of images ( self - likenesses from the same keypoint and three different keypoint pairs ). The experiments demonstrate the effectiveness of the method on the self likenesses generated using the Latent"
SP:9206ae6e31077569313838504ef6daa89ad3b59c,"This paper studies neural networks with layer normalization using the mean field formalism and carry out a non -perturbative analysis of signal propagation. It shows that increasing the depth of the neural network can lead to gradient explosion or representation shrinkage. The authors claim that the appearance of at least one of these problems is not restricted to a specific initialization scheme or a choice of activation function, but rather is an inherent property of the fully - connected architecture itself. They also show that many popular normalization techniques fail to mitigate these problems and that a generic initialization method can be applied to residual networks to guide the choice of initialization variances.   The authors first consider two types of neural networks, one with fully connected components ( i.e., linear and non - linear layers ) and another with components that are connected via auxiliary connections ( e.g., non - fully connected cells ). They define the difference between the two classes of networks as follows :   1. The fully connected network has all the components. 2. The auxiliary connections are only connected when the network is fully connected. 3. The network that is not fully connected is not connected and can not be distinguished from another network by the auxiliary connections. 4. The networks that are fully connected but have auxiliary connections but not connected are not connected by any regularization rules. 5. For each additional connection, the authors define a new normalization rule and apply it to the auxiliary networks. They compare the performance of their method with other normalization methods they use and find that their method performs marginally better than other methods when it comes to stopping the propagation of new connections."
SP:2177be818b5843c580c787f1b2d725154846feb6,"This paper proposes a new line search approach for Deep Learning ( DL ) based on the observation that the full - batch loss behaves locally parabolically in the direction of noisy update step directions, and the trend of the optimal update step size changes slowly. To exploit this observation, the authors propose a line - search method that approximates the full batch loss with a parabola estimated over several mini - batch estimators derived from the learning rate of a stochastic gradient descent model. The authors evaluate the proposed method on three deep learning datasets ( CIFAR-10, ResNet-21, and Tiny - ImageNet ), and compare it to two line search approaches ( line search and line search with a discounting step - size estimator ) and two gradient - based approaches ( gradient ascent and gradient descent ). Results show that the method outperforms the other two methods in most settings, with the exception of line search being slightly worse than the baseline. The paper also presents results that suggest the optimal step size for line search could be smaller than the one used in line search for DL.   The main contributions of the paper are the following :   1 ) The paper proposes an approach to estimate the step size of the gradient update step in order to find optimal step sizes for the loss estimator in DL. The idea is to approximate the loss using the update step estimator from the training data, and then use the estimated step size when computing the gradient step in the estimator to find the optimal line search step size. This approach is a reasonable alternative to line search as line search is computations computations are computations that are computationally expensive and noisy estimations are difficult to compute. 2 ) The method is evaluated on four datasets and two deep learning tasks, and it is compared with two other line search methods on two of them. On the datasets, it is shown that the approach outperforms both the baseline and gradient ascent more often than the other methods, especially when the datasets are smaller and when the estimation step size is smaller."
SP:62233782f9046c85617d9ccfe8427eae7d1c9da7,"This paper studies the problem of noise distribution choice in training unnormalized probabilistic neural networks. It is well known that the noise distribution used for training neural networks is crucial for their performance. However, this paper makes the observation formal and quantitative, stating that :   “ It is not clear whether the difficulties arising from a poorly chosen noise distribution are statistical or algorithmic in nature. In fact, it is not even clear whether it is clear whether... ” This paper introduces a variant of NCE called eNCE ( e - CNCE ) which uses an exponential loss and a normalized gradient descent to address the landscape issues provably when the target and noise distributions are in a given exponential family. The authors prove that there are challenges in training NCE when an inappropriate noise distribution is used. Namely, they prove these challenges arise due to an ill - behaved ( more precisely, flat ) loss landscape that is present in the standard exponential loss. To address this, the authors introduce e-CNCE, which uses a normalized family distribution and a soft exponential loss instead of the flat one used in e-NCE. The benefits of this is that it is easier to identify when the model performs poorly when the distribution is chosen poorly, as it is harder to distinguish between models that perform well with and poor models that have access to the optimal distribution.    The paper is well written and well structured, covering all aspects of the problem. The major contribution is the introduction of the idea of using the exponential loss as a regularizer to train neural networks and the use of the normalized gradient to select the distribution to train the network. This is a novel approach to the problem that has been around for a while, and it is interesting to see this formalized and made quantitative. The paper also includes a nice analysis of the differences between the performance of models trained with and those trained with exponential loss with and without normalized gradient. The experiments are interesting and convincing."
SP:ceba6c1421b2d03863007fdaf029b8b946519c1b,"This paper studies the convergence of distributed SGD ( SGD ) with Byzantine resilience ( BR ) and PPD ( Privacy and Byzantine resilience ). The authors first observe that the integration of standard practices in DP and BR is not straightforward and empirically show that standard approaches might be fruitless, but carefully re - tuning the learning algorithm can obtain reasonable learning accuracy while simultaneously guaranteeing DP & BR. They then show that results obtained under Byzantine faults are rendered invalid when honest workers enforce DP. To circumvent this shortcoming, they revisit the theory of ( reparametrization ) of the original SGD to obtain an approximate convergence guarantee for BR and DP. The paper provides key insights on how to improve this guarantee through hyperparameter optimization.   The main contribution of this paper is to study the extent to which the SGD algorithm, in the standard parameter - server architecture, can learn an accurate model despite ( a ) a fraction of the workers being malicious ( byzantine ) and ( b ) the other fraction, whilst being honest, providing noisy information to the server to ensure differential privacy ( DP ). Their empirical results show that the combination of standard approaches to SGD and BR can be reasonably accurate, but only if carefully ( and only if ) the learning accuracy is sufficiently improved. The main contributions of the paper are the following :   1. They show that existing results under Byzantine fault assumption are invalid when using SGD with BR under DP. 2. They carefully show that by carefully ( carefully ) re -tuning the learning algorithms, by minimizing the difference between the learning loss when using BR and SGD when using DP, a reasonable convergence guarantee can be obtained."
SP:bc783f0c829f90931535e63687d13172879631b3,"This paper considers the problem of source code editing, where query code snippets generated from source code snippets are query snippets and editing exemplars are generated from the snippets themselves. The paper proposes a method to learn an autoencoder to generate edit representations from query exemplars and exemplars that are similar enough to be used during query code editing via a similarity - ranking error estimator ( RED ). The method is based on the multi - extended similarities ensemble ( MEEnsemble ), where nodes in the abstract syntax tree represented by tree representations from individual tree members are sampled to create a collective tree representation for query and support sample matching, and ensemble the matching results. The authors evaluate the proposed method on C## and Python, and show up to 8.6% absolute accuracy improvements compared to the baselines ( without learning ).   The main contributions of this paper are as follows :   1 ) The authors propose a novel deep learning approach to solve the code editing problem automatically using machine learning and deep learning techniques. The proposed learning approach combines edit representations extracted from support exemplar and compositionally generalised query exemplar representations to generalize them to the query code snippet editing via multi - extendsent similarities ensemble. 2 ) It proposes an algorithm for generating edit representations for query snippets from text snippets generated using language - specific grammar into abstract syntax trees. 3 ) It applies the similarities measurement in multiple extents from individual nodes to collective tree representations to obtain matching results of query and sample corresponding to the corresponding tree representations. 4 ) It compares the results of the ensemble and the corresponding representation extracted from the ensemble using similarity measurement in individual nodes and ensemble to the matching representation in the query samples."
SP:ca0c4bdb02f7d939fb6de38b6b446ced4b5984a0,"This paper proposes a generative model for generating sequence data from text or music based on constraints imposed on subcomponents of an example. The constraints are placed in the form of relational constraints between sub components of the example ( e.g., lines of a poem or measures of music ). The model consists of two parts : ( i ) a model to generate a realistic set of constraints from the relational constraints and ( ii ) a second model to produce data satisfying these constraints. For the first part, the authors propose a program synthesis algorithm that infers relational constraints present in the training data, and then learns a model based on the resulting constraint data.    The main contribution of this paper is the following :   1. The authors propose an approach to constraint - based generative models to generate sequence data. The relational constraints used in the first step are the same as those used for generating the data ( i.e., the set of lines from a poem, measure of music measure, and set of measures of the music measure ). 2. A generative algorithm is proposed to learn a set of generative sequences from the constraints and generate data satisfying the generated sequences. The method is evaluated on three datasets ( music, text, and images ) and compared with two baselines. The results show that the proposed approach significantly improves over baselines that do not incorporate relational constraints. The main concern is that the method does not incorporate high - level structure to guide the generative process, and many such models perform well on local coherence, but less so on global coherence. To alleviate this issue, the method introduces a regularizer that takes into account both the local and global structure of the data. This regularizer can be trained to perform comparably well with respect to the comparably or better in terms of low-level structure, and it can also train the regularizer more flexibly for the high level structure. The effectiveness of the proposed regularizer is evaluated by comparing its performance on data generated from the baselines generated using relational constraints with that of a baseline that does not have them. In the experiments, the model achieves better performance than baselines and worse performance than the baseline."
SP:692ae0c583a1585eff1a7d9c0d3b51b7879611cc,"This paper studies set - to - hypergraph ( STH ) prediction, where the goal is to infer relations for a given set of entities from hypergraph representations. This is a common abstraction for applications in particle physics, biological systems and combinatorial optimization. The paper proposes to address two scaling problems encountered in STH : ( 1 ) the exponentially growing number of hyperedges and the run - time complexity, both leading to higher memory requirements ; ( 2 ) the asymptotic memory scaling from exponential to linear. The first contribution is a training method that encourages iterative refinement of the predicted hypergraphs, which allows us to skip iterations in the backward pass for improved efficiency and constant memory usage. The second contribution is to combine both contributions in a single set -to - set - Hypergraph model that enables us to address problems with larger input set sizes. The authors provide ablations for their main technical contributions and show that their model outperforms prior state - of - the - art models, especially for larger sets."
SP:e3481fb6d8d1aa45d6ed4a454e781f5a2c30c57e,"This paper proposes a new post - processing bias mitigation method, called Ethical Module ( PM ), to mitigate the bias of pre - trained deep learning models that discriminate some subgroups of the population. It consists in learning a shallow neural network, called the Ethical module, which transforms the deep embeddings of a pre -trained model to give more representation power to the discriminated subgroups. The training is supervised by the von Mises - Fisher loss, whose hyperparameters allow to control the space allocated to each subgroup in the latent space of the model. Besides being very simple, the resulting methodology is more stable and faster than most current methods of bias mitigation that are currently used. The authors conduct extensive numerical experiments on standard datasets to validate the effectiveness of their method."
SP:3fb5dcc8b8fb731e09c14b16480cada1c7ccfaa7,"This paper studies the problem of learning new classes in class - incremental learning ( CIL ) by distilling old class knowledge from the previous phase model. The authors propose a simple method to compute the KD loss using the placebo data from a free image stream ( e.g., Google Images ), which is both simple and surprisingly effective even when there is no class overlap between the placebos and the old class data. To evaluate the image quality, the authors propose to use an evaluation function to quickly judge the quality of candidate images ( good or bad placebos ) from the image stream. The evaluation function is used to design a pseudo CIL task from the data in the 0 - th phase and design a reinforcement learning algorithm, which can significantly improve a number of top - performing CIL methods, in particular, ImageNet - 1k and ImageNet-Subset.   The main contributions of the paper are the following :   1 ) This paper proposes a simple and easy - to - use way to compute a KD loss for calculating the new class KL loss for each successive phase of CIL based on the image of the target class from the first image in each phase. 2 ) The authors empirically observe that this method outperforms existing methods that use new class data ( KD loss ) and that distil old class information ( KD distillation ) from previous phase data. 3 ) The experiments verify that the proposed method does not require any additional supervision, memory budget, or additional supervision \epsilon in the case of the proposed evaluation function. 4 ) The paper is well - written and well - structured, and the experimental results are convincing."
SP:506e0a888c03a955b708464eed3670c04baf4912,"This paper proposes a novel algorithm for the inference of energy - based models ( EBM ) based on local sampling from the Markov chain Monte Carlo ( MCMC ). MCMC with the informed proposal is a powerful tool for sampling from discrete structures but it requires evaluating all energy changes in the neighborhood. This paper proposes an auxiliary algorithm that only queries the evaluation of energy function twice for each proposal via linearization of the energy function. The main contribution is a composition of local moves that can be used to efficiently explore large neighborhoods. The authors also give a fast version of their algorithm. Empirically, they show that their path auxiliary algorithms considerably outperform other generic samplers on various discrete models for sampling, inference, and learning.   The main contributions of this paper are the following :   1 ) The authors propose an efficient algorithm for sampling the energy distribution from MCMC using local sampling. This is different from the MCMC method since an informed proposal can only allow local updates. 2 ) A fast algorithm is also proposed that can evaluate the proposed energy functions in each proposal twice. 3 ) The method is compared with MCMC based on an alternate set of local sampling and linearized energy functions."
SP:4b466277aa5561a80c48d5e72559de4ce95f228b,"This paper proposes Variational Predictive Routing ( VPR ), a hierarchical hierarchical generative model for deep reinforcement learning. The model is based on a neural network with a latent representation of latent representations of video features arranged in a hierarchical hierarchy. The authors show that VPR is able to dynamically adjust its internal state following changes in the observed features, thus promoting an optimal organisation of representations across the levels of the model ’s latent hierarchy. Event detection is performed using a neural probabilistic inference system that organizes latent representations in a temporal hierarchy, based on their rates of change, and is used to model continuous data as a hierarchical renewal process. Experiments are conducted on two synthetic datasets ( CIFAR-10, Tiny Imagenet ) and three older, higher - resolution sequential videos. VPR outperforms competing models in terms of robustness to perturbations in the temporal structure of the features, as well as fidelity to the underlying hierarchical structure.   The main contributions of the paper are the following :   ( 1 ) A novel event detection mechanism that relies solely on the model's latent representations ( without the need of a separate model ), and ( 2 ) A model - based reinforcement learning framework that incorporates insights from neuroscience and integrates state - of - the - art learning techniques."
SP:459ef2e6bd7638020955dbb4d8ae1098619f7b95,"This paper proposes a new image extraction method, UGALR ( Unifying Global and Attention - based Local Features Retrieval method ), which is an end - to - end and single - stage pipeline approach for extracting local features from global and attention - based datasets. The idea is to search images similar to the given query image by extracting features, then re - rank the images based on global and local features. The re - ranking process of global features is then followed by local feature matching, which has several drawbacks : ( 1 ) it takes up too much time and space ; ( 2 ) the global features are not semantic and accurate ; ( 3 ) the re -ranking process weakens the influence of the local features ; ( 4 ) the learning of local features with attention is trivial because of the trivial design of the extraction pipeline.   The main contribution of this paper is to propose a method that combines the advantages of both of the above mentioned drawbacks and the importance of semantic local features in extracting images. The method is described in detail in the paper, and experiments are conducted on ImageNet and CIFAR-10 datasets to validate the effectiveness of the method. The experiments show that it outperforms other image extraction methods in terms of extraction speed, learning speed, and semantic accuracy. The main contributions of the paper are the following :   1 ) It proposes an efficient way to extract local features by combining global features and attention using the attention mechanism ; 2 ) it learns more accurate and semantic local information through combining spatial and channel attention with the aid of intermediate supervision ; 3 ) It learns more global features that are informative and semantic about the dataset using the learning process ; 4 ) It uses attention to learn more local feature information that is informative but semantic."
SP:487cc308a1e8ee078c54b2158bcae47e920e73f8,"This paper proposes a new method, RotoGrad, to tackle the problem of negative transfer, which refers to the disparities in gradient magnitudes and directions across tasks when optimizing the shared network parameters in multi - label classification tasks in CelebA and computer vision tasks in the NYUv2 dataset. The authors claim that the existing approaches to tackle negative transfer fall short in two ways : ( 1 ) homogenizing the gradient magnitude across tasks or ( 2 ) greedily changing the gradient directions. In this work, the authors propose a homogenization approach that jointly homogenizes gradient magnitude and directions, while ensuring training convergence. The main contributions of the paper are as follows : - The authors propose an algorithm that, based on the recently proposed Gumbel - Softmax - Gradient ( G - G ) method, jointly homogeneously generates gradient parameters ( parameters that are the average of the parameters of previous gradients ), and - Theorem - based training ( based on self - supervised learning ) to ensure that the obtained gradient parameters do not deviate too much from the shared baseline. - The method applies the homogenized gradients to the task - specific gradient parameters, and ensures that the resulting gradients do n’t deviate significantly from the global gradient parameters. - It applies the learned gradient parameters to the gradient direction gradient parameters in order to ensure the training convergence of the resulting method.   The method is evaluated on a variety of tasks, where it is compared with a number of methods based on different homogenous homogenizations of the gradients, as well as the training - based methods. The results show that the proposed method, particularly outperforms the other methods when negative transfer is considered. In particular cases, the method with the homogenous gradients outperforms them both individually and collectively."
SP:050cd8319d84a1bd8c2ccb930ba69b33c8fb6e60,"This paper proposes a novel model fusion framework, CLAFusion, to fuse neural networks with a different number of layers, which the authors refer to as heterogeneous neural networks, via cross - layer alignment. The proposed framework addresses the cross layer alignment problem, which is an unbalanced assignment problem, and can be solved efficiently using dynamic programming. The authors propose to fuse networks that have different numbers of layers via a soft layer - wise model fusion and apply a soft neuron association to unify different pre - trained networks to save computational resources. Experiments are conducted on CIFAR-10 with individual networks trained on heterogeneous data without the need for any extra parametrization ( with an extra finetuning process ) and synthetic experiments are conducted to evaluate the effect of the proposed model fusion on the performance of the individual networks. The main contributions of the paper are as follows.   1. This paper proposes to fuse different neural networks by a soft model fusion method, where the soft model is trained using supervised learning and the individual neural networks are trained using self - supervised learning. This method is referred to as soft - neuron association ( LS ) and is similar to the approach used in OTFusion [ 1 ]. The difference is that LS trains the network using a fixed number of neurons, whereas here the fused network is trained with heterogeneous layers, where each neuron is assigned a number that depends on the heterogeneous layer number. ( see [ 2 ] for more details )   2. This work proposes to apply the soft layerwise model fusion prior to the soft neuron model fusion to heterogeneous networks, and the authors call this approach "" Layerwise Model Fusion "". This approach is different from Layerwise Fusion because it applies the layerwise parameters directly to the neural network layers ( layer ). On synthetic experiments, the authors show that Layerwise fusion from the layer wise approach achieves a more favorable performance compared to the network fused from layerwise fusion with the individual network ( with the additional parameter $ \alpha$ ). However, it is not clear if this improvement is due to the difference in layer size or the fact that layer size is scaled linearly ( with layer size, not linearly with the number of neuron layers ). 3. Finally, this work also proposes a new application for model compression and knowledge distillation when applying to the teacher - student setting, which could improve the performance when applying Layerwise"
SP:f764eae15cd083fdb4eb2af09ac64c2d878a454f,"This paper studies implicit regularization of SGD with stochastic gradient descent ( SGD ) in deep reinforcement learning ( RL ) setting. The paper hypothesizes that SGD benefits from overparameterized optimization as it encourages parsimonious solutions that generalize well on test inputs. However, the paper shows that the implicit regularisation induced by SGD in the offline RL setting can in fact be harmful in the temporal difference setting, leading to poor generalization and degenerate feature representations. To address this issue, the authors propose a new explicit regularizer, DR3, that counteracts the undesirable effects of this implicit regularizer. The method is evaluated on Atari 2600 games, D4RL domains and robotic manipulation from images on three different settings. The results show that DR3 significantly improves performance over SGD and other offline RL methods and substantially improves stability.    The main contributions of this paper are the following :   1. A theoretical analysis of the effect of the SGD regularization when applied to temporal difference learning. The resulting derived regularizer favors degenerate solutions with excessive “aliasing ”, in stark contrast to the supervised learning case where the regularizer is more sensitive to the input. 2. A set of experiments comparing the effects of the derived regularization and the offline regularizer on the Atari 2600 and 4RL domains. 3. Results show that using DR3 improves performance and stability in both online and offline settings."
SP:6fd793b27123bf80504e2ad5957455b7ec311612,"This paper proposes HyperDQN, an exploration method based on deep reinforcement learning ( RL ) that uses a meta - model instead of a linear model for Q - values. The meta model outputs the parameters of the base model, which is used to jointly optimize the Q - value function of both the meta model and the neural network jointly. The hypermodel can generate approximate posterior samples regarding the parameter of the Q-value function, which can be used for efficient exploration. The method is evaluated on Atari games and SuperMarioBros, where it outperforms DQN with 200 M frames in terms of the maximum human - normalized score. It is also compared with exploration bonus and randomized exploration methods on 5 out of 9 games. On the Atari games with 20 M frames the proposed method performs favorably compared to the existing exploration methods. The evaluation is conducted on the Atari 12 - player and Atari 16 - player games."
SP:b428383660928374c953f659ea1e05852dbdcd6e,"This paper proposes to learn a causal representation from observational data by regularizing the learning procedure with mutual information measures according to the hypothetical causal graph. The optimization involves a counterfactual loss, based on which the authors deduce a theoretical guarantee that the learned representation is with reduced sample complexity and better generalization ability. Extensive experiments show that the models trained on the causal representations learned by the approach by our approach are robust under adversarial attacks and the proposed approach is able to generalize more effectively.   The main contributions of this paper are the following :   1. The authors propose a causal graph learning method based on a proxy for the causal relation between features in a label and the downstream task ( labels ). This is different from existing learning approaches that rely on the correlation between features and the labels, which typically results in a representation containing cause, effect and spurious correlated variables of the label. 2. They propose to learn causal graph representations by training a neural network on the data provided by the proxy network. 3. They conduct extensive experiments on image classification, recommender systems, and machine translation to validate their approach."
SP:1258c05a80a17949b50e6dae13deea1d2235f456,"This paper proposes ProgFed, a training framework for efficient and effective federated learning. The training is resource - intensive for edge devices, and limited network bandwidth is often the main bottleneck. Prior work often overcomes the constraints by condensing the models or messages into compact formats, e.g. gradient compression or distillation. This paper proposes a progressive training framework that inherently reduces computation and two - way communication costs while maintaining the strong performance of the final models. Extensive results on a broad range of architectures, including CNNs ( VGG, ResNet, ConvNets ) and U - nets, show that this approach is highly effective and saves up to 20 % computation and up to 63 % communication costs."
SP:8cdaa6e0dafd750ebdb5d7a4c1987a042400662f,"This paper studies the generalization of adversarial training through the lens of Adversarial Rademacher complexity to deep neural networks. The main idea is to generalize the two - layer neural network trained in standard adversarial setting to three - layer network trained under adversarial settings. The reason why it is challenging is that the layers are not peeled off during training as is done in the classical adversarial analysis for standard training. The paper proposes a method to overcome this issue and provide upper bounds of the adversarial RadEmacher complexity that can be used for training deep neural network models. The proposed upper bounds are based on the previous work [ 1 ]. The authors also provide experiments to show that the adversarially trained trained weight weight norms are larger than the standard trained weight norms, thus providing an explanation for the bad generalization performance of the proposed generalization algorithm.   The main contributions of this paper are the following :   ( 1 ) The authors propose a new metric to measure the robustness of neural networks trained with adversarial perturbations to adversarial examples. This metric is the ratio of the adversary ’s complexity with respect to the number of layers of the network. This is in contrast to existing methods that measure the adversary complexity as a linear function of the layer number. ( 2 ) This metric allows the authors to separate the network into two groups, one for adversarial attacks and one for non - adversarial ones. The second group is used for smoothing the training. ( 3 ) Experiments are carried out to show the effectiveness of the new metric and the bounds are compared to the one used in the previous paper. The results suggest that the proposed upper bound is better than the lower bound."
SP:925d6bb051e9b384669fb695085b678c11f7c11a,"This paper proposes a new method, called KNIFE, for estimating differential entropy ( DDP ) using kernel - based estimators. The motivation is to address shortcomings in previous DDP estimators that only consider the log - likelihood of the target distribution. The key advantage of the proposed method is that it is parameterized by kernel parameters that are differentiable and parametrized, making it possible to use differentiable estimators for conditional DDP as well as mutual information. The flexibility of the method allows for using it to estimate DDPs for discrete ( discrete ) and continuous ( continuous ) entropy ( conditional ) distributions. The method is validated on synthetic data ( visual domain adaptation, textual fair classification, textual fine - tuning ) and real - world tasks ( visual dimentionality in classification ). Experiments on a large variety of tasks demonstrate the effectiveness of KNIFE - based estimation."
SP:d2f3beac855f0d72c13552fecb2bdb9d42195df3,"This paper proposes a new soft - greedy operator, resmax, for reinforcement learning ( RL ), that takes actions proportionally to their suboptimality gap : the residual to the estimated maximal value. It is simple to use and ensures coverage of the state - space like   ε - greedy, but focuses exploration more on potentially promising actions like softmax. Unlike softmax, it does not concentrate probability as quickly as softmax and so better avoids overemphasizing sub - optimal actions that appear high - valued during learning. The authors empirically validate that resmax is comparable to or outperforms   hardmax and outperforms \rho - softmax across a variety of environments in tabular and deep RL. Additionally, they prove it is a non - expansion for any fixed exploration hyperparameter unlike the softmax policy which requires a state - action specific temperature ( called mellowmax )."
SP:792ae8808aa6902758146aef1548c975492b833c,"This paper proposes and investigates a new method for controlling the model ’s learnability on a dataset with a special key. It proposes adversarial invertible transformation ( AIT ) that can be viewed as a mapping from image to image, to slightly modify data samples of the same label to “ un - learnable ” data samples so that they become difficult to be detected or reverse - engineered. This ensures that the learnability can be easily restored with a simple inverse transformation. The method is tested empirically on visual classification tasks. The experiments show that the proposed approach works better than baselines that only require access to the original dataset.    The main contributions of the paper are the following :   1. The authors propose a novel approach to control the model’s learningability on the dataset by using a novel adversarial   transformation. It is based on the idea of “ learnability attack ” ( Liu et al., 2019 ) where the goal is to prevent unauthorized exploitation of the dataset with the knowledge that the dataset is “ safe ” from commercial exploitation. 2. It applies a universal transformation function on the AIT to the dataset to ensure that a model trained with the proposed AIT can not learn the same learnability as a baseline model that was trained with a different AIT. 3. It compares the performance of AIT with the baselines of two commercial machine learning models trained with and without AIT and shows that AIT outperforms them both in most of the cases. 4. Finally, the method is applied to two different datasets ( CIFAR10 and Fashion - MNIST ) to test the effectiveness of the proposed method."
SP:9af10703605e620e563241e2602a50b629f3d37a,"This paper proposes Feature Propagation for Graph Neural Networks ( GNNs ), a general approach for handling missing features in graph machine learning applications that is based on minimization of the Dirichlet energy and leads to a diffusion - type differential equation on the graph. The discretization of this equation produces a simple, fast and scalable algorithm which is referred to as feature propagation ( SPI ), which is designed to handle the problem of finding missing nodes or edges of graphs when the graph contains features that are not widely available ( e.g., due to lack of availability of the node or edge features ). The main contributions of this paper are the following :   1. The authors propose an approach for finding missing features of graphs by minimising the energy of the graph distribution over nodes and edges, and then solving the differential equation between the energy distribution and the diffusion equation over graphs. The resulting feature propagation algorithm is simple and fast to implement, and it only requires 10 seconds of running time on a graph with 2.5 M nodes and 3 M edges on a single node. 2. It is shown to outperform previous methods on 7 common node - classification benchmarks and can withstand surprisingly high rates of missing features when only around 4 % of the features are missing.   3. The algorithm is applied to several real - world applications, such as social networks, where features such as age and gender are only partially available. The experimental results show that the proposed approach outperforms the previous methods significantly, even when the missing features are between 99 % and 99 % ( the average is only around 80 % )."
SP:cbaa3f1379fa99159899d79ccb479c0187403aca,This paper introduces Active Learning with a Generalized Bender Decomposition ( BG ) algorithm for unsupervised learning on unlabeled features of a data set to train a model with limited labeled data by selecting a core set of a subset that minimizes the discrete Wasserstein distance from the unlabelED pool. The BG algorithm introduces an integer optimization problem for selecting a set of features to label that minimises the distance between the labeled set and the subset that is not labeled. This problem is formulated as a bijective optimization problem where the goal is to design a classifier that maximizes the probability that the labeled data set is a subset of a set that is high - quality.    The authors propose to solve the bijectivity problem by using a generalized curvature based curvature decomposition of the data set ( GP - DC ) and a latent feature extractor ( L2 Lipschitz - GAN ). They propose an algorithm for training the model using GP - GP and L2 GAN and show that it is competitive with baselines and outperforms them in the low - budget regime ( less than 1 % labeled data ). The authors also propose a variant of their algorithm for the high - dimensional latent features setting where they use L2 regularization to obtain features that are harder to extractorize but are still obtainable with L2 normalization. Numerical results on several data sets show that the BG - GP - L2 - GP algorithm performs better than baselines on the unlabeled data sets.
SP:4c72923f78ca6590dc11e10d1a2403076a583718,"This paper proposes a method for fast and more accurate genome assembly using graph convolutional networks trained on a dataset generated from human genomic data to reconstruct the genome by finding a path through the assembly graph of a sequence that matches the reconstructed sequence. The authors propose to apply geometric deep learning to the central part of the genome assembly—untangling a large assembly graph from which a genomic sequence needs to be reconstructed — to find the path that shortest connects the sequence and the one that is closest to the one reconstructed by the original sequence. They show that this approach is more accurate than hand - crafted methods for assembling genomes, and more importantly, that it is faster than using a human handcrafted method to assemble genomes.   The authors then propose to train such a network using a GP - SGD - like approach where a node is connected to all the sequences that are sampled from the original and reconstructed genome using the same set of sequences. They train the network with a greedy search algorithm, greedy search over the overlap lengths of the sequences, and greedy search with the distance between the sampled sequences and the paths through the graph that are close to the correct path. This approach is referred to as the “ path finding algorithm ” ( PGD - AE ). They then show that their method leads to faster assembly of the reconstructed genome compared to the original when applied to sequences sampled from different parts of the same genome. This favourable result paves the way for the development of powerful graph machine learning algorithms that can solve the de - novo genome assembly problem, which can assemble the genome much quicker and more accurately. The main contributions of the paper are twofold :   ( i ) - The first is that the proposed method is able to obtain a path finding solution for a sequence from a dataset that is sampled from many different sequences and reconstructs the genome more accurately than the original sequences. The second is that it leads to more accurate results for assembling the genome at a much faster time scale compared to handcrafted methods."
SP:24de906e4289c9073b6c55c747b0913b8df5e053,"This paper proposes a meta - training framework that incorporates experience replay ( ER ) into meta - testing to improve the robustness of continual learning algorithms against catastrophic forgetting. The authors argue that the use of ER only in meta testing but not in metatraining implies that the model trained using ER may not be optimally meta - trained. To address this issue, the authors propose to store the samples ’ representations, instead of the samples themselves, into the replay buffer to ensure that the batch nature of ER does not conflict with the online - aware nature of OML. Experimental results on a number of real - world meta - continuing learning benchmark data sets demonstrate that the proposed method outperforms the state - of - the - art. Moreover, the learned representations have better clustering structures and are more discriminative.    The main contributions of this paper are the following :   1 ) The authors propose a framework that improves upon the existing meta - learning framework by integrating ER also into meta training ; 2 ) A sample - augmented version of ER is used to sample from the buffer used for storing the samples representations ; 3 ) The learned representations are stored in the same way as those of the baseline meta - learners ; 4 ) A predictive sample selection strategy is proposed to select the most significant samples to be stored to populate the widely used reservoir of experience replay buffer during training."
SP:3c78454f053f74930979a8054cd7c8a34b6fe63d,"This paper proposes a method for multi - agent joint Q - learning based on centralized training ( CTDE ) for credit assignment. The authors point out that most of the existing methods implicitly learn the credit assignment just by ensuring that the joint Q-value satisfies the Bellman optimality equation. In contrast, this paper formulate an explicit credit assignment problem where each agent gives its suggestion about how to weight individual Q - values to explicitly maximize the joint $ \phi$-value, besides guaranteeing the optimality of the jointly calculated Q - value. Theoretically, the authors propose a gradient ascent solution for this problem. Based on this idea, they instantiate the core idea with deep neural networks and propose Explicit Credit Assignment Joint Q - Learning ( ECAQ ). Experiments are conducted to justify that ECA Q achieves interpretable credit assignment and superior performance compared to several centralized training methods.    The main contributions of the paper are the following : 1 ) The authors propose an explicit joint credit assignment among multiple agents and along the time horizon 2 ) A gradient ascent method based on centralized training with centralizedized execution to learn the assignment in an explicit manner 3 ) A joint distribution of individual Q-values among the agents is derived to obtain joint distributions. The method is evaluated empirically on credit assignment in the following scenarios : e.g., when the individual agents are not training jointly and the joint distribution is used to assign credit to an individual agent, or when multiple agents are training jointly, the individual agent will assign the credit to the joint value and vice versa. The results show that the proposed joint distribution does not negatively affect the overall performance of joint training. 4 ) A set of experiments is performed to validate the effectiveness of the proposed method."
SP:0d2b225ac697679d10df25f371b2a718d4949b42,"There has been an emerging interest in using transductive learning for adversarial robustness ( adversarial defense ) in order to more robustly defend against adversarial attacks. Transductive defenses are different from traditional defenses in that they “dynamically learn ” the model based on test - time input, and theoretically attacking these defenses reduces to solving a bilevel optimization problem, which poses difficulty in crafting adaptive attacks. In this paper, the authors propose Greedy Model Space Attack ( GMSA ), an attack framework that can serve as a new baseline for evaluating and testing GMSA - based defenses. The authors first analyze threat models for GMSA, and point out important subtleties in the two - step procedure for generating the threat models. They show that GMSA even with weak instantiations can break the $ \ell_2$-norm $ $ \gamma$-defensive assumptions of previous attacks, which were resilient to previous attacks such as AutoAttack. Next, they propose the principle of attacking model space for solving $ \mathcal{O}$-bilevel attack objectives, and present Greedy GMSA as a basis for evaluating the model using a systematic evaluation using fresh randomness at the test time. Through systematic evaluation, they show that the attack framework can provide robustness against attacks that were similar or less robust than those considered in previous defenses. Finally, they provide empirical evidence that applying the GMSA framework against attacks from previous defenses provides a statistically significant increase in robustness.    The authors discuss several important aspects of their work. The main contributions are the following : 1 ) - The authors propose a new $ \epsilon$-based attack framework called Greedy model space attack to evaluate the robustness of the model space used for evaluating GMSA. This can be used as a base for evaluating other attack methods as well as the standard defense methods such as auto - attack. 2 ) They study the relationship between model robustness and the number of assumptions used to train the attack model. 3 ) The authors provide clear guidance on when and how to appropriately constrain the assumptions in the model to ensure that the attacks are robust against it."
SP:e7024cae196fc5eb6a62d289a95d76b532b6a36c,"This paper studies normalization methods for training neural networks using batch normalization. Batch normalization is a normalization method that normalizes the training step of a neural network using the gradient of the weights as a function of the batch size. Traditionally normalization considers the case when the dataset of training data is normalized jointly with the inference model. This paper casts normalization as an approximation to the limiting case where the dataset is normalized only between training and inference, and proposes two ways to normalize the gradient when training more than one example per training step. The first way is to keep one example in memory for each training step, and the second is to train the model as a fully per - example basis, which removes the extra training step computation at the cost of a small drop in the final model accuracy.   This paper studies the effect of normalization on the training of neural networks with BN - normalized gradient. The main contributions are the following :    1. The authors propose to use normalization to improve the gradient approximation of batch renormalization for very small minibatches. This is done by normalizing the gradients of the gradient step of the training steps of the neural network training step using the normalized gradient from the training dataset. 2. They show that this normalization removes the need to keep two extra examples in memory during training, and 3. They use the extra examples as an additional training step during inference to train a fully normalized model for a given training procedure, which results in a small increase in the accuracy of the model. 3. 4. The experiments compare the proposed normalization with two different regularization methods, and show that their normalization does not change the function of inference model during training and performs well in the absence of identity shortcuts."
SP:4aa42984fcb0fd66936d668477b2719ef5c427d4,"This paper proposes Low - Rank Adaptation ( LoRA ), a method to reduce the number of trainable parameters in the pre - trained Transformer model parameters during fine - tuning. This is motivated by the fact that as the size of the Transformer models continues to increase, the more difficult it becomes to fine - tune the model parameters required for downstream tasks. To this end, the authors propose to freeze the parameters of the model at each layer and use rank - divergence matrices to reparametrize the parameters into those of the rank matrices of the next layer in the pretrained model. The authors compare LoRA to GPT - 3 175B fine - tuned with Adam, where the maximum trainable parameter is only available after 10,000 times of using Adam. The experimental results show that LoRA performs on par or better than GPT-3 on most tasks, with the exception of a few domains, where it performs worse than Adam.    The authors also provide an empirical investigation into the effect of rank - dependence in language model adaptation on the efficacy of LoRA. This empirical investigation is divided into two parts. The first part focuses on pretraining the model on the general domain data and the second part on the task - specific domains. The experiments compare the performance of the methods based on the RoBERTa, DeBERTa and GPT2 model pre - training ( with Adam ) and the model - based method ( RoRA - R, with no Adam ) pretraining on the domain - specific data and task - adaptation data ( the latter relying on the rank - dependent method ). The results suggest that the methods outperform the methods such as GPT3 and GRA with Adam significantly on the majority of the domains, while being slightly less accurate on the remaining domains."
SP:b77a00beb0802f47810b03d3c4aa24d92781414f,"This paper proposes a generalization of linear - chain conditional random fields ( CRF ), a widely used model class which can learn local dependencies in the output, to a broader class of constraints, including nonlocal ones, by specifying the space of possible output structures as a regular language L. The resulting regular - consstrained CRF ( RegCCRF ) has the same formal properties as a standard CRF, but assigns zero probability to all label sequences not in L if they are not in $ L$. The authors provide empirical evidence that the generalization is robust to both local and nonlocal constraints, and show empirically that it can be substantially better in practice than the CRF ’s Markov assumption. The authors also demonstrate a practical benefit on downstream tasks by incorporating a RegccRF into a deep neural model for semantic role labeling, exceeding state - of - the - art results on a standard dataset."
SP:74c186a96c12adff178264aa84ace8d04dc7d725,"This paper proposes two neural models for camera - based physiological measurement called EfficientPhys that remove the need for face detection, segmentation, normalization, color space transformation or any other preprocessing steps that lead to expensive additional operations in end - to - end training of physiological measurement systems. The authors propose two novel and efficient neural models, i.e., GPT-2 and GPT - PGD, for the network architecture of the Movielense dataset.    The first model is based on the Transformer Network and the second model is the Convolutional Backbone. The main difference between the two is that the Conv - Backbone uses a linear backpropagation network while the GPT model uses a convolutional network with the input of raw video frames. The GPT network shows that the most light - weight - efficient version of the proposed network is the one that achieves state - of - the - art accuracy on three public datasets. However, the cost - efficiency results in the paper are slightly lower than the other two methods ( GPT2 and PGD ) due to the fact that the model uses only half of the computation cost of GPT1. The cost of the second method is higher because it requires to re - train the network after each frame has been viewed. The method is simple and straightforward to use, and the authors argue that it is necessary to have a simple model that only trains the network part of the way to ensure that the final results are similar to the first one. The second model uses the full network to train the rest of the network from raw data frames. They evaluate the performance of their model on three datasets ( CPH1, CPH2 and CPH3 ) and show that the proposed model achieves a 33 % improvement in accuracy over the baselines of the first model. The margin of the improvement is slightly higher than the margin of improvement achieved by PGD using the original model ( PGD + Conv - SGD + transformer + convolutionsal backbone + GPT. The authors also evaluate the latency of their proposed network on two datasets, showing that their model is slightly more latency efficient than PGD+ transformer and slightly less latency than GPTG+. Finally, the authors evaluate the cost effectiveness of their method on the datasets and conclude that their method is the most cost - efficient compared to the other methods."
SP:3003bab6e3f7e2e21cd6cf27ee7d483d877d9fb3,"This paper proposes Hardware - Aware Latency Pruning ( HALP ), a pruning method that treats structural pruning as a resource allocation optimization problem, aiming at maximizing the accuracy while constraining the latency under a predefined budget. It leverages latency table to track the latency reduction potential and global saliency score to gauge the accuracy drop. The paper studies HALP on both classification and detection tasks, over varying networks, and on ImageNet and VOC datasets. It finds that HALP consistently outperforms prior work in pruning efficacy and accuracy - efficiency trade - offs. It also finds that on VOC, HALP improves network throughput by 1.94 % with only a 0.56 mAP drop."
SP:c44d676c09c8e5a70d73b21b507b41a422fec809,"This paper proposes GraphEBM, a permutation invariant and multi - objective molecule generation method based on energy - based models ( EBMs ). The energy function is learned via contrastive divergence and Langevin dynamics. To generate molecules with a desirable property, the authors propose a simple yet effective learning strategy, which pushes down energies with flexible degrees according to the properties of corresponding molecules. The authors conduct comprehensive experiments on random graph generation ( single - objective ), multi - objective molecule generation ( MMD ), and single - molecule graph synthesis ( SMGE ) tasks to evaluate the effectiveness of Graph EBM. The primary contributions of the paper are as follows :   1 ) The authors develop and train a parametrized energy model based on EBMs to learn the energy function for graph generation and generate samples ; 2 ) They use this energy model to parameterize the generated samples for generating multiple objectives via compositional generation. 3 ) They conduct extensive experiments on MMD and SMGE tasks to validate the effectiveness and efficiency of their method.   The main contributions of this paper are the following : 1 ) An energy based method for generating molecules based on permutation - invariant energy models is proposed, which is compared to existing methods ( Graph, GraphGAN and GraphGANGAN ). 2 ) A learning strategy is developed to optimize the energy used for generating samples to achieve the desirable property of MMD with the property of graph distribution."
SP:70e60fa5deef3e3ba77d05d0c3e0e7fbf396aa1d,"The paper proposes a neural - based approach to program synthesis, CROSSBEAM, which trains a neural model to learn a hands - on search policy for bottom - up synthesis of previously explored programs to reduce the search space blowup as the size of the target programs becomes larger. The model is trained on a structured learning task, where it is asked to predict the best way to combine explored programs into new programs, taking into account the search history and partial program executions. Experiments are conducted on two tasks : ( 1 ) evaluate the effectiveness of the neural model on learning to search on the task of predicting the program synthesis policy and ( 2 ) compare the performance of the method with prior combinatorial search approaches that use a learned search policy. The results show that the approach is more effective in exploring much smaller portions of the program space compared to the combinatorially - based approaches that explore a large portion of the space.    The main contributions of the paper are the following :   1 ) A detailed description of the history of prior search approaches for program synthesis ; 2 ) A systematic evaluation of the differences in performance between the methods in terms of the amount of search space explored, the quality of the predictions made by the model, and the number of data points used to train the model ; and 3 ) A set of experiments that compare the performances of the proposed method against prior methods for predicting the search policy from scratch and using data from previous search evaluations."
SP:daa044ffefe80bae16b014f60061d941ed8c2ba6,This paper proposes a new regularization method for Deep Reinforcement Learning ( DRL ) based on target networks. Traditionally DRL has used target networks to stabilize training by using an additional set of lagging parameters. The regularization proposed here is explicit and enables the use up - to - date parameters as well as control the regularization. This leads to a faster yet more stable training method that provides a fast and stable alternative to the target - network based DRL method. The authors experimentally compare the proposed method with target networks and DRL based methods across a range of settings in terms of both sample efficiency and performance. The main contributions of the paper are as follows :   1 ) The authors propose a regularizing regularizer that regularizes the squared Bellman error of the DRL training objective. 2 ) The method is compared with the target network based regularizer. 3 ) The results demonstrate that the proposed regularizer is better suited for training DRL candidates compared to target networks based regularizers.
SP:dd174014d056a7d2bc86ee99119841eafa62ed52,"GraphSNN is a neural model that extends the Weisfeiler Lehman aggregation scheme in message - passing aggregation for graph neural networks ( GNNs ). The authors propose a new hierarchy of local isomorphism on neighborhood subgraphs that can be used as a basis for constructing GNN message aggregates. GraphSNN can be considered as a general solution to injecting structural properties of graphs into the message - passing aggregation scheme of GNN. First, the authors derive a new set of isomorphisms for each node in a graph based on the dynamics of the adjacency matrix. Then, they develop a set of test cases that measure how expressive the message aggregation scheme is for two types of graphs : stationary and moving graphs. The first test case is used to measure how well the aggregation is able to identify nodes that are stationary in the graph. The second one is used for moving graphs that are moving away from stationary positions.   The authors validate the effectiveness of their neural model on three graph learning tasks. They use two methods : state - of - the - art methods and standard GNN aggregation on the standard tasks and one that is based on a new method that combines the use of two different types of graph structures ( e.g., node - centric and node - independent graph structures ). They show that the new model consistently outperforms the baseline GNN on all three tasks ( without sacrificing computational simplicity and efficiency )."
SP:beb9ba0261e176bfc50e9bf5bed2b6169d388285,"This paper proposes PI3NN, a neural network - based method for uncertainty quantification of PIs. It addresses three major issues with the state - of - the - art PI methods : 1 ) existing PI methods require retraining of neural networks ( NNs ) for every given confidence level and suffers from the crossing issue ; 2 ) they usually rely on customized loss functions with extra sensitive hyperparameters for which fine tuning is required to achieve a well -calibrated PI ; 3 ) they underestimate uncertainties of OOD samples leading to PIs with over - confident confidence levels. To address these issues, the proposed method calculates PIs from linear combinations of three NNs, each of which is independently trained using the standard mean squared error loss. The coefficients of the linear combinations are computed using root - finding algorithms to ensure tight PIs for a series of confidence levels without retraining NNs and it completely avoids crossing issues. The method is evaluated on several benchmarks and real - world experiments and it outperforms several previous works from the literature. The main contributions of the paper are as follows.   1 ) It proposes a neural net backbone network from which it computes PIs and trains a linear combination of three neural networks. 2 ) It introduces a PIs initialization scheme to avoid the OOD cross - entropy issue in calculating multiple PIs, which can result in PIs having larger errors than those of the in - distribution samples. 3 ) It applies the method to the prediction interval interval ( PI ) estimation ( PIs ) problem and shows that it is more robust than the previous methods on uncertainty quality, robustness of samples, and OOD identification."
SP:4b44a834e2212bacb4c2d9408a81f1efc76a670b,"This paper proposes Fully Online Meta - Learning ( FOML ), a meta - learning method that tackles continuous learning problems where the goal is to learn a model that can adapt quickly to new tasks and environments in an online setting, e.g., when the task boundaries of the tasks are not known and the model is not fully online, so the model can not be updated back to pre - trained weights as is conventionally done in batch settings. To tackle this problem, the authors propose to meta - train the model to be able to adapt more quickly to changes in the environment and parameters of the model at bootstrapping. To do this, they propose to use the metalearning method. The method is evaluated on the Rainbow - MNIST and CIFAR100 datasets and compared against state - of - the - art online learning methods on the tasks. They also investigate the method on the task - agnostic datasets to see if meta - training is needed to make the model better able to handle the new tasks. The results show that meta training is necessary but not essential to learn new tasks faster. Meta - learning with gradient descent or gradient ascent is not a good choice for continual learning as these methods are conventionally applied to batch settings and do not consider the discrete task boundaries that are required for each task in the batch. The authors propose a method that is based on fully online meta learning, where the model does not learn task boundaries and stays fully online the entire time, and meta training the model only on tasks that are learned from start to finish. This method is referred to as “ full online learning ” and it is experimentally compared to FOMA and FOMC on Rainbow-MNIST to see whether it is better for learning new tasks or not. They find that it is best to use FOMO to learn tasks faster than the other methods and that MetaFOMO is the best on the full tasks but not the best for the experiments on full tasks."
SP:fbae35cb171b3a3eb7c5d4bc83881ed7c4a70aae,"This paper proposes a differentiable scaffolding tree ( DST ) for the study of designing functional molecules, or molecular optimization, also called graph neural network ( GNN ). It is realized by back - propagation ( back - propagating ) the derivatives from the target properties of the DST to the derivatives of the GNN that is used to estimate the mutual distances between the target nodes and the nodes that are not the target molecules ( e.g. atoms, bases, bases of bases ). The goal is to find a scaffolding structure that minimizes a target objective that maximizes the ratio of the target objective and the distances to the ground - truth nodes. This is done by averaging over all the nodes in the tree and computing the distances between them using a weighted sum of their derivatives. The backpropagation proceeds iteratively until convergence, in which case the node nearest to the target node is chosen as the node to be optimized. The authors argue that this is the most natural way to learn the distances because the molecules are discrete and the derivatives are non - differentiable. The method is evaluated empirically on synthetic and real - world data and compared with deep generative models and combinatorial optimization methods. The experiments show that DST outperforms the deep models in terms of cost and accuracy, and the experiments also show that the learned graph parameters are more interpretable."
SP:61b59899cf6ae442d9f8f5226e79708a4280cfb2,This paper proposes a knowledge - augmented approach to predict lab test response of personalized medical imaging ( PIM ) patients. The idea is to use a graph neural network ( GNN ) to model drug - lab interactions and PIM interaction as graphs and design a knowledge augmentation approach to reduce the KL - divergence between the predicted lab response and the actual test response. The GNN is trained using real - world data and PCA data. The authors personalize the GNN predictions by taking into account the patients ’ past lab responses. They show that the proposed approach improves upon the baselines by a significant margin.   The main contributions of this paper are the following :   1. A novel GNN method based on GNNs is proposed to predict the lab test responses of PIM patients. This method reduces the KL divergence of the predicted test response prediction by a large margin. 2. The method is trained with PIM data to personalise the prediction. 3. The proposed approach is tested on two real world datasets and compared with a baselines based on PCA. The results indicate that the approach outperforms the baseline method in terms of accuracy with respect to the number of false positives.
SP:8623cebb515c4a736427449b46ad2cdf8b806b77,"This paper proposes a new single domain generalization method, Open - Set Single Domain Generalization ( OS - SDG ), where the source and target labels of the data may not be in the same label space, and trains a single model only on the source labels, and uses adversarial data augmentation to generate auxiliary samples to train the classifier. The proposed method, called CrossMatch ( adapted from previous works ) generates auxiliary samples out of the source label space by leveraging a multi - binary classifier and using an adversarial training strategy. The authors also adopt a consistency regularization on generated auxiliary samples between the classifiers and the model trained by SDG methods, to improve the model ’s capability on class identification. Experimental results on benchmark datasets prove the effectiveness of CrossMatch on enhancing the performance of the two proposed methods, and the authors propose to use CrossMatch in future versions of their method.    The main contribution of this paper is to propose a new method to learn a classifier from a single source class label ( e.g., the class labels of a set of classes ), and to use it for class identification of unknown classes from the first - order generative model of the target class ( classifier, classifier + classifier ) trained with the adversarial augmentation strategy from the previous works. This method is referred to as a single - set SDG ( under the name generalization with only one source label ). In the experiments, the authors compare the proposed method with two other methods, namely ( 1 ) CrossMatch and ( 2 ) DenseMatch. Results show that the proposed by the authors significantly outperform the other methods in terms of accuracy on target class identification and classotypical distribution prediction."
SP:126f8ffb855aa22eda4d681a499953879ed3679e,"This paper studies policy optimization with Wasserstein and Sinkhorn trust regions in reinforcement learning. The authors propose two new approaches to improve the performance of policy gradient estimators ( PPO and SPO ) which are extensions of the trust region methods in Stein and Schmidhuber ( 1982 ). The main difference between these methods and the original PPO is that the latter uses a parametric distribution while the former directly optimizes the policy distribution via the Lagrangian duality. Theoretically, the authors show that WPO guarantees a monotonic performance improvement and that SPO provably converges to WPO as the entropic regularizer regularizer diminishes. Experiments across tabular domains and robotic locomotion tasks demonstrate the performance improvement of both approaches.   The main contributions of the paper are the following :   1. A new approach to optimizing policy gradient methods based on Kullback -Leibler divergence ( KLD ) is proposed, which is claimed to stabilize the policy optimization due to the fact that the divergence between the policy updates obtained from the KLD policy update and the policy update of the given policy is a closed form solution to the duality, and that the updates are always close to each other in the sense that they are not changing the underlying policy. This approach is shown to converge faster and is more robust to variations in the number of parameters of the regularizer ( compared to KLD - regularizer ) than the approach based on parametrizations of the policy distributions. 2. Two versions of KLD are considered, one based on the Stein and the other on theinkhorn. Results show that the approach performs better than the original Stein and that it converges faster than the Stein approach."
SP:999eacf6500c87205584a3256d7ca45b3016fb1c,"This paper proposes a new paradigm for shaping the learning trajectories of artificial neural networks using forget - and - re - learn ( forget - relearn ) algorithm. The forgetting step selectively removes undesirable information from the model, and the relearning step reinforces features that are consistently useful under different conditions.   The forgetting operation is proposed to unify many existing iterative training algorithms in the image classification and language emergence literature, and allows them to understand the success of these algorithms in terms of the disproportionate forgetting of undesirable information. The paper proposes to leverage this understanding to improve upon existing algorithms by designing more targeted forgetting operations. The proposed forgetting operation consists of two steps : ( 1 ) a pretraining step where the model is pretrained to remove undesirable features from the data, and ( 2 ) a learning step where it is retrained to introduce useful features into the data again. The approach is referred to as forgetting and re - learning ( OR ) in the paper. This approach is similar to the one used by the authors in Sec 4.1, but differs in that it considers only the case when the loss function is intractable, i.e., when the pretraining operation is applied to both pretraining and learning ( pretraining + re - training ). The main difference is that the authors propose to apply the forgetting operation to only pretraining the model when the learning loss consists of pretraining plus the learning step, which is when learning starts from the pretrained model with the previously learnt features. The framework is evaluated empirically on MNIST and CIFAR-10 for image classification tasks, and compared to several previous works on language emergence. The results demonstrate that the forget and relearn algorithm leads to better performance compared to other similar algorithms, and that more information is selectively removed during the forgetting step leading to better learning. The idea is to use the forgetting process to improve the performance."
SP:2789859517b6624730b14a7e010444a72d3dd3ed,"This paper investigates an offline - online setting for training batch RL agents. In this setting, during the training phase, the agent has access to a batch of data but is also able to learn during the evaluation phase in an online manner. This is an extension to batch RL, allowing the agent to adapt to new situations without having to precommit to a policy. The paper finds that standard RL agents trained in this setting can outperform agents trained only offline or online, sometimes by a large margin.   The main contributions of the paper are as follows :   - The paper proposes and studies a setting where the agent is trained using offline data collection and evaluation, where the goal is to learn both during training and evaluation so that the agent can improve its performance in the future. This setting is referred to as “ Offline - Online Batch RL ” - this setting is different from batch RL in the sense that it does not require the data - collection process to be smooth and does not requires assumptions on the data collection process ( e.g. sufficient coverage or a good policy ). The main contribution of this paper is to investigate this setting and show that it can give rise to better performance than batch RL when these assumptions are not very strong. - In the experiments, the paper finds out that it is possible to train a batch RL agent with a policy that allows for learning during evaluation and transfer learning during training but only if the policy is flexible enough to handle new situations emerging in the training data. The agent can learn from the evaluation data in this fashion and transfer learned from the data in the offline setting to the training policy in the evaluation setting. - The experiments show that this setting gives rise to improved performance over batch RL on some tasks compared to the offline - only policy. - On one of the tasks, it is shown that a trained agent trained in offline - offline setting can learn better than another agent trained only online or trained with data collected offline."
SP:76625a25e770415599a34122110d61cb3b7e614c,"This paper studies discrepancy - optimal meta - learning ( DAG ) for domain generalization ( DG ), a setting where the goal is to learn to reduce the domain shift between source and target settings using an episodic training procedure. The domain shift is estimated using the domain - shift metric Y - discrepancy, which measures the discrepancy between the unseen target domain and the source domain only using source - domain samples. The paper derives a generalization bound for DAG based on PAC - style generalization and compares it with other DG bounds, including ERM and domain - invariant learning. The theoretical analyses show that there is a tradeoff between classification performance and computational complexity for discrepancy - Optimal DAG. Empirically, the paper evaluates the algorithm with DomainBed and achieves state - of - the - art results on two benchmarks.   The main contribution of this paper is to develop a bilevel optimization algorithm for DG that uses contrastive learning to optimize the distance between the target and source settings when the target domain is chosen to be learned from. The main contributions of the paper are as follows :   - Theoretically - Theorem 1 that shows that the difference between the expected return of DAGs obtained by different DAG methods is proportional to the ratio of the expected loss of the target DAG with respect to the source DAG and the one obtained by using the contrastive learner. Theorem 2 that generalizes the DAG bound back to the PAC bound in the limit of the discrepancy - optimal generalization of meta - learners, and derive a bound for the difference in terms of the number of instances of discrepancy between DAG instances and the total DAG variance of the dataset. Theoretical analysis shows that this bound is upper bounded by an upper bound on the average DAG difference over the dataset and a lower bound of the average difference in the dataset variance over the datasets used to train the dataset ( Theorem 3 and 4 ). The major contributions of this work are the following : - Prop. 1 ( 1 ) A new set of experiments that compare the performance of the proposed DAG method with the baselines of ERM, domaininvariant learning, domain - uniform learning, and Bilevel DAG ( Prop. 2 ) Results show that the proposed method performs slightly worse than DAG, but is slightly better than baselines and is competitive with DAG"
SP:6421a9759c766641fd8c128a249f1a9c5699d19c,"Traditional combinatorial search methods, such as Best - First Search ( BFS ) and Monte Carlo Tree Search ( MSTS ), are very effective at solving NP - Complete problems in planning NP games such as Sudoku, CSP, and PPO, but they are expensive and time - consuming. This paper proposes a new approach, Deep Neural Networks ( DNN ) heuristic - based best - first search on the Sokoban domain to solve PSPACE - hard problems, combining these methods with a DNN - based policy network ( PPO ). This approach is different from the traditional approaches in that it uses a policy network to predict the best action to solve the problem, rather than a PPO - based method that uses a deep reinforcement learning algorithm. The main contributions of this paper are the following : 1 ) it proposes a heuristic for the search, based on the policy network, to identify whether the left or right - hand side of the input is more likely to be the target of a good solution ; 2 ) it develops an empirical tree model to identify the causes of the left heavy tails ; and 3 ) experiments are conducted to validate the effectiveness of the heuristic and to demonstrate the importance of restarting the search after each set of left and right heavy tails to avoid them ; and 4 ) the cost of running the search is analyzed to understand the effect of the number of leaves and the size of the sub - trees used in the search to identify good and bad choices for restarting search. The experiments show that the DNN heuristics perform better than those of traditional search methods and random restarting is a better alternative."
SP:84c415bc0f120d1997289f91661ff74e7297d3bd,"This paper presents a method for meta - learning from video demonstrations to train a policy for imitation learning, where the goal is to learn a set of actions and behaviors that are similar enough for the robot to generalize to new tasks without additional human demonstrations during the meta - training phase, which usually requires a large number of demonstrations from humans and robots. The presented method is able to translate human videos into practical robot demonstrations and train the policy with adaptive loss based on the quality of the translated data. The training is done in two stages : during the fast learning phase ( during which the data is generated using the translated videos ) and during the data collection phase, during which a meta - policy is trained using the data collected from the fast - learning stage and the collected data from the data - collection stage using the robot demonstrations. The collected data is used to improve the performance of the policy for the task under the assumption that the learned behavior is similar enough to the one observed by the robot during the training phase.    The main contributions of the paper are the following :   ( 1 ) A new method for learning from videos to train meta - pretraining policies, where instead of using human videos as the primary source of data for the pretraining phase, the authors use videos generated from watching robot demonstrations instead. This allows for training the policy using data generated from robot demonstrations but without the need of human demonstrations. ( 2 ) The method is evaluated on the task of vision - based classification and compared to the method for fast learning based on data collection ( based on fast learning ) and fast learning plus data collection based on set of vision- based tasks ( data based set of tasks. The experiments show that the proposed by the authors perform better than the comparable results of the method based on human videos and faster than the results of data based learning."
SP:fedf5c75e83d6ab41ef9d5daa9054ffe4e424ec2,"adaptive optimizers ( Adam ) are a type of optimizers that apply gradient descent ( gradient descent ) to train - based models to improve the generalization of the model. This is done by setting the output scores ( logits ) and network weights ( adaptivity ) of the network in the weight space based on the parameters of the optimizer. However, due to the nature of gradient descent and hyperparameter tuning in the case of SGD - based optimizers, adaptive optimizers tend to lag behind SGD a lot in terms of generalization performance, mainly in the image classification domain. This paper studies the problem of optimizing the loss function of networks trained using gradient descent with Adam optimizers. The main contribution of this paper is to show that optimizing the train loss of Adam with gradient descent causes the network adaptivity to drop as the network's training loss becomes too small, which results in poor generalization. The paper goes on to discuss why this happens and explains how to fix it. The authors then discuss two ways of fixing the problem. The first is to use logits ( logistic regression ) to fix the discrepancy between the output of a network and the training loss of an adaptive optimizer, and the second is to train the network to be more adaptive ( able to move the weights around ) so that the network generalizes better.   Finally, the authors discuss the tradeoff between these two approaches and discuss the advantages and drawbacks of each approach. In the last part of the paper, the main contributions are summarized as follows :   [ 1 ] - The generalization properties of optimizing train loss under gradient descent : the model suffers from the loss loss becoming too small and the adaptivity degrades ( the network loses its ability to escape regions of poor generalisation ) ; [ 2 ] - Adversarial networks suffer from the inability to adaptivizability : the network doesn't learn how to distinguish between states that are dominated by positive and negative states when the network is optimised over."
SP:819df8d847a99f13ed5efdcabae8b464c12b464b,"This paper proposes a method called “ Partial G - CNNs ” to learn equivariant symmetries using a restricted form of the Natural Image Classification Equivariance ( NICE ) framework. The idea is that the NICE framework is able to enforce certain group equivariance in the features that are present in the data, e.g., for rotated MNIST, but is unable to enforce it when non - present. The paper further defines the term “ partial ” as a family of networks that includes the following components :   ( 1 )   * Partially Equivariant Networks : A set of trained network models trained with NICE equivariantly assuming that the features of the target group are invariant against the distribution of the data. These models are then used to estimate the expected value of a feature from the set of data held by the trained network. These estimates are used to compute an EMA that is applied to the training set of the network to obtain the final trained model. The EMA is trained with the objective to obtain a model that maximizes the mutual information between the features and the network ’s representations. ( 2 ) * Partial NICE : A family of trained partial NICE network models is then trained to approximate the full NICE model using only some of the obtained EMA, and is allowed to use the rest of the EMA when it is necessary. The training set is re - trained using the other models “ fully ”.   The paper tests the effectiveness of the proposed method on 5 different types of synthetic datasets, ranging from MNIST images ( up to 100 Minspectors ) to the full dataset ( 200 M images ). The experiments show that NICE models perform on par or slightly worse than G-CNNs when NICE is used, and that G -CNNs perform slightly better when full NIE is used. The method is evaluated on 5 synthetic datasets and 5 real datasets, and compared to 4 non - synthetic datasets. The main differences between NICE and partial G - NICE are : 1 ) NICE trains the models to respect only some group EMA and not all the group symmetrie, which results in weaker performance ; 2 ) In particular datasets, the partial models perform slightly worse when the group EMI is larger or smaller."
SP:0c0ca9df96f1fa2eb8b83a47d0d5964590fef290,"This paper proposes a new deep latent variable model based on amortized Langevin dynamics ( ALD ). Unlike MCMC, where the datapoint - wise MCMC iterations are used for MCMC updates, ALD updates are based on an inference model that maps observations into latent variables. The main advantage of ALD over MCMC is that it enables scalable inference from large - scale datasets. The authors prove that ALD has the target posterior as a stationary distribution under some assumptions, enabling more flexible generative modeling by applying it to the prior distribution of the latent variable. Based on the insights from ALD, the authors propose LAE ( Laplace Autoencoder 1 ), which is similar to ALD but uses ALD for inference and sampling from the latent space EBM. LAE is evaluated on image generation tasks ( SVHN, CIFAR - 10, CelebA - HQ ) and compared with AVI - based methods. It is shown that LAE generates better samples in terms of Fréchet Inception Distance ( FID ) than AVI and converges faster than traditional MCMC methods."
SP:5631097031c7e599bdeae64366ffa6e4558837c6,"This paper proposes Sparse and Local Neural Logic Machines ( SpaLoc ), a structured neural network for hypergraph reasoning. The main idea of SpaLoc is to use the sparse tensors in hypergraph neural networks to represent the grounding of parent and grandparent relationships such as sparse tensor. To leverage the sparsity, the authors propose a novel sampling and label calibration paradigm based on an information - theoretic measure information sufficiency. The authors further introduce a sparsification loss to regularize the number of spars that are used to infer new facts based on the input facts.   The paper shows superior accuracy and efficiency on synthetic datasets compared with prior art and achieves state - of - the - art performance on several real - world knowledge graph reasoning benchmarks. However, there are still several open questions regarding the submission, e.g., what are the limitations of the proposed method and how do the authors intend to address them? The authors have not addressed these questions in the paper, and I have not been able to obtain a reply from the authors. I would like to thank the authors for taking the time to discuss the paper and provide my feedback."
SP:9657121b01c51f78c00d06b47d3e8d678dd85d54,"This paper proposes to relax the assumption that top - k classification accuracy is a function of log - likelihood, where k is assumed to be a positive integer such as 1, 5 or 7. This assumption is made in light of recent advances in differentiable sorting and ranking, e.g., differentiable classification loss. Based on this assumption, the authors propose to draw k from a probability distribution for training classification models, and use it as the basis for differentiable top k classification losses. They show that relaxing this assumption leads to improved top - 1 accuracy and better top - 5 accuracy with ImageNet models trained on ImageNet with a new state - of - the - art $ \epsilon$-1 accuracy of $ 88.37 $ ( for publicly available models with an $ \eps of $ 1 $ and $ 98.68 $ for models up to $ 5 $ with an average of $ 2 $ per class. They also show that top k loss with $ k$ is also more robust to perturbations in the training distribution, which leads to higher accuracy in the top 1 accuracy case.   The main contributions of this paper are the following :   1 ) The authors relax the top k assumption in the framework of machine learning, and propose a new $ k-based classification loss based on k - probability distribution. This is in line with previous work. 2 ) They propose to use k from the probability distribution to train top k cross entropy - based models. 3 ) They use ImageNet as a base network to train these models."
SP:cb3188f435c54a365890e20e4d582c250d919833,"This paper proposes a method for solving large - scale optimal transport ( OT ) problems at an unprecedented combination of speed and accuracy. The method builds on the celebrated Douglas - Rachford splitting ( DR ) technique to solve the original OT problem directly instead of solving an approximate regularized problem, as many state - of - the - art techniques do. The proposed method enjoys an iteration complexity O(1 / O(\sqrt{O(1/2}) ) compared to the best - known O(O(2/1 ) of the Sinkhorn method. In addition, the authors establish a linear convergence rate for the formulation of the OT problem. The experiments demonstrate the effectiveness of the proposed method, both in terms of terms of computation times and robustness.   The main contributions of this paper are the following :   1. The authors develop a method that maintains a sparse transport plan with a linear - descent - based regularization that allows them to provide sparse transport plans and avoid numerical issues of methods that use entropic regularization. 2. The algorithm has the same cost per iteration as that of the popular Sink horn method, and each iteration can be executed efficiently, in parallel, as opposed to iteratively updating the transport plan for each iteration. 3. A series of experiments are performed to validate the efficacy of the method."
SP:9a087cc734a3e7f3ab848bef5e2eff37fe40f303,"This paper proposes a framework for disentangling performance gaps in generalization studies in federated learning. The framework is based on the idea that clients are drawn from a meta - distribution, and their data is drawn from local data distributions. The main contribution of the paper is the introduction of the concept of out - of - sample gap ( OOD gap ) to disentangle performance gaps between client data and data drawn from unseen client distributions ( participation gap ). This concept is further formalized in the paper as a KL divergence between client - data ELBO and data - client ELBO. Using the framework, the authors propose a dataset synthesis strategy for realistic simulations of generalization in Federated Learning. Specifically, they propose a semantic synthesis strategy that enables realistic simulation without naturally - partitioned data. Based on the findings of the presented work, they call out community suggestions for future Federated learning works.   The main contributions of this paper are as follows :   1. The authors introduce a framework that disentangles performance gaps from client data in generalized learning. This framework is referred to as the KL divergence. 2. It defines the difference between client and data performance gaps using the Latent KL divergence ( KL divergence ). 3. It introduces a term that refers to the difference in client performance between data and unseen client data when the data is from the client distribution but the client data is not available to the public. 4. It uses the term Participation Gap ( PGA ) to refer to the performance gap between data that is present in the public distribution but not the client distributions and which is caused by differences in the client and the public distributions."
SP:da0e8c89f343abfe500eb4c1968e418c2fb52ef6,"This paper studies few - shot prompt - based learning with pre - trained language model language models ( PLMs ). The authors observe that the performance of PLMs with few - shots prompts ( as defined in the paper ) on the GLUE and GLUE tasks is comparable to the state - of - the - art prompt learning approaches ( e.g., GLUE - GA with supervised learning and PLMs - with - no - prompting ) on standard few shot tasks. However, they observe that PLMs perform worse on the zero - shot tasks, particularly for the language understanding tasks, and propose to further study the potential and limitations of using PLMs for the zero shot setting.   To conduct the study, the authors utilize 3 models from the most popular BERT family to study the empirical study on 20 different datasets. They are surprised to find that a simple Multi - Null Prompting ( without manually /automatically created prompts ) strategy can yield promising results on the IMDB dataset, and 86.22%(±2.71 ) accuracy on the Amazon dataset, which outperforms manually created prompts without engineering in achieving much better and stable performance. On the other hand, PLMs exhibit some limitations of their performance, particularly when used with GLUE, as indicated by the limitations noted above. To address these limitations, they propose to conduct a further study to explore the maximum and minimum query length of the trained language models with zero - shots prompt learning, and conduct an empirical study to evaluate the model capacity and the model's generalization ability on the tasks. The paper is well - written ( Appendix B, which contains all the experimental results from the paper, and the authors have access to all the source code and supplementary material. The manuscript is also well written and well structured. The only downside is that the text is hard to read, and most of the questions and comments are vague and difficult to understand. The high level goal of the paper is good but the limited scope of the experiments is also a cause for concern."
SP:9817dccb1a121058b23a2ef825ed339cf8b53674,"This paper proposes a new attention mechanism, Attention Mechanism with Target Sharpened Attention ( TAD ), to align relevant parts of the encoded image with the target output. Traditionally, the main reason for using attention is to align the features that are most likely to correspond to the target in the input image through the attention mechanism and the relevant parts that are not the target are difficult to align. This paper proposes to do this by using a target - specific attention module that is trained to be soft - and - hard - attention. The attention module consists of a target selector, a target embedding, a region selector, and a target encoder. The target selector is trained first to extract the target embeddings from the input and then to refine the embedding using a soft - attention layer to be more specific about the target. This refined embedding is then fed into the attention module to get the target specific attention.   The main contributions of this paper are the following :   ( 1 ) A new attention module with target selector and region selector. This module is trained with soft and hard attention. ( 2 ) A set of experiments on synthetic handwritten digits and real - world scene text recognition datasets show that TAD outperforms the mainstream ones such as Soft - Attention and Hard - Attention. ( 3 ) A series of ablation studies are performed to evaluate the effectiveness of the proposed attention module."
SP:3913ed3b3cf6494368e3be6cacb637ff85f80ee6,"This paper proposes a method for learning to solve combinatorial vehicle routing problems, such as the vehicle routing problem, using deep reinforcement learning ( RL ) based approaches. The RL - based approaches either improve an initially given solution iteratively or construct a set of individual tours from scratch, and are limited by a fixed number of vehicles. The authors argue that this makes them less suitable for real applications, as many logistic service providers rely on solutions provided for a specific bounded fleet size and cannot accommodate short term changes in the number of vehicle. In contrast, the authors propose a powerful supervised deep learning framework that constructs a complete tour plan from scratch while respecting an apriori fixed number   of available vehicles. In combination with an efficient post - processing scheme, the supervised approach is able to obtain a tour plan that is not only much faster and easier to train but also achieves competitive results that incorporate the practical aspect of the vehicle costs.   The main contributions of the paper are the following :   ( 1 ) The authors propose an approach to learn a complete vehicle routing plan using RL based on a customer's assignment of the vehicles to routes, and thus bypass the complex assignment problem of the customers onto an given number of available routes ; ( 2 ) The method is compared with a method based on RL, a heuristic - based method, and a classical operations research solver. The results show that the proposed method is more competitive than the classical method in terms of time and cost, with the latter being slightly faster in the sense that it achieves the goal of reducing the total number of turns required to learn the route from scratch ; ( 3 ) It also shows that it is more robust than the heuristic method when it comes to handling unsupervised learning - based route assignments ; and ( 4 ) It sheds some light on existent inconsistencies in the experimentation protocols of the related work that the authors do not disclose."
SP:594a813c0d0baa66738b9c8331370f861ad3c416,"This work proposes a novel link prediction method that enhances graph learning by counterfactual inference. The proposed method is based on the observation of missing links between two nodes and the possibility of learning the causal relationship between two variables : the observed graph structure ( e.g. node structure and node properties ) and the existence of link between a pair of nodes. The nodes are nodes that were included in a graph representation ( learned graph representations ) that were used to predict the node structure from the learned graph representation and the node properties from the graph structural properties. The node representation was used for prediction and the graph structures were used for the learning of the causal connection between the node structures. The experiments show that the proposed method achieves better performance than the state - of - the - art methods on link prediction on both observed and missing link prediction tasks.   The main contributions of this work are the following :   1. The authors propose to learn the link between two sets of variables : ( 1 ) the observation graph structure of nodes and ( 2 ) the link that was observed between nodes. This is done by using the following steps : 1. In the first step, the authors use the observation from node representation and node structure as input variables to train a causal model. The second step trains the causal model using the node representation as input and global graph properties as output variables. The causal model is used to estimate the likelihood that the link exists and the probability that it would be present in the future given the same node structure ( assuming that node structures and graph properties remain the same ). The prediction is made using the observation data and node representations. 2. The method is tested on both synthetic and real datasets and achieves the best performance on the synthetic datasets for link prediction, beating the state-of-the - of the art methods in terms of observed link prediction as well as the likelihood of link occurrence."
SP:48a7e50451b887f55be17b2662aa11ce18791cc1,"This paper proposes a two - stage Second - order unsupervised feature selection via knowledge contrastive disTillation ( SOFT ) model that incorporates the second - order covariance matrix with the first - order data matrix for feature selection in the first stage. In the second stage, the authors learn a sparse attention matrix that can represent second order relations between features in the sparse attention network. The authors also propose to build a relational graph based on the learned attention matrix and perform graph segmentation to estimate feature selection error using the information from the first and second order matrices. The experimental results on 12 public datasets show that SOFT outperforms other unsuper supervised feature selection methods on both classical and recent state - of - the - art visualizations.   The main contributions of this paper are the following :   1 ) The authors propose a 2 - stage SOFT model that consists of two stages. The first stage learns a sparse covariance matrices to represent the second order relation between features. The second stage builds a sparse relational graph to estimate the feature extraction error from the learned matrices using the learned information. This information is used to perform feature selection for downstream tasks using the original features and the features from the subset that was selected for the downstream task using the features estimated from the sparse matrix. The author conducts experiments on 5 datasets to investigate the performance of the method. The experiments show that the SOFT method outperforms the competing methods on 4 out of 5 downstream tasks, and the relational graph used for the feature selection is the best of the other methods on 2 datasets, followed by another 2 methods for 2 downstream tasks that use the learned graph for the graph extraction and a data augmentation method for the 3rd dataset. On the 5 datasets, the SOFAE and SOFT2ST are the only two methods compared. The other 2 methods are used to train the 4 datasets for the 2nd stage of SOFT and are not compared to SOFT1. Overall, the experimental results demonstrate the effectiveness of the proposed SOFT methods."
SP:14bcae11aeede63f28d1b80c05ed18a01d3e3f3c,"This paper proposes a new multimodal generative model based on semisupervised generative models for the joint distribution over heterogeneous data ( e.g. vision, language, language ) over modalities. The authors propose a novel formulation of the model, which they call Mutually supErvised Multimodel VAE ( MEME ), that avoids explicit combinations of VAEs by repurposing semi - supervised VAEs to combine information between modalities implicitly through mutual supervision. This formulation naturally allows learning from partially - observed data where some modalities can be entirely missing — something that most existing VAE approaches either cannot handle or do so to a limited extent. They propose MEME as a way to avoid such explicit combinations and to use VAEs that do so implicitly through supervision. They study the empirical performance of MEME on standard metrics across both partial and complete observation schemes on the MNIST - SVHN and CUB datasets. They also contrast the quality of the representations learnt by mutual supervision against standard approaches and observe interesting trends in its ability to capture relatedness between data.    The main contributions of this paper are the following :   1. A new generative framework for the multivariate VAE, called MEME, is proposed. It replaces the vanilla VAE and its implicit supervision by a more sophisticated formulation that explicitly supervises the representation of the modalities in the implicit VAE. This allows the learned representation to capture a shared representation across modalities that can be leveraged to learn from some of the missing data. 2. A series of experiments compare the performance of the MEME with other VAE baselines, showing that MEME performs better on some metrics than other baselines and worse on other metrics. 3. They conduct some ablation studies to validate their method."
SP:e834a52cadebe5f125ce491273b4ad1146beae3f,"This paper proposes revising Explore Options within the Deep Reinforcement Learning paradigm to tackle complex visual problems. In particular, it proposes Deep Explore Options to learn from multiple intrinsic rewards and ignore harmful intrinsic rewards, and to learn to balance exploration and intrinsic rewards. In order to achieve this, it first introduces J - PER, a new transition - selection algorithm based on the interest of multiple agents, and with a resulting architecture achieving 50% faster wall - clock speed and building a stronger building block. The authors also conduct a series of experiments to validate the effectiveness of their method, including ( 1 ) hard and easy exploration games of the Atari Suite, ( 2 ) a benchmarking study to ensure fairness, and ( 3 ) a set of experiments with simulated rewards from DeepExplore. The experiments show that DeepExplore outperforms DeepExplore and other reward - maximizing methods such as a weighted sum of rewards ( which is the norm in RL ) in most of the environments. In addition, DeepExplore can learn to isolate exploitative or exploratory behaviors, which the authors claim is the main drawback of using intrinsic reward learning as an auxiliary task in RL."
SP:41578dd1a4bdb043b3d68afa5f9cebb3e14f3907,"This paper proposes a new method ( SANN ) for learning Hamiltonian dynamical systems from data. SANN splits the training data into stiff and nonstiff portions based on a stiffness - aware index, a metric introduced to quantify the stiffness of the dynamical system. The authors evaluate SANN on complex physical systems including a three - body problem and billiard model. They show that SANN is more stable and can better preserve energy when compared with the state - of - the - art methods, leading to significant improvement in accuracy."
SP:bfb0a059eeb6f40a18fbd20c0eec5037a64ca09e,"This paper studies the problem of enabling large pre - trained language models to perform complex multistep computations, such as generating realistic text, synthesizing computer programs, or executing arbitrary programs. The authors compare the performance of the language models with the Transformer model on tasks that can be done “in one pass ” ( e.g. adding an integer to a set of variables, or generating a program from scratch from scratch ) versus tasks that require unbounded multi - step computations. The main contributions of the paper are three - folds :   ( 1 ) This paper trains Transformer models to be able to generate computations that are shown to be more complex than those generated by the previous generation of language models using the few - shot method ( Chen et al., 2021 ), and ( 2 ) this paper trains Transformers to generate complex computations by giving them intermediate steps to follow when generating the outputs of the original program.    The main contribution of this paper is the introduction of a series of experiments where the authors first train the models on the task of generating programs from scratch, and then train them to generate intermediate computations steps from those generated programs using the learned intermediate steps. The goal is to encourage the models to learn how to generate programs that are robust to multiple gradients of the input. The experiments compare the performances of the models ( on the synthesizing, adding integers, and synthesizing programs ) compared to the ones trained on the one - pass setting, where the models are trained to generate the input by generating intermediate steps of the program. On the synthesized programs, the authors show that the models perform significantly worse than the prior generation models, and that the Transformers perform significantly better than the previous generations of models on most of the tasks. They also show that training the Transformers on intermediate steps significantly improves the performance on some of the more complex tasks. On two tasks where the model is asked to generate arbitrary programs ( adding a pair of numbers, or synthesizing a program, and executing a binary digits ), the models fail to perform as well as the prior generations, and the authors argue that this is because the overhead from generating arbitrary programs is often much higher and the overhead is often larger for the Transformers than it is for the non - transformer models. On one of these tasks the models fails to generate enough intermediate steps for the program to be shown the output of an arbitrary program ( adding two numbers or generating the values of a binary binary program ), while the other model produces enough output to justify the difference between the output and the estimated value. On another task where the number of intermediate steps is too low ( adding pairs of digits or generating binary programs ) the models struggle to generate a program that matches the output. On this task the authors suggest training the models in a way that leads the model to generate more intermediate steps rather than generate an output that is closer to the output than the highest level of abstraction, which leads to a loss that the model does not learn the intermediate steps from the intermediate representation. The models fail on this task more often than not, leading to a tradeoff between performance and learning. The major contributions of this work are two steps : 1 ) the authors propose a method where the pretrained language models are encouraged to generate lower level intermediate steps in order to improve the performance ( instead of generating lower level representations of the output from the generative model ) and 2 ) a way to train the Transformers in a similar way so that the authors do not have to generate high level representations for each intermediate step. This approach is less exploratory and more likely to lead to bottlenecks that the neural network will not learn all intermediate steps"
SP:e6c1a8b4bba287455dc9cf145b6bd1f04e2148a9,"This paper proposes a novel technique to generate feature - level adversarial attacks at the ImageNet scale that are simultaneously interpretable, universal to any source image, and physically - realizable. The technique is based on the idea that feature - class associations in neural networks are semantically - plausible feature / class associations that can be exploited by novel combinations of natural objects. To generate feature level attacks that are universal to all source image features and can reveal the most plausible feature associations, the authors propose to use a feature fool generator and a feature augmentation algorithm. The authors demonstrate that the feature fool attack generates attacks that can reveal spurious feature associations that are difficult / impossible to distinguish from natural ones. The author also proposes a new objective that is used to estimate the likelihood of a feature from an input image that is likely to be seen by an adversarial attack and uses this estimate to design the perturbation that would make the target most likely to see the feature from the input image. The proposed feature fool algorithm is validated on ImageNet by generating feature fountains from source and target images using the same generator. The method is shown to outperform the original ImageNet - based method as well as other adversarial methods."
SP:873618263dc4246a39c44d0abfecfb5f688817e3,"This paper proposes a new approach to the problem of global optimisation of stochastic annealing ( SA ), where the objective is to find a solution to a global optimization problem that maximises a set of controllable parameters, i.e., the parameters that ensure that the optimizer is robust to changes in these variables over the course of the problem. This approach relies on two components : Neighbour proposal distribution ( PPD ), which is used to predict the probability that a given proposal will be most likely to result in a solution for a particular problem and is used as a tool to learn a policy distribution that maximizes the probability of the proposal being a solution. The paper proposes to use this PPD in conjunction with a reinforcement learning approach ( RL - based approach ) to develop a new SA solver, called Neural SA, that learns the PPD distribution over the set of proposed solutions to global optimization problems based on a reinforcement - learning approach.   The paper shows that using PPD and a learnt policy distribution for the proposed solutions, Neural SA outperforms SA solvers that do not use PPD with hand - selected parameters on a number of problems, including Rosenbrock ’s function, the Knapsack problem, the Bin Packing problem, and the Travelling Salesperson problem. They also show that Neural SA scales well to large problems while again outperforming popular off - the - shelf solutions with PPD. The main contributions of the paper are two aspects of the approach. The first is the use of reinforcement learning to learn the neighbourhood distribution for PPD using a learned policy, while the second is the reinforcement learning of the temperature schedule to choose the final solution temperature in order to optimise the solution quality. The experiments compare the proposed approach to standard global optimizers and Neural SA with PDP."
SP:cae31f7436920eb3946e3f5bca0ac88a73d7c3ec,"This paper studies multi - agent reinforcement learning ( MARL ) and the non - stationarity problem. The authors propose the joint policies ’ divergence ( KL divergence ) estimator to measure the distance between two sets of joint policies in MARL. The divergence can be estimated using the KL divergence of consecutive joint policies. To control the divergence, the authors propose TRD - net ( TR - agent mirror descent policy algorithm ). The algorithm is based on MAMT ( Multi - Agent Mirror descent algorithm with Trust Region decomposition ). In the experiments, the method achieves better performance than baselines MARL method. The method is validated on MNIST and CIFAR10."
SP:989b58167a15ae4fafbe27ff534d327991b6c4d7,"This paper presents a self - supervised representation learning framework for audio - visual speech, dubbed Audio - Visual Hidden Unit BERT ( AV - HuBERT ), which masks multi - stream video input and predicts automatically discovered and iteratively refined multimodal hidden units for speech representation learning from the speaker ’s lip movements and the produced sound. The main contributions are :   ( 1 ) A new multi - modal hidden unit learning framework, dubbed as Audio - visual hidden unit BERT, is proposed that learns hidden units from speaker's lips and audio. ( 2 ) A fine - grained pretraining method is used to train the hidden unit generator, which is trained with a thousand times more transcribed video data. ( 3 ) The method is compared with the state - of - the - art WER method ( Wang et al., 2021 ) on the same benchmark, where audio - only speech recognition leads to a 40 % WER reduction over the WER with only 30 hours of labeled data, while the proposed method leads to an impressive 32.5% WER using the same amount of data ( 433 hours ). ( 4 ) The experimental results demonstrate that the approach outperforms the former state - $6.6$ approach by a significant margin, and the performance is comparable to that of WER trained with much more labeled data ( 1.3% vs. 2.3%).    The main contribution of this paper is the introduction of a multi - parametrized learning framework that learns from speaker ‘s lip and produced sound to produce a powerful speech representation representation, which can be used for both speech representation and automatic speech recognition. The method has the potential to benefit both lip - reading comprehension and automatic recognition tasks."
SP:7c9eb8aa4a4dcb5965157d860e812d81654e3aa7,"This paper proposes ECORD, a new algorithm for reinforcement learning ( RL ) based on graph neural networks ( GNNs ). The main idea is to pre - process large graphs ( up to 500 vertices ) before applying RL in a fast - acting exploratory phase directed by a recurrent unit ( RUs ). To make the processing of the graphs efficient, the authors restrict the GNN computation to a single pre - processing step ( e.g., by only processing graphs with a decreased wall -clock time ). They argue that this reduces the need for expensive graph neural network computation at each decision making stage of RL. The authors also propose a new SOTA for RL algorithms based on the Maximum Cut ( MCT ) problem, which allows for scalability improvement in terms of the order of magnitude of improvement in speed and scalability. ECORD is trained with MCTSOTA and evaluated on two datasets, where it is shown to achieve better performance than the state - of - the - art SOTA ( SOTA ) on the maximum cut problem ( Figure 2 ), while achieving comparable performance to SOTA on the reduced optimality gap ( Figure 3 ).   The main contributions of the paper are the following : 1 ) The authors propose a novel algorithm, ECORD ; a novel RL algorithm that pre - processes large graphs before applying RUs at each step of the decision making process 2 ) An improvement in order of increasing the number of vertices of graphs processed by the previous step ( ECORD preprocessing step 3 ) A proof that ECORD achieves a lower MCT error in the same amount of time as SOTA by using a smaller number of preprocessing steps than SOTA steps 3. The experiments are conducted to demonstrate the effectiveness of ECORD."
SP:f741d980c9c560a21298e947f1605dcbab7ceeac,"variational autoencoders ( VAEs ) are non - linear generative models trained with discrete latents. Traditionally, standard VAE training relies on sampling approximation, reparameterization trick and amortization to approximate the true latents, which is expensive and time - consuming. In this paper, the authors sidesteps these mechanisms and instead relies on discrete discrete optimization to train discrete VAEs. The main idea of the paper is to train a discrete auto - encoder with a discrete latent variable distribution, where the latents can be chosen from a set of latent states selected by the decoder. The decoder network is trained via gradient ascent with the help of evolutionary algorithms. The authors evaluate the direct discrete optimization they use for training VAEs using evolutionary algorithms and show that it is competitive in zero - shot learning and denoising, where VAEs are trained on a single image and have no prior training on large image datasets.    The main contributions of this paper are the following : - The authors train VAEs with discrete latent variables, where they do not rely on any of the usual standard training procedures such as sampling approximation and reparametratorization. They show that direct optimization is more efficient and scalable to hundreds of latent variables using smaller networks than it is with large networks. - They find direct optimization to be highly competitive in the regime of few data where VAE - based methods have previously been outperformed by non - generative approaches. - Direct optimization also makes VAEs competitive for denoisings where they have been previously out - of - domain - competitive in non - supervised learning."
SP:deb189d37bd51b92762ce259a106d9a9e9d81ea4,"Controlled Effect Network ( CEN ) is an unsupervised method based on counterfactual measures of blame to identify effects on the environment controlled by the agent. CEN is evaluated in a wide range of environments showing that it can accurately identify controlled effects. Moreover, it demonstrates CEN ’s capabilities as intrinsic motivator by integrating it in the state - of - the - art exploration method, achieving substantially better performance than action - prediction models.   The main contributions of this paper are as follows :   ( 1 ) This paper proposes a new method, CEN, to identify the controlled effects in an actor - critic framework. The idea is that humans assign blame to their actions to decide what they controlled, whereas in the case of reinforcement learning, the agent takes as input the actions of other agents in the environment. The paper proposes to use this mechanism to identify which actions have the most effect on the target domain. The proposed CEN network is designed to be able to identify this controlled effect. ( 2 ) Empirically, this paper shows that CEN can identify more controlled effects than the action - prediction network ( which can only identify actions that have controlled the target domains ), and the control effect network CEN does not discriminate between actions that the agent controls and actions that are the result of actions the agent does not control."
SP:ea18d57904e25fd09ed0f6c9972029d78779a8a6,"This paper proposes structure - regularized pruning ( SRP ), a new model compression method for SR networks. The motivation is that existing SR methods, such as neural architecture search ( NAP ) and knowledge distillation ( DK ), cost too much computation and data processing power, while pruning SR networks is a cheap and effective model compression technique that can be applied directly to reduce computational costs. To address the above issues, this paper proposes SRP, which imposes regularization on the pruned structure to make sure the locations of pruned filters are aligned across different layers. The authors conduct extensive comparisons with both lightweight and larger image SR networks, resulting in a lightweight network SRPN-L and a very deep one SRPN. The main contributions of the paper are the following :   ( 1 ) For the layers connected by the same residual, the authors use the filters of the same indices as unimportant filters to reduce the expressive power in the un - important filters to the rest of the filters in the network, using L2 regularization to drive the weights towards zero so that eventually their absence will cause minimal performance degradation ( in the absence of their absence ). ( 2 ) The authors train efficient image processors to generate lightweight and more efficient image SRP images. ( 3 ) The experiments demonstrate that the proposed SRP method outperforms NAP and DK in terms of both theoretical performance and empirical performance."
SP:0dee45001ae9600f485614dfe6874a516ac01db5,"This paper proposes a novel contrastive learning framework for few - shot learning, ConFeSS ( Contrastive Learning and Feature Selection System ), which tackles the large domain shift between base and novel categories in the few shot learning setting, where most existing methods mostly generalize well on novel categories from the same domain as the base categories but perform poorly for distant domain categories. The proposed framework trains a feature extracting backbone with the contrastive loss on the base category data and a masking module to select relevant features that are more suited to target domain classification. The authors evaluate the effectiveness of the proposed framework on a recently introduced cross - domain few -shot learning learning benchmark and compare it with recent meta - learning approaches and produces competitive results against recent cross - domains methods.    The main contributions of this paper are the following :   - A novel feature extraction backbone is proposed to replace the backbone backbone in the feature extractor method. This backbone can generalize better to distant target domains. - A feature selection strategy is proposed for masking modules to select features ( such that the backbone produces features similar to the relevant ones ) that are helpful for the task at hand. - Experimental results demonstrate that our framework outperforms several recent methods in terms of performance on the target domain with respect to the baseline methods. - The authors conduct a series of ablation studies to better understand the contributions of the features selection strategy and to compare their performance to other methods."
SP:92aa611d71a8da597358330d84fddbb90de2cf4f,"This paper studies the generalisation ability of neural networks with respect to the functions returned by gradient descent applied to the training data via Bayesian inference and gradient descent on finite width neural networks. The authors consider two families of networks, infinite width Gaussian neural networks trained by Bayes inference and finite width gradient descent trained with gradient descent. They compare the generalizability of typical networks with and without gradient descent and find that typical networks fitted to training data already generalise fairly well, and that gradient descent can further improve generalisation by selecting networks with a large margin. This conclusion is supported by a careful study of the behaviour of infinite width networks trained with Bayes in the presence of gradient descent, as well as finite width network trained using gradient descent using gradient ascent. To measure the implicit bias of architecture, new tools are developed that are both analytically bound and consistently estimate the average test error of the neural network–Gaussian process ( NGP ) posterior. This error is found to be already better than chance, corroborating the findings of Valle-Pérez et al. ( 2019 ). Beyond this result, this paper finds that test performance can be substantially improved by selecting a function with much larger margin than is typical under the NNGP posterior. In summary, new technical tools suggest a nuanced portrait of generalisation involving both the implicit biases of architecture and gradient ascent that can generalise well.    The main contributions of this paper are the following :   ( 1 ) A careful study is performed to establish the relationship between the performance of NGP and the architecture of the network it is applied to. This relationship is strengthened by using tools that are able to both analyze both the architecture and the gradient descent process. ( 2 ) Further experiments are conducted to validate the findings and build upon the conclusions of the paper."
SP:a0e3cf719a95bbc5aad2f663ba5a3169c316ee9b,"This paper proposes a new cross - lingual manifold mixup ( X - mixup ) method to improve the transfer performance of target languages from source to target via multilingual text understanding tasks via cross - localization and mapping. The main idea of the method is to use a mixup layer ( layer 2 of the pre - trained multilingual representations ) to approximate the representation discrepancy between source and target text representations in order to mitigate the discrepancy between the source representation and the representations in the target languages. This is motivated by the fact that the source - target discrepancy is higher for languages where the source language is not fully intelligible to the target language ( e.g., when target languages are written in a non - intelligible language such as Russian ). The authors argue that this discrepancy causes the performance gap between source language and target language which is indicative of the gap between rich and poor source representation. They propose to use layer 2 ( layer 3 ) of the post - trained representation from source language to target language to adaptively calibrate the representation discrepancies and give compromised representations for target languages ( layer 4 ) to avoid the high performance gap. Experimental results show that this approach achieves better transfer performance than the baseline method X - Mixup ( Wang et al., 2020 ) on the multiple text understanding task. However, the performance gain is less for the multilingual tasks ( 1.8 % ) compared to the 1.9 % gain achieved by X -Mixup with the base method ( Wang & Tan, 2021 ). They also show that the representation gains are smaller on the multi - language tasks ( 0.7 % ) than for the ones with strong baselines ( 2 % of source language representations ). Overall, the proposed approach seems to outperform the baselines in terms of transfer performance but is less efficient than the base methods ( 1.9 % and 2.0 % )."
SP:19f8cd8f0c274b6141ba097d2ebb6d18af0986fd,"This paper studies the non - iid Byzantine robust problem, where a server has access to data distributed among workers but a fraction deviate from the prescribed algorithm and send arbitrary messages. Traditionally, most current defenses assume that the workers have identical data. This paper proposes a simple bucketing scheme that adapts the existing robust algorithms to heterogeneous datasets at a negligible computational cost. The experiments theoretically and experimentally validate the approach, showing that combining bucketing with existing robust algorithm is effective against challenging attacks.    The main contribution of this paper is the first to establish guaranteed convergence for the bucketing method under realistic assumptions. This work improves the convergence guarantee for the robust algorithm used in the previous work Wu et al. ( 2021 ). The main contributions of this work are the following :   1. The authors propose a new attack that circumventes the existing defenses for the Byzantine robust setting, leading to significant loss of performance. The attack is based on the fact that the data across workers are not iid, whereas the previous defenses assumed iid across all the workers. 2. The data used for the attack is heterogeneous, meaning that it is possible for the attacker to obtain iid only for a small fraction of the workers ( as is the case in the case of uniform federated learning ). 3. The method is applied to train a machine learning model over data distributed across multiple workers, where the model is trained from scratch using the parameters obtained from each worker. The training is stopped when the model receives too many messages from a particular worker ( i.e., when all workers start sending the same messages from the same batch ). 4. The dataset is partitioned into two subsets, where each dataset contains data for a different subset of workers ( e.g., if the dataset belongs to a pre - trained set and if it belongs to an randomly initialized set, then the data is not used in training. 5. The algorithm is used to train the model for the first sub dataset ( for the pretrained set ) and the data for the second dataset is generated from the original dataset with the data from the randomly initialized workers ( if the data belong to the pre - train set then the model does not change much during training."
SP:4d63513b9a1b9b9fc44a69b3d5679a8f48eb95e7,"This paper studies the role of disentanglement in multi - task learning in the context of deep neural network training for tasks with hard parameter sharing. Multi - task training is a special case of supervised learning, where the goal is to train a neural network that learns jointly on several tasks that are automatically generated by a teacher using a disentangled set of parameters. Traditionally, the task - agnostic approach is used to train the network first on the hard - parameter - sharing task and then fine - tune the network on the remaining tasks based on the learned parameters. The trained network is assumed to be robust to perturbations that occur during the fine - tuning process. The main contribution of the paper is a study of the representations obtained by the network trained to learn the parameters from the teacher on the tasks. The authors compare the representation obtained by a fully - connected network trained on the task with a network that is partially - connected to a task that is not connected to the task at hand, and trained using supervised learning. The results show that the representation of the fully connected network is similar to that of a network trained only on one task and that it is more similar to a network training on multiple tasks using the same parameters. This is consistent with previous work that has seen this model applied to training neural networks for tasks generated from a teacher - student model. However, it is important to distinguish between the two sets of results as the authors note that the results obtained in the first study are not necessarily indicative of generalization to unseen tasks in the second study. In addition, the authors also study the effect of learning rates of learning rate on the number of tasks and the average learning rate of the network."
SP:9851adb72e2918780f661f83f7da06eb866787be,"This paper proposes CROP, a framework of robustness certifications for reinforcement learning ( RL ) against adversarial state perturbations ( state level robustness ), and CROP - cumulative rewards ( cumulative rewards robustness certification ). CROP is based on two components. First, it proposes a local smoothing algorithm to guarantee the robustness of per - state actions under the lower bound of the cumulative rewards. Second, it develops a global smoothing method for certifying $ \ell_\alpha$-regularized cumulative rewards under $ \epsilon$- perturbed state. Third, it introduces a local - smoothing approach that makes use of adaptive search in order to obtain tight bounds for the reward distribution. The authors evaluate CROP using adversarial training and several forms of regularization on three representative Atari games, and show that the proposed methods achieve high certified robustness. In addition, they demonstrate that under the same set of adversarial attacks, the proposed algorithms achieve certifications with tight bounds.   The main contributions of this paper are the following :    1. The proposed CROP framework is used to develop a robustness certificate for the following types of reinforcement learning games : $ Q_\theta$, where $ Q$ is a set of state - action trajectories obtained through reinforcement learning with the help of a policy that is smoothed with Gaussian noise over each encountered state. This allows to obtain state - level and first - level certifications of the $ \theta$. The second type of certifications is for cumulative rewards, where the policy is a finite - horizon collection of actions distributed over a finite horizon. This set of states is obtained by applying the smoothed policy to the cumulative reward distribution, and the third type of certification is for the finite horizon collection that is the average of the actions across all states involved in the set of cumulative rewards that were distributed using the policy that was used to obtain the policy in the first place. The method is evaluated using three games of Atari. The experiments compare the proposed method with two methods that have been shown to yield more robust certifications : one using the method proposed in [ 1 ], and another using methods from [ 2 ]."
SP:78da3c97182ec1baf6a131740bf7c91a9afb2fd2,"This paper proposes a novel approach to the conformal prediction setting, in which a set of prediction candidates is constructed from a limited number of incorrect answers. Standard conformal sets have the property that they can not be flooded with noisy candidates, which renders them unhelpful in practice. This is particularly relevant to large - scale settings where the cost (monetary or otherwise ) of false positives is substantial, such as in - screening for drug discovery, where any positively identified molecular compound is then manufactured and tested.   The authors propose to trade coverage for precision by enforcing that the presence of incorrect candidates in the predicted set is bounded according to a user -specified tolerance. Under the constraint of this constraint, the authors then optimizes for a generalized notion of set coverage ( the true positive rate ) that allows for any number of true answers for a given query ( including zero ) that is greater than the maximum allowed for false positives under the condition that the set contains the correct answer with high probability. The authors then experimentally evaluate the effectiveness of this approach across a number of classification tasks in natural language processing, computer vision, and computational chemistry."
SP:b126d2f3c397633745c8833e22ace93a2470e963,"This paper studies the expected distortion of a unit - length function taken as input by a neural network when considering the complexity of functions computed by the network. The authors first consider ReLU networks, a general class of neural networks that takes a length - based function as input and outputs a set of output functions based on the length of the input function. They use the expected length as a measure of how well the network is able to handle the distorting effects of the function. In this paper, the authors first study the ReLU network with a standard random initialization of the network, and use this to obtain a parametrization of expected distortion. They then generalize this result to other types of distorts, such as the distortion of higher - dimensional volumes, and obtain upper bounds. The theoretical results are corroborated by experiments on MNIST and CIFAR-10."
SP:b3b6d0512edfca461ea295ee8665f7f226c45d57,"This paper proposes SAFER ( SAFEty skill pRiors ), a behavioral prior learning algorithm that accelerates policy learning on complex control tasks, under safety constraints and with limited rewards. The algorithm is motivated by the observation that behavioral priors, which extract useful policy primitives for learning from offline datasets, have recently shown considerable promise at accelerating RL in more complex problems. In SAFER training on safe and unsafe data, SAFER learns to extract a safety variable from offline data that encodes safety requirements, as well as the safe primitive skills over abstract actions in different scenarios. In the inference stage, a safe and successful policy from the safety skills according to the inferred safety variable and abstract action is learned. The method is evaluated on several complex safety - critical robotic grasping tasks inspired by the game Operation,1 in which SAFER outperforms baseline methods in learning successful policies and enforcing safety."
SP:a5dadb3ecc3caed3b9d9a68eda0d48a53c2d1ce2,"This paper proposes a learning based restoration method based on the Human Visual System ( HVSS ). The main contribution is a multi - chan neural network architecture that can handle multiple degradation types ( e.g. image degradation, deblurring, dehazing, and image drop ) that are commonly used in self - supervised learning for image restoration in autonomous cars. The architecture is inspired from the Retinal Ganglion Cells ( RGC ), which is used to train an encoder - decoder network in an autoencoder setup. The authors propose three tasks : image restoration, image augmentation, and semantic segmentation. The three tasks are combined into a single task ( image restoration ) where the encoder is trained to reconstruct the original image and the decoder to predict the degraded image from the reconstructed image. The encoder can then be trained to predict a corresponding semantic feature from each semantic feature using the learned encoder. The decoder can be used to predict features from multiple semantic features from the same image.   Experimental results on four datasets are provided to evaluate the performance of the proposed method, CMFNet, on tasks such as image restoration ( Dehazing ), image enhancement ( DerainDrop ), semantic segmentations ( Deblurring ), and depth estimation ( ImageNet ). Results show that the proposed model performs better than baselines that only consider one degradation type ( Image2vec ) and three datasets ( Image3vec, deraindrop, and ImageNet - E - ECE ) across all degradation types. The method is evaluated on the three datasets and applied to three image restoration tasks, where it scores slightly worse than the baselines in terms of accuracy ( i.e., image2vec, image-epsilon, image - denoising ). In the experiments, the authors demonstrate that the model outperforms baselines and baselines on Image3 Veca, ImageNet-E, and MS - E, and DepthSeg."
SP:263b386beee44b0b45b6f6dc3cf80d020500be62,"In this paper, the authors propose a new federated learning setup, called Inference - Time PFL ( IT - PFL ), where a model trained on a set of clients is evaluated on novel unlabeled clients at inference time, and referred to as novel PFL - HN. The novel clients do not contribute their data to training and thus the authors argue that they can have better data privacy if they choose to participate in the evaluation process of the proposed method. The proposed method is based on a hypernetwork module and an encoder that learns a representation for a client that is fed to a hyper - network that generates a personalized model for that client. The authors evaluate on four benchmark datasets, showing that it generalizes better than previous FL and PFL methods, especially when the novel client has a large domain - free domain ( e.g., multi - task learning, domain adaptation ). They also analyze the generalization error for the novel clients and show how it can be bounded using results from multi -task learning and domain adaptation."
SP:960d0a63a82593f6e72275b65f0501f0469d1924,"This paper proposes the use of the conditional diffusion based generative model ( RCDM ) to visualize representations learned with self - supervised learning ( SSL ). The model is a conditional generative algorithm trained on top of a pre - trained SSL representation. The authors propose to use this model to analyze the representation learned with SSL. They show that the learned representation is not invariant to many data augmentation they were trained on. The main contribution of this work is to develop a new tool, the RCDM, to analyze representations learned from SSL with a discriminative model. The analysis is done using a conditional version of the MLP ( MLP + SSL ) conditional diffusion model, which is based on the same underlying SSL representation as the one used in the training of the SSL model. Using this model, the authors show that a representation trained with SSL is as good as one trained with a state - of - the - art generative modeling ( SOTA ) model, while being faithful to the SSL representation used as conditioning. They also show that SSL representations trained with the new model are more robust to small perturbations than those trained with SOTA."
SP:398899e6c86b4a2a17dfa5c2f4478811f4331c1d,"This paper presents Fp sketch, a well - celebratedbrated streaming algorithm for frequency moments estimation ( FPM estimation is differentially private as is when p \in [ 0, 1 ] is considered a threshold. The paper presents an evaluation code of Fp Sketch, showing that it is exponentially better than existing DP baselines, only worse than the optimal non - private baseline by a logarithmic factor. The main contribution of this paper is to provide the evaluation code that is used in the supplementary material.   The main claim of the paper is as follows :   1. The authors use the Fp algorithm to estimate the frequency of a given event p ( i.e., the time when the event occurred ) in a stochastic Gradient Process ( SDP ). The algorithm is trained using FPs that start from a fixed point and iteratively iterate through all possible permutations of the event p. This process is referred to as iterative training. 2. The resulting sketch p(s ) is then used to compute the expected value of an event ( e.g., when p is sampled from time t, t’s ) at a particular time t. The goal is to arrive at an estimate of the probability that an event occurred at a given time t. 3. The exact timestep of the iterated process is set using a distribution over timesteps of t. 4. The evaluation shows that the resulting estimator is as good as the SDP baselines and slightly better ( on average ) than the FPM baselines that are not parametrized by a parametrization of the time parameter p ( as is the case with SDP and FPM )."
SP:3253b13851b5a3b5e3c8c6e24891db05903a4e57,"The paper proposes Reward - Switching Policy Optimization ( RSPO ), a method that leverages novelty measurement in policy optimization to encourage learning towards an undiscovered local optimum that is both locally optimal and different from existing policies. The motivation is to find policies that are sufficiently different from the existing policies to encourage exploration in order to discover novel strategies in complex RL environments. The method is composed of two components : novelty policy optimization ( PPO ) and reward optimization ( RL policy gradient ). PPO optimizes a set of policies on trajectories sampled from a continuous control game, MuJoCo continuous control task, and multi - agent stag - hunt game using PPO and rewards that are defined using a mixture of intrinsic rewards and extrinsic rewards. The novelty reward is defined by adding a novelty component to the PPO reward when the likelihood under the policies is high. The policy gradient is used to optimize the policy gradient using the intrinsic reward and the novelty policy in PPO. The paper presents experiments that compare the performance of PPO ( with intrinsic rewards ) and PPO + intrinsic policy optimization on a variety of tasks ranging from single agent particle - world tasks to multi agent staghunt games. The results demonstrate that PPO is more robust than PPO in terms of diversity of policies found compared to the intrinsic policy reward and policy gradient. The experiments also demonstrate that the novelty reward encourages exploration in a wide spectrum of strategies across multiple domains."
SP:e3ab3aa87ab023bd9949b99a17d4b6e26c1473c0,"Diffusion models have emerged as an expressive family of generative models rivaling GANs in sample quality and autoregressive models in likelihood scores. Standard diffusion models typically require hundreds of forward passes through the model to generate a single high - fidelity sample. This paper introduces Differentiable Diffusion Sampler Search ( DDSS ) : a method that optimizes fast samplers for any pre - trained diffusion model by differentiating through sample quality scores.   The main contribution of this paper is the introduction of the Generalized Gaussian Diffusion Models ( GGDM ), a new flexible non - Markovian sampler for diffusion models. The authors show that optimizing the degrees of freedom of GGDM by maximizing sample quality score via gradient descent leads to improved sample quality on various datasets. The method is backpropagated through the sampling process using the reparametrization trick and gradient rematerialization. The experimental results demonstrate the effectiveness of the method on unconditional image generation across various datasets (e.g., FID scores on LSUN 128x128 of 116 with only 10 inference steps, and 4.82 with 20 steps, compared to 511 and 14.9 with strongest DDPM / DDIM baselines )."
SP:7a7506f2b5500a573c0cfb8b0822e5ea725c886a,"This paper proposes P - Adapters, a new approach to query large language models ( LLMs ) without using the prompts used to query them. The authors argue that inconsistencies in the query wording of LLMs across different users makes LLMs inaccurate, as different users will query LLMs for the same information using different wording but should receive the same accurate responses regardless. To address this shortcoming, the authors propose to sit between the embedding layer and first attention layer of the LLMs, and take LLM embeddings as input and output continuous prompts that are used in query. They also investigate MoE - based models that learn a set of continuous prompts ( “experts ” ) and select one to query the LLM when querying from a baseline of only using natural language queries. The MoE models require a separate classifier trained on the continuous ones to match the one learned by the P-Adapters. They perform comparably to the more complex Mo - Efficient ( MoE ) models in extracting factual information from BERT and RoBERTa while eliminating the need for additional annotations. They show improvement in consistency of improvement in precision and 36-50% absolute improvement in improvement in accuracy.   The authors also investigate what makes a P - adapter successful and conclude that access to LLM ’s embedding of the original natural language prompt, particularly the subject of the entity pair being asked about, is a significant factor. For the MoE based models, they show between 12 - 26% and 36 - 50% improvement with respect to the baseline of precision and accuracy."
SP:35cdf71f027cc5168b55cc34c64bfb2f3087d6f5,"This paper proposes Continuous Classification of Time Series ( CCTS ), a method to achieve high accuracy classification of time series at every time. In this task, time series always evolves dynamically, changing features introduce multi - distribution forms. Different from the existing one - shot classification methods, most models are hard to achieve it due to their independent identically distributed premise. The main contribution of this paper is to propose an adaptive model training policy, ACCTS, that can overcome two main problems : ( 1 ) the catastrophic forgetting and the over fitting ; ( 2 ) Adaptive importance - based replay policy, that only replays the important samples adaptive to the contribution of data to the model. Experiments on four real - world datasets show that ACCTS can classify more accurately than all baselines.   The main contributions of the paper are the adaptability policy, the multi - distributed distribution policy, and the adaptive learning task with the unclear distribution division. The authors also propose a novel adaptive training framework to further improve the learning performance of the model during the training phase."
SP:d9b74b749aa465496763d3a3a9bf3a53e800587e,"This paper proposes a new approach to training language models to memorize the internal representations of past inputs in order to acquire new knowledge. In contrast to existing approaches that require the language model to read and memorize new data at inference time, this approach relies on the memorization of the representations of the past inputs, i.e., the weights of the language models are updated as the input representations become available, thus acquiring new knowledge immediately. The paper proposes to implement a kNN - based lookup mechanism into the memory used to retrieve the weights from the model's internal representations. This introduces a learning rate mechanism that encourages the model to update the weights as the inputs become more relevant to the task at hand.   The paper presents a set of experiments that compare the performance of language models trained with and without memory in terms of language modeling accuracy on various tasks, including generic webtext ( C4 ), math papers ( arXiv ), books ( PG-19 ), code ( GCode ), as well as formal theorems ( Isabelle ). The results show that language models model performance improves when the size of the memory is increased from 128 k tokens to 131 k. The experiments also show that the model is capable of making use of newly defined functions under conditions where the model does not have access to all the information during training."
SP:7a1bbf86c3fdb8738aa826ca330493e857d050ba,"This paper proposes a sampling scheme based on Metropolis–Hastings Monte Carlo ( MHMC ) algorithm to obtain sequences from masked language modeling ( MLM ) that specify a probability distribution over the space of possible sequences. The authors interpret MLMs as energy - based sequence models and propose two parametrization derived from the trained MLMs. The main contribution of this paper is to develop a tractable sampling scheme that can be applied to obtain samples from the same masked conditionals used for training the masked language models and is robust to the choice of the conditionals that is used to train the models. Based on the sampling scheme proposed in this paper, the authors demonstrate that their approach generates higher quality samples than other recently proposed undirected generation approaches for generating sequences from MLMs that are trained with two different types of conditionals : the first is the masked conditional - free conditionals and the second is the conditionally independent conditionals. The samples are considered valid and rejected based on their energy values according to the target distribution.    The authors then demonstrate the effectiveness of the proposed two energy parametrized models by exploring the quality of samples drawn from these energy based models for both open - ended unconditional generation and a conditional generation task of machine translation. The experiments are conducted in two settings : ( 1 ) in the case of the conditional setting, the obtained samples are used to generate the parametric energy estimates used in ( 2 ) for generating the energy estimates in ( 3 ), and ( 4 ) using the samples proposed in ( 5 ), samples from ( 6 ) are considered legitimate and rejected ( 7 ) based on whether the obtained energy estimates are consistent with ( 8 ) or not consistent with the ( 9 ) energy estimates. The results demonstrate that the proposed approach is more robust and tractable to rejection of the valid samples ( for ( 10 ) compared to other approaches that use the conditional samples ( 11 ). For the experiments in ( 12 ) and ( 13 ) the authors compare the performance of their approach with the baselines from two different sets of MLMs trained with and without conditionals, and show that the approach outperforms them in most cases."
SP:011626ba4fafee13d4a30e3f13c1df5b7071a7f1,"This paper studies the problem of data augmentation to boost the performance of deep neural networks for NLP tasks. It is well known that good augmentation is more effective when only a limited number of labeled samples is available, e.g. low - data or classimbalanced regimes. Most current augmentation techniques rely on parameter tuning or inherent randomness ; hence, their effectiveness largely varies on the tasks. To efficiently find the best augmentation strategy for each task, learning augmentation policy is a promising solution ; the question is how to design the reward function for learning a good policy. In this paper, the authors hypothesize that good policy should construct more diverse and challenging samples for providing informative training signals, while avoiding the risk of losing the semantics of original samples ( DND ). In addition, they introduce a sample re - weighting scheme to focus on difficult augmented samples after the original ones are learned confidently for more effective learning from the augmented ones.   The authors compare their learning - based augmentation method with the recent state - of - the - art augmentation schemes on various text classification tasks and GLUE benchmark by successfully discovering the effective augmentations for each tasks. The method is moreeffective on the challenging low -data and class - imbalance regimes, and it is well - transferable to the different tasks and models. However, their method is not suitable for every task. For example, it is not perfect for training the model, training the training model, or constructing the augmented samples with low confidence but a high semantic similarity with original ones."
SP:69d41a862ea189f72d4e8af2854e27b95a91fa41,"This paper proposes FOCAL, a meta - learning framework for offline reinforcement learning ( ORL ) based on SOTA OMRL, to handle task - based RL with sparse reward and distribution shift. The proposed framework is based on the intra - task attention mechanism and contrastive learning objectives proposed in [ 1 ], and is meant to be able to handle the challenging offline RL setting where task representations are scarce resource resources ( e.g., reward may not be evenly distributed across tasks ). The authors propose to use the attention mechanism from [ 2 ] to learn task representations from task representations and then use it to fine - tune the task representations to be robust to sparse rewards and distribution shifts.   Theoretical analysis and experiments are presented to demonstrate the superior performance and robustness of the proposed model - free framework compared to prior algorithms across multiple meta - RL benchmarks. The main contributions of the paper are the following :   1. A new attention mechanism is proposed to be used within each task context to learn the task representation from the context - based encoder. This is a novel idea and it is interesting to see how it can be combined with attention mechanisms from other tasks. This idea is interesting and it could potentially lead to more robust task representations. 2. Inter - task contrastive learnable learning objectives are introduced to train task representations in order to robustify task representation learning against sparse reward / distribution shift in the offline setting. 3. Model - free distributions of rewards are used for training task representations for model - based ORL based on. The experiments are conducted to evaluate the performance of FOCA on two different settings ( task - independent offline RL and task - dependent RL ), and to compare the performance on ORL with model - model free offline RL. The results are good ( in most cases ) and the robustness seems to be slightly worse ( in some settings )."
SP:ed86c60850d5c8302dcf1c2167db303e778fe681,"This paper proposes belief fine - tuning ( BFT ), a parametric sequential generative modeling approach that leverages approximate dynamic programming to determine the model parameters at each time step. BFT can improve the accuracy of the belief model at test time because it specializes the capacity of the model to the space of local observations. The authors demonstrate that BFT enables public belief state search in Hanabi where the number of possible information states is too large to track. They compare BFT with two other parametric methods, belief state update ( SET ) and belief policy update ( PNE ), both of which are parametric approaches that use a belief policy to update the parameters of a generative model at the time of policy creation. SET and PNE do not require the belief state to process it as input, whereas BFT does not require it for the first time during the training phase of SET. They also compare the performance of SET and SET on four variants of the benchmark game Hanabi, where they find that SET significantly outperforms SET, though SET is slightly better than SET at the end of the training run."
SP:6150725599c10f0e26f0d7cb1fc04b5b227a4456,"The paper proposes Pixelated Butterfly ( PBT ), a sparsity - based deep neural network training method that generalizes over a set of sparse neural networks that generalize well but is computationally expensive to train. The paper proposes to train such a network by optimizing over a continuous subsets of sparse matrices called products of butterfly matrices, where each piece in the product matrix is a weighted sum of two components : ( 1 ) block and ( 2 ) flat. To train the product matrices in time and space efficiently, the authors propose to sparsity the input vectors $ \mathcal{L}$ and output vectors $ p(L_{\theta, l}$, where $ l$ is a block matrix and $ \theta$ is the output of the second component of the input vector.   The paper presents experimental results on CIFAR-10, ImageNet-103, and Vision Transformer ( using GPT-2 ) trained on ImageNet classification and WikiText-103 language modeling tasks. The experiments show that the proposed method achieves higher accuracy than the baseline training methods, and faster training speeds than the MLP-Mixer, MLP - 2.5, and V - Transformer trained on the ImageNet dataset. However, the paper does not show any improvement in test accuracy on the tasks compared to the baseline methods. The authors argue that this is due to the fact that the training is based on a modified version of a classical SparseNet, which is not hardware - efficient, whereas the proposed PBT method uses a simple block matrices instead of graph matrices."
SP:136e31054a55abca840f6478491972023c2296cb,"This paper proposes a new method for learning score - based generative models based on diffusion probabilistic models. The authors first consider the forward process of the Markov chain and explore the class clustering phenomenon. Inspired by this idea, the authors propose to learn the score distribution based on score matching using the data distribution with noise and then recover the score based on the score matching with the learned data distribution using the class distribution.   The authors then propose a conditional diffusion - based model based on this learned score distribution to model the distribution of the class in the forward and reverse process. The method is compared with state - of - the - art methods ( SOTA ) on multiple tasks and achieves competitive results compared with the SOTA methods ( CIFAR-10 with an inception score of 9.58 and FID score of 3.05 ). A modification to the original formulation of the method, which enables controllable generation and gets interpretability, is also proposed for faster sampling and more analysis of the obtained scores. The experiments are shown to demonstrate the effectiveness of the formulated framework and provide insights into the possible interpretations of the models."
SP:fc2196f1f4ecd864398fed6640ff3f8b19870763,"This paper proposes a new method for generating domain generalization predictions in an unseen source domain using data from latent sub - space domains. The authors argue that the existing domain generalisation approaches often rely on the assumption of the existence of fixed domain - invariant features and common hypotheses learned from a set of training source domains, which may be suboptimal when source and target domains share little information or the target domain leverages information from selective source domains in a compositional way. This paper proposes to circumvent this assumption by constructing a unique invariant hypothesis across all source domains and using it to construct a hypothesis for each source domain. To this end, the authors propose a LASSO ( LAtent Sub - Space Orientation - based Learning ) method that explores source and source - free sub - spaces and learns individual hypotheses on those sub - spaces while using label - in - formative features formed by the label -informative features captured in source domains. They evaluate the proposed method on several well - known DG benchmarks where it achieves state - of - the - art generalization performance on some tasks and achieves satisfactory performance on other tasks.    The main contributions of this paper are the following :   1 ) The authors propose to use source domain - free hypothesis for generating source - domain features for label prediction tasks instead of relying on the invariant assumption in most existing approaches ; 2 ) They construct a classifier that distinguishes source domain features that are likely to be present in the source domain and target domain and one that is likely not ; 3 ) They use the classifier to distinguish source domain feature - free from source feature features that is not present in target domain ; 4 ) The method is evaluated empirically on four tasks and empirically evaluated on two well - know DG benchmarks to demonstrate that it achieves satisfactory generalisation performance on the target and source domain tasks while achieving good performance in other tasks on other datasets."
SP:6e8e5bdeb77e3cafe1975da8411fb65118955d14,"The paper studies the robustness of the Theta - based ( KT ) algorithm applied to the target RKHS ( 2021 ) that compresses a probability distribution more effectively by targeting a reproducing kernel Hilbert space. The paper improves upon the prior work ( Yao et al. ( 2021 ) and shows that KT with a fractional power kernel yields better - than -Monte - Carlo ( MMD ) guarantees for non - polynomial kernels, like Gaussian, inverse multiquadric, and sinc, that do not have square - root roots. They also show that KT admits maximum mean discrepancy ( MMD ) guarantees comparable to or better than those of square root KT without making explicit use of a square root kernel. In experiments with target KT and KT+, they witness significant improvements in integration error scores for integration error even in 100 dimensions."
SP:645c3f1864aa843d4899fc2406f694b5aab8460d,"This paper presents a benchmark suite for the Maximum in unpoliced set problem of NP - hard graph combinatorial optimization for graph neural networks ( GNNs ), in both weighted and unweighted versions. The paper first presents a unified interface to various state - of - the - art traditional and machine learning - based solvers for the weighted variant of the problem, and provides an in - depth analysis of the popular guided tree search algorithm by Li et al. [ NeurIPS 2018 ], showing that the results obtained by the algorithm are not reproducible due to the fact that tree search relies on algorithmic techniques like graph kernelization ( GK ) to find good solutions, which can in fact be replaced by random values. Second, the paper extends the analysis to compare the tree search implementations to other solvers, such as classical algorithmic and reinforcement learning based methods, and observes that classical GNN solvers are often faster to solve the problem. Third, it analyzes a recent solver based on reinforcement learning and observe that for this solver, the GNN is responsible for the competitive solution quality.    The paper concludes with a discussion of the advantages and limitations of the proposed approach for reproducing the results from the benchmark suite."
SP:155ecd17d264a084b014abdfd0362146d8fb07e0,"This paper proposes Wavelet Compressed Convolution ( WCC ), a novel approach for activation maps compression for 1 × 1 convolutions ( the workhorse of modern CNNs ). WCC achieves compression ratios and computational savings that are equivalent to low bit quantization rates with a relatively minimal loss of accuracy. To this end, it use a hardware - friendly Haar - wave - transform ( HWT ) known for its image compression effectiveness in image compression, and define the convolution on the compressed activation map. By combining WCC with light quantization, the authors show that they achieve compression rates equal to 2 - bit and 1 -bit with minimal degradation in image - to - image tasks.   The main contributions of this paper are as follows :   1. The authors propose a new compression method, called WCC, to improve the compression of activation maps of convolutional neural networks. The main reason for using such a compression method is that it makes the activation map of CNNs ( which use convolutions to map features ) more expressive. 2. A set of experiments evaluate the effectiveness of WCC against other methods in two image-to - image classification tasks : semantic segmentation and depth prediction. The experiments demonstrate that WCC outperforms other methods with respect to the compression ratio, computational cost, and image compression parameters. 3. An analysis of the experimental results shows that the WCC method is more efficient than other methods for improving CNNs."
SP:004865e6affad32403b7965493a53c8a7ffdda0a,"This paper studies learning in multiplayer general - sum imperfect - information extensive - form games, where the agents play T repetitions of the game according to the accelerated dynamics proposed in [ 1 ], which can capture correlated and coarse correlated equilibria in normal form games. The authors argue that extensive form games are more challenging as they can capture sequential and simultaneous moves, as well as imperfect information. This paper proposes a faster no -regret learning dynamics for extensive form correlated equilibrium ( EFCE ) in EFC games that can be considered as a special case of Gaussian Wasserstein games.   Compared to the previous work in this area, the main contribution of this paper is two - fold :    ( 1 ) The main contribution is to develop a learning algorithm that allows for faster learning with no regret minimization with the framework of a structured Markov chain - based learning method. The second part of the contribution is a method to characterize stability of certain fixed point strategies through a refined perturbation analysis of the distribution of play, which may be of independent interest to the learner. This is similar to [ 2 ], except that instead of using a fixed point strategy ( fixed point hypothesis ), the authors propose to use a learner - critic. The learner critic proposes to measure the stability of the learned equilibrium using a score function calculated from the correlation distribution between the learnt equilibrium and the mean of the ground - truth. The paper shows that this method is more stable than the previous one ( which used a point - based hypothesis method ), and that the stability is enhanced by the use of the score function. The main technical contribution of the authorship is an approach to connect predictive ( that is, optimistic ) regret ( minimization of the loss associated with the expected loss generated by the learning algorithm. The score function is then used to estimate the expected variance of the learning trajectories for each agent in the extended EFC game. This allows the authors to compute a learning rate that is O(T 3/4)-approximate ( learning rate ), which is a lower bound on the learning rate needed to learn from the learned trajectories of all agents in a game ( compared to a prior method, which used an exponential moving average learning rate estimator ). Experiments are conducted to validate the proposed method and compare it to two prior methods. The results show that the proposed algorithm has a better learning rate than both of the previous two methods and that it is faster than the no - regret learning rate ( with a smaller expected variance ) than the one with the optimistic learning rate. In addition, the performance of the extended method is also slightly better than the best prior method."
SP:ee545ff83df4d7ff256ac61fbe0eb0765f52f1d5,"This paper proposes a method, Action Quantization from Demonstrations ( AQuaDem ), to learn a discretization of continuous action spaces by leveraging the priors of demonstrations. This is in contrast to prior work, where discrete actions, as opposed to continuous actions, result in less complex exploration problems and computation of the maximum of the action - value function, which is central to dynamic programming based methods. The proposed method is evaluated on three setups : RL with demonstrations, RL with play data, and RL with a human playing in an environment but not solving any specific task– and evaluated using AQuAQuDem, AQuDaDem with human data and AQuQuDem with synthetic data ( which is more challenging than synthetic data ). The experiments show that AQuTaDem outperforms the state - of - the - art continuous control methods, both in terms of performance and sample efficiency on a variety of hard manipulation tasks.   The main contributions of this paper are the following :   1. The authors propose a novel method, A QuaDem, to apply any discrete action deep RL algorithm to the continuous control problem, named after A. Quarta ( Zhu et al., 2021 ). 2. They use the action priors from demonstrations to learn the action discretisation. 3. They evaluate the proposed method on a setting where the actions are played out in front of the agent in a controlled environment, and the agent has access to a control over the actions taken by the demonstrator. The experimental results show that the method outperforms previous work, especially when the action is played back to the same number of times ( in the action space ). 4. The major contributions of the paper include : 1. It is the first first work to develop a method that leverages the actions as priors in the continuous action space. This leads to a significantly reduced exploration problem, as the actions faced by the agent not only are in a finite number but also are plausible in light of the demonstrators behavior. The action space can be discretized in the same way as the one used in the previous step. The main difference is that the action value function can be directly computed from the action action space instead of the value function. This allows the method to be applied to the discrete action space of the same time. The second major contribution is the use of the demonstrations as the action distribution. The demonstrations provide enough action data to train the agent to learn an action distribution that is independent enough to be independent of the actions that are played back. The third major contribution includes the experiments that evaluate the performance of the method on three different setups where the agent does not need access to the action data during training."
SP:4b39279b98d6aa311bb49dd1384925f9d6f66c2d,"This paper proposes AdvStyle, an adversarial style augmentation approach to learn a robust model using only labeled synthetic ( source ) data, which is expected to perform well on unseen real ( target ) domains. The source domain is assumed to be generalization of the semantic segmentation, and the target domain is the similarity between the source domain and the domain in terms of the image style variation ( channelwise mean and standard deviation of images ). The proposed AdvStyle is an approach to dynamically generate hard stylized images during training and thus can effectively prevent the model from overfitting on the source domains. Specifically, AdvStyle regards the style feature as a learnable parameter and updates it by adversarial training. The learned adversarial image is used to construct an adversary image for robust model training, which produces a clear improvement on the considered datasets. Experiments on two synthetic - to - real semantic segmentations demonstrate that AdvStyle can significantly improve the model performance on the unseen real domains and show that we can achieve the state of the art in training the model using AdvStyle."
SP:4a2e6d70b383e4941e0bc44e7e82972b22e26792,"This paper proposes an event - based guided Variational Autoencoder ( VAE ) for mid - air gesture recognition. The main idea of the VAE is to use a dynamic vision sensor ( DVS ) to measure the similarity between the gestures produced by different machines with respect to each other using the proprioceptive input. The DVS sensor maps the input signal into a latent space representation, which is then fed into an event encoder to compute the similarity score between the DVS and the real - time ( time - varying ) gesture recognition system ( MES ). The VAE has two components, one for event encoding and one for non - event encoding. The former encodes the event in the latent space and the latter is used to predict the response of the machine to the given signal.    The main contribution of this paper is the Hybrid Guided VAE ( GuidedVAE ), which uses the information from two separate events ( one from the human and one from a machine ) to compute a score for each of the simulated gestures. The human scores the machine one and vice versa. The goal is to get a score that maximizes the average of the two events ( the human scores are used for estimating the distance between two states and the machine scores for the unseen states ). This score is then used in the MES system to compute an estimate of the total number of times the machine and the input made contact with the ground - truth MES input ( this is done by sampling from the two event encoders at different times of the same time using the same DVS representation. The score is used in computing the final MES score for the machine ( the second time around ). Hybrid VAE achieves an accuracy of 87 % of the time for the estimated MES scores for each event. The authors claim that this is better than the previous best ( 87 % for the first event, 87 % on the second event ) and that the difference between the two is due to the fact that the event encoded by the first one is more temporal and the second one is based on the magnitude of the event rather than the depth of the input ( the depth is the distance from the machine from the ground in the event compared to the input MES time in the case of the second MES event ). However, the authors admit that there is a trade - off between this and the temporal accuracy ( the temporal resolution is higher for the events encoded from the first MES but the spatial resolution is lower for the second Event Event Encoder ). They argue that the higher resolution is needed for the higher MES accuracy. They also propose to use the encoder for the non event encoded data but the cost of the decoder might be too high ( $ \epsilon$ for the event encoding ), so the authors propose an alternate method ( $ $ \beta$ ) to encode the event - encoded data ( $ p(s, a_t(s ) | s_{t(t_{t : s } ) } ) but only if the event is larger than $ t(s : s, t_t s_t ) \eps_{t_t : t_s } ) for processing the event and the corresponding MES value ( $"
SP:2e66468a6b94177e54b0052b97713ee63902c278,"This paper proposes a Sparse Hierarchical Table Ensemble ( S - HTE ) method for deep learning with ferns. Unlike previous fern - based methods, S -HTE learns useful internal representations, and it earns from increasing depth to achieve deep learning capabilities. The method is based on sparse inference, where the initial sparsification is controlled by annealing, which ensures that the final sparsified representation is close to the optimal one ( i.e., the one that minimises the computational cost of training the fern ).   The paper presents experiments on classification, regression, and machine translation tasks, where it compares the performance of the method with other methods ( fern and hierarchical table ensembles ) on MNIST, CIFAR-10, GEOM - FS, and Fashion - MNIST. The paper also presents results on the task of drone and NUI classification using the method'PyTorch. Overall, the paper is well - written and well - motivated, with clear directions and clear goals. The methods are easy to use and intuitive to follow. The main downside is that the methods are not state - of - the - art and require access to a lot of computational resources, which is difficult to obtain."
SP:b238db9252d83a13438bb747d70e635bb9945958,"This paper proposes Latent Action Q - learning, an offline RL method that can learn effective value functions from state - only experience. The main idea of the paper is to extend tabular Q - Learning in discrete Markov decision processes ( MDPs ) to the latent actions obtained through a latent - variable future prediction model ( LAF ). To achieve this, the authors propose to define a latent action $ z$ in the action space such that the value function $ \ell$ can be learned from any arbitrary action in $ \sqrt{Z}$. This setting is referred to as undirected stateonly experience ( SAE ) and the proposed method is called LAQ.   The paper conducts extensive experiments in 5 environments ranging from 2D grid world to 3D visual navigation in realistic environments. It demonstrates the benefits of LAQ over simpler alternatives, imitation learning oracles, and competing methods. In particular, it shows that LAQ can recover value functions that have high correlation with value functions learned using ground truth actions. In contrast, LAQ does n’t learn a value function that can be recovered from a ground truth action. The major contributions of this paper are the following :   1. The authors develop an interesting and theoretically well - motivated approach to learning value function from a state - alone transition ( transition with no action labels, state transitions without action labels i.e., s, s′, r ) tuples. This approach is called * * LAQ * *. 2. It introduces and studies three different types of latent actions : $ \eta$, $ \tilde{O}$ and $ \gamma$. The experiments compare LAQ with two other offline RL methods, offline RL and imitation learning. The results show that using LAQ leads to better value function recovery and a better generalization error bound than using any of the other methods."
SP:108ebe9045a9e2b8b5aba8352733782462db8a81,"This paper proposes SWARM Parallelism1 — a model parallelism - parallel training algorithm — for training large models. The authors propose to train a Transformer - language model with 1.1B shared parameters ( before sharing ) on a swarm of preemptible T4 GPUs with less than 400 Mb/s network throughput ( SwarmNet ). To reduce the network usage of the network used in the training approach, the authors develop several compression - aware architecture modifications and evaluate their tradeoffs.    The main contributions of this paper are :   ( 1 ) SWARM analyses the communication - efficiency tradeoff between training a large model trained in a dedicated GPU cluster ( with preemptible instances ) and training smaller models in distributed clusters ( using cheap instances that are not available to all GPUs at the same time ), and finds configurations where training larger models becomes less communication - intensive ( in the sense that it is able to handle tasks that are more task - agnostic ). ( 2 ) It proposes to use the same number of parallel nodes as in [ 1 ] to train several smaller models ( one for each of the three regions ) that are typically trained in dedicated GPU clusters. ( 3 ) The authors test their method on the Swarm dataset ( with and without T4 ) and show that SWARM achieves similar performance gain compared to the baseline model ( without SWARM and with SWARM with T4 ; see Table 1 and Table 2 for details ). The experiments show that the proposed method is effective in reducing the amount of communication - efficient training ( in terms of number of messages sent and received ). However, in order of importance, SWARM is not as effective as [ 3 ] and [ 4 ], which is argued to be the main contribution of the paper, but it is worth mentioning as it could lead to significant performance gain in some scenarios ( e.g., in the case of failure )."
SP:91d2f094d5481651b554f58aecc2a6207057a47c,"This paper studies the problem of offline and online multi - agent reinforcement learning ( OTC ). OTC is an RL method that aims to overcome the bias in the transition dynamics of offline RL due to the lack of offline training and online execution. The main contribution of this paper is the introduction of online transition correction ( OTC ) to implicitly correct the biased transition dynamics by modifying the sampling probabilities of the offline RL and online RL. To do so, the authors propose two types of distances, i.e., embedding distance and value - based distance, to measure the similarity between transitions, and further propose an adaptive rank - based prioritization to sample transitions according to the transition similarity of OTC and the agent policy. The authors show that OTC outperforms baselines in a variety of tasks that use OTC.   The main contributions of the paper are the following :   1 ) A new offline transition correction method that explicitly corrects the bias of the biased offline RL transition dynamics via the difference in the value estimates between the offline training data and the online tuning data. This method, called OTC, is based on the idea that offline learning with a fixed offline dataset and online tuning with limited online data is less efficient than training with both online data and limited online experiences. 2 ) Two versions of the OTC method are proposed, one for offline learning and one for online tuning. The experimental results show that the proposed method is more effective than the baseline method in reducing the discrepancy between the behavior policy and the learned policy in OTC transition dynamics. 3 ) The authors conduct extensive experiments to validate the effectiveness of their method and compare their methods to baseline and baselines."
SP:d0e650d568214481b07a0452ec606ccbf6d05410,"This paper proposes an unbiased quantization method for the forward phase of training Deep Neural Networks ( DNNs ) in order to reduce the computational footprint of the training process. The forward phase is quantized using the loss gradients corresponding to the outputs of intermediate neural layers. This paper proposes a logarithmic quantization ( LUQ ) method to quantize both the forward and backward phase to 4 - bits, thus reducing the area used by the multiplier. The main contribution of this paper is to propose a method that exploits the low precision format for training with a variance reduction ( RED ) method that avoids multiplications during the two - thirds of training. The paper shows that this method can achieve state - of - the - art results in training with ResNet50 on ImageNet.   The main contributions of the paper are the following :   1 ) This paper examines the quantization of the neural gradients with respect to the output of the intermediate layers in the forward stage of training and discusses the advantages of having such quantization in quantized neural network training and when to maintain it, and how to do it. 2 ) Based on this, it proposes to use a variance - reduction method ( LQ - RD ) to avoid multiplication during the backward phase, thus leading to a reduction in the area of the multiplier used for quantizing the gradients during this phase. 3 ) The method is evaluated empirically on a variety of datasets, showing that it can achieve a degradation of only 0.64 % after a single epoch of high precision fine - tuning ( $ \mathbb{KL}$ with the forward quantization and $ \text{LQ_KL }. 4 ) The paper also provides a procedure to implement the variance reduction with a multiplicative multiplier during the training phase, which results in a reduction of 0.9 % after $ 1.18 % after epochs 5 and 6. The experiments are conducted on MNIST, CIFAR-10 and Fashion - MNIST and the MNIST datasets."
SP:f2862d1f987164ed6c3c375cd8962e57c369373b,"This paper studies the relationship between meta - learning methods ( Prototypical Networks, Attentional Networks, Polythetic Networks ) and the embedding dimensionality of their classifiers. The main insight is that meta - learners that use features that are not task relevant ( e.g., non - linear embedding ) tend to work better when learning tasks that require the features to interact with the environment. On the other hand, attentional classifiers, such as Matching Networks, are polythetic by default and can solve problems in the domain where the features are non - task relevant. This is because, in the presence of task - irrelevant features, the attentional models are susceptible to misclassification. To address this problem, the authors propose a selfattention feature - selection mechanism that adaptively selects feature embeddings that are relevant to the task at hand. The authors test their method on synthetic data, real data, and a few real - world few - shot learning tasks. The experimental results show that the proposed method outperforms other methods in most cases, especially when the task is synthetic."
SP:e1e513fef25d29e17cdadd1b36d932a8ad8897cd,"This paper studies the question of emergent language between two agents trained using reinforcement learning on a continuous communication channel trained through a multi - agent reinforcement learning framework. The authors propose an environment and training methodology to explore the phenomenon of natural language acquisition and emergence in the presence of a speaker and listener. The speaker is equipped with a vocoder that maps symbols to a continuous waveform ; the listener is provided with a set of hand - crafted hand symbols corresponding to the concepts represented by the speaker. The goal of the paper is to explore whether and how language forms between two listening agents trained in the same environment as each other using a discrete channel can emerge spontaneously. The paper proposes to train the speaker and the listener in a manner similar to the way that language emerged in natural language communication with discrete symbols. The main difference is that the speaker is trained to express concepts to the listener using hand - drawn symbols, while discrete symbols are trained to represent concepts using a stylized waveform mapping the symbol representations to the waveform.   The paper presents a series of experiments that compare the effect of noise level on the emergence of language between listening and non - listening agents using the framework proposed in [ 1 ]. The experiments show that the noise level increases with increasing the depth of the speaker ’s hand and the deeper the listener ‘s hand, indicating that the communication becomes more natural. In addition, the paper also presents results that suggest that noise levels increase with increasing depth in the listener's hand as the number of speaker hand symbols increases. These experiments are conducted in a setting similar to what is presented in [ 2 ], although the speaker - listener environment is slightly different from the natural one. The experimental results suggest that a speaker “ ground - truth ” language may emerge more rapidly in this setting compared to the natural language setting. The results also suggest that there may be opportunities for learning language in environments similar to this one for language acquisition ( e.g., for example, during infancy when infants learn to communicate with their caregivers using continuous acoustic recordings of their n’est. Finally the paper proposes a training methodology that combines reinforcement learning ( speaker ) learning ( using a trained vocoder to map continuous waveforms to a speaker hand and multi - agents learning to map discrete symbols from the speaker hand to a listener. This training method is evaluated empirically for language learning and shows that it is possible to observe language emergence in this learning setting for the first time in some cases."
SP:0e6ff65ba4a3df35947d1b6f4d438612088d90a0,"This paper proposes a novel backdoor attack on the pre - trained natural language processing ( NLP ) language model. The authors claim that the current NLP models have been shown to be vulnerable to backdoor attacks, where a pre - defined trigger word in the input text causes model misprediction. Previous NLP backdoor attacks have focused on some specific tasks. This makes those attacks less general and applicable to other kinds of NLP model and tasks. In this work, the authors propose a general backdoor attack that can be applied to a wide range of downstream NLP tasks. The adversary does not need prior information about the downstream tasks when implanting the backdoor to the model. When this malicious model is released, any downstream models transferred from it will also inherit the backdoor, even after the extensive transfer learning process.   The authors further design a simple yet effective strategy to bypass a state - of - the - art defense strategy to facilitate the implanting of the malicious model. Experimental results indicate that our approach can tolerate the adversary ’s downstream language processing tasks in an effective and stealthy way. The main contributions of this work are as follows :    1 ) The authors propose BadPre, the first task - agnostic backdoor attack against the pre _ trained _ language models. The key feature of _ BadPre _ is that the adversary does   not need to disclose the downstream task details during the attack. It is possible to infer the parametrization of the adversary from the output of the model during implanting. 2 ) The author conducts extensive experiments to validate the effectiveness of their approach. 3 ) The approach is validated on a variety of downstream language tasks using a combination of supervised and unsupervised methods."
SP:58d3ecb4a1906251e79ad883aa97cc2502642658,"This paper studies the problem of skill pre - training and skill discovery in reward - free / unsupervised RL, where the goal is to develop skills that can be used in environments where task supervision is scarce or expensive. The authors make the following contributions :   1. They propose a framework for skill discovery, where skills are learned one after another in an incremental fashion. This allows newly learned skills to adapt to changes in the environment or agent dynamics while the fixed old skills are not forgotten. 2. This framework allows for incremental skill learning where skills can be learned in an evolving or expanding environment. 3. They conduct experiments on both static and evolving environments, where they show that incremental skills significantly outperform current state - of - the - art skill discovery methods on both skill quality and the ability to solve downstream tasks.   The authors also propose a method for training agents that uses a mixture of learned and newly discovered skills. The experimental results show that this approach performs better than the baseline skill discovery method, which learns skills in a stationary and stationary static environment. However, it performs worse on evolving environments where it needs to adapt fast to new situations while not forgetting previously learned skills. 4. The experiments also show that the method outperforms the baseline method on some tasks that are learnt in a static static setting, but not on new situations that arise from the evolving environment. The method is evaluated on a variety of tasks designed by the authors, and it is compared with two methods that use hand - designed rewards. The results demonstrate that the proposed method does better than other methods both in terms of generalization and scalability."
SP:2c6595408f5ec95537eaf555e5fe3d992b58c222,"This paper proposes a novel log - polar space convolution layer ( LPSC ), where the convolution kernel is elliptical and adaptively divides its local receptive field into different regions according to the relative directions and logarithmic distances. The authors claim that the receptive fields exponentially increase with the higher the number of distance levels. The proposed LpsC has the property to encodes local spatial structures and greatly increases the single - layer receptive field while maintaining the same number of parameters. They demonstrate the effectiveness of the proposed layer on different tasks and datasets using experiments on CIFAR-10 and ImageNet to demonstrate that it can be implemented with conventional convolution via log - post - log space pooling.    The main contributions of the paper are as follows :   - The authors propose a novel convolutional layer with a log - polar space kernel, which is different from the typical convolution kernels used in most popular models. - They develop a new receptive field mapping from the receptive field in the receptive region of the kernel to the distance levels and show that it is more receptive than the one in the previous layer. The receptive field maps from the kernel's receptive field to the receptive regions of the different distances. This is in contrast to the typical mapping from receptive region to receptive regions in the lower layers of the convolutions kernel. The different receptive fields correspond to different directions and distances. They claim that this leads to a more receptive field that is more expressive and more expressive than the previous layers. They also show that the new field maps more receptive fields to the single layer receptive fields in the higher layers. - Based on the experimental results, the authors propose to use the proposed L PSC layer as a base layer for training CIFN and perform experiments to verify that it performs better than the baselines. They compare the performance of their method with conventional baselines and a new method based on log-polar space."
SP:7791f96b1eef277a9133975507a750d9e7c6b8ff,"This paper studies the generalization ability of neural networks ( NNs ) based on the PAC - Bayes generalization of weights. The main contribution of this paper is to propose a generalization algorithm based on PIB ( Private Information Bottleneck Information Representation ) to estimate the IIW - based information bottleneck on the trade - off between information accuracy and information complexity of NNs. The idea of IIW is to obtain a non - vacuous generalization bound for the weighted sum of information in weights ( weights ) that maximizes the information compressibility of the weights and minimises the information complexity. This paper proposes an algorithm for the efficient approximation to IIW, and also proposes an MCMC - based algorithm to sample from the optimal weight posterior characterized by PIB, which is claimed to be the source of the information compression that enables IIW to generalize well.   The main contributions of the paper are the following :   1. The authors propose an algorithm to obtain an efficient approximation of the generalized information bottleneck of PIB. 2. They use PIB to analyze the connection between IIW ’s property and that of generalization generalization. 3. They show empirically that the fitting to phase transition during transition during generalization is similar to that of the transition introduced by IIW during training. 4. The algorithm is tested empirically on MNIST and CIFAR-10, and it is shown to outperform the one based on IIW."
SP:a733847ade77ffbf38760fc79da17893dea8d53f,This paper studies the effect of perturbations to training data used for data poisoning attacks designed to maximize the test error1. The authors find that the attacks are able to distinguish the target labels of the corresponding samples when perturbed with the corresponding labels. This is an important property to be aware of as it indicates that the shortcut learning problem is more serious than previously believed and that the deep models heavily relies on shortcuts even if they are of an imperceptible scale. The paper further shows that the recent work on the linear separability is indeed the workhorse for recent attacks and synthesize linear separable data as perturbation to analyze the attacks. Synthetic attacks are as powerful as the deliberately crafted attacks when they are synthesized from real data. It also suggests that the pre - trained feature extractors can be a powerful defense against the speeding up attacks.
SP:7b50be406138ad01db3ee112899f622637896fe9,"This paper studies importance weighted return ( HDR ) in offline policy evaluation, where the goal is to estimate the expected return ( expected value ) of a state policy in the absence of online learning ( e.g., when the state policy is not accessible during offline evaluation ). The paper proposes an algorithm, HDR - VAE, that uses a weighted sum of the state - neighbor ELBO statistics ( normalized by the policy covariance ) to compute the importance return. The algorithm has been proposed before, but this is the first time that it is presented in detail in this form. The authors provide a theoretical justification of the proposed algorithm through a better per - state - neighbour normalization condition, and show the limitation of previous attempts to this approach using an illustrative example. They further test the proposed method in a healthcare - inspired simulator and a logged dataset collected from real hospitals. The experiments show that the algorithm achieves better performance with less overfitting and better test performance compared with with state - of - the - art reinforcement learning algorithms."
SP:c976752a55b9ff47dc63c95a9fd7b51a81e8a42e,"This paper presents CoLLIE, a model for continual learning based on the multimodal embedding model by OpenAI. The core idea is to pre - train a language embedding network that maps language and images to the same semantic space using a pre - trained CLIP embedding, where language and image embeddings are assumed to be from the same source language. Language embedding is then used to learn a language transformation function, which adjusts the embedding based on language - specific data augmentation functions that are learned during training. This is similar to what OpenAI ’s CLIP library does, except that instead of using a single language transformation ( as in OpenAI CLIP, which uses a combination of text augmentation and image augmentation ), the authors use a series of language encoders that correspond to different embedding domains. The authors then propose to train the language encoder using a mixture of image encoder and decoder, where the encoder is the semantic embedding of the source language and the decoder is an auto - encoder that learns the language transformation using the semantic encoder. The decoder can be trained using standard few - shot training approaches such as LSTM. The paper then presents two tasks where the target task is continual learning ( e.g., image classification and object classification ) and the goal is to learn enough labels and examples to generalize well to similar ones. The experiments compare the performance of the model on each task using a few examples and show that the model is able to learn and generalize fairly well from zero - shot to a large set of examples ( 250 ) with little to no dropout ( in terms of accuracy ). In addition, the paper also presents results on a second continual learning task where the model generalizes fairly well to tasks on a smaller set of language domains ( 50 ) using a much smaller dataset ( 160 )."
SP:d3371b322acfc321ee79a2e1b438d82644872fa4,"This paper proposes a novel method for learning image captioning models for describing novel visual concepts unseen in the training captions, i.e., which are unseen due to the absence of caption annotations. The authors first describe the relationship between the above properties and existing visual / language models, and then propose VLAF2, for learning Visual - Linguistic ( VL2 ), for describing visual information of images with novel objects. Next, the authors propose Audacity - Based Captioning ( ABC ), which generates captions based on the learned model using only the captions of novel objects from the training images. The ABC model is trained to be linguistically fluent, contains novel objects of interest, and fits the visual concept of the image to assess the three aspects corresponding to fluency, fidelity, and adequacy, respectively. Experiments are conducted to evaluate the effectiveness of the proposed method on the nocentric dataset, and the authors compare ABC with state - of - the - art novel captioning model in all caption evaluation metrics. They perform quantitative and qualitative analysis to demonstrate how    ABC generates novel object captions with improved   fidelity,   and   adequacy. Implementation details and code are available in the supplementary materials.   The authors also conduct extensive experiments to validate the effectiveness   of their method, and demonstrate how the model generates novel captions that not only outperform the state -of - the _ human _ baseline captioners, but also surpasses the SPICE scores of human baseline ( by a large margin ). They also conduct experiments, demonstrating how the proposed in the paper can be improved with improved fluency and fidelity. Finally, they conduct ablation studies to demonstrate the robustness of the method."
SP:9f3b6486662d80350d77a4b060d4a5b8b22a6130,"This paper studies the problem of transfer learning in classification with few - shot learning, where representations learned by a single classifier over many classes is not transferable to new classes learned by special - purpose algorithms designed for such problems. It builds on the recent observation that the features learned by overparametrized classification networks show an interesting clustering property, called neural collapse, that generalizes to new samples from the training classes and, more importantly, new classes unknown to the classifier. The paper first studies the effect of learning a feature map ( or representation map ) of the feature distribution over a training set of classes, and compares the performance of classifiers trained with and without neural collapse and with a classifier trained only with neural collapse. It shows that neural collapse allows the feature map to generalize well to samples from new classes as well as existing classes. Next, it builds upon previous results showing that the feature maps of neural collapse - trained classifiers provide a competitive performance on transfer learning when compared to that of classifier - free classifiers that are trained only on the training set and don't have access to the features of the new samples. Finally, it applies neural collapse to the transfer learning problem in two different settings : ( 1 ) the setting where the representation map is learned from only a few samples ( e.g., CIFAR-10 ), and ( 2 ) the standard transfer learning setting where representations are learned from all samples but the classifiers do n’t use all the features. In the latter setting, it is observed that the collapse is more effective than not using it ( as it generalizes better to larger numbers of samples ).    The main contribution of this paper is to provide a theoretical explanation for why neural collapse works well in the transfer setting and how it relates to the recent results in the literature showing that classifiers with representation maps of diverse classes learn better representations than those with one - hot classifiers. This is motivated by the fact that collapsing the representation maps across classes leads to a more robust set of features for new samples that is generalizable to all classes, as opposed to just some of them, which is not the case when using the same maps for all classes. It also provides a number of experimental results that support the theoretical findings in the paper, including experiments with transfer learning on standard and transfer learning with standard classifiers, a comparison with a new classifier, and two studies that compare the performances of neural collapses with that of different classifiers on the standard and the new class."
SP:624c95d9ce1ee4b66274e858e2da22bef6b052c7,"Recent studies have been conducted to densify, denoise, and complete inaccurate point cloud. In this paper, the authors advocate that jointly solving these tasks leads to significant improvement for point cloud reconstruction. To this end, they propose a deep point clouds reconstruction network consisting of two stages : 1 ) a 3D sparse stacked - hourglass network as for the initial densification and denoising, 2 ) a refinement via transformers converting the discrete voxels into 3D points. In particular, they further improve the performance of transformer by a newly proposed module called amplified positional encoding. This module has been designed to amplify the magnitude of positional encoding vectors based on the points ’ distances for adaptive refinements. Extensive experiments demonstrate that our network achieves state - of - the - art performance among the recent studies in the ScanNet, ICL - NUIM, and ShapeNetPart datasets."
SP:34a81ca65131576d4c14332a4e9eb3a4c344cab7,"This paper proposes PipeGCN, a method to reduce the communication overhead between communicating node features and feature gradients in distributed Graph Convolutional Networks ( GCN ) training. Given that distributed GCN training incurs a prohibitive overhead in communicating the features and gradients among partitions for every GCN layer in each training iteration, the paper proposes a simple - yet - effective way to reduce this overhead by pipelining inter - partition communication with intra - partition computations. The paper also proposes a smoothing method to further improve the convergence of the method. Experiments are conducted to evaluate the effectiveness of the proposed method. The main contributions of the paper are as follows :   1. The authors propose a new method to decrease the overhead of the communication communication between the different GCN layers during training of GCNs. The proposed method is based on the idea that it is better to train GCNs with distributed training across multiple accelerators such that each accelerator holds a partitioned subgraph of each GCN subgraph. It is non - trivial to use this method during training for efficient GCN features / gradients communication during distributed training, as as soon as the distributed node features/ gradients become stale, the converges will become non - convergent and thus can harm the convergence, negating the benefit of the pipeline benefit.    2. It adopts the same accuracy as its vanilla counterpart while boosting the training throughput ( up to 2.2× ). However, it outperforms existing full - graph training methods, such as GraphSAGE, by a large margin. 3. It also provides a theoretical convergence guarantee but also finds the convergence rate of pipeGCN to be close to that of the vanilla vanilla distributed distributedGCN training without staleness, thus can be used to train with both stale features and stale gradients of gradients."
SP:8302d49558ee0f16392d623d4e604e92db10d041,"This paper studies the problem of test time robustification, i.e. using the test input to improve model robustness in face of distribution shift. The authors propose a simple approach that can be used in any test setting where the model is probabilistic and adaptable : when presented with a test example, perform different data augmentations on the data point, and then adapt ( with the help of the adaptable model ) the model parameters by minimizing the entropy of the model ’s parameters. In the experiments, the authors evaluate two baseline ResNet models, two robust ResNet - 50 models, and a robust vision transformer model and demonstrate that this approach achieves accuracy gains of 1-8% over standard model evaluation and also generally outperforms prior augmentation and adaptation strategies. For the setting in which only one test point is available, they achieve state - of - the - art results on the ImageNet-C, ImageNet - R, and, among ResNet-50 models, imagenet - A distribution shift benchmarks. The experiments are conducted on 5 datasets ( ImageNet, Caffe2, RNN2, ResNet50, and VGG ) and 1 dataset ( VGG - R ), and the robustness achieved by the proposed method is comparable to that achieved by baselines and is robust to perturbations in the input, changes in the domain, and distribution shift sources."
SP:a985de5e940ff3a4160b378201b8c02f68d1914a,"This paper proposes a joint objective for jointly training the model and the policy in reinforcement learning ( RL ). The objective is to avoid states where the model predictions are unrealistic, and updates to either component increase a lower bound on expected return. The resulting algorithm ( MnM ) is similar to a GAN similar to the joint optimization mends the objective mismatch in prior work.    The main contributions of this paper are as follows :   - The authors jointly train a model and a policy with the objective to jointly maximize the accuracy of the model ( i.e., the policies that yield the best policies ), rather than the performance of the policies generated by the trained models. The authors provide a joint evaluation of the joint training procedure and the resulting algorithm. The evaluation is based on the observation that models that achieve better training performance ( e.g. lower MSE ) are not necessarily better for control, and that policies that are more responsive to the preferences of the models are more likely to expose the errors of the inaccurate models. - Based on this observation, the authors propose to jointly train the policy and the model to produce transitions that look realistic, and to avoid transitions where the policy is not responsive enough to the transitions produced by the model. This is different from the previous joint training approach, where the goal is to train a policy that produces transitions that are “ realistic ” even if they are not “ natural ” transitions. The main difficulty of this approach is that it does n’t explicitly state the goal that the model should be trained to maximize accuracy, only that it update the policy to maximize the policies “ accuracy ”. - Because the authors recognize that there is an important tradeoff between accuracy and policy performance, they propose to explicitly state this tradeoff in the joint evaluation paper. - The evaluations are based on a cross - entropy between the expected return of the two models ( assuming that the cost of updating the policy only slightly increases with each update of the policy than the expected cost of the updated model. The evaluations cover a range of assumptions, including assumptions on model accuracy ( MSE, cost of transitions, MSE as a function of policy cost, and policy policy preference ), policy preference ( preference, and whether the updated policy favors transitions that have a low MSE or prefers states with high MSE that have higher MSE. - In the evaluations the authors consider assumptions similar to those in the prior work on joint training, except that the assumptions on MSE are not updated ( the first one assumes that the policy prefers transitions with a MSE lower than the second one ), and the second assumption is that the updates to the policy do not change the agent ’s preference for transitions with MSE higher than"
SP:a469fbcdc20b11dff4085b6fbc384e77f33cd37d,"This paper proposes a simple model combination approach inspired by human decision making : first compute a coarse action based on the instantaneous observation, and then refine it into a final action using historical information. The proposed approach BC -OH has access to all required information, but manifests the “ copycat problem ”, where the policy performs suboptimally due to lack of information. To overcome this issue, the authors propose BC - SO, which first computes the action using the observation and then updates it with historical information using the available data. The authors test the approach on CARLA autonomous driving from images and various MuJoCo continuous control tasks. The experimental results show that BC - OH outperforms all baselines.    The authors acknowledge that behavioral cloning policies acting on single observations and observation histories each have their strengths and drawbacks, and combining them optimally could achieve the best of both worlds. To mitigate the drawbacks of combining two approaches that have different approaches to fuse information from the past and present in order to obtain the best behavior cloning policy, this paper proposes BC - OBD, which combines the advantages of each approach and outperforms both approaches in most settings. To evaluate the effectiveness of the proposed approach, authors evaluate it on the CARLA driving task ( Figure 2 ), MuJoJoCo ( Figure 3 ), and behavioral cloning from observation history ( Figure 4 ). The results generally outperform the baselines except for the one where BC - BOA fails to learn a policy."
SP:95c4533b5d1a865c4cc6a54615e7ad6357bdaad1,"This paper proposes DyAd, a model - based meta - learning method to generalize across heterogeneous domains by partitioning them into different tasks. DyAd consists of two parts : an encoder which infers the time - invariant hidden features of the task with weak supervision and a forecaster which learns the shared dynamics of the entire domain. The encoder adapts and controls the forecaster during inference using adaptive instance normalization and adaptive padding. Theoretically, the authors prove that the generalization error of DyAd is related to the task - level relatedness in the source domain as well as the domain differences between source and target. Empirically, they demonstrate that DyAd outperforms state - of - the - art approaches on the source - level and target - level tasks."
SP:ec70553cb0c27e5349c1b8cce6bcaa96a83bf050,"This paper proposes a weakly supervised monocular 3D object detection method based on the generated 2D boxes and corresponding RoI LiDAR points as the weak supervision. The method is based on using a network to predict the 2D box labels for the corresponding 3D boxes. The network is learned by minimizing the newly proposed 3D box alignment loss between the newly predicted 3Dbox and the corresponding 2DBox labels. The main contributions of the paper are the following :   1 ) It proposes a novel and theoretically well - motivated method for generating 2D Boxes for the detection of 3D objects in 3D scene understanding using the ill - posed nature of monocular imagery 2 ) It introduces several effective designs into the training of the proposed method to overcome the challenges of the above - mentioned learning problem and resolve these challenges 3 ) It presents several experimental results in KITTI, showing that the method outperforms several fully - supervised and weakly - supervised methods for object detection using the training labels manually annotated from the 3D point clouds."
SP:34217c6a8ca43b8eeb9ddc83d6f1f0af05918984,"This paper proposes a new model inductive bias for natural language processing ( NLP ) that learns a sub - word tokenization end - to - end as part of the state - of - the - art NLP model. The proposed model is based on soft gradient - based subword tokenization, which is different from the rigid tokenization algorithms used in previous NLP models, such as GPT-2 and GPT - XL. The authors also propose CHARFORMER, a transformer - based model that integrates the ideas from GPT and XL models and operates on the byte level. The experimental results on English GLUE, multilingual GLUE and noisy text datasets show that the proposed model outperforms the previous models in terms of generalization and speed, while maintaining competitive quality."
SP:d26d25f2ef23a89a2c139d0dd87c4c86fddcff5e,"This paper proposes an adversarial approach to detect backdoor attacks in deep neural networks ( DNNs ). Backdoor attacks inject a backdoor into the target DNN through injecting a backdoor trigger into the training examples, which can cause the target black - box neural network to misclassify an input associated with the backdoor trigger. Existing backdoor detection methods often require access to the original poisoned training data, the parameters of the target neural network, or the predictive confidence for each given input, which is impractical in many real - world applications. This paper proposes a method based on AEVA ( Adversarial Extensive Value Analysis ) to analyze the adversarial input of a DNN under the assumption that only its output label label label is accessible ( in most cases, the output label is not the target network's label ). This approach is referred to as hard - label backdoor detection ( AEVA ), where the DNN is a fully black box network and only its final output label labels are accessible. The authors consider the following scenario :   ( 1 ) A backdoor attack is performed on a target black box DNN with the aim of fooling the black box classification algorithm ( e.g., by poisoning the target networks with backdoor triggers ). The attacker uses a soft backdoor to introduce a backdoor to the blackbox network. The target network ’s output labels are the output labels of the soft backdoor. ( 2 ) The attacker then injects a backdoor with a hard trigger that causes the target classifier to output the input that corresponds to the trigger. ( 3 ) The target networks then receive the input from the hard - labeled backdoor.   The authors evaluate the proposed AEVA approach using the following loss function : 1 ) An adversarial gradient estimator is used to estimate the adversarially ( the loss is bounded by an objective that depends on the loss function ( the objective of the optimization step ) 2 ) An additional adversarial term is added to this loss function to enforce the bound of the loss ( the term “ robustness ”, which refers to the robustness of the output of the algorithm against adversarial noise generated by the loss. ( the authors do not use this term in the paper, but it is widely used in other works ) 3 ) A final score is computed based on the difference between the loss and the expected loss produced by the two adversarial estimators using the robust estimator and the admissible loss. The score is reported as the ratio of the expected risk to the expected reward ( the difference is the average expected risk of the two losses ) 4 ) The authors compare the proposed approach with two other methods for detecting backdoor attacks using AEVA, one relying on"
SP:c6dbca0ed0799b7fec21777606f6f809eb2d8c48,"This paper introduces Kullback - leibler divergence criterion ( KLoS ), a new divergence criterion based on the class - probability simplex, to measure in - distribution and out - of - distribution ( OOD ) class - wise divergence measures of the expected divergence between two classes using the second - order log - likelihood of the evidential models. This is in contrast to the current class - uncertainty measures ( 2nd - order measures ), which are based on first - order data and OOD - generated uncertainty. The proposed criterion is designed to capture class confusion and lack of evidence in a single score, capturing both the distributional information and the class confusion in the full distributional space. The authors also propose an auxiliary neural network ( K loSNet ) to learn such a criterion directly aligned with the learning objective in the realistic training setting, where no OOD data is available during training. The experiments show that K LoSNet outperforms the current 2nd order uncertainty measures to simultaneously detect misclassifications, OOD samples, and to not require OOD training data. They also observe that existing measures are brittle to the choice of the OOD dataset, whereas KLo SNet is more robust. In addition, the authors propose a refined criterion, KLoRNet, to learn a refined feature extractor ( similar to that in LoS ) directly in the learning setting, to capture the feature extraction process in the training setting."
SP:8b4f3916dca4e627931558e14836749bd4a6792f,"This paper studies semi - supervised learning of CNN by linear classifier over datadependent features from unlabeled images. The main contribution is to develop and study a classifier that learns CNNs over features that are datadependently linear in their dimension. The classifier is a linear LSTM, where the dimension of the patches in the input image is estimated by summing over a set of low - dimensional vectors sampled from a lower - dimensional manifold. The paper shows that the classifier provably learns CNN under some natural distributional assumptions. Specifically, it learns CNN when the patch distribution is low - dimensioned ( assumes that the patches sampled from the lower dimension manifold are Gaussians ), and when the dimension is high ( assuming that the manifold distribution is high - dimensional ). Under these assumptions, the method is able to learn CNNs efficiently. The method is applied to synthetic image data, where it is assumed that the data comes from a fixed source ( e.g., a fixed manifold ) and the source features are linear in the dimension. It is compared with CNNs learned using supervised learning on natural image data. The results show that CNNs are provably learnable under the lower - dimension patch distribution assumption, and that the dependence of the learned CNNs on the dimension ( assuming high - dimension patches distribution ) is minimal.   The main contributions of the paper are the following : - The paper develops and studies a method for learning CNN by means of linear classifiers, that learn low -dimensional patches by averaging over features of input images. This method is different from CNNs that are learned using deep learning, in that it does not use deep learning techniques and instead relies on classifier predictions. - It is shown that this method is robust to the choice of the classifiers and that is learned. - The experiments support this claim. The experiments are conducted with synthetic and natural data."
SP:7f2f354d5cc1030bd97bd716aea8fe1d3af86b25,"Graph Convolutional Networks ( GCN ) are state - of - the - art for face clustering. This paper proposes Ada - NetS ( AdaNetS ), a new algorithm to cluster faces by constructing clean graphs for GCNs. The main idea is to replace the kNN relations in the feature space of the GCN graph with a set of relations based on the face features of the nearest neighbours. Each face in the cluster is transformed to a new structure space with reduced number of edges connecting to each face image. Then, an adaptive neighbour discovery strategy is proposed to determine a proper number of neighbours to reduce the number of noise edges. Experiments on multiple public clustering datasets show that Ada-NetS significantly outperforms the previous state -   underperforms current GCN - based methods, proving its superiority and generalization ability.   The main contributions of this paper are the following :   1. A new algorithm named AdaNet(S)-NetS is proposed by combining existing kNN - based graph construction methods and face features from GCN graphs. This algorithm is named after Ada, a popular name for a popular clustering method developed in the 1990s. The authors use AdaNet as the main implementation and the algorithm is computationally expensive. Theoretical guarantees are given for AdaNet and are not given for the proposed clustering strategy. 2. An empirical study is conducted to verify that AdaNet significantly reduces the noise edges while maintaining the good ones to build a graph with clean yet rich yet rich edges for GCN cluster faces. The experiments are conducted on 5 public datasets ( CIFAR-10, CelebA-100, Imagenet-50, CelebImages-200, MSC - 200, CelebS-200 and CelebRescue-200 )."
SP:a3bc8e26f55e78f07de081ca85865afd52b6ae4a,"This paper studies the distributionally robust optimization ( DRO ) method for learning robust models that are able to perform well on a collection of possible data distributions ( the “uncertainty set ” ) without demographics. The authors propose Unit DRO ( UBO ) as an alternative to KL DRO as it is less convex and may not hold for overparameterized neural networks. They show that UBO achieves superior performance on large - scale DG ReID and cross - domain ReID benchmarks compared to standard baselines. They also propose a change - of - magnitude ( CofM ) technique to improve the generalization performance of UBO under distribution shifts in real - world scenarios. The main contributions of the paper are as follows :   ( 1 ) This paper proposes a new method to learn model representations that are ready - to - use cross domain representations for direct cross - data evaluation ( DG ReID ), where the model representations are obtained from a neural network and the domain is assumed to be that of the target domain. This model is then used to train two neural networks, one based on the KL - DRO method and another based on UBO. The network on the UBO side learns a model that is robust to perturbations and the other on the DRO - based model that learns to capture the convexity of the data distribution. The two networks are trained in a way similar to Deep Neural Networks ( DNN ), but DNN has a pre - trained set of latent variables that are not subject to domain - invariant noise, and DNNs trained with DNN activations are not subjected to privacy or privacy concerns. This allows the authors to train their models with and without these latent variables. They compare the performance of their model on the DNN model on DNN vs DNN, and find that the model performs significantly better on the un - domain domain. On the other hand, their model performs much worse on the cross domain domain when the underlying DNN is not fully domain invariant. They evaluate the model on a set of 5 datasets, where 5 of the 5 datasets are uncorrelated ( 4 with and 4 without ). The models perform similarly on all 5 datasets. However, on the 5 unlabeled datasets, the models perform significantly worse ( on the unlabelled datasets ). On 5 datasets the models with Lipschitz noise lower than 0.5 % ( on average ) perform about the same on all of them ( except for the"
SP:62c1f734b7f6c6e7d5114da6f37c9e3cdda73a23,"Graph Neural Networks ( GNNs ) have been used for property prediction and structured learning problems. However, their efficiency is hindered by practical challenges such as oversmoothing. This paper introduces “ Noisy Nodes ”, a simple technique for improved training of GNN. It involves corrupting the input graph with noise and adding a noise correcting node - level loss. The motivation is that adding noise helps overfitting, and the noise correction loss helps ameliorate overSmoothing by encouraging diverse node latents. The main contribution of this paper is the regulariser that applies well - studied methods in simple ways, which allows even generic architectures not designed for quantum chemistry to achieve state - of - the - art results."
SP:24a1b44f37f8eedbab2047fb84600a322d289f3b,"This paper tackles the set2vec problem, the task of extracting a vector representation from an input set consisting of a variable number of feature vectors. The authors propose a new embedding method based on optimal transport kernel embedding, where a fixed number of learnable queries in attention is used to construct the embedding vector. The set embedding feed - forward network is defined as the maximum - a - posterior ( MAP ) steps, where the estimate of the mixture which is approximately attained by a few MAP steps is multiplied by a number of parameters to obtain the final vector representation.    The authors evaluate their approach on various tasks demonstrating improved performance over the state - of - the - art EM baselines. They also find that OTKE can be seen as a special case of the framework, specifically a single - step EM with extra balanced assignment constraints on the E - step. Compared to OTKE, the approach provides more flexible sets embedding as well as prior - induced model regularization. Furthermore, the proposed set data fitting framework allows unsupervised set representation learning naturally via marginal likelihood maximization aka the empirical Bayes distribution. They evaluate the approach on four tasks : MNIST, CIFAR-10, MNIST-103, and STL-2. They find that the proposed approach achieves comparable or better performance with reduced computational cost compared to previous approaches based on self - attention such as ( Set )Transformers."
SP:b4f7b660b84fe7702fbcc8a96c192abc3a64f045,"This paper studies the problem of unsupervised feature selection in contrastive analysis ( CA ) setting, where machine learning practitioners are interested in discovering patterns that are enriched in a target dataset as compared to a background dataset generated from sources of variation irrelevant to the task at hand. The authors propose CFS ( Contrastive Feature Selection ), a method for performing feature selection   in the CA setting. The main contributions of the paper are as follows :   - The authors develop and study a feature selection method ( CFS ) that outperforms previous state - of - the - art feature selection methods ( SMP, PEARL, etc. ) in both the contrastive and non - contrastive settings. The method is validated on four real - world biomedical datasets, and the authors demonstrate that it consistently outperforms the previous SMP and NLP methods. The major limitation of the proposed method is that it only applies to one type of feature ( e.g., genes ), which is difficult to apply to other types of features ( such as non - genes ) that are relevant to the problem at hand ( i.e. genes present in patients with a given disease, but not present in healthy control subjects ). CFS can be used to perform feature selection for other, but potentially more challenging, forms of feature selection, such as gene pool selection.   The authors conduct extensive experiments to validate the effectiveness of their method and show that the feature selection done by CFS is as good as the one done by SMP or NLP ( although the quality of the features picked by SFP is slightly better )."
SP:bc4f69f23aba2034cbf14cb31bdc7a991806bbf6,"This paper studies the effect of early stopping ( early stopping ) on the generalization of linear regression models when the dimension of the model ( i.e. the number of features ) of the training model is higher than the feature dimension ( ii ) and the sample size of the dataset is smaller ( iii ). It builds upon previous work that early stopping is used to prevent over - training in neural networks. This paper extends the previous work on early stopping in linear models to the setting where the model dimension is larger than the features. Theoretical analysis is performed to show that optimal early stopping corresponds to the training process of a deep neural network, and experiments are conducted to show the effect early stopping has on generalization. The paper also presents results on whether early stopping can help mitigate “ double descent ” ( e.g., double training ) in various settings.   The main contributions of this paper are the following :    1 ) A theoretical analysis of the relationship between early stopping and model dimension and sample size for training linear models. Theorem 1 shows that the difference in generalization behavior between the model generalization when early stopping happens on a dataset with dimensionality higher than dimension and when the dataset has dimensionality lower than dimension is a sign that the model is generalizing too much. 2 ) Experimental results are provided on the following tasks ( linear regression regression on logistic regression, linear regression on CIFAR-10, classification on MNIST, and classification on the Fashion - MNIST dataset ) that show that the early stopping improves generalization both theoretically and empirically."
SP:ede87b50cd9c4a6533f17e3e5ddfaaeaaac71dcf,"This paper proposes a new method for regularizing policy gradients with entropy regularization. The authors first regularize the Shannon entropy function, and then propose a new policy gradient method based on the Newton method. The proposed method is claimed to enjoy Newton - type quadratic convergence near the optimal policy. The main contributions are the following :    1 ) The authors develop a new regularization method for the policy gradient algorithm based on Newton.   2 ) They use this regularization to reformulate the Shannon policy gradient as a policy gradient, and apply it to various entropy functions. The resulting algorithm reproduces the natural policy gradient ( NPG ), which is then generalized to other entropy functions and obtained new algorithms. 3 ) They prove that all of the algorithms under the regularization condition converge faster than other state - of - the - art algorithms."
SP:3535504f7599b1f39239f7cd8e09acd40fa8fdf0,"This paper proposes a general approach to generalize efficiently using text - based games ( TBG ) for grounded language understanding and studying problems like generalization and sample efficiency. The approach is based on case - based reasoner to collect instances of positive experiences from the agent ’s interaction with the world in the past and later reuses the collected experiences to act efficiently. The proposed approach is a general method inspired by case reasoning to train agents and generalize out of the training distribution. It can be applied in conjunction with any existing on - policy neural agent in the literature for TBGs. The experiments show that the proposed approach consistently improves existing methods, obtains good out - of - distribution generalization performance, and achieves new state-of - the - art results on widely used environments.   The main contributions of this paper are the following :   1. A new approach to collect and use case representations to learn case representations from the training data to learn a generalization framework that generalizes efficiently from the collected representations to the real - world world experience. This approach is referred to as the Case - based Reasoning - Based Reasoning ( CBER ) approach. 2. A collection of case representations is used to train a neural network that uses the CBER - based reasoning to generate a set of actions that generalize from the learned representations. 3. The collected experiences are then used to generate new actions that leverage the learned case representations using the learned policy to interact with the real world in order to increase the agent's generalization capabilities. The method is evaluated on a variety of grounded language datasets and compared to several RL methods."
SP:9a5dd0148a15dc5b4d2bc6762dfe8a8991f8866c,"This paper proposes a two - stage method to distill multiple word senses from a pre - trained language model ( BERT ) by using attention over the senses of a word in a context and transferring this sense information to fit multi - sense embeddings in a skip - gram - like framework. The first stage is to train the sense disambiguation mechanism in the model with a distribution over word senses extracted from the output layer of BERT. In the second stage, the training is carried out using an embedding - based topic model ( ETM ). Experiments on the contextual word similarity and sense induction tasks show that this method is superior to ( and can outperform ) BERT in tasks with state - of - the - art language models. Further, experiments on downstream tasks demonstrates the benefits of using this multi -sense embedding in a downstream application.    The main contributions of this paper are the following :   1. The authors develop a method to train a language model using a distillable sense distillation pipeline. This distillation process can be used for language understanding tasks, but is unsuitable for resource - constrained systems. 2. It is possible to use one of the embedding vectors from BERT to encode multiple different meanings of words, which may incur errors due to polysemy. 3. The method is tested on the task of predicting the meaning of words from the context, and it is shown to outperform BERT when the sense information is transferred from one word embedding to another embedding."
SP:e4cdba0fc7cd7f440d4436219f3959d8d5e2ad28,"This paper proposes to use the same architecture and pretrained weights of a neural net model to understand 3D point - clouds as used in 2D image and neural net models. The authors empirically investigate the feasibility of the transfer by inflating 2D convolutional filters from FIP - trained models to 3D models and finetuning the inflated 2D / FIP filters. They show that the 3D - trained point - cloud models with the inflated convolutionsal filters can achieve better performance on the few - shot classification task compared to models that do not inflat the convolutions and have to tune the filters manually. Moreover, the performance of the point cloud models trained with FIP improves as the number of target images increases.    The empirical results are presented in two main sections : ( 1 ) Empirically, the authors show that using the same 2D model architectures and weights is enough to achieve competitive performance on 3D Point - Cloud classification, and ( 2 ) The transfer method is shown to improve the performance on several other tasks, which the authors do not explain why."
SP:dc99c307931ae9c5d4a1b998dc94cfc6ac78d11f,"This paper proposes a method for training autoregressive generative models based on an energy - based learning objective to overcome the limitations of chain - style conditional modeling due to exposure bias and lack of long - range coherence. To this end, the authors propose a joint distribution matching approach where the joint distributions are constrained at each time step of the learning objective using a GAN - like approach. The joint distribution is learned using a neural network based on GANs, but unlike previous work, here the authors train the entire model efficiently without requiring an MCMC process. The authors show that the joint distribution approach is capable of alleviating the exposure bias problem and increase temporal coherence by imposing a constraint which fits joint distributions at each step. The method is evaluated on a variety of tasks, covering benchmarks like language modeling, neural machine translation, and image generation to demonstrate the effectiveness of the proposed approach.    The contributions of the paper are as follows :   - The authors propose an approach to train a generative model based on a joint learning objective inspired by the GAN. This approach is tested on a set of tasks where the goal is to learn a learning objective similar to the one used in the original GAN paper, except that the objective does not require the use of an extra neural network ( as is the case with chain - based models ). The experiments show that it is able to achieve better performance compared to the previous joint distributions approach and achieves better accuracy than the joint GAN approach."
SP:51e748c55bd4134047098559577fa3f37aa7433a,"Adversarial training ( AT ) methods typically incorporate adversarial examples during training to strengthen the robustness of a DNN - based classifier. This paper proposes a new framework that connects the two existing AT methods PGD - AT and TRADES and introduces a new distributional robustness algorithm PG - AT - MAE. The main contributions of this paper are as follows. First, the authors propose a new series of risk functions that is meant to bridge the gap between the adversarial training and the distributional AT methods. The authors also propose a method for evaluating the differences between PGD and AT algorithms. Experiments on deep neural networks ( DNNs ) and image classification algorithms ( CIFAR-10 and ImageNet ) show that PG - AGE and PG - CATE robustness algorithms outperform their AT counterparts in various settings."
SP:f192046ea8ad61bfc8e05a0ddb90a8bd15b4640b,"This paper proposes a novel unsupervised representation learning framework for multivariate time series, which is a challenging problem due to its complex dynamics and sparse annotations. The main contribution of this paper is the introduction of the BTSF module, which learns representations of time series through cross - domain interactions with Spectrum - to - Time ( S2T ) and Timeto - Spectral - Aggregation ( T2S ) modules. The authors argue that existing multimodel time series representation learning methods mainly adopt the framework of contrastive learning and involve the data augmentation techniques to sample positives and negatives for contrastive training, which may lead to biased sampling and incorrect optimization with false negatives due to the loss of global context. They also pay no attention to incorporate the spectral information and temporal - spectral relations in feature representation. To address these problems, the authors propose a novel framework, namely, Bilinear Temporal - Spectrumral Fusion ( B TSF ), to explicitly encode the affinities of abundant time - frequency pairs and iteratively refine representations to better preserve global context and capturing long - term dependencies. Extensive experiments are conducted on three major practical tasks for time series such as classification, forecasting and anomaly detection, which are the first to evaluate on all three tasks. Results shows that BTS F achieves the superiority over the state - of - the - art methods and surpasses them by a large margin across downstream tasks. Code will be released."
SP:ef54840009afb095c67bbbc29a7824c20a375ee8,"This paper proposes an algorithm for automatically adjusting the learning rate during gradient descent for deep neural networks ( DNNs ). The learning rate is a function of the weight of the weights in the DNN models, and an extra gradient descent step is added to the gradient of the mean and standard deviation of the gradients to obtain an effective learning rate. The proposed method trains the learning and learning rate along with the model weights, akin to line - search, to select an appropriate learning rate that is robust to the initial learning rate and batch size. The paper provides theoretical analysis of the proposed method and experimental results on a variety of settings, showing that the method is cost - effective and robust to batch size variation. The method is applied to two gradient descent schemes, where the first and second - order gradients are treated as functions of consecutive weight gradients, and the scheme is extended to accommodate for learning rates of different learning rates per layer.   The main contributions of this paper are the following :   ( 1 ) The paper proposes a learning rate adjusting algorithm that is based on the idea of line search, where an extra step of gradient descent is added at the end of the gradient descent steps to the learning of the parameters of the model. This idea is similar to line search in the sense that the extra gradient step is motivated by analyzing the structure of the neural network weights and finding the one that maximizes the least - squares learning rate with the highest weight. This leads to a more robust learning rate compared to the line search. ( 2 ) The second contribution is a scheme that applies the proposed learning rate adjustment algorithm to gradient descent during the gradient ascent step of the first layer of each DNN gradient. This allows the algorithm to adaptively adjust the learning during gradient ascent to the second layer to accommodate learning rate of the second and third gradients. ( 3 ) The authors conduct extensive experimental results to validate the effectiveness of the method and show that the scheme can be applied to a plethora of different settings, demonstrating that it is more robust than the naive approach proposed in the naive setting and is able to adapt learning rate as well as batch size in the case of larger batch sizes."
SP:263c787361cd6d4443ce516d389c694d0fe44b28,"This paper proposes a meta - reinforcement learning method, CoMPS, for sequential multi - task learning. In this setting, the agent ’s goal is to achieve high reward over any sequence of tasks in order to complete a task in a sequential fashion. To this end, the paper proposes to meta - train the agent in an incremental fashion, over each task in the sequence, without revisiting prior tasks. The meta - training is carried out in two stages :    1. The agent trains two meta - policies ( meta - policy policy search and meta - RL policy search with the meta - learner ) using the experience from meta - learning to prepare for the first task 2. The policy gradient is used to compute the reward for the agent to achieve at the end of each task 3. The reward is computed using the policy gradient of the previous task and the agent's previous experience on the tasks to learn the best way to achieve the high reward.   Experiments are carried out on 5 tasks in the continuous control setting, where the agent is given access to all previously seen tasks via the task distribution network. They compare the proposed method with two prior methods, namely ( 1 ) LQR - DQN and ( 2 ) RL - MCTS, and show that the new method outperforms the methods from both of them in terms of generalization ability to new tasks, but not generalization capability to challenging new tasks. They also compare the method with methods from continual learning and off - policy meta - enforcing, and find that the method is slightly more general than the methods on some tasks, though the generalization is slightly worse on some of the new ones."
SP:2bd729b7aa045bf74e31229c9e76e57af36e804b,"This paper proposes a novel method to generate multiple human - in - the - loop triggers to attack classifiers poisoned by adding a small “ trigger ” to a subset of the training data, such that the presence of this trigger at test time causes the classifier to always predict some target class. It is often implicitly assumed that the poisoned classifier is vulnerable exclusively to the adversary who possesses the trigger, but this paper empirically shows empirically that this view of backdoored classifiers is incorrect. The authors propose a new threat model for poisoned classifiers, where one without knowledge of the original trigger, would want to control the poisoned one. Under this threat model, they propose a test - time ( i.e. human ) time - out - time attack that generates multiple effective triggers by generating multiple effective alternative triggers without access to the initial trigger and training data. They construct these alternative triggers by first generating adversarial examples for a   each of the proposed triggers by extracting colors or cropped portions of smoothed adversarial images with human interaction. They demonstrate the effectiveness of their attack through extensive experiments on high - resolution datasets : ImageNet and TrojAI. They also compare their approach to previous work on modeling trigger distributions and find that our method are more scalable and efficient in generating effective triggers that those of the previous methods. Last, a user study demonstrates that the method allows users easily determine the existence of such backdoors in existing poison classifiers. Thus, the authors argue that poisoning a classifier invites attacks from anyone who has access to classifier.    The authors provide the following contributions :   1. They propose a novel way to generate human triggers for poisoning classifiers that relies on the idea of “ backdoors ”. This is a commonly -studied “ poisoning attack against classification models, where an attacker adds a “trigger ”   known as the backdoor to a set of training data ( e.g., “ Denoised Smoothing ”, but the attacker does n’t need to know the exact location of the backdoor in order to add it. This allows the attacker to design a method that is robust against backdoor attacks. The method is simple and elegant, and it can be used to design multiple times to generate different backdoors. It can also be used as a fallback when the target classifier fails to generate backdoors for a given backdoor. This method is referred to as “ human in the loop attack ” and it is easy to distinguish between the human and the adversary. The key idea is to first generate multiple instances of the same backdoor using the same dataset, and then extract colors or crops from each one of them using the extracted images. This process is called extracting colors. In the first instance, extract the colors from the first batch of"
SP:e58ab0e3cff6b18013145a1a99cfa9da0a3d872f,"This paper proposes a new method for distilling conditional GANs based on StyleGAN2, an extension of the StyleGAN architecture. The method is based on the idea that the teacher and student generate different outputs given the same input latent code, and hence distilling methods based on standard knowledge distillation losses typically fail to distill well under heterogeneous heterogeneous code. To tackle this challenge, the authors propose to use a latent - based distillation loss that preserves semantic information of generated images. Based on this approach, they propose a novel strategy to initialize the student model with the teacher model in order to ensure the output consistency to the maximum extent. To further enhance the semantic consistency, they enhance the training of the style module to ensure that the style information is informative and relevant to the task at hand. They conduct thorough analysis about the reasons and effects of the output discrepancy issue, and identify that the Style module plays a vital role in determining the semantic information. The authors conduct extensive experiments to evaluate the effectiveness of their approach. They show that the new method outperforms existing GAN distillation methods by a large margin.    The main contribution of this paper is a comprehensive overhaul of distilling unconditional GAN, especially for the popular styleGAN2 architecture. It provides a comprehensive analysis of the main causes of output discrepancy in StyleGAN and proposes a method to address it. The style module is extensively studied and identified as the key component that plays the most important role to determine the output information of the generated images, leading to significant improvements over the previous methods. The methods proposed in this paper are validated on both synthetic and synthetic data using synthetic data and extensive experiments on real - world datasets to validate their theoretical and empirical results. The main contributions are :   1 ) A new unconditional distillation method for StyleGAN, named Stackelberg - StyleGAN-2, which outperforms previous methods in terms of output consistency ( output consistency ) and semantic information ( semantic information ). This method is validated on synthetic data ( text, images, videos ) and real world datasets ( text and videos ). The experiments show that it outperforms other methods such as StyleGAN - GAN - R, StyleGAN ( although it is not fully trained and is not trained with synthetic data, it is trained with data from StyleGAN to train the model and it is possible to train it with the synthetic data via style"
SP:2c2231743fa33b95828c6615263954ce1c05f95d,"This paper proposes a general methodology for generating online approximations of offline algorithms based on a multi - task learning model trained using graph neural networks. The offline learning model is trained to predict behavioral patterns in graphs based on events that have already occurred and that are likely to happen in the future, while keeping an eye out for patterns that are differentiable and can be used to predict the future behavior of the offline algorithms. The paper proposes to model the offline trajectories of a set of nodes in a graph using a neural network that takes as input two trajectories from the current graph and predicts the next two steps from each one. The trajectories are obtained by taking the nodes from the graph as input and projecting them to the next graph in the set of edges. The goal is to obtain an offline algorithm that is robust to changes in the trajectories that occur in the past that would lead to an out - of - distribution update of the nodes in the graph. This offline algorithm is then approximated with the help of a graph neural network trained to keep track of the transitions in the nodes that have occurred so far using the learned trajectories. The method is validated on synthetic data and historical stock market data.   The main contributions of this paper are as follows. First, the paper proposes and studies a general method for generating offline algorithms that is easy - to - interpret and differentiable ( e.g., it is able to distinguish between the predictions of an algorithm that has happened and the ones that have not and vice versa ). This method is tested on synthetic and historical data, where it is shown to be able to generate plausible offline algorithms as well as generating plausible trajectories in offline settings. Second, the method is applied to real - world data where the prediction is more difficult to interpret. This shows that it is better able to handle the offline data compared to synthetic data. Third, the model used for offline algorithms is also more flexible and end - to end differentiable compared to the one used in the offline setting, which is claimed to be the first one that discriminates between the offline and online worlds. This is demonstrated by comparing the performance of the model on real and imagined worlds using synthetic data, and the prediction performance on imagined ones."
SP:ee3a21d2fb8a073099aa200129a53c31f3b6561d,"This paper studies the problem of training Gaussian Processes ( GP ) models with sparse variational approximations, where inducing points are defined in an approximate posterior distribution q of the observed data and used to train the model. The main contribution of this paper is to develop a method, called Sparse GP ( SGP ), that uses variational inference to train GP models with variational posterior distributions q, to reduce the training instances of inducing points O(M^2 ) per iteration, where M is the number of training instances. SGP trains a GP model with a variational distribution q, where the parameters of the distribution q are estimated from observations using a neural network. The inducing point locations are defined by considering them as parameters of a Gaussian distribution q. This paper proposes to learn these inducing points by considering the observations as an input to the neural network, and to use the parameters as input to a generator that outputs the inducing points. Experiments are conducted to evaluate the performance of SGP with and without inducing points, and the main contributions of the paper are the following :   ( 1 ) In the experiments with SGP, the authors show that SGP performs on par or slightly worse than other state - of - the - art sparse generative models. ( 2 ) However, with the inducing point approach, the dependency on the input data is reduced drastically, which allows SGP to scale to larger datasets and have faster training and prediction times. ( 3 ) On the other hand, experiments with a different SGP approach using a different number of inducing point leads to slightly better performance than SGP. ( 4 )"
SP:f20c99b441545047a16ae524cc2e317b2c3787a2,"This paper proposes a protocol for secure ( BY - BY - tolerant ) decentralized deep learning. In contrast to typical deep learning algorithms, which rely on a server - only communication channel to receive updates from peers, the proposed BY protocol relies on the communication of the entire training team, including the sender of the updates. The idea is that a single person or entity can jeopardize the training run by sending incorrect updates, whether deliberately or by mistake. To prevent this from happening, BY protocol establishes a BY server that receives all updates from the participating parties and reports only the ones that are safe to do so. The authors provide theoretical analysis of BY protocol under the assumptions of Byzantine and Sybil attacks and show that it has a marginal communication overhead overhead. They also provide theoretical bounds for its resistance against Byzantine attack and provide experimental results on image classification and modeling.   The main contributions of the paper are the following :   1 ) The authors propose BY server - based deep learning protocol. This protocol is based on the idea of BY ( Byzantinetolerant ), which is a BY layer added to the top - k layer of the deep learning algorithm ( e.g., a layer that takes as input the parameters of a model conditioned on the input of another model ). This layer encodes the model parameters of the input model as the output of the BY layer. This allows the authors to define the first layer parameters ( $ \mathbb{R}^2 $ ) of the post - processing layer as a weighted sum of parameters of input and output of outputs of the previous layer. Theoretical analysis of the proposed by the authors shows that the proposed protocol has a lower communication overhead ( less than 1 % ) compared to baselines trained with Byzantine / sybil attacks ( which uses more communication overhead ), and that the protocol is more robust against Byzantine attacks ( higher bounds on the number of parameters required for the BY server is preferred ). The experiments show that BY outperforms the baselines. 2 ) In addition to the theoretical analysis, the authors conduct large - scale experiments to validate their protocol. The results show that the BY protocol is robust against the presence of Byzantine attacks and have a higher communication overhead. 3 ) The protocol is applied to distributed deep learning on MNIST and CIFAR-10, and the results indicate that BY is proving to be effective."
SP:93894f20ab2593e5237b6972fef9fe63e96af89a,"This paper presents a mesh - free learning algorithm based on the Lagrangian method for obtaining approximate numerical solutions of the equations of fluid dynamics, which has been widely applied to weakly compressible turbulence in astrophysics and engineering applications. The authors present a learning algorithm that learns a hierarchy of parameterized and “ physics - explainable ” SPH informed fluid simulators using both physics based parameters and Neural Networks as universal function approximators. The learning algorithm develops a mixed mode approach, mixing forward and reverse mode automatic differentiation with forward and adjoint based sensitivity analyses to efficiently perform gradient based optimization.   The main contributions of this paper are the following :   ( 1 ) The authors propose a physics - informed learning method that is capable of solving inverse problems over the physically interpretable parameter space, as well as over the space of Neural Network parameters ; ( b ) learning a learning hierarchy of parameters that learns to build a machine learning model with SPH parameters that is robust to perturbations up to a certain limit ; ( c ) the authors propose an automatic differentiation strategy that allows for more complex regimes of interest with respect to the training sets beyond training sets, which they show improves interpretability, generalizability ( over larger ranges of time scales and Reynolds numbers ) and generalisability ( preservation of physical symmetries ). In particular, the authors show that ( a ) learning the parameters of the Neural Network enables the learning algorithm to learn parameters that are physically plausible enough to solve the inverse problem over the $ \mathcal{L}$ space, ( b) learning a network parametrization that is physically plausible using the parameters as input to the learned parameters, and ( c) learning the distance between ground truth $ l$ and the ground truth of the neural network parameters to learn the distance to the corresponding to the origin of the input $ l$.    In the experiments section the authors demonstrate that the proposed learning algorithm is able to achieve better performances than the previous two methods, and that it is faster and more efficient than the gradient based methods. The main reason for the better performances is the authors ’ claim that the learning method is more physically plausible. The experiments are conducted on a set of synthetic data rather than on real data, which is claimed to have more interpretable parameters, which the authors claim gives the impression that the method is “ more physics - aware ”."
SP:d11b81f9ab414fcf430a03cd70c2d3246b678474,"This paper proposes a data - dependent regularization method for the deterministic neural network ( DNN ), which is a deterministic network with deterministic encoder - decoder and decoder units. The DNN is trained by training a neural network with DDPG, a linear layer on top of the cross entropy loss, and the authors propose to use a regularizer that maximizes the entropy between the embedding space between the class clusters of the DNN. This is achieved by synthetically generating between - cluster samples via the convex combination of two images from different classes and maximizing the entropy on these samples. The authors then propose a solution that ( 1 ) maps out - of - distribution samples to high entropy regions ( creating an entropy barrier ), ( 2 ) is more robust to the superficial input perturbations ( using ResNet and Wide -ResNet architectures ) using the proposed regularizer, and ( 3 ) guides the maximum likelihood estimation to prefer a solution ( solution A ) that is more likely to correspond to the predicted distribution in the regions ( A-1 ). The experiments demonstrate that the proposed approach consistently provides much improved classification accuracy, better calibrated probabilities for in - distribution data, and reliable uncertainty estimates when exposed to situations involving domain - shift data ( DPP )."
SP:365490b872464f00634dc7a50d024fceaf0a61ee,"This paper proposes a new self - supervised animation method called Latent Image Animator ( LIA ) to exploit structure representation extracted from driving videos to transfer motion from videos to still images. Previous approaches exploit keypoints or region representations in videos to obtain structure representation, but such approaches fail when the source image and driving video cover large appearance variation, which is the case in the case when source video is a driving video and the target still image is Marilyn Monroe or Emmanuel Macron. To address this issue, this paper proposes to train an auto - encoder model using GANs and self - supervision to estimate the latent structure representation for the animation - model. To this end, the authors develop a linear navigation in the latent space to navigate from source image to target images. To achieve this, they use a set of orthogonal motion directions simultaneously, and use their linear combination, in order to represent any displacement in the manifest space. The authors evaluate their method on three datasets ( VoxCeleb, Taichi, TED - Talk ), and find that their method is significantly more efficient than the state - of - art methods. They also find that the method is more expressive than other structure representation approaches they have considered, which they term as “ self supervised autoencoder ”.   The main contributions of this paper are as follows :   ( 1 ) The authors develop and train an automatic auto encoder based on self supervision to generate images using self supervision. The resulting animation model, called LIA, is shown in Figure 1 to demonstrate the animation quality. ( 2 ) A set of images are shown from the imagenet dataset ( with Marilyn Monroe and Emmanuel Macron as examples ), which shows how the animation looks like when transformed from the original image to the still image. The images look similar to the one seen in the simulator. However, the difference is that the one from the simulator looks like this : the image looks like it is floating in the air. The difference is the difference between the two : the first one looks like a static image and the second one is like a floating in air with a low - resolution frame. The image is then moved to the frame of the second image to get closer to the original one. This change makes the image look more like the original. The second image is used as the input for the facial animation to the animation. The animation results are shown in Figures 2 and 3. In the experiments, it is shown that the animation results look like the following :"
SP:86f9f89f84e117c86478b9afaf087f65524f5472,"Meta - learning is a popular technique to train deep neural networks in a meta - training scenario, where the goal is to learn a task from a large set of tasks, given only a few labeled examples. The problem is that the available tasks may not densely sample the space of tasks. To address the challenge of limited available tasks, the authors propose to augment the task set through interpolation, by meta - learning with task interpolation ( MLTI ). The approach effectively generates additional tasks by randomly sampling a pair of tasks and interpolating the corresponding features and labels. Theoretical analysis shows that MLTI corresponds to a data -adaptive meta - regularization and further improves the generalization of the proposed approach. The experimental results demonstrate that the proposed general MLTI framework is compatible with several popular meta - learner algorithms and consistently outperforms other state - of - the - art meta learner - based strategies."
SP:73d577e9c4f4af5e11a9e5bdb583ee0f50a315f5,"This paper proposes a new method called Fair Normalizing Flows ( FNF ) to enforce fairness of downstream predictors of learned representations produced by fair representation learning ( FRL ). FRL trains a latent representation encoder to estimate the distance between the latent representations of two groups ( i.e., the target and the target groups ), and trains a normalizing flow to minimize the statistical distance between them. The main advantage of FNF is that its exact likelihood computation allows us to obtain fairness guarantees on the maximum unfairness of any potentially adversarial downstream predictor ( maximum likelihood guarantee ). The authors experimentally demonstrate FNF's effectiveness in enforcing various group fairness notions, as well as other attractive properties such as interpretability and transfer learning.   The main contributions of the paper are the following :   1 ) A new method to train a model of a learned latent representation of two target groups, trained to estimate their distance ; 2 ) A method to enforce fairness on a dataset of target groups produced by FRL - based adversarial predictors ; and 3 ) An approach to enforce group fairness on the dataset generated by a different adversarial predictor ( which is different from the one used in the original FRL approach )."
SP:404d5643327f60f0f06f820033a56081f9e01900,"This paper proposes a novel graph neural network ( GNN ), Count - GNN, for isomorphism counting subgraphs. The main idea is to replace the node - based message passing mechanism in typical GNNs with an edge - centric message passing scheme, which aggregates messages on nodes. The authors argue that traditional node - oriented message passing methods are inadequate for structure matching due to the high computational cost involved. To tackle this challenge, the authors propose to use edge - weighted message passing, where messages on edges are propagated and aggregated based on the edge adjacency of the query and the target graph. The edge message passing algorithm is then used to match the representation of the input graph corresponding to the query given the corresponding edge. The input graph representation is customized for each query individually to improve its matching performance. The proposed method is evaluated on several graph - based tasks and achieves superior performance in comparison to the state - of - the - art baselines.   "
SP:5a94f18156ab2949c86de45fcf0de2e16977eebb,"This paper proposes Agnostic Personalized Federated Learning ( APFL ), a federated learning framework where each client uses their own personalized labels and labels others based on the data from a variety of different datasets. The idea of APFL is to train a model that, assuming that the labeling schemes are all synchronized amongst the clients and the data comes from different datasets, trains a model with two key components : Similarity Matching and Kernel Factorization ( SimFed ). SimFed measures task - level similarity based on locally learned knowledge and matches the relevant ones for personalized knowledge reflection. The authors also factorize their model parameters into two basis vectors and the highly sparse masks to significantly reduce the dimensionlaity of parameter space for alleviating knowledge collapse and information loss when reflecting the heterogeneous knowledge. They extensively validate their method on both singleand multi - domain datasets, showing that APFL outperforms the current state - of - the - art federated learners methods.   The authors then study two essential challenges of the Agnostic Federated learning model, namely agnostic personalization matching and similarity factorization, which are crucial for the success of the proposed method. The first requires the model parameters to be agnostic of the clients ’ labels. The second requires the masks to be sparse, which is helpful especially for the case of sparse - masked learning, where the masks depend on the dimension of the input dimension. They both can be used to mitigate the information loss caused by the information collapse caused by information loss due to the lack of similarity between the input and output labels. For the authors use SimFed and the sparse masks are used for the first and sparse masks for the second. They validate the effectiveness on single datasets ( e.g. federatedlearning ) and multi datasets ( federatedpersonalizedlearning ). They also validate the method on the single datasets and multi - datasets."
SP:97f30bea31eccef6c770fbce1e14fd6d2493a178,"This paper proposes Object Dynamics Distillation Network ( ODDNN ), a method to learn object - centric dynamics representations from video clips. This is done by distilling explicit object dynamic representations ( e.g. velocity ) from the raw video input into a learned object dynamics model, and then using a relation module to predict object - pair interactions using the learned dynamic representations of the objects. The method is evaluated on tasks of video events reasoning and video prediction, which are two important evaluations for video understanding. The results show that visual representations of ODDN perform better in answering reasoning questions around physical events in a video compared to representaions of the previous scene representation methods."
SP:ba8e50d1fa9cb824fa3f76c0c691997cd151d760,"Graph neural networks ( GNNs ) with positional encoding ( PE ) often get criticized because they are not generalizable to unseen graphs ( inductive ) or stable graphs ( stable ). This paper proposes PEG, a class of GNN layers termed PEG with rigorous mathematical analysis to address this problem. PEG maintains the original node features and positional features of nodes given by PE, updates the original features to update the updated nodes with the new positional encoding and applies the positional encoding to all the nodes in the training set. Extensive link prediction experiments over 8 real - world networks demonstrate the advantages of PEG in generalization and scalability.    The main contributions of this paper are the following :   1. The paper proposes a new type of positional encoding, PEG-1, to replace the PE - based node features in the original GNN and update the node features with the updated node features from PEG - 2. The new node features can be applied to all nodes in a training set simultaneously, making the task - specific node features independent of the set of nodes. This is in contrast to the previous approaches, which used either the random node features or the distance - based features of the nodes used for node features ( node distance features ). Theoretical and empirical results are provided to justify the advantages and limitations of the proposed PEG."
SP:cf448479f68c3194c1a9e11729bf70d7cc2ae8fd,"This paper proposes a style transfer framework, LaMer, that leverages the intrinsic parallelism within the data to improve the transfer performance of style transfer models with respect to the source and target text style. This is done by training the model on the roughly parallel expressions in the non - parallel datasets with scene graphs, and then employing MLE training, followed by imitation learning refinement. The paper shows that on two benchmark tasks (sentiment & formality transfer ) and a newly proposed challenging task ( political stance transfer ), the proposed model ( LaMer ) not only makes the training more efficient but also generates more readable and diverse expressions than previous models. Ablation studies and human evaluations demonstrate that the model achieves better transfer performance than the previous models and also generates training that is more efficient and makes the learning more sophisticated.   The main contributions of this paper are as follows :   1. The authors propose a new style transfer model with the objective to transfer the source ( text ) style and the target ( image ) style ( image dimensions ) of images from the same source text to the same target text via the self - attention mechanism of a style - transfer model. The idea is to train the model first on the source style and then on the target style using the MLE framework, and refine the model during the refinement phase based on the imitation learning of the target and source styles. 2. The method is evaluated empirically on three datasets ( English, Russian, and Chinese ) and compared with two previous models ( StyleGAN and StyleGAN ). The results show that the proposed method transfers more source style ( more efficiently ) and generates more expressive sentences ( more than twice as many expressions ) compared to StyleGAN. 3. On the other datasets ( Chinese, Korean, and Russian ) the model transfers fewer sentences but generates fewer expressions ( fewer per sentence )."
SP:8f7b2d1020d9e527118b8fb816760c13b0d0bfcb,"Hyper - Relational Representation Learning ( HAR ) is a method for learning representation learning on knowledge graphs ( KGs ) based on hyper - relational edges. In this paradigm, edges may have several key - value pairs known as qualifiers that provide fine - grained context for facts. In queries, this context modifies the meaning of relations and usually reduces the answer set. However, existing algorithms operate only on classical, triple - based graphs, whereas modern KGs often employ a hyper - relational modeling paradigm where each edge in a graph is represented as a set of edges with several qualifiers. In HAR queries, the context of each edge can be differentiable and may depend on the relations, meaning and relations of the query. It is well known that in real - world knowledge graph ( KG ) applications, and existing approaches for approximate query answering ( QA ) cannot make use of qualifier pairs that are available in the query context. HAR extends the multi - hop reasoning problem to hyper -relational KGs based on recent advancements in Graph Neural Networks and query embedding techniques.    The paper proposes to study how to embed and answer such queries and demonstrate in two experiments that qualifiers improve QA on a diverse set of query patterns. Besides that, the authors propose a method to answer queries that only requires access to the query query pairs that satisfy the condition that the query is query - compatible. The paper also proposes a new type of complex queries that can handle queries that fall under this category. The main contributions of the paper are the following :   1. The authors propose to study the problem of how to handle query queries answering queries answering under HAR paradigm. This requires the authors to bridge the gap between the current type of query answering method and the one proposed in [ 1 ] to handle queries answering with a more complex query answering algorithm ( which uses multi - post - hop logic reasoning. This is a challenging problem and the authors have to come up with a new way of thinking about answering such queries. The proposed approach ( Bridge this gap ) is based on the recent advances in GraphNeural Networks ( GN ). This means that the authors first have access to all the features of the graph ( edges, relations, relations and context ) under the HAR paradigm and then use one or more of them to approximate the query pairs ( query pairs. This gives rise to a more efficient way of answering queries. 2. The second contribution is to propose a way of processing query pairs under HAR that does n’t require access to any of the edge qualifiers. This involves using the edge context of query pairs and usually only needs access to one of them ( the other is used for the other query pairs"
SP:5f8b58424a1a8eeb72217e75189d6f773a298a7a,"This paper proposes DYHPO ( Dynamic Hyperparameter Optimization for Deep Learning ), a method that applies hyperparameter search on multi - budget settings using Bayesian methods. The main idea of the method is to use a surrogate for Gaussian Processes ( GP ) that embeds the learning curve dynamics and a new acquisition function that incorporates multi - Budget information. The method is evaluated on 5 large - scale datasets ( 50 MDB test sets ) against 2 state - of - the - art methods ( SGD - SGP and SGD-RNN ). The experiments compare the performance of the proposed method with SGDP and DGD - SGD on 5 datasets ( 5 MDB sets, 2 SGD sets, 1 Gaussian processes set ), 4 Gaussian processes ( Gaussian - based methods ), and 1 stochastic gradient descent. The results demonstrate that the method outperforms the other methods in terms of accuracy and diversity of hyperparameters, and the acquisition function is better than the other two methods."
SP:99d3d94e3af5d2dc7b92c00ac1345d1d2dd0d15b,"This paper proposes to improve Gaussian mixture model inference for cross - platform image compression by using quantization of post - training quantization and deterministic inference of the probability distribution. The motivation is that the current state - of - the - art image compression models can not handle the non - deterministic calculation of the entropy of the distribution over Gaussian mixtures, which makes the probability prediction cross platform inconsistent and frustrates successful decoding. The proposed approach quantifies the likelihood of the target distribution using a well - developed and efficient quantization method. The authors then propose to use this quantization to train the model inference in an integer - arithmetic - only manner, which is much simpler than the existing training and fine - tuning based approaches used in the literature. Based on the proposed method, Gaussian Mixture Model ( GMM ) is trained and the entropy parameters are optimised to be deterministic, which allows to use deterministic computation. The method is evaluated empirically on a set of image classification tasks and compared with Gaussian ImageNet ( GaNet - C ) and Gaussian Compression ( GIC ). The results show that the proposed approach leads to a better performance compared with GIC and GPM. The main contributions of the paper are the following : 1 ) The proposed quantization technique is more efficient than existing training approaches for training the model in terms of quantization, and 2 ) The entropy parameters of the GMC model are optimized so that they are close to deterministic and do not deviate too much from the deterministic distribution."
SP:85d0df515e9e555f3ea1c21d607304dfaeae69c0,"This paper proposes Noise Reconstruction and Removal Network ( NRRNN ), an unsupervised network for noise reconstruction and removal of noise from 3D electron microscopy images. The network consists of three components, i.e., noise reconstruction unit ( RPU ), noise removal unit ( SNN ) and noise synthesis unit ( SEU ), which are recurrent units that are trained to discriminate true signal from noise in 3D EM spectrograms. The noise reconstructions are made by synthesizing the noise signals from the images generated by RPU and SNN in a supervised manner. The SEUs are trained in two stages. The first stage reconstructs and removes the noise from the original images, and the second stage synthesizes the noise signal from the image representations generated by the RNN using the noise reconstruction units and noise removal module.    The network is validated on a set of 3 EM datasets ( FIB - SMC - D, EMC - SMD - D and EM - C - D ), where it is shown to achieve comparable or better results than the one done by a fully - supervised pretrained expert ( in a semi - supervised manner ). The authors also provide a detailed analysis of the network using numerical as well as empirical metrics. The main contributions of the paper are as follows :   ( 1 ) A new noise reconstruction network is proposed for the 3D emission spectrographic data sets of the cellular ultrastructure ( e.g., EM - SVM ). This network is inspired by the idea of using gated recurrent units ( RUB ) to synthesize noise signals during the training of the EMIRA training. The idea is to use the sequential data to reconstructions to distinguish true signals from noise signals at inference time. This allows the network to capture more noise signals than the training - only training ( in the sense that the noise reconstructed from the data does not affect the prediction of the true signal ). ( 2 ) Noise SEU and SEU are trained using supervised manner to generate noise signals, which is tested on the three data sets. The experiments show that the network produces comparable results to the one trained in a pretrained manner ( with the exception of noise reconstruction )."
SP:e6275b0b103fa90dcebcdd3d3c14c830c3402972,"This paper proposes a new approach for improving the performance of Graph Neural Networks ( GNNs ) for node property prediction tasks based on label propagation ( LP ). The main difference between LP and GNN is that while the former uses message - passing layers that share neighborhood information to transform node features into predictive embedding embeddings, the latter uses a parameter - free diffusion process to spread label information to unlabeled nodes via a distribution over nodes. In this paper, the authors propose to use a randomly - selected portion of the training labels as GNN inputs, concatenated with the original node features for making predictions on the remaining labels. This so - called label trick accommodates the parallel use of features and labels, and is foundational to many of the use of the top - ranking submissions on the Open Graph Graph Benchmark ( OGB ). Under certain simplifying assumptions, the stochastic LP label trick can be reduced to an interpretable, deterministic training objective composed of two factors : ( 1 ) a data - fitting term that naturally resolves potential label leakage issues, while the second serves as a regularization factor conditioned on graph structure that adapts to graph size and connectivity, and ( 2 ) a generalization factor that is adaptable to graph structure. The authors prove that under certain assumptions ( e.g., the assumption that labels are regularized and features are smoothed across the graph, and that there is a sufficient distance between the input nodes and labels ), the LP can improve the performance. They then provide experiments to motivate a broader range of label trick use cases, and provide a perspective to motivate the efficacy of these extensions. The experiments are conducted to evaluate the proposed approach."
SP:b6cbc3661f9c440687c3dd01ee35a118c87db377,"Authors propose to model machine theory of mind ( ToM ) in multi - agent scenario, where agents can speak, listen, see other agents, and move freely through a grid world. Authors build upon previous work that has attempted to measure the ability of machines to develop a ToM theory in a speaker - listener scenario, with one agent attempting to understand anothers “ mental state ”. Authors propose a more flexible and symmetric scenario where all agents can participate in all aspects of SymmToM. Authors develop deep reinforcement learning models that model the deep states of the agents and the deep neural networks that allow them to predict the states of other agents. Authors test their models on a series of tasks that measure agent performance on MNIST, CIFAR-10, MNIST-1, and MNIST - UCI tasks. Results show that the best agents fail to achieve performance comparable to other agents with no ToM, while the best with ToM and access to the gold - standard training data achieve comparable performance with no such ToM. Results also show that developing a deep network capable of understanding another agent ’s ToM requires developing the same network as each agent to maximize each agent’s rewards. Authors conclude that the modeling of ToM in multi agent scenarios is very much an open challenge, and developing deep networks capable of modeling the ToM of agents is essential to develop effective strategies to solve the tasks.   Contributions :    Authors develop and test a deep neural network that can generate data for testing the ability to understand others ‘ ToM ’ and develop deep networks to understand each other agents ’ ToM ; authors develop a framework to test this ability in a multi agent scenario and develop methods to train agents to develop deep network for understanding others ’ MindSets."
SP:f8ce83805eee46c6c196e8477bf10d8d7f7e0f46,"This paper investigates zero - shot object detection for robots in indoor scenes. The authors use the YCB Video Dataset ( YCBVDA ) to train a vision system for robots. To train such a robot vision system, pictures of all the objects in the dataset need to be taken with different orientations and illumination. The main contribution of this paper is to propose a method for doing so using images taken from the same set of objects that is applicable to the manufacturing setting where objects and the environment do not change frequently. In contrast, in the vision of smart manufacturing and high - mix - low - volume production, parts and products for robots to handle may change frequently and so it is unrealistic to re - train the robot vision systems for new products and tasks. Under this situation, the authors propose the necessity to introduce a hot concept, Zero - Shot Object Detection ( ZOD ). ZOD is a subset of unsupervised learning ( U - NET ), and it aims to detect novel objects in an image with the knowledge learned from and only from seen objects. In particular, ZOD detects daily objects ( objects that are present in the image during the training time ) whose size and environment are similar to that of the manufacturing setup since objects of different sizes and environments are present throughout the training process. This paper is the first one to do so at the object size level and on the dataset of 21 different objects. Different from previous works, the detection of daily objects is actually more challenging since the knowledge that can be learned from each object is very limited. For the experiments, authors propose to train ZOD using a dataset consisting of objects of the same size and from different environments. The dataset is divided into two subsets : one for indoor scenes and one for outdoor scenes. On the indoor scene subsets, the indoor scenes subsets are used for indoor scene detection and outdoor scene subset for outdoor scene detection, and the other subset is used for zero shot detection on the outdoor scenes subset. The experiments are conducted on the indoor dataset only.    The authors test their method on the following environments : ( 1 ) indoor scenes ( indoor scenes only ), ( 2 ) outdoor scenes ( both indoor and outdoor scenes with different sizes of objects, ( 3 ) indoor scene with different environments and different environments ( 4 ) outdoor scene and objects from other environments ( 5 ) Outdoor scenes ( excluding the ones in between indoor and indoor scenes with a different size range of objects and their environment"
SP:aa1dcd9217270010f16a00004facede942efea17,"The paper proposes a new method for video prediction based on an autoregressive latent video model. The proposed method is based on a transformer - based image generator ( VQ - GAN ) and a latent video prediction model trained on the latent space of the image generator. The image generator produces high - fidelity ( f - fidelity ) video frames ( 256x256 ), which the proposed method can then use to predict high f - fidelity video frames with minimal modification to the underlying image generator model ( with the possible exception of fine - tuning parameters ). The model is trained using supervised learning and self - supervised training. To improve the performance of the model, the authors propose to use additional techniques of top - k sampling, data augmentation and augmentation to further improve video prediction quality. The experimental results on standard video prediction benchmarks and large - scale datasets show that the proposed proposed method achieves competitive performance to state - of - the - art approaches on standard $ \ell_p$ and $ \epsilon$ video prediction approaches with fewer parameters, and enables high - resolution video prediction on complex and large- scale datasets.   The paper is published with supplementary material and videos. The manuscript contains the following main contributions :   1. The authors develop a new video prediction method based on latent video models and learnable latent frames. The latent frames are trained using a transformer based model, and the latent frames and latent dynamics model are learned using an auto - regressor based on the environment dynamics model. 2. The resulting video frames are used to predict video duration. 3. The method is evaluated on four video datasets, and compared to two baselines. The results indicate that the method outperforms the baselines in terms of Fidelity ( F - F ) and Accuracy ( A - F with a F of f(g ), with the average F of F being the best of the three other methods."
SP:7f57896afd63bc869d2db6ddf7abbeaa71daae11,"This paper studies the integration of ViT - based generative adversarial networks ( GANs ) with ViT discriminators for image generation. The authors claim that the existing regularization methods for GAN training interact poorly with self - attention, causing instability during training. To resolve this issue, they introduce several novel regularization techniques for training GAN with ViTs and obtain comparable performance to the leading CNN based GAN models on three datasets : CIFAR-10, CelebA, LSUN - 10, and CelebA - CelebA and LSUN bedroom. They also examine architectural choices for latent and pixel mapping layers to ensure convergence of GAN - based discriminators to ViT generators.    The main contributions of this paper are the following :   1. Introducing a new regularization method, ViTGAN, to train discriminators and latent discriminators in GAN framework using ViTs. 2. Empirically, this approach is shown to achieve comparable performance as the one used to train image generation models, GAN ( Zhang et al., 2019 ). 3. The techniques introduced are tested on a series of image generation tasks and are evaluated to compare with a set of existing methods, including GAN and ViT."
SP:bbae3afcaea0a2e54904cb8daaed7df4fe37da6e,"This paper proposes a novel approach for generating good likelihoods for generative models trained on high - dimensional image data distributions. The authors propose to model the distribution of high dimensional latent space using variational autoencoders and posit that the nature of such distributions poses an intrinsic challenge for good likelihood modeling. They argue that much of the entropy in these distributions is attributable to visually imperceptible information that is difficult to model. To tackle this challenge, the paper proposes to first prioritize the modeling of visually perceptible information to achieve good sample quality, and then subsequently model the information that provides the bulk of the likelihood signal ( the "" entropy signal "" ). The paper is well - written and well - structured, covering a wide range of data distributions and training objectives. The approach is simple and intuitive to me : it decomposes the task of image generative modeling explicitly into two steps :    1. Modeling the latent space of the image data distribution to generate good likelihood ( $ \mathbb{L}$ ).   2. Establishes a distribution of latent space $ D$, and trains a model $ G(G)$ based on the distribution $ D$.   Note that the authors explicitly state in the paper that “not all bits are created equal”, and demonstrates that this property can and should be exploited in the design of the generative model to ensure that all the “ bits ” that are “generative ” can be modeled successfully. The work highlights the importance of the well ( the well - known adage “ all bits should be created equal ” ). It also highlights the important aspects of the work ( e.g., “ the entropy signal should not dominate the training objective ”, which “ creates an easy way to achieve competitive likelihoods without successful modeling of the visually perceivable bits. ”   The paper concludes with a collection of experiments that compare the performance of the proposed approach against other approaches to generating good likelys for latent space."
SP:bfed56018134ec66cde9a7e958df964d4cca3164,"Diffusion - based models ( DPMs ) are a class of powerful generative models that have achieved a lot of success in recent years. However, the inference of these models is expensive because it generally needs to iterate over thousands of timesteps. A key problem in the inference is to estimate the variance in each timestep of the reverse process. This paper proposes Analytic - DPM, a training - free inference framework that estimates the analytic forms of the variance and KL divergence of a DPM using the Monte Carlo method and a pretrained score - based model. The authors show that optimal reverse variance and the corresponding optimal KL divergence exist as analytic forms w.r.t. its score function. Based on this observation, the authors propose to improve the training - likelihood of the log-likelihood of various D PMs, and enjoy a 20 to 80 percent chance of success with their new method."
SP:3f935ba5784c3e86db72421426bc479061af1a4b,"Recently, vision transformers ( ViTs ) have been proposed as a competitive alternative to neural network - based models ( CNNs ) for automated medical image diagnosis tasks. In this paper, the authors investigate whether it is feasible to switch to ViTs for medical image classification as well, or if we should keep working with CNNs – can we trivially replace CNNs with transformers? The authors consider this question in a series of experiments on several standard medical image benchmark datasets and tasks, using ViTs as an alternative to CNNs. The experiments show that, while CNNs perform better if trained from scratch ( e.g., off - the - shelf vision transformer can perform better than trained CNNs when pretrained on ImageNet, both in a supervised and supervised - self - supervised setting ), ViTs perform better in the par - with - CNNs setting. ViTs also outperform CNNs in the synthetic classification, detection and segmentation tasks. The main finding is that ViTs have higher performance in the natural image domain than CNNs, which is surprising since ViTs are supposed to be a better model for the synthetic domain.    The main contributions of this paper are the following : 1 ) The authors study the effect of training a transformer - based model on the natural - image domain of CNNs on the classification performance in synthetic and synthetic image domains, and find that it is best to train the transformer first on synthetic images, then switch to the synthetic images after classification. 2 ) The experiments compare the performance of ViTs against CNNs and CNNs ( in synthetic images ) in terms of the number of false positives and false negatives, and the accuracy of the false positives when the transformer is used in the classification task. 3 ) The results show that the performance is comparable or slightly better for synthetic images compared to CNN."
SP:a64e0535f268901e38fd51e027c612ebcdbae1a4,"This paper studies the effect of chunking text sequences into training examples, which are contiguous text segments of sizes processable by the neural architecture. The authors highlight a bias introduced by this common practice, which is that the pretrained NLM can model stronger dependencies between text segments that appeared in the same training example than it can between text sequences from different training examples. This intuitive result has twofold role : 1, it formalizes the motivation behind a broad line of recent successful NLM training heuristics, proposed for the pretraining and fine - tuning stages, which do not necessarily appear related at first glance. 2, it clearly indicates further improvements to be made in NLM pretraining for the benefit of Natural Language Understanding tasks."
SP:59066956fa2e423d5f2d2ea4f91c4ddf6afd4683,"This paper presents a method for learning neural networks to parameterize optimization rules by neural networks and learn those numerical rules via meta - training. The method is referred to as Learning to Optimize ( L2O ) because it attempts to automate and accelerate the optimization procedure for complicated tasks. However, there are two common pitfalls that hinder the scalability and interpretability of this method : ( 1 ) neural networks use extra memory overhead, which limits their applicability to optimizing larger tasks, and ( 2 ) it is unclear what each L.2O model has learned in its black - box optimization rule, so it is difficult to compare different models in an explainable way. To avoid both pitfalls, this paper proposes to use symbolic regression to train neural network - based optimization rules parameterized by a neural network to learn the numerical rules, and proves that it can “kill two birds by one stone ” ( Liu et al., 2019 ).    The main contribution of this paper is to develop and test the concept of “ brand - new perspective ” for learning to optimize with neural networks in order to avoid the pitfalls of scalability issues and the unclear interpretability issue. The authors propose to train a lightweight neural network that can be meta - trained on large - scale problems and outperform human - designed and tuned optimizers. To do this, they establish a holistic symbolic representation and analysis framework for learning the learned optimization rules from neural networks with the help of a new perspective. The resulting framework provides a series of insights for learnable optimizers that can improve the performance of the learned model. In particular, the authors focus on three aspects of this framework :   1. The first aspect is to train the neural network only on non - convex problems, and train the optimizer only on convex functions. This part is crucial to ensure that the learned optimizer performs optimizer ’s predictions correctly. The neural network “ learns “ convex and interpretable ” black box rules for all possible values. This means that it does n’t need to learn rule gradients for each value. 2. The second aspect involves training the model to learn weight functions for each possible value. This is done by using the learned weight functions from neural network parameterized optimization rules and learning weight representations from the black box optimization rules. To train the model this part is done using the learn"
SP:54dfeb363beee9959aecc9e0853ff06e43bd94e4,"This paper studies adversarial robustness for reinforcement learning with deep neural networks ( DNNs ). The setting is adapted from a static setting where the agent uses a static neural network to learn a classification model, to a dynamic setting where it is adaptive to the environment and the environment changes over time. The RL adversary can infer the defense strategy used by the victim agent by observing the states, actions, etc. from previous time - steps and adapt itself to produce stronger attacks in future steps ( e.g., by focusing more on states critical to the agent ’s performance ). To counter this, the authors propose policy smoothing where the policy adds Gaussian noise to its observation at each time - step before passing it through the policy function to guarantee that the final total reward obtained by policy smoothed actions remains above a certain threshold. The authors show that their robustness certificates are tight by constructing a worst - case scenario that achieves the bounds derived in the analysis. The experiments on various environments like Cartpole, Pong, Freeway and Mountain Car show that the method can yield meaningful robustness guarantees in practice.    The main theoretical contribution is to prove an adaptive version of the Neyman -Pearson Lemma – a key lemma for smoothing - based certificates – where the adversarial perturbation at a particular time can be a stochastic function of current and previous observations and states as well as previous actions. The main contributions of the authors are the following :   1. Provable robustness in RL with respect to $ \mathcal(L_\theta$ : $ L_\mathcal{L_T}$ for Cartpole$ is provably provable without requiring the policy to be robust $ \theta \to L_T$ ; 2. Policy smoothing with $ l_\alpha$ policy enhancement is provable robust without requiring $ \alpha \to R_T$. 3. The policy policy enhancement can be thought of as an efficient procedure designed specifically to defend against an adaptive RL adversary, that can directly certify the total reward $ \tilde{M}$ given the adversary's $ M$ actions and the actions taken by the policy. The key idea in this paper is to use this smoothing procedure to improve the robustness of the policy enhancement. To this end, authors propose two approaches. The first one is to firstly use a Gaussian distribution of states and actions from the adversary to get at least some of the states at time $ t(a ) to estimate the value of $ m$ and then use the policy policy to update the reward using the distribution. The second one is a weighted averaging approach where the reward value is calculated based on the distance between the value"
SP:e0f9add5fde18eaab0eeb2b10b14928acc8ec5b8,"This paper proposes a method for predicting the target accuracy between source ( training ) and test ( validation ) accuracy using only labeled source data and unlabeled target data. The proposed method is called Average Thresholded Confidence ( ATC ) and it is a practical method that learns a threshold on the model ’s confidence that is predictive of the accuracy as the fraction of examples for which model confidence exceeds a certain threshold.   The authors experiment ATC on real - world machine learning ( RWM ) tasks ( training / validation ) and datasets ( WILDS, ImageNet, BREEDS, CIFAR, and MNIST ) and show that it outperforms previous methods across several model architectures, types of distribution shifts ( e.g. due to synthetic corruptions, dataset reproduction, or novel subpopulations ). They also provide insights concerning when it works ( ATC estimates target performance 2.4 % more accurately than prior methods, ATC performs better on some toy distributions ). The authors also explore the theoretical foundations of the problem and explore how to identify the theoretical assumptions on the nature of the shift that may cause performance drops. Finally, the authors conduct empirical studies to evaluate the effectiveness of ATC and provide insights about when it does not perform well."
SP:e748bf6ee653087cae825df32a8546f9ccebfcf1,"The paper considers the problem of recovering a set transformation that matches one set to the other, given two point distributions. The registration of the set transformation is critical due to the presence of a large number of outliers, the unknown non - rigid deformations and the large sizes of point sets. The paper proposes a method based on the partial Wasserstein - 1 discrepancy ( PW ) to handle the PW discrepancy and obtain robustness against outliers. The method, called PWAN, theoretically analyzes the Kantorovich - Rubinstein duality for the discrepancy and derives a gradient that can be explicitly computed. Based on the theoretical analysis, the authors propose a method to learn the transformation adversarially with the help of a neural network, which approximates the PW discrepancy by minimizing the loss incurred by the transformation. The authors evaluate the proposed method on two point set registration tasks, and show that the method is robust, scalable and performs more favorably than the state - of - the - art methods.    The paper also proposes a second method, which is called PAN - EL, to train a point distribution matching network ( PDM ) that can handle large scale PDM problems. This method is evaluated on a point - set registration task and shows that it is more robust and scalable than the other methods. On the other hand, on the point set uniform distribution matching task, the method does not perform as well as the others."
SP:f94f77696d100b2638fa2a6d82c8df47db3b6a36,"This paper proposes a meta - feature extraction method, Deep Kernel Gaussian Process surrogate with Landmark Meta - Features ( DKLM ), for transfer learning from hyperparameter optimization ( HPO ) tasks to unseen target tasks. The main idea of DKLM is to learn end - to - end meta - features embeds of the set of evaluated configurations and their respective performance for a set of source tasks and then transfer efficiently on a new ( unseen ) target task. To this end, the authors propose a surrogate network that learns the hyperparameters of the source tasks from the evaluation set and the target task from the dataset. The network is trained jointly with a deep neural network ( DNN ) trained on the source task and meta - trained with the DNN on the unseen target task to capture the similarity between the configurations. The authors demonstrate the empirical superiority of their method against a series of state - of - the - art evaluation sets using OpenML and demonstrate the transfer learning strategy for tackling the sample inefficiency of HPO.    The main contributions of the paper are as follows :   - A surrogate network of hyperparametrized tasks is proposed to learn the parameters of a neural network using transfer learning. This surrogate network, dubbed DKLM, is trained with a DNN and the meta - training procedure for the neural network is performed using DNN learning and transfer learning strategies. - A set of evaluation configurations of the sources tasks is derived and evaluated using the DKLM network. The evaluation results demonstrate the performance of the surrogate network against the original HPO in a wide range of configurations. - The authors conduct extensive experiments to validate the performance and compare the performance with other methods."
SP:e3c57f3589e8ab674644d900c14b3473cd71a23f,"This paper proposes a new method for deep fake detection and attribution based on deep generative models ( DPMs ). The authors propose to use a biometric fingerprinting mechanism for DPMs that allows the model inventors to fingerprint their models during training so that the generated samples containing a fingerprint can be accurately detected and attributed to a source. The key idea of the method is to use an efficient and scalable ad - hoc generation of a large population of models with distinct fingerprints to generate samples that are statistically significant enough to be attributed to the corresponding source. Authors propose two methods to achieve this goal : ( 1 ) Generative Fingerprinting Generator ( GFP ), which generates samples that contain a maximum of 10 fingerprints per model and ( 2 ) GFPT, which is an extension of Fingerprint Fingerprint Tag that generates samples with more than 10 fingerprints. Authors evaluate the effectiveness of their method on the following tasks : ( a ) Generate fake samples from 10 models sampled from the same dataset and ( b ) Distribute samples generated from different models sampled using different fingerprints. The experiments compare the proposed method with methods for detecting fakes ( based on fakes generated by different methods ) and for attributing source fingerprints ( based upon real data and fake samples generated by the same models ). Results show that the method does not only detect fakes but also has a moderate to high effectiveness in attributing the source fingerprints.    The main contributions of this paper are the following : 1 ) The authors develop and develop a method for generating samples from a set of 10 identifiable models that detect the source using a GFPMs and generate samples containing fingerprints corresponding to each of them. The resulting generated samples contain enough fingerprints for each of the 10 models to be statistically significant ( with a small number of samples missing from each set ). This allows for more accurate detection of fakes and attributions of the source. 2 ) The method is tested on a range of DPMs where it is able to detect more than half of the samples as fakes, and it is shown to have a comparable or better accuracy than other methods for generating fake samples."
SP:73bffd1a0856b80d29f7a2b2b68be57882531f07,"This paper proposes a new mechanism for explaining the output similarity between two black box models that output on different inputs. The black box similarity learner uses a model agnostic local explanation for the similarity between the output of the model and the input of the control model. The main idea is to use analogies as a new form of explanation in machine learning. The goal is to identify analogous pairs of examples that share the same level of similarity as the input pair and provide insight into ( latent ) factors underlying the model ’s prediction. The selection of analogies can leverage feature attributions to connect the two forms of explanation.   The main contributions of the paper are the following :   ( 1 ) A new mechanism that uses analogies to identify examples that are at least as good as the black box counterparts as an example of how similar they are. This is the main idea of the method. ( 2 ) Two approaches are proposed to explain similarities between sentences as predicted by a black box model and a state - of - the - art machine learning algorithm. The first approach is based on the idea of post - hoc attributions and the second approach is a mixture of the two approaches. The authors provide examples of how to use the first approach and show that it is more efficient than the proposed analogies in terms of accuracy. ( 3 ) A careful evaluation using quantitative evaluations, a careful user study, and examples of explanations is provided. ( 4 ) The authors apply the proposed approaches to two different settings where the model output is different ( e.g., text - to - text, tabular ), and a setting where data is available only for tabular data. The experiments compare the proposed methods with the baselines from the two settings. The results show that the proposed method is more accurate and more plausible ( on some of the lower bounds ) than some baselines, which is claimed to be the norm of baselines in the literature. ( 5 ) Finally, the authors conduct an ablation study to verify the effectiveness of their methods."
SP:6a3c4ae05d582f8896840483b08c735ced2976bc,"This paper studies the robustness of ensemble neural networks ( ensembles ) in the presence of adversarial perturbations. The authors provide sufficient and necessary conditions of robustness for ensemble models to guarantee higher certified robustness than a single base model under mild conditions. They also propose a lightweight DRT - enhanced ensemble model to provide certifiably robust ensemble models under the model - free assumption. Experiments on MNIST, CIFAR-10, and ImageNet datasets demonstrate that the proposed ensemble model is more certified robust than existing single and ensemble ML models, demonstrating the state - of - the - art certified L2 - robustness.    The main contributions of this paper are the following :   1 ) The authors develop and study ensemble models for robustness defense. The ensemble models are shown to be more robust empirically and theoretically than single models. However, in terms of certifiable robustness, the standard ensemble models only achieve marginal improvement compared to a single model. 2 ) Under the proposed Ensemble - before - Smoothing strategy, the authors prove sufficient conditions for ensemble model to be certified robust. 3 ) The ensemble model with certified margin provides sufficient robustness guarantee for DNNs with large confidence margin."
SP:3002b29c27709780238876d8c3f81bbd6a0f8112,"Graph Neural Networks ( GNNs ) have become increasingly popular architectures for learning with graphs. Recent works have revealed important shortcomings in their expressive power, which has motivated this work to develop expressive power via lower - bounds. This paper analyzes a new method for pooling subgraphs using local neighborhoods that allows different tradeoffs of computational cost and expressive power. First, it proves that this model can count subGraphs of size k, and thereby overcomes a known limitation of low - order GNN. Second, it shows how recursive pooling can exploit sparsity to reduce the computational complexity compared to the existing higher - order GA network. More generally, it provides a matching information - theoretical - matching ( matching information-theoretical ) counterpart for graph representations that pool over representations of derived ( sub-)graphs.   The main contributions of this work are the following :   1. Proposing a new pooling method for expressing lower bounds on time complexity of graph neural networks. 2. Exploiting sparsity in local neighborhoods to increase the expressive power of GNN with lower computational cost. 3. Demonstrating the effectiveness of the proposed method on the task of classification."
SP:5d0cbd84336caf5f31e1f98e11f6733230e4d792,"This paper presents a knowledge integration method based on graph convolution ( GCS ) operation to analyze two knowledge - enhanced models, ERNIE and K - adapter, to investigate the integration of knowledge from outside sources into the two existing methods for knowledge integration, KI and GCS. The authors first analyze the KI method from an information - theoretic point of view and show that KI could be interpreted as a GCS operation. Then, the authors propose a simple probe model, GCS - POMDP ( Graph Convolution Simulator ), to evaluate how well KI can integrate relational and time - related knowledge into the models. They find that while KI is better at integrating relational knowledge, relational knowledge is integrated better in ERNie. They also show that increasing the size of KI corpus may not lead to better interpretability and more fundamental advances may be needed to further improve KI methods. Finally, they conduct experiments to verify that our GCS model can indeed be used to correctly interpret the interpretable KI process, and they use it to analyze time - dependent and relational knowledge better than KI."
SP:7e73948421e98307fceb69a316d8a4e7c4926cda,"This paper studies the effect of the adaptation learning rate in meta - learning with mixed linear regression on the adaptation error. The authors first present a principled way to estimate optimal adaptation learning rates that minimize the population risk of MAML. Second, they interpret the underlying dependence between the optimal adaptation rate and the input data. Finally, they prove that compared with empirical risk minimization ( ERM ), M AML produces an initialization with a smaller average distance to the task optima, consistent with previous practical findings. These results are corroborated with numerical experiments.   The main contributions of this paper are as follows :   1 ) The authors study initial weights that allow fast adaptation to new tasks. The adaptation ( inner loop ) learning rate plays a central role in enabling such fast adaptation. However, how to choose this value in practice and how this choice affects theadaptation error remains less explored than other factors such as the empirical risk and the learning rate of the dataset used for the experiments ( e.g., how much does the adaptation affect the error of the meta - learner on the new task from the one from the old task that was retrained on the retrained task?)? This paper proposes a novel and interesting way to explore this question. 2) The authors then experimentally validate their theoretical findings. In particular, the authors show that when the dataset is sparse ( i.e., does not contain any information that would cause the task to perform poorly compared to the tasks that are sparsely sampled from the dataset ), the initialization does not deviate too much from the default initialization. This behavior is consistent with what we would expect from a meta learner with sparse data. 3 ) The experiments confirm that the proposed optimal initialization does indeed provide an improvement over the baseline initialization."
SP:effbc85d89b1197d9c2abcaf5ff13864135dd6e1,"This paper proposes Feature Restoration ( BUFR ), a bottom - up training scheme for source - free domain adaptation ( FR ) for feature extraction from unlabelled source data to improve the accuracy and calibration of SFDA for measurement shift, a type of shift characterized by a change in measurement system that can only be resolved by restoring the source features. The source features are extracted from the source domain using entropy - minimization techniques that do not rely on the source model achieving a good level of feature - space class - separation in the target domain. The authors propose to store a lightweight approximation of the feature distribution under the source data while using the feature - extractor to extract features from source data that are similar to the ones obtained during the feature extraction process under the target data. They also propose to use a learnt feature structure in the later layers of a neural network to enhance the performance of FR which boosts performance by preserving learnt features structure.    The authors evaluate BUFR on real and synthetic data from the Fashion - MNIST dataset and demonstrate that BUFR outperforms existing SFDA methods on real data in terms of accuracy, calibration, and data efficiency. They additionally propose to additionally propose a technique called “ bottom up feature restoration ” where the extracted features are used to train a feature extractor to further enhance the features extraction process of the FR method, which is similar to what was used in the original FR paper. They evaluate the method on MNIST and CIFAR-10 data, and find that it outperforms the other methods on a variety of metrics."
SP:7d63034ec7e6a4f178681ff2a49feb485cd47116,"This paper studies distributed learning ( FL ), where each user has distributionally different ( or non - iid ) data and varying computational resources. Different users may have very limited training data as well as tight computational budgets, to afford the data - hungry and costly adversarial training. The authors propose a novel distributed learning setting that propagates adversarial robustness from high - resource users ( those with high training budget ) that can afford AT to those low - resource ( those who can not afford AT ) that cannot afford it during the FL process. They propose a simple yet effective propagation propagation approach that transfers robustness through carefully designed batch - normalization statistics. They demonstrate the rationality and effectiveness of their method through extensive experiments. Especially, the proposed method is shown to grant FL remarkable robustness even when only a small portion of users afford AT during learning. They show that existing FL techniques cannot effectively propagate robustness among non - non -iid users.    The main contributions of this paper are as follows :   1 ) The authors develop a new distributed learning method, Federated learning, by training a model from a set of participating users without requiring raw data to be shared, and learning the model from each user. This method is different from the typical centralized learning setting, where the training data for each user is available only to the set of users that have access to training data. The training set used in FEDERATED LEARNING ( Li et al., 2020 ) is not available to the general public. 2 ) This paper proposes a method to extend the training set of centralized learning to the distributed setting, and trains a model on top of data from non - participating users to train the model on. 3 ) The method is compared with two centralized learning methods, GAIL and AT - GAIL, and the authors show that GAIL is more robust than both of them when applied to FL."
SP:42c7a79e58b6a9f776fa6ae928bd89c194f9303f,"This paper proposes a transformer - like architecture to learn a utility function mapping from observed equilibrium actions to the network structure of the game without the knowledge of the utility function. The utility function is defined as the sum of the rewards of actions taken by the current and previous players with respect to the neighbors ’ actions. The authors propose a transformer like architecture that takes as input the symmetries of the problem and outputs a set of transformer like actions that correspond to the rewards obtained by matching the actions of the players with the corresponding utility functions.   The proposed method is tested on three types of network games using both synthetic and real - world data, and compared with two prior methods to evaluate the utility mapping. The experiments show that the proposed method generally outperforms the other two methods in terms of utility function inference, with the exception of a few cases where the method fails to obtain a utility mapping for a given action ( e.g., when the value function is large enough to be represented by a convex function ). The main contributions of the paper are the following :   1 ) The authors develop a novel transformer-like architecture that can be used to play network games ( where the rewards depend not only on the players ’ own actions but also on their neighbors ‘ actions ). 2 ) They use the transformer like principle to obtain transformer maps from observed game outcomes ( equilibrium actions ) to learned utility functions using the observed game trajectories. 3 ) The method is compared to two previous methods, one that learns a mapping of the equilibrium actions from the observed games trajectories and another that learns the utility functions from observed games. The results demonstrate that the transformer maps generalize better than the other methods on some scenarios, though it is not quite as good on all scenarios."
SP:1c7b9157cf8c06ca771da78895fc3af969b0fb85,"This paper proposes GraphANGEL, a novel relation prediction framework for transductive graphs based on archiving and embedding learning. The main contribution of the paper is the introduction of a relation prediction algorithm based on the ANalogy SubGraph Embedding Learning ( GraphANalogy ) algorithm. The key idea of the algorithm is to predict the relations between each node pair in a graph by checking whether the subgraphs containing the pair are similar to other subgraphes containing the considered relation. The graph patterns used for this task explicitly represent a specific logical rule, which the authors argue provides inductive bias that facilitates generalization to unseen relation types and leads to more explainable predictive models than the existing relation prediction algorithms. The authors demonstrate the performance of their GraphANergy model in terms of heterogeneous graph based recommendation as well as knowledge graph completion. They also empirically demonstrate the capability of their model in generalizing to new relation types while producing explainable heat."
SP:26ed25a7b42da2cf11b76a727102d8aa36d76657,"Contrastive learning ( CL ) and latent augmentation learning ( LA ) are proposed as approaches for few - shot learning in histology images. CL learns useful representations without labels and LA transfers semantic variations of the base dataset in an unsupervised way. The authors study three tasks that simulate few - shots learning in natural images : ( 1 ) CL generalize better than supervised learning for images ; ( 2 ) LA brings consistent gains over baselines ; ( 3 ) CL outperforms LA in terms of generalizability ; and ( 4 ) LA generalizes better than CL on some unlabeled training data. The experiments compare CL and LA on different natural image classification tasks and show that CL is better than LA in generalization both theoretically and empirically.   The authors also study how the model generalizes in the context of representation learning and histological image analysis. In particular, they study the superiority of CL over supervised learning on the task where the dataset is restricted to images with multi - objects and multi - textures ( Chen & Li, 2020 ). They provide empirical evidence to support their theoretical findings."
SP:badbe687258cd5c282ca167b1f6fbfc6b5400dbf,This paper proposes a novel approach to modeling irregularly - sampled time series using neural networks with continuous - time hidden states. The underlying motivation for the difficulty in modeling the long - term dependencies in RNNs with discrete - time continuous states is that the gradient of the hidden state vanishes or explodes during training. The authors prove that the underlying cause of the exploding gradient is the training error propagation through the memory path of the network. They provide a solution by equipping arbitrary networks with a memory compartment separated from its timecontinuous state and a continuous dynamical flow encoder that encodes the time - continuous gradient flow. The encoder is called the mixed - memory - r - net ( M-RNNs ).   The authors test their solution on a set of recently proposed RNN-based counterparts on non - uniformly sampled data with long -term dependencies. They show that the M - RNN - based counterparts are as good as the RNN based counterparts on the assumption that the input data is irregularly sampled. They also show that a closed - form version of their solution to the problem works better than the one used in the original RNN paper. The experiments demonstrate that the proposed solution is more robust than the original M - MNN and the difference in performance between the two is more significant than the difference between the proposed M-MRA and M - SMA.
SP:4efd22f9122fa5856a9f4302eb6875fa0c414912,"This paper proposes BiBERT, an efficient method to optimize the full binarized BERT model. BERT is a model trained for natural language processing ( NLP ) based on bit - based compression techniques. This paper is the first one to analyze the performance impact of binarization of BERT. The authors identify that the performance suffers due to information degradation and the optimization direction mismatch in the forward and backward propagation of the BERT models. To address this issue, they propose a bi - attentive distribution distillation ( BiBERMatchingDistillation ) scheme. The main idea is to use the same number of bit - activations as in BERT, but for each of the 1 - bit parameters ( weight, embedding, activation, and activation ) with a different number of bits per embedding embedding and activation values. The first batch of experiments is performed on BERT with BERT - base, and compare the performance to other baseline NLP methods. They find the performance degradation mainly due to the information degradation caused by the forward propagation and the direction mismatch between the BBERT training distribution and that of the optimization algorithm. They propose a way to mitigate this issue by using the information - degradation mechanism proposed in [ 1 ]. The second part of the paper is an empirical study on real - world NLP problems where the authors train BERT on different resource - constrained scenarios ( e.g., when the resource is limited, limited search space, limited number of fonts, and limited computational resources ). The experiments show the effectiveness of their method. They also provide some theoretical analysis to understand why the performance degrades.    The main contributions of this paper are : 1 ) Information degradation : the authors identify the main cause of the performance decline of the full BERT training. 2 ) The authors try to identify the source of the information decline. 3 ) They try to mitigate the impact of information degradation by introducing BiBER - Attribute - based Distillation ( BERT - Attraction ) to increase the amount of information sharing between the model output and the distribution of the bit - wise activations of the embeddings and activations. However, the authors find that the proposed BiBER- Attraction does not provide enough information sharing for the analysis and the resulting DMD is not competitive with the other methods. 4 ) They propose to use a weighted sum estimator to estimate the difference between the expected return of the expected output of BBER - based on the expected values of the bERT"
SP:619bd742e92bea6241852f5a9d2b7bacf13b393a,"This paper proposes a new method to solve keypoint detection and instance association by using Transformer. The idea is to use the self - attention in Transformer to measure dependencies between any pair of locations, which can provide association information for keypoints grouping. The authors argue that naive attention patterns of the current model are not subjectively controlled, so there is no guarantee that the keypoints will always attend to the instances to which they belong. To address this problem, they propose a novel approach of supervising self - attentive self - mask using instance masks to supervise self - attentions of multi - person pose estimation models to learn associative information between keypoints. The experiments on the COCO multi - Person Keypoint detection challenge and the instance association task demonstrate the effectiveness and simplicity of the proposed method, and show that it is a promising way to control self - Attention behavior for specific purposes.    The main contribution of the paper is that the instance segmentation results of any number of people can be directly obtained from the supervised attention matrix, thereby simplifying the pixel assignment pipeline. It can assign the detected keypoints to instances based on the pairwise pairwise attention scores, without using pre - defined pre -defined offset vector fields or embedding like CNN - based bottom - up models. An additional benefit of the method is that it allows to train a model without end - to - end supervision of the instance masks."
SP:14750819593136fc9ef4efd032ab6f94dc5f6a02,"This paper proposes a new method for considering mean - variance ( MV ) trade - offs in sequential decision - making ( DDP ), where the goal is to obtain MV - efficient policies that achieve Pareto efficiency. The main idea is to train an agent to maximize the expected quadratic utility function, in which the maximizer corresponds to the Pare - efficient policy. The method does not suffer from the computational difficulties because it does not include gradient estimation of the variance. In experiments, they confirm the effectiveness of their proposed methods.   The main contribution of this paper is the following :   1. The authors propose a new approach for considering the mean - variation trade -off, where instead of using the gradient estimator for the variance term ( which is usually used in the previous approaches ), they use the estimator from the Taylor series. This allows them to avoid the need of gradient estimators in other MV research problems. 2. They propose a method based on Taylor series estimators to estimate the variance of the expected utility function of a given MV policy from the perspective of minimizing the expected cost of the policy. 3. They apply their method to the setting of DDP where the policy is defined as the sum of two MV policies : the first policy is the standard one obtained by minimizing the cost of a MV policy with respect to the cost term of the second policy obtained by applying the standard MV policy to the value function of the former policy, and the latter is the policy whose value function is maximized according to the maximized MV policy ( in the case of the standard policy ). The procedure is similar to the approach of [ 1 ] and [ 2 ], except that it considers a different set of MV policies ( i.e., there is a difference between the two sets of policies ) and the difference is that the method considers only the one set of policies when the cost / value is less than $ \epsilence$.    3. Empirically, the authors observe that their approach is more stable than the approaches that do not consider the gradients ( e.g., those that use gradient estimations ). In the experiments with DDPs, they observe that the performance of their method improves over the methods when the target MV policy has a lower target value."
SP:f675b564b3a9c8626ce7944d752fa3e0d868428e,"This paper studies the problem of test - time domain adaptation for a generatively - modulated mixture density network ( MDN ) autoencoder, which is used for end - to - end learning of a wireless communication system. The authors propose a method for adapting only the channel distribution of the MDN to the target domain using only a small labeled dataset and feature transformations at the decoder to compensate for channel distribution shifts. The experiments are conducted on simulated datasets and real mmWave wireless channels to evaluate the adaptability of the proposed method and the improvement of the auto - encoder error rate. The main contributions of the paper are as follows :    ( 1 ) This paper proposes a method to adapt the generatively modelled MDN distribution using a fully - trained channel model and an autoencoders from a source domain without modifying the encoder and decoder neural networks ; and ( 2 ) This method is shown to be fast and sample - efficient ( with limited number of samples ) on simulated and real datasets, and it is able to maintain the error rate of the automatic encoder under changing channel conditions. ( 3 ) The experiments demonstrate that the proposed adaptor method can outperform the vanilla MDN model on the simulated dataset and the source domain using a very limited set of samples, and can also improve the accuracy slightly on the real dataset.   The major weakness of this paper is that it does not provide a detailed description of the transformations that the adaptor uses to compensate the changes in channel distribution during test time. This information is not clearly stated in the paper, making it difficult to understand how the transformations are made. The paper also does not clearly state the contributions of each transformation. The major contributions are summarized as follows. ( a ) The method is based on the idea from [ 1 ], which states that the distribution distribution of MDN can be adapted in test time using a mixture model ( e.g., a mixture - density network ), and [ 2 ] using only the distribution of channel distribution ( the source - domain distribution can be adaptor can compensate for changes in the distribution. However, the authors do not provide any explanation as to why these transformations are necessary. ( see [ 3 ] for details. ( and see Note 1 and Note 2 for details )   [ 4 ] The authors compare their proposed method with the one proposed in [ 5 ], and show that their adaptor is faster and more efficient ( in terms of time and cost ) than the vanilla adaptor."
SP:77dc92137ea490d3e1b4b8ee1630dbe2ee0bddfa,"This paper proposes a new model for the abductive natural language inference task called joint softmax focal loss ( JFL ) for the αNLI task. In this task, two observations are given and the most plausible hypothesis is asked to pick out from the candidates. Existing methods model the relation between each candidate hypothesis separately and penalize the inference network uniformly. This paper argues that it is unnecessary to distinguish the reasoning abilities among correct hypotheses and similarly, all wrong hypotheses contribute the same when explaining the reasons of the observations. Based on the observation that the hypotheses are generally semantically related, the authors have designed a novel interactive language model aiming at exploiting the rich interaction among competing hypotheses. The experimental results show that the proposed model achieves the highest performance on the RoBERTa - large pretrained model, with ACC and AUC results increased by about about 1% and 5% respectively.    The main contribution of this paper is the introduction of joint soft max focal loss, which is a novel type of loss model designed for the hierarchical inference task where the loss function is a weighted sum of the losses of the posterior probability of each hypothesis of each observation and the prior hypothesis of the hypothesis with respect to the prior observation. The authors argue that this new model is superior to the existing models for the task as it penalizes the posterior probabilities of the hypotheses of the correct and wrong hypotheses in the same way, which leads to a better generalization to unseen phenomena. The main contributions of the paper are the following :   1 ) The authors propose to group the hypotheses into a group instead of ranking the hypotheses and design a structural loss called JFL. 2 ) Based on this group ranking, they propose to use the following loss terms for each hypothesis : ( 1 ) $ \alpha$ \theta$ where $ \eta$ is the probability that the hypothesis of interest is semantically similar to the one of the group \pi$, ( 2 ) $ d$ the cost of the loss that is proportional to the probability of the difference between the posterior of the true and the wrong hypothesis \pi, ( 3 ) $ g_{xi } $ where $ d\theta \eta is the distance between the hypothesized posterior and the observed data and the ground truth, ( 4 ) $ a \eta d \eta g_{z}$ is a logistic regression loss that computes the difference of the expected loss of the hypothesized loss with the observed observations and the posterior hypothesis \phi, ( 5 ) $ p(\theta ) $ where \eta"
SP:17cd72df5fc19398f582d27516fd742b073f79e3,"Deep neural networks are known to produce highly overconfident predictions on out - of - distribution ( OOD ) data. Even if trained to be non - confident, adversarially manipulating OOD data can still lead to high confidence in the classifier again assigning high confidence to the manipulated samples. This paper proposes a novel method that combines a certifiable OOD detector with a standard classifier from first principles into an OOD aware classifier to achieve the best of two worlds : robust OOD detection and robust classifier without loss in either prediction accuracy or detection performance for OOD samples close to the in - distribution distribution ( ID ).   The main contributions of this paper are as follows :   1. The authors propose a method to train machine learning models with OOD - aware classifiers. This is done by training a machine learning model ( MLM ) from the ground up as a classifier on OOD- aware class labels. 2. The classifier is trained from scratch using the original OOD class labels from the original dataset. 3. The method is applied to train OOD detectors for ID and OOD classification tasks. 4. The training is done in two stages : during the pretraining phase ( pretraining the model ) and during the posttraining phase ( post -training ). The goal is to train a model that is robust to manipulations of the class labels obtained through OOD manipulation even if the manipulations are within the detection detection detection threshold. 5. The experiments are conducted on a set of binary classification tasks, where each task consists of ( 1 ) training OODD class labels and ( 2 ) fine - tuning the classifiers to detect OOD manipulations. The experimental results demonstrate that the proposed method is able to detect significant improvements in detection performance over previous methods without loss of accuracy ( in terms of detection accuracy )."
SP:9c3756f13932236aff3e8104f4fa193dcc8fde2f,"This paper proposes a novel method called Image Classification Eraser ( ICE ) to tackle the Generalized Transferable Attack ( GTA ) problem where the attacker has a set of surrogate models trained on different datasets ( with different label sets and image sizes ) and none of them is equal to the dataset used by the victim model. The attacker also needs to attack any randomly encountered images that may not come from the same dataset as those from the target dataset. To this end, the authors propose to use a method called image classification eraser to erase classification information for any encountered images from the attacker's surrogate models and use it to train new surrogate models instead of using the query - free black - box surrogate models. The proposed method is evaluated on Cifar-10 ( standard attack ), CIFAR-100 ( modified to the GTA problem ), and TieredImageNet ( without modification ) to demonstrate the effectiveness of the proposed ICE method. However, it is observed that existing transfer attack methods ( e.g., DNN - based methods ) perform much worse than the proposed method due to the fact that they do not explicitly train the attacker on the same surrogate models as in the previous works. The experiments also show that the attacker can attack with DNN-based methods even though they are trained on a different dataset ( the one considered in this paper, Deep Neural Networks - DNNs ).    The main contributions of this paper are the following :   1. The authors develop and study the idea of using image classification to train surrogate models to prevent transfer attacks in the GTA setting. The idea is very simple and intuitively based on the assumption that the surrogate models owned by the attacker and the white - box - based victim model are trained from same dataset. 2. The author conducts extensive experiments to validate the idea and derive the main results. 3. The main results are summarized in Table 1 and 2."
SP:2e0447c741a3f09be1095633d870200355211260,"This paper proposes a novel approach to train discriminative pre - trained language models ( PrLMs ) to discriminate between original texts from intentionally corrupted ones, based on the assumption that the corrupted texts are given as negative samples from the original texts and the trained model is trained to predict the original text from the corrupted ones. The proposed approach is based on two main ideas : ( 1 ) to define the false negative issue in PrLM that is caused by the training being carried out on wrong data ; and ( 2 ) to encourage pre - training language models on true negatives while correcting the incorrect predictions by correcting the gradient updates subject to false negative predictions. The authors propose three methods to this end : 1 ) To train the PrLM on the true negatives, the authors propose to train the model on true positives and false positives separately ; 2 ) To encourage the negative predictions of the trained PrLM to be correct on the wrong data by using counter - false negative methods ; and 3 ) The authors evaluate the proposed approach on the standard benchmarks of GLUE and SQuAD, showing that the proposed methods indeed bring about better performance together with stronger robustness.   The main contributions of the paper are the following :   1 ) A new approach to define a false negative problem in PrLM. This is done by treating corrupted texts given as a negative sample from the text corpus as a mixture of positive and negative samples, and then training the model to distinguish between real and corrupted texts using the mixture of the two ; and 2 ) A set of methods to encourage the training of PrLM models to correct the wrong predictions on false negatives by training the wrong model on the correct - wrong data and counter - training the harmful gradient updates on the harmful updates generated by the harmful predictions generated from the wrong models. The methods are evaluated on standard benchmarks and compared with the baseline PrLM. The experimental results show that the approach from the authors generate better performance compared with standard PrLM, especially when the counter-false - negative pre-training methods are used."
SP:281bc59d639aa76d84921b3ec4ce1ee8f1ba5b51,"This paper proposes ORCA, an open - world semi - supervised learning framework where unlabeled test data contain instances belonging to novel classes that may not have been included in labeled test data in the training. ORCA assumes that the labeled data contains only classes previously encountered in the labeled training data, but this assumption does not hold for data in - the - wild, where novel classes may appear at testing time. To tackle this challenging problem, ORCA proposes an end - to - end approach that assigns instances to classes that are similar to seen classes or forms novel classes by grouping similar instances without assuming any prior knowledge. The experimental results demonstrate that ORCA outperforms alternative baselines on image classification datasets and a single - cell dataset, achieving improvements over seen and novel classes."
SP:6c572c4c21b01a0cf3fd9ef97fbb348ef4e405ae,"This paper proposes SLIM - QN, a light stochastic quasi - Newton optimizer for training large - scale deep neural networks. The motivation is to tackle two challenges in second - order training of DNNs : obtaining Hessian matrix and computing its inverse in every iteration and to prevent convergence instability due to L - BFGS rule. To tackle the first challenge, SLIM-QN uses the BFGS update rule directly approximating the Hessian inverse using past parameters and gradients, without explicitly constructing the Hessians matrix. The second challenge is to obtain momentum in Hessian updates together with an adaptive damping mechanism to achieve stable convergence. Theoretical and empirical evaluations on various datasets and network architectures are provided to demonstrate the effectiveness of the proposed method. For instance on large datasets such as ImageNet, it achieves near optimal accuracy 1.5x faster when compared with SGD ( 1.36x faster in wall -clock time ) using the same compute resources. It can also be applied to other contemporary non - Convolutional architectures such as Transformers."
SP:4bffce00ebb02d2e676eec897647ac14c3344deb,"Graph Neural Networks ( GNNs ) have emerged as highly successful tools for graph - related tasks. However, real - world problems involve very large graphs, and compute resources needed to fit them to those problems grow rapidly. Recent works show that large graphs often involve many redundant components that can be removed without compromising the performance too much. This includes node or edge removals during inference through GNNS layers or as a pre - processing step that sparsifies the input graph. This intriguing phenomenon enables the development of state - of - the - art GNN - based regularizers, LSP, that are efficient and accurate. In this paper, the authors take a further step towards demystifying this phenomenon and propose a systematic method called LocalitySensitive Pruning ( LSP ) for graph pruning ( PL ) for graphs. It aims to generate similar local environments of the original graph so that similar environments in the resulting sparsified graph can be used for pruning. To justify the application of pruning based on local graph properties, they exemplify the advantage of applying prune based on locality properties over other pruning strategies in various scenarios. They conduct extensive experiments on synthetic and real world datasets demonstrate the superiority of LSP over other graph - based pruning methods.    The main contributions of this paper are as follows : 1. The authors study edge pruning and show that it can remove a significant amount of edges from large graphs without compromising performance, accompanied by a considerable acceleration. 2. They propose a method called PL - SP ( Self - Pruning ) that removes edges from graphs that are similar enough to be pruned in the same way as local nodes. 3. They test the effectiveness of PL and LSP pruning on two datasets, showing that PL outperforms LSP by a significant margin."
SP:c5e024f4e2079586298519ca868630efd7579eca,"This paper proposes Adversarial augmentation ( IDAA ) for self - supervised learning, where the goal is to distinguish positives ( from negatives ) from the ones generated by the data augmentation. The main idea is that strong augmentations may change the sample - identifiability of the positives, while weak augmentation produces easy positives / negatives leading to ineffective learning. IDAA is a simple method that proposes to modify training data to be hard positives /negatives without distorting the key information about their original identities. To do this, it proposes to decompose a sample x to be its variational auto - encoder ( VAE ) reconstruction G(x ) plus the residual R(x) = x = x − G ( x ), where R retains most identitydistinctive information. The authors then apply IDAA to three datasets ( CIFAR-10, Cifar-100, MNIST and Fashion - MNIST ), and show that IDAA improves both their efficiency and generalization performance. They also show that the IDAA learned on a dataset can be transferred to other datasets.   The main contributions of the paper are as follows :   1. Adjudicator - based augmentation is developed and compared to two prior methods : contrastive learning ( contrastive contrastive self - supervision ) and contrastive autoencoder ( E - AE ). It is shown that the proposed IDAA retains most information about the original identities of the samples used for training the auto encoder. 2. An important information is added back to the original VAE using an information - theoretic interpretation of the ELBO ( ELBOOT interpretation ). The key insight is that the original positives / negatives produced by the adversarial augmentations are likely to be similar to the samples from the dataset, while the augmented data. This leads to significantly better generalisation performance for IDAA compared to the contrasting methods."
SP:0991bc5f213bd8ab7572e2fed309e1b57a35835b,"This paper proposes a warning mechanism to detect distribution shifts in the training data distribution of machine learning models. The authors argue that certain distribution shifts could result in significant performance degradation for some models and that it would be sensible to firstly ( a ) detect harmful distribution shifts, and then ( b ) allow continuous monitoring of model performance without increasing the false alarm rate. To do this, they propose to use a non - sequential method to measure the difference between source ( training ) and target ( test ) distributions of training data ( e.g., logistic regression ), and detect whether the distribution is benign ( benign shifts are those for which the performance of a deployed model does not degrade substantially ) or harmful ( shifts that degrade the performance significantly under the assumption that a human expert would have to intervene to correct the distribution ). The proposed warning mechanism uses the following steps : ( 1 ) train a model on a given data distribution ( pretrained and fine - tuned on a pre - defined task ) using supervised learning ( pretraining the model on the data distribution, fine - tuning the parameters of the pretrained model, and fine tuning the labels of labels used to train the target model ). ( 2 ) label the batch of labels that are most likely to induce the largest shift in the distribution of the labels used in the pretraining step. ( 3 ) If the prediction is correct ( i.e., the labels indicate that the distribution shift is large enough, the model will perform significantly worse under the warning mechanism than under the non - shifting distribution, under which the model performs normally.   The authors validate their approach using an extensive empirical studies on a variety of simulated datasets ( both real and synthetic settings ) and argue that their approach is the only one that provides convincing evidence that the proposed method is robust against distribution shifts. The method is validated using both real - world and synthetic data distribution shifts and is shown to outperform competing methods that do not train the model."
SP:1c7b954273e3a9cda333385b15a3e8ed3bf8178a,"This paper proposes a new approach to model physical systems from the perspective of appearance modeling using neural ODEs. The authors propose to combine neural implicit representations for appearance modeling with neural ordinary differential equations ( ODEs ) in order to obtain interpretable physical models directly from visual observations. The proposed model combines several advantages :   ( 1 ) Unlike existing approaches that require large training datasets, the authors are able to identify physical parameters from only a single video ( Figure 1 ), which enables the processing of high - resolution videos and the synthesis of photo - realistic imagery ( Figure 2 ), and ( 3 ) The embedded neural ODEs have a parametric form that allows for the identification of interpretable parameters, which is crucial for the reconstruction of the long - term prediction in state space ( Figure 4 ). Furthermore, the proposed model also enables the rendering of novel scenes with modified physical parameters with modified real synth ( Figure 5 ).   The paper presents a method to estimate physical parameters directly from real - world videos, like the shown pendulum motion, using the parameters estimated from the input frame, and the left half shows the reconstruction based on physical parameters that the model estimates. The pendulum length is estimated using the metric length of the pendulum from the monocular video ( assuming that the error - to - true length is less than 2.5 % ; the authors use 6 out of 10 frames that were used for training ). The presented method is evaluated on the following tasks : ( Figure 3 ), ( 4 ) to train the model and ( 5 ) to obtain the parametric parametric parameters, ( 6 ) and ( 7 ) to render the reconstruction using the learned parameters. The experiments illustrate the performance of the proposed method on a variety of physical systems."
SP:51efd1451343f4994d857daa5490e299b812bc2d,"This paper considers the problem of learning from episodic episodic data to model learning in the context - dependent learning setting, which is characterized by an unknown finite number of not directly observable contexts, abrupt context changes occurring during an episode, and Markovian context evolution ( MICE ). The authors argue that this challenging setting is often met in applications and tackle it using a Bayesian approach and variational inference. The approach is based on a Hierarchical Dirichlet Process ( HDP ) as a prior for model learning, which they argue is arguably best - suited for Markov process modeling. They derive a context distillation procedure, which identifies and removes spurious contexts from the data that are not supported by the data in an unsupervised fashion. They argue that the combination of these two components allows to infer a large number of contexts from data thus dealing with the context cardinality assumption. They then find the representation of the optimal policy enabling efficient policy learning using off - the - shelf RL algorithms. Finally, they demonstrate empirically that our approach succeeds where state - of - the art methods of other frameworks fail and elaborate on the reasons for such failures.   The main contributions of this paper are the following :    1 ) A new model learning algorithm based on MPI, called Context - dependent Reinforcement Learning ( CORD ), is proposed and evaluated. It learns to model temporal sequences of episodic episodes from data using episodic context information only. This allows for learning in cases where the temporal sequences contain context information from more than the data ( e.g., when the data comes from different episodes but the context information comes from the same episode, the model learns to ignore this information. The results suggest that this approach is more efficient than other approaches to modelling temporal sequences from context information. 2 ) The method is applied to two datasets, where it is able to achieve better performance than other methods. The datasets are used to train two models, one based on CORD and another based on DP. The experiments demonstrate that the CORD model learns faster and more sensitively to context information than the other two models. 3 ) The authors also provide empirical evidence that the proposed approach outperforms the baselines in terms of accuracy when using CORD."
SP:ea167b126212b2092bc1190d7f8376bf7c54a888,"This paper presents a novel framework to pretrain knowledge - based multilingual language models, KMLMs, for knowledge - intensive cross - lingual NLP tasks. The framework generates a large amount of code - switched synthetic sentences and reasoning - based training data using the Wikidata knowledge graphs, and from the generated data, they design pretraining tasks to facilitate knowledge learning. The language models are trained with monolingual knowledge graph data, which limits their application to more languages. They demonstrate significant performance improvements on a wide range of knowledge -intensive tasks, including entity recognition ( entity recognition, factual knowledge retrieval, relation classification, and a new task designed by us ). The authors also propose a task - agnostic pretraining framework, which allows the language models to not only memorize the factual knowledge but also learn useful logical patterns.   The main contributions of this paper are the following :   1. A new framework to pre - train knowledge based language models. The generated synthetic sentences are code - SWITCHED, which is then used to train a language model ( MLMs ), and the tasks are designed based on the intra - inter - sentence structures of the generated sentences. This helps the language model to learn both factual knowledge and logical connections between sentences. 2. A training task is proposed to facilitate the learning of new logical patterns between syntactic and logical sentences generated from generated sentences using the pre - trained language model. 3. From the training data generated from the syntactic sentences, they propose a set of tasks to train language models using the knowledge graph structures to learn new logical connections. The proposed pre - training tasks are evaluated on a range of tasks, and their performance shows significant improvements compared to the existing models ( without pretraining ) on a variety of tasks ( e.g. entity entity recognition recognition, entity retrieval, relationship classification, logistic regression, and task design."
SP:6c11cf29c90f923346372ba6f11452c36e69ad6d,"This paper studies the problem of learning to act altruistically towards others in a multi - agent setting where we do not know the goals of the other agent ( e.g., we don't know what their objectives are, preferences are, may be difficult to express fully, or may be ambiguous or contradictory. The authors propose to train a generic RL agent that learns to increase the choices of another agent in order to maximize the number of states in the task - setting that other agent can reach. The goal is to train the agent to act in a self - enhancing manner towards other agents so that they can achieve their goals more easily. This is done by rewarding the agent that has more choices in the tasks it is assigned to achieve more states than the agent with which it does not achieve its goals.   The authors first consider the setting where they know the goal of other agent ’s is known, but do n’t know the objectives of other agents ’ goals, or the preferences they have. They propose to reward the agent who has more choice and assists others more in achieving their goals by increasing the amount of states they have ( up to a max of 8 ). They evaluate their approach on three environments :   ( A1A ), ( B1B ) and ( B2A ). In the B1A setting, they train their agent using reinforcement learning where the goal is known and the goal preferences are known, and in the B2B setting they use an agent - agnostic approach where they give the agent more choices and the agent assists the other agents more in the goals they do not have. The experiments show that the proposed approach leads to improved performance over the one - agent policy compared to a policy that rewards the agent for actions that lead to the maximization of states over which they do favors to other agents. In all three settings the unsupervised agents perform at least as well as the trained agent that is explicitly trained to cooperate cooperatively, and sometimes outperforming the one that is not trained to do so. In some cases they perform even better than the one trained to work cooperatively and in some cases outperform them. The main results are summarized in Table 1, below."
SP:5dbc54201ba184266c5054f0d2944bd197bc307a,"This paper studies the phenomenon of double descent in finite - width neural networks, where the parameters of the Hessian are re - parameterized as a function of the dimension of the network. Double descent is a well - studied phenomenon in deep neural networks and has been studied theoretically since the 1980s when it was first observed in the context of linear and kernel regression models. In this paper, the authors argue that existing analyses of the phenomenon do not adequately capture the mechanisms behind the phenomenon and choose not to consider crucial components, such as the choice of the loss function. The main contribution of this paper is to propose a novel and theoretically tractable expression of the population loss and its lower bound, based on the Neural Tangent Kernel Representations ( NTK ), that can capture the mechanism behind the double descent phenomenon in neural networks.   The main contributions of the paper are as follows :   ( 1 ) This paper proposes a novel expression of population loss for the NTK parametric model, that depends only on the parametric parametric distribution of parameters in the neural network. This expression is then used to compute the upper and lower bounds of the expected Hessian gradient of the mean and standard deviation of the parameterized neural network parameters. The upper bound is derived by computing the average gradient variance of the model parameters over the two regimes : under or over - parametrized. The lower bound is computed by taking the average of the gradient variance over all parameters in both regimes, and dividing it into two equal parts, where one consists of the average variance of all parametric parameters and the other consists of pairs of parametric and Hessian parameters. ( 2 ) This expression enables the authors to compute a Hessian parametric gradient estimator that captures the double - descent phenomenon. The authors then use this parametric parameter estimator to compute Hessian gradients that correspond to the difference in Hessian parameter values between the parametrization of the neural networks with and without double descent. The Hessian estimator is used to derive the expected parameter values for the parameters in each regime, and to compute an estimate of the difference between the expected parametric loss of the two trajectories of the models. The results indicate that for two regimes, the Hessians with double descent exhibit a lower bound of $ \epsilon$ the expected gradient variance, and for another Hessian with higher estimated parameter values exhibits a higher upper bound. Based on these derived derived parameters   the authors then compute two additional estimators, one of which is an empirical measure of the effect of the impact of the second Hessian of doubling the expected loss of a parameter of a neural network with respect to the parameter $ \eps1$. This estimator, the so - called Double - Dissonance Divergence Estimation ( DRE ), is used as the second parameter of the final estimator in the last part of the last line of the manuscript to compute estimated parameters for the second and third regime of the predicted parameter"
SP:b485114712055f39a7afb951dbc3db482ff523fd,"This paper proposes a new method for deep graph neural networks ( GCNs ) to overcome the oversmoothing problem, where node representations tend to be indistinguishable as more layers are stacked up in GCNs. The main contribution of this paper is exploiting the Graph Neural Tangent Kernel ( GNTK ), which governs the optimization trajectory under gradient descent for wide GCNs, to provide expressive power for deep GCNs to replace trainability as the primary metric in optimization of GCNs from a theoretical perspective. The authors formulate the asymptotic behaviors of G NTK in the large depth, which enables them to reveal the dropping capacity of the network in a deep GCN. In addition, they propose Critical DropEdge, a connectivity -aware and graph -adaptive sampling method, inspired by GNNK, to overcome exponential decay of trainability in the optimization process. Experimental evaluation shows that the proposed method can achieve better results compared to relevant counterparts with infinite - width and finite - width settings.    The authors also extend their theoretical framework to analyze residual connection - based techniques, which are found to be only able to be used in settings with sufficiently expressive space of models to be able to find a good solution by gradient descent based optimizer. The experiments are conducted on synthetic and real datasets and compared to standard GCN architectures. The experimental results demonstrate that Critical Drop Edge significantly outperforms the baseline GCN as well as other baseline methods."
SP:25a92b3583afdc6892e59f1e769125d52c8011af,"This paper studies the estimation of high - order dynamics in computer vision ( e.g. optical flow ) with respect to the second derivative of the cardiac pulse ( pulse - pulse second derivative ). The paper first points out that most prior work has focused on extracting summary statistics such as the heart rate, while less emphasis has been put on the accuracy of waveform morphology that is necessary for many clinically impactful scenarios, such as in the case of impactful bleeding scenarios. In this paper, the authors propose a method that explicitly optimizes for in - the - loss function ( i.e., the model with the second - order derivative of both the input frames and the target sign ) when estimating the dynamics of the optical flow. This is motivated by the fact that in many scenarios, the properties of interest are subtle variations in higher - order changes, which are difficult to predict with first - order methods. The method trains a neural model to estimate the dynamics using only the mean and standard deviation of the target trajectories, which is then used to compute the acceleration and velocities of the model. The authors show that the model is better able to estimate left ventricle ejection time ( vent - vent - ejection ) than it is with the lower - order method, and they provide experimental evidence that the acceleration is better estimated by the neural model when explicitly optimized for in the loss function. They also show that adding 2nd - order inputs improves performance when estimating second - orders.    The main contributions of the paper are the following :   ( 1 ) An analysis of the effect of using waveform statistics to estimate dynamics of optical flow with respectral velocity in the presence - and absence - of - sound waveform in the training procedure, which has been previously only used for summary statistics ; ( 2 ) A series of experiments that compare the performance of the proposed method with optical flow - free and waveform - free methods, showing that the latter is better both in terms of accuracy and sensitivity to noise ; ( 3 ) A set of experiments investigating the effects of adding second - ordered inputs on the estimated dynamics of two different scenarios from the paper ; and ( 4 ) Results indicate that the higher - ordered dynamics estimated by neural models is better than those estimated by lower - ordered models when using the lower order models when explicitly optimizing for in-the - loss functions."
SP:0a88d2fcbdfab3e196bf6b9c75adb1006ab87536,"This paper proposes a method to train a language learning agent in dialog games using symbolic mapping. Inspired by the idea that language evolved from simple tasks to more complex ones, the paper proposes to use symbolic mapping to guide the agent to learn a compositional and symmetric language in complex settings. The method is based on the theory that language originated from simple interactions and that language evolving from simple to complex tasks is similar to the way that we learn to communicate in the first place.   The method proposed is called symbolic mapping and it consists of three components. First, symbolic mapping is used to generate a set of symbolic symbols that the agent can use to navigate through the environment. This set of symbols is composed of previously generated symbols by the agent. The agent learns to use one symbolic symbol at a time to create a new symbolic symbol for each task. This process is repeated until the agent reaches a goal. The goal is to maximize the number of times the agent uses the same symbolic symbol during a task to avoid redundant use of symbols that are not expressive enough. Second, the symbolic mapping procedure is carried out in two stages. The first stage is to generate initial symbolic maps and the second stage is the vocabulary expansion step. This stage consists of generating new symbolic symbols and training the agent using the generated symbolic symbols from scratch. The language learned from the first stage and vocabulary expansion stage is used for the task - specific mapping and the agent does not need to learn the new symbols from the previous stage to complete the task. The difference between the agent and the ground - truth is investigated in the experiments. The experiments show that the difference between symbolic mapping done in referential games and vocabulary expanding is mainly due to the difference in the amount of vocabulary used during vocabulary expansion ( less than 1 % of the total vocabulary used in each step )."
SP:89575be04cb33b41d7a0a7b62f9496c2838a1317,"This paper proposes HACR ( Hierarchical Approach for Compositional Reasoning ), a method to train agents to navigate and manipulate objects in a divide - and -conquer manner. The approach operates at three levels of hierarchy. At the highest level, policy is learned by inferring a sequence of subgoals to be executed based on language instructions from a high - level policy composition controller ( PCC ). It is then discriminatively control the agent ’s navigation by a master policy alternating between navigation policy and various independent interaction policies. Finally, the policy can also be used to infer manipulation actions with the corresponding object masks using the appropriate interaction policy.   The main contributions of this work are the following :   1. An approach is proposed to learn a set of policies to navigate an environment and interact with objects in it using language instructions given by PCC. This approach is referred to as “ hierarchical policy learning ” and is meant to be used in conjunction with HAC - R, a prior method for learning policy for interacting with an environment using a combination of implicit language instructions and a hierarchical policy controller. The authors propose to use the latter method in two steps : ( 1 ) to learn the implicit policy for the interaction policy and ( 2 ) to train the policy to interact with the environment using the policy from the interaction policies and the implicit subgoal from the navigation policy. The training of the first level policy is iterated until it reaches a state - of - the - art performance on the task. The second level policy, HAC-R, is trained to achieve the best possible performance in the task using language instruction and interaction policy training. The experiments demonstrate the effectiveness in terms of the number of interactions with objects seen and the ratio of interactions between policy actions and manipulation actions taken compared to the total number of interventions performed by the policy. In addition, the authors also demonstrate the value of their approach on the cross - lingual tasks ( e.g., the task of navigation and object manipulation )."
SP:e2c8efe00db7baba2368f4f6a37815809b9e235e,"This paper proposes a novel method for generating nuisance - free labels for machine learning models that are robust to spurious correlations induced by a changing relationship between the label and a nuisance variable that is correlated with the covariates. The motivation for developing the new method is that existing models that only consider the label - label relationship with the nuisance variable may perform poorly on data that depend on the other relationship ( e.g., the background noise of images of animals classified according to the nuisance can predict the type of animal ). The method, called NURD, aims to generate labels that remain independent of the nuisance while maintaining their robustness against spurious correlations. The main idea of the method is to divide data sets into several distributions that correspond to distributions that differ only in the nuisance - label - covariate relationship, and each distribution is called a "" nuisance - randomized distribution "". Each distribution corresponds to a set of representations such that the representations in this set always perform better than the representations outside of this set that are most informative of the label under the nuisance label relationship. This paper first defines the distribution used for each distribution as those that only account for the changeable nuisance variables. Then, the authors introduce the "" non - nuisance - controllable distribution "", where the nuisance and the label are independent of each other. The authors evaluate the proposed method on several tasks, including chest X - ray classification where, using non - lung patches as the nuisance, NurD produces models that predict pneumonia under strong spurious correlations ( under the non - normal distribution ) and lung patch - free classification. The experiments compare the performance of the proposed methods with other methods that do not consider the nuisance variables ( methods that use the nonnormal distribution and do not have the independence of label and covariate ) on these tasks."
SP:c75998b76f4e0510fc719d25959a10fc07db1c40,"This paper proposes a novel method to train computer vision models using natural language captions for contrastive learning. Previous approaches, such as CLIP, use InfoNCE loss to train a model to predict the pairing between images and text captions but is data hungry and requires more than 400 M image - text pairs for training. The proposed method OTTER ( Optimal TransporT distillation for Efficient zero - shot Recognition - Efficient Learning ) uses online entropic optimal transport to find a soft image -text match ( e.g., 3M pairs ) that is statistically close to the best one - to - one match ratio between two pairs of text - image pairs. To train such a model, the paper proposes to use the text - text match as the label for the model ’s priors, which is trained in natural language using the captions provided to the model in the paper. The paper presents 4 types of losses : ( 1 ) Loss proportional to the distance between the model and the text pairs it is trained to predict from, ( 2 ) Comparative loss that measures the difference of the model's performance with respect to a set of text pairs, ( 3 ) Difference in terms of smoothing ( smoothing is defined as the ratio of the mean squared error of a pair of text-image pairs when the model is trained from the same set of captions ), ( 4 ) Contrastive learning loss that captures the difference between two sets of image pairs when training the model from different captions, and ( 5 ) Natural language training supervision as the paper argues that natural language provides finer descriptions of visual concepts than supervised "" gold label labels "" and hence is better supervised supervision than image - based labels. The main contributions of the paper are the following : 1 ) A novel method for training models trained with natural language to discriminate between text and image captions that is more efficient than the previous approaches to do so using image pairs ; 2 ) A method for using text - based captions as labels for the priors trained from images to train the model ; 3 ) Strong performance on six different datasets ( 6 metrics ), where OTTER consistently outperforms all baselines in 37 of them. However, there are some cases where there are ties or ties between the models and the datasets ( 37 out of them ), and there are also cases where the model outperforms the other baselines ( 37 ) or the other"
SP:e83cd70377542b5d187998e2e4a7ac070f453ed6,"This paper proposes Pix2Seq, a simple and generic framework for object detection based on language modeling. The framework treats object detection as a language modeling task conditioned on the observed pixel inputs. Object descriptions ( e.g. bounding boxes and class labels ) are expressed as sequences of discrete tokens, and a neural net is trained to perceive the image and generate the desired sequence of tokens. The approach is evaluated on the challenging COCO dataset, and compared to highly specialized and well optimized detection algorithms. Compared to the previous approaches, the proposed approach does not explicitly integrate prior knowledge about the task. It is argued that if neural net knows about where and what the objects are, we just need to teach it how to read them out. Beyond the use of task - specific data augmentations ( bounding box augmentations and class label augmentations ), the approach makes minimal assumptions about the tasks to be solved. The experimental results demonstrate that the approach is competitive with the state - of - the - art in terms of detection accuracy."
SP:abc9315f61929cc1c54dfef8ff83d7eac56ec2f2,This paper proposes distilling deep CNN policy network into interpretable symbolic policy via hierarchical learning using a policy regression algorithm called RoundTourMix. The proposed distillation method distills the learned policy into a set of symbolic rules using a teacher - student learning approach. The policy rules are learned using an end - to - end learning pipeline that progressively transforms the policy into the symbolic policy using a distillation process that ends up with a more interpretable set of rules. The method is applied in four different environments to train the policy in distillation stage - wise manner. Results show that the proposed method is more transferable and robust to changes in the distribution of policy distributions than the CNN policy based on the hierarchical learning method.
SP:04e7e181aeb1244ae1c4837ad416aef93ea3ea32,"This paper proposes PIVQGAN with two novel techniques in the framework of StyleGAN2. First, it proposes a Vector - Quantized Spatial Normalization ( VQSN ) module for the generator for better pose -identity disentanglement. The V QSN module automatically learns to encode the shaping and composition information from the commonly shared objects inside the training - set images. Second, it design a joint - training scheme with self - supervision methods for the GANInversion encoder and the generator. Specifically, the encoder lets the generator reconstruct images from two differently augmented variants of the original ones, one defining the pose and the other other for identity. The training scheme ensures the VQ SNS module learns the pose - related representations. The experiments conducted on various datasets show better synthesis image quality and disentangling scores of the model. Moreover, the latent - space reducing feature of the leveraged VQNN is leveraged to improve the performance of the image - to - image translation task."
SP:e51a7f45493064972585109f203a867e9828eb15,"This paper proposes a new multi - layer perceptron ( MLP ) architecture for speech processing tasks such as speech recognition, speech synthesis and speech enhancement. The proposed MLP is based on the perceptron architecture of Transformer - based models. The main idea is to first split feature channels into non - overlapped chunks and processes each chunk individually before merging them into larger chunks that are further processed together to aggregate the output. The authors evaluate the proposed model on two tasks : spotting spotting and spotting with two benchmark datasets. They show that speech - MLP achieves better performance with fewer parameters than the transformer - based solutions ( GFLOPS ) that use more complex models, such as transformers ) on spotting tasks, while achieving worse performance with models that use fewer parameters lower than MLP. On the spotting task, the authors show that using a smaller number of chunks and focusing on different window sizes, speech -MLP learns multiscale local temporal dependency that transformers learn not to need for some tasks. They also show that a larger batch size of MLP helps to achieve better performance on the enhancement task. Overall, the paper is well written and well presented. However, there are a few weak points that prevent some parts of the paper from being of interest to some readers. There are also some questions that need to be addressed."
SP:d708d3886f4abd4552d8ccb2096df7361c803b13,"This paper studies the generalization error of transfer learning ( TLE ) for binary classification problems, where the goal is to reduce the amount of labeled training data required for generalization of state - of - the - art machine learning models. The main contribution of this paper is to develop a novel lower bound on the generalisation error that can be achieved by any known transfer learning algorithm that utilizes the data of a related but different source task to compensate for the lack of training data in a setting where there are few labeled data for the target task. The lower bound is based on deriving a novel notion of distance that depends only on the distance between source ( s ) and target ( t ) and is robust to the fact that it can be easily computed on real world data sets.   The main contributions of the paper are as follows :   ( 1 ) The paper develops a new set of bounds on generalization errors achievable by transfer learning algorithms using the data from a related source task ( source(s ) ) that is used to approximate the loss function of a generalization algorithm that generalizes a given target task to a source task that is not available ( target task is the one for which there is no labeled data ). The method is applied to the binary classification problem setting ( e.g., binary classification with no source data sets and action recognition task with source and target data sets ), and experiments are run to validate the effectiveness of the method. The upper bounds of the lower bound are shown to correspond to the upper bounds achieved by a base - lines that utilize a weighted empirical risk minimization on the combination of source( s and target ) data sets, and are contrasted with the lower bounds obtained by using a different base - line method ( i.e., risk - minimization with weighted average transfer learning loss corresponding to the difference in likelihood of the source data set and target task from the source task. ( 2 ) The authors also conduct a series of experiments to validate their lower bound bounds and show that the transfer learning method outperforms the baselines in terms of performance on target classification tasks when the source / target distance is small. ( 3 ) They also provide a set of lower bounds that apply transfer learning methods to real image classification and action - recognition data sets to evaluate the effect of different sources on the target generalization. ( 4 ) A set of experiments validate the sharpness of the upper and lower bounds and demonstrate that the distance bound obtained by the method works better than the upper bound."
SP:f7511ba9ccad03233b34b1bf41bbac7361d20a57,"This paper proposes a probabilistic shape completion method for the continuous geometry of large - scale 3D scenes. In this context, the paper considers the problem of shape completion in the sparse voxel embedding setting, where the goal is to ensure that the embedding maximizes the variational lower bound of the complete shape distribution. To achieve this goal, the authors employ the Generative Cellular Automata ( GCA ) model from [ 1 ], which learns the multi - modal distribution and transforms the formulation to process large - Scale continuous geometry. The continuous shape is then generated as a sparse embedding, which contains the latent code for each occupied cell. The authors derive the training objective for the GCA model and prove that the progressive generation of GCA is a valid generative model. They also demonstrate that their approach outperforms deterministic models even in less ambiguous cases with a small amount of missing data, which is crucial for high - quality geometry completion.    The main contributions of this paper are the following :   ( 1 ) A new continuous geometry formulation is proposed, which generalizes the sparse GCA embedding objective to handle the continuous 3D scene geometry. This formulation does not require any additional assumptions for the discrete embedding and hence is theoretically tractable. ( 2 ) A series of experiments evaluate the performance of the proposed method on various synthetic datasets, showing that it generates diverse sets of plausible scenes with high quality geometry. ( 3 ) The authors conduct an ablation study to verify the robustness of their method to missing data and show that their method is robust to low level of information in the input."
SP:d22d8f074adbe8fb0f25fb8f8d96201b3159bf6b,"This paper proposes temporal priors as a non - Markovian generalization of behavioral priors for exploration in reinforcement learning. A state - independent temporal prior is proposed, which is claimed to be applicable and generalizes state - invariant priors that are general enough to be applied to a range of tasks beyond policy - based priors commonly used in deep reinforcement learning ( DPR ). The authors argue that DPR is a special case of behavioral - priors - based RL where the generalization does not depend on Markovians but rather on a combination of policy and priors conditioned on past actions. The temporal prior acts as a prior for the actions conditioned on the past actions, and the policy acts are the actions sampled from the temporal prior conditioned on those actions.   The authors then propose a method to sample actions from a probabilistic mixture of the policy and temporal prior using off - policy exploration in unseen downstream tasks. This is done by iteratively updating the policy priors at each task time step using the current state - dependent temporal prior and then updating the action priors based on the observed actions at that point in time. They argue that this allows for faster exploration in long - horizon continuous control tasks with sparse reward settings. They provide empirical evidence that this approach improves upon the baselines used in DPR with reward - agnostic exploration ( e.g., DPP ) and reward - robust exploration ( PEARL ) in tasks where the reward function is scarce. They also provide experimental evidence that the proposed temporal prior generalizes better than baseline priors in two tasks where there is no reward associated with the policy prior. Finally, they provide a procedure for sampling actions from the combined policy - temporal prior - action policy - action samplacement procedure in order to test whether the learned policy - samplers are better than the baseline policy - actions. This procedure is referred to as “ dynamic sampling ”."
SP:25e06c022ae8b3cbbb8db413d7b534a1a5c92391,"This paper proposes Graph - Network - based Scheduler ( GNS ), a novel method for learning rate scheduling in stochastic training of deep neural networks ( DNNs ). The method is based on a directed graph for the underlying neural network of the target DNN and a graph message passing network for the message - passing network, which is used to control the learning rate of the agent controlling the target learning rate via reinforcement learning. The authors show that GNS shows consistent improvement over popular baseline SGD methods. They also evaluate the method on different datasets and network structures.   The main contributions of the paper are as follows :   - A novel method to learn a scheduling mechanism without restrictions to the existing principles, based on graph - network - based scheduling ; - An efficient reward collection procedure is leveraged to speed up training with GNS ; - A comprehensive evaluation of the performance of GNS on DNN benchmarking datasets, showing that it is able to generalize well to problems of varying scales ; - Experiments on Graph - MNIST and CIFAR-10 to evaluate the effectiveness of the method."
SP:d73cb0471c1770607ad3e4621cfc5f170683dd8e,"This paper proposes SPAIR3D, a method to model scenes from a 3D point cloud using a spatial mixture model, where each voxel component corresponds to one object. The method is motivated by object - centric learning from a point cloud, which is crucial for relational reasoning and scalable machine intelligence. The authors derive the Chamfer Mixture Loss ( DML ) to model the spatial mixture and derive an object - specification scheme to describe each object ’s location relative to its local voxels. They evaluate the method on the task of unsupervised scene decomposition and show that the method has strong scalability and is capable of detecting an unknown number of objects.    The main contributions of this paper are the following :   1 ) A new point cloud model is proposed, called SPARMA3D. This model is based on parametric point clouds and parametric mixture models. 2 ) An object - specification scheme is introduced to describe the location of each object in the model space. 3 ) A sampling strategy is used to generate scene models from the generated point clouds using the parametric cloud models. The experimental evaluation shows that the proposed method has better scalability than other methods and is able to detect more objects in the scene model compared to other methods. The main concern of mine is that the learning from the point cloud is not deep enough to support relational reasoning."
SP:3c57e921c1bf23e482551ceb71702931a7f07439,"This paper investigates the possibility of grounding high - level tasks, expressed in natural language, to a chosen set of actionable steps ( i.e. “ open fridge ” ). Prior work has focused on learning from explicit step - by - step examples of how to act, whereas this paper surprisingly finds that if pre - trained LMs are large enough and prompted appropriately, they can effectively decompose high -level tasks into low - level plans without any further training. However, the plans produced naively by LLMs often cannot map precisely to admissible actions, and the authors propose a procedure that conditions on existing demonstrations and semantically translates the plans into actions. The resulting method substantially improves executability over the one relying on the LLM without the LMs. The authors evaluate the procedure in the recent VirtualHome environment ( VHA ) paper and conclude that the resulting procedure substantially improves the resulting method.    The main contributions of this paper are the following :   1. This paper proposes to train large language models ( LMs ) to be able to act in interactive environments. The main question is how to train such LMs? The authors answer affirmatively by : 1. Providing LMs with the language model ’s actionable knowledge from language models1. 2. Encouraging LMs to generate actionable actionable information from the actionable data. 3. Conducting a human evaluation reveals a trade - off between executability and correctness but shows a promising sign towards extracting extracting actionable info from the language models"
SP:e0159d1c9df2e657892a3a0c77549df4698d9a1a,"This paper proposes a new interpretation of the Variational Autoencoder ( VAE ) framework. The main idea is to use the uniform distribution deriving from the Riemannian manifold learned by a VAE to generate samples that can be used to approximate the latent space of a generative model. The paper shows that the VAE naturally adopts a manifold structure corresponding to the learned latent space. The method proposed is robust to the low data regime, which is known as challenging for deep generative models. On four benchmark datasets, the proposed method is able to generate VAEs that can compete with more advanced VAE models.   The main contributions of the paper are as follows. First, the paper proposes an interpretation of VAE, which can improve the generation from the vanilla VAE. Second, the method for generating samples from VAE is validated on a complex neuroimaging dataset combining high dimensional data and low sample sizes."
SP:b4b8e1727f8617894f10f20365cb68de79f0e650,"This paper proposes Transformer with a Mixture of Gaussian Keys ( transformer - MGK ), a novel transformer architecture that replaces redundant heads in transformers with a mixture of keys at each head. The keys follow a Gaussian mixture model and allow each attention head to focus on different parts of the input sequence efficiently. Compared to its conventional transformer counterpart, Transformer -MGK accelerates training and inference, has fewer parameters, and requires less FLOPs to compute. The authors empirically demonstrate the advantage of the new architecture of Transformer-MGK over a range of practical applications including language modeling and tasks that involve very long sequences. On the Wikitext-103 and Long Range Arena benchmark, transformers using 4 heads attain comparable or better performance to the baseline transformers   with 8 heads. On tasks with 6 heads heads or more, the proposed transformers achieve comparable performance while achieving better accuracy across tasks.   The main contributions of this paper are as follows :   1. This paper proposes a new transformers architecture, called Transformer. 2. This architecture has fewer heads, and can be easily extended to use with linear attentions. 3. This new architecture is compared with a set of transformers, including transformer - GMK, transformer - FPGA, and transformer - TRPGA. The results show that the proposed model outperforms the other transformers and is competitive with the baselines in terms of accuracy and accuracy with respect to the number of heads."
SP:82731dcce233e748f63382e09b6224a513fe9689,"This paper proposes a novel approach for integrating information from multiple sources ( image, action, and proprioception ) in a two - dimensional continuous environment. The authors propose to fuse image and action related signals into a single stream of information via a direct - inverse model of the dynamics of the two successive images in the continuous environment, and use it to predict the value of the new image from the values of the previous two images and the action taken by the previous one. To train the model, the authors propose a minimalistic recurrent architecture, called RPI ( Resetting Path Integrator ), which updates the internal state of the model using the ( possibly noisy ) self -motion signal, and occasionally resets it when the image signal is present. RPI is trained to keep track of its position relative to its starting point during a sequence of movements, and is stable across long trajectories through resetting, and allows for disambiguation of visually confusing positions in the environment through integration of past movement. On a series of tasks designed by the authors to assess the performance of their model, RPI consistently shows better performance while also offering interpretable internal dynamics and higher - quality representations. Comparisons are made to LSTM networks on two tasks and compared to off - the -shelf networks on identical tasks, and RPI, which is applied to both linear and angular trajectories, is shown to provide better performance."
SP:1a27c397d1e73def5e724c5c6f25548975ba50fa,"This paper studies the problem of feature learning in neural networks, where the goal is to learn representations of the input data with effective features for prediction, which is believed to be a key factor in their superior empirical performance. The authors consider a setting where the labels are determined by a set of class relevant patterns and the inputs are generated from these along with some background patterns. They prove that neural networks trained by gradient descent can succeed on these problems. The success relies on the emergence and improvement of effective features, which are learned among exponentially many candidates efficiently by exploiting the data. In contrast, no linear models on data - independent features of polynomial sizes can learn to as good errors when the input distribution distribution is fixed.   The authors then carry out experimental results on synthetic and real data, where they prove that the specific input structure used in the training of neural networks can lead to superior performance when compared to linear models. The experimental results also provide theoretical evidence showing that feature learning depends on the input structure and leads to the superior performance, as opposed to the linear models which do not depend on the data ( in particular, the structure of input distribution )."
SP:8ada73ed7eade9ebdeef376485e849c42575bc5f,"The robustness of machine learning models to adversarial examples generated by test - time adversaries is a problem of great interest. Recent theoretical work has derived lower bounds on how robust any model can be, when a data distribution and attacker constraints are specified. However, these bounds only apply to arbitrary classification functions and do not account for specific architectures and models used in practice, such as neural networks.   In this paper, the authors develop a methodology to analyze the robustness   of fixed feature extractors, which in turn provides bounds on the robust    quality of any classifier trained on top of such an extractor. The tightness of these bounds relies on the effectiveness of the method used to find collisions between pairs of perturbed examples at deeper layers. For linear feature extractor, they provide closed - form expressions for collision finding while for arbitrary features, they propose a bespoke algorithm based on the iterative solution of a convex program that provably finds collisions. The authors also utilize their bounds to identify the layers of robustly trained models that contribute the most to a lack of robustness, as well as compare the same layer across different training methods to provide a quantitative comparison of their relative robustness."
SP:874b5fa51924cbcceed490d98a0ea80f74586b32,"This paper proposes Expectile V - Learning, a method for offline reinforcement learning ( RL ) that learns the V - function instead of the Q - function in order to keep the learning procedure within the offline dataset. The main contributions of the paper are as follows :   1. The authors propose a new offline RL method called Value - based Episodic Memory ( V - EM ) that extends Expectile Q - Learning ( Q - learning ) in two ways : 1. It interpolates between the optimal value learning and behavior cloning trajectories, and 2. It introduces implicit planning along offline trajectories to enhance learned V - values and accelerate convergence. Theoretical analysis is provided for the convergence properties of the proposed method, and empirical results in the D4RL benchmark show that it achieves superior performance.   2. A second set of experiments is presented that compare the performance of VEM with offline RL methods that do not use the implicit planning. The results show that VEM outperforms the offline methods in most tasks, particularly in sparse - reccommendations."
SP:34f08d92681504490c2f739b0d08f79f9764b2f5,"This paper proposes a novel adversarial training framework that learns to reweight the loss associated with individual training samples based on a notion of class - conditioned margin, with the goal of improving robust generalization. Inspired by MAML - based approaches, the authors formulate the adversarial defense as a bilevel optimization problem where the upper - level task corresponds to learning a robust classifier, and the lower - level tasks corresponds to learn a parametric function that maps from a sample ’s multi - class margin to an importance weight. The proposed framework is evaluated on both clean and robust accuracy on MNIST and CIFAR-10 datasets, and compared to related techniques and state - of - the - art adversarial defenses. The main contributions of the paper are as follows :   1. A new weighting scheme is proposed for training neural network classifiers to defend against adversarial perturbations. The upper level task is treated as a learning - efficient parametric optimization problem ; the lower level task as a mapping - efficient classifier optimization problem. 2. This framework is applied to two classes of neural network discriminative models, one for robust classification and one for standard classification.   3. It is experimentally verified that the proposed framework significantly improves clean accuracy and robust generalisation over the baselines trained with standard and robust classifiers in MNIST."
SP:3ad36be6b6900aabe43da043461cf178ce977082,"This paper proposes Steerable E(3 ) Equivariant Graph Neural Networks ( SEGNNs ), a generalised version of Graph Neural Network ( GraphNet ) that generalises equivariant graph networks to include node and edge attributes that are not restricted to invariant scalars, but can contain covariant information, such as vectors or tensors. This model, composed of steerable MLPs, is able to incorporate geometric and physical information in both the message and update functions through the definition of node attributes.   The authors provide a new class of activation functions for general use with steerable feature fields ( e.g., $ \epsilon$ ) and discuss the use of SEGNNs : non - linear message aggregation improves upon classic linear ( steerable ) message aggregation ; steerable $ \ell_2$-functions improve upon recent   graph networks that send invariant messages ; and the authors demonstrate the effectiveness of their method on several tasks in computational physics and chemistry and provide extensive ablation studies. The main contributions of the paper are as follows :    1. The authors introduce SEgNNs that generalise graph neural networks (GraphNet ) to include covariant node attributes, such that node and edges can contain edge information that is covariant ( geometric ) and can incorporate geometric ( angular ) features. 2. They extend GraphNet to include vector and tensor attributes in the MLPs that are steerable ( geometric and angular ). 3. They demonstrate the importance of the curvature properties of the vectors and tensors in the node attributes and the geometric curvature of the nodes. 4."
SP:8928aa83f7ebd4e310f4fe1d01ff0eb0c96e4d2b,"Differentiable physics modeling combines physics models with gradient - based learning to provide model explicability and data efficiency. It has been used to learn dynamics, solve inverse problems and facilitate design, and is at its inception of impact. Previous successes have concentrated on general physics models such as rigid bodies, deformable sheets, assuming relatively simple structures and forces. This paper proposes a new differentiable fabrics model for composite materials such as cloths, where we dive into the granularity of yarns and model individual yarn physics and yarn - to - yarn interactions. To this end, it proposes several differentiable forces, whose counterparts in empirical physics are differentiable and whose counterparts are ubiquitous in various physical systems. Through comprehensive evaluation and comparison, the authors demonstrate their model’s ability to incorporate complex physical structures, versatility in incorporating complex physical parameters, data - efficiency in learning, and high - fidelity in capturing subtle dynamics."
SP:2c8358c095b10981d3015b9f6c75765419a9480d,"This paper proposes a method to train an agent to generalise over a distribution of tasks over which it has no prior knowledge of how to solve, and to which it can transfer a set of base skills that it has learned during its lifetime to solve the new tasks. The method is based on the transfer learning approach of [ 1 ], where a policy is learned first on base tasks and then transferred to new tasks in the distribution, with the agent generating an estimate of the optimal policy to be used when applying the learned policy to the new task. The paper shows that this method generalizes over the full set of tasks ( which is the whole distribution ) as well as a subset of tasks that were added to the distribution after learning only a few of them. The main contributions of the paper are the following :   ( 1 ) It proposes a framework that can be used to train a policy to transfer the learned base skills to solve new tasks by using the agent's existing abilities and knowledge of the base tasks ; and ( 2 ) It provides bounds on the number of base tasks that need to be learned and the amount of time it will take for the policy to generalize over the entire distribution.   The paper presents results that show that the proposed method generalise faster and more precisely over the distribution when learning base tasks only, compared to learning tasks that are part of the distribution that have a different set of goals, and that the method generalises more rapidly when learning tasks from the distribution with different goals. The results are shown in terms of the expected return on policy cost as a function of the total number of tasks learned as well over the lifetime of the agent and the expected generalisation error in terms."
SP:c85d71d05164d019cc32bf423e4c4fe20c169f41,"This paper presents LightWaveS ( LWS ), a distributed solution for the multivariate time series classification ( MTSC ) problem based on the framework of the recent state - of - the - art ROCKET ( Liu et al., 2018 ).   The main contribution of this paper is to propose a solution that employs just 2.5 % of the features of the rocket - based - features, while achieving accuracy comparable to recent deep learning solutions with more nodes and large numbers of channels. The authors present three versions of their algorithm and their results on training time, accuracy, inference speedup and scalability, and show that they achieve speedup ranging from 9x to 65x compared to ROCKET during inference on an edge device, on datasets with comparable accuracy, and a scalability that is comparable to that of ROCKET. The experiments are conducted on synthetic and real - world datasets, and they compare the performance of LWS with two versions of the original ROCKET model ( LightWave and LightWave+LW ) and two variants of LightWave, showing that the former significantly reduces the input size while the latter keeps only the most relevant channels ( in LightWave - LW ). LWS also shows scalability improvements compared to the first and second versions. To evaluate the effectiveness of the proposed method, the authors provide a theoretical analysis of the assumptions and limitations of the method to understand the advantages and disadvantages of each part of the algorithm. The main contributions of the paper are the following :    ( 1 ) LWS is an extension of the idea originally proposed by Liu et a few years ago ( Liu and Tan ( 2018 ) about using convolutional kernels to represent time series in a multivariate logistic regression problems with multivariate information. The idea is to learn a distribution over time series and feature vectors, and use features from the distribution to represent the features in the time series, and then predict the values from the feature vectors. This is similar to the approach used in the original LightWave. However, it differs from LightWave in the sense that it does not require the same number of features per feature vector, and also has the capability to predict values from multiple time series ( instead of just one. This allows for more flexibility in the number of feature vectors and also allows for using features from different epochs of the same time series. This paper studies the effect of this distribution on the prediction accuracy ( prediction accuracy ) and the inference time ( training and inference time ). It also shows that the LWS - based method is scalable and can be used in conjunction with a number of deep learning based methods ( e.g., RNN or DenseNet - based approaches ) to learn deep neural networks ( Li et al, 2019 ). The paper also presents an evaluation on synthetic datasets to evaluate the performance"
SP:db43614ca016280a79448f44a97c81c8ff5ba981,"This paper proposes a new approach for adversarial pretraining based on auxiliary masked language models ( MLMs ), where the main encoder is trained as a discriminator to detect replaced tokens generated by MLMs. Different from ELECTRA which trains one MLM as the generator, the authors jointly train multiple MLMs of different sizes to provide training signals at various levels of difficulty. The main idea is to learn mixture weights over the auxiliary MLMs ’ outputs to maximize the discriminator loss by backpropagating the gradient from the discriminators via Gumbel - Softmax. For better pretraining efficiency, the author proposes to assemble multiple MLM into one unified auxiliary model. The authors test their approach on GLUE and SQuAD benchmarks for BERT base - sized models, and they plan to release their pretrained models for future uses."
SP:db3825633ab5d0671340390b23ab655838cc38b2,"This paper proposes an approach to extract relational knowledge from large pre - trained language models by a clozestyle sentence serving as a query. The query sentence, also known under the term prompt, is used to improve the query query performance of the language models. Language models can be queried similar to knowledge graphs, and the performance of this paper depends significantly on the query sentence. The paper first trains a language model on the standard fill - mask task using a small training dataset of existing facts from a knowledge graph. Then, the authors propose an adaptive fine - tuning procedure to train the language model further on the training dataset using a larger dataset of facts from the knowledge graph and additional text corpora. The authors evaluate the learning capabilities of this adapted language model by training on a restricted set of relations to show that even fewer training relations are needed to achieve high knowledge extraction extraction quality.   The main contributions of the paper are as follows :    1. This paper proposes a method to train language models on the relational fact extraction task using the prompt technique. The main difference between the standard prompt technique and this adapted prompt technique is investigated by comparing the differences between the adapted and unadapted prompt techniques. The method is referred to as Adaptive Fine - Tuning of the Language Model ( APT ). 2. This method is compared with two other methods : Complex prompting ( Pertsch et al., 2018 ) and Adaptive Auto - tuning ( Schmidhuber & Sohl, 2019 ). The results show that APT using APT outperforms the other two methods in most cases, although there are trade - offs between APT and auto - tuning in terms of accuracy and accuracy. 3. Nevertheless, the method is still preferred over the other methods in some cases, especially in the domains where there is a need for higher accuracy ( e.g., finance and accounting ). 4. The manuscript is published with supplementary material and is available online only."
SP:ae25d32714b2b9f7e02cc20f4a36252e20e78e4f,"This paper proposes to learn knowledge base embeddings in different geometric spaces and apply manifold alignment to align the shared entities. The hyperbolic space characterizes the transitivity naturally because of its tree - like properties, whereas the Euclidean space reveals its weakness for other relations. Therefore, building a representation learning framework for all relation properties is highly difficult. In this paper, the authors propose to learn the base embedding from scratch in each of the following ways : 1 ) learn the embedding in the given space from scratch using gradient descent ; 2 ) apply the manifold alignment from the learned embedding to the entities in the learned space ; and 3 ) evaluate the results using out - of - taxonomy entity - based tasks to evaluate the performance of the learning method.   The main contributions of this paper are the following contributions :   - A new embedding learning framework from scratch for the transductive properties of the ReLU family of geometries ; - A set of manifold alignment methods for embedding the learned knowledge base in the obtained space via gradient descent from the obtained embedding ; - Experimental results on two datasets based on YAGO3 demonstrate that the approach has significantly better performance compared to the unsupervised baselines ; - An improvement in performance is noted especially in low dimensions and on small training rates for the tasks considered."
SP:9ab3bc525ee4a9c96518c43e4c43082655a7674f,"This paper proposes a one - shot learning framework for link prediction in temporal knowledge graphs based on a self - attention mechanism for temporal interactions between entities and a similarity network to compute a similarity score between a given query and a ( one - shots ) example. The authors claim that the existing approaches, which are tailored to static knowledge graphs and do not generalize to temporal settings, are ill suited for dealing with long - tail settings where data scarcity poses even bigger problems, e.g. due to occurrence of new relations or the discovery of previously unseen relations. The proposed framework addresses this shortcoming by proposing a link prediction algorithm that is able to generalize from only a few examples per relation. To this end, the authors propose to encode temporal interactions in the self - Attention mechanism to effectively encode temporal interaction between entities, and to use the similarity score computed from a query and an example to compute similarity scores for a relation and a comparison example.    The authors experimentally compare the proposed algorithm with the following : ( 1 ) Sinkhorn ’s algorithm, ( 2 ) DenseNet, and ( 3 ) Gumbel - Monte Carlo Networks ( Gumble ). The experimental results indicate that the proposed method outperforms the aforementioned methods in terms of accuracy for generalization to sparse relations while achieving significantly better performance for sparse relations with respect to the Gumble algorithm for long tail settings."
SP:91f92a40e12afd0702f07ae7f4175ecce57b7007,"The paper proposes a neural model for learning reasoning processes for reasoning tasks. The basic idea is to represent a solver for each task as a neural module that calls existing modules ( solvers for simpler tasks ) in a program - like manner. The lower modules are a black box to the calling module, and communicate only via a query and an output. Thus, a module for a new task learns to query existing modules and composes their outputs in order to produce its own output. The model effectively combines previous skill - sets, does not suffer from forgetting, and is fully differentiable, the authors claim. The authors test their model in learning a set of visual reasoning tasks, and demonstrate improved performances in all tasks by learning progressively ( learning more reasoning modules as the tasks become more complex ). They also compare their model to a prior work that learns reasoning processes using human judges, and show that our model is more interpretable than an attention - based baseline."
SP:de33b02e7f2faec5bcae9a5516721aa1ef190572,"This paper proposes a new method for improving parameter efficiency of deep convolutional neural networks ( CNNs ) with bottlenecks based on the information - preserving nature of identity connection in CNNs. In particular, the authors propose the Selective Convolutional Unit ( SCU ) that learns channel - selectivity via the alternative usage of ( a ) pruning unimportant channels, and ( b ) rewiring the pruned parameters to important channels.   The main contribution of this paper is the introduction of SCU, which is a widely -applicable architectural unit that improves parameter efficiency for deep CNNs by learning the channel - selectorivity via gradient descent. The authors conduct extensive experiments to validate the effectiveness of their method and demonstrate that SCU with no additional postprocessing generally achieves both model improvement and model compression accuracy improvement compared to the baselines, consistently for all tested architectures. The main contributions of the paper are the following :   1 ) The authors develop a method for learning channel - selectiveivity using gradient descent via the idea of self - attention and self - relative weighting. This is similar to what was done in [ 1 ], but it is different in that the authors apply this method directly to the CNN layer ( i.e., instead of relying on self - attentive attention as in [ 2 ] ). The key difference is that the self - attentiveness is used to learn the channel selectorivity while the paper uses it to train the network layer ( in the sense that the network learns how to select the important channels from the rest of the channels when computing the parameters of the network ). 2 ) The method is tested on a variety of tasks ( e.g., drug discovery, robotics, robotic vision control, and drug discovery ) and the experimental results demonstrate that the SCU - based models without any post processing generally achieve both model and model improvement in terms of both model speed and model efficiency. 3 ) The methods are tested on CIFAR-10 and ImageNet and compare with SCU and other baseline CNNs ( without any model improvement or postprocessing except for the one involving gradient descent that uses gradient descent as the training procedure."
SP:2d80fa4bc440061be2234b5070503d3fa056baed,"This paper proposes a method for partially identifying the classifier in PU learning ( learning from positive unlabeled data ). The classifier is a bi - level neural network that learns a scoring function that preserves the order induced by the class posterior under mild assumptions, which can be used as a classifier by setting an appropriate threshold. The proposed algorithm is based on the Bayes optimal classifier for learning a binary classifier only from positive data ( P2P ), which is obtained by learning the classifiers for P1P data using the label distribution and the class labels. The authors propose a method to learn the scoring function by assuming that the class distributions of the labeled positive data are identically distributed with respect to the unlabelED positive data. This assumption is important for PU learning as it captures the existence of a bias in the labeling process. The scoring function in the proposed method is trained using gradient descent. The method is applied to several real - world datasets ( CIFAR-10, Fashion MNIST, Fashion Dynamics, Fashion - MNIST - E, FashionMNIST - FTSE ), where it is able to learn classifiers ( Bayes - optimal classifiers ) on P3P and P4P datasets using the proposed scoring function. The methods are applied to four different settings ( P3D, P4D, FashionNNE, FashionMTE and FashionMIX ) and compared with three different methods ( BLEU, PPO and StyleNNE ) on each setting. The results show that the proposed by the authors outperforms the methods of the authors in terms of accuracy and generalization on all settings."
SP:5f312626b0613d2e07c59214c5f00db208a98717,"This paper proposes an algorithm to predict when an auxiliary task will be helpful for the main task based on cosine similarity between gradients of tasks. The main idea is to use the similarity in gradients between tasks of different tasks as an adaptive weight to detect when auxiliary losses are helpful and when they could be hurting. The algorithm is based on supervised learning on subsets of ImageNet, reinforcement learning on gridworld, and reinforcement learning   on Atari games. The authors propose to use a multi - task supervised learning algorithm that learns from the gradient of the task on which the auxiliary task was learnt in order to get an upper bound on the cardinality of the target task. This upper bound is obtained by taking the average gradient of auxiliary task gradients over all tasks in a set and computing the similarity between the gradients in the set with respect to the task statistics. The proposed algorithm is then used to compute a lower bound of the gradient term used to classify auxiliary task gradient as helpful and harmful. This lower bound is used as the upper bound for the variance upper bound of a logistic normalization term that is used to assign weights to auxiliary gradients.   The authors test the proposed algorithm on three tasks : supervised learning of the ImageNet set, Reinforcement Learning on GridWorld, and Multi - Task Supervised Learning on Atari Games. The experiments show that the algorithm is able to converge to critical points in time for the majority of tasks and that it can generalize to other tasks as well. The method is tested on ImageNet with ImageNet subsets and on the Atari games dataset."
SP:e270ae3eeb7ab4fa91ba37d4d68ce10f2fa0a3b5,"This paper proposes a geometric framework for analyzing the high - dimensional geometry of adversarial examples derived from machine learning ( ML ) models. It draws inspiration from manifold reconstruction tools from the literature and emphasizes the importance of codimension when constructing examples from low - dimensional data manifolds embedded in high -dimensional space. The main idea is to use a decision boundary that classifies the low -dimensional data manifold well, but classifies points near the manifold incorrectly when training a model on the manifold. The geometric framework is then used to construct examples from the manifold in which to train an adversarial example. Three main results are presented :   ( 1 ) There is a tradeoff between robustness under different assumptions on the affine data manifold compared to the one trained with adversarial training on the real data manifold. Adversarial examples trained with the geometric framework are robust to perturbations in the input $ \mathbb{R}$ that are not present in the training set under the different assumptions ( e.g., $ \nabla_{d}$ where $ d$ is the size of the data manifold, $ b$ points in the manifold that are missing under the geometric assumptions, and $ c$ points that are present under the higher - dimensional assumptions. The framework is applied to train adversarial models on two different sets of data ( $ m$ and $ s$ ), and the results show that under these settings the robustness of the trained adversarial model is higher than under the lower - dimensional setting.   The main result of the framework is obtained by averaging over the set of affine examples obtained from the two sets of training sets ( adversarial and non - adversarial ) trained with different decision boundary classes ( $ \theta$ ). The authors then use this framework to analyze the geometry of some of the perturbation settings in the generated adversarial sets. The results demonstrate that under the geometry analysis the adversarial samples from the higher dimensional setting are more robust than the ones from the lower dimensional setting ( for example, when sampled from a lower dimensional space ). In addition, the authors show that adversarial sampling from the data sets generated by different decision boundaries leads to higher or lower robustness in some cases ( for instance, for points closer to the upper and lower bounds on the data ). Finally, a set of experiments is used to conclude that the geometric frame used in the analysis is the best for training adversarial networks."
SP:e07d948a79d478ecd23a0a4406d4ddd3ac5e3be3,"This paper proposes a new representation learning algorithm for discrete time series using GNNs ( Fashion - MNIST ) and a gradient - based self - organizing map ( GP ) algorithm. The GP algorithm is motivated by the observation that most representation learning algorithms for time series data are non - interpretable due to non - intuitive mappings from data features to salient properties of the representation and non - smoothness over time. The authors propose to introduce a new way to overcome the non - differentiability of GP algorithms in discrete representation learning by adapting GP to the setting of high - dimensional time series. To this end, they propose to learn discrete representations of time series, which give rise to interpretable embeddings with superior clustering performance and provide additional explanatory insights as well as a natural representation of uncertainty. They evaluate the learned representations on static MNIST images, a chaotic Lorenz attractor system with two macro states, a real world medical time series application on the eICU data set and facilitate downstream tasks on the real world data. The learned representations compare favorably with competitor methods. They also evaluate the performance of GP and GP on a time series of linearly interpolated ( FashionMNIST images ) and interpretable data, and evaluate the interpretability and interpretability of the GP algorithm on the data.    The contributions of the paper are as follows. First, the authors propose a new GP method to learn representations from interpretable discrete dimensionality reduction and deep generative modeling. This allows them to learn smooth embedding representations from time series that are interpretable and interpretive. Second, they introduce a gradient based GP that is more performant than the original GP. Third, they integrate a Markov model in the representation space to improve the performance even further."
SP:5915ee71ea58dbdbafa31c1ad291d1e5940a0cf4,"This paper studies the distribution mismatch between linear and non - linear interpolations when considering the latent space prior distributions of generative models based on GANs. Specifically, the authors consider the multidimensional Cauchy distribution as an example of the prior distribution. They show that there is a distribution mismatch that can be eliminated either via the choice of the latent probability distribution or by using non -linear interpolations. The distribution mismatch is defined as the difference of the mean and standard deviation of the posterior probability of a vector sampled from the latent distribution with respect to the origin of the vector. The authors prove that the linear distribution has all the properties required for a stable training procedure, such as finite mean and regularity, and the nonlinear distribution does not have any of these properties. They also provide a general method of creating non - Linear interpolations that is easily applicable to a large family of commonly used latent distributions.    The main contributions of the paper are the following :   1. The paper studies linear interpolation between two random latent vectors in the generative model setting, and proposes to use the multi - headed ant - ant distribution as a prior distribution to represent regions of latent space that are not present in the training data. This is in contrast to the standard prior distribution of the GAN, which is a closed - form distribution. The ant distribution has the form $ \mathbb{R}$ with $ \gamma_0 $ and a mean of $ \theta$ and a standard deviation $ \alpha_0$. The authors use $ \to R$ to represent the difference between the prior and the ant distribution and show that it is a trade - off between $ \eta_0$ and $ \text{M}$, where $ M$ is the number of latent vectors. 2. The main result of the work is a generalization of the result from [ 1 ], showing that for any fixed training distribution there exists a latent distribution $ \mu$ that satisfies all the conditions needed for training to be considered stable ( e.g., a finite mean, regularity and a regularity distribution ), and that $ \Delta(M\to M^2$ is not less than $ \epsilon$ for training but isn'theta^{-1}$ where M \etaM^2 $ is the mean of the distribution of training data, and $ D \to M$.   3. Finally, the paper also gives a general idea of how to obtain a distribution for training data that does not depend on the training distribution, i.e., if the distribution \mu is not finite, but is regular and regular \eta_{M }, then training data will not be stable and will need to be re - trained using a nonlinear interpolation to obtain data from the trained data. The method they use is called the Multi - headed Ant distribution."
SP:19b63ca635712f1509ca6e0141303c192f2709e0,"This paper proposes a hyperbolic embedding space for the attention mechanisms of deep neural networks, based on the geometry of embedding of object representations, to learn the parameters of the model in this space more efficiently. This is achieved by only changing the embedding coordinates of the representations of the network. The embeddings are the same as those of standard Euclidean representations, except that they are in a hyper - bolic space. The idea is that as the number of objects in the query exponentially increases, so does the distance between the query and embedding location, so the hyper - bilinear embedding can better represent those objects. The paper shows improvements in generalization on neural machine translation on WMT’14 ( English to German ), learning on graphs ( both on synthetic and real - world graph tasks ), and visual question answering ( CLEVR ) tasks while keeping the neural representations compact."
SP:f6049e9f80a63c9306c1cebcb6b229aa6da44ddc,"This paper presents the first in - depth security analysis of DNN fingerprinting attacks that exploit cache side - channel attacks exploiting the fact that the attacker does not need access to the victim network ’s features but observes the accesses of the target functions in the shared framework through a co - locating process on the target and co - participating in the process of learning the parameters of the DL system on the other side. The paper proposes and evaluates new framework - level defense techniques that obfuscate the attacker’s observations, including DeepRecon, an attack that reconstructs the architecture of the victim networks using the internal information extracted via Flush+Reload. The authors also demonstrate that an attacker can build a meta - model that accurately fingerprints the architecture and family of the pretrained model in a transfer learning setting. Based on the extracted architecture attributes, the authors evaluate the importance of the observed attributes in the fingerprinting process. The empirical security analysis represents a step toward understanding DNNs’ vulnerability to cache side channel attacks and provides a framework to develop defense strategies to counter such attacks."
SP:6a3dd89db6c24a1f98e8866ef0a4c1c2c1ec6635,"This paper proposes a Hierarchical Prediction Network ( HPNet ) based on self - supervised learning to learn spatiotemporal representations to predict future video frames. The model is inspired by the feedforward, feedback and lateral recurrent circuits in the hierarchical visual system in humans and monkeys. It assumes that spatiotemeporal memories are encoded in the recurrent connections within each level and between different levels of the hierarchy.   The model contains a feed - forward path that computes and encodes spatiotemic features of successive complexity and a feedback path that projects interpretation from a higher level to the level below. Within each level, the feed forward path and the feedback path intersect in a recurrent gated circuit that integrates their signals as well as the circuit ’s internal memory states to generate a prediction of the incoming signals. The network learns by comparing the incoming signal with its prediction, updating its internal model of the world by minimizing the prediction errors at each level of the hierarchically ordered hierarchy, and learning relationships among movement patterns, yielding state - of - the - art performance in long range video sequence predictions in benchmark datasets. The authors observe that hierarchical interaction in the network introduces sensitivity to memories of global movement patterns even in the population representation of the units in the earliest level. This is contrasted with hierarchical interaction without hierarchical interaction which is thought to be crucial for self - supervision. Finally, the authors provide neurophysiological evidence, showing that neurons in the early visual cortex of awake monkeys exhibit very similar sensitivity and behaviors to the ones found in the brains of humans. These findings suggest that predictive self supervision might be an important principle for representational learning in the visual cortex."
SP:fb74e57f35666742caf651e6da33b5defcf259a8,"This paper presents a method to compute continuous embeddings for kmers from raw RNA -seq data in a reference - free fashion. The authors propose a latent space representation space that captures information of both DNA sequence similarity as well as DNA sequence abundance in the embedding latent space. The latent space is obtained by vector embedding vectors computed from the raw data using a linear model of the gene sub - structure. The vectors in the latent space are compared to known gene sub structure vectors and obtained from raw data from acute myeloid leukemia patients. This latent space allows the detection of genomic abnormalities such as translocations and patient - specific mutations, making this representation space useful for visualization and analysis.   The authors present the results of their method in the paper in two different settings : ( 1 ) in the case of leukemia patients, they report that the obtained latent space contains information of exon information from the complete set of all the cells present in the patient and ( 2 ) in a setting where only some cells are present but not all the genes are present, they show that the extracted exon vectors are similar to the ones captured in the original data. This is in contrast with the case where they only sampled cells from a subset of the patients, which they reported contained mutations that they did not observe in the full data set. ( 3 ) In the other setting, they reported that they detected the presence of deletions such as duplications and chromosomal translocations in the extracted latent space but did not find any deletions in the analysed data. Overall, their method seems to perform better than the baselines in terms of accuracy than the one could expect from a reference baseline."
SP:03aca6ff6a7f0ad2d5ccbcb15ed9536e305a9880,"This paper proposes a novel approach to model compression termed Architecture Compression ( AP ). AP is different from the classical model compression methods in that it operates in the architecture space instead of the weight or filter space of the network.   During the compression phase, AP first encodes the network and then performs gradient descent in continuous space to optimize a compression objective function that maximizes accuracy and minimizes parameter count. The final continuous feature is then mapped to a discrete architecture using the decoder. The encoder / decoder is jointly trained to regress accuracy and parameter count in order to incorporate information about the architecture ’s effectiveness on the dataset. They demonstrate the merits of this approach on visual recognition tasks such as CIFAR-10/100, FMNIST and SVHN and achieve a greater than 20x compression on Cifar-10."
SP:0511b5d10a90e3fe814e2d35208b4a987894ea62,"This paper studies the role of local model - based control ( LBC ), global value function learning ( GFL ), and trajectory optimization ( ILO ) in the context of learning value function approximations for an agent with an internal model of the world. In particular, the paper focuses on the application of LBC and GFL to the problem of planning, exploration, and value function estimation.   The main contributions of the paper are the following :   1. The paper proposes a framework for learning value functions for planning in the offline setting, where the agent is guided by a local model and has access to a global model, but needs to act and learn in the world at the same time. This is different from the typical offline setting in which the agent has access only to the model's state space, but uses the global model to explore the world in order to learn value functions. The proposed framework, called Plan Online and Learn offline ( PADE ), can be viewed as an extension of the planning - and - exploration ( planning + exploration ) framework from Yao et al. ( 2021 ), where agents are guided by external and internal models, but also have access to the full set of state space and the ability to explore policies beyond the local state space. The main idea of PADE is to use ILO to estimate the uncertainty in the value function of the agent's trajectory when value function estimates are uncertain. This uncertainty can then be used to perform temporally coordinated exploration, which allows for fast learning of the value functions with respect to the uncertainty. This paper shows how ILO can be combined with local and global value functions, and the benefits this has for planning ( stability, faster exploration, reduced planning horizon, and faster learning of value functions ). In addition, PADE can also be used for complex control tasks, such as humanoid locomotion and deoxidous in - hand manipulation, which can be realized with a few minutes of planning ( equivalent of a few hours of experience in the real world )   2. Empirically, this paper shows that PADE improves the performance of value function estimating and exploration when planning with ILO in the same amount of time, and that trajectory optimization can improve the performance even further when value functions are estimated using ILO."
SP:771494fda4702cd8c7efbf225b19028f91b449b9,"This paper presents a zero - shot machine translation model that combines reinforcement learning and dual learning for low - resource languages. The model is based on Neural Machine Translation ( NMT ), an unsupervised machine translation ( MLT ) model that uses a transformer - based encoder - decoder. The encoder is trained with LSTM-based data, and the decoder is semi - supervised using self - supervised reinforcement learning. The target language pairs for the model are English - French and English - Spanish, while the target task is Spanish - French, which is a mixture of English and French. They train the model with zero - shots of each language, and train the encoder and decoder separately for each language pair. They evaluate the proposed model on the task of zero shot translation on the UN corpus ( in both directions ) and evaluate the reinforcement learning - based model ( Z - learnt model ) on tasks with parallel data. They show that the Z - learned model outperforms a standard NMT system in zero -shot translation performance on SpanishFrench ( in all directions ). The proposed model also outperforms the standard MLT on the dual learning task, where the model is trained using reinforcement learning instead of self - training. They also evaluate the model on two different sets of tasks, one where the language pairs are only trained using parallel data and one where they use supervised learning. They compare the proposed method with two sets of MLT models trained with different amounts of parallel data, one trained on English-French and English-Spanish, and one trained using the Chinese ( Simplified ) language pairs, and they compare the performance on both of them."
SP:1558dc03f99670f9ddccdca9c223a2baf962d438,"This paper presents a generative adversarial network based on GANs called IRGAN ( Graph - based Information - Retrieval Generative Generative Adversarial Networks ), which is based on PEARL ( Li et al., 2019 ) and the GAN - GP - GP framework ( Liu et al, 2020 ). They extend the original idea of using a co - operating generator to model the conditional probability distribution p(d|q|q ) over the documents ( documents ) given the query $ d$, and present a set of experiments that compare their loss - functions based on the minimax loss function and the co - training - like setup ( where two models are trained in co - operation rather than an adversarial setting ). The results suggest that the proposed method has better performance than the baselines that are based on exact adversarial training. The main reason for this is that the setup of IRGAN differs from the adversarial formulation used in the authors ’ original work, where one model is trained adversarially and the other one is trained as a generator. The authors argue that this is because the generator “ learns ” the distribution of the probability distribution given the data, while the discriminator is trained to estimate the actual probability distribution from the data. They also point out some errors in the formulation of the assumptions used to train the generator ( e.g., the fact that the generator is only trained on documents and not on all possible combinations of documents, and that the discriminators are not trained to discriminate between documents that are identical to each other and ones that are differentiable. The experiments are conducted using the same set of documents and datasets. They compare and contrast the performance of their proposed method with their baseline GANet - GAN, which uses a GAN that discriminator, and show that their generator performs better than the baseline that uses a discriminator that discriminates between documents and the documents. Finally, the authors present results that show that IRGAN can outperform the baseline by an order of magnitude ( on average by a factor of 2.7 for documents and 1.9 for datasets that are similar to the one they evaluate."
SP:6a13dda852ab075a3c0fb691476d6dc57919c729,"The paper proposes Sparsity in sparse generative models for VAEs, a generative model consisting of variational auto - encoders and sparse coding with a Spike and Slab prior distribution. The idea is to model sparsity in the latent space of a VAE with a discrete mixture recognition function thereby making approximate posterior inference as computational efficient as in the standard VAE case. The authors derive sparse representations with generally intractable non - linear probabilistic models and demonstrate improved classification accuracy and significantly increased robustness to the number of latent dimensions.   The main contributions of the paper are the following :   1 ) The authors propose to model sparse latent codes in the VAE latent space using a variational autoencoder, sparse coding, and a Spike recognition function. The sparse representations are compared with sparse representations on two benchmark classification tasks ( MNIST and Fashion - MNIST ), showing that the obtained representations are significantly more accurate than the sparse representations obtained by standard VAEs under the assumption of sparsity. 2 ) A set of experiments evaluate the performance of the proposed sparsity method on the classification and interpretation tasks of two VAE models, one of which is based on sparse coding and the other on the Spike recognition model. The experiments demonstrate that the representations are more accurate and robust to variations in the sparse coding introduced by the authors compared to the baseline VAE, and that sparsity is more prominent in the representations."
SP:06a22143186fa2948fbe324ccae96a62ff12064e,"Generative Feature Matching Networks ( GFMN ) is a feature extraction approach that leverages pre - trained generative models such as ConvNet and autoencoders to achieve state - of - the - art results on datasets such as CIFAR10 and STL10. The main idea of the approach is to use a feature matching network that first extract the features from the input data and then match the features with the extracted data via feature extraction matrices. The training is done using ConvNet classifiers trained on ImageNet. The authors conduct extensive experiments to validate the effectiveness of their approach. The experimental results demonstrate that the extracted features are expressive enough to warrant using the feature matching networks even if only the first order statistics are matched.    The main contributions of this paper are as follows :   1. A new feature extraction method, based on the feature extraction network, is proposed. The exact mechanism for extracting the features is not fully understood. It is possible to approximate the exact process using the features extracted from the training by other methods, but it is not clear if this is possible and if so if it is possible for the proposed method to achieve the same feature extraction results as the ones achieved by the other methods. 2. A set of experiments are performed to verify the expressiveness of the features obtained from the feature extracting network using the classifiers. The experiments are divided into two parts : one uses ImageNet to extract features and another uses the autoencoder and the classifier trained on ConvNet to generate the features. The results of the experiments indicate that the obtained feature extraction methods are the most expressive and the obtained features are the best when the features are extracted from training data using only the features matching network. 3. In the second part of the experiment, the authors use a different set of classifiers to extract different features from ImageNet, this time using a slightly different training procedure to obtain more expressive features."
SP:2d7cf2f07a27d6c8e304a1b47c25387ad2e4432d,"Graph Neural Networks ( GNNs ) have revolutionized graph representation learning, but there is limited understanding of their representational properties and limitations. This paper presents a theoretical framework for analyzing the expressive power of different graph structures. The main contribution is to develop a simple GNN architecture that is provably the most expressive among the class of GraphSAGE and GraphGANDAGE, and is as powerful as the most powerful graph neural networks. The authors empirically validate their theoretical findings on a number of graph classification benchmarks, and demonstrate that their model achieves state - of - the - art performance on node and graph classification tasks. The results show that the discriminative power of popular GNN variants, such as graphSAGE, can not learn to distinguish simple graph structures, even when the target task is graph classification.   The main contributions of this paper are as follows :   1 ) The authors develop and evaluate a simple graph neural network architecture based on a neighborhood aggregation scheme, where the representation vector of a node is computed by recursively aggregating and transforming representation vectors of its neighboring nodes. 2 ) They provide a simple empirical evaluation that shows that the proposed GNN is not as expressive as the powerful graphNNs and GNNGANs under mild conditions. 3 ) They develop and test a GNN variant that is more expressive than both GNN and GANs, and show that it is able to learn the target target task better than the other two."
SP:51126f2dd37ce57d2614c9044ede1e43627f0829,"This paper proposes ICL - ICL, a framework for interpretable continual learning. ICL is based on the variational continual learning framework ( VCL ), developed originally to deal with catastrophic forgetting in the context of reinforcement learning. The idea is to generate a good explanation of previously performed tasks, which can then be used to improve performance on new tasks that are learned from scratch. The paper proposes to assess the quality of the explanations generated by ICL by using a new metric, the saliency metric, which measures the distance between the average query query score ( i.e. query accuracy ) of tasks learned from previous tasks and the query score of new task from ICL. The metric is motivated by the observation that the query scores of tasks from the previous task are less likely to be queried compared to tasks from a new task that were learned from the same query but from different subsets of the same data.   The paper presents experiments comparing ICL to other methods of continual learning, mainly focusing on the VCL framework. The main results show that ICL outperforms other methods in terms of overall continual learning performance ( measured by average classification accuracy ) and explanations quality ( measured using the proposed metric - qualitatively and quantitatively using the metric - based estimator ). However, there are some inconsistencies in the experimental results and explanations between ICL and other methods, including the use of different explanations for different tasks."
SP:27a565b3e5442b93d208652784051e640b0c1bfe,"This paper proposes a new evaluation framework for assessing the robustness of neural sequence - to - sequence ( seq2seq ) models by applying perturbations to the input of a model leading to large degradation in performance. The main idea is to use the machine translation ( MT ) model as an example, where the input sequence is represented by a machine translation model, and the perturbation is applied to the semantics of the input in a way that would change the expected output from the model. The authors show that the existing evaluation methods do not take meaning preservation into account, and propose new constraints for attacks on word - based MT systems that require the input to be semantically similar to the output of the target model in order to detect weaknesses in the MT model.   The main contribution of this paper is the introduction of a framework that evaluates the performance of the proposed adversarial attacks on the following types of input sequences : 1 ) input sequence : If the input is semantically consistent with the output ( e.g., if the output does not change significantly from the input ), then the attacks do not have a significant impact on the performance. 2 ) The input sequence can be any sequence : The input could be any set of sequences, or it could be a collection of sequences starting from one input sequence and ending in another set of similar sequences. 3 ) The output of each sequence could be sampled from a set of subsequences such that the mean and the variance of the subsequences are close to each other or they could be independent of each other. The goal is to find a sequence that has a high mean and a low variance in the input sequences so that the memory used to train the model is not too full and the memory does not become too small after training the model in the adversarial attack. The proposed evaluation framework considers two types of attacks : one that attacks input sequences with the same semantics ( meaning - preserving ) and another that attacks inputs that are semantically different from each other ( different from the ones used for the mean or the variance control ). The framework is evaluated using the MT example and evaluates using a combination of human evaluation and automatic evaluation. The evaluation shows that the proposed evaluation methods perform significantly better than the baselines that do not evaluate the input through the meaning. Moreover, the evaluation using the human evaluation evaluates the input more accurately than using the automatic evaluation and the human evaluations do not require the meaning preserving step, suggesting that the methods may not preserve the meaning in general."
SP:54ddd8132bf9e4259d2c2d72b348d2bb5f9e227c,"This paper presents a broad - spectrum improvement for reinforcement learning algorithms which combines the policies using original rewards and inverse ( negative ) rewards to obtain rewards competitive with the original policies. The main contributions are three - folds : ( 1 ) Towards Inverse Rewards Convergence, ( 2 ) Inverse Policy Inverse Learning, and ( 3 ) On - policy Actor - Critic. The paper first proposes to use the inverse rewards to train policies to correct mis - actions of the policy using in - policy policies using inverse rewards. Then, the paper shows that the convergence of the inverse policies is proven using experiments in OpenAI gym games using three different policies based on Q - learning, Double Q - Learning and actor - critic policies. Inverse policy convergence results in rewards obtaining up to 54.7 % more than the original policy in some games. The improved policies are stable and more flexible than the policies with inverse policies.    The main contribution of this paper is the following : ( a ) Towards INREDUE CONCEALATION. This paper proposes to develop policies that use inverse rewards such that the rewards obtained by using inverse policies are at least as good as those obtained using original policies, and vice versa. ( b ) Towards Double - Q - LE ( the third approach proposed in this paper ) is the first step towards achieving the convergence towards the proposed Inverse Reward Convergence."
SP:89a732b57934d08b937c93560f391b7758e54f8a,"This paper proposes a model for predicting object motion patterns in videos using a parts - structure - and - dynamics model. The model is called Parts, Structure, and Dynamics ( PSD ) and it consists of three components. The first component is a hierarchical representation of object parts that represents them as nodes in a hierarchical hierarchy. This representation is learned by watching object parts in a video and learning their hierarchical structure by watching how they move and then predicting how each node will move in the future. The second component is the hierarchical structure that takes a low - level symbolic structure and embeds it into a hierarchical structure using a transformer. This transformer is then used to segment the video to get object parts. The third component, the dynamics component, is used to predict the future state of the transformer using past and future trajectories of the objects in the video. PSD is trained with three components : an object segmentation component that learns how to identify object parts from the hierarchical representation, a structural component that embeds low level symbolic concepts into hierarchical structures, and a dynamics component that predicts the dynamics of the model. Experiments are conducted on four tasks : segmenting the video, predicting the hierarchy, predicting how the nodes in the hierarchy will move, tracking the motion of the nodes, and capturing the motion distributions of the dynamics components. On all four tasks the model is shown to learn well and to be able to predict most of the time. On the segmentation task, PSD seems to have trouble with the low level concept embedding but with the higher level embedding it is able to learn quickly and accurately."
SP:bb2a655d67bed9da43f0b8ec7d888b89c217d12e,"This paper proposes a novel inference method, Deep Determinantal generative classifier ( DDGC ), which can obtain a more robust decision boundary under any softmax neural classifier pre - trained on noisy datasets. The proposed method is based on estimating the parametrized covariance determinant estimator from the hidden feature spaces of the discriminative deep model to build a generative model on top of the hidden features from the deep model. The authors show that DDGC significantly improves the classification accuracy, with neither re - training of the deep models nor changing its architectures. They also propose an ensemble version of DDGC to improve its performance, by investigating the layer - wise characteristics of the generator. They conduct extensive experimental results to demonstrate the superiority of the DDGC given different learning models optimized by various training techniques to handle noisy labels or adversarial samples.    The main contributions of this paper are as follows :   ( 1 ) The authors propose an inference method to estimate the parametric covariance of the generated classifier from the features in hidden feature space of discriminatives using the minimum covariance estimator ; ( 2 ) The method is shown to generalize well from noisy labels and is robust against adversarial perturbations due to its large margin. ( 3 ) A set of experiments are performed on CIFAR-10 datasets containing 45 % to 43 % noisy labels, where DDGC is compared with a deep model optimized by the state - of - the - art noise - handling training method from 33.34% to 43.02%. ( 4 ) They conduct a series of experiments to evaluate the robustness of the proposed method, DDGC against other methods to improve the test accuracy of the classifier."
SP:0fa525cc708470b757a60117cb608bb2feaa2c50,"This paper proposes a method for subgoal discovery in hierarchical reinforcement learning ( HRL ) based on incremental unsupervised learning ( i.e. learning action selection policies at multiple levels of temporal abstraction ) that uses state - action pairs in the Montezuma's Revenge environment from the Atari 2600 game with sparse delayed feedback. The authors claim that this method is suitable for large - scale applications involving large state spaces and sparse delayed reward feedback due to the scalability issues of large action selection in HRL.   The main contribution of this paper is the method for discovering states that are likely to be useful subgoals for a given action in the state space using a Hierarchical Reinforcement Learning policy and then learning the corresponding skill policies to achieve those subgoal goals. This is achieved by using a relatively small set of states that can be identified using a model of the environment, a state distribution model, and action policies that are selected based on intrinsic motivation. Once subgoal states are identified, skills may be learned through intrinsic motivation, introducing an internal reward signal marking subgoal attainment. This paper proposes to combine intrinsic motivation learning and skill learning to learn these intrinsic motivation and skills together, based on on experiences in the environment. In order to achieve this goal, the authors propose to use an approach similar to what is proposed in [ 1 ], except that instead of using intrinsic motivation it uses an approach based on learning the intrinsic state distribution. This approach is referred to as the "" model - free approach to HRL "" and is similar to the approach in [ 2 ]. The major difference between the two approaches is that the first one proposes to learn the state distribution using an intrinsic motivation alone, while the second one proposes a combination of state distribution and intrinsic motivation to learn skill distribution. The differences are discussed briefly and briefly in the main text of the paper. The main results of the experiments are the following :   ( 1 ) The authors demonstrate that their method is able to achieve similar performance as HRL policy HRL with the proposed intrinsic motivation method using state - based state distribution modeling, state - level policies, action policy selection at state level, and skill - based action selection at policy level using the intrinsic motivation approach. ( 2 ) They compare their method with two different state - space HRL policies in the ATARI 2600 environment that they claim to be able to learn similar performance to the original HRL method ( with intrinsic motivation ) and a different policy based state - state HRL approach ( intrinsic state - policy learning ). The experiments show that the proposed method achieves better performance than both of them on the tested environment compared to the first and second policy setting. However, the"
SP:e5861538bc8bb9165cb33299bbf12dd875abf976,"This paper proposes a neural framework to solve the Circuit Satisfiability ( SAT ) problem by embedding the problem in a rich neural network. This is similar to the recently developed NeuroSAT method for solving combinatorial SAT problems. The main difference is that the proposed approach trains the neural network directly on the SAT problem instead of using an embedding network to represent the problem. The embedding is modelled with a similarity to Reinforcement Learning ( RL ) model, and the training procedure mimics the way RL is learnt in the case of the Sinkhorn method. The authors conduct experiments comparing the performance of their approach to that of SAT and a naive approach that learns the embedding directly from the data. The experimental results show that the approach outperforms the naive approach in terms of generalization, especially when the number of samples is small.    The main contributions of the paper are the following :   1 ) A neural embedding that allows the training of the model to be done end - to - end, mimicking the approach of RL. 2 ) A training procedure that trains the model directly from data to train the network. 3 ) A method for training the network using the learned embedding and training the model using gradient descent."
SP:ff3e5d44619df3825632b0b1a943add081364861,"This paper proposes a new method combining the cross - entropy method ( CEM ) and DDPG ( Deep Deterministic Policy Gradient ) for policy search. The authors show that CEM - CDPG is a sample efficient off - policy deep RL algorithm with good performance and low overhead. They also compare the resulting method, CEM-RL, with DDPGP, a sample - efficient algorithm for deep reinforcement learning ( DRL ) and show that it has advantages over DRL and offers a satisfactory trade - off between performance and sample efficiency. CEM is evaluated on a set of benchmarks ( TD3, RMSRP, and Twin Delayed Delayed ), and compared with two previously existing combinations use either an ad hoc evolutionary algorithm or a goal exploration process together with CEM. The experiments are conducted to evaluate the effect of combining the two methods and to compare the performance of CEM with that of the two DRL algorithms."
SP:78b2eb326695da0b0cc4ba39a9206d11644a5e32,"This paper proposes a new multi - variable recurrent neural network ( LSTM ) based on hidden state matrix and update process called Hidden State Matrix Update ( SSM ) to learn the hidden states of the target and exogenous states. The update process uses hidden state vectors to update the state matrix at each time step of the predictor and uses attention mechanism and summarization methods to quantify the temporal and variable importance in the data. The authors also propose a novel ELBO - style ELBO to train the latent variable representations of hidden states. Experimental results show that the proposed model outperforms other baselines in terms of prediction performance and interpretability.    The main contributions of the paper are as follows :   - A new state matrix based on latent state vectors is learned using hidden state update process with update process and attention mechanism. This is compared to previous state - based methods ( hidden state vector, hidden state attention, ELBO ) on two datasets ( CIFAR-10 and Fashion - MNIST ). Results show that this new model performs better on both the prediction performance ( prediction of MNIST vs FMI ) and the variable - level importance quantification. - The ELBO and ELBO are used for training the model and experiments are conducted to demonstrate the effectiveness of the ELBO."
SP:1c26660569b579f060f7b4a31e321c6d2356b928,"This paper proposes feature smoothing, a data augmentation method with little computational overhead to train a neural network on virtual training data as an interpolation of features from a pair of samples, with the new label remaining the same as the dominant data point.   The intuition behind feature smoothed is to generate virtual data points as close as adversarial examples, and to avoid the computational burden of generating data during training. The experiments on MNIST and CIFAR-10 datasets explore different combinations of known regularization and data augmentation methods, and show that the smoothing with logit squeezing performs the best for both adversarial defense both in terms of adversarial clean and clean accuracy. The authors also propose an unified framework to understand the connections and differences among different efficient methods by analyzing the biases and biases of the decision makers. In the experiments, they show that under some symmetrical assumptions, label smoothing ( logit squeeze ), weight decay, mix up, and feature smoothhing, all produce an unbiased estimation of decision boundary with smaller estimated variance. All of those methods except weight decay are stable except for weight decay when the assumptions no longer hold. In addition, the authors propose an unifying framework to enable comparisons of different efficient and less efficient methods."
SP:88d652f9e411dd3a2e9ad651d9011e579653c6aa,"This paper studies the problem of understanding theoretical properties of deep and locally connected nonlinear neural networks, such as deep convolutional neural networks ( DCNNs ). To this end, it proposes a novel theoretical framework for such networks with ReLU nonlinearity. The framework bridges data distribution with gradient descent rules, favors disentangled representations and is compatible with common regularization techniques such as Batch Norm, after a novel discovery of its projection nature.   The framework is built upon teacher - student setting, by projecting the student ’s forward / backward pass onto the teacher’s computational graph. The ReLU framework could help facilitate theoretical analysis of many practical issues, e.g. understanding the activation of ReLU neural networks. The main contributions of this paper are the following :   1. A new theoretical framework, the ReLU - DCNN, is proposed for understanding the non - linearity of deep neural networks ;   2. It proposes to study the distribution distribution of parameters in the DCNN by ReLU graph, and to use gradient descent to approximate the gradients ; 3. It is experimentally tested on a small set of experiments on MNIST and Fashion - MNIST, and it is shown that it outperforms the related DeepDCNN framework on some tasks."
SP:7842bbe0e2324cfd732db8745550733ccc3dfcdc,"This paper proposes a modular architecture of neural networks, called Pre - Frontal Cortex ( PFC ), consisting of a Behavioral Module ( BM ) and an end - to - end training strategy ( ET ) strategy for learning behaviors and preferences. This approach is based on the idea that the PFC is a part of the brain which is responsible for behavior formation process and the BMs are modules of the network that are connected via PFC to the network ’s functionality and connectivity with the rest of the neurons in the network. The main idea of the paper is to use BMs to learn a pre - trained model of user preferences and behaviors, which can then be used for task learning ( dialog agent ) and recommendation tasks. The paper presents experiments that compare the performance of the proposed method ( Behavioral Module ) against state - of - the - art methods in video game interaction modeling and behavioral cloning. The experiments also show network extendability through independent learning of new behavior patterns that are learned from the learned behavior modules. Moreover, the paper presents a strategy for an efficient transfer of newly learned BMs from one task to another using ET as a learning strategy."
SP:300c391ff644b6889cd9ae27cf0d162dfcdd4451,"This paper proposes a differentiable formulation for the neuromodulated plasticity that allows for training neural networks with gradient descent. Based on differentiable Hebbian plasticity, this formulation is similar to the one used in the original Neuromodulation Theory of Plasticity ( Zhu et al., 2021 ). The main difference is that the proposed formulation does not require the network's connectivity changes to be modulated by the neurons themselves, which is claimed to be the self - modulating ability of the plasticity. This formulation is then used to train neural networks in two reinforcement learning tasks ( reinforcement learning and supervised learning ) using LSTMs. The authors compare the performance of the trained neural networks against the un - trained ones on both tasks. The experiments show that the trained networks perform significantly better on the supervised learning tasks compared to unpredicted neural networks.   The main contributions of the paper are the following :   1 ) The authors develop a new formulation of the parameterized neurodulation of plasticity and use it to motivate the training of neural networks using gradient descent 2 ) The formulation is based on the idea of self - modifying abilities of the brain, which are well known to play an important role in learning and adaptation and are a major basis of reinforcement learning in biological reinforcement learning   3 ) They use this formulation to motivate a neural network training method that relies on gradient descent to learn the parameters of the neural network trained by gradient descent using the neurodulated version of the weight vector. This training method is referred to earlier work ( Zhang & Tan, 2018a ) and is similar in spirit to what they do with neural networks and gradient descent ( Zhang et al, 2021a ). However, the difference between the two is more subtle and is mainly motivated by the fact that the neural networks learn the weights of the corresponding neurodulations in the paper rather than the neurons in the case of the first method. The paper does n’t propose a gradient descent gradient estimator, but rather a weighted average estimator. This allows the authors to use the same number of parameters for training as in the first paper, but with the weight estimator scaled according to the number of neurons ( instead of the original weight estimate which is done by number of synaptic connections per layer as done in Zhu & Tan. 4 ) The experiments compare the effect of the formulation of neurodulating plasticity with the one proposed in Zhang & tan ( Wang & Tan ) and their training method ( gradient descent + LSTM ) and show that in general, the proposed method performs slightly better ( on average )."
SP:1ab5d94d31e99351433436c026799c8aa597bf73,"This paper presents a non - intrusive quantization method for deep neural networks ( DNNs ) based on re - training the full precision model followed by optimizing the corresponding binary model. The main contributions are : 1 ) A new loss function to regularize the weights of the weights used to train the binary model is proposed, leading to reduced quantization error ; and 2 ) A method to combine the quantization training and the binary quantization to achieve full precision accuracy on WikiText - 2 using 2 bit quantization. The method is evaluated on the CIFAR and WikiText-2 datasets and compared with other quantization methods. Results show that the proposed method leads to a significant reduction in the accuracy loss for the full - precision DNN and achieves a significant increase in accuracy for the binary - quantized model. Comparable results are also shown for ImageNet and ImageNet with LSTM.    The main contribution of this paper is the following :   1 ) The proposed method for quantizing deep neural network weights using binary quantized weights is proposed. This method is shown to achieve a significant decrease in the training time and error of quantized neural network models. 2 ) The loss function proposed to regularise the weights is also applied to the training of binary quantised models to achieve reduced quantisation error."
SP:0876b1d9a6d664808ca1ab15865679fbf638267e,"This paper proposes Style Transfer onto Open - Ended Content ( STOC ), a method for style transfer onto open - ended content representation ( OEC ). The core idea of STOC is to train a style encoder and a content encoder on top of an embedding from a deep metric learning ( DML ) model, such as VAE, so that the latent representations of the DML model can be decomposed into style and content representations, which can then be used for reconstruction and recombination. The method is different from previous work in three ways :   1. STOC can transfer the learned style representations directly from the training data to the test set, which means that the learned representations do not need to be conditioned on the class labels used in the training. This is in contrast to previous work that conditioned the style representations on the labels of the content representations.   2. In contrast to prior work, STOC does not require the training examples to be differentiable and can be used to synthesize novel images by decoding the style representation obtained from one image with the content representation from another. This enables the method to generalize to images that are not present in the original training data. 3. Previous work based on OEC has an explicit objective of leakage filtering, which is not found in most previous work, to isolate content and style. As a result, synthesized examples may fail to preserve content as style is varied and vice versa. 4. In addition, the method requires labeling entities by content class, but style labels are not required. This allows STOC to obtain performance results on few - shot learning tasks that are distinguished not only by class label but also by attributes orthogonal to class label. For example, within - class variation is due to lighting, pose, expression, hairstyle ; if masterworks of art are classified by the painter, within- class variation as subject matter, respectively, the attributes are differentiable. The authors obtain state - of - the - art performance on the VGG - face dataset. Style is well transferred, but content is fairly well transferred to the degree that the faces in the middle row are more similar to top - row than bottom - row faces. The images in the top and bottom rows are of identities ( content ) held out from training. The training faces are labeled by identity ; style is induced by the training procedure. Figure 1 shows examples of content - style decomposition using STOC using STO - style encode"
SP:d37e15cde7765fca87595a242f0a4511b3346d46,"This paper proposes a new method to speed up deep reinforcement learning ( deep RL ) training for problems that have the property of state - action permissibility ( SAP ). There are two types of states that are considered under SAP : 1 ) states that an action is not permissible in if it does not lead to an optimal solution and thus should not be tried ; 2 ) states where the action is permissible but not if the action can not be done in any of the given states. The paper proposes to incorporate the proposed SAP property into two state - of - the - art deep RL algorithms to guide their state -action exploration. The first algorithm is based on the fact that under the first type of SAP the agent can already decide whether an action at is permissible or not in a state if it can be done at least as long as it is possible at the new state st+1. The second algorithm builds on the idea that even without performing the action at in the first state, an agent can decide whether to take action at ( before reaching state st ).   The paper conducts extensive experiments to show that the proposed method can produce results that are competitive with existing methods for speeding up training in deep RL. The main contributions of the paper are as follows :   1 ) The paper develops and studies a method for training agents to solve problems that fall under the class of State - Action Permissibility Problems, where the state is a collection of states, each state is made up of several sub - states ( called states ) that correspond to actions that can be taken in each sub - state. The training goal is to train agents to take actions in states when they reach a state of ( at least ). This is achieved by training the agent in states with high probability ( high probability ) action selection ( low probability action selection is performed in states that have high probability that the action will lead to a state that has high probability action in it. The proposed method trains the agent to distinguish between states of probability, states of action at and action not taking action at under the state of probability. The difference between states is measured using the ratio of the probability of action taking the action in each state with the current state and action taken in the previous state ( the action from the action not taken in that state ). The method is evaluated on a series of problems where it has successively higher success rate for states with lower success rates for action selection than states with higher success rates. The experiments show that adopting the proposed methods results in a substantial speed up in solving these problems compared to existing methods. In particular, when the number of states in the training set is small ( 5 % of the total number of actions taken ), the developed method is able to complete training in half the time. When there is a sufficiently large difference in terms of time between states and actions taken, the speed up is even faster."
SP:20015d8b60e13300586b67c281858cbe28825c48,"This paper studies the autoencoder model with multilayer vanilla autoencoders with the assumption of random weights. The authors provide quantitative answers and insights to three questions that were not yet fully understood in the literature : 1 ) how the model performs approximate inference as posed by Scellier et al. ( 2018 ) and its connection to reversibility considered by several theoretical studies ; 2 ) the sensitivity of the model to perturbations in the parameters of the generative model compared to the shallow model ; 3 ) the role of training initialization in preventing pitfalls in training initialization practice.   The authors study the behavior of weight - tied multilayers with uniform weights, pretrained with the tanh activation and a depth as large as 200 layers, without resorting to techniques such as layer - wise pre - training or batch normalization. They find that the deep model exhibits a higher degree of sensitivity to perturbed parameters, distinct from the shallow counterparts. They also demonstrate experimentally that it is possible to train a deep model with a depth of up to 200 layers even with no additional training ( without using Lipschitz activations ). The main contributions of the paper are the following :   1 ) The analysis is conducted with an exact characterization in the limit of large dimensions. This allows them to identify interesting phase transition phenomena when the depth becomes large. This, in particular, provides quantitative answers to the questions 1 ) and 2 ) providing insights to 3 ) providing quantitative answers. 2 ) The authors show that deep models exhibit a higher learning rate than shallow models. 3 ) The experiments demonstrate that the model learns faster and more accurately with deeper layers."
SP:91764f80dbe2401ade38b35a8253ba05f0f86386,"This paper proposes a new adversarial image search algorithm based on the DCT iterative principle. The algorithm randomly chooses a low frequency component of the discrete cosine transform ( DCT ) and either add or subtract it from the target image when computing the adversarial update. The paper studies adversarial black - box attacks ( AD ) using the proposed algorithm. The proposed algorithm can be used for both targeted attacks and untargeted attacks, and it achieves previously unprecedented query efficiency in both settings. The main contributions are as follows :   - Proposes a new algorithm to search for adversarial images within the high dimensions within a small region around a target image. The goal is to find an imperceptibly modified image that is misclassified by the target model, and the only feedback is provided is through the model evaluations. The method is extremely fast and can be implemented in less than 20 lines of PyTorch code. The authors argue that our proposed algorithm should serve as a strong baseline for the future future Adversarial Black Box Attacks. - In particular, we propose a method that, given a median of 600 black box model queries ( ResNet - 50 ) to produce an adversarial ImageNet image, and we successfully attack Google with $ \ell_2 $ images ( $ 3 $ per image ), produces an $ \epsilon$ adversary that is $ \sqrt{50}$ smaller than the target.    The paper compares the proposed method with two baselines : ( 1 ) DCT - DCT, a prior method based on Gaussian Mixture Model Transform ( GMM ), and ( 2 ) GCT - MCTM, a variant of DCTM that uses a different Gaussian mappings to obtain a different set of target and adversary images. The differences between DCT and DCT are discussed briefly in the main text, but the differences between the two methods are not significant enough to warrant a separate review. In addition, the authors also compare the cost of running DCT+GMM with and without GCT and GCT+M to running both methods and argue that the choice of GMM has a major impact on the final cost."
SP:fc20ae0fbf57a1ce489c04b85c7c2f4c93dc2450,"This paper proposes a method for option discovery based on the hierarchical options framework, where a set of well connected sub - goals is sampled from a state space so that a densely connected set of states are easily accessible. The authors propose a new model called Successor options that leverages the leverages Successor representations to achieve the same. The key idea of the model is to firstly predict a state from the set of sub - goal sub - goals that is well connected to the rest of the state and vice versa. Then, the authors propose to learn a sequence of high - level state - action sequences that, when sequences are drawn from the top - level states of the first state, correspond to the options set. When the sequence is complete, the state is returned to the previous state. The goal of the paper is to predict the value of each sequence from the sub - Goal 1 to the next state using a combination of a value function, a logistic function, and a likelihood ratio function. This is similar to the way of thinking of the options framework. However, instead of predicting the value function as in the previous work, in this paper the authors use the term “ mark ” to refer to the points along the path from the goal state to the other states that are sampled from the well - connected set. The idea is that the Mark “ Mark ” represents the distance along the route from the Goal State to other Goal States. When a Goal State is reached, the distance between Goal State and other Goal Sub - Goal is converted into a margin. When multiple Goal States are reached, a margin is drawn from Goal 1 and Goal 2. The margin is the average margin over all Goal States that was reached before reaching Goal State.    The authors also propose a novel pseudo - learning framework for learning the learning the intra - option policies under the option framework, which they call the pseudo - pseudo - successor options leveraged learning the options leverages. In the appendix, they describe an Incremental Successor model that iteratively builds options and explores in environments where exploration through primitive actions is inadequate to form the parametrized representations in the initial state using the pseudohierarchical successor representations. The pseudo - leverages learnable transferable skills from the framework are compared with the original model and learnable options from the employable leverages from the original. They demonstrate the efficacy of their approach on a collection of grid worlds and on complex high dimensional environments like Deepmind-Lab."
SP:12a172c1e2892d016b37932acfc48dcb56874a89,"This paper proposes a domain division method to handle the problem of classifying instances drawn from different probabilistic distributions. This is similar to the approach in Open Set Learning ( OSL ) and Generalized Zero - Shot Learning ( G - ZSL ), where the testing instances come from either seen or unseen / novel classes with different probability distributions. The main difference is that this paper proposes to directly estimate and fine - tune the decision boundary between seen and unseen classes by means of a new two - level domain division consisting of known, unknown and uncertain domains. In particular, the domain division consists of three components : ( 1 ) a classifier to split the instances into known / unknown classes, ( 2 ) a conduct recognition task in each of the three domains, and ( 3 ) a test procedure in each domain to test whether the classifier is correct in classifying the seen / unseen classes as outliers or not. The authors also propose an additional procedure in the middle section to adopt instances whose domain labels can not be predicted confidently using the seen - novel classifier. This procedure is referred to as fine - tuning the boundary between the seen class boundary and the unseen class boundary. Extensive experiments demonstrate that the proposed method improves upon the state - of - the - art performance on OSL and G -ZSL benchmarks. The domain division is applied to both standard and experimental settings. The results demonstrate that it leads to better performance than the classifiers used in previous works. The proposed method is also compared with two prior works that calibrate the confident classifiers of seen classes :   [ 1 ] and [ 2 ]."
SP:28bcf7c6a4673e9ec2b4ebed09839d85188e0b2a,"This paper proposes a new method for regression and classification using neural networks without the need for learning layout structures in the output space. The proposed method, called polar prototype networks, is a priori distributed with maximal margin separation and equal shares on the hypersphere of the input space. Each class is described by a single prototype and they are assigned to prototypes randomly or based on semantic priors. For regression, the training can be performed as a cross - entropy between two prototypes, arriving at a point at the end of a regression with higher - dimensional inputs and outputs. The performance of the proposed method is on par or slightly better than that of standard network methods, with the main advantage over standard methods being that they do not require learning the layout structures.    The main contributions of the paper are as follows :   1. The authors propose a new class of neural networks, named polar prototypes, that explicitly state the layout of the output of the class space using prototypes. This is different from standard methods that parametrize inductive structures such as maximum margin separation ( MMS ) and simplicity ( occam's razor ), which are parametric and learnable. 2. The class is defined by a set of prototypes that are assigned randomly to classes in the space of output dimensions. 3. The network is trained to output dimensions using MMS and MSE, and the prototypes are used to generate class labels for each class. 4. The training procedure is repeated until all prototypes become identical. 5. The method is evaluated empirically on classification and regression tasks and compared to standard methods. The results show that the proposed by the authors are better than the performance on both tasks when compared to the methods based on MESR ( MSE )."
SP:d1034342785d133cf8372b8624897963cc2ee83a,"This paper proposes a new approach for evaluating the idea of implicit bias in reinforcement learning ( RL ). The idea is that when a robot is deployed in an environment that humans act in, the state of the environment is already optimized for what humans want, so we can use this implicit preference information from the state to fill in the blanks of what not to do. The paper proposes an algorithm based on Maximum Causal Entropy IRL ( MAERL ) to evaluate the idea in a suite of proof -of - concept environments designed to show its properties. The algorithm is applied to two scenarios :    ( 1 ) A proof - of - concept environment in which the agent is given a fixed state ( i.e., the current state, the action distribution and the reward function ), and a control state where the action is sampled from the control state, but the action does not have access to the state yet. This state can be used to infer both the side effects that should be avoided as well as preferences for how the environment should be organized ( e.g., how much light should be shone on objects in the environment and how much should the robot be trained to avoid the effects of noise ).   The paper evaluates the algorithm using the following scenarios : - In the first scenario, the agent receives an input from a human agent that says it wants to avoid a certain action ( “ do not observe the object ” ) and observes the actions of other humans doing the same thing. The agent enforces a human - like bias in order to prevent this from happening. The feedback from the human agent is used to update the value function of the state. The difference between the value of actions done by humans and robots is that in a human policy ( in the case when the robot is not following the human policy ) is that it is constrained to observe actions that correspond to the human preferences, whereas in a robot policy, it is free to ignore actions that are consistent with the policy. - The second scenario considers a slightly different set of states, this time the state is assumed to be the same as the first one ( but differing only in the amount of light on objects but not in the number of strokes of the camera. The robot is trained to observe the state ( using a policy gradient method similar to what is proposed in the paper ) and to avoid features that are “ not observed ” by humans ( but not necessarily the actions that humans would prefer to avoid ). This time the policy gradient is applied only to the states that the robot does not observe ( the ones that are observed but not the ones it does observe ), but not to the things that are not observed by humans. The evaluation considers only actions that occurred in the observed state ( which may or may not have been observed by the robot ) in both the control and the non - human action space. The experiments evaluate how the algorithm performs in both of these scenarios. The main finding is that the algorithm is able to infer more information about the human and robot preferences for actions that should not be done compared to actions that were not done in the assumed state ( and vice versa ) than it can do from the initial state. However, the experiments do n’t evaluate how well the algorithm learns these preferences for the assumed states, only how well it learns how to infer how to avoid side effects of actions that did not happen in the imagined state ( this is a different topic for another paper )."
SP:417a4e0acee699b3e004ad30d0ecf533a9ed987e,"The paper proposes a general modeling and inference framework that combines the complementary strengths of deep generative models and probabilistic graphical models. In particular, the latent variable space of a VAE is expressed in terms of a Bayesian network with a learned, flexible dependency structure. The network parameters, variational parameters as well as the latent topology are optimized simultaneously with a single objective. Inference is formulated via a sampling procedure that produces expectations over latent variable structures and incorporates top - down and bottom - up reasoning over latent variables. The experimental results validate the framework in extensive experiments on MNIST, Omniglot, and CIFAR - 10. Comparisons to state - of - the - art structured variational autoencoder baselines show improvements.   The main contribution of this paper is the introduction of a method for learning the dependency structure between latent variables in a deep latent variable model. The authors propose a method called Deep Bayesian Networks ( DBS ) that extends VAE. DBS is similar in structure to VAE but differs in the terms of the expressiveness of the learned model. This difference is important to ensure the learning is transferable to other models."
SP:976dedab53e69610692a563382ada1dbb82c1e9d,"This paper proposes a dynamical network for solving the $ \ell_1 $-minimizing dictionary learning problem. The authors consider the setting of learning problems where the goal is to find a set of neurons that, over time ( i.e., states in the associated state space that correspond to numerical solutions to certain mathematical optimization or learning problems. A typical approach to this problem is to use a neural network composed of neurons connected by a "" local memory "", where each neuron has access only to local information and the other neurons have access to global ( non - local ) information. This paper proposes to combine ideas from two learning methods, namely contrastive learning and top - down feedback, to learn how much gradients to use for each neuron in order to maximize the sum of local and global information across the neurons. To this end, the authors present a learning process, a learning algorithm, and its rigorous mathematical analysis, which is used to derive gradients from the network's various states. They show that the resulting dynamical networks outperform the state - based methods that are commonly used to solve the problem.   The main contributions of the paper are the following :   ( 1 ) A dynamical algorithm that can be seen as an extension of the neuron - based neural network. This allows the authors to study the evolution of the dynamical system ’s state space in terms of its limit points. This is important as it is shown that the evolution and/or limit points in the state space can correspond to solutions to some mathematical optimization problems. ( 2 ) A learning algorithm that learns how to generate gradients for the corresponding state - spaces using the learned dynamical states. This method is referred to as the “ contrastive algorithm ”. ( 3 ) The authors apply the contrastive algorithms to the case when the gradient descent method is not applicable ( e.g., when the gradients are not available for the classical gradient descent methods ), and obtain results that give the desired gradients. ( 4 ) The experiments are conducted on a toy example and compare the performance of the proposed dynamical nets with the classical ones. The experiments demonstrate that the proposed method outperforms the classical methods and the proposed contrastive methods."
SP:f45117a6beaeb86a70b1380b4fac3cfba37fb892,"This paper presents an encoder - decoder network for lane detection based on CNN. The main contributions are three - fold : ( 1 ) It leverages CNN for both high - level and low - level features representations of the road network. ( 2 ) It proposes to use multiple encoder decoders for each layer of the CNN encoder to train a different decoder module in an end - to - end fashion. ( 3 ) It compares the performance of the proposed network on lane detection tasks with two methods based on image segmentation and lane detection. The second contribution is to propose an evaluation method based on IoU to rethink the evaluation of the methods for improvement.   The main contribution of the paper is the introduction of the multi - encoder network. The network consists of three modules ( encoder-decoders module, encoder module and two reverse encoders modules ). The encoder modules are used to train the encoder and decoder modules ( module 1 and module 2 ) and the reverse module is used to generate the reverse decoder results ( module 3 ), which is used for the classification task of the detected lane in the reverse direction. The authors compare the performance on the lane detection task using the proposed method with the two encoder / reverse module methods ( CNN and reverse encoder ) in terms of detection accuracy ( pixel - level vs. visual - level ) and semantic semantic segmentation ( semantic similarity vs. semantic similarity ). For the reverse modules, the authors propose to use the same encoder but slightly different activation functions for each one. The experimental results show that the proposed model performs better than the one based on the CNN network ( CNN ) on the reversed direction. Finally, for the semantic similarity task, the method performs slightly worse than the CNN model ( on average by a margin of 0.02 % )."
SP:68b0a10ca06df74612d0753cc3f3ddddde806035,"This paper studies the problem of surrogate policy learning in contextual bandit learning, where one only has access to a collection of logged feedback from the actions taken by a historical policy, and expects to learn a policy that takes good actions in possibly unseen contexts. This setting is ubiquitous in online and interactive systems, such as ad platforms and recommendation systems.   The authors propose a new approach named Maximum Likelihood Inverse Propensity Scoring ( MLIPS ) for batch learning from logged bandit feedback. Instead of using the given historical policy as the proposal in inverse propensity weights, the authors propose to estimate a maximum likelihood surrogate policy based on the logged action - context pairs, and then use this surrogate policy as a proposal to learn the correct policy in a batch learning setting. The authors prove that MLIPS is asymptotically unbiased, and moreover, has a smaller nonasymptotic mean squared error than IPS. Results on multi - label classification problems and a large - scale ad placement dataset demonstrate the empirical effectiveness of MLIPS. Furthermore, the proposed surrogate policy technique is complementary to existing error reduction techniques, and when combined is able to consistently boost the performance of several widely used approaches."
SP:8e0ed65c5dded23b34798499b2436b24422fd729,"This paper proposes a meta - learning framework for few - shot classification tasks that uses a kernel generator as the meta - learner to learn about model optimization, parameter initialization, or similarity metric. The idea is to learn how to create an individualized feature embedding specific to a given query image for better classifying. The kernel generator is designed to generalize convolutional kernels for different query images during training, which can generalize to unseen categories without fine - tuning. The authors propose to train the kernel generator with two standard few - shots classification data sets : data sets i and ii. During training, the feature embeddings for query images are extracted from the kernel and used to individualize the feature space in which the query image can be classified more accurately. The author conducts extensive experiments to validate the effectiveness of the proposed method and achieve good results.   The main contributions of this paper are the following : 1 ) The proposed method is able to obtain good results with a small number of trained examples. 2 ) It uses the same kernel generator ( kernel - generator ) from scratch for each query image instead of using a generator - only approach used in previous methods. 3 ) The method is flexible and adaptable to many different image classification tasks, which is important for many real - world applications. 4 ) The authors conduct extensive experimentation to validate their method."
SP:faa3f7ffdcfb6e3b8ec0421193dae3d9987b015c,"This paper proposes a non - gradient - based evolutionary algorithm to train deep neural networks ( DNNs ) at the scale of deep reinforcement learning ( RL ), challenging backpropagation - based Evolution Strategies ( ES ) and challenging deep RL algorithms such as Q - learning and policy gradients based on stochastic gradient descent. The authors propose to use population - based genetic algorithm ( GA ) to update the weights of a DNN using a simple, gradient - free, finite - difference approximation of the gradient, and train the weights using a mixture of ES and GA. They compare the performance of ES, GA, DQN, A3C, and GA with ES on Atari, humanoid locomotion, and show that GA is faster and more efficient than ES, A 3C and D QN on hard RL problems. They also propose a 10,000 - fold compact encoding technique for Deep GA.    The main contributions of the paper are the following :   ( 1 ) This paper proposes to train the largest neural network ever evolved with a traditional evolutionary algorithm, Deep GA, using ES with novelty search, which encourages exploration on tasks with deceptive or sparse reward functions ; ( 2 ) it demonstrates that in some cases following the gradient is not the best choice for optimizing performance, and ( 3 ) it makes available the multitude of neuroevolution techniques that improve performance, such as novelty searching, that can help improve performance. The paper also shows that the Deep GA algorithm is capable of evolving networks with over four million free parameters, the largest   parameters of the evolutionary algorithm with traditional ES without using any of them ; ( 4 ) it is possible to train Atari on one GPU in under $ \mathcal{4}$ hours ; and ( 5 ) it enables a 10k conditional coding algorithms to be trained on Atari."
SP:dfdbe3267a8160f24746884cdf5297993e424231,"This paper proposes a curiosity method for reinforcement learning ( RL ), inspired by the curiosity module in animals, which rewards the agent when it observes something novel. The novelty bonus is computed by taking the observation from the current environment and comparing it with the observations from the previous time step in the environment. This is done based on how many environment steps it takes to reach the current observation from those in memory, which incorporates rich information about environment dynamics. The paper shows that with the proposed method, it is possible to overcome the known “couch - potato ” issues of prior work — when the agent finds a way to instantly gratify itself by exploiting actions which lead to hardly predictable consequences.   The main contributions of the paper are as follows :   ( 1 ) The paper proposes to use the novelty bonus to motivate the agent to create rewards for itself, thus making rewards dense and more suitable for learning. This leads to a paradigm shift in reinforcement learning. Prior to novelty bonus, the agent was only allowed to generate rewards based on the novelty of the observation it was trying to learn from. Now novelty bonus can be generated by combining the observation observation of the current time with observations from previous time using the observations in memory. This in turn leads to learning from the combined reward generated by the agent and the task. ( 2 ) The method is evaluated on two environments, where it is claimed that it outperforms the state - of - the - art curiosity method ICM ( Liu et al., 2021 ) on the tasks. ( 3 ) On the tasks from ICM it is shown that it is able to learn faster and more accurately compared to ICM with respect to the original curiosity method. On the task from DMLP it is observed that novelty bonus leads to faster learning in terms of accuracy."
SP:1e58a1c5344d1b5b7c8a40210a243700bd933d65,"This paper describes a method for learning transition models in uncertain domains using relational rules. The transition model consists of two components : an iterative greedy algorithm and feed - forward neural networks. The algorithm iteratively considers a state of the domain, a set of relevant objects, and a distribution over properties of just those objects in the resulting state given their properties in the previous state. The key idea of the paper is to use a relational rule that acts as a middle ground between the previous action and the action that takes place in the state after which the action was taken. The rule can be used to iteratively update the reference distribution of the relevant objects ’ properties when the action is taken. This is achieved by iteratively updating the set of references to the states in the domain that the transition model is most likely to be applied to. The references are constructed using a greedy algorithm that iterates through iterative gradients until it reaches a state that satisfies all the conditions. A set of deictic references are used to identify which objects are relevant in any given state. Feed - forward networks are then used to learn the transition distribution on the transition properties of those objects. The paper demonstrates that this approach is more versatile and more sample efficient than learning a monolithic transition model in a simulated domain in which a robot pushes stacks of objects on a cluttered table.    The main contributions of this paper are the following :   1. A paper that proposes to use relational rules to learn transition models for uncertain domains. The main idea is to first consider the state of a domain, and then apply a rule that iteratively updates a collection of objects according to the properties of the state. This iterative process is referred to as the “ reference rule ”. 2. A second paper that extends the original paper in the reference rule in the above. The difference between the two is that the reference rules for the reference set used in the first paper is not directly related to the action, but is merely used to update the distribution of properties of objects that the rule “ applies to when applying the action. ” 3. A neural network network is used to perform feed - froward neural network optimization to obtain the relevant reference distribution for the relevant action."
SP:8ce00a3fedbf54a7f2c1ff414511cbb7d59b4597,"This paper proposes instance - wise feature selection method based on actor - critic framework. The proposed method, called INVASE, consists of 3 neural networks, a selector network, a predictor network, and a baseline network. The selector network is trained using actor critic framework, and the predictor network is used to predict the best feature subset for the selector network from the instance history. The experiments show that INVASE significantly outperforms state - of - the - art feature selection methods ( SOTA ) on synthetic and real data, and is able to flexibly discover feature subsets of a different size for each instance, which is a key limitation of existing SOTA methods. The experimental results are conducted on synthetic data and real world benchmarks.   The main contributions of this paper are the following :   1. The use of actor critic as a framework to train neural networks for instance feature selection ;   2. A new selector network trained from actor critic model, 3 times faster than SOTA, and 4 times more efficient than a baseline selector network. 3. The actor critic - based predictor network and the baseline network that predict the feature subset of selector network in each instance. 4. A significantly improved performance over SOTA and a significantly more robust mechanism to the limitation of the number of subsets found in the selector networks."
SP:b91d6c33349df0bb6cb7e1c5e9433f0d4744b4da,"This paper proposes an adversarial learning method to learn patch - level alignment between source and target patches using deep neural networks without per - pixel annotations. The method is motivated by the observation that strong neural networks trained on one data domain may not generalize well to other data domains that are not annotated with model finetuning. To this end, the authors propose to learn discriminative feature representations of patches based on label histograms in the source domain, through the construction of a disentangled space of patches corresponding to the label of the corresponding source distribution. They then use adversarial training to push the feature representations in target patches to be closer to the closer distributions in source ones using the learned feature representations. The authors show that the proposed method is able to achieve state - of - the - art performance on semantic segmentation tasks with the proposed patch-level alignment process with the help of a global alignment process.   The authors also show that their method can integrate a global alignable patch distribution ( G - SPL ) into the training of neural networks and achieve better performance than the baseline convolutional neural network trained on a different source domain ( e.g., CIFAR-10 ). The experiments are conducted on several datasets with various settings, such as synthetic - synthetic-to-real and synthetic synthetic logistic regression. The main contributions of the paper are the proposed domain adaptation method and the adversarial learn scheme to learn feature representations for the source patches that are then used to learn the features for the target patches."
SP:00922af13a21464cbc4cd7b34c196dd4f86c9247,"This paper proposes two new algorithms, AMSGrad and Adam, for training deep neural nets using stochastic gradient descent. The motivation for the new algorithms is based on the observation that the mini - batches of gradients in consecutive iterations do not change drastically and consequently may be predictable, similar to the setting in online learning literature called OPTIMISTIC ONLINE LEARNING. The authors propose two new optimistic algorithms for training neural nets :   1 ) Adam - Gradient, which combines the idea of momentum method, adaptive gradient method, and algorithms in Optimal Online Learning ( OEL ) ( Liu et al., 2019 ) to train neural nets, and 2 ) ADAM, which is an extension of Adam. The main difference between Adam and ADAM is that ADAM uses the adaptive gradients, while in OEL the gradients are fixed, whereas in ADAM the gradient updates are sampled from a fixed distribution, which allows for faster training in practice.   The main contributions of this paper are the following : 1 ) The authors show that the predictability of mini - batch gradients can be leveraged to improve the performance of ADAM. 2 ) They propose a new algorithm, called Adam - Momentum, which uses the momentum method and adaptive gradient methods from OEL to predict the minibatch gradients of Adam, and is similar in principle to the approach used in Momentum - Adaptive Gradient ( MAG ). The key difference is that Adam uses momentum to predict gradients while MAG uses gradient updates to adaptively pick up gradients that are consistent with the update of the minima. The algorithm is evaluated on a synthetic dataset and compared with the one trained with Adam."
SP:52228b48f2776d57dd422edb33b82e247f056b75,"This paper proposes new robustness benchmarks for image classifier robustness. The primary focus of the paper is corruption robustness, which is used to evaluate the robustness of classifiers against adversarial perturbations. The paper proposes to standardize and expand on a dataset that is used for this purpose, called IMAGENET - C. This dataset consists of corruptions and perturbation cases that are similar to each other, except that the corruptions are generated by the same classifier ( in this case, ResNet - C ). The authors then propose to use this dataset as a benchmark for other datasets that are not corruption - robust ( e.g., Networks - A and Networks - B ). Based on this dataset, the authors develop a robustness metric for classifiers that measures the classifier ’s robustness to perturbational adversarial background noise.    The main contributions of this paper are the following :   ( 1 ) The authors develop and evaluates a corruption robust baseline that is similar to the one used in the previous paper ( Rössler et al., 2018 ). This corruption baseline is designed to be robust to common adversarial noise ( common corruptions ), not to worst - case adversarial cases. The robustness is compared between different corruption classifiers ( AlexNet and ResNet ) on this corruption baseline. The main finding is that the ResNet classifiers are more robust than AlexNet on the majority of corruption cases, while there is some evidence that AlexNet is slightly less robust than ResNet on some corruption cases. ( see Table 1 and Table 2 ) ( 2 ) Based on the obtained from the corruption baseline, this paper proposes a new dataset that combines corruptions from different adversarial defenses ( bypassed adversarial defense on some corruptions, strong corruption on others ). On the corruption benchmark, it is found that the most robust defense is the strong corruption defense, followed by the strong defense with the weaker one on the weaker corruptions ( weak corruption ). ( 3 ) On the other datasets, there are no significant differences between the corruption benchmarks for ResNet and AlexNet. Overall, the main contribution of this work is the creation of the new datasets."
SP:20358ea0f769e6ea9222d8e35159d711ee1b20b2,"The paper shows that dropout training can be understood as performing MAP estimation for a family of conditional models whose objectives are lower bounded than the usual dropout objective. This discovery allows them to pick any model from this family after training, which leads to a substantial improvement on language modelling tasks. The family includes models that compute a power mean over the sampled dropout masks, and their less stochastic subvariants with tighter and higher lower bounds than the fully stochastically dropout objectives. The deterministic subvariant ’s bound is equal to its objective, and the highest amongst these models. It also exhibits the best model fit in the experiments. Together, these results suggest that the predominant view of deterministic dropout as a good approximation to MC is misguided, and that the deterministic model provides the best approximation to the true objective."
SP:ac1b950ad29429ae045bb5e53279014a6a0b9d2b,"This paper proposes a new pruning method, called Global Soft Filter Pruning ( GSFP ), to prune redundant filters in CNNs. The method combines the global pruning ( measuring the global redundancy of the filter in the whole model ) with the soft pruning used in previous works ( e.g., Global Pruning with Soft Filter Extraction ( GPE ) ).   The authors argue that GSFP has two advantages over previous works : ( 1 ) More accurate pruning guidance since the filter's saliency is calculated based on the entire data set, and accumulating the saliency of filter over the data set can provide more accurate guidance for pruning. ( 2 ) More robust pruning strategy to achieve higher compression ratio on MNIST and CIFAR-10 compared with prior work. 	 The authors also propose a cumulative saliency strategy to improve the model recovery process after pruning, which is used as a final step in model recovery. Theoretical analysis is presented and experiments are conducted to validate the effectiveness of GSFP on many classic CNN architectures and different data sets. The main concerns are summarized below."
SP:621e41d4199e333ec7f9d0936d4e34c918f39c11,"This paper proposes a cross - lingual document classification framework ( CACO ) between related language pairs to exploit sub - word similarities. The authors propose a character - based embedder and a word - based classifier to jointly train a character model for source language words and target language words with similar forms. The embedder derives vector representations for input words from their written forms, and the classifier makes predictions based on the word vectors. They use a joint character representation for both the source language and the target language, which allows the embedder to generalize knowledge about source language word to target language word. They also propose a multi - task objective ( MOU ) to further improve the model if additional cross -lingual or monolingual resources are available.   The authors trained two models, the Source Language Embedding ( SDE ) model and the Language Representation ( LRA ) model, in parallel with each other using supervised learning, on source and target text documents. The source language models were used to derive the embedding for the LRA. The LRA model was used to generate the predictions for the word classifier, which is used in the MOU to predict the class for the source word. During the validation phase, the authors also train a second model, the Cross - Lingual Classifier ( C4PM ), to generate predictions for target and source word classifiers. The latter is used during the fine - tuning phase to ensure that the predictions are similar to the predictions from the first model. The MOU is used to train a classifier that predicts the class from the predictions of the embeddings of the first and second model. They evaluate the effectiveness of their methods during validation phase and fine - tune the parameters of both models. They do not provide any additional training data during the evaluation phase and only use the generated predictions as guidance."
SP:544e421f9c747640d949f433e3091763508b7237,"This paper proposes a new marginalized average attentional network ( MAAN ) to suppress dominant response of the most salient regions in weakly - supervised temporal action. The MAAN employs a novel marginalized average aggregation ( MAA ) module that learns a set of latent discriminative probabilities in an end - to - end fashion to construct a marginalised average distribution over subsets of features from the video clips. The MAA module is trained to parametrize $ \mathcal{L}$ $ features $ p(s, a)$ using a learned latent distribution over features and $ \nabla_p(s,a)$.   The experiments are conducted on two large - scale video datasets ( O(2 ) $ and O(T )$, where $ O(L)$ is the average of the features of all the subsets sampled from MAA and $ T(A|s, b ) is the expectation over all the averaged subset features of MAA. The experiments show that MAA with learned $ \theta$ latent distributions reduces the difference in responses between most salient region and the others.    Next, the authors propose a fast algorithm to reduce the complexity of constructing MAA by sampling MAA from the constructed latent distribution. The proposed algorithm, called MAA - SGD, is designed to be able to generate better class activation sequences and identify dense and integral regions for each of the action regions in the videos. It is motivated by the fact that the dense regions tend to be overestimated in the majority of cases, while the integral regions are underrepresented in most salient cases due to the underestimates of the response expected from the dominant response."
SP:9f98c9bac99003741dd14e093b54d692c0b0e8d8,"This paper introduces language models with representations informed by the framework of Holographic Reduced Representation ( HRR ). The vast majority of neural models in the field of natural language processing ( NLP ) adopt a form of structureless distributed representations, which are powerful at making predictions but representational form is rather crude and does not provide insights into linguistic structures. This paper introduces novel language models and replaces the representation in the NLP with one informed by HRR. This allows us to inject structures directly into the word - level and chunk - level representations of these models. The analyses show that by using HRR as a structured compositional representation, our models are able to discover crude linguistic roles, which roughly resembles a classic division between syntax and semantics. The experiments are conducted to investigate the effect of introducing structures into the language models.    The main contributions of this paper are as follows : 1 ) The authors introduce language models ( PEARL - D2 ) and a representation framework ( HRL - R ). 2 ) They use the HRR to augment the language model with structures from the representation of HRL. 3 ) They conduct extensive experiments to validate the performance of their models and compare their performance to other state - of - the - art NLP models."
SP:5908b6acfed0e7c51e203c72eba907e6635e6c60,"This paper proposes a new method to reduce the uncertainty in state - action dynamics in POMDPs. The motivation is that in many real - world scenarios, the agent has an active role in its perception of the environment ( i.e., it can be computationally intractable to integrate the perception decision with the planning decision ). To prevent such expansion of the action space, the authors propose a greedy strategy for observation selection that aims to minimize the uncertainty. The main contribution is a novel point - based value iteration algorithm that incorporates the greedy strategy to achieve near - optimal uncertainty reduction for sampled belief points. This in turn enables the solver to efficiently approximate the approximately approximate the reachable belief of belief.   The experiments are conducted to evaluate the proposed method and demonstrate its performance and computational advantage in a range of robotic scenarios where the robot simultaneously performs active perception and planning."
SP:0adec4abec17b3aab0c6eb69d11925dc20544950,"This paper proposes a novel algorithm for training deep neural networks, based on curriculum learning, to counter internal covariate shift in the training of the network. The distribution changes in weight of top layers can affect training of preceding layers in the network during the backward pass. This phenomenon is termed as the inverse of the "" covariate - shift in forward pass "" and is motivated by the fact that the weight of the top layers tends to increase in the forward pass, whereas the distribution of the weights of the layers at the back pass tends to decrease, whereas prior layers tend to stay close to the mean. The paper proposes to train the network using a combination of two methods : ( a ) adaptive weight that encourages the top layer to learn a better representation from its superior neighbours, and ( b ) an additional representation loss for low - weighted samples that encourages them to also learn a good representation from their neighbours. The adaptive weight assigns small values to hard examples, reducing the influence of noisy gradients, while the less - weighted hard samples receives the representation loss from the proposed representation loss. The proposed loss is easy to combine with existing stochastic algorithms like SGD and Experimental result shows an consistent improvement over several benchmark datasets. However, the method is not perfect and needs random sampling between tasks for better training.    The main contributions of this paper are the following : 1 ) The authors introduce a novel curriculum loss that consists of two parts : a ) adaptation weight that mitigates large shifting and large early punishment ; b ) representation loss that encourages low - weighting of the hard samples to get training signals from the same representation as the high - weight top layer. This way of training the network's representations is similar to the way of learning representations from the prior layers and hence leads to better performance. The main difference between the two methods is the adaptive weighting and representation loss in the adaptation weighting. 2 ) The method is evaluated on two datasets ( CIFAR10 and MNIST ) and compared with SGD. The results show that the proposed method leads to a consistent performance gain over the SGD method. Although the method does not perform as well as SGD, the performance gain is comparable to that of the method. 3 ) The methods are used to train top layers on “ good ” samples to reduce large shifting, and encourage “bad ”"
SP:8b555b9f24044bc68c204169d6a37e262361d706,"The paper presents a heuristic approach for learning heuristics for combinatorial optimization problems based on attention layers with benefits over the Pointer Network ( PN ). The authors propose a deterministic greedy rollout model based on Reinforce ( REINFORCE ), a reinforcement learning approach that trains a neural network with attention layers on top of PN and a value function on each of the PN nodes. They show how to train the network using a simple deterministic rollout method, where each node in the network is assigned a value value using the deterministic policy gradient. The network is trained to predict the value function of each PN node using the policy gradient, and then used this value function to update the nodes of the network as they move through the layers.    The authors then show how the TSP heuristic ( Travelling Salesman Problem heuristic ) can be used to train models for TSP, VVPP, OPP and ODE. They train the model using the same hyperparameters as in TSP and obtain similar results. However, they use a slightly modified version of the approach from TSP ( instead of the greedy rollout method they originally used for OPE, they train a model with deterministic gradient descent. They also use a different hyperparameter for the attention layer and show that this leads to better results than the original TSP model. They test their heuristic on VDPP and OPE and show they can get close to optimal results for problems up to 100 nodes ( with the same number of nodes )."
SP:efb76bcf1dbd9a9cf6b5db74b5d4256a9f9e9e73,This paper proposes a differentiable neural architecture search ( DNAS ) framework to efficiently explore its exponential search space with gradient - based optimization. DNAS quantizes different layers of neural networks quantized with different bit - widths as opposed to quantizing all weights and activations with the same precision. The authors formulate DNAS as an architecture search problem and propose a novel differentiable architecture search algorithm to solve this problem. The optimization algorithm is based on gradient descent. Experiments show that DNAS outperforms the state - of - the - art compression of ResNet on CIFAR-10 and ImageNet using full - precision quantization.
SP:ea4173f8265bc50296de51c4ee7ecb6b8f78bec0,"This paper proposes Posterior Attention Models ( PAM ), a new attention architecture that combines the joint distribution of the attention and output variables of the neural network with a PAM framework. The authors claim that the prevalent attention architectures do not adequately model the dependence among the attention, output and tokens across a predicted sequence. They propose to use a posterior attention distribution conditioned on the output variables in order to achieve better BLEU score and alignment accuracy than existing attention models. PAM outperforms the attention models on five translation tasks and two morphological inflection tasks.    The main contributions of the paper are the following :   1. A new attention distribution p(x, z ) is proposed, where attention is first marginalized from the input to the output and then propagated to the next decoding stage as a posterior distribution of attention to be used in the next stage of the PAM network. This distribution is the same as the one used in PAM ( e.g., PAM-1 ). 2. A principled factorization is proposed to ensure that the posterior distribution is independent of the inputs and outputs. 3. Two new tasks are defined, one is a cross entropy task where the output is predicted from the cross entropy loss of the input and the other is a bi - level task with the output being the average of the outputs of the previous two stages. The experiments show that the proposed PAM model performs better on both cross entropy tasks than the attention model with respect to the input, and the two new tasks have better performance than PAM - 1."
SP:987e2c14abc091d4d3ef9b48fb2046408eb1f59e,"This paper proposes a bi - directional method called HarmonicGAN to learn bi - directional translations between the source and the target domains using GANs. The main idea of the method is to introduce a smoothness term over the sample graph to attain harmonic functions to enforce consistent mappings during the translation process. The paper also proposes similarity - consistency rules to ensure that the self - consistent properties of samples can be maintained. The method is evaluated on a number of image - to - image tasks including medical imaging, object transfiguration, and semantic labeling tasks. It shows that it outperforms the competing methods in all tasks, and for a medical imaging task in particular our method turns CycleGAN from a failure to a success ( with a small training - time cost ) to generate images that radiologists prefer over competing methods ( i.e., images that the radiologist prefers over the labeled images from the source domain ). The distance metrics defined on two types of features including histogram and CNN are exploited to demonstrate that the method demonstrates significant qualitative and quantitative improvement over the state of the art methods. The experimental results in this paper are presented.    The main contributions of the paper are the following : 1. The introduction of a bi directional method based on a graph smoothing term to enforce a consistent mapping during translation of source and target domain. 2. The use of similarity - Consistency bounds on samples to enforce self - consistency. 3. A similarity - based loss function to enforce similarity between the samples and the source domains. 4. A self - directional loss function that ensures that the distance between two samples of the same dimension ( e.g, i.g., $ \epsilon$ ) is not too large in order of samples ( $ \gamma$ )."
SP:885a69003bad0e79cb2872a4e5c772191ad7e34f,"This paper proposes an algorithm, called h - detach, to suppress gradients that flow through the linear path in the LSTM computational graph when the weight of the weights of the gradients in LSTMs are large. This is motivated by the idea that suppressing gradients flowing through this path conveys information about long - term dependencies of the gradient components. The main idea of h -detach is to use a stochastic gradient - based approach to approximate the gradient of the last layer of the computational graph with respect to the input vector $ l$, which is sampled from a vector of size $ l$. The authors show that the gradient component of the final gradient flow through this linear path is suppressed, and that this suppression is due to the presence of noise. They then propose to use this suppression mechanism to improve the convergence rate of the resulting gradient w.r.t. the stationary point of the linear gradients. The authors argue that this is because the suppressed gradients are the ones that are most likely to capture information about the long term dependencies that the stationary gradients of the vector of reference have.   The main contributions of this paper are the following : ( 1 ) The authors propose to modify the way in which the weight vector of the first stage of the L STM is calculated, so that it is less likely to be drawn from the stationary points of the input vectors, and ( 2 ) They show that this modification leads to a significant speedup in terms of time, up to a constant factor in the number of steps, and a reduction in the error of the step in the gradient rate for the second stage. The experiments are conducted on CIFAR-10 and ImageNet, and compare with prior work. They compare favorably to prior work, especially when the modifications are applied to the L1 - L2 - L3 - L4 - L5 gradient paths. They also compare with previous work when the authors modified the way of obtaining the gradient paths of the corresponding vector of support vectors ( L1, L2, L3, L5 - L6 - L7 ). They find that the obtained convergence rates are faster than when these gradient paths are used in the baselines. However, they do not improve as much when the weights are very large ( L6, L7, L9, L10 ), and the authors note that the average speedup is slower ( for L1 and L6 ), even though it is still faster than the previous method ( L2 ). Finally, the authors also find out that the cost of running the experiments is comparable or slightly lower for vanilla L1 M and L2 gradients when the gradient path is not fully suppressed ( L"
SP:9aaff3777321347d1194884af5690b0b5185eff9,"This paper proposes a method for training real policy neural networks from scratch using binary weight neural networks without layer - wise scaling factors. The policy network is trained using a reinforcement learning approach where the policy parameters are learned via a policy gradient method. The method is named SnapQuant, and the posterior distribution of the generated binary weights is estimated using a Bayesian deep learning approach. The paper presents experiments comparing the performance of SnapQuant with several visual recognition tasks including ImageNet.    The main contributions of this paper are the following :   1 ) The paper proposes to train a policy network with scratch - under - the - fly distribution of binary weights. This is different from previous work in that the policy network does not need to know the values of all the parameters of the input binary weights, only the value of the highest value pair ( the policy policy weights ), and this is done using a gradient - based approach similar to that of [ 1 ]. The key difference is that, instead of using a value function for the policy weights, they use a probability distribution weighted by the policy distribution parameters. This probability distribution has the form $ \theta_p(t\theta_{\text{policy}^T}$ where $ p(t)$ is the policy's value, $ t_t$ is its dimensionality, and $ \eta$ is a weighted sum of its parameters over the input variables. The probability distribution can be thought of as the policy gradient's weight matrix. The idea is to use this policy network to estimate the probability of the weight matrix's dimensionality over the output variables ( $ t_{t}$ ) at each time step of the policy updates. The posterior distribution can then be estimated from the next time step using the policy update distribution using the new policy update parameters. ( Note that this posterior distribution is the same as the one used during the training phase. )   2 ) Using this modified policy network for training, the paper shows that it is possible to generate binary weight instances for a given recognition architecture from the learnt policy network using ImageNet, where each instance represents a layer of the given recognition layer. In particular, for every instance sample generated from the learned policy network, there is one additional layer of ImageNet layer. The obtained from ImageNet layers can be used to generate a new set of instances representing the parameters from the corresponding layer. These additional layers are used to sample the output of the corresponding neural network ( layer ) corresponding to that instance ( layer"
SP:29d1f6d0661a51e56c59bbb106da56700fc22d9a,"This paper proposes Bayesian nonparametric framework for federated learning with neural networks. Federated learning involves training neural networks on data at different servers without data exchange or data pooling, which is often impractical or prohibited. In this paper, the authors propose to model the local neural network weights of the data at each server using a Bayesian framework, where each data server is assumed to train local network weights, which are then used to synthesize a global network weight via an inference method. This approach is referred to as the Bayesian Neural Network Estimation ( BNE ) in the paper. The main contributions of this paper are the following :    1. A Bayesian Framework for Federated Learning with Neural Networks.   2. An Inference Approach to Model the Local Neural Network Weight via Bayesian Estimation. The approach is applied to two popular image classification datasets ( CIFAR-10 and Tiny ImageNet ), where the authors train local neural networks ( based on the BNE framework ) on each server, and then use an inference approach to learn a global neural network weight using an ensemble of weights from each server weights. This allows for learning with a more expressive global network without additional supervision. 3. Empirically, the approach is shown to outperform a local BNE - based approach on MNIST and Fashion - MNIST, and is sometimes competitive with the global BNE approach on ImageNet."
SP:ab1f2bd216635d63450688866c729a501bd7e9d0,"This paper studies the problem of supporting theoretical guarantees for RL algorithms for differentiable multi - agent games where the agents play multiple objectives that are inter - dependent, inter - player, and intra - agent. It starts with a review of Opponent - learning awareness ( LOLA ), a recent RL algorithm that exploits the notion of opponent - learning to improve learning dynamics in games with multiple objectives accounting for player influence on others ’ updates. The authors show that LOLA agents can exhibit ‘arrogant ’ behaviour directly at odds with convergence if they do not provide the required guarantees. In fact, remarkably few algorithms have theoretical guarantees applying across all multi - player ( n - player ), non - convex ( non - concvex ) games. This paper proposes SOS, a new method that supports the theoretical guarantees between LOLA and a stable variant named LookAhead ( SOS ). Theoretically, the authors prove that SOS is provably easier to incorporate into LOLA than matching or outperforming LOLA. They also show that the performance of LOLA improves when the learning trajectories of the agents are similar to those of SOS and vice versa.    The main contributions of this paper are the following : ( 1 ) The authors develop and validate a theoretical guarantee for the existence of the principle principle of anti - opponent learning, i.e., that opponents can be prevented from learning the same strategy as the learner from learning only their own trajectories ; ( 2 ) They study the effect of the presence of opponent noise ( noise in LOLA vs SOS vs. opponent noise in different games with different objectives ; ( 3 ) They show that in some games, LOLA outperforms SOS by a large margin but SOS outperforms LOLA by a smaller margin in other games when opponents are noisy or the noise levels are low."
SP:bdafb5fca09a775a8c92d2826d5dc977d28091c2,"This paper presents an algorithm that uses a Variational Auto - Encoder ( VAE ) designed for segmentation tasks to predict the quality of the segmentation result from the value of loss function using the feature space of the task. The main idea of the algorithm is to project the full segmentation results of a set of tasks into a low dimensional feature space, and then to learn classifiers / regressors in the space that can predict the qualities of the segmentsation result. The algorithm is trained using VAE with only the ground truth masks, therefore the bad features become the rare events when tested with the VAE. The paper evaluates the proposed algorithm on several recent segmentation algorithms for the medical segmentation task and finds that the proposed method is able to set off alarms when the segmentations result are unsatisfactory. Ablation studies are performed to evaluate the effectiveness of the method.    The main contributions of the paper are the following :   1 ) The algorithm uses a VAE that can detect all kinds of shapes that are out of the distribution of normal shapes in ground truth ( GAT ) during testing. This is done using the average value of the loss function of each task. 2 ) It learns a feature space using shape feature that is a strong prior information shared among different data, so it is capable to predict good and bad features. 3 ) It uses the same shape feature to learn the representation in the one - dimension feature space to capture the features that are important for the prediction of the classifier / regressor. 4 ) It evaluates the method on different datasets and finds out that the method provides reliable predictions."
SP:60738395d9efe2b3fe3a00c542ebb4261e54386c,"Deep neural networks ( DNNs ) have become effective tools for compressing images and solving inverse problems including denoising, inpainting, and reconstruction from few and noisy measurements. This success can be attributed in part to their ability to represent and generate natural images well. In this paper, the authors propose an untrained simple image model, called the deep decoder, which is a deep neural network that can Generate natural images from very few weight parameters. The proposed model has a simple architecture with no convolutions and fewer weight parameters than the output dimensionality of the model. This underparameterization enables the deep network to compress images into a concise set of network weights, which they show is on par with a linear combination of channel - wise linear combinations of channels, ReLU activation, and channelwise normalization.   The main contributions of the paper are the following :   1. The authors propose a simple image compression method, called deep decoders, which consists of only one upsampling unit, only one parametrization of the network weights. 2. They study the effect of training a DNN with the proposed method on the performance of a set of image compressing tools, called state - of - the - art performance - based denoisers. 3. They show that the proposed approach outperforms competing methods for image compression and inverse problem solving such as Inverse SVM ( Wang et al., 2020 ) and Inverse CV ( Liu et. al. 2021 )."
SP:1c9bad3bd4d670172f65aa0304e9837ecafc6b3d,"This paper proposes an end - to - end neural network for synthesis from natural language ( NL ) specifications to snippets of executable code. The proposed method, called SAPS, is trained on abstract syntax trees, trained with a pretrained word embedding and a bi - directional multi - layer LSTM for processing of word sequences. The decoder features doubly - recurrent LSTMs, for which the authors propose novel signal propagation schemes and soft attention mechanism. The authors also propose a novel soft - attention mechanism to encourage the decoder to focus only on sequences that are close to the target distribution. They evaluate SAPS on a large dataset of problems proposed in a previous work ( Wang et al., 2018 ), and show that SAPS performs on par or better than the method proposed there, producing correct programs in over 92% of cases. In contrast to other methods, it does not require post - processing of the resulting programs, and uses a fixed -dimensional latent representation as the only interface between the NL analyzer and the source code generator generator.    The main contributions of this paper are the following :   1 ) A novel neural network capable of mapping relatively complex, multi -sentence NL specifications to executable code snippets. This is different from previous methods, such as Synthesis from Natural Language Synthesis ( SNA ), which relies exclusively on neural components. 2 ) A syntactic embedding that allows for embedding word sequences into sentences with the same number of bases as the source codes. This embedding allows for word sequences to be processed by the same neural network without the need for soft attention. 3 ) A signal propagation scheme that encourages the network to only process sequences with soft attention to propagate the signals to the same set of bases."
SP:d2ec231bb6153a303e5110e671dea14c2721e636,"This paper studies the robustness of deep neural networks against adversarial perturbations in terms of L0 robustness ( L_{0 } robustness ), L_{2 robustness } and L_{\theta robustness   against L$(L2 ) perturbation using a new adversarial attack that exploits the structure of the defended model. This is done by devising a novel decision - based attack that seeks to minimize the number of perturbed pixels ( L0 ). The authors evaluate their model using maximally effective adversarial attacks by ( a ) applying decision - making, gradient - based, score - based and transfer - based attacks for several different Lp norms, ( b ) designing a new attack that maximizes the size of the perturbed examples and ( c ) matching the loss function of the original model to the one generated by the new attack. The results suggest that our approach yields state - of - the - art robustness on MNIST against L0, L2 and L{L}(L_{2 } robust examples ) and that most adversarial examples are perturbed towards the perceptual boundary between the original and the adversarial class. They also show that the L0 - robust version of their model performs not much better than simple input binarization against the L2 - robust set. The most successful and by far most successful L∞ robust defense by Madry et al. ( MADE ) has lower L 0 robustness than undefended networks and is still highly susceptible to L2 perturbational noise. The main contribution of this work is to develop and evaluate a robustness framework for neural networks for L0 that makes sense to humans.    The main contributions of the paper are as follows. First, the authors develop and evaluates a novel adversarial defense model that can defend neural networks with high robustness against the most commonly used adversarial defenses such as the Madry Defense. The robustness results are evaluated on the popular toy dataset of MNIST and compared to the widely recognized and most successful MADE model and show that MADE is far less robust than the first most successful defense and the second most robust model and that is still susceptible to the most common adversarial noise. Second, they demonstrate that the neural network model they develop is robust to L$ \epsilon$ ( L_0 $ robustness that no one else in the literature can match, and that L$$ robustness is much lower than the second and third most robust. Third and fourth, they evaluate the model using the new $ \epsigma$ loss function developed by MADE and find that the"
SP:91a24e7f4b952c37441feab4a7e8555014c856a4,"This paper proposes a framework for training generative adversarial networks ( GANs ) based on reparameterization of discriminator weight matrices. The motivation for this is that previous work shows that controlling the spectra of the weight matrixes in discriminator can improve training the discriminator. Motivated by this observation, the authors propose to reparametrize the discriminators ’ spectra using various regularizers and constraints, without computing singular value decompositions. They show that the proposed framework allows for more flexible spectrum control, which improves the generalization ability of the GAN. The authors conduct experiments on CIFAR-10 - 10, STL-10, and ImgaeNet datasets to validate the effectiveness of their proposed method. The experiments show that compared to other methods, the proposed method is capable of generating more competitive images with competitive quality by utilizing spectral normalization and encouraging the slow singular value decay.    The main contributions of this paper are the following :   1 ) The authors propose a framework to train discriminator weights matrices in a generative adversarial network based on parametrization of discriminators. This is motivated by previous works that control the specta of weight matrice in discriminators to improve training. The spectra manipulation can be controlled using regularizers such as soft clamping and soft normalization. 2 ) The method is tested on a set of datasets, where it compares favourably to the other methods. The results demonstrate that the method is more stable and robust to perturbations in terms of generating image quality than other methods and that the training is more efficient."
SP:8115fd9b681198d62100c36794926fb57dc0a4f5,"This paper proposes an accelerated value iteration method for reinforcement learning based on the Anderson Accelerated Value Iteration ( A2VI ) technique. The main contribution of this paper is to combine the Anderson acceleration technique into the value iteration by introducing a value iteration algorithm that is more efficient than the modified policy iteration, which is a classical approximate method for policy evaluation in toy problems and Atari games. The authors also apply their method to the Deep Q - learning algorithm to improve the performance of the DA2Q algorithm. They give theoretical analysis of their algorithm and conduct experiments on both toy problem and Atari game settings to evaluate the effectiveness of the algorithm.   The main contributions of the paper are as follows :   1 ) The authors introduce the Anderson accelerated technique for value iteration and apply it to value iteration, developing a new algorithm that outperforms the previous state - of - the - art DQN algorithm. 2 ) They show that applying their algorithm to the policy evaluation by interpolating on historical data gives rise to the new policy evaluation method, A 2VI. 3 ) In experiments, the authors show that A2V is significantly more efficient in terms of policy performance than the previous method, PEARL."
SP:bd79b0c0af778a36008a0c0cf2fb6393fd2789d4,"This paper proposes SupportNet, a method to solve the catastrophic forgetting problem in class incremental learning. The proposed method combines the strength of deep learning and support vector machine ( SVM ), where SVM is used to identify the support data from the old data and fed to the deep learning model together with the new data for further training. Two powerful consolidation regularizers are applied to stabilize the learned representation and ensure the robustness of the learned model. The authors validate their method with comprehensive experiments on various tasks, which show that SupportNet significantly outperforms the state - of - the - art incremental learning methods and even reaches similar performance as the deep - learning model trained from scratch on the old and new data."
SP:d228d213f79716774043cea253305fecece659ec,"This paper studies the selectivity of representations learned in recurrent neural networks ( RNNs ) by means of various unit selectivity measures : Bowers et al. ( 2014 ) precision, class - conditional mean activity selectivity CCMAS, and a new measure called top - class selectivity ( MMM ). The focus of the paper is on learning representations in neural networks based on AlexNet, a generative model based on recurrent convolutional neural networks. The authors compare these measures to previous ones as well as the recently proposed MMM, and find that the precision and CCMAS measures provide a much higher level of selectivity than is warranted, with the most selective hidden units only responding strongly to a small minority of images from within a category. Furthermore, the authors find that interpretable images in the hidden layers were not associated with highly selective units, as expected. These findings highlight the problem with current selectivity methods and show that new measures are required in order to provide a better assessment of learned representations in NNs. The manuscript also considers why localist representations are learned in RNN and not AlexNet."
SP:b9deae0392e0160b400d76c549d382e235196f8c,"This paper proposes Graph Neural Networks ( GNNs ) for solving community detection problems in a supervised learning setting. It builds on the recent belief propagation algorithm for solving binary and multiclass stochastic block models, which is believed to reach the computational threshold in these cases. The authors show that, in a data - driven manner and without access to the underlying generative models, they can match or even surpass the performance of the belief propagation algorithms on binary and multimorphic stochastically block models. In particular, they show that under certain simplifications and assumptions, the loss value at any local minimum is close to the loss valued at the global minimum /minima. They also show that the GNN can achieve good performance on the real - world datasets.   The main contributions of this paper are the following :   1 ) The authors develop a novel family of Graph neural networks, called The GNN family, which can be used to solve graphs with node - wise classification problems ( node detection ). This is in contrast to the previous approaches to community detection, which focused on random graph families such as the stoChastic block model, and identified both statistical and computational detection thresholds in terms of the signal - to - noise ratio. 2 ) By recasting community detection as a node wise classification problem on graphs, the authors can study it from a learning perspective and obtain good performance under certain assumptions. 3 ) They provide the first analysis of the optimization landscape of using ( linear ) GNNS to solve community detection."
SP:a9ed31090e55f6152fc31c7512af5d634cc7225a,"This paper proposes a new dictionary learning algorithm, called NoODL, for the linear combination of a few columns of a matrix known as a dictionary learning, and the sparse weights formed by the dictionary. In this setting, the authors consider a setting where the linear model is based on a few column dictionary and the coefficients of the dictionary are known as the "" coefficients of recovery "". Since the dictionary and coefficients are not parametrized, parameterizing the model is non - convex and the corresponding optimization is inherently non - concave. This was a major challenge until recently, when provable dictionary learning algorithms for learning were proposed, which provide guarantees only on the recovered dictionary, but do not explicitly guarantee recovery of the coefficients. This paper aims to bridge the gap between the dictionary learning problem and the coefficient recovery problem by proposing a method that explicitly guarantees recovery of both dictionary and coefficient recovery. To this end, the paper proposes to use a simple Neurally plausible Optimization - based Online Dictionary Learning ( OODL ) algorithm, which recovers the dictionary but not the coefficients, to localize and estimate the coefficient of recovery. The main contributions of the paper are the following :   1. The authors develop a simple neural network based on the Gaussian Mixture Model ( GMM ), which is robust to dictionary error and coefficient estimation error. 2. They ensure that the dictionary recovery guarantees are explicit and enforceable, and provide explicit recovery guarantees on the coefficients recovery. 3. They provide experimental evaluation of the proposed algorithm with state - of - the art dictionary learning methods, which compare the performance of their algorithm with the current state-of - the - art method. 4. They empirically verify that their algorithm is more robust than the previous dictionary learning method, and show that their method is better than the baseline.    The main contribution of this paper is the introduction of a new algorithm that guarantees explicit recovery of dictionary recovery and recovery of coefficients recovery with explicit parametric guarantees."
SP:85232b72a2643d6dc81cf952ccbb95192032b7c5,"This paper proposes a new loss function and training scheme for learning binary hash codes with any differentiable model and similarity function. The proposed loss function improves over prior methods by using log likelihood loss on top of an accurate approximation for the probability that two inputs fall within a Hamming distance target. The training scheme obtains a good estimate of the true gradient by better sampling inputs and evaluating loss terms between all pairs of inputs in each minibatch. To fully leverage the resulting hashes, the authors use multi - indexing. The authors provide the best results to date on competitive information retrieval tasks for ImageNet and SIFT 1M, improving MAP from 73 % to 85 % and reducing query cost by a factor of 2 - 8."
SP:3bd4ccff7f48380d2db8dff2c4ca515894a7f1db,"This paper proposes Graph HyperNetwork ( GHN ), a novel method to perform task - specific neural network topology search using graph neural networks. The main idea of GHN is that given an architecture, it directly generates the weights by running inference on a graph neural network ( GNN ) that helps to model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, they randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast – they can search nearly 10x faster than other random search methods on CIFAR-10 and ImageNet. GHN can be further extended to the anytime setting, where they have found networks with better speed-accuracy tradeoff than the state - of - the - art manual designs."
SP:65ccf43cd4e033d22239069057f5200d49f33724,"This paper proposes a method to improve generative adversarial imitation learning ( GAIL ) using information from non - expert demonstrations. The idea is to perform a multiclass classification to learn discriminator functions where non - experts demonstrations are regarded as being drawn from an extra class. The proposed method, called IAM - DAG, is trained with a discriminator whose parameters are drawn from the same class as the discriminator in the case of the expert policy. The discriminator function is learned by iteratively applying the proposed discriminator to all samples in the dataset. Different from the GAIL baseline, which uses the policy obtained from the expert when the total number of expert demonstrations is small, IAM-DAG learns the policy from a larger set of demonstrations when the number of demonstrations is large enough. The authors perform experiments in continuous control tasks to demonstrate that the proposed method learns better policies than GAIL and other GAIL baselines when using additional information from demonstrations that are easier to obtain.   The main contributions of the paper are as follows :   ( 1 ) A new discriminator network is proposed that learns discriminators from expert demonstrations to learn policies. This network has the property to discriminate between any two samples in a dataset. This distinguishes it from other discriminator networks that only consider one class of samples ( e.g., GAIL, which only considers samples from all demonstrations ). ( 2 ) An algorithm is developed to classify demonstrations according to the class of discriminator that is used to learn the policy. This classifier is trained using a mixture of supervised and unsupervised learning. ( 3 ) The method is tested on CIFAR-10 and ImageNet, where it outperforms GAIL by a large margin."
SP:e8427949a98effbd37ce7604fa11f240e2342196,"This paper proposes a new type of neural network, called Invertible Neural Networks ( INNs ), for the inverse problem of hidden system parameter estimation. In INNs, the forward process from parametrized measurement space is learned implicitly, while the corresponding inverse process is learned explicitly using latent output variables to capture information otherwise lost in forward process. The authors argue that INNs are a powerful analysis tool to find multi - modalities in parameter space, uncover parameter correlations, and identify unrecoverable parameters. They compare INNs with classical neural networks, which attempt to solve inverse problem directly, and Inverts, which use the learned forward process but does not learn the inverse process. In the experiments, the authors prove theoretically and verify experimentally on artificial data and real - world problems from medicine and astrophysics, that InNs are effective and efficient at solving inverse problem."
SP:75c9bb53bac29bdb390f9ba5707caee4ab1f5925,"Deep neural networks ( DNNs ) have been a hugely successful research topic recently. However, finding good quantifiable measures to quantify uncertainty in DNN models is still an open problem. This paper proposes Compound Density Networks ( CDNs ), an extension of the ensemble method for deep NNs that was recently studied in Bayesian NNs. The main difference between CDNs and other methods for quantifying uncertainty in NNs is that CDNs have uniform mixing weights, while Bayesian methods trained with a scoring rule do not. In this paper, the mixing weights of CDNs are modelled using an ensemble of NNs trained with the scoring rule. This ensemble method can be understood as a finite mixture model with uniform mixes weights. To make the model more flexible, the authors propose to use an adaptive, input - dependent distribution to parametrize the probability of each component represented by an NN, and by considering uncountably many mixture components. The resulting model can be seen as the continuous counterpart to mixture density networks and is therefore referred to as compound density networks ( DPNs ). The authors empirically show that the proposed model results in better uncertainty estimates and is more robust to adversarial examples than previous approaches."
SP:e1e38289285c1b8fdb318e4f6d37a198a08787a2,"This paper studies the problem of model compression in deep neural network architectures with a fixed memory budget. The authors propose a method that relaxes weight determinism by using a full variational distribution over the weights, which allows for more efficient coding schemes and consequently higher compression rates. In particular, following the classical bits - back argument, they encode the network weights using a random sample, requiring only a number of bits corresponding to the KullbackLeibler divergence between the sampled generative distribution and the encoding distribution. They show that this method sets new state - of - the - art compression rates in neural network compression, as it strictly dominates previous approaches in a setting where the weights are deterministic. They also show that their method achieves the highest compression rates for a fixed test performance on LeNet-5/MNIST and VGG-16/CIFAR-10 on the benchmarks LeNet -5 /MNIST.    The main contributions of this paper are the following :   1 ) The authors relax the weight - determinism constraint on the empirical weight distribution of the neural network weights, in order to allow Shannon - style coding schemes to be used. This leads to more efficient compression schemes. 2 ) The employed encoding scheme can be shown to be close to the optimal information - theoretical lower bound, where only a small fraction of bits need be used to encode the weights. 3 ) The method is evaluated on a set of networks trained with MNIST, VGG - 16 and CIFAR - 10 on a fixed - memory budget, and vice versa, where it yields the best test performance for those networks on the MNIST dataset. 4 ) On LeNet5 / MNIST the method is shown to have the highest rate of compression for trained models with fixed memory. On the other hand, on the CIFar-10 network the method has the highest rates of compression. 5 ) When applied to trained networks on MNIST data, the method shows the expected loss is lower than when applied to the training data."
SP:ad70d8cf3a4558aab0d3b7155594464a3debd912,"This paper presents ProxylessNAS, an architecture search algorithm that directly learns the architectures for large - scale target tasks and hardware with direct hardware metrics ( e.g. hardware latency ) instead of with pretrained models. The main contributions of the paper are as follows :   1 ) It proposes a method that addresses the high memory consumption issue of differentiable NAS by directly learning the architecture for the target task with the same computational cost ( GPU hours and GPU memory ) of regular training while still allowing a large candidate set.    2 ) It also applies proxylessNAS to specialize neural architectures for hardware with hardware metrics such as latency and provides insights for efficient CNN architecture design. Benefiting from this directness and specialization, Proxyless NAS achieves better results than previous proxy - based approaches, with 200 fewer MNASNet hours ( 200 × fewer MNet, with 1.4x fewer parameters ), while achieving the same accuracy level of MobileNetV2 while being 1.8x faster. 3 ) The authors also remove the restriction of repeating repeating blocks in previous works ( Zoph et al. 2018 ) and allow all of the blocks to be specified and learned in the same way, so that all the parameters of the learned models can be of the same size and all predictions can be made from the same set of connections. 	   The paper also presents empirical results on CIFAR-10 and ImageNet to demonstrate the effectiveness of directness, specialization and how the proposed method can reduce the computational cost. The evaluation code is released at https://github.com/MIT - HAN - lab/ProxylessNAS and evaluation results are available for evaluation. The paper is published as a conference paper at ICLR 2019   ( Table 1 ) Table 2 : Proxy - Less than a year after the start of the original ZophNAS paper, the authors continue with their work and propose a method called Proxyless ( no meta - controller ) to learn the architectures on target task and hardware without pre - training the model on the proxy tasks. This method is referred to as “ normal train - normal train ” in the paper, but the authors later change the name to “ proxy - less train - regular ” to reflect the fact that it trains the network on the real data instead of the proxy data. The authors further discuss the advantages of using regular train - only blocks in the following ways : 1 ) More blocks can be specified to be used in the general case, 2 ) Training starts at the same level of the regular training ( i.e. a few epochs or a few training epochs ), 3 ) Models trained in the specified way can be trained on different proxy tasks with different"
SP:e5b70d43d301d1980fae02623ea711976b429c14,"This paper studies the problem of penalizing players in two - player min - max games whose objective is to learn an appropriately fair classifier on a Lagrangian dual with additive linear penalties. In non - convex ( or large - data ) settings, adding linear penalties to the objective may be difficult as the resulting problem may not have deterministic saddle - point equilibrium. To address this problem, the authors propose to modify the linear penalties in the objective from first - order to second - order. The motivation is that, as the penalty coefficient of the penalized objective has a fixed value, it is easier to train the player to correctly assign the correct parameters to achieve the objective with a lower bound. The authors argue that this avoids instability and lack of convergence issues associated with two - players min - min games ( e.g., instability of learning to penalize a 2nd - order gradients ). They also propose a method for efficiently computing the gradients associated with the second - ordered penalties in order to learn the resulting algorithm.   The experiments are conducted on four games, where the objective is defined as ( 1 ) a linear penalty where each player is allowed to take part in two games of the form ( 2 ) a maximum over the opponent ’s two games, ( 3 ) a no - player max - max game where the opponent takes part in only one game ( i.e., the first game is played by the same number of players ), ( 4 ) and four standard benchmarks where the losses are defined according to a number of standard benchmarks ( 1 - D, 2 - D+D, 3 - D + E ). For each of the four games ( 4 - D and 5 - E ), they compare their proposed penalized loss estimator with the standard penalty and penalized gradient estimator. For the games with and without penalty coefficients in the first and second order penalties, they show that the resulting resulting algorithm is significantly faster and more accurate than the one obtained by averaging over the standard penalties. Finally, they provide a procedure for computing the gradient of the second order penalty for training the final objective on the standard benchmarks with the modified penalized losses in the same way."
SP:e4720b8e4efdb222c45eafd47fd8a7fbf15d881d,"This paper studies the problem of learning deep generative models for learning discrete latent variable models with high variational gradient estimators. It notes that the current state - of - the - art methods employ control - variableate schemes for the sampling and continuous - relaxation methods for the relaxation of the latent variables, which are limited by the complexities of implementing and training effective control - variance schemes and the necessity of evaluating ( potentially exponentially ) how many branch paths in the model can be obtained. The authors propose the reweighted wake - sleep ( RWS ) algorithm, which is an alternative to the control - variables - based methods employed in the previous two works, due to the fact that, given sufficient training and supervision, RWS should be able to learn better models and learn more variational gradients. The paper presents a comprehensive evaluation of RWS that compares it to several other methods, including R - VAE, R - GAE, and R - Relaxation, and finds that RWS generally outperforms them in terms of generalization ability, learning ability, and test accuracy. The main contributions of the paper are the following : ( 1 ) it presents a detailed justification for why RWS is superior to previous methods for learning deep latent variables with high variance gradients, ( 2 ) it sets out to train RWS as a competitive alternative to RGS, and ( 3 ) it proposes ways to improve RWS training in order to reduce the number of sample paths leading to high - variance estimators in RWS."
SP:7459ae5b1d886e68930c4c9e21df508bc8ab3c9a,"This paper proposes SPENs ( Structured Prediction Energy Networks ), a novel method to evaluate predictions made with a scalar reward function for structured output prediction when the true output of the model is unknown. In contrast to prior work ( e.g. [ 1 ] and [ 2 ] ), where the reward function is the sum of a set of scalar inputs ( i.e., the learned score representation of the score landscape ) and the outputs of the trained models, the paper proposes to use a truncated randomized search instead of the full output space in order to train neural networks with efficient test - time inference using gradient - based search on a smooth score representation. The authors argue that this method is more efficient than other methods for training neural networks and yields state - of - the - art results in structured prediction tasks. However, the experimental results do not appear to support this claim. In particular, it is not clear why the authors do not provide experimental evidence supporting their claim that the neural networks are better than other neural networks that they train. The main contributions of the paper are the following : ( 1 ) A novel method for evaluating the predictions made by neural networks trained with a neural network with scalar rewards using gradient descent descent descent on the score representation ; ( 2 ) The use of gradient descent as a reward function in the neural network evaluation is a novel approach that does not rely on prior knowledge and uses techniques from non - differentiable reward functions for structured learning ( see [ 3 ], [ 4 ] for more details ; ( 3 ) The authors provide no additional explanation for the observed behavior of their neural networks in terms and refer only to the experiments only as references in the paper."
SP:638c1bc09992029b78bd83f0127594dcccb96c06,"This paper proposes an active learning based framework, EffAcTS, to selectively choose model parameters for transfer learning. The idea is to collect only as much data as necessary to select the robust model parameters with which to transfer policies from a simulation environment to the real world. This is different from previous approaches which sample large batches of trajectories and select the subset that are robust to varying environments, such as the ones that result in the worst performance. The main contribution of this paper is the introduction of a multi - task learning perspective to the problem of Robust Policy Search, where the goal is to find policies that do not degrade in performance when subject to unseen environment model parameters. The proposed framework, called * * active learning * *, is designed to be able to handle this task more flexibly.   The main contributions are the following : * * A learning framework from which it is possible to select only a subset of parameters to transfer robust policies when learning from a simulator environment to a real world setting. This allows to avoid having to choose between robust and non - robust parameters. * * An application of the learned model parameters ( from the active learning stage ) to the continuous control task setting, where they can be used to transfer the robust policies learned from the simulation from one environment to another ( similar to EPOpt ). This approach is referred to as “ active learning ” in the paper as it is not meant to be used during the learning process.  * * Sample efficiency analysis * * : This paper analyzes the gains in sample efficiency of the proposed method compared to the EPOpt method on standard continuous control tasks. It shows that the difference between the two methods is mainly due to the difference in sample complexity between the control task tasks ( EPOpt has more sample complexity and the proposed approach has fewer sample complexity ) and the fact that the sample complexity does not scale with the number of control tasks ( with EPOpt having larger sample size ). It also shows that there is a trade - off between sample complexity ( in terms of sample efficiency ) and sample efficiency when comparing the two approaches ( with a sample size that is not larger than the training batch size used to learn the robust policy from the control tasks, and with larger sample complexity when using the learned robust policy as the control policy. *    Analysis * * Of the contributions * * This paper presents three main results. First, it presents a learning framework based on active learning from the perspective of self - supervised learning to learn robust policies in a continuous control setting, which is similar to the work on Multi -Task Learning. This method is different in some ways from the way that the authors approach this problem. It is argued that the main contributions of this work is the use of active learning to select a set of parameters that is robust to changing environment parameters, and that the choice of these parameters is important to the preservation of robustness of the learning policy. The second main result is that the model parameters used for active learning are similar to those used for passive learning in the passive learning stage of EPOpt. The authors argue that this choice of model parameters is better because it allows for a better preservation of learning robust"
SP:491c239713a6489f0b1790ca26db54a1813c67ae,"This paper proposes a two - timescale network ( TTN ) to enable linear methods to be used to learn values, with a nonlinear representation learned at a slower timescale. The approach facilitates the use of algorithms developed for the linear setting, such as data - efficient least - squares - methods, eligibility traces and the myriad of recently developed linear policy evaluation algorithms. The authors also provide convergence analysis for the TTN to ensure convergence of the fast linear component under potentially dependent features provided by the learned representation. The main contributions of the paper are as follows :   ( 1 ) This paper proposes an architecture for learning values that is different from previous approaches to non - linear function approximation. This approach is referred to as Two - Time Network ( 2T ), and it can be seen as a kind of soft network. The 2T allows the learning values to be obtained with a fixed basis or a fixed representation. This is in contrast to previous approaches that used a gradient based representation or gradient based learning as the basis. ( 2 ) The authors show the relative performance of TTN with the linear methods against TTN in terms of policy evaluation and control, and also with respect to other nonlinear value function approximation algorithms, and they compare the performance of their two - time network to other TTN - based algorithms. ( 3 ) They also provide empirical analysis of the characteristics of the authors ’ TTN and show that TTN is more efficient than other methods for learning value functions."
SP:327d606cf3813b00a009a7785e08ef9e11f89493,"This paper proposes LEArning and Planning with Semantics ( LEAPS ), a model - based approach to planning and executing policy actions in visual - semantic semantic navigation tasks in 3D environments with human - designed indoor scenes with real - world objects. The approach consists of a multi - target sub - policy that acts on visual inputs and a Bayesian model over semantic structures, which is trained using reinforcement learning and reinforcement learning agents. The paper presents experiments in visual navigation tasks using House3D, a 3D environment that contains diverse human-designed indoor scenes containing semantic regularities that do not appear in the environment when viewed from the outside. Experimental results show that the approach outperforms the baseline model - free approach in tasks where the agent generalizes the learned policy to unseen environments and vice versa.   The main contributions of the paper are as follows : - The paper proposes a new approach for planning and planning in semantic semantic environments, called LEAPS, which consists of three components : - A visual policy network that is trained to predict the next sub - target action from the target policy and the semantic model - A semantic model that is used to make high - level decisions on the visual sub - targets that the visual policy will execute - A reinforcement learning agent that learns to execute the proposed semantic model actions in the visual - target network - A Bayesian policy implementation that proposes the next semantic target action to execute based on the current state of the model - and - an agent that executes the semantic target actions and the corresponding semantic embedding of the proposed embedding using the embedding. The method is evaluated in three tasks where it is shown to perform better than the baselines in two of them."
SP:d7c26f43bc68d160095b1f50447528843d79edbd,"This paper proposes a new approach to tackle the problem of generalization and accident explanation in deep learning driven models. The authors claim that the current deep learning models have two main weaknesses : ( 1 ) poor generalization ability of unobserved driving environment when diversity of training driving dataset is limited and ( 2 ) lack of accident explanation ability when driving models don’t work as expected. To tackle these two problems, the authors propose a new model composed of two modules : perception module for see and think and driving module for behave, and trained it with multi - task perception-related basic knowledge and driving knowledge stepwisely. Specifically segmentation map and depth map ( pixel level understanding of images ) were considered as what & where and how far knowledge for tackling easier drivingrelated perception problems for generating final control commands for difficult driving tasks. The proposed model, Multi - Task Self - Control Model ( MSC ), solves the two problems. Based on the belief that knowledge of associated easy task knowledge is benificial for addressing difficult task, MSC first generates knowledge of difficult task associated with MDPs and then addresses the difficult task with the knowledge generated from the knowledge of easy task. MSC achieves better generalization for better generalizability and the authors compare MSC with two baselines : easy and hard - to - drive. The results of experiments demonstrated the effectiveness of multitask perception knowledge for the easier task and the importance of the different modules for the harder task.    The authors conducted a series of experiments on the following tasks :   1. Multitask Self - Self - control : train a model on a set of tasks with the assumption that the learner is motivated by self - supervised learning ( i.e., self - control is motivated from self - observation and self - driving ; ii. train the model on self - observed trajectories ; iii. show that the model achieves better performance on the tasks compared to the baselines. 3. Multi - task Self - supervision : the model is able to learn self - supervision better on the difficult tasks compared with the easy tasks. However, the model still lags in terms with respect to the other baselines and the learning rate of the authors ’ method."
SP:b6bd98cc70fab97e1245cbb63a42ef89ab7e7ed5,"This paper studies the trade - off between adversarial robustness and generalization accuracy of classifiers trained with robust models. The authors propose that robust classifiers learn fundamentally different feature representations than standard classifiers and that the features learned by robust models tend to align better with salient data characteristics and human perception. The main contribution of the paper is that it proposes a theoretical explanation for why robust models learn features that are more in tune with human characteristics than those learned by standard classifier classifiers. This is demonstrated by a series of experiments where the robust classifier is trained with adversarial perturbations on a toy example, and the accuracy of the classifier drops as a function of the model's robustness to the perturbation is increased. The paper then extends its theoretical results to a more realistic setting in which the robust model is trained to generalize to all possible combinations of the toy examples, and it is shown that the accuracy does not drop as much for robust models as it does for standard ones. Finally, the paper proposes an empirical explanation for the observed phenomenon of the better alignment of features learned with robust features with human features. The experiments are conducted on toy examples and toy data, and they compare with standard and robust models in terms of their accuracy and robustness."
SP:9c9275d75cd95b1b82e0cbb1421e3d3ade1ce33a,"The authors propose an extension of the Equilibrium Propagation ( EPG ) method for gradient - based training of neural networks to biological networks. The original EPG was developed in Scellier & Bengio ( 2017 ) as an extension to the local learning rule for training neural networks. However, due to its iterative optimization of neural activations to find a fixed point, and the number of steps required to closely approximate this fixed point scales poorly with the depth of the network, the authors propose to use a feed - forward network to initialize the iterative inference procedure for EPG in order to train deep neural networks without using backpropagation. The proposed method, dubbed Informed Feed - Forward Network ( FedFoF ), learns to approximate the state of the fixed point of EPG using a local - learning rule, and then uses this initializing network for inference, resulting in a learned feedforward network. The authors evaluate FedFPoF on MNIST and Fashion - MNIST tasks and compare it to the original Equilibrium propagation while requiring fewer steps to converge. The experimental results are favorable to the proposed approach."
SP:ac9ea91eb465517de495477cf67bc94d5ed1b0cb,"This paper studies the convergence of ZO - sign SGD, a new stochastic optimization algorithm that enjoys the advantages of gradient - free operations and signSGD - type offline estimators. The convergence rate is given in the equation $ \tilde{O}(\sqrt{T})$, where $ O$ is the number of optimization variables and $ T \in \mathbb{R}^{T } \log T(d\mid T ) = \sum_t \mid T \cdot T \pi T \bar S$. The paper shows that under some mild assumptions the convergence rate of $ O(\mid O(t))$ with $ d/\dots T$ is as good as the best possible convergence rate with SGD-type algorithms. In addition to the convergence analysis presented in the paper, the authors also analyze the effects of gradient estimators and propose several variants of the algorithm.   The main contributions of the paper are as follows :   1 ) The authors develop and study a new zeroth - order ( ZO ) optimization algorithm with gradient estimates, which is able to achieve a comparable or better convergence speed than SGD - Type algorithms. 2 ) They demonstrate the performance of the new algorithm on the generation of adversarial examples from black - box neural networks. 3 ) They also explore the connection between ZO-signSGD and black -box adversarial attacks in robust deep learning."
SP:5f79b11777f6ef1d70c85418bfc2e4616dd7d960,"This paper proposes a new method to reduce the computation cost of deep learning by optimizing a convolutional filter using multiply - cumulate operations ( MAC ). The paper proposes to set a checkpoint in the MAC process to determine whether a filter could terminate early based on the intermediate result of a previous MAC operation. The authors also propose a fine - tuning process to recover the accuracy drop due to the applied checkpoints. The experiments show that the proposed method can save approximately 50% accuracy drop for CIFAR-10 with less than 1 % accuracy drop and is competitive on the CifAR-100 dataset. Compared with the state -ofthe -art method, the proposed algorithm is more effective on the $ \ell_2$- dataset and $ \epsilon$- datasets. It also outperforms the state-of - the - art method when applied to the deep learning network in the State - OFTCHA dataset."
SP:7801e9c854ad7d960c0d24fda15597af6994c23f,"This paper studies the impact of adversarial attacks on the robustness of automatic speech recognition ( ASR ) systems using image - based defense ( image defense ). Specifically, three adversarial examples are used to train ASR systems with two image defense variants and two temporal defense variants, one based on image adversarial defense ( ID ) and another based on temporal defense ( TAD ). Results show that ( i ) image defense provides limited robustness improvement and is subtle to advanced attacks ; ( ii ) temporal dependency can be exploited to gain discriminative power against audio adversarial example and is resistant to adaptive attacks considered in the experiments ; and ( iii ) TAD can be used to mitigate the negative effects of temporal dependency in exploiting domain - specific data ( DSD ) to mitigate adversarial attack.   The authors conducted experiments on three tasks on ASR and speech recognition using image defense and three recent audio attacks. They found that ( 1 ) input transformation developed from image defense only improves robustness slightly more than the one developed from temporal defense and ( 2 ) DSD can be more robust than temporal dependency but is less robust than TAD. They also found that using temporal dependency to mitigate temporal dependency with AD is more effective than using AD with DSD. The authors also investigated the use of DSD to mitigate AD in ASR tasks and showed that DSD helps more than using the temporal dependency."
SP:51830b811a8e39b4f0a5b7609df719e026fac6a1,"This paper proposes a new approach to generate GANs by means of composition to account for the compositional way in which humans structure images, and proposes to structure the generator of a GAN to consider objects and their relations explicitly in the context of the image generation process in order to learn a more accurate generative model of real - world images and serves as an initial step towards learning corresponding object representations. The authors evaluate their approach on several multi - object image datasets and find that the generator learns to identify and disentangle information corresponding to different objects at a representational level. A human study reveals that the resulting generative models are better able to generate images that are more faithful to the reference distribution.   The main contributions of this paper are as follows : - The authors propose a new way to construct the generator for GAN models by considering the composition of images in terms of the objects with which they are associated ; - This provides a way to efficiently learn object representations ; - It is experimentally verified that the generated images do indeed correspond to objects in the images ; - Similar representations of objects can be learned ( at least at a symbolic level ) for which the generator is more likely to generate high - quality samples ( compared to the original image )."
SP:fb59990b8da0e95d8202383478a456667de60449,"The paper proposes a supervised learning setting called reference - based disentangling ( reference based variational autoencoders ) where the only supervision comes from an auxiliary reference set of images that contains the factors of interest constant in the training set. The authors propose to learn disentangled representations from the reference set with minimal supervision using a variational generative model called DeepGenerative Model ( DPM ). The DPM is based on the idea of deep generative adversarial inference ( DVA ) where an adversary is used to learn a representation from a set of target factors that are disentangles from others. In the experiments, the authors demonstrate the effectiveness of the DPM on tasks such as feature learning, conditional image generation and attribute transfer.    The main contributions of the paper are the following :   1. The introduction of a learning setting based on variational inference where the target factors are constant and the supervision is provided by a reference set. This setting allows the authors to learn representations from a fixed set of image source vectors that do not require annotation. This sets the groundwork for supervised learning with respect to DVA. 2. The use of DPM in the learning setting is justified using the observation that DPMs with DVA learn representations that are independent of the supervision ( e.g., those that do n’t depend on the supervision ) are less likely to converge to the same representation when learning from the same source vectors. 3. The author validates the ability of the proposed model in terms of learning the learned representation from DPM representations using a toy example. 4. The experiments demonstrate that the learning pipeline for DPM learnable representations leads to better performance than the baseline without DPM learning."
SP:dbc1983d9b9d72aa14f8e8515d793d2bbde26c9c,"This paper proposes a method for continual online learning from an incoming stream of data using deep neural network models. The method is based on a Chinese restaurant learning procedure that uses stochastic gradient descent to update model parameters and an expectation maximization algorithm with a Chinese process prior to developing and maintaining a mixture of models to handle non - stationary task distributions. This allows for all models to be adapted as necessary, with new models instantiated for task changes and old models recalled when previously seen tasks are encountered again. The authors also apply their meta - learning for online learning ( MOLe ) approach to model - based reinforcement learning ( MLR ), where adapting the predictive model is critical for control. They demonstrate that MOLe outperforms alternative prior methods, and enables effective continuous adaptation in   tasks with varying terrains, motor failures, and unexpected disturbances. They also provide empirical evidence that the method is effective in online adaptation with SGD, which is otherwise not the case for large function approximators."
SP:5665e5f006f84927beb0440e145f476e02538077,"This paper investigates the effect of parameter lag and representational drift on the training of RL agents trained via distributed prioritized experience replay ( PVR ). It builds on the recent successes of distributed training of RNN - based RL agents and trains a PVR agent using a single network architecture and fixed set of hyperparameters. The resulting agent, Recurrent Replay Distributed DQN, quadruples the previous state of the art on Atari - 57 and matches the state of art on DMLab - 30. It is the first agent to exceed human - level performance in 52 of the 57 Atari games. The authors empirically derive an improved training strategy to counter the effects of lag and state staleness.    The main contributions of this paper are the following :   1. The main contribution of the paper is to develop a network architecture to train PVR agents using distributed PVR. This is different from the previous work which trained RL agents solely using a RNN architecture. The network architecture is more general and can be applied to training other networks. 2. A second major contribution is the development of a learning algorithm to learn the hyper - parameters of the PVR network using a fixed set. The method is referred to as “ recurrent replay distributed network ” ( RRTD ) and it is similar in spirit to the Distributed Neural Network ( DNN ) method ( Wang et al., 2019 ). The difference is that the DNN uses a learned hyperparameter distribution to learn parameters, while the RNN uses an actor - critic network to learn weights. This allows the authors to distinguish between learning from learning via DNN and learning using RNN. The learning algorithm can be used to train RL agents from learning from RNN or learning from DNN. 3. Finally, the authors provide empirical evaluations of the performance of their proposed method."
SP:47ace37f31a46d5ee85c283e62ddb71a12f2c5c4,"This paper studies the problem of training sequential generative models for capturing coordinated multi - agent trajectory behavior in settings where the goal is to capture long - term coordination using intermediate variables and high - level behavioral semantics. The paper proposes a hierarchical generative model that can capture both the long - horizon and intermediate state of the trajectories. The model is trained using a recurrent neural network and trained in a stochastic fashion using labels learned from a programmatically produced weak label network. The authors then show how to instantiate the hierarchical model that they use to model complex interactions between basketball players and generate realistic multi - agents trajectories of basketball gameplay over long time periods in two synthetic settings and one real world setting. The framework is validated using both quantitative and qualitative evaluations, including a user study comparison conducted with professional sports analysts.   The main contributions of the paper are as follows :   1 ) The authors develop and train a neural network that can learn to generate labels for the spatiotemporal regime using a hierarchical model. 2 ) They extend the neural network trained in the previous work on leveraging programmatic produced weak labels to generate spatiotemic labels in the temporal regime. 3 ) They use this neural network to generate intermediate state trajectories that are used to model long - time coordination between players in order to generate realistic trajectories for long - range planning and defense."
SP:1a90cdf028068528b0559e7d44bf26dda20310bd,"This paper proposes a method, Graph - VNN, to learn to integrate visual information ( from a learned dynamics model, a learned vision model, and a vision - augmented model ) in the context of interacting agents using a graph - structured variational recurrent neural network ( Graph -NN ). The network is trained end - to - end to infer the current state of the ( partial observed ) world, as well as to forecast future states of the past, using graph - structures learned from trajectories from the dynamics model and the vision model. The method is evaluated on 4 datasets ( 3 based on real trajectories, one based on a simulated one, one generated by a soccer game engine, and one using data from a graph neural network trained with data from an agent ) and 5 environments ( 2 simulated, 2 real, and 1 synthetic ). Graph - NN outperforms its baselines in all 4 cases. The main reason for the superior performance is due to the robustness of the architecture, compared to the other baselines, which may have been affected by the nature of the datasets or the fact that they use trajectories that are not unique to the agent.   The main contributions of the paper are the following :   1. It proposes a learning framework that learns to integrate the visual information from the learned model with the two types of visual inputs : ambiguous visual information, from the projection model. This is achieved using a variational graph structure, which is a weighted sum of two components : the first component, the graph - VNets, is a graph that maps the trajectories of the agent with the visual input, and the second component is the projections of the graph from the agent to the past. The projection. This means that the learning process can take in both the visual inputs and the visual projections as input and learn how to combine them to form a composite of the two. The projections can then be used to update the agent's estimated trajectories in time. The idea is that the projection from the image of the future state can be updated using the updated graph with the updated trajectories obtained from the past using the projection of the previous state. This method is shown to outperform the other two baselines on the simulated and real data ( from the latter two scenarios ), and it is also shown to learn better than the one trained with real data from the simulation model ( on simulated trajectories ) on simulated data."
SP:8392f04b7265f665ba6d44d297bca245d44b4708,"This paper proposes a method for end - to - end training of a base neural network that integrates calls to existing blackbox functions by approximating the blackbox functionality with a differentiable neural network in a way that drives the base network to comply with the black - box function interface during the optimization process.   The main contribution of this paper is to propose a way to train a neural network, end to end, to compute the input to black box functionality while eliminating the need for intermediate labels. The training procedure consists of three steps :    ( 1 ) training the neural network parametrized by a Gaussian Mixture Model ( GMM ), which is trained by gradient descent with the input from the GMM to the black box function provided by the task ; ( 2 ) training a model parameterized by a neural net parametrization ; ( 3 ) training and evaluating a model trained on a set of tasks that consist of four tasks ( four objectives ), where each objective functions are black box functions, each of which can be obtained by decomposing the task into a series of functions of the form ( “ decomposing a task into functions of interest ”, where “ interesting ” refers to the functions that can be used to solve the currently relevant task ; and ( 4 ) a training procedure that aims to maximize the output of the model parameters of each of the functions while minimizing the training time of the neural net parameters. The experiments compare the proposed training procedure with three differentiable models, two gradient - based models, and a fully differentiable model, and show that the integrated model generalizes better than the other two models and learns more efficiently compared to the RL - based methods. The main contributions of the paper are the following : ( a ) Inference studies comparing the performance of integrated model and the one trained with gradient descent are conducted, and ( b ) the method is compared with two gradient descent methods, and the results show that integrated model performs better in terms of generalization and generalization performance than the vanilla model."
SP:13fb86de763a0b34ac6fa34ea9dfbd1c476ce43e,"This paper proposes a method for generalizing the model - agnostic metalearning algorithm ( MAML ) for meta - learning ( learning - to - learn or LTL ) in settings where transfer between tasks is not mutually beneficial, for instance when the tasks are sufficiently dissimilar or change over time. The authors propose a stochastic expectation maximization procedure to jointly estimate parameter initializations for gradient descent and gradient descent as well as a latent assignment of tasks to initializations in order to better captures the diversity of training tasks as opposed to consolidating inductive biases into a single set of tasks. This approach is referred to as the joint gradient descent approach ( JAE ) in the paper and is based on the connection between gradient - based meta learning and hierarchical Bayes ( Grant et al., 2018 ), which is used to propose a mixture of hierarchical Bayesian models over the parameters of an arbitrary function approximator such as a neural network. In the experiments, the authors demonstrate better generalization performance on the standard miniImageNet classification and benchmark for learning on the few - shot regression tasks.    The authors further derive a novel and scalable non - parametric variant of their method that captures the evolution of a task distribution over time as demonstrated on a set of few-shot regression tasks that they use to evaluate their method. The experimental results demonstrate that the method outperforms other methods for generalization and transfer learning in terms of learning rate and transfer efficiency. The main contributions of the paper are as follows :   ( 1 ) They propose a method to generalize the model-agnostic metalearnings algorithm based on a joint distribution of parameters that allows for learning to transfer between different functions using a Bayesian neural network ; ( 2 ) They use the joint distribution as a learning rate estimator to estimate parameters of gradient descent to learnable functions so that the learning rate can be increased on tasks that have similar initializations."
SP:a410144dbe19713a06c63da87d9fb58b999a7492,"This paper proposes Meta Auxiliary Learning ( MAXL ), a method to automatically train a multi - task classification model using auxiliary tasks defined by the meta - learner. The auxiliary task is hierarchical sub - class image classification, where the primary task is to determine target labels for the model to classify sub - classes of the principal task to maximize its generalisation performance. The proposed method is based on the idea that it may be possible to automatically learn auxiliary task labels that best suit the principal labels to generalise generalisation better than those obtained by manually - defined auxiliary tasks based on domain knowledge. The authors propose a novel algorithm for this task, which they call meta - auxiliary learning ( MaxL ). MaxL is trained using supervised learning with the auxiliary task definition. The training is done using supervised gradient descent from the principal classification task to the auxiliary tasks to train the model. The main difference between MaxL and the other auxiliary learning methods is that MaxL trains the target labels of the auxiliary learning method using gradient descent, while the other methods trains the sub - task labels using a linear model. They evaluate their method on three CIFAR-10 datasets and show that it generalises better than the other two methods and is competitive even with a method which uses human - defined sub - assignment hierarchies. They also show that MAXL generalize better than two other methods that they compare.    The main contributions of this paper are the following :   1 ) A novel method for the task of image classification. The idea of using auxiliary learning to generalize the generalisation of a principal task based on a set of target labels is novel. This idea is similar to what has been proposed in prior work and is different from the way of thinking about auxiliary learning in that it does not require the user to come up with the labels. 2 ) A better way to train a target label for auxiliary tasks is to use a weighted sum - weighted sum of information from principal task and auxiliary tasks. This is similar in spirit to what was proposed in the previous work [ 1 ]. However, the authors do not use the same level of detail in the training of sub - tasks as in the first step. 3 ) The method is different in the sense that it trains a target classifier to predict the target class labels of auxiliary tasks instead of the domain - specific classifier. This means that the training starts from the domain knowledge of the meta learner and the task - specific sub - target labels are not used."
SP:76248e1c914c60ce69de244fe7ec62488d01e161,"This paper presents a neural network based representation for addressing the open set recognition problem. The main contributions are as follows :   ( 1 ) A new neural network representation is developed, based on the existing neural network. This representation is then used to construct a set of open set labels. This set of labels is used to predict the likelihood of a given instance in an instance from the same class. This is in contrast to the typical training in which the labels of different classes are drawn from different open set dictionaries. ( 2 ) A set of three datasets is constructed, from which the neural network representations are drawn. The three datasets are used to generate the synthetic data used for the training ( e.g., CIFAR-10, MNIST, Fashion - MNIST ). The synthetic data is used in the experiments to compare the performance of the different methods. The results show that the proposed methods ( neural network and set of classes ) have a statistically significant performance advantage over the other two methods ( open set and set - centric ) when tested on three datasets from two different domains. ( 3 ) The main contribution of this paper is the use of neural networks to represent instances from different classes in a set. This helps to build a more complete set of instances for training. The neural network used for training is different from the one used for designing the original neural network, as it is not used during training. Instead, this neural network is used during testing to create a representation of instances from a given class. ( 4 ) The paper also includes an appendix with additional information regarding the different types of classifications used in training."
SP:d4ee856bbf2dfb6390e5247086fec2e52dcb6858,"This paper studies the use of low - precision networks ( LPs ) on the ImageNet classification task. LPs are models trained with finetuning, where energy and area scale quadratically with the reduction in precision. This paper proposes several LPs that leverage the availability of pretrained fp32 precision models to train LPs with 8 - bit precision that match the accuracy of the full - precision baseline networks. The paper shows that ResNet-18, ResNet - 34, Res net - 50, Inception - v3, densenet161, and VGG - 16bn can all be trained with 8- bit precision and achieve results that are at least as good as those obtained with full precision LPs. The authors also show that gradient noise due to quantization during training increases with reduced precision, and seek ways to overcome this noise. The number of iterations required by stochastic gradient descent to achieve a given training error is related to the square of ( a ) the distance of the initial solution from the final plus ( b ) the maximum variance of the gradient estimates.    The paper proposes to reduce solution distance by starting with pretrained $ \epsilon$ precision networks and fine - tuning, and combat noise introduced by quantizing weights and activations during training, by using larger batches along with matched learning rate annealing. Sensitivity analysis indicates that these techniques, coupled with proper activation function range calibration, offer a promising heuristic to discover LPs close to $ \eps32$.   Overall, the paper is well written and well presented. The major weakness is the lack of detailed description of the training procedure and lack of experiments. The manuscript could use some clarifications to clarify some points and provide more detail on the benefits of using LPs for classification tasks."
SP:6bfdc37b346e6ddfa049e0414647f4beda8ede3f,"This paper proposes a new model, Bounce and Learn, to predict post - bounce trajectories and infer two underlying physical properties governing bouncing restitution and collision normals. The model consists of two modules : PIM and VIM. PIM learns to model physical parameters and interactions for the prediction task given PIM parameters and observed pre - collision 3D trajectories. VIM is used to learn to model locations in a scene given a single still image and PIM interactions are used to model post - bouncing trajectories given real - world parameters and observations. The experiments compare the performance of the proposed model with other baselines including trajectory fitting with Newtonian physics, in predicting post - bounces and in inferring the two underlying properties. To achieve the results, the authors introduce the Bounce Dataset comprising 5 K RGB - D videos of bouncing trajectory of a foam ball from different surfaces of varying shapes and materials in everyday scenes including homes and offices. They also introduce an approach to model surface properties governing bounces governing collision norms governing bounces.    The main contributions of this paper are as follows :   1. A new model is proposed, which learns end - to - end, starting from sensor inputs to predict trajectories for bouncing and collision prediction tasks. The learning process is called PIM - Learn. It comprises two modules – a Physics Inference Module ( PIM ) and a Visual Inference module ( VIM ). The first PIM parameter learns to infer locations and interactions from a still image, while the second VIM parameter is used for predicting trajectories following a trajectory trajectory following a collision trajectory. The second PIM variable is used as a parametriz to predict the post bouncing trajectory after bouncing. The difference between the two PIM modules is that VIM parameters are parametrized as functions of a vector, while PIM is parametrised as a vector of interactions between two vectors. The experimental results show that the PIM model outperforms the other two models in terms of accuracy and accuracy with respect to the number of bounces and collision collision norms. 2. The approach is evaluated on a dataset of real world bounces and real world collision trajectories with additional information from simple physics simulations. On the real world bouncing dataset, the model outperformed the other methods by a large margin. On a second dataset of bouncing trajectory trajectories, the approach did not perform as well as the others and the performance lagged slightly."
SP:010bd055310c363d3cb0fbe0e11546de58220e15,"This paper studies the adversarial vulnerability of neural networks in terms of the gradients of the training objective when viewed as a function of the inputs. It shows that the most current network architectures are vulnerable to adversarial perturbations on the $ \sqrt{1}$ gradients as the square root of the input size. This is motivated by the fact that adversarial attacks on the network often lead to different predictions depending on the magnitude of the perturbation compared to attacks that are not adversarial.   The main contributions of this paper are the following :   ( 1 ) The authors study the dependence of the network ’s weight distribution ( $ \theta$ ) on the number of gradients used to train the objective of the neural network. They show that the network is invariant to the number ( $ 1 \eta$ ) that is training the objective. This invariance is broken down into two terms, one relating to the size of the gradient of the objective ( $ gradients $ G$ ) and another relating to its $ \alpha$ value. The latter term refers to the probability that the output of a given input is closer to the `1 - norm `1 ’ than the input value $ G$. The authors prove that this is because the probability of the output gradients is proportional to $ G(G)$ only if it is smaller than $ G(\theta)$, where $ G \in \mathbb{G}$ is a weighted sum of $ G_{\theta } - G$.    In other words, this means that for any input of size $ G_i_i$ that is larger than $ 1 $, there exists a set of smaller gradients that have higher probability of being adversarial ( higher value ). The authors show that these higher gradients are more likely to be biased towards the image representations of larger gradients. This sets the network architecture apart from prior work that has studied this phenomenon, which has studied adversarial defenses against adversarial images. The main difference between the two is that the previous work studies this phenomenon from a purely adversarial perspective from the perspective of image - based defenses. This work focused on images that are the subject of the given the same set of data ( e.g., labels ). In contrast, this work studies the phenomenon from the viewpoint of invariance to the domain of the images given the given training data. In this work, the authors take the opposite view : that the representations of the data belong to a class of images that is not the target domain ( the domain is the class of data given the training data ). For example, in the case of images given to the class DNNs from the DNN"
SP:5fa3ae057e55be6b71cc94a7dbfe31e54e1c536f,"This paper proposes a new approach to agent modeling, in which the probing agent is encouraged to interact with the environment and a target agent in order to maximize the change in the observed behaviors of that agent compared to the target. The probing agent learns to observe the behaviors of the other agent and use these observations to learn a more accurate mind model of the target agent to improve the performance of the agent modeling. This is achieved through two learning processes : ( i ) imitation learning for an approximated agent model and ( ii ) pure curiosity - driven reinforcement learning to discover new behaviors that can be used for an efficient probing policy to discover behaviors that otherwise can not be observed. The proposed approach is validated in four different tasks and the experimental results suggest that the agent model learned by our approach generalizes better in the novel scenarios than the ones learned by passive observation, random probing, and other curiosity driven approaches do.   The main contributions of this paper are the following :   ( 1 ) A new probing policy encouraging an agent to learn to probe is proposed to improve agent modeling performance in multiple agent interaction scenarios, including distilling optimal planning to a policy net, collaboration, and competition. ( 2 ) An imitation learning approach for training the probabilistic agent model is developed, which learns to imitate the behavior of a teacher agent and a student agent, and is evaluated in two scenarios, where the student agent is allowed to explore the environment while the teacher agent is restricted to following a fixed policies. ( 3 ) The probing policy is applied to both the imitation learning and reinforcement learning cases, where it is shown that the probing policy leads to better performance than the teacher model, and it is used to train a probing policy that leads to a better probing policy in the other scenarios. ( 4 ) The experiments show that the proposed probing policy improves agent performance in all scenarios, and that it is better in some cases even when the target policy does not improve agent performance ( e.g., in the case when the teacher policy improves the performance significantly more than the probe policy ). The paper is well written and well presented. The major weakness is that it uses the word “ probing policy ” too many times in the single paper. This can cause confusion between different parts of the paper, leading to confusing results and difficult to follow. Also, the paper may not be intuitive for some users. For example, the use of the word probing policy ( which is supposed to encourage probing to improve performance ) is confusing to some users because it implies that probing is only used for enhancing the probing policies when it is actually used for improving the probing. ( This is not necessarily the case. )"
SP:3af184a5529d6ec2a0862efd1af80ef5b50d2952,"This paper proposes a modification to the training procedure for artificial neural networks ( ANNs ) inspired by biological Neuromodulators, which activate neurons based on their intrinsic affinities with peripheral factors ( e.g., stimulus, reward ). The authors propose a new type of ANN nodes, termed modulators, that mimic the function of a neuromodulator and are trained to adjust the sensitivity of the activations of other ANN nodes in run - time based on the input patterns from the modulators. This is different from the standard ANNs that operate by simply summing up the synaptic inputs and then transforming the integrated information. The main contribution of this work is that it proposes to train a modulated ANN node that, in addition to the usual activation of the ANN node, can also adjust its sensitivity to the inputs of other nodes based on these input patterns. The modulators are trained in two ways : ( 1 ) in the context of Convolutional Neural Networks and Long - Short - term Memory Networks ( LSMNs ), where they are trained with the same training procedure as the original ANNs, and ( 2 ) with two different types of augmentation, one for short - term memory networks ( SMM ) and one for full - term networks ( LSTM ).   The experiments show that the proposed modulators show statistically significant improvements in terms of accuracy over the baseline ANNs when training with SMM and one or more of the two augmentation methods. However, it is not clear if these improvements are due to the new modulators or simply to the fact that the activation no longer needs to be parametrized."
SP:287a577834fd2820a939a1113b39146a22727491,"This paper proposes a neural analysis and synthesis framework ( NANSY ) based on information perturbation to manipulate the voice, pitch and frequency response of an arbitrary speech signal. The main idea is to perturb the information in the original input signal ( e.g. formant, pitch, frequency response ) so that the synthesis networks can take the essential attributes to reconstruct the input signal, thereby avoiding the information bottleneck that usually results from using such analysis features for controllable synthesis, which usually results in poor reconstruction quality and controllability issues. To achieve this, the authors propose a novel training strategy based on the idea of using the self - supervised training strategy proposed in ( Zhang et al., 2020 ) to train synthesis networks using the information perturbed information from the input signals, which is then fed into the neural networks to construct the reconstructed input signal. Since the training strategy does not require any information bottlenecks, the resulting neural networks can be trained in a reproducible way, which allows for better reconstruction quality. The authors conduct extensive experiments in zero - shot voice conversion, pitch - shift, pitch shift, and time - scale modification tasks with speech data. The experiments show that NansY can achieve significant improvement in performance in several applications.   The main contributions of this paper are the following :   1 ) The authors develop and train a neural network based on an artificial multilingual speaker dataset. The training strategy, called information perturbing training, is simple and effective, and can be extended to a multilingual setting by simply training it with the artificial dataset. 2 ) The network is able to achieve better performance in some cases compared to the SOTA networks ( SOTA by training the network on the speaker data. 3 ) The method is also able to attain better performance compared to SOTA on some tasks using the new training strategy."
SP:90f35ad1ec0c38b0817f5678ee2a5c4f0e08fb38,"This paper presents a generalization analysis of the gradient - based bilevel programming framework ( GPF ) based on uniform stability of the validation set. The main contributions are two - fold : ( 1 ) An upper bound on the variance of the set w.r.t. the validation distribution is provided, which can explain why the GPF tends to be overfitting to the validation ; ( 2 ) An expectation bound for the classical cross - validation algorithm is also presented, which is used to derive a lower bound on generalization error bound for GPF generalization. The upper bound is built on the assumption that the set is stable with respect to a pre - defined distribution p. The paper shows that the upper bound holds for both the outer and inner validation sets of GPF. The lower bound is tested empirically on the feature learning and data reweighting task, where it compares favourably to the gradient based GPF and cross - validation algorithms. The empirical results suggest that GPF is slightly more stable than crossvalidation under certain stability assumptions, while being slightly worse than gradient based algorithms under other conditions. The paper also shows that regularization terms can be used to alleviate the overfitting problem of gradient based methods."
SP:42f52aec3a776d87daa5fd72b8e6325d12c88d63,"This paper proposes a knowledge distillation approach to facilitate the transfer of dark knowledge from a teacher to a student. The key idea of the approach is to learn the teacher models that are friendly to students and, consequently, more appropriate for knowledge transfer. To achieve this goal, the teacher network is first trained with supervised learning, where the student branches are optimized jointly to obtain student - friendly representations. The main motivation for this approach is that, since the training procedure is straightforward and the subsequent distillation procedure is easy, most of the existing knowledge distilling methods can adopt this technique to improve the performance of diverse student models in terms of accuracy and convergence speed. The proposed algorithm demonstrates outstanding accuracy in several well - known distillation techniques with various combinations of teacher and student models. It achieves good performance even in the case that their architectures are heterogeneous and there is no prior knowledge about student models about the teacher networks.   The main contributions of the paper are as follows :    1. The paper proposes an approach to jointly train teacher networks to learn student models given pretrained teachers. This approach is referred to as “ mutual information transfer ” ( MADE ). 2. The student models are trained jointly with the pretrained teacher network to obtain representations that are similar enough to the student model ’s representation. 3. The teacher networks are used to train the student models on the unlabeled dataset. 4. In the final distillation step, the student and teacher models are updated jointly for each other using supervised learning to obtain the student - teacher representations."
SP:e15a1c21229233fd97dc1dfa0a4ef48b69dc9f95,"This paper studies generalization of out - of - distribution ( OOD ) learning algorithms based on the idea of extracting invariant features from OOD data. The paper proposes two definitions of OOD generalization : 1 ) what is OOD ; and 2 ) what does it mean by saying an OOD problem is learnable? The paper introduces a new concept of expansion function, which characterizes to what extent the variance is amplified in the test domains over the training domains, and therefore give a quantitative meaning of invariant generalization guarantees. Based on this concept, the paper proposes a generalization algorithm, named OOD - EXPAND, to obtain generalization to OOD problems. The main contributions of the paper are as follows :   1 ) The paper develops and studies the generalization properties of Expanded OOD Learning ( EXPAND ) algorithm. This is done by analyzing the following factors : ( 1 ) What kind of invariance does EXPAND guarantee for OODs that generalization is guaranteed ; ( 2 ) What is the empirical relationship between EXPAND and generalization for invariant and non - invariant functions under two conditions ; ( 3 ) How well do EXPAND algorithms generalize to arbitrary OOD test domains under different settings ( e.g., if the test domain is in the same distribution as the training domain or not, and the class domain is different across training and test domains ).   The main contribution of this paper is the introduction of the expansion function to characterize how much the variance of EXPAND depends on how much invariance is guaranteed for each function under EXPAND. ExpAND is then used to obtain a quantitative understanding of the guarantees of generalization under OOD. 2 ) Extensive experiments on benchmark OODD datasets demonstrate that EXPAND algorithm has a significant advantage over baselines on some tasks."
SP:37b04b9068d39bcf0a581eb8181d13cf1a8926bf,"This paper proposes a Variational Continual Bayesian Meta - Learning algorithm based on a Chinese Restaurant Process ( DPR ) for complex online learning where tasks arrive sequentially and follow a non - stationary distribution. The main contributions are :   ( 1 ) A Variational Gaussian Mixture Model ( DMM ) for meta - learning is proposed, which extends the variational variational inference in prior work ( MLP - ML ) to a more complex setting with dynamic mixtures for the parameters of the meta - learner. This allows the DMM to adapt to more complex tasks and to handle tasks with dissimilar distributions ( e.g., different tasks arising from different tasks occurring at the same time ) with a larger parameter space. The DMM is used to estimate the posterior distributions of parameters of meta learner parameters using the Variational Variational Bayesian estimation ( VI - MLA ) method. This gives a better upper bound on the posterior approximation error of the model parameters when estimating the posterior distribution of parameters ( compared to the previously used point estimation method ). ( 2 ) A more robust posterior approximation method ( RVA - VAE ) is used for the inference of the parametrizations of the parameters in the model. The empirical results show that the proposed algorithm is superior in transferring knowledge among diverse tasks and alleviates catastrophic forgetting in an online setting.    The main contribution of this paper is the use of Dynamic Mixture Models for meta learning, which extend previous work DMM - MLP. The authors also propose a more robust prior approximation method, VAE - RVAE, which uses a more accurately inferring the posterior of parameters in order to reduce the catastrophic forgetting problem. The experiments are conducted to compare the performance of the proposed method with MLP and other methods."
SP:776d5b02b8d3a8bbcc1f52706f3887c384cb149e,"This paper studies the problem of solving ODE boundary value problems ( BVPs ), which are ordinary differential equations subject to boundary conditions. The authors propose Gauss - Markov prior ( GP prior ) for ODEs that is specifically tailored to solve BVPS. They show how the GP prior allows computing a posterior distribution over the solution in linear time, at a cost that is comparable to that of well established non - probabilistic methods. The proposed method also provides uncertainty quantification, mesh refinement, and hyperparameter adaptation for the BVP solver. They demonstrate how these practical considerations positively impact the efficiency of the scheme. Altogether, this results in a practically usable probabilistically solver that is compatible with other SBM algorithms. This work develops a class of algorithms for solving the ODE ( ODEDE - MDP - OVP - ODE ) problem ( Table 1 ). Table 2 provides a detailed summary of the proposed algorithm.   The main contributions of the paper are the following :   1. Proposes a new algorithm for the solver of the GP pre - prior and the hyperparameters of the hyper - parameter adaptation algorithm ( Table 2 ). The algorithm is shown to converge to the solution of a BVP problem asymptotically ( Figure 3 ). 2. It introduces a first - order boundary value problem, which can be transformed into higher - order problems. 3. It provides an efficient computation of ( geodesic ) distances between two points, which is relevant to several scientific applications of machine learning. 4. It proposes a second algorithm for solving BVPAs a first example, the authors consider the following example : when recovering the trajectory of a pendulum between two positions ( Figure 1 ), and obtain the output as follows. The trajectories are assumed to be ODE ÿ(t ) = −9.81 sin(y(t)) subject to the positions as boundary conditions, so the authors first obtain the position values. Then, the trajectories of the pendulum can be obtained by computing the values $ \sqrt{O}(t, y}$, and the distance between the positions $ \sigma$. The authors compute the values for $ t$ and $ y$ using the vector field f : R → R, as well as L ∈ RdL×d, t0 ∈ R,. tmax   tmax"
SP:86aac0c6b75fdc12f84bba342934865616f866d4,"This paper considers reinforcement learning in a reward - mixing Markov decision process ( MDP ), where a reward function is drawn from one of multiple possible reward models, but the identity of the chosen reward model is not revealed to the agent. The latent state space, for which the dynamics are Markovian, is not given to the policy in this MDP. The authors propose an algorithm that finds an $ \ell_2$-optimal policy after exploring an episode of the MDP, where $ M$ is the number of states and actions in the episode, and assumes no assumptions on the dynamics. This is the first efficient algorithm that does not require any assumptions in partially observed environments where the observation space is smaller than $ \sqrt{L}$. The authors study the problem of learning a near optimal policy for two reward - Mixing MDPs, and provide the first algorithm for learning a policy $ \epsilon$ for one reward and $ S$ for the other. They provide analysis techniques for efficient exploration.   The main contributions of this paper are the following :   1 ) The authors develop a method to train an agent to learn a policy in a partially observable system using reinforcement learning, where the policy is a mixture of two reward models ( one mix - up reward model and one fixed reward model ), and the learning process is episodic. The method is referred to as learning - augmented RL ( ELBO ). 2 ) It develops a method for training the policy using self - supervised learning ( self - imitation learning ). 3 ) It applies the learned policy to learning in episodic RL using imitation learning."
SP:1a3c70ae9cf2a806d603f4b9e7ca6e10b720a956,"This paper proposes Single - Cause Perturbation ( SP ), a novel two - step procedure to estimate the single - cause treatment effect for conditional average treatment ( CATE ) estimation. SP estimates the effect of interventions made on a single cause ( i.e., the variable that was intervened on at one time ) on the treatment effect of variables that depend on multiple ( multi - cause ) causes. The main contribution of this paper is to develop and develop SP that can handle the combinatorial nature of the problem, where each intervention depends on a different cause combination ( e.g., each intervention could be made on multiple variables with the same cause combinations ). The proposed SP procedure has the following steps :   1. The author proposes to augment the observational dataset with the estimated potential outcomes from SP ( assuming that the interventions are single cause ones ). 2. It performs a covariate adjustment on the augmented dataset using the parametric statistics from SP and the covariate upperbound on the dataset from SP. 3. Finally, the author performs experiments to validate the correctness of the proposed estimator.    The main contributions of the paper are the following : ( 1 ) The author develops and implements SP, which is based on the idea of single cause perturbation, and ( 2 ) It develops a parametric estimator for single cause clustering ( the second step of SP ) to capture the confounding bias of the data used in the estimation of the single cause effect ( the first step is to estimate potential outcomes of interventions with multiple ( single cause ) variables. The method is tested on a synthetic dataset augmented from SP, and compared with SP and SP. The experiments show that the proposed SP achieves better results compared to SP, SP, as well as better results for extrapolation from the synthetic dataset to a larger dataset."
SP:247bc6675cce89d51558537daf63dadb0c4307f8,"The paper proposes a multi - wavelet transform - based neural operator learning method for solving partial differential equations ( PDEs ) based on the operator map between the input space and the solution space of a PDE. This is similar to the approach of [ 1 ], [ 2 ] and [ 3 ], but the difference is that the proposed method compresses the operator ’s kernel instead of compressing the corresponding wavelet. The proposed method is based on learning the projection of the kernel onto polynomial bases, which are obtained by using the inverse multiwavelet filters. The projected kernel is trained at multiple scales derived from using repeated computation of multi wavelet transforms. This allows learning the complex dependencies at various scales and results in a resolution - independent scheme. Compared to the existing neural operator approaches, this method shows significantly higher accuracy and achieves state - of - the - art performance in a range of datasets.   The main contributions of the paper are the following :   1. A new multi - Wavelet transform based learning scheme is proposed that compresses operator's kernel using fine - grained wavelets, which is different from the previous approaches that only computes the associated operator ‘s kernel. The new method is trained using gradient descent and gradient ascent to obtain a kernel that is linearly independent of the number of wavelets. 2. This method is tested on the Korteweg-de Vries equation ( KdV ) equation, Burgers’ equation with improved accuracy ( by learning from lower - resolution data ) and the L2 error for Burgers ’ equation. The results show that this method is more numerically efficient than the other approaches. 3. The major contributions of this paper are as follows. 1. The first part of the above is key. The second part is related to the second part. The third part is the part about learning the mappings between function spaces. The last part is about learning to find the solution of a high - resolution input after learning from"
SP:1153785e6a016cfee2644952a772aa08927299b6,"This paper proposes a new method for training binary neural networks ( BNNs ) based on the Fourier frequency domain approximation ( FFDA ). The idea is to approximate the gradient of sign function in the FFDA using the combination of sine functions, namely low - frequency information of the original sign function, and high - frequency coefficients will be ignored to avoid computational overhead. The proposed approach is evaluated on several benchmark datasets and experiments on several neural network architectures. The main contributions of the paper are the following :    1. A new FFDA method is proposed for training neural networks. The authors use FFDA to estimate the sign function gradient of the FFD approximation using the sine function and the energy information from BNN activations. The method is compared with two other methods : ( 1 ) Fourier - frequency domain gradient estimator ( FFT ) and ( 2 ) Noise adaptation module into the training phase to compensate for the approximation error. The experiments show that the proposed approach outperforms the other two methods.   2. An additional noise adaptation module is included in the training to deal with the noise introduced by the high frequency coefficients of the BNN training. The results show that noise adaptation reduces the amount of overhead incurred by training the neural network. The paper also includes an appendix with detailed procedures for learning the network."
SP:33b95ea8da4d30b8e8f9d3fe3acca023d4b8d831,"This paper uses multi - area neural networks ( RNNs ) trained on neuroscience - based tasks to investigate the representation learning and inference processes of multi - Area Neural Networks ( MANDPs ) for biologically plausible multi - task computations.   The authors build upon previous work that used single - area RNN as the model for learning multivariate regularization tasks ( e.g., logistic regression ) but with neuroscience - inspired constraints and assumptions to motivate the analysis. They show that MDPs incorporating multiple areas and Dale's Law is critical for biasing the networks to learn biologically plausible solutions. They also show that output - relevant information is preferentially propagated between areas using the observability of the RNN. The main contributions of the paper are the following :   1. The authors develop a framework for understanding the representations and interactions of RNN components. This framework is based on two key ideas : ( 1 ) the importance of integrating information from different parts of the network ( i.e., information propagated from one area to another ) and ( 2 ) the role of modularity in generating representations. They use a toy example to illustrate how modularity helps the networks generate biologically plausible representations of tasks. The toy example is used to show that the task - relevant representations are generated using only a small fraction of the total number of neurons in each area and that neurons in the same area are required to generate the same amount of information. This suggests that the networks are able to efficiently and effectively generate representations of the tasks. 2. Using the toy examples, the authors derive the following conclusions : 1. First, it is well - known that task representations are sparse and sparsely - distributed, suggesting that the network is unable to fully process all the relevant information. And 2. The networks are unable to generate sufficient representations of all the tasks that are biologically plausible. The conclusion is supported by experiments that compare the representations generated by the networks using the toy example with representations from other networks that are not used for the task."
SP:db3ced65d67e3373fb3936ec50f41c8ef010bbbe,"This paper proposes a new approach to interpret saliency maps for explaining the decisions of convolutional neural networks ( CNNs ) for image classification. The authors argue that a single saliency map provides an incomplete understanding and that there are often many other maps that can explain a classification equally well. To this end, they propose to utilize a beam search algorithm to systematically search for multiple explanations for each image. They introduce structured attention graphs ( SAGs ), which compactly represent sets of attention maps for an image by visualizing how different combinations of image regions impact the confidence of a classifier computing a compact and representative SAG for visualization. They conduct a user study comparing the use of the new SAGs to traditional saliency mapping for answering comparative counterfactual questions about image classifications. Their results show that user accuracy is increased significantly when presented with SAGs compared to standard saliency mapper baselines."
SP:f2b385bfd9ada0e26aa8829214b424f58582d9f7,"This paper studies how the choice of training objective affects the transferability of the hidden representations of convolutional neural networks trained on ImageNet. The choice of loss has little effect when networks are fully fine - tuned on the new tasks, according to the authors. They find that differences among loss functions are apparent only in the last few layers of the network. They delve deeper into representations of the penultimate layer, finding that different objectives and hyperparameter combinations lead to dramatically different levels of class separation. They suggest there exists a trade - off between learning invariant features for the original task and features relevant for transfer tasks."
SP:b66b5e24f68563e2e200eda660f0dbaff53efeff,"This paper proposes a novel neural network training strategy, selective backpropagation through time ( SBTT ), to learn deep generative models of latent dynamics from data in which the set of observed variables changes at each time step. The resulting models are able to infer activity for missing samples by combining observations with learned latent dynamics. The authors test SBTT applied to sequential autoencoders and demonstrate more efficient and higher - fidelity characterization of neural population dynamics in the presence of neural activity data. They also demonstrate that performance could be further improved by using limited, highbandwidth sampling to pretrain dynamics models, and then using SBTT to adapt these models for sparsely -sampled data.   The paper is presented at the 35th Conference on Neural Information Processing Systems ( NeurIPS 2021 ) in Las Vegas. The manuscript includes the following main contributions : ( 1 ) The authors develop a spatio - temporal temporal structure of neural time series by exploiting relationships among neurons, embedded in latent low - dimensional population dynamics ; ( 2 ) They provide an avenue to significant power savings for implanted neuroelectronic interfaces that substantially outperforms the current state - of - the - art. ( 3 ) They conduct extensive experiments to validate the effectiveness of their method."
SP:3513a83806e71006b86d60b779d8bd6bb87c3546,"This paper proposes a hierarchical approach to sequence - to - sequence learning ( STS ) with quasi - synchronous grammars. The motivation is that traditional STS models, while flexible and performant, require large datasets and can fail spectacularly on benchmarks designed to test for compositional generalization. The proposed model is based on a hierarchical tree - based model, where the source and target trees are treated as latent and induced during training. The authors develop a neural parameterization of the grammar which enables parameter sharing over the combinatorial space of derivation rules without the need for manual feature engineering. They then apply this latent neural grammar to various domains ( SCAN, style transfer, small - scale machine translation ) and find that it performs as well as the state - of - the - art.   The main contributions of the paper are the following : 1 ) The authors propose a hierarchical model for STS, where each node in the target tree is transduced by a node in    the source tree. This model is more hierarchical than previous approaches to STS which typically models the local distribution over the next word with a powerful neural network that can condition on arbitrary context. 2 ) It develops a neural parametrized grammar that allows for the use of generative adversarial examples to test the robustness of the proposed model."
SP:d06fc251f2a9287f7a2236a188349628d8f39d9a,"This paper proposes a novel algorithm for the function - on - smooth - surface ( FLS ) regression analysis of Elastic Net, where the objective is to select the most functional feature from a set of scalar functions. The proposed algorithm is based on the Augmented Lagrangian ( AR ) algorithm, which has been applied successfully in the context of Group Elastic Net ( GNN ).   The main idea of the algorithm is to use AR as a scalar predictor for the feature selection step in the GNN, and then use the scalar outputs to compute the functional features from the feature vectors. This is similar to the approach of [ 1 ] and [ 2 ], but the difference is that the proposed algorithm uses the sparsity structure from AR to reduce the computational burden of the AR estimator. The paper also proposes an extension of AR to FLS, where functional features can be selected from a fixed fixed set ( instead of from all scalar vectors ). This approach is called AR - FPN ( Functional Principal Components Algorithm for Function - on Scalar Features ). The main empirical results are applied to the FLS problem on the toy dataset from the Fashion - MNIST, and compared with the baselines of two other works ( one based on FPN and another based on Gaussian Mixture Modeling – GMM )."
SP:e0b53f76f3a6b756fedd09926f9cf034f89f4a5a,"This paper presents an approach to cluster repeatedly observed marked point processes in a multi - level marked point process framework to identify potential heterogeneity in the observed data. The proposed framework is based on ES - GP ( Expectation - Solution ( ES ) algorithm combined with functional principal component analysis ( FPCA ) of point processes, which is a semi - parametric solution algorithm for predicting the distribution of points in a log - Gaussian process matrix. The authors study a matrix whose entries are marked log Gaussian Cox processes and cluster rows of such a matrix. They propose to estimate the log - gaussian processes of each entry in the matrix from the cluster of entries of the matrix if the entries are within a distance of 1, 2,.... The main contributions of the paper are as follows :   ( 1 ) A new clustering method is proposed to identify the distance of the entries in a matrix of the obtained point process matrices within each cluster. This is done by computing the distances of entries in the matrices of each cluster based on the expected distribution of their entries. ( 2 ) A mixture model is proposed for estimating the log-Gaussian processes in the obtained matrices from the observed point processes. This model consists of the following components : 1 ) The entries of each row in the dot product matrix are the same : entries 1 - D are the points in the cluster that were observed in the previous time interval ( up to time 3 hours ). The entries D - entries are the ones that were not observed during the time interval between the last timestep and the observed ( down to time 1 hour ) and the rows D-1 and D-2 are the new arrivals at time 0 ( seen from the current timesteps. ( 3 ) Each dot product is constructed by applying the ES algorithm of the observed points to rows D and rows A and D of the dot products A and E, with the entries A and A being the same in each time interval.    The main contribution of this paper is the introduction of the mixture model. The effectiveness of the proposed model is demonstrated through simulation studies and real data analyses. In particular, simulation studies are conducted to train the model using simulated data and real datasets ( e.g., MNIST, CIFNIST, Fashion - MNIST ) where the model is trained with data augmentation and fine - tuning. In addition, simulations are conducted using a custom - tuned hyperparameters on MNIST and a custom hyperparameter on the CIFAR-10 dataset. The empirical results show that the proposed approach is more robust than the baselines on both"
SP:3aa213076f3e9f9838ac654517df2fe1fca33499,"This paper proposes a meta - adaptive control framework, called Online Meta - Adaptive Control ( OMAC ), for multi - task nonlinear control with adaptive nonlinear dynamics. The framework consists of three components : ( 1 ) Meta - Control Representation Learning ( MRL ), ( 2) Meta - Learning - Theory ( MLT ), and ( 3 ) Meta Meta - Dynamic Control ( MDC ).   The key idea of MRL is to learn a shared representation of the dynamics of the system under the assumption that the dynamics can be well captured with MRL. The authors integrate MRL with existing methods from control theory in order to arrive at a unified framework that yields control - theoretic and learning - theoretically guarantees. They provide instantiations of the MRL - MLT framework under various assumptions to demonstrate that the guarantees are the first non - asymmetric convergence of the two components leading to the first MTL - CE guarantee for adaptive non - linear control with the assumed assumption that MRL can be integrated with deep representation learning. They also provide the first instantiation of the guarantees for the meta - learning - theory based approach under different assumptions of the adversarial and environment - dependent dynamics. They compare the performance of the proposed framework with the one based on MRL and MDC and show that under some conditions, MRL outperforms MDC significantly, leading to faster convergence than the alternative methods of adaptive control approaches that do not learn the shared representation. Finally, they provide a set of experiments to demonstrate the performance gains of their framework compared to MRL, showing that MTL is more stable than MRL in terms."
SP:cb274c93a169b199ea09120ca02105a3f16b31c5,"This paper studies training neural networks with certifiable robustness with interval bound propagation ( IBP ) training with state - of - the - art pretrained methods such as CROWN - IBP and IBP - CROWN with per - batch training complexity similar to standard neural network training, using a long warmup schedule with hundreds or thousands epochs to reach SOTA performance. The authors identify two important issues in existing methods, namely exploded bounds at initialization, and the imbalance in ReLU activation states and improve IBP training. To mitigate these issues and conduct faster certified training with shorter warmup schedules, they propose three improvements based on IBP : 1 ) They derive a new weight initialization method for IBP ; 2 ) They propose to fully add Batch Normalization ( BN ) to each layer in the model, since they find BN can reduce the imbalance between BN and BN - BN training ( where BN is used during training ), and 3 ) They also design a design regularization to explicitly tighten certified bounds and balance ReLU activations.    The main contributions of this paper are the following :   1 ) This paper identifies the discrepancy between IBP pretraining and CROWN pretraining, and shows that CROWN training schedules need to be changed to accommodate IBP methods with longer warmups. This is despite the fact that SOTA methods including CROWN use a longer warmup with more epochs. 2 ) The authors also propose a method to obtain 65.03% error on CIFAR-10 that is lower than the one used in CROWN that is used in IBP. 3 ) This method is tested on TinyImageNet and it outperforms SOTA by achieving accuracy of 82.36% verified error on the network with very short training schedules using very short epochs, outperforming literature SOTA trained with hundreds   under the same network architecture. 4 ) These three improvements are tested on two networks and compared with each other."
SP:18ffeb199a670fb2b1f4417b8653479001944dab,"This paper proposes a novel change point detection method, Huber - ε - contamination ( CDP ), for the robust detection of spurious change point occurrence detection. CDP is motivated by the observation that there have been exponentially growing attacks from adversaries who may pose systematic contamination on data to create spurious change points or disguise true change points. To counter this threat, the authors propose to use the simplest and most natural way to detect change points, matching the minimax lower bound under certain conditions, which allows the contamination distributions to be different at each time point. This detection boundary is a function of the authors ’ interpretation of the definition of the contamination proportion under terms of the Haudber - $ \epsilon$-contamination framework ( Liu et al., 2021 ). The authors derive a new minimax - lower bound of $ 2.5 $ per sqrt(L/L)$ for each sample from the distribution of heavy - tailed noise under the formulation of the adversarial attacks formulated by the authors. They conduct extensive numerical experiments to demonstrate the effectiveness of the proposed CDP against state - of - the - art methods and model - free baselines. They also compare the proposed method with a few baselines in terms of accuracy, sensitivity, and cost. The experiments demonstrate that CDP significantly outperforms other methods and demonstrates a transition from naive to robust CDP detection in some areas.    The main contributions of this paper are the following : ( 1 ) A novel approach to the robust and theoretically justified CDP problem ; ( 2 ) A new detection boundary for the simple CDP proposed by using the aforementioned Haud ́� - $\epsilent$ - contaminants framework ; ( 3 ) Extensive numerical experiments comparing the performance of CDP and baselines to other methods in the same and different regions ; ( 4 ) An analysis of the effect of different sampling strategies on CDP performance ; and ( 5 ) Comparisons with other methods on different regions of the literature."
SP:d03617b5fc446768809cf015c9234b0c9386a690,"This paper studies stochastic gradient descent ( SGD ) and batch Gradient Descent ( GD ) for empirical learning of a differentiable model or neural network. The authors compare the empirical losses of SGD and GD on the population loss, and argue that their ability to go beyond that depends on the precision ρ of the gradient calculations relative to the minibatch size b ( for SGD ; see Figure 2 ) and sample size m ( for GD ). They show that SGD can go beyond SQ learning and simulate any sample - based learning algorithm and thus its learning power is equivalent to that of PAC learning. On the other hand, GD can simulate PAC learning regardless of the mini - batch size ( Figure 3 ). Finally, with enough precision ( Figure 4 ), the authors show that GD can also simulate any parametric learning algorithm based on m samples.   The main contributions of this paper are the following :    1. This paper studies the empirical loss of a neural network trained with differentiable, parameter - agnostic, parametric Gaussians trained with parametric neural networks trained with Gaussian Mixture Model ( GMM ), which is a parametric model of the neural network from Gaussian Population Lipschitz ( PML ). 2. It compares the empirical and parametric losses of the model from the perspective of learning via SGD vs GD. 3. It shows that the precision of the gradients used in SGD is better than that of GD and thus SGD has more power to simulate learning."
SP:1de2864fe2f53e25596a9bd2c61e2048e79296f6,"This paper studies the problem of generating discrete data from a probabilistic model, as if sampled from a model probability distribution, to estimate the Wasserstein distance between the true distribution and the uniform distribution over the points corresponding to the atoms in the model distribution. The authors show that in most cases, a modified version of Lloyd ’s algorithm ( in which Voronoi cells are replaced by Power cells ) that generates the discrete data, the distribution converges to a uniform distribution with an error term depending on the distance between Dirac masses in the discrete distribution. This is surprising because, due to the non - convex nature of the problem, as well as the existence of spurious critical points, of spurious errors.   The authors provide explicit estimates for the convergence of this Lloyd - type algorithm, starting from a cloud of points that are sufficiently far from each other ( starting from an point cloud that is evenly distributed in the ambient space ). Similar estimates can be deduced for the corresponding gradient descent. The main contribution of this paper is to show that under certain assumptions on the distribution ( e.g., that the distribution is uniform and that the distance minimizes the distance to the distribution with respect to $ \mathbb{R}$ ), the min - max - probability distribution convergence results in configurations with small Wassersteins errors. In particular, the authors consider a setting in which the distribution of atoms is atom - based, and point cloud $ \theta$ is assumed to be isotropic ( i.e., the atoms are atoms with the same number of bases as the corresponding dot product probability distribution of bases ). This assumption results in a distribution convergence bound that is $ \sqrt{Omega}$, where $ Omega \leq(Omega)$ is a weighted sum of $ \Delta_Omega, $ \Phi$-C_{K}$ where $ K \in Omega$ is the unit cell size and $ K$ the number of units of power cells $ K$. The authors also consider an alternate setting in the paper in which there is no atom - basis uniform distribution and there are atoms - based distribution with and without dot product. The difference between the two distributions is the difference in the cost between the cost of energy ( $ \eta$ ) of each atom - base and the energy of the unit of the atom - bases of the cloud of bases. The convergence bound can be thought of as $ \epsilon$ ( \lambda_{K}\Phi\mid{K}\)-Omega$. The paper shows that under this setting, the expected distribution of the expected value of energy for a dot product of atoms with a given cloud of"
SP:c3d364aeee55230a436c3ce4e8dc8310ee73959e,"The paper proposes a dynamic feature transform, relational self - attention ( RSA ), for video understanding where correspondence relations in space and time, i.e. motion information, are crucial for effective representation. The authors argue that the stationary representations provided by the existing dynamic transforms, including self - attentive blocks, are limited in the video understanding setting where spatio - temporal relations in time and space ( e.g., when viewing a video ) are represented by motion information. To address this limitation, the authors propose to dynamically generate relational kernels by generating relational kernels and aggregating features from different contexts. They then propose to use these generated relational kernels to represent the rich features in videos by generating, on average, two types of features, one based on the sender and the receiver ( in this case, the sender represents the sender as a set of spatiotemporal features ), and using the receiver as a feature extractor to aggregate the features from the two different types of contexts ( sender and receiver ). This relational feature transform is called RSA after the rich structure of the relations that it leverages. They evaluate RSA on various benchmarks for video action recognition, such as Something-Something-V1&V2, Diving48, and FineGym, and show that it substantially outperforms convolution and self - attentions in terms of achieving the state of the art on the standard motion - based benchmarks."
SP:2c2530069d5cab485629090243da464d107feadd,"This paper studies the infinite - width regime of gradient descent mean field training for multilayer neural networks, in which the learning dynamics are shown to be closely tracked by the mean field limit. Previous works have studied the infinite width regime in the case of shallow networks, where previous works employ heavily technical notions or additional formulation ideas amenable only to the shallow setting. The main difficulty in finding a formulation that captures the stochastic dependency across not only time but also depth in the multilayers case has been, with the main difficulty being, to capture both time and depth. In this work, the authors study the fluctuation around this infinite width limit that is expected from a large - width expansion to the next order, which they term the "" random fluctuation "".   The main contribution of this paper is to formulate the mean - field limit in terms of the network depth and to derive a system of dynamical equations, called the second - order mean field ; the authors show that this captures the limiting fluctuation distribution. They demonstrate through the framework the complex interaction among neurons in this second-order mean field, the non - linear time evolution with cross - layer dependency and the limit theorem, which relate quantitatively this limit to the limit of the expansion realized by large -width networks. The authors then apply the result to training networks with a loss function that is not necessarily convex, and obtain a stability property that, when applied to a solution with “minimal fluctuation ” ( vanishing fluctuation ) in the learned output function, persists even after the network has been initialized at or has converged ( sufficientlyly fast ) to a global optimum. This extends a similar phenomenon previously shown only for shallow networks with squared loss in the empirical risk minimization setting to multilayered networks with loss functions that are not always convex. They also demonstrate a nonlinear time evolution inherent in the limit that they study, and extend a similar result from the convex setting to networks that have not necessarily a convex loss."
SP:a3d927854d9d7fd39b8d05a79666810d585d5062,"The paper proposes a framework for learning irreversible reversible dynamical systems from a data - driven model ( consisting of a metaplectic dynamical system ) where energy and entropy are guaranteed to be conserved and nondecreasing, respectively. This framework is based on the Poisson brackets of Hamiltonian / Lagrangian mechanics which can be cast in terms of dissipative chaotic systems and obtain several mimetic properties related to thermodynamic consistency, including satisfaction of the first and second laws of thermodynamics and a fluctuation dissipation theorem. The authors then describe a method similar to neural ODEs ( NODEs ) for generating the data from such a system using a Gaussian Process Model ( GMM ), but instead of using the a priori known universal differential equation ( UDE ) model, they assume a more inductive bias that lies somewhere between that of an ODE and a black - box model with a known model form, which they term the "" structure preserving "" Hamiltonian "". They describe a procedure similar to Gaussian ODE for generating such a GMM from data modeled from a metriplectic system and train the GMM using a loss function similar to that used in NODE to approximate the Hamiltonian.    The authors show that their method is robust to perturbations in the data $ \epsilon$ which cause the temperature $ T$ to exponentially diverge and provide long - term forecasting information whose latent dimension is governed by the dissipative structure, governed by order - modulated noise ( the "" fly "" ). They provide benchmarks for dissipative systems where they show learned dynamics are better able to generalize better than either "" black box "" or penalty - based models, and in some cases worse than no dynamics at all. They also provide empirical evidence that the learned dissipative system is more stable and more robust to noise than either black box model. The method is evaluated for both coarse - series and fine - graining problems where they have access to coarse - scale data from coarse - range control tasks where they are also able to account for the entropic effects which emerge from the structure - preserving treatment of dissipation which is critical for robotic control. Finally, they evaluate their method for long - time - series forecasting problems where there is no access to time - scale representations of the data and the first principles principles of structure preserving first principles can be first principles from the second principles that can be derived from first principles. The empirical results demonstrate that the proposed method outperforms both black box and penalty based models in most cases. The paper also provides a theoretical justification for the robustness and the empirical evidence for the better generalization of the learned dynamics."
SP:32e8e83e06b1e9a4dad761334d5947c91bfd1853,"This paper proposes a sample selection - based algorithm for fair and robust training of Trustworthy AI models. The idea is that the robustness is about learning from unobserved data and the fairness is about obtaining an unbiased model. To achieve this goal, the authors propose a corruption - free sample selection problem, which is formulated as a combinatorial optimization problem, and they propose a greedy algorithm to solve it.   The main contributions of this paper are the following :   1. The authors propose an unbiased sample selection algorithm for the unbiased selection of samples in the presence of data corruption. Theoretically, this is a reasonable assumption as it is well known that the data used to train the model is likely to be corrupted. Theorem 1. shows that the probability of the corruption is proportional to the magnitude of the bias of the model and the number of the corrupted samples. The main motivation behind this is that even if the probability is low, it will go up as the training goes on and the data becomes more corrupted as more samples are generated. The paper proposes to use this probability in order to increase the total number of samples to avoid the bias going up as many of the previously generated samples become too many. The proposed algorithm, called Aggressive Sample Selection ( Agg ), is motivated by the observation that greedy algorithms solving the optimization problem are NP - hard ; hence, the main idea is to make the gradient descent descent as efficient as possible so that the final gradient descent only needs to pass through the last few steps of the problem in order for the samples to be chosen that are not affected by the bias ( the last two steps being the hardest ones ). 2. They show empirically that Agg is compatible with the state - of - the - art training algorithm for robust and fair pretraining, and that it obtains fairness and robustness that are better than or comparable to that obtained by Agatha ( Zhang et al., 2019 ). 3. They also show that Agg relies on the same set of assumptions as Ag, but the differences between Ag and Ag are subtle and can be explained away using the difference between the assumptions of Ag and the assumptions in the case of robust and fairness. 4. They discuss the trade - off between robustness and fairness in terms, and argue that Ag is more sensitive to the assumptions than Ag on the robust data than Ag. 5. Finally, they discuss the advantages and drawbacks of Agg."
SP:991127729bf067fe27fdd7ed360aab39e4df5921,"This paper studies the relationship between Gaussian prior priors and activation functions of Bayesian neural networks ( BNNs ). It is well - known that Gaussian priors are biased in the sense that they are predicated on the prior of the weights of a neural network, i.e., ‘ know what they do not know ’. This paper proposes to introduce inductive biases in the function space of the BNN by introducing priors that depend on the activation function of the network. This is similar to what is done in Fourier activation theory, but instead of focusing on the sinusoidal activation, they extend it to also include triangular wave and periodic ReLU activation functions. They show that these functions obtain comparable performance for in - domain data and capture sensitivity to perturbed inputs in deep neural networks for out - of - domain detection.   The main contributions of this paper are the following :   1. The authors introduce Gaussian regularization priors for the activation of the Bayesian BNN, which they term periodic activation functions ( periodic reLU activations ). They use the term ‘ periodic activation ’ to refer to a type of activation that is activated according to the time dilation of the input ( as in the case of triangular wave activation ), which is different from the more commonly used activation function ( periodic Fourier ). This means that the regularization is applied only to functions that activate when the input changes ( e.g., the triangular wave ) is not present in the original input. The regularization term can be thought of as a kind of ‘ regularization ’ that is used to make the model ‘ aware ‘ of what it knows ’ about the function ‘ it ’s trying to predict. This kind of regularization removes the inductive bias of the prior and replaces it with an expectation that the function is invariant to the input. This expectation can be phrased as a ‘ knowledge graph ’, which refers to a list of all possible activations that can be used to predict the function ( the parameters of the neural network ). In other words, this expectation does not depend on any particular activation function, but is simply the average of the previous and all activations of the function. The idea is that this regularization could lead to a model that ‘knows ’ ( rather than inferring all the activation functions ‘ what the input ’ should know about a particular function ). 2. They introduce regularization terms that correspond to regularization mechanisms that activate the regularized function at time d ( this is called ‘ time d ’ in the paper, but there is no need for these terms in the"
SP:d61a2aecfea4612c473b4e6fd41f3dc2fcbb04a1,"This paper proposes a method to provide feedback for learning Markov decision processes ( MDPs ) by autonomous agent using an autoregressive ( AR ) model. The idea is that interactive computer programs with user interaction and complex dynamic systems, such as mouse based games, require feedback mechanisms that are not possible with traditional unit tests. The paper proposes to train an agent to collect MDP feedback for each MDP by classifying the dynamics and reward model of the input MDP based on the agent ’s actions and the dynamics of the MDP from the input trajectories. The main idea is to train the agent in a way that allows a classifier to determine under reasonable reasonable generalization, under reasonable expectations, if the dynamics, reward model and dynamics under the assumed MDP are correct or broken, then provide feedback to the agent to determine whether the assumed dynamics and rewards are correct / broken.    The main contributions of this paper are the following :   ( 1 ) The paper develops and implements an automatic feedback system ( ARC ) based on a Markov Decision Processes classifier that is trained using a dataset of 7.11 m and274 m student submissions to a single assignment with hand -coded bug labels to support future research ; and ( 2 ) Develops a method for training an autonomous AR model using a cooperative objective between an agent and an AR model, which allows the AR model to sample trajectories from a set of trajectories under the assumption that the trajectories are consistent with each other. The method is evaluated empirically using a toy example. The experiments show that the method outperforms the baselines of baselines, both in terms when the ARC is used for training the model."
SP:daf99ad91613d6e11b13315ccbd1bbe25094ae4b,"This paper proposes Represent And Mimic ( RAMi ), a framework for training Deep Reinforcement Learning ( DRL ) models that uses a disentangled latent representation to capture object and feature variation independent of the objects and a mimic tree to extract the causal impact from the latent features. The key idea of RAMi is to use the high - level features of the latent representation that are not typically visualized in previous DRL methods such as superpixels, attentions, or saliency maps to explain a low - level feature of a DRL model by visualizing the importance of the input features. To achieve this goal, the authors derive a novel Minimum Description Length ( MDL ) objective based on the Information Bottleneck ( IB ) principle. Based on this objective, they describe a Monte Carlo Regression Tree Search ( MCRTS ) algorithm that explores different splits to find the IB - optimal mimic tree. They demonstrate the interpretability of their mimic tree by showing latent traversals, decision rules, causal impacts, and human evaluation results. Experiments show that our mimic tree achieves strong approximation performance with significantly fewer nodes than the baseline models.    The main contributions of this paper are the following :   1 ) An approach to train deep reinforcement learning models by using a learned latent representation and a learned mimic tree ; 2 ) A method to train DRL action values using a MDP and a MCRT algorithm ; 3 ) A set of experimental results to demonstrate the fidelity of the methods used for training DRL models."
SP:84560de78af979354fff83d1370d8675c1e9191f,"The paper proposes a Bayesian framework, called Gaussian latent information martingale, or GLIM, for modeling the structure of dynamic predictions over time. Given a set of Gaussian distributions $ \mathbb R^2 $, the authors propose to model the distribution of posterior probability paths over the set of possible outcomes $ P(Y|x)=\sum_i\theta(x)$, where P(y|x ) is the expected value of $ x$ that will be experienced by the recipient over the next several days.    The authors argue that this approach preserves important properties of the Gaussian distribution, such as the Martingale structure, of probability paths, and that it preserves a appropriate amount of volatility and quantifies future uncertainties around probability paths. They show that GLIM outperforms three popular baseline methods, producing better estimated posterior probability path distributions measured by three different metrics. The authors also study GLIM with and without assumptions, assuming that the predictions update according to a latent process of information flow, which is inferred from historical data. The experiments compare the proposed method with two other Bayesian methods for time series analysis, one with a time - series analysis method and one with an unsupervised method. They compare the performance of all three methods and find that the method with assumptions produces better performances than the other two methods, especially when the assumptions on the posterior distribution are updated according to the new information arriving in the form of $ \text{L}$ and $ \theta$.   Overall, the paper is well - written and well - structured, and the results are interesting and convincing."
SP:0c4bfb44e0a353256692d5e5ae96f65c1a14363d,"This paper studies the problem of active exploration with fixed confidence in stochastic bandit environments, where the goal of the learner is to answer a query about the environment with a given level of certainty while minimizing her sampling budget. The authors propose Frank -Wolfe - based Sampling ( FWS ), a simple algorithm whose sample complexity matches the lower bounds for a wide class of pure exploration problems. The algorithm is computationally efficient as, to learn and track the optimal proportion of arm draws an Oracle algorithm would apply, it relies on a single iteration of Frank - Wolfe algorithm applied to the lower - bound optimization problem applied to FWS to various pure exploration tasks. The experiments demonstrate that FWS is competitive compared to state - of - the - art algorithms for learning and exploration.   The main contributions of this paper are the following :   ( 1 ) A new algorithm, FWS - ELBO, is proposed, based on the Frank - Wolfe algorithm. The main difference between FWS and other algorithms is the introduction of instance - specific lower bounds on the expected sample complexity that, when bounded out, reveal the optimal proportions of arm draw an Oracle method would apply to solve the problem. ( 2 ) A set of assumptions on the assumptions of the environment, including the assumption that the environment is composed of modular structures, are introduced, which, although not directly related to the learning problem, may be instrumental in the design of efficient learning algorithms. The assumption is that the structures are modular and modularity is a good property to have on the environment. ( 3 ) It is shown that the maximum and minimum arm draw sizes for FWS are upper and lower bounds of the expected log - likelihood. ( 4 ) The main result of the paper is an agreement between the lower bound on the max - pool size of FWS ( the maximum arm draw size ) and the upper bound on expected sample size of ELBO. ( 5 ) The experiments show that the FWS algorithm is competitive in terms of computation cost for learning compared to other algorithms, though it is not as computationally tractable as some of the other algorithms."
SP:0947a0f08fba53d3c8af9b78dd64e6e10fc73e32,"This paper proposes a new method for optimizing combinatorial spaces ( e.g. sequences, trees, and graphs ) using expensive black - box function evaluations using a learned surrogate model. The proposed method is based on a reduction to BO over continuous spaces by learning a latent representation of structures using deep generative models ( DGMs ). The selected input from the continuous space is decoded into a discrete structure for performing function evaluation. However, the surrogate model over the latent space only uses the information learned by the DGM, which may not have the desired inductive bias to approximate the target black -box function. To overcome this drawback, this paper proposes to use a principled approach referred as LADDER ( Labourer - ADder ) to define a novel structure -coupled kernel that explicitly integrates the structural information from decoded structures with the learned latent space representation for better surrogate modeling. The authors conduct experiments on real - world benchmarks show that LADder significantly improves over the BO over latent space method, and performs better or similar to state - of - the - art methods.   The main contributions of this paper are the following :   1 ) The authors propose a new approach to learn a learned latent representation from structures using DGM to perform function evaluations. This approach is referred to as DAGM ( Deep Generative Model for Learning Deep Structures ). 2 ) It adopts the DAGMs representation for learning the latent representation and uses it to design a surrogate model to learn the target function evaluation using the learned DGM. 3 ) It is important to distinguish between the learned surrogate models and the original DGM ( DGM ). 4 ) The key idea in each step of the authors ‘ contribution is to explicitly integrate the information from"
SP:37adabdc6615c5199a481553c8ccc06d57363614,"This paper studies the regret minimization in finite - horizon Markov Decision Processes ( MDPs ) with linear reward functions. It first analyzes the representation of state - action value functions in regret minimisation with linear structure, and derive a necessary condition to achieve constant regret in any MDP that has linear reward function. This condition is universally spanning optimal features ( UN ISOFT ), which encompasses the well - known setting of low - rank MDP, zero inherent Bellman error ( also known as the Bellman closure assumption ). The paper then demonstrates that this condition is sufficient for two classes of problems by deriving a constant regret bound for two optimistic algorithms : LSVI - UCB and ELEANOR. Finally, it proposes an algorithm for representation selection, and shows that it achieves constant regret when one of the given representations, or a suitable combination of them, satisfies the UN ISO FT condition."
SP:92566b664ab2f6ee9b73f29327aeef85d14ecf60,"This paper proposes a differentiable contact model to enforce energy conservation in the learned dynamics by encoding Lagrangian or Hamiltonian dynamics into the neural network architecture. The contact model captures contact mechanics : frictionless / frictional, as well as elastic /inelastic contact. This model can accommodate inequality constraints, such as limits on the joint angles. The proposed contact model extends the scope of Lagrangeian and Hamiltonian neural networks by allowing simultaneous learning of contact and system properties. The authors demonstrate this framework on a series of challenging 2D and 3D physical systems with different coefficients of restitution and friction. The learned dynamics can be used as a physics simulator for downstream gradient - based optimization tasks.    The main contributions of this paper are the following :   1 ) The authors introduce a contact model that can capture contact mechanics, which can accommodate frictionless or elastic / elastic contact. 2 ) This model is compatible with two types of distributions ( e.g., frictionless $ L$ and elastic $ F$$ ), and 3 ) It is possible to extend the learning dynamics of the contact model in two differentiable distributions, one of which is based on the frictionless distribution and the other one on the elastic distribution. 3 ) Using the learned learned dynamics, the authors demonstrate that they can learn a set of physical systems ( D3D, D4D, and D5D ) with different coefficient of friction and coefficient of elasticity under the assumptions. The experimental results demonstrate that this contact model can learn more physical systems than previous approaches that are based on differential equations. 4 ) The proposed in this paper can learn the same number of states as previous approaches, which is claimed to enforce discontinuity in the states and introduce discontinuities in the trajectories. However, in fact that most physical systems involve contacts and collisions, which introduce discontinuousities in states. 5 ) This paper shows that the proposed contact contact model is able to learn more states than existing approaches that use differential equations that encode state - state interactions."
SP:82d59a3609dfd458f90f23d4e477c8b497e9dc18,"This paper analyzes the effect of stochastic training on the Lipschitz constant of the parameter trajectories of deep neural networks trained with Benevolent Training Hypothesis ( BTH ), a theory that claims that the training dynamics of neural networks can be used to infer the complexity of the function a neural network is learning, which can then be deduced from its training dynamics. The paper proposes to use BTH to investigate the impact of training dynamics on the parameter trajectory of the NN ’s parameter interactions with the input space. The main idea of the paper is to use the BTH principle that the behavior of the training procedure can be interpreted as a good indicator of the robustness of the network to perturbations to the inputs that are introduced during training. To this end, the paper proposes a series of experiments where it is shown that the parameters of NNs trained with BTH have bounded trajectories in different regions of input space that are far from any training point, as well as trajectories that are longer, more variable, and more bounded in regions that are closer to the training data. The experiments are conducted on MNIST, Fashion - MNIST and Fashion - CIFAR-10, MNIST with MNIST - X - Factor, and MNIST-FP103 trained with a mixture of BTH and BTH with Dropout implies a training - implies - dropout training ( where BTH is used to train the network with a training distribution that is independent of the distribution of the dropout parameters ). The results show that BTH does indeed lead to more robustness in general, but that it can be improved with additional training ( e.g., by training networks that are more complex networks with longer trajectories, more variance in the parameters, and by using BTH - enhanced training distributions."
SP:9b329c915fa8d4045c167c9df37a49ee314d190e,"This paper proposes a polynomial - time algorithm for distribution - independent PAC learning of halfspaces in the Massart noise model using a Forster transform. The authors show that any distribution can be efficiently decomposed as a disjoint mixture of few distributions for which there exist Forster transforms exists and can be computed efficiently. The main application of this result is as the main contribution of the paper. The algorithm is called Polynomial PAC Learning ( PAC - HAL ) and it is a distance learning algorithm for the noise model with strongly polynomials sample complexity, independent of the bit complexity of the examples. Previous algorithms for this learning problem incurred sample complexity scaling polynomanically with bit complexity, even though such a dependence is not information - theoretically necessary.   The main contributions of this paper are as follows :   1 ) The authors propose the first PAC learning algorithm with a significantly higher sample complexity than the one used in the previous algorithms ( PAC2 ), named after the fact that it is the first algorithm to learn representations of the input distribution from the output distribution. 2 ) It is shown that the distance between any two distributions can be learned efficiently via PAC if the distances between them is at most one-to -one. 3 ) The samples used for the PAC learning are obtained by first computing the distances from the input to the outputs of each input distribution, and then computing the distance again using the output of the corresponding output distribution as a function of the samples from the outputs. 4 ) The sample used for calculating distances is obtained by computing the average distance between the input and output of each output distribution, which is the product of the average distances between the output distributions of the two distributions. 5 ) The algorithm can also be used to compute distances between two distributions when the samples are obtained from a distribution with high probability ( probability ) and low probability ( low probability ) of the output from the distribution of the distribution from which the samples come from."
SP:e5229305af00067ae2dbabd903e585964aec8928,"This paper presents a new adversarial attack method for graph neural networks ( GNNs ), a class of models that are vulnerable to adversarial attacks on node - level graph classification tasks. The authors propose a Bayesian optimisation - based attack method that combines black - box, query - efficient and parsimonious attacks, with the aim to reduce the number of queries required by the adversary. The proposed method is applied on a range of graph - based learning tasks with varying graph properties, constraints and modes of attack. The main contributions are as follows :   - First, the authors develop and validate the adversarial samples produced by the proposed method, which are used to train the attack model ( Bayesian Optimisation - Based Adversarial Attacks ). The samples are split into three equal chunks ( $ L$, $ R$ and $ \mathcal{O}$ ) depending on the type of attack ( e.g., black box attack where the target node is attacked first and the query - based one afterwards ). These chunks are used for training the target nodes ( $ l$, r$ and p://www.biorxiv.org/abs/content/early/2018/06/29/1590300 ). - The authors validate the effectiveness and flexibility of the proposed attack method ( with respect to the perturbation modes ) on a wide range of GNN classification tasks ( node level, graph - level and node level ).    The authors conduct an in - depth analysis of the generated queries for the three types of attacks ( $ \theta$ for node level attacks, $ \text{L}$ for pNets and $ pN$ for graph level attacks with and without black box queries and show that the queries are significantly more efficient than the queries generated by the other two attack methods. They also provide a detailed explanation of the differences between the three attack methods in terms of the importance of the different query types and show the authors “ balance ” between query complexity and effectiveness of the attacks. Finally, they provide an explanation for the perplexity of the black box attacks and explain the rationale for the choice of query types in the Bayesian optimization approach, which they argue is necessary for improving the performance of their method."
SP:4999e5664383066fdacd14be6242c7b83f85f3dd,"This paper studies the problem of online learning with label distribution shift adaptation, where the test - time label distribution is continually changing and the model must dynamically adapt to it without observing the true label distribution. The authors propose two adaptation algorithms inspired by classical online learning techniques such as Follow The Leader ( FTL ) and Online Gradient Descent ( OGD ) and derive their regret bounds. They empirically verify their findings under both simulated and real world label distribution shifts and show that OGD is particularly effective and robust to a variety of challenging label shift scenarios.   The main contribution of this paper is to propose an online learning algorithm based on FTL and OGD that can be applied to the setting of label shift adaptation in the simulated online learning setting where the distribution of the labels during test time is not known. The main idea of the algorithm is to firstly use FTL to estimate the expected test loss from the FTL - based online learning algorithms and then apply the modified version of the loss estimator from FTL in the real world to the online setting to derive the regret bounds of the proposed algorithm, which can then be used to optimize the model in the offline setting. The proposed algorithm is shown to outperform FTL on four out of five label shift tasks. The experiments are conducted on both synthetic and real - world data, with varying number of labels ( e.g., text - to - text, images, videos, question - answer ). The method is applied to both online and offline tasks and the results are compared favourably across both."
SP:806515ae07fb1c9d02773592005d53d4158ef102,"This paper proposes a method for detecting and localizing gradual changes in the distribution of a sequence of time - ordered observations. The goal is to avoid the simpler abrupt setting, which assumes discontinuity jump in distribution, and is unrealistic for some applied settings. The main contribution is a general method that does not require a specific data generating model, a particular data type, or prior knowledge about which features of the distribution are subject to change. Under relaxed assumptions, the proposed method possesses theoretical guarantees for both detection and localization of gradual changes.   The main contributions are the following contributions :   1 ) A general method to detect and localize gradual changes of a set of observations that has been collected over a long period of time. This is different from the abrupt setting where discontinuity jumps are assumed during the collected time steps. The assumption is that the data does not tend to diverge significantly during this time step. 2 ) A method to train such a model that is able to detect gradual changes without any prior knowledge of which features are most likely to be affected by a change in distribution of the observations. 3 ) A set of assumptions under which the method is robust to changes in distribution that do not affect the training distribution ( e.g., data distribution does not shift significantly between training and test sets ; and 4 ) A procedure for training the model under the assumption that the training data is invariant to the distribution changes ( assuming that the distribution does n’t shift from training to test set during training ), and the localization procedure that is robustness to the new data distribution ( assuming the data is stable and the training set is stable ; and 5 ) Theoretical guarantees for detection of the changes are the same as those for localization of abrupt changes under the same assumptions."
SP:7a3c8a7b17ecab19361d36e1d3d73fa35b71214c,"This paper proposes a biologically plausible online neural network ( ICA neural network ) from which to construct a model of the neural architecture and the synaptic learning rules of a biological circuit from data and parameters present in the vicinity of a synapse. To construct such a model, the paper requires that the following conditions are met :   ( 1 ) The model is based on ICA ( Liu et al., 2021 ), which is an online model of a neural circuit from which data samples are streamed one at a time without storing any significant fraction of the data in memory ; ( 2 ) The parameters of the ICA Neural Network ( NN ) used to train it satisfy at least one of the above two conditions ; ( 3 ) The update of the weight of the synapses corresponding to the parameters of ICA NN is local ( i.e., it depends only on the parameters present at the time of the update ).    The authors then propose a novel objective function for ICA ICA, called BioSynaptic Weight Update ( BWE ), from which they derive biologically plausible parameters from which ICA can be replaced by biologically plausible NN. They define this objective function as the following : 1. The input to the neural network should be biologically plausible such that it satisfies the two conditions above ; 2. The data samples should be generated on the fly using a neural network that computes the sources from the data samples and parameters provided by the input at time of update ; and 3. The weight update should be local so that it only depends on parameters present during the update. The authors argue that biological plausibly derives the parameters from ICA that satisfies all three conditions. Based on these conditions, the authors then devise an online algorithm to approximate the functions of biologically plausible ICA using data streaming and parameter estimation. They describe their algorithm in detail and demonstrate that it is computationally tractable. The paper is well - written and well - researched. The major weakness is that the authors do not provide any empirical evidence that the proposed method is biologically plausible. Also, they do not compare their algorithm to ICA or other state - of - the - art ICA methods and claim to beat them only when the cost of the method is $ \epsilon$ per neuron is less than $ 1.0$. The major / minor difference between their proposed method and ICA is that ICA costs $ 0.05   less per neuron but their method uses the same number of neurons ( $ 1 per neuron instead of $ 2.0 $, and they claim to be able to achieve results comparable or better."
SP:22f8b517a3df65144412938f5891c463d7bae0ab,"This paper studies the problem of understanding the structure of the space of solutions in neural networks operating under the implicit assumption that the solutions obtained by neural networks for a given task are universal. This is in contrast to existing work in neuroscience and machine learning which assumes that the strategies and strategies used to achieve a goal depend on the set of solutions that are easy to obtain. This paper presents a simple two - neuron network trained with supervised learning ( RNNs ) on a task that leads to multiple solutions, and traces the solutions back to the network's connectivity with the task via a graph representation of the dynamics of the network. Using this representation, the authors propose to partition the solutions to each task into a handful of types and show that neural features can partially predict them. They also propose a method to relate extrapolation patterns of learned networks to specific dynamical objects and effective algorithms found by the networks. Taken together, the results shed light on the concept of the Space of Solutions and its uses both in Machine learning and in Neuroscience to interpret behavioral trajectories.    The authors first study three neuroscience - inspired tasks. For each task, they find a rich set of possible solutions that can be found directly in the neural activity of the networks involved. Then they test the network ’s ability to extrapolate, as a perturbation to a system often reveals hidden structure that can reveal structure. The experiments compare the performance of the trained networks with two different learning algorithms, one based on supervised learning and another based on unsupervised learning. The results show that the network outperforms the other on both tasks, especially in the case where the network is not fully trained for the task."
SP:9b08a0f547ead3b59077a43b1052c6d46a0730f6,"This paper proposes Arbitrary Conditioning with Energy ( ACE ), a conditional density estimation method for unsupervised learning ( un - supervised learning ) that aims to model any possible conditional distribution over a set of covariates over some unobserved features xu and observed features xo using a joint distribution p(xu | xo ), where the covariates are assumed to be learned from some prior distribution. The main difference between ACE and prior methods for conditional density estimations is that prior methods usually consider joint distributions, while ACE considers all possible subsets of observed features and possible distributions of features obtained from the joint distribution, which is of limited utility in practical situations. To this end, the authors propose a method that can simultaneously estimate the distribution p(\xu|xo ) for all possible subets of unobserved factors xu, for which it is possible to obtain parametric estimates of the expected values xo for both the observed features. To achieve this, the estimator is parametrized with a highly expressive energy function, such that the energy function is limited to only one - dimensional conditionals, while the parametrization of the densities is expressive enough to allow for learning two - dimensional conditionsals ( where more complex distributions can be recovered during inference ). The method is evaluated empirically on MNIST, CIFAR-10, Fashion MNIST and Fashion - MNIST+E, and compared with two prior methods ( DenseNet and DenseMSE ), with the goal being to obtain an approach that is both simpler and more robust to changes in the environment. The experiments compare the proposed by the authors to previous methods and demonstrate that the proposed approach is more stable and robust to perturbations of the environment, leading to better results."
SP:f2b14f5854e6aa6922795d1d2051b7402486cef6,"This paper proposes a new adaptive weighted loss for SISR to train deep networks focusing on challenging situations such as textured and edge pixels with high uncertainty. The proposed variance estimation characterizes the uncertainty on a pixel - by - pixel basis into the proposed loss function. The authors demonstrate that such uncertainty - driven loss can achieve better results than MSE or L1 loss for a wide range of network architectures. The experimental results on three popular SIsR networks show that proposed loss has achieved better PSNR performance than traditional loss functions without any increased computation during testing. The code is available at https://see.xidianedu.cn/faculty/wsdong/Projects/UDL -SR. For the first time, they demonstrate that their proposed loss can outperform MSE   in some situations.   The authors acknowledge that it has been long recognized that texture and edge areas carry more important visual information than smooth areas in photographic images and have been trying to find a way to spatial adaptation in a principled manner. In this paper, they propose a loss function that can be learned simultaneously with the corresponding corresponding uncertainty estimation. They provide experiments on CIFAR-10 and Imagenet to demonstrate the effectiveness of their approach."
SP:9997583f40fa648adf57bb4fc34228f357be0cf1,"This paper proposes a generalization of the PAC - Bayesian framework, PACBayesian Risk Analysis ( PACBA ), to estimate the robustness of a Gaussian Mixture Model ( GMM ) with respect to perturbation at test time under adversarial perturbations. More specifically, this is a worst - case analysis of the risk of a hypothesis over all the possible pertubations, where the risk is estimated as a sum of the average of the expected risk of the perturbed values for the majority of the possible values over the entire class of hypotheses.   The main contribution of this paper is to provide general bounds ( i ) that are valid for any kind of adversarial attacks ( i.i.d. attacks that can be directly minimized during the learning phase to obtain a robust model on different attacks ) using PACBA, that are tight thanks to the PACBA framework, and that are extended to cover a wider class of attacks thanks to PACBA ( ii ). This is done by proposing the first general extension of PACBA to the GMM setting. The main contributions of the paper are the following :    1. A new set of bounds for adversarial robustness, defined as the difference in expected robustness between the expected loss for a GMM on a set of adversarially perturbed inputs $ \gamma$ and the MDPs generated by the GMMs on the test set $ \mathbb{R}$. These bounds can be extended to $ \text{M}$ for different attacks using PAC - DAGBM. The authors extend the bounds in the previous work ( Yao et al. ( 2021 ) to include the adversarial attack bounds ( $ \theta$ ) as well. 2. The robustness bounds for $ \tau$-1 $, $ \log n$, and $ \nabla_{tau } \log tau$ ( $ tau=0, tau+\gamma)$, where $ t$ is a weighted sum of $ \eta$ over the $ \epsilon$ of the adversaried inputs and $\eta$ weights for the perturbational $ \mu$ ( \eta$.   3. The generalization for PACBA is the same as in Yao eta, except that it uses the PACBay framework to bound the average risk on the mean and standard deviation of the log - likelihood of the mean for all the perturbing values instead of the worst case ( worst case as in [ Yao et a. 2021 ] ). The major difference is that the authors extend PACBA in the way of bounding the mean of the standard deviation for the max - norm of the min - max difference in the expected misspecifications of $\theta$. The main result of this approach is that it does not require a max - max misspecification of the difference between the estimated GMM and the true GMM, instead it estimates the mean instead. The cost of the bounding is the cost of"
SP:90b72e8dc41584e38f25dff9fb2853f5b11dc8fa,"This paper proposes a probabilistic entity representation model ( PERM ) to model the logical operations of projection, intersection, and union. The key idea of PERM is to encode entities as a multivariate Gaussian density with mean and covariance parameters to capture its semantic position and smooth decision boundary, respectively. It also defines the closed logical operations : the projection operation is defined so that it can be aggregated using an end - to - end objective function. The authors evaluate the performance of the proposed PERM on a COVID - 19 drug - reparameterization case study and show that it is able to recommend drugs with substantially better F1 than current methods. Finally, the authors demonstrate the query answering process through a low -dimensional visualization of the Gaussian representations.    The main contributions of this paper are as follows :   - A new model of Gaussian distributions of entities encodes them as a weighted Gaussian distribution weighted by mean, covariance, and mean squared. This is in contrast to the previous approaches that only consider mean squared distributions. This allows for more flexibility in capturing the relationship between entities. - The authors also define the closed operations : The intersection operation is extended to cover all possible values of the variable $ \mathbb{R}$ and the value matrix $ \theta$, which is then used to define the final value of the projection. The method is evaluated on a KG dataset and compared with several recent methods. The results show that the proposed method performs significantly better than the other methods, especially in terms of query accuracy and query query answering. - A case study of the per Gaussian representation shows that the method performs comparably to other methods."
SP:b6184c9732dbb7eba7c20cae8869d975c428efe4," meta - learning is challenging for tasks with long horizons due to memory scaling and gradient degradation issues. A common workaround is to learn hyperparameters online, but this introduces greediness which comes with a performance drop. This paper proposes forward - mode differentiation with sharing ( FDS ), a simple and efficient algorithm to tackle the issues of memory scaling issues with forward mode differentiation ( FMD ) and gradient degrading issues by sharing hyperparameter that are contiguous in time. The paper provides theoretical guarantees about the noise reduction properties of FDS and empirically verifies its efficiency by differentiating through 10 gradient steps of unrolled optimization. The main contributions of the paper are as follows :   ( 1 ) The paper proposes FDS, a novel algorithm to solve the gradient degradation and memory scaling problems of gradient descent by sharing forward mode gradient estimators. The authors provide theoretical guarantees and empirical evidence that FDS achieves better performance than gradient descent with greedy gradient descent ( DGD ) on CIFAR-10. ( 2 ) Differentiating through $ \epsilon$ of training data, FDS shows significantly better performance gain compared to DGD with $ \eps1 $ and $ \psi$-1 $ on tasks where the training horizon is longer than $ 20. ( 3 ) The main contribution of this paper is to develop FDS that is computationally tractable and produces better performance compared to the previous algorithm, DGD. ( 4 ) The method is evaluated on the task of meta - image classification and compared to several baselines, where FDS is compared to greedy DGD and DGD - based methods."
SP:9c3a326e5ee4e862923d3bf9415f32a077db8534,"This paper proposes a new method for improving the performance of neural sequence models ( NPs ) by adding a symbolic, logical reasoning module to evaluate generations from a NPs generation using symbolic reasoning. The idea is that we can use symbolic reasoning to distinguish between the logical ( System 2 ) and intuitive ( System 1 ) generations in NPs. The reasoning module can either accept or reject the generations produced by the current generation. The paper proposes three different variations of this approach : ( 1 ) A symbolic reasoning cross - over between System 1 and System 2 ; ( 2 ) NLP - based reasoning between NPs ; ( 3 ) Two versions of the same approach are considered, where the reasoning module considers only one generation from each NPs ( i.e., the current one ) ; and ( 4 ) A neural extrapolation between the current NPs and the logical, deliberative, System 2 ( extrapolated from the previous one ).    The main contribution of this paper is the use of symbolic reasoning in the extrapolation step. The authors propose three versions of their method. The first uses symbolic reasoning between two NPs in which the symbolic reasoning module constructs two generations from an NPs sample. The second uses neural inference to predict the logical consequences of each generation from the parameters of the third. The experiments compare the proposed method with two other methods of extrapolation, including a stochastic extrapolation and a contrastive extrapolation. The experimental results show that the proposed approach generally outperforms the other methods in terms of learning time and accuracy. The major limitation of the proposed by the authors is that the neural reasoning module takes up to three generations to perform the reasoning. This may seem like a small number of lines of reasoning, but the authors argue that this is enough to cover most of the cases and that the extra work is worth the extra effort."
SP:d77d046095e4c8336c0c76ac48cb046923230753,"This paper proposes a novel method for estimating the true outcome of personalized dose - finding ( PDE ) in continuous treatment settings under off - policy evaluation ( OPE ) rules with historical data generated by a different decision rule. The method adaptively discretizes the treatment space using deep discretization, by leveraging deep learning and multiscale change point detection. This allows the proposed method to apply existing OPE methods in discrete treatments to handle continuous treatments with discrete treatment settings. The proposed method is further justified by theoretical results, simulations, and a real application to Warfarin Dosing.   The main contributions of this paper are as follows :    1. Develop a novel estimation method for PDE in the discrete treatment setting of OPE using deep jump learning. 2. Leverage the techniques from Deep Discretization and Multiscale Change Point Detection ( MDPD ) to estimate the mean outcome of PDE under a new treatment decision rule using historical data from a different set of cases. 3. Empirically validate the effectiveness of the method using a set of experiments."
SP:4d085e57286fdd36143108a002d16914222c239a,"This paper proposes a variational variational inference algorithm based on Markov jump processes for continuous - time stochastic dynamical systems. The authors provide the exact evolution equations for the prior and posterior marginal densities, the direct solutions of which are computationally intractable. They then propose to approximate the Gaussian process approximation on the diffusion level by minimizing the path - wise Kullback - Leibler divergence, and then use the posterior inference for Markov jumps in order to obtain variational approximations of the Markov processes.   The main contributions of this paper are the following :   1. A new variational family of Markov process approximators is proposed, which can be viewed as Gaussian processes modulated with a subroutine gradient descent. 2. The corresponding variational density estimator is derived, which is then used to estimate the mean and covariance of the variational gradient of the posterior gradient. 3. A variational lower bound on the mean of the covariance is obtained by computing the mean - covariance term of the lower bound of the gradient term with respect to the prior of the diffusion process and the marginal process. 4. The posterior gradient estimator of the prior is used to compute the marginal gradient term and the posterior density of the marginal processes, which are then used as upper bounds of the min - max quadratic gradient estimators for the posterior distributions of the densities of the model parameters ( which are obtained by backpropagating from the prior to the marginal distributions ). 5. The variational posterior distributions are used to obtain the true variational densities and the corresponding mean - max - min gradient estimations for the true and min - min variational distributions, and the true posterior distributions for the marginal parameters of the joint posterior distributions. The paper also includes a detailed experimental evaluation of the proposed variational algorithm, which compares the proposed method with two previous variational approaches, one based on Gaussian - type inference and another based on Stein - style inference. The experimental results show that the proposed approach outperforms the Stein - type approach more often than not, especially when the second approach is applied to longer - time series data ( e.g., when the time complexity is higher than the first approach when the data is short - chain continuous time."
SP:d1f396e691f9d331adfb7b694a99c50e8004331f,"This paper studies the effect of the spikiness of the spectrum of the expectation propagation algorithm ( EP ) when applied to the nonlinear inverse problem of recovering x from y with respect to the componentwise nonlinear transformation of Ax ( f(Ax ), where x is the signal of interest and A is a known linear mapping ). The main contribution of this paper is to develop a framework for analyzing the performance of EP and to generalize it to the whole spectrum of sensing matrices.    The main results of the paper are :   ( 1 ) An analysis of the empirical behavior of EP on the compressed sensing problem, where the loss function of EP is defined as the sum of the losses of two matrices ( one Gaussian and one orthogonal ). This paper is able to show that for instance, in phase - retrieval problems, matrices with spikier spectrums ( those that are less spiky ) offer better recoveries compared to matrices that are spiky - dominant. This finding alone is significant, and it leads to reasonable optimism about the generalization ability of EP to the full spectrum. ( 2 ) A set of experiments that compare the performances of EP against other methods for recovering nonlinear functions of interest ( e.g., expectation propagation, expectation clustering, expectation retrieval ). These experiments are conducted to establish a theoretical understanding of the relationships between the spickiness of spectrums and the recoverability of EP in terms of the amount of information encoded in the matrices by the data points ( spectrums of interest ). ( 3 ) An empirical study is performed to establish empirically that EP recovers more data in cases where the spectrums are sparse, as opposed to dense, which is more common in other cases. ( 4 ) The results of this study are used to build a theoretical framework for understanding the behavior of the EP and its variants, and the resulting framework is applied to several signal processing problems, such as compressed sensing, phase retrieval and compressed retrieval, where it is shown that for compressed sensing the recovered data tends to be more evenly distributed across the spectrum."
SP:ee66604d4da9fd04826e90ccbb94f0499eba4c63,"This paper proposes a novel method to tackle the domain shift problem in zero - shot learning ( GZSL ), i.e. confusion between seen and unseen categories, by progressively improving cross - domain transferability and category discriminability of visual representations. The approach, dubbed Dual Progressive Prototype Network ( DPPN ), constructs two types of prototypes, namely, attribute prototypes and category prototypes, to capture the prototypical visual patterns for attributes and categories, respectively. The first type of prototypes is used to track attribute - related local regions and updates corresponding attribute prototypes to explore accurate attribute -region correspondence, while the category prototypes are used to produce visual representations with accurate attribute localization ability, which helps the semantic - visual alignment and representation transferability. Experiments on four benchmarks ( 1 ), 2 ), 3 ), 4 ) and 5 ) show the effectiveness of the proposed approach. The experiments are conducted to evaluate the proposed method, and the main contributions of the paper are the following : 1 ) The approach addresses the critical issue of the confusion between the seen and the unseen categories by ( i ) constructing ( and tracking ) visual representations that capture the attributes ( e.g., category attributes ), and ( ii ) improving the category and attribute representations to discriminate between the representations of the same and different categories. 2 ) The method is able to distinguish between the semantic representations of attributes and category representations, and 3 ) the principal components of the method are the attribute prototypes ( category prototypes ) and the attribute and location - based category prototypes ( both of which are learned in a unifed framework, and are subsequently refined to improve the category - based attributes. The method also shows that the improvement in the transferability of the category representations to the attribute representations is due to the improvement of the attribute - region representations."
SP:61eb6297568c3f6869fbb03eaf6a21260de5466c,"This paper presents an end - to - end deep learning approach for removing defocus blur from a single image. The main idea is to have an all - in - focus image for consequent vision tasks. A pixel - wise Gaussian kernel mixture ( GKM ) model is proposed for representing spatially variant defocus kernels in an efficient linear parametric form, with higher accuracy than existing models. Then, a deep neural network called G - KMNet is developed by unrolling a fixed - point iteration of the GkM - based deblurring module, which is designed on a lightweight scale - recurrent architecture. Experiments show that the G - GMKNet has advantages in terms of model complexity and computational efficiency.   The main contributions of this paper are as follows :   1. The authors develop a novel defocus - blur removal method, which works better than existing methods for removing the blur in high - resolution images. The method is referred to as DefocusNet ( Denoising Gaussian Kernel Mixture - Net ). 2. A set of experiments evaluate the effectiveness of the method on the task of predicting the mixing coefficient of a kernel when the kernel is drawn from a Gaussian distribution."
SP:18bf447c90935c373e5ec4cdfbbf8f2a273d2edb,"This paper proposes a new method for self - supervised video representation learning ( SSVRL ) based on Motion Vector based Cross Guidance Contrastive learning ( MVCGC ). In this setting, the goal is to simultaneously capture mutual information between two input streams ( i.e., RGB frames and motion vectors ) from compressed videos and to train a model that is computation - efficient and storage - efficient. To achieve this goal, the authors propose a cross - guidance contrastive learning algorithm ( CG ) to capture the cross - entropy information between the vectors of motion vectors of the input vectors ( RGB frames ) and the vector representations produced by the model ( Motion Vector ). CG has two components : 1 ) to directly decode RGB frames to estimate the motion vectors from the compressed videos ; 2 ) to enhance the representation ability of the CG motion vectors to improve the effectiveness of the learning method. The authors test their CG method on two downstream tasks and show that it yields new state - of - the - art models that are significantly more efficient than those of their competitors.    The main contributions of this paper are the following :   1 ) A novel CG method that captures mutual information ( cross entropy information ) between the input streams and the motion vector representations of the motion models ( RGB and optical flow ) from the videos. 2 ) A method to directly estimate the RGB frames of a compressed video ( using the CG method ) that directly predicts motion vectors ( using low - resolution optical flows ) that correspond to the frames of the compressed video. 3 ) An improved version of the original CG method ( using a vector encoder instead of an optical flow to obtain more accurate motion vectors. 4 ) Two additional contributions are the cross guidance CG methods ( the second and third one ) to increase the distance between input vectors and the learned model ( the first one ) and to the source vectors."
SP:8c7b1d976d9758cd534c565ec31a23f97892e503,"This paper studies the problem of Bayesian neural networks ( BNNs ) and Bayesian linear models ( BLEU ) with infinite - width Gaussian processes ( GP ). The authors show that BLEu with finitely many features is quadratic in the distance from the training data, while GP with finite widths converge to a variance that grows cubically with infinite number of parameters. They then propose a way to train GP via a finite number of ReLU features via the GP and show that the resulting model is asymptotically robust to perturbations in the data far away from the data while the BNN ’s ‘ predictive power ’ is unaffected near the data. They also show how to apply the resulting resulting model post - hoc to any pre - trained ReLU BNN at a low cost.   While this may seem of mostly theoretical interest, in this work, they show that it can be used in practice to improve the performance of BLEUNNs compared to GP models. The main contributions of the paper are the following :   1 ) The authors develop a novel approach to train a Gaussian process by training a ReLU ( Bayesian ) neural network with the output of a GP that is orthogonal to each ReLU feature. This approach is referred to as “ Bayesian posterior planning ” ( BPR ) and it is based on the fact that the posterior probability of a model trained with BPR is independent of the number of features and can be reduced to that is parameterized by the output variance of a BPRN. This gives rise to the idea that the probability of the output depends only on the posterior distribution of features ( rather than the feature distribution itself. 2 ) They show that training a GP with infinite widths converges to a parametric distribution that is parametric to a specific GP parameter that has a power that scales cubically to all possible values of the GP parameter. The resulting BPR has the property that it is able to learn all the parameters of the resulting BNN without losing any predictive power due to its parametric structure. 3 ) They use this idea to improve BPR for training neural networks that are trained from scratch using the resulting posterior probability."
SP:e77276f61626e896f6a985296f1d832129242cdf,"This paper considers the problem of selecting a formula for identifying a causal quantity of interest among a set of available formulas. It assumes a setting in which the investigator may alter the data collection mechanism in a data - dependent way with the aim of identifying the formula with lowest asymptotic variance in as few samples as possible. It formalizes this setting by using the bestarm - identification bandit framework, where the standard goal of learning the arm with the lowest loss is replaced with the goal to learn the arm that will produce the best estimate.   The authors introduce new tools for constructing finite - sample confidence bounds on estimates of the variance that account for the estimation of potentially complex nuisance functions, and adapt the best - arm - identifiability algorithms of LUCB and SUE to use these bounds. They validate their method by providing upper bounds on the sample complexity and an empirical study on artificially generated data."
SP:471361588bfc6c6033631509d1e43e77fd9721ce,"The paper studies the problem of scalability for distributed learning with compression - based variance reduced algorithms. The authors propose ErrorCompensatedX ( ECE ), which uses the compression error from the previous step of the stochastic gradient descent ( SGD ) algorithm to reduce the communication cost of the algorithm. They show that adding back the prior step ’s compression error does not fully compensate the original error. In addition, they study the convergence speed of the proposed algorithm with and without the added compression error. They provide a unified theoretical analysis framework for this class of variance - reduced algorithms, where the variance is reduced by taking a moving average over all history gradients.   The main contributions of the paper are as follows :   1. The paper proposes a new algorithm with the added back - step compression error for SGD that converges faster than the algorithm with no compression. Theoretical analysis shows that the new algorithm converges at the same convergence rate as the one proposed by ECE, but with or without the error correction. 2. Theorem 3.1 shows that in the case of ECE with the back - stepped compression error, the convergence rate is faster than that of the original algorithm without it. 3. Theorem 4.2 shows that using the compressed gradients in the previous two steps of SGD accelerates convergence faster than using the compression in the first step of ErrorCompenatedX, and vice versa in the second step. They compare this method to the one where the compression is applied only to the first two steps, and show that the gradient does not converge as fast. 4."
SP:3b7ff0dc668cac2191d95fcc4dc6e0335dec3206,"This paper studies the problem of explainability of graph neural network ( GNN ) explainers. Specifically, the authors focus on two aspects : ( 1 ) local explainability, which explains each instance independently, thus hardly exhibits the class - wise patterns ; and ( 2 ) global explainability which systematizes the globally important patterns, but might be trivial in the local context. Authors argue that this dichotomy limits the flexibility and effectiveness of explainers and that a performant paradigm towards multi - grained explainers ( AUC ) is needed to increase explainability until - now lacking. In this work, they exploit the advantages of the pre - training, pre - pre - implanting and fine - tuning phase of GNN explainers to generate multi - granular explanations that generalize beyond the global context to the local one. Authors compare their explainer, Graph Explainer ( HAR ), with three other explainer methods on two synthetic datasets and one real - world dataset. They show that the explainer ( GG ) outperforms the other two ( GG+ and GGDC ) in terms of AUC on explaining graph classification over the leading baselines. However, authors note that the performance of GG+ is lower on synthetic datasets due to the fact that it only considers global patterns ( which are globally significant in the real world ), while GGDC considers local patterns that are important in the locally relevant context. They also show that GG+ performs worse on real world datasets than AUC but perform slightly better than GGDC. Authors also study the effect of different assumptions on explainer performance and demonstrate the advantage of using different assumptions."
SP:9b5a62d3a2b27bc60da28980e9fb0ecdff1215c0,"Graph Neural Networks ( GNNs ) generate explanations for predictions that are robust to noise and align well with human intuition. Most existing methods generate explanations by identifying a subgraph of an input graph that has a strong correlation with the prediction. However, independently optimizing the correlation for a single input can easily overfit noise and produce explanations that are not counterfactual. In this paper, the authors propose a novel method that explicitly models the common decision logic of the authors of previous works ( e.g., GNN2 ) on similar input graphs. The authors first obtain a set of predictions that correspond to the set of edges identified by an explanation from the input graph corresponding to the prediction significantly larger than the observation subgraph. Then, they propose a method that generates counter -factual explanations for the predictions by explicitly modelling the common reasoning behind the predictions in the authors ’ previous works. The main contributions are the following :   ( 1 ) A novel method to generate robust counter - Factual Explanations for predictions in Graph Neural Networks. This method is based on the observation that removing an identified subgraph from an input GNN does not necessarily change the prediction result of the original GNN ; and ( 2 ) A set of experiments on many public datasets to demonstrate the superior performance of the proposed method. The experimental results demonstrate the robustness of the explanations produced by the method against the noise. The explanations are also counter - plausible because removing the feature extractor from a GNN that does not correspond to a different subgraph can lead to different predictions. The experiments are conducted on two datasets, one measuring the correlation between the prediction subgraphs and the features extracted from the GNN, and the other datasets measuring the impact of changes in the prediction features between the input and observations made by the features from the two datasets."
SP:4edb870786c9cea2c6075359cb4e79b02a8e2f5f,"This paper proposes a new method for self - supervised voice - transfer learning based on information bottleneck and adversarial feedback. The method, dubbed VoiceMixer, is based on the idea of using information bottleneck to decompose and transfer source speech content and style through a discriminator with self - supervision. The discriminator is decomposed into a content discriminator and style discriminator using self supervision. During adversarial training, the discriminator tries to predict the source speech style using the self supervision data and the target voice using the data from the content bottleneck. Experiments are conducted on synthetic data ( voice mails converted from target voice to source speech ) and on a text - to - text ( text+speech ) task with the goal of improving the generalization ability of the method to the voice style of the converted speech. The results demonstrate the superiority of the proposed method over existing methods for voice transfer based on self supervision and data augmentation.    The main contributions of the paper are the following :   ( 1 ) A new method to learn the content and voice style from source speech using an information bottleneck ; ( 2 ) An adversarial approach to training discriminators to estimate the source voice style through self supervision ; and ( 3 ) A method to train discriminators based on a self supervision network using the learned discriminator to discriminate the source and target voice."
SP:9fbb0c6beb3f8f88972f13dcf0e1fe7db03233c7,"This paper proposes a voxel - to - BEV target tracking method in 3D point clouds using a Siamese shape - aware feature learning network and a target localization network. The key idea of the network is to learn the discriminative features of the object so that the potential target from the background in sparse point clouds can be identified. To this end, it first performs template feature embedding to embed the template ’s feature into the target and then generate a dense 3D shape to characterize the shape information of the 3D object with which to track the target. The target is then localized with the help of the 2D center and z - axis center from the dense BEV feature map obtained from the template. The paper evaluates the proposed method on KITTI and nuScenes datasets and shows that it significantly outperforms the current state - of - the - art methods by a large margin. The method is applicable to point clouds with sparse 3D data, and the code is available at the source code of the paper.    The main contributions of this paper are the following :   ( 1 ) A Siamesese Shape - Aware Feature Learning Network ( SAWN ), which learns a 3D feature representation from 2D features and targets. ( 2 ) A Target Locally Locating Voxel to BEV Target Locating Network ( TOV ), where the target is localized using the features of 2D targets and voxels of target from BEV features. ( 3 ) A Dynamic Target Locator, which uses the features from TOV target to localization network to estimate the distance to the target object from the nearest neighbor. ( 4 ) A Quantitative Estimation of the distance from the target to the latent space of the target using a logistic regression. ( 5 ) An Ablation of the difference between the target features and the latent representations of the other targets to obtain the final target feature. ( 6 ) Ablation using Gaussian noise injection to estimate distance to all the targets in the target domain from the latent features of other than the target feature and the z-axis center. ( 7 ) Empirical evaluation of the method performed on KITI and NuScenes Dataset using the V2B dataset shows that the method significantly outperformes the previous SOTAR and BEV tracking methods. ( 8 ) Ablations of the manuscript performed using the current"
SP:8b788c78680a54c453a04f4551436763ee57585e,"This paper proposes a multi - dimensional positional encoding method based on learnable Fourier features. The method is based on the idea of positional encoding, which is a crucial component of attention - based deep model architectures such as Transformer. In this paper, each position in a sequence or image is represented as a trainable encoding modulated with multi - layer perceptron. The perceptron is learnable and can be obtained via a Fourier feature mapping. The authors propose to use the learnable feature mapping to represent the position of each feature in an image as a vector representation. The paper shows that the proposed method outperforms the state - of - the - art positional encoding methods using two existing methods : L2 - LSTM and L - LADIES. The main contributions of the paper are the following :   1 ) A new feature encoding method for the Fourier representations of positions in images. This is done by replacing the vector representation of position in each image with a learnable representation of the feature mapping of the corresponding position in the image. 2 ) An encoding scheme for the feature encoding is proposed for the L2 distance between two position vectors, where each position is represented by a L2 embedding. The embedding of the position embedding is modulated according to the distance between the first and second position of the input image. 3 ) The authors test their method on three tasks designed to measure the performance of the proposed feature encoding. The results show that the method is competitive with and sometimes better than the SOTA methods used in SOTA for positional encoding."
SP:d2ac1b6381315bce4449f09bd519f33a2a42d714,"This paper proposes a new method for learning the causal structure of a multivariate autoencoder system from observational data in the presence of latent variables and selection bias. The main idea is to learn the structure efficiently and recursively, as this allows us to reduce both the number of required conditional conditional independence ( CI ) tests and the size of the conditioning sets. The proposed method is based on a novel and computationally efficient recursive constraint - based method. The authors provide experimental results to compare the proposed approach with the state of the art on both synthetic and real - world structures.   The main contributions of the paper are the following :   1 ) The authors propose a novel, cost - efficient, and highly tractable learning method for constructing multivariate logistic regression models from observations and latent variable information. The key idea of the approach is that at each iteration a specific type of variable is identified and removed, e.g., at the next iteration a new latent variable is introduced. The former substantially reduces the computational complexity, while the latter results in more reliable CI tests. As a result, this is the main contribution of this paper. The lower bound of the cost - efficiency method is lower than the upper bound on the required CI tests in the worst case, while it is slightly higher than the lower bound required in the best case. However, the authors provide an upper bound of $ \ell_{2}$ on the total number of conditional independence tests required by any constraint-based method $ \mathbb{R}$ for the general case, which is a lower bound for the worst - case CI test ( $ \epsilon$ ) as a fraction of the total cost of learning the structure. The upper bound is upper bounded by a factor equal to $ \eps_{1}$.    2 ) Experimental results of the proposed method are provided to demonstrate that the learned structure is comparable to that of state - of - the art under different assumptions, and that the learning process is time - efficient and cost efficient. In particular, the difference between the obtained by using the current method and the one based on the previous one is measured by the difference in terms of the average number of closed - form errors incurred by the learning during each iteration. The average errors incurred during the first iteration and during the second iteration, and the average errors during the third iteration, if the latter is achieved, is subtracted from the total learning cost of the current iteration, to get an average of the first and second iteration. In the case of the latter method, the average error is"
SP:49a4912ce457f5f5ec62c44fa10444af8075fabf,"This paper studies batch Thompson Sampling ( BP ) for stochastic multi - arm bandit and linear contextual bandit online decision making problems, and proposes BP policies for each of them. The authors show that their BP policies achieve the same regret bound as a fully sequential one while carrying out only O(log T ) batch queries, which is exponential in the number of interactions with the environment. In order to mitigate the negative impact of the exploration - exploitation trade - off between the BP policy and the linear BP policy, the authors propose a dynamic BP policy where the duration of each BP run is dynamically controlled based on the amount of exploration done in the previous batch. They show that the dynamic BP with a fixed duration leads to a regret bound that is upper bounded by the regret bound of the full sequential BP policy with fixed query length. They also show that dynamic BP outperforms BP with fixed duration BP under some assumptions.    The main contributions of this paper are the following :   1 ) A BP policy for each arm of the linear bandit is proposed, which extends the previous BP policy in a way that ensures that the maximum BP query length of each arm is the same across all the arms. 2 ) A dynamic BP allocation strategy is proposed to control the BP duration in order to ensure that only a small fraction of the queries are queried in each batch. 3 ) The authors test their BP policy on a synthetic dataset, and show that it achieves the best regret bound ( compared to BP policy ) of all the BP policies they study."
SP:653a519e3c799c25e0d0b4240322642040b121a3,"This paper studies the problem of learning domain - invariant representations for the task of domain adaptation ( DA ) in the post - hoc setting of domain generalization ( DG ). The main contributions are the following :   1. The authors develop a novel upper - bound for the target general loss that captures the generalization ability of the target domain. 2. They use this upper bound to define two kinds of domain invariant representation, one that is invariant to the source domain ( e.g., GPT-2 ) and another that invariants to the domain specific domain ( i.e., DSD ). 3. The corresponding lower bounds enable the authors to estimate the cost - efficiency ratio of training and/or testing the two types of representations. 4. They conduct experiments to measure the effectiveness of the upper bounds and of the lower bounds used for training and testing the representations."
SP:2a7bee950cd07494d59dfee60ac2e86cc0e481b1,"This paper proposes aligned structured sparsity learning ( ASSL ), a model compression method for sparse SR networks, named as AssamLN, with smaller model size and lower computation cost than state - of - the - art SR methods. ASSL introduces a weight normalization layer and applies L2 regularization to the scale parameters for sparsity. To align the pruned filter locations across different layers, the authors propose a sparsity structure alignment penalty term, ASSL - PGD, which minimizes the norm of soft mask in expectation of alignment with the structure of the sparsity distribution. The authors conduct extensive comparisons with lightweight SR methods, and demonstrate that ASSL achieves superior performance gains over recent methods. The main contributions of this paper are as follows :    ( 1 ) The authors propose ASSL, an alignment method between sparsity based model compression methods and lightweight SR networks. This method is evaluated empirically on a set of lightweight neural network architectures, and compared with the following : - DenseNet, DenseGAN - L2 - SPADE, and DenseLSTM. - ASSL outperforms the lightweight methods in terms of model performance, model efficiency, and model robustness to perturbations. - The authors demonstrate the effectiveness of ASSL on a range of datasets, including CIFAR-10, UCI, and Fashion - MNIST."
SP:e9830bb9e7d3ddc3bd1c2994590fdb5d8f3668be,"This paper proposes a method ( Episodic Multi - agent Reinforcement Learning with Curiosity - driven Exploration, EMC ) for coordinated exploration in deep multi - agent RL with factorized MARL. The method leverages the individual Q - values of MARL ’s individual policy gradient update function to learn the individual utility functions used for local execution, which are the embeddings of local actionobservation histories, and can capture the interaction between agents due to reward backpropagation during centralized training. The authors propose to use prediction errors of individual Q-values as intrinsic rewards to induce coordinated exploration and utilize episodic memory to exploit explored informative experience to boost policy training. They demonstrate the advantages of their method by didactic examples, and demonstrate its significant outperformance over state - of - the - art MARL on challenging tasks in the StarCraft II.    The main contributions of this paper are the following :   1 ) The authors introduce a method for factorizing MARL algorithms that the “induced ” individual policies “ induces “, ” where the state and action trajectories of the agent involved are obtained by maximizing the gradient of the Q - value of the policy update function using the mutual information between states and actions observed by the agent ; and 2 ) A method for generating policy gradient updates for exploration using the exploration trajectories obtained by factorizing individual policy updates using the state trajectories ; and 3 ) A technique for generating intrinsic rewards for exploration based on extrapolation from the learned policy gradient using extrapolation of the learned individual Q values ; and 4 ) A procedure to generate intrinsic reward can induce exploration to new states that the agent can use for policy improvement ; and a technique to generate new exploration that can be used to generate policy gradient to generate exploration policy updates that can improve policy gradient ; and"
SP:c7e33d479575c88e22282ee6fd4f978bcd3c06ed,"This paper studies the problem of list - controllable linear regression, where an adversary can corrupt a majority of the examples, and the goal is to output a small list of hypothesis vectors from a linear regression model such that at least one of them is close to the target regression vector. The main result is a statistical query ( SQ ) lower bound of d for this problem, which matches the performance of previously developed algorithms, and whose lower bound is qualitatively lower than the upper bound for this task.   The main contribution of this paper is to develop a lower bound for SQ that is competitive with the upper bounds for SQ in the sense that it does not rely on assumptions that the data in the list are clean and the adversary can not corrupt the majority of examples. The upper bound is based on the assumption that the Gaussian covariates of the regression model are Gaussian and that the distribution of the points in the set T obtained from the model is Gaussian. The lower bound comes from an arbitrary noise distribution of points sampled from a distribution of noise vectors drawn from an unknown source. The idea is to use the noise distribution to construct a list of possible hypothesis vectors for each point in T such that some of them are likely to match the target linear regression vector, and that a subset of them agrees with at least some of the other hypothesis vectors. The authors develop two algorithms ( LSTM and SQSQ ) based on linear regression models and two noise distributions ( Gaussian noise distribution and random noise distribution ), and demonstrate that their lower bound reproduces the results of LSTMs and SQsQ with improved accuracy. For the authors use two different sets of noise distributions, one based on Gaussian distribution ( Random Noise Distribution ( RD ) and Random Random Population ( SDP ). The experimental results show that the SDP reproduces better than the other and the other uses the original noise distribution ( RD. For example, in the case of SDP the average score of both RD and SDP is slightly higher than the average of the two distributions. For SDPs used in the authors obtain lower scores for the random Population ( higher for RD than for SDP and for RD )."
SP:7b258252a9063514348f5fa8d9c85afd85748747,"This paper proposes a latent hybridisation model ( LHM ) to integrate a system of expert - designed ODEs with machine - learned counterparts to predict patient health status and disease progression over time. The authors consider an application where a wealth of domain knowledge is available from pharmacology ( such as the mechanism of drug interactions ), which is used to incorporate expert domain knowledge into ML models. To close the gap between the expert and model variables, the authors propose a latent variable extractor ( LDE ) to fully describe the dynamics of the ODE system, and an expert auxiliary ( LMI ) to predict the expert variables from the LDE model.    The authors evaluated LHM on synthetic data as well as real - world intensive care data of COVID-19 patients. The main contributions of the paper are as follows :   - Proposes a LHM that extends the framework from pharmacological models to one based on machine learning ( ML ) models. The LDE has the capability to predict expert variables directly from the expert model variables. This is a major advance over previous LHM approaches that only considered a limited set of expert variables. - Demonstrates the effectiveness of LDEs by comparing the performance of the proposed LDE with that of two baselines based on pharmacology, namely the Gumbel - Monte Carlo ( GBM ) and the Sapiens - Newton ( SNR )."
SP:3ea9e86e5755ef84d28e3163c60531ace5d62e3a,"This paper presents a theoretical framework for analyzing a MAML - like algorithm that learns task - specific representations by finding an initial representation requiring minimal per - task adaptation ( i.e. a "" Frozen Representation "" objective ). The authors provide risk bounds on predictors found by finetuning via gradient descent, demonstrating that the method provably leverages the shared structure. The bounds are extended to settings where learning one representation for all tasks ( $ f$-\frozen $ \mathbb{R}$ representation ) fails in the presence of no other information, in the worst case - case assumption that the initial representation is frozen - over. They also establish risk bounds in the logistic regression and neural network settings.   The main contributions of the paper are the following :   1 ) The theoretical framework provides the conditions under which a learning algorithm with Frozen Representations requires minimal adaptation per task ( assuming all available tasks require approximately the same representation ) can be analyzed. 2 ) The authors extend the risk bounds provided in the theoretical framework to the case when the learning algorithm is applied directly to the tasks ( e.g., learning the target task in the first order ). 3 ) The risk bound on the predictors obtained from the finetuned estimator provided by the method is extended to the setting where the learner has access to all the parameters required to learn the task representations in the second order. 4 ) A set of experiments illustrate the behavior of the algorithm in two settings, where the learning rate is limited to $ \epsilon$ and learning rates are restricted to $ n/s$. The experiments are conducted to compare the performance of the learning method with the learning strategy compared to a baseline learning strategy that doesn't require any additional fine - tuning. The experimental evidence is presented in Table 2."
SP:8ba5a2ac80f7c53f81ad008e96c033ecad14ac0d,"The paper proposes G2L2 ( 2L2 ), a language model based on semantic programming and lexicon - based learning, where the semantic program is a neural network embedding and the lexicon entries are a collection of entries mapping each word to a syntactic type and a semantic program. For example, the word shiny has the syntactic form $ \lambdaxfilter(x,SHINY)$ where the concept SHINY is associated with a neural networks embedding, which will be used to classify shiny objects. The authors evaluate the model on two domains : visual reasoning and language - driven navigation.    The first part of the experiment evaluates the ability of the model to generalize from small amounts of data to novel compositions of words using a lexicalist approach to learn a compositional and grounded meaning representation of language from grounded data, such as paired images and texts. The second part uses a joint parsing and expected execution algorithm, which does local marginalization over derivations to reduce the training time, to evaluate the learning performance of the method. The experimental results show that the method outperforms other models in terms of vocabulary acquisition speed and generalization ability when compared to other methods such as L2L1 and L1L1. The main concern of the paper is the cost of training the models, which may become prohibitive in some cases."
SP:16c458651815813efdcbe8ba1205bbddbe3e4e68,"This paper proposes and studies distributed stochastic convex optimization ( DSDPs ) with Newton's algorithm for convex population distribution with Hessian - vector products, where each machine has access to the Hessian of the population vector and the means to compute the gradients. The authors provide convergence guarantees for quasi - self - concordant objectives ( e.g. logistic regression ), which are obtained by iteratively computing Hessian vectors using the communication rounds between machines that achieve the same set of gradients under different Hessian estimators. The convergence guarantees are obtained using the following steps :   1. In each round the authors communicate with each machine ( up to a countable number of machines ) and compute the gradient of the vector vector using the estimator that corresponds to the distribution over population vectors. 2. In the next round the machines compute the mean and variance of the vectors corresponding to the set gradients obtained in the previous round. 3. In between rounds the machines update the vector estimators of the estimators to ensure that the convergence is guaranteed.   The authors test the convergence of their convergence results using the DSDP and Hessian vector products obtained in round 1. They compare the convergence rates of the convergence results of their method with other methods that do not require communication rounds ( including SGD, which does not require the vectors to be computed in the first round ) and find that their method is the fastest in terms of convergence and has the lowest number of rounds ( compared to SGD ). The paper also presents convergence rates for other methods based on the assumption that the vector estimates are Hessian weighted by some fixed number of the Hessians, which they do not use for the distribution estimators ( which is not the case with the distributed DSDP objective ). In addition, the authors present convergence results for other objectives that do require communication round in excess of the ones used in the paper, as well as results that are inconsistent with each other. The experiments show that the proposed method is more robust than the other methods and faster than the baselines on some of the objectives, though the authors do n’t provide any comparisons."
SP:d7e479d59f82d4c55372a68ca7b4516f2871f346,"This paper proposes a new distance measure between two point sets Chamfer Distance ( CD ) and Earth - over's Distance ( EMD ). It is based on the fact that CD is sensitive to mismatched local density and EMD is dominated by global distribution, while EMD overlooks the fidelity of detailed structures. The proposed CD is derived from CD and benefits from several desirable properties : 1 ) it can detect disparity of density distributions and is thus a more intensive measure of similarity compared to CD ; 2 ) it is stricter with detailed structures and significantly more computationally efficient than EMD ; 3 ) the bounded value range encourages a more stable evaluation over the whole test set, where experimental results show that DCD pays attention to both the overall structure and local geometric details and provides a more reliable evaluation. The paper also proposes a novel point discriminator module to evaluate the point cloud completion task, which outperforms the same model trained with CD loss on all three metrics. In addition, the authors propose a novel downsampling step to improve the performance of DCD. The experimental results suggest that the proposed method achieves noticeable improvements under DCD together with competitive results for both CD and E MD.    The paper is well written and well structured, with clear goals and clear directions. The manuscript is easy to follow and easy to read. The major weakness is the lack of clarity on the experimental results and lack of reproducibility of the experiments. The method is interesting and well written, but needs some clarifications and clarifications to make it more tractable. I enjoy reading the paper and the discussions."
SP:e4b302009520770814ff2c096020b779a9fc38fe,"This paper studies the effect of knowledge distillation ( KD ) on student generalization when training a small student network to emulate a larger teacher model, such as an ensemble of networks. The authors find that there remains a surprisingly large discrepancy between the predictive distributions of the teacher and the student, even in cases when the student has the capacity to perfectly match the teacher. They identify difficulties in optimization as a key reason for why the student is unable to match the teachers. They also show how the details of the dataset used for distillation play a role in how closely the student matches the teacher — and that more closely matching the teacher paradoxically does not always lead to better student generalisation.   The main contributions of the paper are as follows :   - The authors study the relationship between KD and generalization in two ways : 1 ) the generalization error of KD does not improve as much for the student as it does for the teacher ; 2 ) the impact of distillation on generalization is studied."
SP:895c7e03f9e4dadb94be1f39d61bf0b5e1533f4f,"This paper studies the problem of computing k - trees ( or k - branches ) from a partition of a matrix ( k-2D - signal ) into k - 1 block matrices, where each block matrix is a collection of axis - parallel rectangles assigned a label. The goal is to come up with a k - tree that maximizes the expected regression or classification loss to a given matrix D of D of N entries ( labels ), where t is the sum of squared differences over every label in D and its assigned label by t given an error parameter $ \varepsilon$. The paper proposes to do this by first computing the partition of the matrix into k blocks, and then computing the expected loss over the rectangles in each set of the partition matrices ( up to a multiplicative factor of 1 / \sqrt(\sqrt{1 + \�)$ ) for each set in the partition. This is done by dividing the input k - matrices into sets of k columns ( rows ), and by computing the k - leaves of each row from those sets for each row. The paper presents experiments on synthetic and real - world data sets to show that applying these coresets to the synthetic data - sets boosts the computation time of random forests by up to 10 %, while keeping similar accuracy. The experiments are conducted on synthetic data ( MNIST, Fashion - MNIST and CIFAR-10 ), random forests ( random forest with different tree partition splits from the machine learning algorithm, and random forests with different partition trees from machine learning ).   The paper also presents results showing that applying the coresets on real data - set conditions ( e.g., temperature, seasonality, availability of seeds, etc. ) increases the computation speed of k - forests. However, the paper does n’t provide any empirical evidence that this increase is due to increased computation cost of running the coreets on the real data sets, only that it is because of the higher number of trees ( number of labels assigned to each tree )."
SP:f3ece96b15ec06d703925df2061ed9694ec3bca5,"This paper studies the identification of m arms with the largest means under a fixed error rate $ \delta$ for misspecified linear bandit models. This problem is motivated by practical applications, especially in medicine and recommendation systems, where linear models are popular due to their simplicity and the existence of efficient algorithms, but in which data inevitably deviates from linearity.   The authors first derive a lower bound on the sample complexity of any $ \tilde{O}$-correct algorithm for the general Top - m identification problem. They then describe the first algorithm for this setting, which is both practical and adapts to the amount of misspecification. Finally, the authors evaluate their algorithm on both synthetic and real - world data, showing competitive performance with respect to existing baselines."
SP:e71c5e39b8d8d1640d6de2352ac51ddd52eea89d,"This paper studies the problem of learning disentangled graph representations with self - supervised learning ( SSL ) for graph neural networks ( GNNs ). The authors propose a novel method, Disentangled Graph Contrastive Learning ( DGCL ), which is able to learn graph - level representations with SSL without using self - supervision. The key idea is to leverage the latent factors of the input graph to derive its factorized representations of the factorized representation of the GNN structure from a latent factor specific to a specific latent factor of the graph structure. In order to do this, the authors propose to use a novel factor - wise discrimination objective in a contrastive learning manner, which can force the factorised representations to independently reflect the expressive information from different latent factors. Experiments on both synthetic and real - world datasets demonstrate the superiority of the method over several state - of - the - art baselines. Comparisons with SSL are also provided to demonstrate the learned representations are suboptimal for downstream tasks and difficult to interpret."
SP:0a7edbbdabab11273689c40c517001eb46491113,"This paper studies the robustness of locally robust networks based on a stochastic belief - splitting simulation. The simulation is based on the Importance Splitting Simulation ( IS ), a statistical hypothesis testing procedure in Reliability Engineering ( RR ) where the network is considered robust if the estimated probability of failure is lower than a critical level. The authors use this simulation to construct a robustness metric that measures the ability of a network to cope with inputs such as errors and outliers. The robustness is measured using a statistician who measures the distance between any two inputs in the simulation and the output of the network. This distance is modelled as a log - likelihood of each input ( i.e., the probability that the network would be robust to a failure that occurred if the first input was a miss and the second input was an error that occurred at a value other than the critical level ).   The authors derive theoretical guarantees that the simulation is nonasymptotic w.r.t. a sample size of $ \ell_2$. They also investigate the efficiency of their method by making a low number of calls to the network function during the training phase and comparing their metric with the one used in previous works. The experimental results show that their metric is more robust than other metric methods ( e.g., robustness scores for errors and robust scores for outliers ) on small - scale networks. On medium - sized networks, the method is able to achieve similar results to the previous work ( Wang et al., 2021 ) using a much smaller sample size. On larger networks, their method achieves better results."
SP:c1db485ff1ff9573daa421e167225654babb55ac,"This paper proposes CoPE, a generative model for conditional image generation based on polynomial expansion of two inputs, i.e., the noise variable and the conditional variable. The noise variable can be thought of as the noise input, while the conditional variables can be any one of three types of random variables used in generative models : alpha, beta, and cosine, which are all single - variable polynomials that are typically used for unsupervised image generation tasks. The main contribution of this paper is to propose a general framework that can handle the conditional generation of two noise variables ( $ \ell_2$, $ \epsilon$ ) and a conditional $ \nabla$ that can be augmented with arbitrary number of input variables. The proposed CoPE is evaluated in five tasks ( class - conditional generation, assignment generation, generation - to - image translation, attributeguided generation, attribute - guided generation ) involving eight datasets, where the goal is to generate an image from a noise input vector mapped to a synthesized image. The experiments compare the performance of CoPE against that of PNNs, PNN - based methods, and show that CoPE outperforms them in most cases, especially when the noise and conditional variables are chosen to be the two - variable variables. Moreover, the experiments demonstrate that the CoPE model is robust to the choice of the number of variables and the amount of noise input that is used to train the model, showing that it is better than the PNN models on some tasks."
SP:5a75bc7a3ea0ce971cfceebbc1c2434e3aa2584d,"This paper proposes a new two - sample test statistic based on neural network Maximum Mean Discrepancy ( MMD ) and neural tangent kernel ( NTK ) to compute the MMD statistic and perform two - test based estimations of the Type I error of the NTK statistic. The authors claim that NTK shares many properties with MMD, such as the Type - I error and testing power for performing the two - samples test, by adapting existing theories for kernel MMD. The proposed MMD - NTK estimator is computationally and memory - efficient compared to the traditional one - sample - per - kernel estimator ( O'Donoghue et al., 2020 ), which uses a large amount of memory and computing power. The paper proposes to use only one sample per kernel for computing MMD and two samples per sample for NTK, which use the same computing power and memory resources. Experiments on synthetic and real - world datasets validate the theory and demonstrate the effectiveness of the proposed NTK - MMD estimator.   "
SP:1df2ffbbe56b8018067820980b93af2a8b57f891,"This paper proposes a method called “ class - disentanglement ” for extracting the “ minimum necessary information ” ( MICE ) required by a neural net from an image x to accurately predict its class G(x ) from the input space x. The key idea is to train a variational autoencoder ( VAE ) such that it can allocate the areas D(· ) mainly attending to and shedding novel insights to the detection and defense of adversarial attacks. The method is based on the idea that : ( 1 ) in a generative model with generative adversarial examples it is possible to obtain a class - independent feature extractor that, when given a class x, predicts the probability distribution of the features x given the input x. ( 2 ) in an adversarial model with a classifier that is able to distinguish between the features produced by each adversarial example and the ones produced by the one obtained by the generative models, it can detect which ones are likely to be the most likely to belong to a particular class.   The procedure is described in detail in the paper and the experiments are conducted to test the effectiveness of the proposed method. The experiments include : ( a ) training adversarial models with the class - dependent information extracted from the VAE ; ( b ) conducting adversarial experiments with clean and adversarial images to test whether the perturbations generated by adversarial defenses are significant enough to warrant requiring the use of the classifier ; ( c ) applying the proposed classifier to clean images to detect whether they should be classified as positive or negative class. On the clean images, the authors find that using the adversarial defense on the positive images significantly reduces the probability that the image is classified as negative, and on the negative image the probability is significantly increased. The authors also conduct a series of experiments to validate their classifier. The results are presented in Table 2."
SP:2789874561620ba7894c4672f935056bb911e919,"The paper proposes a federated learning ( FL ) setting for Bayesian Optimization ( BO ) based on FedFed Thompson Sampling ( FTS ), an algorithm for training deep neural networks that federates hyperparameters from a FedFed dataset. FTS is differentially private, but does not provide a rigorous privacy guarantee for user - level data. This paper proposes to replace the $ \ell_2 $ privacy guarantee in FTS with $ \epsilon$ ( DP - FTS - DE ; see paper for details ), which is based on differential privacy ( DP ) framework for adding DP to iterative algorithms. The main contribution of this paper is to leverage the ability of this general DP framework to handle different parameter vectors ( e.g. parameter vectors used for BO ) to improve the utility of BO algorithm through distributed exploration ( DE ) to further improve the privacy of BO. The paper presents experiments to show that DP-FTS -DE achieves high utility ( competitive performance ) with a strong privacy guarantee ( small privacy loss ) and induces a trade - off between privacy and utility.    The main contributions of the paper are the following :   1 ) Integrate DP into FedFedThompsonSampling to improve privacy guarantees for user level data ; 2 ) Leverage DP framework for handling parameter vectors ; 3 ) Improperly train BO using local modeling for BO."
SP:be7d6b81736a2c3f89abd8771b41b18802e88832,This paper proposes a new model for multi - label active learning ( ML - AL ) based on Gaussian Process - Bayesian Bernoulli Mixture model ( GP - BN ). The model is integrated with a predictive distribution that provides both the label prediction and their correlations in the form of a label covariance matrix. The sampling function is designed to naturally capture both the feature uncertainty ( through GP ) and label crossover ( through BM ) for effective data sampling. Experiments on real - world multi - labels datasets demonstrate the state - of - the - art AL performance of the proposed model.   The main contributions of the paper are the following :   1. The introduction of a Gaussian process - based Gaussian Mixture Model with Bayesian components to estimate the overall contribution of each mixture component to a correlated label space and to choose the most informative samples for cost - effective annotation. 2. A mapping process for efficient end - to - end posterior inference to generate feature - component - label mapping. 3. The use of Gaussian processes to predict the coefficients of mixture components that help to recover the final set of labels of a data sample. 4. An auxiliary auxiliary variable based variational inference algorithm is developed to tackle the non - non - concordant label clusters introduced along with the mapping process.
SP:2b7270b0370c193300bcbbb5fb0a4101b3329d99,"This paper proposes a new coordinate processing method, Polar coordinate processing ( P - CP ), for deep learning on the nuScenes dataset. The proposed method is based on the fact that previous work on deep learning for point cloud based methods, such as LIDAR, uses coordinate processing based on cartesian coordinate systems to represent the sectors as rectangular regions, which uses memory and compute resources inefficiently. The authors propose to instead use multi - scale padding from neighboring sectors of the target point cloud, preceding sector from the current scan and following sector of the past scan, which adds spatial context to the model's representation of the sectors. They also propose to use feature undistortion and range stratified convolutions to improve the core of the proposed method. Experimental results show that the proposed methods achieve comparable results to existing non - streaming based methods but with a higher spatial context.    The main contributions of this paper are the following :   1. The use of the P - COP coordinate system to represent neighboring sectors in the view of the lidar model provides spatial context for the sectors from the target and preceding clouds ; and 2. The addition of the features from the neighboring sectors to the view from the point cloud allows the model to perceive the preceding and following sectors more clearly."
SP:7ae2c5b7d9c8a6c8f4a353606aa419929c47f31b,"The paper proposes a novel deep learning model based on score function estimators for learning latent variables from structured domains. Traditionally, the standard approach for learning with discrete latent variables is to use a differentiable surrogate for training such that the gradient estimates are unbiased. The paper proposes to avoid this by leveraging the score function surrogates by extending the Gumbel - Max trick to the structured domain setting. The authors highlight a family of recursive algorithms with a common feature ( stochastic invariant ) that allows them to construct reliable gradient estimates and control variates without additional constraints on the model. The main contribution of the paper is the extension of score function gradient estimators to the domain setting of structured latent variable models and use them for learning score functions in order to avoid the bias issue of gradient estimates of the surrogate gradient estimator. The obtained estimators generalize well to other domains and are competitive with relaxation - based counterparts. In experiments, the authors apply their model to three different latent variable domains and achieve good results compared to two other models based on differentiable surrogates that don't provide gradient estimates."
SP:415d363c66a6967c1daca9dc02001b85bf7f0752,"This paper proposes GainTuning, a methodology by which CNN models pre - trained on large datasets can be adaptively and selectively adjusted for individual test images to improve their performance on standard image - denoising benchmarks. The proposed method is based on the idea that it is possible to train denoisers on a single noisy image to reconstruct the structure of catalytic nanoparticles from a synthetic dataset with extremely low signal - to - noise ratios. To avoid overfitting, the authors optimizes a single multiplicative scaling parameter ( $ \mathcal{L}$ ) of each channel of each CNN in the convolutional layers of the CNNs, corresponding to the noise level or image type of the synthetic data. The authors provide experiments on three image datasets ( CIFAR-10, Imagenet, MNIST and Fashion - MNIST ) where they show that their method achieves state - of - the - art performance on nearly every image in a held - out test set, while achieving more substantial improvements for test images differing systematically from the training data. They also provide results on four different image datasets where the network performs significantly better than when using a CNN model trained only on the test images.   The main contributions of the paper are the following : ( 1 ) The authors propose a method to adaptively adjust the parameters of CNNs by pre - training them on synthetic data using a network architecture that is different from the one used in the training ; ( 2 ) The method is compared with a method that uses a trained CNN model to predict the distribution of the catalytic particles from a training dataset and to the one that is used to train the denoiser. The results show that the proposed method gives improved performance over the one trained on the training dataset but worse performance on test images that deviate from training distribution."
SP:90afa1102683b456bc72a54abef466326827546a,"This paper proposes a combinatorial optimization method ( COPS ) for the problem of instance segmentation ( a.k.a panoptic segmentation ), consisting of a convolutional neural network and an asymmetric multi - way cut problem solver. The proposed method, called backpropagating through the optimization problem w.r.t. w ( w^t^t + w ), is based on the gradient descent approach of [ 1 ] and [ 2 ], where the goal is to maximize a smooth surrogate of the quality metric G_\theta ( i.e., the distance between the input and output dimensions of a sample from the output dimension of a segmentation instance ). The authors argue that this is the most natural way to solve the problem since prior methods ( e.g., G_0 and G_1 ) do n’t directly maximize the distance but only the average value of the input dimension, while the gradient flow maximizes the overall distance.    The authors then describe their approach and show that it is comparable to the one used in COCO ( Xie et. al., 2021 ) and Cityscapes ( Wang & Hsu, 2020 ), a set of combinatorially solvable dataset for instance segmentations of real world data. They further argue that COPS is important because it provides insights into how to incorporate semantic and boundary predictions into training such an architecture. Finally, the authors present an empirical evaluation of their method, in which they show that their method yields better results than the one they use ( COCPO ) and show the benefits of using optimization in tandem with deep learning ( Wang et al. 2021 )."
SP:1952e174d9ec7b83ad1d394ece7fe77ea1f6d78d,"This paper proposes Recursive Bayesian Networks ( RBNs ), a generalisation and unify PCFGs and DBNs, combining their strengths and containing both as special cases. Unlike dynamic bayesian networks ( DBNs ) which use discrete latent variables and hierarchical dependency structures, RBNS assume continuous latent variables, hierarchical structure and discrete dependencies. They define a joint distribution over tree - structured latent variables over discrete or continuous variables, which allows for segmentation and tree induction from noisy sequences. They additionally derive an analytic approximation of the marginal data likelihood ( evidence ) and marginal posterior distribution, allowing for robust parameter optimisation and Bayesian inference. On synthetic data, they demonstrate the advantage of Rbnas over DBNs on segmentation, tree induction and hierarchical clustering. On music, they approach the unsolved problem of hierarchical music analysis from the raw note level and compare their results to expert annotations. They provide two solutions : ( 1 ) for arbitrary Rbns and ( 2 ) for cases where the latent variables are assumed to be continuous and also to have a nested hierarchical dependency structure. In the first case, the continuous latent variable is estimated using gradient descent, while marginalising over network structures, in the second case, using the exponential number of possible structures and the continuous variables.   The authors provide the empirical results on two synthetic data instances :    1. Segmentation of the synthetic data by RBN ; 2. Tree induction of a synthetic data distribution by Rbn ;   3. A musical data application where they first consider the toy example and then the more realistic synthetic data obtained from the Gaussian distribution."
SP:5f29b169d3e4bbaeeec85e1aeebe2094fae4be6e,"The paper proposes constrained backpropagation ( CBP ) algorithm based on the pseudo - range multiplier method to obtain the optimal set of weights that satisfies a given set of constraints. The defining characteristic of the proposed CBP algorithm is the utilization of a Lagrangian function ( loss function plus constraint function ) as its objective function. The authors considered various types of constraints — binary, ternary, one - bit shift, and two - bits - shift by employing appropriate constraint functions. The proposed algorithm outperforms the state - of - the - art methods on ImageNet, ImageNet and GoogleNet with ImageNet - like accuracy ( up to 74.4 % ). This highlights CBP as a learning algorithm to address diverse constraints with the minimal performance loss.   The code for CBP is publicly available at https://github.com/dooseokjeong/CBP and the source code is available online. The main contributions of the paper are the following :    1. The paper introduces a new constraint function, the Lagrange multiplier, to constrain the loss function of Backward Proposal of Errors ( BackPropagation ), which is a method to minimize objective functions ( e.g., loss functions ) of deep neural networks by identifying optimal sets of weights and biases 2. The motivation behind this constraint function is that existing algorithms, such as back - propagation of errors, do not have the capability to consider constraints on weight precision. 3. The constraint function allows the algorithm to learn a weight distribution that is optimal for a given the given constraints. 4. The method is evaluated on several standard deep neural network architectures and achieves accuracy up to 64.0 % for ResNet-18 and ResNet50 with binary constraints, and achieves a top - 1 accuracy of 64.1 % for those architectures. 5. The algorithm is also able to achieve high accuracy for some architectures when using the one - part - two - bit - shift constraint function."
SP:3ddf8e2e108fb261bb23aec8a27a25aba7523dc1,"This paper studies two active learning scenarios for Gaussian Process Classification ( GPC ), where the active learning strategy is to maximize the estimated error reduction ( EER ), which is typically prohibitive as it requires retraining the GPC with every new query. As the EER is not smooth, it can not be combined with gradient - based optimization techniques to efficiently explore the continuous instance space for query synthesis, which leads to computationally inefficient algorithms. In this paper, the authors develop computationally efficient algorithms for EER - based active learning and active learning with GPC. The main contributions include :   ( 1 ) A new active learning algorithm based on EER reduces the classification error after training with the new acquired instance in a onestep - look - ahead manner. The authors also derive the gradient chain rule to efficiently calculate the gradient of the acquisition function in order to reduce the computational overhead of the algorithm. ( 2 ) Two algorithms are proposed, one for discrete instances set ( pool - based scenario ) and one for continuous instances space ( query synthesis scenario ). The experiments clearly demonstrate the computational efficiency of the proposed algorithms. ( 3 ) The proposed algorithms are tested on both synthetic and real - world datasets, which show superior performance in terms of sampling efficiency compared to the existing state - of - the - art algorithms."
SP:fa1fac04cd4ccb1f3eaf80807db09f9683ce6b50,"This paper studies the effect of over - regularization of variational autoencoder - based models ( VAE ) on training continuous variational variational approximations of the energy function in the presence of low - dimensional features ( e.g. natural images ). The authors consider two settings : ( 1 ) the case where the variational parametrization is assumed to be continuous and ( 2 ) where it is assumed that the parameters of the model are unobservable and can be parameterized by a finite - dimensional feature vector. The paper finds that under the assumption that the feature vector is parametrized by a fixed - dimensional vector, the VAE energy function converges to an energy function with infinite gradients around $ \mathbb{R}^2 $, where $ R$ is the number of samples and $ G$ is a measure of the dimension of the space of gradients used to train the model. However, the authors find that under certain assumptions on the assumptions and guarantees in VAE, the gradients of interest tend to infinity. This leads to the conclusion that there may be heuristics in the choice of parameters for the energy functions of VAE models, and that large gradients should be accommodated to the extent possible. The main finding is investigated in terms of the difference between the expected log - likelihood of a VAE model with and without under - regularized variational regularization, and the difference in the case when the model is applied to real - valued samples ( $ n$ ).   The main result of the study is that under $ n > 2, VAE suffers from poor generated sample quality and suboptimal feature selection. This result is summarized as follows :   1 ) for $ n=2 $ n/2 $ where $ n \leq_{\text{O}^n } = \nabla_O(\log n)$ and $ \log n+\gamma_Omega_H$ where $ \eta(0,1)$ is an integer modulo some noise in the $ n>2 $ \gamma$ feature vector and $ Omega$ a \bar{H}$ is modeled as a Gaussian whose parameters are the same as those of the real valued samples $ n$.   2 ) For $ n < 1 $, the main result is that for $ N=1 $ and $ N > 2 $, for all $ N \epsilon$ weights $ \lambda_{Omega>"
SP:2611cfd6e0696a57d061687993cef1fe5c95999d,"This paper studies the min - max regret of a directed graph G = ( V, E ), where V is the collection of bandit arms and E is the total number of incident arms. The paper proposes the k - packing independence number capturing upper bound and lower bound for the regret corresponding to the graph's graph packing problem and shows how it relates to the linear program of the weakly dominating set and its dual, the fractional vertex packing set. Based on this connection, the paper uses the strong duality theorem to prove a general regret upper bound of O ( 3 ) where O is the integrality gap for the vertex packing problem including trees and graphs with bounded degree. Moreover, it shows that for several special families of graphs, one can get rid of the ( log | V | ) 3 factor and establish optimal regret for a fixed set of graphs by using the Strong Duality theorem.   The main contribution of this paper is to study the relation between the graph packing problems and regret via the notions of fractional weak domination number ( F$ ) and k - packed independence number ( K$ ), and show how the two notions are inherently connected via aligning them with the Linear Program of the Weakly Dominating Sets ( LPS ), which is a set composed of the dominant set, its fractional sub - sets, and the sub - set that is not so dominant. F$ and K$ can be used to obtain upper and lower bounds of the regret in the bandit problem setting, respectively. This paper also provides a procedure for testing the regret of trees planted with a k-packing problem with a bounded integral error. The procedure is referred to as the “ tree packing procedure ”, and it is important to distinguish between tree packing problems with bounded error and those with no bounded error. This procedure is important because in the tree packing problem, the probability of finding a planted k-packing node larger than a threshold value than any threshold value is low. The probability is used to establish upper bound regret of the tree planted with K-punchunk."
SP:e50dec57af337839cbde4b65fb7b431785fda44d,"This paper considers the formulation of neighbourhood reference distributions to improve the local interpretability of Neighbourhood Shapley values. In particular, it considers the Nadaraya - Watson estimator, a well - studied kernel regressor, which can be expressed as a self - normalised importance sampling estimator by replacing the global population of the estimator with a local population. The paper shows that the formulation results in an increase in on - manifold explainability and robustness to the construction of adversarial classifiers. The main contributions of the paper are as follows : 1 ) it proposes to use the well - known and well - validated Nadarayaswadi estimator to formulate the neighbourhood reference distribution, which is then used to obtain the neighbourhood values. 2 ) The paper then applies the derived neighbourhood values to a set of sparse feature relevance attributions that are derived from the local model behaviour, and shows that they are more interpretable than the value estimators that are based on global population. 3 ) They show that the obtained neighbourhood values are better interpretable and robust to adversarial inference than the values based on a global population, and 4 ) they provide more explainability to the classifiers developed by the paper."
SP:35bdeb78f9fe74e754177fb54b48e7399dc8590d,"This paper proposes PlayVirtual, a method for generating cycle - consistent trajectories for deep reinforcement learning ( DRL ) with limited data inefficiency for training un - experienced or less - experienced agents. The method is based on two components : a forward - projected state - action model ( PAM ) that predicts the future state and action by taking in the current state and the action taken by the agent and applying the learned dynamics model ( PDM ) to it, and a backward projection from the PAM to the previous states of the state and actions that were predicted by the PDM. The PAM predicts the states and actions, and the backward projections are used to generate a trajectory cycle to ensure that the trajectories meet the cycle consistency constraint, which can enhance the data efficiency for training DRL agents. This trajectory cycle is then used to predict future states and previous states from the latent space using PAM and PDM, which are then used for training the DRL agent. The authors validate the effectiveness of their method on the Atari and DeepMind Control benchmarks. They demonstrate that their method achieves the state - of - the - art performance on both benchmarks.   The main contributions of this paper are the following : ( 1 ) PAM is an effective predictor of future states in a latent space for DRL ; ( 2 ) PDM and PlayVirtual are complementary and complementary extensions of each other, allowing them to be used together to generate large amounts of virtual trajectories ; ( 3 ) A key innovation of PlayVirtual is that it augments the trajectory cycle generation process with a set of actions that can be used for generating new trajectories in addition to the one generated from PAM in order to augment the one that was generated from the previous one ; and ( 4 ) The experiments demonstrate that the method outperforms other DRL methods in terms of DRL data efficiency and feature learning accuracy on Atari tasks."
SP:ca09e472cbcf2ac8c8c9b192a87df2ed59218210,"This paper proposes a robustness metric for neural networks that measures how well the network's architecture is aligned with the target and noise functions in order to ensure that the network is robust to noisy labels. This is an area that has been understudied in the literature of neural network robustness and has the potential to be a powerful metric for assessing the robustness of neural networks in the era of deep learning. This paper proposes to measure the network ’s predictive power in representations via the test performance of a linear model trained on the learned representations using a small set of clean labels. The authors hypothesize that a network is more robust to noise labels if its architecture is more aligned with target function than noise function, and provide both theoretical and empirical evidence across various neural network architectures and different domains.   The main contributions of this paper are the following :   1. A new robustness measure is proposed that measures the relationship between the architecture of a neural network and the alignments between its architecture and target / noise functions. This can be viewed as a measure of the distance between the network architecture and the target function in terms of how well it aligns with it. The main intuition behind this is that if the architecture is well aligned with its target function ( i.e., the goal function is to maximize the sum of the probability of the input data points that are positive and negative for the output of the target functions ), then the network will be more robust than if it is not well aligned ( the probability is negative when the input is positive but positive when it is negative ). The paper empirically shows that the neural network architecture provides the most predictive power for robustness ( more predictive power is better ) for target functions than noise functions when the architecture does not align with target functions. 2. Empirically, the authors find that neural networks with well aligned architecture provide the highest robustness to noise ( higher robustness than network architecture with low predictive power ). 3. The robustness is further enhanced when the network has well aligned target functions such that its predictive power matches the predictive power of target functions ( higher architecture gives better robustness )."
SP:903727fe028684623a8ccadec210e641ecffc685,"This paper considers the problem of learning reward functions for reinforcement learning ( RL ), where the goal is to learn a reward function that maximizes a task - specific reward function given a task description and a set of transition - and - success examples. This problem is similar to the one addressed in [ 1 ], but differs in that [ 2 ] learns the reward function directly from transitions and successful outcomes, without learning an intermediate reward function. This paper proposes to learn the value function by using a combination of the transition - based reward function and the success - based value function. The value function is defined as a sum of the rewards for transitions and the transitions with high probability, and the control function is learned by maximising the probability that the transitions leading to a given value are also likely to lead to a positive outcome. The paper presents a proof that this value function maximizes the probability of outcomes that follow a certain distribution. The proof is built on the assumption that the distribution over transitions is learned jointly with the transitions and rewards.    The main contributions of this paper are the following contributions :   ( 1 ) A new data - driven Bellman equation is introduced, where examples of successful transitions take the place of the typical reward function in the learning process. This new term replaces the term "" reward function "" in the previous approach and replaces it with "" examples of rewards "". The authors argue that this new term is necessary to ensure that the learned value function converges to the optimal value function without resorting to costly hyperparameters to tune and lines of code to debug. ( see [ 3 ] for details ). ( 2 ) A proof that the obtained value function minimizes the expected value function with respect to the transition and successively larger transitions rewards is then used to learn an effective reward function ( learn the upper bound for the lower bound of the upper and lower bounds of the average value function to optimize the lower and upper bound. ( See [ 4 ] )   [ 5 ] - [ 6 ] This paper presents the experimental results showing that the proposed method outperforms the baselines on average by a large margin on the task description task compared to the cost - aware approach ( which uses the reward functions learned from the transitions - based learning step and the intermediate rewards step. The main differences between the two approaches is that [ 8 ] and [ 9 ] ( where the latter uses the intermediate reward functions learnt from transitions as input and the former uses a value function that is learned directly from successful transitions. The experimental results show that the approach from [ 10 ] outperforms [ 11 ] by a wide margin on average, though the margin is smaller on the tasks considered ( by a margin of 0.02 % ) on the average compared to [ 12 ] ( although this is not entirely explained clearly in the paper )."
SP:39ccbd5909a1d7ed212fe92d8d6843c2c70dfe1f,"This paper studies differentially private stochastic optimization in convex and non - convex losses, with a particular focus on the convex case consisting of the family of non - smooth generalized linear losses ( GLLs ).   The main contributions include :   ( 1 ) A new algorithm for the l2 - case setting called L2 - SGD is proposed, which achieves optimal excess population risk in near - linear time, while the best known differentially public algorithms for general convex loss run in super -linear time. ( 2 ) Several new algorithms are proposed for approximating stationary points of the population risk, for convex lp setting, with only polylogarithmic ( in the dimension ) overhead in the rates. ( 3 ) The first method is proposed for non - private SGD for the case where the loss function is a convex function with dimension $ \sqrt{d}$. ( 4 ) The second method is a generalization of the first method for l2- case, where the losses are smooth. ( 5 ) The third method is an extension of the second one for lp - case, with the additional parameter $ p(1, 2 ) = \frac{d}{p(3,2) } \log p(s, a )$.   This paper is published with supplementary material ( Table 1 and Table 2 ), which contains all the previously published results, as well as the main text and supplementary material not available for the public version ( Table 2 and Table 3 ). The supplementary material can be found at the supplementary material section of this paper. ( Note that Table 1 contains the dimension - wise lower bound of [ AFKT21 ], which is the upper bound of the lower bound for any convex GLL with dimension > p>2 ). ( See Note 1 and Note 2 for the details )   In addition to the above mentioned algorithms, the authors also propose a linear - time algorithm with rate â '(log d ( log d (nε)1/3 ) ) ; d = O( O( n ) )"
SP:99a476f71e6901aefe281f11fb72ff78265a5b6e,"This paper studies the cooperative bandit learning problem in three real - world distributed communication scenarios : message - passing over stochastic time - varying networks, instantaneous reward - sharing over a network with random delays and adversarially corrupted rewards, and two environments where the communication is adversarial. The paper presents decentralized algorithms that achieve competitive performance in each of the three scenarios, and proposes near - optimal guarantees on the incurred group regret as well as an improved delayed - update algorithm for the second scenario. The proposed algorithms are straightforward to implement and obtain competitive performance, according to the authors.    The main contributions of this paper are the following :   1. The authors study the problem of cooperative learning in three distributed communication settings, where the goal is to learn a good network - based policy distribution. This is different from previous work which studies cooperative learning only in the setting of perfect communication, as in this paper the authors consider distributed communication with arbitrary corruptions and delays. In particular, they consider three environments where it is possible for the policy distribution to be adversarial corrupted rewards ( e.g., adversarial communication with a Byzantine communication policy ), time varying delays, and instantaneous rewards. They show that in two of the environments, cooperative learning with adversarial corruptions achieves competitive performance. In the other two environments, the proposed decentralized algorithms achieve near optimal performance in the case of instantaneous rewards and improved delayed updates for the reward sharing, and the authors propose near optimal guarantees for the third environment where the agent learns a good policy distribution using a greedy network - agnostic policy distribution ( the final policy distribution is the result of the decentralized algorithm proposed in the paper ). This paper is interesting and well presented, and it is worth checking the quality of the experiments to see if the authors have compared their decentralized algorithms with the one based on perfect communication. The experiments and the improvements they propose for instantaneous reward sharing do not significantly improve the performance of the agent in the instantaneous reward sharing case. The improvements for instantaneous delays and the greedy network network learning do not improve the agent's performance. The improvement for the instantaneous rewards learning case is the best of the authors tested their decentralized algorithm for ( a ), ( b ), and ( c )."
SP:d3e896a65470f2439bc7753b4f66e152306b2d6f,"This paper proposes VTPTQ, a post - training quantization algorithm for training vision transformers that uses low - bit quantization intervals to reduce the memory storage and computational cost of training transformers. To preserve the functionality of the attention mechanism, the authors introduce a ranking loss into the quantization objective that aims to keep the relative order of the self - attention results after quantization. The authors also analyze the relationship between quantization loss of different layers and the feature diversity, and explore a mixed - precision quantization scheme by exploiting the nuclear norm of each layer. The experimental results demonstrate the effectiveness of the proposed method on several benchmark models and datasets, which outperforms the state - of - the - art post - hoc quantization and mixed - precision quantization algorithms of previous work.   The main contributions of the paper are as follows :   1. The paper proposes a quantization method that uses 8 - bit intervals for quantization of weights and inputs to approximate the task of finding the optimal low - bits of quantization for each layer in the transformer architecture. This method is evaluated empirically on ImageNet using DeiT - B model and compared to several other methods. The results demonstrate that VTPQ achieves better performance compared to other methods, and the authors further investigate the effect of the different quantization methods on the quality of the feature representations extracted from transformers with different layers."
SP:aa6b1328585b5916267a3ff4f9119e7aa4ce2bb5,"This paper studies the convergence rate of synchronous and asynchronous Double Q - learning ( DQ - learning ), which is a special type of Q learning method that uses a polynomial learning rate in order to overcome the overestimation problem. The theoretical contribution of this paper is to develop analytical tools that improve the existing convergence rate by order of magnitude when considering the case of a constant learning rate. To this end, first, the authors use the existing finite - time analysis framework established in ( Xie et al., 2020 ) to study the convergence of DQ learning. This analysis considers the case when the learning rate is constant, where polynomials are used as the learning rates. The authors show that the synchronous algorithm converges to a global optimum with a time complexity of $ \ell_2 $ ( lnD / \le M ( 1 + \gamma_7 ) $, where $ M$ is the number of samples and $ L$ is a parameter related to the sampling strategy for the asynchronous algorithm. On the other hand, asynchronous algorithm uses a parametrization of $ L$. The authors then show that under certain assumptions ( e.g., L being the dimensionality of the state - action space, $ D$ the discount factor, and L the dependency on the parameters of asynchronous algorithm ), the algorithms converge to the global optimum in ~2 hours. This shows that synchronous double Q - Learning attains an - accurate global optimum ( $ \le \le\mm{D}$ ; $ L(\le D / m)$ ; \epsilence ), while asynchronous algorithm attains a time - aware of $ l(\lambda_7)$.   The second contribution of the paper is a new analytical tool that uses the existing analytical tools from Xie et. al. to generate graphs showing the convergence rates of the synchronised and asynchronous algorithms. The graphs are simple and easy to understand, and the authors have compared their results with those of previous work. The experimental results show that their methods converge faster and more accurately than the previous methods, which the authors claim as being more in line with the empirical observations. The paper is also interesting and well written, and is worth reading."
SP:04fd4d83717c4f7e1a4b5651a59200151f33411d,"This paper studies semi - supervised OOD detection using an approach called Structure - keep - unzipping ( STU ).   This approach builds upon the idea of semi supervised learning ( SSL ), where the goal is to train an algorithm that can detect out - of - distribution ( OOD ) samples ( i.e., unlabeled ) samples from the same distribution as labeled data, while also being able to detect OOD samples from an unknown distribution ( ii ) that could be unseen during training. The main challenges that the authors tackle in this setting are i ) the lack of labeled data and in - distribution data ; ii ) the possibility that some of the samples could be seen during training and could be difficult to classify. The authors propose a novel approach called STU - SGD ( Structure - Keep - Unzipping - Gradient Gradient Update ) to learn a new representation space in which the hidden samples of the algorithm could be separated well so that the learned space could be used to efficiently optimize the gradients of the optimization algorithm. The paper also proposes a new technique called STRA - MLE ( Single - Shot - Out - Of - Distillation - Drop - In - Hand ) to further improve the performance of the proposed algorithm, which is based on the idea that it can learn a feature extraction strategy that allows it to distinguish between samples that are likely to be seen as part of the labeled data distribution ( i ) and samples that may have been generated by the algorithm while being away from the labeled distribution ; and finally, a variant of STU that allows the algorithm to detect samples that were generated during training that were likely generated outside of the training data distribution. In experiments, the authors compare STU with other methods on several benchmarks. They show that STU outperforms other methods including other methods by a large margin and achieves significant improvements in detection performance over other methods in terms of detection accuracy. They also provide a set of experiments that compare their approach to other methods that are not based on STU and other methods based on other methods, showing that their approach is more efficient and more robust than other methods and achieves similar or better results than the best of the other methods they compare. The experiments are divided into two parts. The first part is about training the algorithm in a supervised setting where the labels and test data are not available, and the second part includes experiments that use the STU technique to train the algorithm without labeled data or test data. The second part compares the performances of the methods from the first part and the one that uses labeled data to the ones used in the training. They find that the approach significantly improves the performance. However, there are still some issues with the performance ( especially in the experiments with the"
SP:6bf8b94483b26033795b0eda9649518027f5e1c2,"This paper proposes a transformer - based multi - task framework for grounding visual tasks, where two modalities are fused in a visual - lingual encoder, where the encoder generates contextualized lingual queries and the decoder uses them to directly regress the bounding box of the ELBO. The framework is built on the Transformer framework from Yao et al. ( 2021 ), where a transformer encoder is used to fuse two representations of the same modality ( e.g., text embeddings and images ) into the same embedding space, and a decoder is learned to predict the queries from the two representations. The decoder and decoder are trained in a two - stage manner : in the first stage, the model learns to generate contextualized queries, and in the second stage, it uses the queries generated by the contextualized query generator to produce segmentation masks for the corresponding regions of the input. The method is applied to three visual grounding tasks : Segmentation of Locomotion Representations ( RE ), Graph Representations of Graph Structures ( GRAPHIC ), Referencing Expressions of Symbolic Symbols ( RE - SGD ), and Point - of - view segmentation ( POS ). The experiments show that the proposed framework performs well on all three tasks, with slightly better performance than the baselines that are used in the training of the model. The authors also show that a simple pre - training schedule ( on an external dataset ) further improves the performance of the proposed model."
SP:29b552b36696c9bda72f3ab4f31605d98880fd6b,"This paper studies the problem of boosting based on the idea of combining weak and moderately inaccurate hypotheses to a strong and accurate one. The weak learner is assumed to belong to an easy - to - learn class, and the booster is an agnostic PAC learner for that class with respect to the standard classification loss. The goal of the overall boosting algorithm is then to learn a combination of weak hypotheses by repeatedly calling the weak learnersner. The paper studies multiclass boosting with a possibly large number of classes or categories. In particular, it focuses on an especially natural formulation in which the weak hypotheses are assumed to be easy to learn. This is in contrast with other, more complicated losses as have often been considered in the past.   The paper first analyzes the resources required for boosting, especially how they depend on the number of class k, for both the booster and the weaklearner. It shows that the booster only requires O(log k ) samples for each class k to learn the weak hypothesis. Then, it shows that there is a trade - off between number of oracle calls and resources required of weak learners, with the fewer calls to weak learners the more that is demanded on each call. When class k is large, the weaker learner ’s accuracy parameter must be smaller than an inverse polynomial in k, showing that the returned weak hypotheses must be nearly the best in their class when class is large. Finally, the paper provides theoretical guarantees for the robustness of the boosting algorithm against counter - intuitively weaker counterintuitively weaker hypotheses."
SP:f63b050773871338c48b778c362172e4b72477a4,"This paper proposes a clustering - based approach to embedding - based generative modeling for unsupervised image segmentation and object - centric scene generation ( both in synthetic and real - world datasets ). The embedding is modelled using a stochastic stick - breaking process, where embeddings of pixels are clustered in a differentiable fashion using a fixed number of clusters. The paper proposes to use this clustering procedure to generate a new model, GENESIS - V2, which can infer a variable number of object representations without using RNNs or iterative refinement. The authors evaluate the performance of the new model on synthetic datasets ( CIFAR-10, CelebA - HQ, CelebWorld ) and datasets with more complex object representations ( Arrhythmia ), and compare it to two baselines ( GANs and RNN - GAN ).    The main contributions of this paper are the following : 1 ) A new model is proposed for object segmentation of synthetic images ; 2 ) A clustering approach is used to model embedding of pixels in differentiable ways, leading to a more interpretable embedding from the original image embedding. The method is compared with baselines for both simulated and real world datasets. The results show that the proposed approach ( with the exception of the clustering method ) outperforms the baselines in terms of performance on synthetic data and interpretability of the object representations, while being slightly less interpretable on real data."
SP:408deb9e5577ee7118b836fee77135df641fe545,"This paper proposes adaptive conformal inference ( AC ) for generating prediction sets in an online setting where the data generating distribution is allowed to vary over time in an unknown fashion. The main idea is to model the distribution shift as a learning problem in a single parameter whose optimal value is varying over time and must be continuously re -estimated. AC is a general approach that can be combined with any black box method that produces point predictions of the unseen label or estimated quantiles of its distribution. The authors test AC on two real world datasets and find that its predictions are robust to visible and significant distribution shifts.   The main contributions of this paper are the following :   1. A new approach to model distribution shifts in a learning setting based on a parametric autoencoder. This approach is similar in spirit to the Adaptive Conformal Inference ( AdaEI ) approach from Yin and Zhou ( 2021 ), but is different in that it explicitly considers the possibility that the distribution of the data points sampled from the generator during the data generation process could be different from the true data generating process. This allows for more flexibility when computing the predictions for the generator points. The key difference is that AdaEi considers the generating process as an adaptive learning problem, while AC considers the distribution as a discrete function that is sampled from a fixed distribution at each time step. The advantage of this approach is that it does n’t require the true generating process to be known in advance. 2. A variant of AC, called ADAMETRA, is used to predict the likelihood of the generator predictions for a given data point from a black box dataset. This method is quite similar to the approach of Jin et al. ( 2020 ), who also use a parametrization of the black box data to make predictions for unseen labels. 3. 4. Finally, the authors propose a method for estimating the log likelihood of a predicted label from the predicted distribution of log likelihoods of the generated data, which they call LADIES. This is similar to AC, but differs in that the authors explicitly state the importance of the predicted labels for the predicted data distribution and do not require the data distribution."
SP:e6e5b1e2428abcf1a163ec1cce15cd299f9a544f,"This paper proposes Pose - based Inference Network ( PINet ) for multi - person pose estimation in crowded scenes. The main idea is to avoid bounding boxes and infer pose cues from individual keypoints by using a pose - level network that is free of bounding box detection and keypoint grouping. PINet first applies the Part - based Pose Generation ( PPG ) to infer multiple coarse poses for each person from his / her body parts, refined by the Pose Refinement module through incorporating pose priors, and finally fused in the Pose Fusion module to obtain the global pose estimation.   The main contributions of the paper are the following :    ( 1 ) PINet - A pose estimation network that directly predicts the pose for a person based on body parts from the multi - view multi - pose estimation ( MPS ) ; ( 2 ) A method to refine the coarse poses used in PINet to obtain more refined global pose estimates ; ( 3 ) An approach to estimate the pose of different body parts using discriminative body parts to differentiate overlapped persons and applies visual body cues to infer global pose cues ; and ( 4 ) A procedure to approximate the depth of the facial expression using the relative positions of body parts and the angle of the head and body to the body parts in order to generate the final pose estimation for each body part. The method is validated on the OCH dataset and compared with several other methods. The results demonstrate the superiority of PINet over other methods and demonstrate the flexibility of the methods compared to PINet."
SP:e76f048c3dccffcb8bcc6a66f6165fc19d175610,"This paper proposes a new algorithm for computing the Bellman operator for S - rectangular robust Markov decision processes with L - concained rectangular ambiguity sets. The algorithm combines a novel homotopy continuation method with a bisection method to solve S - rectangular ambiguity in quasi - linear time in the number of states and actions. The proposed algorithm improves on the cubic time required by leading general linear programming methods. The experimental results confirm the practical viability of the method and show that it outperforms a leading commercial optimization package by several orders of magnitude.    The main contributions of this paper are as follows :   1. A new algorithm, Bellman, is proposed to solve the S - Rectangular Markov Decision Process ( RMDPs ) with L-constrained rectangular ambigamens sets. This algorithm is claimed to be the only one that combines the homotopoeic continuation method and bisection algorithm. The authors claim that it is faster and more efficient than the one proposed by [ 1 ] and [ 2 ]. The major contributions of the paper are the following : 1. It proposes a novel algorithm that improves the time complexity of solving the RMDP problem with bisection methods. 2. It is the first time that the authors have used bisection in solving RMDP problems. The use of bisection has been previously introduced in [ 3 ], but the benefits of using it are not immediately apparent. The benefits come only from the fact that the bisection is easier to apply in this case. The advantages come from the simplicity of the proposed method compared to the previous two methods, as both methods require access to a large set of states. 3. The main drawbacks are the complexity of the algorithms and the factorial nature of the Bisection used for computing Bellman. The novelty of the ideas in this paper comes from combining homotopic continuosities and bisections."
SP:c4af66a64a5c2bd58ca2e29dbc4b27d5bf4b63b8,"This paper continues the line of work by studying the online knapsack problem, but with very weak predictions : in the form of knowing an upper and lower bound for the number of items of each value. They systematically derive online algorithms that attain the best possible competitive ratio for any fixed prediction ; they extend the results to more general settings such as generalized one - way trading and two - stage online knapack, and their experiments show that even seemingly weak predictions can be utilized effectively to provably improve the performance of online algorithms.   The main contributions of this paper are as follows :   1. The authors study a general online algorithm to obtain a set of fixed parameters that allows one to obtain an upper bound on the expected return for the sum of the lowest and highest possible value of any pair of items obtained from the online algorithm ; 2. They use this lower bound to obtain the upper bound of the ratio between the expected returns of the top and the expected values of the items from the algorithm ; and 3. They apply this upper bound to the algorithm and the resulting lower bound is used to update the guarantee of the algorithm to ensure that the final competitive ratio is higher than the lower bound. The algorithm is trained using supervised learning ( using machine - learned predictions ) and empirical evidence is provided that this updating procedure is effective. The experimental results demonstrate that even with the weak predictions, the algorithm provably improves the performance. 3. A follow - up study is performed to verify their results and compare their algorithm with other algorithms they have used in the past, showing that their approach is not only more efficient but more effective in general."
SP:1d478d4fa3f5df0ded963ef164325667fd744dbb,"This paper proposes a new method to build an episodic memory for reinforcement learning. The idea is to use the learned trajectories from previous experiences to estimate value values for the current policy in order to guide the learning process towards good policies. Based on the learned trajectory values, the authors propose to build a learning model that combines model - based, episodic and habitual learning into a single architecture. The learning model consists of three components : ( 1 ) A learned baseline that computes the trajectory values from the past experiences ( using an auto - regressive mechanism similar to what is used in SimCLR ) ( 2 ) A self - supervised learning method that learns from the trajectories generated by the self - supervision mechanism in the baseline. ( 3 ) A learning method based on a learned baseline from past experiences that learns the values of the previously generated trajectories.   The experiments compare the proposed method with other reinforcement learning methods in different settings including stochastic and non - Markovian settings. The main finding is that the proposed model is faster and more robust to perturbations in the environment than the other methods."
SP:551174c1266b5f4b6aaf5432a4c713386f90898c," Semi - supervised learning ( SSL ) is a promising technique to leverage unlabeled data by providing pseudo labels. However, when the size of labeled data is very small ( say a few labeled samples per class ), SSL performs poorly and unstably. This paper proposes a new SSL method called DP - SSL that adopts an innovative data programming ( DP ) scheme to generate probabilistic labels for unlabelED data. Different from existing DP methods that rely on human experts to provide initial labeling functions ( LFs ), the authors develop a multiple - choice learning ( MCL ) based approach to automatically generate LFs from scratch in SSL style. With the LFs produced by the authors, they design a label model to resolve the conflict and overlap among the noisy labels, and finally infer a label distribution. The experimental results on four standard SSL benchmarks show that DP -SSL can provide reliable labels and achieve better classification performance on test sets than existing SSL methods, especially when only a small number of labeled samples are available. For example, for CIFAR-10 with only 40 labeled samples, DP - RSA achieves 93.82% annotation accuracy and 93.46% classification accuracy on test data."
SP:d1d6a40a8bde62a21da4fc18a076e344c84ab0d0,"This paper presents MVPT ( Multi - View Pose Transformer ), a method for estimating 3D 3D joint locations of multi - person skeleton joints from multi - view images using volumetric skeleton joints. The key idea of the method is to use a query embedding of skeleton joints for estimating joint locations directly from the 3D pose representations obtained from the multi - views. This is in contrast to previous approaches that relied on estimating per - person or joint pose from multiple detected 2D skeleton joints as in previous methods. The method presents a hierarchical scheme to concisely represent query embeddings of the joints and introduces an input dependent query adaptation approach to improve the accuracy of the estimated joint locations.   The method is evaluated on the Panoptic dataset and compared with state - of - the - art methods on several benchmarks. The main contributions of the paper are the following :   ( 1 ) MVP presents a novel and efficient representation of the joint joints, representing skeleton joints in a learnable embedding format. ( 2 ) It introduces a RayConv operation to integrate the view - dependent camera geometry into the feature representations for augmenting the projective attention of the proposed embedding. ( 3 ) It uses the learned embedding to estimate the joint locations from the input images to directly regress the actual 3D joints. ( 4 ) It is experimentally verified that the proposed method achieves better accuracy than the previous best approach AP25 ( Wang et al., 2021 ) on the challenging PanOptic dataset, thus setting a new SOTA."
SP:2e147bd5321e25bb27d2531fd58c46460a1e5320,"This paper proposes two sets of generalizations of support recovery and approximate recovery problems based on Gandikota et al. 2020 ( 2020 ). The first problem is to design queries such that all sparse vectors from the family can be approximately reconstructed based on the error - free responses to queries using a learning model that was introduced in the work of [ 1 ]. The second problem is similar in spirit to [ 2 ], except that instead of vectors, they use a sequence of noisy responses to represent the inner product between a randomly chosen query vector and the query vector in the first problem. The authors provide the necessary conditions under which each response to a query vector can be reconstructed to produce an inner product of the query and the response vector. The problem is well - studied using the framework of 1 - bit compressed sensing.   The authors prove the existence of the learning algorithms for the first and second problem which work without any assumptions. Under a mild structural assumption on the unknown vectors, the authors propose two learning algorithms that analyze query complexity to estimate the supports of all the possible query vectors from a family of sparse vectors with most k non - zero elements. They show that the first one is robust and the second one is not. The experiments demonstrate that the robust algorithm is better than the one used for the second problem. However, the experimental results do not support the claim that the algorithm is superior to the robust one because it is unable to recover the full extent of the support for query vectors. The main contribution of the paper is therefore limited to supporting the robust learning algorithm and the experiments do not provide any theoretical analysis of the robustness of the other than to compare and contrast the performance of the two algorithms against each other learning algorithms."
SP:e3388e479a825be429f3a878e2c4d8b05903ff10,"This paper considers the bandit - quickest changepoint detection problem, where sensing actions ( or sensors ) are sequentially chosen, and only measurements corresponding to the chosen actions are observed. The authors propose a novel and computationally efficient online sensing scheme, which seamlessly balances the need for exploration of different sensing options with exploitation of querying informative actions. The main contributions include :    ( 1 ) The main contribution is to propose an information - theoretic lower bound on the detection delay for a general class of finitely parameterized probability distributions, and to derive expected delay bounds for the proposed scheme and show that these bounds match the information - theoretic lower bounds at low false alarm rates. ( 2 ) The authors conduct a number of experiments on synthetic and real datasets to demonstrate the effectiveness of their proposed method, which they claim to have used for detecting abrupt changes in temporal behavior patterns."
SP:268260e9452ba2bc57e50a6b7b3328233137ac9b,"This paper proposes ALTERNATING STochastic Gradient DEscenT ( ALSET ) for nested optimization of stochastic bilevel, min - max, and compositional optimization problems. It unifies several SGD - type updates for nested problems into a single SGD approach that the authors term ALternating SGD Update ( AD Update ). The main contributions are : ( 1 ) to leverage the hidden smoothness of the nested problem to make the analysis more tractable, this paper proposes a tighter analysis of the original SGD update, ( 2 ) to make sure that the proposed AD Update matches the best - known sample complexity in the respective cases, and ( 3 ) to improve the convergence of the SGD updates proposed in this paper. The experiments are conducted on three nested optimization problems, where each problem consists of 3 classes : 1 ) a nested optimization problem over a set of linear functions ( e.g., bilinearly symmetric bilinear ), 2 ) a cross - entropy - regularization problem over functions over non - linear functions, and 3 ) a compositional problem over weighted lists, where the weights of the non - compositional problems are re - weighted according to the order of the weights in the nested problems. The authors compare the convergence rate of AD Update with SGD, and show that it converges at a slower rate, which is argued to be due to the fact that in nested problems the number of variables tends to infinity, whereas in non - nested problems it tends to zero at some point. ( 4 ) In addition, the authors propose an additional procedure called ALTERNATE that combines SGD and AD Update to get rid of the need for updating the first variable in AD Update, and get riden of the second variable. This procedure is referred to as Alter Alterate the Gradient ( Alterate ). ( 5 ) In the experiments section, it is shown that the average convergence time of ADET improves over SGD by a significant margin in most cases, though in a few cases it does not. ( 6 ) The authors conduct a series of experiments where they compare the performance of ADETA with the original ADET and a modified ADETA. The experimental results show that in most of the cases the proposed Alterate improves the convergence faster, but in other cases the convergence speed is slower. ( 7 ) In order to evaluate the effectiveness of the proposed ALTERATE the authors conduct another set of experiments which compare the proposed method with"
SP:82ad52361bc5b2c421f1dc6b76e1a5520570fc6c,"This paper proposes a Siamese Sampling and Reasoning ( SiaSamRea ) approach to video question answering ( VQA ) based on fine - tuning each clip - text pair independently on the pretrained transformer - based model via supervised learning. The idea is that multiple samples ( i.e. clips ) from the same video should be interdependent to capture similar visual and semantic information in the video that are similar across different frames. To consider the interdependent knowledge between contextual clips into the network inference, the paper proposes to generate similar clips ( siamese clips ) and a novel reasoning strategy for integrating the inter - dependent knowledge between clip - level contextual information and the one obtained from the transformer model using the reasoning strategy. The reasoning strategy consists of two modules : ( 1 ) siamesese sampling to generate clips that capture similar information across frames and ( 2 ) generation to learn the generative model to produce the label by propagating the weights of the samples generated by the sampling mechanism. The authors supplement the current multimodal reasoning paradigm with the ability of learning from inside via the guidance of soft labels, which leads to improved performance on VideoQA tasks. The experiments demonstrate that the proposed approach achieves state - of - the - art performance on 5 video QA benchmarks. The paper is well - written and well - motivated, with clear explanations and explanations explaining the benefits of the proposed method. However, there are still several weak points in the manuscript, which need to be addressed ( e.g., the authors should discuss these more clearly and clearly.   The main weakness of the paper is that the authors ’ claim to have solved the video QAno / QA problem using the fine - tuned model paradigm, which they claim is “ outdated ” and “ can not keep up “ with current video QAs ”. This claim is not supported by any of the experiments that they compare with the current state of the art in terms of performance ( MSVTT - QA, MSVD-QA, etc., as well as the one they propose. They also claim that the method “ might not be suited for the high - dimensional / high - resolution video settings of today’s high - definition QA datasets. ” This claim may not be supported by the experiments, as the authors also test the model on a lower - resolution version of the dataset ( MSRVTT- QA ), which is far less robust."
SP:160022e2cd61159da92f92e85520b7062a337a8d,"This paper proposes a simple approach to reduce the computational and memory complexity of a large class of structured models, including Hidden Markov Models ( HMMs ) and Probabilistic Context - Free Grammars ( PCFGs ), that are commonly used to learn latent probabilistic representations from observed data. The authors show that by viewing the central inference step as a matrix - vector product and using a low - rank constraint, we can trade off model expressivity and speed via the rank. Experiments with neural parameterized structured models for language modeling, polyphonic music modeling, unsupervised grammar induction, and video modeling show that our approach matches the accuracy of standard models at large state spaces while providing practical speedups."
SP:238592ad73927194cdf0c0cf9ae2e48ca86e182c,"This paper proposes Sample Average Uncertainty ( SAU ), a simple and efficient uncertainty measure for contextual bandits that can be used as a drop - in replacement for epsilongreedy exploration in the exploration - exploitation dilemma. The motivation for introducing SAU is that prior techniques that approximate the parameters of the action - value function have been shown to underperform in the deep bandit scenario due to computational intractability to maintain probability distributions over parameters of outcome models of corresponding complexity. The authors argue that the approximation techniques introduced to mitigate this issue typically result in poor exploration - exploratory trade -offs, as observed in the case of deep neural network models with approximate posterior methods. Because of its simplicity, SAU can be seamlessly applied to deep contextual bandits and is computationally tractable with a small additional computation cost. Empirically, the authors show that SAU - based exploration outperforms current state - of - the - art deep Bayesian bandit methods on several real - world datasets at modest computation cost, and make the code to reproduce the results available at https://github.com /ibm /sau - explore. They also study the effect of assumptions on SAU and show theoretically that the uncertainty measure estimated by SAU asymptotically matches the uncertainty measures provided by Thompson Sampling."
SP:ffc5b18f7e18607b2934e5aa199e7542005d79f4,"This paper proposes Variational Disentangled Behavior Embedding ( VDBE ), an end - to - end approach that learns meaningful discrete behavior representations and generates interpretable behavioral videos from unlabeled, multi - view, high - resolution behavioral videos across different animals and multiple sessions. The authors combine DBE with a stochastic temporal model ( DBE ) to propose Variational disentangled behavior encoder ( VBE ), which learns discrete embedding representations and a dynamic encoder to generate interpretable behavior videos. VBE is trained with behavioral videos generated by DBE and the authors demonstrate superior performance on downstream tasks such as fine - grained behavioral motif generation and behavior decoding. The experiments in neuroscience often include an animal performing a repeated behavior such as a motor task as a control mechanism, and experiments in computer vision and deep learning have shown great potential in the automated analysis of behavior by leveraging large and high - quality video datasets. This paper aims to exploit the potential of this data to learn robust embedding from behavioral videos to better understand the relationship between behavior and neural activity.   The authors learn consistent behavior representations by explicitly disentangling the dynamic behavioral factors ( pose ) in a deep auto - autoencoder ( pose - aware ) framework. They learn the dynamic embedding ( non - parametric expression ) from time - aware ( time - varying ) behavioral factors using a learned feature extractor. They propose VBE to learn the discrete behavior embedding that learns the dynamic behavior representations from the dynamic latent embedding and the actor network ( latent variable ) using an encoder - decoder model. They demonstrate that VBE and VBE can learn the same behavior representations in different environments with different dynamic encoders. They also show superior performance compared to competing approaches to learning the latent representation from time and space."
SP:bf78a450e4aad6b87fdeb8ec0d68adaaff7b595b,"The paper proposes DMTET, a deep 3D conditional generative model that can synthesize high - resolution 3D shapes using simple user guides such as coarse voxels. It marries the merits of implicit and explicit 3D representations by leveraging a novel hybrid 3D representation, which is trained to regress the signed distance values. Compared to the current implicit approaches, which are trained to evaluate the reconstructed distance with a Gaussian Mixture Model ( GMM ), D MTET directly optimizes for the reconstructed surface, which enables the model to synthesize finer geometric details with fewer artifacts. The core of DMT ET includes a deformable tetrahedral grid that encodes a discretized signed distance function and a differentiable marching tetrahedra layer that converts the implicit signed distance representation to the explicit surface mesh representation. This combination allows joint optimization of the surface geometry and the parametric features as well as generation of the hierarchy of the subdivisions using reconstruction and adversarial losses defined explicitly on the surface mesh mesh.   The paper significantly outperforms existing work on conditional shape synthesis synthesis by training a model trained on a dataset of complex 3D animal shapes, trained with arbitrary topology, and trained to generate explicit representations such as meshes."
SP:2bc0bd6aa2a12691b16145f0d23542c4c86e3a44,"This paper proposes sliced mutual information ( SMI ) as a surrogate measure of statistical dependence. SMI is defined as an average of MI terms between one - dimensional random projections, and the authors show that SMI preserves many of the structural properties of classic MI, while gaining scalable computation and efficient estimation from samples. Furthermore, and in contrast to traditional MI, SMI can grow as a result of deterministic transformations, which enables leveraging SMI for feature extraction by optimizing it over processing functions of raw data to identify useful representations thereof. The authors demonstrate the potential gains SMI offers over classic MI for high -dimensional inference."
SP:e220b348901b476c2afd95f97630fb5400582f40,"This paper studies Bayesian Optimization ( BO ) methods for non - myopic optimization of the Monte Carlo rollout acquisition function with expected improvement, with only modest increase in computational cost. The paper mainly focuses on unconstrained BO with a few exceptions, including the reparameterization trick and infinitesimal perturbation analysis. To enable fast acquisition function optimization, the paper proposes a likelihood - ratio - based estimator unbiased estimator of the gradient of the two - step optimal acquisition function ( 2 - OP - T - C ) supporting both sequential and batch settings, with discontinuities introduced in the sampled acquisition function surface. In numerical experiments, 2 - O - BO - C typically improves query efficiency by 2x or more over previous methods, and in some cases by 10X or more.    The main contributions of the paper are the following :   1. The authors develop a novel method for the Bayesian optimization of gradient - based gradient estimators unbiased estimators. Theoretically, the authors prove that the gradient estimator is unbiased if only the parameters of the estimator are Gaussians, and if not, then the gradient estimates are Gaussian. 2. Theorem 1 provides the empirical evidence that under certain assumptions on the distribution of Gaussian perturbations of the mean and covariance of the distribution over the Gaussian distribution with respect to the covariance matrix, the gradient estimate is unbiased. 3. The method is empirically verified using numerical experiments that it is able to achieve better query efficiency than the baselines. 4. The main contribution of this paper is the introduction of a method for finding the optimal solution to the acquisition function under constrained setting where the parametrization assumption is lower than $ \mathcal{O}$ and the assumption assumption is upper - bounded ( $ O(\log O(log n)^T)$ ), and the authors argue that this method is more computationally efficient than other methods that use lower bound $ \log n$ and hence should be used more often. 5. The experiments are conducted to validate the effectiveness of the proposed method."
SP:51fbd861422647912f275b48861ea3c4812afdc8,"This paper proposes Multi - dimensional Distributional DQN ( MD3QN ), which extends distributional RL to model the joint return distribution from multiple reward sources. The main contributions of the paper are as follows :   1. The authors propose a joint distribution model for return distribution between source reward vectors. The joint distribution is optimized by minimizing the Maximum Mean Discrepancy ( MMD ) between return distribution and its Bellman target.   2. In addition, the authors propose Multi - Dimensional Distributional HRA in RL ( MDAHR ) to model source - specific value functions for each source of reward, which is also studied to be more informative than scalar value functions in the value network setting. 3. In experiments with MDPs in environments with richly correlated reward functions, and outperforms previous RL methods utilizing multi -dimensional reward functions    The main contribution of this paper is the introduction of the multi - dimensional distribution model in RL. As the authors note in the paper, there is a growing trend for value - based reinforcement learning ( RL ) algorithms to model more information than the return distribution in order to capture more information about value function properties. As such, it is important to have a good understanding of the properties of the reward sources used in previous work for joint distribution modeling. In this paper, the main contribution is to develop a model that captures the rich reward correlation between the randomness of reward sources in the control setting and the distributional setting with respect to the source reward."
SP:1f85c93d6bbfd65bf497c92c9cd534d799753097,"This paper introduces a new deep learning model, CorticalFlow, that learns to deform a 3 - dimensional reference template towards a target object using a set of diffeomorphic transformations, inspired by the Ordinary Differential Equation (ODE ) framework. This new implementation of theODE allows for the generation of surfaces with several hundred thousand vertices. More importantly, more significantly, the training of the model can be done with a small GPU memory footprint, which allows for faster computation time from nine and a half minutes to one second. To demonstrate the utility of the new model, the authors conduct experiments on the task of brain surface reconstruction, where they first consider the setting of cortical surface reconstruction and show that their model significantly outperforms that of state - of - the - art methods.    The main contributions of this paper are as follows :   1. The authors introduce a new geometric deep - learning model that, given a 3 dimensional image, chooses a template template template to deform towards a reference template to reduce the template mesh ’s topological properties ; this template is then used to train a neural network that generates the target object from the learned template template and the reference template. The goal is to generate surfaces that are anatomically plausible, while minimizing the computation time. This is achieved using a novel method called Cortical Flow ( introduced in Sec 3.1 ), which iteratively generates a new set of plausible points using the same template template, but distributes the points using a different set of transformations. Each of these points corresponds to one of three types of transformations, each of which corresponds to a different type of triangle mesh. These transformations can be thought of as “ diffeomorphism ”. The most likely to lead to a more plausible points ( the first is a max - pooling of points corresponding to the most plausible points ). The second type is an iterative process similar to the one described in Sec 4.1, where points are sampled from the first step of the process according to a max pool. The third step is the “ max pool ” which is a weighted average of all points sampled from each of the first two steps. This last step followed by iterative steps is the smoothing step, where the obtained points correspond to points that are chosen from the max pool of the second step. Theoretical results show that the proposed max pool can be used to generate plausible points more quickly ( less than a third of the time ). However, it is not clear if this means that the generated points are actually more plausible or just that there are less likely to be plausible points, since plausible points are those that the model does not need to learn to deform the template template ( since it does not have to learn the max max pool to deform it from the"
SP:2f31d9cf4ad17ad08344439ca0aef7ec91944545,"This paper studies the problem of adaptive and non - adaptive deletion of data points from trained models by deleting data points at a cheaper cost than retraining the models. Most prior work in the non - convex setting gives valid guarantees only for sequences of deletions that are chosen independently of the models that are published. In this paper, the authors combine ideas from prior work which give guarantees for non -adaptive deletion sequences which gives guarantees against adaptive sequences to deletion guarantees against non - adaptedive sequences, using differential privacy and its connection to max information. The main contribution of this paper is to develop adaptive deletion algorithms that are more flexible than those which are based on adaptive deletion sequences.   The main contributions of the paper are as follows :   1. The authors develop a general reduction from deletion guarantees for adaptive to deletion sequences ; 2. They use this intuition to design a practical attack against the SISA algorithm of Bourtoule et al. 3. They improve the performance of the proposed adaptive deletion algorithm on CIFAR-10, MNIST, Fashion - MNIST and Fashion -MNIST by using techniques from previous work."
SP:7150006590e268ab732c9be6c9048f67a377f956,"This paper studies the conditional value at risk ( CVaR ) in Bayes - Adaptive Markov decision processes ( MDPs ), a type of reinforcement learning method. The authors show that optimising CVaRs in this setting is risk - averse due to two uncertainty factors : the prior distribution of the MDP decision processes and the aleatoric uncertainty due to the stochasticity of the decision processes under two players. They propose an algorithm based on Monte Carlo tree search and Bayesian optimisation to approximate the true conditional value via a Monte Carlo estimator. They test their algorithm on MNIST and CIFAR-10, and show that it performs significantly better than the baselines.    The main contributions of this paper are the following :   1 ) The authors propose an approximate conditional value optimisation method based on MDP and MDP. The algorithm, called conditional value minimization ( CVM ), is based on the Monte Carlo Tree Search ( MST ) algorithm and the Bayesian Optimisation ( BIN ) algorithm. 2 ) They show that conditional value maximisation with CVM produces better conditional values than without it. 3 ) They conduct extensive experiments to validate their algorithm and compare it with other baseline optimisation methods."
SP:a94f39406f73d7483ddd744ed2f03c78b8bc5d44,"This paper studies the problem of learning deep neural networks with logistic loss via gradient descent on binary classification problems where the underlying data distribution is general and the ( optimal ) Bayes risk is not necessarily zero. The authors consider the simplest possible network, a shallow ReLU network with only the inner ( input - facing ) weights, and train the network using gradient descent with a constant step size.    The paper shows that as the number of samples, the size of the network, and the amount of training time increase, so do the logistic losses. However, as the network gets larger, so does the population misclassification rate. The paper then shows that the loss function over the population, defined as the sum of the empirical logistic risk and logistic logistic error, converges to optimality over all measurable functions. This implies that the induced conditional model ( defined by a sigmoid mapping ) that is trained with early stopping can be described as approximating the true underlying conditional distribution arbitrarily well. This is in contrast with prior work which either only considers the training risk, or can only handle restricted conditional models, and thus can not represent the general case where the data distribution may be noisy or the labels may be arbitrary. The main result of the paper is summarized below, and it will be highlighted in the main part in the section on calibration via the theory of Bartlett et al. ( 2004 ) via the main result below, as well as the main lemma of classification theory via the calibration of the model ( which is already well parametrized in the paper ). The other than the calibration part can be phrased as follows : ( 1 ) any univariate predictor satisfying a local interpolation property ( i ) can not achieve optimal test error for noisy distributions ( ii ). ( 2 ) Any univariate classifier satisfying the property i.i that is inconsistent with Pr[Y = 1|X = x, where x is the input feature and y is the output feature of the classifier ( i.e., the distance between features x and y ) can be approximated with high complexity ( 3 ) by a low - complexity infinite - width random feature model ( Pr[y = 1 | x, Pr[^2|x, i ] ), which is also approximated well by Bartlett's equation ( eq. ( 4 ) ). In the experiments, the authors train ReLU networks with a very small number of layers, and they show that their proposed method achieves population risk approximately close to optimal in terms of both logistic and mis classification losses, and at least as far as calibration, meaning the sigmoids mapping of its outputs approximates the true true conditional model arbitrarily finely. In addition, the necessary iteration, sample, and architectural complexities of this analysis all scale naturally with a certain complexity measure of"
SP:a9c786cbb61e1f10f3542161b13e43a1a68ab34d,"This paper proposes a neural - temporal point - based coordination detection framework incorporating neural temporal point process with prior knowledge such as temporal logic or pre - defined filtering functions to detect coordinated group activities on social media in the presence of high - sparsity of account activities. Prior knowledge is leveraged to design a Gibbs distribution of group assignment based on how consistent an assignment is to ( 1 ) the account embedding space and ( 2 ) the challenge that the distribution is hard to be efficiently computed and efficiently distributed. Experimental results on a real - world dataset show the effectiveness of the proposed method compared to state - of - the - art methods in both unsupervised and semi - supervised settings. The detection result suggests presence of suspicious coordinated efforts on spreading misinformation about COVID-19 vaccines.    The authors further apply their model on a COVID - 19 Vaccine Tweets dataset to train a coordination detector on a dataset of social media accounts corresponding to the top 20 most visited vaccine providers in the U.S. in terms of the number of interactions with the public in the last three months. The proposed method is compared with two prior methods ( DeepSocialNet and DenseNet ) on this dataset. The main difference between these methods is the use of neural networks to model the observed data from social media with neural temporal points distribution instead of using a neural network to predict the distribution of the group assignments based on the prior knowledge. The authors also compare their proposed method on the dataset of top 100 most visited vaccines in the United States in the past three months, showing that their method is more effective than DeepSocialNeuralNet in detecting coordinated efforts."
SP:b5c6e967a26a02861db2ecd620e9061db0c03e59,"This paper studies the generalization of a neural network with low - dimensional nonlinear structure to a binary classification task with two disjoint smooth curves. The data consists of two smooth functions $ \mathbb{R}$ and a unit - sphere $ \sqrt{U}$, and the classifier is a fully connected neural network $ f(x ) = f(y)$, where $ y$ is the unit - radius and $ z$ is a function of the unit $ \epsilon$. The paper shows that randomly - initialized gradient descent learns to correctly classify $ x$ on the two curves with high probability when the network depth is sufficiently deep and the number of samples is polynomial in the depth. This is the first generalization guarantee for deep neural networks with nonlinear data that depends only on the intrinsic data properties.   The main contribution of this paper is the following :   1. The authors define a model problem with two smooth curves $ \phi$ and $ \tilde{O}$ where $ \theta$ are smooth functions defined over the unit sphere ( $ \pi$, $ \gamma$ ), and $ d$ is an orthogonal mapping from the unit to the edges of the space. The goal is to find a set of points on the unit that maximizes the ratio of the smoothness of the two functions. The probability that each point on $ \eta$ agrees with the other point on the other side of the curve is computed by minimizing the difference between the probability of each classifier's prediction over $ d$.    2. The neural network is trained to solve the binary classification problem by using the following the gradient descent algorithm. Three conditions are satisfied to train the neural network : ( 1 ) the network must be at least as deep as $ \nabla_t$ and must satisfy certain geometric properties of the problem ; ( 2 ) the maximum and minimum dimension of the network and the dimension of samples must be close enough to ensure that the network learns correctly to classify all points on both smooth functions. ( 3 ) The network must also be able to handle strongly convex functions ( i.e., the distance between any two points on either the unit or the edges ; and ( ii ) the dimension between two smooth function classes is small enough to allow the network to handle all data on one of them with high accuracy. The experiments are conducted on a toy example, and compare the performance of the proposed method with the performance on the toy example on two different sets of $ \text{Y}$ tasks. The results show that the proposed approach generally outperforms other methods for solving binary classification with non - convex nonlinear classifiers on all of the"
SP:8f6bee3be43df6b6e80804974014caaafe08c49e,"This paper studies the training and experimental performance of ReACGAN, an auxiliary classifier GAN with softmax cross entropy loss ( ACGAN ). It is known that training ACGAN is challenging as the number of classes in the dataset increases, and ACGAN also tends to generate easily classifiable samples with a lack of diversity. This paper proposes two cures for the causes of the collapse in training of ACGAN. First, it identifies that gradient exploding in the classifier can cause an undesirable collapse in early training, and projecting input vectors onto a unit hypersphere can resolve the problem. Second, it proposes the Data - to - data Cross - Entropy loss ( D2D - CE ) to exploit relational information from the class - labeled dataset to generate more diverse samples. The experimental results show that, under milder conditions, ReacGAN achieves state - of - the - art results on CIFAR10, Tiny -ImageNet, CUB200, and ImageNet. The authors also verify that ReACAN can benefit from differentiable augmentations and that D2 - CE can harmonize with StyleGAN2 architecture.    The paper is published with a software package that provides implementations of representative cGANs and all experiments in the paper are available at https://github.com/POSTECH-CVLab/PyTorch -StudioGAN. The software package also provides weights and a training algorithm to train ACGANs."
SP:080e80746a87228b156408ff649ab7a17f44e92d,"This paper proposes a deep reinforcement learning ( RL ) algorithm for two - player zero - sum games called Extensive - Form Double Oracle ( XDO ), an extensive - form double oracle algorithm for zero sum games that is guaranteed to converge to an Nash equilibrium linearly in the number of infostates. Unlike PSRO, which mixes best responses at the root of the game with the best response obtained through deep RL at every infostate, XDO mixes best response learned through the best available deep RL algorithm ( at least the one that starts with the most recent state ) with the responses obtained from the least - explored states. The authors empirically demonstrate that XDO achieves Nash equilibria that is an order of magnitude smaller than that of PSRO in a number of iterations. They also introduce Neural XDO ( NXDO ) that is the first deep RL method that can find an approximate Nash equilibrium in high - dimensional continuous - action sequential games. The main contributions of this paper are as follows.   1. This paper proposes an algorithm that extends the well - known PSRO algorithm to games in which there are two players and two states, and names it PSRO - MDPs. 2. This algorithm is empirically shown to find an equilibrium that is $ \ell_2$-optimal, $ \epsilon$-compact, and $ \sqrt{O}$-equilibrium for $ \gamma$-1 $ \cdot$-sigma$. 3. This game is played by one of the randomly chosen players and the other than the two states are chosen by the other player. 4. The algorithm is compared to PSRO and NXRO, and the results show that it achieves a lower exploitability than PSRO with the same amount of computation. 5. In addition, the authors also propose a procedure to train a neural XDO algorithm that learns a neural network that produces the best responses to queries from the best possible queries provided the neural network is initialized with $ \theta$. This procedure is referred to as $ \nabla_t$ ( where $ T$ is a random vector fed into the network and $ A$ is the output of the network query. The experiments compare this method to the one based on PSRO ( based on policy space response oracle, PSRO ) and XDO. Results show that under certain assumptions on the distribution of states and distribution of values in the network that the neural networks produced by XDO produce better responses than the ones produced by PSRO but worse responses when the distribution changes over all the states or values in"
SP:bda04facef4f34679fc4e17b8ea1aae74c3d649f,"This paper proposes a graph - level unsupervised representation learning method based on variational autoencoder for graph structured data for graph representation learning. The main idea of the paper is to use variational inference to learn a node - level representation of a graph p such that the learned representation p(n|x ), where p is the number of nodes in the graph, can be represented by adjacency matrices p(x|, n ) with respect to a set of nodes p(z||x), where z is the size of the graph and n is the total node count. This is in contrast to node - based representation learning methods such as node or link - level supervised learning or graph classification, which use the exact node order of input and output nodes. The idea of indirectly learning a node representation to match the one obtained by matching p(a|x| ) and output node order is borrowed from prior work ( Zhang et al., 2019 ).    The main contributions of this paper are the following :   1. The authors propose a variational generative model for learning a graph representation from structured graph data using a permutation - invariant variational auto - encoder. 2. They use the Variational Algorithm for Graph Representation Learning ( VAR - GAIL ), a variant of VAR-GAIL, to train the model using data augmentation and node - wise node ordering matching. 3. They evaluate the performance of their proposed model on three graph datasets, showing that the obtained representations are better than the ones obtained from offline. 4. They also show that the generated representations are more expressive than the raw data, indicating that the learning is more expressive."
SP:e17ea6aeba78c9dfc25596d8b35a2a4f1f1f6763,"Graph Neural Networks ( GNNs ) have limited scalability with respect to the graph and model sizes and increasing the model depth often means exponential expansion of the scope ( i.e. receptive field ).   This paper proposes a novel approach to decouple the depth and scope of the GNN by first extracting a localized subgraph as the bounded - size scope, and then applying a GNN of arbitrary depth on top of the subgraphs that are derived from the original GNN. The proposed approach is tested on seven graphs ( with up to 110M nodes ) and six backbone GNN architectures, and achieves significant accuracy improvement with orders of magnitude reduction in computation and hardware cost. The evaluation is conducted using GraphSAGE ( a graph neural network generator that generates representation of a target entity from the graph signal processing ( GCN ), graph approximation ( GSAGE ) and topological learning ( GIN )."
SP:4890f251db559a0a572afc66e0c1f899b577d9ff,"Normalizing flows are a widely used class of latent - variable generative models with a tractable likelihood. Affine coupling models are a particularly common type of normalizing flows, for which the Jacobian of the latent - to - observable - variable transformation is triangular, allowing the likelihood to be computed in linear time. This paper provides theoretical proof that distributions can be approximated reasonably well using affine coupling networks when trained with networks with a nearly -singular Jacobian. The authors use three different techniques to obtain the proof : ( 1 ) leverage connections between affine - coupling architectures, ( 2 ) Leverage connections with Hénon dynamics ( a stochastic differential equation often used to sample from Gibbs measures ) and ( 3 ) approximate a padded version of the input distribution with iid Gaussians, a strategy which Koehler et al. empirically observed to result in better - conditioned flows, but had hitherto no theoretical grounding.   The main contribution of this paper is to provide theoretical evidence for the benefits of Gaussian padding when training normalizing flow models with Gaussian - augmented distributions. The paper also provides theoretical support for the practice of training affine couplings."
SP:5ffa81488ed1092deb89bd5e150fa146325057ce,"This paper proposes a Lagrangian - based policy learning framework to solve the problem of coupon allocation within a fixed budget on the e -commerce platform with respect to user retention. Specifically, the authors propose :   1. a generalization method called \� - generalization that learns a policy according to $ \lambda$ value adaptively, avoiding re - learning new polices from scratch 2. an offline reinforcement learning method called $ \beta$-reinforcement learning that learns the policy via gradient descent based on the value of $ \phi$-value, 3. a policy evaluation algorithm based on policy learning and policy evaluation, and 4. an off - policy policy evaluation network.   The authors validate the effectiveness of the proposed method on a simulated platform and real - world e - commerce market. The main contribution of this paper is the introduction of the $ \mathcal{L}$-generalization method and the application of it to the policy learning process, where the policy value is learned according to \phi$.   3. The authors conduct extensive experiments on the simulation platform and the real e -Commerce market to validate the efficacy of their approach. The experiments are conducted with different levels of detail ( e.g. amount of coupons, amount of discounting, response time, etc. ), and they compare their proposed method with existing methods from the real - time and fast - response settings. They also conduct extensive ablation studies to validate their method and to compare their method with the state - of - the - art methods. Finally, they conduct extensive evaluations on the simulated platform to validate that their method is more effective than the existing methods. They are encouraged to share their evaluation results for validating their method. They evaluate their method on the following scenarios : -    ( 1 )   - Online coupon allocation policy learning where the goal is to develop a policy that encourages users ’ retention rate on the platform while ensuring the cost of coupons allocation does not exceed the budget - ( 2 ) Online coupon policy learning when the budget is fixed, but the company needs to find a good balance between user retention and the goal of increasing the amount of coupon sales while maintaining a low discounting rate - ( 3 ) Online coupons allocation policy when the company wants to attract users to buy more coupons - ( 4 ) Online policy learning with different policies depending on the company's business strategy - ( 5 )"
SP:6b04cc7b4e45b9e65a1d34c15e3f75a2ef27d601,"This paper proposes a source - free domain adaptation ( DA ) method, SFDA_neighbors, for the target - free DA problem, where the source pretrained model is adapted to the target domain in the absence of source data. The method is based on the observation that target data might no longer align with the source domain classifier, but still forms clear clusters. It captures this intrinsic structure by defining local affinity of the target data, and encourage label consistency among data with high local affinity. The experimental results demonstrate that the method achieves state - of - the - art performance on several 2D image and 3D point cloud datasets.   The authors observe that higher affinity should be assigned to reciprocal neighbors, and propose a self - regularization loss to decrease the negative impact of noisy neighbors. In the experimental results, the authors show that the aggregate information with more context is able to capture information from expanded neighborhoods with small affinity values more efficiently. The authors propose to use the term “ expanded neighborhood ” to refer to those neighborhoods that are not included in the original DA when the source data is not available. The experiments demonstrate that this can be efficiently captured by considering the local structure, the local neighbors, the reciprocal neighbors and the expanded neighborhood. They also demonstrate that high affinity with respect to the original source data can lead to better performance on DA when source data are not available, e.g., for example, when the data is available only from the source but not from the target. In conclusion, this paper is well - written and well - structured, and the method is easy to use."
SP:ac1bf04ff782e5892a0bc5fe5949848ca8e731c2,"This paper proposes a generic pooling mechanism for aggregating features from a set of features into a fixed - dimensional representation for learning representation learning tasks. The proposed pooling method treats elements of a set as samples from a probability distribution and proposes an end - to - end trainable Euclidean embedding for sliced - Wasserstein distance to learn from set - structured data effectively. The authors evaluate the proposed method on a wide variety of set - structures data, including point - cloud, graph, and image classification tasks and demonstrate that it provides superior performance over existing set representation learning approaches.   The main contributions of this paper are as follows :    1 ) The authors propose an embedding mechanism for learning representations from sets that is generic and can be applied to many existing learning tasks, such as point cloud processing, graph learning, image / video recognition, and object detection. 2 ) They develop and evaluate a training algorithm based on a generic embedding that can be used to learn representations from data using a set and a set structure. 3 ) They compare the performance of their method with the existing set - based pooling methods and show that their method performs better on some tasks compared to the existing methods."
SP:6cb2f0cbc076f8680cb00411790629f8e1478053,"This paper studies the training stability of recurrent neural networks ( RNN ) and proposes a family of RNNs, called SBO - RNN, that can be formulated using stochastic bilevel optimization ( SBO ). The authors show that under mild conditions there is no vanishing or exploding gradient in training SBO-RNN and prove convergence of the family with fewer parameters and fewer training data. Empirically, they demonstrate the approach with superior performance on several benchmark datasets.    The main contributions of this paper are the following :   1 ) The authors consider the problem of learning hidden states and their hyperparameters from a set of hidden states using RNN. The feedforward and backpropagation problems of the RNN solve the lower and upper - level optimization for learning the hidden states, respectively. 2 ) Using SGD, the authors convert the SBO problem into an RNN with the help of the SGD algorithm to learn the lower - level states and the hyper parameters. 3 ) They prove that the gradient of the hidden state is stationary and does not move very far away from the training distribution. 4 ) They use SGD to approximate the lower level optimization of the feedforward problem and solve the back - propagation problem for the upper level optimization."
SP:d3a4300e21ca215334f256f0467a428470548fe4,"This paper studies the problem of minimizing power consumption in systems with multiple power - saving states, where an algorithm has to choose between different energy saving states of different energy consumption and wake - up costs during idle periods of unknown lengths. The main contribution is a learning - augmented online algorithm that makes decisions based on ( potentially inaccurate ) predicted lengths of the idle periods. The algorithm ’s performance is near - optimal when predictions are accurate and degrades gracefully with increasing prediction error, with a worst - case guarantee almost identical to the optimal classical online algorithm for the problem. A key ingredient in the approach is a new algorithm for online ski rental problem in the learning augmented setting with tight dependence on the prediction error. The experiments support the theoretical findings with experiments.   The main contributions are the following :   1. The paper proposes an algorithm to learn an upper bound on the expected power consumption of a state w.r.t. the average user during an idle period ( assuming that the predictions of the state prediction are correct ). The upper bound is based on the assumption that the user will visit the same states during all idle period s during which they have access to the same amount of power. This assumption is similar to the one used in the classical solution. The difference is that the algorithm does not require the user to visit all states during the idle period in order to learn the upper bound. The average user visits the states during each idle period only if they are within a certain threshold distance from all the states of the power saving state. The lower bound does n’t require the states to be within the same threshold s with a different upper bound, but not be close to each other in terms. 2. The authors compare the performance of their algorithm with that of a classical algorithm and a modified version of theirs. The experimental results show that the proposed algorithm outperforms the classical one in most cases, with the exception of the latter being the case when the error prediction error is larger than 5 %."
SP:22aba6284123af0ecd6605ee4e89b351bd7e10a3,"This paper proposes a transferability framework for quantifying the transferability in multi - source transfer learning problems, with both the task similarities and the sample complexity of learning models taken into account. The theoretical expression of this transferability measure is characterized by the sample sizes, model complexity, and the similarities between source and target tasks, which provides fundamental insights of the knowledge transferring mechanism and the guidance for algorithm designs. The authors also apply the analytical expression for practical learning tasks to develop an algorithm to implement the theoretical results for training deep neural networks in multi-source transfer learning tasks, and conduct experiments on the classification tasks to show that our approach outperforms existing transfer learning algorithms.   The main contributions of this paper are the following :   1 ) The authors develop a theoretical transferability metric that measures the mutual information transferability between two source tasks ( e.g., a teacher ’s dataset and a student ‘s dataset ) learned by linearly combining the results from the source tasks and the target task using the optimal combining coefficients. 2 ) They use the theoretical expression to design a transfer learning algorithm that applies the obtained knowledge from source tasks to target tasks to transfer the knowledge from one source task to another using the linearly combined results. 3 ) They develop an empirical procedure to test the effectiveness of their transfer learning method on a set of small - batch classification tasks, where the goal is to train a neural network using supervised learning to transfer knowledge from a small number of tasks to a large number of source tasks. The methods are applied to train neural networks for training in both the multi - batch and few - shot setting, and they show that the results are competitive with the state - of - the art in terms of transferability, with the exception of the neural network training in the latter setting being slightly worse than the former. 4 ) In addition, the authors also develop an alternating learning algorithm to apply their theoretical results to practical tasks to improve the performance of their theoretical algorithm."
SP:0fb8dcf15e0d43547d566fdba7bc70b3bb600005,"This paper proposes a neural network - based model for visual search based on target - dependent cue - dependent top - down cues. The model is trained using augmented versions of ImageNet with and without the need for task - specific training. It is trained to generate an eye - tracking trajectory from a target image and a search image, conditioned on the pair of targets that it is trying to find, by tracking the eye's movements in the direction the target is appearing in the search image's field of view. The eye tracking trajectory is estimated using a model that combines an attention - dependent feature extractor with a distractor that predicts whether the eye is interested in the target or not.   The authors test the model on visual search tasks where they assume that the search is asymmetric ( i.e., finding a target A among distractors B can be easier than finding B among A ) and show that the model produces a sequence of eye movements that correspond to the time it takes to find the target A by following the search trajectory. They compare the model against human behavior on six tasks that are considered paradigmatic for search asymmetry in humans. They show that in three tasks, the model provides a plausible mechanism for explaining why the eye tracking trajectories produced by the model converge to the target in search. They also test whether the polarity of search depends on the amount of distractors or whether it is a result of the statistical properties of the experience with the environment that is masked out by the training. In the last task, they show that a model with no training provides the most plausible explanation for the mechanism for the asymmetry. Finally, they compare the proposed by the authors to the one using human behavior. The results suggest that the proposed model is able to explain why the mechanism of eye tracking in search as a consequence of the information encoded in search images."
SP:f0cc968ea9da4884dcdaf6d0c75ea9f1511bdfc3,"This paper studies the problem of training certifiable robust models against adversarial examples. The authors claim that Interval Bound Propagation ( IBP ) training uses much looser bounds but outperforms other models that use tighter bounds. They also claim another key factor that influences the performance of certifiable training : smoothness of the loss landscape. They find significant differences in the loss landscapes across many linear relaxation - based methods, and that the current state - of - the - arts method often has a landscape with favorable optimization properties. Moreover, to test the claim, they design a new method, the proposed method, which achieves a decent performance under a wide range of perturbations under the assumption that each perturbation is well - behaved.   The paper is published with supplementary material. The manuscript includes the following main contributions :   1 ) A detailed description of the history of IBP training and its evolution from the first to the current regime. 2 ) A careful analysis of the relationship between each type of loss landscape ( e.g., the one obtained by linear relaxation and the one generated by state - based training methods ), showing that the landscape generated by SOTAP is more complex and more likely to be smooth ( compared to other loss landscapes ). 3 ) Key assumptions and terms in the manuscript that govern the properties of the losses under each of the three types of loss landscapes, and how they relate to each other. 4 ) Method development and testing. The proposed method is evaluated on a set of synthetic data sets, where one is assumed to be generated by IBP and the other is assumed not to have any IBP loss at all. The experimental results show that under certain assumptions ( i.e., assuming that the true worst - case loss is lower than the worst case loss in each case, and assuming lower bounds on the allowed perturbational examples ), the method generally performs well. However, when the assumptions are relaxed, the performance degrades and the results do not improve as much. To test whether a particular assumption is correct, the authors propose a modified version of their method, where they assume the same assumptions as in the original, but with slightly different assumptions. This method is tested on synthetic data and real world data and it seems to perform about as well as the original IBP method."
SP:a158f8772a9dada059ffd1d6d7838ed40d8483da,"This paper studies the problem of online linear regression in the stochastic setting with the help of high probability regret bounds derived from ridge regression and forward algorithm. The main contributions are as follows :   - First, the authors study the regret bounds of forward algorithm in lieu of ridge regression due to its boundedness and robustness to the regularization parameter. They show how to integrate this algorithm in algorithms involving linear function approximation to remove a boundedness assumption without deteriorating theoretical bounds and showcase this modification in settings where it yields improved regret bounds ( e.g., linear bandit ). They also provide numerical experiments to illustrate the results and endorse their intuitions. The forward algorithm is proposed to be used in the online setting to improve the robustness and bounds of the forward algorithm for linear function approximations where the bound on the bound is lower bounded. This is particularly relevant for the setting where the target function is a linear function. The proposed forward algorithm can be used to solve the online problem in a linear regression setting with lower target function bound, which allows for more accurate prediction error bounds and fewer assumptions of bounded observations and predictions. - Second, they show how forward algorithm improves the regret of the proposed ridge algorithm in the setting when the target functions are lower bounded, and they show numerical experiments where forward algorithm yields better regret bounds than the ridge algorithm.    Third, they discuss the possibility of using forward algorithm as a regularization regularizer in some settings, and propose a setting where this is possible. They provide empirical results showing that forward algorithm leads to improved regret in this setting."
SP:17ff9a2133aebf2d1b1787e8efc49d709389c0e7,"This paper presents two variants of the extragradient ( EG ) method with an anchoring technique, named EAG+ and FEG+, which are both nonconvex - convex nonconcave learning methods. The first one is a two - time - scale variant of the EG method with a slow O(1/k ) rate on the squared gradient norm, where k denotes the number of iterations. The second one is an extension of EAG with a backtracking line - search operator, named FEG - A, for the case where the problem parameters are not available. The authors provide stochastic analysis of FEG and EAG. The experimental results are useful to understand the properties of the methods.   The main contributions of this paper are the following :   ( 1 ) This paper proposes an efficient method, named Fast Expensive Gradient Update ( FEG ), to solve the minimax minimax problem of the EAG method under a smooth convex - unconcave setting. The main idea is to estimate the gradient variance ( variance / cosine of the gradient norm ) as a function of the order of K in the gradient estimator. The paper gives a good approximation of the true gradient variance of $ O(k / O(sqrt(1 / k))$ for a fixed point $ \sqrt{K}$ and shows that the resulting estimate is orders of magnitude faster than the one used to estimate gradient variance in the original paper. This paper also gives an explanation of why FEG is more efficient than FEG. ( 2 ) It is shown that FEG can be used to train a generative adversarial networks ( GANs ) faster than EAG, and it is shown how FEG + trains a saddle - gradient operator faster than AAG. Finally, and the authors give a procedure to train an AAG that is similar to FEG, but with a slightly different anchoring."
SP:4e38973033de24fc183c6112e1146f8eef0ddaea,"This paper studies uniformity testing for ranking data that consists of rankings over m items, where the alternative class is restricted to Mallows models. It shows that uniform distribution can be distinguished from Mallows model with O(m 1/2 ) samples based on simple pairwise statistics, which allows to test uniformity using only two samples, if m is large enough. The paper also consider uniforming with central and local differential privacy ( DP ) constraints, which present a central DP algorithm that requires O(max{1 / m}(1 / p m ), where   $ $ $ ( 0, 1 / m)$ is the privacy budget parameter. Interestingly, the proposed uniforming algorithm is straightforward to apply to the local DP scenario, since it works with binary statistics extracted from the ranking data. The experiments carry out large - scale experiments, including m = 10, 000, to show that our uniforming algorithms scale gracefully with m.   The main contributions of this paper are the following :   1 ) The paper proposes uniforming testing with DP constraints. Central DP algorithm requires $ \max\max\sqrt{1/p m}$, where $ $ m = m^2 $ ( where $ m=1 / 2 $ and $ p=0 $ is the dimensionality of the domain. 2 ) It proposes a local DP algorithm with $ \theta_0 $ as its budget parameter, which is similar to the $ \mathbb{O}(m^2 / p}$ but is easier to implement. 3 ) It applies the proposed by the previous paper ( Zhang et. al. ( 2021 ) to the uniforming problem, and shows that it is compatible with both local DP constraints and the central DP constraint. 4 ) The experiments are conducted to evaluate the performance of both proposed methods."
SP:99a835191a3ba8372e391b6d3316e9b68e543295,"Greedy algorithms have long been a workhorse for learning graphical models, and more broadly for learning statistical models with sparse structure. In the context of learning directed acyclic graphs, greedy algorithms are popular despite their worst - case exponential runtime. In practice, however, they are very efficient. This paper provides new insight into this phenomenon by studying a general greedy scorebased algorithm for learning DAGs. Unlike edge - greedy algorithms such as the popular GES and hill - climbing algorithms, the approach is vertex -greedy and requires at most a polynomial number of score evaluations. The experiments are conducted suggesting that this algorithm indeed optimizes the score in a variety of settings."
SP:b60989706296b963b6671c01f22384978a334be1,"This paper proposes a novel adversarial robustness enhancement algorithm to improve the accuracy and robustness of convolutional neural networks ( CNNs ). The main motivation of this paper is that CNNs are vulnerable to adversarial attacks and adversarial training can improve the standard accuracy. To address this shortcoming of CNNs, this paper proposes to introduce a dilation - based architecture that is expected to be friendly with the standard performance of the backbone CNN while pursuing adversarial augmentation robustness. The proposed algorithm consists of two parts : ( 1 ) A neural architecture update step that updates the weights of two CNN backbone networks according to the adversarial perturbations ; ( 2 ) A loss function that penalizes the deviation of the weights from the output of the network with respect to the new weights obtained from the updated weights ; and ( 3 ) A training algorithm that optimizes the parameters of the loss function using a mixture of standard CNNs and modified CNNs with the modified weights. Experimental results on real - world datasets and benchmark CNNs show that the proposed algorithm is able to achieve better accuracy than the baselines while maintaining the same robustness ( in terms of accuracy ).    The main contributions of the paper are as follows :   - The authors propose a neural network architecture update that introduces a new weights for the backbone network and a modified loss function for the perturbation network. This change is motivated by the observation that the accuracy of the neural network with modified weights increases with the larger size of the input network. The authors then propose to update the weights in the same way as the backbone networks but with slightly different weights to achieve higher accuracy. This approach is referred to as “ gradient update ” in the paper. - The method is evaluated on MNIST, Fashion - MNIST and CIFAR and compared with the proposed by [ 1 ] and [ 2 ]. The experimental results on the MNIST dataset show the effectiveness of the proposed change as well as the trade - off between the expected gain in accuracy and the proposed loss function."
SP:77ed765e911a4e5f2bfba13cbd2403500a5d05e6,"This paper proposes UCRL - RFE, a reward - free RL algorithm based on linear function approximation for episodic Markov decision processes ( MDPs ), where the transition probability kernel of the MDP can be parameterized by a linear function over feature mappings defined on the triplet of state, action, and next state. In this setting, the algorithm has two phases : In the exploration phase, the agent interacts with the environment and collects samples without the reward ; and in the planning phase, given a specific reward function, the policy uses samples collected from exploration phase to learn a good policy. The main contribution of this paper is to extend the linear Mixture MDP assumption under the linear function assumption to the multi - feature assumption and derive a new algorithm that is provably efficient. The upper bound matches the lower bound in terms of the dependence on $ \mathcal{H}$ and dependence on d$. The authors show that to obtain an $ \rho(H)$-optimal policy for arbitrary reward function ( UCRL-RFE needs to sample at most $ h$ during exploration phase ; they also show that it needs $ h(1 + h)$ episodes during planning phase to obtain $ \ell_2 $ episodes during exploration.    The authors also prove that for any reward - based RL algorithm, it needs at least $ \tilde{O}(\sqrt{H})$(H^2/\delta)$.   Finally, the authors propose a variant of their algorithm, UC - R - FE, where $ \nabla_{R}$ is replaced by $ \sigma(R^3/\epsilon)$ where $ R$ is the dimension of the feature mapping and $ sigma$ is a linear operator over $ \theta_t$ features. This variant is more efficient than the original UC - FE as it does not require the linear operator to be parametrized. The authors evaluate their algorithm on a toy example and show that for $ t$-1 $ linear MDP, $ d$-MDP, and $ \text{MDPM}$ case, $ h(\text{R}(\sigma_t)$ is equivalent to $ t_{\text{"
SP:28563ba0975f56ddb662cd46e85de78bb6024d36,"This paper proposes a method ( SSMF ) to predict future events using a data stream of events with seasonal patterns that evolves over time based on the Shifting Seasonalal Matrix Factorization ( SSFM ) approach. SSMF is an approach to learn and process multiple seasonal patterns ( regimes ) using a lossless data compression scheme. The paper shows that SSMF accurately forecasts future events by detecting regime shifts in seasonal patterns as the data stream evolves and applies the detected regime shifts to the predicted future events. The method works in an online setting, i.e., processes each observation in constant time and memory for each observation ( e.g., each observation can be repeated several times ). The authors demonstrate that ( a ) SSMF works well on state - of - the - art methods by accurately forecasting upcoming events on three real - world data streams ; ( b ) ( c ) it effectively realizes regime shifts without human intervention by using a Lossless Data Compressive ( LDC ) approach to detect regime shifts ; and ( d ) it works reasonably well when using LDC to predict the future state of the data.    The main contributions of this paper are the following :   - A method to detect and process seasonal patterns in the data using a time - varying ( stochastic ) gradient - based approach that can adaptively learn multiple regimes ( called regimes ), as well as switching between them ; - An approach to process the data in two regimes simultaneously, which is referred to as regime shifting ; - A KL divergence ; and - A LDC - based method to learn a regime - shift that is sensitive to the seasonality of the observed patterns, and prevents the observed seasonal patterns from changing between regimes."
SP:e4bb07033001be4d04695ef058f426d49fe440be,"This paper proposes WeaveNet, a learning - based method to solve assignment problems that are NP - hard due to their incomplete input and approximation algorithms. The paper proposes to open a new vista for real - world assignment problems by proposing a novel neural network architecture. The network consists of three modules : ( 1 ) A core module, feature weaving layer, is used to match the features of a pre - trained task - matching generator, ( 2 ) A communication module is used for communication between modules in a parameter - efficient way for solving the assignment problems, ( 3 ) A final module, the self - attention module, provides the final assignment solution. The authors compare their method with the state - of - the - art algorithmic method and the most popular non - linear assignment problem, stable matching with two features each. The experimental results showed its impressive performance among the best among the learning-based baselines. However, it is important to note that the results do not give a clear indication of whether the proposed method is better than the one evaluated in the original paper, as the authors did not evaluate the model in all the experiments.    The main contributions of this paper are the following : 1 ) The authors propose a learning based method, Weave net, to match a feature - based generator, feature - weaving layer and a communication module in a neural network. The idea is to use the feature - sharing module in the learning model to transfer information from one module to the other module in an efficient way so that the communication is not lost during the evaluation process. The experiments. 2) The authors evaluate the performance of their method in three different settings : ( i.e., uniform assignment problem settings, conditional assignment problems with different number of elements and with different levels of difficulty, conditional assignments ). In the conditional assignments, the results show that Weave Net solves the problems in all three settings with comparable or better performance compared to the results obtained from the baselines and other methods. In some cases, the authors show that the performance is slightly worse or slightly better depending on the setting ( e.g., in the case of conditional assignments the results are compared to other methods, or the number of features or the amount of elements used in the communication module ). The major contributions of the paper are as follows : ( a ) A neural network with a feature sharing module that is used in conjunction with the combinatorial generator in the neural network for solving assignment problems ( feature sharing ), ( b ) A weighted average of the features in each module to ensure that the generator is only used in low - level tasks when the other modules are not used in high - level"
SP:8a559e21d45661eef427b310e5fe8488d5749137,"This paper studies the robustness of 3D deep learning models against adversarial attacks using self - supervised learning proxy tasks on different architectures and threat models for 3D point clouds. The three architectures studied are PointNet, Convolution - based ( DGCNN ), and PCT - based 3D architectures. Through extensive experimentation, the authors demonstrated that appropriate applications of self - supervision can significantly enhance robustness in 3 D point cloud recognition, achieving considerable improvements compared to the standard adversarial training baseline. The analysis reveals that local feature learning is desirable for adversarial robustness   in point clouds since it limits the adversarial propagation between the point - level input and the model - level output. This insight also explains the success of the   jigsaw proxy task in achieving stronger 3D robustness.    The authors conducted extensive experimentation to demonstrate the benefits of using self supervision. The robustness achieved by PointNet and ConvolutionNet with self supervision is qualitatively evaluated compared to PointNet with no self supervision, PCT with transformer - based learning, and LocalNet with PCT learning. However, the advantages of using SelfSupervision are more marginal since it requires the user to make use of features extracted from the target clouds, which is difficult to do with PointNet."
SP:657c5a1114c0d054b9e767d85990bbbb0492912d,"In this paper, the authors studied the problem of computing the regret of online Frank - Wolfe descent, a variant of the mirror - wolfe algorithm. The main contributions are two - fold :   ( 1 ) The first is to develop a toolkit to speed up the computation of projections using both discrete and continuous perspectives. The second is to improve the runtime of computing certain Bregman projections by a factor of ( a ) factor of \�(n / log(n ) over widely - prevalent sub - aggregates.   The authors considered three variants of the Frank - Wolfe algorithm, the Newton's method, FISTA, mirror - Wolfe and conditional gradient variants. The Newton ’s method enjoys near - optimal regret bounds and convergence rates, while the other two variants have suboptimal rates. Motivated by this trade - off in runtime v / s convergence rates between the two, they proposed to use iterative projections of close - by points over the iterative gradient updates ( iterates of several rounds ) to compute the projection of the final Markov chain. Based on this idea, they developed a method to adapt the away - step - FrankWolfe algorithm to use this information and enable early termination for computing the projections. The authors conducted experiments to evaluate the effectiveness of their method and compared it with several prior works. They compared the performance of the method on real - world benchmarks and benchmark datasets, and showed that the method outperforms the other methods in most cases, especially when computing the final regret. They also conducted some ablation studies to investigate the effect of the number of iterations of the projection."
SP:8dae43d6b5cebb7ef6c39437d997b390c2380536,"The paper considers learning the natural parameters of a k - parametrized minimal exponential family from i.i.d. samples in a statistically efficient manner. The setting under which the estimator is expected to be computationally efficient is when the support as well as the natural parameter are appropriately bounded. Traditional maximum likelihood estimator for this class of exponential family is consistent, asymptotically normal, and efficient, but evaluating it is computationally hard. In this work, the authors propose an efficient estimator with finite sample guarantees to achieve an ( $ \gamma_2 $ ) error of $ \alpha$ in the parameter estimation with sample complexity $ O(\poly(poly(k / \alpha))$, where $ O(log(k/\alpha ) ) is the computational complexity.   The authors first consider the setting where the family is monotonic, i.e., there exists a set of parameters $ \mathbb{K}$ such that the expected growth rate $ \theta$ of the set of k exponential family members $ k$ with bounded support $ \nabla_t$ where $ t$ is the number of sets of parameters in the family. Then, they propose an estimator $ \pi(\mathbf{O}(\sqrt{K } ) \log p(\theta_t)$, which is a parametrization of $ p(k)/p(k )$ and is equivalent to the maximum likelihood estimation of the family $ k$. The authors argue that this estimator can be used to evaluate the true growth rate of a re - parameter $ \tilde{k}$ under mild assumptions ( e.g., assuming that the support and natural parameters are well - bounded ). They compare their estimator to the one used in prior work ( Zhang et al., 2021 ) and argue that their method is more computationally tractable and more accurate than the latter. The authors then discuss the difference between their estimators and the prior work, showing that the difference is the difference in sample complexity between the two estimators. Finally, they argue that the estimators are computationally more tractable than the previous work, and show that the one can learn true growth rates of the exponential family with higher sample complexity."
SP:4f9ddb697e86356fb293ef34a69ca3702c4e8164,"This paper proposes DIBR++, a physics - based differentiable renderer for inverse graphics based on path tracing and rasterization based renderers. The main idea of the work is to predict intrinsic object properties from a single image without using any ground truth assumptions from the data. This is similar to the approach of [ 1 ], but different from [ 2 ], which uses a rasterized version of the input. The key difference is the use of path tracing to predict the path from the input image to the outputs of the renderer, where the path is estimated either via direct estimation or via spherical basis learning. The authors argue that this allows them to build a renderer that is physically differentiable, which allows for better integration with learning learning frameworks for geometry, reflectance and lighting prediction from the image. They also argue that environmental lighting and spatially - varying material models can be used to approximate light transport, which is needed to account for non - Lambertian reflections commonly observed in the wild. They demonstrate that their approach achieves superior performance on synthetic and real data compared to existing learning - based approaches and showcase several artistic applications including material editing and relighting.   The main contributions of this work are the following :    1. A new renderer based on the path tracing framework, DIB - R++, developed using path tracing leveraging path tracing, is able to predict object properties and predict lighting with accuracy comparable to that of a state - of - the - art physics based renderer. This leads to faster than previous approaches. 2. The method is also able to handle different types of data ( e.g., images with different lighting, different shades of the same color, different lighting patterns, different levels of depth, different resolutions and different lighting modes. 3. They compare the performance of their approach on synthetic data using synthetic data and lighting from real and synthetic data."
SP:6ac1c8556e7131939cc582f513bc9921470e1b09,"This paper proposes sampling - max - max, a differentiable training method to train deep neural networks with soft - argmax. Sampling - max trains a neural network with a probability distribution distribution $ \max$ over the input space $ x$ and output $ \mathbb{R}$. The output distribution is the sum of $ \theta_i$ and $ \tilde \gamma_i$. The authors estimate the average $ \eta_j$ of the localization errors incurred by training the network with $ \sqrt{x}$ and use it to constrain the distribution of samples drawn from the output distribution. Samples are sampled using a continuous estimator whose variance is proportional to $ \beta_j$. Samples from $ \times p(x)=\sum_{i } \log p(y|x)$ are aggregated into $ \nabla_i \leq \mathbf{max}(y)$. The sampling process is continuous and can be made differentiable via a parametrization of the sampling distribution. The method is evaluated on 5 different localization tasks and compared with a baseline training method where $ \text{sparse}$ is used for training and a standard training method which uses $ \alpha_p(y )$. Sampling-max is shown to outperform its baseline counterpart on the 5 selected tasks, and is competitive with other methods on the remaining 5 tasks. The main contributions of the paper are as follows."
SP:478c05c90090f9d80b72ac352c488073b45a5d8b,"Graph Contrastive Learning ( GCL ) is a method to learn representations from contrastive views to generalize graph contrastive representations from a pre - trained contrastive model. The authors have two concerns about the current graph structure of GCL : 1 ) changing the graph structure through data augmentation to generate contrastive view may mislead the message passing scheme, as such graph changing action deprives the intrinsic graph structural information, especially the directional structure in directed graphs ; 2) since GCL usually uses predefined contrastive values with hand - picking parameters, it does not take full advantage of the contrastive information provided by data augmented graphs, resulting in incomplete structure information for models learning. To address these concerns, they propose Laplacian perturbation - based directed graph augmentation method and theoretically analyze how it provides contrastive info without changing the directed graph structure. To train it using multi - task curriculum learning to learn from multiple easy - to -difficult contrastive viewing views, they empirically show that our method can retain more structural features of directed graphs than other GCL models because of its ability to provide complete contrastive Information. Experiments on various benchmarks reveal their dominance over the state - of - the - art approaches.   The main contributions of this paper are the following :   - First, they develop a directed graph data augmentation method using GCL - style augmentation, which learns from all possible contrastive points of view generated by the directed contrastive learning framework ; - Second, they conduct extensive experiments to show their method is superior to other methods in terms of generalizability and interpretability of the learned features from directed graphs."
SP:85b383d2f722f7bff438840e423f5cb4c67d5980,"This paper proposes SILG, a multi - environment Symbolic Interactive Language Grounding benchmark that unifies a collection of grounded language learning environments under a common interface. SILG consists of grid - world environments that require generalization to new dynamics, entities, and partially observed worlds ( RTFM, Messenger, NetHack ), as well as symbolic counterparts of visual worlds that require interpreting rich natural language with respect to complex scenes ( ALFWorld, Touchdown ). The authors provide diverse grounding challenges in richness of observation space, action space, language specification, and plan complexity. In addition, the authors propose the first shared shared model architecture for RL on these environments, and evaluate recent advances such as egocentric local convolution, recurrent state - tracking, entity - centered attention, and a reparameterization of the model architecture.   The authors find that many recent modelling advances do not result in significant gains in significant significant gains on environments other than the one they were designed for. This highlights the need for a Multi - Environment Symbolic IL Benchmark ( MEL ). Finally, the best models are significantly underperform humans on SILG compared to the human - based models on MEL, which suggests there is plenty of room for future work."
SP:23c8db56f59f778fe812a5dd161f7a1f21c3cdba,"This paper presents a sparse version of the Vision Transformer, dubbed V - MoE, that is scalable and competitive with the largest dense networks. The main contributions of the paper are :   1. It proposes a sparse network that can be used for image recognition tasks, while requiring as little as half of the compute at inference time. 2. It develops an extension to the routing algorithm that can prioritize subsets of each input across the entire batch, leading to adaptive per - image compute. 3. It demonstrates the potential of $ \ell_2$-conv on the image recognition task when applied to models, and train a 15B parameter model that attains 90 % accuracy."
SP:c5235f41dfb8b5cc478f11c5d5e0ab0b8676871e,"This paper studies the expressivity of training deep neural networks with hidden layers. The authors consider a limited set of hidden layer neural networks, where each layer consists of one or more neurons with a total of n neurons. The expressivity is measured using the cosine similarity between the weights of the hidden layer neurons when the activation is smooth. They also study the loss landscape for training such networks, which they term as 1 - hidden layer networks with fewer than n hidden neurons.    They answer two theoretical questions :   1 ) Can narrow networks have as strong expressivity as wide ones? If so, does the loss function exhibit a benign optimization landscape?   2 ) Is it possible to train narrow networks with a constrained optimization formulation where the feasible region is the nice local region, and prove that every KKT point is a nearly global minimizer with a $ n$-strong local minimizer if d is the input dimension of the neural network. They provide partial affirmative answers to both questions in the affirmative. They evaluate this approach for training narrow neural nets under mild conditions, and show that projected gradient methods on this constrained formulation significantly outperform SGD for training neural nets. They leave the rigorous convergence analysis to future work, and perform no analysis on the convergence of the gradient methods to KKT points."
SP:0be529f5254afd59dcfa6b34a359c7037e7a8323,"This paper proposes a continuous - learning - with - covariance - based bandit model that explicitly takes into account option correlation to estimate the risk measures of individual options. The underlying algorithm is based on the continuous - evolution - by - proxy ( CURIOUS ) algorithm from [ 1 ] and [ 2 ], where the agent ’s objective is to achieve the best trade - off between reward and risk, measured with option covariance, and the goal is to capture different reward observation scenarios in practice using three different feedback settings : i.e., full - information, semi - bandit and full - band it feedback. The authors propose novel analytical techniques for exploiting the estimated covariance to build the parameters of the bandit estimator. They also propose novel algorithms with optimal regrets to validate the risk - aware bandits and provide matching lower bounds to validate their optimalities. The experimental results demonstrate the superiority of their algorithms.    The main contributions of this paper are the following :   1. Introducing the idea of using covariance as a regularizer in bandit learning to explicitly account for option correlation ; 2. A continuous learning algorithm with covariance regularization to regularize the learning process ; and 3. A novel method for estimating the covariance between the learning parameters and those of the agent when performing bandit analyses using the full bandit discount rule ; and 4. A set of analytical techniques to capture the effect of covariance on the learning performance that explicitly quantifies how the different covariance structures ( covariance weighting, option correlation, option weighting - based weighting and the agent's objective, quantification of the feedback and the policy ) impact learning performance ; and 5. An empirical study to evaluate the performance of their methods on a set of real - world problems."
SP:472a90bb175b0286765c5a47b040e1a58f594a05,"This paper proposes Matrix Multiplicative Update ( MMU ) algorithm for computing PSD factorizations of nonnegative semidefinite vectors satisfying the condition Xij = tr(AiBj ) for all i, j. The main idea of the paper is to generalize the nonnegative Matrix Factorization ( NMF ) problem in which a collection of r - dimensional non - negative vectors {ai } and {bj } satisfying Xij can be used to compute a positive semi - definite ( PSD ) factorization of a given data point X. The paper proposes to use the MMU algorithm to implement the update scheme of the multiplicative update algorithm for NMF to ensure that updates remain PSD by congruence scaling with the matrix geometric mean of appropriate PSD matrices. The proposed algorithm is generalizable to other PSD tasks and uses the same update scheme as that used for minimizing the squared loss objective under the MajorizationMinimization framework. It is shown that under the proposed update scheme squared loss is non - increasing and fixed points correspond to critical points. The analysis relies on Lieb ’s Concavity Theorem and the authors demonstrate the utility of the method with experiments on real and synthetic data.   The main contributions of this paper are the following :    1. The authors propose a non - commutative update algorithm, which is referred to as MMU, to be used as an alternative to the matrix factorization update algorithm of the original NMF problem, called NMF - Update ( Liu et al., 2021 ), in which updates are preserved by scaling with positive diagonal matrices and ensuring that the updates are non - negatived. 2. Theoretically, the authors show that under certain assumptions ( e.g., fixed points at critical points of the update objective and squared loss constraints ), the proposed algorithm achieves non - decreasing squared loss objectives. 3. Theorem 1 provides the intuition for the robustness of the proposed method against the scalability constraints of the NMF update objective. 4. Experimental results show that the method outperforms the widely used NMF algorithm in terms of accuracy, computation speed, and computation cost."
SP:83abd6d149d88cc6e96cbc4d488e4fe9dc2a4fcb,"This paper proposes a meta - learning framework that extends beyond the invariance view to extract domain - specific information from source domain representations to improve generalization to target domain representations. The authors argue that the prior DG approaches have focused on extracting domaininvariant information across sources to generalize on target domains while useful domain -specific information which strongly correlates with labels in individual domains is usually ignored. The proposed framework is called Meta - Domain Specific - Domain Invariant ( mDSDI ) and its goal is to disentangle features in the latent space while jointly learning both domain - invariant and domainspecific features in a unified framework to capture the usefulness of domain specific information. To achieve this goal, the authors propose a disentangled version of their domain - aware learning framework, called DisentangleNet ( DNetNet ), which first learns a feature extractor and a domain discriminator, and then uses the learned features to generate a domain representation representation for the domain. The domain representation is then used to train a robust generalization layer on top of the source domain representation to obtain a more generalization capability for the target domain ( compared with only using domain - invariant - based methods ).   The authors conduct a thorough investigation of their proposed framework and compare it to state - of - the - art techniques in the field. They compare the performance of their method with that of two prior methods, namely, Domain Generalization ( DG ) and Domain - Aware - Aware ( DAI ). They find that the proposed method outperforms DAI in terms of test accuracy on target domain generalization as well as test accuracy for DAI on source and target domains. They also compare their method to DAI and DAI that uses domain - unawareness for target domains only. Finally, they conclude that their method is more cost - efficient and perform better on test domains than DAI."
SP:4191474c75e2fedf514f0f3001a67a047eb74c30,"This paper studies generative image synthesis with deep diffusion diffusion models ( DDPs ), aiming to build generative models that can achieve image sample quality comparable to or better than the state of the art GANs. The approach is based on finding a better architecture through a series of ablations that leads to unconditional image synthesis and conditional image synthesis. The authors further improve sample quality with classifier guidance : they propose a simple, compute - efficient method for trading off diversity for fidelity using gradients from a classifier. They achieve an FID of 2.97 on ImageNet 128⇥128, 4.59 on   ImageNet 256 ⇥256, and 7.72 on  ImageNet 512 ⇳$. They match BigGAN - deep even with as few as 25 forward passes per sample, all while maintaining better coverage of the distribution. The experiments show that the proposed approach improves image synthesis as a function of the number of classifiers improves the FID.   The main contributions of the paper are the following :   1. A better architecture for image synthesis is found, which leads to higher FID scores for unconditional DPPs. This is achieved by ablating the generative model several times with different ablations. The ablations are simple and iterative. 2. Classifier guidance combines well with upsampling diffusion models, further improving image synthesis quality. 3. They show that BigGAN- deep image synthesis can achieve FIDs as high as $ 3.94 on imageNet 256 / 256 ( conditional )    4. They also show that using the proposed in this paper improves FID score for ImageNet - based classifier up to $ 512 / 512 ( conditional DDP )."
SP:fe3cab08596cde4c14ecf6fca8d0f95b02bab229,"This paper proposes an approach to leverage out - of - distribution ( OOD ) samples ( unlabeled samples from outside target classes ) for improving few - shot learning in both inductive and transductive learning settings. The proposed approach is simple to implement, agnostic to feature extractors and lightweight ( with no additional cost for pre - training ), applicable to both the inductive setting and trans - debductive setting. The main idea is to use the distance between prototypes and out of distribution samples to drive the classifier to avoid irrelevant features by maximizing the distance from prototypes to OOD samples while minimizing that to in - distribution samples ( support and query data ). Extensive experiments on various standard benchmarks demonstrate that the proposed method consistently improves the performance of pretrained networks with different architectures pretrained from different architectures.   The main contributions of this paper are as follows :    1 ) The paper proposes a simple OOD - based approach to improve the learning performance of several Trans - debuggable neural networks, including TransDAC and Trans - Auxiliary Neural Networks ( TANs ). 2 ) The method is tested on two networks trained from scratch on MNIST and CIFAR-10, where it outperforms the baselines by a large margin. 3 ) The approach is compared with two baselines trained with different pretrained neural networks and compared with a simple approach that does n’t require the feature extractor. 4 ) The major contributions of the paper are the following : 1 ) It introduces a simple method to train a neural network from scratch using features extracted from base classes and features from transductived networks, which is shown to significantly improve performance over baselines, and 2 ) It proposes a novel way to query features from base classifiers to train the pretrained network, which leads to improved performance over transductively trained networks."
SP:b1f65724926f136979829b7a6c870bc31f38f591,"This paper studies the problem of prioritizing policy updates in reinforcement learning with respect to the regret minimization objective. Prior criteria for prioritization have been the TD error, recentness and corrective feedback, which are mostly heuristically designed. This paper proposes to use the previously proposed Prioritized sampling to better utilize these samples. The paper proposes two methods to compute the prioritization weight, namely ReMERN and ReMERT. The first method is based on the idea of learning an error network to outperform previous prioritized sampling algorithms, while the second method uses the temporal ordering of states to obtain an optimal prioritized update strategy.   The paper provides theoretical justifications for previous criteria and proposes two new methods, which outperform the previous methods. The main contributions of the paper are the following :   1 ) The paper develops and studies a new prioritized policy update method based on prioritized sampling. This method is similar in spirit to the Prioritized Sampling ( PSA ) method, but is different in the sense that it considers data with higher hindsight TD error and better on - polarity ( as measured by the Q - value ) during sampling. The authors argue that PSA should be assigned with higher weights during sampling as it leads to better quality data and hence leads to higher regret minimisation. 2 ) The experiments are conducted to compare the proposed PSA with two methods that use the same or similar prioritization weights : Re - MERT and Re - MAERT. Results show that the proposed method is better than the methods of PSA and MAERT, and outperforms them in most of the time even when the sample size is small."
SP:601ebf30b3c6aa35fcef49633aa8eb0acd0f2c66,"This paper studies the problem of sequential prediction with expert advice in a nonstationary environment with long - term memory guarantees in the sense of Bousquet and Warmuth [ 4 ]. It proposes a linear - time algorithm that improves on the best known regret bounds [ 27 ]. This algorithm incorporates a relative entropy projection step that is advantageous over previous weight - sharing approaches in that weight updates may come with implicit costs, as in for example portfolio optimization. The authors provide an algorithm to compute the projection step in linear time, which may be of independent interest. They also provide a classification algorithm to classify expert advice as well as the non - expert advice.   The main contributions of this paper are as follows :   1. The paper introduces a new sequential prediction problem, sequential AdvPair. This problem is different from previous sequential prediction problems in that it considers a non - stationary environment where the goal is to predict the future value of an object ( e.g., a stock ) rather than the goal of the state. The main result of the paper is that the sequential prediction error does not go as high as it did in the previous work. This is due to the fact that the expert advice does not need to be correlated with the history of the object. The expert advice still needs to be compared with the original object if it is to be used as a basis for future investment decisions. This information can be found in the supplementary material for the paper. 2. The method for computing the relative entropy projections is compared with two prior methods. The first one is based on Euler ’s principle and it is called Euler’s Gradient Update ( EGO ) and it computes the projections based on the mutual information between the weights of the objects in the state and the environment. It is important to distinguish between EGO and EGO because EGO may contain information that belongs to a different class of objects. The second one, based on a Lagrangian called Luyendijk ‘s rule, computes a lower bound on the log likelihood of the entropy of the environment that depends on the distance between the object in the environment and the distance to the object from the origin. In the case of EGO, the lower bound is lower than the upper bound, which indicates that the environment is more stable. 3. Finally, the authors compare the performance of their proposed method with two previous methods that use EGO to estimate the cost of a KL divergence between the original and the target distribution. They find that the proposed method performs better than the first two methods in most cases."
SP:b2439973063e827b3cbe92306a2fdee3286b6b44,"This paper proposes an algorithm for learning a hidden d - dimensional value $ \tilde{x}$ given a set of actions $ R$ from a contextual linear bandits problem, where the learner is presented with a subset of possible actions $ Xt Xt ⊆ R$, and the user has to choose one of them to maximize the utility. The paper proposes two algorithms for this problem, one which achieves regret O(d log T ) and exp(O(D log d ), the other which achieves distance between the true value and the best action the user could have obtained with the currently selected action. The algorithm for the former is based on a variant of Steiner ’s formula for the centroid of a convex set ( which may be of independent interest ), while the one for the latter relies on existing algorithmic techniques in convex geometry.   The paper presents results of the proposed algorithm in two scenarios. In the first scenario, the first round of the problem is similar to the one in [ 1 ]. The difference is that instead of the user learning the value ( value x ), they learn the utility ( value w ), and in the second, the user learns the action ( action. x ) that is better than the one they currently choose to take. The second scenario is similar in spirit to [ 2 ], except that the user does not need to provide a list of actions in order to learn the value. The learner only needs access to one action in each round to obtain utility. This is done by computing the difference between the total distance between value x and recommended action w and value, and computing the distance between recommendation and utility. In this case, the distance is computed using the ratio between recommended and action value. Finally, the paper also provides results of a similar algorithm for a weaker version of this problem where the recommendation is only used in the upper - eights rounds. The main difference between these two scenarios is the fact that in the first case the recommendation does not require the user to use the hyperplane ; in the latter case it does so only if the value does not exceed a certain threshold. The experiments compare the proposed algorithms for the higher and lower bounds on the utility obtained by the upper and lower bound of the utility using the upper bound. The experimental results show that the algorithms outperform the lower bounds in most cases, especially in the cases where the value is smaller than $ \ell_2$.   "
SP:abe83c7e0bcf4829742609d709637e2f84d8a4d9,"This paper proposes orthogonal combinators for composing machinelearning operators into pipelines. It describes a translation scheme from pipelines and associated hyperparameter schemas to search spaces for AutoML optimizers. It presents Lale, an open - source sklearn - compatible AutoML library and evaluates it with a user study.   The main contributions of this paper are the following :   1 ) This paper introduces a set of combinators, each of which can be used to generate different permutations of the input sequence ( e.g., "" operator "" and "" filter "" ) by passing the input through a pipeline operator. The combinators are trained via gradient descent using a stochastic gradient descent method. The authors evaluate the combinators and the resulting operator in the experiments section of the manuscript. The experimental results are good. 2 ) The authors compare their proposed combinators to the state - of - the - art in terms of expressive power, showing that the combinator approach is more effective than the gradient descent approach and that the operator design is more flexible."
SP:0d7f1cae577ed598048b64617e85ca6bd5c6d7fa,"This paper studies the problem of finding neural network weights that generalize well on small datasets. A promising approach is to learn a weight initialization such that a small number of weight changes results in low generalization error. The paper shows that this form of meta - learning can be improved by letting the learning algorithm decide which weights to change in order to improve generalization. The main results show that patterned sparsity emerges from this process, with the pattern of sparsity varying on a problem - by - problem basis. This selective sparsity results in better generalization and less interference in a range of few - shot and continual learning problems. Moreover, the paper also finds that sparse learning also emerges in a more expressive model where learning rates are meta - learneded.   The main contribution of this paper is to shed light on an ongoing debate on whether meta learning can discover adaptable features and suggest that learning by sparse gradient descent is a powerful inductive bias for meta learning systems."
SP:05037e1850003a725a466b64d3e32aa2aed458fb,"This paper tackles a multi - view learning problem where one wants to identify common components from multiple datasets or views. The authors propose to model each view as a linear transform of shared independent components contaminated by additive Gaussian noise. They show that this model is identifiable if the components are either non - Gaussian or have enough diversity in noise variances. They then show that in some cases multi - set canonical correlation analysis can recover the correct unmixing matrices, but that even a small amount of sampling noise makes Multiset CCA fail. To solve this problem, they propose to use joint diagonalization after Multisetting CCA, leading to a new approach called ShICA - J, which is based on second - order statistics. They provide empirical evidence on fMRI and MEG datasets that ShICA yields more accurate estimation of the components than alternatives. They further propose to leverage non -Gaussianity of the   components using a maximum - likelihood method, ShICA-ML, that is both more accurate and more costly."
SP:44dd1faa1813c433fd7581d05cae3df440bfb93e,"This paper proposes a new multi - agent reinforcement learning approach called Fictitious Co - Play ( FCP ) to solve the problem of how to train agents that collaborate well with human partners without using human data and data augmentation. The approach is based on the two - player collaborative cooking simulator that has been proposed as a challenge problem for coordination with humans. The authors propose to train agent A ( A - C ) and partner D ( D - P ) using a population of self - play agents ( FC ) and their past checkpoints taken throughout training, a method they call flexitious co - play ( FCP ). They conduct extensive experiments on a two - agent collaborative cooking simulators ( PCS ) that has recently been proposed to solve this problem. They find that FCP agents score significantly higher than SP, PP, and BCP when paired with novel agent and human partners. They also report that humans also report a strong subjective preference to partnering with FCP agent over all baselines.    The authors argue that the crux of the problem is to produce a diverse set of training partners that is as effective as possible without using a human data set of the training partners. The main contribution of this paper is to propose a new approach that can be used to improve the generalization of agents to new human co - players to improve their generalization performance when training with them. In the experiments, the authors demonstrate that a surprisingly simple approach to training with FCP is highly effective. The major concern of mine is that the authors do not provide sufficient explanation as to why FCP is superior to other approaches to generalize agents to humans. This is not entirely clear and I would appreciate the authors explain the differences between their results."
SP:21c84bd720b1e90ea0f88fbf8fd24dbcb49b547c,"This paper proposes FACMAC, a method for cooperative multi - agent reinforcement learning in both discrete and continuous action spaces. Like MADDPG, which uses deterministic policy gradients to learn policies, FACMAC learns a centralised but factored critic, which combines per - agent utilities into the joint action - value function via a non - linear monotonic function, as in QMIX, a popular multi -agent Q - learning algorithm. However, unlike QMI X, there are no inherent constraints on factoring the critic. FACMAC also employs a nonmonotonic factorisation to evaluate its representational capacity and empirically demonstrate that it can solve some tasks that cannot be solved with monolithic or monotonically factored critics. The authors evaluate FACMAC on variants of the multi - agents particle environments, a novel multi - Agent MuJoCo benchmark, and a challenging set of StarCraft II micromanagement tasks. Empirical results demonstrate FACMAC’s superior performance over MAD DPG and other baselines on all three domains."
SP:1c8351b8a6cdf1212840388e19a596729b3bfda4,"This paper proposes a biologically plausible alternative to the Hopfield network as a model of biological long - term memory, which relies on Hebbian plasticity for storage and attractor dynamics for recall. In contrast, memory - augmented neural networks in machine learning commonly use a key value mechanism to store and read out memories in a single step. This paper proposes an implementation of basic key - value memory that stores inputs using a combination of biologically plausible three - factor plasticity rules. The same rules are recovered when network parameters are meta - learneded. The proposed method performs on par with classical Hopfield networks on auto - agglomerative memory tasks. It can be extended to continual recall, hetero - associative memory, and sequence learning."
SP:7ad6da2c63859d64970e9b35326e9ceab48add47,"This paper proposes simple stochastic and online gradient descent methods for pairwise learning ( Pairwise Learning ), where the loss function depends on a pair of instances. It instantiates many important machine learning tasks such as bipartite ranking and metric learning. The main contributions are the following :   1 ) A new algorithm for the gradient direction of the learned pairwise function, named SGD - OBD, is proposed which is efficient in both the storage and computational complexity. This algorithm is based on the popular gradient descent ( gradient descent ) algorithm of Zhang et al. ( 2021 ). 2 ) A stability analysis is performed to evaluate the stability of the SGD algorithm used by the proposed algorithm. 3 ) The authors develop novel techniques to improve the efficiency of SGD in terms of stability, optimization, and generalization error bounds for both convex and nonconvex tasks as well as both smooth and smooth nonsmooth problems."
SP:cb11dacc930d71a616ee2fbe4acfae030f9dca59,"This paper proposes REDO, a class -agnostic framework to construct the Dynamic Objects from RGBD or calibrated videos. The setting is more realistic yet more challenging for three reasons : due to occlusion or camera settings an object of interest may never be entirely visible, but the paper aims to reconstruct the complete shape ; 2) the authors aim to handle different object dynamics including rigid motion, non -rigid motion, and articulation ; 3 ) they aim to reconstruct different categories of objects with one unified framework.   To address these challenges, they develop two novel modules : 1 ) A canonical 4D implicit function which is pixel - aligned with aggregated temporal visual cues to capture object dynamics. 2 ) A 4D transformation module which captures object dynamics to support temporal propagation and aggregation. The experiments are conducted on synthetic RGBD video datasets SAIL - VOS 3D and DeformingThings4D++, and on real - world video data 3DPW 3D. They find REDO outperforms state -of - the - art dynamic reconstruction methods by a margin. In ablation studies, they validate each developed component."
SP:8ae97752e74b4395774575009031abcb6ba5cea7,"This paper studies the analysis of linear stochastic approximation ( LSA ) algorithms with fixed stepsize, which is used to obtain approximate solutions of a linear system   for which $ \varepsilon$ and $ b$ can only be accessed through estimates $ \ell_2 $ : $ ( An,bn : $ n 2 $, \epsilon : n 2 N⇤)$. The paper derives high probability bounds on the performance of LSA under weaker conditions on the sequence $ $ An,bn : n $ $ ( $ n : 2 $ $, $ N\bar{An,bn})$, where $ n$ can be thought of as the number of iterations and $ \bar{B}$ is the step size in the linear system. The analysis is based on new results regarding the moments and high _ probability bounds for products of matrices which are shown to be tight. The paper shows that LSA with tightness $ \theta$ is equivalent to LSA without any additional assumptions ( i.e., no Gaussian or exponential high probability estimates are used ). However, in contrast, with polynomial matrices appearing in the central limit theorems, LSA is able to maintain polynoma concentration bounds with order depending on the stepsize.    The paper provides a non -asymptotic analysis of the LSA algorithm with fixed step sizes and non - Gaussian assumptions on the following tasks :   ( 1 ) Linear regression with Gaussian discounting ( 2 ) Multiplicative Neural Networks ( MLE ) ( 3 ) Neural Network ( NL ) ( 4 ) ReLU ( 5 ) Neural network ( NL - GP ( 6 ) Neural net ( 7 )"
SP:86c1e937755e35efafecc09dfe2606ffb1653a41,"This paper extends the options framework for temporal abstraction in reinforcement learning from discounted Markov decision processes ( MDPs ) to average - return ones. The main contributions include general convergent off - policy inter - option learning algorithms, intra - option algorithms for learning values and models, as well as sample - based planning variants of existing deep learning algorithms. The convergence algorithms and convergence proofs extend those recently developed by Wan, Naik, and Sutton ( 2018 ), and extend the notion of option - interrupting behavior from the discounted to the average - reward formulation. The efficacy of the proposed algorithms is demonstrated with experiments on a continuing version of the Four - Room domain."
SP:7e4e1e20e7c253d02c6ae58457fb30029f130f0c,"This paper proposes Visual Transformers ( VTs ), an architectural paradigm alternative to Convolutional Networks ( CNNs ). Differently from CNNs, VTs can capture global relations between image elements and they potentially have a larger representation capacity. However, the lack of typical convolutional inductive bias makes these models more data hungry than common CNNs. In fact, some local properties of the visual domain which are embedded in the CNN architectural design, in VTs should be learned from samples. The authors empirically analyse different VTs, comparing their robustness in a small training set regime, and show that, despite having a comparable accuracy when trained on ImageNet, their performance on smaller datasets can be largely different. Moreover, the authors propose an auxiliary self - supervised task which can extract additional information from images with only a negligible computational overhead, to learn spatial relations within an image. This task is used jointly with the standard (supervised ) training and it does not depend on specific architectural choices, thus it can be easily plugged in the existing VTs that are already trained.    The authors evaluate the proposed method with different VTs and datasets, and conclude that their method can improve ( sometimes dramatically - sometimes dramatically ) the final accuracy of the VTs."
SP:0132ef17585e293b23e9dc45189c0989d829b52a,"Hyperbolic Procrustes Analysis ( HPA ) is a new label - free alignment method for hierarchical data. It proposes to use a three - component method for aligning data ( translation, scaling, and rotation ) based on the Riemannian geometry of the Lorentz model of hyperbolic space. This is in contrast to previous methods for label alignment based on logistic regression, e.g. KL - divergence, logistic normalization, and KL - regularization. The authors propose three new versions of the components of HPA, which are translation ( based on Gumbel ’s principle of translation ), scaling ( based upon the coordinate angle between the coordinate vectors ) and rotation (based on the rotation angle of the coordinate vector ). They evaluate the effectiveness of the proposed method on three datasets ( CIFAR10, MNIST, and Fashion - MNIST ) and three batch correction tasks ( gene expression, batch effect removal from data, mass cytometry batch correction ), and showcase its performance on two datasets ( MNIST and Gene Expression - Batch Correction ). In addition, they conduct simulations to evaluate the HPA against existing label alignment methods and to compare its computational and theoretical properties.   The main contributions of this paper are the following :    ( 1 ) It proposes a new type of label alignment method based on a three component method, which can be applied to align data at different times and locations using different methods ( Langevin, LSTM, and kLorentz ). This method is referred to as HPA and is proposed as the third method in this paper. ( 2 ) It introduces a new version of the three components of the method, called HPA - R, which is similar in spirit to the previous two versions. The difference is that the original HPA has only three components instead of the original four in that it uses rotation, translation and scaling. This means that the authors do not have to re - use any coordinate vectors during the alignment process ( rotation and scaling ), which they do not need to do during translation. ( 3 ) The authors argue that this is more stable since only scaling and rotation need to be used ( translation can be re - used multiple times and scaling can be done many times to get a consistent representation of the data, while rotation can be reused many times. ( again, this is not argued to be true for all datasets )   In the experiments, the authors compare HPA with existing methods ( HL - RMS and HL - Normalization ) and find that HPA performs about equally on all three tasks. They also compare the proposed methods with two new methods that do not use rotation, one that only uses translation and one that uses scaling. Finally, HPA is compared with HL - normalization on the three tasks and finds that it performs slightly worse ( on the gene expression task only )."
SP:3580ac64f09e3021de5d4c92411bcc0f3c5d10f3,"This paper studies the trade - off between accuracy for sum queries ( collected using a differentially private algorithm that produces micro - data ) vs. accuracy for its component sub - populations when collected using point queries. The paper shows that for pure differential privacy algorithms that do n’t require the microdata, the accuracy can degrade by a logarithmic factor ( log O(1 / O(d ) ), which is the average squared error of the answers to sum queries and all point queries that are not produced by the algorithm. The uncertainty principle is studied in terms of the difference between the number of queries ( $ n$ ) for a population of interest $ z$, and for queries that can be thought of as the sum of points of interest ( $ p$ ). It is shown that for point queries, one can guarantee that each answer has squared error $ \sqrt{O(1/\dagger)}$ for all queries while allowing an extra $ \nabla(d) factor for the sum queries. For sum queries, the uncertainty principle can be viewed as the difference in the ratio of the expected return for each query for a subset of $ z$. The paper then goes on to propose two mitigation strategies to ensure that the accuracy of the query answering algorithm does not degrade : ( 1 ) guarantee that the answer to each query is correct for all subpopulation $ p(z ) $, and ( 2 ) allow an additional $ o(2 / d ) factor for some queries that is greater than $ \sigma(0, \epsilon)$ ( for all other queries ). Finally, the paper proposes a collection of benchmark datasets to measure the uncertainty between the true and approximation of the true query accuracy when the algorithm is applied. The datasets are used for the experiments and the main results are presented in the paper as appendix."
SP:c0e64dc8acfaed3e4d7745af12fd34003d0e5017,"This paper proposes a novel algorithm CO - PILOT ( “ Path - Planner - Agent Interaction Learning over Deep Tree Structured Sub - Task Sequences ” ) to learnable path - planners and RL agents to produce dense feedback to train each other on a curriculum of tree -structured sub - task sequences to improve each other ’s performance on long - horizon tasks. The algorithm is based on the idea that planning can find the shortest path to a distant goal that provides dense reward / guidance but is inaccurate without a precise environment model, and that RL and planning can learn from each other to overcome their own drawbacks of sparse reward and inefficient exploration in long horizon tasks, where planning is required to estimate the distance to goal from the current state and RL to goal, which is difficult without a detailed environment model. The method involves a planner decomposing a long horizon task into a tree of sub - tasks whose layers are constructed coarse - to - fine with a RL agent so that the layers are easier to learn from, and then the planner trains the RL agent to progressively increase the rewards on the lower layers while reducing the ones on the upper layers. The planning policy is trained to minimize the ‘ cost ’ of completing the task with the lower layer rewards while increasing the rewards at the upper layer. The RL agent and the planner then train jointly on the task from the previous episode to the one in the tree for a set of multiple episodes before moving on to the next task, and so on. The idea is that the higher the number of layers of the tree, the better the planner can estimate the task - related rewards at each layer. CO - planning layer, and vice versa. The paper compares CO - OT with RL ( SAC, HER, PPO, and PPO ), planning ( RRT * NEXT, SGT ), and their combination ( SoRB ) on navigation and continuous control tasks, and shows that the proposed method significantly improves the success rate and sample efficiency. The main differences between the methods are the following : ( 1 ) in the case of SoRB, the planning policy does not require the agent to learn the depth of each layer of the layers ( the planner does ), ( 2 ) in SAC there is no need for planning layer rewards on top layers, but there is a need for the planner to learn depth information at the layer(s ) of the layer with the lowest layer rewards, and ( 3 ) in case of PPO there are no planning layer denser rewards at all, the planner only needs to learn a sparse amount of depth information from the agent.   The method is evaluated on a series of navigation tasks where the planner is asked to predict the path to achieve higher rewards at a task from a lower layer than at a layer"
SP:9911693a04a300b5a93634fb0267ef83e5489d77,"This paper proposes a Bayesian framework for generating local explanations along with their associated uncertainty. The framework is built on top of Bayesian versions of LIME and KernelSHAP to obtain plausible intervals for the feature importances, capturing the associated uncertainty, and to generate consistent explanations with guarantees in a computationally efficient manner. The resulting explanations not only enable the author to make concrete inferences about their quality ( e.g., there is a 95% chance that the feature importance lies within the given range ), but are also highly consistent and stable. Experiments on real world datasets and user studies demonstrate the efficacy of the proposed framework.   The authors carry out a detailed theoretical analysis that leverages the aforementioned uncertainty to estimate how many perturbations there are in the sample, and how to sample for faster convergence. This work makes the first attempt at addressing several critical issues with popular explanation methods, thereby generating consistent, stable, and reliable explanations. However, the authors do not provide any analysis of the black box explanations generated by state - of - the - art techniques, and provide very little insight into their correctness and reliability. In addition, these methods are also computationally inefficient, and require significant hyper -parameter tuning. The main contribution of this work is to develop a framework that can generate consistent, stable and reliable local explanations with the guarantees in one shot, thereby enabling them to generate more consistent explanations in the future."
SP:5efb4b81bd37c70640e8768e9dfb5bba14a0cfb8,"This paper studies the property difference between convolutional neural networks ( ANNs ) and their counterparts ( CNNs ) based on the similarity measurement between features and filters. The main contribution of this paper is to propose a novel method for tackling existing heavy tails in ANNs with only a modification of classifier where ANN features are clustered with their tails wellformulated through an angle - based constraint on the distribution parameters to encourage high diversity of tails. The authors claim that ANNs suffer from low accuracy as compared to CNNs where the accuracy of ANNs is not as good as that of CNNs due to the inherent discrepancy in similarity measurement of filters and features. To alleviate this discrepancy, the paper proposes to measure the difference between the distribution of the features and the similarity of the filters with respect to the feature space through the pre - defined pre - training parameters of the ANNs and the CNNs. To this end, the authors propose a weighted sum method for the distribution distribution of features under the assumption that the distribution is fully controlled and designed for various properties. The paper further proposes to use a novel approach for tackling the problem of the high percentage of overlap in the features among the distribution tails when training ANNs. The proposed method is evaluated on several benchmarks and compared with other distributions. The experiments demonstrate that the proposed approach can boost the performance of ANN on some tasks compared with CNNs while not achieving superior performance on others.   The main contributions of the paper are the following :   1 ) The paper proposes a new method for measuring the difference in distribution of feature space between the filters and the features in an ANNs based on similarity measurement 2 ) The method is compared with the distribution distributions of features in CNNs and ANNs, and shows that the ANN features tend to have larger overlap in feature space than CNNs, leading to lower accuracy. 3 ) The authors further propose to use the proposed method to tackle the issue of high proportion of overlap between the feature spaces of ANN and CNNs with the aim of boosting the performance on ANNs on tasks such as drug discovery and drug discovery."
SP:cbccb65457564992d534504c0d060da44cafce8c,"This paper studies the phenomenon of feature imbalance in neural networks when cross - entropy loss is minimized, i.e., only a subset of features relevant for the task is exploited, while other predictive features are ignored. The authors propose a formalism for this phenomenon, which they call feature imbalance, and they formalize using tools from Dynamical Systems theory ( DS ). They show that there is a certain statistical structure in training data that ensures that such a situation can be expected given certain structure of learning dynamics. Based on this formalism, they develop a novel but simple regularization method, Gradient Starvation, to improve the accuracy and robustness of neural networks that are hindered by gradient starvation. They illustrate their findings with simple experiments.    The main contribution of this paper is the following :   1. Identification of the feature imbalance phenomenon of gradient descent, and how it affects neural networks. This is done by showing that the features that are exploited most during gradient descent are the ones that are missing during the gradient starvation step, and when the features are not exploited during gradient starvation, the network ’s weights remain the same. 2. Proposing a regularization procedure to ensure that the weights of the neural network do not drop below a certain threshold value, which is upper bounded by a constant constant. 3. Demonstrating that the learning dynamics of a neural network under gradient starvation are the same as when the weights are not scaled according to the scale of the network, they provide a theoretical explanation for why the weights tend to stay the same throughout the training process, and also provide an upper bound for the weights that drop below the threshold value."
SP:8f6fe37cb0a332b66e10cc00261a44622841c8c6,"This paper investigates the question of whether humans prefer AI that improves objective metrics of team performance over those that improve subjective metrics of trust in the cooperative card game Hanabi. The question is framed as follows :    1. In Hanabi, humans and AI agents are given a cooperative game in which they must play as a team of four players and must score as many as possible to progress to the next round in the game.   2. The game is played in two rounds : during the first round the AI agent is allowed to run a rule - based AI teammate ( SmartBot ) during the second round and during the third round the human AI agent ( LearnBot ). The AI teammate is selected based on a state - of - the - art learning - based agent ( learnt from a deep reinforcement learning expert ) that is trained to be competitive with the AI teammate. 3. The human and AI agent teams are evaluated using the following metrics : 1. Game score ( collected as part of the objective evaluation ). 2. Perceived performance ( measured using a proxy measure of trust ), 3. Teamwork, interpretability, and preference of AI teammate measured using 4. Overall, the paper finds that humans prefer SmartBot over LearnBot and that humans are more trusting of AI teammates that are more cooperative with each other and more supportive of each other in the games they play. On the other hand, the majority of AI agents in the study showed that they do not learn as much from their human teammates as they do from the learning learning teacher. Taken together with the paper ’s other experimental results, the study finds that SmartBot outperforms LearnBot in terms of ( 1 ) perceived performance ( 2 ) interpretability ( 3 ) and ( 4 ) trust ( 5 ) teamwork ( 6 ) in the Hanabi evaluations. The paper concludes with a set of questions that encourage the use of learning teachers to further develop AI as a “ teacher ” in future cooperative games."
SP:2a05e333fc1a14057515ef3addde9a40152373db,"This paper proposes a novel learning approach for the task of visual question generation ( VQG ), a task that aims to generate human - like visual questions from an image and a set of visual hints. The key idea is to use a similarity matching method ( rule - based similarity matching ) to obtain candidate visual hints that are statistically close to the one - image - to - many - questions mapping problem, which generates uninformative and non - referential questions. The proposed method, called Double - Hinted Visual Question Generation ( DVG ), can be cast as a weakly supervised learning problem with noises where the goal is to generate high - quality visual hints to guide the generation of questions from the image and the other side information, e.g., answer type or the answer itself. DVG is proposed as an alternative to the standard visual - question generation approaches that use only visual hints because they are noisy practically and thus restrict the quality of generated questions. It is shown to outperform the state - of - the - art visual and answer - matching approaches by a large margin on a variety of metrics, including both automatic machine metrics and human evaluation. The main contributions of the paper are the following :    ( 1 ) A novel approach for generating visual hints for the VQ generation task based on noise - matching ; ( 2 ) A strong assumption that the probability of being ground truth about the true ground truth of a given visual clue is lower than that of being misled by the noise matching, which allows DGV to focus less on estimating the estimating probability of the ground truth and more on the predicted visual clue, which is higher than the estimated ground truth. ( 3 ) A set of experiments that compare the performance of DGV with other noise matching methods on different datasets, showing that DGV outperforms them in terms of both accuracy ( on the ground - truth questions and the visual hints ) as well as other metrics such as AUC and AFFID."
SP:15756d6ef47b39ded404acea2135c93bd5ee1062,"This paper proposes Generalized Data Weighting ( GDW ) to mitigate label noise and class imbalance by manipulating gradients at the class level. GDW unrolls the loss gradient to class - level gradients by the chain rule and reweights the flow of each gradient separately. In this way, GDW achieves remarkable performance improvement on both issues.   The main contributions of this paper are as follows :   ( 1 ) This paper proposes a novel generalized data weighting method, which leverages a small amount of clean and unbiased data to generate large class - specific weights for each instance of each dataset. The proposed method is called GDW. ( 2 ) It conducts extensive experiments in various settings to demonstrate the effectiveness of GDW and to compare its performance compared with state - of - the - art methods. ( 3 ) It is important to note that the experiments conducted by GDW do not directly compare GDW with other methods ( e.g., CIFAR-10 ), as the paper claims to be “ fully transferable ” between different datasets. ( 4 ) In the experiments with GDW, the authors conducted extensive experiments to discover the primary contributions of each method. The main results show that GDW has a significant performance improvement compared with the other methods in terms of both label noise ( which is magnified significantly by the presence of noise in the dataset ) as well as class imbalance."
SP:7a8f56a01bec51ebf70d9ff689005a62cccfe5c6,"This paper proposes a new task to learn grounded language for spatio - temporal descriptions of behavioral traces of an embodied agent. The task is based on the idea that embodied agents need to be able to generate behavioral traces that match observations and observations from the past using language grounded in sensorimotor modalities. To achieve this task, the authors propose to train a truth function that predicts if a description matches a given history of observations. To train this function, they use time - extended predicates that include past and present tense expressions as well as spatio temporal references to objects in the scene. To study the role of architectural biases in the learning of the task, they train several models including multimodal architectures, transformer - based and transformer - free architectures. The authors test their models on two classes of generalization ( generalization overall and generalization with randomly generated held - out sentences ) against a set of embodied agent models and two sets of pretrained models. They show that maintaining object identity in the attention computation of the Transformers is instrumental to achieving good performance on generalization and that summarizing object traces in a single token has little influence on performance. They also discuss how this opens up new perspectives for language - guided autonomous embodied agents. Finally, they release their code under open - source license to encourage the wider community to build upon and extend their work in the future."
SP:3d4a9d439bc84c3b0e6600f6985a23bdf95cd67f,"This paper proposes a novel method for multiple object tracking and segmentation, called Prototypical Cross - Attention Network ( PCAN ), which leverages rich spatio - temporal information for online tracking via cross - attention to retrieve rich information from the past frames. The method first distills a space - time memory into a set of prototypes, from which objects can be identified by tracking one - stage, two - stage and three - stage segmentation. To segment each object, PCAN adopts a prototypical appearance module to learn a set   contrastive foreground and background prototypes, which are then propagated over time to become more realistic representations of the object. Experiments demonstrate that PCAN outperforms the state - of - the - art methods in terms of accuracy, detection accuracy, and tracking accuracy.   The main contributions of this paper are the following :   1. A novel approach to the association problem between objects of the same class, based on the prototypical features learned from past frames, and the features that can be segmented using the learned prototypes. This approach, while temporal in nature, leads to poorer performance compared to the existing methods ( e.g., CVPROP and PEARL ). 2. A method to learn the distance between two prototypes by distilling features from different frames, which leads to better performance compared with the previous approaches. 3. An approach to track multiple objects from a single frame using a masked feature extraction method, which again leverages temporal inversion to improve the temporal property of the feature extraction, and a method to track objects from multiple frames using the masked feature extractor."
SP:1175ad16382b349ab1a39895150172d266abe571,"This paper studies the possibility that gradient descent may represent gradient descent in the optimization problem of deep learning. Deep learning is an important research field that aims to improve the computational efficiency of deep neural networks. To this end, many approaches have been proposed to analyze the gradient descent of neural networks in order to determine whether or not it represents gradient descent. One such approach is gradient descent with conventional step size estimation. This paper proposes to study the possibility of representing gradient descent as a solution to the initial value problem of gradient flow, and derive a bound on the degree of approximation depending on the curvature around the gradient flow trajectory. Gradient flow is amenable to theoretical analysis, but is stylized and disregards computational efficiency. The main contribution of this paper is to explore whether gradient flow can be regarded as a discrete optimization problem, or as a continuous optimization problem that is either parametrized by ( gradient variants of ) gradient flow or directly treating ( gradient descent ).    The main results of the paper are the following :   ( 1 ) Theorem 1 : Gradient descent may be parametrizated as an approximation to the solution of a value problem in terms of curvature. Theorem 2 : The probability of obtaining an approximate solution of the original value problem can be expressed as a function of the number of curvatures of the gradients of the vector $ \theta$. Theorem 3 : For any fixed point $ z$, the approximation probability of $ A$ depends only on the angle between $ A \to -\theta$ and $ \Omega(Z)$ with respect to $ Z$.   In the experiments, the authors consider three different settings of gradient descent : ( a ), ( b ) a general case, ( c ) a case with homogeneous activations, ( d ) annealed gradient flow trajectories, and ( e ) gradient descent trajectories. The experiments show that the generalization error bound for $ Z$ is bounded by $ \epsilon$, $ \gamma$. The authors conjecture that this bound is independent of $ \eta$ of the $ \mu$ and that $ \Delta$, but not $ \Phi$, and use it to derive the bound $ \sum\pi$. The experiments suggest that the upper bound is close to the lower bound, suggesting that the approximation error may depend only on $ \pi$ on the $ z$. ( 2 ) The authors derive a lower bound for the bound of $"
SP:b8412e9ce82ce92125fe7cd3aff7bea8b906d16e,"This paper studies the delayed and long - term impact of actions within the context of multi - armed bandits. In particular, it studies the problem of MAB, where actions taken in the past impact the arm rewards in the subsequent future. The authors generalize the bandit setting to encode the dependency of this “ bias ” due to the action history during learning. They propose an algorithm that achieves a regret of â’¬(KT 2/3 ) and show a matching regret lower bound of �‚T ( where K is the number of arms and T is the learning horizon ). The goal is to maximize the collected utilities over time while taking into account the dynamics created by the delayed impacts of historical actions. The experiments compare the proposed algorithm with two baselines, a stochastic bandit and a more general bandit with adding techniques to deal with actions with long -term impacts. The experimental results demonstrate that the proposed method can achieve higher accuracy than the baselines. The main concern of mine is that the experiments fail to distinguish between “ typical ” bandit behavior and “ extreme ” behavior. For example, the capability to pay back a loan for people in a certain social group might depend on historically how frequently that group has been approved loan applications. In this paper, we only consider the extreme behavior experiment and do not investigate the more commonly used bandit behaviour experiment in the appendix."
SP:9c1d678dff5f609197dc3cfb67b841827f4a439a,This paper proposes a per - clip model for video instance segmentation ( VIMP ) based on transformers. The main contributions are :    ( 1 ) The proposed model is based on the idea of encoding the context within the input clips as a means of conveying information between frames ; and ( 2 ) The features of each frame are enriched and correlated with other frames through exchange of information between the precisely encoded memory tokens. ( 3 ) The authors validate their method on the latest benchmark sets and achieve state - of - the - art performance ( with the help of a considerably considerably faster runtime ( 89.4 FPS ) than the baseline model. ( 4 ) The method can also be applied to apply to the near - online inference for processing a video in real - time with only a small delay.   The paper is published online under the name Inter - frame Communication Transformers ( IFC ). The manuscript contains the following main contributions : - The authors propose an inter - frame communication transformer ( IC ) to facilitate information passing between frames by efficiently encoding the features within the clips ; - The features are enriched through the encoding of memory tokens corresponding to the features of the clips in the frames discussed in IC ; - Each token represents a specific frame in the IC and is used to generate a summary of the features for each frame ; - This summary is then used to compute the feature embedding for the token representing the frame from IC. The summary features can then be used in the per - frame model to generate frames with similar features. - The method is validated on a series of short - term training datasets and is shown to achieve comparable performance to the baseline frame - to - frame ( frame - wise ) model.
SP:6c922eaa358f6fb9771690b1240e4f6f08a35b69,"This paper proposes a general graph embedding method, called residual2vec, that can be used for embedding graphs obtained from random walks. The authors claim that the degree of each node in a graph can be biased due to the structural properties of graphs, and propose a method to mitigate this bias by sampling node degree proportionally to its maximal value. The main contribution of this paper is to investigate the impact of the random walks ‘ bias on graph embeddings and propose residual 2vec, a method that can counter this biased sampler by using a more robust embedding procedure, called embedd2vec. The proposed method is based on the idea that the embedding process can be made robust to structural biases in graphs obtained by using random graphs. Under this assumption, the authors propose to train a neural network to predict the nearest neighbor of a node given a sample from a distribution over nodes sampled from the distribution over all the nodes in the graph. To train the network, the nodes are sampled according to their degree with respect to the degree maximal value, and the likelihood of the node is estimated by the mean squared error of the distance between each node and the average distance between node and average node. The network is trained using GraphSAGE, GraphSAINT, and RAG - GAT. The experiments show that the proposed method significantly improves link prediction and clustering performance over the baselines, and also allows to explicitly model salient structural biases that would otherwise not be considered when embedding a graph."
SP:851eac96135b577a5014166edcb43db6a190cf4b,"This paper studies the problem of quadratic risk estimation for estimating the power sum functional of discrete distributions under local differential privacy ( LDP ), where $ p(x)|$, $ x^2 $, $ \nabla_p$ and $ pK$ are assumed to belong to an unknown discrete distribution p = p, $ p_p(x^1 $, p_k ), $ z^{(x_{p}$, z_k)}$ where $ z_i$ is produced using one individual attribute xi. This paper studies LDP in two settings : 1 ) in the sequentially interactive case, where the data are allowed to use already published confidential data ( PM ), and 2 ) in a non - interactive setting where data can be generated sequentially using data that is not necessarily interactive with the others. They use the Gaussian multinomial model for the interactive setting, which they term Gaussian LDP, and obtain lower bounds on the parametric rates for all α - LDP mechanisms and all estimators using the private samples. 2 ) In the non - interactive setting they use two plug - in type estimators that are similar to the one used in Gaussian MLE analyzed by Jiao et al. [ 18 ], except that due to the privacy constraint, due to which the rates they attain are slower and similar to those obtained in the case of Gaussian model, they obtain higher bounds. They also describe the behavior of the quadratically risk for estimating power sum using private samples, which is obtained by using the two - step procedure described in [ 9 ]. The authors give lower bounds results over all $ \alpha$-LDPs.    The main contribution of this paper is the following. First, they study the case when $ p(\alpha,k)$ is assumed to be a discrete distribution, where p(z^{(k ) }, p(\sqrt{K})$ is the expected value of private samples and $ \theta$ is a function of the expected power of the discrete distribution. This is done using two mechanisms, the first one is a linear estimator ( linear and non - linear in its estimator ), the second one is an exponential moving average estimator. They show lower bound results for the linear in the first case, and upper bounds results for all the linear estimators. In the second case, the authors show lower bounds for the algorithm using the algorithm. The main result of the paper comes from using the plug -in - type estimator and the plug-in - estimator estimators of F."
SP:a0408b54f88a26479f33f36bb27e0a675f637ccd,"This paper proposes APPLETRON, a surrogate regret - based multiclass classification algorithm based on an arbitrary directed feedback graph. The main novelty of the paper lies in the use of the feedback graph as the classifier in the proposed method. Traditionally, multi - class classification algorithms have been developed for bandit feedback as a special case. However, in this paper, the authors instead focus on the setting where the learner ’s feedback is determined by a graph - theoretic directed graph. This allows the algorithm to work with arbitrary feedback graphs that allow for more efficient label efficient classification and filtering.   The main contributions of this paper are the following :   1. The paper proposes a new surrogate regret bound that holds for surrogate losses over a large class of surrogate losses. The bounds are of order BKT, where BKT is the diameter of the prediction space, K is the number of classes, T is the time horizon, and ρ is the domination number ( a parameter controlling the amount of exploration ). 2. The authors prove surrogate regret bounds that hold in expectation and with high probability for a class of surrogates. 3. The algorithm is compared with GAPPLE - TRON, an existing algorithm that uses a classifier to predict the regret of a given class using a directed graph directed towards a target class. The comparison is made using synthetic data, and the results show that for various feedback graphs our algorithm is competitive against known known baselines ( e.g., SGD, GAT - SGD ). 4. In the full information case, the algorithm achieves a constant surrogate regret with a lower bound of $ \epsilon$ that holds in both the expectation and the probability of the surrogate loss. 5. Theoretical results and experimental results are provided to justify the effectiveness of the algorithm."
SP:490262589efce6fb10b913431ec6db8d4e5b2dec,"This paper studies the problem of explainable k - clustering in the setting first formalized by Dasgupta, Frost, Moshkovitz, and Rashtchian ( ICML 2020 ). A k - cluster is said to be explainable if it is given by a decision tree where each internal node splits data points with a threshold cut in a single dimension ( feature ), and each of the k leaves corresponds to a cluster. This paper gives an algorithm that outputs an explainable clustering that loses at most a factor of O(log k ) compared to an optimal ( not necessarily explainable ) clustering for the k - median objective and factor of $ O(k log k ) for k - means objective.   The main contributions of this paper are as follows : 1. The paper introduces a k clustering algorithm, which is remarkably simple to implement. The algorithm is oblivious to the data points and runs in time O(dk log k, independent of the number of data points n ). This improves over the previous best algorithms that could not explainably explain the clustering produced by the proposed algorithm. 2. The authors generalize the upper bounds of the bounds mentioned above ( upper and lower bounds ) to also generalize to objectives given by higher `p - norms ( higher than the upper bound ). 3. In addition, the authors introduce a new $ \ell_{p}$-earlier bound for k-means objective that is slightly larger than the previous upper bound."
SP:6a9e47be710ddaf386bffc54d003d7dc2b67fdc3,"This paper proposes a multilingual language model ( PrLM ) that supports both explicit universal dependency parsing and implicit language modeling for downstream natural language processing tasks, in which multilingual PrLM takes advantage of language universality to alleviate the issue of limited resources for language processing in low - resource languages. Syntax in terms of universal dependency parse serves as not only pre - training objective but also learned representation in the model, which brings unprecedented interpretability and convenience in downstream task use. The proposed model outperforms two popular mult - bilingual PrLM, multilingual-BERT and mult - BERT - R, on cross - lingual natural language understanding ( NLU ) benchmarks and linguistic structure parsing datasets, demonstrating effectiveness and the effectiveness and stronger cross -lingual modeling capabilities of the approach of our approach. The main contributions are the following :   1. The authors propose a novel mult -   language model, called Multi - Language Model ( MLM ), which is pre - trained and trained in two different ways : ( 1 ) for dependency parsing, and ( 2 ) for implicit language modelling. This model has the capability to predict the probability distribution of variables in a task from the implicit representation provided by the language model. This allows for more interpretability in tasks where the PrLMs only focus on plain text and ignore obvious universal linguistic structure clues ( e.g., when mult - text text is searched through the implicit language model ). This paper is an extension of the multi - language PrLM ( Xie et. al., 2021 ) where the implicit representations are learned from the text. The difference between MLM and MLM is that the learned representation of the text representations is represented in the latent space of the MLM model as a weighted sum of two terms, one representing the probability distributions of variables with respect to each other and another representing the total number of pairs of variables. This representation is similar to the one used in Xie et al. ( 2021 ), but the difference is more subtle and less concrete.    2. The primary contribution of this paper is to the literature is to develop a model that can be used for downstream tasks where language structure knowledge is scarce and the downstream task is text - based. The use of monolingual linguistic structure knowledge may bring about better performance ( as it is able to discriminate between text and structure representations ), and implicit representation of structure knowledge can be biased towards language structure. This is the main contribution of the paper. 3. The experiments are conducted on two datasets, NLU and LSTM. The results demonstrate the effectiveness of the model and the authors ’ claim that the model is more interpretable and more convenient to use in downstream tasks."
SP:94f4b65214a648cbc84f13beba45a825e2e9901a,"This paper presents a novel Dual - Aspect Collaborative Transformer ( DACT ) algorithm to learn embeddings for node and positional features separately, instead of fusing them together as done in existing ones. The motivation is that existing positional encoding ( PE ) method is not suitable for representing VRP solutions because it does not capture the circularity and symmetry of the solutions. To this end, DACT introduces a cyclic positional encoding method ( CPE ) to allow Transformer to effectively capture the symmetries and circularity of VRP solution. The authors also train DACT using Proximal Policy Optimization ( PPO ) and design a curriculum learning strategy for better sample efficiency. Experimental results show that DACT achieves much better generalization performance across different problem sizes on synthetic and benchmark instances.   Contributions :   - This paper proposes a novel algorithm for learning improvement models for solving vehicle routing problems ( VRP ) based on transformer architecture. - The authors develop and apply CPE to learn node embedding and positional embedding in DACT. - They conduct experiments to evaluate the effectiveness of DACT and PPO."
SP:e5c8680d8da9e7548fcb9bb5c073848eb80e1dd0,"This paper proposes a new approach to compute the Bayes error of generative generative models based on normalizing flows. The authors use it to evaluate the generative model performance on synthetic datasets generated by varying the temperature of the state - of - the - art learned flow models, and find that in some cases the models are capable of obtaining accuracy very near optimal, while in other cases, the obtained models are not as good. The method relies on the following contributions :   ( 1 ) The authors show that, given a Gaussian distribution $ \mathbb{R}$ and a temperature $ \epsilon$ of $ \theta$, they can generate synthetic datasets $ \nabla_{\theta}$ whose mean and standard deviation are Gaussian distributions. This is done efficiently using Holmes - Diaconis - Ross integration ( H - DRA ). ( 2 ) They use the same parameters ( $ \eta$ and $ \gamma$ ) that were used in computing the Gaussian base distributions to obtain the optimal classifier in the learned flow model by using H - DRRA. ( 3 ) They show that the generated datasets generated using their approach are as good as those generated using standard Bayes - optimal classifiers. ( 4 ) They also use their approach to conduct a thorough investigation of the learned models, finding out if the obtained classifier is robust to perturbations in the learning process, and if so, how much perturbation is needed to keep the model robust."
SP:2896679f0472522bc3334178cd7574494cf12b7b,"This paper presents GradInit, an automated and architecture agnostic method for initializing neural networks. The method is based on the heuristic that the norm of each layer in a neural network should be adjusted so that a single step of SGD or Adam with prescribed hyperparameters results in the smallest possible loss value. The adjustment is done by introducing a scalar multiplier variable in front of each parameter block of each neural network. GradInit then optimizing these variables using a simple numerical scheme. Grad Init accelerates the convergence and test performance of many convolutional architectures, both with or without skip connections, and even without normalization layers. It also improves the stability of the original Transformer architecture for machine translation, enabling training it without learning rate warmup using either Adam or SGD under a wide range of learning rates and momentum coefficients."
SP:f69731403592fa5bdd4ca327708582d615aa131c,"This paper proposes a new method for tracking disease progression through linear - mixed - effect models for Alzheimer's disease ( AD ) progression estimation using data from the Alzheimer's Disease Neuroimaging Initiative ( ADNI ) database. The authors learn the metric update of the Euclidean metric by a diffeomorphism estimated iteratively as the composition of radial basis functions belonging to a reproducible kernel in Hilbert space. The objective is to learn patient - specific trajectories distributed around a central geodesic in order to predict disease progression trajectories for a set of patients whose trajectories have been identified as having slowed down or stopped moving in the last few years.   The authors first obtain the data from ADNI ( although the authors do not use the same dataset as the original ADNI and hence do not have access to the original data, the authors use data from a different database maintained by the Alzheimer’s disease neuroimaging initiative ( E - DADS ). They also obtain data from other sources ( e.g., the French government under management of Agence Nationale de la Recherche ) as well as the U.S. government under the ""Investissements d’avenir"" program ( PRAIRIE 3IA Institute ). In addition, they obtain data under the joint programme in neurodegenerative diseases ( JPND ) ANR - ANR ANR-19 - JPW2 -000 from the University of California, Los Angeles. They use the data to build a linear model of the progression of a patient's disease through the trajectory of a single neuron. They estimate the mean and covariance of a neuron activations in the trajectory. The linear model is trained to fit the trajectory and the covariance matrix with respect to the objective function. They then apply the linear model to the E - EADS dataset and show that the proposed linear model leads to better disease progression estimations. They compare the proposed approach favorably to the methods of the EADS and other methods of state - of - the - art in the TADPOLE challenge. The EADS results are evaluated in terms of the expected mortality rate for a subset of the patients and the expected survival rate for the control patients. The results demonstrate that the linear models outperform the other methods by a wide margin, especially when controlling for confounding factors such as the number of neurons and the rate at which the patients ’ trajectories are estimated."
SP:438e906f52c4c0538956b51a2270b3ac498b27a8,"This paper proposes a novel routing - by - memory mechanism for extracting semantic features from convolutional blocks in neural networks. The authors propose to use the same procedure sequence for all inputs, regardless of the intermediate features, in each stage of the extraction process. They introduce parallel Neural Units ( PUs ), which consists of a memory head and a procedure. The memory head maintains a summary of a type of features. For an intermediate feature, the memory head locates its closest memory and forward it to the corresponding procedure in both training and testing. In this way, different procedures are tailored to the different features and therefore tackle them better. Experimental results show that our proposed mechanism improves on Tiny ImageNet, ImageNet, CIFAR-100 benchmarks with a negligible extra computational cost.    The authors also propose a mechanism to train routing by memory in CNN architectures, where they use a four - step training strategy. The training strategy is based on VGGNet, ResNet, and EfficientNet. The proposed mechanism is tested on TIPNet, Tiny imagenet, and Tiny - ImageNet. It is shown to significantly improve the performance of these methods compared to the baselines. The experimental results also show that the proposed method with the proposed PUs is better than the methods without PUs in terms of time, accuracy, and accuracy with respect to other CNN architectures."
SP:d240173080cd3647dbaa5173a6422396f226775b,"This paper analyzes the scalar - based method for designing neural networks that respect the symmetries and coordinate freedoms of physical law. It shows that a large fraction ( possibly all ) of classical physics is equivariant on translation, rotation, reflection ( parity ), boost ( Relativity ), and permutations, and analyzes this equivariance to prove that it is simple to parameterize universally approximating polynomial functions that are equivariantly symmetric under these symmetsries, or under the Euclidean, Lorentz, and Poincaré groups, at any dimensionality d. The key observation is that non - linear O(d)-equivariant functions can be universally expressed in terms of a lightweight collection of scalar, vector, and tensor products, provided they are parametrized with scalar $ \ell$-contraction and vector $ \nabla$-norm. The paper supports its theory with numerical examples that show that scalar based method is simple, efficient, and scalable.   The main results of the paper are the following : 1. Theorem 1 : For any set of polynomials $ p(s, a ) = \mathbb{R}^2 $, where p is a scalar operator and a \theta is a tensor operator ( $ \lambda$-th order tensor ), we can find functions $ \tilde{s}$ such that p(\lambda, a) = \sum_t\lambda(s ) \to_t, where s(\lambda(\lambda ) ) = s ) where s ) is a function of $ \gamma_t$ that depends on $ \Delta_t$. Theorem 2 ) Equivariantness of functions $ p(\Delta_{t } ) = 1 -\alpha(s)$ where p(\gamma)\theta \rightarrow \lambda(\Delta)(\lambda)(\Delta ) ) is the function we wish to parametrizate. Note that $ \eta$ can be thought of as a weighted sum of functions such that \Delta(s)-p(\lambda\theta, s ) can be represented as $ \sum_{t}^n$ by tensor \lambda$.   3. The main result of this paper is that for any set $ \phi$-\sigma p(a, b\lambda(\theta ) = 0, \Delta\tilde\tau(\lambda)-tau)\tau\mid ) \epsilon(\tau ) \times p("
SP:72c0f47566904deb27d8157da30807ec1d6b5685,"This paper studies the loss functions for bbox regression based on the power of the intersection over union ( IoU ) loss and its variants. It generalizes existing IoU - based losses to a new family of power IoU-based losses that have a different power parameter and regularization term, and analyzes properties such as order preservingness and loss / gradient reweighting. The main contributions of the paper are three - fold :    1 ) it proposes a new loss function based on α - IoU loss that surpasses IoU losses by a noticeable margin ( Figure 1 ). 2 ) it introduces three new methods to increase the sensitivity of the bBoxReg ( Figure 2 ), 3 ) and 4 ) it studies the properties of the obtained loss functions.   The paper is well written and clear to follow. The major weakness is that it spends too much time discussing the differences between IoU and α-IoU losses and not enough time explaining the similarities between the two families of losses. It also uses the wrong terminology for the difference between the Gaussian ( Gaussian - like ) losses and the power Gaussian losses ( Power Gaussian ) losses, confusingly calling the former a Gaussian term and the latter a weighted sum of Gaussian terms, when in fact it is actually a weighted average of the two terms with the first one being the weighted average. The authors clearly state the differences in the definitions and provide the proper explanation for the differences. The experiments are conducted to demonstrate the superiority of the proposed α - Gaussian loss over IoU Loss and the comparisons are made with respect to 3 other loss classes that are not considered in the paper."
SP:397125177d7007316d67194ec00d5dc57b44ac79,"This paper studies Distributionally Robust Imitation Learning ( DROIL ) and establishes a close connection between DROIL and Maximum Entropy Inverse Reinforcement Learning ( MIRED ). DROIL can be seen as a framework that maximizes a generalized concept of entropy, and the authors propose a novel approach to transform the objective function into a convex optimization problem over a polynomial number of loss functions that are additive over state and action spaces. The authors experimentally show the significant benefits of DROIL’s new optimization method on synthetic data and a highway driving environment.   The authors further propose a method to optimize both stationary and non - stationary policies and, unlike prevalent previous methods, it does not require repeatedly solving an inner reinforcement learning problem. The method, called Robust Robust Learning ( RobustRL ), is not related to the previous methods and instead leverages recent advances in reinforcement learning to learn a policy that produces behaviors that are nearly as good as the experts ’ for a desired task. In particular, the authors show that, for the task on which DROIL is applied, the reward function is not given, but demonstrations from experts are available. In order to ensure that the policy is distributionally robust against noisy demonstrations based on an adversarial construction potentially solves this problem by avoiding optimistic generalizations of the demonstrated data. However, in practice, assumptions of consistent optimality for demonstrated behaviors are often violated in practice. To prevent this from happening in practice the authors develop a policy optimization method that optimizes both the stationary policy and the non - stationary policy based on a weighted sum of the observed behaviors with respect to the observed policy. The approach is quite simple and straightforward. It consists of three steps : 1 ) train the policy using expert demonstrations 2 ) fine - tune the policy by averaging over all the sampled behaviors 3 ) transfer the policy parameters to a random distribution sampled from the random sampled behaviors using a discriminator 3 ) and apply the policy to the randomly generated samples using a policy matching policy matching loss. In the experiments the authors have demonstrated that the proposed approach, unlike the previous approaches, leads to behavior improvements on many tasks that were not observed by the experts. In general, the benefits of using DROIL over MIRD and MIRED are more noticeable when compared to the baseline approaches."
SP:58f220bbbed8d3e0633b408fca3b6838c4ad323d,"This paper proposes a general post - processing algorithm for individual fairness ( IF ) based on Laplacian regularization for the linear similarity graph between individuals guided by the fairness constraints. The authors cast the IF post -processing problem as a graph smoothing problem corresponding to graph laplacians, and propose a general algorithm to approximate the graph regularization that preserves the desired “ similar individuals similarly ” interpretation. Empirically, the authors show that the proposed algorithm can correct individual biases in large - scale NLP models such as BERT, while preserving accuracy. The main appeal of postprocessing is that it avoids expensive retraining.    The main contribution of this paper is to cast post processing as a problem that can be treated with graph smoothed regularization, where the objective function is to reduce the similarity gap between the predictions of the original model and the similarity graph of individuals with respect to which the fairness constraint is inversely proportional. This formulation allows the authors to study a setting where the learner has access to only two data points : the prediction of the model and a similarity graph. The proposed algorithm generalizes the original post processing algorithm in two steps : in the first step, it computes the similarity graphs for the two sets of data points ( e.g., the pairwise similarity graph and the individuals ). In the second step, the algorithm computes a similarity vector for the graph used to graph - smoothing the graph in the previous step and uses it to compute the similarity vector in the current step. The algorithm. The obtained similarity graphs are used to update the classifier in the last step of the optimization step to obtain the final similarity graph for the model in the second stage. The method is applied in both the training and the testing phase of the algorithm to obtain uniform similarity graphs. The experimental results demonstrate the effectiveness of the proposed method. The major contributions of the paper are the following :   1 ) The authors develop a general framework for post processing algorithms for the individual fairness problem. This framework is flexible enough to handle different settings of similarity graphs, different learning objectives, and different learning sizes. This flexibility allows them to apply their algorithm to a variety of datasets, such as the BERT model ( small scale, large scale, and ML - based models. They compare their algorithm with BERT based algorithms and show that their algorithm produces similar results on all of them. 2 ) In the experiments, their algorithms are applied to a range of datasets ( small - scale, medium - sized, and large scale ), yielding results that are competitive with or slightly better than the best baselines."
SP:ef791aa29decd839e7e583c9d1f71e8309ca87ef,"This paper proposes a structure - aware Dual Graph Aggregation Network ( SADGA ) for cross - domain Text - to - SQL ( T2S ), where the goal is to generalize the trained model to the unseen database schemas. The authors study three methods : ( 1 ) encoding method to model the question and the database ; ( 2 ) question - schema linking method to learn the mapping between words in question and tables /columns in the database schema ; and ( 3 ) mapping between query words and the rows / columns in database schema. Based on the encoding method and linking method, they propose a structure-aware aggregation method, where each graph in the question graph and database graph are aggregated to get a 3 - dimentional encoding of both the natural language question and database schema based on the graph structure of the target domain. The method is tested on the benchmark T1S benchmark and compared with two baselines, namely, T4S and T5S. Results show that the proposed method outperforms the baselines in terms of generalizability and accuracy.    Next, the authors propose a second method, called SAD - AGE, which uses the same graph structure as in the first method, but is applied to the query question graph instead of the database graph. This method is claimed to be more robust than the first one in that it does not require the same number of graph pairs for each query graph ( which can be problematic in high - dimensional queries ). The experimental results show that SAD-AGE outperforms T1s by a wide margin, especially in high dimensional queries. Finally, in the low dimensional queries, the method seems to perform about as well as the proposed baselines."
SP:a2fa25a4539a38af61a0993f65ecc14339f26c2e,"This paper studies the problem of learning end - to - end learnable discrete - continuous models for supervised and reinforcement learning ( SSL ) on stochastic computations graphs with multiple sequential discrete components. The authors propose two strategies to improve the behavior of these models. The first is to increase the scale of the Gumbel noise perturbation during training to improve learning behavior. The second is to use dropout residual connections to reduce the dropout complexity of the discrete - continuum models.   The main contributions of the paper are the following :   1 ) The authors study the effect of learning discrete components at each step of the graph evolution process on the learnability and interpretability of the models. They find that the more complex the discrete components are, the more challenging it is to learn the optimal model parameters. This is mainly due to small gradients and local minima for the parameterization of the convolutional layers. 2 ) They propose to use gradient - descent based optimization to train more complex discrete-continuous models which one cannot train with standard stochastically softmax tricks. 3 ) They test the effectiveness of their methods on several benchmark datasets and show that the learned models generalize better than their continuous counterparts."
SP:bb3ec363e90269db4a2ba99d8107cb56f86e68f0,"This paper studies the covariate shift and generalization of Bayesian neural networks ( BNNs ) with approximate inference via Hamiltonian Monte Carlo ( HMC ). The authors find that BNN with high - fidelity approximate inference achieves poor generalization under covariate shifts, even underperforming classical estimation. The main reasons for this are three - fold. First, the authors identify the source of the generalization problem : linear dependencies in the input features cause a lack of posterior contraction. Second, they show why the same issue does not affect approximate inference with HMC or classical maximum a - posteriori ( MAP ) training. Third, they propose novel priors that improve the robustness of BNN s to many sources of covariate shifted data."
SP:f86ec7042e9b73ae071704a6d3ed17d7e3da1b75,"This paper categorizes meta - learning evaluation into two settings, i.e., in - distribution ( ID ) and out of distribution ( OOD ), where the tasks sampled from the same underlying task distribution as in ID but not from OOD, due to disjoint sets of train ( novel ) and task ( iid ) classes. They identify that most existing few - shot classification benchmarks instead reflect OOD evaluation, as they use disjointed sets of task and train. This discrepancy is problematic because meta - learners methods that perform better on OOD datasets may perform significantly worse in the ID setting. They provide suggestions on how to construct FSL benchmarks to allow for ID evaluation as well as more reliable Ood evaluation.   The paper evaluates several methods ( Metaschool, Metalearning Theory ( META ), Meta - Learning ( ML ), FSL ( FastSlim - based Self - Control ) ) on a few datasets from the OOD dataset using both base and test tasks. They find that meta - learner methods with OOD - > ID evaluation performance are more likely to be selected for tasks that are OOD > ID, and those that are not considered for OOD / ID evaluation are less likely to learn tasks from the base dataset. They also provide suggestions for how to improve the robustness of the model selection for a given meta -learning method in OOD setting ( suggestions 1 and 2 ). The paper also provides comparisons of the performance of different methods ( suggestions 3 ) that are empirically verified using the current benchmarks ( suggestions 4 and 5 ). They evaluate their methods on 5 datasets and find that Meta - learning methods generally perform better than OODE methods on average, but worse than baseline methods on rare - test tasks, and that methods perform even worse on rare / ID datasets."
SP:371f77148b4f00a929f7c118b1bb7c5a6238d264,"This paper proposes two methods for rule induction based on LM - based methods. The first one is open rule induction ( OORD ), which aims to automatically induct open rules from the knowledge base LMs without requiring annotated rules. The second one is based on the language model ( LM ) rule generation and aims to augment the expressive power of the LM methods by augmenting the language of the inducted rules with features extracted from the LM rules. Authors argue that the difference between LM and KB rule induction is that whereas KB induction uses commonalities between the data and the rules to induct the rules, the LM method uses the current LM methods to “ learn rules from rules ”, which leads to limited generative power compared to the KB method. Authors propose to use OORD to generate open rules whose patterns are constrained by those of the annotated set of rules. OORD experiments are conducted to verify the quality and quantity of the automatically inducted open rules produced by OORD."
SP:8be2e0ea4a83fe32a4859f456007a829e5e9270a,"This paper proposes Implicit Constraint Q - learning ( ICQ ) for offline RL in multi - agent settings. Multi - agent setting has more agents with larger state and action spaces compared to single agent setting, which makes for more challenging offline RL tasks. The main contribution of this paper is to propose a novel offline RL algorithm that uses implicit constraints to enforce a value constraint on the joint action taken by each agent to minimize the extrapolation error. The value constraint is imposed by only allowing the value estimates of the action pairs taken by the joint policy of each agent given the state - action pairs from the dataset. The authors extend the implicit constraint approach from single agent offline RL to multi agent setting by using it in task definition for implicit constraint extension. The proposed ICQ algorithm is validated on StarCraft II dataset. Results show that ICQ achieves better performance than state - of - the - art offline RL algorithms in terms of expected return on invested policy matrices when applied to task definition."
SP:1939b24b68970c33ca16ce238deed257f76d009e,"This paper proposes a new approach for generating adversarial examples ( AEs ) using machine learning models. The key idea is to train AEs with non - uniform perturbations that represent semantically meaningful dependencies in the features of the machine learning model. This is in contrast to prior work which trained AEs by uniform norm - bounded perturbation across features. This paper proposes to use empirical data distribution for generating such non uniform perturbed examples. Three main components are proposed :    ( 1 ) A general approach to generate AEs that is robust to adversarial attacks ( robustness = ability to distinguish real - world adversaries from the AEs generated by the agent ), ( 2 ) A robustness method for generating AEs using data augmentation, ( 3 ) Correlations between the features and the importance of the features in generating the features via the proposed approach, and ( 4 ) Data augmentation method to produce AEs from scratch using only the features.   The main contribution of this paper is the three main components proposed in the main paper. The first component is a general idea of using empirical data to generate a robust set of AEs for training AEs. The second component is the empirical distribution of the collected AEs to generate the corresponding features. The experiments show that this approach is more robust than the uniform pertubation approach ( sensitivity analysis ) in terms of the number of correlations with the features ( more robustness w.r.t. the average number of logits ). The third component is robustness in terms to ensure that AEs produced by the proposed method are comparable to the one used in the first part of the paper, i.e., the robustness is higher than the expected loss value. The authors test their method on a set of synthetic AEs and AEs, and show that their approach is indeed more robust. The empirical experiments are conducted on synthetic data from CIFAR-10, MS - RCN-16 and MS - FFN-2, as well as some real world datasets ( e.g., credit risk prediction, credit loss prediction, and spam detection )."
SP:417b30930b245667d777e5d90ee80dd41546760e,"This paper extends the theory of spectral filtering developed by Marteau - Ferey et al. ( 2013 ) to generalize generalized self concordant loss functions ( GSC ). In particular, the authors extend the original Tikhonov regularization ( introduced in [ 1 ] ) to GSCs that contain the logistic loss. The authors then show that the optimal convergence rate ( in terms of the excess risk ) for GSC is achieved by using the iterated Tikh on - ov regularization scheme ( Figure 4 ). Figure 4 shows that the best convergence rate for the optimal risk is achieved when the target distribution is learned with spectral filtering ( Figure 5 ).   The authors show that spectral filtering with GSC regularization converges faster to the optimal distribution than without regularization, and that this convergence rate is larger than the one obtained with TikhOnov Regularization ( Figure 6 ). However, it is not guaranteed that this improvement is statistically significant. In fact, the convergence rate might only be the average of the two rates if the difference between the two is less than 0.05 ( Figure 8 ), which is within the theoretical tolerance range that the paper claims can be reached with regularization using spectral filtering without using it ( Figure 9 ). This assumption is important because spectral filtering is a special case of GSC that depends on two assumptions ( e.g., the source and capacity conditions of the loss function ), and it is possible that the assumptions may turn out to be intractable under certain assumptions ( see [ 2 ] for details ). To test whether or not this assumption can be broken down into a straightforward set of assumptions is then tested empirically using the experiments from [ 3 ]."
SP:1caeee4f00b52fe356ff4e5dd004d0203e838370,"This paper proposes a new neural network architecture called Deformable butterfly ( DeBut ) that generalizes the conventional butterfly matrices and can be adapted to various input - output dimensions. It inherits the fine - to - coarse - grained learnable hierarchy of traditional butterflies and when deployed to neural networks, the prominent structures and sparsity in a DeBut layer constitutes a new way for network compression. The authors apply DeBut as a drop - in replacement of standard fully connected and convolutional layers, and demonstrate its superiority in homogenizing a neural network and rendering it favorable properties such as light weight and low inference complexity, without compromising accuracy. The natural complexity -accuracy tradeoff arising from the myriad deformations of a deBut layer also opens up new rooms for analytical and practical research."
SP:d345ce1d7afc367ee1a9fb68d50ff1b2219f02cb,"This paper proposes a method to tackle the problem of catastrophic forgetfulness, which is caused by forgetting of old information in neural network training. The authors propose MetA Reusable Knowledge ( MARK ), a method that keeps a set of shared weights among tasks that can be used to avoid forgetting when learning a new task. The shared weights form part of a Knowledge Base ( KB ) that is enriched with new knowledge as the model learns new tasks. The idea is to prevent the weights of the KB from getting overwritten during the training of a task, thereby causing forgetting of existing information about the tasks. To this end, the authors propose to use a weighted metalearning approach to enrich the KB with knowledge acquired during training to foster weight reusability among tasks.   The authors demonstrate that using MARK, they achieve state - of - the - art results in several popular benchmarks, while achieving almost zero forgetfulness using only 55 % of the number of parameters ( compared to 55 % using in previous methods ). Furthermore, an ablation study provides evidence that, indeed, MARK is learning reusable knowledge that is selectively used by each task."
SP:722c52467e384058f8fdffa254d0e8db47440a64,"This paper studies the problem of scheduling heuristics in MDP solvers for mixed integer programming ( MIP ). The main contributions are two - fold : ( 1 ) synthesizing the heuristic scheduling heuristic framework and ( 2 ) proposing an efficient algorithm for computing such a heuristic under such a schedule. The first part of the work proposes to reduce the average primal integral by up to 49 % on two classes of challenging instances of MDP. This is motivated by the fact that real - world applications of MIP typically require finding good solutions early on in the search to enable fast decision - making. The second part proposes to learn from data describing the performance of primal heuristic schedules in an exact MIP setting to obtain a problem - specific schedule of heuristically - specific schedules of heuristic trajectories that collectively find many solutions at minimal cost. To this end, the authors develop a learning task and propose a data - driven framework to learn and use heuristic schedules to design a scheduling algorithm that matches the best possible schedule for computing a set of suitable heuristic policies under the assumption that the setting is robust to the type of problem under which the policy is being solved. The proposed framework is evaluated empirically on four MDP instances and compared to two baselines. The results show that the proposed scheduling algorithm is more effective than the baselines and more efficient than the learning task.   The main contribution of this work is the introduction of the idea of multi - heuristic policy scheduling for MIP solvers. Prior to this work, the only MIP heuristic design was to use one heuristic for solving one MDP problem and another for solving anotherDP problem with the same heuristic. This paper proposes to combine the two heuristic designs for improved performance."
SP:5a21f0a49731dcb1d68deb06a75138e8e9d514d5,"This paper proposes a new approach for reinforcement learning ( RL ) in which the reward function is only given at the end of each episode and the labels are generated by a parametric model. The idea is that this is more realistic than the traditional RL requirement that the learner receive feedback at every time step of the trajectory. The paper proposes to study the possibility of learning using RL in this setting by training an encoder - decoder model that generates the labels for the trajectory using trajectories sampled from the output of the encoder. The encoder is trained to predict the labels at each time step using the trajectories of previous steps of the learned policy. The goal is to learn a good or bad label for each trajectory, but not for every step, so that the model can generate labels for all possible trajectories. The method is referred to as multi - trajectory learning ( MTL ) and is different from standard linear MTL in the sense that it considers trajectories that are sampled from a fixed, fixed - point model ( e.g., the one that is used in standard MTL training ) rather than the parametric one. The main contribution of the paper is to show that it is possible to learn using MTL if the label labels are not generated by the model, but rather by sampling trajectories from it using the parameters of the parameterized model. Moreover, the authors show that the method is computationally efficient in terms of the number of steps required to learn the labels ( $ \mathcal{0,1}$ ) and the ratio of the rewards ( $ K$ for a good trajectory and $ \eps$ for bad ones ).    The main contributions of this paper are two - fold. First, the first is a collection of experiments that compare the performance of the proposed method, using the MTL model, with and without parametric labels, on the task of predicting trajectories using the LASSO dataset. The experiments show that MTL can learn trajectories with better performance than the standard LSTM. The second is a set of experiments comparing the performance with a different version of MTL, showing that the latter model is more robust to perturbations to the parameters. The authors also compare the proposed approach with two different versions of their method, one with parametric label generation ( i.e., “ good ” and “ bad ” ) and another with random label generation."
SP:e66bd9582058ba0f6091bb1042ce2ecfdaae1515,"This paper proposes a novel edge representation learning framework based on Dual Hypergraph Transformation ( DHT ), which transforms the edges of a graph into the nodes of a hypergraph. This dual hypergraph construction allows the author to apply message - passing techniques for node representations to edges in order to obtain edge representations from the hypergraphs, then obtain a cluster of nodes or drop edges to obtain holistic graph - level edge representations.   The authors validate their Edge Representation Learning ( ERL ) method with three different graph datasets, diverse graph datasets for graph representation and generation performance, on which our method largely outperforms existing graph representation learning methods, including GraphSAGE, GraphSAINT, and GraphNetsGraph. The authors also propose a node embedding and graph pooling method for graph reconstruction and graph classification, which is based on DHT. The experiments show that the proposed ERL method is effective for both graph reconstruction tasks and node pooling for graph classification tasks, and the authors validate the effectiveness of their methods as well as the efficiency with which they extract node representations from DHT nodes."
SP:e398873e29b05176e1d52dc6f86a59a4f405e6fd,"This paper studies the problem of learning representations of data from a simulated environment for reinforcement learning ( RL ). The learning representations are used to guide the reinforcement learning by discarding irrelevant and redundant information, while retaining the information necessary for control. The paper introduces Mutual Information ( MDP ) as a formalism for estimating MDP representations from samples of high - dimensional observations. It is not clear how much is understood about which MI objectives yield representations that are sufficient for RL from a theoretical perspective. This paper formalizes the sufficiency of a state representation for learning and representing the optimal policy, and study several popular MI objectives through this lens. Surprisingly, two of these objectives can yield insufficient representations given mild assumptions on the structure of the MDP. The authors corroborate their theoretical results with empirical experiments on a simulated game environment with visual observations.   The main contributions of this paper are the following :   1. Introducing MDP as a theoretical tool to estimate the state representation of a learning policy and guide the learning process 2. Empirically, the authors find that two of the objectives ( 1 ) and 2 ) do not correspond to the optimal representations when learning from the simulated environment."
SP:50181f740910195d3a50dd7d7f8cbb1c476d730b,"Deep feature learning, steerable convolution has recently demonstrated its advantages for 3D semantic analysis. However, it is computationally expensive on dense volumetric data, which prevents its practical use for efficient processing of 3D data that are inherently sparse. To address this shortcoming, this paper proposes Sparse Steerable Convolution ( SS - Conv ) to address the shortcoming by providing a general pipeline for precise estimation of object poses, wherein a key design is a Feature - Steering module that takes the full advantage of SE(3)-equivariance to maximize the advantage of deep feature learning over feature convolution. The authors conduct experiments on three tasks measuring the accuracy and efficiency of their proposed method, which greatly accelerates steerable Convolutions with sparse tensors, while strictly preserving the property of SE - equivariance. Their proposed pipeline based on SS - Conv outperforms existing methods on almost all the metrics evaluated by the three tasks. Ablation studies also show the superiority of their SS -Conv over alternative convolutions in terms of either accuracy or efficiency.    The paper is released publicly at https://github.com/Gorilla-Lab - SCUT/SS - Conv / designs."
SP:d746bfb200577c980d92727bb0b1a3c23e7bfdc5,"This paper proposes a dynamic token sparsification framework to prune redundant tokens progressively and dynamically based on the input. Specifically, the authors devise a lightweight prediction module to estimate the importance score of each token given the current features. The module is added to different layers of the transformer and prune tokens hierarchically. To optimize the prediction module in an end - to - end manner, authors propose an attention masking strategy to differentiably prune a token by blocking its interactions with other tokens. DynamicViT models achieve very competitive complexity / accuracy trade -offs compared to state - of - the - art CNNs and vision transformers on ImageNet.    The main contributions of this work are as follows. First, authors observe that the final prediction in vision transforms is only based on a subset of most informative tokens, which is not sufficient for accurate image recognition. Based on this observation, they propose a dynamic Token Sparsification ( TSP ) framework that progressively prunes redundant tokens by adding a prediction module and a pruning strategy to remove information tokens that do not contribute a lot to the predictions. The proposed dynamic TSP can achieve a speed - up of up to 37.5 % for the majority of tasks. Second, authors develop a method to increase the accuracy of the predictions by increasing the drop of accuracy from 0.5% to 0.7 % for various input tokens. This method is referred to as Dynamic ViT ( DynamicVT ) and it is similar in spirit to the self - supervised pretraining ( dynamic pretraining ) method ( Zhang et al., 2019 ). Different from DynamicVT, DynamicVT trains a model with the same number of tokens to predict the importance of each one of the input tokens, while it trains a different number of token predictions ( number of interactions with the other tokens ). The difference between DynamicVT and DynamicVT is that the former trains two models ( one with a single token prediction and one with multiple tokens predictions ), while the latter trains two ( with one using a combination of multiple tokens and another using a mixture of tokens. The authors claim that DynamicVT can achieve faster speed - upsampling in terms of accuracy while maintaining the same accuracy. Third, authors use the FLOPs method to improve the throughput by over 40 %, which improves the throughput over over 40%. The authors also propose a method for improving the throughput"
SP:d0b6cde42b1cba5e6e3c7c5131426fd84adbd3d7,"This paper studies the problem of continuous continuous regression when we do n’t have access to the distributional guarantees of the underlying regression function. The question is how to guarantee the non - vanishing intervals of the confidence intervals of a continuous mean regression function E [ Y | X ] under the continuous setting where the features X are continuously distributed. Traditionally, any confidence interval of the mean E must have non - vanishing width, even as sample size tends to infinity. This is motivated by recent work that established that any confidence intervals in the continuous case of E [ X | Y |X ] must be at least as wide as the average width of the samples ( assuming that the average number of possible values of features X is infinity ). In contrast, in the finite setting, one can guarantee the same confidence intervals but only if the effective support size of the distribution of distribution of X is smaller than the square of the average squared error in the expected values of the regression function ( E ).    The main contribution of this paper is to study the distribution - free guarantees for predictive inference in settings where the feature distribution is continuous. The authors first consider the setting where there is no finite feature distribution and assume that the mean function E is a function of continuous samples. This setting is referred to as Continuous Continuous Regression ( CCR ) and is distinguished from the finite Setting ( FSR ) in that it doesn't depend on the number of features $ X$. The authors argue that CCR is the only setting in which it is possible to guarantee all the guarantees for CCR under certain assumptions ( e.g., sample size $ \theta$ and $ \nabla_t$ ), and that without CCR it is impossible to obtain any guarantees at all. They compare the performance of various holdout methods ( holdout method, cross validation method, conformal prediction, holdout estimator ) against those of some regression methods ( conformal method ) that do rely on distributional assumptions. They also consider the continuous Setting ( CVR ) in the sense that there are two extremes of confidence intervals, one where the average of the sample size is infinity and the other where it is much smaller. They show that for CVR there are several distinct regimes that can guarantee confidence intervals ( in the range between $ \epsilon$ and \sigma^2 $ \tilde{O}$ where vanishing-width confidence intervals are achievable if and only if $ O(t(t ) \leq \gamma_t \Vert\Vert\Omega(T ) \bar{"
SP:123952325765c040c3078fc7dca2b6d370e55590,"This paper proposes Representation Neutralization Neutralization for Fairness ( RNF ), a method to mitigate the bias of Deep Net Network ( DNN ) models by debiasing only the task - specific classification head of DNN models. The key idea of RNF is to discourage the classification head from capturing information that is unfair or undesirable. To this end, the authors leverage samples with the same ground - truth label but different class labels to generate proxy annotations for sensitive attributes. Experimental results over several benchmark datasets demonstrate that RNF framework is able to effectively reduce the discrimination of Dnn models with minimal degradation in task-specific performance.   The main contributions of this paper are as follows : ( 1 ) The authors propose a new representation learning method for DNN heads, namely RNF, which is based on the idea of “ principal assumption ” ( 2 ) It leverages neutralized representations to train the class head of the DNN model to ensure that the discrimination is reduced even with biased representations as inputs. ( 3 ) The method is evaluated empirically on three datasets ( CIFAR-10, UCI-101, UCF-103, and UC-103 ) and compared with two baselines ( UCF and UCF101 )."
SP:210eb2c811f966bb1ac53932cacabbad9bb608fe,"The paper proposes a new type of convolutional layer, B - CNNs, that is invariant to all the possible rotations and angles by design. In particular, the proposed layer takes advantage of the Bessel functions to build a Bessel - CNN that is continuous and isotropic.    The main contributions of the paper are the following :   ( 1 ) A new convolution layer based on Bessel is proposed. This new layer is a continuous convolution with a B - key. ( 2 ) This key is used to train a neural network ( CNN ) that maps a set of possible rotation angles ( by design ) to the corresponding continuous rotation angle. ( 3 ) In order to train the CNN, the authors propose two methods : one that learns the translation invariance and one that trains the rotation invariance ( the second method is a bit like the first one ). The authors discuss the advantages and drawbacks of each approach in the introduction and paper is published with supplementary material."
SP:ee51ecbd476d5b65903c942a62be89ff5d91698b,"This paper introduces ParK, a new statistical approach for learning on large - scale datasets that combines partitioning with random projections and iterative optimization to reduce space and time complexity while maintaining the same statistical accuracy. In particular, constructing suitable partitions directly in the feature space rather than in the input space of the dataset is considered important to ensure orthogonality between the local estimators, thus ensuring that key quantities such as local effective dimension and bias remain under control. The authors characterize the statistical - computational tradeoff of their model, and demonstrate the effectiveness of their method by numerical experiments on several standard benchmark datasets.   The main contributions of this paper are as follows :   1. Introducing ParK - a new model - based approach to learn on large datasets, named after ParK ( Singh, Sridharan, Kumar, and Rakhlinan, 2020 ). 2. Demonstrating that ParK can learn on standard datasets such as CIFAR-10, MNIST, and Fashion - MNIST with better accuracy and longer runtimes than previous approaches. 3. Conducting experiments on the following standard datasets : MNIST ( 10, 100, 200, 250, 500, and 1000 m ). 4. Providing the experimental results on ParK and learning on MNIST that compare favorably to other methods ( including SGD - based approaches )."
SP:1f096d6fabd5b1fde43d06c552d46d87cd35cb4a,"This paper proposes a novel approach to learning discrete communication tokens with one - hot vectors to communicate among agents via word embedding using reinforcement learning. The authors argue that the current approach, in which one hot vectors are used as the communication vectors, prevents agents from acquiring more desirable aspects of communication, such as zero - shot understanding. They propose to use discrete vectors derived from learned, continuous embedding vectors instead of hot vectors. The word embeddings in the proposed approach are derived from natural language embedding techniques from NLP.   The authors propose a neural network architecture based on reinforcement learning and decision theoretic framework to learn the discrete communication vectors via self - play using a reinforcement learning approach. They show that this approach optimizes the communication over a wide range of scenarios, whereas one hot tokens are only optimal under restrictive assumptions. They also validate that trained agents learn to cluster tokens in semantically - meaningful ways, allowing them to communicate in noisy environments where other techniques fail. In the experiments, they demonstrate that the trained agents using their method can effectively respond to human queries in ways that do not require the agent to understand the human query."
SP:8630ccc627534f9033bced04e2137a897ffef701,"This paper proposes a new architecture called CoAtNets ( pronounced “coat nets ” ) that combines ideas from depthwise convolutional nets ( DNN ) and self - attention nets ( AttentionNet ) to combine the strengths from both architectures to improve generalization and capacity. More specifically, the authors show that DNNs and AttentionNet can be naturally unified via simple relative attention and that stacking layers of attention nets on top of convolution layers is effective in improving generalization, capacity and efficiency. To achieve this, they propose to stack layers of AttentionNet attention layers vertically. They also propose to combine attention nets with convolution nets in order to improve the overall capacity of the network. They evaluate the effectiveness of their architecture on ImageNet with different number of layers and different datasets. The experiments compare the performance of the CoAtNet with ImageNet, ConvNets, and TransformerNet under different resource constraints. The main contributions of the paper are the following :   ( 1 ) Combining DNN and attention nets for the first time, they show that depthwise Convolutional Networks can be unified via relative attention ; ( 2 ) Sticking to the DNN family of layers, stacking attention nets in a principled way can improve the generalization of both attention nets and generalize the network more efficiently ; ( 3 ) In addition, the approach is shown to achieve better top - 1 accuracy compared to ImageNet and Transformers when stacking multiple layers."
SP:d3ecbeeffa5ab365743ba8653c6739f24742ee31,"This paper proposes a new oracle bound based on parametric form of Chebyshev - Cantelli inequality ( CGII ), which is amenable to efficient minimization. The new bound resolves the optimization challenge faced by prior oracle bounds based on CGII, the C - bounds [ Germain et al., 2015 ], and Markov ’s inequality introduced by Masegosa et al [ 2020 ]. Based on the new bound, the authors derive a new concentration of measure inequality, PAC - Bayes - Bennett ( PAC - B - Bennett ), named after the fact that it combines PAC-Bayesian bounding with PAC - Bennett - Maddox. The authors provide an empirical evaluation demonstrating that the new bounds can improve on the existing bounds. The main contributions of the paper are as follows :   ( 1 ) The authors develop a new parametric CGII inequality, based on the one - sided version of CGII ; ( 2 ) A new set of bounds is derived for the expected risk of a weighted majority vote, which can be expressed as a function of the expected return of each candidate on the ballot. The bounds are evaluated empirically using the Masego - Markov inequality, and compared with the bounds of the previous oracle based on Markov. The results show that the proposed bounds do not suffer from the same decline in performance as those of the prior bounds ; however, they do suffer a decline in precision. ( 3 ) The main contribution of this paper is the introduction of a new second - order bound for the oracle of the CGII bound, which improves upon the first order bound. This second order bound can be seen as a second order version of the one made available in [ 1 ] ( although it is not quite as computationally tractable as the first one. ( 4 ) It is important to distinguish between the second order and the first - order oracle oracle. The experiments demonstrate that the first oracle can not match the performance of the second oracle, while the second one can match it. ( 5 ) The paper also includes an appendix that describes the differences between the two oracle types."
SP:5bac542a6532d43cf100e085398b4a4783719814,"This paper proposes a weakly supervised audio - visual video parsing framework that uses cross - video and cross - modality event co - occurrence to localize target events and exclude irrelevant ones. The proposed method exploits both the common and diverse event semantics across videos to identify audio or visual events using only video - level annotations. It is labor - intensive to temporally annotate audio and visual events and thus hampers the learning of a parsing model. To alleviate this issue, the authors propose to explore and train a supervisory network composed of 5 different videos and 5 different event encoders. The discovered supervisory signals across the videos and modalities can greatly facilitate the training of the proposed method. The experimental results show that the proposed framework performs favorably against existing weakly - supervised and self - supervised methods on the task.   The main contributions of the paper are the following :   1 ) The authors propose a new event - based event encoder that uses the cross - module co - occurrence to localise segments of target events for each target event. This is similar to the approach used in Gu et al. ( 2021 ) [ 1 ]. However, unlike that approach, the proposed localization technique localizes the target events only for selected segments of events ( i.e., only the selected segments that are relevant to the training ), not for all target events. This allows the trained model to only localize segments of relevant target events while ignoring other irrelevant ones ( e.g., the ones that are not related to the target event ). 2 ) It is important to train a network that only uses the generated event annotations for target events to avoid over - training and over - annotating. 3 ) The main contribution of this paper is the use of the event - aware network to generate the supervisory signal across videos and event handlers to leverage the learned event annotations."
SP:8fd6a03c1794afa524328d45f4232eacf6f86693,"This paper proposes QuPeD ( personalized model compression ) algorithm for personalized learning via knowledge distillation ( KD ) in federated learning ( FL ) setting, where clients train a single global model while collaboratively using multiple clients and a server. Two natural challenges that FL algorithms face are heterogeneity in data across clients and collaboration of clients with diverse resources. This paper proposes an algorithm for learning quantized models through a relaxed optimization problem, where quantization values are optimized over. For personalization, clients can learn compressed models with different quantization parameters and model dimensions /structures. The main contributions are :   ( 1 ) An algorithm is proposed for learning compressed models by gradient update for solving the compressed personalization problem, named Relaxed Relaxed Optimization ( LO ) ; ( 2 ) A research protocol is developed for training personalised models using QuPe algorithm ; and ( 3 ) Experiments are conducted to validate the effectiveness of the algorithm and compare it with other algorithms, including personalised FL methods, FedAvg, and local training of clients in heterogeneous settings."
SP:fca8b4f1e765cf1724a37f0ae9a7dac1cb79c8b1,"This paper proposes a novel framework for constrained clustering, DC - GMM, inspired by deep generative models, to leverage prior information on a limited amount of labeled data. It extends the framework of stochastic gradient variational inference ( SDVI ) in the sense that it explicitly integrates domain knowledge in the form of probabilistic relations, by explicitly integrating the underlying distribution of data conditioned on prior clustering preferences, expressed as pairwise constraints. The authors propose to use this knowledge to guide the clustering process towards a desirable partition of the data by indicating which samples should or should not belong to the same cluster using labels, and provide extensive experiments to demonstrate the superiority of the proposed method over other clustered - based methods on a wide range of data sets. They further demonstrate the usefulness of the approach on two challenging real - world applications.   The main contributions of this paper are the following :   1. A novel clustering framework based on SDVI is proposed, which is intuitive and interpretable, and can be trained efficiently with neural network training   2. This framework is compared to the existing methods ( DC - SVDV, SDC - SMI, SDP - DC - MMM ) in terms of performance and robustness on a small number of datasets ( MNIST, CIFAR-10, and Fashion - MNIST ), showing that it outperforms them in most cases."
SP:84379c0c881b7390ecc22fb398edfaf66d1af1ff,"The paper presents a new method to accelerate the training of deep neural networks trained with least squares loss by gradient descent ( NTK ) by sketching the polynomial expansions of the convolutional kernel of NTK ( CNTK ). Previous works have shown that NTK can outperform finitely - wide neural networks on small - scale datasets, but the computational complexity of kernel methods has limited its use in large - scale learning tasks. This paper proposes a near - input - sparse time approximation algorithm for NTK to speed up learning with NTK - based methods. The main contributions are :   1 ) A new method for speeding up learning of the exponentially - parameterized kernel methods for learning deep neural nets with least - squares - loss NTK by polynomials ;   2 ) A spectral approximation guarantee for the kernel matrix of the proposed method, called spectral approximation for the NTK matrix, by combining random features ( based on leverage score sampling ) of the arc - cosine kernels with a sketching algorithm for the corresponding parametrization of the kernel. 3 ) A detailed experimental evaluation is provided to verify that the spectral approximation guarantees the linear runtime in the number of pixels for transforming any image using linear runtime."
SP:fa2668083ff3bb592c29a4c6822ae96ff54d0dbe,"The paper proposes Multi - Range Transformer ( MRT ), a framework for 3D motion trajectory prediction for multi - person 3D models. The idea of the model is based on the observation that a human ’s action and behaviors may highly depend on the other persons around. To handle the prediction of human pose trajectories in isolation, the MRT introduces a global and local range encoder for individual trajectories and a social interaction encoder which attends to both local range and global range features of the person around. The MRT is trained using a Transformer encoder and decoder, and poses taken from the target pose are treated as queries to the encoder. The target pose is used to train the global range decoder and the individual pose is taken as a query to the transformer encoder, which is used for motion prediction and social interaction prediction respectively. The authors show that their model outperforms state - of - the - art methods on long - term MRT motion prediction, and generates diverse social interactions. More interestingly, the model can even predict 15 - person motion simultaneously by automatically dividing the persons into different interaction groups.    The main contributions of the paper are the following :   1. The introduction of a multi - range transformer framework for predicting motion trajectories of multi - people ; 2. The use of global range encoders for individual and social trajectories for the motion prediction ; 3. An effective approach to handle the pose queries for the individual trajectory in MRT ; and 4. A novel approach for social interactions by automatically splitting the person into interaction groups based on their social interaction."
SP:0a0e07af37c8fe8580639b1df62d27b6f63f8dee,"This paper proposes a new approach for training reinforcement learning agents in long - horizon planning problems where the goal is to train agents to achieve similar performance as using handcrafted programs to guide the agent. The approach, Model Predictive Program Synthesis ( MPPS ), trains a generative model to predict the unobserved portion of the world, and then synthesizes a program based on samples from this model in a way that is robust to its uncertainty. The method is evaluated on a set of challenging benchmarks, including a 2D Minecraft - inspired environment where the agent must complete a complex sequence of subtasks to achieve its goal, and achieves a similar performance to that obtained using hand - crafted programs. The results demonstrate that our approach can obtain the benefits of program - guided reinforcement learning without requiring the user to provide a new guiding program for every new task. In the experiments, our approach significantly outperforms non - program -guided approaches.    The key challenge for reinforcement learning is solving long - term planning problems. While there are several approaches to train RL agents to generate guiding programs in these settings, these approaches impose a high manual burden on the user, requiring them to devise a new program in each new task that can handle unobserved and/or partially observed environments. In this paper, the authors propose a model predictive program synthesis approach that uses program synthesis to automatically generate the guiding programs, which is then used to train a new training model and generate a program from scratch using the predictions from the training model. The training model is trained to be robust to the uncertainty of its predictions, and to be able to learn in a manner that allows for learning in unobserved environments that is consistent with its predictions. This approach is evaluated and compared with two other approaches to training RL agents in the setting, including one that trains the model directly and one that relies on a guiding program to generate new training data and another that trains an agent to generate training data using a program synthesis. The experimental results show that the approach outperforms the other two approaches in most settings."
SP:5bb42b178b0d27da271bfa60e633fdac718638c4,"This paper studies the problem of causal imitation learning in sequential settings, where the imitator must make multiple decisions per episode. Specifically, the authors consider the following two settings : ( 1 ) sequential settings where there is a mismatch between the dataset ( e.g., episodes 3 and 4 ) and ( 2 ) continuous settings where the dataset consists of episodes ( episodes 5 and 6 ), in which case the mismatch can be upper or lower bounds.    The first setting is assumed that the dataset belongs to a pre - trained demonstrator and the second one is assumed to belong to a fully - functional agent ( i.e., it has access to all the features that the demonstrator needs to learn to reproduce the behavior of the agent in the sequential setting. The authors define the term “ naïve imitation ” as learning to reproduce a system ’s underlying mechanics without understanding the underlying mechanics of such a system ( see “ Monkey see monkey do ”, Zhang et al. 2020 ). This definition is somewhat different from the original meaning of “ imitation learning ” in the sense that it does not refer to learning to imitate a purely visual representation of a stimulus but rather a set of visualizations of the stimulus, which can be obtained by training the agent to imitate the visual representations of real world objects. This paper considers the case where the real - world objects are represented by monkeys and the simulated ones by humans, and assumes that the monkeys have access to the same set of sensors as the demonstrators, which means that they can also see the same things that the humans can not see. This setting is referred to as sequential setting ( sequential setting ). The main contributions of this paper are the following Zhang et. al. ( 2020 ), which is concerned with the case when the dataset is sequential and the learning algorithm is single - stage. In particular, it considers two types of sequential learning algorithms. First, the GraphQL - based algorithm ( GraphQL ) is used to evaluate the performance of the learned agent by comparing its behavior with that of a fully functional agent with respect to the learned policy from the demonstration policy. This is the same algorithm that is used when training the imitation policy, but with a different policy. The key difference between GraphQL and RL is that the former trains the algorithm to distinguish between real - value actions taken by the agent from its simulated actions, while the latter trains it to distinguish real value actions from simulated actions. The difference between the two is the difference between real and simulated actions when learning the algorithm from the representation of the real data. The experiments show that under this setting, the proposed GraphQL results in lower performance ( for sequential learning ) are better than the results obtained under the first setting ( when the RL is single stage only ), and"
SP:85bd81f0c5b6ccbc421ebbaf6f5c72164bc70b7f,"This paper proposes a novel object - based transition model that decomposes a scene into objects, aligns them ( with respect to a slot - wise object memory ) to maintain a consistent order across time, and predicts how those objects evolve over successive frames. The model is trained end - to - end without supervision using transition losses at the level of the object - structured representation rather than pixels. The introduction of the alignment module allows the model to deal properly with two issues that are not handled satisfactorily by other transition models, namely object persistence and object identity. They show that the combination of an object - level loss and correct object alignment over time enables the proposed model to outperform a state - of - the - art baseline that is trained without supervision.   The main contributions of this paper are as follows :   1. The authors develop and train a new transition model, the Object - based Transition Model ( O - TTS ). This model is different from the previous transition models in two ways : 1. It decomposes the scene space into objects ( instead of pixels as done in previous methods ), and 2. It uses object - wise alignment to predict how objects will look like when viewed from a fixed point in time. The key property of this approach is that it is able to handle the problem of object persistence better than previous methods, as objects persisting in the same place in time are predicted from the same position in time using the same object representations ( but not from the fixed points in time ) with better accuracy. 2. The alignment module is important for the smoothness of the predictions over time as it helps the model cope with the uncertainty of object representations over different frames ( which may vary between frames and objects ). The experiments show that this approach works better than the previous approaches to handling object identity and object persistence."
SP:f32eddbb5c33a8422c075579ff08aa9833338d44,"This paper presents a generalization algorithm for ERM with model - agnostic guarantees for regression and policy learning. The algorithm is generic and based on importance - weighted weighted ERM, which is designed to work with adaptively collected data to minimize the average of a loss function over a hypothesis class over which the algorithm is trained. The paper proposes a new maximal inequality that carefully leverages the importance sampling structure to obtain rates with the good dependence on the exploration rate in the data. For regression, the paper provides fast rates that leverage the strong convexity of squared - error loss for regression. For policy learning, it provides regret guarantees that close an open gap in the existing literature whenever the case for bandit - collelected data is encountered.   The main contribution of this paper is to propose and develop a generic importance sampling weighted algorithm for the generalization of ERM. The main contributions are as follows :    1. The authors propose an algorithm that extends the generic importance weighting algorithm used in the prior work ( Wang et al., 2021 ) to the case when the data is not available ( adaptive data is used ). The new algorithm is designed for the case where the data does not come from a dataset that is unavailable for training ( e.g., when the training data comes from a policy distribution that does not have access to the dataset ). This allows the authors to obtain generalization guarantees that generalize beyond those of the previous algorithm with modelagnostic guarantees and fast convergence rates that are typically only used for fast convergence. 2. The method is evaluated on the problem of off - policy policy learning where the goal is to learn a classification classifier from data that does n’t appear in the training set, and applied to regression when the target class is known. 3. The experiments are conducted to validate that the proposed algorithm generalizes better than the one used for policy learning and to demonstrate that the obtained generalization generalization has faster convergence rates."
SP:f549a0c231b71bae0acbed6e3afb41890ee89cd9,This paper proposes reparametrizing the sample weights of kernel - reweighted regression by using a doubly non - negative matrix to approximate the log - determinant divergence ( KD ) and Bures - Wasserstein distance when the uncertainty set is set using either the log divergence or the BWS distance. The motivation is that the predictive power of the weighted regression model deteriorates under low sample sizes or under covariate perturbations of the regression model. The paper proposes reweighting the training samples of the model as an effective mitigation strategy to these problems. The authors develop a novel and coherent scheme for rew averaging the samples in training the model. They show that the adversarially reweighed estimate can be solved efficiently using first - order methods. Numerical experiments show that our rewe averaging strategy delivers promising results on several datasets.
SP:fe12e13602925b9400fd596a987755beb10aa3d1,"This paper extends the gradient estimator from Dong et al. ( 2020 ) to the categorical setting by introducing a new estimator based on reparameterization of categorical variables. This is in contrast to the previous work that only considers binary random variables and thus relies on the relaxation of a continuous distribution. The authors argue that a continuous relaxation of the continuous distribution is needed as it is not always available or tractable. The proposed estimator is motivated by the construction of a stick - breaking coupling that allows it to capture categorical distributions that are not constrained to be binary. The main contributions of the paper are the following :   1. Motivated by the fact that binary relaxations are limited to discrete binary variables, the authors propose a performant estimator that does not rely on continuous relaxations and is based on importance sampling and statistical couplings. 2. They introduce gradient estimators that estimate the gradient of the mean and standard deviation of a set of $ \mathbb{R}$ variables $ \tilde{O}$ for categorical $ \rho$-\alpha$-contraction and $ \nabla_{\textrm{O } \log p}$. The authors show that their estimators provide state - of - the - art performance in terms of the ratio of expected return to expected return with respect to the number of log - likelihood of the variables. 3. They also show that the proposed estimators are better than the previous estimators when applied to a categorical distribution where the average of the parametrizations is higher than $ \theta$."
SP:e16fdf963ec2f9c0d79fa404e47e7862a5d6e922,"This paper proposes a new predictor - based architecture search method, dubbed WeakNAS, to solve the problem of finding the best NAS architectures. WeakNAS is based on the observation that the better a weak predictor of the architecture performance for a set of weaker predictors is, the better the sampled better architectures become, as the stronger the predictor becomes, the more accurate it is to find the best possible NAS architecture. To alleviate the computational cost of training such a strong predictor, the paper proposes progressively fitting a search path towards the high - performance sub - space through a set ( a ) weaker predictor and ( b ) stronger ( yet equally as strong ) predictor. The weaker predictor is trained to find better architectures as the probability of sampling better architectures increases with increasing number of weak predictors ( Figure 5 ). Experiments demonstrate that WeakNAS uses fewer samples to find top - performance architectures on NAS- Bench-101 and NAS-Bench-201, and achieves better performance than the state - of - the - art predictors - based NAS methods.   WeakNAS outperforms all the other predictors by notable margins, e.g. requiring at least 7.5x less samples ; it can also absorb ideas from the other methods to boost performance more. The paper presents a paradigm shift from fitting the whole architecture space using one strong predictor to progressively fitting search paths towards the search paths of the predictors in a gradient descent direction. The main contribution of this paper is the introduction of a framework that produces coarse - to - fine iterations to gradually refine the ranking of the predictor and the parameters of the different sub - spaces to progressively refine the search. The method is easy to use and produces results that are competitive with the best known architectures in terms of performance. The approach is robustness, robustness to perturbations in the search space, and ablation studies that compare the performance of the proposed method to other approaches are provided."
SP:8f74abb04037ba2e59dcf8320dc555b149f68ed8,"The paper proposes a new coordinate system based on Deep Entropic Desired Dynamics for Intrinsic ConTrol ( EDDICT ). It is based on the idea that the best way for an agent to learn is to maximize the effective number of states it can reliably reach, i.e. the number of latent codes that can be discriminated from future states under some short time horizon. The paper presents a simple instantiation of this idea, which assumes a fixed additive latent dynamics and uses it to learn latent codes in a globally consistent coordinate system. This allows the agent to reach more states in the long term while still optimizing a local objective.   The paper shows that the resulting system is globally consistent, which allows for improved state coverage and increased unsupervised performance on hard exploration games such as Mujoco. The main contributions of the paper are as follows :    1. A new global coordinate system for learning latent codes from the environment is proposed, which replaces the original coordinate system with a more globally consistent one. This results in a more interpretable latent code space that allows for better learning in tractable ways. 2. The method is compared to previous coordinate systems based on latent dynamics ( DDP - SGD ) and based on learned latent codes ( PD - CGD ), and it is shown that EDD1 can learn more latent codes and is more exploratory. 3. A set of experiments is presented that compare the performance of the proposed method with other methods based on state - based coordinate systems, showing that it is better both in terms of state coverage ( in terms ) and exploration performance ( measured using MSE."
SP:c731a78c3e7f98ccd0253b51a0d42bf8deeb71f9,"This paper proposes a novel RL framework, FREED, to generate pharmacochemically acceptable molecules with large docking scores. The docking score optimization is a difficult problem that involves many local optima and less smooth surfaces with respect to molecular structure. To tackle these challenges, the authors propose a novel fragment - based generative RL framework that produces molecules of higher quality compared to existing methods while achieving state - of - the - art performance on two of three targets in terms of the docking scores of the generated molecules. The authors also show with ablation studies that their method, predictive error - PER (FREED(PE)), significantly improves the model performance.    The authors first describe the problem of generating molecules with desired properties from a molecular docking model. The molecular docking program is a physical simulation that estimates protein - small molecule binding affinity ( PFI ), which is a straightforward proxy of the therapeutic potential of a given drug. While molecular docking programs have been shown to generate biologically plausible molecules with high PFI, docking scores are computationally expensive and involve a tradeoff between computational efficiency and PFI affinity. Given the high cost of computing PFI and the high computational cost of running the docking program in RL ( Table 1, Figure 2, Figure 3, Table 4, Figure 5, Table 6, Table 7, Table 8, Table 9, Table 10, Table 11, Table 12, Table 13, Table 15, Table 16, Table 17, Table 19, Table 20, Table 21, Table 22, Table 23, Table 28, Table 29, Table 30, Table 27, Table"
SP:b938bca513e7de1231212064caf8877a78d8b612,"This paper studies the problem of learning directed acyclic graphical models from observational data in general settings without specific distributional assumptions. The approach is information - theoretic and uses a local Markov boundary search procedure in order to recursively construct ancestral sets in the underlying graphical model. This is then applied to learn the entire graph under a novel identifiability condition that generalizes existing conditions from the literature. The authors show that for certain graph ensembles, a simple forward greedy search algorithm ( i.e. without a backward pruning phase ) suffices to learn Markov boundaries of each node. This substantially improves the sample complexity, which they show is at most polynomial in the number of nodes.   The authors further illustrate the performance of the algorithm, which is easy to implement, in a simulation study. This approach is general and works for discrete or continuous distributions without distributional assumption, and as such sheds light on the minimal assumptions required to learn graph structure efficiently. In the appendix, the authors apply their results to the special case of special - case of polytrees with finite - sample guarantees for the problem."
SP:af08109d4c45dc9401efb0e63c22167e9da28adb,"This paper studies differential privacy ( DP ) with global stability, where each user has a single sample and the privacy protection is enforced at the level of each user ’s data. The authors show that, as long as each user receives sufficiently many samples, we can learn any privately learnable class via an (, )DP algorithm using only O(log(1 / ) /"") users. For example, in the local model, where d is the probabilistic representation dimension, they show that   ( 1 ) can be learned with only O ( d ) users even in the global setting. In both cases, the authors show a nearly - matching lower bound on the number of users required. A crucial component of the results is a generalization of global stability [ BLM20 ] that allows the use of public randomness. Under this relaxed notion,   the authors employ a correlated sampling strategy to show that the global stability can be boosted to be arbitrarily close to one, at a polynomial expense in the   number of samples required.    The main contributions of this paper are the following :   1. This paper studies the problem of differential privacy with DP, in which each user holds m samples. In particular, it considers the setting where : 1. A user chooses a class distribution ( e.g., [ s, a ] ) for which it wishes to learn a private label. 2. A private label is chosen based on a mapping from the class distribution to the label space. 3. The class is learned using a standard MLP learning policy, such that the private label belongs to the class that is being learned from. 4. The learning policy does n’t require the user to disclose the class they are learning from. 5. This is the main contribution of the paper."
SP:da4f21d107a7f442c4d3e3ec13bdb44b041e07cf,"This paper studies the implicit implicit representation of value functions via theory and focused experimentation. The implicit representation is used to learn transition and reward models of a latent Markov decision process whose value predictions fit the data. The authors prove that gradient descent converges to global optima under conditions under which the implicit representation ( SGD - SGD ) with this implicit representation converges substantially faster than its explicit counterpart. In addition, they derive convergence rates for both linear parametrizations of the value function under the assumptions of implicit representation and gradient descent. Finally, they provide empirical results in some simple domains that illustrate the theoretical findings.   The main contributions of this paper are as follows :   - Theoretically, the authors prove the convergence of gradient descent under SGD under the assumption that the transition model and reward model are implicit representations of the Markov Decision Process ( MDP ). This assumption holds even under assumptions of non - convexity of the MDP ( e.g., gradient descent does not need to be smooth for the transitions to converge ). - In two cases, the implicit representations are used to train two value functions, one over the linear MDP and another over the Cartesian Product Model. Theoretical convergence rates are derived for both MDPs in the experiments and the authors compare the convergence rates of the two implicit representations. - Theorem 1 shows that the gradient descent of a value function trained via SGD converges faster than that of a MDP trained via gradient descent without SGD ( faster than the one trained via DGD )."
SP:992aa07d4f815d1c81f967374590eece933833b1,"This paper proposes a method to refine Graph Graphs ( KGs ) extracted from text sources with respect to noise reduction through KG refinement. Graphs extracted from KGs are noisy and lead to poor performance in downstream application tasks such as KG - based question answering. Recent work addresses the sparsity of KGs by using embeddings for inferring new facts. This paper proposes to combine two techniques : one that uses ontological information and inferences rules, the other that uses inference rules and reasoning over ontologies. Theoretically, this paper shows that the latter method, IterefinE, is able to exploit the power of the former to perform longer chains of reasoning and reject noisy facts from KG while inferring higher quality new facts at the same time. Experiments on a range of KG benchmarks show that the embeddeddings that the authors produce are able to outperform PSL - KGI and other noise - free baselines.    The main contributions of this paper are the following : 1. The authors propose to combine the two techniques – one which uses ensembles to refine KGs and the other which uses inferences and rules, viz. PSL-KGI, to refine the knowledge graph ( KG ). 2. They show that using the latter leads to superior performance compared to the former in terms of F1 score on several KG question answering tasks. 3. They also propose a new type of embedding, called TypeE - X, to be used in conjunction with refined KGs."
SP:676fc4a3041af22e8f20ccba7daa2a0b1f5d6af5,"This paper proposes a new evaluation paradigm for estimating the likelihood of candidate facts from a knowledge base ( KB ) to distinguish between true facts and false ones. The authors argue that binary predictions are essential to reflect the actual KBC quality, and propose a novel evaluation paradigm, where models do not actually decide whether a new fact should be accepted or not, but are instead judged on the position of true facts in a likelihood ranking with other candidates. The proposed paradigm is based on the following : 1 ) to construct the data set FB14k - QAQ with an alternative evaluation data structure : instead of single facts, the authors use KB queries, i.e. facts where one entity is replaced with a variable, and construct corresponding sets of entities that are correct answers. 2 ) to randomly remove some of these correct answers from the correct answer set, simulating the realistic scenario of real - world entities missing from a KB ( where one person or entity is missing from the KB but the others are included in the dataset ), and provide more transparent model selection criteria for a realistic scenario. 3 ) to obtain models that have more correct answers in the real world than in the KB and can handle queries that have fewer correct answers but are difficult to classify.   The authors experimentally evaluate a number of state - of - the - art KB embedding models on their new benchmark. They observe that there are clear differences in relative performance between ranking - based and classification - based evaluation, and that good performance on ranking task does not necessarily translate to good performance in the actual completion task. The results motivate future work on KB embeddings models with better prediction separability and, as a first step, propose a simple variant of TransE that encourages thresholding and achieves a significant improvement in classification F1 score relative to the original TransE."
SP:83fe0a496a79bcf97ccba1c6d34b7d11e7d5c330,"This paper proposes a new approach to training pre - trained language models for dialog response generation in dialog management tasks. The approach is based on the Alternating Roles Dialog Model ( ARDM ), which is similar to the BERT and GPT - 2 language model pretrained language models. The difference is that ARDM trains the language model separately for each speaker and uses it to generate human - like responses to persuade people to donate to a charity. The paper compares ARDM to state - of - the - art methods on two popular task - oriented datasets : CamRest and MultiWOZ. ARDM outperforms SOTAP and is on par with SOTAR on tasks such as CIFAR-10 and A2C on the popular CamRest dataset. On the multi - wand datasets, ARDM performs about the same as SOTA and slightly worse than ADAM. However, on tasks where the dialog is difficult to generate or the task - to - task ratio is low ( e.g., convincing people to give to charity ), the approach outperforms ADAM by a large margin.   The main contributions of this paper are as follows :   1. The authors propose a new language model for dialog generation, which they call ARDM. The model is trained separately for speaker and listener. 2. They use the same $ \mathcal{L}$ parametrization for the speaker model and listener model in each task. 3. They compare the performance of ARDM and ADAM on the two popular tasks. 4. They provide no human supervision of the model and the resulting in significantly lower error rates for ADAM and SOTAM."
SP:b11c06b7c4ef1aa43c59f808a679425e302d158e,"This paper proposes a confidence measure for the confidence that a classifier predicted by a deep neural network is in the top 5 classes ( or in the Top k ) on the test set. It is well - known that the softmax values of the network are not estimates of the probabilities of class labels but estimations of the class labels. There is a misconception that these values are not informative. This paper proposes to use the notion of implied loss to define the uncertainty measure and prove that if an uncertainty measure is an implied loss, then low uncertainty means high probability of correct ( or top k ) classification. The paper is simple to use on existing networks : it proposed confidence measures for Top k which can be evaluated by binning values on the tests set. The experiments are conducted on CIFAR-10 and ImageNet networks.   The main contributions of this paper are the following :   1. A new method for computing the confidence measure of classifiers predicted by deep neural networks based on the implied loss. This is done by defining implied loss and proving that low uncertainty in the network predictions corresponds to a high class probability of the correct class. 2. A set of assumptions that underlines that the class probabilities are likely to be close to the true class probabilities. 3. A loss function that defines the uncertainty of the neural network predictions. 4. A confidence measure that measures the ratio of the confidence of class probabilities with respect to the expected class probabilities of the predicted class probabilities ( which is a weighted sum of all class probabilities over all possible class distributions over the entire set of classes."
SP:ab9666e15f2a0113d96cb4b47b1cbb30fa1f7982,"This paper studies generalization and trainability of neural networks as a function of their architecture and hyperparameters. In particular, the authors consider the case when training neural networks with deep neural networks ( DNNs ) where the network architecture is considered to be Gaussian processes governed by a kernel called Neural Network Gaussian Process ( NGP ). Recent results have shown that at large depths the spectrum of the NNGP kernel simplifies considerably and becomes “ weakly data - dependent ”, and that gradient descent training of wide neural networks is described by a Kernel called Neural Tangent Kernel ( NTK ) that is related to the NTGP kernel. The authors show that in the limit where the kernel is $ \epsilon$ large, training with NTK simplifies in much the same way as that of training with a kernel based on Gaussian process $ \theta$. Based on these theoretical results and a careful empirical investigation on real datasets ( e.g., CNNs with average pooling and FCNs without ), they show that CNNs have very nearly identical learning dynamics to FCNs while CNNs   with pooling contain a correction that alters its generalization performance.   The authors then perform a thorough empirical investigation and find that networks can only memorize the training set in the sense they reach perfect training accuracy but completely fail to generalize outside the training data set, in contrast with several recent results. They then show that networks with average pooled gradient descent learning can generalize better than networks without average pooled descent learning. Finally, they provide a precise characterization of the characterization of trainability and a necessary condition for generalization across a range of architectures including Fully Connected Networks ( FCNs ) and Convolutional Neural Networks ( CNNs ). The empirical results are verified and verified with experiments on both synthetic and real datasets."
SP:d3470c35aae48bf92439a55fdb98ccf07100e567,"This paper presents a graph - based method, GRAPHQA, to estimate the quality of the predicted protein structures from a hand - engine and representation learning approach to identify protein structures. The authors propose GraphGraphQA ( GQA ), which is a graph based method based representation learning method that leverages the power of graph neural networks ( GraphNet and GraphSAGE, respectively ) to learn the representation of graphs and uses GPs to model the sequential and 3D protein folds. The method is evaluated on the task of estimating the predicted structures from hand - Engineered and Representable Protein Structures ( RSP ) models. Compared to the state - of - the - art methods, this paper shows significant improvements in the estimated protein structures for hand -engineered and representation - learning approaches as well as the graph based approach. The main contributions of the paper are summarized below.   - GraphGraphNet : Graph - based Representation Learning - Graph - Based Graph Modeling - Graphs - Protein Structure Estimation - GraphQA : Theorem 1. Theorem states that the probability of obtaining a valid representation of the sequential fold of a protein protein is proportional to its predicted 3D structure, and that probability is independent of the number of folds and folds of the protein matrices used for computing the predicted matrices. - Theorem 2. Representation learning - Graph Representation of Protein Matrices - Graph Based Modeling of Structure - GPs - Protein folding - Graph Q - Q - A - Structure - Representation - GQ - Protein Identification - Graph"
SP:5188280131b58a35d3deda126a0754aea8fa6e58,"This paper revisits and extends the loss function analysis of linear neural networks with determinantal networks. The authors make the distinction between pure critical points ( which depend only on the functional space ) and spurious critical points, which arise from the parameterization of the critical space. The definition of critical points in neural networks is based on the following :   1. Pure critical points : any critical value that arises from the network ’s weights.    2. Spurious critical points arising from the parametrized critical points that arise due to the fact that the critical value obtained from these points depends on the weights. 3. Distilled critical points from points that are not connected to any of these points by any of the parameters in the network. 4. Spurred critical points arise when the weights of the network are not distributed evenly over all critical points but are connected to points only if one of them is located in the spurious critical point ( as in the case of pure critical point 1 ). The paper derives new results on the landscape of loss analysis for linear networks with different loss functions and different parameterizations. The main results relate the absence of “ bad local minima ” ( absence of convex losses ) in the loss landscape of linear networks of DAG with DAGs of different architectures to the loss of linear nets with a DAG of fixed rank ( bounded rank ). This is contrasted with the case when the network architecture is DAGS with fixed rank, where there is no assumption on the architecture. The new results show that without any assumption of the architecture assumption, convex loss may lead to landscapes with many bad minima. The results also show that DAGL may have higher rates of criticality than when there is an assumption of bounded rank. In addition, the authors derive new results for networks with and without fixed rank."
SP:ee71597ceab23eb4db1d6608f15f80ad51f7ff6d,"This paper proposes SEED ( Sampling, Encoding, and Embedding Distributions for Graph Representation Learning ), a general framework for unsupervised and inductive graph representation learning on graph structured objects. Given an input graph, the SEED framework samples a number of subgraphs whose reconstruction errors could be efficiently evaluated using graph similarity evaluation, and encodes the subgraph samples into a collection of sub graph vectors, and employs the embedding of the sub graph vector distribution as the output vector representation for the input graph.   The main contributions of this paper are the following :   1. The introduction of SEED, a learning framework that extends the sampler - encoding - embedding - sampling ( SAM ) framework from graph embeddings to representation learning for graph learning on structured objects ; 2. The use of embedding to represent subgraph vectors in SEED is a novel and interesting idea ; 3. The SEED method is evaluated empirically using two datasets ( GraphSAGE and GraphLIPSE ), and the results show that SEED achieves up to 10 % improvement in representation learning with respect to both competitive baseline methods and the baselines, while the SAM - encoder - only achieves about 5 % improvement compared with the baseline methods."
SP:d9406fdf0a180a5efc6f15ba8739524665f0f9d2,"This paper proposes Lazy - CFR, a new algorithm for solving minimization games in zero - sum minimization with imperfect information. The objective is to reduce the update time of the vanilla CFR algorithm, which updates the whole game tree in each round, which is time - consuming in large - scale games. To this end, the authors propose an algorithm that updates the game tree only once per round and use a lazy update strategy to do so. The proposed algorithm is called Lazy-CFR and it is different from the vanilla CFR in the sense that it only updates the tree a few times in a round instead of the whole tree every round as in the case of vanilla CFR. The main idea of the algorithm is that it uses a counterfactual regret mechanism similar to the one used in vanilla CFR to estimate the regret of the current state of the game after visiting only a small portion of the nodes in the tree. The authors show that this is a good idea as it reduces the updating time of CFR, which can be very time consuming in games with a large number of nodes. They then show that the new algorithm is provably faster in terms of updating the regret than the one based on the previous update strategy, CFR, by using a technique called “ lazy updating ” where the updated game tree is only updated after visiting a few nodes of the original game tree rather than the full game tree ( as is the case with CFR ). They also show empirical results that support their claim that this method is fast in practice.    The main contributions of the paper are the following :   ( 1 ) - The authors propose a new CFRR algorithm based on counterfactorical regret minimization ( CFRM ), which uses the same approach as vanilla CFR but does so in a much smaller number of visits ( instead of traversing the entire game tree as in CFR ) - ( 2 ) They show empirically that this leads to a significant reduction in the average regret of CFRMs over the course of a round, and in fact leads to almost the same regret as the one achieved by updating the entire tree in the first round using the updated CFR. This is verified using a series of experiments ( e.g., the one where the algorithm was used to solve the original CFR problem and one where it used the lazy update method to update the game trees in a single round ) - and again using the empirical results from vanilla CFR they show that their method is significantly faster than the vanilla one even though they use the same update strategy."
SP:023aa3dca1cf7992b22993a7088e8a74c92bb47e,"This paper proposes Distributed Matching Prototypical Network ( DMPN ), a novel feature distribution model for Unsupervised Domain Adaptation ( UDA ) based on Gaussian mixture distributions, to learn transferable features from source and target unlabeled features by minimizing the feature distribution discrepancy between them. The authors propose two new domain discrepancy losses with probabilistic interpretations, the first one minimizes the distances between corresponding Gaussian component means of the source features, and the second minimizes pseudo negative log likelihood of generating the target features from the source feature distribution.   The hyper - parameter sensitivity analysis shows that the approach is robust w.r.t hyper -parameter changes. Extensive experiments are conducted over two UDA tasks. The approach yields a large margin in the Digits Image transfer task over state - of - the - art approaches. More remarkably, the approach obtains a mean accuracy of 81.4% on VisDA ( compared to 81.3% on the previous approach, UDA+ES ). This approach is more robust than the previous approaches to learning both discriminative features and feature distribution distributions."
SP:40be996e8bb86e887077b762b87c7c34a786ac98,"This paper proposes InfoCNF, a new conditional generative model for conditional image generation using normalizing normalizing flows ( CNFs ). The main idea is to use deep generative models for a wide range of tasks thanks to their invertibility and exact likelihood estimation. The problem is that conditioning CNF on the latent codes generated by the deep models is inefficient due to the highdimensional latent code generated from the model, which needs to be of the same size as the input data in order to represent the signals of interest. The paper proposes to partition the latent space into a class - specific supervised code and an unsupervised code that are shared among all classes for efficient use of labeled information. Since the partitioning strategy ( slightly ) increases the number of function evaluations ( NFEs ), InfoC NF also employs gating networks to learn the error tolerances of its ordinary differential equation (ODE ) solvers for better speed and performance. The experimental results show that the new method leads to comparable test accuracy over the baseline while yielding comparable likelihood scores and reducing reducing the N FEs on CIFAR10 on time - series data. The major contributions of the paper are the following : 1. A new class of supervised codes is introduced that is partitioned among classes of latent codes to represent signal of interest for image generation ( e.g., signals that arise in the case when the latent code generation task is conditioned on them ) ; 2. A gating network is introduced to learn error tolerance of the output of the differential equation to learn information about the error of the error tolerance of the distribution that would be used to generate the error estimate for the output class of the discriminator ; and 3. Using the same partitioning technique ( slightly ) for the supervised codes ( but slightly different in the class of unlabeled ones ) in InfoCNP as in InfoDPG ( see Note 1 ), the authors show that it leads to better performance on time series data and reduces the need for NFE evaluations."
SP:97764e3393216106ff2ac3f550845acf4636119f,"This paper studies nonlinear neural networks trained with the Temporal - difference ( TD ) learning algorithm and the Markov Reward Processes ( MRP ) with nonlinear functions trained with TD. It shows that under certain scaling of the approximating function leading to a regime called lazy training, the parameters of the model vary only slightly during the learning process, and studies the convergence of MRP and TD with local and global minimizers of the minimizer of the above algorithm in the lazy training regime. The convergence results are obtained for both the under and over - parametrized case settings, where the scaling is naturally induced implicit in the initialization of their parameters. The paper also gives examples of convergence results in the case of models that diverge if trained with non - lazy TD learning, and shows that the convergence does not hold even when the value function is polynomial in the number of parameters."
SP:c518e4030f12b0f59ad1d7c0fc0ebd313c68ef95,"This paper proposes a method to train a hypothesis verification agent that can generate observations that can help determine whether a hypothesis about the dynamics of the world is true or false. The main idea is to train the agent to generate hypotheses that can be verified end - to - end using a reinforcement learning problem. The agent is trained to formulate the hypotheses as triplets ( pre - condition, action sequence, post - condition ) and to act on the generated hypotheses in a pre - conditioned way ( before - action, during - action and after - action condition ). The paper shows that this approach works better than other hypothesis verification approaches that use reward - conditioned hypothesis verification ( e.g., TD3 ) and reward - dependent agent ( TD4 ). It also shows that using the triplets approach, the agent can be trained to generate more general hypotheses such as generalizable hypotheses.    The main contribution of this paper is to formulate hypothesis verification as a problem that is well - addressed by reinforcement learning, where the agent is given a hypothesis and given a set of actions ( i.e., conditions, actions and observations ), can take actions to generate observations which can help predict whether the hypothesis is true / false. This approach is contrasted with prior work ( Yao et al., 2020 ) that uses reward - conditional hypothesis verification using a reward function ( pretraining, reward reward function + action - sequence ) to train agents in an end - conditional learning way. The experiments show that the proposed approach sometimes outperforms TD3 and TD4 approaches in terms of test accuracy."
SP:6fa2f842b1bc993ed8024a3ce13dbd91529c61be,"This paper presents a simple experiment to test whether neural networks can perform approximate reasoning in a fixed dimensional latent space using a set of rewrites ( i.e. transformations ) that can be successfully performed on a statement. The paper first considers a formula that represents essential semantic features of the statement, and trains a neural network to predict the embedding of this formula in a vector space, such that the vector associated with a formula can be used to predict whether a statement can be rewritten by other theorems. To measure the effectiveness of this embedding prediction, the paper performs sequences of rewrite steps both in formula space and in latent space, and compares the quality of embeddings of the resulting formulas to their predicted embedding from the authors. The experiments show that the neural network can make non - trivial predictions about the predictions of the authors about the rewrite - success of statements. The authors also conduct experiments to see if the predictions are accurate even when they propagate predicted latent representations for several steps. The main contributions of the paper are as follows.   1 ) The paper proposes a formula prediction algorithm that predicts the embedde of a formula generated by some rewrite rule from the perspective of approximate reasoning. This is done by embedding the formula in the latent space of the corresponding theorem, and the authors use the following steps to do so : 1 ) In the first step, the authors predict a latent embedding for the formula by the following formula formulation :    * Theorem $ \mathbb{R}$ : $ \theorems \theta = \sum_{\theta } \mapsto_i}$ + \mu_{\text{actual_t } \cdot \mu } \rightarrow \text{t}$ where $ \eta_t \mu$ is a set $ \hat{T}$, and $ \mu \eta$ is the vector \eta of the rewinding rule \hat_{t}$. The authors predict that $ \tau_t$ corresponds to the set \mu rewording rule \mu_t$. The second step is a sequence of several steps where the first three steps are similar : 1. Theorem 1 : Theorem 2 : Rejective embedding $ x_{t } = \eta_{t\mid s}$ is similar to $ \frac{\text{T } \log t}$ except that $ x_t\mu_{t \infty } \to \eta"
SP:a77ab500a5e7d4ea8430871d1e603941e92974fd,"This paper proposes a method for learning depth estimation from images with very sparse ground truth ( just a few pixels per image ) using a global - local network architecture. The method is motivated by the idea that natural agents ( e.g., non - projective agents ) who interact with the environment via visual and haptic feedback are unlikely to have the precise equations of projective geometry hard - wired in the brain. To train the model with such sparse supervision, the authors propose to bias towards learning monocular dense depth estimation by designing a specialized global network architecture, called Global Local Network Architecture ( GNN ).   The proposed model is validated on several synthetic datasets ( CIFAR10, CelebA3, Celeb8, Celeb9, Celeb12, Celeb13, Celeb18 ) and evaluated with ground truth, ground measurements, and a localization bias ( global parameters extracted by the network ). The experiments show that the proposed model outperforms the state - of - the - art deep learning methods ( including methods based on multi - view geometry ) in terms of generalization and accuracy. The main contributions of the paper are the following :    ( 1 ) A deep network architecture is proposed to learn monocular depth estimation when trained with sparse groundtruth and ground measurements ; ( 2 ) An inductive bias is introduced to bias the global network to perform better than other Deep Learning methods when training the model on ground truth and measurements obtained from the network ; ( 3 ) Global parameters are optimized to ensure that the learned depth estimates are monocular and the global parameters of the network are global."
SP:2afba5e24478da4e9d493887c7cf00e288cc0deb,"This paper proposes to use Transformer - based models for solving ML problems with large vocabulary size. The authors extend the idea of word pieces in natural language models to machine learning tasks on opaque ids. The key observation is that it is important to use a multi - layer Transformer for Bloom filter digests to remove ambiguity in the hashed input. They show that by applying a Transformer to these Bloom filter models, they are able to obtain models with high accuracy that outperform models of a similar size without hashing and a much larger size trained using sampled softmax with the same computational budget. They believe this provides an alternative method to solving problems with    large vocabulary   size.   The main contribution of this paper is to suggest using Transformer as a model backbone for constructing probabilistic models of the input to be used in conjunction with Bloom filters to solve ML problems. The use of Transformer augments the original idea of using a word component per input to construct a model that can be used for solving tasks with large   vocabulary size, as opposed to using a single word component for each input ( as is done in Bloom filters ). This is demonstrated by comparing the performance of the proposed method with a set of Bloom filters that use a much smaller set of hash functions, corresponding to each input token in a smaller space, and by comparing their performance with the output of a Bloom filter that uses hash functions mapping each input to multiple hash tokens in a space much larger than the one used in the original problem. The results show that the proposed approach, when applied to Bloom filters, leads to better performance than the approaches that use hash functions."
SP:745dd86d7f7bba79a02d27922003b764b620f83e,"This paper proposes a learning - based agglomerative clustering framework for learning 3D parts from data - driven shape segmentation approaches. The core idea of the framework is to group small part proposals into bigger ones in a "" bottom - up "" fashion. This is motivated by the fact that in many real - world applications of 3D segmentation, the objects that are predicted from the geometry prior of parts are assumed to be present in unseen categories. The framework considers this problem as a contextual bandit problem and learns a grouping policy to progressively group small parts proposals into larger ones. The key idea is to restrict the local context for extracting part - level features, which encourages the generalizability to unseen categories to the extent possible. The proposed framework is applied to PartNet, a dataset of trained 3D part representations that is used to transfer knowledge of parts learned from 3 training categories to 21 unseen testing categories without seeing any annotated samples. The main contributions of the proposed framework are as follows :    1. The clustering policy is learned progressively by iteratively splitting a part proposal into two subpart proposals. Each subpart proposal is split into two subsets, one of which is the original part and one which is a modified part. The first subpart is then used to generate a larger part for the larger part proposal. The second part is used for testing.   2. The learning policy is applied progressively by expanding the original small part proposal each time it is split. This process repeats until it reaches a target subpart. The goal is to maximize the ratio of the number of subpart in each subpart for testing the original target part ( as a ratio of samples from the original and the modified part from the smaller part )   3. The network is trained to aggregate knowledge of the geometry of the subpart from all training parts to a subset of training parts, and to transfer this knowledge to the larger subpart via a weighted summing procedure. The method is applied in two stages : during the first stage ( training ) and during the second stage ( testing ). During the second phase ( testing the large part ), the small subpart can be transferred to a smaller part in one step of the learning process. The larger part can then be transferred directly to the bigger part in the next stage. The overall learning procedure ( during the"
SP:868fc6df740b04963442d5abcfe2f4845585cfc8,"This paper proposes a technique called neuron editing to train deep generative neural networks ( GNNs ) to generate data that is different from the one that they are trained on ( e.g., a GAN trained on images of blond - haired men would need to change features such as hair color from images of black -haired women to fool a discriminator ). To train such networks, they need to have a trained set of target and source datasets, which is problematic as it can be possible to obtain a pair of ( source, target ) distributions but then have a second source distribution where the target distribution is unknown. To overcome this issue, the paper proposes to split the source and target datasets into a latent space, where the source data can be generated from within the manifold of the data that the trained model is good at generating within the dataset, and the target data generated from outside the manifold can be extrapolated to the target dataset. To do this, the authors propose to define an editing transformation on the neurons that produces the transformed data by performing the transformation in the latent space. The method, dubbed neuron editing, can handle both linear transformations and non - linear transformations to the data with much simpler distribution shifts to the neuron ’s activations. The authors demonstrate the method on image transformations and then move to two main applications in biology : removing of batch artifacts representing unwanted noise and modeling the effect of drug treatments to predict synergy between drugs. The experiments demonstrate the effectiveness of neuron editing both in image and drug treatment data settings."
SP:6dee6932e64fe47bb44dd42fc242fa9d89b8d89c,"This paper proposes a meta - learning framework to address the problem of learning from few - shot to many - shot datasets using deep neural network representations. The main contribution of this paper is to develop and study a method for first - order meta learning of initializations for deep neural networks that must produce dense, structured predictions given an arbitrary amount of training data for a new task. The method is called EfficientMetaLearning ( E - MAML ) and it consists of ( 1 ) an extension and experimental analysis of a model agnostic meta learning algorithm, ( 2 ) a novel neural network architecture built for parameter efficiency and learning which the authors call EfficientLab, ( 3 ) a benchmark dataset ( FSS - 1000 ), ( 4 ) a small benchmark dataset, FP - k and ( 5 ) experiments on real - world datasets to evaluate the performance of the proposed method. The authors provide both theoretical analysis and empirical studies of how the method performs in both the few - shots and many - shots settings. The theoretical analysis shows that with an empirically estimated optimal update procedure the proposed approach yields state - of - the - art results on the FSS-1000 dataset, while only requiring one forward pass through the single model at evaluation time. The empirical study shows that the meta - learnable initializations outperform random and ImageNet - trained initialisations for image segmentation on datasets with up to 400 labeled examples. Finally, the authors also empirically show that the single update routine used by meta - learner works best when adapting to new tasks, as it is not conditioned on the available data for each task."
SP:ec6f390f6d45fb79c33ae5d9c8a24cadb96fbd60,"This paper proposes Prototypical Random Walk Networks ( PRWN ), a graph - based approach for few - shot learning with unlabelled data for supervised prototypical networks. This approach is similar to the recently proposed Graph - based FSL for SS - FSL ( Ren et al., 2018 ), where the goal is to learn representations that are compact and well - separated.   The main difference between PRWN and the Graph - Based FSL is that PRWN trains a parametric network instead of a graph neural network ( PN ), which is used in the previous work. The PN learns representations from the ground - truth data that are independent of the class labels, and the authors propose to use this intuition to learn a "" prototypical "" classifier from the unlabeled examples. The authors show that this prototypical classifier is robust to class distribution mismatch, and outperforms the fully supervised PN trained on all the labels ( trained on 100 % of the labels ). They also show that the PRWN model is more robust to distractors and better able to handle challenging discriminative power tests ( 20 classes on mini - Imagenet and 800 classes on Omniglot ). PRWN is evaluated on 5 - shot classification tasks and compared with several recent methods, achieving better accuracy scores than the supervised methods. The main contributions are the following :   ( 1 ) A new classifier, based on a PN, that learns representations without requiring additional graph - parameters ( unlike Graph - BN ) without a classifier. ( 2 ) A more robust loss that allows the learned representations to be independent of class labels. ( 3 ) A well - designed classifier that can learn representations from all the class examples, without the need for additional graph parametrization. ( 4 ) A good balance between robustness and robustness ( neither of the above mentioned properties )    Finally, the authors conduct some ablation studies to validate their method and compare their method with other methods, and show that their method outperforms them in some cases, especially when the class distribution is very different from the supervised ones."
SP:d12e687bd2ee9fa60554312e644bb0a6487974f1,"This paper proposes Contrastive Sensor Fusion ( VSF ), a self - supervised training objective for machine learning on multi - sensor data for deep learning in the remote sensing domain, where labeled data is often scarce or expensive and unlabeled data is abundant. VSF is motivated by the fact that recent selfsupervised learning approaches are ill -suited to this domain, as they are applied to the machine learning of deep convolutional neural networks. Most remote sensing applications currently use only a small subset of the multi - channel information available, motivating the need for fused multi - sensory representations. To achieve this, VSF exploits coterminous data from multiple sources to learn useful representations of every possible combination of those sources, and trains a single model to produce representations that remain similar when any subset of its input channels is used. The training objective is to obtain representations that are meaningful from all the possible combinations of channels from the input sensors, while training the model to be able to improve as more sensors are fused. The method uses information common across multiple sensors and bands by training a representation that is similar when using a subset of input channels ( e.g., common but different for each band ), while keeping the training objective similar across all the sensors and channels. To this end, the authors propose a training objective that is independent of each other and train the model only on samples that are not significantly different from the ones used in the training of the input channels. The representations produced by the model are compared with representations obtained by training the input channel representations from a single channel - based model, and representations from multiple channels - based models are used to train the representation of the band. To ensure that the representations remain similar across multiple channels, the method trains a representation from each channel based model to learn a representation of every combination of channels.   The main contributions of this paper are the following : ( 1 ) A new objective that encourages learning representations that improve upon the features of input sensors that are common across all input channels that are learned from training a single input channel model. ( 2 ) A dataset of multi - sensing data that encourages the learning of representations that is meaningful when using all the inputs that are learnable. ( 3 ) An encoder that enforces semantically meaningful representations from all possible combinations ( semantically"
SP:4d8e054f07006b4f896721b5c24da805727d2c22,"This paper proposes a method for weight rewinding, which rewinds unpruned weights to their values from earlier in training and retrains them from there using the original training schedule. Frankle et al. ( 2019 ) proposed this method as a way to recover accuracy from fine - tuning, which trains weights from their final trained values using a small fixed learning rate. In this paper, the authors propose to use the same learning rate schedule as the one used in the original paper to train fine - tuners to train the weights. The authors compare the proposed method with two standard methods for fine - Tuning and weight re - winding, which can be thought of as being similar in spirit to the way of learning rate - based methods for re - training. The main difference between the methods is that the former trains the weights with a fixed number of parameters, while the latter trains them with a number that scales linearly with the size of the network. The experimental results show that the proposed approach re - winds the weights more quickly than the fine - tuned method. The paper also shows that the re - winding technique recovers the accuracy from the fine tuning method faster than the standard method."
SP:3bb1c79f9482e09828eda45fbb2e654f37219365,"This paper studies the all - layer margin ( margin between output and generalization ) in neural nets. The authors argue that the existing analyses of the output margin give complicated bounds which depend exponentially on the depth of the neural net. They propose to analyze a new notion of margin, which they call the “All - Layer Margin ”, and obtain tighter bounds for the generalization bounds of neural nets using this margin. They show that this margin has a clear and direct relationship with generalization for deep models. This enables the following concrete applications :   ( 1 ) by analyzing the all layer margin,   obtained tighter bounds of the net norm for neural nets which depend on Jacobian and hidden layer norms ( remove the exponential dependency on depth ). ( 2 ) their neural net results easily translate to the English language ( with the help of a theoretically inspired training algorithm ) for increasing the all _ layer _ margin. ( 3 ) their training algorithm improves both clean and adversarially robust test performance over strong baselines in practice.   The main contributions of this paper are as follows : 1 ) The authors propose a new margin term, “ All _ layer margin ”. This term replaces the previous margin terms ( normalized ) margin and ( prior ) margin ( prior - output margin ) and captures the relationship between generalization and generalizability, where a large output margin implies good generalization. 2 ) It provides a theoretical motivation for increasing margin by increasing the layer. 3 ) The experiments are conducted to demonstrate the effectiveness of their new margin."
SP:3d44f27468087280e85dfb1fc7291db05179fe6d,"This paper proposes a disentangled response generation model based on a generative model for generating response sequences for queries from a set of grounded dialogues. The authors consider a low - resource setting where only a small number of response generation examples per query can be generated from a large number of ungrounded dialogues and unstructured documents. Based on this assumption, the authors propose a decoder model that can learn the decoder function and the parameters that depend on the response from the entire generation model. The decoder can be seen as an encoder - decoder framework that encodes the query into a sequence of possible responses. Each response can be fitted to one of seven possible combinations of the seven possible responses by sampling from the encoder. These seven responses can be used to generate the query from the response generated from each response.    The authors evaluate the proposed decoder on two benchmarks, where the goal is to generate state - of - the - art response generation with only 1.5 - 2.5 ( out of 8 ) training examples. They consider a setting where the response generation process takes place in an autoencoder - only way : the agent is asked to generate a response to a question posed by a question mark. The question is posed using a ground - truth dialog from the generation model, and the response is the concatenation of the question and the answer. The method is referred to as a knowledge - grounded dialogue generation ( KGD ) model. Since the authors assume that only limited training examples are available ( 1 - 8 ), they propose a learning schedule that scales linearly with the number of training examples to maximize the learning schedule. This schedule can be extended to accommodate more training examples in later stages of the training ( up to a total of 20 training epochs ). They evaluate their decoder in two scenarios : the first scenario ( i.e., when training starts at 0 and ends at 30 ) and the second scenario ( when training reaches 80 % of the total training steps ). In the latter scenario, the model is trained to be able to generate approximately the same number of responses as in the original scenario ( 80 % ) with a minimum of additional training steps ( additional 20 % training steps are used for scaling and fine - tuning ). On the evaluation benchmarks ( Table 1, Table 2 ), it is shown that with 1 / 8 training examples and 1 - 80 training steps, the KGD model can achieve the state of the art in terms of response performance ( with a margin of 0.7 - 0.9 % out of 80 % training data ), while with 2 - 8 training steps it is slightly less ( 0.8 - 0.9 % ) above the performance threshold. However, on the second dataset ( Table 3 ) it is not quite as good ( after rolling out to all training steps at 80 % accuracy ), indicating that the learning curve is still not quite high enough to achieve the desired state. To further improve the performance, authors propose an additional step ( Figure 5 ) that augments the training schedule with additional steps that encourage the agent to generate more response sequences that are closer to the optimal set of responses when starting from a given query. This step, which is motivated by the observation that the average response length at 30 % is closer to 60 % ( 60 % for the first step and 60 %"
SP:9b555f7fe743f5effdbdc8701ed519ce3159c4b0,"This paper proposes a mirror - generative neural machine translation model ( MGNMT ) based on the Transformer - Neural Machine Translation Model ( TMT ) and the Language Model - Generator ( LM - Generator ). The main idea of the model is to combine the source - to - target translation model, the target to source translation model and the language model into a single model, which is then used for both training and decoding. The motivation is that since the source and target translation directions share the same latent semantic space, the translation directions can learn from non - parallel data more effectively. The authors also propose a joint language model and a decoding model which can be used for training the language models and the translation models to collaborate together during decoding. They test their model on a variety of language pairs and scenarios, including resource - rich ( low - resource ) and resource - poor ( high resource ) scenarios, and they show that their model outperforms existing models in most cases. They also propose an extension of their model to deal with language pairs that are not represented separately in the training data, called Mirror - Generative Language Model ( M - LMLM ). They evaluate their model in 5 different scenarios ( e.g., Kinship, Bilingualism, Tagalog, Creole, Semantic Graffiti ) and they compare their model with 2 other models ( LMT and LMT ) in terms of accuracy. They find that the proposed model performs better than the other 2 models and also outperforms the other models in some scenarios."
SP:d7a530a0ec4112095a58cef4cda9646f8ca6449d,"This paper studies the relationship between the entropy term and the performance of maximum entropy reinforcement learning algorithms. The main focus of the paper is to understand how the primary contribution of the maximum entropy term can be explained in terms of the bounded nature of the action spaces in the Mujoco benchmark. To this end, the paper proposes a simple non - uniform sampling method for selecting transitions from the replay buffer during training that can be used to improve the sample efficiency of the algorithm. The experiments are conducted on the Soft Actor Critic algorithm ( SAC ), a maximum entropy policy optimization algorithm for reinforcement learning ( PRe ). The paper compares SAC with other algorithms ( including standard PRe and maximum entropy policies ) based on the assumption that the action space is bounded, and shows that SAC outperforms the other algorithms when entropy is used as the primary motivation for the policy optimization. The authors also provide empirical evidence that the proposed non - uniform sampling method outperforms SAC on the state - of - the - art continuous control tasks that are posed by PRe."
SP:545e8da553fcb47d84eaa044d8a4947d3cd3230e,"This paper studies adversarial attacks on industrial copyright detection systems. The focus of the paper is on neural net based systems that detect the presence of copyrighted works ( e.g. music ). The authors first provide a proof of concept of a well - known music identification method and implement this system in the form of a neural net. They then attack this system using simple gradient methods using adversarial music created this way successfully fools several industrial systems, including the AudioTag copyright detector and YouTube ‘s Content ID system. The main contribution of this paper is to raise awareness of the threats posed by adversarial examples in this space and to highlight the importance of hardening the hardening capabilities of neural net systems to protect against such attacks.   The authors also provide an empirical evaluation of the accuracy of the methods used to train the neural net system."
SP:b511822850da3bf1079a36ed6f5ad4db80fbc424,"This paper proposes a decomposition - based activation mapping for deep metric learning ( DML ) that maps the final activation of two DML representations ( e.g. Gaussian Mixture Model ) to the activation maps of the original representations. The idea is to show where contributes the most to the overall similarity of two input images by decomposing the final representations. This is in contrast to the usual activation maps that are based on the final classification of the representations.   The proposed decomposition maps decompose the final representation of two images into two regions : the center and the periphery. Different regions correspond to different regions of the image and are associated with different regions in the DML model. The goal is to generate point - to - point activation intensity between two images so that the relationship between different regions is uncovered. The authors show that the proposed framework can be directly deployed to a large range of metric learning applications and provides valuable information for understanding the model. They conduct experiments on two potential applications, i.e. cross - view pattern discovery and interactive retrieval. The experiments are conducted to evaluate the effectiveness of the proposed DML decomposition mapping and to compare the performance of DML with standard DML."
SP:67bf71219fe6bedec5f5525200e734638e4a6ca2,"This paper studies the problem of lifelong learning in an online learning setting where mistakes can compound catastrophically into the future and the underlying dynamics of the environment may change. Traditional model - free policy learning methods have achieved successes in difficult tasks due to their broad flexibility, and capably condense broad experiences into compact networks, but struggle in this setting due to the activation of failure modes early in their lifetimes which are difficult to recover from and face performance degradation as dynamics change. On the other hand, model - based planning methods learn and adapt quickly, but require prohibitive levels of computational resources. This paper proposes to combine the benefits of these two approaches by providing a new algorithm, Adaptive Online Planning ( AOP ), that can provide more extensive planning only when necessary, leading to reduced computation times.   The main contribution of this paper is to study the relationship between AOP and the ability of policy learning algorithms to learn well in the online setting, where the goal is to learn policies and behaviors that can effectively adapt in the face of unpredictable changes in the world – challenges that a continual learning agent naturally faces over an extended lifetime – even when traditional reinforcement learning methods fail. The experiments compare the performance of AOP with that of two baselines, one based on reinforcement learning and another based on traditional policy learning. The results demonstrate that AOP is able to more effectively deals with novel situations, adapting behaviors and policies effectively even when the environment changes rapidly. The main contributions of the paper are the following :   ( 1 ) It proposes to study two methods of planning - based methods, planningnet and planningnet - free planning, and apply the results to a setting where the planningnet has limited capacity ( e.g., the task is intractable ). The idea is that if planningnet can learn to predict the future performance of the target task better than the current planningnet based on the current dynamics, then planningnet could learn faster to act more flexibly in the future. However, the authors argue that planningnet may not learn as well as the baselines because it needs to make predictions on the past, and hence needs to learn both the past and the present. The authors provide a procedure to train a planningnet that combines the information from the past with the present to learn the planning policy. This procedure is referred to as “ rolling out planning ”. ( 2 ) It also provides a procedure for training a policy network using the learned model from the rolled - out planning data, but the authors do n’t compare this model to the one trained with the model"
SP:11159cb878a436a5d4fc6edb4132f2cc3c1b3f72,"This paper proposes to replace the softmax attention mechanism in image generation with two sparse - promoting attention mechanisms, i.e. sparse - max and total - variation - sparse attention ( TVMAX ). The main contribution of this paper is to introduce the sparse - maximum and sparse - variance attention mechanisms for image generation, which are proposed to be used in conjunction with the visual attention mechanism ( VAT ) in order to promote sparsity and encourage fusing of the related adjacent spatial locations. The paper presents results in the Microsoft COCO and Flickr30k datasets, obtaining gains in comparison to softmax VAT and TVMAX compared to the other compared attention mechanisms in terms of human-rated caption quality and attention relevance."
SP:fb0c3ce3db6ad674ddc615bdc6203cdcbe42c804,"This paper proposes a generative model to predict the topology of dynamic graphs from their graphs'trajectories. This is important as dynamic graphs are more dynamic than static graphs as their topologies tend to change over time ( e.g., stochasticity ). The proposed model consists of a graph neural network ( GNN ) and a recurrent network ( RNN ), which first capture the temporal evolution patterns of the graphs. Then, the authors use a GNN - based generative approach where they use the predictions from the GNN and the recurrent network to construct a graph instance corresponding to the predicted topology from the two networks. The authors evaluate the effectiveness of the proposed model on three datasets to evaluate the model's ability to generate dynamic graphs. The experiments demonstrate that the model outperforms the baselines on both real - world and synthetic data.   The main contributions of the paper are the following :   ( 1 ) A novel and theoretically challenging way of constructing dynamic graphs by combining graph neural networks and recurrent networks. This method is more challenging than previous methods due to the large number of graphs in the target class and the fact that dynamic graphs tend to have more complex topologies ( compared to static graphs ). It is worth mentioning that prior work in this area has focused mainly on generating static graphs and not on generating dynamic graphs since the latter is computationally more challenging. The main contribution of this paper is the combination of the two methods to develop a model that can capture the time - evolution patterns in dynamic graphs which is then used to construct graphs with similar topology at the next time step. ( 2 ) The authors test their model on synthetic data and three datasets where they compare their proposed method with existing models ( NeurIPS, GraphDAGE, GraphSAGE, and GAT - GP - SGD ). They find that the proposed method performs about equally well on all three tasks. However, the differences between the three methods ( especially in terms of accuracy and sample efficiency ) can be more noticeable when compared to the existing methods which focus on static graphs."
SP:ff722957a1765c0568426ed88dd910a6b74054ef,"This paper proposes a method for generating imputations for missing class distributions for target class assignments in machine learning tasks with incomplete datasets. The paper proposes to use a generator network to generate imputations that a discriminator network is tasked to distinguish, and then a predictor network is trained using the imputed samples to capture the classification uncertainties and make predictions accordingly. The proposed method is evaluated on the CIFAR-10 image dataset as well as three real - world tabular classification datasets, under different missingness rates and different different assumptions. The experimental results show the effectiveness of the proposed method in generating imputation and the uncertainty reduction proposed by the predictor network.    The main contributions of the paper are as follows :   1 ) A generator network is proposed for generating missing features for class distributions of target assignments of a given dataset. This is in contrast to the existing missing data imputation techniques which are mainly concerned with filling missing values. 2 ) The discriminator networks are trained to distinguish between the imputations generated by the generator network and the discriminator class assignments. 3 ) The predictor network uses the predictions from the generator networks to estimate the distribution of the missing features and class assignments of the discriminators. 4 ) The experiments evaluate the imputation method on three real world datasets and three different assumptions ( assumptions being missingness, missingness rate, and assumptions on class assignments )."
SP:c051b0fe779d9e4131016970b7ba469b596f3009,"This paper proposes a novel approach for solving long - horizon estimation for value - based policy evaluation using importance - sampling - based methods. This is a well - studied problem, where high - fidelity simulators are not available and on - policy evaluation is expensive or impossible. In this work, the authors formulate the problem as solving for the fixed point of a certain operator. They use tools from Reproducing Kernel Hilbert Spaces ( RKHSs ) to develop a new estimator that computes importance ratios of stationary distributions of value - sampling - based estimators. They analyze its asymptotic consistency and finite - sample generalization to derive insights into how the off - policy data are collected. They compare the proposed estimator with two prior methods : ( 1 ) Value - based SAM ( Liu et al., 2018 ) and ( 2 ) Value Sampling - Based DA ( Liu & Tan, 2019 ). The main contributions of this paper are the following :    1 ) The authors develop a novel estimator to analyze the off-policy data collected under the assumption that the operator's distribution is stationary. This assumption is based on the fact that the average value of all samples obtained by the operator is the sum of the average values of previous samples and the expected value of the next samples from the operator. The estimator computes the average of the expected values of all sampled samples from both previous and stationary distributions to get an estimate of the mean of the operator ’s expected value. This estimate is used to compute the expected log - likelihood of each sample from the stationary distribution when computing the value for the operator, which is used as the primary metric in the estimator. This estimator is also used to estimate the expected cost of running the operator in the future. The authors compare the estimated operator cost with the estimated mean and variance of the stationary operator in terms of the ratio of expected value and variance between the expected operator cost and the average operator cost in the previous and future updates. They also compare their estimator against two prior estimators, Value - Based SAM and Value - Sampled - DA. They find that the approach outperforms the previous methods in most cases, with the exception of the latter slightly worse in the latter case.   2 ) Based on these results, they propose to use a modified version of their estimators to evaluate the effectiveness of their approach. In particular, the first estimator, called RK - SGD, is used for benchmarking. The second estimator ( Theorem 1 and Theorem 2 is used in the evaluations to compare the performance of the proposed method with the one proposed in Liu et. al. and the one developed in the original manuscript. The experimental results show that the proposed approach does not require data from stationary distributions which is better suited for evaluation. However, there are some limitations in the"
SP:065c900843011a71b70ed35357a2f71fe83872a7,"The paper proposes a new approach to computing the conditional likelihood p(x|k|x, \� ), as well as responsibility probability p(k| x, θ ) which describes the distribution index corresponds to the data in Gaussian Mixture Model ( GMM ). The authors use GAN to compute these probabilities at the data ’s latent space z, where z is the corresponding latent representation of x, and corresponding latent representations of the data through an additional classification network which is trained with the GAN in an “end - to - end ” fashion. They also propose a new “ segmentation ” approach by smooth linear interpolation across any combinations of the modes in an unsupervised manner, which allows them to generate new ‘ outdist distribution ’ data by means of a smooth linear projection. The main contributions of the paper are as follows. First, they define a new GMM framework under the assumption that the data points x and the modes x are associated with a Gaussian distribution. This assumes that there exists a random index k which identifies which Gaussian the data is associated with. In a traditional GMM paradigm, it is straightforward to compute in closed form, conditional likelihood $ p( x|k, \�)$. Instead, the authors use the Generative Adversarial Network ( GAN ) framework to achieve an alternative plausible method of computing these probabilities, where the parameters can be defined more flexibly. Second, they propose a modified GAN by allowing them to define the distribution using p(z|k, \.(x|x,\� ) ), and obtain statistics such as the weights of each mode. Third, they introduce a new GANetical distribution method, where they define the parameters p(a, b ), where a   each mode is a weighted sum of Gaussian distributions sampled from the dataset. They use this distribution method to compute the parameters of the second GAN, which is then used in conjunction with the closed - form GMM to compute responsibility probability and other parameters such as weight of modes in the GMM. The obtained from computing the parameters in the first GAN.   Finally, they demonstrate some interesting properties of their new approach, including the fact that the dataset segments can be generated by linear extrapolation across any combination of modes by smooth extrapolation from the mean and covariance matrix using a linear projection on the mean."
SP:2da1608209058d214f8671062cc9eb0833ba4831,"This paper proposes a method to train deep neural networks with improved accuracy and lower dynamic computational cost. It achieves this by gating the deep - learning architecture on a fine - grained - level with individual convolutional maps that are turned on / off conditionally on features in the network. To achieve this, it introduces a new residual block architecture that is trained with two techniques : individual block gate and batch - shaping. Results on CIFAR-10 and ImageNet datasets for image classification, and Cityscapes for semantic segmentation show that the resulting networks automatically learn to use more features for difficult examples and fewer features for simple examples. In particular, on ImageNet, our ResNet50 and ResNet34 gated networks obtain 74.60% and 72.55% top - 1 accuracy compared to the 69.76% accuracy of the baseline ResNet18 model, for similar complexity."
SP:f90e9f0eb53f92601bdfa3f7bf86f71d037aad30,"This paper proposes a probabilistic importance inference approach for pruning deep neural networks ( DNNs ). Specifically, the authors propose to score the relevance of connections between inputs of a DNN and its outputs using a nonparemetric scoring test and only keep the significant ones. This is done by first computing the correlation between the inputs of the DNN with the outputs of a pre - defined classifier and then computing the importance scores for each connected pair of the inputs. The importance scores are obtained by computing the mean and variance of a pair of samples from the output of each DNN of the pre - determined classifier. The authors then compute the log - likelihood of the connected pairs as a measure of the importance of the connections between the outputs and the inputs, and use this as a threshold to reject connections that do not have high importance.   The main contribution of this paper is that it proposes an approach for testing whether or not the scores obtained from a pruned DNN are significant enough to warrant using when computing the pruning label. This pruning is motivated by the fact that most of the real - world applications of the pruned labels ( e.g. machine translation, bi - level machine translation ) depend on the similarity of the input - output pairs, and that the ones kept by pruning are often the ones with the lowest importance ( i.e. the ones whose connections to the outputs are the most significant ). The experiments show that the proposed approach achieves better lossless compression rates than existing pruning methods, while maintaining or improving upon the performance levels of these pruned methods. The main contributions are two - fold :    the first is a proof that the obtained scores do not correspond to the true importance of connected pairs found in the original DNN, and the second is an extension of a pruning approach that uses the clustering trick from the original pruning problem to find the pairs with the highest importance connected to the inputs and the outputs ( the “ significant ones ” ). In the experiments the authors compare their pruning method with two other pruning approaches that prune the original output of the network, one based on a KL divergence ( KL divergence from the weights of the original and the other based on the weighted average KL divergence. The experimental results show that their approach pruned the original outputs at a lower cost ( with respect to the KL loss ), but at a higher cost ( in terms of computational overhead ) during pruning. When pruning the original weights, their approach performs marginally better ( though still slightly better ). When using the original KL divergence as a benchmark, they show that pruning with the proposed pruning strategy leads to a loss of 0.05 % fewer pruning error in the experiments compared to when it does not"
SP:64cbbb6a2f6847ef71cd5a23ba3e4cc5c815a56e,"This paper presents a method for hierarchical reinforcement learning ( HRL ) based on Motif - based Approach. Motifs are repeated action sequences that can be compressed to yield a compact code of action trajectories. The method proposes to learn nested behavioral hierarchies of arbitrary depth, with actions of arbitrary length. The learned temporally extended actions provide new action primitives that can participate in deeper hierarchies as the agent learns. The main contribution of this paper is to develop and evaluate a framework for using this approach for learning in tasks with non -rivial hierarchical structure. It is shown that the approach can be used to accelerate learning in recursively more complex tasks through transfer.   The main contributions of the paper are the following :   1. A method for iteratively compressing action paths in order to learn in depth hierarchical structures in tasks through HRL. This is done by iteratively extending action sequences up to length arbitrary length, and then compressing the action sequences again up to the length desired by the task. This allows the learned actions to become part of hierarchies for which the task is a sub - goal, not the goal, as is the case with standard hierarchical RL approaches. The compressing step is carried out iteratively until the task converges to the goal. The goal is to maximize the ratio of the number of sub - goals in the learned action sequences to the total number of actions. This gives rise to a hierarchical task completion rate that is higher than the learning rate without action sequence compressing. ( Note that this method is not meant to be used for all hierarchical tasks ; rather, it is meant to apply it to tasks that have non - hierarchical structures. )    2. The motivation for developing the framework for HRL is given as follows : 1. To reduce the burden on the RL process as a whole, the authors propose to use the following approach as a bridge between different types of RL tasks : ( 1 ) a meta - RL tasks where the goal ( i.e., the goal of the RL agent ) is to learn a hierarchical structure from the actions in the task ; ( 2 ) meta - tasks with a smaller hierarchical structure where the goals are easier to learn ( e.g., if the goal is smaller than the task goal, then the goal can be learnt from a single action in each action. ( See Note 1 for details ) 3. A meta - task with smaller goals and fewer action sequences ( see Note 2 ), where larger goals are learned from fewer actions"
SP:e1ccfb3a684aef8a0fb36194eb16af1667811e81,"The paper proposes a new generative model, Hierarchical Bayes Autoencoder ( HBAE ), for generating complex image sets. The model is based on variational autoencoders ( VAE ) and uses a latent code generator ( latent code recovery ) to recover latent codes conditioned on the inputs. The latent code is then used to train a decoder ( EBM ) using variational inference. The decoder is trained using an adversarial approximation where a conditional generator is trained to match the EBM. The paper shows that the resulting model outperforms VAE and other widely adopted unimodal autoencoders adopted in the mainstream image generative models, such as GANs.   The authors also show that the model is capable of modeling sets and recovering latent codes for a set of examples. In the experiments, the paper compares the proposed model with VAE, HAE, and other VAE - based models and shows that HAE outperforms them in terms of generative power, image quality, and modeling accuracy."
SP:1130a391afa30d1e0fddadedd2a3aaa70a4cb751,"This paper proposes a normalization technique called cross - normalization for off - policy learning ( OTL ), which is a special case of normalization applied to feature normalization ( also known as normalization in RL ). Cross normalization is an extension of batch normalization that re - centers data for two different distributions, as present in OTL learning. The main contribution of this paper is that it proposes to apply cross normalization to the naive application of existing normalization techniques ( e.g. DDPG and TD3 ) in a setting where the target domain is OTL and the batch distribution is not OTL, to improve stability and remove the need for target labels from the model representations. The authors show that in this setting, the proposed Cross - Normalization ( Cross - NLP ) improves stability and removes the need of target labels in order to learn the OTL features. They also show that cross - nLP improves the stability of the model on a range of MuJoCo tasks compared to naive applications of BN in the naive setting. The experiments are conducted on a toy example and 3 datasets, where the Cross - normalized Feature Model is applied to 1 ) OTL on MNIST, 2 ) MuJoJoCo on CIFAR-10, and 3 ) Omniglot on UCF - MNIST. The results show that the proposed approach, compared to BN and BN, is more stable and robust on the three datasets, and is more robust to the choice of target domain on OTL."
SP:f9cafaa5131176290fa069e6d24046c079cd9eea,"This paper proposes an adversarial training strategy to learn discriminative features unbiased and invariant to the confounder(s ). The main idea is to train a neural network with features extracted from a dataset of medical images, face recognition images, and synthetic data that are assumed to be unbiased ( i.e., they do not contain any confounding variables ). To train such a network, the authors propose to augment the features learned from the dataset with features that are generated from the adversarial loss function of the training dataset. The adversarial losses are trained using a loss function that encourages a vanished correlation between the bias and learned features. The authors test their method on synthetic data, medical images and a gender classification dataset. They show that the learned features generated by their method not only result in superior prediction performance but also are uncorrelated with the bias or bias or confounding effects of the dataset.    The main contributions of this paper are the following :   ( 1 ) The authors develop and apply a new adversarial learning method to generate features from the synthetic data and images. This method is referred to as the Adversarial Training Algorithm ( ATA ). ( 2 ) The training data used to train the ATA network is synthesized using synthetic data from the Dataset of Implicit Bias Control ( IDC ) dataset. ( 3 ) The dataset used in the training is the same as the original IDC dataset except that it is augmented with more synthetic data. ( 4 ) The main contribution of the paper is the development of a method that derives features from these synthetic data using the adversarially trained features. It is compared to the discriminator(ATA ) trained from the original dataset ( ADA ) using the features generated from ADC training. The method is compared with two other methods : traditional statistical methods ( stratification to precomputed features and residualization of features ) and new ATA. The experimental results show that ATA outperforms the other methods in terms of generalization but not generalization and is less general than traditional methods when it comes to the prediction performance with respect to the confounding variables."
SP:783049ff463edd1283c058c6106a3e1f9a033df4,"This paper proposes Group - Transformer, a transformer - based model for character - level language modeling based on the GPT-2 algorithm. The authors argue that the existing Transformer - based models require computational resources and are not suited for practical application. To address this, they propose a lightweight model that factorizes the calculation paths by grouped embedding operators and employs inter - group linear operators to prevent performance degradation from the group strategy. The proposed model is evaluated on LSTM, enwik8 and text8 tasks and compared with the baselines. The experimental results demonstrate that the proposed Group - Transformers achieves better performance than baselines on all three tasks. Ablation studies and qualitative analysis are also performed to validate the effectiveness of the proposed model.    The main contributions of this paper are as follows :   - A new transformer model based on GPT - 2 is proposed. - The authors develop a new embedding operator, Group - Operator, to factorize the paths of the generator when the embedding is computed. - They apply the new operator to the generator of the base Transformer model, and show that the resulting group operator is computationally tractable. - Experimental results show that Group - transformer outperforms baselines and the best performing baselines when applied with a comparable number of parameters to Group - Generator."
SP:946c26d371297c88d0ac246257104099b4585edc,"The paper proposes Optimal Transport ( OT ), a non - likelihood - based framework for training generative models based on hierarchical Latent Volcanic Structures ( LSTMs ). The motivation for adopting OT is that it allows easier training convergence between distributions, in principle allowing easier transfer of knowledge between models. The training is done using the generative model ( G ) and the Optimal Transformer ( PT ) model ( D ).   The main contributions are :   ( 1 ) A new training objective is proposed, which aims to leverage the advantages of using a hierarchical LSTM over the Variational Autoencoders ( VA ) approach. This is done by training the G and D models on top of each other, using the same training distribution for D and P. ( 2 ) A training procedure is used to train the PT model and D model in a parallel way, where the target distribution is shared between the two models ( instead of being separated as in VA training where the D model is used for the training of the model in the parallel training ). This allows the authors to train both models on the same dataset ( training D and D ) without the need for highly bespoke models and inference networks. The experimental results show that the proposed approach is more effective than the VA - based training approach ( DAE ) and that the D - model is more robust to perturbations in the training distribution ( in terms of accuracy )."
SP:309b47441d227ffa33f96f9f16f2addc607e5bb0,"The paper presents a new autoregressive video generation model based on a three - dimensional self - attention mechanism for generating video continuations. The model consists of three parts : ( 1 ) a generative model for generating high - quality continuations that is trained via adversarial training, ( 2 ) a latent variable model to model the latent representations produced by the generated video, and ( 3 ) a transformer - based model to predict the outputs of the transformer. The latent representations of the generative models are trained via a mixture of supervised learning and self - training. The authors compare the proposed model with state - of - the - art video generation models based on neural network architectures, latent variable models, and adversarial learning. They show that the proposed method, while conceptually simple, achieves high fidelity on multiple metrics on popular benchmark datasets, for which they produce continuations of high fidelity and realism. They also present results from training their models on Kinetics, a large scale action recognition dataset comprised of YouTube videos exhibiting phenomena such as camera movement, complex object interactions and diverse human movement.    The main contributions of the paper are the following : 1 ) The authors develop a simple autoregressively - trained model to generate high fidelity continuations for video generated from scratch using latent representations generated from a neural network model. 2 ) The model is able to generate diverse continuations on both synthetic and real - world video datasets."
SP:ad8fcdbc47a50dd2bf58aba2bc6cfe199e84dd4d,"This paper proposes a latent feature generation framework for generalized zero - shot ICD classification on the International Classification of Diseases ( ICD ). ICD is a multi - label text classification task with noisy clinical document inputs and extremely long - tailed label distribution, making it difficult to perform fine - grained classification on both frequent and zeroshot codes at the same time. This paper proposes to improve the prediction on codes that have no labeled data without compromising the performance on seen codes by exploiting ICD code hierarchical structure and a novel cycle architecture that reconstructs the relevant keywords. This is the first adversarial generative model for the generalized zero shot learning on multi -label text classification. The experiments are conducted to evaluate the effectiveness of the proposed method.   The main contributions of this paper are the following :   1. A new hierarchical structure for ICD codes, based on ICD hierarchical structure, is proposed. 2. A cycle architecture is proposed to reconstruct the relevant words in the ICD Code Hierarchy using a latent variable. 3. A latent variable generator is used to generate the latent features for zero - shots codes by maximizing the mutual information between the latent variable and the latent feature of the code. 4. Experiments are conducted on the public MIMIC - III dataset, where our methods improve the F1 score from nearly 0 to 20 % for the zero -shot codes, and increase the AUC score by 3% ( AUC with improvement ) from previous state of the art. 5. A series of experiments are performed to test the quality of the features generated by the proposed latent feature generator."
SP:3ce82ae297e5759ab957babe9927062e7a71b0ba,"This paper proposes a method for simultaneously learning embeddings of states and action sequences to improve sample efficiency in reinforcement learning. The goal of the method is to learn a forward prediction objective that captures the structure of the environment ’s dynamics, enabling efficient policy learning in a model - free RL setting. To achieve this goal, the authors propose to learn embedding of both the state and action sequence, with the goal being that the action embedding captures the dynamics of the state in order to learn policy trajectories that lead to efficient action selection in the goal - conditioned continuous control setting. The proposed approach is based on self - supervised representation learning ( SDP ), which is a type of representation learning that can be applied to a variety of reinforcement learning tasks, including policy learning, self - supervision, and data augmentation.   The main contributions of this paper are the following :   ( 1 ) The authors propose a method to simultaneously learn the states and actions in an RL setting by embedding them in the same embedding space. This is similar to what was done in [ 1 ], but different from the approach used in [ 2 ]. The key difference is that the authors use a different set of embedding functions for the states ( state - action - state ) and action - action sequences ( action - sequence - action ). This allows for combining the learning of the states in one step and the actions in the next step with the action sequences in the previous step without the need to re - construct the states from the actions. This approach is referred to as “ joint action learning ” ( joint action and state - state embedding ). The authors claim that this approach is more efficient than action - based learning because it is able to capture both the structure and dynamics of an environment. ( 2 ) The experiments are conducted on a goal - conditioned continuous control from pixel observations of the MNIST dataset, where the control is obtained using only 1 - 2 million environment steps. They compare the performance of the proposed joint action & state based approach with standard SDP and action based approaches, and show that the joint action based approach leads to better performance in terms of the number of collected actions and the average number of interactions with the environment steps ( compared to standard action based methods ( averaging out all interactions with all samples )."
SP:11ce1616e721340eea9e80dad7460c77355ac7d1," meta - learning is a popular technique to transfer knowledge learned from previous tasks to the new ones. However, due to the high level of task heterogeneity, it is not possible to share globally the meta - knowledge across tasks. To cope with this challenge, meta - learners typically use task - specific graph structures that are customized for each task. In this paper, the authors propose a framework ( ARML ) that automatically generates the relevant cross - task relations when a new task arrives, based on the existing meta - learner and task structure. The authors claim that the proposed framework not only addresses the challenge of the task heterogeneity by a learned learned graph, but also increases the capacity of the learned model to interpret the structure.    The main contributions of the paper are as follows :   - A framework is proposed ( ArML - ML ) to automatically generate the relevant structure for the meta learner ( based on existing task - structure ) and the task structure using a graph - matching algorithm. - The resulting graph is used to efficiently transfer meta - learned structure knowledge from the learned task structure to the task - learning model. - A series of experiments is conducted to validate the effectiveness of the ARML framework. The experiments compare the performance of ARML with several baselines, including ( i ) baselines that do not use the extracted meta - graph and ( ii ) a model - agnostic approach that does not require access to the meta graph to learn the structure ;-)-)-))-- the authors conduct extensive experiments on 2D toy regression and a few shots to validate their method and show that the results are competitive with the state - of - the - art ( in terms of generalization and accuracy )."
SP:37c209cd1c628b5c2f2b282fbeaf4bbf437c7670,"This paper proposes a controllable language generation method based on transformer - based language models ( LMs ) called PPLM, which combines a pretrained LM with one or more simple attribute classifiers that guide text generation without any further training of the LM. The authors present the canonical scenario where the attribute models are simple classifiers consisting of a user - specified bag of words or a single learned layer with 100,000 times fewer parameters than the LM, and control the attributes of the generated language via the classifiers. The main novelty of the method is that it allows for diverse and creative applications beyond the examples given in this paper, which will allow for more advanced and diverse use cases. The method is evaluated on a range of topics and sentiment styles, and extensive automated and human annotated evaluations show attribute alignment and show that any combination of differentiable attribute models may be used to steer text generation.   The main contributions of this paper are the following : ( 1 ) A transformer based language model ( LM ) trained on huge text corpora has been shown to achieve state - of - the - art generation capabilities ; ( 2 ) controlling attributes of generated language ( e.g. switching topic or sentiment ) is difficult without modifying the model architecture or fine - tuning on attribute - specific data and entailing the significant cost of retraining ; ( 3 ) The authors propose a simple alternative : the Plug and Play Language Model ( P PLM ) that combines the LM and the classifier from one of the three different attribute models to generate text using only the learned parameters from the LM ; and ( 4 ) Sampling between LM and classifiers from the three classifiers to learn the text generation parameters."
SP:12d0980bfea2de880905a0b87b40856969bb1c58,"This paper proposes to learn data representations with a denoising autoencoder, where the noisy input data is generated by corrupting clean data in the gradient domain. The idea is to learn a Laplacian pyramid representation of the input data so that the agent learns more robust representations that exploits the underlying data structures across multiple scales. The paper proposes a generic unsupervised learning framework that can be easily generalized to other domains. Experiments on several visual benchmarks demonstrate that better representations can be learned with the proposed approach compared to its counterpart with single - scale corruption. Furthermore, we also demonstrate that the learned representations perform well when transferring to other vision tasks."
SP:12afc1b259e51a31cbeb72366d2b93fbee1aafaa,"This paper proposes an approach to tackle the under - sensitivity problem in natural language processing ( NLP ), where the model is both over - sensitive to small changes in input and under - sensitive about large fractional deletions of words from input text. The authors propose to use interval bound propagation ( IBP ) to verifiably verify that a particular NLP sample is free from the under sensitivity problem through natural language inference ( NLI ). This is done by ensuring that the models do not become more confident in their predictions as arbitrary subsets of word from the input text are deleted from the NLP input. The paper develops a novel technique for formal verification of this specification for models based on the popular decomposable attention mechanism by employing the efficient yet effective IBP approach. Using IBP, the authors efficiently prove that ( given a model ), given a set of samples ( e.g., $ \mathbb{R}^2 $ ), that an instance of $ \text{N_{\text{L}$ ) generated from input and assumed to be free from under sensitivity is provably so ( Figure 2 ). The method is tested on both standard NLP datasets ( SNLI and MNLI - DP ), and compared with IBP and ICLR. The results show that IBP with standard training leads to significantly improved accuracy ( on the SNLI test set ) compared to IBP which leads to a significantly improved verified accuracy ( Figure 3 ). Ablation studies are performed to evaluate the effectiveness of the proposed method and compare with other training methods to address the problem."
SP:14257af9fe83522c6e5b5d6b0d68945b944e30fb,"This paper proposes a simple Markov Decision Process ( MDP ) for continuous deep reinforcement learning ( DRL ) called QGRAPH based on a replay memory. The authors show that the Q - value for each transition in the simplified MDP is a lower bound of the Q value for the same transition in DRL based on continuous Q - learning ( original continuous DRL problem ). They use this lower bound to provide a sample efficiency bound for TD learning in the MDP that exhibits increased sample efficiency while being more robust to soft divergences. They also show that exact Q - values can be computed efficiently as more data comes in to the replay memory, resulting in a more efficient algorithm. The main contributions of the paper are the following :   ( 1 ) The authors construct a simple MDP from a data graph and link its structure to soft divergence by selecting a subgraph with a favorable structure, which allows them to retain information from transitions that have already been overwritten in the replay    memory, which can decrease the algorithm's sensitivity to the soft divergence. ( 2 ) They use the lower bound in TD learning to provide sample efficiency for the transition value of Q - Value for a transition in MDP based on data graph that represents these transitions in the original DRL. ( 3 ) By using these lower bounds, the authors provide an upper bound for soft divergence of TD learning with respect to the Q-value for transitions represented in the data graph. ( 4 ) They show that using the upper bound, TD learning can exhibit more sample efficiency and a reduced risk of soft divergence while still enjoying high sample efficiency.   The main weakness of the proposed by the authors is that it relies on assumptions on a continuous replay memory that only holds a finite number of transitions, which limits the amount of transitions that can be represented using the replay memories. They address this issue by providing a simple transition representation that represents transitions in a graph that is representative of a continuous Markov decision process, which they call "" data graph "". ( 5 ) They also provide an algorithm to obtain exact Q-values for the data graphs in the graph using soft divergence that can handle soft divergence up to a certain threshold values. ( 6 ) They compare the proposed method with a standard DRL method based on DQN and show that their method is better suited for cases where the transitions are represented in graph data graphs, where the transition values correspond to lower bounds of Q values."
SP:c92c97e47d8b218dfd009bbf61f5b3547b395f91,"This paper studies the effect of the embedding complexity on generalization to the target domain from source domain to target domain in the multilayer neural network setting. In particular, the authors study the impact of the layer - dependent complexity on the generalization risk ( upper bound on the target risk ). Next, they specify a theoretical framework to apply the learned embedding across layers and provide experimental evidence to support their theoretical findings.   The main contribution of this paper is the development of a strategy to learn the target embedding that mitigates the sensitivity to the embeddings complexity and empirically achieves performance on par with or better than the best layer - dependent complexity tradeoff strategies from the literature. The paper is well - written and clear to follow, which is a plus in my eyes. The major concern of the paper is that the proposed approach does not provide a robust alternative to the commonly used domain - invariant embedding method for the source and target domains. This concern can be addressed by providing alternative embedding strategies that provide robustness to the domain invariance ( e.g., Gumbel - softmax ) as well as a robustness strategy that provides robustness against the source domain domain noise ( which is exacerbated by the domain noise )."
SP:f3f3c6fbae757836551b3f1ee54a7d1e040132b8,"This paper studies generalization error bounds for learning general non - convex objectives using stochastic gradient Langevin dynamics ( SGLD ), which has attracted significant attention in recent years. The authors propose a new framework, termed Bayes - Stability, for proving algorithm - dependent generalisation error bounds. The new framework combines ideas from both the PAC - Bayesian theory and the notion of algorithmic stability to obtain generalization bounds that do not become vacuous even when T tends to infinity. They obtain new bounds for the continuous Langevin dynamic in this setting by developing a new Log - Sobolev inequality for the parameter distribution at any time. They also obtain data - dependent bounds for SGL and other noisy gradient methods, which provide explanation to intriguing phenomena observed in Zhang et al. ( 2017a ). The main contributions of the paper are the following :   ( 1 ) The authors develop a generalization algorithm that, when the noise level of the process is not very small, provides data - independent bounds that distinguish randomly labelled data from normal data. This allows them to obtain bounds that provide an explanation to the intriguing phenomena that occurs when data labelled with different labels for different tasks are learned from the same distribution. ( 2 ) They also study the setting where the total loss is the sum of a bounded loss and an additional $ \ell_2$ regularization term, and provide new bounds that are more desirable when the number of training samples is large. ( 3 ) They conduct extensive experiments to demonstrate that the bounds provided in the paper can recover data from data that is not present in training data. ( e.g., with momentum, mini - batch, Langevin acceleration, etc. ) and improves upon the results in recent result in Mou et al ( 2018 ).   	"
SP:a82fcd1d3196ddf078cfe8f4bc6f445d9d2bdc11,"This paper investigates the role of the hippocampus in continual learning of two navigational strategies, egocentric and allocentric spatial navigation, in the context of the task of spatial navigation in learning to navigate between two different locations using two allocentric strategies, by using the principal component analysis method ( dPCA ). The authors investigate the firing activity of the hippocampal CA1 neurons in response to the task in a continual learning setting, where the goal is to learn strategies to navigate from one location to another using the allocentric strategy and the goal - directed strategy for the second strategy is to avoid converging to the starting position of the first strategy. The results show that the neurons encode relevant task variables such as decision, navigational, and reward location variables that are leveraged to learn the two strategies. They also compare this hippocampal features with standard reinforcement learning algorithms, highlighting similarities and differences. Finally, they demonstrate that a standard deep reinforcement learning model achieves similar performance when compared to animal learning, but fails to mimic the behavior of animals during task switching."
SP:51acf1f8108683dce543a1fb4a61fbd593f9b4cc,"The paper proposes TPO, a policy optimization method for continuous MCTS, a tree search based policy method for discrete action spaces, for the problem of policy improvement in high dimensional action spaces in the multi - dimensional settings of the popular multi - agent action space strategy, Humanoid, developed in the context of action space optimization and policy improvement ( PPO ). PPO is used as the baseline algorithm, and the authors propose TPO as an extension of PPO to handle the continuous setting. TPO takes two different approaches : 1 ) to reduce the tree search branching factor by using only a few action samples from the policy distribution 2 ) to introduce a new loss function based on the trajectories ’ mean and standard deviations. Experiments show that using TPO significantly improves the policy on most environments. However, some non - intuitive findings are observed, such as that tree search with a pre - trained policy improves policy improvement significantly less than tree search without the policy bootstrapping, rendering it prohibitively expensive.    The main contributions of the paper are the following :   ( 1 ) The paper proposes a new algorithm for continuous action spaces based on tree search and policy optimization, TPO ; ( 2 ) it proposes to use a limited number of action samples and a limited amount of branching operations to improve the policy improvement. The experiments show that TPO achieves better policy improvement than PPO on Humanoid with a 17 dimensional action space, achieving a 2.5x improvement over the baseline. This is consistent with the results achieved by PPO in the discrete action space setting. It is not clear to me if there are any significant differences between PPOO and TPO in terms of the empirical performance ( measured with respect to the number of samples and branching factor )."
SP:1ce3bc4d31712886f7dcada5b5ae67c3c376819a,"This paper studies the problem of generating "" winning tickets "" for ImageNet classification tasks based on the lottery ticket hypothesis, which states that neural networks contain subnetworks that, if appropriately initialized ( the winning tickets ) are capable of matching the accuracy of the full network when trained in isolation. However, the properties of winning tickets are not well understood, especially the importance of supervision in the generating process, and this paper aims to answer the following open questions : can we find winning tickets with few data samples or few labels? can we even obtain “ good ” tickets without supervision?   The main contribution of this paper is to investigate the dynamics of neural network optimization and generate winning tickets for the task of classifying ImageNet images. The authors first consider two scenarios :   ( 1 ) Lottery ticket hypothesis : with limited data and few labels ( e.g., few labels and ImageNet only ), and ( 2 ) TicketMatch : with large labels and lots of training data ( large data and many labels ). They find that winning tickets found in these scenarios are, perhaps surprisingly, competitive with winning tickets generated on the full ImageNet dataset when evaluated on ImageNet Classification task ( Table 1 ).    However, in contrast to the first scenario ( i.e., where winning tickets can be generated only with limited training data and limited labels ), in the second scenario ( where training data is abundant but the labels are difficult to obtain and there is no training data, the authors find that it is possible to obtain winning tickets in this scenario that are competitive with the best possible ( in terms of accuracy ). This observation is verified experimentally by comparing the performance of ImageNet classifiers ( Table 2 ) and the corresponding winning tickets ( Table 3 ). Interestingly, the best performing classifier is found to be the one generated from training ImageNet with full labels ( Table 4 ), but it is not quite as good as the best winning tickets. The performance of the classifier generated from scratch ( Table 5 ) is slightly worse than the winning ticket generated from ImageNet but it outperforms the best one generated with limited labels and even more so when using full labels."
SP:dbcebe5b73486885d9f4478b258047c02f8481a2,"This paper studies the problem of “ excessive prediction undersensitivity ” where the input text is meaningfully changed and the model ’s prediction does not change when it should. The paper proposes a noisy adversarial attack which searches among semantic variations of comprehension questions for which a model still erroneously produces the same answer as the original question – and with an even higher probability – and shows that – despite comprising unanswerable questions – SQuAD22.0 and NewsQA models are vulnerable to this attack and commit a substantial fraction of errors on adversarially generated questions. This indicates that current models — even where they can correctly predict the answer — may perform poorly on adversarial generated questions where they are not necessarily aware of all information provided in a given comprehension question. To address this problem, they experiment with both data augmentation and adversarial training as defence strategies : 1. Train / evaluation distribution mismatch : train and model weights are compared in a biased data setting with a train/evaluation distribution mismatch ; they are compared to a conventional model in the training set and outperform a conventional models in the biased data set by up to 11 % F1. 2. Adversarially robust training also used to train models generalise more generalise in a data setting where they generalise better than the conventional model.   The paper also provides a set of experiments where it compares the performance of two models, one based on the training data set and another on the public dataset, with respect to each other. The results show that both models perform comparably worse than the other on public data and outperforming the other model when using the public data setting. The authors should use these results as a warning to avoid future underestimating errors when using these models."
SP:5da870060778de460c1abe91562d6f3e707efef4,"This paper proposes a model - based approach to ensuring the safety of the agent while learning to solve a real - world task using reinforcement learning ( RL ) agents. The proposed approach is based on two components : ( 1 ) A “ future state ” module that takes the agent ’s actions as a whole and predicts the consequences of those actions, ( 2 ) A graph generation module that predicts the transition dynamics of the environment and generate a directed graph called the “ imaginative module ”. The future state module predicts the action that would most likely result in the current state being different from the action taken in the imagined state. The graph is used to generate the action trajectories that can be followed by the agent, allowing the agent to efficiently traverse through the imagined environment without ever taking any action in the real world. The imagination module can be seen as a “ plug - and - play ” approach to ensure safety, as it is compatible with any existing RL algorithm and any task with discrete action spaces. The safety module ensures that the agent does not visit unsafe states significantly less frequently than a baseline. Experiments are conducted on two gridworld environments and a self - driving car simulator. Results indicate that the safety module is more effective at preventing the agent from visiting unsafe states than the other two safety module approaches ( baseline and imagined safety module ) on the gridworld domain and more so on the simulator domain. Results are not reported for the contrastive RL setting used in the imagination module, which may introduce bias to the predictions. Results also do not indicate whether the proposed method is suitable for the task under different settings ( e.g., assume the agent is already familiar with the assumed actions and the task is not challenging enough )."
SP:c2796f28fb067138303df8d424d646f4ada31558,"This paper proposes a new physics - aware difference graph network ( PA - DGN ) that leverages neighboring information to learn finite differences inspired by physics equations inspired by end - to - end learning to discover underlying dynamical relations between the spatial and temporal differences in given sequential observations of a physical system. The authors propose a novel architecture, Physics - aware Difference Graph Networks, which leverages data - driven end to end learning and the approximation of directional derivatives to build a deep learning model to handle physics - governing observations on an unstructured grid. They demonstrate the superiority of their architecture over DGNs in terms of the prediction accuracy of graph signals on the synthetic data and the real - world climate observations from weather stations.   The main contributions of this paper are the following :   1 ) The authors develop and study a novel algorithm to learn the difference between two sets of points on a Gaussian Mixture Model distribution $ \mathbb{R}$, where $ R$ is the number of samples and $ D$ is a weighted sum of the distances to the corresponding points in the MDP space. This algorithm is then used to learn a graph function $ f$ that maps the samples to a set of points of the same dimension $ \theta$ with respect to the underlying MDP. This function is trained to be robust to perturbations made by the perturbed MDP due to the presence of noise in the graph space of $ \mu$ points and the fact that $ u$ and $ z$ are independent of each other and do not depend on the order of the samples ( e.g., order of magnitude of the particles in a MDP or order of velocities in a system ). The resulting f$ is trained with a neural network to predict the derivative function $ \eta$. The authors show that the f$ and the graph function \eta$ can be learned in close proximity thanks to the neighboring information provided by the DGN and that $ p$ is independent of $ u$.   2 ) They compare the performance of their algorithm with DGN - GP - SGD and DGN-DGN and show that GP-SGDGN outperforms DGN by a wide margin when the differences are p\theta smaller than a threshold."
SP:db8ed4f4fc3967f5dd4d208d5d029730eb99e840,"This paper considers training structured neural networks with constraints ( e.g. $ \ell_1$-norm constraint ) and regularization. The authors formulate training as a constrained nonsmooth nonconvex optimization problem and propose a proximal - type stochastic gradient descent ( ProxSGD ) algorithm to solve this problem. They show that under properly selected learning rates, with probability 1, every limit point of the sequence generated by the proposed Prox SGD algorithm is a stationary point. Furthermore, to support the theoretical analysis and demonstrate the flexibility of the proposed algorithm, the authors conduct extensive numerical tests to show that ProxSDD can be used to train either sparse neural networks or binary neural networks through an adequate selection of the regularization function and constraint set.   The main contributions of this paper are as follows :   - A theoretical analysis of training neural networks constrained by constraints ( as well as regularization constraints ), in which the goal is to design a learning rate and a constraint set such that the training converges to the target distribution. The main result of the analysis is that under the suitable learning rates and the appropriate constraints, the training convergence results in a gradient descent solution that is both expressive and computationally efficient."
SP:2ca1f4da9faee79768764cda5d09d949cc942acc,"This paper proposes a novel framework for lossy image compression based on a non - deterministic compression codec. The encoder maps an input image to a discrete code using an encoder from which the original image can be reconstructed through a decoder. Due to the quantization step, which quantizes the code length, which is non - differentiable, existing compression algorithms have to rely on approximate methods to train the encoder and decoder end - to - end. This paper proposes to circumvent this by relying on a compression codec that is deterministic and whose expected code length is proportional to the relative entropy of the encoding distribution with respect to the input image. The resulting framework is straight - forwardly trained using standard gradient - based optimizers. The experimental results show that the method is competitive with the state - of - the - art on the CLIC dataset on low bitrates.    The main contributions of this paper are the following :   1. The authors propose a novel compression framework that can be used to train image encoders and decoders in a principled way. This is different from standard methods that use gradient descent or gradient ascent to train encoder / decoder and have to be parametrized using a quantized version of the quantized encoder. 2. The method trains the decoder in a way that allows it to estimate the distance between input image and code distribution in a continuous space from which a sample can be constructed. 3. The decoder is trained with gradient descent so that it is able to estimate code length from the distance in continuous space and distance in input image from the code distribution. 4. The training shows that the distance and code length are the same for input and code and output images."
SP:788fd2b6956dd69bf7752d39ea21883947128c8a,"This paper proposes a novel super - resolution ( SR ) model based on compressed JPG ( C - JPG ) images to obtain better SR results from low - level computer vision ( CV ) tasks. The authors propose a novel SR structure with two components : ( 1 ) high - quality image processing ( H - Q - QPG ) and ( 2 ) sub - model to recover information for C -JPG images ( instead of the traditional SR elimination in traditional SR approaches ), and ( 3 ) integrate cycle loss into SR model to enhance its performance. The first part of the SR structure can be seen as an extension of the supervision rule in Section 3.1. The second part is a modification of the original SR model in Section 2.2. This modification adds a cycle loss to the SR equation to ensure that the output of the model is consistent with the one obtained from the third stage of the processing step.   The authors conduct extensive experiments to validate the effectiveness of their SR model on various CV tasks and compare with other state - of - the - art methods. They find that their approach achieves the best performance compared with other methods. However, they also find that the approach is not the most cost - efficient and time - efficient, and they need to conduct more experiments to confirm that their method is superior to other SR methods. For example, they tested their method on PCA - CPGP images and found that it is the only one to achieve the best results. They also tested their approach on the PCA-CPGP image and C - PGD images, and the results do not compare favourably to other methods ( e.g. )"
SP:18dd92f2f55020be4f5a089b3b251327e47886f4,"This paper presents an approach to estimate a full surface of pass probabilities from single - location labels derived from high frequency spatio - temporal data of professional soccer matches using a feature hierarchy - based neural network. The network is able to perform remarkably well from low - level inputs that are fed into it at a very low level by learning a feature hierarchically - distributed feature extraction process that produces predictions at different sampling levels that are merged together to preserve both coarse and fine detail. The presented method is an extreme case of weakly supervised learning where there is just a single pixel correspondence between ground - truth outcomes and the predicted probability map. The proposed deep learning architecture can be easily adapted to solve many other related problems in sports analytics.   The authors propose a fully convolutional network ( FPN ) that extends the network to learn to estimate pass - probability estimates. They demonstrate this by extending the neural network to measure the distance between two points in the dataset that are sampled from the same direction at different epochs of the match. The distance is estimated using a neural network that learns a KL divergence between the distance at each location of the two sampled epochs. The authors show that the FPN can recover a distribution over all possible positions in the pitch that would have seen players take part in the match and the ball rolling in the final few minutes of play. This distribution is then used to estimate the probability of a ball rolling into each of the three possible outcomes : ( 1 ) the location at which the ball rolled ; ( 2 ) the distance to each possible location from the ball when the ball was in play ; ( 3 ) the position of the ball at time t if the ball is in play. The FPN is trained to predict the probability values for all possible outcomes from the single location labels at each epoch. The method is evaluated on a set of high - dimensional temporal data sources, where the players ’ actions can be seen as measures of their impact on the environment. The results demonstrate that the proposed FPN does not only provide an accurate evaluation of observed events but also a visual interpretation of the results of other potential actions, which is important for spatiotemporal decision - making analysis. They also demonstrate that their approach can be used to solve other related problem in sports related to image recognition and image classification. The paper is well written and well presented. The major weakness is the use of the word “ map ” to refer to the feature extractor used to learn the feature hierarchy. This word implies that the network learns a map from a single location and uses it to draw both a visual and a textual representation of the features in the input space. This is not the same as using the word map to describe the features but rather a mapping from one location to another using the same location and a text representation to draw a visual representation ( which is different from what is done in the"
SP:1ae31baf383fc520687b255d9cac14c3b040e253,"This paper proposes an inductive matrix completion method based on factorizing the ( rating ) matrix into the product of low - dimensional latent embeddings of rows ( users ) and columns ( items ), a majority of existing matrix completion methods are transductive. The authors argue that this is because the embedding learned during training can not generalize to unseen rows / columns or to new matrices, and also because high - quality side information, such as user’s age or movie ’s genre, is not always available, and can be hard to extract. They propose IGMC ( Graph - based Matrix Composition Model ) to address this problem and use a graph neural network ( GNN ) to generate pairs of pairs generated from the rating matrix and maps these subgraphs to their corresponding corresponding corresponding ratings. The GNN is trained to predict user and item rating from the input matrices and achieves highly competitive performance with state - of - the - art Transductive baselines. In addition, IGMC is inductive – it can generalise to users / items unseen during the training ( given that their interactions exist ) and can even transfer to new tasks. Experiments on MovieLens dataset show that a model trained out of the Movie Lens dataset can be directly used to predict Douban movie ratings with surprisingly good performance.   The main contributions of this paper are the following :   1 ) it is possible to train a matrix completion model without using side information and achieving similar performances than state -    transductIVE methods ; 2 ) local graph patterns around a ( user, item pair ) are effective predictors of the rating this user gives to the item ; and 3 ) long - range dependencies might not be necessary for modeling recommender systems."
SP:c5cb1b50e17a69e88d5ae28848e265215162da1e,"This paper proposes SMTP, a momentum version of the stochastic three - point method ( STP ) by Bergou et al. ( 2019 ), which is a state - of - the - art derivative - free optimization algorithm. The authors show that SMTP outperforms STP and other methods that they considered in their analysis in various numerical experiments. In particular, SMTP is shown to be more robust than STP for convex functions ( non - convex and strongly convex ), and it is also more robust for learning to continuous control tasks on MuJoCo Todorov et al ( 2012 ) environments with varying difficulty.    The main contributions of this paper are as follows :   ( 1 ) This paper proposes and studies a new method ( SMTP ) to solve the convex optimization problem with a smooth objective function in setting R, where only function evaluations are possible ( e.g., RMSE ). This new method is called SMTP_IS ( with importance SMTP with importance sampling ). ( 2 ) The authors provide convergence analysis of this method for non-convex, convex   objectives, where the objective functions are assumed to be smooth and the parameters are smooth functions with heavy ball momentum. ( 3 ) They test SMTP on a collection of learning tasks and compare it against STP, other methods, and a policy gradient method. ( 4 ) They show SMTP has higher convergence than other methods and achieves better performance than the average of the methods they compare against. ( 5 ) They consider the following problem : - Consider a convex function R = \epsilon \mathbb{Omega}$ where R is the number of smooth functions and the objective function \theta_t is the size of the set of functions in the set. - Consider an instance of R such that the learning task is R_t(x ) = \sum_t\Omega_t \cdot x_t, where R \in O(T)^{-1}(x - T } \to T \in T_T } - For each instance of T_t the learner is provided access to all possible actions and all possible combinations of actions, and the learning tasks are used to train the softmax function \eta_t.   This paper considers three different classes of functions : - For one of the functions, each function is parametrized by a different set of softmax functions \"
SP:a216cfc29937eb398ea98cb1aea3481c9aed8240,"This paper proposes Action Semantic Network ( ASN ), a multi - agent network based on action semantics between agents in multiagent systems ( MASs ). The main contribution of this paper is the use of action semantics to represent the agent ’s actions ’ influence on the actions of other agents using neural networks. Specifically, the authors use the action difference between two agents ( agent A ) and agent B ( agent C ) as the input action to the action network network ( action semantics ). They show that ASN can be combined with existing deep reinforcement learning ( DRL ) algorithms to boost the performance of the algorithms used to learn the agent A. The authors also show that the ASN significantly improves performance of state - of - the - art DRL approaches compared with several network architectures. The major contributions of the paper are as follows.   1 ) The authors introduce a novel network architecture, named ASN, that represents the agent action semantics. This is different from the previous multiagent network ( MNN ), which only considers the action of the co - learning agent A, but does not consider the agent's actions on other agents. 2 ) They use action statistics to train the network. 3 ) They test the effectiveness of ASN on the popular StarCraft II MDP and the NeurasMongolNet."
SP:efaf3a440dc17e05177832083ffbc23760ed7c97,"This paper proposes to exploit the low - rank structure of the state - action value function, i.e., Q function, for both planning and deep reinforcement learning ( RL ) in order to improve the performance of the Q function for both control and deep RL tasks. Low rank structure is obtained by taking the mean rank of the target state action function and applying the ME ( Matrix Estimation ( ME ) techniques ) to it. The paper proposes a general framework to exploit low rank structure in Q function to improve planning procedure for classical control, and additionally proposes a simple scheme that can be applied to value - based RL techniques to improve performance on “ low rank ” tasks. Extensive experiments on control tasks and Atari games confirm the efficacy of the approach.    The main contribution of this paper is :   1. Leveraging ME ME techniques, by leveraging the global structure of Q function that is obtained from the mean and covariance matrix of the input state action value matrices, the authors propose to exploit a general low rank method for the planning of low rank Q function. This method is referred to as the Low Rank Exploitation Method ( LRR ). 2. Empirically, the method shows that the LRR method leads to a better performance on the target tasks when compared to the standard planning procedure ( standard control ) and the LS ( deep RL ) baseline ( LS ). 3. The main contributions of the paper are the contributions of ( 1 ) leveraging low rank ( as a measure of the mean of a target of the low rank function and ( 2 ) a generalization of LRR to use it for planning."
SP:430336893b247b7bd45687d78b0d0511a7369e87,"This paper proposes a new algorithm for Deep Reinforcement Learning ( DRL ) called Best - Action Imitation Learning ( BAIL ). BAIL is an off - policy DRL algorithm for the batch DRL setting, where the agent is trained using imitation learning from a fixed set of actions and states. The algorithm is simple and straightforward and can be viewed as a next - order DRL step after the policy gradient algorithm, where state - action pairs are selected from the action space and policy gradient is used to learn a policy using the learned state - actions. The paper shows that BAIL achieves state - of - the - art performance on the Mujoco benchmark.    The main contributions of this paper are as follows :   - A new algorithm, BAIL, is proposed for DRL. It is the first time in the history of DRL that an algorithm is proposed that uses imitation learning to learn the policy from the actions in the state space instead of the policy. This avoids the need of planning a policy gradient ( which is common in other DRL algorithms ) and is therefore more efficient. - The algorithm first considers the action spaces of the states and actions from the given data set and selects actions that it thinks are the best performing ( out of all the actions ) for the corresponding states. - Then it uses the action - state pairs from the batch ( selected by the action selection procedure in the previous step ) in the next step to generate policy pairs for the states from the current state and actions. - It shows that the policy pairs produced by BAIL are better than the ones obtained from the off policy algorithm ( which uses policy gradient methods ) on the states sampled from the previous state action pairs and vice versa action pairs."
SP:94078964876667e8a5d9ae7728d779d5b91a576e,"This paper studies deep extreme multi - label learning ( DAEML ), where feature representations and classifiers are trained jointly to automatically tag data points with the most relevant subset of labels from an extremely large label set. The authors argue that the current state - of - the - art deep - extreme - classifier methods are either not scalable or inaccurate for short text documents. The proposed DeepXML algorithm increases the accuracy by ( a ) learning word embeddings on head labels and transferring them through a novel residual connection to data impoverished tail labels ; ( b ) increasing the amount of negative training data available by extending negative sub - sampling techniques ; and ( c ) re - ranking the set of predicted labels to eliminate the hardest negatives for the original classifier.   The authors test the effectiveness of their algorithm on the task of matching search engine queries to advertiser bid phrases using DeepBid, AttentionXML, and DeepMLP. The experiments show that DeepX - MLP is faster at training and more accurate than XML - CNN and Attention - XML, while being less scalable and inaccurate."
SP:b1b1252d82fa1bea18309e0b0b894e0f28f48bc9,"This paper proposes a novel approach to the problem of hash - based collaborative filtering ( HBC ) based on the Hamming distance. The authors propose the self - masking approach, where the user hash code acts as a mask for the items to learn which bits are important to the user, rather than the user itself. The key idea of the approach is to use the vector representations ( hash codes ) of users and items, such that recommendations can be computed very efficiently using the standard distance computation between two hash codes. The paper introduces the concept of self - masked items, which is a binary vector representation of items such that the importance of each bit encoded in the item depends on the user. This allows a binary user - level importance score to be computed for each item without the need to store additional weights for each user. The method is evaluated on 4 datasets and obtained significant gains of up to 12 % in NDCG compared to the standard HBC distance computation ( which yields 4 % overhead ). The main contributions of the paper are the following :    ( 1 ) A new approach to learn the mutual information representation of user and items ( using the Boolean AND operation ), which learns to encode which bits of the item representations ( bits encoded by the vectors representing the user and the items ) are the most important to encode in order to provide better recommendation. This is in contrast to standard hashing distance computation, where each bit is equally weighted in the distance computation. ( 2 ) An improvement in the efficiency of the proposed method is made by using self - masksing, where a masking mask is generated for each mask of the user bit ( which is generated by the same way as the original user bit ). ( 3 ) An empirical study is conducted to evaluate the effectiveness of the method. The results show that the method is more efficient in terms of prediction error and prediction error variance than the baselines of HBC. The major drawback of the methods is that the variance in the amount of masking generated is larger than the variance of the recommendation error."
SP:80898d0f2b2c8dc3388fa9164e529eae36aa1b21,"This paper studies mode collapse of GANs learned distribution. Mode collapse refers to the inability of the learned distribution to capture high - level perceptual quality of the simulated data from a GAN to capture the diversity of the input data. The authors present a set of statistical tools to quantitatively measure mode collapse and propose two simple yet effective methods to calibrate the GAN learned distribution without access to the model parameters or the original training data.   The main contributions of the paper are as follows : 1 ) The authors develop and develop the mode collapse metric, which quantifies the probability that the sampled GAN image is of low quality ( low - level ) quality ( i.e., not high enough to be considered representative of the training data ). 2 ) They use this metric to quantify mode collapse empirically for the first time on two GAN models, GAN - E and GAN2 ) The mode collapse metrics are validated empirically on four GAN model distributions ( GAN-E, GAP - E, GGAN - M, and PEARL ), and show that mode collapse is indeed a significant phenomenon on these models. 3 ) The method is applied to three different settings of mode collapse, where mode collapse has been observed to varying degrees on each of them. 4 ) The results demonstrate that mode collapses are more severe on GAN Models E and M for E than they are on the other two settings. 5 ) Mode collapse is also observed to be more severe for GANModel M for M on the E and less so for the M - E datasets, suggesting that there may be more opportunities for mode collapse in the future."
SP:e5b5dda2f024cfda10526e744aa035e0165af58a,"This paper proposes Randomizing Neural Tangent Kernels ( NTKs ) to train over - parametrized neural networks that are beyond the linearized models governed by the NTK regime, yet still governed by Taylor expansion of the network. The authors propose randomizing the neural networks, which allows them to escape their NTK and couple with quadratic models. They show that the optimization landscape of randomized two - layer networks are nice and amenable to escaping - saddle algorithms. They prove concrete generalization and expressivity results on these randomized networks that lead to sample complexity bounds ( with certain learning certain simple functions ) that match the match of the original NTK with a matching model that can in addition be better by a dimension factor when mild distributional assumptions are present.    The main contributions of this paper are the following :   1. This paper proposes randomizing neural networks so that they are governed by different NTK regimes, which is called escaping NTK. 2. This gives rise to generative models that are trained with Taylor expansion, where Taylor expansion is replaced by a Taylor expansion term each time the network is trained. 3. This allows the authors to train neural networks governed by two different models, one with linearized and one with a randomized version of the latter model. 4. They demonstrate that our randomization technique can be generalized systematically beyond the quadratically - trained case, by using it to find networks ( that are coupled with higher - order terms in their Taylor series ) that are nice to optimize with the escaping models."
SP:cef7ea513eb3e42be4edf40e4ee1701a969bcbea,"Graph Neural Networks ( GNNs ) have recently received a lot of attention due to their power in handling graph data for different downstream tasks across different application domains. This paper attempts to answer three questions for the semi - supervised node classification task : 1 )    Whether there exists an optimal filter that performs the best on all graph data ; 2 ) Which graph properties should be considered for finding the optimal graph filter ; and 3 ) How to design appropriate filters that adapt to a given graph. To answer the first question, the authors propose a novel assessment tool, Graph Filter Discriminant Score ( GFD ), for evaluating the effectiveness of graph filter in terms of node classification.   The second question, which is similar to the first one, is how to learn data - specific filters for a graph? The authors answer this by proposing Adaptive Filter Graph Neural Network ( AFGNN ), a simple but powerful model that can adaptively learn data-specific filters to handle graphs with different properties. The authors develop a graph filter assessment as an extra loss term and learn to combine a set of base filters. On both synthetic and real - world benchmark datasets, the proposed model has the flexibility in learning an appropriate filter and consistently provides state - of - the - art performance across all the datasets."
SP:3c5ec9dbcf914c8901e4e35f3c2a7df4707422ab,"This paper studies distributionally robust optimization ( DRO ) for training neural networks, where the goal is to learn models that minimize the worst - case training loss over a set of pre - defined groups of i.i.d. samples. The authors find that naively applying group DRO to overparameterized neural networks with vanishing average training loss to train these models provably fails to fit the training data. Instead, the poor worst case performance arises from poor generalization on some groups, which can be explained away by the presence of spurious correlations that hold on average but not in such groups for atypical groups. To address this problem, the authors introduce a stochastic optimization algorithm, which is trained with convergence guarantees, with the aim of increasing the ratio of the average generalization error to the training loss in each group. The main contributions of the paper are as follows :   1. Train a group of network models ( pretrained on the same data as the training set ) on a synthetic data distribution where the mean and standard deviation of the data are assumed to be the same across all training sets.   2. Train the group models on each training set according to the assumption that the average between training and test set training is set to 0, and train the network on the average training set with the standard deviation between 0 and 1, and the data set with a standard deviation above 0, 0.3. 3. Train each group model on the data one training set at a time, one after another. The group models are trained to have vanishing training losses, and any model with vanishing training loss also has vanishing worst case training losses. 4. 5. Train group models with increased regularization ( with the same regularization as the previous models ) on the training sets while maintaining high average accuracies. The idea is to allow the network models to generalize more generalization across training sets, even if it is not needed for the generalization ( for example, when training on the synthetic data set ). The training set is pretrained with the data and training set in the same way as the others, but the assumptions are modified to allow for the coupling of the group model with the regularized data sets."
SP:eb1ee2e0f7d8466a04b58508ecb3da7b667eecdf,"This paper proposes a new approach for explaining black box classification loss using relevance scores of features according to contributions from classifiers. The relevance scores are a weighted sum of the contributions of each classifier with respect to the features they classify, and the contributions are weighted by a KL divergence between the features that do not appear relevant to the classifier and those that do appear relevant ( e.g., features that are not present in the input but are predicted from the feature representations by the classifiers ). The paper proposes to use a KL - divergence between these relevance scores and the classification loss in order to provide explainability. The KL divergence can be thought of as a measure of the distance between features that appear relevant on the black box classifier but not in the output classifier. This paper studies the KL divergence of the features from the input classifier using a neural network. The neural network consists of a distribution controller and a discriminative loss. The distribution controller is trained using a loss function that penalizes the deviation of the feature classifier from the mean classifier's predictions over the features it does not consider relevant. The proposed method is evaluated on both synthetic and real - world datasets and compared with a number of existing methods. The experimental results demonstrate that the proposed method not only provides better explainability but also outperforms other methods in terms of faithfulness and faithfulness of the explanations provided."
SP:32ea7cbc47cbdb1f703f4e07c31ce90abe083424,"The paper proposes a deep neural network that can be trained to solve image reconstruction and classification problems that involve detection of multiple object instances without any supervision. The most challenging part of training such a network is the non - differentiable top - K selection process, which is addressed by treating the result of top - k selection as a slack variable and training in a multi - stage fashion. The proposed method is able to learn to detect recurring structures in the training dataset by learning to reconstruct images from the dataset. It can also learn to localize structures when only knowledge on the occurrence of the object is provided, and in doing so it outperforms an auto - encoder or classifier that is trained only on the distribution of instances.   The main contributions of the paper are as follows :   1. The paper proposes to train a deep network to tackle image reconstruction problems, where the goal is to extract the most significant patches of the target domain, and feed these patches to a task - specific network, e.g., a classifier or encoder, to solve a domain specific problem. The challenge of the training optimization is that the extracted patches are not differentiable and need to be re - parameterized to be able to handle different distributions of the patches. This is done by introducing a KL divergence between the patches that are extracted during the training procedure and the ones that are used during the inference procedure to solve the task. The extracted patches become independent of each other and can be used to feed the task specific patches that solve the target task. 2. The method is shown to outperform competing methods, such as Auto - Encoder and classifier, when applied in a two - stage iterative fashion. 3. The major contributions include : ( 1 ) A deep network that learns to detect and localize recurrent patterns in the dataset, and ( 2 ) a method that uses self - attention to learn a feature extractor that can detect recurring patterns in images that are present in training data, and learn how to fix these recurring patterns ( learn via reconstructions )   Overall, the paper is interesting and well - written, and the major contributions can be summarized in two main lines."
SP:da1c5f6351d531482e90b86c3cceb52850c520de,"This paper studies neural program synthesis, which is the task of generating instructions that can produce desired outputs from inputs. The authors focus on the generation of a chunk of assembly code that can be executed to match a state change inside the CPU and RAM. They propose an algorithm called AutoAssemblet that uses a policy network and value network learned via self - learning reinforcement learning to explore the large code space efficiently and reduce the depth of the Monte Carlo Tree Search. They also propose an effective multi - entropy policy sampling technique to alleviate online update correlations. The main contributions of the paper are as follows :   - The authors develop and deploy a policy - based program synthesis algorithm, Auto - Assemblet, that is based on a neural network and a value network. This algorithm is evaluated on several tasks and compared to several competing program synthesis algorithms. They show significant higher success rates compared to the average of the competing algorithms. - They learn a policy policy network using reinforcement learning and learn the value network using self - training to learn the policy distribution.    The authors also propose a technique called Multi - entropy Policy Sampling ( MSE ) where a policy distribution is sampled from the MSE network based on the parameters of the value distribution of the policy network, and a distribution weighted by the policy parameters. This technique is tested on two tasks, one where the goal is to generate a program that matches the output of a recent update to the current state of the program, and the other task where a user has to select a sub - task to execute. They demonstrate that MSE with Auto - Sampling achieves better performance compared to MSE."
SP:0d4687fc36c02e27d1b95d532a3947589f92b1da,"This paper studies the effect of the model architecture on the speed of training in the context of gradient descent optimization. The authors build upon the idea from prior work that shows gradient descent can be modeled as a first - order ODE and use ODE’s coefficient matrix H to characterize the convergence rate. They introduce a simple analysis technique that enumerates H in terms of all possible “ paths ” in the network. They show that changes in model architecture parameters reflect as changes in the number of paths and the properties of each path. They also jointly control the speed and the cost of convergence of the analysis technique.    The main contributions of this paper are as follows :   - The authors study the impact of the change in the model parameters of the GDA with respect to the convergence speed and cost of training using gradient descent. They use the same two matrices, ODE ’s matrix H and the ODE - matrix H - paths, that were used in the previous work. The first one is the most general, while the second one considers only the paths that converge faster than the first one. This allows them to make comparisons across different versions of the same model. They find that the faster convergence rate for the faster matrices is better for the slower matrices. The second one is more specific and can be used to identify the more difficult paths to converge faster. They compare the convergence rates for two versions of their analysis method and find that for the first version faster convergence rates are better than the second. This leads to a trade - off between accuracy and speed in the case of faster convergence, which they do not consider."
SP:3e3bc8f617df742a395e7d315ec3810a42071294,"This paper studies the connections between strongly overparametrized neural networks ( NNs ) and kernel methods to understand the convergence and generalization behaviors of NNs. More specifically, the authors show that the test error of wide ReLU - NNs trained with squared loss are essentially a sum of two parts : The first is the minimum complexity solution of an interpolating kernel method, while the second contributes to the test errors only and depends heavily on the initialization procedure.    The main contribution of this paper is to prove that the second part of the contribution is negligible in the regime of small initialization variances ( e.g., when the number of initialization rounds is very small ). This allows them to transfer generalization bounds from minimum complexity interpolating kernels methods to NNs ( b ) in the opposite regime. The authors also study the effect of providing a novel criterion to identify good initialization strategies ( c ). In particular, they study the initialization bias of initialization of ReLU nets trained with gradient descent where the gradient norm of the ReLU net is significantly higher than that of gradient descent trained with no gradient norm at all. This leads to two main results : ( a ) the generalization error of general NNs increases significantly with the increase in the variance of the initialization procedure and the test parameters ; (b ) the performance of the general NN generalizes significantly ( although still only on a small fraction of the training data ). The main contributions of the paper are the first and second results. The second result is the construction of a new set of test parameters for the kernel methods under the gradient descent regime that does not depend on the parameter values of the NNs and instead relies only on their initial values. This new test parameters allow the authors to study the convergence behavior of generalNs with and without gradient descent. The experiments demonstrate that this new test parameter setting leads to improved generalization performance."
SP:b15ea009a36a0a76728dfc103d668d6781a8a99a,"This paper studies depth estimation for detection of objects in 3D environment using pseudo - LiDAR. Previous approaches to this task rely on Li - DAR sensors to estimate depth but they are expensive and provide limited depth information. This paper proposes to leverage cheaper but less accurate but equally as effective pseudo -LiDAR sensors, which are based solely on stereo images, to improve the depth estimation through improved stereo depth estimation. To achieve this goal, the authors propose to use a depthpropagation algorithm guided by the initial depth estimates of the Li - dar sensor to estimate the depth of objects detected by the depth - Propagation ( PD ) algorithm with respect to the environment. The authors also propose a loss function that encourages the loss estimation to be more aligned with depth estimation of faraway objects, as this is currently the primary weakness of pseudo - LIAR. In addition, they explore the idea of leverageing cheaper but extremely sparse Li - DhAR sensors ( which alone provide insufficient information for 3D detection, to de - de - bias our depth estimation ) to improve depth estimation in order to leverage more depth information for detection.   The authors report on the KITTI object detection benchmark that they use to evaluate their approach and show that their approach yields substantial improvements in depth estimation and stereo - based 3D object detection — outperforming the previous state - of - the - art detection accuracy for far away objects by 40%. The paper also presents results on the task of autonomous vehicle detection using a modified version of the KL - KITT dataset. The paper is well - written and well - presented. The quality of the experimental results are generally good. However, there are a few weak points that need to be addressed ( e.g., some of the methods not addressed in the main paper )."
SP:983d84502264633f3385d426c1d4601a0744ea9a,"This paper proposes an adversarial example detection method based on GAT - Generative - Adversarial - Training ( GAT-ADE ). It proposes to train K - base detectors where the i - th detector is trained to discriminate natural data of class i from adversarial examples perturbed from other classes. It also proposes a generative approach to interpret each base detector as an unnormalized density of the class - k under the assumption that the adversarial samples generated by the base detector are of class k. The authors evaluate the proposed method on two domains : Deep Neural Networks ( DNN ) and Deep Neural Autoencoders ( DAE ). They show competitive performances of the proposed methods against DAE and DAE - augmented DAE. They also provide a comprehensive evaluation of the new classification method.    The main contributions of this paper are the following :   1 ) The proposed adversarial detection method for DAE is trained on K - class classification problems. The training is done in two stages. During the training phase, the DAE first generates the class labels for the input samples. The class labels are used during the inference phase to determine whether the input is a natural sample ( class k ) of k - class ( class of k ) k or one of other classes k ( class p ). At inference time, the class label is used to assign the k - th label to the input sample. The second stage of the training is used during inference to determine the classification of the samples generated from the predicted class labels ( class labels ). The proposed classifications are the same for both DAE input samples and class labels. 2 ) The classification is applied during inference for both training and inference at inference time to obtain the final class label for input sampled from k - k class p.   3 ) The authors conduct experiments on two datasets to validate their proposed method and to evaluate their classification methods. The experiments show that the proposed approach outperforms the baselines in terms of accuracy and robustness against adversarial attacks using the proposed detection method."
SP:461e9308d050bc3dc7b35233452668bb31f5d491,"This paper proposes a model - free reinforcement learning approach for generating intrinsic rewards for exploration in procedurally - generated environments where the agent is unlikely to visit every state in the environment more than once and interacts with objects in each state that it can control. The authors propose an intrinsic reward function that encourages the agent to take actions that lead to significant changes in its learned state representation. This intrinsic reward is modeled as a weighted sum of the agent's expected rewards from interacting with objects and the observations it collected from the environment. The proposed intrinsic reward can be defined as a sum of ( i ) the expected return on each state visited by the agent over the course of training ( ii ) a set of rewards that the agent receives based on its actions taken during the training period ( iii ) and the observed observations ( iv ).   The authors evaluate their method on multiple challenging tasks in MiniGrid, as well as on tasks with high - dimensional observations used in prior work. The experiments demonstrate that this approach is more sample efficient than existing exploration methods, particularly for procedurally generated MiniGrid environments. In contrast to previous approaches, the differences between the learned behavior and the intrinsic reward received by our agent in the experiments are analyzed both in terms of the distance the agent moves in and distance it moves away from the target state when interacting with the objects in the task space ( i.e., the distance between the agent and the objects it moves to when it does not move the object from the state it is trying to interact with is analyzed. The differences are also analyzed using the learned state representations from the different tasks. The results show that our method is better able to handle large changes in the learned representations compared to the other intrinsic reward methods. The main contributions of the paper are as follows :   1 ) A novel intrinsic reward formulation for generating state representations for reinforcement learning, which is different from the existing state - free intrinsic rewards used in the state - of - the - art reinforcement learning methods 2 ) An exploration strategy to generate state representations that is more robust to agent actions than the existing intrinsic rewards 3 ) A learning strategy to learn a learned representation of a state from the observations generated by intrinsic reward using both observed and learned state trajectories from the observed trajectories 4 ) A set of experiments evaluating the performance of our method on tasks in the MiniGrid and tasks in two other environments ( e.g., Ant - v2 )."
SP:c002c20b5e8696588e029c0f65e88860418826c4,"This paper studies the problem of large - scale query - document retrieval using Transformer - based models. The authors study three types of paragraph - level pre - training tasks designed to train the Transformer embedding model : ( 1 ) Paragraph level query - level tasks ( ICT, BFS, Wiki Link Prediction ), and embedding models without Transformers ( WLP ). They compare the performance of the models on the tasks when compared to baseline methods such as BM - 25 ( token matching + TF - IDF weight ), BFP ( without Transformers ), WLP - WAE ( with and without BFP ). The main contributions of the paper are as follows : 1 ) The authors identify the key ingredients of learning a strong embedding - based Transformer model, which they use to train a query - based retrieval model ( e.g., query + return, paragraphs containing the answer ) for the ICT tasks ; 2 ) They show that with sufficient training on the three tasks, the retrieval model can learn to return candidates in time sublinear to the number of documents in the corpus ; 3 ) The retrieval model is shown to be highly efficient when it comes to returning documents in time based on the query size. The paper also shows that the transfer learning from query size to retrieval size is easier for the retrieval - based model compared to the baselines ( BFPT, Wiki - WLP, and BM-25 ).   The authors carry out extensive experiments to validate their findings and compare their models with other baselines. They also conduct extensive ablations of their models to verify their results. The experiments to confirm their findings."
SP:4e161e08a624f87633dfb49dfd46bd1665e15189,"The paper proposes bipartite graph convolution ( BP ) operation to replace graph pooling in hierarchical graph neural networks by eliminating pooling layers. BP is introduced in order to facilitate the transformation between input and output graphs of graph neural network ( GNN ) without parameterization. The authors argue that without BP, the representational hierarchy of GNN can be reduced to a set of non - parametrized pooling operations followed by expansion layers. They compare BP to early convolutional network architectures, which later have been replaced by more effective parameterized strided and transpose convolution operations in combination with skip connections. In the experiments, the authors demonstrate that the proposed BP operation is effective and comparable to the methods of skip connections and graph autoencoders. They also show that the general BiGraphNet formalism provides the modeling flexibility to build efficient architectures such as graph skip connections, and they evaluate the effect of BP on the performance of various GNNs."
SP:9b9b6ee9014e5538442ba76d6059ed01f59ec8fb,"Few - shot classification ( few - shot ) aims to recognize novel categories with only a few labeled images in each class. This paper proposes feature - wise transformation layers for augmenting the image features using affine transforms to simulate various feature distributions under different domains ( e.g., depth, width, and rotation ) during the training stage. The proposed method is based on the Metric - Based Few - Shot Classification ( MBC ) algorithm, which uses a learned metric function to classify query images into categories by comparing feature embeddings of query images with those of labeled images. The main contribution of this paper is to address the problem of few - shots classification under domain shifts for metric - based methods, where the feature distribution used to predict categories is different for each domain. In particular, the proposed feature-wise transformation layers are designed to use affine transformers to obtain feature distributions that are similar across all the different domain distributions. The authors further propose a learning - to - learn approach to capture variations of the feature distributions of the MBC feature estimator under different domain settings. The feature estimators are trained using a few datasets : mini -ImageNet, CUB - CUB, Places, and Plantae. Results demonstrate that the proposed proposed proposed feature -wise transformation layer is applicable to various metric-based models, and provides consistent improvements on the few -shot classification performance under the domain shift.   The authors conduct extensive experiments to validate the proposed features augmenting layer and to investigate the performance of the proposed method. The experiments are divided into two parts : ( 1 ) the feature augmenting stage, in which the feature features are augmented with the features from each affine transformation layer and ( 2 ) an exploration stage where the features are sampled from the affine transformations and used as feature features. The results show that the feature augmentation stage results in consistent improvements for the proposed augmentations compared to the feature feature feature augmentations during the feature estimation stage of MBC. However, the exploration stage results are not statistically significant compared with the original MBC training stage, suggesting that the features augmentations fail to generalize to unseen domains due to large discrepancy in feature distribution across domains. The manuscript also includes a detailed explanation of the features augmentation process, which explains the inconsistencies between the two stages of image augmentation and feature estimation. Finally, the manuscript also contains a detailed appendix with detailed experimental results and ablation results to evaluate the proposed methods."
SP:df46627cb984a56bba36d510bfc52e00751e9107,"This paper proposes a new type of convolutional network based on Lagrangian dynamics ( LDPs ) for fluid simulation. Unlike previous approaches, which use a graph structure to connect the particles and a set of continuous convolutions as the connections between them, this work proposes to use spatial convolutions instead of graph structures. The motivation is to be able to simulate different materials ( different materials can be thought of as states that are moving in time and space ) and different materials have different properties ( e.g. different densities of particles ). The main contribution of this work is the use of convolutions to represent the distances between particles in a different space and time. This is in contrast to previous approaches which used graph - based graphs to represent distances in time or space. The authors show that this approach is more accurate and faster than previous methods and generalizes better to different surfaces ( different surfaces can be imagined as different phases of the same fluid ). They also show that the proposed network architecture is robust to different materials and different settings and can be used for inverse problems.    The main contributions of the paper are the following : - A novel extension of N - D convolutions from the continuous domain to the LDP domain, which is based on a spatial convolution ; - A generalizes the convolutions proposed in this work to arbitrary collision geometries and uses them to represent different sets of particles in time, space and a differentiable mapping of the particles to their neighbors. - A set of experiments comparing the performance of the proposed by the proposed method to existing methods on a variety of different problems."
SP:3e17f333cf07183969c02bb66afdd3ccbf25bb19,"This paper proposes BatchEnsemble, an ensemble method whose computational and memory costs are significantly lower than typical ensembles. It achieves this by defining each weight matrix to be the Hadamard product of a shared weight among all ensemble members and a rank - one matrix per member. The authors also propose parallelizable across devices, where one device trains one member, and parallelizable within a device, where multiple ensemble members are updated simultaneously for a given mini -batch of size 4. Experiments are conducted on Split - CIFAR-100, Split - ImageNet which involves 100 sequential learning tasks, and lifelong learning on ImageNet - D.   The main contributions of the paper are as follows :   1. This paper proposes a new ensemble method for training neural networks, called BATCHEnsemble. The main idea is to parallelize the training of neural networks so that when it comes to testing, the number of networks does n’t tend to go to zero as it does when training starts from a single network. 2. In addition to the parallelization introduced in # 1, the authors also introduce a new update mechanism called BatchUpdate. The update mechanism is similar to the one used in # 2, except that it updates the updated weights of the ensemble members not the individual network weights. The updated weights are then used to update the predictions of the neural network members. This approach is quite simple and straightforward to implement. The only difference from the previous approach is that the update mechanism uses the updated weighted classifier instead of the updated weight of the network member. 3. This is the only change the authors make to the original approach. The rest of the changes are subtle and involve only a few steps of the training procedure. The major contributions of this paper are the following : 1. It proposes a method to train neural networks by using an ensemble of smaller size. This method is computationally and memory efficient and it only requires about 30 % of the total training time of a neural network to update its weights. This compares favourably to the previous method # 2. It also suggests a way of updating the weights in the ensemble that does not require the update of the weights of each network member during the update process. This last step is referred to as the “ automatic update ” step. The proposed approach is also compared with # 1 and # 2 in the supplementary material. The evaluation results for # 1 are very good and the comparisons with # 2 are very similar ( although the"
SP:a123a425ef3eb6188833d5a42e851bc3fa59df65,"This paper proposes a neural network - based PDE solver based on partial differential equations solver for forward and inverse problems where the solver is grid - free, mesh - free and shape - free. The method is based on PDEs such that the input to the network is a points set in an arbitrary domain, and the output is the set of the corresponding function values. The network is trained to minimize the deviations of the learned function from the strong PDE solution and satisfy the boundary conditions. The resulting solution in turn is an explicit smooth differentiable function with a known analytical form, which is then used to obtain the desired PDE. Unlike other numerical methods such as finite differences and finite elements, the derivatives of the desired function can be analytically calculated to any order. This framework therefore, enables the solution of high order non - linear PDPEs. The proposed algorithm is a unified formulation of both forward - and inverse - problem formulation where the optimized loss function consists of a few elements.   The authors demonstrate the method on several free shape 2D second order systems with application to Electrical Impedance Tomography ( EIT ), such as EIT diffusion and wave equations. They compare the proposed method with previous methods that unlike previous methods promote a strong solution, the current method is more flexible in the sense that regularizers are included as well to ensure that the regularizer can be tailored to specific problems."
SP:973d0ad0faadcf7298300f2758de9154205e7113,"This paper studies the problem of training SAT solvers on large binarized neural networks ( BNNs ). The main bottleneck that stops these solvers from being able to reason efficiently about large BNN is the architecture of the reasoners. The reasoners are trained to solve a set of SAT queries on a BNN of size $ \mathbb{R}^2 $, where $ R$ is the number of nodes in the network, $ \theta$ the dimension of the neural network, and $ \eta$ the weights of the connected nodes. The authors propose a number of changes to the training procedure and architecture of BNN to encourage the solvers to solve queries on smaller and more complicated networks more efficiently.   The main contributions of the paper are the following :   1 ) The authors analyze the architectural design choices of reasoners trained on BNN and compare them with existing solvers trained on other networks. They show that the choice of solver architecture and training procedure, as well as the amount of iterations required for each solver, affect the performance of the proposed method. 2 ) They propose a reduction in the training step size and training step length to train the solver on smaller networks. 3 ) They conduct extensive experiments to compare their proposed method with existing methods and show that their method outperforms them on a variety of datasets."
SP:ca985e758f195bd04fb9f24b290a83974d6d308b,"This paper studies the expressive power of graph neural networks ( GNNs ) falling within the message-passing framework. The main results are as follows :    - Graph neural networks are shown to be Turing universal under sufficient conditions on their depth, width, node attributes, and layer expressiveness. - Second, it is discovered that graphs can lose a significant portion of their power when their depth and width is restricted. - A new technique that enables the repurposing of seminal results from distributed computing and leads to lower bounds for an array of decision, optimization, and estimation problems involving graphs is introduced, leading to impossibility statements for several tasks that are deemed impossible without the product of a GNN.   Third, the dependence of the GNN on the accuracy of the approximation used is examined and revealed to be significant even for tasks that appear simple or when considering approximation."
SP:a98ae70a91850bbe624c307ba61d3daeb2494b82,"This paper proposes localised generative flows ( LGF ), a generalization of flow - based generative models based on continuous bijections. The authors argue that such models are limited in their ability to learn target distributions with complicated topologies, and propose a simple variational scheme to approximate the log likelihood of the target distribution. The method is called Localised Generative Flows and it is composed of stacked continuous mixtures of bijection which enables each bijection to learn a local region of a target rather than its entirety. The experimental results show that the proposed method outperforms GFLs on a variety of density estimation tasks.    The main contributions of the paper are as follows :   - A generalisation of flow based methods that can be used without modification as the basis for an LGF model. - A method to approximate target distributions of a generative model by using continuous mixture - of - generative - flows, which is claimed to yield better performance than other methods ( e.g., GFL, GFP ). - An empirical study of the performance of LGF on a range of different tasks, which shows that it yields similar or slightly better results than the other methods tested ( GFL and FPGA )."
SP:3adc341dece170f428195e4dccadfb5f5daddf2d,"This paper studies the problem of interpretability of vision - language - language navigation ( VLN ) in unseen testing environments where the goal is to train a neural agent to navigate to the desired target locations in an unseen environment from the agent's point - of view. The paper proposes two exploration strategies to investigate the possible explanations for the observed performance differences between trained and tested unseen environments of VLNs trained on seen and unseen data. The first strategy is to use the same baseline and training setup as in the baseline study, i.e., the agent is trained with the same language model and the same navigational instructions, and the target location is navigated to by following the same instructions from the language model. The second strategy is exploration - based strategy, in which the agent explores the environment in search of the target locations and the goal, and uses the same    language - guided navigation to guide the agent to reach the desired locations. The explored semantic features ( e.g., features that the agent learns to associate with the environment that is similar to the one it is trained in ) that are different from the ones that are present in the training environment but identical in the tested unseen environment are investigated to see if they also affect the performance of the agent. The experimental results show that the exploration strategies that the paper proposes to investigate could be helpful for the agent in the seen - unseen testing environment but not the training - unseen environment. The experiments are conducted on three datasets ( R2R, R4R, and CVDN ) and achieve competitive unseen results compared to previous state - of - the - art results on seen - and - unseen datasets using the baseline model and training method. The authors propose three exploration strategies ( language exploration, environment re - splitting, and environment - based feature replacement ) to explore the possible explanation for the performance differences in the unseen tested environments : 1 ) explanations for environment bias ( explanations based on language - based explanations, 2 ) explanation based on environment / language bias, and 3 ) possible reasons for the unexplained performance differences ( although there is no evidence for any of these explanations, the experiments show the agent still performs much better in the visited and unseen environments when compared to the trained and trained environments.   The paper is well - written and well - structured, and most of the explanations are well - researched and related to the proposed exploration strategies. However, the novelty of the paper is limited, and some of the claims are not supported by the evidence."
SP:298e0043e99f586d314fbd9d16fdc6ae885e1ebb,"This paper proposes an approach for Deep Reinforcement Learning ( DRL ) in which humans observe ( and assess ) a DRL agent interacting with the environment and provide feedback to the agent via event - related electric potentials ( EFP ) measured using electrodes placed on the human scalp. The implicit feedback is then used to augment the agent's learning in the RL tasks.   The paper proposes two different frameworks to combine recent advances in DRL into the error - potential based feedback system, namely ErrP - DRL and ErrP + Human. In the first framework, using an EEG - logged observer as a surrogate feedback source, the paper proposes to capture EFP signals from the human observation and use them as an auxiliary reward function to a trained DRL algorithm with the intent of accelerating its learning of the game. The second framework builds on top of the baseline idea of capturing error - pots ( generalizes error - potentials across different Atari games ) using an electroencephalogram ( EEG ) cap, and then decoding the signals appropriately and using them as auxiliary reward functions to train the agent. The paper also proposes a method to obtain and accurately decode the implicit human feedback ( specifically error - related event potentials ) for state - action pairs in an Atari - type environment. The experiments are conducted in two Atari games, one where the human observer observes the agent in one game and another where the agent plays the observer in another game, and cover a range of settings varying between the two games. The results demonstrate that both methods can be used to train an effective policy in both settings. Finally, the method is applied to training DRL agents in several Atari games ( varying the number of players and difficulty levels ), and the results are evaluated using simulated and real data from the Atari games. In addition to the experiments in the first experiment, the authors also conduct a series of experiments in a second setting where the humans observe the agent while playing the Atari game in a different environment ( varying from a baseline of vanilla DRL to a higher - level DRL setting ). The simulations show that the proposed method is effective in both controlling the learning rate of the policy and the agent ’s learning rate. Finally the authors conduct extensive experiments in four Atari games to validate the effectiveness of their method."
SP:a8395f8b877e1eebaef9ff2e8b4e488d55a74ef4,"This paper proposes an approach to estimate the minimal entropy ( aka information entropy ) required in order for classifiers to provide correct classifications for samples from a dataset of image classifiers ( humans and machine - based classifiers ). The idea is to use the notion of entropy as a metric that allows to combine and compare the effects of various types of reductions ( e.g., crop, colour reduction, resolution reduction ) on classification performance, in turn generalising similar methods explored in previous works. The paper proposes two complementary frameworks for computing the minimal - entropy positive images of both human and machine classifiers : ( 1 ) Based on the proposed laconic classification framework, the first computes an approximate minimal entropy positive image for each classifier for which the classifier provides a correct classification, becoming incorrect upon any further reduction in the information entropy ; ( 2 ) Combining the two frameworks, the second computes a set of approximately correct classifiers for each machine classifier and human classifier, corresponding to the corresponding minimal entropy - positive classifier in each case. The method is evaluated empirically using the ILSVRC - COCO test - set and compared with other methods ( such as colour reduction and resolution reduction, as well as reduced resolution for humans ) with the goal to minimise the amount of information required in individual test images to maintain correct classification. The experiments show that the proposed method outperforms other methods in terms of accuracy and accuracy with respect to the number of classifier error bounds, and also achieves higher accuracy for machine classifying error than it does for humans. The main contributions of the paper are the following :    1 ) Prop. 1. Prop. 1 : The proposed method is a novel way to understand and compare image classifier performance 2. It generalises similar methods from previous works 3. Prop. 2. In particular, it proposes a method for computing a classifier ’s error bounds 4. The second contribution is to provide an approximate loss function 5. This loss function allows to distinguish between correct classifier errors and incorrect classifiers ‘ error ’ ( for example, between a classified image and an image that is likely to be seen as ‘ contaminated ’ by unseen colours or textures due to colour reduction or other than the one used to classify the image. The classifier uses this loss function to compute a loss for each image to distinguish representations that are likely contaminated with such ‘ corrupt colours.   The paper also includes experiments comparing the proposed loss function with other loss functions from other"
SP:81cec8f907d8fa0653b5bc08af1f59bfefd49619,This paper studies the robustness of deterministic lossy compression algorithms for neural network deep learning under instability assumption. The authors identify a family of defenses that are based on the instability assumption and the randomized perturbations to the input that all lead to similar gains in robustness. They provide a comprehensive experimental analysis of when and why perturbation defenses work and potential mechanisms that could explain their effectiveness ( or ineffectiveness ) in different settings. The main contributions are : 1 ) A comprehensive analysis of the dynamics of perturbational defenses for neural networks with deterministic LLL and randomized LLL. 2 ) A set of experiments that compare the effect of using one or more of these defenses against adversarial examples from the literature. 3 ) An analysis of why the defenses work ( and when they fail ) and a set of strategies that could improve upon the defenses.   The paper is published with supplementary material and is available for free online.
SP:a136b98e0ed478144ce9dd26e2b6d611543124e8,"This paper proposes a self - supervised learning method for 3D object detection using a 3D feature mapping network. The network maps 3D features from input 2.5D color and depth images to the features extracted from 3D visual recognition ( feature maps of the scene, by disentangling the scene content from the motion of the camera ). View prediction is the ability to make predictions about how a scene would look like from an alternative viewpoint. This paper proposes to learn view prediction by predicting observations at various levels of abstraction. The learning is done in two stages. First, the model is trained using supervised learning. This stage is designed to be able to handle 3D moving object detectors. The second stage is the learning stage that uses the predicted feature maps.   The main contribution of this paper is the use of contrastive learning to learn the features of a 2D input from a moving camera. This is done by projecting the 2D feature maps into the 3D space using a feature extractor network, and learning the feature maps with the predicted features. The feature extractors are trained to match the features produced by the feature map from the camera. The main contributions of the paper are the following :   ( 1 ) The proposed method is shown to significantly improve the performance of object detectors trained with self supervision. The improvement is especially noticeable in the case when the objects are stationary, which is more likely due to the fact that the camera moves a lot ( up and down during processing ). ( 2 ) The method is also shown to increase the accuracy when the camera is moving fast ( faster than the average of the frames in a scene ). The experiments show that the method leads to a reduction in the number of false positives and false negatives, and that it leads to better performance on object detection tasks when the false positives are higher than the true positives."
SP:6fd61604a2eeb8a2cbbda6c40807cebef6d40f2f,"This paper studies the problem of unsupervised domain translation ( UDT ), which consists in finding meaningful correspondences between two domains without access to pairings between them. It builds upon the CycleGAN model of Zhu et al. ( 2017a ) ( which has led to extensions for many applications and has given impressive results ) and aims to understand and study this successful approach as there remains little theoretical understanding of why these models work. The authors define UDT in a rigorous and non - ambiguous manner to explore the implicit biases present in the approach and demonstrate the limits of the approaches. Specifically, they show that mappings produced by these methods are biased towards low energy transformations, leading them to cast UDT into an Optimal Transport ( OT ) framework by making this implicit bias explicit. This allows them to provide theoretical guarantees for existing methods, such as providing a link between the dynamic formulation of OT and CycleGAN, to solve UDT problems where previous methods fail. Finally, they propose a simple approach, called Simple UDT, which is a dynamical regularizer to regularize UDT models in this context and its dynamical formulation, based on optimal transport theory, to overcome shortcomings of CycleGAN - like models.   The main contributions are the following :   1. Assuming the outputs uniquely define the weights up to invariants of the model ( assuming the weights are not currently shown to be intractable ), the authors theoretically show that the optimal mapping function satisfying the objective is expected to be small 1. This is in contradiction with the empirical results from the model and shows that there must be an implicit bias towards well - behaved mappings. 2. Using Optimal transport theory as a regularizer, they build a model which regularizes the model to be more robust against this bias. 3. Using this model, they derive a simple solution to the simple UDT problem, and illustrate its capabilities in two distinct settings : 1. Given pairs of elements from two different domains, domain translation consists in learning a mapping from one domain to another, linking these paired elements together and 2. Providing the mapping is easier, but some ambiguity remains : For example, when translating photographs to paintings, instead of preserving the content of the input, may want to preserve the same color palette? No mapping can solve both problems : What is the right notion of complexity to explain this convergence? Can we steer the model toward a certain task?   This paper first rigorously defines the problem and further bridge the gap between practice and theory by unambiguously defining the UDT"
SP:8bb3ce11ad773685f6e41d90db3e7a5481e5ba47,"This paper proposes a new regularization method, RotationOut, for neural networks. Different from Dropout that handles each neuron / channel independently, R rotationout regards its input layer as an entire vector and introduces regularization by randomly rotating the vector. The proposed method can also be used in convolutional layers and recurrent layers with small modifications. The authors also use a noise analysis method to interpret the difference between Rotation out and Dropout in co -adaptation reduction and show how to use Rotationout / Dropout together with Batch Normalization. Extensive experiments in vision and language tasks are conducted to show the effectiveness of the proposed method."
SP:37620ae8dc5683eb2843792e0aa4cbe6cba366f7,"This paper proposes a method to create UAPs ( Universal Adversarial Perturbations ) in a data - free setting, where the original training data is unavailable for crafting adversaries. The method is based on a sequential optimization of the adversarial perturbation with the proposed dilate loss. The Dilate loss basically maximizes the Euclidean norm of the output before nonlinearity at any layer. It constrains the ReLU activation function at every layer to act roughly linear for data points and thus eliminate the dependency on data for crafting ReLU activations. Extensive experiments demonstrate that the proposed method not only has theoretical support, but achieves higher fooling rate than the existing data -free work in some limited data cases.   The main contributions of this paper are as follows :   1. The authors propose a method ( Dilate Loss - UAP ) to construct UAP in an adversarial setting where the adversary generation with full training data can be approximated with a formulation approximated by a formulation without data. The main idea is to perform gradient ascent as a prior art in adversarial training to obtain an upper bound on the adversary gradient that can be used to approximate the lower bound of the gradient of the corresponding UAP with data. 2. This method is evaluated in two different settings : ( 1 ) in the limited data setting ( e.g., limited data vs. no data ), and ( 2 ) in data - rich / abundant settings ( where data is available but not abundant ). The experiments are carried out to demonstrate the effectiveness of the method and to obtain the upper bound. 3. The major contributions of the paper are the following : 1. First, it proposes a novel way to train adversaries by performing gradient ascent using the dilate perturbations ; 2. It shows that the method is robust to the choice of adversarial weights used to train the adversaries."
SP:2fd7d5507a8727db743dc89379a6f021d31ed39a,"This paper proposes a meta - learning - based transferable neural architecture search method ( T - NAS ) to tackle transferability issues in artificial neural network ( NAS ) and fast adaptation to new tasks. The authors focus on the transferability issue because most existing NAS methods only apply to a single task at a time and do not consider the possibility of transferability for datasets with multiple tasks or datasets with different datasets or architectures. To tackle this issue, they propose a method where the architecture for a new task is either searched from scratch, which is neither efficient nor flexible enough for practical application scenarios, or borrowed from the ones searched on other tasks, which might be not optimal. The main contribution of this paper is to propose T - TANet - NAS, a method that applies the learned meta - learner ( from meta - training ) to a task on which it is assumed that the architecture is suitable for the specific task, and transfers that architecture to the new task through a few gradient steps with minimal additional cost. Experimental results show that the proposed method achieves state - of - the - art performance in few - shot learning and comparable performance in supervised learning but with 50x less searching cost, which demonstrates the effectiveness of the method.    The main contributions of the paper are the following : 1 ) The authors propose to use meta - learners to learn a neural architecture that is flexible and transferable enough to handle multiple tasks at the same time, and 2 ) The method uses gradient descent to learn the architecture at each task using only gradient steps to ensure that the transferred architecture is similar to the one used for the original task. The method is evaluated on four tasks and applied to three of them, and it transfers the architecture from one task to the other three with comparable or slightly better performance ( on average return on average on each task ). The results demonstrate that the method transfers architecture from task to task with minimal amount of additional gradient descent steps and that the neural architecture transferred from task is similar or better than the one learned from task on average."
SP:1314a79ba12474adb33ff31b3cb22bed25b94fb7,"This paper proposes a stochastic neural network ( SNN ) architecture for discriminative learning, named SE - SNN, which is simpler to implement and faster to train than SNNs and achieves state of the art results on network compression by pruning, adversarial defense and learning with label noise. This paper directly models activation uncertainty by directly modeling activation uncertainty and encouraging high activation variability.   The main contributions of this paper are the following :   1. The authors propose a simple, effective and easy - to - implement stochastically - parameterized learning paradigm, named SNN - VIB ( Variational Information Bottleneck ), which extends dropout, the variational information bottleneck ( VIB ), noise regularized learning and dropout variants of neural network variants of dropout. This paradigm is used to train SNN and achieves better generalization, network compression and robustness against adversarial attack and label noise than the existing SNN variants. 2. It is possible to train a SNN with VIB by training the latent variable activations of the VIB activations independently of the weights of the corresponding activations in the dropout and VIB variants. 3. It achieves state - of - the - art results for the network compression metric on the PCA task, which measures the average log - likelihood of a given input $ \mathbb{R}$ and output $ \text{L}$.   3. For the experiments, the authors used the following experimental results : 1. VIB - based SNN is easier to train and implement ; 2. The activation uncertainty model is more plausible ; 3. Dropout training is faster and more plausible. 4. Label noise is robust ; 5. The experiments compare favorably to the SNN model."
SP:bd4935d4fcf33f60f22e0f2fd9f7dc8ddfab6d17,"This paper proposes a meta - learning algorithm for generating curious behavior. The algorithm is based on the idea that curiosity is a mechanism found by evolution that encourages meaningful exploration early in an agent ’s life in order to expose it to experiences that enable it to obtain high rewards over the course of its lifetime. The paper proposes to use pieces of code similar to those designed by humans in ML papers to meta - learn algorithms. To this end, it combines neural networks with other building blocks such as buffers, nearest - neighbor modules and custom loss functions. The proposed algorithm, called Curiosity Algorithm, is designed to work on par or better than human - designed published curiosity algorithms in domains as disparate as grid navigation with image inputs, acrobot, lunar lander, ant and hopper.   The main contributions of this paper are the following :   1. It proposes an algorithm that performs standard reinforcement learning using the adapted reward signal while exploring a space of curiosity mechanisms that dynamically adapt the agent’s reward signal. 2. It uses the same neural network weights as in [ 1 ] to generalize the generalization between very similar tasks. 3. It provides a rich language of programs that allows the evaluation of the proposed algorithm."
SP:6dff0f3a84809ae0ba9f58f36303597f1ba6dcc5,"This paper proposes a new method for generating code snippets for the Any - Code - to - Code Generation ( AnyC2C ) task, which is based on the Structural Language Modeling ( SLM ) approach. This approach leverages the strict syntax of programming languages to model a code snippet as a tree, and estimates the probability of the program ’s abstract syntax tree (AST ) by decomposing it into a product of conditional probabilities over its nodes. The authors present a neural model that computes these conditional probabilities by considering all AST paths leading to a target node with respect to the paths corresponding to generating expressions in the target language under the assumption that the tree contains all paths that would lead to a valid expression under the target target language. Unlike previous approaches ( Seq2seq and SequentSequence2seq ), which treat code snippets as sequences, this approach does not leverage any structural information in the syntax of the programming languages used to generate the code snippets, and leverages only the syntactic structure of the source code to generate expressions.    The main contributions of this paper are the following :   1. The introduction of a language modeling approach based on SLM that decomposes the syntax tree into a probability distribution that estimates the program's probability of generating expressions under a target language using the decomposition of the abstract syntax trees. 2. A neural network based on which the probability distribution over the nodes of the tree is derived. 3. A variety of experiments comparing the performance of the proposed approach with the previous SEQ approaches, showing that SLM outperforms them both in terms of accuracy and number of expressions generated. 4."
SP:7fc60d6fd1cfcc135c34f9664d172d3fd1c0ae0a,"This paper studies non - convex optimization for learning large - scale neural networks ( NNs ) using gradient descent methods. To this end, it introduces the so - called canonical space, a theoretical tool that allows to study the relationship between the objective functions of gradient descent in learning NNs with the canonical model space, the original NN model space and the canonical representation of the gradients between them. This space is represented by a pointwise linear transformation, which is defined as a matrix of $ L_0 $ disparity matrices. The paper shows that the gradient descent algorithms surely converge to a global minimum of zero loss provided that the disparity matrixes maintain full rank. Furthermore, the learning of large NNs behaves in the same way as learning of small NNs.    The main contributions of this paper are the following :   1. The authors introduce the theoretical tool canonical space and prove the following results with it : 1. A function of the canonical space can be viewed as a set of points in the space of all possible functions of the neural network ( e.g., the weight vector between any two neurons in the network, which can be represented as a weighted sum of two vectors ). The gradients in this function correspond to functions of weight vector f, where f is a weighted average of the weights of neurons in both the canonical and the original neural network. The gradient descent algorithm can be thought of as a procedure that applies f different gradients to different points in f to obtain a new weight vector. 2. Gradient descent algorithms can then apply gradient descent to these new weights using the same set of gradients, but with a different set of gradient updates. The main difference is that gradient updates can occur between the updated weights of the updated gradient updates and the gradient updates of the original weights. 3. The convergence result of the paper is the convergence of all gradient updates using the updated weight vectors and gradient updates with respect to the new weight vectors, where updated weights correspond to a new set of $ \tilde{L_0}$ matrices, where $ l_0$ is the difference between the gradient of a neuron in the updated vector and its weights in the original vector. The new weight matrices can be obtained by running the gradient update algorithm using the new weights from the updated neural network and the updated canonical space. The experiments show that the convergence does not deviate too much from the convergence rate of the previous work, and most of the time converges with a lower bound of $ 0$.   4. In particular, the paper focuses on the case when the dataset size is large enough that the variance matrices have a singular number of neurons. This is done by showing that there is a low chance that the dataset will have singular distributions of neurons, but higher chance that there will be distributional distributions of"
SP:78a536138570fe9b5d88350e4b16d598a7db1fe0,This paper investigates interactive graph - based segmentation algorithms that enforce connectivity. It introduces instance - aware heuristics and a class - aware ILP formulation for graph segmentation. The paper also presents competitive semantic ( and panoptic ) segmentation results on the PASCAL VOC 2012 and Cityscapes dataset given initial scribbles.    The main contributions of the paper are as follows :   - A new instance aware heuristic of a discrete Potts model is introduced to ensure connectivity between nodes in the target graph. - A class - informed ILP formulation is introduced for Graph segmentation to ensure global optimality of the proposed algorithm. - The paper presents a set of experimental results that demonstrate the effectiveness of the instance aware algorithm and the ILP - based heuristic for improving the segmentation accuracy.
SP:2eb90879ddbc39b6b5c05152784d6044d1940513,"This paper proposes a new adversarial defense for image classification based on gradient - based saliency models. The authors argue that the current state - of - the - art gradient saliency method, while effective for classifying images, is ineffective as a defense against adversarial perturbations caused by the presence of adversarial examples. To address this, the authors propose to use a learnt saliency model to estimate the shift in the saliency due to perturbation of the salient features of an image with the help of a map showing the difference between the image's salient features and the ones produced by the adversarial example. The key idea of the defense is to train a CNN that distinguishes between adversarial images and natural images using salient pixels as its input, and also proposes a novel defense that uses the learnt model to detect images generated by strong adversarial attacks such as C&W and DeepFool. The defense is evaluated on MNIST, CIFAR-10, CIFAAR - 10 and ASSIRA and compared to a baseline baseline using the same model but with the learned saliency map removed, showing that the proposed defense does not only improve on using the map but also outperforms the baseline defense using the learned model alone.   The main contributions of the paper are the following :   1. Demonstrating that the learnt learnt models can capture the shifts in the salient feature features of images that are caused by perturbing examples of images generated from the image classifier while also having a low computational cost. This allows the learnt models to be used effectively as a real - time defense. 2. Proposing a novel adversarial image detection method, which uses the learned learnt models and a CNN to detect examples generated by the defense."
SP:fe5510d05ff091a5f133f2dbcd1b23d8d58d2c3e,"This paper studies the robustness / accuracy trade - off between local and global adversarial robustness for machine learning models. Specifically, the authors consider the problem of computing the probability that its prediction at any point sampled from the ( unknown ) input distribution is susceptible to adversarial attacks, assuming the model is valid and the input is from the known distribution. Global robustness is defined as the sum of the expected loss at each point in the input distribution over the set of possible attacks that could have come from the adversarial examples.   The authors first consider the literature on global robustness of local robustness ( LUS ), which is the property that guarantees that any point in any input distribution sampled from a trained model that is not already adversarial susceptible to attack is not less susceptible than any other point in that distribution. They show how to compute LUS by using a concentration inequality, which allows them to compute the upper bound on the estimation error of the global Lipschitz constant with respect to the training distribution ( $ \mathbb{R}^2 $ ) of the attacks on MNIST, Fashion - MNIST and CIFAR-10 trained with stochastic gradient descent. The authors then provide statistically sound analysis of the robusts / accuracies for a variety of neural networks architectures and training methods, using techniques from the literature. They observe that robustness and accuracy tend to be negatively correlated for networks trained via stochastically gradient descent and with iterative pruning techniques, while a positive trend is observed with a trained network trained with MMD. Finally, they provide empirical evidence that positive accuracy is more robustness while negative robustness indicates that network is more vulnerable to attacks."
SP:8f5616a1480b68c04b496ed498d237d5a7e87794,"This paper proposes Wasserstein distance as a new measure of disturbance to measure the reference transition kernel in Robust Robust Residual Learning ( RobustRL ). The motivation of the paper is that the existing Robust RL algorithms are not robust enough to the current state or simulated environmental parameters in a heuristic way, which is why they do not provide quantified robustness quantified to the system dynamics. To overcome this issue, the paper proposes to use the distance between the reference kernel and the state in the infinite - dimensional optimization problem reduced to a finite - dimensional risk - aware problem.    The main contribution of this paper is the introduction of the concept of Wassersteins distance and how it can be used to connect the transition kernel disturbance to the state disturbance in a reduction problem to a lower dimensional risk aware optimal Bellman equation. The paper shows that optimal robust policies exist for Robust LSTM and proposes a method to obtain them. The authors also provide a sensitivity analysis for the perturbations used in the proposed method and show the effectiveness of the actor - critic ( WRAAC ) algorithm proposed in the paper. The main contributions of this work are the following :   1. The introduction of a novel method for obtaining quantified and quantified measures of the disturbance of the reference kernels in the Robust RSTM learning algorithms. 2. The use of the distance measure between reference kernels and state disturbances in the corresponding transition kernel to obtain quantified estimates of the transition probability. 3. The application of the measure of the disturbances to the optimization problem reduces it to a risk aware risk aware Bellman problem. 4. A weighting analysis is provided that shows the sensitivity of the perturbed states to the disturbance measures used to obtain the transition probabilities."
SP:d85963f5f0f6b20cf08f2a7c169ae33a45db7de2,"This paper proposes a method to obtain mixed strategy Nash equilibria in multi - player continuous games by using the pushforward measure technique to represent a mixed strategy in continuous spaces. The continuous ones are treated as a special case, and the pure strategy always exists in the continuous case. The authors generalize the Gradient - based Nikaido - Isoda ( GNI ) to represent the distance between the players ’ joint strategy profile and a Nash equilibrium that is shown to converge to a stationary Nash equilibrium under the assumption on the payoff functions, the same popular setting as in previous studies. They use it to approximate Nash equilibrium for quadratic games, general blotto games, and GAMUT games. The experiments compare the performance of the proposed method with other methods that are based on Nash equilibrium, and show that the method consistently outperforms the other methods.   The main contributions of this paper are the following :   1. A new continuous strategy Nash equilibrium framework is proposed to approximate a mixed Nash equilibrium in continuous games using the Pushforward Measure technique. The main idea of the framework is to assume that the players always play according to the same strategy distribution, and that the pure ones are always included in the mixed strategy equilibrium. This assumption is motivated by the fact that pure Nash equilibrium has been shown to exist only for games where the strategy distribution is not continuous. 2. Using the generalization of GNI, they obtain mixed equilibrium for continuous games that is consistent with the one obtained in previous works. 3. They test their method on three games, where they find that the mixed equilibrium results in lower variance ( lower variance ) and higher variance ( higher variance in the Nash equilibrium."
SP:280d85cd8164a268f9d496ae5f17189c50f30dc1,"This paper proposes a method to augment training data for text classification using natural language explanations ( NL explanations ) for NLP tasks using deep neural networks ( DNNs ).    The authors note that while deep NLP relies on labeled data for most of its applications, there are scenarios where data annotation is expensive and natural language ( NL ) explanations can be useful additional supervision. However, directly applying them for augmenting model learning encounters two challenges : ( 1 ) NL explanations are unstructured and inherently compositional, which asks for a modularized model to represent their semantics, and ( 2) NL explanations often have large numbers of linguistic variants, resulting in low recall and limited generalization ability. The authors propose to transform NL explanations into executable logical forms by semantic parsing, NExT, and semantic parsing with transforming annotations into executable forms for labeling data instances, which substantially increases the coverage of each NL explanation. The resulting framework, dubbed Natural Language Explanation Transformer ( NT ), is tested on two tasks ( multi - hop question answering ) and achieves performance gain with light annotation effort compared to baseline methods ( NLP, DNN ). On one task, NT shows superiority over baseline methods, while on the other it extends its extension to multi - Hop question answering with the help of NL explanations. On the second task, it shows performance gain and improvement over the baseline methods on a set of four tasks ( e.g., multi - lingual question answering, drug discovery, drug distribution prediction, machine translation, and drug discovery ), which are all tasks that use NL explanations for training data. The NT is evaluated on both DNN and text classification tasks and compared with two baselines ( NL explanation - based and model - based methods."
SP:a9b5f7257dedd719cfe341fca275776734af1d98,"This paper extends the formal verification of machine learning models to recurrent neural networks ( RNNs ) and recurrent neural network architectures. More specifically, this paper verifies the robustness of the classifier for misclassification under perturbations of the input features. This is done by using the verifiably robust training method of [ 1 ], which verifies that the output of a language model always produces sentences of bounded length. The authors extend the formalism of this verification method to more complex specifications, such as requiring that a robot periodically visits a charging station or that the model produces a set of bounded - length sentences. They show that while models trained using standard training often violate desired specifications, their verified training method produces models that can be shown to be provably consistent with the specifications. They also show that the training method is robust to adversarial attacks on the labels."
SP:3903680e07b676409e3cf6a1044b67291fe38630,"This paper proposes a regularization method for reinforcement learning based on visual domain randomization ( VDN ), where at the start of each training episode some visual aspects of the environment are randomized so that the agent is exposed to many possible variations. However, this method is inefficient as it may lead to policies with high variance across domains. To address this issue, this paper formalizes the VDN randomization problem as a KL - regularization problem and minimizes the policy ’s Lipschitz constant with respect to the randomization parameters, and proposes a method to regularize the learned state representations of the agent during training to minimize the variance in the learned policies. To do this, the paper proposes to only train the agent on one visual variation of each environment ( e.g., only on the blue background ) during training, and regularize its learned representations during inference to ensure that it is at least as accurate as possible. The paper presents experiments that demonstrate that the method is more efficient and robust to robust learning than standard VDN - based policy randomization while achieving equal generalization scores.    The main contributions of this paper are the following :   1. This paper proposes an approach for regularization of the KL - based randomization method to address the inefficient nature of the method as a method for tackling the challenge of generalizing to visually different environments in reinforcement learning. The authors formalize the problem of VDN in the following way : 1. They propose to use the same set of parameters ( $ \mathcal{L}$, $ \theta_p(L_\theta)$ as in the case of standard randomization, but change the parameters of the L_t operator in the policy gradient estimator to a fixed ratio of $ \Delta_p(\Delta_t ) \to \eta_t$. 2. They show that this regularization technique is more effective than randomization when the number of variations of the domain is small ( less than $ \epsilon$ ). 3. The method is tested on a suite of tasks where the goal is to generalize to a diverse set of environments, and the experiments show that the proposed regularization leads to more robust learning and robust policies."
SP:c79046dc56b9ee9c926f87386046422ea134ae8d,"This paper proposes a new approach for updating the Deep Metric Learning Model ( DML ) in terms of imbalanced data pairs. The authors cast DML as a pairwise binary classification problem ( PBDPM ), which is defined as a set of pairs of examples that are classified as similar or dissimilar based on their similarities or similarities with respect to each other. A distributionally robust optimization ( PDO ) approach is used to estimate a robust loss for pairs that are imbalanced in the set of examples when updating the model. In the experiments, the authors show that their approach leads to better performance than the previous approaches that design complicated losses or use hard example mining.    The main contributions of this paper are the following :   1 ) A new approach to update the DML model using PDO for imbalanced pairs ;   2 ) A simple and effective way to estimate the robustness of the pairs in a batch of data for each update of the model ; and 3 ) A dual variable approach to handle uncertainty in the uncertainty of the classifications in the dual variable setting of the PDO."
SP:38420928e40ef80c0136ad607b9275f9ab1e0769,"This paper proposes a stochastic stochastically - parametrized estimator of the local minimum in non - convex finite - sum minimization ( FSM ) based on the trust region method with inexact gradient and Hessian estimation. The authors prove that the estimator is robust to $ \sqrt{O(1/k)$, as long as the gradient estimator $ \theta \in \mathbb R^k$ is accurate. Combining this estimator with the Hessian estimator, the authors propose a novel estimator that is more parametric than the one used in the original Trust - Region Method ( TRM ) and improves the convergence rate of the TRM by a factor of $ O(1 / k)$. The authors also propose STR, which is a parametric estimator for the locally - approximated local minimum within the FSM setting. The main advantage of this approach over the existing methods is that it is parametric, meaning that it does not rely on assumptions that are not present in the underlying TRM method, such as the assumption that Hessian estimates are inaccurate. Finally, STR is Hessian - free, which the authors claim achieves the lowest runtime complexity. Experiments are carried out to verify the theoretical conclusions and the efficiency of the proposed algorithms.   The main contributions of this paper are as follows :   1 ) The authors develop and validate the estimators used in TRM and STR. The experimental results are compared with the state - of - the - art. They show that the obtained estimators are parametric and parametric for the SSM setting, and that the parametric results are better for the STR setting. 2 ) They compare the performance of their estimators with other methods that do not use Hessian oracle queries, and show that STR is the most parametric."
SP:28a35b70b5e6915af28cacebc4ea50690c9534af,"This paper proposes Farkas layers, a training method that ensures at least one neuron is active at a given layer in each layer of a neural network. It is motivated by the observation that the training capacity of networks trained with ReLU activations degrades as the number of active neurons increases, and the goal is to reduce this effect. To this end, it adopts ideas from linear programming, where the goal of each layer is to maximize the sum of the activations of neurons at each layer. The authors propose to use elementary results from ReLU activation as the primary input to a linear program, and use the results as input to the outer layers of the network to compute the activation of the layers at each neuron. This outer layer is then used to update the weights of each neuron at the layers below to ensure that each neuron has the same number of activations. The method is tested on a range of network sizes ( ReLU - trained on MNIST, CIFAR-10, MNIST - FS, and Movielens - UCFNet ), and compared with methods such as batch normalization, appropriate weight initialization, and method of initialization. The results show that the method generally outperforms the methods of Batch Normalization ( BN ) and Adaptive Weight Estimation ( AWE ) in terms of training capacity w.r.t. of ReLu activations, even when the network sizes are small ( a few neurons per layer ). However, it does not outperform AWE when training larger networks ( 1000 or more neurons. In addition, the method is not computations - agnostic."
SP:1d325b148e3efe407241c1f1cbe8d17400499741,"This paper provides computationally efficient robustness certificates for deep classifiers with differentiable activation functions for adversarial training of classifiers trained with adversarial examples. The robustness certificate defines the distance between a given input and the decision boundary of the classifier ( or its lower bound ). For any perturbation of the input with a magnitude smaller than the certificate value, the classification output will provably remain unchanged. This paper shows that if the eigenvalues of the Hessian of the network ( Curvatures of the Network ) are bounded, a robustness computation in the l2 norm can be computed efficiently using convex optimization. In addition, the authors also derive a computationallyefficient differentiable upper bound on the curvature of a deep network to boost its certified robustness against adversarial samples. The authors combine these two steps in two steps :   1. The first step is to train a network to be robust with eigenvalue - bounded Hessians.   2. The second step is the training step. During training, the network trains a classifier to be more robust than a baseline classifier. The classifier is trained to be at least as robust as the baselines on which the baseline classifiers are trained. The training is done in two stages : during the training phase ( called CRT training ) and during the post - training stage ( called CTR training ). During the CTR phase ( after the training has finished ), the classifiers will be re - trained using the CRT results. The trained classifier will be used in the final training of the discriminator. Results show that the proposed robustness methods ( CRT and CTR ) lead to improved robustness over baselines, and that the robustness of the base classifiers improves over time."
SP:33f6f5aa0d4655e5d75fe612e0eff05e579d45c5,"This paper proposes a method for compressed sensing recovery based on deep generative models. The method is based on the recently proposed Deep Image Prior ( DIP ) approach, where the convolutional weights of the network are optimized to match the observed measurements. The main contributions are :    ( 1 ) A novel learned regularization technique, which incorporates prior information on the network weights. This reduces reconstruction error, especially for noisy measurements. ( 2 ) A moderately overparameterized single - layer networks trained on the DIP optimization approach can perfectly fit any signal despite the nonconvex nature of the fitting problem. ( 3 ) A theoretical result provides justification for early stopping.   The main contribution of this paper is to develop and apply a learned method based on DIP to solve any differentiable linear inverse problem. This approach outperforms previous learned and learned - based methods, and is easy to generalize to other datasets."
SP:23c0f621e6041003b59bf0532130760694cf6a4a,"This paper proposes TAIC - HRL, an approach to temporal abstraction in hierarchical reinforcement learning by dividing the task into hierarchies, often with hand - tuned network structure or pre - defined subgoals. The temporal abstraction is learned from past experience or expert demonstrations without task - specific knowledge. The authors formulate the temporal abstraction as learning latent representations of action sequences and present a novel approach of regularizing the latent space by adding information - theoretic constraints. Specifically, they maximize the mutual information between the latent variables and the state changes that arise from the action - reward distribution. They show that a visualization of the learned abstraction demonstrates that TAIC learns an effective abstraction of the long action sequences. The learned abstraction allows them to learn new tasks on higher level more efficiently. They also demonstrate that learning temporal abstractions is an effective technique in increasing the convergence of the convergence rate and the sample efficiency of RL algorithms."
SP:4e54c9196ba1eb2b6a0b0eee41e4a6f3a9de72dd,"This paper presents a novel layer - wise sampling strategy for training graph neural network ( GCN ) based on GNNs on graph neural networks. The motivation of this paper is that existing GCN based methods are limited to training GCNs on shallow layers ( e.g. 2 layers ) on relatively small graphs, whereas the main challenge of training GCN on larger graphs and deeper layers is the over - expansion of neighborhoods across layers. To address this challenge, the authors propose a novel Layerwise sampling strategy, which samples the nodes layer by layer conditionally based on the factors of the bi - directional diffusion between layers. In this way, they potentially restrict the time complexity to be linear to the number of layers, and construct a mini - batch of nodes with high local bi - directional influence ( LDA ). Extensive experiments on three large benchmark graphs demonstrate the effectiveness and efficiency of the proposed model.    The main contributions of the paper are the following :   1. The authors develop a new sampling strategy to train GCN - based GNN based on layerwise sampling. The main idea is to first sample the layers ( conditionally ) from the same set of nodes conditionally by computing the factor $ \beta$ of the diffusion coefficient between the layers. This is the main idea of Layerwise Sampling ( layerwise ). 2. Then, they apply the self -attention mechanism to learn suitable weights for the sampled nodes, which allows the model to be able to incorporate both the first - order and higher - order components during a single layer propagation process without extra recursive propagation process ( layer propagation ). 3. They conduct extensive experiments on 3 large graphs to evaluate the proposed method."
SP:bb0af9c011ef982c34fcadb545f6b5771818e7fa,"This paper proposes a new unsupervised state - space model for videos called STOVE, which combines an image - based model and a dynamics model in a compositional manner. The dynamics model is used for inference, accelerating and regularizing training, and the image model for training the state space model. The model is trained using a mixture of supervised training and self - supervised training. The state space models are trained with timesteps of a given video. They are trained to predict the state of the videos from the objects and interactions with the environment using a combination of self - attention, position estimation, velocities, interactions with other objects and the dynamics model's estimates of the trajectories of the objects. The authors evaluate the performance of the model on a variety of video classification tasks including object localization, object tracking, object interaction and interaction prediction with a toy environment. They also test the model as a simulator for sample efficient model - based control tasks with interacting objects and show that it outperforms the performance on these tasks of supervised baselines and approaches trained with self - supervision."
SP:e67b463bc0aec2345925d609fa521ea49df57fd9,"This paper proposes a generative adversarial network ( GAN ) based variational autoencoders ( VAE ) model. It is known that GAN can produce very realistic samples while VAE does not suffer from mode collapsing problem. However, the straightforward way of substituting the VAE loss does not work well if we use an explicit likelihood such as Gaussian or Laplace which have limited flexibility in high dimensions and are unnatural for modelling images in the space of pixels. To tackle this problem, the authors propose a novel approach where they first train the GAN with an implicit likelihood by training an adversarially trained discriminator. The second part of their model is the objective that is optimized using the standard adversarial training. They show that their model achieves the state - of - the - art trade -off between generation and reconstruction quality. They also demonstrate how to balance between mode - seeking and mass - covering.   The main contributions of this paper are the following :   1. They propose a GAN - based VAE model that they call VAE - GAN. The name of this model comes from the fact that VAE trains the discriminator to distinguish between the distribution of the model distribution and the true data distribution. 2. They use GANs to train VAE and GAN objectives. 3. They conduct extensive experiments on CIFAR-10 and TinyImagent datasets to validate their method."
SP:87056d0147ddcaf5d78f6888b05161fbdbb3346c,"This paper studies adversarial attacks on CNN classifiers where the classifier is trained to ignore an imperceptible change to an input image and alter the classification result. The source of these failures is still poorly understood, and many explanations invoke the “ unreasonably linear extrapolation ” used by CNNs ( Goodfellow et al., 2018 ) along with the geometry of high dimensions. This paper shows that similar attacks can be used against the Bayes - optimal classifier for certain class distributions, while optimal classifiers are robust to such attacks. The authors present analytical results showing conditions on the data distribution under which all points can be made arbitrarily close to the optimal decision boundary. They show that this can happen even when the classes are easy to separate, when the ideal classifier has a smooth decision surface and when the data lies in low dimensions. They introduce new datasets of realistic images of faces and where the optimale classifier can be calculated efficiently. The experiments show that standard CNN training consistently finds a vulnerable classifier that is hard - bitten, while large - margin methods often find a robust classifier with the exact same training data. The results suggest that adversarial vulnerability is not an unavoidable consequence of machine learning in high dimensions, and may be the result of the specific distributions of commonly used datasets or of suboptimal training methods used in current practice."
SP:a7b3a35e6a79084bdfd1e4a963dfa081279cd8bb,"This paper studies the effect of pruning the network representations of sparse and non - sparse neural network members with respect to the accuracy of the top - 1 test set on classification accuracy for sparse and sparse - sparse non - sarsparse models. The authors first consider a setting where the majority of the weights in the network has been removed, with the intention of improving the test accuracy. This setting is called sparse - identified exemplars ( PIE ), which are examples of examples that the authors consider to be hard - to - generalize - to images that are difficult to generalize to or have a low image quality. They then show that removing PIE images from the test - set significantly improves the test set accuracy for both sparse - sarpend models as well as sparse - non - psarsamples. They also show how different classes of examples and images are more sensitive to pruning. The main results are summarized in Table 1, where the authors compare the impact of removing examples ( and the extent to which PIEs are removed ) for different classes and images on the top-1 test set. They show that images of certain classes and classes of classes ( e.g., classes 3 and 4 ) tend to be more impacted by the introduction of sparsity, and that classes of images of classes 5 and 6 ( which are more commonly pruned ) are less sensitive to sparsity than classes 1 and 2. This is particularly true for images of cells of the same dimension ( which is more likely to be seen in the sparse network ). They further show how the class - wise pruning affects images of objects of different sizes ( which may be seen by different classes ). For images of varying sizes and classifications, they show how pruning classes leads to higher or lower image quality ( for some images higher image quality ) and how images of larger classes of objects ( which might be seen more often ) are mislabeled. This leads to a trade - off between image quality and image mislabeling when compared to images of smaller classes. For example, when the image of a larger class of objects is mislabelled, the image quality is lower and the image size is larger, which leads to less image information being sent to the pruned. This results in higher error rates for the images that were originally pruned, which is why the authors prefer to use sparsity to remove them. When the images from sparsity instead of PIE for image captioning, the images become more similar to the original images.    The main contributions of this paper are the following : - First, the authors show that the effects of introducing sparsity in sparse networks are more marked when the class of images that was pruned is larger than the class that was not considered when the network was designed for classification - and that sparsity is"
SP:4b17edaa7ec6201891433320d85f9a415656b763,"This paper presents KG - A2C1, an agent that learns via reinforcement learning to explore and act in combinatorially large text - based action spaces using a knowledge graph and a self - attention mechanism. The paper proposes using the knowledge graph for two purposes : ( 1 ) to reason about the game state and ( 2 ) to constrain natural language generation. The idea is that the two tasks are complementary and complementary and can be combined to form a unified knowledge graph that can guide the exploration and action taking steps in the action space. This is in contrast to existing approaches that rely on a static knowledge graph ( e.g., GNN ) that is frozen during exploration and only used for action taking.   The main contribution of this paper is to propose a method that combines the use of knowledge graphs for both of these tasks. The method is referred to as Knowledge Graph Exploitation ( KG ) and the authors argue that it is important to distinguish KG from traditional action - based RL methods that use action sequences as the action sequences are often difficult to predict or difficult to generate due to their large action sequences being intractable for RL agents. To this end, the authors propose to use a template - based learning approach where the agent first constructs a dynamic knowledge graph of the state of the game, the actions that the agent will take based on this knowledge graph, and then uses the generated knowledge graph to make predictions about the state and actions. This approach is similar to the approach used in [ 1 ], but is different in that it uses the graph to predict actions rather than action sequences. The authors show that this approach is more scalable and robustly able to handle the large action spaces. The experiments are conducted in three different types of IF games, where the action spaces are much larger than those in the original KG. They compare the performance of KG-A1C with that of two baseline RL agents and show that KG performs significantly better than the baseline KG even with the increased action space size ( in some cases slightly better ) across all the games."
SP:b1784ecbb8f36eef9cae33d61ce60d80c2f9c38d,"This paper proposes a novel approach to tackle typical sequence prediction problems such as language generation, where it augments the typical maximum likelihood estimation ( MLE ) approach by introducing an extra Kullback - Leibler divergence term ( KD - LEBler term ) to counter the biased MLE in terms of diversity of predictions. This term refers to the fact that MLE, due to its focus on the once - to - all matching between the predicted sequence and gold - standard sequences, treats all incorrect predictions as being equally incorrect. The authors argue that this leads to a biased representation of sequence predictions, which unfairly downplays the nuance of these sequences ’ detailed token - wise structure. To counter this, they propose a data - dependent Gaussian prior ( D2GPo ) objective that is defined over a prior topological order of tokens and is distinguished from the data - independent Gaussian Gaussians apart from the time when tokens are taken from the distribution over data that is not Gaussian. They also propose to use a more detailed Gaussian distribution ( DGD ) than the one used in the prior method ( DMP ) in order to encourage more effective use of the more detailed prior in the data and has improved performance in typical language generation tasks, including supervised and unsupervised machine translation, text summarization, and image captioning. The experimental results show that the proposed method makes the proposed DGD method more effective in typical tasks.    The main contributions of this paper are the following : ( 1 ) A new approach to augment MLE ’s diversity loss by using an extra KD - leibler term derived from the previous work ( Zhang et. al. ( 2021 ) ( 2 ) Data augmentation to MLE to counter MLE’s negative diversity ignorance : The authors propose data augmentation methods that explicitly distinguish between Gaussian - dependent prior and the detailed training - based Gaussian distributions that are independent of each other. The experiments show that DGD outperforms DGPO in most tasks, and the proposed approach is more effective than the DGD - GPO."
SP:7c29cb5a32b14e1392408dc5daba4cd35848bea9,"This paper studies the calibration of deep neural networks ( DNNs ) with temperature scaling and focal loss. Focal loss is the most common approach to calibrate DNN but it is not state - of - the - art. The authors propose to replace the widely used cross - entropy loss ( CE ) with focal loss, which is based on the idea that a DNN that is confident in its predictions will not make incorrect predictions while being inaccurate or underconfident of its predictions. The paper shows that the proposed focal loss calibration method leads to more stable calibration of the network than the baseline temperature scaling approach, while also leading to higher accuracy than the CE approach. This is demonstrated by experiments on a variety of datasets ( CIFAR-10/100, MS - NLP, Amazon Web Services - E - Bayesian - Newsgroup ) and with a wide variety of different network architectures. They also provide a thorough analysis of the factors causing miscalibration, and use insights gleaned from this to theoretically justify the theoretically plausible explanation for the excellent performance of the proposed method."
SP:cd6b8417ec8bcb773c78cff677bb0a76d6b3f6f3,"This paper introduces LiPopt, a polynomial optimization framework for computing increasingly tighter upper bounds on the Lipschitz constant of neural networks. The underlying optimization problems boil down to either linear LP ( Lp ) or semidefinite ( SDP ) programming, and the authors show how to use the sparse connectivity of a network to significantly reduce the complexity of computation in the LP or SDP cases. This is specially useful for convolutional as well as pruned neural nets. The main contribution of the paper is the introduction of LiPOpt, which extends the idea originally introduced in [ 1 ] ( Xie et al., 2021 ) to the case of the $ \ell_2 $-norm LipsChitz constant by introducing a new set of weights, called LiP(L_\ell_p\ell_{p}$, which can be thought of as a weighted sum of the weights of the neural network components. The authors show that this new weight classifies the network components into two classes, one composed of neurons ( neurons with sparse connectivity ) and one composed with neurons with strong connectivity ( neural network with strong sparsity ). The neurons are trained to have the same number of neurons per layer as the number of connections in the network. The network components are partitioned into two equal subsets, where one contains all the neurons with sparsity, and one contains only the neurons that have strong connectivity. The networks are trained with the sparsity in order of importance ( layer by layer ) and the connectivity in the neuron number ( layer that has strong connectivity is partitioned off to the lowest layer ( layer 2 ). This partitioning allows the network to be partitioned according to the importance of each neuron ( layer. ).   The authors conduct experiments on networks with random weights ( trained on MNIST ) and networks trained with and without sparsity. They show that their approach yields superior estimates, compared to baselines available in the literature, in terms of upper bounds, for the $ Lp$-Lipsschitz constant in the case. The experiments also show that the approach yields better upper bounds than the one proposed by Xie ( Xie ( Li[1 ] ) and SDP[2 ] ( Wang, 2021a, Li[3 ] ), and that the weights used by Li[2] are closer to the upper bounds in the sense that they do not tend to deviate too much from the mean in the lower bound."
SP:31c9dc0dd8806daddc9cb48c56ec819577fe46cd,"This paper proposes a self - supervised learning approach for learning representations of video features that improves performance on downstream tasks, such as video classification, captioning and segmentation. The method extends the BERT model for text sequences to the case of sequences of real - valued feature vectors, by replacing the softmax loss with noise contrastive estimation ( NCE ). This paper also shows how to learn representations from sequences of visual features and sequences of words derived from ASR ( automatic speech recognition ). The experiments show that cross - modal training ( when possible ) helps even more.   The main contributions of this paper are the following :   1. The paper proposes to learn a feature embedding using self - supervision and self - training. This embedding can be used in combination with BERT, a text - based model that learns the embedding. The proposed embedding is different from BERT in the sense that it does not require the embeddings to be of the same form. This means that the learning process does not need to be repeated for every sequence. 2. It is possible to use ASR to generate sequences of features that are similar enough to the one learned using BERT. This is done by sampling feature vectors from the same distribution as the one obtained using ASR. The difference is that ASR samples feature vectors that are close to each other and those that are far from each other. 3. The authors test their method on the task of video classification and captioning, and show that their method performs significantly better than the one that does n’t self - supervise."
SP:0f24424d10f1201dd25e8c56354e10afc9b2b11c,"This paper proposes a data - transfer mechanism to handle the data transfer between clients and the server during the inference phase of a neural network training procedure. The idea is to use a proxy - based mechanism to select certain parts of the input data that are most relevant for the subsequent application of a given neural network to a given dataset. This is done using the associated selection masks that are learned jointly by the server and the neural network. During inference, only the parts selected by the proxy - selection masks are available to be used. The paper shows that this proxy mechanism can significantly reduce the amount of data needed to be transferred during inference in order to achieve good model performance without affecting the model performance much.   The paper presents a simple yet effective framework for using the proxy mechanism. It works as follows : during inference, the server stores the data and the client stores the client's data ( masks ). During the inference process, the data from the server that is most relevant to the selected masks ( masks of the client ) is used to update the model parameters. The client and the associated server then transfer the selected data to the corresponding masks during the next phase of the training procedure, which is called inference transfer. During this phase, the client and server use the same masks to update their model parameters and the parameters of the associated mask of the server. The results show that this approach is more effective than previous methods of data transfer transfer ( e.g., Gumbel et al., Adv. 2020 ) when data is not initially available to the client or the server with respect to the bandwidth of the model training policy."
SP:aa4fcf5b2cae05c5c6a903c24e4992b56655dee2,"This paper proposes a method for training a neural network to detect out - of - distribution ( OOD ) samples without compromising classification accuracy on the test examples from known classes. The method is based on the Outlier Exposure ( OE ) technique, which trains a model to discriminate between samples that are likely to belong to a specific class ( i.e., out of distribution samples ), and samples that belong to other classes that do not appear in the class distribution. The authors show that this training procedure leads to a robust classifier that is able to distinguish novel samples from the known class distributions, while being able to detect OOD samples with accuracy comparable to the model that is trained to detect novel class distributions.   The main contributions of this paper are the following :   1 ) The authors propose a novel loss function, called OE - LAP ( Out - Of - Distribution Loss Representation ), which is used to train a classifier to distinguish between samples belonging to a class that is likely to be present in the test distribution, but whose distribution is not included in the sample distribution. This classifier is trained with two types of loss functions, one that penalizes the deviation of the class from the distribution sampled from when the class is absent from the test distributions, and one that regularizes the gradients of the loss parameters based on whether the samples belong to the class or not. The experimental results show that the proposed method achieves better than the state of the art results in OE detection with OE on image and text classification tasks, and comparable results with the Mahalanobis distance - based classifier on the Mah - OBD task ( Wang et. al. 2020 ). 2 ) A set of experimental results are presented that show the effectiveness of the proposed loss function and the benefits of combining OE training and regularization for OE with regularization ( the generalization to non - OE loss functions is better on image classification tasks and the regularization to classifier training than it is for Mah- ODE."
SP:89bc528ef801182365ac279e8963803afccb391d,"This paper proposes E2Efold, an end - to - end deep learning model for predicting RNA secondary structure using constrained programming constraints. The main idea is to use an unrolled algorithm for constrained programming as the template for deep architectures to enforce constraints on the predicted secondary structures using the base - pairing matrix, and use the unrolled version as the learning model when constrained programming is not possible. The paper presents results on 5 datasets ( CIFAR-10, 23, 23R, 23Sigma, pseudoknotted, Random Forest, and MuJoCo ) showing superior performance over the previous SOTA models and a slightly worse performance than the previous unrolled SOTA model, while being the fastest in terms of inference time. The authors also present results on the synthetic data used to train the model and conduct ablation studies to better understand the structure prediction process. The experiments are conducted on MNIST, FSD-100, CIFARS-103, and 23R-1, using synthetic and real data."
SP:b68560cce8c64ebe0ca5e6534b3732c775d36452,"This paper presents a method to train a policy based on a trained virtual simulation of the agent ’s own biased observations. The goal is to train such a policy so that when applied to the real world, the trained policy will achieve higher returns than the best individually trained policy. The method is based on the idea that different agents have their own biased views of the world and interactions with the environment. The idea is to make agents imagine together ; make them take turns to host virtual episodes within which all agents participate and interact with their biased representations. The developed policy is used to transfer the learned policy from the virtual episodes to real - world interactions. The experimental results show that the collective policy does better than the individual policies when applied individually. The main contributions of the paper are the following :   ( 1 ) The method trains a virtual episode model from which each agent asynchronously constructs their own predictive model of the environment and forms a virtual simulation within which the agent plays trials of the episodes in entirety. This allows the agent to develop a collective policy trained solely inside the virtual simulation that can transfer policy knowledge from simulation to real world. ( 2 ) It is important to distinguish between simulated episodes and real episodes since simulated episodes can be manipulated in different ways ( e.g., different policies can be applied sequentially to different parts of the same episode ). ( 3 ) The approach is evaluated empirically on the synthetic drug discovery task, where it is shown that the collected evidence from the simulated episodes is better than that collected from individual agents ’ actions.    The main contribution of this paper is the method of training a collective policies, which is referred to as “ imagining together ”. This is similar to the idea from [ 1 ]. However, the main difference between the two methods is that the idea of imagining together and imagining separately is that in imagining together, all agents have access to all episodes from the same set of episodes. In contrast, in imagining alone, each agent only has access to a subset of episodes from each episode. This means that the experience collected from all agents “ imaginations ” is limited to a small fraction of episodes, which means that there is less evidence collected for taking optimal actions. On the synthetic data ( from each agent “ imagined ” episodes, there is a lower bound on the average action taken by all agents which is lower than the upper bound of the average agent action taken in an episode. In order to account for this lower bound, the authors propose to use a policy that encourages agents to act in a way that leads to lower action taking higher than they would have taken if the episodes were from a completely different set of agents ‘ imagined episodes. This leads to a policy gradient where higher action taken leads to higher returns for some actions but lower returns for others"
SP:bd1dc08b4fd9a5cc78d26d7eb7f05dbb4a629ab1,"This paper proposes a dialog generation model that learns a semantic latent space, on which representations of semantically related sentences are close to each other. This latent space is learned by maximizing correlation between the features extracted from prompt and responses. The key idea is to learn the pair relationship between the prompts and responses as a regression task on the latent space. Instead of classification on the vocabulary using MLE loss, the model uses a Gaussian mixture model to estimate the semantically similar responses collectively. Experimental results show that the proposed model eliminates the generic response problem, while achieving comparable or better coherence compared to other open - domain dialog generation models.   The main contributions of this paper are as follows :   1. A model is proposed for dialog generation, based on GPT-2. This model is different from the previous approaches in that it considers the dialog generation task as a one - to - many task, hence being able to integrate information from multiple semantically like responses of a prompt. 2. An autoencoder is trained, for recovering the full sentence from the learned latent space ( latent space ). 3. The authors test their model on the task of generating sentences from text generated from a dialog prompt and response. The experimental results indicate that the model achieves comparable performance to other models while achieving a higher ELBO ( or better )."
SP:ef0d5fd333ed60feb3946d24002e9a90642aea66,"This paper proposes Gaussian light and shadow ( GLAS ) as a salient explanation method for fine - grained classification task. The main contributions are :   ( 1 ) This paper introduces a novel notion of salient explanation and proposes a simple yet effective method to estimate the spatial impact of the feature perturbation inspired by light and shadows in nature when using Gaussian models ; ( 2 ) It provides a useful coarseto - fine control using the scalability of Gaussian mask ; and ( 3 ) It uses the ability to identify multiple instances through recursive GLAS - based instances identification to demonstrate the effectiveness of the method.   The main contribution of this paper is the introduction of the notion of GLAS as an explanation for the salient features that contribute to separating different classes in a classification task using the Gaussian model. The method is validated using the dataset Gaussian Mask - Fine - Grained Classification ( GP - FGC ), a dataset of classification tasks using only the discriminative features ( only the most salient ones ) for which the method is able to distinguish different classes. The empirical results show that the method outperforms other salient explanation methods in terms of accuracy, general applicability, and scalability."
SP:d17ca20cc527c28ab7358cb5b14954e5fb56409f,"This paper proposes a new method to train deep neural networks, called network deconvolution, by removing pixel - wise and channel - wise correlations in convolutional kernels. The motivation is that due to the strong correlations in real - world image data, existing methods to train neural networks based on convolutions that apply a kernel to overlapping regions of the input image are in effect re - learning redundant data. The method proposes to deconvert the convolution kernels by first applying a layer - by - layer convolution layer that aggregates all the pixels and channels that appear to be overlapped in the input. After that, the data from each layer is fed into the next layer of the convolutions layer. The paper shows that the layers are trained to have a kernel that maximizes the average squared distance between each pixel and channel in each layer. This maximisation reduces the computational cost of training neural networks by a factor of several orders of magnitude. The authors compare the proposed method with the original CNNs and propose to apply the method to 10 modern neural network models by replacing batch normalization within each of them with the method proposed in this paper. The experiments show that the method outperforms CNNs based on the original training method on the CIFAR-10, MNIST, FashionMNIST, Cityscapes, and ImageNet datasets. The main contributions of the paper are the following :   1 ) The authors propose a method to learn a kernel with a center - round structure similar to that is found in neurons in the visual processing centers of the human visual system 2 ) The method is compared with a method that learns a kernel similar to the one found in biological neurons 3 ) The results show that this method leads to faster convergence and superior results without the use of the much larger learning graph used in the training of CNNs ( compared to the method that trains the original network ) 4 ) The paper is well - written and clear about the motivation behind the method and the benefits of using the method."
SP:e1b0de9a36bf8359df368b7a55a7f23e99d88db7,"This paper studies quantization methods for GANs with extreme low bits. The authors first study the quantization accuracy of CNN - based methods for training GAN models and find that none of them generate samples with reasonable quality. The underrepresentation of quantized weights in models leads to different sensitivities between generator and discriminator networks. Motivated by these observations, the authors propose a novel quantization method, named QGAN, to quantize weights of GAN generators and discriminators based on EM algorithms named as QGAN - B. The authors also propose a multi - precision algorithm to help find an appropriate quantization procedure that is appropriate for the GAN setting. Experiments on CIFAR-10 and CelebA show that QGAN can produce representations that are comparable to the best possible 1 - bit or 2 - bit representations with results of quality comparable to original models.    The authors conclude their paper with the following observations : ( 1 ) Quantization methods are not well suited for generating samples of high quality on GAN ; ( 2 ) GAN training is unstable and different for different bits ; ( 3 ) Quantized weights are not representative of the weights in the models and the generator networks."
SP:58c4905f59f04a50b30d27c99521126a6455d38a,"This paper studies the problem of last - iterate convergence of convex - concave min - max optimization with gradient descent. The main contributions are two - fold : ( 1 ) The main contribution is a proof that the gradient descent algorithm of Hamiltonian gradient descent ( HGD ) achieves linear convergence when the last iterate of the gradient is invertible, and ( 2 ) A proof that HGD achieves convergence in more general settings than just bilinear and convex concave settings ( e.g., bil - inear or strongly concave ). The paper compares HGD with two other algorithms based on gradient descent, one based on SGD and another based on GDA - GAN ( Generative Adversarial Networks ). While HGD is faster than the other two ( in terms of convergence rate ), the paper shows that it is slightly slower than the first one ( by a factor of 2.5 or 3.5 ), and the second one ( on averageiterate convergence ) is slightly faster ( by 0.7 or 0.8 ) than the third one ( which is based on the SGD algorithm ).    The paper also includes experiments on proving convergence rates for stochastic HGD and for some parameter settings of the Consensus Optimization algorithm of Mescheder et al. ( 2017 ), showing that it converges faster and achieves better rates than the previous two algorithms even in cases where the parameter settings are convex-concave ( inversus - convex ), strongly convex ( with a max factor of 6 or 7 ). This paper is also the first to show that the HGD algorithm converges to a rate that is at least $ \epsilon$ for a given data point $ \in [ 6,8,9]$."
SP:d8556b52272321a1415ac2d85bb12e88b51ee73a,"This paper studies the stability of the forward / backward process of ResNet in terms of scalar scalar $ \sqrt{L}$ with ReLU activation, where $ L$ is the number of residual blocks in ResNet and $ h$ is its activation function. The authors show that the stability is guaranteed for $ \tau \leq 1 $ ( \rho(L)$ where $ l$ is ResNet's residual block size and $ g(hl−1 ) $ is the distance between the first and second residual block in the ResNet training procedure. They also show that deep ResNet with $ t$-layer normalization provides stability for forward and backward process for a constant factor $ t$. Conversely, forward process explodes for $ t = 1 $ when $ t < L$ and $ t > L$ ( \sigma(t ) + \epsilon$ ) for a negative value of $ t(t)$. The authors also demonstrate that the over - parametrized $ t=1 $ for ResNet only weakly depends on the depth, which corroborates the advantage of using ResNet structure over the feedforward network. Finally, the authors provide empirical evidence that ResNet is robust to perturbations in the learning procedure."
SP:cf70dc496825ece2f28fdf4f1a6f4316c69e0e48,"This paper proposes a method to train sparse neural networks with a fixed parameter count and a fixed computational cost throughout training, without sacrificing accuracy relative to existing dense - to - s sparse training methods. The main contributions are :   1. A method is proposed to update the topology of the sparse network during training by using parameter magnitudes and infrequent gradient calculations. 2. It is experimentally shown that this approach requires fewer floating - point operations ( FLOPs ) than the one proposed in prior works to achieve a similar level of accuracy compared to the high accuracy achieved with prior techniques. 3. The method is compared to state - of - the - art sparse training results with ResNet - 50, MobileNet - v1 and MobileNet v2 on the ImageNet - 2012 dataset, WideResNets on the CIFAR-10 dataset and RNNs on the WikiText -103 dataset.   4. The authors provide insights into why allowing the model topology to change during the optimization can overcome local minima encountered when the topological remains static. 5. Finally, the authors provide an insight into why it is possible to achieve high accuracy with sparse training without gradient descent."
SP:d2d2b892518d54d0e63e26a056f2298be3be2610,"This paper proposes a new method to control specific properties of the generated image with a GAN - based generative model via the interpretability of the latent space of the model. The key idea is to use the semantics of the generative models studied in recent work such as [ 1 ] and [ 2 ] to interpret the latent representations obtained from the GAN model. To this end, the authors propose to use a method based on the BigGAN model to generate latent representations from the latent representation obtained from a generative modeling task using the learned representation of the target image. The paper presents the following contributions :   ( 1 ) A new method for controlling the position and scale of the object in the image latent representations of GAN models from the interpretable latent space. This is done by embedding the object representations into a latent space $ \mathcal{L}$ with the learned latent representation of a target image, and then using GANs to generate the corresponding latent representations. The authors claim that this gives them a way to control the position of object in image latent space via the position vector and the scale vector of target image in latent space with GAN.   The authors demonstrate the effectiveness of their method on the task of image classification using a set of synthetic images generated with their method. The synthetic images are obtained by using a standard GAN ( without any additional annotations from the authors ) and then fed into a custom - designed decoder which generates the embedding. The resulting embedding is compared with different versions of the original GAN and show that the difference between them is mainly due to the choice of embedding size. The difference between the original and the synthetic embedding in the original is the difference in the difference of $ \text{L$ between the embeddings of the two original versions.   [ 1]   This paper is presented in two versions. In the first, the author presents the generated images and the resulting latent representations as separate sets of images. The second version, the decoder produces the synthetic images with and without embedding, which is presented as a hybrid of the first and the second. The author claims that the differences between the two sets are due to different choices of the encoder used in each of them and that the first one does not require human input. The choice of encoder / decoder. The experiments are conducted on synthetic images of the left and right hand side of the image and compare the proposed method with the one using the reconstructed embedding and the one without the reconstruction error correction. The experimental results indicate that the proposed approach generally outperforms the competing methods in terms of both image quality and cost. However, there are some issues with the quality of"
SP:1c63389e972d4652fac831e9d11609cd3c3c371a,"This paper proposes a physics - as - inverse - graphics ( P3G ) model for unsupervised physical parameter estimation of systems from video where the differential equations governing the scene dynamics are known but labeled states or objects are not available. The proposed model is based on PDP - based model - predictive control ( P2C ), which is an extension of the vision - based ( VOC ) model from [ 1 ].   The main contributions of the paper are the following :   ( 1 ) It proposes an interpretable PDP model that is able to learn interpretable system parameters and states from video without object state or state - state supervision ( existing methods do not integrate with differentiable physics ). This allows the author to perform long - term extrapolative video prediction as well as model - based vision - prediction with P3C controller. The controller ’s interpretability provides unique capabilities in goal - driven control and physical reasoning for zero - data adaptation. The value of this tight tight integration is demonstrated by demonstrating data - efficient learning of the learning of a $ \ell_2$-model - based control for a pendulum system. ( 2 ) It also shows that the controller with interpretable state and velocity representations enables the controller to achieve better performance than the one with object state and state - velocity representations. ( 3 ) It is important to note that the control model does not require any assumptions for the interpretable states and states. ( 4 ) The controller does not constrain the model learning in any way, which makes it possible to use the controller in other than a few cases ( e.g., ball - spring or 3 - body gravitational systems )."
SP:c6b8b682bf3087a65cb2379700b8a0183853c2af,"Graph Convolutional Networks ( GCN ) are used to predict class relevance of noisy examples. For each class, the GCN is treated as a binary classifier learning to discriminate clean from noisy examples using a weighted binary cross - entropy loss function, and then the “ clean ” probability is exploited as a relevance measure. Each noisy example is weighted by its relevance when learning a classifier for the end task. The authors evaluate the method on an extended version of a few - shot learning problem, where the few clean examples of novel classes are supplemented with additional noisy data. The proposed GCN - based cleaning process significantly improves the classification accuracy over the classification over cleaning the noisy data and a few shots of clean data. Experimental results show that the proposed method outperforms several baselines in the extended setting."
SP:dd9c9a5dccbba5dd15b03ca6b314a9e153e95548,"This paper proposes a new approach to update graph neural networks ( GNNs ) based on message - passing aggregation using edge features. In contrast to the typical approach where the message of a neighbor node is pre - processed with a parameterized transform matrix, the proposed approach updates the node representation using the message from neighbor nodes. The proposed approach is based on Edge Information Maximized Graph Neural Network ( EIGNN ), a novel approach that reformulates the mutual information ( MI ) between edge features and message passing channels as a differentiable objective via a variational approach. The newly introduced objective enables the model to preserve edge information and maximise mutual information. Empirically, the authors show that the approach improves the performance of MI - maximized models across a broad range of learning tasks including regression on molecular graphs and relation prediction in knowledge graphs.   The main contributions of the paper are the following :   1. A new objective for updating the graph representation of neighbor nodes is introduced, motivated by the idea that the message passing aggregation can be better utilized if the updated node representation is better able to capture edge information. 2. The corresponding objective is formulated as an objective that can be efficiently parameterized using a transform matrix. 3. The approach is tested on a set of experiments where it is shown to outperform other GNN approaches ( e.g., RNNs, Graph Neural Networks, GraphSAGE )."
SP:f1cf63d728da51b4f83eb50ef69e3788b3a5ed74,"This paper proposes a new verifier APPROXLINE to verify the non - convexity in the latent space of generative networks. The main idea is to use a generative model ( GNN ) with a latent space $ \mathbb{R}$ and a latent vector $ \tilde{L}$, where $ L$ is the latent vector produced by the model and $ \eta$ the vector of the network's input.   The authors show that the proposed method is robust to both deterministic and probabilistic interpretations of the outputs produced by GNNs. They also show that it is able to capture interesting interpolations in the network ’s latent space. The verifier is capable of producing bounds on the output of both the input and the latent vectors. The authors also propose a multilayered version of the method to capture the sets of output of the model with different degrees of freedom. The experimental results demonstrate that the method is more robust than the deterministic one and the multilayed one in terms of the magnitude of the bounds produced by each set."
SP:2b0887dcf09249e8cee30d38163aeb9ef1e92b27,"This paper studies the problem of suspended animation in graph neural networks ( GNNs ). It identifies that the main cause of the suspended animation problem is the model depth reaching the limit, where the model will not respond to the training data any more and become not learnable. To address this problem, the paper introduces the GRESNET ( Graph Residual Network ) framework to model depth of the GNN. The main idea of the framework is to use the graph residual features ( GPRs ) of the graph convolutional operator ( GPC ) to model the difference in representations between layers of the model. The authors provide detailed analysis about the causes of the problem and several other factors that impact the problem. Experiments on several popular benchmark datasets are conducted to validate the effectiveness of the new method.   The main contribution of this paper is to propose a new method to address the suspension animation problem in the existing GNN models. The method is based on the idea that model depth reaches the limit and then the model stops responding to training data. The experimental results show that the proposed GRES NET model has a better performance than GCN, GAT, and LOOPYNET."
SP:dc436ade4d04072de35a90e5e4a1bfebfddb04e9,"This paper proposes a nonlinear parametric 3D face reconstruction method based on CNN - based model using convolutional neural networks trained on a dataset generated from a linear 3D morphable facial image model ( 3DMM ). Based on CNN, the model is trained to regress the face shape and texture directly, identity, expression, pose, and lighting representations, which helps improve the overall reconstruction performance and facilitates facial editing applications, e.g. expression transfer. Experiments demonstrate that the proposed model produces high - quality reconstruction compared to state - of - the - art methods and is robust to various expression, pose, and lighting conditions. The authors also train their model with adversarial loss in a semi - supervised manner on hybrid batches of unlabeled and labeled face images to exploit the value of the large amounts of labeled face image to be used in the reconstruction process. A novel center loss is introduced to make sure that different facial images from the same person have the same identity shape and albedo.   The manuscript includes the following technical details :   1 ) The authors train a non - linear parametric model with a dataset of face images. 2 ) The dataset is split into two batches of 8 face images ( each batch includes 5 face images and 5 non - face images ). The first batch is used to train the model and the second one is used for training the identity and expression representations ( the second batch includes the lighting representations ). 3 ) During the training of the model, the datasets are augmented with additional images that are generated from the original dataset ( excluding the images that were not used during the training ) to obtain additional data points. The additional images are added to the training set to obtain the final dataset and the models are trained to train. During the inference process, the dataset is updated to include the additional images during the inference phase and the final training stage to obtain new data points and the identity / expression representations are updated to reflect the new dataset. 4 ) The models are validated on the additional datasets that are not included during training and the training that were used during inference. The main contributions of the paper are summarized as follows : 1 ) A detailed description of the training procedure is given, which explains how the model was trained and how the losses are calculated ( trainings are parametrized from the identity, expressions, poses and lighting ) 2 ) A discussion of the advantages and challenges of using the encoder / decoder model in the face reconstruction process 3 ) An ablation study is performed to evaluate the advantages of the proposed method for face"
SP:f7bc06697b09e2d59ec06b2cbcf3c0828ece32ae,"The paper introduces the Expert Induced Markov Decision Process ( eMDP ), a model for policy evaluation in imitation learning when only partial knowledge about the transition kernel is available. The key idea is to replace the unknown transition kernel of the policy with a synthetic kernel that can simulate the transition of state components for which the kernel is known ( s ) and can not be used in the policy ; instead, the next state is constructed from the two components : s = { { s }, su }. The paper describes in detail the recipe for building such a synthetic model and analyzes the errors caused by its synthetic kernel. The experiments include imitation tasks in multiplayer games, where the agent has to imitate one expert in an imitation task and the goal is to find a policy gradient algorithm that achieves superior performance compared to the simulation - free alternative.   The main contributions of this paper are the following :   1 ) The paper introduces a new model for evaluation of policy gradient algorithms for imitation learning with reinforcement learning, which is referred to as expert - induced learning ( EI ) in the paper as opposed to reinforcement learning ( RL ), as done in the case of EI. The idea of using RL in EI is to learn an expert policy gradient that, when the state components of the target state are known, extracts from demonstrations the states from which there is no known kernel, and the state from which kernel is unknown is then used to design the policy gradient for evaluation. This is similar to what is done in SimCLR. The difference is that instead of learning the gradient based on state components, the expert network learns the one based on samples from demonstrations. The resulting policy gradient can then be used for evaluation to design a new state from the sampled demonstrations. This approach is called expert - guided policy gradient. 2 ) In the experiments, the paper compares the performance of the proposed model with simulating the learned state components from the learned expert network against that of simulating states from the ground - truth kernel and shows that the expert model outperforms the ground truth model in most cases, especially in high - dimensional settings."
SP:82cce92821e8168ab4a6fd67573b66c1d17673b8,"This paper proposes Mutual Information - based State - Control ( MISC ), a self - supervised reinforcement learning approach for learning to control states of interest without any external reward function. The key idea is to formulate the intrinsic objective as rewarding the skills that maximize the mutual information between the context states and the state of interest. The context states are the robot states in the paper, and the states in interest are the states of an object. The authors evaluate their approach for different simulated robotic manipulation tasks from OpenAI Gym and a navigation task in the Gazebo simulator. They show that MISC is able to learn to manipulate the object, such as pushing and picking up, purely based on the intrinsic mutual information rewards. Furthermore, they show that the self - supervision based mutual information can be an effective ingredient for overcoming the challenges of robot manipulation tasks with sparse rewards.   The paper is published online with supplementary material. The manuscript and related papers can be found at the Amazon Review Online Repository. The paper with the supplementary material is also available on the Amazon Web Services Review Online Database. The text of the paper and the related materials are available at the authors ’ 48 - page summary. The abstract includes the following main contributions :    1. MISC proposes a self supervision based state - control method that leverages mutual information to learn useful skills without a manually - designed reward function ( except for pushing / picking up ). 2. In particular, the authors propose a mutual information loss function that penalizes actions that generate more mutual information than actions that do not generate mutual information. 3. They use it to train a self supervised learner that learns to maximize mutual information in order of importance. The main contributions are the following : 1. The first part trains the self agent to learn mutual information ( mutual information ) to maximize the information loss between context states ( the context of interest ) and states of the interest ( the robot state ). The second part penalizes action that does not generate as much mutual information as the first part does. The third part trains a self agent that generates mutual information using the action that maximizes the information generated by the action ( the value of the value maximization step ). In the last part, the algorithm is trained using self supervision to generate action that generates most mutual information but does not penalize the action based on mutual information from context states."
SP:5db63d39cfd8132bec832ab64b8fbd403b3b8df0,"This paper proposes a trojaning attack method for large neural network ( NN ) models that is different from adversarial attacks in the sense that it hides malicious functionality in the weight parameters of the NN models. The attack is programmable that the malicious misclassification target is not fixed and can be generated on demand even after the victim ’s deployment of the target class NN model. The authors propose a trojaned attack method that outperforms existing studies in capability, generality, and stealthiness. The main contributions are three - fold :    ( 1 ) The attack method is able to generate fixed target classes that can be used to train trojans on a large - scale dataset. ( 2 ) The authors show that the attack is not limited in a small domain when one trojanized model is used on a small dataset with limited target classes. ( 3 ) Different from previous works, the trojanized model that was used in this paper can be deployed on different domains that are not the same size ( e.g., the one used for the small dataset was only used for image classification ). ( 4 ) This paper proposes an attack that is more difficult to defend because it uses different trojanization techniques for different target classes, which makes it more difficult for the defense to defend.   The authors validate their method on two synthetic datasets. The first one is based on cross - entropy loss and the second one on log - likelihood loss. They compare the performance of their method with other trojanised models and show that their method outperforms other methods that are based on fixed target classifications and have access to more training data."
SP:35ea626ee4dd1a7a368a660eb852192924966b7f,"This paper proposes a few - shot regression ( FSR ) algorithm for the task of drug discovery. Few - shot classification and reinforcement learning algorithms have been developed for this task and few FSR methods exist for reinforcement learning, but few of them are suitable for the drug discovery setting due to the fact that few of the samples used to train them are likely to be inaccurate. This paper proposes an FSR algorithm that is better suited to the setting of few shot regression and is inspired by deep kernel learning. It consists of learning a deep network in combination with a kernel function and a differentiable kernel 8 algorithm. As the choice of kernel is critical, the algorithm learns to find the appropriate kernel for each task during inference. It thus performs more effectively with complex task distributions, outperforming current state - of - the - art algorithms on both toy and novel tasks.    The main contributions of this paper are the following :   1. The authors develop a novel algorithm based on FSR that is able to handle tasks that require prediction tasks within drug discovery with few shot data and few sample values. The choice of the kernel used to learn the optimal one for kernel selection is important and the authors use deep learning to learn a kernel that is robust to this choice. 2. This algorithm is tested on toy discovery tasks using both toy datasets and datasets derived from real - world drug discovery datasets. It is shown to outperform several recent FSR algorithms on the toy dataset and achieves better performance on the novel datasets that it is tested with. 3. This is further tested on drug discovery tasks that the authors developed based on real world data derived from drug discovery that they do not use for the reinforcement learning setting and obtained through reinforcement learning. The results suggest that the proposed algorithm may be able to achieve better performance under these settings than several previous FSRs that are not suitable for these tasks."
SP:91ca4c3ee07617356250bae9f4ef9799b3b134ff,"Graph Neural Networks ( GNNs ) perform well on many reasoning tasks, but less structured networks fail to do so. Theoretically, there is limited understanding of why and when a particular network structure generalizes better than others. This paper proposes a framework to characterize which reasoning tasks a network can learn well, by studying how well its computation structure aligns with the algorithmic structure of the relevant reasoning process. It derives a sample complexity bound that decreases with better alignment. This framework offers an explanation for the empirical success of popular reasoning models, and suggests their limitations.    The contributions of the paper are as follows :   1. The authors develop and characterize a framework that captures the relationship between the computational complexity of a GNN and the relevant algorithmic alignment of the reasoning process, such that the GNN can learn to solve the reasoning tasks better than other networks. This is done by ( 1 ) characterizing the relevant computational complexity as the sum of the squared squared variance of the two tasks ( \mathcal{C}_t ), and ( 2 ) defining the distance between the two matrices ( \theta_t \log c ), which measures how well the learned GNN ’s “ align ” with the relevant algorithms ( e.g., graph neural network, GAT, GraphSAGE, etc. ). The main contribution of this paper is the introduction of the so - called “ alignment matrices ”, which measure the degree to which the learned networks “ match ” ( or “ approximate ” ) the objective function of a particular GNN on the tasks it is designed to solve. For example, if the objective on the reasoning task is to predict the answer to a question “ What is the probability of the current state of the triplet you are trying to predict from a photoelectric image of the left hand side of the right hand window of the image ( from the angle of the user “ nose ” up to the window “ back ” from the right “ side ” of the window in the shot “ face ” taken from the camera ( “ left ” side “ upward ” shot ), then the alignment matrix s is defined. This matrices is the ratio of the learned network “ approximating ” the output of the objective with respect to the input ( the weights of the trees ), the distance to the trees ( the number of trees from the input images ) and the probability that the output is close to the output ( the “ nearest ” weight of the tree from the output images of the input objects ( the left and the"
SP:a52aee8da5cf5acd2baf3c2a62cb679e13b18bd5,"The paper proposes a new statistical metric, Fréchetchet distance ( FJD ), to measure the distance between joint distributions of images and conditioning obtained from GAN - based models ( GANs ). Prior to FJD, there were existing metrics for image quality, conditional consistency, and intra - conditioning diversity, which may indicate a different “ best ” model for each metric. The paper proposes FJD as a single metric that captures all three properties in one metric, and uses it to benchmark the performance of the models. Experiments are conducted on a controllable synthetic dataset, in which the authors show that FJD outperforms existing metrics ( e.g. contrastive contrastive similarity, contrastive uniformity, and conditional consistency ). Moreover, they show that the newly introduced metric of FJD can be used as a promising single metric for benchmarking cGAN benchmarking and model selection.    The main contributions of the paper are the following : 1. The authors propose a new metric for measuring the joint distribution distance of GAN-based models, named FJD ; 2. They use it as a benchmarking metric for assessing the properties of the joint models, and 3. They conduct several experiments to demonstrate the benefits of using FJD."
SP:fa822e8472efae17c7dfde8258057898383ecbbb,"This paper studies the problem of identifying ‘ decision states ’, a parsimonious set of states where decisions made by an agent can affect the future states it can reach in an environment. This is done using the VIC framework ( Gregor et al., 2016 ), which maximizes an agent ’s ‘empowerment ’. The authors identify three types of decision states : ( 1 ) states that are often interpretable, ( 2 ) lead to better exploration on downstream goal - driven tasks in partially observable environments, and ( 3 ) states the difference between two states ( i.e. states that the agent can reach reliably and states that it can not reach reliably ). Based on these three definitions, the authors formulate a sandwich bound on the empowerment objective that allows them to identify decision states. Unlike previous work ( Goyal et al., 2019 ), their decision states are discovered without extrinsic rewards – simply by interacting with the world.    The main contributions of this paper are the following :   1 ) Identification of the decision states and the definition of ‘ empowerment, ’ which is the ability to identify a set of empowered states that allows an agent to make decisions that affect future states. This definition is important because it defines the ‘ power ’ that an agent has to reach in order to obtain an empowered state. It is important to distinguish between ‘ empower ’ and ‘ not empower, as in the case of the former, which refers to a state that does not empower the agent to reach the highest possible epsilon of a given state. Empowerment is defined as the ratio of the power of a state with respect to the state it is empowered to reach compared to a lower state. The definition of empower is similar to that used in the original VIC paper, except that it explicitly distinguishes between empowered states and not just the first and second states of the hierarchy of states. ( See Note 1 for the definitions of empower and not empower. ) 2 ) Identification and definition of the “ power states ”, which are the states the agent has access to that can empower another state ( e.g., by making a decision that will help another state achieve a goal similar to the one it is aiming to achieve ). These definitions are important because they help identify a class of states that is not always accessible to the agent. In other words, if an agent is not able to identify the power states of"
SP:a19a51df7e28a5d3380be4fba13842efbfe3efec,"This paper proposes SEFT ( Set Functions for Time Series ), a framework for classifying irregularly sampled time series with unaligned measurements. The proposed SEFT is based on recent advances in differentiable set function learning and is extremely parallelizable and parallelizable, and scales well to very large datasets and online monitoring scenarios. The authors extensively compare their method to competitors on multiple healthcare time series datasets and show that it performs competitively whilst significantly reducing runtime.   The main contributions of this paper are as follows :   ( 1 ) The authors propose a novel framework, SEFT, a method to classify time series into classes based on the classifiers defined on the set function of each sample. This is similar to the approach used in Deep Neural Networks ( DNN ) [ 1 ], but unlike DNNs, here the classifications are based on real - world datasets, such as healthcare datasets. The idea is to use the same set functions for all samples in the classifier to get classifications for all possible combinations of the samples. The key advantage of this approach is that it does n’t have to deal with the noisy gradients of asynchronous time series, which is more common in DNN - based methods. ( 2 ) It is possible to parallelize the training of the learned set function classifiers in SEFT so that each sample can be used for only a small fraction of the possible classes in a classifier, which allows for better scalability. ( 3 ) The method is evaluated on two datasets, healthcare and finance. The experiments show that SEFT achieves better performance than the baselines of both of them ( in terms of the number of samples and computation time )."
SP:4ae89d64460b08749acc192004545c1fa8b7553b,"This paper proposes an operation called Harmonic Convolution to train deep neural networks to model priors in audio signals by explicitly utilizing the harmonic structure. The operation is done by engineering the kernels to be supported by sets of harmonic series, instead of by local neighborhoods as convolutional kernels when training CNNs. The authors empirically show that current network architectures for audio processing do not show strong evidence in capturing priors for the audio signals using natural image priors. They then propose to train CNNs using the operation where the kernel of the generative model is composed of two consecutive harmonic series $ K$ followed by a set of neighbors $ A$ and $ B$. The neighbors are generated by sampling $ k$ points from the harmonic distribution $ K$. The first set is used to train the CNNs while the second one is used as input to the generator of the output set $ G$.   The authors then empirically demonstrate that the trained CNNs trained with the proposed operation perform better on unsupervised audio restoration tasks than the networks trained without the operation. They also show that with the operation in use, CNNs also achieve better generalization performance for supervised musical supervision tasks.    Contributions : - The authors propose and empirically validate a method to train a deep neural network to model audio priors by using a specific type of harmonic distribution as the generator ( instead of using a generic set of harmonic distributions as in previous work ) - They show that the training of CNNs with this method yields better results on audio restoration than the training with other methods that do not use such a specific harmonic distribution. - They conduct a series of experiments that compare the performance of the proposed method to that of other methods on different audio datasets. They compare their method with a method that uses a random walk to another method that only trains CNNs and show that their method achieves better performance. - A set of experiments validate that the method works better than the other methods."
SP:c81a2b3fd1c56b9b18e4a358e3ff8b40aea5256a,"This paper introduces data echoing, a technique to slow down the training of neural networks by reusing intermediate outputs from earlier stages of the training pipeline that do not run on accelerators. The idea is that as accelerators continue to improve, these earlier stages will increasingly become the bottleneck that limits the total computation used by the earlier stages. To counter this phenomenon, data echoing reuses intermediate outputs ( or “echoes ” ) from earlier pipeline stages in order to reclaim idle capacity that has been run out by accelerators, such as disk I/O and data preprocessing. The main idea of the technique is to run the data echoing algorithm ( or data reuses ) on intermediate outputs of previous stages that were not used during training, such that their computation no longer needs to be re - used. The paper provides a theoretical analysis of data echoing and experiments with different data echoing algorithms on various workloads, for various amounts of echoing, and for various batch sizes. The experiments show that data echoing with at least one data re - output ( or echoe ) can match the performance of performance - matching algorithm with less data echoing ( using less upstream computation ). Data echoing with more than one data output ( e.g., 512 ) significantly outperforms data reusing algorithm with large amount of echoing ( 1000 ), and with data averaging ( 1, 500, 1.5, 2, 6, 8 ). However, in practice, the average performance of both algorithms decreases as the number of echoes increases."
SP:b4cf56d3fa7d65cacde33f17cd04bd5bbc52dd71,"This paper studies the problem of training agents to generalize beyond the finite set of behaviors that can be explicitly learned in the Markov decision process ( MDP ) via rewarding a policy for being distinguishable from other policies. To tackle the generalization challenge posed by the linear reward function in the MDP, the paper proposes to combine two techniques : ( 1 ) a Variational Intrinsic Successor Features ( VISR ) algorithm that learns a policy's ability to distinguish distinguishable actions from actions that are similar to each other, and ( 2 ) a VIRUS algorithm that adds the differences between rewards of states that are differentiable in some grounded feature space. The main contribution of the paper lies in showing that the combination of the two techniques can solve the limitations of the first technique ( one of which is the linearity of the reward function ).   The experiments compare the performance of the proposed VISR method with two approaches for training MDPs that use differentiable rewards for distinguishable policies : ( a ) ABOVE, where the rewards are only exposed briefly after a long unsupervised phase in the training procedure and ( b ) VISR, which uses the rewards to learn quickly with limited feedback from the policy reward function. The experiments show that VISR outperforms the other two reward - based methods in terms of human - level performance on 12 games, and vice versa for 5 games. The paper also shows that a combination of VISR and the ABOAST method can outperform the other rewards more than the other methods when the rewards function is linear in the feature space provided by each of them. The experimental results demonstrate that the proposed method can learn faster than the baselines that use baselines."
SP:83500230586a9134f910ad067b7233dc563dc1ba,"This paper proposes a functional framework for understanding deep neural networks ( DNNs ). The functional framework is based on the idea that neural networks are approximated by a Gaussian mixture of functional approximations and a flat initialization of the weights. The paper shows that the smoothness of the functional approximation is enhanced with the number of units, which explains why overparameterized networks tend to generalize well. In experiments, the paper investigates the effect of the initializations of standard DNN weights on the strength of generalization and the depth of the loss surface of the network. The experiments show that the generalization is enhanced by the combination of the smooth initializations and the flat initializations.    The main contribution of this paper is to develop a functional view of neural networks from the perspective of a functional model. This functional view allows the reader to see the network dynamics through the eyes of a modeler rather than a black box modeler as is the case with black box models. In particular, the functional modeler is used to understand the effect the initialisations have on generalization. The main contributions of the paper are the following :   ( 1 ) Theoretical and experimentally probing the properties of the Gaussian MDPs that the paper studies ( in shallow settings ) leads to insights into generalization mechanisms of the networks. This is done by considering the following three components : smoothness / smoothness as a function of the unit - wise initialisations ; ( 2 ) Theorem 1, which states that the smoothing effect of initialisations increases with the more units / number of unit initializations ; ( 3 ) The effect of depth / depth in terms of the average unit depth is studied in this paper. Theorem 2 and 3 are the first and second results of a set of experiments where the authors compare the effects of different Gaussian distributions on the generalizability of depth in the presence and absence of noise in the network compared to when the network is fully functional."
SP:7225825e353b711a7d023f706fafe5e17e4e2fb2,"This paper proposes a new approach to the image - to - image translation problem GAN ( Generative Adversarial Network ) based on attention mechanism. The main idea of the approach is to use an attention mechanism to predict the probability that the discriminator will generate images that are more plausible than the generator. The attention map is then used to generate more plausible and realistic images for the target classifier ( e.g., higher dimensional features ). This paper proposes to use this attention mechanism in two ways - ( 1 ) to predict high - level features from the attention map ( i.e., the features that are critical for the prediction of the attention mechanism ) and ( 2 ) to adjust the attention of the generator to maximize the likelihood of generating high - dimensional features from input that are higher dimensional than input that is not considered. The proposed approach is called a GuideGAN and it is based on the idea that most GAN - based methods suffer from the imbalance problem between the generator and discriminator ( Figure 1 ). The relative model capacities of the generators and discriminators do not match ( Figure 2 ), leading to mode collapse and/or diminished gradients. To tackle this imbalance problem, the authors propose to augment the generator with a higher - dimensional attention map of discriminator's features ( Figure 3 ). They evaluate the proposed approach on a number of image transfer tasks ( Figure 4 ), and show quantitative and qualitative results to demonstrate the superiority of their approach."
SP:41c089ba65393174dae1dc136f79030a0a4fc532,"This paper studies the role of multiplicative interaction layers in designing neural networks and argues that their presence as primitive operations has a long - established presence in the literature, though it is often not emphasized and thus under - appreciated. They conjecture that multiplicative interactions offer a particularly powerful inductive bias when fusing multiple streams of information or when conditional computation is required, and argue that they should be considered in many situation where multiple compute or information paths need to be combined, in place of the simple and oft -used concatenation operation. They show that such layers strictly enrich the representable function classes of neural networks. Finally, they back up their claims and demonstrate the potential of such multiplicative layers to design neural networks by applying them in a large - scale complex RL and RL sequence modelling task, where their use allows us to deliver state - of - the - art results."
SP:5144391584e6d3825e12684b7c053e4e282cff2b,"The paper proposes a new algorithm for active learning called Batch Active Learning by Diverse Gradient Embeddings ( BADGE ), which samples groups of points of high magnitude when represented in a hallucinated gradient space, a strategy designed to incorporate both predictive uncertainty and sample diversity into every selected batch. The authors combine deep neural network models ( DNNs ) with a Batch Neural Network ( BNN ) backbone, and the proposed algorithm is called BNN - BADGE. The main difference between DNN - BAG and BADGE is that BNN uses hyperparameters to trade off between uncertainty and diversity, while BADGE uses a weighted average of the predicted and observed trajectories to estimate the uncertainty for each batch. While other approaches sometimes succeed for particular batch sizes or architectures, BADGE consistently performs as well or better, making it a useful option for real world active learning problems.   The main contributions of the paper are the following :   1 ) The authors develop a novel algorithm to sample the points in the gradient space represented in the hallucinated space with a DNN backbone, using a BNN backbone as the backbone. This allows them to sample from a diverse and high magnitude distribution of points, which is different from other approaches to sampling the points from the DNN baseline. 2 ) They use the same set of assumptions as in BN - DAG ( Zhang et al., 2018 ) to update the weights of the BNN and the underlying algorithm BADGE to ensure that the updated weights do not deviate too much from the baseline. 3 ) They study the effect of perturbations to the weights in the given batch."
SP:ce6023b1e6bf45b071a6f5457b2575425ae03366,"Deep neural networks ( DNNs ) are hard to interpret due to the non - linearity of the activation functions, complex architectures, and the obscure feature extraction and transformation process. This paper proposes a novel feature leveling architecture that isolates low level features from high level features on a per - layer basis to better utilize the GLM layer in the proposed architecture for interpretation. Compared to the main - stream architectures on standard datasets while being more self - efficient, this paper proposes to use the features extracted from the high level layer with the help of a feature extractor layer that extracts features from the low level layer using the extracted features. The authors conducted extensive experiments to validate the effectiveness of their proposed feature leveling layer and showed that it improved the performance of the modified models compared to the vanilla DNN on both synthetic and real - world datasets.    The main contributions of this paper are the following :   1 ) The authors propose a new class of self - explaining models, the Deep Self - Explaining Models ( DSPMs ). These models are models that reveal the decision making parameters in an interpretable manner so that the model reasoning process can be directly understood by human beings. In contrast to the typical self - explanation mechanism of a linear model, the DSPM can not explain the feature extraction process because the model weights directly show how each feature contributes to the output value of the model. This is in contrast to a typical linear model that weights the model parameters based on the feature embeddings and the output values of the weights of the hidden in the network. 2 ) This paper introduces a new feature extraction method, the Gradient extraction, that extracts the features from a Gradient Gradient layer of a DNN by Gradient. Gradient layers are the same size as the weights in the GLMs and are applied to extract features from each layer. The extracted features are then used to update the output of the gradient layer of the DNN. This produces a gradient update. 3 ) Results show that the proposed feature extraction technique is more effective than the vanilla extraction method in terms of improving the performance on synthetic datasets."
SP:b70ceead1bf6c7dc684c74501716e7012b891022,"This paper proposes an adversarial training method for ‘ extreme classification ’, where the goal is to train a classifier over a large number of classes ( e.g., 10 classes ) such that the resulting gradient is proportional to the average cost of each class. This is in contrast to traditional softmax regression, which has a gradient cost per class in terms of the number of class(s ), and hence is expensive to train. This paper proposes to train the classifier by using adversarial sampling to generate negative samples from the data distribution. The negative samples are drawn from a model that mimics the distribution of the data, and the authors argue that this produces negative samples that are minimizes the logarithmic variance of the gradient while still resulting in cheap gradient updates. The authors provide three contributions : ( i ) a training method that generates negative samples at a cost of $ \epsilon$ for each class in the training set $ C$ that is obtained by using the adversarial model ; ( ii ) a proof method that shows that negative samples produced by the proposed training method are statistically significant enough to warrant using the training method in practice ; and ( iii ) experimental results on large scale data sets that show a reduction of the training time by an order of magnitude relative to several adversarial models ( i.e., $ \nabla_t$ ).    The main contributions of this paper are the following :   ( 1 ) A training method to produce gradient updates for a large classifier that is trained to classify 10 classes such that it is able to obtain a gradient of $ n$ classes with a cost proportional to $ t$ ; ( 2 ) A method to obtain negative samples for the training procedure that produces $ \sigma$. ( 3 ) A proof method to show that the obtained negative samples is statistically significant with respect to $ T$ and $ T$.   Finally, the authors provide experimental results showing that the proposed method leads to a reduction in the cost of gradient updates in practice."
SP:29b52fee83309268d9864f3b1fc3617948577d41,"This paper proposes a novel exploration method in representational deep learning where the goal is to learn a low - dimensional encoding of the environment using a combination of model based and model - free objectives. The approach leverages intrinsic rewards that are based on a weighted distance of nearest neighbors in the low dimensional representational space to gauge novelty and then leverage these intrinsic rewards for sample - efficient exploration with planning routines in representingational space. One key element of the approach is that the model is updated more gradient steps in - between every environment step in order to ensure the model accuracy. The authors test their approach on a number of maze tasks, as well as a control problem and show that their exploration approach is more sample -efficient compared to strong baselines.   The main contributions of this paper are the following :   1. A new approach in deep learning for efficient exploration, which leverages the intrinsic rewards of a model based exploration method for measuring novelty. The key idea is to use a weighted sum of the distance of the nearest neighbors of the current state of the model state with the environment state to get a measure of how close the model states are to the ground truth. This is then used to compute a reward function that is used in conjunction with the exploration objective to estimate how likely it is that a particular state is the state that offers the highest novelty. This reward is used to inform the planning objective for the exploration step. 2. The method is tested on maze tasks and shows that it is able to achieve better performance compared to a strong baseline exploration approach. 3. The methods are tested on a set of tasks, where the rewards are used to estimate the distance between state and ground truth neighbors and used for exploration step planning."
SP:257c98dc1a9f3efcbf9544d9ee2ff524b000543d,"This paper studies few - shot classification and out - of - distribution detection for supervised learning in the few - shots setting. The authors propose two tasks and benchmark datasets based on popular few shot classification datasets and propose two new methods for detection. The first task is to train a classifier that can detect examples that do not belong to any of the classes in a few labeled examples per class. This task is named OOD detection ( Out - Of - Distribution detection in Few - Shot Classification ) and it is based on the fact that the classifier needs to be able to distinguish between examples that are from the same class and those from classes that are not present in the class label. The second task is for training a discriminator that is able to discriminate between examples from classes A and B that are out of the distribution, using only labeled examples from each class A and class B. The authors develop and test two methods for training this classifier, the first one is called OOD ( Optimal OOD Classification and Location Based OOD ) and the second is called ADAM ( Adversarial Dequantization by Importance of Class Representations by Missing Representations ). The experiments compare the proposed methods to existing methods ( ADAM and ADAM+ ) and show that ADAM outperforms ADAM by a large margin, ADAM is better than ADAM on the proposed task on the benchmark datasets. The experimental results also show that the proposed ADAM could detect out of distribution more often than the existing methods on the new benchmark datasets and the new tasks."
SP:a3632b773143dfb3a8f104c6b658dfa1167d155b,"This paper proposes a generative model for generating sequences from directed sequence models based on the discriminative natural language understanding model BERT. BERT is a monotonic sequence model that encodes both the directed and undirected sequences. This paper proposes to combine the advantages of these models in order to generate sequences directly from them. To this end, the authors propose a generalized model of sequence generation that unifies decoding in directed and Undirected models. The proposed framework models the process of generation rather than a resulting sequence, and under this framework, various neural sequence models are treated as special cases, such as autoregressive, semi - autoradian, and refinement - based non - autore Progressive models. This unification enables the proposed approach to decoding algorithms originally developed for directed sequence model to adapt decoding algorithms for the undirectED models to the one proposed in this paper, and is competitive with the state of the art on WMT’14 English - German translation. The authors demonstrate this by evaluating various decoding strategies for a cross - lingual masked translation model ( L and ConLample ), and show that generation from the proposed generative models, under the framework, is competitive and comparable with the one generated from the state - of - the - art WMT model. They also demonstrate that the proposed approaches enables constant - time translation with similar performance to that of the one developed for the original BERT model ( Wang et al., 2019 ).   The authors conclude the paper with a set of experiments that compare the performance of BERT with the generation from generative methods derived from the unsupervised and refined models."
SP:eca5e2be9831dfb79c4f5e633cbfadcfd2e00eb1,"This paper proposes a two - stage method for generating LaTeX sequences based on MEs ( mathematical expression recognition ) from a printed mathematical expression image as input and LaTeX sequence as output. In the first stage, this method locates and recognizes the math symbols of input image by object detection algorithm and translates them into LaTeX with position information by seq2seq model equipped with attention mechanism. The second stage, structural analysis of mathematical formulas is carried out separately in two steps, which effectively improves the recognition accuracy and enhances the generalization ability. The experimental results demonstrate that the two -stage method significantly outperforms the end - to - end method of the baseline method. In particular, detection of mathematical symbols and analysis of formulas are carried out in two separate steps, as suggested in the paper ( Liu et al., 2021 ), which is convenient and time - efficient, and can lead to higher accuracy than in the single - stage approach of the baselines. The main contributions of this paper are as follows :   ( 1 ) The authors propose a method to generate LaTeX based MEs from a 3D image of a set of mathematical expressions ( e.g., a scene from a scene in a movie ). The key idea is to use object detection and position information to predict the position of the mathematical symbols from the 3D input. This is similar to the approach of [ 1 ], but the difference is that the object detection is done in two stages ( the first one is based on the image and the second one on the position ). This allows for more efficient computation of position information during the second stage. The authors claim that this approach is more stable than the one based on image prediction ( stage 1 ) and more stable during the two stage training ( stage 2 ). ( 2 ) The method is evaluated on three datasets, where it compares favourably to the baseline ( in terms of accuracy and generalizability ). However, the results do n’t support the authors ’ claim for the higher accuracy ( on the three datasets ). On one of the datasets, the discrepancy between the two stages is less ( 0.02 % ) than that it is for the single stage method. On the authors claim this discrepancy is due to the fact that in stage training is performed using the same number of steps ( 2 / 3 of the steps ), while in stage one ( stage one it is only used for detection and not the other ( stage two )."
SP:923fee8623da1569a7f54a57b4b326f29440b4c0,"This paper proposes a new quantization method for neural network reconstruction based on vector quantization. The idea is to quantize the reconstruction loss of the convolutional neural network with respect to the weights of the outputs rather than its weights. The method quantizes the loss reconstruction error for the in - domain inputs of the neural network to a vector quantized set of unlabeled data, which is then used to compute the true reconstruction loss for the outputs of the network from the quantized data. The quantized neural network outputs are then used for computing the log - likelihood of the loss as a function of the reconstruction error of the weights for the inputs. The paper quantifies the method using the ResNet - 50 model with a memory size of 5 MB ( 20× compression factor ), which it claims preserves a top - 1 accuracy of 76.1 % on ImageNet object classification and a Mask R - CNN with a 26× factor of CNN.    The main contribution of this paper is to develop and validate a method for quantizing a high performing ResNet-50 model by quantizing it using a vector based method based on the quantization of the output of a neural network. This method is different from previous methods in that it does not require the data to be quantized at the time of quantization but rather uses it to estimate the loss at the reconstruction time. This allows for efficient inference on the CPU by using bytealigned codebooks to store the compressed weights at the quantisation time. The authors validate their approach by quantized the output outputs of their neural network on the 5 MB ResNet50 model using a byte - aligned codebook."
SP:74850ad70241948f93fed95ba1f0ac11360437c1,"This paper proposes Tensor - product transformer ( TP - transformer ), a transformer - based approach for solving the recently introduced Mathematica Dataset ( MD - DP ). The authors propose a novel attention mechanism, TP - Attention, which explicitly encodes the relations between each Transformer cell and the other cells from which values have been retrieved by attention. The paper proposes to go beyond linear combination of retrieved values, strengthening representation - building and resolving ambiguities introduced by multiple layers of standard attention. A set of attention maps is presented showing the distance between the original attention layer and the attention layers obtained by TP - attention with respect to the values retrieved by the attention layer. The experiments demonstrate the effectiveness of the attention mechanism and the representation building strategy.   The paper also presents a set of experimental results showing that the proposed attention mechanism TP - Attention leads to better accuracy than the one used by previous methods ( e.g., KL - attention ) and leads to fewer errors than the KL - Attention. The main contributions of the paper are as follows :   ( 1 ) A new attention map showing the distances between original and retrieved values. This helps improve the understanding of the relation structure between cells in the Transformer. ( 2 ) An improvement in the robustness of the computation cost of the TP-Attention compared to KL - Attribute. ( 3 ) An improved set of experiments comparing the performance of the new attention mechanism with that of previous methods."
SP:d319df820c6630c409fab32097652a083e8f53ea,"This paper proposes an approach to generalize deep neural networks ( DNNs ) based on an optimization method to learn a more general classification function, based on a learning algorithm that first reformulates a DNN learning algorithm as a procedure for searching for a source code that maps input features to classes, and derives a necessary and sufficient condition for generalization using a metric based on Kolmogorov complexity ( KDPM ). The empirical sample set, which consists of real - world input samples, can be drawn from an underrepresented or unrepresented subset during inference, which can cause the gap between the training and inference accuracies to be significant. To address this problem, the paper proposes to extend the input features by concatenating the corrupted or perturbed input features with those of input features from empirical samples that belong to the sample set but not to training and test sets, and train the classifier on the extended features. The paper shows that a model trained on encoded input features is significantly more robust to common corruptions, Gaussian and shot noise, as well as adversarial perturbations, than one trained on uncoded input features, e.g., those found via projected gradient descent. Extensive experiments are also carried out to validate the effectiveness of the proposed approach. The main contributions of the paper are as follows.   1. The authors formulate an optimization problem to learn an optimization technique to generalise a general DNN function. The idea is to first reformulate a   learning algorithm    from the original formulation to the one proposed in [ 1 ], and derive a sufficient condition   for generalisation using a universal cognitive similarity metric, namely information distance ( IED ). [ 2 ] Information distance is a metric that measures the distance between input features and classes of a neural network classifier, defined as the average of the features of a classifier and features of another classifier. Information distance can be used to estimate the information distance between features of two neural networks of the same classifier with respect to each other, and to measure the generalization ability of the network to learn features that are similar to classes of classes under the condition that information distance is less than information distance. The proposed generalization condition can be computed using the Kolmohormorphology metric, which is a measure of the similarity between features and classifier features. [ 3 ] The method proposed is evaluated on four image classification tasks, where it is shown that it leads to better generalization than the DNN classification"
SP:b8e86f5e89330d81ba4967a7ed2dbfb56375d8a0,"Graph Neural Networks ( GNNs ) are used for graph classification and graph - based regression tasks. Graph pooling is a critical component of such tasks. This paper proposes a new graph pooling operation based on compressive Haar transforms. The proposed HaarPooling is computed by following a chain of sequential clusterings of the input graph. The input of each pooling layer is transformed by the Haar basis of the corresponding clustering. It operates in the frequency domain by the synthesis of nodes in the same cluster and filters out fine detail information. The main contribution of this paper is to introduce a new algorithm for pooling graphs that is composed of two components : ( 1 ) Haar pooling and ( 2 ) node pooling. The first part synthesizes nodes in a cluster and distributes them among the pooling layers ; the second part pools nodes that do not appear in the initial cluster ; the nodes that are not included in the synthesis layer are discarded, and the ones that are included are re - pooled. The authors evaluate the effectiveness of their algorithm on three graph classification tasks : Graph classification, Graph regression, and TreeNet.   The main contributions of the paper are the following :   1. The introduction of a new combinatorial algorithm based on Haar transform to perform pooling of graphs ; 2. The use of Haar to transform the input graphs ; and 3. The application of the proposed algorithm to GNN tasks."
SP:17bea301d6718ef5f28864dd2445552b3cf65eeb,"This paper studies point - cloud decoders that map a shape representation to a point feature distribution, allowing an arbitrary number of sampled features to be transformed into individual output points. The authors develop three sample - based decoder architectures and compare their performance to each other and show their improved effectiveness over feedforward architectures.   The main contributions of this paper are as follows :   - The first contribution is to develop and study a class of point decoder networks that map shape representations to a distribution of feature vectors instead of a fixed set of distribution points. This class is called variable - sized point clouds. - The second contribution is a set of sample based point - clouds that map feature vectors to a fixed number of output points and a learned distribution to the learned distributions to gain insight into the output transformation. The learned distribution is then used to train the decoder to output high - dimensional representations of the features sampled from the fixed distribution. The trained decoder and the learned distribution decoder are compared and contrasted to a naive feedforward encoder and a fully connected decoder in order to highlight the differences between the two types of architectures and the importance of the different choices of shape representations and the choice of parameters to transform the input features into output points, which is claimed to be crucial to the success of the point cloud decoder. - A set of experiments is performed to verify the effectiveness of the proposed method and compare it to two previous methods, one based on fully connected networks and another based on a fully sampled decoder with a fixed distribution of features. The experimental results are compared to the previous two methods as well as the authors have not used them as a baseline for future work. The main finding of the paper is that the obtained point cloud representations are more expressive and more likely to match the semantics of the input point clouds, which leads to better performance over the feedforward method. The paper also includes an ablation showing that the most expressive point clouds are the ones with the highest resolution."
SP:51d826ead5d1d9cb89d493ce4c39728651bbc57b,"This paper studies deep neural networks ( DNNs ) on real - world noise. It is important to understand the difference between DNN generalization on real and synthetic noise as synthetic noise is generated in a laboratory setting ( with varying amounts of controllable noise per batch ), and real world noise has never been studied in a controlled setting. To this end, this paper establishes a benchmark of realworld noisy labels at 10 controlled noise levels to establish a benchmark. The authors conduct a large - scale study across a variety of noise levels and types, architectures, methods, and training settings. They find that Deep Neural Networks generalize much better on real-world noise than it does on synthetic noise. In particular, when networks are fine - tuned ( i.e. not exposed to noise while connected to a network that is exposed to a lot of synthetic noise, which is common in the real world setting ), DNNS generalize significantly better than they do on synthetic data. When networks are not fine tuned ( e.g. when the network is not robust enough to handle the high level of noise present in real world data ), the generalization performs much worse. In addition, the authors find that it is more difficult for robust DNN methods to generalize well on real noise compared to synthetic data, and vice versa.   The main contributions of this paper are the following :   ( 1 ) A comprehensive literature review of the literature on deep learning and neural networks. This includes a large amount of source data, including synthetic and real data, as well as ablation studies of the effects of different noise levels on DNN performance. This is important because it is the first time this type of research has been conducted on real data. The quality of the source data ( and the diversity of the sources ) is also very high, which makes it hard to compare and compare different types of networks. ( 2 ) The authors perform extensive experiments on both synthetic ( real ) and real datasets to validate their findings, which they hope will facilitate further research on deep - learning on noisy data. ( 3 ) They also conduct a series of discussions on the importance of training neural networks for generalization to noisy data, which are helpful for understanding the properties of DNN"
SP:9873f78fb2821afdbb5551700e6ab6a0e8bcb9f0,"This paper proposes rule - exemplar method for collecting human supervision of denoising rules. The idea is to combine the efficiency of rules with the quality of instance labels. The training algorithm jointly denoises rules via latent coverage variables and trains the model through a soft implication loss over the coverage and label variables. The denoised rules and trained model are used jointly for inference. Empirical evaluation on five different tasks shows that ( 1 ) the proposed method is more accurate than several existing methods of learning from a mix of clean and noisy supervision, ( 2 ) the coupled rule - exemplar supervision is effective in applying the proposed algorithm, and ( 3 ) the rule - exp - rule supervision is synergistic with human supervision.   The main contributions of this paper are the following :   1. The joint denoisation of the set of general rules that is used to jointly train the model is a novel idea. This is similar to the approach of [ 1 ], [ 2 ] and [ 3 ], but the difference is that the former denodes the general rule via latent variables, while the latter denodes it using latent variables obtained from the joint training of the model and the ground - truth coverage variables. This allows for combining the advantages of latent variable denoisers and soft implication losses. The difference is the advantage of the former over the latter in terms of the smoothness of the soft implication as it is easier for the model to learn under soft implication. The authors clearly state this in the paper, and the only requirement for human supervision is that it has to be on a task where the supervision is not too different from the one done by the previous method. This requirement is fulfilled by using the same number of instances per set of rules. 2. The main contribution of the paper is the training algorithm that jointly denoises the ground truth coverage variable and label variable using a soft imply loss. This avoids the need for the human supervision to choose between two sets of instance instances, which may be difficult to distinguish between the one set of instance instance labels and the set that has the full set of instances. 3. The proposed training algorithm is evaluated on 5 different tasks."
SP:6f2c656dbb7629f652a4291d6971625184d8118b,"Graph neural networks ( GNNs ) are a class of deep models that operate on data with arbitrary topology represented as graphs. This paper proposes Mem - GNN, a new layer that can jointly learn node representations and coarsen the graph. It also proposes two new networks based on this layer : memory - based GNN ( MemGNN ) and graph memory network ( GMN ) that can learn hierarchical graph representations. The experimental results show that the proposed models achieve state - of - the - art results in 8 out of 9 graph classification and regression benchmarks. The learned representations could correspond to chemical features in the molecule data."
SP:81bc52d734c86975d741b6482d65ca71a9d81620,"This paper studies the convergence of orthogonal weighted Gaussian initializations for deep linear neural networks ( DLNs ). The authors compare the convergence time with and without iid initializations and highlight the advantage of using iid initialization over the standard Gaussian initialization with iid weights. In particular, the authors study the effect of the choice of the initialization scales between the depth of the network and the number of initializations ( linearly in the depth ). They show that for deep networks, the width needed for efficient convergence to a global minimum with   minimum initializations is independent of the depth, whereas it is more relevant for orthogonally weighted Gaussians.    The authors then provide a rigorous proof that drawing the initial weights from the Orthogonal group speeds up convergence compared to   the standard gaussian initialization and show that the difference in convergence time between   iid and   wide initializations can be explained by the fact that the distance between the initializations of the two networks is greater in deep networks with linearly distributed initializations than it is with shallow networks with large initializations. They also provide an explanation for the discrepancy between the convergence times of different initialization schemes and show how the benefits of a good initialization can persist throughout learning. The paper concludes with a discussion of recent empirical results suggesting that a good initialization can help improve convergence times and the importance of the chosen initialization parameter width is well explained."
SP:9f5d95fc89c2f0d59d04838aa180f3db67997dfa,"This paper proposes a method to optimize the bit allocation of weights and activations for deep CNNs compression. The authors observe that the performance of CNNs up to 4 bits drops to 0.7 % accuracy, while performance drops to 2 bits are noticeable. The reason for the performance drop is that the compression methods assign equal bit rate to quantize all the activations and weights in all layers. This is not reasonable in the case of high rate compression, such as 2 - bit quantization, as some layers in deep neural networks are sensitive to quantization and performing coarse quantization on these layers can hurt the accuracy. To address the problem, the authors first explore the additivity of output error caused by quantization in CNNs. They find that additivity property holds for CNNs which are continuously differentiable in the layers. Based on this observation, they formulate the optimal bit allocation problem of weights, activations in a joint framework and propose a very efficient method to solve the optimization problem via Lagrangian Formulation.   The authors test their method obtains excellent results on CNNs, and find that it can compress deep CNN ResNet-50 down to 2 bit with only 0.8 % accuracy loss. 			"
SP:7191d7b217a12b1bf9c47d790896a8227c14cc3d,"iWGAN is a novel inference method to fuse auto - encoders and generative generative models in order to avoid mode collapse and convergence issues of Wasserstein GANs ( WGANs ). The proposed iWGAN jointly learns an encoder network and a generative network using an iterative primal dual optimization process. The authors establish the generalization error bound of the iwGANs. They further provide a rigorous probabilistic interpretation of the model under the framework of maximum likelihood estimation ( MLE ). They provide a clear explanation of the advantages of their method over other methods for generating agents with a clear stopping criteria, which has many advantages over other generators. They conduct experiments to demonstrate the ability of their iwgan to avoid the modes collapse and converge to the target distribution with fast convergence speeds.   The authors thank the previous authors for their contributions to the field for providing a principled and competitive training framework for training inference models. The contributions of this paper are as follows :   - The authors propose a novel joint learning framework to learn generative networks by combining the variational gradient descent and iterative dual optimization ( PDE ) learning. The iterative PDE iterates iteratively through iterative gradient descent iterates until convergence to a target distribution. This iterative process is called PDE - ER and it is similar to the one used in the original WGAN paper ( Xie et al., 2021 ). - It is important to distinguish between PDE and PDE because PDE encourages the learning of latent variables from the outputs of the gradient descent step, whereas in PDE the latent variable is only used to estimate the gradient of the output of the iterate. - In this work, the authors show that PDE is necessary to learn the parameters of the generative neural network in order for PDE to be differentiable."
SP:cca6ae14fd0dd12352855e594acf7f3263bb1f24,"This paper proposes mention pair model of anaphoric annotation ( MPA ) to alleviate the effects of sparsity inherent in some crowdsourcing environments. Specifically, it proposes to use a nonparametric partially pooled structure ( PPA ) for annotation tasks where the set of classes is not set - conditioned, and most models of annotation focus on classification tasks where set of class is set predefined. The main contribution of this paper is to propose a model that extends the MPA framework that is used in standard crowdsourcing tasks ( e.g., classification tasks with predefined class labels ). The proposed model is based on the recently published large - scale crowdsourced dataset. The authors show that the proposed model performs better than its unpooled counterpart in conditions of sufficient sparsity, and on par when enough observations are available. The model is also more resilient to different crowdsourcing setups, and it further provides insights into the community of workers. The individual estimates can thus be improved using information about the community about the annotators when the data is scarce.    The main contributions of the paper are the following :   ( 1 ) The authors propose to extend MPA, a generative annotation framework, to handle the cases where class labels are not set predicated. This is done by using a non - parametric, fully parametric encoder - decoder model of the class labels. The encoder encoder maps class labels to a lower dimensional representation, and the decoder is trained to predict the likelihood of class labels from the lower dimension of the parametric representation. The decoder can thus determine the probability that class labels belong to a particular class. This allows the authors to predict class labels more accurately. ( 2 ) Using the newly proposed model for classification tasks, the authors propose a hierarchical community - based annotation task where the class label is predicted from the hierarchical community of annotators. They compare the performance of their proposed model with the state - of the art on standard crowdsourced classification tasks for classification where it is on par performance with the standard annotators and on a few rare datasets where it performs better. On these rare datasets, they show that their model performs on par or slightly better than the SOTA baseline."
SP:4295cae4a56a02eb21c486408c1bf37a7483cb49,"This paper proposes a novel intrinsic reward mechanism for reinforcement learning in the face of sparse reward reinforcement learning, where the reward signal is sparse but the state - of - the - art methods use intrinsic reward signals to supplement the sparse extrinsic reward signal, giving the agent more opportunities to receive feedback during exploration and stabilizing learning. The proposed mechanism is called successor feature control ( SFC ), which is general and not task - specific. It takes into account statistics over complete trajectories and thus differs from previous methods that only use local information to evaluate intrinsic motivation for calculating intrinsic reward signal. The experimental results evaluate the proposed SFC using three different environments with pure visual inputs : VizDoom, DeepMind Lab and DeepMind Control Suite. The results show a substantially improved exploration efficiency with SFC and the hierarchical usage of the intrinsic drives.   The main contributions of the paper are as follows :   1 ) The authors introduce a new type of intrinsic reward denoted as SFC ( Sec. 2 ) to evaluate the intrinsic motivation. 3 ) They propose to learn separate intrinsic task policies and schedule between the intrinsic reward and the task - dependent reward signal to accelerate exploration and stabilize learning. 4 ) They conduct extensive experiments to validate their method and show that SFC does indeed improve exploration efficiency."
SP:9fa22eb03a79bce0fc1c8e84ae8640e010701eca,"This paper presents a method for weakly supervised ( wMAN ) video moment retrieval based on a sentence - to - video ( P2PM ) model using a multi - level co - attention mechanism to learn richer multimodal representations of the time - varying sentence features in a video. This is in contrast to the strongly supervised ( SNR ) method which uses temporal annotations during training. The proposed method is called wMAN ( Weakly - supervised Moment Alignment Network ) and it consists of two components :    1 ) A frame - by - word interaction module to learn language representations for interaction with the visual representations 2 ) A W - WORD - encoder to learn semantic embedding for embedding the sentence features 3 ) A positional encodings module for learning the relative positions of the embeddings in the temporal sequence 4 ) A final mechanism for evaluating the learned representations is the W - SNAIL module. The experimental results on the DiDeMo and Charades - STA datasets demonstrate the effectiveness of the proposed method wMAN as well as the improvement of the SNR method over the state - of - the - art methods.   The main contributions of the paper are as follows. 	 First, the authors propose a novel method for learning video representations from a sentence and a video ( given a video - sentence pair ) pair using a wMAN model. This requires the model to learn how to identify the correct segment ( i.e., moment ) when only being provided with video -sentence pairs. Since the sentence pairs are not available for retrieval, the model must inferring the video segment which is described by the sentence in the video without having access to the temporal annotations. Thus, an inherent challenge is to automatically infer the latent correspondence between the visual and language representations. The authors propose an alignment network to facilitate this alignment. The alignment network consists of a Frame - By - Word interaction module and a Word - conditioned Visual Graph ( WCVG ) module which is a novel application of a WORD embedding to learn visual-semantic representations that contain contextual information of the relative position of their relative positions in the time sequence through iterative message -passing. The experiments show that the proposed network can improve the performance of wMAN over SNR by a significant margin but also obtains an improvement of 10% for the Recall@1 accuracy metric over stronglysupervised state -of - theart methods. The results also show the advantage of WCVG over the W.S.A.R."
SP:27ac670353f34ee7a23bb7622f80c1dfbc0985e0,"This paper proposes a method to train an object - specific deep neural network to synthesize the view - dependent appearance of an object using an RGB video of the object. The goal is to generate photo - realistic re - rendering of reconstructed objects from the RGB video using a proxy geometry that is obtained via multi - view stereo stereo images. The proposed method is called “ learned image - guided rendering ”. It combines image - based rendering and GAN - based image synthesis to obtain a better representation of objects.    The main contributions of the paper are the following :   1. The method proposes to train a neural network that learns how to combine the appearance of captured images with a set of diffuse images that are projected into the target view. The network is trained to predict the view dependent effects of the diffuse images. 2. The diffuse images from the trained network can be projected into other views using a 3D proxy. 3. Based on the predicted views, the pipeline reinserts the original views into the pipeline to obtain the original view. 4. The views are reprojected into the output of a composition network that produces a composite image from multiple reprojected images. 5. The final image is rendered into a final image using an image encoder that produces the final image from the original and reprojected image as input to the decoder. The entire pipeline is trained with supervised learning to learn how to get the desired final image composition from the multiple observations and diffuse images, and self - training to learn the ratio of observed images to diffuse images to the original images to get a final diffuse image with the desired diffuse image composition.   In the experiments, the authors demonstrate the effectiveness of their method on synthetic as well as well - known object geometry from RGB images and augmented data. They also show that the method is effective on augmented data from virtual and augmented reality applications."
SP:257d124367b1da9a595dc11a9df750d6bade298e,"This paper presents a sparse representation of model uncertainty for deep neural networks ( DNNs ) that relies on an inverse formulation of Multivariate Normal Distribution ( MND ), an information form. It shows that the uncertainty can be estimated in this form using a scalable Laplace Approximation scheme, which involves a diagonal correction of the Kronecker - factorized eigenbasis. The paper further devise a novel low - rank approximation of this eigenvalue, which exploits spectral sparsity of DNN to realize a sparsification that develops into a memory - wise tractable sampling computations. Empirical evaluations over various benchmarks show the superiority of the proposed approach over existing methods.   The main contributions of this paper are as follows :   1. The authors develop and study an approximate distribution over parameters of a Bayesian neural network, based on MND, using Laplace approximation methods ; 2. They show that the obtained distribution is expressive and general enough to represent the uncertainty of the DNN model. 3. They further devise methods to obtain sparsified versions of MNDs that are computationally tractable. 4. They provide empirical evaluations over several benchmarks."
SP:2e03ceba4004b82f86f8349352a8ee4520e9c35d,"Min Hash is a fundamental method to compute set similarities and compact high - dimensional data for efficient learning and searching. The bottleneck of MinHash is computing k ( usually hundreds ) MinHash values. One drawback of OPH is that the load of the bins ( the number of elements in a bin ) could be unbalanced, which leads to the existence of empty bins and false similarity computation. Several strategies for densification, that is, filling empty bins, have been proposed. This paper proposes a method called AHash, which can generate as few empty bins as possible without hurting runtime efficiency compared with OPH and densification strategies ( e.g., AHash is more load - balanced and accurate without hurting the runtime efficiency ).   The authors first give background on min - hash, min - set similarity and set - to - set hashing ( min - SET ). Then, the authors propose a method to densify the bins to reduce the amount of error incurred by the unbalanced load incurred by OPH ( AHash ). The authors argue that AHash can achieve better performance than APH and OPH because AHash has a lower computational complexity ( A.H.C. ) and uses fewer elements per permutation. Next, this paper proposes to use the same permutation per element in each bin to obtain a value for a given element, but split elements into k bins ( instead of using permutations per elements in OPH, which requires many permutations ). This way of splitting elements into bins has the advantage that it does not require much computation overhead ( compared to OPH ). In order to encourage the use of the full bins in AHash with smaller permutations, authors propose to use a technique called load-balanced amortization ( amortized hash ( $ \epsilon$ ) to generate more balanced elements in the empty bins. However, this method is not as efficient as the densification method ( $ densification$ ) as it is costly and time - consuming, and hence authors argue in the paper that the advantages of the proposed method is only for the first stage of densification and not the second stage which is the final stage which uses the full bin to compute the value. To support the idea of $ $ $ amortised hash $ a.h$, authors consider two scenarios : ( 1 ) a scenario where the elements are divided into k ( each element can be split into k separate bins ; ( 2 ) another scenario where each element is split into"
SP:d73827ab98b0ff6bd92abfefea43a5f88ea40de2,"This paper proposes a feature extraction method for extracting features from phase shift data by adding a graph structure to each data point and constructing a suitable machine learning architecture for graph data with graph parametrization. The authors consider the problem of collecting data about periodicity of rotating shafts in various machine transportation systems. They argue that it is difficult to control the collection timing of the measurements because pre -cise timing creates phase shifts in the resulting data that alter the ordering of the data points collected. They propose a robust method to identify and quantify these alterations in the order of the input vectors.   The main contributions of this paper are as follows :   ( 1 ) The authors observe that the order in which input vectors are composed depends on the order ( i.e., order of vectors ) of input vectors ’ components ( e.g., input vector A is the axis of input vector D ). Therefore, if input vectors A and D are composed of the same, the resulting input vector vector D contains the same number of base vectors ( 0, 0, 1 ) and, if multiple base vectors are used ( more than one, multiple layers ), then a phase shift can be observed in the collected data points. This phenomenon is termed as the “ phase shiftion ”. ( 2 ) They identify a suitable graph structure for extracting the features from the data point generated by the graph structure used to generate the base vectors and propose to use it to generate graphs for the extracted features. ( 3 ) They use graph structure extracted from data point A and graph structure generated from base vectors to generate graph features for extracted features from data points A and data B.   In the experiments section, the authors compare their proposed method with two baselines : a linear model extraction method ( linear model with linear model graph structure extraction and a nonlinear model extraction process with graph graph structure extractor. The experiments show that the proposed method generally outperforms the baselines more often than not, especially when the features extracted from the linear model are not related to the predicted phase shift. When the authors do not have access to the raw data points during the training phase, the features are difficult to extract. When all data points are generated during training phase shift is within the same distribution, the extracted feature is useless."
SP:0df5ad333eb4ff9cca7f2d117909e2ce533a65d8,"This paper proposes a novel method to train neural text generation decoders that are more faithful to the source text than state - of - the - art methods. The main idea is to train the decoder by assigning a confidence score to each position in the input text, which is used as a measure of the confidence of the generation at each time step. This score is learned in training using a variational Bayes objective, and can be leveraged at inference time using a calibration technique to promote more faithful generation. The method is evaluated on a structured data - to - text dataset ( WikiBio ), and compared with two prior methods ( NeurASP and GPT-2 ). The results show that the proposed method is more faithful than the previous methods according to both human evaluation metrics and the assumptions of the source generation method."
SP:03307deac29173b2968fbd08f95fc77eb1f82410,"This paper proposes a new pruning method, lookahead pruning, which extends the single layer optimization for magnitude - based pruning to multi - layer pruning. The motivation comes from the observation that the Frobenius distortion of a linear operator corresponding to a single layer is minimised when the number of layers is polynomial in the dimension of the network. Inspired by this observation, the authors propose a simple pruning algorithm, which can be viewed as an extension of the multi layer optimization proposed in [ 1 ] to the neural network setting. The proposed method is evaluated empirically on various networks, including VGG and ResNet, particularly in the high - sparsity regime. The experimental results demonstrate that the proposed method consistently outperforms magnitude-based pruning on these networks.    The main contributions of this paper are the following :   1. The authors develop a new layer - wise pruning approach, which generalizes the single - layer optimization to a multi -layer optimization. This approach is shown to outperform the magnitude pruning and its variants on the ReLU - based Network ( VGG ), ResNet ( RNet ), and VGG+ ( ResNet - GP ) by a large margin. The main reason for this is that, for each layer, the pruning gradient does n’t go as high as it did for the first layer in the case of VGG, and for RNet it only goes as low as the second layer. 2. Theoretical results are provided for evaluating the performance of the lookahead method on the networks considered in this paper, and experiments are compared with the one - layer and two - layer versions of lookahead. The results show that lookahead outperforms the other pruning methods both in terms of accuracy ( in the sense that the upper bound on the average pruning error is higher for the upper layers )."
SP:dc80fdc75bc14ae19fe4ba9b85c35ce00b12856f,"This paper proposes Moniqua, a decentralized graph communication method for SGD where parallel workers are connected to form a graph and communicate adjacently. The main idea of the method is to use a graph neural network ( graph neural networks ) to communicate among workers who are not connected in a non - convex way ( e.g., only the nodes connected to the graph are used to communicate ). This allows for using graph communication in decentralized SGD that does not require the use of gradient clipping or gradient assumptions ( which are costly and time consuming ).   The main contributions of this paper are the following :   ( 1 ) This paper proposes a new method called Monqua, which is based on the Graph Neural Network ( GraphNet ). GraphNet is a neural network that allows for graph communication between parallel workers without the need for gradient clipping / gradient assumption ( as is the case with full - precision communication ). The paper shows that this method is robust to very low bit - counts, allowing for faster convergence without affecting convergence when training VGG16 on CIFAR10. ( 2 ) It shows that the method improves upon prior works in that it requires no additional memory ( with respect to the wall clock time ) when computing the objective function ( which is costly ). ( 3 ) It supports biased quantizers ( if the quantizer is linear in its weights ) and shows that it converges faster than other quantized decentralized algorithms ( which do not support biased quantization or linear quantizers ). Empirically, it is shown that it is more robust than GraphNet in terms of the number of bits it needs to communicate with each iteration ( which seems to be a lower bound in theory )."
SP:86c61a658d07ab86e2d84cef7e480bf7a06e4ddb,"This paper proposes a new type of partial models for reinforcement learning ( RL ). Previous works considered partial models, which model only part of the observation, as a way to jointly learn a model of future rewards and observations and use it to plan the agent’s next actions. However, jointly modeling future observations can be computationally expensive or intractable if the observations are high - dimensional ( e.g. images ). In this paper, the authors propose a general family of models that are provably correct, yet fast to learn because they do not need to fully model future observations. The authors first show that partial models can be causally incorrect : they are confounded by the observations they don’t model, and can therefore lead to incorrect planning. To address this, they introduce a new class of models, the Fast Partial Models ( PFPMs ). The PFPMS family consists of three main components :   ( 1 ) A fast partial model for rewards. This part is fast because it only needs to learn some of the parameters of the reward function to be accurate. ( 2 ) It is careful to only learn parameters that are relevant to the task at hand. ( 3 ) It learns parameters that depend only on the reward but also has access to all rewards and actions.   The main contribution of this paper is the introduction of the FFPMs, which are a set of 3 models that extend the fast partial models from [ 1 ] to [ 2 ]. The full text of the models is available online for pre - training and post - training. The experimental results are presented in Table 1, and the full text is available in the supplementary material ( Figure 2 and Table 2 )."
SP:c70479b2096a52584b242de58272ca8d8565feea,"This paper proposes a new generative model based on the VAE framework by Wyner ( 1994 ). The core idea of the model is to learn a succinct representation of two variables that is useful for joint generation and for self - training. The representation is a weighted sum of local representations capturing the remaining randomness ( e.g., texture and style ) in respective data variables by imposing the mutual information between the data variables and the common representation as a regularization term. Experimental results show that learning a succinct common representation achieves better learning performance than learning a local representation with style - agnostic generative filters.   The main contributions of the paper are the following : - A new VAE architecture is proposed that decomposes a pair of correlated data variables into their common representation and local representations ( i.e., a shared concept ). - The method is compared with two previous VAE approaches, DAE and VAE - Channel Synthesis ( Wang et al., 2018 ), in which common information arises as the limit of the expressiveness of the local representations. - Experimental results demonstrate that the proposed approach is more effective than the previous approaches in learning a representation that is more expressiveness. - A joint generation task is proposed where the learned representation is used to generate samples with the same distribution as the original data. Results show that the joint representation is better learnable than the local representation and the derived representation."
