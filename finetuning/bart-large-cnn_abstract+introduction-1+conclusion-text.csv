paper_id,summary
SP:b19df5243359791fbaad005d6f13d7e9fdb0ff63,"This paper proposes a new method for multi-agent multi-task learning based on role-based learning. The key idea is to decompose joint action spaces into restricted role action spaces by clustering actions according to their effects on the environment and other agents. A role selector is learned in a smaller role space and at a lower temporal resolution, while role policies are learned in significantly reduced primitive action-observation spaces. The authors further integrate information about action effects into the role policies to boost learning efficiency and policy generalization. The proposed method outperforms the current state-of-the-art MARL algorithms on 9 of the 14 scenarios that comprise the challenging StarCraft II micromanagement benchmark."
SP:7deb61890d97422a0fe141ca807f968c70ab239a,"This paper studies the behavior of the stochastic subgradient descent (SSGD) method applied to over-parameterized nonsmooth optimization problems that satisfy an interpolation condition. By leveraging the composite structure of the empirical risk minimization problems, the authors prove that SSGD converges with rates O(1/ ) and O(log(\frac{1}{1/}) for convex and strongly-convex objectives when interpolation holds. These rates coincide with established rates for the SGD method under the same interpolation conditions. The analysis provides a partial explanation for the empirical observation that sometimes SGD and SSGD behave similarly for training smooth and nonsm smooth machine learning models."
SP:c7e0b3fedc0d0409d662dd612b529fdacad2b03e,"This paper proposes a method to improve the efficiency of transformer architectures by introducing non-linear ""reservoir"" layers, which are randomly initialized and never updated during training. The reservoir layers can be either convolutional or recurrent neural networks. The authors also propose to skip the backward pass by approximating top-layer gradients using an approach they call backskipping, with a relatively small sacrifice in performance. Experiments are conducted on a variety of machine translation and language modeling tasks. "
SP:ba9f1d4738ec67a440346f3ac6c4cf35f7232077,"This paper proposes a new method for constructing steerable convolutional filters based on group representation theory. In particular, the authors show that filter transformed kernels can be used to convolve input/output features in different group representations. This interpretation helps complete the puzzle of steerable CNN theory and provides a novel and simple approach to implement steerable filters. Experiments are performed on multiple datasets to verify the feasibility of the proposed approach."
SP:c1116fbb4d058eb6be195b5d13d19a55ba86b602,"This paper proposes an optimal neural synthesis approach where the goal is to find a program that satisfies user-provided constraints while also maximizing the program’s score with respect to a neural model. Specifically, the authors focus on multimodal synthesis tasks in which the user intent is expressed using combination of natural language (NL) and input-output examples. At the core of the method is a top-down recurrent neural model that places distributions over abstract syntax trees conditioned on the NL input. This model not only allows for efficient search over the space of syntactically valid programs, but it also allows us to leverage automated program analysis techniques for pruning the search space based on infeasibility of partial programs."
SP:55e02d79146bbb42f1ab6d4fafa2db5ddbe599b0,"This paper proposes a protein graph convolutional neural network (PGCN) to predict the specificity of a protease enzyme from the Hepatitic C virus. The proposed method is based on a protein-substrate interaction graph generated using the Rosetta energy function that describes the topology and energetic features, to determine the substrate specificity of the enzyme. The authors use the PGCN to recapitulate and predict the specificity of the NS3/4 protease from the hepatitis C virus and show that its performance in classification tasks is equivalent or better than existing methods. "
SP:7727eeb7b17ad94ddfa0cf24e64a9626d83a8876,"This paper studies the underestimation bias of double Q-learning and its variants in deep Q learning. The authors show that double Q learning may lead to multiple non-optimal fixed points under an approximate Bellman operator. To address this issue, this paper proposes a doubly bounded estimator that utilizes an abstracted dynamic programming as a lower bound estimation to rule out the potential non-optimality fixed points. The experiments show that the proposed method has shown great promise in improving both sample efficiency and convergence performance."
SP:1d630b69f95392a5ef3d7d580b523e077a3555a8,"This paper proposes a two-step training framework for deep generative models (DGMs) of high-dimensional natural images. First, it generates images in low-frequency bands by training a sampler in the wavelet domain. Then, it super-resolves these images back to the pixel-space with a novel wavelet super-resolution decoder network. Since the sampler and decoder can be trained in parallel and operate on much lower dimensional spaces than end-to-end models, the training cost is substantially reduced. On ImageNet 512x512, the proposed method achieves a FID of 10.59 – beating the baseline BigGAN model – at half the compute (256 TPU-v3 cores)."
SP:b943a73b1ec34867371325748dc3a91ff4011947,"This paper analyzes self-supervised learning for few-shot learning (FSL). In particular, it analyzes why a pre-trained embedding network with self supervised training can provide representation for downstream FSL tasks in theory. The authors first summarized the supervised FSL methods and explained why SSL is suitable for FSL. Then, they further analyzed the main difference between supervised training and self supervised learning on FSL and obtained the bound for the gap between self supervised loss and supervised loss. Finally, they proposed potential ways to improve the test accuracy under the setting of self supervised setting. "
SP:bd552f98e6a447cefa6b1a9bbdf40bc6539fb643,"This paper studies the convergence of teacher-student neural networks with finite width. In particular, the authors consider the case of a two-layer network with ReLU activation and Gaussian inputs. They show that the student neurons all align with one of the teacher neurons, hinting that there are no local minima near any random initialization. The authors prove that under the most basic settings, all student neurons must align with the teacher neuron at any local maxima. The methodology is extendable to more general cases, where the proof can be reduced to analyzing the properties of a special class of functions that we call angular distance (AD) function."
SP:0f62846913ec10b44ed32845770da0565479dc75,"This paper proposes Deep Adaptive Semantic Logic (DASL), a framework for automating the generation of deep neural networks that incorporates user-provided formal knowledge to improve learning from data. The authors provide formal semantics that demonstrate that our knowledge representation captures all of first order logic and that finite sampling from infinite domains converges to correct truth values. DASL’s representation improves on prior neuro-symbolic work by avoiding vanishing gradients, allowing deeper logical structure, and enabling richer interactions between the knowledge and learning components. Experiments on two computer vision problems with limited training data demonstrate that knowledge reduces data requirements for learning deep models."
SP:2f19259d65fab904c1b771244da3dcb2f8aa0c26,"This paper studies the effect of regularization on the learning of feedforward residual neural networks (ResNets). The authors show that, even though ResNets can express iterative solutions, they do not learn them when trained conventionally on computer vision tasks. They then introduce regularizations to encourage iterative convergent computation and test whether this provides a useful inductive bias. To make the networks more iterative, they manipulate the degree of weight sharing across layers using soft gradient coupling. They also impose a Lipschitz constraint on the residual functions using spectral normalization."
SP:6c14506b8b2b06043409d912e6bf877651aaa665,"This paper proposes two new normalization techniques for improving robustness to out-of-distribution (OOD) data. The first technique, SelfNorm, uses attention to recalibrate statistics (channel-wise mean and variance), while the second technique, CrossNorm, exchanges the statistics between feature maps. The authors show that SelfNorm and CrossNorm can complement each other in OOD generalization. Extensive experiments on different domains (vision and language), tasks (classification and segmentation), and settings (supervised and semi-supervised) show their effectiveness."
SP:2774abdc11917321dd4994af0f0da1ff824bea03,"This paper proposes to use an attention module in the convolutional encoder of an RL agent to improve the sample efficiency and final performance of reinforcement learning from pixels. The attention module consists of two modules: (1) an encoder-attention module that maps the input pixels to a latent space, and (2) a convolution layer that takes the latent space as input and outputs the output of the attention module. The proposed method is evaluated on the DeepMind Control Suite (DMC Suite) benchmark."
SP:31a7051d08d19c01e11f1fac2f3041ed2fa28f15,"This paper proposes an extension of the GradNorm method for multi-task learning, called Rotograd, which aims to minimize negative transfer among tasks by homogenizing the gradient magnitudes and directions across tasks. Specifically, the proposed method adds a layer of task-specific rotation matrices that aligns all the task gradients. Theoretical guarantees on the algorithm stability and convergence are provided. Empirical results on several real-world datasets and network architectures show that the proposed algorithm outperforms previous approaches."
SP:ac9ebd027b92527d9a87b13ad11d002d99a2b0f6,"This paper proposes a new constraint for unsupervised geometry-invariant image translation, called minimal geometry-distortion constraint (MGC), as a general I2I translation constraint to guarantee the consistency of geometry structure of source and translated images, and thus reduce translation mismatch in the translation process. In addition, the authors propose an approximate representation of mutual information called relative Squared-loss Mutual Information (rSMI) that can be efficiently estimated analytically. The experimental results demonstrate that MGC achieves high quality translation to maintain the geometry of images in original domain."
SP:92a38d7d18f07f68b8f93c61180e2cc1dddd21de,"This paper studies the effect of sampling patterns in point cloud GANs. The authors show that sampling-insensitive discriminators (e.g. PointNet-Max) produce shape point clouds with point clustering artifacts, while sampling-oversensitive discriminator (PointNet++, DGCNN, PointConv, KPConv) fail to guide valid shape generation. They propose the concept of sampling spectrum to depict the different sampling sensitivities of discriminators. They further study how different evaluation metrics weigh the sampling pattern against the geometry and propose several perceptual metrics forming a sampling spectrum of metrics. Guided by the proposed sampling spectrum, they discover a middle-point sampling-aware baseline discriminator, which improves all existing point cloud generators by a large margin."
SP:16c4be3eb162bc81cb3343c2fc115eb8e926a5b5,"This paper studies the adversarial robustness of Capsule Networks (CapsNets). CapsNets have been shown to be more robust to white-box attacks than CNNs under popular attack protocols. Besides, the class-conditional reconstruction part of CapsNet is also used to detect adversarial examples. This paper investigates how the inner workings of CapsNet change when the output capsules are attacked. Based on the observation, this paper proposes a novel vote attack where we attack the votes of the CapsNet directly. The vote attack is not only effective but also efficient by circumventing the routing process. "
SP:dbd093dff7a38ba8882bb8119c34623ddaaf4cc6,"This paper proposes a meta-reinforcement learning algorithm that uses privileged information in the form of a task descriptor at train time to improve the learning of recurrent policies. The method learns an informed policy (i.e., a policy receiving as input the description of the current task) that is used to both construct task embeddings from the descriptors, and to regularize the training of the recurrent policy through parameters sharing and an auxiliary objective. This approach significantly reduces the learning sample complexity without altering the representational power of RNNs, by focusing on the relevant characteristics of the task, and by exploiting them efficiently. The proposed method is evaluated in a variety of environments that require sophisticated exploration/exploitation strategies and shows that it outperforms vanilla RNN, Thompson sampling and the task-inference approaches to meta reinforcement learning."
SP:bd89d254fbf31db61db237d08ab42981e27c52df,"This paper proposes a method to learn an RL policy from offline data in the real-world sequential recommendation system (SRS). Instead of increasing the fidelity of models for policy learning, this paper handles the distortion issue via learning to adapt to diverse simulators generated by the offline dataset. Experiments are conducted in synthetic environments and a real world ride-hailing platform. The results show that the method overcomes the distortion problem and produces robust recommendations in the unseen real world."
SP:1a166b28cf684e0d5759bd629f6a53370d2bf11c,"This paper proposes a reinforcement learning algorithm that uses imitation learning to learn goal-reaching policies from scratch, without the need for expert demonstrations or a value function. The main idea is to leverage the property that any trajectory is a successful demonstration for reaching the final state in that trajectory. The authors propose a simple algorithm in which an agent continually relabels and imitates the trajectories it generates to progressively learn goal reaching behaviors from scratch. Each iteration, the agent collects new trajectories using the latest policy, and maximizes the likelihood of the actions along these trajectories under the goal that was actually reached, so as to improve the policy. They formally show that this iterated supervised learning procedure optimizes a bound on the RL objective, derive performance bounds of the learned policy and demonstrate improved goal reaching performance and robustness over current RL algorithms in several benchmark tasks."
SP:c306530164d677e670554eeba8203c66bb3d9f7a,"This paper proposes FastSpeech 2, a fast and high-quality end-to-end TTS system to address the issues in FastSpech. The authors propose to directly train the model with ground-truth mel-spectrograms to simplify the training pipeline and avoid information loss compared with FastSpeach. They also introduce more variation information of speech (e.g., pitch, energy and more accurate duration) as conditional inputs to improve the duration accuracy and introduce more variance information including pitch and energy to ease the one to many mapping problem, and improve pitch prediction by introducing continuous wavelet transform. The experimental results show that the proposed method achieves a 3x training speed-up over the original fastSpeech."
SP:79e9fb20d383816f54738ce70d137131ebc10290,"This paper studies the unsupervised dimension reduction problem (UDR) in the language of tempered distributions, i.e. approximating an empirical probability density function p(x) by another tempered distribution q(x), whose support is in a k-dimensional subspace. The authors reformulate the UDR problem as the minimization of the distance between q and q, D(q,p) over a set of generalized functions. This formulation allows to establish a connection with another classical problem of data science — the sufficient dimension reduction (SDR) problem. An algorithm for solving the first problem induces an algorithm for the second and vice versa. "
SP:93e54522e6c2b805905d21fc968fc40866f2898b,"This paper proposes Feature Contrastive Learning (FCL) to balance robustness and sensitivity in deep neural network training. FCL aims to promote model sensitivity to perturbations of high utility features, and inhibit model sensitivity of low utility features. The performance of FCL is validated on both synthetic and real image classification datasets."
SP:f03c50f15022c4f56ac2b3085354ffed38ad1145,"This paper proposes a novel method for imitation learning based on adversarial learning. The key idea is to use a discriminator network to learn a latent representation of the expert's state and action space. The discriminator is regularized with two mutual information constraints to encourage the discriminator to learn features that encode goal-completion information and discard domain information about the observations. The proposed method is evaluated on a variety of control tasks, including balancing, manipulation and locomotion."
SP:ef18f4188426bc01be309633b486884b0e7a81a4,"This paper analyzes the generalization of the lottery ticket hypothesis (LTH) by analyzing the geometric structure of the objective function and the sample complexity to achieve zero generalization error. It shows that the convex region near a desirable model with guaranteed generalization enlarges as the neural network model is pruned, indicating the structural importance of a winning ticket. Moreover, when the algorithm for training a pruned neural network is specified as an (accelerated) stochastic gradient descent algorithm, it is shown that the number of samples required for achieving zero generalisation error is proportional to the size of the non-pruned weights in the hidden layer. "
SP:eed6cb2f8caed39f8295f4aeb6e044c2ac981c4d,"This paper proposes AutoLabel to automatically learn the labels for augmented data, based on the distance between the clean distribution and augmented distribution. AutoLabel is built on label smoothing and is guided by the calibration-performance over a hold-out validation set. Experiments on CIFAR-10, Cifar-100 and ImageNet show that AutoLabel can improve models’ accuracy and calibration performance, especially under distributional shift. "
SP:0d5017e1a405bf86e3bac40e6e59886d4bf48450,"This paper analyzes self-supervised representation learning using a causal framework. The authors show that representations need to be invariant predictors of proxy targets under interventions on features that are only correlated, but not causally related to the downstream tasks. Based on this, the authors propose a new objective, Representation Learning via Invariant Causal Mechanisms (RELIC), that enforces invariant prediction of proxy target across augmentations using an invariance regularizer. Experiments show that RELIC significantly outperforms competing methods in terms of robustness and out-of-distribution generalization."
SP:8f80a6f79f78c6421857f392c9a5e98061d7eb60,This paper proposes a visual transformer network (VT) for object goal navigation. The main idea is to learn a spatial-aware visual representation of the scene and use it to guide the agent towards a target object. The proposed method is evaluated on the artificial environment AI2Thor. 
SP:3e7cbe3dff592ef371e48dd86be7719fc5343f17,This paper studies the problem of federated learning. The authors propose a communication-computation efficient secure aggregation (CCESA) method to reduce the amount of communication/computational resources at least by a factor of $\sqrt{n/log n}$ relative to the existing secure solution without sacrificing data privacy. The key idea is to design the topology of the secret-sharing nodes (denoted by the assignment graph G) as sparse random graphs instead of the complete graph corresponding to the secure aggregation method. Theoretical guarantees on the reliability/privacy of the proposed scheme are provided. Experiments on real-world datasets show that the proposed method achieves the same level of reliability and privacy.
SP:00fae41e0eca0a1575cd7b2dcfabf0dc5c9c8b8a,"This paper proposes a new neural network architecture for auction design. The proposed architecture is based on a two-player game between an Auctioneer and a Misreporter. The paper proposes to use a time-independent Lagrangian instead of a non-stationary objective function, which is easier to train and makes comparisons between mechanisms possible. Experiments are conducted to demonstrate the effectiveness of the proposed method."
SP:a0e8061beb5e9a6c631419861559d22b8d645cb4,"This paper proposes a bi-tuning approach to fine-tune pre-trained representations for supervised and unsupervised pre-training. The proposed approach is based on two heads: a classifier head with an improved contrastive cross-entropy loss to better leverage the label information in an instance contrast way, and a projector head with a newly-designed categorical contrastive learning loss to fully exploit the intrinsic structure of data in a category-consistent way. The experimental results show that the proposed approach achieves state-of-the-art results on CUB tasks on both supervised and Unsupervised pretrained models."
SP:87e5b552c13d73bd85249062a152c6c140e594a9,"This paper studies the problem of adversarial robustness and adversarial training. The authors argue that standard adversarial accuracy is not a good measure of robustness, and propose a new measure called ""Genuine Adversarial Accuracy"" to measure the robustness of classifiers. This measure does not trade-off accuracy on clean data and accuracy on the adversarially perturbed samples. In addition, it does not favor a model with invariance-based adversarial examples. "
SP:2fda410b9281c5e253d385bc4382ec168bc161f3,"This paper studies the problem of fairness in graph-structured data. Specifically, the authors focus on dyadic fairness, which articulates a fairness concept that a predictive relationship between two instances should be independent of the sensitive attributes. Based on this, they theoretically relate the graph connections to Dyadic fairness on link predictive scores in learning graph neural networks. Then, they propose an algorithm, FairAdj, to empirically learn a fair adjacency matrix with proper graph structural constraints for fair link prediction, and in the meanwhile preserve predictive accuracy as much as possible."
SP:b614e9fbec58e9efa7722d2ec4a60fc93d210f92,"This paper proposes a new autoencoder model, called DEAE, which uses disentangled representation and regularization to guarantee the validity of exploration in latent space and achieve controllable synthesis. The encoder of DEAE first turns the input sample into a disentangling latent code, then explores the latent code space through directed interpolation. To aid the interpolated latent code in successfully outputting a meaningful sample, after the decoder, DEAE regularizes the output by “reusing” the encoder to force the obtained latent representation to maintain perfect disentanglement. Experiments demonstrate that DEAE can improve the performance of downstream tasks by synthesizing attribute-controllable augmented samples."
SP:c934adb14926a00ef9c73c9773cb0b3a2669921e,"This paper proposes a new Bayesian memory allocation scheme that bridges the gap between episodic and semantic memory via a hierarchical latent variable model. The authors take inspiration from traditional heap allocation and extend the idea of locally contiguous memory to the Kanerva Machine, enabling a novel differentiable block allocated latent memory. They demonstrate that this allocation scheme improves performance in memory conditional image generation."
SP:e63d7d8c581019e17585fb9c0eac33d6836e187d,"This paper analyzes the effect of attention mechanisms on the loss landscape of neural networks on attention mechanisms. The authors show that, under mild assumptions, every local minimum of the attention model has low prediction error, and attention models require lower sample complexity than models without attention. Besides revealing why popular self-attention works, the theoretical results also provide guidelines for designing future attention models."
SP:f739d199fdee26f09994e3f9487aec1eab0f2e89,"This paper extends the concept of expected free energy (EFE), which is a core quantity in active inference, and claims that EFE can be treated as a negative value function. Motivated by this connection, the authors propose a simple but novel method for learning a prior preference from experts. This illustrates that the problem with inverse RL can be approached with a new perspective of active inference. The experiments show the applicability of the proposed method to an inverse RL problem."
SP:5592b79e49eba95c15103a3348f2bde57b60f2ab,"This paper proposes a data augmentation method to improve generalization in both adversarial and standard learning by using out-of-distribution (OOD) data that are devoid of the abovementioned issues. The authors show how to improve the generalization theoretically using OOD data in each learning scenario and complement their theoretical analysis with experiments on CIFAR-10, Cifar-100, and a subset of ImageNet. The results indicate that undesirable features are shared even among image data that seem to have little correlation from a human point of view."
SP:3cac7a2c310165ed0de46d8e5546c3bfbd639158,"This paper proposes a new method for meta-reinforcement learning (meta-RL) called Fast Linearized Adaptive Policy (FLAP) that learns a shared linear representation of the policy so that when adapting to a new task, it suffices to predict a set of linear weights. A separate adapter network is trained simultaneously with the policy such that during adaptation, we can directly use the adapter network to predict these linear weights instead of updating a meta-policy via gradient descent, such as in prior meta-RL methods like MAML, to obtain the new policy. The application of the separate feed-forward network not only speeds up the adaptation run-time significantly, but also generalizes extremely well to very different tasks that prior MetaRL methods fail to generalize to. Experiments on standard continuous-control tasks show FLAP presenting significantly stronger performance on out-of-distribution tasks."
SP:21a1bd4ada0723c96c0dbf7a142a2faf5defa4e3,"This paper proposes a federated kernel k-means algorithm to solve the optimization problem of kernel k means under the federated setting. The authors propose a distributed stochastic proximal gradient descent (DSPGD) algorithm to determine an approximate solution to the optimization of the problem. Then, a communication efficient mech anism (CEM) is designed to reduce the communication cost. Theoretical analysis shows that DSPGD with CEM converges with an O(1/T) rate, where T is the number of iterations. The experimental results show that the proposed algorithm achieves the highest clustering quality."
SP:be568dd3fea51ce33a6d1e4b07dda5aee6342395,"This paper proposes CompOFA, a method to reduce the size of the search space for once-for-all (OFA) networks. The method is based on the idea of compound couplings between model dimensions. The authors show that this simple heuristic can reduce search space by several orders of magnitude. They also show that their method can achieve a 2x reduction in training time and a 216x speedup in model search/extraction time compared to the SOTA."
SP:04b84d26cf282dbb753cbf27f14c334f65d3f8ec,"This paper proposes a meta-learning algorithm, ADML (ADversarial Meta-Learner), which leverages clean and adversarial samples to optimize the initialization of a learning model in an adversarial manner. The authors claim that the proposed method is robust to adversarial attacks and can be used to tackle the cases with limited and even contaminated samples. Experiments are conducted on two widely-used image datasets, MiniImageNet and CIFAR100, to demonstrate the effectiveness of ADML."
SP:dfbaa6b53c4e8328d52666ad4641fc917bf0c0b3,"This paper proposes a self-attention mechanism to improve the decoding of linear error correction codes. The proposed method is based on the self attention mechanism of Vaswani et al. (2017) to embed all the differentiated group permutations of a code in a word-independent manner, by extracting relevant features. This is done once before the test phase during a preprocess phase. At test time, a trained NN accepts a corrupted word and the embedded permutations and predicts the probability for successful decoding for each permutation. "
SP:c860a7b0952d708e7851c9bc4b63d246f64d1cba,"This paper proposes to use a Bag of Words (BOW) clustering technique to partition the unlabeled training data into relatively homogeneous clusters of text instances, and treat these clusters as labeled data for an intermediate text classification task, and train BERT with respect to this multi-class problem, prior to the final fine-tuning over the actual target-task labeled data. Experiments are conducted on a variety of benchmark datasets. "
SP:ea37f5882fd98dd4ce233077bb3069517d4ed4ea,This paper studies model-based reinforcement learning (MBRL) in the context of the Acrobot environment. The authors compare a set of generative models (Mixture Density Networks (MDNs) and deterministic models (Deterministic MDPs) using a fixed random shooting control agent. They show that the MDNs outperform the deterministic MDNs when multimodality is required. They also show that heteroscedasticity at training time alleviates error accumulation down the horizon.
SP:4e25ba3714d78ba59a0d8efbb65e0ef5201702f8,"This paper proposes an affine disentangled GAN (ADIS-GAN) that explicitly disentangles affine transformations in a self-supervised and rigorous manner. The affine regularizer is derived by decomposing the affine matrix into separate transformation matrices and inferring the transformation parameters by maximum likelihood estimation. Experiments on MNIST, CelebA, and dSprites demonstrate the effectiveness of the proposed method."
SP:121f8420cfb49c6d80b5ebb4051e85947182594a,This paper proposes a self-supervised contrastive learning method that leverages the distributional divergence between the weakly and strongly augmented images over the representation bank to supervise the retrieval of strongly augmented queries from a pool of candidates. The proposed method achieves top-1 accuracy of 76.2% on ImageNet with a standard ResNet-50 architecture with a single-layer classifier fine-tuned. This is almost the same as 76.5% performance with a fully supervised network.
SP:af54e542223097c315ecd677d0b968e9a0b2a1d4,"This paper proposes a new method for de-identification of MRI scans. The proposed method is based on a GAN architecture that takes a patient’s MRI scan as input and generates a 3D volume in which the brain is not modified but the face has been de-identified. Compared to the classical removal-based techniques, the proposed method preserves privacy more reliably without adversely affecting downstream medical analyses on the brain. "
SP:0ac3964bd2320341488476d60f57b75d2a79f92c,"This paper proposes a multi-head attention based global pooling layer to capture the interaction between nodes according to their structural dependencies. The authors show that the proposed pooling function satisfies both injectiveness and permutation invariance, such that it is at most as powerful as the Weisfeiler-Lehman graph isomorphism test. The experimental results show that GMT significantly outperforms state-of-the-art graph pooling methods. "
SP:76848e7ac3e6709e92f6a6db60269cb5177495d1,"This paper studies the problem of over-squashing in GNNs. The authors propose a new explanation for this problem, which is based on the observation that a bottleneck causes the message to be squashed into a fixed-size vector, which prevents the GNN from propagating long-range information. They show empirically that GCN and GIN are more susceptible to this problem than GAT and GGNN. They also show that prior work that extensively tuned GNN models of long range problems suffer from this problem and that breaking the bottleneck improves their performance."
SP:90d8fa381446923902e42b259392e5e975e6caa1,This paper proposes a new method for cross-domain sentiment analysis based on aligning two domain-specific distributions in a shared embedding space. The authors introduce a new domain adaptation method which induces large margins between different classes in an embedding spaces based on the notion of prototypical distribution. This embedding is trained to be domain-agnostic by matching the data distributions across the domains. Theoretical and empirical analysis are provided to demonstrate that the method is effective.
SP:893fd7440b82f5da0d4c0944928810322eaee2f0,"-bias stereotypes have recently raised significant ethical concerns in natural language processing. This paper proposes an evaluation methodology to measure these biases by constructing a challenge task which involves pairing gender neutral premise against gender-specific hypothesis. They use their challenge task to investigate state-of-the-art NLI models on the presence of gender stereotypes using occupations. Their findings suggest that three models (BERT, RoBERTa, BART) trained on MNLI and SNLI data-sets are significantly prone to gender induced prediction errors. They also find that debiasing techniques such as augmenting the training dataset to ensure a gender-balanced dataset can help reduce such bias in certain cases."
SP:a32ab755bd249c393b70938036ce8e810c0c439f,"This paper revisits the variational intrinsic control (VIC) method proposed by Gregor et al. (2016), which is an unsupervised reinforcement learning method for finding the largest set of intrinsic options available to an agent. The authors show that the intrinsic reward used in the implicit VIC is subject to bias in stochastic environments, causing convergence to suboptimal solutions. To compensate this bias and achieve the maximal empowerment, the authors suggest two modifications of implicit Vic: the environment dynamics modeling with the transitional probability (Section 3) and Gaussian mixture model (Section 4)."
SP:b4df2c4627a6d46c5100133e38c4bea20b296dd8,"This paper studies the use of ensembles of deep neural networks for the task of image classification with a limited number of labeled examples. The authors compare the performance of different ensemble configurations to their deeper and wider competitors given a total fixed computational budget and provide empirical evidence of their advantage. Furthermore, they investigate the effectiveness of different losses and show that their choice should be made considering different factors. "
SP:4a0ee01f4897efa81659f37ef0468ee8195bbc4f,"This paper proposes Sparse Binary Neural Network (SBNN), a method to further compress Binary Neural Networks (BNNs) by introducing sparsity, while reducing their required computations. The approach is based on quantization of weights in the 0/1 binary domain and a highly sparse initialization of the network. It is formulated as a mixed optimization problem and solved using a modified version of the BNN training algorithm with -1/1 weights (Courbariaux et al., 2016). The method has been evaluated on feed-forward linear and convolutional network on MNIST and CIFAR-10."
SP:5be8539ad02595ad3c7a2d7afe8cbb3e9924467d,This paper proposes a post hoc calibration method for predicting predictive uncertainty for deep neural networks. The method uses outlier exposure to calibrate the model probabilities. The proposed method is model-agnostic and can be applied to any deep neural network architecture. The paper is well-written and easy to follow. 
SP:ea503f67e38fce7dee9cc4996b55b8959911f030,"This paper studies the expressive power of graph neural networks and graph kernels from an empirical perspective. Specifically, it compares the graph representations and similarities produced by these algorithms against those generated by a well-accepted, but intractable graph similarity function. The authors also investigate the impact of node attributes on the performance of the different models and kernels. "
SP:0cf7b7d929f50e0b7f4fda5e1f68e5ade2f7c29b,"This paper proposes a new method for self-supervised image animation based on the occlusion mask. The proposed method is based on cutting and mixing patches of different images to regularize discriminator predictions on inpainting. The method is evaluated on the VoxCeleb, BAIR, and Tai-Chi-HD datasets. "
SP:60b535fc6cbc1a7a26ad53f706ebb17de346dc4f,"This paper proposes a self-supervised method to learn independent causal mechanisms (ICM) from observational data. The authors propose to learn a model that disentangles each mechanism and approximates the groundtruth mechanisms. The paper also provides sufficient conditions under which the mechanisms can be learned using a single model with an unconventional mixture prior. Experiments show that the proposed method is more robust against interventions, covariant shift, and noise compared to disentangled representations."
SP:44d4e24428d043a69b40013919cda0e8e7bff99c,This paper studies the problem of predicting a molecular graph structure given a 2D image of a chemical compound (U). The authors propose a graph aligning approach that generates rich or detailed labels given normal labels W. The proposed method is based on graph alignment. The authors show that the proposed method can achieve state-of-the-art performance on the Maybridge compound data set.
SP:ad906dd9a176cffd283593321ff6b9ad19595528,This paper proposes a neural network-based method to solve the energy optimization problem of chiller plants. The authors propose a monotonic neural network (MNN) to constrain the input-output of the chiller power model to conform to physical laws and provide accurate function space about chiller plant. Experiments on a cooling system of a data center demonstrate the effectiveness of the proposed method.
SP:6cb65ee5d2926858570601eeeade24fe86c7f32f,"This paper proposes a new method for spatio-temporal forecasting, named CausalTrans, to establish the collaborative causal effects of predictors on multiple forecasting targets, such as supply and demand in ride-sharing platforms. Specifically, the authors integrate the causal attention with the Conditional Average Treatment Effect (CATE) estimation method in causal inference. Moreover, they propose a novel and fast multi-head attention evolved from Taylor’s expansion instead of softmax, reducing the time complexity from O(V) to O(\sqrt{V}) where V is the number of nodes in a graph. The authors conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various model components, and the time efficiency of the proposed method."
SP:223980a1954d626d90ff54d8dc61b5d85a6b349c,"This paper proposes a method for joint learning of discrete and continuous factors of variability. The method is based on augmenting the training samples with a type-preserving augmentation. The authors formulate the joint learning problem as a variational inference problem with multiple agents. The proposed method is evaluated on MNIST, dSprites and a gene expression dataset."
SP:c982610ad28662c3bd13132abe1f7307d1a61b68,"This paper provides a general characterization of steerable kernels in the kernel space of G-steerable convolutional neural networks (G-CNNs). The kernel space is defined in terms of generalized reduced matrix elements, Clebsch-Gordan coefficients, and harmonic basis functions on homogeneous spaces. The paper is motivated by a striking analogy between the constraints underlying steerable kernel on the one hand and spherical tensor operators from quantum mechanics on the other hand."
SP:7b2ea39069277ad0f4f79476a77ef84587a804d9,", this paper studies the effect of selective classification on the accuracy disparities between different groups in a population. The authors show that selective classification can improve average accuracy while magnifying existing accuracy disparities, especially in the presence of spurious correlations. They observe this behavior consistently across five vision and NLP datasets and show that increasing abstentions can even decrease accuracies on some groups. Motivated by their analysis, the authors train distributionally-robust models that achieve similar full-coverage accuracies across groups. "
SP:f1d57ee27e901daf7e4e2b84139019e945818911,"This paper proposes a hierarchical nonnegative CANDECOMP/PARAFAC (CP) decomposition (hierarchical NCPD) model and a training method, Neural NCPD, for performing hierarchical topic modeling on multi-modal tensor data. The proposed method utilizes a neural network architecture and backpropagation to mitigate error propagation through hierarchical NCPD. Experiments are conducted on both real and synthetic datasets."
SP:b6ddc3a560aa7155e7e927bf5360bedc36586597,This paper proposes a new adversarial robustness certificate for semi-supervised node classification. The key idea is to fuse multiple single-node certificates into a stronger collective certificate. The authors leverage the fact that an adversary must use a single adversarial example to attack all predictions. The proposed method is agnostic towards network architectures and base certification procedures. 
SP:cc93dd2f68e415e2457166e78627865dc1b44697,"This paper proposes Quantile Regression GAN (QRGAN), a new GAN model that uses quantile regression to minimize the 1-Wasserstein distance between real and generated data distribution. The proposed method is based on the observation that LSGAN and WGAN suffer from mode collapse and non-convergence problems, respectively. To address this issue, the authors propose to use a discriminator that does not have to be bounded to specific numbers. Experiments are conducted on the mixture of gussian dataset and image generation experiments."
SP:4ddb47ee77c374ae6c3e419412d92ca77260692e,"This paper investigates relevance metrics that can provide reasonable explanations to users. Specifically, they adopted three tests to evaluate whether the relevance metrics satisfy the minimal requirements for similarity-based explanation. The experiments revealed that the cosine similarity of the gradients of the loss performs best, which would be a recommended choice in practice. In addition, they showed that some metrics perform poorly in our tests and analyzed the reasons of their failure."
SP:6c2cbf2bc0f6dabe974e80ec1e82d2d12189906e,"This paper proposes a low-rank global attention (LRGA) module to improve the generalization power of Graph Neural Networks (GNNs). The authors show that the LRGA module can align with the powerful 2-FWL isomorphism test by learning simple monomial functions, which have a known sample complexity bound. Experiments are conducted to demonstrate the effectiveness of the proposed method."
SP:b4abdd28504b4c1de239eabd4e0e27d370efee71,"This paper proposes an adaptive label smoothing method to improve the calibration of CNNs. The main idea is to use bounding box information for a portion of the ImageNet dataset (Russakovsky et al., 2015) to compute a smoothing factor that is adaptive based on relative object size within an image. Experiments show that the proposed method is able to produce an order of magnitude reduction in confidence when predicting on context only images."
SP:5254658923e594294b69d124a8d004166852822a,"This paper proposes a two-layer fully-convolutional ReLU denoising network that is amenable to convex optimization. The convex dual network not only offers the optimum training with convex solvers, but also facilitates interpreting training and prediction. In particular, it implies training neural networks with weight decay regularization induces path sparsity while the prediction is piecewise linear filtering. Experiments with MNIST and fastMRI datasets confirm the efficacy of the dual network optimization problem."
SP:085cad6bc143c8713580bddfaa71f06496dac314,This paper proposes an end-to-end speech synthesis model that uses a differentiable alignment scheme based on token length prediction to generate high fidelity audio through a combination of adversarial feedback and prediction losses. The proposed generator is feed-forward and thus efficient for both training and inference. The authors also employ soft dynamic time warping in the spectrogram-based prediction loss to capture temporal variation in the generated audio. 
SP:01148cea55db606aa78d27e900818684a8bce9ab,This paper proposes a non-parametric framework for node representation learning with missing node attributes. The key idea is to embed nodes into a low-dimension discrete Wasserstein space through matrix decomposition and diffusion. This allows us to reduce the distortion caused by missing attributes and obtain integrated representations expressing information of both topology structure and attributes. Experiments on node classification and matrix completion show the effectiveness of the proposed method.
SP:aeeb5909f7123ef631f569b469af9715205c881f,"This paper proposes a meta-learning method for reinforcement learning with an adversarial teacher and a student policy. The teacher is trained to generate goals that are difficult to achieve, while the student policy is conditioned on the teacher's goals to maximize an intrinsic reward. The proposed method is evaluated on 6 procedurally generated environments and compared with several baselines."
SP:3d05bc7dca97681cb582298e318b9b973841eed3,"This paper studies the problem of information retrieval from a dataset of files stored on a single server under both a user distortion and a user privacy constraint. Specifically, a user requesting a file from the dataset should be able to reconstruct the requested file with a prescribed distortion, and in addition, the identity of the request should be kept private from the server. The proposed model can be seen as an extension of the well-known concept of private information retrieval by allowing for distortion in the retrieval process and relaxing the perfect privacy requirement. The authors show that the optimal rate-distortion-leakage tradeoff is convex and that in the limit of large file sizes this allows for a concise information-theoretical formulation in terms of mutual information. Moreover, they propose a new data-driven framework by leveraging recent advancements in generative adversarial models which allows a user to learn efficient schemes."
SP:3f9e2db00fc3dcd7a40588adcb638503ec10dc09,"This paper proposes a decoupled greedy learning method for GNNs that decouples the GNN into smaller modules and associates each module with greedy auxiliary objectives. This approach allows GNN layers to be updated during the training process without waiting for feedback from successor layers, thus making parallel GNN training possible. The proposed method achieves improved efficiency without significantly compromising model performances, which would be important for time or memory limited applications."
SP:5ecb1b288f7fc02aead4493f81640867bc349290,"This paper proposes a framework for answering complex queries on incomplete Knowledge Graphs. The authors translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor, and then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. The experiments show that the proposed approach produces more accurate results than state-of-the-art methods."
SP:f04a522fd04c503754fdb8c52da68646d31271a4,"This paper proposes a method for verifying the local robustness of neural networks with piecewise linear activation functions. The key idea is to partition the input space into a set of convex polyhedral regions in which the network’s behavior is linear; hence, a systematic search for decision boundaries within the regions around a given input is sufficient for assessing robustness. The authors show how the region around a point can be analyzed using simple geometric projections, thus admitting an efficient, highly-parallel GPU implementation that excels particularly for the $\ell_2$ norm, where previous work has been less effective."
SP:5297651ff873f97c07b9c47ed3eff52251661844,"This paper presents an approach for learning an embedding of objects in an affordance space, in which each dimension corresponds to an aspect of meaning shared by many actions, using text corpora. This embedding makes it possible to predict which verbs will be applicable to a given object, as captured in human judgments of affordance, better than a variety of alternative approaches. The dimensions learned are interpretable and correspond to typical patterns of interaction with objects. Finally, the dimensions can be used to predict a state-of-the-art mental representation of objects, derived purely from human judgements of object similarity."
SP:72b4f3b40c6c6fa2eb53e95ed9a10a4077ffa049,"This paper proposes a method for the emergence of individualism in multi-agent reinforcement learning. Specifically, the method learns a probabilistic classifier that predicts a probability distribution over agents given their observation and gives each agent an intrinsic reward of being correctly predicted by the classifier. The intrinsic reward encourages the agents to visit their own familiar observations, which makes the intrinsic reward signals stronger and in turn makes the agents more identifiable. Two regularizers are proposed to increase the discriminability of the classifiers. Empirically, the authors show that EOI outperforms existing methods in a variety of multiagent cooperative scenarios."
SP:112509d6d3573a9d495d182fdfae6ec0327cddf5,This paper proposes a new randomized smoothing method called Smoothed WEIGHTed Ensembling (SWEEN) to improve the performance of randomized smoothed classifiers. The authors show that SWEEN can achieve optimal certified robustness w.r.t. our defined $\gamma$-robustness index. They also prove that the optimal SWEen model can be obtained from training under mild assumptions. Extensive experiments show that the proposed method outperforms the upper envelope of their corresponding candidate models.
SP:ea892e3d199ed6121279b20061a87f43afae8796,This paper proposes a method to learn a hierarchy of subtasks by learning from demonstration trajectories. The method is based on a memory-based policy network that is ordered to update the memory of each subtask at each time step. It is shown that the method is able to recover the subtask boundary in both unsupervised and weakly supervised settings with behavior cloning. Experiments are conducted on both grid world and robotic tasks.
SP:cc6aa977ce561a2493ae74bb694205cd67c8d890,"This paper proposes a Causal Semantic Generative Model (CSG) for out-of-distribution (OOD) prediction. The CSG is based on a causal reasoning approach, and the authors show that under certain conditions, CSG can identify the semantic factor by fitting training data, and this semantic-identification guarantees the boundedness of OOD generalization error and the success of adaptation. Empirical study shows improved OOD performance over prevailing baselines."
SP:be3f34a59e5e61dcdbc7cb085f031ba4a5a5b758,"This paper studies the problem of robust online learning under adversarial corruptions. In particular, the authors consider the setting where an online algorithm makes a prediction at each time step, and receives a stochastic reward from the environment that can be arbitrarily corrupted with probability $\mathcal{0, 12}. The authors study the design of algorithms with small regret over a period of time steps. However, while the algorithm observes corrupted rewards, the algorithm needs its regret to be small with respect to the true uncorrupted reward distribution. The authors build upon recent advances in robust estimation for unsupervised learning problems to design robust online algorithms with near optimal regret in three different scenarios.  The authors provide empirical evidence regarding the robustness of their proposed algorithms on synthetic and real datasets."
SP:6d62a80aaebb2988df3953d4d7164e5a2fa1aa6d,"This paper proposes Rewriter-Evaluator, a neural machine translation (NMT) framework that consists of a rewriter and an evaluator. The rewriter produces a new translation to improve the past translation and the evaluators estimates the translation quality to decide whether to terminate the rewriting process. The authors also propose a prioritized gradient descent (PGD) method that facilitates training the rewriter-evaluator jointly. Experiments on two translation tasks, Chinese-English and English-German, show that the proposed framework significantly improves the performance of NMT models."
SP:9761fca8848868dfc9cacdab2537f8276ca76e0f,"This paper proposes a two-stage method for semantic segmentation. In the first stage, the model is trained with a categorical likelihood, and in the second stage, an adversarial network is trained to sample an arbitrary number of coherent predictions. The model can be used independently or integrated into any black-box segmentation framework to facilitate learning of calibrated stochastic mappings. The authors demonstrate the utility and versatility of the approach on the multigrader LIDC dataset and a modified Cityscapes dataset."
SP:ce965758f1b795a56c02f45d6a8d06cb8bdf29cb,"This paper studies the problem of compressed communication with error feedback (EF) for dealing with biased compressors. The authors show that unbiased compressors are better than contractive compressors in terms of convergence rate, communication complexity, and memory requirements. In addition, the authors propose a new construction for transforming any biased compressor into an unbiased compressor using a compressed EF-like approach. The theoretical results are corroborated with numerical experiments."
SP:4fd702490293e481c79614852ba27dd3ce9215a4,"This paper proposes a new research framework called hyperparameter transfer across adjustments (HT-AA) to improve efficiency during the development of machine learning (ML) algorithms. The authors provide four simple HT-AA baseline algorithms and eight benchmarks changing various aspects of ML algorithms, their hyper parameter search spaces, and the neural architectures used. The best baseline, on average and depending on the budgets for the old and new HPO, reaches a given performance 1.2–3.6x faster than a prominent HPO algorithm without transfer. "
SP:e8f99bae5853de525450fcb8facd23cf973fc161,"This paper studies the role of label representation in training deep neural networks. The authors propose a new paradigm for the image classification task by using speech as the supervised signal. They demonstrate that speech models can achieve comparable performance to traditional models that rely on categorical outputs. They quantitatively show that high-dimensional label representations with high entropy (e.g. audio spectrograms and composition of Gaussians) produce more robust and data-efficient neural networks, while high dimensional labels with low entropy (i.e. constant matrices) and low-dimensional labels with high-entropy do not have these benefits and may even lead to worse performance. "
SP:4e8d924cba7367af0999b30d79250b4dc40413e1,"This paper proposes a multi-input multi-output (MIMO) method to improve the robustness and uncertainty performance of neural networks. The key idea is to use a single model to train multiple sub-networks that independently learn the task at hand. By ensembling the predictions made by the subnetworks, the method can improve model robustness without increasing the number of parameters. The method is evaluated on CIFAR-10, Cifar-100, and ImageNet."
SP:d2f1c23b67c6744101034dc5e1c70765a733b169,"This paper proposes a method to transfer intermediate knowledge from one CNN to another by utilizing sparse representation learning. The method first extracts sparse representations of the hidden features of the teacher CNN, which are then used to generate both pixel-level and image-level labels for training intermediate feature maps of the student network. Experiments demonstrate that SRM is robust to architectural differences between the teacher and student networks, and outperforms other KD techniques across several datasets."
SP:e8c0f43bd5debf6544f588cd3442dc3dd62d0eee,This paper proposes a policy similarity metric (PSM) to measure behavioral similarity between states. The authors also propose a contrastive representation learning procedure to embed any state similarity metric to obtain policy similarity embeddings (PSEs) to improve generalization. Experiments show that the proposed method improves generalization on diverse benchmarks.
SP:92f3b4942da9075440dda618f561a85f8fde5a5c,"This paper studies the disentanglement of affine transformations in the latent space of deep neural networks. The authors show that a popular approach to disentangle such transformations introduces discontinuities in the encoder, and propose an alternative approach that relies on distributed equivariant operators. The paper provides theoretical justification for the effectiveness of the approach and provides empirical evidence that the approach is effective."
SP:ef0f58c462bc5dd1c7b78f562c42a4e17f0f252b,"This paper proposes an expectation-maximization (EM) algorithm to estimate the maximum a posteriori (MAP) estimate of the Hawkes process for neural spike trains. Three auxiliary latent variables (Pólya-Gamma variables, latent marked Poisson processes and sparsity variables) are augmented to make functional connection weights in a Gaussian form, which allows for a simple iterative algorithm with analytical updates. Experiments are conducted on synthetic and real neural recordings to demonstrate the effectiveness of the EM algorithm."
SP:1156d3deac022829bda930ffcb081947609d972b,"This paper studies the dynamics of gradient descent for training two-layer neural networks in the under-parameterized and over-parametrized regime. The authors show that there are two phases in the dynamics: an early phase in which the GD dynamics follow closely that of the corresponding random feature model, followed by a late phase where the neurons are divided into two groups: a group of a few (maybe none) “activated” neurons that dominate the dynamics and a group that are “quenched”. In particular, when the target function can be accurately approximated by a relatively small number of neurons, this quenching-activation process biases GD to picking sparse solutions. This neural network-like behavior is continued into the mildly overparametrization regime, in which it undergoes a transition to a random featurelike behavior where the inner-layer parameters are effectively frozen during the training process. "
SP:9e81401a6f30c70d870a12cce0cf600557f92b80,"This paper proposes a method for solving constrained Markov decision process (CMDP) problems by decomposing the CMDPs into a pair of MDPs: reconnaissance MDP and planning MDP. In R-MDP, the agent trains the threat function, which is the Q-function analogue of danger, to determine whether a given state-action pair is safe or not. In P-DP, a reward-seeking policy is trained while using a fixed threat function to determine the safeness of each action. The authors also propose an efficient approximation method that can greatly reduce the difficulty of solving R-DPs. The proposed method is evaluated on the Jam environment."
SP:f1d4ac7d5516dd0df742e224c8c09c721d0d0886,"This paper compares the cross-entropy loss with the square loss for training neural networks for classification tasks. The authors show that square loss outperforms cross entropy loss on a variety of tasks, including NLP, ASR, and computer vision tasks. They also show that training with square loss is less sensitive to the randomness in initialization. "
SP:915f1f0fc4850507c28c1d609239b41775863ebe,"This paper proposes a self-supervised reinforcement learning method called Self-Predictive Representations (SPR) that learns to predict its own latent state representations multiple steps into the future using an exponential moving average of the agent’s parameters and makes predictions using a learned transition model. On its own, this future prediction objective outperforms prior methods for sample-efficient deep RL from pixels. The authors further improve performance by adding data augmentation to the future prediction loss, which forces the representation to be consistent across multiple views of an observation. The proposed method achieves a median human-normalized score of 0.415 on Atari in a setting limited to 100k steps of environment interaction."
SP:983f01c170909c8c67fd3be25f121bd61bdd8307,"This paper proposes a local node embedding method for learning embeddings for a single node in a graph. The proposed method is based on local PageRank computations. The authors provide theoretical guarantees on the locality of the computation, as well as the proof of the global consistency of the generated embedding. Empirical results show that the proposed method outperforms state-of-the-art methods in terms of computational time and memory usage. "
SP:d11037b8fe2b10aee672ba82f69410b40181f0f9,"This paper studies the problem of graph coarsening, i.e. reducing the size of a graph while maintaining some of its essential properties. The authors propose a framework for measuring the quality of the algorithm and show that depending on the goal, we need to carefully choose the Laplace operator on the coarse graph and associated projection/lift operators. Motivated by the observation that the current choice of edge weight for the coarse graphs may be suboptimal, the authors propose to parametrize the weight assignment map with graph neural networks and train it to improve the quality in an unsupervised way. Through extensive experiments on both synthetic graphs and real networks, they demonstrate that their method GOREN significantly improves the performance of the existing Graph Coarsening methods."
SP:0d680213339f0e2aedb0be4aeed51423706b8bf6,"This paper proposes a geometric deep learning algorithm to compute the scattering properties of 3D objects based on discrete-laplacian and implicit encoders. The paper uses a point cloud approximation of each object, and each point is encoded in a high-dimensional latent space. The multi-layer network can accurately estimate these acoustic properties for arbitrary topologies and takes less than 1ms per object on a NVIDIA GeForce RTX 2080 Ti GPU. The authors also prove that their method is permutation and rotation invariant and demonstrate its application to generating environmental acoustic effects in dynamic environments."
SP:afc33a782c43e3d4c5c4fbf047d0b1108bc30bae,"This paper proposes Risk Extrapolation (REx) as a method for robust optimization over a perturbation set of extrapolated domains (MMREx), and proposes a penalty on the variance of training risks (V-REx). The authors prove that variants of REx can recover the causal mechanisms of the target, while also providing some robustness to changes in the input distribution (“covariate shift”). "
SP:411d5bcf7698d534ad60f581d479ff74849ba4de,"This paper proposes a neural operator for learning partial differential equations (PDEs). The neural operator is based on the Fourier transform of the integral kernel, which allows for an expressive and efficient architecture. Experiments on Burgers’ equation, Darcy flow, and Navier-Stokes equation demonstrate the effectiveness of the proposed method. "
SP:41d268d0eac9b4c84baa156fb641aa6d3060b5a4,"This paper studies the implicit bias of gradient descent with infinitesimal step size on linear neural network training. The authors propose a tensor formulation of neural networks that includes fully-connected, diagonal, and convolutional networks as special cases, and investigate the linear version of the formulation called linear tensor networks. With this formulation, they characterize the convergence direction of the network parameters as singular vectors of the tensor defined by the network. They show that gradient flow on separable classification finds a stationary point of the $\ell_2$/L max-margin problem in a transformed input space. For underdetermined linear regression, they prove that the gradient flow finds a global minimum which minimizes a norm-like function that interpolates between weighted $\ell_{1}$ and \ell_{2} norms in the transformed space."
SP:e27907ef4a4e6e0f5841618fcaa7e7e0db443f91,"This paper studies the problem of training slimmable neural networks by optimizing the width-multipliers for different layers and the shared weights. The authors propose a new training algorithm, Pareto-aware channel optimization (PareCO), which jointly optimizes the width multipliers and the weight multipliers. The proposed method is evaluated on 15 network and dataset combinations and two types of cost objectives, i.e., FLOPs and memory footprint."
SP:cf59403abb6ca89ccee4f8e77e9a33d99e6a00f5,"This paper studies the problem of federated semi-supervised learning in the presence of partially labeled or completely unlabeled data. The authors propose FedMatch, a federated federated learning algorithm that uses a new loss function called FedMatch (FedMatch) that aims to improve the consistency between models trained at different clients. Specifically, FedMatch is based on the idea of FedMix, which is a variant of the FedMix algorithm. FedMatch uses the same loss function as FedMix but with an additional regularization term that encourages the models to be close to each other. Experiments are conducted on synthetic and real-world data."
SP:9457b6d430a2cd864d526d7e90bf3e1ab13d6df4,This paper proposes a self-supervised method for learning embeddings of discrete event sequences. The method is based on contrastive learning (CL) and is applied to the discrete event sequence domain. The authors provide a theoretical justification for CL and provide empirical results on several public datasets. The experiments show the effectiveness of the method.
SP:385942a5bcee7384bb722a1669b541f2fac0cd36,"This paper proposes a method for unsupervised dependency and constituency parsing. The main idea is to introduce a dependency-constrained self-attention mechanism into the transformer architecture. The proposed method is evaluated on three tasks: constituency parsing, dependency parsing, and masked language modeling. "
SP:078966ff62775bba6031e47d374bda95f4a7dde3,This paper proposes a method for learning a metric between visual objects and scene graph nodes by incorporating information from both object features and relational features. The proposed metric is based on the ground-truth bounding boxes in the image. The method is evaluated on the Visual Genome (VG) and Visual Relation Detection (VRD) datasets. Experiments show that the proposed method outperforms existing mapping methods. 
SP:4644dbf7466b6234d8abf69995fdfb357efcc119,"This paper proposes a new variant of sliced fused Gromov wasserstein (SFG) to reduce the inner discrepancy between the prior and aggregated posterior distributions in the relational regularized autoencoder (RAE) framework. Specifically, the paper proposes to use a von Mises-Fisher distribution to replace the uniform distribution over slicing direction in SFG. The paper also proposes two variants of SSFG to improve the performance and stability of SFFG. Extensive experiments are conducted to demonstrate the effectiveness of the proposed SSFG."
SP:5ae2c0af82cac89a65f1cc38c43e2d05ea298901,This paper proposes a simple weight sharing method to speed up the training of deep networks with repeated layers. The proposed method is motivated by the successes of weight sharing models in the literature as well as the theoretic analysis on deep linear models. The authors show that their method is able to reduce the training time of BERT by 50%. 
SP:a51710551142316b67e2fccd969fea1ece35ba39,"This paper analyzes the adversarial transferability of adversarial perturbations from the perspective of interactions based on game theory. The authors show a negative correlation between the transferability and the interaction between the perturbation units during adversarial attacks. Based on this, they propose to penalize interactions during the attacking process, which significantly improves the adversarially transferable transferability."
SP:f1565319075c1442c2cb52d96443facb492c06c2,"This paper studies the role of deep neural networks (DNNs) in the phenomenon of catastrophic forgetting. The authors show that the forgetting is not evenly distributed throughout the DNN layers, but concentrated at the higher layers, which change significantly and erase earlier task subspaces through sequential training. They also show that mitigation methods all stabilize higher layer representations, but vary on whether they enforce more feature reuse, or store tasks in orthogonal subspace. Finally, they formulate an analytic model to investigate the connections between forgetting and task semantic similarity. "
SP:30d7532cdcf420bff3be6b92eea3d93bce59e6bd,"This paper proposes an efficient training framework for large-scale language model pre-training and fine-tuning. Based on Lottery Ticket Hypothesis, this paper identifies structured winning tickets in an early stage, then uses the pruned network for efficient training. Extensive experiments on GLUE and SQuAD demonstrate that the proposed method is able to achieve comparable performance to standard BERT with much less training time."
SP:c547f23ff6caaf5e9f35d258490b86ae0ac8ed03,"This paper studies the robustness of f-divergence measures when used to train a classifier in the presence of label noise. The authors derive a nice decoupling property for a family of f divergence measures when label noise presents, where the divergence is shown to be a linear combination of the variational difference defined on the clean distribution and a bias term introduced due to the noise. They also propose fixes to make them robust. Finally, they empirically verify their findings."
SP:841888179dcdac901889c8d62cb5234311fe28f1,This paper proposes an ensemble-based weighted Bellman backup method for off-policy deep reinforcement learning. The proposed method re-weighs the target Q-values based on uncertainty estimates from a Q-ensemble. The experiments show that the proposed method stabilizes and improves learning on both continuous and discrete control tasks. The authors also investigate the signal-to-noise aspect by studying environments with noisy rewards.
SP:afc08f203562b841180811aef943bfb63a1659ea,This paper proposes a method for few-shot classification based on class-wise similarity between support and query sets. The method is algorithm-agnostic and can be applied to a range of meta-learning models. The proposed method is evaluated on a variety of tasks and datasets. 
SP:12ae325ea3bce1e60195afac7d85895d2d20c29c,"This paper proposes a method for learning video-text representations for cross-model retrieval. The authors argue that the current contrastive learning paradigm is too strict, enforcing dissimilar representations even for samples that are semantically related. To alleviate this problem, the authors propose a generative model to naturally push these related samples together: each sample’s caption must be reconstructed as a weighted combination of other support samples’ visual representations. This simple idea ensures that representations are not overly-specialized to individual samples, are reusable across the dataset, and results in representations that explicitly encode semantics shared between samples. The proposed method outperforms others by a large margin on MSR-VTT, VATEX, ActivityNet, and MSVD for video-to-text and text to video retrieval."
SP:8a71d8fad25a126aff01431cacf348c05de75667,"This paper proposes a method, seg tok, to re-build the vocabulary of Chinese BERT with the help of Chinese word segmentation (CWS) and subword tokenization. The authors also propose 3 MVP strategies for enhancing the Chinese PLMs. Experiments show that the proposed method improves the performance of Chinese PLM on sentence-level tasks, and MVP improves PLMs’ downstream performance."
SP:b93ec7bc02b48068073ffe705f71d2643e663d51,This paper studies the problem of distributed training of GCNs on large full-graphs. The authors propose an unbiased boundary sampling strategy to enable efficient and scalable distributed GCN training while maintaining the full graph accuracy. The proposed method is evaluated on the Reddit and ogbn-products datasets. 
SP:2d4ba873d11e969ebd1fc31f9b5ab450c964d154,"This paper presents a graph neural network (GNN) based model for estimating the per-atom forces of a complex molecular system. The model is based on a GNN with a message-passing architecture. The authors show that the model is able to reduce the estimation error of atomic forces by 30% compared to existing ML models, and generalizes well to out-of-distribution structures. Finally, the authors apply the model to the large-scale catalyst dataset, OC20."
SP:8bdcf4fe6abf4739d4732b7ea8538513135dcccc,"This paper proposes a new generalization bound for neural networks based on the distance of the final weights from their initial values. The authors show that this new bound has no dependence on the number of weights and compares favourably to other generalization bounds when applied to convolutional networks. Inspired by this, the authors propose a simple yet effective fine-tuning algorithm that constrains the hypothesis class to a small sphere centred on the initial pre-trained weights, thus obtaining provably better generalization performance than conventional transfer learning. Empirical evaluation shows that this algorithm works well, corroborating the theoretical results."
SP:3a3249e97ef2345ea2264de5ed8287e16687838e,"This paper studies the phenomenon of decoupled find-evaluation-mask generation, where the hyperparameters for mask discovery (Hfind) and mask evaluation (Heval) are different. The authors show that different Hfind values yield masks with different layerwise pruning ratios and that the phenomenon is causally mediated by these ratios. They also show that this phenomenon holds across a number of models, datasets, configurations, and also for one-shot structured pruning."
SP:2d6f5d72b21675f74ff4cde4d16bfb36abd5795f,"This paper proposes a new metric called m-coherence to study the alignment of per-example gradients in the course of training. The metric is based on the observation that the number of examples that benefit from a small step along the gradient of any one example on average is larger than that of any other example. The authors show that this metric is more interpretable, cheaper to compute, and mathematically cleaner than other commonly used metrics. "
SP:e7c5de9a475d0ba71bc79580e8436024fb2c6f59,"This paper proposes a method for learning sufficient statistics for likelihood-free inference in implicit generative models. The proposed method is based on the infomax principle, i.e., learning the mutual information maximizing representation of the data with the help of deep neural networks. The method is applied to both approximate Bayesian computation and recent neural likelihood methods, and is shown to improve their performance on a range of tasks. "
SP:c5997bf2348e94949684f45fbd418661e85220c1,This paper proposes an unsupervised image-to-image translation model (TUNIT) that simultaneously learns to separate image domains and translate input images into the estimated pseudo-domains. TUNIT is trained with pseudo-labels from the ground-truth labels of several samples. The experimental results show that the proposed model achieves comparable or even better performance than the set-level supervised model trained with full labels.
SP:0cd97e64e638cabbeea0fdef3e9c5b33f4000f72,This paper studies the implicit bias of gradient descent for regression problems. The authors focus on wide ReLU networks and describe the bias in function space. They show that the solution of training a width-n shallow ReLU network is within n-1/2 of the function which fits the training data and whose difference from initialization has smallest 2-norm of the weighted second derivative with respect to the input.
SP:8b885142facbb3b8db41ec9d83822cee81324694,"This paper studies the effect of weight decay in the training of deep neural networks. The authors show that weight decay is unstable for all optimizers that use Momentum, such as stochastic gradient descent (SGD). They further propose the Stable Weight Decay (SWD) method to fix the unstable weight decay problem from a dynamical perspective. The proposed SWD method makes significant improvements over L2 regularization and decoupled weight decay."
SP:a3206dc71e32ba1830895bf442d3840f3331a532,"This paper proposes a novel method to combine the strengths of both translation memory (TM) and neural machine translation (NMT) by treating the matched sentence pair of TM as the additional signal and applying one encoder enhanced by the pre-trained language model (PLM) to encode the TM information and source sentence together. The authors extend the sentence level retrieval method to the n-gram retrieval method so that we don’t need to calculate the similarity score. Further, they explore new methods to manipulate the information flow from TM to the NMT decoder."
SP:72b43991a242872b2ceb1861e8ffbdf26c9f4818,"This paper presents a novel view of convolutional neural networks from the perspective of rate reduction and shift invariant classification. The authors show that the basic iterative gradient ascent scheme for maximizing the rate reduction of learned features naturally leads to a deep network, one iteration per layer. The architectures, operators (linear or nonlinear), and parameters of the network are all explicitly constructed layer-by-layer in a forward propagation fashion. All components of this “white box” network have precise optimization, statistical, and geometric interpretation. The experiments show that such a network can already learn a good discriminative deep representation without any back propagation training."
SP:f8b02cf1b918b0956761829ec6ef9127596071ec,"This paper studies the implicit acceleration of gradient flow in over-parameterized two-layer linear models. The authors show that implicit acceleration emerges from a conservation law that constrains the dynamics to follow certain trajectories. More precisely, gradient flow preserves the difference of the Gramian matrices of the input and output weights and they show that the amount of acceleration depends on both the magnitude of that difference (which is fixed at initialization) and the spectrum of the data. "
SP:e5f086c806be88d50e461a782b5b00124f4656fb,"This paper proposes a new method CLIME, a model-agnostic explanation framework that is able to operate on constrained subspaces of inputs. Specifically, CLIME allows the user to define the precise subspace of the input domain to be explained. The authors demonstrate that the OOD sampling problem stems from rigidity of the perturbation procedure and propose a theoretically sound framework based on uniform sampling of user-defined subspace. Experiments are conducted to demonstrate the effectiveness of CLIME."
SP:b1d5ef15772e192eb8c8a0e65b3c21ee7c794295,"This paper proposes a novel pre-trained language model called AMBERT (A Multi-grained BERT), which is an extension of BERT that uses both words and phrases in English and both characters and words in Chinese. The key idea is to use two encoders, one for processing the sequence of words and the other for processing sequence of phrases, with shared parameters. Experiments are conducted on benchmark datasets for Chinese and English, including CLUE, GLUE, SQuAD, and RACE."
SP:fd1cfe80343d3789227d99d836a5674374a234f5," the Transformer architecture for semantic parsing. The main idea is to incorporate Long Short-Term Memory (LSTM) into the Self-Attention mechanism of the original Transformer to capture more local context of phrases. Experimental results show that the proposed model captures the detailed meaning better than Transformer, raises local context awareness and achieves strong competitive performance."
SP:2056a65a7500d79465685af883083cd706277c1f,"This paper proposes a new adversarial training method for improving the robustness of deep neural networks (DNNs) against compositions of adversarial perturbations. The method is based on the observation that adversarial attacks that ""compose"" multiple perturbation models (e.g., pixel and spatial transformations) can be more effective than individual attacks. The proposed method is evaluated on a variety of benchmark datasets and models."
SP:006e5b9ac9a8eb7223843731488bfefbd8eb09bd,"This paper proposes a new recurrent network architecture, the Emergent Symbol Binding Network (ESBN), which is a recurrent network augmented with an external memory that enables a form of variable-binding and indirection. This binding mechanism allows symbol-like representations to emerge through the learning process without the need to explicitly incorporate symbol-processing machinery, enabling the ESBN to learn rules in a manner that is abstracted away from the particular entities to which those rules apply. The authors evaluate this architecture on a suite of tasks involving relationships among images that are governed by abstract rules. They show that this architecture is capable of learning abstract rules from a limited number of training examples and systematically generalizing these rules to novel entities."
SP:4171ce45966ac499f51450a19fb233934c0847f0,"This paper proposes a generative model for structured prediction tasks. The proposed model is based on the translation between augmented natural languages (TANL) to solve structured prediction language tasks such as joint entity and relation extraction, nested named entity recognition, relation classification, semantic role labeling, event extraction, coreference resolution, and dialogue state tracking. The authors show that the proposed TANL model can match or outperform task-specific models on all tasks and achieves new state-of-the-art results on several tasks. "
SP:8f1b2fc6829e0bdfcc981020b0dcf3e63a947910,"This paper studies the problem of unlabeled entity problem in named entity recognition (NER) models. The authors claim that two causes of performance degradation are attributed to the reduction of annotated entities and the other is treating unlabeling entities as negative instances. Based on the above observations, the authors propose a general approach, which can almost eliminate the misguidance brought by unlabelled entities. The key idea is to use negative sampling that, to a large extent, avoids training NER models with unlabelling entities. Experiments on synthetic datasets and real-world datasets show that the proposed method is robust to unlabeling entity problem and surpasses prior baselines."
SP:dd76ece8d92a8a230a8b43033d8cb2368c677a94,"This paper proposes a novel embedding method based on stochastic neighbor embedding (SNE) for embedding words of arbitrary length into a vector space of fixed, reduced dimensions. The Euclidean distance between coordinates in the embedding space reflects the phonetic confusability between their corresponding sequences. Two encoder neural networks are trained: an acoustic encoder that accepts speech signals in the form of frame-wise subword posterior probabilities obtained from an acoustic model and a text encoder network that accepts text in form of subword transcriptions. Compared to a triplet loss criterion, the proposed method is shown to have more effective gradients for neural network training. Experimentally, it also gives more accurate results with low-dimensional embeddings. "
SP:9142189126b8612ac0acee6fe18a0cfcb70b6545,"This paper proposes a reinforcement learning algorithm for stationary mean-field games, where the goal is to learn a pair of mean field state and stationary policy that constitutes the Nash equilibrium. The authors propose a fictitious play algorithm which alternatively updates the mean field states and the policy via gradient descent and proximal policy optimization, respectively. The algorithm is in stark contrast with previous literature which solves each single-agent reinforcement learning problem induced by the iterates mean- field states to the optimum. "
SP:c498f8a199da1818fe64ed88b0825c5aad688aec,"This paper proposes a variational inference framework for approximate probabilistic inference on the joint distribution defined by a normalizing flow model. The authors first show that this task is computationally hard for a large class of flow models. Motivated by this hardness result, the authors propose a framework that trains a new generative model with the property that its composition with the given model approximates the target conditional distribution. By parametrizing this new distribution as another flow model, the proposed framework can efficiently train it using VAE-like inference and handle conditioning under arbitrary differentiable transformations. "
SP:1d0f27f61c9d32911b8bd15d6b82ef5eec644f0f,This paper proposes an ultra-high resolution image segmentation dataset for Electron Microscopy (EM) for the Cell Membrane with multiple iterative annotations and uncompressed high-resolution raw data. The authors also propose a new evaluation criterion called Perceptual Hausdorff Distance (PHD) to measure the quality of cell membrane segmentation results. Experiments on the U-RISC show that PHD is more consistent with human perception.
SP:8ca7aff87c82be69c9542550c814f52c9419ab0a,"This paper proposes a modular neural network architecture for continual learning. The main idea is to decompose the network into a set of modules, each of which can be used to solve a given task. The modules can either be reused from previous tasks or new tasks, or they can be added to the network to solve the current task. This is done by using a task-driven prior over the exponential search space of all possible ways to combine modules, enabling efficient learning on long streams of tasks. The experiments show that this modular architecture and learning algorithm perform competitively on widely used CL benchmarks while yielding superior performance on the more challenging benchmarks."
SP:cc819c61f408e88f247eb87946187ccec3dad32e,"This paper proposes a generative meta-learning method for few-shot learning. The proposed method is based on generative models that generate pairs of in-class and out-of-class samples from the latent space in a principled way to create synthetic classes forming the training and validation data of a meta-task. The authors show that the proposed approach, LAtent Space Interpolation Unsupervised Meta-learning (LASIUM), outperforms or is competitive with current unsupervised learning baselines on several benchmark tasks on the Omniglot dataset."
SP:b25771e5c214a352f74ba6196fbd88bca6c43c98,"This paper studies the injectivity of ReLU neural networks. The authors show that injectivity is necessary and sufficient for injectivity by constructing appropriate weight matrices. They show that global injectivity with iid Gaussian matrices, a commonly used tractable model, requires larger expansivity between 3.4 and 10.5. They also characterize the stability of inverting an injective network via worst-case Lipschitz constants of the inverse. "
SP:a95a153d3fe9bcf535ebf8514f51d00df483f210,"This paper proposes a conditional generative adversarial network (CcGAN) for image generation conditional on continuous, scalar conditions (termed regression labels). The authors propose two empirical discriminator losses (HVDL and SVDL), a novel empirical generator loss, and a novel label input method are proposed to overcome the two problems of existing conditional GANs. The experimental results show that CcGAN is able to generate diverse, high-quality samples from the image distribution conditional on a given regression label."
SP:10dd09ab315870631d1451d200f2c87a023f8226,This paper proposes an active learning (AL) algorithm that can be combined with semi-supervised learning (SSL) to improve the sample efficiency of AL. The main idea is to control the convergence rate of a classification network by actively querying unlabeled instances to improve its rate of convergence upon inclusion to the labeled set. The proposed algorithm is motivated by the neural tangent kernel (NTK) and is based on the assumption that a well-optimized network induced by the SSL objective is a good approximation of a model that generalizes well. The experiments show that a deep neural network trained using a combination of the proposed AL algorithm and a recently proposed SSL algorithm can achieve high performance using far less labeled samples than SL.
SP:7f3947c3fa5b09674507d8f3e10d9280376ecb94,"This paper proposes FedDyn, a federated learning method for training neural network models. The method is based on exact minimization, where each participating device updates its regularizer so that the optimal model for the regularized loss is in conformity with the global empirical loss. The authors demonstrate the effectiveness of the proposed method on both convex and non-convex settings."
SP:a3fbb073b0e2371b20d5d9df6ab829673f90354f," self-supervised learning has achieved great success in computer vision tasks. However, the huge computation cost prevents many researchers from using it on their research topics. In this paper, the authors focus on accelerating the training of contrastive learning methods by introducing additional intermediate contrastive losses. The proposed method can save the training time with almost no loss on the final performance of the downstream tasks. "
SP:5b5e705ea1ee1b857e17e64d560a39052804949d,"This paper studies the global convergence and global optimality of actor-critic with linear function approximation. In particular, this paper focuses on the single-time-step setting, where the critic update is obtained by applying the Bellman evaluation operator only once while the actor is updated in the policy gradient direction computed using the critic. The authors prove that the actor sequence converges to a globally optimal policy at a sublinear O(K-1/2) rate, where K is the number of iterations. Moreover, under the broader scope of policy optimization with nonlinear function approximation, the authors also prove that actor critic with deep neural network finds the global optimal policy."
SP:26705a4dc305cce336f657c5937d1f5b4209548a,"This paper proposes to represent a sequence of log files in a vector space. The vector space is represented at three levels of abstraction: field level, log level, and sequence level. These representations are in vector format and serve as interfaces to downstream applications. The authors show how a number of log processing applications can be readily solved with their representation. "
SP:165c51a16f17fb8726e968f8b34742b62011d60e,"This paper proposes a novel wavelet decomposition method for convolutional neural networks. The proposed method is motivated by the similarity between CNN kernels and oriented Gabor filters. The authors propose three variants of wavelet transform: 1) separable wavelet, 2) dual-tree real and complex wavelet and 3) discrete cosine transform. Experiments show that the proposed method outperforms other wavelet CNN methods. "
SP:d0a284da462584724ba6a3a48c9e986d391233f6,"This paper proposes a coach-player framework for multi-agent reinforcement learning, where the players have a partial view of the environment, while the coach has a complete view. The authors propose an attention mechanism for both the players and the coach, incorporate a variational objective to regularize learning, and design an adaptive communication method to let the coach decide when to communicate with different players. They validate their methods on resource collection tasks in multiagent particle environment. "
SP:4eb662b527d556758aaa1a0b589495fcc337fad0,"This paper provides an empirical study of influence functions in deep neural networks with non-convex loss functions. The authors show that the network architecture, depth and width of the network, as well as the extent of model parameterization and regularization techniques have strong effects in the accuracy of influence function estimates. They show that influence estimates are fairly accurate for shallow networks, while for deeper networks the estimates are often erroneous. They also show that training with weight-decay regularization is important to get high-quality influence estimates. "
SP:5fea74a2031d097a99dacf613bedcb054b0c3831,"This paper studies the relationship between language modeling and the task of text classification. The authors hypothesize and verify empirically, that classification tasks of interest can be reformulated as sentence completion tasks, thus making language modeling a meaningful pretraining task. They show that language models that are -optimal in cross-entropy (log-perplexity) learn features that can linearly solve such classification tasks with O(sqrt(\sqrt{C}) error, thus demonstrating that doing well on language modeling can be beneficial for downstream tasks. They also propose a Quad objective that provably learns good features for these natural tasks."
SP:a67da438e9821010284416170c3699ae7ff96c99,"This paper proposes a new method for membership inference attacks (MIA) based on conditional image generation models (e.g. image translation). The main idea is to use the reconstruction error to discriminate between easy and hard images in the training set. To do so, the authors propose to use a novel difficulty score that can be computed for each image and its computation does not require a training set, which is shown to achieve high MIA accuracy on an extensive number of benchmarks."
SP:6fe23ebe09f2a4e42a21598f8e9c79edeca99863,"This paper proposes a differentiable architecture search method by formulating it into a distribution learning problem. The authors treat the continuously relaxed architecture mixing weight as random variables, modeled by Dirichlet distribution. This formulation improves the generalization ability and induces stochasticity that naturally encourages exploration in the search space. Furthermore, to alleviate the large memory consumption of differentiable NAS, the authors propose a simple yet effective progressive learning scheme that enables searching directly on large-scale tasks, eliminating the gap between search and evaluation phases. Extensive experiments demonstrate the effectiveness of our method."
SP:c590d0ed2487b42480b53fc077546a4a0bc27a78,"This paper proposes a new neural network architecture for approximating low-dimensional functions with Fourier or Gabor wavelet functions. The authors propose a multiplicative filter network (MFN) that is a linear combination of a Fourier function and a Gabor function, and show that it performs as well or better than the SIREN or Fourier feature networks. They also show that MFN achieves better performance deltas when increasing the depth or width of the network."
SP:f5be855300f63c185a006834302bd4b033b56258,"This paper proposes a teacher-student scheme for the gradient-based meta-learning algorithm. The key idea is to employ a student network to adequately explore the search space of task-specific models (e.g., by more than ten steps), and a teacher then takes a “leap” toward the regions probed by the student. The teacher not only arrives at a high-quality model but also defines a lightweight computation graph for meta-gradients. Experiments are conducted on few-shot learning, long-tailed classification, and meta-attack."
SP:0361e02d56b7d121cb5ede1cb582284cc18fc599,This paper proposes a new algorithm for offline reinforcement learning based on behavior regularization. The main idea is to use an analytical upper bound on KL divergence as the behavior regularizor to reduce variance associated with sample-based estimations. The authors also employ state-dependent Lagrange multipliers for the regularization term to avoid distributing KL divergence penalty across all states of the sampled batch. Experiments show that the proposed algorithm outperforms existing model-free and model-based offline RL algorithms in various datasets.
SP:b2cfb380aa2a21f72f508b453cf5949257a5b4ec,This paper proposes Adjoined networks as a training approach that can regularize and compress any CNN-based neural architecture. The one-shot learning paradigm trains both the original and the smaller networks together. The parameters of the smaller network are shared across both the architectures. The authors prove strong theoretical guarantees on the regularization behavior of the adjoint training paradigm. They complement their theoretical analysis by an extensive empirical evaluation of both the compression and regularization behaviour of adjoint networks.
SP:dba40073f79143e5355d194aa16db9eee0267a5d,"This paper proposes z-greedy, a variant of greedy exploration, which is based on the idea that greedy exploration is limited by its lack of temporal persistence, which limits its ability to escape local optima. To address this limitation, the authors propose to replace actions with temporally extended sequences of actions, or options, in order to modulate the inductive bias associated with greedy exploration. Experiments are conducted on a variety of environments to show the effectiveness of the proposed method."
SP:5efb581a368ace3bd085d48801a899559d6a43ef,This paper studies the implicit regularization of gradient descent in matrix factorization. The authors show that gradient flow with infinitesimal initialization is mathematically equivalent to Greedy Low-Rank Learning (GLRL) under some reasonable assumptions. This generalizes the rank minimization view from previous works to a much broader setting and enables them to construct counter-examples to refute the conjecture from Gunasekar et al. (2017). The authors also extend the results to the case where depth > 3. 
SP:7f997cf7a63a7330fc12fd525516080c91a3cb9b,"This paper proposes a two-stage model patching method to improve the robustness of classifiers. The first stage models subgroup features within a class and learns semantic transformations between them, and then trains a classifier with data augmentations that deliberately manipulate sub group features. The second stage uses a CycleGAN to learn the intra-class, inter-subgroup augmentations, and balances subgroup performance using a theoretically-motivated subgroup consistency regularizer, accompanied by a new robust objective. The authors demonstrate the effectiveness of the proposed method on three benchmark datasets. "
SP:de6cea1e35a0555175e17546a93422e9a96a511e,"This paper proposes a rule-based representation learning method, called Rule-based Representation Learner (RRL), that learns interpretable non-fuzzy rules for data representation. To train the non-differentiable RRL effectively, the authors project it to a continuous space and propose a novel training method, Gradient Grafting, that can directly optimize the discrete model using gradient descent. An improved design of logical activation functions is also devised to increase the scalability of RRL and enable it to discretize the continuous features end-to-end. Experiments on 9 small and 4 large data sets show that RRL outperforms the competitive approaches and has low complexity close to the simple decision trees."
SP:e36388a9452e557dd51bf0170bf2f9da22271a49,"This paper proposes a new regret minimization algorithm for generalization across structured biomedical domains such as molecular scaffolds or protein families. The proposed method is based on invariant risk minimization (IRM) by recasting simultaneous optimality condition in terms of predictive regret. The paper also proposes a structured extension adaptively highlights variation due to complex environments via specialized domain perturbations. Experiments on molecular property prediction, protein homology and stability prediction show that the proposed method significantly outperforms previous state-of-the-art baselines."
SP:cad3ed2fba57faf17a3e8899dc5a744d5358aa68,"This paper proposes a new BERT architecture, Cross-Probe BERT (CP) BERT, to improve the efficiency of text-vision BERT. The proposed method is based on devised text and vision probes, and the cross-modal attentions are conducted on text and image probes. It takes lightweight computation cost, and meanwhile effectively exploits crossmodal attention. Experiments conducted on two public benchmarks demonstrate the effectiveness and efficiency of the proposed method."
SP:51fd82de525fcb738fdeaeeae20fbb2cdf975f0c,This paper proposes a new actor-critic algorithm named forward-looking actor (FORK) for Actor-Critic algorithms. The proposed method can be easily integrated into a model-free ActorCritic algorithm. The experiments on six Box2D and MuJoCo environments with continuous state and action spaces demonstrate significant performance improvement FORK can bring to the state-of-the-art algorithms. 
SP:6e730239e6e8b43c4988dd61dca30f15dc039ef7," federated learning (FL) has been shown to be challenging when users have non-i.i.d. data. In this paper, the authors propose a novel aggregation algorithm named FEDBE, which takes a Bayesian inference perspective by sampling higher-quality global models and combining them via Bayesian model Ensemble, leading to much robust aggregation. The authors show that an effective model distribution can be constructed by simply fitting a Gaussian or Dirichlet distribution to the local models. The empirical studies validate FedsBE’s superior performance, especially when users’ data are not iid and when the neural networks go deeper."
SP:3ac5f437fc349a33810d0645664d1c448528af74,"This paper presents a method for analyzing the influence patterns of a DNN model. The method is based on the idea of using multi-partite influence patterns to localize the model’s handling of a concept of interest. In particular, the authors propose to use a pattern refinement method to refine the influence pattern of the DNN. The proposed method is evaluated on two tasks: subject-verb number agreement and reflexive anaphora. "
SP:efa2343ead47263a0d09e1c17f9aa044605b9650,"This paper studies the convergence of deep neural networks. The authors formulate the supervised learning framework as a control problem where weights of the network are control inputs and learning translates into a tracking problem. The Lyapunov function is used to derive an a priori upper bound on the settling time of the neural network. An analytical formula for finite-time convergence is provided under the assumptions of boundedness of input. Finally, the authors prove that the loss function is robust against input perturbations."
SP:7a0ded4b3b2d08d43765ff7b722da9b9863aabd6,This paper studies the problem of disentangled representation learning in nonlinear ICA. The authors point out that the method taken by GIN for informative latent variables selection is not theoretically supported and can be disproved by experiments. They propose to use the mutual information between each learned latent variables and the auxiliary variable to correctly identify informative latent variable. They directly verify the improvement brought by our method in experiments on synthetic data. 
SP:0d9ba12bbf47b13a46c2225f9dc06878418daaea,"This paper proposes a new pooling method for deep convolutional neural networks. The proposed method is based on the classical lifting scheme from signal processing. It decomposes a feature map into various downsized sub-bands, each of which contains information with different frequencies. Then, a corresponding up-pooling layer LiftUpPool is able to generate a refined upsampled feature map. Experiments show that the proposed method achieves better results on image classification and semantic segmentation tasks."
SP:147239edceb17bade6ea5d3dca44e3a59998aa47,"This paper proposes a fast, distance-preserving, binary embedding algorithm to transform a high-dimensional dataset T into binary sequences in the cube {±1}. When T consists of well-spread (i.e., non-sparse) vectors, the embedding method applies a stable noise-shaping quantization scheme to Ax where A is a sparse Gaussian random matrix. The authors show that Euclidean distances among the elements of T are approximated by the $\ell_1$ norm on the images of T under a fast linear transformation. The proposed method is both fast and memory efficient, with time complexity O(m) and space complexity $m$ on well spread data. When the data is not well spread, the approach still works provided that data is transformed via a Walsh-Hadamard matrix, but now the cost is O(n log n). "
SP:f65e229bca3904095743e7a501b1083cc60f1e22,"This paper proposes to use plasticity rules to improve the robustness and generalization of artificial neural networks (ANNs). The authors hypothesize that the plasticity rule serves as a proxy for Gradient Descent (GD) on the parameters of the RNN. They provide both empirical and theoretical evidence for this hypothesis. In their experiments, plasticity-rules for the synaptic weights of RNNs are learned through GD and are found to perform reasonably well (with no backpropagation). They also show that the rules learned by this process generalize from one type of data/classifier to others."
SP:f435530146fa975cb27cd375a857df9bcbd87682,"This paper proposes a new method for visual question generation (VQG) based on double-hints guided Graph-to-Sequence (DH-Graph2Seq) model. In particular, the authors propose a novel learning paradigm to generate visual questions with answer-awareness and region-reference. The proposed method is evaluated on VQA2.0 and COCO-QA datasets. "
SP:53a26ce11647866d3f6ba8b84ca9f13106197a8d,"This paper studies the effect of optimal regularization on the monotonicity of linear regression with isotropic covariates. The authors prove that optimal ridge-regression is sample-monotonic, and show that optimally-tuned $\ell_2$ regularization achieves monotonic test performance as we grow either the sample size or the model size. They also show empirically that optimal-2 can mitigate double descent for more general models, including neural networks."
SP:c193ccc74b987beaf8d53a29a8529a0af5e87742,"This paper proposes a spatial dependency network (SDN) to improve generative modeling by better exploiting spatial regularities and coherence in images. The authors show that augmenting the decoder of a hierarchical VAE by spatial dependency layers considerably improves density estimation over baseline convolutional architectures and the state-of-the-art among the models within the same class. In addition, the authors demonstrate that SDN can be applied to large images by synthesizing samples of high quality and spatial coherence."
SP:db91512a90e75675af03c2f197751c8526d6f5e9,"This paper proposes a new offline RL algorithm based on the Expect-Max Q-Learning (EMaQ) operator. EMaQ is a simplified version of BCQ (Fujimoto et al., 2018a), which removes a heuristic design choice and naturally restricts extracted policies to remain exactly within the support of a given behavior policy. Theoretical analysis is provided to show that EMaq explicitly considers the number of samples and the proposal distribution, which can serve as a novel measure of complexity for offline RL problems. Empirical results are provided on the D4RL benchmark and the online RL benchmark. "
SP:e2b80adeaa9208e0667a64a3f24661f77b48e487,"This paper proposes a batch selection algorithm for improving model fairness. The algorithm is based on a bilevel optimization framework where the inner optimizer is SGD, and the outer optimizer performs adaptive batch selection to improve fairness. Experiments are conducted on both synthetic and real data to demonstrate the effectiveness of the proposed algorithm. "
SP:72f26b850bb2258223c0fc71598e35ad07d690e6,"This paper derives Lipschitz bounds for monotone DEQs, a recently proposed class of impicit-layer networks, and shows that they depend in a straighforward manner on the strong monotonicity parameter m of these networks. They also show how to use these bounds to develop PAC-Bayes generalization bounds that do not depend on any depth of the network, and which avoid the exponential depth-dependence of comparable DNN bounds. Finally, they validate the significance of the small LPschitz bound for monDEQs by demonstrating strong adversarial robustness on MNIST and CIFAR-10."
SP:bcfd4d7fd4590e3bc248a0a5422ce4b67db74a74,This paper proposes a method for imitation learning and goal-conditioned reinforcement learning. The main idea is to use density estimation to estimate the density of states that the agent is not likely to visit and use this density estimate to guide the agent towards states that it will visit. The paper shows that the proposed method is able to learn from sparse expert data using self-supervised environment interactions only and achieves state-of-the-art results on a benchmark.
SP:d57550b2f323b356d7e609acc35ee33039f376b4,This paper proposes a variational multi-task learning method based on Gumbel-softmax priors. The main idea is to use a mixture of variational posteriors of related tasks to learn the prior of each task on related tasks. The mixing weights are learned in a data-driven manner for each individual task. Experiments show that the proposed method achieves state-of-the-art performance.
SP:3ccdf8322f16c8a7bef82e32fad4c03969a510d1,"This paper proposes a systematic and unified benchmark, Long-Range Arena (LRA), for evaluating model quality under long-context scenarios. The benchmark is a suite of tasks consisting of sequences ranging from 1K to 16K tokens, encompassing a wide range of data types and modalities such as text, natural, synthetic images, and mathematical expressions requiring similarity, structural, and visual-spatial reasoning. The authors systematically evaluate ten well-established long-range Transformer models (Reformers, Linformer, Linear Transformers, Sinkhorn Transformers, Performers, Synthesizers, Sparse Transformers, and Longformers) on our newly proposed benchmark suite. "
SP:e12e410c3335b76133ceda4c865b244fbbab8580,"This paper proposes a new code summarization model that combines source code (context) and abstract syntax tree (AST; Structure) representations. The main contribution of this paper is that the model uses language-agnostic features, i.e., source code and features that can be computed directly from the AST. The paper also proposes a multilingual code summarisation model that jointly learns on Context and Structure of source code. Experiments show that the proposed model achieves the state-of-the-art on monolingual code summarizing on all five programming languages considered in this work."
SP:f46e98d48f90071831f1c0069bf74a7993be6db8,"This paper proposes a reinforcement learning approach for audio-visual navigation. The key idea is to learn to set waypoints that are dynamically set and learned end-to-end within the navigation policy, and an acoustic memory that provides a structured, spatially grounded record of what the agent has heard as it moves. The proposed method is evaluated on two challenging datasets of real-world 3D scenes, Replica and Matterport3D."
SP:23bfe317dcef00a91ea92389b3f39d9b93972454,"This paper studies the effect of weight initializations on the convergence of CNNs trained to predict n steps of the two-dimensional cellular automaton Conway’s Game of Life. The authors show that networks of this architecture trained on this task require substantially more parameters to consistently converge. They also show that the initialization parameters that gradient descent converges to a solution are sensitive to small perturbations, such as a single sign change. Finally, they observe a critical value d0 such that training minimal networks with examples in which cells are alive with probability d0 dramatically increases the chance of convergence."
SP:1b5ba618d3e28d48f9205c0780f8288a08fa5392,"This paper proposes a semi-supervised learning method based on the idea of consistency regularization and metric learning. The proposed method considers not only the perturbed inputs but also the similarity among the inputs having the same label. The authors also introduce a new objective function, dubbed BatchMean Triplet loss, which has the advantage of computational efficiency while taking into account all input samples. The experiments show that the proposed method achieves state-of-the-art performance across many standard SSL benchmarks with various labeled data amounts."
SP:f3abccf4a2566ffbc821aba209fab15058639ad4,"This paper proposes a meta-learning algorithm for sequential learning, where the tasks are presented in a sequence of tasks. The authors propose a new algorithm that adapts to variable amounts of data. The algorithm is based on a scaling rule for the learning rate that scales with the number of shots. Experiments show that the proposed algorithm outperforms empirical risk minimization and a previous meta learning method on two online image classification problems consisting of sequences of tasks and one online regression problem."
SP:95cb420d92ec42e12a4bbb0e66224f1c498a7161,"This paper presents a series of experiments to test the sensitivity of Transformer representations to syntactic structure in sentences. Each probe involves swapping words in a sentence and comparing the representations from perturbed sentences against the original. They experiment with three different perturbations: random permutations of n-grams of varying width, swapping of two spans which do or do not form a syntactic phrase, and swapping two adjacent words which are or are not syntactically distinct. They also connect their probe results to the Transformer architecture by relating the attention mechanism to the syntactic distance between two words. "
SP:cb27b27a6fefc192ad1c2bd083d13eb9e51a5c44,"This paper studies the few-shot image synthesis task for GANs with minimum computing cost. The authors propose a light-weight GAN structure that gains superior quality on 1024x 1024 resolution. The model converges from scratch with just a few hours of training on a single GPU, and has a consistent performance, even with less than 100 training samples. "
SP:c0dbeb5d94b2388595cf7ad9675c55df0bac7f8e,"This paper proposes a specialised specialised dual solver for neural network bounding. The main contribution of this paper is a novel dual algorithm that uses a small active set of dual variables to recover the strengths of the new relaxation in the dual space: tightness and a linear separation oracle. The method shares the benefits of previous dual approaches for weaker relaxations: massive parallelism, GPU implementation, low cost per iteration and valid bounds at any time. The authors show that their method achieves better bounds than off-the-shelf solvers in only a fraction of their running time."
SP:56e3837417dbcce0d65338dc3aac4e1a20eb0df8,"This paper proposes a self-supervised approach to improve the performance of a pre-trained text-to-text language model (PTLM) by augmenting it with concept-centric commonsense knowledge. Specifically, the authors propose to use a combination of generative and contrastive objectives for learning common sense from the text, and use them as intermediate self supervised learning tasks for incrementally pre-training PTLMs (before task-specific fine-tuning on downstream tasks). The authors also develop a joint pre- training framework to unify generative objective and discriminative objective so that they can mutually reinforce each other. Extensive experimental results show that the proposed method, Concept-Aware Language Model (CALM), outperforms baseline methods by a consistent margin and is comparable with larger PTLM."
SP:7ec69bdee021af506293c87a3b75bce1c40a03d7,"This paper proposes a method for unsupervised 3D physical object discovery from video. The method is based on multi-scale pixel cues and physical motion cues to accurately segment observable and partially occluded objects of varying sizes, and infer properties of those objects. The proposed method is evaluated on both synthetic and real-world scenes."
SP:66997bc19a3ba6548fcf21f114e748bea95cad1c,This paper proposes an adversarial training method to improve the robustness of deep neural networks against adversarial attacks. The proposed method increases the margins of training samples by moving the decision boundaries of the DNN model far away from the training samples to improve robustness. The method is evaluated on six publicly available datasets (including a COVID-19 CT image dataset) under strong 100-PGD white-box adversarial attack and the proposed method significantly improved classification accuracy on noisy data while keeping a relatively high accuracy on clean data. 
SP:276ffd59fbf49e3ee02756da8920218102214917,"This paper proposes ProKT, a knowledge distillation method that projects the supervision signals of a teacher model into the student’s parameter space by decomposing the training objective into local intermediate targets with approximate mirror descent technique. The proposed method could be less sensitive with the quirks during optimization which could result in a better local optima. Experiments on both image and text datasets show that the proposed ProKT consistently achieves the state-of-the-art performance."
SP:906dc21d6988953fcf57d63bbdd12973e5818d16,"This paper proposes a hyper-structure network (HSN) for channel pruning of CNNs. The main idea is to use the architecture of the HSN to generate a subnetwork of the main network, which can be optimized by regular backpropagation. In addition, a regularization term is proposed to specify the computational resource of the compact network. Extensive experiments on CIFAR-10 and ImageNet show that the proposed method can outperform both conventional channel-pruning methods."
SP:890fd9454596c051b0e9535baf73b1dd1fae67ca,"This paper proposes a method for theorem proving in the presence of a large knowledge base of potential premises without learning from human proofs. The method is based on the exploration of premises based on a simple TF-idf (term frequency-inverse document frequency) based lookup in a deep reinforcement learning scenario. The experiments show that a theorem prover trained with this exploration mechanism but no human proofs, dubbed DeepHOL Zero, outperforms provers that are trained only on human proofs and approaches the performance of a prover training by a combination of imitation and reinforcement learning."
SP:88209417a8ad07e6103084e41709be900303ce5f,"This paper proposes MODALS (Modality-agnostic Automated Data Augmentation in the Latent Space) to augment data for any modality in a generic way. MODALS exploits automated data augmentation to fine-tune four universal data transformation operations in the latent space to adapt the transform to data of different modalities. The proposed method is tested on text, tabular, time-series, and image data and can be readily integrated with popular deep learning models."
SP:6d84670d321b0d584b097c630574bd748e85c9a2,"This paper studies the optimization dynamics of three-layer neural networks in the mean-field regime. The authors show that the learning dynamics of such networks tends to a nonlinear and nontrivial dynamical limit, known as the ""mean-field limit"". The authors propose a neuronal embedding, which comprises of a fixed probability space that encapsulates neural networks of arbitrary sizes. The identified mean field limit is then used to prove a global convergence guarantee under suitable regularity and convergence mode assumptions. "
SP:b90f893f927db9c439595fd119a565cf43c971f4,"This paper proposes a method for learning explanations of expert decisions by modeling their reward function in terms of preferences with respect to “what if” outcomes: Given the current history of observations, what would happen if we took a particular action? To learn these costbenefit tradeoffs associated with the expert’s actions, the authors integrate counterfactual reasoning into batch inverse reinforcement learning. This offers a principled way of defining reward functions and explaining expert behavior. It also satisfies the constraints of real-world decision-making, where active experimentation is often impossible (e.g. in healthcare). "
SP:c92916780418bfa7f0796fd9766b6d28b9eea5ef,"This paper investigates the role of explicit morphological information in graph-based continous control. The authors argue that the benefits GNNs extract from the graph structure are outweighed by difficulties they create for message passing, and propose AMORPHEUS, a transformer-based approach, to address the problem. The experiments are conducted on incompatible MTRL environments. "
SP:2cf58f5cac20dccdc2034ef60e8e46b7988ebd7d,"This paper proposes a method for visual counting, which aims to predict the number of occurrences given a natural image and a query (e.g. a question or a category). The method is based on modulated convolutions that fuse the query and the image locally. The proposed method is called MoVie, short for Modulated conVolutional bottlenecks. The authors show that the proposed method can improve the state-of-the-art on counting-specific VQA tasks while being more efficient, outperforming prior-art in COCO for common object counting. The paper also shows that the method can be integrated as a module for ‘number’ related questions when integrated as part of a generic V QA model."
SP:c64e77507e562f236cb69361b22fb1a7951ffb22,"This paper studies the problem of model-targeted poisoning attacks, where the goal is to attack a model that misbehaves in a way that induces the model to misclassify certain inputs. The authors propose an online poisoning attack that can target a desired model based on online convex optimization. They prove that the attack converges to the target classifier as the number of poison points increases, given that the loss function is convex and proper regularization is adopted in training. They also provide a lower bound on the minimum number of poisoning points needed to reach the target model. "
SP:a526023ec4cb839b83c574d31f59a9a67bc7af00,"This paper proposes a binarization approach for efficient deep learning on point clouds. The authors claim that the performance drop of binarized models for point clouds mainly stems from two challenges: aggregation-induced feature homogenization that leads to a degradation of information entropy, and scale distortion that hinders optimization and invalidates scale-sensitive structures. To tackle these challenges, the authors introduce Entropy-Maximizing Aggregation (EMA) to modulate the distribution before aggregation for the maximum information entropy and Layer-wise Scale Recovery (LSR) to restore feature representation capacity. Extensive experiments show that the proposed method outperforms existing binarizing methods by convincing margins."
SP:825b4d1db0c537a607655bb5b4bf221ec672c8af,"This paper presents a series of memory-augmented transformer-based models, including MemTransformer, MemCtrl, and MemBottleneck transformers. The main idea of the paper is to add a memory module to the top of the transformer head to allow it to selectively store local and global representations of a sequence. Experiments are conducted on a variety of tasks, including language modeling, question answering and machine translation."
SP:f0fa1b7684bc605f6edd4813c44be20988fe8b4c,"This paper proposes Prototypical Contrastive Learning (PCL), an unsupervised representation learning method that bridges contrastive learning with clustering. Specifically, PCL introduces prototypes as latent variables to help find the maximum-likelihood estimation of the network parameters in an Expectation-Maximization framework. PCL iteratively performs E-step as finding the distribution of prototypes via clustering and M-step is optimizing the network via contrastive training. The paper also proposes ProtoNCE loss, a generalized version of the InfoNCE for contrastive representation learning, which encourages representations to be closer to their assigned prototypes. Experiments on several benchmark datasets demonstrate the effectiveness of PCL."
SP:5342a5e1d87fd17b1a2efed967dbbfeafa440ee7,This paper proposes an orthogonal multi-path (OMP) block to improve the robustness of deep neural networks against adversarial attacks. The proposed OMP block consists of a forward and backward correction block. The backward correction is done by forcing the follow-up layers to learn to fit all the paths and correcting the features learned by front layers. Experiments are conducted on white-box and black-box attacks to demonstrate the effectiveness of the proposed method.
SP:776df66274ed12449fde8dcef873a593980f397c,"This paper proposes a self-supervised graph attention network (SuperGAT) for noisy graphs. Specifically, the authors exploit two attention forms compatible with a self supervised task to predict edges, whose presence and absence contain the inherent information about the importance of the relationships between nodes. By encoding edges, SuperGAT learns more expressive attention in distinguishing mislinked neighbors. Experiments are conducted on 17 real-world datasets."
SP:80a05296d6b1e4c6e9e2df01938c73029ff8487d,"This paper proposes a new DSMAD agent, called INS-DS, which consists of two modules: an inquiry module for proposing symptom-inquiries and an introspective module for deciding when to inform a disease. The inquiry module is responsible for selecting the most valuable symptom to be inquired about, while the introspection module intervenes the potential answers of this inquiry to decide whether to inquire the symptom or inform the disease. Two evaluation metrics are proposed to validate the reliability and robustness of DSMAD methods. Extensive experimental results demonstrate the effectiveness of the proposed method."
SP:10ae09d90d465125433a9b4f15b1405ab017920d,"This paper proposes a batch-wise regularization based on the proposed Batch Confusion Norm (BCN) to flexibly address the natural world distribution which usually involves fine-grained and long-tailed properties at the same time. When inter-class similarity prevails in a batch, the BCN term can alleviate possible overfitting due to exploring image features of fine details. On the other hand, when inter- class similarity is not an issue, the class predictions from different samples would unavoidably yield a substantial BCN loss, and prompt the network learning to further reduce the cross-entropy loss. The proposed BCN considers the confusion regularization within each training batch and thus is more general than the relevant formulation of pairwise confusion energy. The resulting model is shown to be capable of learning discriminative features within regions of interest."
SP:90f1e0fe1e9678d1e9a4dcb519d4e8fd61098ce0,This paper proposes a method for learning an approximate posterior distribution over the reward that scales to arbitrarily complicated state spaces with an appropriate policy in a completely offline manner through a variational approach to the latent reward. The proposed method is applied to real medical data and classic control simulations. Experiments show that the proposed method can achieve Bayesian reward inference in environments beyond the scope of current methods.
SP:ccd251d95c0a2d8dc5ad2a148ec29955e105e71e,"This paper proposes a method for performing policy search in partially observable POMDPs. The proposed method is based on an auto-regressive counterfactual belief model that is learned as a supervised task. The method is applied to Hanabi and Hanabi self-play, and is shown to outperform baselines in Hanabi."
SP:db408e6bfe69a9b3984f3b27ca92b802aa37af42,"This paper proposes a new tree search algorithm, called Shoot Tree Search (STS), which aims to address the problem of balance between depth and breadth search in large state spaces. The main idea is to use a multi-step expansion to control the depth of search and inject into planning more randomness via random multi step expansions. Experiments show that STS can get the best of both worlds consistently achieving higher scores. "
SP:5efc271ccc555fd9aa542548838170bd4c98e957,"This paper proposes a method for pre-training a neural network on mathematical reasoning tasks. The authors propose to pre-train the network on a set of synthetic tasks that require deduction, induction, and abduction. These synthetic tasks are designed in a way that they are devoid of mathematical knowledge to ensure that only the fundamental reasoning biases can be learned from these tasks. This defines a new pretraining methodology called “LIME” (Learning Inductive bias for Mathematical rEasoning). Models trained with LIME significantly outperform vanilla transformers on three mathematical reasoning benchmarks."
SP:bb8e0b554d3b3314fa343c902d9e60f1a141ea30,"This paper analyzes the inductive bias of weight normalization (EWN) for smooth homogeneous neural networks. The authors show that the gradient flow path with EWN is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. These results can be extended to hold for gradient descent via an appropriate learning rate. Experiments on simple data sets and architectures support the claim."
SP:c71f9d2a602516865a0b103028186e83b52e5f00,"This paper proposes a method to prevent mode collapse in GANs. The authors claim that the mode collapse problem is due to catastrophic forgetting in the discriminator, and propose a training procedure that dynamically spawns additional discriminators to remember previous modes of generation. Experiments are conducted on MNIST, CIFAR-10, and Fashion-MNIST. "
SP:52c48198c95826e042f9e5a512ef3265daaff882," regularization is a promising direction to regularize BERT based on pruning its attention heads based on a proxy score for head importance. However, heuristic-based methods are usually suboptimal since they predetermine the order by which attention heads are pruned. In order to overcome such a limitation, this paper proposes a regularization method that leverages reinforcement learning to automatically prune attention heads from BERT. Instead of depending on heuristics or rule-based policies, AUBER learns a pruning policy that determines which attention head should or should not be pruned for regularization. Experimental results show that the proposed method achieves up to 9.39% better accuracy."
SP:abcbbad146f1b0d5d579c215952c95e5499a378a,"This paper proposes a method for learning correspondence between robotic states and actions. The method is based on a cycle-consistency constraint, which is used to find a correspondence between the state and action trajectories of a real robot and a simulated robot. This correspondence is learned using unpaired and randomly collected data from the two domains. The proposed method is evaluated on a variety of problem domains, both in simulation and on real robot. "
SP:006434d56992836ab9420d7d4215bc70664de304,"This paper studies the off-manifold Shapley explainability, i.e., the Shapley framework for explainability that attributes a model’s predictions to its input features in a mathematically principled and model-agnostic way. The authors argue that general implementations of Shapley values make an untenable assumption: that the model's features are uncorrelated. They demonstrate unambiguous drawbacks of this assumption and develop two solutions to Shapley explainedability that respect the data manifold. One solution is based on generative modelling, which provides flexible access to data imputations; the other one is a Shapley value function that is learned directly. "
SP:7cda6bccf08887c7cef66d0ac3ccefdea8f5d7c8,This paper proposes a VAE-based method for learning an opponent model conditioned only on the local observations of the agent under control. The proposed method is evaluated on the multi-agent particle environment and level-based foraging tasks. The results show that the proposed method achieves comparable performance to an ideal baseline which has full access to opponent’s information.
SP:c239bc531bcf7293032748af29a1b786e9d893dd," contrastive learning has been adopted as a core method for unsupervised visual representation learning. However, the common practice is to perform an instance discrimination task: given a query image crop, this task labels crops from the same image as positives, and crops from other randomly sampled images as negatives. An important limitation of this label assignment strategy is that it can not reflect the heterogeneous similarity between the query crop and each crop from other images, taking them as equally negative, while some of them may even belong to the same semantic class as the query. To address this issue, this paper proposes Consistent Contrast (CO2), which introduces a consistency regularization term into the current contrastive framework. The consistency term takes the corresponding similarity of a positive crop as a pseudo label, and encourages consistency between these two similarities. Empirically, CO2 improves Momentum Contrast (MoCo) by 2.9% on top-1 accuracy on ImageNet linear protocol, 3.8% and 1.1% top-5 accuracy on 1% and 10% labeled semi-supervised settings, and shows that CO2 learns better visual representations for these downstream tasks."
SP:d18bab21790713e2facb053c47298fc9079ab783,"This paper studies the convergence rate of OGDA and OMWU in bilinear games over the probability simplex. The authors show that when the equilibrium is unique, linear last-iterate convergence is achieved with a learning rate whose value is set to a universal constant, improving the result of (Daskalakis & Panageas, 2019b) under the same assumption. They also extend the results to more general objectives and feasible sets for the projected OGDA algorithm. Finally, they provide experimental results to further support their theory."
SP:bbc7f77308b298c332a39747f693bc396f00a89f,"This paper proposes a federated user verification framework called Federated User Verification (FedUV) to solve the problem of training user verification models in federated setup. In FedUV, users jointly learn a set of vectors and maximize the correlation of their instance embeddings with a secret user-defined linear combination of those vectors. The authors show that choosing the linear combinations from the codewords of an error-correcting code allows users to collaboratively train the model without revealing their embedding vectors. Experiments are conducted on voice, face, and handwriting data and show that FedUV is on par with existing approaches, while not sharing the embedding vector with the server."
SP:40fa47cc0928e2925ef5ce6d808073f368ca2cd4,"This paper proposes a method to estimate the effective dimension of class manifolds (CMs) by computing their intersection with random affine subspaces of varying dimension. The authors provide a theory for the technique and verify that their theoretical predictions agree with measurements on real neural networks. Through extensive experiments, they leverage this method to show deep connections between the geometry of CMs, generalization, and robustness. "
SP:09bce202ac7a750c3700a8ef3cd92cfe8ed00c39,"This paper proposes a novel method to improve the exploration-exploitation trade-off in reinforcement learning. The key idea is to use the state prediction error to model curiosity, which is added to the entropy to increase the entropy temperature for unfamiliar states and decrease the target entropy for familiar states. To model curiosity for feature inputs, the authors propose a new curiosity model, X-RND, optimized by contrastive self-supervised learning. Experimental results on the MuJoCo benchmark show the effectiveness of the proposed method."
SP:dce5eb20581a21c5de0a9fc07a8a79a1fbb28c71,"This paper proposes a meta-reinforcement learning algorithm that is both efficient and extrapolates well when faced with out-of-distribution tasks at test time. The proposed method is based on a simple insight: we recognize that dynamics models can be adapted efficiently and consistently with off-policy data, more easily than policies and value functions. To leverage all data collected from other tasks during meta-training, the proposed method uses the learned model to relabel the next state and reward on every previously seen transition, obtaining synthetic data to continue training the policy. Experiments show that the proposed algorithm can adapt consistently to out of distribution tasks by adapting the model first, relabeling all data from the meta training tasks with this model, and then fine-tuning on that data using a standard off policy RL method."
SP:34d78aa11f9d50baf75a9646a6f9128318c3389a,"This paper studies the problem of few-shot learning in meta-learning. The authors propose a new algorithm, Eigen-Reptile, that updates the meta-parameters with the main direction of historical taskspecific parameters to alleviate gradient noise. The main direction is computed by a special mechanism for the parameter’s large size. Furthermore, the authors propose Introspective Self-paced Learning (ISPL) that constructs a plurality of prior models to determine which sample should be abandoned. Experiments on different tasks demonstrate the effectiveness of the proposed methods."
SP:a571bff9ffe4edafd7bc064c4d10609e6b981ce3,"This paper proposes Adversarial batch normalization (Adversarial Batch Normalization (AdvBN) to adapt adversarial training by adversarially perturbing these feature statistics, rather than image pixels, to produce models that are robust to distributional shifts. The authors demonstrate that AdvBN significantly improves the performance of ResNet-50 on ImageNet-C, Stylized-ImageNet, and ImageNetInstagram over standard training practices."
SP:6a9c46bd3cf854299f360bff136e1d79d3edb2e4,This paper proposes Variance of Gradients (VoG) as a proxy metric for detecting outliers in the data distribution. The authors provide quantitative and qualitative support that VoG is a meaningful way to rank data by difficulty and to surface a tractable subset of the most challenging examples for human-in-the-loop auditing. Data points with high VoG scores are far more difficult for the model to learn and over-index on corrupted or memorized examples. 
SP:074bfacc75837bb19049be8a2890e10de073dd8e,"This paper proposes a method to improve the quality of generated samples from deep generative models by refining them using gradient flow of f-divergences between the real and the generator data distributions. The method is based on a non-linear Fokker-Plank equation, which can be simulated by sampling from the equivalent McKean-Vlasov process. Experiments show that the proposed method can be applied to GANs, VAEs, and Normalizing Flows."
SP:74ecbc5a6d464bfa49337da9e0dd6a0fe714d4bb,"This paper proposes a variable encoder-decoder (VECO) pre-training approach to unify the two mainstreams in both model architectures and pretraining tasks. VECO splits the standard Transformer block into several sub-modules trained with both inner-sequence and cross-sequence masked language modeling, and reorganizes certain sub- modules for understanding and generation tasks during inference. Such a workflow not only ensures to train the most streamlined parameters necessary for two kinds of tasks, but also enables them to boost each other via sharing common sub-modules. The experimental results on various cross-lingual understanding tasks of the XTREME benchmark covering text classification, sequence labeling, question answering, and sentence retrieval demonstrate the effectiveness of the proposed approach."
SP:3d177ad50727d1a2619b68ab8a897b79d8652beb,"This paper proposes an intrinsic reward function for reinforcement learning based on the prediction of auditory event clusters. The key idea is to train a neural network to predict the auditory events and use the prediction errors as intrinsic rewards to guide RL exploration. The proposed method is evaluated on Atari games, Habitat simulator, and TDW."
SP:014f6118ebe55ece6be23c3a10f12e4591e444b1,"This paper studies the problem of novel category discovery on single and multi-modal data with labels from different but relevant categories. The authors propose a generic, end-to-end framework to jointly learn a reliable representation and assign clusters to unlabelled data. To avoid overfitting the learnt embedding to labelled data, they take inspiration from self-supervised representation learning by noise-contrastive estimation and extend it to jointly handle labelled and unlabeled data. In particular, they propose using category discrimination on labelled data and cross-modality discrimination on multi- modal data to augment instance discrimination used in conventional contrastive learning approaches. They further employ Winner-Take-All (WTA) hashing algorithm on the shared representation space to generate pairwise pseudo labels for unlabeling data to better predict cluster assignments."
SP:4df640f502e88ddba2d7e183625231d70b083e82,"This paper proposes a method for weakly supervised segmentation of images. The authors formulate the task as a semi-supervised metric learning problem, where pixels of the same semantics need to be mapped to the same (distinctive) features. They propose 4 types of contrastive relationships between pixels and segments in the feature space, capturing low-level image similarity, semantic annotation, co-occurrence, feature affinity, and feature affinity. They show that the pixel-wise feature can be learned from training images with any partial annotations in a data-driven fashion. The experiments on Pascal VOC and DensePose demonstrate consistent gains over the state-of-the-art."
SP:f7d6099adb40a0ce2f8a3563dbd5207cf1fdea0f,"This paper proposes a self-supervised distillation method, BINGO, which is short for Bag of InstaNces aGgregatiOn, to transfer the relationship learned by the teacher to the student. The goal of distillation is to aggregate compact representations over the student with respect to instances in a bag. The method achieves new state-of-the-art performance on small scale models with linear evaluation on ImageNet."
SP:328866aad6544c81ded8980934df31dc4472435f,"This paper proposes GATSBI (Generative Adversarial Training for Simulation-based Inference), an adversarial variational inference algorithm for simulation-based inference (SBI). The main contribution of this paper is to reformulate the variational objective in the adversarial setting to learn implicit posterior distributions, which is amortized across observations, works in high-dimensional posterior spaces, and supports implicit priors. Experiments are conducted on two SBI benchmark problems and on two high dimensional simulators. "
SP:2915e82097eae4eb8546dc500f32b3ec37e3766f,"This paper studies the identification and estimation of individualized treatment effects (TEs) under limited overlap. The authors propose a variational autoencoder (VAE) based approach that uses a prognostic score to model the treatment effect. The prognostic scores are derived from observed variables and the model is learned as a beta-Intact-VAE, which is a new type of variational VAE. The paper also derives the TE error bounds that enable representations balanced for treatment groups conditioned on individualized features. The proposed method is compared with recent methods using (semi-)synthetic datasets. "
SP:ca358c9f36aac6e58ed1b3949c349d210c49a48e,"This paper proposes a framework for autonomous reinforcement learning (ARL) where the agent not only learns through its own experience, but also contends with lack of human supervision to reset between trials. The authors introduce a benchmark for autonomous RL (EARL1) around this framework, containing a set of diverse and challenging simulated tasks reflective of the hurdles introduced to learning when only a minimal reliance on extrinsic intervention can be assumed. The experiments show that standard approaches to episodic RL and existing approaches struggle as interventions are minimized. "
SP:abe51d4a9817c08f0abde5da0bb8e6ca4e02e7cf,"This paper analyzes the state-of-the-art GNN-based QA systems and shows that they are over-parameterized and over-complex. The authors show that the initial node embeddings and some GNN layers are completely dispensable. They also show that GNN essentially works as a counter in the QA reasoning process. To verify this point, they design soft / hard counter models, which achieve comparable or even better experimental results than existing GNN based methods."
SP:3ea5a38e7fcd9111dcd299ad039b634e2781685f,"This paper proposes a method to improve inference performance with compressed neural networks during inference time. The main idea is to leverage the Succinct Data Structures (SuccinctDS) to query directly on compressed representation without decompression. The method first transforms DNN models as their proposed formulations in either Element-wise or Block-wise manner. Then, the method compresses transformed DNN model using succinct data structures. Finally, this method exploits the specialized execution pipelines for different model formulations, to retrieve relevant data for DNN inference. "
SP:94c395afc794a9cc163e362078769ff83f3d20d0,"This paper proposes a new training method for improving the performance of tiny neural networks. The authors argue that training tiny models is different from training large models: rather than augmenting the data, we should augment the model, since tiny models tend to suffer from under-fitting rather than over-fitting due to limited capacity. To alleviate this issue, this paper augments the network (reverse dropout) instead of inserting noise into the dataset or the network. It puts the tiny model into larger models and encourages it to work as a sub-model of larger models to get extra supervision."
SP:9c24549b980e415616f818acbf4cf680ef8edb52,"This paper proposes a GAN-based method for generating dynamic point cloud sequences without requiring point correspondence annotations. The proposed method is based on a temporal Point Cloud Upsampling GAN (TPU-GAN), which is able to learn the underlying temporal coherence from point cloud sequence, which in turn guides the generator to produce temporally coherent output. In addition, a learnable masking module is proposed to adapt upsampling ratio according to the point distribution. Extensive experiments are conducted to demonstrate the effectiveness of the proposed method."
SP:67efe60ad37807505369b7852bc0abed29ffdda8,This paper proposes a novel method for fully pre-training an encoder-only transformer and finetune it for object detection via a task adapter. The proposed method is inspired by the success of textual prompts in NLP and treats query positional embeddings as visual prompts to help the model attend to the target area (prompting) and recognize the object. Experiments on the challenging COCO dataset demonstrate that our PT-DETR achieves competitive performance.
SP:a1f9897496303984fc7ad469222106b14b4a6233,"This paper proposes FedPAGE, a new federated learning algorithm for convex and non-convex optimization. The main idea is to use the optimal PAGE method to reduce the number of communication rounds in FedAvg and SCAFFOLD. In the convex setting, the authors improve the best-known result of Karimireddy et al. (2020) by a factor of 3/4, where N is the total number of clients, S is the sampled subset of clients in each communication round, and is the target error. The authors show that in the case of a convex convex optimization problem, the communication round complexity is O(sqrt(3/4 S^2/3 S^3) where S is a subset of the clients sampled in each round. The same result is achieved in the non-Convex setting."
SP:81e74765abc6524edd8fdf9a3ba107d7bddaa04b,"This paper studies the decision boundary geometry of ANN classifiers by utilizing adversarial perturbations. The authors define adversarial subspaces, which are spanned by orthogonal directions of minimal perturbation to decision boundary from any given input sample. The decision boundary lies close to input samples in a large subspace, where the distance to the boundary grows smoothly and sub-linearly as one increases the dimensionality of the subspace. The geometry of the boundary is more curved within the adversarial space than within a random subspace of equal dimensionality. "
SP:af5c25ecf38c5c3f3387720bdc80c2c54c5699fe,"This paper proposes a clustering-based contrastive learning method for learning weakly-supervised representations. The authors argue that auxiliary information is a form of the valuable information provided by the auxiliary information, i.e., its implied data clustering information. Based on this intuition, the authors propose a two-stage method to cluster data according to its auxiliary information. The second stage is to learn similar representations within the same cluster and dissimilar representations for data from different clusters. Experiments are conducted on learning visual representations using UT-zappos50K, CUB-200-2011, Wider Attribute, and ImageNet-100 datasets."
SP:0a92fcc52970201de4a66b1e76c93dbea9dfd3f1,"This paper studies the problem of recovering sparse parameters from observational data. The authors propose an iterative iterative sparse recovery algorithm (PLISA) based on unrolling a path-following algorithm with some components being more flexible and learnable. With this structure, they theoretically show the improved recovery accuracy achievable by PLISA. Furthermore, they analyze the empirical Rademacher complexity of PLISA to characterize its generalization ability to solve new problems outside the training set."
SP:5064eda9ba27060af15e81b2b317b2e4558b0ac4,"This paper proposes a method to learn a compact and decodable latent representation space for discrete-continuous hybrid action space. The method is based on an embedding table and conditional Variational Auto-Encoder (VAE). The action representation is trained to be semantically smooth through unsupervised environmental dynamics prediction. Finally, the agent learns its policy with conventional DRL algorithms in the learned representation space and interacts with the environment by decoding the hybrid action embeddings to the original action space using conventional RL algorithms. "
SP:5128bf712f6b197de113c7a371b4bec36f978eca,"This paper proposes SGEM, Stochastic Gradient Descent with Energy and Momentum to solve a class of general non-convex stochastic optimization problems, based on the AEGD method that originated in the work. The authors show that SGEM has an unconditional energy stability property, and derive energy-dependent convergence rates in the general nonconveX setting, as well as a regret bound in the online convex setting. A lower threshold for the energy variable is also provided. The experimental results show that the proposed method outperforms SGDM in training some deep neural networks."
SP:11f49b0a975be87769be29e85d7e3924699cf2c9,"This paper proposes a Conditional Masked Language Model with Correction (CMLMC) for non-autoregressive (NAR) machine translation. The authors claim that leading NAR models still lag behind their AR counterparts, and only become competitive when trained with distillation. To address this problem, they modify the decoder structure by exposing the positional encodings and incorporating causal attention layers to differentiate adjacent tokens. They also propose a novel correction loss that teaches the model how to correct translation mistakes made in early decoding iterations from the fully masked sentence. Empirically, they show that CMLMC achieves state-of-the-art NAR performance when trained on raw data without distillation and approaches AR performance on multiple datasets."
SP:96f8ac3c6163e56d8ae1954a162bae01e6b58a0a,"This paper proposes WaveSense, a neural network architecture inspired by the WaveNet architecture. WaveSense uses simple neural dynamics, fixed time-constants and a simple feed-forward architecture and hence is particularly well suited for a neuromorphic implementation. The authors test the capabilities of this model on several datasets for keyword-spotting. The results show that the proposed network beats the state of the art of other spiking neural networks and reaches near state-of-the-art performance."
SP:7f20a2e4e95f857140b87b0730360b3ff2f371f4,"This paper proposes Shifty, a class of classification algorithms that provide high-confidence fairness guarantees that hold when the distribution of demographics changes between training and deployment. Shifty algorithms allow the proportions of demographics to change after training, provided the user has some information describing this change. The authors evaluate Shifty using a real-world dataset of university entrance exams and subsequent student success. They show that the learned models avoid bias under demographic shift, unlike existing methods."
SP:94f097921bee5fdc10ec2e7c901b2ddb876d9d41,"This paper proposes Neural Stochastic Dual Dynamic Programming (ν-SDDP), a neural network-based method for solving multi-stage stochastic optimization problems. The main idea is to use a neural model to learn to map problem instances to a piece-wise linear value function within intrinsic low-dimension space, which is designed to interact with a base SDDP solver, so that it can accelerate optimization performance on new instances. The proposed method is evaluated on a range of synthetic and real-world problem settings."
SP:3d9f5132f9ec3807dbca78462a459fd123a09b24,"This paper proposes a new protocol for private next-token prediction, called Submodularity, to prevent privacy violations by language models that were fine-tuned on a private corpus after pre-training on a public corpus. The proposed method is based on a relaxation of group differentially private prediction. The authors show that the proposed submodularity can prevent the leakage of information that is unique to any individual user in the private corpus. "
SP:7f524d186ea939309c7eeb843c62b6a4b4cfbc8a,"This paper proposes an unsupervised method to detect OOD samples using a k-NN density estimate with respect to a classification model’s intermediate activations on indistribution samples. The authors leverage a recent insight about label smoothing, which they call the Label Smoothed Embedding Hypothesis, and show that one of the implications is that the proposed method performs better as an OOD detection method both theoretically and empirically when the model is trained with label smoothed. The proposed method outperforms many OOD baselines."
SP:aafbd6ada14cc59a272fe4bf95fac71fa18e57ab,This paper proposes a method to learn a representation of the latent space of an autoencoder using a diffusion-based generative model. The main idea is to use a denoising score matching objective to learn the latent representation. The authors show that the proposed method is able to achieve better performance than GANs and VAEs on semi-supervised image classification tasks. They also show how adversarial training can improve sample quality and sampling speed.
SP:8cfc837d5c10d539bbd098df7134c42e4830ba25,"This paper proposes a method for goal-conditioned reinforcement learning that learns to reach distant goal-reaching tasks by using planning at training time to automatically generate a curriculum of intermediate states. The algorithm, C-Planning, is based on expectation maximization, where the E-step is used to plan a sequence of waypoints using graph planning, while the M-step aims to learn a policy to reach those waypoints. Unlike prior methods, the proposed method performs planning only during training and not testing, significantly decreasing the compute costs of deploying the learned policy. Empirically, the authors demonstrate that their method is more sample efficient that prior methods."
SP:ef3193842e06d4a6edb8a6a86ea5bc97ee5eaa4a,"This paper proposes a new mixup regularization method for training deep neural networks, called k-mixup, which is an extension of mixup (Zhang et al., 2018). Mixup is a popular regularization technique for training neural networks that can improve generalization and increase adversarial robustness. In this paper, the authors propose to use a displacement interpolation method to improve mixup by perturbing training data in the direction of other randomly-chosen instances in the training set. The authors demonstrate theoretically and in simulations that k-Mixup preserves cluster and manifold structures, and extend theory studying the efficacy of standard mixup to the k- mixup case. Empirical results show that training with k- Mixup further improves generalisation and robustness across several network architectures and benchmark datasets of differing modalities."
SP:0fe6a9848026e5f6436a380199e27a9ad26cffed,"This paper proposes a kernelized classification layer for deep neural networks aiming to extract the best possible classifier with embeddings produced by a given representation learner. The classification layer classifies embeddins in a high dimensional RKHS while automatically learning the optimal kernel that enables this high-dimensional mapping. The authors show that a classification network with a lightweight representation learning backbone can be made more effective by replacing the usual softmax classifier by the kernelized classifier. The experiments show consistent and substantial accuracy improvements in image classification, natural language understanding, distillation and active learning settings."
SP:01ee8ec81619784788eb0ce9785098e437d17a7c,"This paper analyzes the sources of bias in node representations obtained via Graph Neural Networks (GNNs). The paper shows that both nodal features and graph structure lead to bias in the obtained representations. Based on the analysis, fairness-aware data augmentation frameworks are developed to reduce the intrinsic bias. Extensive experiments are carried out over real networks in the context of graph contrastive learning. "
SP:7739dc9e37f7f1384f87d2e60281e5bb27fece99,"This paper studies the problem of treatment effect estimation in the presence of unobserved confounders in observational data. The authors propose a confounder-balanced IV regression (CB-IV) algorithm to jointly remove the bias from the unmeasured confoundsers with IV regression and achieve better bias-variance trade-off in imbalanced treatment distributions. The proposed algorithm consists of three main modules: (1) treatment regression: regressing the treatment with IVs and confounding like previous nonlinear IV methods for removing the confounding; (2) Confounder balancing: learning a balanced representation to eliminate the bias induced by the observed confounds; and (3) outcome regression: Regressing the outcome with the predicted treatment and the balanced representation. Extensive experiments demonstrate that CB-IV algorithm outperforms the state-of-the-art methods, including other instrumental variable methods, for treatment effect estimations. "
SP:fdb68c39fce254b73310a3101b2fe97ba47e69fe,"This paper analyzes the effectiveness of MAML in a linear regression setting with a mixture of easy and hard tasks, where hardness is related to the rate that gradient descent converges on the task. The authors prove that in order to achieve substantial gain over NAL, (i) there must be some discrepancy in hardness among the tasks, and (ii) the optimal solutions of the hard tasks must be closely packed with the center far from the center of the easy tasks optimal solutions. They also give numerical and analytical results suggesting that these insights apply to two-layer neural networks."
SP:e8143c7880c16ee9ce7a544e0fd80f001b1b4f9f,This paper proposes a novel unrolling method for sparse blind source separation. The method is based on the Proximal Alternating Linearized Minimization (PALM) algorithm. The main idea is to leverage the data-driven knowledge stemming from realistic simulations or ground-truth data by learning both PALM hyperparameters and variables. The proposed LPALM algorithm is shown to outperform other unrolled source separation methods in the semi-blind setting. The algorithm is also shown to be more robust to spurious solutions.
SP:7716315001949ab88c8a216302fe51bae872fc87,"This paper proposes a Legendre Memory Unit-based model with implicit self-attention to improve the performance of transformers on the task of language modeling. The authors show that for the same amount of training, their model improves the loss over transformers about as much as transformers improve over LSTMs. They also show that adding global self attention to transformers improves the performance even further."
SP:832f422b3554e89702e13c8c5690ee26f2289e3b,"This paper proposes LatentKeypointGAN, a generative adversarial network (GAN) that generates a set of keypoint embeddings that can be used to re-arrange the generated images by re-positioning and exchanging keypoints. The keypoints have an appearance embedding that controls the position and style of the generated objects and their parts. The proposed method is trained end-to-end on the classical GAN objective with internal conditioning on the set of space keypoints and matching images. The experiments show that the proposed method can generate different types of keypoints, such as face, eyes, and mouth from different images. "
SP:9206ae6e31077569313838504ef6daa89ad3b59c,"This paper studies the effect of depth on the signal propagation of fully connected neural networks with layer normalization using the mean field formalism. The authors show that increasing the depth leads to gradient explosion or to another undesirable phenomenon they call representation shrinkage. They show that this phenomenon is not restricted to a specific initialization scheme or a choice of activation function, but rather is an inherent property of the fully-connected architecture itself. They also show that many popular normalization techniques fail to mitigate these problems. "
SP:2177be818b5843c580c787f1b2d725154846feb6,"This paper proposes a line search method to approximate the full-batch loss with a parabola estimated over several mini-batches. Learning rates are derived from such parabolas during training. In the experiments, the proposed method mostly outperforms SGD tuned with a piece-wise constant learning rate schedule and other line search approaches for Deep Learning across models, datasets, and batch sizes on validation and test accuracy."
SP:62233782f9046c85617d9ccfe8427eae7d1c9da7,"This paper studies the problem of noise-contrastive estimation (NCE) when the noise distribution is not well chosen. The authors provide a theoretical analysis of the algorithmic difficulties that arise when optimizing the NCE objective with an uninformative noise distribution, stemming from an ill-behaved loss landscape. They show that even on the simple task of Gaussian mean estimation, even assuming access to the population gradient, gradient descent and Newton’s method with standard step size choice still require an exponential number of steps to reach a good solution. To address this, they propose the eNCE loss, a variant to NCE that replaces the log loss in NCE with an exponential loss, and they show that the resulting condition number is polynomial in the dimension and the parameter distance between P and Q when they belong to an exponential family. The proposed loss can be efficiently optimized using normalized gradient descent."
SP:ceba6c1421b2d03863007fdaf029b8b946519c1b,"This paper studies the problem of how to combine DP and Byzantine resilience in distributed machine learning. In particular, the authors consider the case where a fraction of the workers are malicious (Byzantine) and the other fraction are honest while providing noisy information to the server to ensure differential privacy (DP). They show that many existing results on the convergence of distributed SGD under Byzantine faults, especially those relying on Byzantine resilience, are rendered invalid when honest workers enforce DP. To circumvent this shortcoming, they revisit the theory of (alpha, f)-BR to obtain an approximate convergence guarantee. "
SP:bc783f0c829f90931535e63687d13172879631b3,This paper proposes a method for code editing with few exemplars. The authors propose a multi-extent similarity-based method to capture the code snippet similarity and compositing support exemplars for the query code snippet decoding. The method is evaluated on C# and Python code editing datasets. The results show that the proposed method outperforms baseline methods by a large margin.
SP:ca0c4bdb02f7d939fb6de38b6b446ced4b5984a0,"This paper proposes a program synthesis approach for generating high-level relational constraints between different sub-components of an example (e.g., lines of a poem or measures of music). The approach consists of two parts: (i) one model to generate a realistic set of relational constraints, and (ii) a second model that generates realistic data satisfying these constraints. For model (i), the authors propose to use program synthesis algorithm that infers the relational constraints present in the training data, and then learn a generative model based on the resulting constraint data. The experiments show that the proposed approach significantly improves over state-of-the-art in terms of capturing high level structure in the data. "
SP:692ae0c583a1585eff1a7d9c0d3b51b7879611cc,"This paper studies the problem of set-to-hypergraph prediction, where the goal is to infer the set of relations for a given set of entities. This is a common abstraction for applications in particle physics, biological systems and combinatorial optimization. The paper addresses two common scaling problems encountered in set to hypergraph tasks that limit the size of the input set: exponentially growing number of hyperedges and the run-time complexity, both leading to higher memory requirements. The authors make three contributions. First, they propose to predict and supervise the positive edges only, which changes the asymptotic memory scaling from exponential to linear. Second, they introduce a training method that encourages iterative refinement of the predicted hypergraph, which allows us to skip iterations in the backward pass for improved efficiency and constant memory usage. Third, they combine in Section 4 the efficient representation from the first contribution with the requirements of the scalable training method from the second contribution in a recurrent model that performs iteratively refinement on a pruned hypergraph. They provide ablations for their main technical contributions and show that their model outperforms prior state-of-the-art."
SP:e3481fb6d8d1aa45d6ed4a454e781f5a2c30c57e,"This paper proposes a post-processing method to mitigate gender bias in face recognition models. The proposed method consists in learning a shallow neural network, called the Ethical Module, which transforms the deep embeddings of a pre-trained model to give more representation power to the discriminated subgroups. Its training is supervised by the von Mises-Fisher loss, whose hyperparameters allow to control the space allocated to each subgroup in the latent space. Besides being very simple, the resulting methodology is more stable and faster than most current methods of bias mitigation."
SP:3fb5dcc8b8fb731e09c14b16480cada1c7ccfaa7,"This paper studies the problem of class-incremental learning (CIL) and proposes a novel method PlaceboCIL for tackling the forgetting problem in CIL tasks. The proposed method leverages unlabeled placebo data from a free image stream to improve the effect of KD between the models learned in adjacent phases, while not harming the learning of new classes in the new model. The authors also propose an RL algorithm to make the selection of placebos more adaptive in different phases. Extensive experiments on multiple baselines show that the proposed method is general and efficient."
SP:506e0a888c03a955b708464eed3670c04baf4912,"This paper proposes a method for sampling from discrete energy-based models (EBMs) using a path auxiliary algorithm that uses a composition of local moves to efficiently explore large neighborhoods. The authors also give a fast version of their algorithm that only queries the evaluation of energy function twice for each proposal via linearization of the energy function. Empirically, they show that their path auxiliary algorithms considerably outperform other generic samplers on various discrete models for sampling, inference, and learning. "
SP:4b466277aa5561a80c48d5e72559de4ce95f228b,"This paper proposes a method for learning a hierarchical generative model that is able to adapt to different temporal dynamics. The method is based on a neural probabilistic inference system that organizes latent representations of video features in a temporal hierarchy, based on their rates of change, thus modeling continuous data as a hierarchical renewal process. The proposed method is evaluated on several video datasets, showing that it can detect event boundaries, disentangle spatiotemporal features across its hierarchy, adapt to the dynamics of the data, and produce accurate time-agnostic rollouts. "
SP:459ef2e6bd7638020955dbb4d8ae1098619f7b95,This paper proposes a new method for image retrieval that combines global and local features. The main idea is to replace the re-ranking process with information fusion to obtain more powerful features and overcome the low efficiency of local features in storage and matching. The proposed method is an end-to-end and single-stage pipeline. Experiments on Revisited Oxford and Paris datasets validate the effectiveness of the proposed method.
SP:487cc308a1e8ee078c54b2158bcae47e920e73f8,"This paper proposes RotoGrad, a multi-task learning algorithm that homogenizes gradient magnitudes and directions to avoid negative transfer. The main idea is to homogenize task gradients in terms of both magnitude and directions. The authors provide theoretical analysis to show that the cooperation between gradient magnitude and direction-homogenization ensures the stability of the overall learning process. Empirical results demonstrate the effectiveness of the proposed method."
SP:050cd8319d84a1bd8c2ccb930ba69b33c8fb6e60,This paper proposes a method to fuse heterogeneous neural networks with different number of layers via cross-layer alignment. The proposed method is based on a dynamic programming-based method to solve the alignment problem and a layer balancing method to balance the number of neural networks before applying layer-wise model fusion. Experiments are conducted to demonstrate the effectiveness of the proposed method. 
SP:f764eae15cd083fdb4eb2af09ac64c2d878a454f,"This paper analyzes the implicit regularization effect of SGD in the offline deep RL setting. The authors show that the resulting derived regularizer favors degenerate solutions with excessive “aliasing”, in stark contrast to the supervised learning case. To address this issue, this paper proposes a simple and effective explicit regularizer, called DR3, that counteracts the undesirable effects of this implicit regularizer. Experiments are conducted to demonstrate the effectiveness of the proposed DR3."
SP:6fd793b27123bf80504e2ad5957455b7ec311612,"This paper proposes HyperDQN, an exploration method for deep reinforcement learning (RL) that uses a probabilistic hyper-model to generate approximate posterior samples of the Q-value function. The authors claim that the hypermodel is able to generate diverse Q-values, which can be used to select the best action sequences to explore. The proposed method is evaluated on the Atari suite, where it outperforms DQN and OPIQ."
SP:b428383660928374c953f659ea1e05852dbdcd6e,"This paper proposes a method to learn causal representations from observational data by regularizing the learning procedure with mutual information measures according to our hypothetical causal graph. The optimization involves a counterfactual loss, based on which the authors deduce a theoretical guarantee that the causality-inspired learning is with reduced sample complexity and better generalization ability. Extensive experiments show that the models trained on causal representations learned by our approach is robust under adversarial attacks and distribution shift."
SP:1258c05a80a17949b50e6dae13deea1d2235f456,"This paper proposes ProgFed, a progressive training framework for efficient and effective federated learning. It reduces computation and two-way communication costs while maintaining the strong performance of the final models. Theoretically, the authors prove that Progfed converges at the same asymptotic rate as standard training on full models. Extensive experiments on different architectures show that the proposed method is communication and computation-efficient."
SP:8cdaa6e0dafd750ebdb5d7a4c1987a042400662f,"This paper studies the generalization of adversarial training through the lens of the adversarial Rademacher complexity of deep neural networks. The main contribution of this paper is to provide an upper bound on the adversarially trained weight norms, which is based on the product of weight norms. The authors also provide experiments to show that the weight norms are larger than the standard trained weight norm, thus providing an explanation for the bad generalization performance of training adversarial networks."
SP:925d6bb051e9b384669fb695085b678c11f7c11a,"This paper proposes a kernel-based differential entropy estimator, called Kernelized Neural Differential Entropy Estimation (KNIFE). The proposed estimator is based on the kernelized neural differential entropy (KDE) estimator (Schraudolph, 2004; McAllester & Stratos, 2020), which is a kernelized, differentiable estimator of differential entropy. The authors also propose an estimator for conditional differential entropy and mutual information. Experiments are conducted on a variety of tasks, including visual domain adaptation, textual fair classification and textual fine-tuning."
SP:d2f3beac855f0d72c13552fecb2bdb9d42195df3,"This paper proposes a new soft-greedy operator, called resmax, that takes actions proportionally to their suboptimality gap: the residual to the estimated maximal value. The authors prove that it is a non-expansion for any fixed exploration hyperparameter, unlike the softmax policy which requires a state-action specific temperature to obtain a nonexpansion (called mellowmax). The authors empirically validate that resmax is comparable to or outperforms softmax and softmax across a variety of environments in tabular and deep RL."
SP:792ae8808aa6902758146aef1548c975492b833c,"This paper proposes a method to control the learnability of a specific dataset with a special key. In particular, the authors propose an adversarial invertible transformation, that can be viewed as a mapping from image to image, to slightly modify data samples so that they become “unlearnable” by machine learning models with negligible loss of visual features. Meanwhile, one can unlock the learnable of the dataset and train models normally using the corresponding key. The proposed learnability lock leverages class-wise perturbation that applies a universal transformation function on data samples of the same label. The authors empirically demonstrate the success and practicability of our method on visual classification tasks."
SP:9af10703605e620e563241e2602a50b629f3d37a,"This paper proposes a novel method for handling missing node features in graph learning. The proposed method is based on a diffusion-type differential equation on the graph. The discretization of this equation produces a simple, fast and scalable algorithm which the authors call Feature Propagation. The experimental results show that the proposed approach outperforms previous methods on seven common node-classification benchmarks. "
SP:cbaa3f1379fa99159899d79ccb479c0187403aca,This paper studies the problem of active learning in the presence of limited labeled data by selecting a core subset of an unlabeled data pool to label. The authors propose a Generalized Benders Decomposition (GBD) algorithm to solve the optimization problem of selecting the core set that minimizes the discrete Wasserstein distance between the unlabelled data pool and the labeled data pool. The proposed method is shown to be competitive with baselines and outperforms them in the low budget regime. 
SP:4c72923f78ca6590dc11e10d1a2403076a583718,"This paper proposes a method to solve the de novo genome assembly problem by finding a path through the assembly graph. A graph convolutional network is trained on a dataset generated from human genomic data to reconstruct the genome by finding the path through assembly graphs. The authors show that their model can compute scores from the lengths of the overlaps between the sequences and the graph topology which, when traversed with a greedy search algorithm, outperforms the greedy search over the overlap lengths only. Moreover, the method reconstructs the correct path in the fraction of time required for the state-of-the-art genome assembly methods."
SP:24de906e4289c9073b6c55c747b0913b8df5e053,"This paper addresses the problem of catastrophic forgetting in meta-continual learning by incorporating experience replay (ER) into meta-testing. The authors propose to store the samples’ representations, instead of the samples themselves, into the replay buffer. This ensures the batch nature of ER does not conflict with the online-aware nature of OML. Moreover, the authors introduce a meta-learned Predictive Sample Selection to replace the widely used reservoir sampling to populate the replay buffers. Experimental results on a number of real-world meta-learning benchmarks demonstrate that the proposed method outperforms the state-of-the-art."
SP:3c78454f053f74930979a8054cd7c8a34b6fe63d,"This paper proposes a new method for multi-agent joint Q-learning based on centralized training with decentralized execution (CTDE). The authors formulate an explicit credit assignment problem where each agent gives its suggestion about how to weight individual Q-values to explicitly maximize the joint Q value. Theoretically, they give a gradient ascent solution for this problem. Empirically, the authors demonstrate that ECAQ achieves interpretable credit assignment and superior performance compared to several advanced baselines. "
SP:0d2b225ac697679d10df25f371b2a718d4949b42,"This paper studies the problem of attacking transductive learning-based adversarial robustness. The authors propose a new attack framework called Greedy Model Space Attack (GMSA) that can be used as a new baseline for evaluating adversarial learning based defenses. They show that GMSA, even with weak instantiations, can break the existing defenses. On the other hand, they show that adversarially retraining the model using fresh randomness at the test time gives a significant increase in robustness against attacks. "
SP:e7024cae196fc5eb6a62d289a95d76b532b6a36c,"This paper studies the problem of batch normalization, i.e., the case where the entire dataset is normalized jointly. The authors propose a method for performing per-example normalization in a way that does not modify the inference-time architecture. Specifically, the authors propose an aggregation step that aggregates the information from multiple examples, similar to the way that the gradients with respect to the model parameters are commonly averaged over the minibatch in SGD. "
SP:4aa42984fcb0fd66936d668477b2719ef5c427d4,This paper proposes a low-rank adaptation (LoRA) method to reduce the number of trainable parameters in a pre-trained language model. The key idea is to freeze the pretrained model weights and inject trainable rank decomposition matrices into each layer of the Transformer architecture. The proposed method is evaluated on a variety of tasks and compared with Adam. 
SP:b77a00beb0802f47810b03d3c4aa24d92781414f,"This paper proposes a regular-constrained linear-chain conditional random field (CRF) model that is guaranteed to output label sequences from a regular language. The main idea is to constrain the output of a CRF to be written in a language such that the resulting regular CRF (RegCCRF) has the same formal properties as a standard CRF, but assigns zero probability to all label sequences not in the language. RegCCRFs can incorporate their constraints during training, while related models only enforce constraints during decoding. The authors prove that constrained training is never worse than constrained decoding, and show empirically that it can be substantially better in practice. "
SP:74c186a96c12adff178264aa84ace8d04dc7d725,"This paper proposes an end-to-end neural network architecture for camera-based physiological measurement. The proposed architecture is based on a transformer and a convolutional neural network, which do not require any preprocessing steps. Experiments show that the proposed model achieves state-of-the-art accuracy on three public datasets."
SP:3003bab6e3f7e2e21cd6cf27ee7d483d877d9fb3,"This paper proposes a hardware-aware latency pruning (HALP) method for network architecture pruning. The authors formulate the problem as a global resource allocation optimization problem, aiming at maximizing the accuracy while constraining latency under a predefined budget. The latency lookup table is used to track latency reduction potential and global saliency score to gauge accuracy drop. The proposed method is evaluated on both classification and detection tasks on ImageNet and VOC datasets."
SP:c44d676c09c8e5a70d73b21b507b41a422fec809,"This paper proposes a molecular graph generation method via energy-based models (EBMs) to perform permutation invariant and multi-objective molecule generation. Particularly, thanks to the flexibility of EBMs and our parameterized permutation-invariant energy function, our GraphEBM can define a permutation invariant distribution over molecular graphs. In addition, to generate molecules with a specific desirable property, the authors propose a simple yet effective learning strategy, which pushes down energies with flexible degrees according to the properties of corresponding molecules. Further, they explore to use our graphEBM for generating molecules towards multiple objectives via compositional generation, which is practically desired in drug discovery. The experimental results demonstrate that the proposed method is effective."
SP:70e60fa5deef3e3ba77d05d0c3e0e7fbf396aa1d,"This paper proposes a neural-network-based program synthesis method, called CROSSBEAM. The method is based on bottom-up search, where a neural network is trained to learn a policy to combine previously explored programs into new programs, taking into account the search history and partial program executions. The proposed method is evaluated on string manipulation and inductive logic programming tasks. "
SP:daa044ffefe80bae16b014f60061d941ed8c2ba6,"This paper proposes a new objective function for deep reinforcement learning, called FR Squared Bellman Error (FR DQN), which is an alternative to the standard squared Bellman error. The main idea is to add a regularization term to the original objective function, i.e., the FR loss function, which is a weighted sum of two terms. The first term is a normalization term, while the second term is an additional term that is added to the loss function to control the stability of the objective function. The authors demonstrate the effectiveness of the proposed objective function on a variety of Atari games."
SP:dd174014d056a7d2bc86ee99119841eafa62ed52,"This paper proposes a new graph neural network architecture, called GraphSNN, that injects structural information into the message-passing aggregation scheme of GNNs. The proposed architecture is based on a new hierarchy of local isomorphism on neighborhood subgraphs, and the authors prove that it is more expressive than the Weisfeiler Lehman test in distinguishing graph structures. Experiments are conducted on node classification and graph classification tasks to demonstrate the effectiveness of the proposed architecture."
SP:beb9ba0261e176bfc50e9bf5bed2b6169d388285,"This paper proposes a novel prediction interval (PI) method for uncertainty quantification. The proposed method is based on linear combinations of three neural networks, each of which is independently trained using the standard mean squared error loss. The coefficients of the linear combinations are computed using root-finding algorithms to ensure tight PIs for a given confidence level. The authors theoretically prove that PI3NN can calculate PIs without retraining NNs and it completely avoids the crossing issue. Furthermore, the authors address OOD identification challenge by introducing an initialization scheme which provides reasonably larger PIs of the OOD samples than those of in-distribution samples."
SP:4b44a834e2212bacb4c2d9408a81f1efc76a670b,"This paper proposes a meta-learning method for online meta-training of deep neural networks. The proposed method is based on MAML, where the meta-parameters are updated in a fully online fashion. The main contribution of the paper is that the proposed method does not require any ground truth knowledge of task boundaries, and does not reset the online parameters back to the meta parameters between tasks. The method is evaluated on Rainbow-MNIST and CIFAR-100 datasets. "
SP:fbae35cb171b3a3eb7c5d4bc83881ed7c4a70aae,"This paper proposes a differentiable scaffolding tree (DST) to make a molecular graph locally differentiable, allowing a continuous gradient-based optimization. DST uses a graph neural network (GNN) to back-propagate the derivatives from the target properties through the graph. The experiments show that DST is effective and sample efficient. "
SP:61b59899cf6ae442d9f8f5226e79708a4280cfb2,"This paper proposes a personalized lab test result prediction approach that learns a strong patient representation incorporating both patient information accumulated over the visits as well as information from other similar patients. The authors augment the patient representation with the knowledge of drug-lab interactions, diagnosis-lab interaction, and use graph attention networks to model the positive and negative effects of drugs and diagnosis on the target lab result. Experiments on real-world datasets demonstrate the effectiveness of the proposed solution in reducing prediction errors by a significant margin."
SP:8623cebb515c4a736427449b46ad2cdf8b806b77,"This paper proposes a new open-set single domain generalization (OS-SDG) problem, where the target domain may contain unseen categories out of the source label space. The goal of the paper is to learn a model, with only one source domain, to classify a target sample with correct class if it belongs to the source domain or assign it to unknown classes. The authors propose a CrossMatch approach to improve the performance of SDG methods on identifying unknown classes by leveraging a multi-binary classifier. CrossMatch generates auxiliary samples out of source domain label space by using an adversarial data augmentation strategy. It also adopts a consistency regularization on generated auxiliary samples between multibinary classifiers and the model. Experimental results on benchmark datasets prove the effectiveness of CrossMatch."
SP:126f8ffb855aa22eda4d681a499953879ed3679e,"This paper studies policy optimization with Wasserstein and Sinkhorn trust regions. The main idea is to use the Lagrangian duality to represent the policy updates. The authors show that WPO and SPO can be viewed as extensions of TRPO and PPO. Theoretically, the authors prove that the convergence rate of WPO is monotonic and that SPO converges to WPO as the weight of the entropic regularizer diminishes. Experiments are conducted on a variety of tabular and robotic tasks. "
SP:999eacf6500c87205584a3256d7ca45b3016fb1c,"This paper proposes a forget-and-relearn framework for shaping the learning trajectories of artificial neural networks. In this process, the forgetting step selectively removes undesirable information from the model, and the relearning step reinforces features that are consistently useful under different conditions. This framework unifies many existing iterative training algorithms in the image classification and language emergence literature, and allows us to understand the success of these algorithms in terms of the disproportionate forgetting of undesirable information. The authors leverage this understanding to improve upon existing algorithms by designing more targeted forgetting operations."
SP:2789859517b6624730b14a7e010444a72d3dd3ed,". This paper investigates the offline-online setting, where the agent has access to a batch of data to train on but is also allowed to learn during the evaluation phase in an online manner. This is an extension to batch RL, allowing the agent to adapt to new situations without having to precommit to a policy. The experiments show that standard RL agents trained in an offline-Online manner can outperform agents trained only offline or online, highlighting the potential of this new setting."
SP:76625a25e770415599a34122110d61cb3b7e614c,"This paper proposes a meta-learning method for domain generalization (DG) based on minimizing the discrepancy between the source and target domains. The authors provide a PAC-style generalization bound for discrepancy-optimal meta learning and compare it with other DG bounds including ERM and domain-invariant learning. The paper also provides a bilevel optimization algorithm for DG. Empirically, the proposed method achieves state-of-the-art results on two DG benchmarks."
SP:6421a9759c766641fd8c128a249f1a9c5699d19c,"This paper studies the role of policy and value networks in best-first search on the Sokoban domain for solving hard planning problems. The authors show that the policy network is a powerful heuristic guiding the search, which can lead to left heavy tails with polynomial scaling by avoiding exploring exponentially sized sub-trees. They also show that random restart strategies can improve the effectiveness of DNN-based search."
SP:84c415bc0f120d1997289f91661ff74e7297d3bd,This paper proposes a method for meta-imitation learning from video demonstrations from humans. The method is based on a GAN-based method to translate human videos into practical robot demonstrations and train the meta-policy with adaptive loss based on the quality of the translated data. Experiments show that the proposed method achieves comparable performance to the baseline on fast learning a set of vision-based tasks through watching a single video demonstration.
SP:fedf5c75e83d6ab41ef9d5daa9054ffe4e424ec2," training large neural networks with gradient-based optimizers is a popular way to solve classification and ranking problems. Without appropriately tuned regularization, such networks have the tendency to make output scores (logits) and network weights large, causing training loss to become too small and the network to lose its adaptivity (ability to move around and escape regions of poor generalization) in the weight space. Adaptive optimizers like Adam, being aggressive at optimizing the train loss, are particularly affected by this. It is well known that, even with weight decay (WD) and normal hyper-parameter tuning, adaptive optimizers lag behind SGD a lot in terms of generalization performance, mainly in the image classification domain. It has been observed that small batch sizes yield better generalisation performance due to the noise of mini-batch gradients and the large learning rate. The noise diminishes with increasing batch sizes."
SP:819df8d847a99f13ed5efdcabae8b464c12b464b,"The paper proposes a method for learning group equivariant convolutional neural networks. The method is based on the idea that the equivariance of the network can be divided into two parts, i.e., partial and full. In the partial part, the network is able to keep full group equivariances, while in the full part, it is only able to maintain partial equivariances. The authors show that the proposed method outperforms the state-of-the-art G-CNNs on MNIST and CIFAR-10 datasets. "
SP:0c0ca9df96f1fa2eb8b83a47d0d5964590fef290,"This paper proposes an amortized Langevin dynamics (ALD) method for training deep latent variable models. ALD is an extension of the Langevin autoencoder (VAE) method, where the forward model is replaced by an inference model that maps observations into latent variables. The authors prove that ALD has the target posterior as a stationary distribution under some assumptions, and show that it converges to the target distribution faster than VAE. Then, the authors propose a new deep generative model (LAE) based on ALD, which uses ALD for posterior inference and sampling from the latent space EBM."
SP:5631097031c7e599bdeae64366ffa6e4558837c6,"This paper proposes a method for hypergraph reasoning based on sparse tensor representation and finite-domain quantification. The method is motivated by the observation that in logical reasoning, logical rules (e.g., my parent’s parent is my grandparent) usually apply locally and sparsely. To leverage the sparsity in hypergraph neural networks, SpaLoc represents the grounding of relationships such as parent and grandparent as sparse tensors and uses neural networks to infer new facts based on the input. The authors also introduce a sparsification loss to regularize the number of hyperedges in intermediate layers of a SpaLoc model. To enable training on large-scale graphs such as real-world knowledge graphs, the proposed method makes training and inference-time sub-sampling of the input graphs. To remedy the information loss in sampled sub-graphs, the authors propose a novel sampling and label calibration paradigm based on an information-theoretic measure information sufficiency."
SP:9657121b01c51f78c00d06b47d3e8d678dd85d54,"This paper proposes a new family of differentiable top-k cross-entropy classification loss based on differentiable sorting and ranking. The authors relax the assumption of a fixed k and propose to draw k from a probability distribution for training. They show that relaxing k does not only produce better top-5 accuracies, but also makes models more robust, which leads to top-1 accuracy improvements. They achieve new state-of-the-art results on ImageNet1K."
SP:cb3188f435c54a365890e20e4d582c250d919833,"This paper proposes a new method for solving large-scale optimal transport (OT) problems at an unprecedented combination of speed and accuracy. The method is built on the Douglas-Rachford splitting (DRF) technique, which allows to provide sparse transport plans and avoid numerical issues of methods that use entropic regularization. The algorithm has the same cost per iteration as the popular Sinkhorn method, and each iteration can be executed efficiently, in parallel. The proposed method enjoys an iteration complexity of $O(1/\epsilon^2)$ compared to the best-known $O(\sqrt{1/2})$ of the popular DRF method. The paper also provides a linear convergence rate for the formulation of the OT problem. "
SP:9a087cc734a3e7f3ab848bef5e2eff37fe40f303,"This paper proposes a framework for disentangling performance gaps in federated learning. Specifically, the authors propose to separate performance gaps from unseen client data (out-of-sample gap) from performance gap from unseen clients distributions (participation gap). The authors also propose a semantic synthesis strategy that enables realistic simulation without naturally-partitioned data. "
SP:da0e8c89f343abfe500eb4c1968e418c2fb52ef6,This paper studies the few-shot learning methods on pretrained language models from the BERT family in the zero-shot setting. They find that simply introducing a few prompt [MASK]s could significantly improve the performance and robustness of the null prompt method and even exceed cherry-piked manual prompts. They also propose a coarse-to-fine study to learn the influence of multiple components in our proposed method. 
SP:9817dccb1a121058b23a2ef825ed339cf8b53674,"This paper proposes a method to improve the performance of the attention mechanism by adding a sharpener to the attention module. Specifically, the sharpener is a feature extractor that maps the input image to a target image. The sharpener maps the target image to the region of the original image that is close to the center of the input. The authors show that this sharpener can improve the alignment and interpretability of attention. Experiments on synthetic handwritten digits as well as real-world scene text recognition datasets show the effectiveness of the proposed method. "
SP:3913ed3b3cf6494368e3be6cacb637ff85f80ee6,"This paper proposes a reinforcement learning-based approach to solve the vehicle routing problem (VRP) with a fixed number of vehicles. The approach is based on reinforcement learning, where the agent is given a tour plan and the goal is to find a route that minimizes the cost of each vehicle. The authors show that the approach is much faster and easier to train and achieves competitive results that incorporate the practical aspect of vehicle costs."
SP:594a813c0d0baa66738b9c8331370f861ad3c416,"This paper proposes a method to improve link prediction by causal inference, specifically, learning to answer counterfactual questions about link existence. Specifically, the authors propose a novel link prediction method, Counterfactual Graph Learning for Link Prediction (CFLP), that creates counterfactually links from the observed ones, and learns representations from both the observed and counter-factual links. Experiments on benchmark datasets show that the proposed method achieves state-of-the-art performance on link prediction. "
SP:48a7e50451b887f55be17b2662aa11ce18791cc1,"This paper proposes a two-stage Second-Order Unsupervised Feature Selection (SOFT) model that incorporates the second-order covariance matrix with the first-order data matrix for unsupervised feature selection. In the first stage, the authors learn a sparse attention matrix that can represent second order relations between features, and in the second stage, they build a relational graph based on the learned attention matrix and perform graph segmentation. Experiments on 12 public datasets show that SOFT outperforms classical and recent state-of-the-art methods."
SP:14bcae11aeede63f28d1b80c05ed18a01d3e3f3c,"This paper proposes a novel multi-modal variational autoencoder (MEME) that combines information between modalities implicitly through mutual supervision. This formulation naturally allows learning from partially-observed data where some modalities can be entirely missing, something that most existing approaches either cannot handle, or do so to a limited extent. The authors demonstrate that MEME outperforms baselines on standard metrics across both partial and complete observation schemes on the MNIST-SVHN (image-image) and CUB (image–text) datasets."
SP:e834a52cadebe5f125ce491273b4ad1146beae3f,"This paper proposes Deep Explore Options, a method to combine intrinsic and extrinsic rewards in the Dopamine framework to tackle complex visual problems. The authors propose a new multi-agent buffer-selection algorithm, showing that agents can benefit from observing data that is interesting accoding to others. They also propose to consider intrinsic reward learning as an auxiliary task, with a resulting architecture achieving 50% faster wall-clock speed and building a stronger, shared representation. They test the proposed method on hard and easy exploration games of the Atari Suite."
SP:41578dd1a4bdb043b3d68afa5f9cebb3e14f3907,This paper proposes a new method for learning Hamiltonian dynamical systems from data. The proposed method is based on a new metric SAI (stiffness-aware index) to classify the training data into stiff and non-stiff portions. This classification along with a resampling technique allows to apply different time integration strategies such as step size adaptation to better capture the dynamical characteristics of the Hamiltonian vector field. Experiments on complex physical systems including a three-body problem and a billiard model demonstrate the effectiveness of the proposed method.
SP:bfb0a059eeb6f40a18fbd20c0eec5037a64ca09e,"This paper studies the problem of learning to perform multi-step computations using scratchpads. In particular, the authors train a Transformer model to generate a scratchpad of intermediate steps of an arbitrary program, and then ask the model to output the results of these steps. The authors show that this approach improves the performance of the model on a variety of tasks, ranging from long addition to execution of arbitrary programs.   "
SP:e6c1a8b4bba287455dc9cf145b6bd1f04e2148a9,"This paper studies adversarial perturbations at the feature level of deep neural networks. The authors propose a method to generate adversarial examples that are interpretable, universal to any source image, and physically-realizable. These attacks can also reveal spurious, semantically-describable feature/class associations that can be exploited by novel combinations of natural objects. They also use them to guide the design of “copy/paste” adversaries in which one natural image is pasted into another to cause a targeted misclassification."
SP:873618263dc4246a39c44d0abfecfb5f688817e3,"This paper proposes a novel approach to simulated annealing based on reinforcement learning. In particular, the authors propose to use a reinforcement learning approach to learn the proposal distribution for each step of the SA algorithm. The authors show that the proposed method outperforms baselines with hand-selected parameters on Rosenbrock’s function, the Knapsack problem, the Bin Packing problem, and the Travelling Salesperson problem. "
SP:cae31f7436920eb3946e3f5bca0ac88a73d7c3ec,"This paper studies the problem of policy non-stationarity in multi-agent reinforcement learning. The authors propose a novel notion, the $\delta_stationarity$ measure, to explicitly measure the non-stability of a policy sequence, which can be further proved to be bounded by the KL-divergence of consecutive joint policies. A straightforward but highly non-trivial way is to control the joint policies’ divergence, which is difficult to estimate accurately by imposing the trust-region constraint on the joint policy. Although it has lower computational complexity to decompose joint policy, simple policy factorization like mean-field approximation will lead to more considerable policy divergence. To solve the trust region decomposition dilemma, the authors propose an efficient and robust algorithm MAMT combining message passing and mirror descent with the purpose to satisfy the \delta_{stationarity}. Experiments show that the proposed method can bring noticeable and stable performance improvement compared with baselines in cooperative tasks of different complexity."
SP:989b58167a15ae4fafbe27ff534d327991b6c4d7,"This paper proposes a self-supervised representation learning framework for audio-visual speech. The key idea is to use multi-stream video input and predict automatically discovered and iteratively refined multimodal hidden units. Experiments on visual speech recognition show that the contextualized representations learned by AV-HuBERT show excellent transferability to the lipreading task, where only the visual modality is available. "
SP:7c9eb8aa4a4dcb5965157d860e812d81654e3aa7," of state-of-the-art RL algorithms for combinatorial optimization on graphs. This paper proposes a novel RL algorithm called ECORD, which uses a recurrent unit to guide the exploration phase of the RL algorithm. The authors show that ECORD achieves a new SOTA for RL algorithms on the Maximum Cut problem. ECORD reduces the optimality gap by up to 73% on 500 vertices."
SP:f741d980c9c560a21298e947f1605dcbab7ceeac,"This paper studies the problem of training VAEs with discrete latent variables. The authors propose a variational autoencoder (VAE) model with discrete latents, where the latent variables are sampled from a discrete distribution, and the encoder and decoder networks are trained using a discrete optimization approach. The approach is based on evolutionary algorithms, and is shown to be more efficient than amortized VAE training. In addition, the authors show that the proposed approach is competitive in zero-shot denoising."
SP:deb189d37bd51b92762ce259a106d9a9e9d81ea4,"This paper proposes Controlled Effect Network (CEN), an unsupervised method based on counterfactual measures of blame to identify effects on the environment controlled by the agent. CEN is composed of a two-branch forward model that creates a normal and controlled view of the world. The experiments show that CEN can disentangle effects precisely, outperforming state-of-the-art approaches to detect controlled effects. Moreover, it is evaluated as an intrinsic motivator by integrating CEN into the state of the art exploration method."
SP:ea18d57904e25fd09ed0f6c9972029d78779a8a6,"This paper proposes a new method for reducing the computational cost of SR networks. The proposed method is based on structure-regularized pruning (SRP), which imposes regularization on the pruned structure to make sure the locations of pruned filters are aligned across different layers. Specifically, for the layers connected by the same residual, the authors select the filters of the same indices as unimportant filters. Then, they employ L2 regularization to drive the weights towards zero so that eventually their absence will cause minimal performance degradation. The authors apply SRP to train efficient image SR networks resulting in a lightweight network SRPN-L and a very deep one SRPN."
SP:0dee45001ae9600f485614dfe6874a516ac01db5,"This paper proposes a novel method for few-shot learning based on contrastive learning and feature selection. The main idea is to train a feature extracting backbone with the contrastive loss on the base category data. Then, a masking module is trained to select relevant features that are more suited to target domain classification. Finally, a classifier is fine-tuned along with the backbone such that the backbone produces features similar to the relevant ones. The proposed method is evaluated on a recently introduced cross-domain few shot learning benchmark. "
SP:92aa611d71a8da597358330d84fddbb90de2cf4f,"This paper studies the generalization performance of neural networks trained with gradient descent. The authors show that gradient descent can improve generalization by selecting networks with a large margin. In particular, they show that the average test error of the neural network-Gaussian process (NNGP) posterior is better than chance, corroborating the findings of Valle-Pérez et al. (2019). They also show that test performance can be substantially improved by selecting a function with much larger margin than is typical under the NNGP posterior. "
SP:a0e3cf719a95bbc5aad2f663ba5a3169c316ee9b,"This paper proposes a manifold mixup method to improve the performance of cross-lingual transfer methods. The authors claim that the performance gap between source and target languages is strongly associated with the representation discrepancy. The proposed method, X-Mixup, adaptively calibrates the discrepancy and gives compromised representations for target languages. Empirical evaluations on the XTREME benchmark show the effectiveness of the proposed method."
SP:19f8cd8f0c274b6141ba097d2ebb6d18af0986fd,"This paper studies the problem of Byzantine robust optimization in the non-iid federated learning setting, where a fraction of the workers may deviate from the prescribed algorithm and send arbitrary updates to the server. The authors propose a simple bucketing scheme that adapts existing robust algorithms to heterogeneous datasets at a negligible computational cost. They also theoretically and experimentally validate their approach, showing that it is effective against challenging attacks."
SP:4d63513b9a1b9b9fc44a69b3d5679a8f48eb95e7,"This paper studies the relationship between disentanglement and multi-task learning based on hard parameter sharing. The authors show that disentangled representations appear naturally during the process of multi- task neural network training. They verify their hypotheses by training multiple models in single- and multi task settings and investigating the level of disentangling achieved in their latent representations. In their experiments, they find that in a hard-parameter sharing scenario multi-Task learning indeed seems to encourage disentangler. However, it is inconclusive whether disentangle representations have a clear positive impact on the models performance. "
SP:9851adb72e2918780f661f83f7da06eb866787be,"This paper proposes a framework of certified robust policies (CROP) for reinforcement learning against adversarial state perturbations, which provides state-level robustness certification and the first certification for cumulative rewards. The authors propose a local smoothing algorithm that uses a policy derived from Q-functions smoothed with Gaussian noise over each encountered state to guarantee the robustness of actions taken along this trajectory. A global smoothing method is also proposed for certifying the robust behavior of a finite-horizon cumulative reward under adversarial attacks. "
SP:78da3c97182ec1baf6a131740bf7c91a9afb2fd2,"This paper proposes a new approach to conformal prediction. Conformal prediction provides the ability to adapt to model uncertainty by constructing a calibrated candidate set in place of a single prediction, with guarantees that the set contains the correct answer with high probability. This paper proposes to trade coverage for precision by enforcing that the presence of incorrect candidates in the predicted conformal sets (i.e., the total number of false positives) is bounded according to a user-specified tolerance. Subject to this constraint, the proposed algorithm then optimizes for a generalized notion of set coverage that allows for any number of true answers for a given query (including zero). Empirical results demonstrate the effectiveness of this approach across a number of classification tasks in natural language processing, computer vision, and computational chemistry."
SP:b126d2f3c397633745c8833e22ace93a2470e963,"This paper studies the effect of initialization on the length and volume distortion of ReLU networks with random initialization. The authors show that the expected length distortion does not grow with depth, and indeed shrinks slightly. They also generalize this result by proving upper bounds for higher moments of the distortion and for the distortion of higher dimensional volumes. These theoretical results are corroborated by empirical results."
SP:b3b6d0512edfca461ea295ee8665f7f226c45d57,"This paper proposes SAFEty skill pRiors (SAFER), a behavioral prior learning algorithm that accelerates policy learning on complex control tasks, under safety constraints. Through principled contrastive training on safe and unsafe data, SAFER learns to extract a safety variable from offline data that encodes safety requirements, as well as the safe primitive skills over abstract actions in different scenarios. The inference stage composes a safe and successful policy according to the inferred safety variable and abstract action. Experiments on several complex safety-critical robotic grasping tasks inspired by the game Operation show that SAFER outperforms baseline methods in learning successful policies."
SP:a5dadb3ecc3caed3b9d9a68eda0d48a53c2d1ce2,"This paper proposes a multi-branch neural network architecture for image restoration. The architecture is inspired by the Retinal Ganglion Cells (RGCs) and is able to tackle multiple degradation types, including blur, haze, and rain. The authors also propose a novel loss function for general restoration tasks and an MSC to replace the traditional skip connection. Experiments show that the proposed architecture can achieve competitive performance results on four datasets."
SP:263b386beee44b0b45b6f6dc3cf80d020500be62,"This paper proposes a new federated learning method, Inference-Time Federated Learning (IT-PFL), which learns a personalized model to be applied to novel clients at inference time. The proposed method is based on learning an encoder network that learns a representation for a client given its unlabeled data. The client representation is fed to a hypernetwork that generates the personalized model for that client. The authors also analyze and bound the generalization error for the novel client."
SP:960d0a63a82593f6e72275b65f0501f0469d1924,"This paper uses a conditional diffusion based generative model (RCDM) to visualize representations learned with self-supervised learning. The authors demonstrate how this model’s generation quality is on par with state-of-the-art generative models while being faithful to the representation used as conditioning. By using this new tool, the authors can show visually that SSL (backbone) representation are not really invariant to many data augmentation they were trained on, SSL projector embedding appear too invariant for tasks like classification, SSL representations are more robust to small adversarial perturbation of their inputs, and there is an inherent structure learned with SSL model that can be used for image manipulation."
SP:398899e6c86b4a2a17dfa5c2f4478811f4331c1d,"This paper studies the problem of frequency moments estimation with differential privacy. The authors prove that Fp sketch, a well-celebrated streaming algorithm, is differentially private as is when p \in (0,1]. The paper also proposes a new sensitivity definition called pure multiplicative sensitivity. The paper shows that the space complexity is exponentially better than existing DP baselines and only worse than the optimal non-private baseline by a logarithmic factor."
SP:3253b13851b5a3b5e3c8c6e24891db05903a4e57,"This paper proposes a novel policy optimization method for learning policies that are both locally optimal and sufficiently different from existing policies. The key idea is to switch between extrinsic and intrinsic rewards via a trajectory-based novelty measurement during the optimization process. When a sampled trajectory is sufficiently distinct, RSPO performs standard policy optimization with intrinsic rewards. For trajectories with high likelihood under existing policies, the proposed method utilizes an intrinsic diversity reward to promote exploration. Experiments show that the proposed algorithm is able to discover a wide spectrum of strategies in a variety of environments. "
SP:e3ab3aa87ab023bd9949b99a17d4b6e26c1473c0,"This paper proposes a differentiable diffusion model sampler search method that can be applied to any pre-trained diffusion model by differentiating through sample quality scores. The authors propose Generalized Gaussian Diffusion Models (GGDM), a family of flexible non-Markovian samplers for diffusion models. They show how to optimize a perceptual loss over a space of diffusion processes by leveraging the reparametrization trick and gradient rematerialization. The experimental results demonstrate the effectiveness of the proposed method."
SP:7a7506f2b5500a573c0cfb8b0822e5ea725c886a,"This paper proposes P-Adapters, a lightweight model that takes LLM embeddings as input and output continuous prompts that are used to query the large language model (LLM). The authors claim that the quality of the factual information extracted from LLMs depends on the prompts used by different users. The proposed method is based on the observation that different users will query LLMs for the same information using different wording, but should receive the same, accurate responses regardless. The authors propose a P-Adapter model that sits between the embedding layer and the first attention layer of the LLM. They also investigate Mixture of Experts (MoE) models that learn a set of continuous prompts (“experts”) and select one to query LLM, which require a separate classifier trained on human-annotated data."
SP:35cdf71f027cc5168b55cc34c64bfb2f3087d6f5,"This paper proposes a continuous classification of time series (CCTS) method, which is based on a multi-distribution model. The key idea is to model multiple distributions simultaneously. This is different from the existing one-shot classification methods, which are hard to achieve due to their independent identically distributed premise. Two main problems are the catastrophic forgetting and the overfitting. To overcome these problems, the authors propose a novel Adaptive model training policy ACCTS, which extracts data distributions adaptive to the time series evolution and the model change. Experiments on four real-world datasets show that ACCTS can classify more accurately than all baselines."
SP:d9b74b749aa465496763d3a3a9bf3a53e800587e,"This paper proposes a kNN-augmented attention mechanism to improve the memorization capacity of language models. The idea is to use k-nearest-neighbor attention (KNN) to retrieve the k nearest neighbors of a given input document and store them in an external memory. The paper shows that the kNN memory size increases with the size of the external memory up to 131k tokens. Experiments are conducted on a variety of language modeling tasks, including generic webtext (C4), math papers (arXiv), books (PG-19), code (Github), and formal proofs (Isabelle)."
SP:7a1bbf86c3fdb8738aa826ca330493e857d050ba,This paper proposes a sampling scheme based on the Metropolis-hastings Monte Carlo algorithm to sample from the energy-based sequence models. The authors interpret MLMs as energy based sequence models and propose two energy parametrizations derivable from the trained MLMs. They validate the effectiveness of the proposed parameter by exploring the quality of samples drawn from these energy based models for both open-ended unconditional generation and a conditional generation task of machine translation. 
SP:011626ba4fafee13d4a30e3f13c1df5b7071a7f1,"This paper proposes a novel augmentation policy learning method for NLP tasks. The main idea is to learn a policy to construct difficult but not too different augmented samples for providing informative training signals, while avoiding the risk of losing the semantics of original samples. The authors propose a novel reward function for updating the augmentation policies to construct the augmented samples with low confidence but a high semantic similarity with original ones. In addition, they introduce a sample re-weighting scheme to focus on difficult augmented samples after the original ones are learned confidently for more effective learning from the augmented ones. Experiments are conducted on text classification tasks and GLUE benchmark. "
SP:69d41a862ea189f72d4e8af2854e27b95a91fa41,"This paper proposes a method to improve upon FOCAL by incorporating intra-task attention mechanism and inter-task contrastive learning objectives. Specifically, for each task, a batch-wise gated attention is applied to recalibrate the weights of transition samples, and a sequence-wise self-attention is used to better capture the correlation within the transition (state, action, reward) dimensions. In addition, a matrix-form objective of the Momentum Contrast (MoCo) is proposed for task-level representation learning, by replacing its dictionary queue with a meta-batch sampled on the fly. Theoretical analysis and experiments are presented to demonstrate the superior performance and robustness of the proposed method."
SP:ed86c60850d5c8302dcf1c2167db303e778fe681,"This paper proposes a method to improve the performance of a belief state model in a partially observable Markov system. The method is based on a sequential generative modeling approach, where the model is fine-tuned at each time step. The authors show that this approach can improve the accuracy of the model at test time. In addition, the method does not require the model to process the action or policy as input at inference time. Experiments are conducted on the Hanabi game."
SP:6150725599c10f0e26f0d7cb1fc04b5b227a4456,"This paper proposes Pixelated Butterfly, a new method for sparse training of neural networks. The method is based on a simple fixed sparsity pattern based on flat block butterfly and low-rank matrices to sparsify most network layers (e.g., attention, MLP). The paper empirically shows that the proposed method can speed up the training of models (Transformers, ViT, MLPMixer) without quality drop compared to baselines on a wide range of domains and tasks. "
SP:136e31054a55abca840f6478491972023c2296cb,"This paper proposes a conditional diffusion probabilistic model (DDPM) that explicitly models the class center in the forward and reverse process of the Markov chain. The proposed method is inspired by the class clustering phenomenon and makes an elegant modification to the original DDPM formulation, which enables controllable generation and gets interpretability. Extensive experiments are conducted to verify the effectiveness of the formulated framework. "
SP:fc2196f1f4ecd864398fed6640ff3f8b19870763,"This paper studies the problem of domain generalization (DG). The authors propose a novel method, LASSO, that explores diverse latent sub-spaces and learns individual hypotheses on those sub-space. The latent subspaces are formed by the label-informative features captured in source domains, which allows us to project source and target examples onto appropriate sub-subspaces. Experiments on several well-known DG benchmarks demonstrate the effectiveness of the proposed method. "
SP:6e8e5bdeb77e3cafe1975da8411fb65118955d14,"This paper studies the kernel thinning (KT) algorithm of Dwivedi and Mackey (2021) which compresses a probability distribution more effectively than independent sampling by targeting a reproducing kernel Hilbert space (RKHS) and leveraging a less smooth squareroot kernel. The authors show that KT applied directly to the target RKHS yields tighter, dimension-free guarantees for any kernel, any distribution, and any fixed function in the RkHS. They also show that, for analytic kernels like Gaussian, inverse multiquadric, and sinc, target KT admits maximum mean discrepancy (MMD) guarantees comparable to or better than those of square-root KT without making explicit use of a square root kernel. Finally, they prove that KT with a fractional power kernel yields better-than-Monte-Carlo MMD guarantees for non-smooth kernels, like Laplace and Matérn."
SP:645c3f1864aa843d4899fc2406f694b5aab8460d,"This paper presents an open-source benchmark suite for the MAXIMUM INDEPENDENT SET problem, in both its weighted and unweighted variants. The suite offers a unified interface to various state-of-the-art traditional and machine learning-based solvers. The authors also conduct an in-depth analysis of the popular guided tree search algorithm by Li et al. [NeurIPS 2018], testing various configurations on small and large synthetic and real-world graphs. They show that the graph convolution network used in the tree search does not learn a meaningful representation of the solution structure, and can in fact be replaced by random values."
SP:155ecd17d264a084b014abdfd0362146d8fb07e0,"This paper proposes Wavelet Compressed Convolution (WCC) to reduce the memory bandwidth and computational cost of image-to-image CNNs. WCC is based on the Haar-wavelet transform and can be used with any 1x1 convolution in an existing network architecture. By combining WCC with light quantization, WCC achieves compression rates equal to 2-bit and 1-bit with minimal degradation in image to image tasks. The experimental results show that using WCC dramatically improves the results over aggressive quantization for the same compression rates while retaining the baseline network architecture while reducing the computational cost."
SP:004865e6affad32403b7965493a53c8a7ffdda0a,This paper studies the problem of finding correlated equilibrium in extensive-form games. The authors propose a new algorithm for learning dynamics for correlated and coarse correlated equilibria. The algorithm is based on the no-regret learning dynamics and is shown to converge to an approximate correlated equilibrium (EFCE) at a rate of $O(T^{3/4}$ times faster than the best prior rate of $\mathcal{O}(T 1/2)$. The authors show that the stability of fixed points associated with trigger deviation functions is characterized by a refined perturbation analysis.
SP:ee545ff83df4d7ff256ac61fbe0eb0765f52f1d5,"This paper proposes a method to learn a discretization of continuous action spaces by leveraging the priors of demonstrations. By discretizing the action space we can apply any discrete action deep RL algorithm to the continuous control problem. The proposed method is evaluated on three different setups: RL with demonstrations, RL with play data –demonstrations of a human playing in an environment but not solving any specific task– and Imitation Learning."
SP:4b39279b98d6aa311bb49dd1384925f9d6f66c2d,"This paper proposes an adversarial style augmentation (AdvStyle) method for domain generalization (DG) in semantic segmentation. Specifically, AdvStyle dynamically generates hard stylized images by learning adversarial image-level style feature, which can encourage the model learning with more diverse samples. With AdvStyle, the model can refrain from the problem of overfitting on the source domain and thus can be more robust to style variations of unseen domains. Experiments on two synthetic-to-real settings show that AdvStyle can improve the generalization performance and achieve state-of-the-art performance."
SP:4a2e6d70b383e4941e0bc44e7e82972b22e26792,"This paper proposes a novel method for mid-air gesture recognition. The method consists of an event-based guided variational autoencoder (Guided-VAE) and an encoder model that learns to represent extremely sparse, high-dimensional visual data captured at the sensor in a small number of latent dimensions. The encoder is jointly trained by two classifiers such that the latent space disentangles and accurately represents target features. Experiments show that the proposed method achieves 87% classification accuracy on the DVSGesture dataset."
SP:2e66468a6b94177e54b0052b97713ee63902c278,"This paper proposes a Sparse Hierarchical Table Ensemble (S-HTE) for sparse deep learning for tabular data. The main idea is to use ferns (oblivious decision trees) instead of neurons for inference. The inference is dense at the beginning of the training process and becomes sparse using an annealing mechanism, leading to an efficient final predictor. The experimental results show its accuracy is comparable to alternatives, while having an order of magnitude lower computational complexity."
SP:b238db9252d83a13438bb747d70e635bb9945958,"This paper proposes Latent Action Q-learning (LAQ), an offline RL method that learns effective value functions from state-only experience. LAQ learns value functions using Q-Learning on discrete latent actions obtained through a latent-variable future prediction model. The authors show that LAQ can recover value functions that have high correlation with value functions learned using ground truth actions. The proposed method is evaluated in 5 environments ranging from 2D grid world to 3D visual navigation. "
SP:108ebe9045a9e2b8b5aba8352733782462db8a81,"This paper proposes SWARM parallelism, a model parallelism method for training large neural networks in a distributed setting. The main idea is to use preemptible preemptible GPU instances (preemptible GPUs) to train a large neural network on low-power preemptible GPUs with low network bandwidth. The authors show that the proposed method is effective at re-balancing the number of preemptible nodes in the parallel training process. They also propose compression-aware techniques to further reduce the network usage of their approach."
SP:91d2f094d5481651b554f58aecc2a6207057a47c,"This paper proposes a method for bridging offline training and online tuning in decentralized multi-agent reinforcement learning (D4RL). The authors claim that the transition dynamics in offline experiences do not accord with the dynamics in online execution, which creates severe errors in value estimates, leading to uncoordinated and suboptimal policies. To remedy this issue, the authors introduce online transition correction (OTC) to implicitly correct the biased transition dynamics by modifying sampling probabilities. OTC consists of two types of distances, i.e., embedding-based and value-based distance, to measure the similarity between transitions, and an adaptive rank-based prioritization to sample transitions according to the transition similarity. Experimental results show that OTC outperforms baselines in a variety of tasks."
SP:d0e650d568214481b07a0452ec606ccbf6d05410,"This paper proposes a logarithmic unbiased quantization (LUQ) method to quantize both the forward and backward phase of neural networks to 4-bit. The main contribution of this paper is to analyze the difference between two rounding schemes: round-to-nearest and stochastic-rounding. The paper shows that the former has lower MSE and works better for the quantization of the forward phase (weights and activations), while the latter is an unbiased approximation of the original data and works well for the backward phase (specifically, the neural gradients). Based on these conclusions, the authors propose a quantization method that quantizes the forward part of the network to FP4 format. The proposed method achieves state-of-the-art results in 4- bit training."
SP:f2862d1f987164ed6c3c375cd8962e57c369373b,"This paper studies the problem of few-shot meta-learning with polythetic classifiers. The authors propose a self-attention feature-selection mechanism that dilutes non-discriminative features in the meta-classifier. They show that threshold classifiers require an embedding space that is exponential in the number of active features and that attentional classifiers are overly sensitive and susceptible to misclassification. To address this issue, they propose an attention based method for feature selection and demonstrate the effectiveness of their approach in several synthetic and real-world few shot learning problems. "
SP:e1e513fef25d29e17cdadd1b36d932a8ad8897cd,"This paper studies the question of whether and how language emerges when using RL to train agents that communicate via continuous acoustic signals. The authors propose an environment and training methodology to carry out an initial exploration of these questions. They use a simple messaging environment where a speaker agent needs to convey a concept to a listener agent. The speaker is equipped with a vocoder that maps symbols to a continuous waveform, this is passed over a lossy continuous channel, and the listener needs to map the continuous signal to the concept. Using deep Q-learning, they show that basic compositionality emerges in the learned language representations. They find that noise is essential in the communication channel when conveying unseen concept combinations."
SP:0e6ff65ba4a3df35947d1b6f4d438612088d90a0,"This paper proposes a backdoor attack on pre-trained NLP models. The authors propose a two-stage attack, where the first stage reconstructs the pre-training data by poisoning public corpus and fine-tune a clean foundation model with the poisoned data, and the second stage injects triggers to the input text and attacks the target model. Experiments show that the proposed attack can achieve performance drop for up to 100%."
SP:58d3ecb4a1906251e79ad883aa97cc2502642658,"This paper proposes a method for skill discovery that learns skills in an incremental fashion, where skills are learned one after another in an iterative fashion. This framework allows newly learned skills to adapt to new environment or agent dynamics, while the fixed old skills ensure the agent doesn’t forget a learned skill. Experiments are conducted in both dynamic and static environments to demonstrate the effectiveness of the method."
SP:2c6595408f5ec95537eaf555e5fe3d992b58c222,"This paper proposes a new convolutional layer, called log-polar space convolution (LPSC), where the convolution kernel is elliptical and adaptively divides its local receptive field into different regions according to the relative directions and logarithmic distances. The proposed LPSC not only naturally encodes local spatial structures, but also greatly increases the single-layer receptive field while maintaining the number of parameters. Experiments on different tasks and datasets demonstrate the effectiveness of the proposed layer."
SP:7791f96b1eef277a9133975507a750d9e7c6b8ff,"This paper proposes PAC-Bayesian Information Bottleneck (PAC-Bayes IB), a new information bottleneck on the trade-off between accuracy and information complexity of neural networks (NNs), which is based on the compression of information stored in weights (IIW). The authors provide an algorithm for the efficient approximation of IIW, and propose an MCMC-based algorithm to sample from the optimal weight posterior characterized by PIB. Experiments are conducted to demonstrate the effectiveness of the proposed method."
SP:a733847ade77ffbf38760fc79da17893dea8d53f,This paper investigates why indiscriminate data poisoning attacks work in principle. The authors find that the perturbations of advanced attacks are almost linear separable when assigned with the target labels of the corresponding samples. They further confirm that linear separability is indeed the workhorse for recent attacks. The paper also shows that pre-trained feature extractors can be a powerful defense.
SP:7b50be406138ad01db3ee112899f622637896fe9,"This paper proposes a method for offline policy optimization. The main idea is to use importance weighted return (IS) as an estimator for policy evaluation. However, the paper points out that the IS estimator is prone to overfitting. To address this issue, the authors propose Policy Optimization with Eligible Actions (POELA) algorithm, which constrains the potential action set to the set of observed actions with similar states to prevent improper avoidance to lower-reward initial states. The authors provide a theoretical justification of the proposed algorithm through a better per-state-neighborhood normalization condition and show the limitation of previous attempts to this approach through an illustrative example. The experiments show the proposed method with less overfitting and better test performance compared with state-of-the-art batch reinforcement learning algorithms."
SP:c976752a55b9ff47dc63c95a9fd7b51a81e8a42e,"This paper presents a method for continual learning of how language is grounded in vision. The method is based on a pre-trained multimodal embedding model, where language and images are projected in the same semantic space (in this case CLIP by OpenAI), CoLLIE learns a transformation function that adjusts the language embeddings when needed to accommodate new language use. Unlike traditional few-shot learning, the model does not just learn new classes and labels, but can also generalize to similar language use, and can efficiently learn and generalize from only a few examples with little interference with the model’s original zero-shot performance."
SP:d3371b322acfc321ee79a2e1b438d82644872fa4,This paper proposes a novel object captioning (NOC) method based on visual-linguistic reinforcement learning (VLAF2) to improve the quality of novel object captions. VLAF2 is motivated by the observation that BERT and CLIP are good models for NOC. The proposed method is evaluated on the nocaps dataset and shows promising results. 
SP:9f3b6486662d80350d77a4b060d4a5b8b22a6130,"This paper studies the problem of transfer learning in few-shot learning. In particular, this paper focuses on the phenomenon of neural collapse, i.e., the phenomenon that features learned by overparameterized classification networks show an interesting clustering property, called neural collapse. The authors show that neural collapse generalizes to new samples from the training classes, and more importantly, to new classes as well, allowing foundation models to provide feature maps that work well in transfer learning and, specifically, in the few shot setting. "
SP:624c95d9ce1ee4b66274e858e2da22bef6b052c7,"This paper proposes a novel method for point cloud reconstruction. The method consists of two stages: 1) a sparse stacked-hourglass network as for the initial densification and denoising, 2) a refinement via transformers converting the discrete voxels into 3D points. In particular, a module called amplified positional encoding is proposed to amplify the magnitude of positional encoding vectors based on the points’ distances for adaptive refinements. Extensive experiments demonstrate that the network achieves state-of-the-art performance among the recent studies in the ScanNet, ICL-NUIM, and ShapeNetPart datasets."
SP:34a81ca65131576d4c14332a4e9eb3a4c344cab7,"This paper proposes a new method for efficient distributed GCN training, called PipeGCN, to reduce the communication overhead of communicating node features and feature gradients among partitions for every GCN layer in each training iteration. The proposed method is based on pipelining inter-partition communication with intra-partitions computation. The paper also provides a theoretical convergence guarantee and shows that the convergence rate is close to that of the vanilla distributed GNN training without staleness. Extensive experiments show the effectiveness of the proposed method."
SP:8302d49558ee0f16392d623d4e604e92db10d041,"This paper studies the problem of test time robustification, i.e., using the test input to improve model robustness. The authors propose a simple approach that can be used in any test setting where the model is probabilistic and adaptable: when presented with a test example, perform different data augmentations on the data point, and then adapt (all of) the model parameters by minimizing the entropy of the model’s average, or marginal, output distribution across the augmentations. This objective encourages the model to make the same prediction across different augmentations, thus enforcing the invariances encoded in these augmentations and maintaining confidence in its predictions. Experiments show that this approach achieves accuracy gains of 1-8% over standard model evaluation and also generally outperforms prior adaptation and adaptation strategies."
SP:a985de5e940ff3a4160b378201b8c02f68d1914a,"This paper proposes a model-based reinforcement learning algorithm that jointly optimizes a lower bound on the expected return of the policy and the dynamics model. The main contribution of this paper is the formulation of a new objective function that is a global lower-bound on the standard expected return objective. The authors show that this new objective is tight under certain assumptions. The proposed algorithm is similar to a GAN, where a classifier distinguishes between real and fake transitions, the model is updated to produce transitions that look realistic, and the policy updates to avoid states where the model predictions are unrealistic. Experiments show that the proposed algorithm outperforms prior methods based on maximum likelihood estimation."
SP:a469fbcdc20b11dff4085b6fbc384e77f33cd37d,"This paper proposes an imitation learning method that combines behavioral cloning (BC) and behavioral cloning from observation history (BC-OH) to avoid the ""copycat problem"". The main idea is to combine the advantages of BC-SO and BC-OH by first computing a coarse action based on the instantaneous observation, and then refine it into a final action using historical information. The proposed method is evaluated on CARLA autonomous driving from images and various MuJoCo continuous control tasks."
SP:95c4533b5d1a865c4cc6a54615e7ad6357bdaad1,"This paper proposes a model-based meta-learning method called DyAd to forecast physical dynamics. DyAd has two parts: an encoder which infers the time-invariant hidden features of the task with weak supervision, and a forecaster which learns the shared dynamics of the entire domain. The encoder adapts and controls the forecaster during inference using adaptive instance normalization and adaptive padding. Theoretically, the authors prove that the generalization error of such procedure is related to the task relatedness in the source domain, as well as the domain differences between source and target. Experiments are conducted on turbulent flow prediction and real-world ocean temperature and currents forecasting tasks."
SP:ec70553cb0c27e5349c1b8cce6bcaa96a83bf050,"This paper proposes a novel method for weakly supervised monocular 3D object detection. The proposed method is based on 2D boxes on the image, which are generated from RoI LiDAR points. Then, a network is trained to predict 3D boxes which can be aligned with the corresponding RoI points. Experiments are conducted on the KITTI benchmark to validate the effectiveness of the method."
SP:34217c6a8ca43b8eeb9ddc83d6f1f0af05918984,"This paper proposes a soft gradient-based subword tokenization module (GBST) that automatically learns latent subword representations from characters in a data-driven fashion. GBST enumerates candidate subword blocks and learns to score them in a position-wise fashion using a block scoring network. The authors also introduce a deep Transformer model that integrates GBST and operates on the byte level. Experiments on English GLUE, multilingual, and noisy text datasets show that the proposed model outperforms a series of competitive byte-level baselines while generally performing on par and sometimes outperforming subword-based models."
SP:d26d25f2ef23a89a2c139d0dd87c4c86fddcff5e,"This paper proposes an adversarial extreme value analysis (AEVA) algorithm to detect backdoors in black-box hard-label backdoor detection. AEVA is based on the observation that a singularity is often observed in the adversarial map of a backdoorinfected example, which the authors refer to as the ""adversarial singularity phenomenon"". This observation is motivated by the fact that adversarial maps with high singularity are more likely to be generated by backdoor-infected examples. The authors show that AEVA can be applied to detect backdoor attacks under the hard-labelled backdoor attack scenario. "
SP:c6dbca0ed0799b7fec21777606f6f809eb2d8c48,"This paper proposes a new uncertainty measure, called Kullback-leibler divergence (KLoS), which is a class-wise divergence between the Dirichlet distribution of the model's predicted Dirichlets and a specific class-specific Dirichlett distribution. The authors claim that KLoS captures both class confusion and lack of evidence in a single score, which is more robust to out-of-distribution (OOD) samples. In addition, the authors propose an auxiliary neural network to learn a refined criterion directly aligned with the evidential training objective. Experiments are conducted on MNIST, CIFAR-10, SVHN, and Imagenet."
SP:8b4f3916dca4e627931558e14836749bd4a6792f,"This paper studies a semi-supervised learning algorithm that learns a linear classifier over features obtained from unlabeled data. The authors assume that the distribution of important patches in the input images has a low-dimensional structure (e.g., when the patches are sampled from a low dimensional manifold). Under this assumption, the authors analyze a two-step algorithm that first constructs a representation based on an unlabelled set of examples, and then learns a classifier based on the produced representation. They show that their algorithm has run-time and sample complexity that depend on the covering number of the space of patches, and therefore the algorithm is efficient when the patch space has low dimensional structure. They complement this result with a lower bound, showing that the dependence of the algorithm on the dimension of the patch distribution is essentially optimal."
SP:7f2f354d5cc1030bd97bd716aea8fe1d3af86b25,"This paper proposes a novel graph convolutional neural network (GCN) based face clustering algorithm, Ada-NETS. The key idea of the algorithm is to reduce the number of noise edges in the graph by first transforming the features into a structure space, and then using an adaptive neighbour discovery strategy to determine a proper number of edges connecting to each face image. Experiments show that the proposed algorithm outperforms existing state-of-the-art methods on multiple public clustering datasets."
SP:a3bc8e26f55e78f07de081ca85865afd52b6ae4a,"This paper proposes a new method for Generalizable Person Re-Identification (DG ReID) based on distributionally robust optimization (DRO). The authors argue that the convex condition of KL DRO may not hold for overparameterized neural networks and applying KL DRo fails to generalize under distribution shifts in real scenarios. Instead, the authors propose a simple yet efficient approach, Unit DRO, which minimizes the loss over a reweighted dataset where important samples (i.e., samples on which models perform poorly) will be upweighted and others will be downweighted. Empirical results show that the proposed method achieves superior performance on large-scale DG ReID and cross-domain ReID benchmarks compared to standard baselines."
SP:62c1f734b7f6c6e7d5114da6f37c9e3cdda73a23,"This paper proposes a novel regularization technique for GNNs to improve the oversmoothing problem. The proposed method is based on corrupting the input graph with noise, and adding a noise correcting node-level loss. Experiments are conducted on 3D molecular property prediction tasks, and some generic GNN benchmark datasets."
SP:24a1b44f37f8eedbab2047fb84600a322d289f3b,"This paper proposes a differentiable EM model for the set2vec problem. The model is built from the perspective of fitting a Gaussian mixture model to the set data, which offers more flexibility and prior-induced model regularization in a principled Bayesian manner. The proposed model is also shown to generalize the recent set embedding models based on optimal transport and attention, leading to a computationally efficient model with superb performance on tasks in bioinformatics and NLP."
SP:b4f7b660b84fe7702fbcc8a96c192abc3a64f045,"This paper proposes a contrastive feature selection method for unsupervised feature selection in the contrastive analysis (CA) setting. The main idea is to select a small number of informative features for use in unknown downstream tasks. The proposed method, called CFS (Contrastive Feature Selection), is evaluated on a semi-synthetic dataset and four real-world biomedical datasets."
SP:bc4f69f23aba2034cbf14cb31bdc7a991806bbf6,"This paper studies the effect of early stopping on the generalization of linear regression models. The authors propose a new model of overparametrization that captures the phenomenon that the model size usually exceeds the number of features in practice. Theoretically, the authors show that the optimal early stopping time corresponds to the training process of deep neural network. Moreover, they show that early stopping can help mitigate double descent in various settings."
SP:ede87b50cd9c4a6533f17e3e5ddfaaeaaac71dcf,"This paper proposes a quasi-Newton method for the policy gradient algorithm with entropy regularization. In the case of Shannon entropy, the resulting algorithm reproduces the natural policy gradient (NPG) algorithm. For other entropy functions, this method results in new policy gradient algorithms. The authors provide a simple proof that all these algorithms enjoy the Newton-type quadratic convergence near the optimal policy. The experiments show that the proposed method converges in single-digit iterations."
SP:3535504f7599b1f39239f7cd8e09acd40fa8fdf0,"This paper proposes a new reinforcement learning agent for text-based text games. The agent is based on a case-based reasoner that collects positive experiences from the agent’s interaction with the world in the past and later reuses the collected experiences to act efficiently. The method can be applied in conjunction with any existing on-policy neural agent in the literature for TBGs. The experiments show that the proposed approach consistently improves existing methods, obtains good out-of-distribution generalization, and achieves new state-of the-art results on widely used environments."
SP:9a5dd0148a15dc5b4d2bc6762dfe8a8991f8866c,This paper proposes a two-stage method to distill multiple word senses from a pre-trained contextual language model (BERT) by using attention over the senses of a word in a context and transferring this sense information to fit multi-sense embeddings in a skip-gram-like framework. They demonstrate an effective approach to training the sense disambiguation mechanism in our model with a distribution over word senses extracted from the output layer embedding of BERT. Experiments on the contextual word similarity and sense induction tasks show that this method is superior to or competitive with the state-of-the-art.
SP:e4cdba0fc7cd7f440d4436219f3959d8d5e2ad28,"This paper proposes to transfer a pre-trained 2D convolutional neural network to a 3D point-cloud model by inflating 2D filters to 3D filters and finetuning the inflated image-pretrained models (FIP). The authors show that FIP can achieve competitive performance on 3D Point-cloud classification tasks with minimal fine-tuning efforts. The authors also show that the FIP improves data efficiency, reaching up to 10.0 points top-1 accuracy gain on few-shot classification. "
SP:dc99c307931ae9c5d4a1b998dc94cfc6ac78d11f,"This paper proposes an energy-based learning objective for training autoregressive generative models. The proposed method is based on the energy based learning objective of Mihaylova & Martins (2019). The authors show that their method is capable of alleviating the exposure bias problem and increase temporal coherence by imposing a constraint which fits joint distributions at each time step. Besides, the authors estimate energy scores using the underlying auto-regressive network itself, which does not require any extra network. Finally, thanks to importance sampling, they can train the entire model efficiently without requiring an MCMC process."
SP:51e748c55bd4134047098559577fa3f37aa7433a,"This paper proposes a new distributional robustness framework for adversarial training, which unifies and generalizes standard AT approaches with improved adversarial robustness. By defining a new family of risk functions, the proposed framework facilitates the development of the standard AT methods including PGD-AT, TRADES, MART and AWP. Extensive experiments show that the proposed algorithms are able to boost the model robustness against strong attacks with better generalization capacity."
SP:f192046ea8ad61bfc8e05a0ddb90a8bd15b4640b,"This paper proposes a novel unsupervised representation learning method for multivariate time series. The proposed method is based on instance-level augmentation, which uses the entire time series as input and applies dropout to generate different views for training. An iterative bilinear temporal-spectral fusion module is devised to explicitly encode the affinities of abundant time-frequency pairs and iteratively refine representations of time series through cross-domain interactions with Spectrum-to-Time (S2T) and Timeto-Spectrum (T2S) Aggregation modules. Extensive experiments are conducted on three major practical tasks for time series such as classification, forecasting and anomaly detection to demonstrate the effectiveness of the proposed method."
SP:ef54840009afb095c67bbbc29a7824c20a375ee8,"This paper proposes an algorithm for automatically adjusting the learning rate during gradient descent. The learning rate is optimized via a simple extra gradient descent step, justified by an analysis that exploits the structure of neural networks. The authors formulate first and second-order gradients with respect to learning rate as functions of consecutive weight gradients, leading to a cost-effective implementation. They also show that the scheme can be extended to accommodate for different learning rates per layer."
SP:263c787361cd6d4443ce516d389c694d0fe44b28,"This paper proposes a meta-reinforcement learning algorithm for sequential multi-task learning, where the agent cannot revisit previous tasks to collect data. The proposed algorithm, called CoMPS, consists of two subroutines: (1) learning a new task using RL and (2) using the experience from RL to perform offline meta-learning to prepare for subsequent task learning. The experiments show that the proposed method outperforms other methods, achieving a higher average reward with fewer samples on average over each of the tasks in the sequence."
SP:2bd729b7aa045bf74e31229c9e76e57af36e804b,"This paper proposes a new threat model for poisoned classifiers, where one without knowledge of the original trigger, would want to control the poisoned classifier. Under this threat model, the authors propose a test-time, human-in-the-loop attack method to generate multiple effective alternative triggers without access to the initial backdoor and the training data. They construct these alternative triggers by first generating adversarial examples for a smoothed version of the classifier, created with a procedure called Denoised Smoothing, and then extracting colors or cropped portions of adversarial images with human interaction. They demonstrate the effectiveness of our attack through extensive experiments on high-resolution datasets."
SP:e58ab0e3cff6b18013145a1a99cfa9da0a3d872f,"This paper studies the problem of unconditional GAN distillation, especially for the StyleGAN2 architecture. The authors propose a novel initialization strategy for the student model, which can ensure the output consistency to the maximum extent. A latent-direction-based distillation loss is also proposed to further enhance the semantic consistency between the teacher and student model. Extensive experiments demonstrate the effectiveness of the proposed method."
SP:2c2231743fa33b95828c6615263954ce1c05f95d,"This paper proposes a method for learning a model to predict the next step of an offline algorithm. The model is based on a multi-task learning model, where the model is trained to simultaneously detect behavioral structures which have already occurred and predict those that may come next. The method is evaluated on both synthetic data and historical stock market data. "
SP:ee3a21d2fb8a073099aa200129a53c31f3b6561d,"This paper proposes a method to reduce the number of inducing points in Gaussian process (GP) approximations by amortizing the computation of the inducing points locations, as well as the parameters of the variational posterior approximation. The inducing points are computed by a neural network that receives the observed data as an input and outputs inducing point locations and the parameters. The method is evaluated on several regression and binary classification problems."
SP:f20c99b441545047a16ae524cc2e317b2c3787a2,"This paper proposes a decentralized training algorithm for large neural networks that is Byzantine-tolerant and robust to Byzantine and Sybil attacks. The proposed algorithm is based on the standard SGD algorithm, but with a modification to the gradient descent algorithm. Theoretical analysis is provided to prove the robustness of the proposed algorithm. Experiments are conducted on image classification and language modeling tasks. "
SP:93894f20ab2593e5237b6972fef9fe63e96af89a,"This paper presents a method for learning a physics-explained Lagrangian model of turbulence. The method is based on the smoothed particle hydrodynamics (SPH) method, which is a mesh-free method for approximate numerical solutions of the equations of fluid dynamics. The authors propose a learnable hierarchy of parameterized SPH-informed fluid simulators using both physics-based parameters and Neural Networks as universal function approximators. They show that their method is capable of solving inverse problems over the physically interpretable parameter space, as well as over the space of Neural Network parameters. They also show that it can be used to learn unknown functions embedded within SPH based models."
SP:d11b81f9ab414fcf430a03cd70c2d3246b678474,"This paper proposes Mix-MaxEnt, a novel approach to regularize a single deterministic neural network to obtain improved accuracy and reliable uncertainty estimates. The approach is based on adding an entropy maximization regularizer corresponding to the predictive distribution in the regions of the embedding space between the class clusters. This is achieved by synthetically generating between-cluster samples via the convex combination of two images from different classes and maximizing the entropy on these samples. Experiments on real-world datasets (CIFAR10 and CIFAR-100) using ResNet and Wide-ResNet architectures demonstrate that the proposed approach consistently provides much improved classification accuracy, better calibrated probabilities for in-distribution data, and reliable uncertainties estimates."
SP:365490b872464f00634dc7a50d024fceaf0a61ee,"This paper proposes a self-supervised auto-encoder-based method for animating images. The key idea is to learn a set of orthogonal motion directions in the latent space of the autoencoder, and use their linear combination to represent any displacement in latent space. The proposed method is evaluated on the VoxCeleb, Taichi and TED-talk datasets."
SP:86f9f89f84e117c86478b9afaf087f65524f5472,This paper proposes a meta-learning method called task interpolation (MLTI) to generate additional meta-training tasks by randomly sampling a pair of tasks and interpolating the corresponding features and labels. The authors prove that MLTI corresponds to a data-adaptive meta-regularization and improves the generalization. Experiments are conducted on 8 real-world datasets from various domains to demonstrate the effectiveness of the proposed method.
SP:73d577e9c4f4af5e11a9e5bdb583ee0f50a315f5,"This paper proposes a new method for fair representation learning based on normalizing flows. The idea is to model the encoder as a normalizing flow, which is trained to minimize the statistical distance between the latent representations of different groups. The main advantage of this approach is that its exact likelihood computation allows us to obtain guarantees on the maximum unfairness of any potentially adversarial downstream predictor. Experiments are conducted to demonstrate the effectiveness of the proposed method."
SP:404d5643327f60f0f06f820033a56081f9e01900,"This paper proposes a graph neural network (GNN) based method for subgraph isomorphism counting. The proposed method is based on edge-centric message passing and query-conditioned graph modulation. In particular, the edge is treated as first-class citizens and the graph is modulated with respect to the query. Extensive experiments are conducted to demonstrate the effectiveness of the proposed method."
SP:5a94f18156ab2949c86de45fcf0de2e16977eebb,"This paper studies the problem of federated learning at a global scale, where each client has their own personalized labels, which might not be compatible with others (even for the same class), and can be also possibly from a variety of multiple domains. The authors propose a novel method, namely Similarity Matching and Kernel Factorization (SimFed), which measures task-level similarity based on locally learned knowledge and matches the relevant ones for personalized knowledge reflection. Furthermore, they factorize the model parameters into two basis vectors and the highly sparse masks to significantly reduce the dimensionlaity of parameter space for alleviating knowledge collapse and information loss when reflecting the heterogeneous knowledge. "
SP:97f30bea31eccef6c770fbce1e14fd6d2493a178,"This paper proposes a method to learn object-centric representations of scenes with multiple objects by distilling explicit object dynamic representations from raw video input. The proposed method is based on distillation network that distills explicit object dynamics representations (e.g., velocity) and a relation module that calculates object-pair interactions and applies it to the corresponding dynamic representations of objects. The method is evaluated on tasks of video events reasoning and video prediction. "
SP:ba8e50d1fa9cb824fa3f76c0c691997cd151d760,"This paper proposes a new GNN layer, called Permutation Equivariant Graph Neural Network (PEG), which is based on the positional encoding (PE) technique. The proposed PEG layer is a permutation equivariant graph neural network (GNN) layer that uses the original node features and the positional features simultaneously. Theoretical analysis is provided to show that PEG is permutation-equivariant and stable. Experiments are conducted on link prediction tasks and show that the PEG achieves comparable performance with strong baselines."
SP:cf448479f68c3194c1a9e11729bf70d7cc2ae8fd,"This paper proposes LaMer, a self-supervised text style transfer method built on large-scale language models. LaMer first mines the roughly parallel expressions in the non-parallel datasets with scene graphs, and then employs MLE training, followed by imitation learning refinement, to leverage the intrinsic parallelism within the data. On two benchmark tasks (sentiment & formality transfer) and a newly proposed challenging task (political stance transfer), LaMer achieves qualitative advances in transfer accuracy, content preservation, and fluency. "
SP:8f7b2d1020d9e527118b8fb816760c13b0d0bfcb,This paper studies the problem of answering hyper-relational queries in knowledge graphs. The authors propose a query embedding method based on Graph Neural Networks (GNNs) and a method to answer conjunctive queries in latent space. The proposed method is evaluated on a set of hyper relational knowledge graphs (KGs) and is shown to outperform baselines.
SP:5f8b58424a1a8eeb72217e75189d6f773a298a7a,This paper proposes a new Bayesian optimization method for hyperparameter optimization in deep neural networks. The main idea is to use a surrogate for Gaussian processes that embeds the learning curve dynamics and a new acquisition function that incorporates multi-budget information. Experiments show that the proposed method outperforms the state-of-the-art methods on a variety of tasks. 
SP:99d3d94e3af5d2dc7b92c00ac1345d1d2dd0d15b,"This paper proposes to improve the performance of learned image compression by introducing post-training quantization and making the model inference integer arithmetic-only, which is much simpler than the existing training and fine-tuning based approaches. The authors further improve the discretization of the entropy parameters and extend the deterministic inference to fit Gaussian mixture models. With the proposed methods, the current state-ofthe-art image compression models can infer in a cross-platform consistent manner, which makes the further development and practice of learned images compression more promising."
SP:85d0df515e9e555f3ea1c21d607304dfaeae69c0,"This paper proposes a neural network architecture for denoising scanning electron microscopy images. The proposed method is based on gated recurrent units, which reconstructs and removes the noise by synthesizing the sequential data. The paper also proposes a novel noise reconstruction module with soft attention and signal boosting, that upon deployment on large images (more than 24M pixels) homogeneously remove the noise. Experiments are conducted on FIB-SEM data."
SP:e6275b0b103fa90dcebcdd3d3c14c830c3402972,"This paper studies the label trick in GNNs. In particular, the authors show that under certain simplifying assumptions, the stochastic label trick can be reduced to an interpretable, deterministic training objective composed of two factors. The first is a data-fitting term that naturally resolves potential label leakage issues, while the second serves as a regularization factor conditioned on graph structure that adapts to graph size and connectivity. The authors then leverage this perspective to motivate a broader range of label trick use cases."
SP:b6cbc3661f9c440687c3dd01ee35a118c87db377,"This paper proposes a new multi-agent reinforcement learning task called SymmToM, where all agents can speak, listen, see other agents, and move freely through a grid world. To solve the task, the agent needs to develop a theory of mind to maximize each agent’s rewards. The authors define a framework to analyze the problem in a symmetric setting and provide a simplified setup on which to test the problem. They show that even maintaining the simple rules of the environment, modifying its parameters results in much more difficult challenges. "
SP:f8ce83805eee46c6c196e8477bf10d8d7f7e0f46,This paper proposes a novel zero-shot object detection method based on a modified YOLOv5 neural network to perform generalized zeroshot detection on seen and unseen objects. The authors also propose a novel splitting method for YCB Video dataset to train and test the gZSD algorithms. The proposed method is evaluated on the YCB video dataset.
SP:aa1dcd9217270010f16a00004facede942efea17,"This paper proposes an autoregressive latent video prediction model (HARP) that is capable of predicting high-fidelity future frames with minimal modification to existing models, and produces high-resolution (256x256) videos. Specifically, the authors scale up prior models by employing a high-Fidelity image generator (VQ-GAN) with a causal transformer model, and introduce additional techniques of top-k sampling and data augmentation to further improve video prediction quality. The proposed method achieves competitive performance to state-of-the-art approaches on standard video prediction benchmarks with fewer parameters, and enables high resolution video prediction on complex and large-scale datasets."
SP:7f57896afd63bc869d2db6ddf7abbeaa71daae11,"This paper proposes a new generative adversarial network (GAN) architecture based on Vision Transformers (ViT) for image generation. The authors claim that the ViT discriminators interact poorly with self-attention, causing instability during training. To resolve this issue, they introduce several novel regularization techniques for training GANs with ViTs. For ViT generators, they examine architectural choices for latent and pixel mapping layers to improve convergence. The proposed ViTGAN achieves comparable performance to the leading CNN-based GAN models on three datasets. "
SP:bbae3afcaea0a2e54904cb8daaed7df4fe37da6e,"This paper studies the problem of learning a generative model with variational autoencoder (VAE) that achieves good likelihoods but poor sample quality. The authors propose a two-stage training procedure that prioritizes the modeling the perceptible information. By doing so, they can train VAEs with good sample quality while still achieving ELBOs comparable to conventionally-trained VAEs. "
SP:bfed56018134ec66cde9a7e958df964d4cca3164,"This paper proposes a method to estimate the optimal reverse variance and the optimal KL divergence of a DPM using a Monte Carlo method and a score-based model. The authors show that both of them have analytic forms w.r.t. its score function. They also provide a lower and upper bound of the optimal variance and clip the estimate for a better result. Empirically, their analytic-DPM improves the log-likelihood of various DPMs and produces high-quality samples."
SP:3f935ba5784c3e86db72421426bc479061af1a4b,"This paper investigates whether it is feasible to switch to vision transformers for medical image classification, or if we should keep working with CNNs. The authors conducted a series of experiments on several standard medical image benchmark datasets and tasks. Their findings show that, while CNNs perform better if trained from scratch, off-the-shelf vision transformer-based models can perform on par with convolutional neural networks when pretrained on ImageNet. "
SP:a64e0535f268901e38fd51e027c612ebcdbae1a4,"This paper analyzes the effect of chunking the text into training examples, which are contiguous text segments of sizes processable by the neural architecture. The authors show that the pretrained NLM can model much stronger dependencies between text segments that appeared in the same training example, than it can between different training examples. This intuitive result has a twofold role. First, it formalizes the motivation behind a broad line of recent successful NLM training heuristics, proposed for the pretraining and fine-tuning stages. Second, it indicates further improvements to be made in NLM pretraining for the benefit of NLP tasks."
SP:59066956fa2e423d5f2d2ea4f91c4ddf6afd4683,"This paper proposes a new method for learning to optimize (L2O) based on symbolic regression. The main contribution of this paper is to propose a symbolic L2O method that can be meta-trained on large-scale problems and outperform human-designed and tuned optimizers. The paper also proposes a lightweight symbolic representation and analysis framework for learnable optimizers, which yields a series of insights for learning and analysis."
SP:54dfeb363beee9959aecc9e0853ff06e43bd94e4,This paper studies the problem of adversarial robustness in reinforcement learning. The authors propose a method based on randomized smoothing to add Gaussian noise to the observation at each time-step. They show that this method is provably robust to adversarial perturbations. They also provide theoretical guarantees on the robustness of the proposed method. 
SP:e0f9add5fde18eaab0eeb2b10b14928acc8ec5b8,"This paper studies the problem of estimating the accuracy of a classifier using only labeled source data and unlabeled target data. The authors propose Average Thresholded Confidence (ATC), a method that learns a threshold on the model’s confidence, predicting accuracy as the fraction of unlabeling examples for which model confidence exceeds that threshold. ATC outperforms previous methods across several model architectures, types of distribution shifts (e.g., due to synthetic corruptions, dataset reproduction, or novel subpopulations), and datasets (WILDS, ImageNet, BREEDS, CIFAR, and MNIST). In the experiments, ATC estimates target performance 2–4ˆ more accurately than prior methods. "
SP:e748bf6ee653087cae825df32a8546f9ccebfcf1,"This paper proposes a method for partial distribution matching (PDM) based on the partial Wasserstein-1 (PW) discrepancy. The authors derive the duality of the PW discrepancy and show its gradient can be explicitly computed. Based on this, the authors propose a neural network that approximates the discrepancy and learns the transformation adversarially with the network. It also incorporates an efficient coherence regularizer for non-rigid transformations to avoid unrealistic deformations. Experiments are conducted to show the effectiveness of the method."
SP:f94f77696d100b2638fa2a6d82c8df47db3b6a36,"This paper proposes a novel method for hyperparameter optimization (HPO) based on landmark meta-features (DKLM) to capture the similarity between hyperparameters with an end-to-end meta-feature network that embeds the set of evaluated configurations and their respective performance. As a result, our novel DKLM can learn contextualized dataset-specific similarity representations for hyper-parameter configurations. Experiments are conducted to validate the performance of DKLM in a wide range of HPO meta-datasets."
SP:e3c57f3589e8ab674644d900c14b3473cd71a23f,This paper proposes a novel method for responsible disclosure of generative models by a novel fingerprinting mechanism. It allows scalable ad-hoc generation of a large population of models with distinct fingerprints. Experiments show that the proposed method is effective in deep fake detection and attribution tasks. 
SP:73bffd1a0856b80d29f7a2b2b68be57882531f07,"This paper proposes a method to provide local explanations for black-box similarity learners. The method is based on two steps. First, feature attributions are used to explain the similarity between a pair of inputs as determined by a black box similarity learner. Second, analogies are proposed as a new form of explanation in machine learning. The goal is to identify diverse analogous pairs of examples that share the same level of similarity as the input pair and provide insight into (latent) factors underlying the model’s prediction. "
SP:6a3c4ae05d582f8896840483b08c735ced2976bc,"This paper studies the certified robustness of ensembles of ML models. The authors show that ensemble models are shown to be more robust than a single model empirically, however, they find that standard ensemble models only achieve marginal improvement compared to single model. Based on the theoretical findings, the authors propose the lightweight Diversity Regularized Training (DRT) to train ensemble ML models to achieve higher certified L2-robustness. Extensive experiments show that DRT-enhanced ensemble models achieve the highest certified robusts compared with existing baselines."
SP:3002b29c27709780238876d8c3f81bbd6a0f8112,"This paper studies the expressive power of local neighborhood pooling in graph neural networks (GNNs). In particular, the authors analyze a new pooling technique of local neighborhoods that allows different tradeoffs of computational cost and expressive power. First, they prove that this model can count subgraphs of size k, and thereby overcomes a known limitation of low-order GNNs. Second, they show how recursive pooling can exploit sparsity to reduce the computational complexity compared to the existing higher-order graph neural network architectures. More generally, they provide a (near) matching information-theoretic lower bound for counting subGraphs with graph representations that pool over representations of derived (sub-)graphs."
SP:5d0cbd84336caf5f31e1f98e11f6733230e4d792,"This paper revisits the KI process in an information-theoretic view and shows that KI could be interpreted using a graph convolution operation. The authors propose a simple probe model called Graph Convolution Simulator (GCS) for interpreting knowledge-enhanced LMs and exposing what kind of knowledge is integrated into these models. They conduct experiments to verify that our GCS model can indeed be used to correctly interpret the process, and use it to analyze two typical KI methods: K-Adapter and ERNIE. They find that only a small amount of factual knowledge is captured in these models during integration."
SP:7e73948421e98307fceb69a316d8a4e7c4926cda,"This paper studies the effect of the adaptation learning rate in meta-learning with mixed linear regression. The authors provide a principled way to estimate optimal adaptation learning rates that minimize the population risk of MAML. They also interpret the underlying dependence between the optimal learning rate and the input data. Finally, they prove that compared with empirical risk minimization (ERM), MAMIL produces an initialization with a smaller average distance to the task optima."
SP:effbc85d89b1197d9c2abcaf5ff13864135dd6e1,"This paper studies the problem of source-free domain adaptation (SFDA), where a model is trained on labeled data in a source domain to adapt to unlabelled data in the target domain without access to the source-domain data during adaptation. Existing methods for SFDA leverage entropy-minimization techniques which: (i) apply only to classification; (ii) destroy model calibration; and (iii) rely on the source model achieving a good level of feature-space class-separation. This paper addresses these issues for a particularly pervasive type of domain shift called measurement shift, characterized by a change in measurement system, which can be resolved by restoring the source features. The authors propose a bottom-up training scheme for FR which boosts performance by preserving learnt structure in the later layers of a network. The experimental results show that the proposed method outperforms existing SFDA methods on real and synthetic data."
SP:7d63034ec7e6a4f178681ff2a49feb485cd47116,"This paper studies the problem of federated learning with non-iid users. Specifically, the authors propose a federated robust learning algorithm that propagates adversarial robustness from high-resource users that can afford adversarial training (AT) to those low resource users that cannot afford it during the FL process. The authors show that existing FL techniques cannot effectively propagate robustness among non-IID users, and propose a simple yet effective propagation approach that transfers robustness through carefully designed batch-normalization statistics. The experimental results demonstrate the rationality and effectiveness of the proposed method."
SP:42c7a79e58b6a9f776fa6ae928bd89c194f9303f,This paper proposes a method to infer the network structure of a game from its equilibrium actions. The method is based on a transformer-like architecture that learns a mapping from the equilibrium actions to the structure of the game without explicit knowledge of the utility function. The proposed method is tested on three different types of network games using both synthetic and real-world data. 
SP:1c7b9157cf8c06ca771da78895fc3af969b0fb85,"This paper proposes a novel relation prediction framework that predicts relations between each node pair based on the subgraph containing the pair and other subgraphs with identical graph patterns, and has a strong inductive bias for the generalization to unseen relation types. The proposed method is evaluated on heterogeneous graph based recommendation and knowledge graph completion tasks with the state-of-the-art methods. "
SP:26ed25a7b42da2cf11b76a727102d8aa36d76657,"This paper studies the few-shot learning problem for histology images. The authors propose to use contrastive learning (CL) with latent augmentation (LA) to improve the performance of self-supervised learning. The main idea is to use CL to learn representations without manual labels, while LA to transfer semantic variations of the base dataset in an unsupervised way. Experiments show that CL learned models generalize better than supervised counterparts for histological images. "
SP:badbe687258cd5c282ca167b1f6fbfc6b5400dbf," RNNs with continuous-time hidden states are a natural fit for modeling irregularly-sampled time series. These models, however, face difficulties when the input data possess long-term dependencies. The authors prove that similar to standard RNN, the underlying reason for this issue is the vanishing or exploding of the gradient during training. This phenomenon is expressed by the ordinary differential equation (ODE) representation of the hidden state, regardless of the ODE solver’s choice. They provide a solution by equipping arbitrary continuous time networks with a memory compartment separated from its time-continuous state. This way, they encode a continuous time dynamical flow within the RNN allowing it to respond to inputs arriving at arbitrary time-lags while ensuring a constant error propagation through the memory path. "
SP:4efd22f9122fa5856a9f4302eb6875fa0c414912,"This paper proposes BiBERT, a quantized version of BERT with 1-bit activations. The authors analyze the performance drop of binarized BERT and propose a method to address it. The main contribution of the paper is to identify the bottlenecks of the full binarization and propose an efficient Bi-Attention structure for maximizing representation information statistically and a DirectionMatching Distillation (DMD) scheme to optimize the binarised BERT accurately. Extensive experiments show that the proposed method outperforms both the straightforward baseline and existing state-of-the-art quantization methods with ultra-low bit activations on the NLP benchmark."
SP:619bd742e92bea6241852f5a9d2b7bacf13b393a,"This paper proposes a transformer-based method for multi-person keypoint detection and instance association. Specifically, the self-attention in Transformer measures dependencies between any pair of locations, which can provide association information for keypoints grouping. However, the naive attention patterns are still not subjectively controlled, so there is no guarantee that the keypoints will always attend to the instances to which they belong. To address this issue, the authors propose a novel approach of supervising self attention by supervising the attention mask of each person instance by the mask of the instance. Experiments on the COCO Multi-Person Keypoint detection challenge and person instance segmentation task demonstrate the effectiveness and simplicity of the proposed method."
SP:14750819593136fc9ef4efd032ab6f94dc5f6a02,"This paper studies the problem of learning Pareto-efficient policies for reinforcement learning under the mean-variance (MV) trade-off. The authors propose an algorithm called EQUMRL, which is based on maximizing the expected quadratic utility function. The utility function is defined as the expected utility of a policy that maximizes the utility of the policy that minimizes the variance of the utility function, i.e., the policy with the lowest utility is the one that maximises the utility maximization. The algorithm is evaluated on both synthetic and real-world datasets. "
SP:f675b564b3a9c8626ce7944d752fa3e0d868428e,"This paper studies the problem of test-time domain adaptation for an autoencoder system whose channel is generatively-modeled using a mixture density network (MDN). Different from the setting of conventional training-time (unsupervised or semi-supervised) domain adaptation, the authors propose a fast and sample-efficient method for adapting the channel model without modifying the encoder and decoder neural networks, and adapting only the MDN channel model. The method utilizes feature transformations at the decoder to compensate for changes in the channel distribution, and effectively present to decoder samples close to the source distribution. Experimental evaluation on simulated datasets and real mmWave wireless channels demonstrate the effectiveness of the proposed method."
SP:77dc92137ea490d3e1b4b8ee1630dbe2ee0bddfa,"This paper studies the abductive natural language inference task (alpha-NLI), where the goal is to infer the most plausible explanation between the cause and the event. The authors argue that it is unnecessary to distinguish the reasoning abilities among correct hypotheses and similarly, all wrong hypotheses contribute the same when explaining the reasons of the observations. Therefore, they propose to group instead of ranking the hypotheses and design a structural loss called “joint softmax focal loss” in this paper. Based on the observation that the hypotheses are generally semantically related, they have designed a novel interactive language model aiming at exploiting the rich interaction among competing hypotheses. The experimental results show that our IMSL achieves the highest performance on the RoBERTa-large pretrained model, with ACC and AUC results increased by about 1% and 5% respectively."
SP:17cd72df5fc19398f582d27516fd742b073f79e3,This paper proposes a method for adversarially robust out-of-distribution (OOD) OOD detection. The proposed method is based on a binary discriminator between in- and out-distributed samples. The discriminator is a simple ReLU classifier with negative weights. The authors show that the discriminator can be trained to be robust to adversarial manipulations of the OOD samples. They also show that this discriminator avoids the asymptotic overconfidence problem of standard neural networks.
SP:9c3756f13932236aff3e8104f4fa193dcc8fde2f,"This paper proposes a new Generalized Transferable Attack (GTA) problem where the attacker has a set of surrogate models trained on different datasets (with different label sets and image sizes), and none of them is equal to the dataset used by the victim model. To solve this novel problem, the authors propose a novel method called Image Classification Eraser (ICE) to erase classification information for any encountered images from arbitrary dataset. Extensive experiments on Cifar-10, CIFAR-100, and TieredImageNet demonstrate the effectiveness of the proposed ICE on the GTA problem."
SP:2e0447c741a3f09be1095633d870200355211260,"This paper studies the problem of discriminative pre-trained language models (PrLMs) that suffer from the false negative issue where training is carried out on wrong data and leads to less efficiency and less robustness in the resulting PrLMs. To address this problem, this paper proposes two pre-training methods to counteract false negative predictions and encourage pre- training language models on true negatives, by correcting the harmful gradient updates subject to false-negative predictions. Experimental results on GLUE and SQuAD benchmarks show that the proposed methods indeed bring about better performance together with stronger robustness."
SP:281bc59d639aa76d84921b3ec4ce1ee8f1ba5b51,"This paper proposes a novel semi-supervised learning setting where novel classes may appear in the unlabeled test data. The authors propose ORCA, an end-to-end approach that assigns instances to previously seen classes or novel classes by grouping similar instances without assuming any prior knowledge. The key idea in ORCA is to utilize uncertainty adaptive margin to circumvent the bias towards seen classes caused by learning seen classes faster than the novel classes. Extensive experiments on image classification datasets and a single-cell dataset demonstrate that ORCA consistently outperforms alternative baselines."
SP:6c572c4c21b01a0cf3fd9ef97fbb348ef4e405ae,"This paper proposes SLIM-QN, a light-stochastic quasi-Newton optimizer for training large-scale deep neural networks (DNNs). It addresses two key barriers in existing second-order methods for training DNNs: 1) the high computational cost of obtaining the Hessian matrix and its inverse in every iteration; 2) convergence instability due to stochastic training (e.g. L-BFGS). To tackle the first challenge, the authors propose to use the BFGS update rule that directly approximates Hessian inverse using past parameters and gradients, without explicitly constructing the Hessians matrix and then computing its inverse. To achieve stable convergence, the proposed method introduces momentum in Hessian updates together with an adaptive damping mechanism. The authors provide rigorous theoretical results on the convergence of the proposed algorithm. The experiments on various datasets and network architectures demonstrate the effectiveness of the method."
SP:4bffce00ebb02d2e676eec897647ac14c3344deb,"This paper proposes a method for graph pruning based on locality-sensitive hashing (LSH) to reduce the number of edges in a graph. Specifically, the proposed method is based on the observation that similar local environments of the original graph result in similar environments in the resulting sparsified graph, which is an essential feature for graph-related tasks. Experiments are conducted to demonstrate the effectiveness of the proposed approach. "
SP:c5e024f4e2079586298519ca868630efd7579eca,"This paper proposes a data augmentation method for self-supervised learning based on adversarial perturbations. The proposed method is based on a VAE that is trained to reconstruct the original input x, and then adversarially perturbs the VAE’s output x to add it back to the original x as an augmentation. The authors show that the proposed method can improve the efficiency and generalization of SSL methods on several benchmark datasets."
SP:0991bc5f213bd8ab7572e2fed309e1b57a35835b,"This paper studies the problem of detecting distributional shifts in the training and test distributions of a machine learning model. In particular, the authors propose a simple sequential method for testing if the difference between source (training) and target (test) distributions leads to a significant increase in a risk function of interest, like accuracy or calibration. The proposed method is based on time-uniform confidence sequences (TCCS) and is applicable in settings where (some) true labels are revealed after the prediction is performed, or when batches of labels become available in a delayed fashion. Experiments are conducted on simulated and real datasets. "
SP:1c7b954273e3a9cda333385b15a3e8ed3bf8178a,This paper presents a method for learning a physical model of a physical phenomenon from a short video. The method is based on neural ODEs and neural implicit representations. The key idea is to learn the parameters of an underlying ODE-based physical model that directly allows for interpretability and long-term predictions. Experiments show that the proposed method can recover the metric length of the pendulum from the monocular video. 
SP:51efd1451343f4994d857daa5490e299b812bc2d,"This paper studies the context-dependent reinforcement learning (C-MDP) problem, which is characterized by an unknown finite number of not directly observable contexts, abrupt context changes occurring during an episode, and Markovian context evolution. The authors propose a variational inference algorithm for model learning using a sticky Hierarchical Dirichlet Process (HDP) prior. They derive a context distillation procedure, which identifies and removes spurious contexts in an unsupervised fashion. They show that the combination of these two components allows to infer the number of contexts from data thus dealing with the context cardinality assumption. They then find the representation of the optimal policy enabling efficient policy learning using off-the-shelf RL algorithms."
SP:ea167b126212b2092bc1190d7f8376bf7c54a888,"This paper presents a framework to pretrain knowledge-based multilingual language models (KMLMs) for knowledge-intensive cross-lingual NLP tasks. The authors first generate a large amount of code-switched synthetic sentences and training data using the Wikidata knowledge graphs. Then based on the intra-and inter-sentence structures of the generated data, the authors design pretraining tasks to facilitate knowledge learning, which allows the language models to not only memorize the factual knowledge but also learn useful logical patterns. The pretrained KMLMs demonstrate significant performance improvements on a wide range of Knowledge-intensive Cross-Lingual tasks, including named entity recognition, factual knowledge retrieval, relation classification, and a new task designed by the authors."
SP:6c11cf29c90f923346372ba6f11452c36e69ad6d,This paper studies the problem of unsupervised reinforcement learning agents that can be trained to assist others in achieving their goals without knowing what those goals are. The authors propose to act altruistically towards other agents by giving them more choice and thereby allowing them to better achieve their goals. They formalize this concept and propose an altruistic agent that learns to increase the choices another agent has by preferring to maximize the number of states that the other agent can reach in its future. They evaluate their approach on three different multi-agent environments where another agent’s success depends on the behavior of the agent. 
SP:5dbc54201ba184266c5054f0d2944bd197bc307a,"This paper studies the phenomenon of double descent in neural networks. In particular, the authors study the effect of the choice of the loss function on the double descent phenomenon. The authors use influence functions to derive the lower bound of the population loss and its lower bound on the Hessian at the optimum. The derived lower bound is shown to exhibit a double descent behavior at the interpolation threshold. "
SP:b485114712055f39a7afb951dbc3db482ff523fd,"This paper analyzes the asymptotic behavior of the graph neural tangent kernel (GNTK) in the large depth of a GNN. The authors show that the trainability of the GNTK converges to zero at an exponential rate when the number of layers goes to infinity. They also show that residual connection-based techniques are only able to mildly mitigate the exponential decay of trainability. Finally, they propose Critical DropEdge, a connectivity-aware and graph-adaptive sampling method, inspired by the theoretical insights on the dropping trainability problem."
SP:25a92b3583afdc6892e59f1e769125d52c8011af,"This paper studies the problem of estimating the left ventricle ejection time (LVET) using video-based vital sign measurement. The authors propose to use the second derivative of both the input frames and the target vital sign signals into the training procedure to better estimate the LVET interval. They show that by incorporating higher-order dynamics into the loss function, they improve the quality of the estimated higher order signals. "
SP:0a88d2fcbdfab3e196bf6b9c75adb1006ab87536,"This paper proposes a symbolic mapping method to help agents learn a compositional and symmetric language in complex settings like dialog games. Inspired by the theory that human language was originated from simple interactions, the authors hypothesize that language may evolve from simple tasks to difficult tasks. They propose a novel architecture called symbolic mapping as a basic component of the communication system of agent. They find that symbolic mapping learned in simple referential games can notably promote language learning in difficult tasks and explore vocabulary expansion, and show that agents can easily learn to use new symbols when the environment becomes more complex. "
SP:89575be04cb33b41d7a0a7b62f9496c2838a1317,"This paper proposes a hierarchical modular approach to learn agents that navigate and manipulate objects in a divide-and-conquer manner. Specifically, the authors first infer a sequence of subgoals to be executed based on language instructions by high-level policy composition controller (PCC). Then discriminatively control the agent’s navigation by a master policy by alternating between navigation policy and various independent interaction policies. Finally, they infer manipulation actions with the corresponding object masks using the appropriate interaction policy. The proposed agent achieves state-of-the-art performance on the ALFRED benchmark."
SP:e2c8efe00db7baba2368f4f6a37815809b9e235e,"This paper proposes Nuisance-randomized distillation (NURD), a method for training classifiers that perform well regardless of the nuisance-label relationship. The authors define a nuisance-varying family, which is a set of distributions that differ only in the nuisance and label relationship. Then, they define the set of representations such that conditioning on any member of the family, the nuisance variable and the label remain independent. They prove that the representations in this set always perform better than chance, while representations outside of this set may not. NURD finds a representation from this set that is most informative of the label under the nuisance randomized distribution, and prove that this representation achieves the highest performance within the set on every distribution in the family. "
SP:c75998b76f4e0510fc719d25959a10fc07db1c40,"This paper proposes OTTER (Optimal TransporT distillation for Efficient zero-shot recognition), which uses online entropic optimal transport to find a soft image-text match as labels for contrastive learning. Based on pretrained image and text encoders, models trained with OTTER achieve strong performance with only 3M image text pairs. Compared with InfoNCE loss, label smoothing, and knowledge distillation, OTTER consistently outperforms these baselines in zero shot evaluation on Google Open Images (19,958 classes) and multi-labeled ImageNet 10K (10032 classes) from Tencent ML-Images."
SP:e83cd70377542b5d187998e2e4a7ac070f453ed6,"This paper presents Pix2Seq, a simple and generic framework for object detection. Unlike existing approaches that explicitly integrate prior knowledge about the task, this paper casts object detection as a language modeling task conditioned on the observed pixel inputs. Object descriptions (e.g., bounding boxes and class labels) are expressed as sequences of discrete tokens, and we train a neural net to perceive the image and generate the desired sequence. The proposed method achieves competitive results on the challenging COCO dataset."
SP:abc9315f61929cc1c54dfef8ff83d7eac56ec2f2,"This paper proposes a symbolic policy distillation method for visual reinforcement learning. The key idea is to distill the symbolic policy into a discrete and abstracted representation of the policy network, which is more interpretable, robust and transferable. The symbolic policy is learned by a policy regression algorithm called RoundTourMix. Experiments show that the proposed method is able to maintain the performance and “denoise” the CNN policy."
SP:04e7e181aeb1244ae1c4837ad416aef93ea3ea32,"This paper proposes a GAN-based method for image-to-image translation that disentangles the pose-identity disentanglement of the generated image from two exemplar sources. The proposed method is based on a joint training scheme with self-supervision methods for the GANInversion encoder and the generator. Specifically, the authors propose a Vector-Quantized Spatial Normalization (VQSN) module for the generator to better disentangle the pose and identity. The VQSN module automatically learns to encode the shaping and composition information from the commonly shared objects inside the training-set images. Experiments conducted on various datasets show better synthesis image quality and disentangling scores. "
SP:e51a7f45493064972585109f203a867e9828eb15,"This paper proposes a simple MLP-based model for the task of keyword spotting and speech enhancement. The main idea is to split the input speech signal into multiple chunks and process each chunk individually. The chunks are then merged together and further processed to consolidate the output. The proposed model is evaluated on two speech enhancement tasks, keyword spotting (KWS) and Speech enhancement (SE). The results show that the proposed model achieves comparable performance with less parameters and inference time."
SP:d708d3886f4abd4552d8ccb2096df7361c803b13," transfer learning is gaining momentum in machine learning. However, there is a fundamental understanding of when and how much one can transfer knowledge from a related domain to reduce the amount of labeled training data. This paper provides a precise answer to this question for binary classification problems by deriving a novel lower bound on the generalization error that can be achieved by any transfer learning algorithm (regardless of its computational complexity) as a function of the number of source and target samples. The authors also consider a more general setting where there are more than one source domains for knowledge transfer to the target task and develop new bounds on generalization errors. "
SP:f7511ba9ccad03233b34b1bf41bbac7361d20a57,This paper proposes a generative model for the task of shape completion from incomplete point clouds. The model compresses the implicit field into sparse voxels associated with their latent codes and incrementally generates diverse implicit surfaces. The training objective is proven to maximize the variational lower bound of the likelihood of sparse Voxel embeddings. Experiments show that the proposed method is able to faithfully generate multiple plausible surfaces from partial observation.
SP:d22d8f074adbe8fb0f25fb8f8d96201b3159bf6b,This paper proposes a temporal prior for off-policy exploration in reinforcement learning. The temporal prior is a non-Markovian generalization of behavioral priors. The authors argue that state-conditioned temporal priors struggle with transferring knowledge across domain gaps and provide empirical evidence on how a state-independent temporal prior can accelerate learning in unseen longhorizon control tasks with sparse rewards. 
SP:25e06c022ae8b3cbbb8db413d7b534a1a5c92391,"This paper proposes a learning rate scheduler to control the learning rate dynamically by reinforcement learning. The proposed method is based on a graph message-passing network to encode the current dynamics with a message passing network and trains an agent to control learning rate accordingly via reinforcement learning (RL). The proposed scheduler can capture the intermediate layer information while being able to generalize to problems of varying scales. Besides, an efficient reward collection procedure is leveraged to speed up training. Experiments are conducted on benchmarking datasets, Fashion-MNIST and CIFAR10 for image classification, and GLUE for language understanding."
SP:d73cb0471c1770607ad3e4621cfc5f170683dd8e,"This paper proposes a method to decompose a 3D point cloud into a spatial mixture model where each component corresponds to one object. The proposed method is based on the Chamfer Mixture Loss, which is used to model the spatial mixture loss. The method is evaluated on the task of unsupervised scene decomposition."
SP:3c57e921c1bf23e482551ceb71702931a7f07439,"This paper studies the problem of grounding high-level tasks, expressed in natural language, to a chosen set of actionable steps (i.e., open fridge). The authors propose a procedure that conditions on existing demonstrations and semantically translates the plans to admissible actions. The proposed method is evaluated in the recent VirtualHome environment. "
SP:e0159d1c9df2e657892a3a0c77549df4698d9a1a,This paper proposes a new generative model based on VAE. The authors show that VAEs naturally unveil a Riemannian structure of the learned latent space. They show that using these geometrical considerations can significantly improve the generation from the vanilla VAE which can now compete with more advanced VAE models on four benchmark datasets. They also stress the proposed method’s robustness in the low data regime which is known as very challenging for deep generative models.
SP:b4b8e1727f8617894f10f20365cb68de79f0e650,"This paper proposes a new transformer architecture called Transformer with a Mixture of Gaussian Keys (Transformer-MGK) that replaces redundant heads in transformers with a mixture of keys at each head. These mixtures of keys follow a Gaussian mixture model and allow each attention head to focus on different parts of the input sequence efficiently. Compared to its conventional transformer counterpart, the proposed Transformer- MGK accelerates training and inference, has fewer parameters, and requires less FLOPs to compute while achieving comparable or better accuracy across tasks."
SP:82731dcce233e748f63382e09b6224a513fe9689,"This paper proposes a method to fuse image and action related signals in order to solve the problem of navigation in a two-dimensional continuous environment. The proposed method is based on a recurrent neural network (RNN) that is trained to keep track of its position relative to its starting point during a sequence of movements. The RNN updates its internal state using the (possibly noisy) self-motion signal, and occasionally resets it when the image signal is present. The internal state of this minimal model exhibits strong correlation with position in the environment due to the direct-inverse models, is stable across long trajectories through resetting, and allows for disambiguation of visually confusing positions through integration of past movement."
SP:1a27c397d1e73def5e724c5c6f25548975ba50fa,"This paper studies the effect of structure of the input distribution on the performance of neural networks. Specifically, the authors consider a setting where the labels are determined by a set of class-relevant patterns and the inputs are generated from these patterns along with some background patterns. They prove that neural networks trained by gradient descent can succeed on these problems. The success relies on the emergence and improvement of effective features, which are learned among exponentially many candidates efficiently by exploiting the data (in particular, the structure of input distribution). In contrast, no linear models on data-independent features of polynomial sizes can learn to as good errors. Furthermore, if the specific input structure is removed, no polynomials algorithm in the Statistical Query model can learn even weakly. "
SP:8ada73ed7eade9ebdeef376485e849c42575bc5f,"This paper studies the robustness of feature extractors to adversarial perturbations. In particular, the authors consider the linear feature extractor and propose an algorithm to find collisions between adversarially perturbed examples at deeper layers. The authors show that for linear features, the algorithm is closed-form, and for arbitrary features, they propose a bespoke algorithm based on the iterative solution of a convex program that provably finds collisions. Finally, they use the bounds to identify layers of robustly trained models that contribute the most to a lack of robustness."
SP:874b5fa51924cbcceed490d98a0ea80f74586b32,"This paper proposes a new offline reinforcement learning method, Value-based Episodic Memory (VEM), which learns the V-function instead of the Q-function to naturally keep the learning procedure within the offline dataset. The authors propose Expectile V-Learning (EVL), which interpolates between the optimal value learning and behavior cloning, and introduce implicit planning along offline trajectories to enhance learned V-values and accelerate convergence. They provide theoretical analysis for the convergence properties, and empirical results in the D4RL benchmark show that the proposed method achieves superior performance in most tasks."
SP:34f08d92681504490c2f739b0d08f79f9764b2f5,"This paper proposes a novel adversarial training framework that learns to reweight the loss associated with individual training samples based on a notion of class-conditioned margin, with the goal of improving robust generalization. Inspired by MAML-based approaches, the authors formulate weighted adversarial learning as a bilevel optimization problem where the upper-level task corresponds to learning a robust classifier, and the lower-level function corresponds to learn a parametric function that maps from a sample’s multi-class margin to an importance weight. Extensive experiments demonstrate that the approach improves both clean and robust accuracy compared to related techniques and state-of-the-art baselines."
SP:3ad36be6b6900aabe43da043461cf178ce977082,"This paper proposes a new type of equivariant graph neural network, called steerable E(3) Equivariant Graph Neural Networks (SEGNNs) that can incorporate geometric and physical information in both the message and update functions. Specifically, the authors define steerable node attributes and MLPs that provide a new class of activation functions for general use with steerable feature fields. The authors demonstrate the effectiveness of their method on several tasks in computational physics and chemistry."
SP:8928aa83f7ebd4e310f4fe1d01ff0eb0c96e4d2b,"This paper proposes a new differentiable physics model for cloths. The model is based on a differentiable model of the interaction between different types of forces, such as friction, shear, etc. The main contribution of this paper is the introduction of differentiable forces that are differentiable at different levels of granularity. The authors show that the model can be used to solve inverse problems, provide high data efficiency, and capture subtle dynamics."
SP:2c8358c095b10981d3015b9f6c75765419a9480d,"This paper proposes a method for efficient transfer learning in reinforcement learning. The method is based on the logical composition framework of Nangue Tasse et al. (2020) and leverages the Boolean algebra framework to determine which skills should be reused in a new task. The authors provide theoretical results on the performance of the transferred policy and the necessary and sufficient number of tasks that need to be learned throughout an agent’s lifetime to generalize over a distribution. They verify their approach in a series of experiments where they perform transfer learning both after learning a set of base tasks, and after learning an arbitrary set of tasks."
SP:c85d71d05164d019cc32bf423e4c4fe20c169f41,"This paper proposes LightWaveS, a distributed solution for multivariate time series classification (MTSC) based on a wavelet scattering transformation of the time series and distributed feature selection. The main contribution of the paper is to propose a solution that employs just 2,5% of the ROCKET features, while achieving accuracy comparable to recent deep learning solutions. The paper also shows that the proposed method scales well with more nodes and large numbers of channels. "
SP:db43614ca016280a79448f44a97c81c8ff5ba981,This paper proposes a novel approach to pretraining text encoders with an adversarial learning curriculum via a Mixture of Signals (AMOS) approach. The main idea is to use auxiliary masked language models (MLMs) of different sizes to provide training signals at various levels of difficulty to push the discriminator to learn better with challenging replaced tokens. The weights of the mixtures are learned to maximize the training signals difficulty by backpropagating the gradient from the discriminators via Gumbel-Softmax. AMOS outperforms ELECTRA and recent state-of-the-art pretrained models by about 1 point on GLUE and SQuAD benchmarks. 
SP:db3825633ab5d0671340390b23ab655838cc38b2,"This paper proposes an adaptive fine-tuning method for cloze-style relational fact extraction. The main idea is to fine-tune a pre-trained language model on the standard fill-mask task using a small training dataset of existing facts from a knowledge graph. The authors evaluate their method on the LAMA probe and show that it outperforms baselines, even with significantly fewer training facts. They also analyze the transfer learning capabilities of this adapted language model by training on a restricted set of relations to show that even fewer training relations are needed to achieve high knowledge extraction quality."
SP:ae25d32714b2b9f7e02cc20f4a36252e20e78e4f,"This paper proposes to learn the embeddings of knowledge bases in different geometric spaces and apply manifold alignment to align the shared entities. The proposed method is evaluated on the out-of-taxonomy entity typing task, where the goal is to predict the types of the entities from the knowledge graph. Experimental results on two datasets based on YAGO3 demonstrate that the approach has significantly good performances, especially in low dimensions and on small training rates."
SP:9ab3bc525ee4a9c96518c43e4c43082655a7674f,"This paper proposes a one-shot learning framework for link prediction in temporal knowledge graphs. The proposed method employs a self-attention mechanism to effectively encode temporal interactions between entities, and a network to compute a similarity score between a given query and a (one-shot) example. The experiments show that the proposed algorithm outperforms the state-of-the-art baselines for two well-studied benchmarks."
SP:91f92a40e12afd0702f07ae7f4175ecce57b7007,"This paper proposes Progressive Module Networks (PMN), a multi-task learning method that learns a module for each task as a neural module that calls existing modules (solvers for simpler tasks) in a functional program-like manner. Lower modules are a black box to the calling module, and communicate only via a query and an output. PMN is tested on a set of visual reasoning tasks, and demonstrates improved performance in all tasks. "
SP:de33b02e7f2faec5bcae9a5516721aa1ef190572,"This paper proposes a method to improve the parameter efficiency of CNNs by rewiring the convolutional filters to be more channel-selective. The method is based on the fact that the identity connection in a CNN can preserve the information preserving nature of the input features. The authors propose to do this by either pruning unimportant channels and then re-wiring them, or by re-initializing the pruned parameters to the important channels. Experiments are conducted on CIFAR-10 and ImageNet to demonstrate the effectiveness of the proposed method. "
SP:2d80fa4bc440061be2234b5070503d3fa056baed,"This paper studies the problem of learning a binary classifier only from positive data and unlabeled data (PU learning). The authors propose a method to partially identify the classifier. The proposed algorithm learns a scoring function that preserves the order induced by the class posterior under mild assumptions, which can be used as a classifier by setting an appropriate threshold. Through experiments, the method outperforms previous methods for PU learning on various real-world datasets."
SP:5f312626b0613d2e07c59214c5f00db208a98717,This paper proposes to use the cosine similarity between gradients of tasks as an adaptive weight to detect when an auxiliary loss is helpful to the main loss. The authors show that their approach is guaranteed to converge to critical points of the main task and demonstrate the practical usefulness of the proposed algorithm in a few domains. 
SP:e270ae3eeb7ab4fa91ba37d4d68ce10f2fa0a3b5,"This paper proposes a geometric framework to analyze the high-dimensional geometry of adversarial examples. It shows that for low-dimensional data manifolds embedded in high dimensional space, there are many directions off the manifold in which to construct adversarial perturbations. The paper also shows that a tradeoff between robustness under different norms, adversarial training in balls around the data is sample inefficient, and sufficient sampling conditions under which nearest neighbor classifiers and ball-based adversarial learning are robust. "
SP:e07d948a79d478ecd23a0a4406d4ddd3ac5e3be3,"-VAE is a method for learning discrete representations of time series. The method is based on the idea of discrete dimensionality reduction and deep generative modeling. In particular, the authors propose to use a Markov model in the representation space to allow for a probabilistic interpretation of the learned representations. The authors also introduce a gradient-based version of the traditional self-organizing map algorithm to overcome the non-differentiability in discrete representation learning. The proposed method is evaluated on static MNIST data, a chaotic Lorenz attractor system and a real world medical time series application."
SP:5915ee71ea58dbdbafa31c1ad291d1e5940a0cf4,"This paper investigates the properties of multidimensional probability distributions in the context of latent space prior distributions of implicit generative models. The authors show that the distribution mismatch can be eliminated completely by a proper choice of the latent probability distribution or using non-linear interpolations. They prove that there is a trade-off between the interpolation being linear, and the latent distribution having even the most basic properties required for stable training, such as finite mean. They also provide a general method of creating nonlinear interpolation that is easily applicable to a large family of commonly used latent distributions."
SP:19b63ca635712f1509ca6e0141303c192f2709e0,"This paper proposes a method to learn the parameters of shallow neural networks in hyperbolic space. The main idea is to use the geometry of embedding of object representations to reduce the number of parameters of the network without changing the geometry. In particular, the authors propose to use a hyperboloid model to represent the embeddings of the neural network. The authors show that the proposed method can achieve better performance on a variety of tasks."
SP:f6049e9f80a63c9306c1cebcb6b229aa6da44ddc,"This paper studies the problem of DNN fingerprinting attacks that exploit cache side-channels. The authors define the threat model for these attacks: the attacker runs a co-located process on the host machine where the victim’s deep learning (DL) system is running and passively monitors the accesses of the target functions in the shared framework. They introduce DeepRecon, an attack that reconstructs the architecture of the victim network using the internal information extracted via Flush+Reload, a cache side channel technique. They demonstrate that an attacker can accurately reconstruct two networks (VGG19 and ResNet50) having observed only one forward propagation. Based on the extracted architecture attributes, the attacker can also build a meta-model that accurately fingerprints the architecture and family of the pre-trained model in a transfer learning setting. Finally, they propose and evaluate new framework-level defense techniques that obfuscate our attacker's observations."
SP:6a3dd89db6c24a1f98e8866ef0a4c1c2c1ec6635,"This paper proposes a hierarchical network model for video prediction. The model is inspired by the feedforward, feedback and lateral recurrent circuits in the mammalian hierarchical visual system. It assumes that spatiotemporal memories are encoded in the recurrent connections within each level and between different levels of the hierarchy. The network learns by comparing the incoming signals with its prediction, updating its internal model of the world by minimizing the prediction errors at each level. "
SP:fb74e57f35666742caf651e6da33b5defcf259a8,"This paper proposes a method to compute continuous embeddings for kmers from raw RNA-seq data, in a reference-free fashion. The authors show that their model captures information of both DNA sequence similarity as well as DNA sequence abundance in the embedding latent space. They confirm the quality of these vectors by comparing them to known gene sub-structures and report that the latent space recovers exon information. Furthermore, they show that this latent space allows the detection of genomic abnormalities such as translocations and patient-specific mutations."
SP:03aca6ff6a7f0ad2d5ccbcb15ed9536e305a9880,"This paper proposes a method to compress CNNs by first training a continuous embedding on a representation of the architecture and then performing gradient descent to determine an optimal architecture for the given task. The proposed method first compresses the network and then performs gradient descent in continuous space to optimize a compression objective function that maximizes accuracy and minimizes parameter count. The final continuous feature is then mapped to a discrete architecture using the decoder. Experiments are conducted on CIFAR-10/100, FMNIST, SVHN, and Cifar-10."
SP:0511b5d10a90e3fe814e2d35208b4a987894ea62,"This paper proposes a new method for planning and learning in the offline setting where the agent needs to continually act and learn in the world. The method builds on the synergistic relationship between local model-based control, global value function learning, and exploration. The authors study how local trajectory optimization can cope with approximation errors in the value function, and how approximate value functions can help reduce the planning horizon and allow for better policies beyond local solutions. Finally, the authors demonstrate how trajectory optimization is used to perform temporally coordinated exploration in conjunction with estimating uncertainty in value function approximation."
SP:771494fda4702cd8c7efbf225b19028f91b449b9,"This paper proposes a zero-shot dual machine translation method for low-resource languages. It builds on the multi-language NMT framework of Johnson et al. (2016) and uses reinforcement learning to leverage the duality of the machine translation task. Experiments on the UN corpus show that the proposed method outperforms the LSTM-based unsupervised NMT system proposed in (Lample et al., 2018b) on the en-to-en task, while it outperforms LSTMs-based and Transformers-based NMT systems."
SP:1558dc03f99670f9ddccdca9c223a2baf962d438,"This paper criticizes the IRGAN, a generative adversarial network (GAN) framework that is based on the information retrieval framework. The paper points out that the generator of IRGAN is useless after training, and the discriminator is useless. The authors propose a co-training method to improve the performance of the generator. "
SP:6a13dda852ab075a3c0fb691476d6dc57919c729,"This paper proposes a variational auto-encoder (VAE) based method to induce sparsity in the latent space of VAEs, allowing approximate variational inference with arbitrarily complicated and probabilistic sparse coding models. The authors derive a lower bound which is of clear interpretation and efficient to estimate and optimise, as the ELBO of a standard VAE. With the resulting encoders, they recover efficient sparse codes, which proved to be optimal learning inputs in standard classification benchmarks and exhibit good interpretation in the generated observations."
SP:06a22143186fa2948fbe324ccae96a62ff12064e,"This paper proposes a non-adversarial feature matching-based approach to train generative models. The approach, Generative Feature Matching Networks (GFMN), leverages pretrained neural networks such as autoencoders and ConvNet classifiers to perform feature extraction. The experimental results demonstrate that, due to the expressiveness of the features from pretrained ImageNet classifier, even by just matching first order statistics, the approach can achieve state-of-the-art results for challenging benchmarks such as CIFAR10 and STL10."
SP:2d7cf2f07a27d6c8e304a1b47c25387ad2e4432d,"This paper studies the expressive power of graph neural networks (GNNs) for graph representation learning. The authors provide a theoretical framework for analyzing the expressiveness of GNNs to capture different graph structures. They show that the discriminative power of popular GNN variants, such as Graph Convolutional Networks (GCN) and GraphSAGE, cannot learn to distinguish certain simple graphs. Then, they develop a simple architecture that is provably the most expressive among the class of Graph Neural Networks and is as powerful as the Weisfeiler-Lehman graph isomorphism test. They validate their theory via experiments on graph classification datasets."
SP:51126f2dd37ce57d2614c9044ede1e43627f0829,"This paper proposes a method for interpretable continual learning (ICL) that uses saliency maps to provide explanations of previously performed tasks and proposes a new metric to assess their quality. The main idea is to generate a good explanation of a finished task, then use this to focus attention on what is important when facing a new task. Experiments show that ICL achieves state-of-the-art results in terms of overall continual learning performance and explanations."
SP:27a565b3e5442b93d208652784051e640b0c1bfe,"This paper proposes a new evaluation framework for adversarial attacks on neural sequence-to-sequence (seq2seq) models taking the meaning preservation into account. The authors propose a new constraint for attacks on word-based MT systems and show, via human and automatic evaluation, that they produce more semantically similar adversarial inputs. Furthermore, they show that performing adversarial training with meaning-preserving attacks is beneficial to the model in terms of adversarial robustness without hurting test performance."
SP:54ddd8132bf9e4259d2c2d72b348d2bb5f9e227c,"This paper proposes a method to improve the performance of reinforcement learning algorithms by combining the policies using original rewards and inverse (negative) rewards. The authors prove the convergence of the inverse policies and propose a hybrid policy based on deep Q-learning, double-Q-learning and on-policy actor-critic. Experiments are conducted on the CartPole and Pendulum environments. "
SP:89a732b57934d08b937c93560f391b7758e54f8a,"This paper proposes a method for learning a hierarchical, disentangled object representation and a dynamics model for object parts from unlabeled videos. The model learns to recognize the object parts via a layered image representation, predict hierarchy via a structural descriptor that composes low-level concepts into a hierarchical structure, and model the system dynamics by predicting the future. Experiments on multiple real and synthetic datasets demonstrate that the proposed method works well on all three tasks: segmenting object parts, building their hierarchical structure and capturing their motion distributions."
SP:bb2a655d67bed9da43f0b8ec7d888b89c217d12e," generative classifiers have been largely dismissed for full-supervised classification settings as they are often substantially outperformed by discriminative deep classifiers (e.g., softmax classifiers). In this paper, the authors propose a novel inference method, Deep Determinantal Generative Classifier (DDGC), which can obtain a more robust decision boundary under any softmax neural classifier pre-trained on noisy datasets. The main idea of DDGC is inducing a generative classification classifier on top of hidden feature spaces of the discriminatively deep model. By estimating the parameters of the classifier using the minimum covariance determinant estimator, DDGC can significantly improve the classification accuracy, with no re-training of the deep model nor changing its architectures. The authors also show that DDGC not only generalizes well from noisy labels, but also is robust against adversarial perturbations due to its large margin property."
SP:0fa525cc708470b757a60117cb608bb2feaa2c50,"This paper proposes a model-free method for subgoal discovery using incremental unsupervised learning over a small memory of the most recent experiences of the agent. This method learns subgoals and skills together, based on experiences in the environment. The proposed method is evaluated on a variant of the rooms environment and the ATARI game called Montezuma's Revenge."
SP:e5861538bc8bb9165cb33299bbf12dd875abf976,"This paper proposes a method to solve the Circuit Satisfiability problem (aka Circuit-SAT), which is an NP-complete combinatorial optimization problem. The authors propose a neural framework that can learn to solve this problem from data. The proposed method is built upon two contributions: a rich embedding architecture that encodes the problem structure, and an end-to-end differentiable training procedure that mimics Reinforcement Learning. The experimental results show the superior out-of-sample generalization performance of the proposed method compared to the NeuroSAT method."
SP:ff3e5d44619df3825632b0b1a943add081364861,"This paper proposes to combine the Cross-Entropy Method (CEM) with Deep Deterministic Policy Gradient (DDPG) and TD3 to improve the sample efficiency of policy search in deep RL. CEM-RL is a combination of CEM, TD3, and DDPG. The authors show that CEM is more sample-efficient than the other methods in terms of performance and sample efficiency. They also show that it is competitive with the state-of-the-art. "
SP:78b2eb326695da0b0cc4ba39a9206d11644a5e32,This paper proposes a multi-variate LSTM recurrent neural network (IMV-LSTM) for time series with exogenous variables. The main idea is to learn a hidden state matrix and update process to learn variables-wise hidden states. A mixture attention mechanism and associated summarization methods are proposed to quantify the temporal and variable importance in data. Extensive experiments using real datasets demonstrate the prediction performance and interpretability of the proposed model.
SP:1c26660569b579f060f7b4a31e321c6d2356b928,"This paper proposes feature smoothing, a simple data augmentation method with little computational overhead to defend against adversarial attacks. The proposed method trains a neural network on virtual training data as an interpolation of features from a pair of samples, with the new label remaining the same as the dominant data point. The experiments on MNIST and CIFAR10 datasets explore different combinations of known regularization and data augmentations methods and show that the proposed method performs best for both adversarial and clean accuracy. "
SP:88d652f9e411dd3a2e9ad651d9011e579653c6aa,"This paper proposes a theoretical framework for explaining deep neural networks with ReLU nonlinearity. The framework is built upon teacher-student setting, by projecting the student's forward/backward pass onto the teacher's computational graph. This framework bridges data distribution with gradient descent rules, favors disentangled representations, and is compatible with common regularization techniques such as Batch Norm. "
SP:7842bbe0e2324cfd732db8745550733ccc3dfcdc,"This paper proposes a modular architecture of neural networks with a Behavioral Module (BM) and corresponding end-to-end training strategy. This approach allows efficient learning of behaviors and preferences representation. This property is particularly useful for user modeling (as for dialog agents) and recommendation tasks, as allows learning personalized representations of different user states. In the experiment with video games playing, the proposed method allows separation of main task’s objectives and behaviors between different BMs. The experiments also show network extendability through independent learning of new behavior patterns. Moreover, the authors demonstrate a strategy for an efficient transfer of newly learned BMs to unseen tasks."
SP:300c391ff644b6889cd9ae27cf0d162dfcdd4451,"This paper proposes a method for training neural networks with neuromodulated plasticity. The method is based on the differentiable Hebbian plasticity framework (Miconi et al., 2017; Miconi, 2016; Wang et al. 2018), which allows the network to control its own weight changes. The authors show that their method can be used to improve the performance of neural networks on both reinforcement learning and supervised learning tasks. They also show that the method outperforms non-plastic LSTMs on a language modeling task."
SP:1ab5d94d31e99351433436c026799c8aa597bf73,"This paper proposes an iterative quantization technique to reduce the inference latency/memory consumption of deep neural networks. The method is based on re-training the full precision model, followed by directly optimizing the corresponding binary model. The quantization training process takes no longer than the original training process. The authors also propose a new loss function to regularize the weights, resulting in reduced quantization error. Experiments on CIFAR and WikiText-2 show the effectiveness of the proposed method."
SP:0876b1d9a6d664808ca1ab15865679fbf638267e,"This paper proposes a method for the open-ended recombination of style of one image with the content of another. The method starts by constructing a content embedding using an existing deep metric-learning technique. The trained content encoder is incorporated into a variational autoencoder (VAE) paired with a to-be-trained style encoder. The VAE reconstruction loss alone is inadequate to ensure a decomposition of the latent representation into style and content. The authors propose an auxiliary loss, leakage filtering, which ensures that no style information remaining in the content representation is used for reconstruction and vice versa. The proposed method is evaluated on few-shot learning tasks."
SP:d37e15cde7765fca87595a242f0a4511b3346d46,"This paper studies the problem of state-action permissibility (SAP) in the context of reinforcement learning. In particular, the authors propose to use the property of SAP to guide the exploration of deep reinforcement learning algorithms. Specifically, they define two types of SAP: one that says that after an action at is performed in a state and the agent reaches the new state st+1, the agent can decide whether the action is permissible or not permissible in state st. The second type says that even without performing the action at in state s, an agent can already decide whether at is permitted or not permitted in s. The authors propose a method to incorporate the proposed SAP property into two state-of-the-art deep RL algorithms to guide their exploration. "
SP:20015d8b60e13300586b67c281858cbe28825c48,"This paper studies the behavior of weight-tied multilayer vanilla autoencoders under the assumption of random weights. Via an exact characterization in the limit of large dimensions, the analysis reveals interesting phase transition phenomena when the depth becomes large. This provides quantitative answers and insights to three questions that were yet fully understood in the literature. "
SP:91764f80dbe2401ade38b35a8253ba05f0f86386,"This paper proposes SimBA, a simple black-box adversarial attack that takes small steps iteratively towards the decision boundary. SimBA randomly picks a low frequency component of the discrete cosine transform (DCT) and either adds or subtracts it to the target image. The proposed method can be used for targeted and untargeted attacks, resulting in previously unprecedented query efficiency in both settings. The paper also provides some theoretical insight on the efficacy of the approach and evaluate various orthogonal search subspaces."
SP:fc20ae0fbf57a1ce489c04b85c7c2f4c93dc2450,"This paper proposes a method for option discovery in hierarchical reinforcement learning. The method is based on clustering the state embeddings of a set of sub-samples of the original set of options. The clustering is done by finding a subset of states that are close to each other in the set of original options. Then, a pseudo-reward is proposed to encourage the clustering of the options. Experiments are conducted on grid worlds and deepmind-lab environments."
SP:12a172c1e2892d016b37932acfc48dcb56874a89,"This paper studies the problem of domain division, which aims to segment instances drawn from different probabilistic distributions. In particular, this paper proposes a domain division algorithm to split the testing instances into known, unknown and uncertain domains, and then conduct recognition tasks in each domain. Two statistical tools, namely, bootstrapping and Kolmogorov-Smirnov (K-S) Test, are introduced to uncover and fine-tune the decision boundary of each domain, for the first time. The experimental results demonstrate that the proposed method achieves the state-of-the-art performance on OSL and G-ZSL benchmarks."
SP:28bcf7c6a4673e9ec2b4ebed09839d85188e0b2a,"This paper proposes polar prototype networks, a neural network that explicitly states the layout of the output. The structure is defined by polar prototypes, points on the hypersphere of the input space. For classification, each class is described by a single polar prototype and they are a priori distributed with maximal separation and equal shares. For regression, training can be performed as a polar interpolation between two prototypes, arriving at a regression with higher-dimensional outputs. "
SP:d1034342785d133cf8372b8624897963cc2ee83a,This paper proposes a reward learning algorithm based on Maximum Causal Entropy IRL (MCE IRL) that uses the state of the world at initialization as a source of information about human preferences. The authors show that the initial state can be used to infer both side effects that should be avoided as well as preferences for how the environment should be organized. The algorithm is evaluated in a suite of proof-of-concept environments designed to show its properties.
SP:417a4e0acee699b3e004ad30d0ecf533a9ed987e,"This paper proposes a method for learning the dependency structure between latent variables in deep latent variable models. The method is based on a variational autoencoder (VAE) with a learned dependency structure. Inference is formulated via a sampling procedure that produces expectations over latent variable structures and incorporates top-down and bottom-up reasoning over latent variables. Experiments are conducted on MNIST, Omniglot, and CIFAR-10 to demonstrate the effectiveness of the method."
SP:976dedab53e69610692a563382ada1dbb82c1e9d,"This paper proposes a dynamical neural network for solving dictionary learning problems. The proposed method is based on top-down feedback and contrastive learning. The authors show that the true gradients for learning are provably computable by individual neurons. They also provide a learning process, its rigorous mathematical analysis, and numerical results on several dictionary learning problem. "
SP:f45117a6beaeb86a70b1380b4fac3cfba37fb892,This paper proposes a novel CNN-based network for the task of lane detection. The proposed method is based on multiple encoder-decoders module in end-to-end ways and shows the promising results on the CU-Lane dataset. The authors also propose a small quantity of channel to reduce overfitting by considering interdependencies among channels.
SP:68b0a10ca06df74612d0753cc3f3ddddde806035,"This paper proposes Maximum Likelihood Inverse Propensity Scoring (MLIPS) for policy evaluation and optimization in the context of batch contextual bandit learning. The main idea is to estimate a maximum likelihood surrogate policy based on the logged action-context pairs, and then use this surrogate policy as the proposal. Theoretical analysis shows that MLIPS is asymptotically unbiased and has a smaller nonasymptotic mean squared error than the classical inverse propensity scoring (IPS) estimator. Empirical results on multi-label classification problems and a large-scale ad placement dataset demonstrate the empirical effectiveness of MLIPS."
SP:8e0ed65c5dded23b34798499b2436b24422fd729,"This paper proposes a meta-learning method for few-shot classification. The key idea is to learn how to create an individualized feature embedding specific to a given query image for better classifying, i.e., given a query image, a specific feature embeddings tailored for its characteristics is created accordingly, leading to an individualised feature space in which the query image can be more accurately classified. Specifically, the authors introduce a kernel generator as meta-learner to learn to construct feature embedDings for query images. The kernel generator acquires meta-knowledge of generating adequate convolutional kernels for different query images during training, which can generalize to unseen categories without fine-tuning. "
SP:faa3f7ffdcfb6e3b8ec0421193dae3d9987b015c,"This paper proposes a population-based genetic algorithm (GA) for training deep neural networks for reinforcement learning. The authors show that the GA can be used to train DNNs on hard deep RL problems, including Atari and humanoid locomotion. The GA is faster than ES, A3C, and DQN, and it can train Atari in ∼4 hours on one workstation or ∼1 hour distributed on 720 cores. It also enables a state-of-the-art, up to 10,000-fold compact encoding technique."
SP:dfdbe3267a8160f24746884cdf5297993e424231,"This paper proposes a curiosity bonus for reinforcement learning. The novelty bonus is computed by comparing the current observation with the observations in memory. This is done based on how many environment steps it takes to reach the current observations from those in memory, which incorporates rich information about environment dynamics. This allows the agent to overcome the known “couch-potato” issues of prior work — when the agent finds a way to instantly gratify itself by exploiting actions which lead to hardly predictable consequences."
SP:1e58a1c5344d1b5b7c8a40210a243700bd933d65,"This paper presents a method for learning a transition model for complex uncertain domains using relational rules. For any action, a rule selects a set of relevant objects and computes a distribution over properties of just those objects in the resulting state given their properties in the previous state. An iterative greedy algorithm is used to construct deictic references that determine which objects are relevant in any given state. Feed-forward neural networks are used to learn the transition distribution on the relevant objects’ properties. This strategy is demonstrated to be both more versatile and more sample efficient than learning a monolithic transition model in a simulated domain."
SP:8ce00a3fedbf54a7f2c1ff414511cbb7d59b4597,"This paper proposes a novel method for instance-wise feature selection. The proposed method is based on the actor-critic method, where the selector network is trained iteratively to minimize a KL divergence between the full conditional distribution and the selected-features-only conditional distribution of the outcome. Experiments are conducted on both synthetic and real-word data. "
SP:b91d6c33349df0bb6cb7e1c5e9433f0d4744b4da,"This paper proposes a domain adaptation method for structured output prediction by utilizing global and patch-level adversarial learning modules. The global alignment is achieved by the output space adaptation, while the patch level one is performed via learning discriminative representations of patches across domains. The proposed method is based on a clustered space of source patches and adopt an adversarial training scheme to push the target patch distributions closer to the source ones. Extensive ablation study and experiments are conducted to validate the effectiveness of the proposed method."
SP:00922af13a21464cbc4cd7b34c196dd4f86c9247,"This paper proposes a new optimistic algorithm for training deep neural networks based on the observation that mini-batch of stochastic gradients in consecutive iterations do not change drastically and consequently may be predictable. Inspired by the similar setting in online learning literature called OPTIMISTIC ONLINE LEARNING, the authors propose two new optimistic algorithms for AMSGrad and Adam, respectively, by exploiting the predictability of gradients. The new algorithms combine the idea of momentum method, adaptive gradient method, and algorithms in OPTIMISSIBLISTIC OPEILING. The authors also provide theoretical analysis of the proposed algorithm."
SP:52228b48f2776d57dd422edb33b82e247f056b75,"This paper studies the robustness of image classifiers to common common perturbations and corruptions. The authors propose a new benchmark, ImageNet-C, to evaluate robustness to common corruptions and perturbation. They show that there are negligible changes in relative corruption robustness from AlexNet classifier to ResNet classifiers. They also show that a bypassed adversarial defense provides substantial common-perturbation robustness. "
SP:20358ea0f769e6ea9222d8e35159d711ee1b20b2,"This paper shows that dropout training can be understood as performing MAP estimation concurrently for an entire family of conditional models whose objectives are lower bounded by the usual dropout objective. This discovery allows us to pick any model from this family after training, which leads to a substantial improvement on regularization-heavy language modelling. The family includes models that compute a power mean over the sampled dropout masks, and their less stochastic subvariants with tighter and higher lower bounds than the fully-stochastic objective. The deterministic subvariant’s bound is equal to its objective, and the highest among these models. It also exhibits the best model fit in the experiments."
SP:ac1b950ad29429ae045bb5e53279014a6a0b9d2b,"This paper proposes a global soft filter pruning (GSFP) method to prune redundant filters of convolutional neural networks. The proposed method is based on cumulative saliency based global soft pruning, which measures the global redundancy of the filter in the whole model. The authors also propose a normalization formula to prevent certain layers of filters in the network from being completely clipped due to excessive pruning rate. Experimental results show that GSFP is effective on many classic CNN architectures and different data sets."
SP:621e41d4199e333ec7f9d0936d4e34c918f39c11,"This paper proposes a cross-lingual document classification framework (CACO) between related language pairs. The key idea is to jointly train a character-based embedder and a word-based classifier. The embedder derives vector representations for input words from their written forms, and the classifier makes predictions based on the word vectors. The experiments show that CACO can match the accuracy of CLWE-based models without using any target language data."
SP:544e421f9c747640d949f433e3091763508b7237,"This paper proposes a novel method for weakly supervised temporal action localization. The proposed method is based on the marginalized average aggregation (MAA) module and learns a set of latent discriminative probabilities in an end-to-end fashion. MAA samples multiple subsets from the video snippet features and takes the expectation over all the averaged subset features. Theoretically, the authors prove that MAA reduces the gap between the most discriminant regions in the video to the others, and thus MAAN generates better class activation sequences to infer the action locations. The authors also propose a fast algorithm to reduce the complexity of constructing MAA from O(2^2) to O(T^2). Extensive experiments on two large-scale video datasets show that the proposed method achieves a superior performance on weakly-supervised time series action localization task."
SP:9f98c9bac99003741dd14e093b54d692c0b0e8d8,"This paper proposes a method for learning disentangled representations of word-level and chunk-level representations. The method is based on the Holographic Reduced Representation (HRR) framework, which is a decomposition of word and chunk embeddings. The authors show that their method is able to disentangle word- and chunk representations into syntactic and semantic roles, which roughly corresponds to syntax and semantics."
SP:5908b6acfed0e7c51e203c72eba907e6635e6c60,"This paper studies the problem of joint active perception and planning in partially observable Markov decision processes (POMDPs), where the agent has an active role in its perception by selecting which observations to receive. The authors propose a greedy strategy for observation selection that aims to minimize the uncertainty in state. They develop a novel point-based value iteration algorithm that incorporates the greedy strategy to achieve near-optimal uncertainty reduction for sampled belief points. They demonstrate its performance and computational advantage in a range of robotic scenarios."
SP:0adec4abec17b3aab0c6eb69d11925dc20544950,"This paper proposes a new curriculum loss for training deep neural networks. The main idea is to introduce a curriculum loss that consists of two parts: a) an adaptive weight that mitigates large early punishment; b) an additional representation loss for low-weighted samples. The authors claim that the hard examples aggravate the distribution shifting and damages the training. To address this problem, the authors propose to add an additional weight that assigns small values to hard examples, reducing the influence of noisy gradients, while the other part is a representation loss. Experiments are conducted on MNIST, CIFAR-10 and Cifar-100 to show the effectiveness of the proposed method."
SP:8b555b9f24044bc68c204169d6a37e262361d706,"This paper proposes a method to learn heuristic heuristics for combinatorial optimization problems. The proposed method is based on an attention layer, which is trained with REINFORCE. The method is evaluated on the Vehicle Routing Problem (VRP), the Orienteering Problem (OP), the Prize Collecting TSP (PCTSP), and the Travelling Salesman Problem (TSP). The results show that the proposed method outperforms several baselines."
SP:efb76bcf1dbd9a9cf6b5db74b5d4256a9f9e9e73,"This paper proposes a neural architecture search (NAS) method for quantizing convolutional neural networks with different bit-widths. The authors formulate the problem as a neural network search problem and propose a differentiable architecture search method (DNAS) to solve it. The proposed method is based on differentiable neural network supernet, which is a supernet whose macro architecture is the same as the target network. Experiments are conducted on CIFAR-10 and ImageNet to demonstrate the effectiveness of the proposed method."
SP:ea4173f8265bc50296de51c4ee7ecb6b8f78bec0,"This paper proposes a new attention model, called posterior attention, which is based on the joint distribution of the attention and output variables. The authors argue that the current attention models do not adequately model the dependence of the output and attention variables across a predicted sequence. The proposed posterior attention model is motivated by a principled factorization of the full joint distribution and proposes two major changes. First, the position where attention is marginalized is changed from the input to the output, and the attention propagated to the next decoding stage is a posterior attention distribution conditioned on the output. Second, the authors propose a principled way to incorporate task-specific structural biases and prior knowledge into attention. Empirically, the proposed model yields better BLEU score and alignment accuracy than existing attention models. "
SP:987e2c14abc091d4d3ef9b48fb2046408eb1f59e,"This paper proposes a new method for the unpaired image-to-image translation problem. The proposed method is based on a smoothness term over the sample graph to enforce smoothness-consistency between the source and target domains. The method is evaluated on a variety of applications including medical imaging, object transfiguration, and semantic labeling."
SP:885a69003bad0e79cb2872a4e5c772191ad7e34f,"This paper studies the exploding and vanishing gradient problem (EVGP) in recurrent neural networks. The authors propose a simple stochastic algorithm (h-detach) that is specific to LSTM optimization and targeted towards addressing this problem. Specifically, the authors show that when the weights of LSTMs are large, the gradient components through the linear path (cell state) in the computational graph get suppressed. Based on the hypothesis that these components carry information about long term dependencies (which they show empirically), their suppression can prevent LSTm from capturing them. To address this problem, this paper proposes a simple algorithm, which prevents gradients flowing through this path from getting suppressed, thus allowing the LST model to capture such dependencies better. "
SP:9aaff3777321347d1194884af5690b0b5185eff9,"This paper proposes a method for training binary weight neural networks from scratch under the Bayesian deep learning perspective. The posterior distribution is parameterized as a policy network trained with a reinforcement learning scheme. The policy network has a nested parameter structure consisting of layer-wise, filter-wise and kernel-wise parameter sharing designs. The performance of the proposed method is evaluated with several visual recognition tasks including ImageNet."
SP:29d1f6d0661a51e56c59bbb106da56700fc22d9a,"This paper proposes a Bayesian nonparametric framework for federated learning with neural networks. Each data server is assumed to train local neural network weights, which are modeled through the framework. Then, an inference approach is developed to synthesize a more expressive global network without additional supervision or data pooling. Experiments are conducted on two popular image classification datasets."
SP:ab1f2bd216635d63450688866c729a501bd7e9d0,This paper studies the problem of learning in differentiable games. The authors propose a new algorithm called Stable Opponent Shaping (SOS) that interpolates between LOLA and a stable variant named LookAhead. Theoretical convergence guarantees are provided for the proposed algorithm. Experiments are conducted to show the effectiveness of the proposed method. 
SP:bdafb5fca09a775a8c92d2826d5dc977d28091c2,This paper proposes a VAE-based alarm system for segmentation based on the shape feature of the segmentation results. The proposed method is based on VAEs that are trained with ground truth masks. The shape feature is captured using the value of the loss function. The method is evaluated on several recent segmentation algorithms for the medical segmentation task.
SP:60738395d9efe2b3fe3a00c542ebb4261e54386c,"This paper proposes a simple deep decoder network that can generate natural images from very few weight parameters. The network is simple in the sense that each layer has an identical structure that consists of only one upsampling unit, pixel-wise linear combination of channels, ReLU activation, and channelwise normalization. This simplicity makes the network amenable to theoretical analysis, and it sheds light on the aspects of neural networks that enable them to form effective signal representations. "
SP:1c9bad3bd4d670172f65aa0304e9837ecafc6b3d,This paper presents a neural architecture for program synthesis from natural language (NL) specifications. The main idea is to use a pretrained word embedding and a bi-directional multi-layer LSTM for processing word sequences. The decoder features a doubly-recurrent LSTMs and a soft attention mechanism. Experiments show that the proposed method can produce correct programs in over 92% of cases. 
SP:d2ec231bb6153a303e5110e671dea14c2721e636,"This paper studies the problem of adversarial robustness of deep neural networks on MNIST. The authors show that even the widely recognized and by far most successful L∞ defense by Madry et al. (1) has lower L0 robustness than undefended networks and is still highly susceptible to L2 perturbations, classifies unrecognizable images with high certainty, performs not much better than simple input binarization, and features adversarial perturbation that make little sense to humans. They present a novel robust classification model that performs analysis by synthesis using learned class-conditional data distributions. They derive bounds on the robustness and go to great length to empirically evaluate our model using maximally effective adversarial attacks by (a) applying decision-based, score-based,. gradient-based and transfer-based attacks for several different Lp norms, (b) by designing a new attack that exploits the structure of our defended model and (c) by devising a novel attack that seeks to minimize the number of perturbed pixels (L0)."
SP:91a24e7f4b952c37441feab4a7e8555014c856a4,"This paper proposes a reparameterization approach for weight matrices of the discriminator in GANs, which allows us to directly manipulate the spectra of the weights matrices through various regularizers and constraints, without intensively computing singular value decompositions. Theoretically, this paper shows that the spectrum control improves the generalization ability of GAN. Experiments on CIFAR-10, STL-10 and ImgaeNet datasets confirm that the proposed method is capable of generating images with competitive quality."
SP:8115fd9b681198d62100c36794926fb57dc0a4f5,This paper proposes Anderson accelerated value iteration (A2VI) to accelerate the value iteration in reinforcement learning. A2VI is based on Anderson accelerated policy iteration (AXPI) and the Anderson accelerated Q-learning (DA2Q) algorithm. The authors provide convergence analysis of the proposed method under certain conditions. Empirical results on toy problems and Atari games validate the effectiveness of the method. 
SP:bd79b0c0af778a36008a0c0cf2fb6393fd2789d4,"This paper proposes a class incremental learning (CIL) method to solve the catastrophic forgetting problem. The proposed method is based on SVM to identify the support data from the old data, which are fed to the deep learning model together with the new data for further training. Two powerful consolidation regularizers are applied to stabilize the learned representation and ensure the robustness of the learned model. Experiments are conducted to validate the effectiveness of the proposed method."
SP:d228d213f79716774043cea253305fecece659ec,"This paper compares four different measures of unit selectivity on AlexNet, namely localist selectivity, precision, CCMAS, top-class selectivity and activation maximization (AM) images. The authors find that AlexNet does not have any localist representations, and the interpretable images in the hidden layers are not associated with highly selective units. They also show that the precision and CCMAS measures provide a much higher level of selectivity than is warranted. "
SP:b9deae0392e0160b400d76c549d382e235196f8c,"This paper studies the problem of node-wise community detection in graphs. The authors propose a novel family of graph neural networks (GNNs) for solving community detection problems in a supervised learning setting. They show that, in a data-driven manner and without access to the underlying generative models, they can match or even surpass the performance of the belief propagation algorithm on binary and multiclass stochastic block models, which is believed to reach the computational threshold in these cases. In particular, they propose to augment GNNs with the non-backtracking operator defined on the line graph of edge adjacencies. They also provide a theoretical analysis of the optimization landscape of simplified linear GNN for community detection."
SP:a9ed31090e55f6152fc31c7512af5d634cc7225a,"This paper proposes an online dictionary learning algorithm that recovers both the dictionary and coefficients exactly at a geometric rate, when initialized appropriately. The algorithm is based on an iterative hard thresholding (IHT)-based update step, alternating between this IHT-based update for coefficients, and a gradient descent-based step for the dictionary. Theoretical analysis is provided to show that the proposed algorithm has linear convergence to the true factors, and is scalable and amenable for large scale distributed implementations in neural architectures. Experiments are conducted on synthetic and real-world data."
SP:85232b72a2643d6dc81cf952ccbb95192032b7c5,This paper proposes a new loss function and training scheme for learning binary hash codes with any differentiable model and similarity function. The loss function improves over prior methods by using log likelihood loss on top of an accurate approximation for the probability that two inputs fall within a Hamming distance target. The training scheme obtains a good estimate of the true gradient by better sampling inputs and evaluating loss terms between all pairs of inputs in each minibatch. The authors demonstrate that these techniques provide large improvements to a similarity search tasks.
SP:3bd4ccff7f48380d2db8dff2c4ca515894a7f1db,"This paper proposes a method for neural architecture search (NAS) that generates the weights of any architecture by running inference on a graph neural network (GHN). The GHN model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, the authors randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast – they can search nearly 10x faster than other random search methods on CIFAR-10 and ImageNet. They can be further extended to the anytime prediction setting."
SP:65ccf43cd4e033d22239069057f5200d49f33724,"This paper proposes a method for imitation learning that uses non-expert demonstrations as an extra class in discriminator learning. Specifically, the discriminator is trained with a discriminator that is trained to discriminate between expert and non-experts demonstrations. The discriminator function is learned by minimizing the KL divergence between the two classes of demonstrations. Experiments show that the proposed method is able to outperform the baselines when the number of expert demonstrations is small. "
SP:e8427949a98effbd37ce7604fa11f240e2342196,"This paper studies the problem of learning the posterior distribution of the forward process conditioned on a set of measurements. The authors propose a neural network architecture, called Invertible Neural Networks (INNs), that is able to learn the posterior over the measurement space. The INN is based on a forward process that is invertible, i.e., the output of the INN has to be the same as the true posterior. The paper provides a theoretical justification for why this is a good model for this problem. In particular, the paper shows that the posterior can be learned implicitly, and that the inverse pass of an INN provides the full posterior over parameter space. Finally, the method is applied to two real-world problems from medicine and astronomy."
SP:75c9bb53bac29bdb390f9ba5707caee4ab1f5925,"This paper proposes a new method for quantifying the uncertainty of neural network predictions. The proposed method is based on a mixture density network (MDN), which is a finite mixture model with uniform mixing weights. The authors propose to replace the mixing weights by an adaptive, input-dependent distribution (specifying the probability of each component) represented by an NN and by considering uncountably many mixture components. The resulting model can be seen as the continuous counterpart to mixture density networks and is therefore referred to as compound density networks (CDNs). The authors empirically show that the proposed model results in better uncertainty estimates and is more robust to adversarial examples than previous approaches."
SP:e1e38289285c1b8fdb318e4f6d37a198a08787a2,"This paper proposes a method to compress the weights of a neural network by using a variational distribution over weights. The proposed method is based on the bits-back argument, where the weights are encoded using a random sample, and the number of bits corresponding to the Kullback-Leibler divergence between the sampled distribution and the encoding distribution is used to control the compression rate, while optimizing the expected loss on the training set. The method is shown to be close to the optimal information-theoretical lower bound, with respect to the employed variational family. "
SP:ad70d8cf3a4558aab0d3b7155594464a3debd912,"This paper proposes ProxylessNAS, a differentiable neural architecture search method that directly learns the architectures for large-scale target tasks and target hardware platforms. The main idea is to remove the restriction of repeating blocks in previous proxy-based NAS works and allow all of the specified blocks to be learned. The proposed method is evaluated on CIFAR-10 and ImageNet. "
SP:e5b70d43d301d1980fae02623ea711976b429c14,"This paper proposes to modify the linear penalties to second-order penalties in the Lagrangian dual of a convex optimization problem with additive linear penalties. The authors argue that this modification results in a more practical training procedure in non-convex, large-data settings. In addition, the authors derive a method for efficiently computing the gradients associated with the second order penalties in stochastic mini-batch settings. The resulting algorithm performs well empirically on a number of benchmarks."
SP:e4720b8e4efdb222c45eafd47fd8a7fbf15d881d,"This paper revisits the reweighted wake-sleep (RWS) algorithm for learning discrete latent-variable models. The authors show that RWS outperforms current state-of-the-art methods for discrete latent variable models. They also show that, unlike the importance weighted autoencoder, RWS learns better models and inference networks with increasing number of particles."
SP:7459ae5b1d886e68930c4c9e21df508bc8ab3c9a,"This paper proposes a method for training structured prediction energy networks (SPENs) with a reward function. The reward function is defined as a scalar function, which can be constructed from human-written functions or complex non-differentiable pipelines. The authors propose to use truncated randomized search in this reward function to train SPENs, which provides efficient test-time inference using gradient-based search on a smooth, learned representation of the score landscape. The proposed method, SG-SPEN, is based on the idea of sampling from the reward function through randomized search, which is used to generate informative optimization constraints to guide gradient-descent inference toward finding better prediction according to the reward. The experiments show that the proposed method outperforms previous state-of-the-art baselines."
SP:638c1bc09992029b78bd83f0127594dcccb96c06,"This paper studies the problem of learning policies that do not degrade in performance when subject to unseen environment model parameters. The authors propose an active learning based framework, EffAcTS, to selectively choose model parameters for this purpose so as to collect only as much data as necessary to select such a subset. They apply this framework to an existing method, namely EPOpt, and experimentally validate the gains in sample efficiency and the performance of our approach on standard continuous control tasks. "
SP:491c239713a6489f0b1790ca26db54a1813c67ae,"This paper proposes a two-timescale network (TTN) architecture for policy evaluation with non-linear function approximation. The main idea is to learn a linear value function with a slow learning process for adapting features and a fast process for learning a linear function. The authors prove convergence of the fast linear component under potentially dependent features provided by the learned representation. They empirically demonstrate the benefits of TTNs, compared to other nonlinear value function approximation algorithms. "
SP:327d606cf3813b00a009a7785e08ef9e11f89493,"This paper proposes a model-based and model-free reinforcement learning approach, LEArning and Planning with Semantics (LEAPS), which consists of a multi-target sub-policy that acts on visual inputs, and a Bayesian model over semantic structures. When placed in an unseen environment, the agent plans with the semantic model to make high-level decisions, proposes the next sub-target to execute, and updates the model based on new observations. Experiments on House3D show that the proposed approach outperforms strong baselines that do not explicitly plan using semantic content."
SP:d7c26f43bc68d160095b1f50447528843d79edbd,"This paper proposes a method to improve the generalization and explanation ability of the driving system. The method consists of two modules: a perception module and a driving module. The perception module is used for learning easier driving-related perception knowledge, which the authors refer to as ability of pixel level understanding of input including what & where and how far knowledge. The driving module is then used to generate final control commands for difficult driving task. The results of experiments demonstrate the effectiveness of the proposed method."
SP:b6bd98cc70fab97e1245cbb63a42ef89ab7e7ed5,"This paper studies the trade-off between adversarial robustness and generalization. The authors show that adversarially robust classifiers learn fundamentally different feature representations than standard classifiers. They also show that the features learned by robust models tend to align better with salient data characteristics and human perception. Finally, they show that robust models yield clean feature interpolations similar to those obtained from GANs."
SP:9c9275d75cd95b1b82e0cbb1421e3d3ade1ce33a,"This paper proposes a new method for gradient-based training of neural networks that does not rely on back-propagating error gradients. The proposed method, Initialized Equilibrium Propagation (IPP), trains a feedforward network to initialize the iterative inference procedure for Equilibrium propagation. After training, IPP can be used for inference. Experiments on MNIST and CIFAR-10 show the effectiveness of the proposed method."
SP:ac9ea91eb465517de495477cf67bc94d5ed1b0cb,"This paper proposes a zeroth-order stochastic optimization algorithm, ZO-signSGD, which requires only the sign information of gradient estimates but is able to achieve a comparable or better convergence speed than SGD-type algorithms. The convergence rate is proved to be $O(\sqrt{d/T})$ under some mild conditions, where $d$ is the number of optimization variables and $T$ is number of iterations. In addition, the authors analyze the effects of different types of gradient estimators on the convergence of the proposed algorithm, and propose several variants of the algorithm with similar convergence rates. Finally, the paper shows the connection between the proposed method and black-box adversarial attacks in robust deep learning."
SP:5f79b11777f6ef1d70c85418bfc2e4616dd7d960," to reduce the computation efforts of convolutional neural networks. This paper proposes to set a checkpoint in the MAC process to determine whether a filter could terminate early based on the intermediate result. Furthermore, a fine-tuning process is conducted to recover the accuracy drop due to the applied checkpoints. The experimental results show that the proposed method can save approximately 50% MAC operations with less than 1% accuracy drop for CIFAR-10 example model and Network in Network on the Cifar-10 and CifAR-100 datasets."
SP:7801e9c854ad7d960c0d24fda15597af6994c23f,"This paper proposes to exploit temporal dependency in audio data to characterize audio adversarial examples to improve the robustness of automatic speech recognition (ASR) systems against adversarial attacks. Specifically, the authors propose to exploit the temporal dependency property in audio to characterize the adversarial example. The proposed method is compatible with any ASR model and does not require adversarial training or data augmentation. The experimental results show that while four primitive input transformations on audio fail to withstand adaptive attacks, temporal dependency is shown to be resistant to these attacks. "
SP:51830b811a8e39b4f0a5b7609df719e026fac6a1,"This paper proposes to use compositionality in the generator of a generative model to generate images by means of composition. Specifically, the generator is trained to consider objects and their relations explicitly, and generates images by composing individual objects and background. Experiments on several multi-object image datasets show that the generator learns to identify and disentangle information corresponding to different objects at a representational level. "
SP:fb59990b8da0e95d8202383478a456667de60449,"This paper proposes a method for learning disentangled representations from unlabelled images. The method is based on a variational autoencoder (VAE) model that is trained on a reference set of images where the factors of interest are constant. The authors show that the standard variational learning objective can lead to degenerate solutions, and propose an alternative training strategy that exploits adversarial learning. Experiments on feature learning, conditional image generation, and attribute transfer demonstrate the effectiveness of the proposed method."
SP:dbc1983d9b9d72aa14f8e8515d793d2bbde26c9c,"This paper proposes a meta-learning for online learning (MOLe) algorithm that uses expectation maximization, in conjunction with a Chinese restaurant process prior on the task distribution, to learn mixtures of neural network models that are each updated with online SGD. The method’s online assignment of soft task probabilities allows for task specialization to emerge naturally, without requiring task delineations to be specified in advance. The proposed method is evaluated on a suite of challenging simulated robotic tasks including disturbances, environmental changes, and simulated motor failures."
SP:5665e5f006f84927beb0440e145f476e02538077,"This paper investigates the effect of experience replay on parameter lag and recurrent state staleness in distributed reinforcement learning. The authors show that the effects of parameter lag can lead to representational drift and recurrent staleness, which is exacerbated in the distributed training setting. Based on these observations, the authors propose a new training strategy, Recurrent Replay Distributed DQN (R2D2), which achieves state-of-the-art performance on Atari-57 and DMLab-30."
SP:47ace37f31a46d5ee85c283e62ddb71a12f2c5c4,"This paper proposes a hierarchical generative model for modeling coordinated multi-agent trajectory behavior, such as offensive basketball gameplay. The authors propose a hierarchical framework that can capture high-level behavioral semantics in an interpretable and manipulatable way. Their approach is inspired by recent work on leveraging programmatically produced weak labels, which they extend to the spatiotemporal regime. They show how to instantiate their framework to model complex interactions between basketball players and generate realistic multiagent trajectories of basketball gameplay over long time periods. "
SP:1a90cdf028068528b0559e7d44bf26dda20310bd,"This paper proposes a graph-structured variational recurrent neural network (Graph-VRNN) that is trained to infer the current state of the (partially observed) world, as well as to forecast future states. The authors show that their method outperforms various baselines on two sports datasets, one based on real basketball trajectories, and one generated by a soccer game engine. "
SP:8392f04b7265f665ba6d44d297bca245d44b4708,"This paper proposes a method for training a neural network to predict the output of a black-box function. The main idea is to use a differentiable estimator to estimate the function at training time, and then replace the estimator with its concrete black box counterpart at inference time. The method is evaluated on MNIST and CIFAR-10 datasets. "
SP:13fb86de763a0b34ac6fa34ea9dfbd1c476ce43e,This paper proposes a meta-learning method that uses a mixture of hierarchical Bayesian models over the parameters of an arbitrary function approximator such as a neural network. The authors propose a stochastic expectation maximization procedure to jointly estimate parameter initializations for gradient descent as well as a latent assignment of tasks to initializations. This approach better captures the diversity of training tasks as opposed to consolidating inductive biases into a single set of hyperparameters. The experiments demonstrate better generalization performance on the standard miniImageNet benchmark for 1-shot classification. 
SP:a410144dbe19713a06c63da87d9fb58b999a7492,"This paper proposes Meta Auxiliary Learning (MAXL), a self-supervised auxiliary learning method for the task of image classification. The auxiliary task is hierarchical sub-class image classification, where the task is to predict sub-classes of an image. The main contribution of the paper is to propose a meta-learning approach to learn the auxiliary tasks to maximize the generalization of the principal task. The proposed method is evaluated on three CIFAR-10/100 datasets. "
SP:76248e1c914c60ce69de244fe7ec62488d01e161,This paper proposes a neural network-based approach for open set recognition. The key idea is to learn a representation that projects instances of the same class closer together while projecting instances of different classes further apart. The paper also proposes a loss function that enables us to use the same distance function both when training and when computing an outlier score. The proposed method is evaluated on three datasets from two different domains and achieves statistically significant improvement.
SP:d4ee856bbf2dfb6390e5247086fec2e52dcb6858,"This paper studies the problem of training low-precision convolutional neural networks on the ImageNet benchmark. The authors show that the accuracy of the networks trained with 8-bit and 4-bit precision is comparable to that of full precision networks after one epoch of fine-tuning. They also demonstrate that the weights of the low precision networks are very close (in cosine similarity) to the corresponding baseline networks, making training from scratch unnecessary. They find that gradient noise due to quantization during training increases with reduced precision, and seek ways to overcome this noise."
SP:6bfdc37b346e6ddfa049e0414647f4beda8ede3f,"This paper proposes a method to predict post-bounce trajectories of a bouncing ball. The method consists of two modules: a Physics Inference Module (PIM) and a Visual Inference module (VIM). VIM is used to infer physical parameters for locations in a scene given a single still image, while PIM learns to model physical interactions for the prediction task given physical parameters and observed pre-collision 3D trajectories. The experiments show that the proposed method outperforms baselines, including trajectory fitting with Newtonian physics, in predicting trajectories and inferring physical properties of a scene."
SP:010bd055310c363d3cb0fbe0e11546de58220e15,"This paper analyzes the relationship between adversarial vulnerability and the gradient norm of the training objective of a differentiable classifier. The authors prove that the norm of gradients grows as the square root of the input size, and show that CNNs and most feed-forward networks exhibit increasingly large gradients with input dimension d, almost independently of their architecture. They corroborate their theoretical results by extensive experiments. "
SP:5fa3ae057e55be6b71cc94a7dbfe31e54e1c536f,"This paper proposes an interactive agent modeling scheme that encourages an agent to learn to probe. In particular, the probing agent learns to interact with the environment and with a target agent (i.e., a demonstrator) to maximize the change in the observed behaviors of that agent. Through probing, rich behaviors can be observed and are used for enhancing the agent modeling to learn a more accurate mind model of the target agent. The framework consists of two learning processes: i) imitation learning for an approximated agent model and ii) pure curiosity-driven reinforcement learning. The experimental results show that the agent model learned by the approach generalizes better in novel scenarios than the ones learned by passive observation, random probing, and other curiosity-based approaches. "
SP:3af184a5529d6ec2a0862efd1af80ef5b50d2952," neural networks. This paper proposes a modification to traditional artificial neural networks (ANNs) inspired by biological neurons. Specifically, the authors introduce a new type of ANN nodes, which mimic the function of biological neuromodulators and are termed modulators, to enable other traditional ANN nodes to adjust their activation sensitivities in run-time based on their input patterns. This modification produces statistically significant improvements in comparison with traditional ANNs in the context of Convolutional Neural Networks and Long Short-Term Memory networks. "
SP:287a577834fd2820a939a1113b39146a22727491,"This paper presents a neural analysis and synthesis (NANSY) framework that can manipulate voice, pitch, and speed of an arbitrary speech signal. NANSY does not require any labels associated with speech data such as text and speaker information, but rather uses a new set of analysis features, i.e., wav2vec feature and newly proposed pitch feature, which allows for fully self-supervised training. The experiments show significant improvement in performance in several applications such as zero-shot voice conversion, pitch shift, and time-scale modification. "
SP:90f35ad1ec0c38b0817f5678ee2a5c4f0e08fb38,"This paper analyzes the generalization properties of gradient-based bilevel programming algorithms for hyperparameter optimization. In particular, the authors prove an expectation bound for the unrolled differentiation algorithm based on a notion of uniform stability on validation. They also provide a bound on the expectation bound of the classical cross-validation algorithm. Theoretical results are corroborated by experiments on feature learning and data reweighting."
SP:42f52aec3a776d87daa5fd72b8e6325d12c88d63,"This paper proposes a novel knowledge distillation approach to facilitate the transfer of dark knowledge from a teacher to a student. The main idea is to learn the teacher models that are friendly to students and, consequently, more appropriate for knowledge transfer. The proposed method is based on a teacher-friendly teacher network (SFTN) that learns the student branches jointly to obtain student-friendly representations. The experimental results demonstrate the effectiveness of the proposed SFTN."
SP:e15a1c21229233fd97dc1dfa0a4ef48b69dc9f95,This paper studies the generalization to out-of-distribution (OOD) data. The authors propose a generalization bound for OOD generalization based on the expansion function. They also propose a model selection criterion to check the model’s variation and validation accuracy simultaneously. Experiments on benchmark OOD datasets demonstrate that the proposed method outperforms baselines.
SP:37b04b9068d39bcf0a581eb8181d13cf1a8926bf,"This paper proposes a Variational Continual Bayesian Meta-Learning (VC-BML) algorithm that addresses the issues of negative knowledge transfer and catastrophic forgetting for streaming low-resource tasks that follow non-stationary distributions. The authors propose a Dynamic Gaussian Mixture Model for meta-parameters, with the number of component distributions determined by a Chinese Restaurant Process. To infer the posteriors of model parameters, the authors develop a more robust posterior approximation method – structured variational inference for the sake of avoiding forgetting knowledge. The experimental results show that the proposed algorithm outperforms state-of-the-art baselines."
SP:776d5b02b8d3a8bbcc1f52706f3887c384cb149e,"This paper proposes a probabilistic method for solving boundary value problems (BVPs), which are ordinary differential equations (ODEs) subject to boundary conditions. The authors propose a Gauss-Markov prior for solving BVPs, which allows computing a posterior distribution over the solution in linear time, at a quality and cost comparable to that of well established, non-probabilistic methods. They also introduce uncertainty quantification, mesh refinement, and hyperparameter adaptation to improve the efficiency of the proposed method."
SP:86aac0c6b75fdc12f84bba342934865616f866d4,"This paper studies the reward mixing Markov decision process (RM-MDP) problem, where a reward function is drawn from one of multiple reward models at the beginning of every episode, but the identity of the chosen reward model is not revealed to the agent. The authors study the problem of learning a near optimal policy for two reward-mixing MDPs. They provide the first polynomial-time algorithm that finds an optimal policy after exploring poly(poly(H, −1)·S2A2) episodes, where H is time-horizon and S,A are the number of states and actions respectively. "
SP:1a3c70ae9cf2a806d603f4b9e7ca6e10b720a956,This paper proposes a two-step procedure to estimate the multi-cause treatment effect. The first step augments the observational data with the estimated potential outcomes under single-cause interventions. The second step is a covariate adjustment on the augmented dataset to obtain the estimator. The proposed method is agnostic to the exact choice of algorithm in either step. The experimental results demonstrate the performance gain of the proposed method.
SP:247bc6675cce89d51558537daf63dadb0c4307f8,"This paper proposes a multi-wavelet-based neural operator learning scheme that compresses the associated operator’s kernel using fine-grained wavelets. By explicitly embedding the inverse multiwavelet filters, the proposed method learns the projection of the kernel onto fixed multi wavelet polynomial bases. Experiments on the Korteweg-de Vries (KdV) equation, Burgers’ equation, Darcy Flow, and Navier-Stokes equation demonstrate the effectiveness of the proposed model."
SP:1153785e6a016cfee2644952a772aa08927299b6,"This paper proposes a frequency domain approximation (FDA) method to approximate the gradient of the sign function in the Fourier frequency domain using the combination of sine functions for training BNNs. The proposed approach does not affect the low-frequency information of the original sign function which occupies most of the overall energy, and high-frequency coefficients will be ignored to avoid the huge computational overhead. The experiments on several benchmark datasets and neural architectures illustrate that the binary network learned using the proposed method achieves the state-of-the-art accuracy."
SP:33b95ea8da4d30b8e8f9d3fe3acca023d4b8d831,"This paper proposes to use multi-area RNNs with neuroscience-inspired architecture constraints to derive key features of multi- area computation. The authors show that incorporating multiple areas and Dale’s law is critical for biasing the networks to learn biologically plausible solutions. Additionally, they leverage the full observability of the RNN to show that output-relevant information is preferentially propagated between areas. These results suggest that cortex uses modular computation to generate minimal sufficient representations of task information."
SP:db3ced65d67e3373fb3936ec50f41c8ef010bbbe,This paper proposes a method for visualizing multiple explanations of an image. The main idea is to use a beam search algorithm to systematically search for multiple explanations for each image. A structured attention graph (SAG) is proposed to compactly represent sets of attention maps for an image by visualizing how different combinations of image regions impact the confidence of a classifier. An approach to computing a compact and representative SAG for visualization is proposed via diverse sampling. A user study is conducted to demonstrate the effectiveness of the proposed method.
SP:f2b385bfd9ada0e26aa8829214b424f58582d9f7,"This paper studies how the choice of training objective affects the transferability of the hidden representations of convolutional neural networks trained on ImageNet. The authors show that many objectives lead to statistically significant improvements in ImageNet accuracy over vanilla softmax cross-entropy, but the resulting fixed feature extractors transfer substantially worse to downstream tasks. The choice of loss has little effect when networks are fully fine-tuned on the new tasks, and the difference among loss functions are apparent only in the last few layers of the network."
SP:b66b5e24f68563e2e200eda660f0dbaff53efeff,"This paper presents a method for learning a generative model of neural population dynamics from neural time series data. The method is based on an autoencoder-based model, which is trained with selective backpropagation through time (SBTT). The authors show that SBTT is able to learn a latent dynamics model of the time series, which can be used to infer missing samples. The authors also show that the proposed method can be applied to sequential autoencoders and demonstrate that it is more efficient and higher-fidelity."
SP:3513a83806e71006b86d60b779d8bd6bb87c3546,"This paper proposes a hierarchical approach to sequence-to-sequence learning with quasi-synchronous grammars, where each node in the target tree is transduced by a node in a source tree. Both the source and target trees are treated as latent and induced during training. They develop a neural parameterization of the grammar which enables parameter sharing over the combinatorial space of derivation rules without the need for manual feature engineering. They apply this latent neural grammar to various domains, a diagnostic language navigation task designed to test for compositional generalization (SCAN), style transfer, and small-scale machine translation."
SP:d06fc251f2a9287f7a2236a188349628d8f39d9a,"This paper proposes a novel algorithm for solving the Group Elastic Net problem. The algorithm is based on the SsNAL algorithm, which is then extended to the function-on-scalar regression framework. The main contribution of the paper is the use of the sparsity structure of the Augmented Lagrangian to reduce the computational burden of the algorithm. The proposed algorithm is evaluated on simulated and real-world data."
SP:e0b53f76f3a6b756fedd09926f9cf034f89f4a5a,This paper proposes a clustering method for structured point process data. The proposed method is based on a mixture model of multi-level marked point processes to cluster repeatedly observed marked event sequences. A semi-parametric Expectation-Solution (ES) algorithm combined with functional principal component analysis (FPCA) is proposed for model estimation. The effectiveness of the proposed framework is demonstrated through simulation studies and real data analyses.
SP:3aa213076f3e9f9838ac654517df2fe1fca33499,"This paper proposes an online meta-adaptive control algorithm, called Online Meta-Adaptive Control (OMAC), for adaptive non-linear control in a sequence of unknown environments. The authors provide convergence guarantees for the proposed algorithm under different assumptions and conditions. They also validate the effectiveness of the algorithm empirically. "
SP:cb274c93a169b199ea09120ca02105a3f16b31c5,"This paper studies the problem of training neural networks with certifiable robustness guarantees. The authors identify two important issues in existing methods, namely exploded bounds at initialization, and the imbalance in ReLU activation states and improve IBP training. To mitigate these issues and conduct faster certified training with shorter warmup, the authors propose three improvements based on IBP: 1) a new weight initialization method for IBP, 2) adding Batch Normalization (BN) to each layer in the model, and 3) regularization to tighten certified bounds and balance ReLU activations states during wamrup. The proposed method is able to obtain 65.03% verified error on CIFAR-10 and 82.36% on TinyImageNet."
SP:18ffeb199a670fb2b1f4417b8653479001944dab,"This paper studies the problem of change point detection in the presence of adversarial perturbations to the data. The authors propose to use the Huber-contamination framework, which allows the contamination distributions to be different at each time point. The detection boundary is a function of the contamination proportion and is the first time shown in the literature. In addition, the authors derive the minimax-rate optimal localisation error rate, quantifying the cost of accuracy in terms of contamination proportion. They propose a computationally-feasible method, which matches the lower bound under certain conditions."
SP:d03617b5fc446768809cf015c9234b0c9386a690,"This paper studies the power of learning via mini-batch stochastic gradient descent (SGD) and batch Gradient Descent (GD) on the empirical loss of a differentiable model or neural network. The authors show that SGD and GD can always simulate learning with statistical queries (SQ), but their ability to go beyond that depends on the precision ρ of the gradient calculations relative to the minibatch size b and sample size m (for GD). This paper extends prior work that achieved this result for b = 1. In particular, with polynomially many bits of precision (i.e. when ρ is exponentially small), SGD can both simulate PAC learning regardless of the mini batch size. "
SP:1de2864fe2f53e25596a9bd2c61e2048e79296f6,"This paper studies the problem of optimal uniform quantization, i.e., the construction of a uniform probability distribution over a set of N points that minimizes the Wasserstein distance to the model distribution. This minimization problem, where the unknowns are the positions of the atoms, is non-convex. Yet, in most cases, a suitably adjusted version of Lloyd’s algorithm — in which Voronoi cells are replaced by Power cells — leads to configurations with small Wassersteins error. This is surprising because, again, of the non-Convex nature of the problem, as well as the existence of spurious critical points. The authors provide explicit estimates for the convergence of this Lloyd-type algorithm, starting from a cloud of points that are sufficiently far from each other. "
SP:c3d364aeee55230a436c3ce4e8dc8310ee73959e,This paper proposes a novel self-attention-based feature transform for video understanding. The proposed RSA feature transform leverages the rich structures of spatio-temporal relations in videos by dynamically generating relational kernels and aggregating relational contexts. The experiments show that the proposed RSA network substantially outperforms convolution and self attention counterparts. 
SP:2c2530069d5cab485629090243da464d107feadd,This paper studies the mean field theory of multilayer neural networks. The authors propose a second-order mean field limit that captures the limiting fluctuation distribution around the infinite-width limit. They show that this limit is related to the fluctuation realized by large-width networks. They also show a stability property of gradient descent mean field training and show that it progressively biases towards a solution with minimal fluctuation.
SP:a3d927854d9d7fd39b8d05a79666810d585d5062,"This paper proposes a method to model a metriplectic dynamical system as a solution to learnable dynamics. The method is based on learning generalized Casimirs for energy and entropy, which are guaranteed to be conserved and nondecreasing. The authors show that the learned dynamics are more robust and generalize better than penalty-based or black-box approaches. "
SP:32e8e83e06b1e9a4dad761334d5947c91bfd1853,This paper proposes a sample selection-based algorithm for fair and robust training. The authors formulate a combinatorial optimization problem for the unbiased selection of samples in the presence of data corruption. They propose a greedy algorithm that is efficient and effective in practice. Experiments show that the proposed algorithm obtains fairness and robustness that are better than or comparable to the state-of-the-art technique.
SP:991127729bf067fe27fdd7ed360aab39e4df5921,"This paper studies the relationship between periodic activation functions in Bayesian neural networks (BNNs) and stationary Gaussian process priors. The authors show that periodic activation function establishes a direct connection between the prior on the network weights and the spectral density of the covariance function of the limiting stationary gaussian process (GP) of single hidden layer BNNs. They also show that this correspondence is exact for the sinusoidal and sin-cos activations and approximate for the triangle and periodic ReLU activations. Finally, they show in a range of experiments that the proposed method achieves comparable performance for in-domain data, do not result in overconfident predictions, and enable robust out-of-domain detection."
SP:d61a2aecfea4612c473b4e6fd41f3dc2fcbb04a1,"This paper studies the problem of providing feedback to interactive programs as a task of classifying Markov Decision Processes (MDPs). Each student’s program fully specifies an MDP where the agent needs to operate and decide, under reasonable generalization, if the dynamics and reward model of the input MDP should be categorized as correct or broken. The authors demonstrate that by designing a cooperative objective between an agent and an autoregressive model, they can use the agent to sample differential trajectories from the inputs MDP that allows a classifier to determine membership: Play to Grade. Their method enables an automatic feedback system for interactive code assignments."
SP:daf99ad91613d6e11b13315ccbd1bbe25094ae4b,"This paper proposes a method to explain a DRL model by visualizing the importance of low-level input features with a disentangled representation. The authors propose a Represent And Mimic (RAMi) framework for training an identifiable latent representation to capture the independent factors of variation for the objects and a mimic tree that extracts the causal impact of the latent features on DRL action values. To jointly optimize both the fidelity and the simplicity of the mimic tree, the authors derive a novel Minimum Description Length (MDL) objective based on the Information Bottleneck (IB) principle. Experiments show that our mimic tree achieves strong approximation performance with significantly fewer nodes than baseline models."
SP:84560de78af979354fff83d1370d8675c1e9191f,"This paper proposes a Bayesian framework for modeling the structure of dynamic predictions over time. In particular, the authors propose a Gaussian latent information martingale (GLIM) framework to model the distribution over probability paths. The GLIM is based on a latent process of information flow, which is inferred from historical data. The authors show that GLIM preserves important properties of probability paths such as the martingales structure and appropriate amount of volatility. "
SP:0c4bfb44e0a353256692d5e5ae96f65c1a14363d,"This paper studies the problem of active pure exploration with fixed confidence in generic stochastic bandit environments. The goal of the learner is to answer a query about the environment with a given level of certainty while minimizing her sampling budget. For this problem, instance-specific lower bounds on the expected sample complexity reveal the optimal proportions of arm draws an Oracle algorithm would apply. The authors devise Frank-Wolfe-based Sampling (FWS), a simple algorithm whose sample complexity matches the lower bounds for a wide class of pure exploration problems. They apply FWS to various pure exploration tasks, including best arm identification in unstructured, thresholded, linear, and Lipschitz bandits."
SP:0947a0f08fba53d3c8af9b78dd64e6e10fc73e32,This paper proposes a new Bayesian optimization method for optimizing combinatorial spaces. The main idea is to use a structure-coupled kernel that explicitly integrates the structural information from decoded structures with the learned latent space representation for better surrogate modeling. Experiments on real-world benchmarks show that LADDER significantly improves over the BO over latent space method.
SP:37adabdc6615c5199a481553c8ccc06d57363614,"This paper studies the role of representation of state-action value functions in regret minimization in finite-horizon Markov Decision Processes (MDPs) with linear structure. The authors first derive a necessary condition on the representation, called universally spanning optimal features (UNISOFT), to achieve constant regret in any MDP with linear reward function. This result encompasses the well-known settings of low-rank MDPs and, more generally, zero inherent Bellman error (also known as the Bellman closure assumption). They then demonstrate that this condition is also sufficient for these classes of problems by deriving a constant regret bound for two optimistic algorithms (LSVI-UCB and ELEANOR). Finally, they propose an algorithm for representation selection and prove that it achieves constant regret when one of the given representations, or a suitable combination of them, satisfies the UNISOFT condition."
SP:92566b664ab2f6ee9b73f29327aeef85d14ecf60,"This paper proposes a differentiable contact model that can capture contact mechanics: frictionless/frictional, as well as elastic/inelastic. This model can also accommodate inequality constraints, such as limits on the joint angles. The proposed contact model extends the scope of Lagrangian and Hamiltonian neural networks by allowing simultaneous learning of contact and system properties. The authors demonstrate this framework on a series of challenging 2D and 3D physical systems with different coefficients of restitution and friction."
SP:82d59a3609dfd458f90f23d4e477c8b497e9dc18,This paper analyzes the relationship between the Lipschitz constant of a neural network and its behavior during training. The paper shows that networks with a small Lipshitz constant will exhibit a shorter bias trajectory and their bias will vary less. The authors also show that networks whose 1st layer bias is trained more steadily have bounded complexity even in regions of the input space that are far from any training point. 
SP:9b329c915fa8d4045c167c9df37a49ee314d190e,"This paper studies the problem of learning half-spaces in the Massart noise model. The main contribution of this paper is to show that any distribution can be decomposed as a disjoint mixture of few distributions for which a Forster transform exists and can be computed efficiently. Based on this result, the authors obtain the first polynomial-time algorithm for distribution-independent PAC learning of half-space in the noise model with strongly polynomially sample complexity, independent of the bit complexity of the examples."
SP:e5229305af00067ae2dbabd903e585964aec8928,"This paper proposes a Bayesian optimisation-based adversarial attack method for graph classification. The proposed method is black-box, query-efficient and parsimonious with respect to the perturbation applied. The authors empirically validate the effectiveness and flexibility of the proposed method on a wide range of graph classification tasks involving varying graph properties, constraints and modes of attack. Finally, the authors analyze common interpretable patterns behind the adversarial samples produced, which may shed further light on adversarial robustness of the graph classification models."
SP:4999e5664383066fdacd14be6242c7b83f85f3dd,"This paper studies the problem of online label shift adaptation in the online setting, where the test-time label distribution is continually changing and the model must dynamically adapt to it without observing the true label. The authors propose two adaptation algorithms inspired by classical online learning techniques such as Follow The Leader (FTL) and Online Gradient Descent (OGD) and derive their regret bounds. They empirically verify their findings under both simulated and real-world label distribution shifts. "
SP:806515ae07fb1c9d02773592005d53d4158ef102,"This paper considers the problem of detecting and localization of gradual changes in the distribution of a sequence of time-ordered observations. The authors propose a nonparametric method for detecting and localizing gradual changes. The proposed method requires no prior domain knowledge, and they offer theoretical guarantees on both detection (false positive rate, power) and localization (consistency). "
SP:7a3c8a7b17ecab19361d36e1d3d73fa35b71214c," in signal processing, linear BSS problems are often solved by Independent Component Analysis (ICA). To serve as a model of a biological circuit, the ICA neural network (NN) must satisfy at least the following requirements: 1. The algorithm must operate in the online setting where data samples are streamed one at a time, and the NN computes the sources on the fly without storing any significant fraction of the data in memory. 2. The synaptic weight update is local, i.e., it depends only on the biophysical variables present in the vicinity of a synapse. The authors propose a novel objective function for ICA from which they derive a biologically plausible NN, including both the neural architecture and the synaptic learning rules. Interestingly, the algorithm relies on modulating synaptic plasticity by the total activity of the output neurons."
SP:22f8b517a3df65144412938f5891c463d7bae0ab,"This paper studies the space of solutions of a two-neuron network trained on a task that leads to multiple solutions. The authors show that the solutions of the network can be traced back to the network’s initial connectivity and identify discrete dynamical regimes that underlie this diversity. They then examine three neuroscience-inspired tasks: Delayed discrimination, Interval discrimination, and Time Reproduction. For each task, they find a rich set of solutions. One layer of variability can be found directly in the neural activity of the networks. An additional layer is uncovered by testing the trained networks’ ability to extrapolate, as a perturbation to a system often reveals hidden structure. Furthermore, they relate extrapolation patterns to specific dynamical objects and effective algorithms found by networks. "
SP:9b08a0f547ead3b59077a43b1052c6d46a0730f6,"This paper proposes a new method for density estimation of arbitrary conditional distributions over a set of covariates. The main idea is to use an energy-based approach to model the conditional distribution over the covariates, which can be expressed as a function of an energy function. The authors show that the proposed method achieves state-of-the-art performance for arbitrary conditional likelihood estimation and data imputation. "
SP:f2b14f5854e6aa6922795d1d2051b7402486cef6,"This paper proposes a new loss function for single-image super-resolution (SISR) based on variance estimation. Specifically, the loss function is based on a weighted combination of the mean and variance of the pixels in a high-resolution image (mean) and their corresponding uncertainty (variance). The paper also proposes to use sparsity prior for regularizing the SISR loss function. Experiments show that the proposed loss function outperforms MSE and L1 loss. "
SP:9997583f40fa648adf57bb4fc34228f357be0cf1,This paper proposes a general PAC-Bayesian generalization bound for adversarial robustness. The main idea is to use the PACBayesian framework to bound the averaged risk on the perturbations for majority votes (over the whole class of hypotheses) to estimate how much a model will be invariant to imperceptible perturbation in the input at test time. The authors show that the bound is tight and can be directly minimized during the learning phase to obtain a robust model on different attacks. 
SP:90b72e8dc41584e38f25dff9fb2853f5b11dc8fa,"This paper proposes a probabilistic entity representation model (PERM) for logical reasoning over Knowledge Graphs (KGs). The proposed model encodes entities as a multivariate Gaussian density with mean and covariance parameters to capture its semantic position and smooth decision boundary, respectively. The authors also define the closed logical operations of projection, intersection, and union that can be aggregated using an end-to-end objective function. Experiments are conducted on DRKG and COVID-19 to demonstrate the effectiveness of the proposed model."
SP:b6184c9732dbb7eba7c20cae8869d975c428efe4,"This paper proposes a new gradient-based hyperparameter optimization method, FDS (Foward-mode Differentiation with Hyperparameter Sharing), which is based on forward-mode differentiation with hyperparameters that are contiguous in time. The authors provide theoretical guarantees about the noise reduction properties of their algorithm, and demonstrate its efficiency empirically by differentiating through 10 gradient steps of unrolled optimization. The experiments show that FDS outperforms greedy gradient based alternatives in the quality of hyperparametrization found, while being significantly faster than all state of the art black-box methods."
SP:9c3a326e5ee4e862923d3bf9415f32a077db8534,"This paper proposes a method to improve the consistency and coherence of neural sequence models by adding a symbolic reasoning module that can either accept or reject the generation of a neural sequence model. The method is based on a few-shot learning approach with state-of-the-art neural language models (GPT-3), which requires no additional training or fine-tuning. Results in robust story generation and grounded instruction-following show that this approach can increase the coherence and accuracy of neurally-based generations."
SP:d77d046095e4c8336c0c76ac48cb046923230753,"This paper studies the problem of off-policy evaluation (OPE) in continuous treatment settings. The authors propose a novel estimation method for OPE using deep jump learning. The key ingredient of their method lies in adaptively discretizing the treatment space using deep discretization, by leveraging deep learning and multiscale change point detection. The method is further justified by theoretical results, simulations, and a real application to Warfarin Dosing."
SP:4d085e57286fdd36143108a002d16914222c239a,"This paper proposes a variational inference framework for continuous-time hybrid processes. The model is based on a Markov jump process modulating a subordinated diffusion process. The authors provide the exact evolution equations for the prior and posterior marginal densities, the direct solutions of which are however computationally intractable. Instead, the authors propose to approximate the exact model by minimizing the path-wise Kullback-Leibler divergence, which yields Bayesian latent state estimates for arbitrary points on the real axis and point estimates of unknown system parameters. "
SP:d1f396e691f9d331adfb7b694a99c50e8004331f,"This paper studies the impact of the spectrum of the sensing matrices on the performance of expectation propagation algorithm (EP). The authors define a notion for the spikiness of spectrum of A and show the importance of this measure in the performance. They define certain quantities based on the function f that enables them to describe the impact on impact of spikier spectrum on EP recovery. Based on our framework, they are able to show that for instance, in phase-retrieval problems, matrices with spiky spectrums are better for EP, while in 1-bit compressed sensing problems, less spiky (flatter) spectrums offer better recoveries."
SP:ee66604d4da9fd04826e90ccbb94f0499eba4c63,"This paper proposes a novel method for Generalized Zero-Shot Learning (GZSL) that addresses the problem of domain shift by progressively improving cross-domain transferability and category discriminability of visual representations. The proposed method constructs two types of prototypes that record prototypical visual patterns for attributes and categories, respectively. With attribute prototypes, DPPN alternately searches attribute-related local regions and updates corresponding attribute prototypes to progressively explore accurate attribute-region correspondence. Besides, along with progressive attribute localization, the proposed method further projects category prototypes into multiple spaces to progressively repel visual representations from different categories. Experiments on four benchmarks demonstrate the effectiveness of the proposed approach."
SP:61eb6297568c3f6869fbb03eaf6a21260de5466c,"This paper presents an end-to-end deep learning approach for removing defocus blur from a single image, so as to have an all-in-focus image for consequent vision tasks. A pixel-wise Gaussian kernel mixture (GKM) model is proposed for representing spatially variant blur kernels in an efficient linear parametric form, with higher accuracy than existing models. Then, a deep neural network (DNN) is developed by unrolling a fixed-point iteration of the GKM-based deblurring. Extensive experiments show that the proposed method achieves state-of-the-art results on existing datasets."
SP:18bf447c90935c373e5ec4cdfbbf8f2a273d2edb,This paper proposes a self-supervised video representation learning method based on Motion Vector based Cross-Guidance Contrastive Learning (MVCGC). The proposed method decodes RGB frames and motion vectors from compressed videos on-the-fly and uses a cross guidance contrastive learning algorithm based on multi-instance InfoNCE loss to enhance the representation ability of the motion vectors. Extensive experiments are carried out to validate the efficiency and effectiveness of the proposed method.
SP:8c7b1d976d9758cd534c565ec31a23f97892e503,"This paper studies the problem of asymptotic overconfidence of ReLU Bayesian neural networks (BNNs) with infinite ReLU features. The authors show that the output variance of a BNN with finitely many features is quadratic in the distance from the data region. Meanwhile, Bayesian linear models converge to a particular Gaussian process (GP) with a variance that grows cubically so as to avoid this issue. This paper extends finite ReLU BNNs with infinite reLU features via the GP and shows that the resulting model is maximally uncertain far away from the training data while the BNN’s predictive power is unaffected near the data. "
SP:e77276f61626e896f6a985296f1d832129242cdf,"This paper considers the problem of selecting a causal quantity of interest among a set of causal formulas. The authors propose a sequential strategy in which the investigator decides, observation-by-observation, which subset of variables to observe with the goal of identifying the best formula with the fewest observations. They cast this strategy into the best-arm-identification bandit framework, by considering each formula as one arm and by replacing the typical goal of learning the arm with the best mean with a goal of finding the best long-run cost-adjusted statistical performance. They adapt well-known bandit algorithms to this goal by introducing finite-sample confidence intervals on the asymptotic variance. "
SP:471361588bfc6c6033631509d1e43e77fd9721ce,"This paper studies the problem of how to fully compensate the compression error for variance reduced optimization algorithms. In particular, the authors propose ErrorCompensatedX, which uses the compression errors from the previous two steps to achieve the same asymptotic convergence rate with the training without compression. They also provide a unified theoretical analysis framework for this class of variance reduced algorithms, with or without error compensation. Numerical experiments are implemented to show the convergence and its better performance."
SP:3b7ff0dc668cac2191d95fcc4dc6e0335dec3206,"This paper proposes a method for generating multi-grained explanations for graph neural networks (GNNs). The main idea is to use the pre-training and fine-tuning idea to develop the explainer and generate multi-granularity explanations. Specifically, the authors propose a generative probabilistic model, ReFine, to generate explanations with both global patterns and local features. Experiments on both synthetic and real-world datasets show the superiority of the proposed method."
SP:9b5a62d3a2b27bc60da28980e9fb0ecdff1215c0,"This paper proposes a method to generate counterfactual explanations for GNNs. The main idea is to use decision boundaries extracted from the given GNN model to formulate an intuitive and effective Counterfactual loss function, and optimize this loss to train a neural network to produce explanations with strong counterfactually characteristics. Experiments on synthetic and real-world benchmark datasets demonstrate the efficacy of the proposed method."
SP:4edb870786c9cea2c6075359cb4e79b02a8e2f5f,"This paper proposes a self-supervised voice-to-speech model called VoiceMixer. The proposed method is based on a new information bottleneck and adversarial feedback to decompose and transfer voice style through a novel information bottleneck. The discriminator is decomposed into a content discriminator and a style discriminator, which enables the model to achieve better generalization to the voice style of the converted speech. The experimental results show the superiority of the proposed method. "
SP:9fbb0c6beb3f8f88972f13dcf0e1fe7db03233c7,"This paper proposes a Siamese voxel-to-BEV (V2B) tracker for 3D single object tracking on sparse point clouds. The key idea is to learn the discriminative features of the object so that the potential target from the background in sparse 3D point clouds can be identified. To this end, the paper first performs template feature embedding to embed the template’s feature into the target and then generates a dense 3D shape to characterize the shape information of a potential target. For localizing the tracked target, the v2B target localization network regresses the 2D center and the z-axis center from the dense bird's eye view (BEV) feature map in an anchor-free manner."
SP:8b788c78680a54c453a04f4551436763ee57585e,"This paper proposes a positional encoding method based on learnable Fourier features for multi-dimensional positional encoding. Instead of hard-coding each position as a token or a vector, the authors represent each position, which can be multi-dim, as a learnable encoding based on a multi-layer perceptron. The proposed method is parameter-efficient and is initialized in such a way that the inner products of the positional encodings approximate Euclidean distances. Experiments are conducted on image generation, object detection, image classification, and sparse spatial structure modeling in graphical user interfaces."
SP:d2ac1b6381315bce4449f09bd519f33a2a42d714,"This paper considers the problem of learning the causal structure of a system from observational data in the presence of latent variables and selection bias. Constraint-based methods are one of the main approaches for solving this problem, but the existing methods are either computationally impractical when dealing with large graphs or lacking completeness guarantees. This paper proposes a novel computationally efficient recursive constraint-based method that is sound and complete. The key idea of the approach is that at each iteration a specific type of variable is identified and removed. This allows us to learn the structure efficiently and recursively, as this technique reduces both the number of required conditional independence (CI) tests and the size of the conditioning sets. The former substantially reduces the computational complexity, while the latter results in more reliable CI tests. "
SP:49a4912ce457f5f5ec62c44fa10444af8075fabf,This paper proposes a new Thompson Sampling algorithm for stochastic multi-arm bandit and linear contextual bandit. The algorithm is based on a dynamic batch allocation mechanism that determines the duration of each batch based on an offline estimation of the regret accumulated during that phase. The authors prove that the proposed algorithm achieves the same regret bound as a fully sequential algorithm while reducing the number of sequential interactions from T to O(log T) while using only O(T) batch queries. Experiments are conducted on both synthetic and real-world datasets.
SP:653a519e3c799c25e0d0b4240322642040b121a3,"This paper studies the problem of representation learning in the multi-source domain adaptation (MSDA) and domain generalization (DG) settings. The authors provide theoretical upper bounds for the target general loss and define two kinds of domain-invariant representations. They further study the pros and cons as well as the trade-offs of enforcing learning each domain invariant representation. Finally, they conduct experiments to inspect the tradeoff of these representations. "
SP:2a7bee950cd07494d59dfee60ac2e86cc0e481b1,"This paper proposes an aligned structured sparsity learning (ASSL) method for lightweight image super-resolution (SR) networks. The proposed method is based on a weight normalization layer and a sparsity structure alignment penalty term, which aligns the pruned filter locations across different layers. Experiments are conducted to demonstrate the effectiveness of the proposed method."
SP:e9830bb9e7d3ddc3bd1c2994590fdb5d8f3668be,This paper proposes a novel exploration method for multi-agent reinforcement learning. The authors propose to use prediction errors of individual Q-values as intrinsic rewards for coordinated exploration and utilize episodic memory to exploit explored informative experience to boost policy training. The experiments show that the proposed method outperforms state-of-the-art MARL baselines on more complicated StarCraft II tasks.
SP:c7e33d479575c88e22282ee6fd4f978bcd3c06ed," the problem of list-decodable linear regression, where an adversary can corrupt a majority of the examples. The goal is to output a small list of hypothesis vectors such that at least one of them is close to the target regression vector. The main result is a Statistical Query (SQ) lower bound of d for this problem. The SQ lower bound qualitatively matches the performance of previously developed algorithms. "
SP:7b258252a9063514348f5fa8d9c85afd85748747,This paper proposes a new model for predicting the patient health status and disease progression over time. The model is based on a pharmacological model and a neural ODE model. The neural model is trained to model the evolution of unobservable latent variables and the relationship between measurements and latent variables. Experiments are conducted on synthetic and real-world intensive care data of COVID-19 patients. 
SP:3ea9e86e5755ef84d28e3163c60531ace5d62e3a,"This paper studies the problem of meta-reinforcement learning for few-shot learning. The authors provide a theoretical framework for analyzing a MAML-like algorithm, assuming all available tasks require approximately the same representation. They then provide risk bounds on predictors found by finetuning via gradient descent, demonstrating that the method provably leverages the shared structure. In contrast, they establish settings where learning one representation for all tasks (i.e. using a “frozen representation” objective) fails."
SP:8ba5a2ac80f7c53f81ad008e96c033ecad14ac0d,"This paper presents Grammar-Based Grounded Lexicon Learning (G2L2), a lexicalist approach to learning a compositional and grounded meaning representation of language from grounded data, such as paired images and texts. Given an input sentence, the model first looks up the lexicon entries associated with each token, then derives the meaning of the sentence as an executable neuro-symbolic program by composing lexical meanings based on syntax. The recovered meaning programs can be executed on grounded inputs. To facilitate learning in an exponentially growing compositional space, the authors introduce a joint parsing and expected execution algorithm, which does local marginalization over derivations to reduce the training time. Experiments are conducted on two domains: visual reasoning and language-driven navigation."
SP:16c458651815813efdcbe8ba1205bbddbe3e4e68,"This paper proposes a distributed stochastic Newton algorithm for convex quasi-self-concordant convex optimization. In this setting, each machine has the ability to calculate stochastically independent gradients of the same population objective, as well as the product of independent unbiased estimators of the Hessian of the population objective with arbitrary vectors. The authors show that the proposed algorithm can reduce the number, and frequency, of required communication rounds compared to existing methods without hurting performance. "
SP:d7e479d59f82d4c55372a68ca7b4516f2871f346,"This paper proposes a new distance metric, Density-aware Chamfer Distance (DCD), which is based on Chamfer distance (CD) and Earth Mover’s Distance (EMD) to measure the similarity between two point sets. The authors claim that DCD is more sensitive to the difference of density distributions and is more computationally efficient than CD and EMD. In addition, the authors propose to use DCD as the training loss function, which outperforms the same model trained with CD loss on all three metrics. Finally, they propose a novel point discriminator module that estimates the priority for another guided downsampling step."
SP:e4b302009520770814ff2c096020b779a9fc38fe,"This paper studies the effect of knowledge distillation (KD) on student generalization. The authors show that KD does not always work as well as it is commonly understood. They show that there often remains a surprisingly large discrepancy between the predictive distributions of the teacher and the student, even in cases when the student has the capacity to perfectly match the teacher. They identify difficulties in optimization as a key reason for why the student is unable to match the teachers. They also show how the details of the dataset used for distillation play a role in how closely the student matches the teacher — and that more closely matching the teacher paradoxically does not necessarily lead to better student generalisation."
SP:895c7e03f9e4dadb94be1f39d61bf0b5e1533f4f,"This paper studies the problem of learning a k-decision tree, which is a recursive partition of a matrix (2D-signal) into k+1 block matrices (axis-parallel rectangles, leaves) where each rectangle is assigned a real label. Its regression or classification loss to a given matrix D of N entries (labels) is the sum of squared differences over every label in D and its assigned label by t. Given an error parameter $\� \in (0,1), a (k, \�)-coreset C of D is a small summarization that provably approximates this loss to every such tree, up to a multiplicative factor of 1/\epsilon. In particular, the optimal k-tree of C is a (1 + $\�)-approximation to the optimal decision tree of D. The size of the coreset is polynomial in k log(N)/ε, and its construction takes O(Nk) time. Experimental results on sklearn and lightGBM show that applying our coresets on real-world data-sets boosts the computation time of random forests and parameter tuning by up to x10, while keeping similar accuracy."
SP:f3ece96b15ec06d703925df2061ed9694ec3bca5,"This paper studies the problem of best-arm identification of m arms with largest means under a fixed error rate $\delta$ (fixed-confidence Top-m identification), for misspecified linear bandit models. This problem is motivated by practical applications, especially in medicine and recommendation systems, where linear models are popular due to their simplicity and the existence of efficient algorithms, but in which the data inevitably deviates from linearity. The authors first derive a tractable lower bound on the sample complexity of any \delta-correct algorithm for the general Top m identification problem. Then, they describe a first algorithm for this setting, which is both practical and adapts to the amount of misspecification. Finally, they evaluate their algorithm on both synthetic and real-world data, showing competitive performance with respect to existing baselines."
SP:e71c5e39b8d8d1640d6de2352ac51ddd52eea89d,"This paper proposes a self-supervised method for learning disentangled representations for graph neural networks (GNNs). In particular, the authors propose a novel contrastive learning approach to disentangle the latent factors of the input graph and derive its factorized representations. Each of the representations describes a latent and disentanglement aspect pertinent to a specific latent factor of the graph. Experiments on both synthetic and real-world datasets demonstrate the effectiveness of the proposed method."
SP:0a7edbbdabab11273689c40c517001eb46491113,This paper proposes a statistical simulation to assess the robustness of a neural network to adversarial and corruption perturbations. The authors propose a stochastic simulation inspired by the field of Statistical Reliability Engineering (SRE) based on an Importance Splitting simulation generating samples of rare events. They derive theoretical guarantees that are nonasymptotic w.r.t. sample size. Experiments on large scale networks show the efficiency of the proposed method.
SP:c1db485ff1ff9573daa421e167225654babb55ac,"This paper proposes a general framework, called CoPE, that enables a polynomial expansion of two input variables and captures their auto- and cross-correlations. CoPE is evaluated in five tasks (class-conditional generation, inverse problems, edges to image translation, image-to-image translation, attribute-guided generation, and super-resolution) involving eight datasets. The thorough evaluation suggests that CoPE can be useful for tackling diverse conditional generation tasks. "
SP:5a75bc7a3ea0ce971cfceebbc1c2434e3aa2584d,"This paper proposes a neural tangent kernel (NTK) based two-sample test based on neural network Maximum Mean Discrepancy (MMD) statistic. The NTK-MMD statistic is based on the connection between NTK and kernel MMD. Theoretically, the authors show that the NTK test statistic has the following properties: (1) Type-I error and testing power for performing the two sample test, (2) computational complexity, (3) memory and computational complexity of the MMD statistic, and (4) computational and memory-efficient. "
SP:1df2ffbbe56b8018067820980b93af2a8b57f891,"This paper proposes a variational autoencoder (VAE) based method to decompose an image x into x = G(x)+R(x), where R(x) captures the essential information for classification while G covers all class-redundant information. The authors show that the perturbations generated by adversarial attacks mainly lie in the class-dependent part x-G(x). The decomposition results also provide novel interpretations to classification and attack models. Inspired by these observations, the authors propose to conduct adversarial detection and adversarial defense respectively on x - G(X) and G(Y), which consistently outperform the results on the original x."
SP:2789874561620ba7894c4672f935056bb911e919,"This paper proposes a federated Thompson sampling (FTS) algorithm with differential privacy (DP) guarantee for federated learning. The algorithm is based on the general DP framework and uses distributed exploration (DE) to further improve the utility of the algorithm. The authors provide theoretical guarantees for both the privacy and utility of DP-FTS-DE, which combine to yield a number of elegant theoretical insights about the privacy-utility trade-off. Empirical results show that the proposed algorithm achieves high utility (competitive performance) with a strong privacy guarantee (small privacy loss). "
SP:be7d6b81736a2c3f89abd8771b41b18802e88832,"This paper proposes a Gaussian process-Bayesian Bernoulli mixture model (GP-BM) for multi-label active learning (ML-AL). The BM encodes label correlations using a Bayesian mixture of label clusters, where each mixture component corresponds to a global pattern of label correlations. To tackle highly sparse labels under AL, the BM is further integrated with a predictive GP to connect data features as an effective inductive bias and achieve a feature-component-label mapping. A novel auxiliary variable based variational inference algorithm is developed to tackle the non-conjugacy introduced along with the mapping process for efficient end-to-end posterior inference. A principled sampling function is designed accordingly to capture both the feature uncertainty (through GP) and label covariance (through BM) for effective data sampling."
SP:2b7270b0370c193300bcbbb5fb0a4101b3329d99,"This paper proposes a new method for 3D object detection, segmentation, and segmentation on the nuScenes dataset. The main contribution of this paper is the use of a polar coordinate system to represent the point cloud. The proposed method is based on the multi-scale padding from neighboring sectors. The authors also propose feature undistortion and range stratified convolutions to improve the performance of the proposed method. "
SP:7ae2c5b7d9c8a6c8f4a353606aa419929c47f31b,"This paper studies the problem of learning structured latent variables. The authors propose a framework to define structured variables along with a low-variance score function gradient estimator. The goal is to allow training models that do not admit relaxed variables and to improve optimization by alleviating the bias of the relaxed estimators. To achieve the goal, the authors define the structured variable as an output of an algorithm with a perturbed input. Then, they outline a family of algorithms with a common property that they call stochastic invariant. In the experiments, they consider various structured latent variable models and achieve results competitive with relaxation-based counterparts."
SP:415d363c66a6967c1daca9dc02001b85bf7f0752,"This paper proposes GainTuning, a method for adapting CNN denoisers trained on large datasets to a single test image. To avoid overfitting, the method optimizes a single multiplicative scaling parameter (the Gain) of each channel in the convolutional layers of the CNN. The method is evaluated on standard image denoising benchmarks, where it is shown to outperform existing methods. It is also demonstrated in a real-world application to reconstruct the structure of catalytic nanoparticles."
SP:90afa1102683b456bc72a54abef466326827546a,This paper proposes a differentiable architecture for panoptic segmentation (a.k.a. semantic and instance segmentation) consisting of a convolutional neural network and an asymmetric multi-way cut problem solver. The latter solves a combinatorial optimization problem that elegantly incorporates semantic and boundary predictions to produce a pan-optic labeling. The formulation allows to directly maximize a smooth surrogate of the pan-opinion quality metric by backpropagating the gradient through the optimization problem. Experiments on Cityscapes and COCO datasets demonstrate the effectiveness of the proposed method.
SP:1952e174d9ec7b83ad1d394ece7fe77ea1f6d78d,"This paper proposes Recursive Bayesian Networks (RBNs), which generalize and unify PCFGs and DBNs by combining their strengths and containing both as special cases. RBNs define a joint distribution over tree-structured Bayesian networks with discrete or continuous latent variables. The main challenge lies in performing joint inference over the exponential number of possible structures and the continuous variables. Two solutions are provided: 1) generalizing inside and outside probabilities from PCFG to the mixed discrete-continuous case, which allows for maximum posterior estimates of the continuous latent variable via gradient descent, while marginalising over network structures. 2) for Gaussian RBN, the authors derive an analytic approximation of the marginal data likelihood (evidence) and marginal posterior distribution, allowing for robust parameter optimisation and Bayesian inference. "
SP:5f29b169d3e4bbaeeec85e1aeebe2094fae4be6e,"This paper proposes a constrained backpropagation (CBP) algorithm based on the pseudo-Lagrange multiplier method to obtain the optimal set of weights that satisfy a given set of constraints. The proposed CBP algorithm is the utilization of a Lagrangian function (loss function plus constraint function) as its objective function. The authors considered various types of constraints — binary, ternary, one-bit shift, and two bit shift weight constraints. As a post-training method, CBP applied to AlexNet, Resnet-18, ResNet-50, and GoogLeNet on ImageNet. "
SP:3ddf8e2e108fb261bb23aec8a27a25aba7523dc1,"This paper studies active learning for Gaussian Process Classification (GPC) with query synthesis. The authors propose a novel active learning strategy based on estimating the estimated error reduction (EER) of the joint distribution of label pairs, which avoids retraining the GPC for each query when calculating the EER-based acquisition function. They also derive the gradient chain rule to efficiently calculate the gradient of the acquisition function, which leads to the first query synthesis active learning algorithm implementing EER based strategies. The experiments demonstrate the effectiveness of the proposed algorithms. "
SP:fa1fac04cd4ccb1f3eaf80807db09f9683ce6b50,"This paper studies the effect of unbounded gradients on the regularization of variational autoencoder (VAE) models when the data lies on a low-dimensional manifold (e.g., natural images). It shows that if the ultimate goal is to simultaneously avoid over-regularization (high reconstruction errors, sometimes referred to as posterior collapse) and under regularization (excessive latent dimensions are not pruned from the model), then a VAE-based energy function with infinite gradients around optimal representations is provably required per a certain technical sense. This result suggests that heuristic modifications to or constraints on the VAE energy function may at times be ill-advised. "
SP:2611cfd6e0696a57d061687993cef1fe5c95999d,"This paper studies the regret of a directed graph G = (V,E) where V is the collection of bandit arms and E is the number of incident arms. The authors propose the fractional weak domination number and the k-packing independence number to capture the upper bound and lower bound for the regret respectively. They show that the two notions are inherently connected via aligning them with the linear program of the weakly dominating set and its dual. They then utilize the strong duality theorem to prove a general regret upper bound O(\delta,\delta) and a lower bound $\Omega(1/\alpha)$ where alpha is the integrality gap of the dual linear program. Their bounds are tight up to a (log |V |) 1 3 factor on graphs with bounded integrality gaps. "
SP:e50dec57af337839cbde4b65fb7b431785fda44d,"This paper proposes a new neighbourhood reference distribution to improve the interpretability of Shapley values. The authors show that the Nadaraya-Watson estimator, a well-studied kernel regressor, can be expressed as a self-normalized importance sampling estimator. The proposed neighborhood reference distributions are shown to be more interpretable than the standard SHAP values. They also show how smoothing can be used to stabilize the SHAP value."
SP:35bdeb78f9fe74e754177fb54b48e7399dc8590d,"This paper proposes PlayVirtual, which augments cycle-consistent virtual trajectories to enhance the data efficiency for RL feature representation learning. Specifically, PlayVirtual predicts future states in a latent space based on the current state and action by a dynamics model and then predicts the previous states by a backward dynamics model, which forms a trajectory cycle. Based on this, the authors augment the actions to generate a large amount of virtual state-action trajectories. The authors validate the effectiveness of their designs on the Atari and DeepMind Control Suite benchmarks."
SP:ca09e472cbcf2ac8c8c9b192a87df2ed59218210,This paper studies the relationship between network architecture and robustness to noisy labels. The authors propose a formal framework connecting the robustness of a network to the alignments between its architecture and target/noise functions. The framework measures a network’s robustness via the predictive power in its representations — the test performance of a linear model trained on the learned representations using a small set of clean labels. They hypothesize that a network is more robust if its architecture is more aligned with the target function than the noise. They provide both theoretical and empirical evidence to support their hypothesis.
SP:903727fe028684623a8ccadec210e641ecffc685,"This paper proposes an algorithm for off-policy example-based control. The key idea is to directly learn to predict whether the task will be solved in the future via recursive classification, without using separate reward learning and policy search procedures. The authors show that their method satisfies a new data-driven Bellman equation, where examples take the place of the typical reward function term. Experiments show that the proposed method outperforms prior methods that learn explicit reward functions."
SP:39ccbd5909a1d7ed212fe92d8d6843c2c70dfe1f,"This paper studies differentially private stochastic optimization in convex and non-convex settings. In the convex case, the authors focus on the family of non-smooth generalized linear losses (GLLs). Their algorithm for the l2 setting achieves optimal excess population risk in near-linear time, while the best known differential private algorithms for general convex losses run in superlinear time. The authors also provide several new algorithms for approximating stationary points of the population risk. "
SP:99a476f71e6901aefe281f11fb72ff78265a5b6e,"This paper studies the cooperative bandit problem in three different imperfect communication settings: stochastic time-varying networks, instantaneous reward sharing over a network with random delays, and message-passing with adversarially corrupted rewards. The authors propose decentralized algorithms that achieve competitive performance, along with near-optimal guarantees on the incurred group regret as well. In the setting with perfect communication, they present an improved delayed-update algorithm that outperforms the existing state-of-the-art on various network topologies. "
SP:d3e896a65470f2439bc7753b4f66e152306b2d6f,"This paper proposes a post-training quantization method for vision transformers. The quantization process in the transformer is formulated as an optimization problem for finding the optimal quantization intervals. To preserve the functionality of the attention mechanism, the authors introduce a ranking loss into the conventional quantization objective that aims to keep the relative order of the self-attention results after quantization. Moreover, they thoroughly analyze the relationship between quantization loss of different layers and the feature diversity, and explore a mixed-precision quantization scheme by exploiting the nuclear norm of each attention map and output feature."
SP:aa6b1328585b5916267a3ff4f9119e7aa4ce2bb5,"This paper studies the convergence rate of double Q-learning under the assumption of a constant learning rate. The main contribution of this paper is to provide convergence rates for synchronous and asynchronous double-Q-learning. In particular, the authors show that synchronous double-q-learning converges to a global optimum with a time complexity of $\Omega(\sqrt{L}(1-\gamma)^7^2)$, where $\gamma$ is the discount factor, $D$ the cardinality of the state-action space, and $L$ is a parameter related to the sampling strategy for asynchronous double Q learning. The authors also provide convergence guarantees for function approximation."
SP:04fd4d83717c4f7e1a4b5651a59200151f33411d,This paper proposes a semi-supervised OOD detection method based on the Structure-Keep Unzipping (Steps) method. The main idea is to learn a new representation space in which OOD samples can be separated well. An efficient optimization algorithm is derived to solve the objective. Comprehensive experiments are conducted to demonstrate the effectiveness of the proposed method. 
SP:6bf8b94483b26033795b0eda9649518027f5e1c2,"This paper proposes a transformer-based model for the task of referring expression comprehension (REC) and segmentation (RES). The main idea is to use a transformer architecture, where two modalities are fused in a visual-lingual encoder. In the decoder, the model learns to generate contextualized lingual queries which are then decoded and used to directly regress the bounding box and produce a segmentation mask for the corresponding referred regions. With this simple but highly contextualized model, the authors outperform state-of-the-art methods on both REC and RES tasks."
SP:29b552b36696c9bda72f3ab4f31605d98880fd6b,"This paper studies the problem of multiclass boosting, where the weak learner is assumed to belong to an easy-to-learn base class and the booster is an agnostic PAC learner for that class with respect to the standard classification loss. The goal of the overall boosting algorithm is then to learn a combination of weak hypotheses by repeatedly calling the weak learners. The authors study the resources required for boosting, especially how they depend on the number of classes k, for both the booster and weak learners, and show that the boosting algorithm itself only requires O(log k) samples, as they show by analyzing a variant of AdaBoost for our setting. In stark contrast, assuming typical limits on number of weak-learner calls, they prove that the number samples required by a weak learners is at least polynomial in k."
SP:f63b050773871338c48b778c362172e4b72477a4,"This paper proposes a novel method for unsupervised object segmentation and object-centric scene generation. The proposed method is based on embedding-based approach in which embeddings of pixels are clustered in a differentiable fashion using a stochastic stick-breaking process. Similar to iterative refinement, this clustering procedure also leads to randomly ordered object representations, but without the need of initialising a fixed number of clusters a priori. This is used to develop a new model, GENESIS-V2, which can infer a variable number of object representations without using RNNs or iterative refining. Experiments show that the proposed method outperforms several baselines on synthetic datasets and more complex real-world datasets."
SP:408deb9e5577ee7118b836fee77135df641fe545,This paper proposes an adaptive conformal inference method for prediction sets that are robust to changes in the marginal distribution of the data. The main idea is to model the distribution shift as a learning problem in a single parameter whose optimal value is varying over time and must be continuously re-estimated. The authors show that over long time intervals ACI achieves the target coverage frequency without any assumptions on the data-generating distribution. The performance of ACI is controlled by the size of the shift in the optimal parameter.
SP:e6e5b1e2428abcf1a163ec1cce15cd299f9a544f,"This paper proposes a Pose-level Inference Network (PINet) for multi-person pose estimation in crowded scenes. PINet first applies the Part-based Pose Generation (PPG) to infer multiple coarse poses for each person from his/her body parts. Those coarse poses are refined by the Pose Refinement module through incorporating pose priors, and finally are fused in the Pose Fusion module. Experiments on several crowded scenes pose estimation benchmarks demonstrate the superiority of PINet."
SP:e76f048c3dccffcb8bcc6a66f6165fc19d175610,This paper studies the problem of solving robust RMDPs with L-constrained rectangular ambiguity sets. The authors propose a homotopy continuation method and a bisection method to solve S-rectangular ambiguity in quasi-linear time in the number of states and actions. The algorithm improves on the cubic time required by leading general linear programming methods. The experimental results confirm the practical viability of the proposed method.
SP:c4af66a64a5c2bd58ca2e29dbc4b27d5bf4b63b8,"This paper studies the problem of online knapsack with frequency predictions, where the frequency predictions are a lower bound and an upper bound on the number of items of each value. The goal is to design an online algorithm with the best competitive ratio for this prediction model. The authors show that even seemingly weak predictions can be exploited to give provably better competitive ratios. "
SP:1d478d4fa3f5df0ded963ef164325667fd744dbb,"This paper proposes an episodic memory-based episodic control method that combines model-based, episodic and episodic-regularized learning to improve sample efficiency in reinforcement learning. The proposed method is based on a trajectory model that stores episodic trajectories and a memory that is updated based on the trajectory model. The memory estimates trajectory values, which are then used to guide the agent towards good policies. Experiments are conducted on a variety of environments including stochastic and non-Markovian settings."
SP:551174c1266b5f4b6aaf5432a4c713386f90898c,"This paper proposes a new semi-supervised learning method called DP-SSL that uses data programming (DP) to generate probabilistic labels for unlabeled data. Different from existing DP methods that rely on human experts to provide initial labeling functions (LFs), this paper develops a multiple-choice learning (MCL) based approach to automatically generate LFs from scratch in SSL style. With the noisy labels produced by the LFs, a label model is designed to resolve the conflict and overlap among noisy labels, and finally infer probablistic labels. Extensive experiments on four standard SSL benchmarks show that the proposed method achieves better classification performance than existing SSL methods."
SP:d1d6a40a8bde62a21da4fc18a076e344c84ab0d0,This paper proposes a multi-view Pose Transformer (MVPT) model for estimating multi-person 3D poses. The key idea is to use a joint embedding to represent the joint locations and a projective attention module to fuse the cross-view information for each joint. Experiments are conducted on the Panoptic dataset to demonstrate the effectiveness of the proposed method.
SP:2e147bd5321e25bb27d2531fd58c46460a1e5320,"This paper studies the problem of recovering the supports of unknown sparse vectors from a mixture of noisy responses. The authors show that under a mild assumption on the support of unknown vectors, they also show the existence of learning algorithms for the second problem and rigorously analyze their query complexity. For the approximate recovery problem, they suggest single-stage and two-stage reconstruction algorithms working under Assumption 1. "
SP:e3388e479a825be429f3a878e2c4d8b05903ff10,"This paper studies the problem of bandit changepoint detection, where sensing actions (or sensors) are sequentially chosen, and only measurements corresponding to chosen actions are observed. The authors derive an information-theoretic lower bound on the detection delay for a general class of finitely parameterized probability distributions. They then propose a computationally efficient online sensing scheme, which seamlessly balances the need for exploration of different sensing options with exploitation of querying informative actions. They derive expected delay bounds for the proposed scheme and show that these bounds match the information lower bound at low false alarm rates, establishing optimality of the proposed method."
SP:268260e9452ba2bc57e50a6b7b3328233137ac9b,"This paper studies the convergence of stochastic nested optimization algorithms. The authors propose a new algorithm called ALternating Stochastic Gradient dEscenT (ALSET) that unifies several SGD-type updates for nested problems into a single SGD approach. The main contribution of this paper is to provide a tighter analysis of ALSET for nested optimization problems. Under the new analysis, to achieve an -stationary point of the nested problem, it requires O(-2) samples in total. Under certain regularity conditions, applying their results to stochastically compositional, min-max, and reinforcement learning problems either improves or matches the best-known sample complexity in the respective cases."
SP:82ad52361bc5b2c421f1dc6b76e1a5520570fc6c,This paper proposes a Siamese Sampling and Reasoning (SiaSamRea) method for video question answering. The key idea is to use a siamese sampling mechanism to generate sparse and similar clips from the same video. The reasoning strategy is composed of two modules: (1) siamesese knowledge generation to learn the inter-relationship among clips; and (2) siamee knowledge reasoning to produce the refined soft label by propagating the weights of the predicted candidates of all clips. Extensive experiments demonstrate the effectiveness of the proposed method.
SP:160022e2cd61159da92f92e85520b7062a337a8d,"This paper proposes a method to reduce the computational and memory complexity of a large class of structured distributions, i.e. distributions over combinatorial spaces, which are commonly used to learn latent probabilistic representations from observed data. This work shows that by viewing the central inference step as a matrix-vector product and using a low-rank constraint, we can trade off model expressivity and speed via the rank. Experiments with neural parameterized structured models for language modeling, polyphonic music modeling, unsupervised grammar induction, and video modeling show that our approach matches the accuracy of standard models at large state spaces while providing practical speedups."
SP:238592ad73927194cdf0c0cf9ae2e48ca86e182c,"This paper introduces Sample Average Uncertainty (SAU), a simple and efficient uncertainty measure for contextual bandit problems. SAU is a frequentist approach that directly estimates the uncertainty of the outcomes based on the value predictions. The authors show theoretically that the uncertainty measure estimated by SAU asymptotically matches the uncertainty provided by Thompson Sampling, as well as its regret bounds. Because of its simplicity SAU can be seamlessly applied to deep contextual bandits as a very scalable drop-in replacement for epsilongreedy exploration."
SP:ffc5b18f7e18607b2934e5aa199e7542005d79f4,"This paper presents a method for learning behavioral embeddings from multi-view, high-resolution behavioral videos. The method is based on disentangling the dynamic behavioral factors (pose) from time-invariant, non-behavioral nuisance factors (context) in a deep autoencoder, and exploit the temporal structures of pose dynamics. The authors further combine DBE with a stochastic temporal model to propose Variational Disentangled Behavior Embedding (VDBE), an end-to-end approach that learns meaningful discrete behavior representations and generates interpretable behavior videos. Compared to competing approaches, DBE and VDBE enjoy superior performance on downstream tasks like fine-grained behavioral motif generation and behavior decoding."
SP:bf78a450e4aad6b87fdeb8ec0d68adaaff7b595b,This paper proposes a deep 3D conditional generative model (DMTET) that can synthesize high-resolution 3D shapes using simple user guides such as coarse voxels. It marries the merits of implicit and explicit 3D representations by leveraging a novel hybrid 3D representation. The core of DMTET includes a deformable tetrahedral grid that encodes a discretized signed distance function and a differentiable marching tetrahedra layer that converts the implicit signed distance representation to the explicit surface mesh representation. This combination allows joint optimization of the surface geometry and topology as well as generation of the hierarchy of subdivisions using reconstruction and adversarial losses defined explicitly on the surface mesh.
SP:2bc0bd6aa2a12691b16145f0d23542c4c86e3a44,"This paper proposes sliced mutual information (SMI) as a surrogate measure of dependence between high dimensional random variables. SMI is defined as an average of MI terms between one-dimensional random projections. The authors show that SMI preserves many of the structural properties of classic MI, while gaining scalable computation and efficient estimation from samples. Experiments validating the theoretical study are provided, demonstrating dimension free empirical convergence rates, statistical efficiency for independence testing, and feature extraction examples."
SP:e220b348901b476c2afd95f97630fb5400582f40,"This paper proposes a two-step lookahead constrained constrained Bayesian optimization acquisition function (2-OPT-C) for both sequential and batch settings. The authors argue that being non-myopic is even more important in constrained problems because fear of violating constraints pushes myopic methods away from sampling the boundary between feasible and infeasible regions, slowing the discovery of optimal solutions with tight constraints. The likelihood ratio method that they use here to estimate the gradient of the acquisition function relies on a change of measure of the same type used within importance sampling. In numerical experiments, the proposed method improves query efficiency by 2x or more over previous methods."
SP:51fbd861422647912f275b48861ea3c4812afdc8,"This paper proposes Multi-Dimensional Distributional DQN (MD3QN), which extends distributional RL to model the joint return distribution from multiple reward sources. The authors prove the convergence for the joint distributional Bellman operator and build an empirical algorithm by minimizing the Maximum Mean Discrepancy between joint return distributions and its Bellman target. The proposed method is evaluated on pixel-input environments with richly correlated reward functions, and outperforms previous RL methods."
SP:1f85c93d6bbfd65bf497c92c9cd534d799753097,"This paper proposes a method to reconstruct high-resolution, accurate, and regular triangular meshes from volumetric images. The method is based on a neural network to predict a dense 3D flow vector field from an image, and a Diffeomorphic Mesh Deformation (DMD) module, which is parameterized by a set of diffeomorphic mappings. The proposed method achieves state-of-the-art performance in the challenging brain cortical surface reconstruction problem."
SP:2f31d9cf4ad17ad08344439ca0aef7ec91944545,"This paper studies the problem of data deletion in the non-convex setting. In particular, the authors consider the case where the deletion request is adaptive, i.e., the deletion requests are made by a user in response to a model inversion attack. In this setting, the paper provides a general reduction from deletion guarantees against adaptive sequences to deletion guarantees for non-adaptive sequences, using differential privacy and its connection to max information. The paper also provides a practical attack against the SISA algorithm of Bourtoule et al. on CIFAR-10, MNIST, Fashion-MNIST. "
SP:7150006590e268ab732c9be6c9048f67a377f956,"This paper studies the conditional value at risk (CVaR) of the total return in Bayes-adaptive Markov decision processes (MDPs). The authors show that a policy optimising CVaR in this setting is risk-averse to both the epistemic uncertainty due to the prior distribution over MDPs, and the aleatoric uncertainty. They reformulate the problem as a two-player stochastic game and propose an approximate algorithm based on Monte Carlo tree search and Bayesian optimisation. Their experiments demonstrate that their approach significantly outperforms baseline approaches for this problem."
SP:a94f39406f73d7483ddd744ed2f03c78b8bc5d44,"This paper studies the behavior of shallow ReLU networks trained with the logistic loss via gradient descent on binary classification data where the underlying data distribution is general, and the (optimal) Bayes risk is not necessarily zero. In this setting, it is shown that gradient descent with early stopping achieves population risk arbitrarily close to optimal in terms of not just logistic and misclassification losses, but also in terms calibration, meaning the sigmoid mapping of its outputs approximates the true underlying conditional distribution arbitrarily finely. Moreover, the necessary iteration, sample, and architectural complexities of this analysis all scale naturally with a certain complexity measure of the true conditional model."
SP:a9c786cbb61e1f10f3542161b13e43a1a68ab34d,"This paper proposes a method for coordinated group detection on social media based on neural temporal point process (NTP) with prior knowledge. The method is based on learning a Gibbs distribution of group assignment based on how consistent an assignment is to (1) the account embedding space and (2) the prior knowledge, and the authors propose a theoretically guaranteed variational inference approach to learn a mean-field approximation for it. Experimental results on a real-world dataset show the effectiveness of the proposed method compared to state-of-the-art model in both unsupervised and semi-supervised settings."
SP:b5c6e967a26a02861db2ecd620e9061db0c03e59,"This paper studies the problem of binary classification of two disjoint smooth curves on the unit sphere. The authors prove that when the network depth is large relative to certain geometric properties that set the difficulty of the problem and the network width and number of samples are polynomial in the depth, randomly-initialized gradient descent quickly learns to correctly classify all points on the two curves with high probability. This is the first generalization guarantee for deep networks with nonlinear data that depends only on intrinsic data properties. The analysis proceeds by a reduction to dynamics in the neural tangent kernel (NTK) regime. "
SP:8f6bee3be43df6b6e80804974014caaafe08c49e,"This paper proposes a new auxiliary classifier GAN, ReACGAN, to address the issue of gradient exploding in the classifier in the early stages of training. Specifically, the authors identify that the gradient exploding problem is caused by the unboundedness of input feature vectors and poor classification ability of classifier. To alleviate this problem, they propose the Data-to-Data Cross-Entropy loss (D2D-CE) and the Rebooted Auxiliary Classifier Generative Adversarial Network (ReACGAN) to alleviate the instability and reinforce ACGAN. The experimental results show the effectiveness of the proposed method. "
SP:080e80746a87228b156408ff649ab7a17f44e92d,"This paper proposes an extensive form double oracle (XDO) algorithm for two-player zero-sum games that is guaranteed to converge to an approximate Nash equilibrium linearly in the number of infostates. Unlike PSRO, XDO mixes best responses at every infostate. The authors also introduce Neural XDO (NXDO), where the best response is learned through deep RL. Experiments on a modified Leduc poker game and Oshi-Zumo show that XDO achieves a lower exploitability than CFR with the same amount of computation."
SP:bda04facef4f34679fc4e17b8ea1aae74c3d649f,"This paper proposes a permutation-invariant variational autoencoder for graph structured data. The proposed model indirectly learns to match the node order of input and output graph, without imposing a particular node order or performing expensive graph matching. The authors demonstrate the effectiveness of the proposed model for graph reconstruction, generation and interpolation. "
SP:e17ea6aeba78c9dfc25596d8b35a2a4f1f1f6763,"This paper proposes a method to decouple the depth and scope of GNNs. Specifically, to generate representation of a target entity (i.e., a node or an edge), the authors first extract a localized subgraph as the bounded-size scope, and then apply a GNN of arbitrary depth on top of the subgraph. A properly extracted subgraph consists of a small number of critical neighbors, while excluding irrelevant ones. The GNN, no matter how deep it is, smooths the local neighborhood into informative representation rather than oversmoothing the global graph into “white noise”. Theoretically, the paper shows that the proposed method improves the GNN expressive power from the perspectives of graph signal processing (GCN), function approximation (GraphSAGE) and topological learning (GIN). Empirically, on seven graphs (with up to 110M nodes) and six backbone GNN architectures, the design achieves significant accuracy improvement with orders of magnitude reduction in computation and hardware cost."
SP:4890f251db559a0a572afc66e0c1f899b577d9ff,This paper studies the universal approximation of any log-concave distribution with well-conditioned affine-coupling normalizing flows. The authors show that any distribution can be approximated by affine coupling networks with a well-conditional Jacobian. The proof is based on underdamped Langevin dynamics and Hénon-like maps. 
SP:5ffa81488ed1092deb89bd5e150fa146325057ce,"This paper studies the problem of coupons allocation in an online e-commerce market. The authors propose a budget constrained offline reinforcement learning and evaluation with $\lambda$-generalization (BCORLE(lambda)$ framework to solve the CMDP problem of coupon allocation. Specifically, the proposed method is based on a generalization of the Lagrangian of the value of $\lambda$. The authors also propose a new offline RL algorithm called R-BCQ to improve the performance of policy learning. Experiments on a simulation platform and a real mobile shopping app validate the effectiveness of the proposed methods."
SP:6b04cc7b4e45b9e65a1d34c15e3f75a2ef27d601,"This paper proposes a method for source-free domain adaptation (SFDA) where the source pretrained model is adapted to the target domain in the absence of source data. The method is based on the observation that target data, which might no longer align with the source domain classifier, still form clear clusters. To capture this intrinsic structure, the authors define local affinity of the target data and encourage label consistency among data with high local affinity. The authors observe that higher affinity should be assigned to reciprocal neighbors, and propose a self regularization loss to decrease the negative impact of noisy neighbors. To aggregate information with more context, they consider expanded neighborhoods with small affinity values."
SP:ac1bf04ff782e5892a0bc5fe5949848ca8e731c2,"This paper proposes a novel pooling mechanism for embedding sets of various sizes into a fixed-size representation. The proposed method, Pooling by Sliced-Wasserstein Embedding (PSWE), provides an exact Euclidean embedding for the (generalized) sliced-SW distance between the set elements and a reference set, whose elements are learned in an end-to-end fashion, alongside with the slicer parameters. Experiments show that PSWE outperforms baseline pooling mechanisms on a variety of supervised classification tasks on point cloud, graph, and image datasets."
SP:6cb2f0cbc076f8680cb00411790629f8e1478053,"This paper proposes a new family of RNNs, called SBO-RNN, that can be formulated using stochastic bilevel optimization (SBO) to solve the lower and upper-level optimization for learning hidden states and their hyperparameters, respectively. The authors prove that under mild conditions there is no vanishing or exploding gradient in training the proposed RNN. Empirically, the proposed method achieves superior performance on several benchmark datasets with fewer parameters, less training data, and faster convergence."
SP:d3a4300e21ca215334f256f0467a428470548fe4,"This paper studies the online problem of minimizing power consumption in systems with multiple power-saving states. During idle periods of unknown lengths, an algorithm has to choose between power saving states of different energy consumption and wake-up costs. The authors develop a learning-augmented online algorithm that makes decisions based on (potentially inaccurate) predicted lengths of the idle periods. The algorithm’s performance is near-optimal when predictions are accurate and degrades gracefully with increasing prediction error. "
SP:22aba6284123af0ecd6605ee4e89b351bd7e10a3,"This paper studies the problem of multi-source transfer learning in the setting where the source and target tasks are linearly combined for learning the target task. The authors propose a transferability measure based on the sample sizes, model complexity, and the similarities between the target and source tasks. Theoretical analysis of the transferability is provided, and an alternating iterative algorithm is proposed. Experiments on image classification tasks show that the proposed method outperforms existing transfer learning algorithms in multi- source and few-shot scenarios."
SP:0fb8dcf15e0d43547d566fdba7bc70b3bb600005,"This paper proposes a neural network model called eccNET, which takes a target and a search image as inputs and produces a sequence of eye movements until the target is found. The model integrates eccentricity-dependent visual recognition with target-dependent top-down cues. It is compared with human behavior in six paradigmatic search tasks that show asymmetry in humans."
SP:f0cc968ea9da4884dcdaf6d0c75ea9f1511bdfc3,"This paper studies the problem of certifiable robustness, i.e., robustness to adversarial perturbations. The authors propose a new method for certifiable training based on a linear relaxation of the worst-case loss. The main contribution of the paper is that the authors identify that the smoothness of the loss landscape is an important factor that influences in building certifiably robust models. Based on this observation, they propose a method that satisfies the two criteria. "
SP:a158f8772a9dada059ffd1d6d7838ed40d8483da,"This paper studies the problem of online linear regression in the stochastic setting. The authors derive high probability regret bounds for online ridge regression and the forward algorithm. The main contribution of this paper is to show that the forward method is better than the ridge method in terms of the regret. The paper also shows how to integrate it in algorithms involving linear function approximation to remove a boundedness assumption without deteriorating theoretical bounds. Finally, numerical experiments are provided to validate the theoretical results."
SP:17ff9a2133aebf2d1b1787e8efc49d709389c0e7,"This paper proposes a two-time-scale and anchored extragradient (FEG) method for smooth structured nonconvex-nonconcave problems. The proposed FEG has an accelerated O(1/k2) rate, with respect to the squared gradient norm, for the Lipschitz continuous and negative comonotone operators for the first time. This paper further develops its backtracking line-search version, named FEG-A for the case where the problem parameters are not available. "
SP:4e38973033de24fc183c6112e1146f8eef0ddaea,"This paper studies the problem of uniformity testing for ranking data that consists of rankings over m items, where the alternative class is restricted to Mallows models. The authors show that uniform distribution can be distinguished from Mallows model with O(m 1/2) samples based on simple pairwise statistics, which allows us to test uniformity using only two samples, if m is large enough. They also propose a central DP algorithm that requires O(max{1/\�0, 1/p m}), where $\�0$ is the privacy budget parameter."
SP:99a835191a3ba8372e391b6d3316e9b68e543295,This paper studies a general greedy score-based algorithm for learning directed acyclic graphs (DAGs). The main contribution of the paper is to show that the proposed algorithm is vertex-greedy and requires at most a polynomial number of score evaluations. The paper also shows that recent polynomials-time algorithms for learning DAG models are a special case of this algorithm. This observation suggests new score functions and optimality conditions based on the duality between Bregman divergences and exponential families. 
SP:b60989706296b963b6671c01f22384978a334be1,This paper proposes a neural architecture dilation for adversarial robustness (NADAR) method to improve the robustness of the backbone CNNs that have a satisfactory accuracy. The main idea is to dilate the backbone network to achieve a maximal robustness gain while preserving a minimal accuracy drop. Theoretical analysis on the standard and adversarial error bounds naturally motivate the proposed method. The experimental results on real-world datasets and benchmark neural networks demonstrate the effectiveness of the proposed algorithm.
SP:77ed765e911a4e5f2bfba13cbd2403500a5d05e6,"This paper studies the problem of model-based reward-free reinforcement learning with linear function approximation for episodic Markov decision processes (MDPs). In this setting, the agent works in two phases. The first phase is the exploration phase, where the agent interacts with the environment and collects samples without the reward. In the second phase, the policy is given a specific reward function and uses the samples collected from the first phase to learn a good policy in the planning phase. The authors propose a new provably efficient algorithm UCRL-RFE under the linear mixture MDP assumption where the transition probability kernel of the MDP can be parameterized by a linear function over certain feature mappings defined on the triplet of state, action, and next state. They show that to obtain an $\epsilon$-optimal policy for arbitrary reward function, the algorithm needs to sample at most $\tilde{O}(H^5d^2\eps^{-2})$ episodes during the exploration phases. They also propose a variant of UCRLRFE using Bernstein-type bonus and show that it needs to samples at most $O(Hd(H + d)$ samples to achieve an $\eps^{2}$ samples for any reward function. The sample complexity of the algorithm matches the lower bound in terms of the dependence on accuracy and feature dimension $d$."
SP:28563ba0975f56ddb662cd46e85de78bb6024d36,"This paper proposes a method for forecasting future events in a data stream of events with seasonal patterns that evolve over time. The proposed method is based on the Shifting Seasonal Matrix Factorization (SSMF) approach that can adaptively learn multiple seasonal patterns (called regimes), as well as switching between them. The method has the following properties: (a) it accurately forecasts future events by detecting regime shifts in seasonal patterns as the data stream evolves; (b) it works in an online setting, i.e., processes each observation in constant time and memory; and (c) it effectively realizes regime shifts without human intervention by using a lossless data compression scheme. Experiments are conducted on three real-world data streams."
SP:e4bb07033001be4d04695ef058f426d49fe440be,"This paper proposes a novel neural network architecture, WeaveNet, to solve the assignment problem. The core module, feature weaving layer, is stacked to model frequent communication between elements in a parameter-efficient way for solving the combinatorial problem of assignment. The experimental results show its impressive performance among the learning-based baselines."
SP:8a559e21d45661eef427b310e5fe8488d5749137,"This paper systematically studies the impact of various self-supervised learning proxy tasks on different architectures and threat models for 3D point clouds with adversarial training. Specifically, they study MLP-based PointNet, convolution-based DGCNN, and transformer-based (PCT) 3D architectures. Through extensive experimentation, they demonstrate that appropriate applications of Self-supervision can significantly enhance the robustness in 3d point cloud recognition, achieving considerable improvements compared to the standard adversarial robustness baseline. "
SP:657c5a1114c0d054b9e767d85990bbbb0492912d,This paper studies the problem of convex optimization over submodular base polytopes. The authors propose a method for computing iterative projections of close-by points over widely-prevalent sub-modular bases. The main contribution of the paper is to develop a toolkit to speed up the computation of projections using both discrete and continuous perspectives. They also adapt the away-step Frank-Wolfe algorithm to use this information and enable early termination. Theoretical results show orders of magnitude reduction in runtime.
SP:8dae43d6b5cebb7ef6c39437d997b390c2380536,This paper studies the problem of learning the natural parameters of a k-parameter minimal exponential family from i.i.d. samples in a computationally and statistically efficient manner. The authors focus on the setting where the support as well as natural parameters are appropriately bounded. They provide finite sample guarantees to achieve an error of alpha in the parameter estimation with sample complexity O(poly(k/alpha) and computational complexity $O(poly(\k/\alpha)$. They also provide an interpretation of their estimator in terms of a maximum likelihood estimation.
SP:4f9ddb697e86356fb293ef34a69ca3702c4e8164,This paper proposes a differentiable renderer for inverse graphics. The main idea is to use a convolutional neural network to predict 3D attributes of a mesh with pre-determined topology (sphere in the case of the paper) and then render these parameters back to an image using the renderer and apply a loss on the RGB output to compare the input image I and the rendered image I. Experiments are conducted on both synthetic and real images to demonstrate the effectiveness of the proposed method.
SP:6ac1c8556e7131939cc582f513bc9921470e1b09,"This paper proposes a differentiable training method that imposes implicit constraints to the shape of the probability map by minimizing the expectation of the localization error. To approximate the expectation, the authors introduce a continuous formulation of the output distribution and develop a sampling process. The expectation can be approximated by calculating the average error of all samples drawn from the distribution. Sampling-argmax is shown to be effective and flexible to different localization tasks."
SP:478c05c90090f9d80b72ac352c488073b45a5d8b,"This paper proposes a directed graph data augmentation method called Laplacian perturbation for graph contrastive learning (GCL). The proposed method is based on the observation that GCL usually uses predefined contrastive views with hand-picking parameters and does not take full advantage of the contrastive information provided by data augmentations, resulting in incomplete structure information for models learning. Based on this observation, this paper proposes to dynamically learn from all possible contrastive view generated by the Laplace perturbations. The method is trained using multi-task curriculum learning to progressively learn from multiple easy-to-difficult views. Experiments on various benchmarks reveal the dominance over the state-of-the-art approaches. "
SP:85b383d2f722f7bff438840e423f5cb4c67d5980,"This paper proposes a new benchmark for evaluating language grounded RL agents. The benchmark consists of five different environments: RTFM, Messenger, NetHack, ALFWorld, Touchdown, and NetHack. The authors propose the first shared model architecture for RL on these environments, and evaluate recent advances such as egocentric local convolution, recurrent state-tracking, entity-centric attention, and pretrained LM using the benchmark. They show that a shared architecture achieves comparable performance to environment-specific architectures. "
SP:23c8db56f59f778fe812a5dd161f7a1f21c3cdba,"This paper proposes Vision MoE (V-MoE), a sparse version of the Vision Transformer (ViT) that is scalable and competitive with the largest dense networks. The authors propose a new routing algorithm that can prioritize subsets of each input across the entire batch, leading to adaptive per-image compute. This allows V-MoEs to trade-off performance and compute smoothly at test-time. Finally, the authors demonstrate the potential of the proposed method to scale vision models and train a 15B parameter model that attains 90.35% on ImageNet."
SP:c5235f41dfb8b5cc478f11c5d5e0ab0b8676871e,"This paper studies the expressivity and trainability of narrow neural networks. The authors consider the case of a 1-hidden-layer network with n hidden neurons, where the activation function is smooth and the width is at most 2. They show that as long as the width m > 2n/d (where d is the input dimension), there exists at least one global minimizer with zero training loss. They also identify a nice local region with no local-min or saddle points and show that gradient descent can stay in this nice region. Finally, they show that the proposed training regime outperforms SGD for training narrow networks."
SP:0be529f5254afd59dcfa6b34a359c7037e7a8323,"This paper proposes a continuous mean-covariance bandit (CMCB) model that takes into account option correlation. Specifically, in CMCB, there is a learner who sequentially chooses weight vectors on given options and observes random feedback according to the decisions. The agent’s objective is to achieve the best trade-off between reward and risk, measured with option covariance. To capture different reward observation scenarios in practice, the authors consider three feedback settings, i.e., full-information, semi-bandit and full bandit feedback. They propose novel algorithms with optimal regrets (within logarithmic factors), and provide matching lower bounds to validate their optimalities. The experimental results also demonstrate the superiority of the algorithms."
SP:472a90bb175b0286765c5a47b040e1a58f594a05,"This paper studies the problem of computing PSD factorization of a matrix X, which is a collection of positive semidefinite matrices {Ai} and {Bj} satisfying the condition Xij = tr(AiBj) for all i \in [m, j\in [n]. The authors propose a non-commutative extension of Lee-Seung’s Multiplicative Update (MMU) algorithm, which they refer to as the matrix multiplicative update algorithm, to solve this problem. The authors show that under their update scheme the squared loss objective is non-increasing and fixed points correspond to critical points. They also show that the MMU algorithm can be used as a primitive to calculate block-diagonal PSD matrices and tensor PSD matrix factorizations."
SP:83abd6d149d88cc6e96cbc4d488e4fe9dc2a4fcb,"This paper proposes a meta-learning framework for domain generalization (DG) that disentangles domain-invariant and domain-specific features in a unified framework. The key insight is to disentangle features in the latent space while jointly learning both the domain invariant and the domain specific features. The domain specific representation is optimized through the meta learning framework to adapt from source domains, targeting a robust generalization on unseen domains. The experimental results show that mDSDI provides competitive results with state-of-the-art techniques in DG. "
SP:4191474c75e2fedf514f0f3001a67a047eb74c30,"This paper presents a method to improve the FID of diffusion models by using a series of ablations. The method is based on the DDIM model, which is a diffusion model that is trained with a denoising step. The authors show that their method is able to achieve better FID than the state-of-the-art on unconditional image synthesis and conditional image synthesis tasks. They also show that the proposed method can improve the quality of the generated images by using classifier guidance."
SP:fe3cab08596cde4c14ecf6fca8d0f95b02bab229,"This paper proposes to leverage out-of-distribution samples for improving few-shot learning. Specifically, the proposed method maximizes the distance from prototypes to out- of distribution samples while minimizing the distance between prototypes and support samples. The proposed approach is simple to implement, agnostic to feature extractors, lightweight without any additional cost for pre-training, and applicable to both inductive and transductive settings. Extensive experiments on various standard benchmarks demonstrate that the proposed approach consistently improves the performance of pretrained networks with different architectures."
SP:b1f65724926f136979829b7a6c870bc31f38f591,"This paper studies the problem of prioritized sampling in reinforcement learning. The authors propose two new prioritization strategies, ReMERN and ReMERT, based on the perspective of regret minimization. Theoretically, the authors show that prior prioritization methods such as PER, LFIW and DisCor are suboptimal when the objective function is different from the objective of RL. Based on this, they propose two practical prioritisation strategies, namely ReMern and ReERT, that directly aims to improve the policy. Experiments are conducted on MuJoCo, Atari and Meta-World to show the effectiveness of the proposed methods."
SP:601ebf30b3c6aa35fcef49633aa8eb0acd0f2c66,This paper studies the problem of sequential prediction with expert advice in a nonstationary environment with long-term memory guarantees in the sense of Bousquet and Warmuth [4]. The authors give a linear-time algorithm that improves on the best known regret bounds [27]. This algorithm incorporates a relative entropy projection step. This projection is advantageous over previous weight-sharing approaches in that weight updates may come with implicit costs as in for example portfolio optimization. 
SP:b2439973063e827b3cbe92306a2fdee3286b6b44,"This paper studies the problem of contextual linear bandits motivated by routing applications in navigational engines and recommendation systems. In this problem, the learner is presented with a subset Xt of possible actions, and the goal is to learn a hidden d-dimensional value w. Every round, we are presented with Xt. If we choose (i.e., recommend to the user) action Xxt, we obtain utility w. However, if we only learn the identity of the best action Xt, we only get utility w*. The authors provide algorithms for this problem that achieve regret O(d log T) and exp(O(dlog d). The authors also consider the variant where we are allowed to provide a list of several recommendations. "
SP:abe83c7e0bcf4829742609d709637e2f84d8a4d9,"This paper presents Lale, an open-source sklearn-compatible AutoML library. It introduces a small set of orthogonal combinators for composing machine learning operators into pipelines. It describes a translation scheme from pipelines and associated hyperparameter schemas to search spaces for AutoML optimizers. Lale gives users fine-grained control over AutoML without requiring them to be AutoML experts. "
SP:0d7f1cae577ed598048b64617e85ca6bd5c6d7fa," meta-learning is an interesting area of research in machine learning. This paper studies the effect of meta-learned learning rates on the generalization performance of the meta-learner. The authors show that the learning rates are sparse and that this sparsity is dependent on the task. They also show that this patterned sparsity emerges from this process, with the pattern of sparsity varying on a problem-by-problem basis."
SP:05037e1850003a725a466b64d3e32aa2aed458fb,"This paper studies the problem of identifying common components from multiple views. The authors propose a shared independent component analysis (ShICA) model that models each view as a linear transform of shared independent components contaminated by additive Gaussian noise. They show that this model is identifiable if the components are either non-Gaussian or have enough diversity in noise variances. They also show that in some cases multi-set canonical correlation analysis can recover the correct unmixing matrices, but that even a small amount of sampling noise makes Multiset CCA fail. To solve this problem, the authors propose to use joint diagonalization after Multisets CCA, leading to a new approach called ShICA-J. Experiments on fMRI and MEG show that ShICA leads to improved results while being very fast to fit."
SP:44dd1faa1813c433fd7581d05cae3df440bfb93e,"This paper proposes a novel multi-agent reinforcement learning method called Fictitious Co-Play (FCP) to improve the generalization of agents to new human co-players. The proposed method is based on self-play (SP) and population play (PP) techniques. The agent is trained as the best response to a population of self- play agents and their past checkpoints taken throughout training. The experiments show that FCP agents score significantly higher than SP, PP, and BCP when paired with novel agent and human partners."
SP:21c84bd720b1e90ea0f88fbf8fd24dbcb49b547c,"This paper proposes a multi-agent actor-critic method that learns decentralised policies with a centralised but factored critic. The centralised policy gradient estimator is based on a non-linear monotonic function that combines per-agent utilities into the joint action-value function. Experiments are conducted on multiagent particle environments, a novel multiagent MuJoCo benchmark and a challenging set of StarCraft II micromanagement tasks."
SP:1c8351b8a6cdf1212840388e19a596729b3bfda4,"This paper proposes a new neural network architecture that uses a combination of biologically plausible three-factor plasticity rules to store and read out memories in a single step. The key-value mechanism is based on Hebbian and non-Hebbian rules. The authors show that the same rules are recovered when network parameters are meta-learned. The proposed network performs on par with classical Hopfield networks on auto-associative memory tasks and can be naturally extended to continual recall, hetero-associationative memory, and sequence learning."
SP:7ad6da2c63859d64970e9b35326e9ceab48add47,"This paper studies the problem of learning a loss function that depends on a pair of instances. The authors propose stochastic and online gradient descent methods for pairwise learning. The main contribution of this paper is to propose a differentially private localized SGD algorithm for learning the loss function. The algorithm is based on SGD, and the main difference is that it only pairs the current instance with the previous one in building a gradient direction, which is efficient in both the storage and computational complexity. The paper also provides novel stability results, optimization, and generalization error bounds for both convex and nonconvex problems. "
SP:cb11dacc930d71a616ee2fbe4acfae030f9dca59,"This paper proposes a method to reconstruct dynamic objects from videos. The method is based on a canonical 4D implicit function which is pixel-aligned with aggregated temporal visual cues, and a 4D transformation module which captures object dynamics to support temporal propagation and aggregation. Experiments are conducted on SAIL-VOS 3D and DeformingThings4D++, and on real-world calibrated video data 3DPW."
SP:8ae97752e74b4395774575009031abcb6ba5cea7,This paper provides a non-asymptotic analysis of linear stochastic approximation (LSA) algorithms with fixed stepsize. The analysis is based on new results regarding moments and high probability bounds for products of matrices which are shown to be tight. The main contribution of this paper is to establish polynomial concentration bounds with order depending on the stepsize and show that no Gaussian or exponential high-probability bounds can hold. 
SP:86c1e937755e35efafecc09dfe2606ffb1653a41,"This paper extends the options framework for temporal abstraction in reinforcement learning from discounted to average-reward MDPs. The authors propose general convergent off-policy inter-option learning algorithms, intra-option algorithms for learning values and models, as well as sample-based planning variants of the learning algorithms. The algorithms and convergence proofs extend those recently developed by Wan, Naik, and Sutton. They also extend the notion of option-interrupting behavior from the discounted to the average reward formulation. "
SP:7e4e1e20e7c253d02c6ae58457fb30029f130f0c,"This paper proposes a self-supervised auxiliary task to regularize the training of visual transformers (VTs). The proposed task is based on the idea of dense token embedding pairs, and it encourages the VT to learn spatial information. Experiments show that the proposed task can improve the final accuracy of the trained VTs."
SP:0132ef17585e293b23e9dc45189c0989d829b52a,"This paper proposes a new method for label-free alignment of hierarchical data. The proposed method is based on hyperbolic Procrustes analysis (HPA), which consists of three components: translation, scaling, and rotation. The authors analyze the proposed components, highlight their useful properties for alignment. The efficacy of HPA, its theoretical properties, stability and computational efficiency are demonstrated in simulations. Finally, the authors demonstrate its performance on three batch correction tasks."
SP:3580ac64f09e3021de5d4c92411bcc0f3c5d10f3,"This paper studies the problem of generating privacy-protected micro-datasets for differentially private query answering. The authors show that there is a tradeoff between accuracy for a population of interest (sum query) vs. accuracy for its component sub-populations (point queries). This tradeoff is due to an uncertainty principle that governs the trade-off between the accuracy for the sum query and the accuracy of the sub-population of interest. The paper also provides lower bounds for pure, approximate, and concentrated differential privacy. Finally, the paper presents a collection of benchmark datasets that can be used for public study of this problem. "
SP:c0e64dc8acfaed3e4d7745af12fd34003d0e5017,"This paper proposes a method to combine RL and planning for long-horizon tasks. The method is based on decomposing a task into a series of sub-tasks and training the planner to minimize the RL agent’s cost of completing the sub-task sequence in each layer from top to bottom layers. The planning policy is trained to minimize its cost on top layers, while RL agent is trained on the easier sub- tasks with denser rewards on bottom layers and harder ones on the top layers. Experiments on navigation and continuous control tasks demonstrate the effectiveness of the proposed method."
SP:9911693a04a300b5a93634fb0267ef83e5489d77,"This paper proposes a Bayesian framework for generating local explanations for black-box classifiers. The framework is based on Bayesian versions of LIME and KernelSHAP, which output credible intervals for the feature importances, capturing the associated uncertainty. The resulting explanations not only enable us to make concrete inferences about their quality (e.g., there is a 95% chance that the feature importance lies within the given range), but are also highly consistent and stable. The authors also carry out a detailed theoretical analysis that leverages the aforementioned uncertainty to estimate how many perturbations to sample, and how to sample for faster convergence."
SP:5efb4b81bd37c70640e8768e9dfb5bba14a0cfb8,"This paper studies the problem of unordered heavy tails in Adder Neural Networks (ANNs). Specifically, the authors argue that the heavy-tailed feature distributions in ANNs could lead to worse classification and propose to pre-define ANN features to follow a mixture of Multivariate Skew Laplace distributions, with which the heavy tails can be better controlled with high order moment skewness. The authors propose to embed this mixture of skew Laplace into the loss function through substituting the distribution parameters for the classifier head. Experiments conducted on several benchmarks and comparison with other distributions demonstrate the effectiveness of proposed approach for boosting the performance of ANNs."
SP:cbccb65457564992d534504c0d060da44cafce8c,"This paper studies the phenomenon of Gradient Starvation (GS), a phenomenon that arises when training with cross-entropy loss in neural networks. The authors formalize GS by analyzing the dynamical system corresponding to the learning process in a dual space. They show that GS could slow down the learning of certain features, even if they are present in the training set. They derive spectral decoupling (SD) regularization as a possible remedy to GS."
SP:8f6fe37cb0a332b66e10cc00261a44622841c8c6,"This paper presents a single-blind evaluation of teams of humans and AI agents in the cooperative card game Hanabi, with both rule-based and learning-based agents. In addition to the game score, the authors also quantify subjective measures of the human’s perceived performance, teamwork, interpretability, trust, and overall preference of AI teammate. They find that humans have a clear preference toward a rule based AI teammate (SmartBot) over a state-of-the-art learning based AI agent (Other-Play) across nearly all subjective metrics, and generally view the learning based agent negatively, despite no statistical difference in game score. This result has implications for future AI design and reinforcement learning."
SP:2a05e333fc1a14057515ef3addde9a40152373db,"This paper proposes a new method for visual question generation (VQG) based on double-hints. The main idea is to use visual hints to guide the generation of high-quality questions. The proposed method is based on a GAN-based approach, where the discriminator is trained to distinguish whether a sample triplet (i.e., the image, answer, and question) is generated from the generator or ground truth. Experiments on two benchmark datasets show that the proposed method outperforms the baselines."
SP:15756d6ef47b39ded404acea2135c93bd5ee1062,"This paper proposes Generalized Data Weighting (GDW) to mitigate label noise and class imbalance by manipulating gradients at the class level. To be specific, GDW unrolls the loss gradient to class-level gradients by the chain rule and reweights the flow of each gradient separately. Extensive experiments in various settings verify the effectiveness of GDW."
SP:7a8f56a01bec51ebf70d9ff689005a62cccfe5c6,This paper introduces a novel task of learning spatio-temporal language grounding. The goal is to learn a truth function that predicts if a given sentence is true of temporally-extended observations of an agent interacting with a collection of objects. The paper proposes to use a Transformer architecture to learn the truth function. The experiments show that maintaining object identity in the attention computation of the Transformer is instrumental to achieving good performance on generalization overall. 
SP:3d4a9d439bc84c3b0e6600f6985a23bdf95cd67f,"This paper proposes Prototypical Cross-Attention Network (PCAN) for online multiple object tracking and segmentation. PCAN first distills a space-time memory into a set of prototypes and then employs cross-attention to retrieve rich information from the past frames. To segment each object, PCAN adopts a prototypical appearance module to learn aset of contrastive foreground and background prototypes, which are propagated over time. Extensive experiments demonstrate that PCAN outperforms current video instance tracking and video segmentation competition winners on both Youtube-VIS and BDD100K datasets. "
SP:1175ad16382b349ab1a39895150172d266abe571,"This paper studies the relationship between gradient flow and gradient descent in the context of deep neural networks. The authors show that gradient descent converges to the global minimum almost surely under random initialization. They also show that over deep neural network with homogeneous activations, gradient flow trajectories enjoy favorable curvature, suggesting that they are well approximated by gradient descent. This finding allows them to translate an analysis of gradient flow over deep linear neural networks into a guarantee of gradient descent convergence. "
SP:b8412e9ce82ce92125fe7cd3aff7bea8b906d16e,"This paper considers a stochastic multi-armed bandit problem with delayed impact of actions. In this setting, actions taken in the past impact the arm rewards in the subsequent future. This paper generalizes the bandit setting to encode the dependency of this ""bias"" due to the action history during learning. The goal is to maximize the collected utilities over time while taking into account the dynamics created by the delayed impacts of historical actions. The authors propose an algorithm that achieves a regret of $\tilde{O}(\KT^2/3)$ and a matching regret lower bound of $\Omega(KT^3)$, where K is the number arms and T is the learning horizon."
SP:9c1d678dff5f609197dc3cfb67b841827f4a439a,"This paper proposes an end-to-end solution for video instance segmentation (VIS) based on transformers. Specifically, the authors propose to utilize concise memory tokens as a means of conveying information as well as summarizing each frame scene. The features of each frame are enriched and correlated with other frames through exchange of information between the precisely encoded memory tokens. They validate their method on the latest benchmark sets and achieve state-of-the-art performance (AP 42.6 on YouTube-VIS 2019 val set using offline inference) while having a considerably fast runtime (89.4 FPS)."
SP:6c922eaa358f6fb9771690b1240e4f6f08a35b69,"This paper proposes a general graph embedding method, residual2vec, that can debias various structural biases in graphs by using random graphs. In particular, random walks are biased by the degree of each node, where a node is sampled proportionally to its degree. The authors show that this debiasing not only improves link prediction and clustering performance but also allows us to explicitly model salient structural properties in graph embeddings. "
SP:851eac96135b577a5014166edcb43db6a190cf4b,"This paper studies the problem of estimating non-linear functionals of discrete distributions in the context of local differential privacy. In particular, the authors consider the case where the data are i.i.d. and distributed according to an unknown discrete distribution p = (p1,..., pK). Only α-locally differentially private (LDP) samples are publicly available, where the term ‘local’ means that each zi is produced using one individual attribute xi. The authors study two plug-in type estimators of Fgamma for the non-interactive case and for the interactive case. They give lower bounds on the quadratic risk for estimating the power sum functional. "
SP:a0408b54f88a26479f33f36bb27e0a675f637ccd,"This paper studies the problem of online multiclass classification in a setting where the learner’s feedback is determined by an arbitrary directed graph. The authors prove surrogate regret bounds that hold, both in expectation and with high probability, for a large class of surrogate losses. Experiments on synthetic data show that for various feedback graphs our algorithm is competitive with known baselines."
SP:490262589efce6fb10b913431ec6db8d4e5b2dec,"This paper studies the problem of explainable k-clustering, which is the problem formalized by Dasgupta, Frost, Moshkovitz, and Rashtchian (ICML 2020). The authors propose an algorithm that outputs an explainable clustering that loses at most a factor of O(log k) compared to an optimal (not necessarily explainable) clustering for the k-medians objective. This improves over the previous best upper bounds of $O(k)$ and $O(\k^2)$ for k-means objective, and nearly matches the previous $\Omega(k^3)$ lower bound. The algorithm is remarkably simple and runs in time O(dk log k). "
SP:6a9e47be710ddaf386bffc54d003d7dc2b67fdc3,"This paper proposes a multilingual pre-trained language model (PrLM) that supports both explicit universal dependency parsing and implicit language modeling. Syntax in terms of universal dependency parse serves as not only pre-training objective but also learned representation in the model, which brings unprecedented PrLM interpretability and convenience in downstream task use. The model outperforms two popular multilingual PrLM, multilingual-BERT and XLM-R, on cross-lingual natural language understanding (NLU) benchmarks and linguistic structure parsing datasets."
SP:94f4b65214a648cbc84f13beba45a825e2e9901a,"This paper proposes a novel transformer-based method for solving vehicle routing problems (VRPs). The proposed method is based on the Dual-Aspect Collaborative Transformer (DACT) to learn embeddings for the node and positional features separately, instead of fusing them together as done in existing ones, so as to avoid potential noises and incompatible correlations. The positional features are embedded through a novel cyclic positional encoding (CPE) method to allow Transformer to effectively capture the circularity and symmetry of VRP solutions (i.e., cyclic sequences). The authors train DACT using Proximal Policy Optimization and design a curriculum learning strategy for better sample efficiency. They apply DACT to solve the traveling salesman problem (TSP) and capacitated vehicle routing problem (CVRP). Results show that DACT outperforms existing Transformer based improvement models, and exhibits much better generalization performance across different problem sizes on synthetic and benchmark instances."
SP:e5c8680d8da9e7548fcb9bb5c073848eb80e1dd0,"This paper studies the problem of estimating the exact Bayes error of a generative model trained with normalizing flows. The authors show that this error is invariant under invertible transformations, which allows them to compute the exact error of the learned flow models by computing it for Gaussian base distributions. They also show that by varying the temperature of the flow models, they can generate synthetic datasets that closely resemble standard benchmark datasets, but with almost any desired Bayesian error. They use their approach to conduct a thorough investigation of state-of-the-art classification models. "
SP:2896679f0472522bc3334178cd7574494cf12b7b,"This paper proposes a new initialization method for neural networks, called GradInit. The method is based on a simple heuristic: the norm of each network layer is adjusted so that a single step of SGD or Adam with prescribed hyperparameters results in the smallest possible loss value. This adjustment is done by introducing a scalar multiplier variable in front of each parameter block, and then optimizing these variables using a simple numerical scheme. GradInit accelerates the convergence and test performance of many convolutional architectures, both with or without skip connections, and even without normalization layers. It also improves the stability of the original Transformer architecture for machine translation, enabling training it without learning rate warmup using either Adam or SGD under a wide range of learning rates and momentum coefficients."
SP:f69731403592fa5bdd4ca327708582d615aa131c,"This paper proposes a new approach to predict the progression of Alzheimer's disease from longitudinal data. The approach is based on embedding the data in a Riemannian manifold and learning patient-specific trajectories distributed around a central geodesic. A few interpretable parameters characterize subject trajectories at the cost of a prior choice of a metric, which determines the shape of the trajectories. The authors extend this approach by learning the metric from the data allowing more flexibility while keeping the interpretability. Specifically, they learn the metric as the push-forward of the Euclidean metric by a diffeomorphism. The metric update allows to improve the forecasting of imaging and clinical biomarkers in the Alzheimer’s Disease Neuroimaging Initiative (ADNI) cohort."
SP:438e906f52c4c0538956b51a2270b3ac498b27a8,"This paper proposes a routing-by-memory mechanism for existing CNN architectures. In each stage of the network, they introduce parallel Procedural Units (PUs). A PU consists of a memory head and a procedure. The memory head maintains a summary of a type of features. For an intermediate feature, we search its closest memory and forward it to the corresponding procedure in both training and testing. "
SP:d240173080cd3647dbaa5173a6422396f226775b,"This paper studies the equivariance of polynomial functions that are equivariant to translation, rotation, reflection (parity), boost (relativity), and permutation. The authors show that it is possible to parametrize polynomials in terms of scalar products and scalar contractions of the scalar, vector, and tensor inputs. The paper also provides numerical experiments to demonstrate the effectiveness of the method."
SP:72c0f47566904deb27d8157da30807ec1d6b5685,This paper proposes a generalization of the Intersection over Union (IoU) loss to a new family of power IoU loss functions that have a power i.i.d. IoU term and an additional power regularization term with a single power parameter alpha. The authors analyze properties such as order preservingness and loss/gradient reweighting. Experiments on multiple object detection benchmarks and models demonstrate that the proposed loss function can outperform existing IoU-based losses by a noticeable performance margin.
SP:397125177d7007316d67194ec00d5dc57b44ac79,This paper studies Distributionally Robust Imitation Learning (DROIL) and establishes a close connection between DROIL and Maximum Entropy Inverse Reinforcement Learning (MaxEnt) by showing that MaxEnt IRL is a special case of DROIL when a certain loss function and policy description is used. DROIL is a framework for maximizing a general entropy function that is defined based on a particular loss of interest. The authors develop a novel approach to transform the objective function into a convex optimization problem over a polynomial number of variables for a class of loss functions that are additive over state and action spaces. Experiments on synthetic data and a highway driving environment demonstrate the effectiveness of the proposed method.
SP:58f220bbbed8d3e0633b408fca3b6838c4ad323d,"This paper studies the problem of post-processing in algorithmic fairness. The authors cast the problem as a graph smoothing problem corresponding to graph Laplacian regularization that preserves the desired “treat similar individuals similarly” interpretation. Theoretical results demonstrate the connection of the new objective function to a local relaxation of the original individual fairness. Empirically, the authors demonstrate the effectiveness of the proposed methods."
SP:ef791aa29decd839e7e583c9d1f71e8309ca87ef,"This paper proposes a new method for the cross-domain text-to-SQL task. The proposed method is based on the dual graph encoding and the question-schema linking method to learn the mapping between words in the question and tables/columns in the database schema. The paper also proposes a structure-aware aggregation method with global graph linking, local graph linking and DualGraph Aggregation Mechanism. The experimental results show that the proposed method outperforms the baseline methods and achieves 3rd place on the benchmark Spider."
SP:a2fa25a4539a38af61a0993f65ecc14339f26c2e,"This paper studies the problem of learning discrete-continuous computation graphs with multiple discrete components. The authors show that it is challenging to optimize the parameters of these models, mainly due to small gradients and local minima. They propose two new strategies to overcome these challenges. First, they show that increasing the scale parameter of the Gumbel noise perturbations during training improves the learning behavior. Second, they propose dropout residual connections specifically tailored to stochastic computation graphs."
SP:bb3ec363e90269db4a2ba99d8107cb56f86e68f0,"This paper shows that Bayesian neural networks (BNNs) with Hamiltonian Monte-Carlo (HMC) approximations achieve poor generalization under covariate shift, even under classical estimation. The authors explain this phenomenon by showing how a Bayesian model average can in fact be problematic under covariances shift, particularly in cases where linear dependencies in the input features cause a lack of posterior contraction. They additionally show why the same issue does not affect many approximate inference procedures, or classical maximum a-posteriori (MAP) training. Finally, the authors propose novel priors that improve the robustness of BNNs to many sources of covariates shift."
SP:f86ec7042e9b73ae071704a6d3ed17d7e3da1b75,"This paper categorizes meta few-shot learning evaluation into two settings: in-distribution (ID) and out of distribution (OOD). Based on this categorization, the authors identify that most existing FSL benchmarks instead reflect OOD evaluation, as they use disjoint sets of train (base) and test (novel) classes for task generation. This discrepancy is problematic because—as the authors show on numerous benchmarks— meta-learning methods that perform better on existing OOD datasets may perform significantly worse in the ID setting. The authors also highlight concerns in the OOD setting, such as reliably performing model selection and consistently comparing the performance of different methods. To address these concerns, they provide suggestions on how to construct FSL benchmark to allow for ID evaluation."
SP:371f77148b4f00a929f7c118b1bb7c5a6238d264,"This paper studies the problem of open rule induction in the context of language model-based rule generation. The authors argue that the current LM-based methods are “learning rules from rules”, which limits these methods to only produce “canned” rules whose patterns are constrained by the annotated rules, while discarding the rich expressive power of LMs for free text. Therefore, this paper proposes to induce open rules utilizing the knowledge in LMs. Besides, the authors propose the Orion (open rule induction) system to automatically mine open rules from LMs without supervision. The experiments are conducted to verify the quality and quantity of inducted open rules."
SP:8be2e0ea4a83fe32a4859f456007a829e5e9270a,This paper proposes Implicit Constraint Q-learning (ICQ) for offline multi-agent reinforcement learning. The main idea of ICQ is to use the state-action pairs given in the dataset for value estimation. The authors also extend ICQ to multi-Agent tasks by decomposing the joint-policy under the implicit constraint. ICQ achieves the SOTA performance in the offline offline tasks of StarCraft II.
SP:1939b24b68970c33ca16ce238deed257f76d009e,"This paper studies adversarial robustness against evasion attacks, with a focus on applications where input features have to comply with certain domain constraints. The authors propose a methodology to generate non-uniform perturbations that take into account the characteristics of the empirical data distribution. The experiments show that the proposed method is more robust to real-world attacks. "
SP:417b30930b245667d777e5d90ee80dd41546760e,This paper studies the convergence of iterated Tikhonov regularization (IT) for generalized self concordant loss functions (GSCs). The main contribution of this paper is to show that the iterated IT regularization is optimal in terms of convergence rate and convergence rate. This is achieved by showing that the convergence rate of IT is better than that of the original Tikhonoov method. The paper also shows that IT is more adaptive to the regularity of the learning problem.
SP:1caeee4f00b52fe356ff4e5dd004d0203e838370,"This paper proposes a new kind of linear transform called Deformable butterfly (DeBut) that generalizes the conventional butterfly matrices and can be adapted to various input-output dimensions. It inherits the fine-to-coarse-grained learnable hierarchy of traditional butterflies and when deployed to neural networks, the prominent structures and sparsity in a DeBut layer constitutes a new way for network compression. The authors apply DeBut as a drop-in replacement of standard fully connected and convolutional layers, and demonstrate its superiority in homogenizing a neural network and rendering it favorable properties such as light weight and low inference complexity, without compromising accuracy."
SP:d345ce1d7afc367ee1a9fb68d50ff1b2219f02cb,"This paper proposes MetA Reusable Knowledge or Marked Knowledge Base (MARK) to address the problem of catastrophic forgetting (CF) in continual learning. Specifically, the proposed method keeps a set of shared weights among tasks and uses a metalearning approach to incrementally enrich the KB with new knowledge and to foster weight reusability among tasks. Experiments show that Mark achieves state-of-the-art results in several benchmark datasets."
SP:722c52467e384058f8fdffa254d0e8db47440a64,"This paper proposes a data-driven framework for scheduling heuristics in an exact MIP solver. By learning from data describing the performance of primal heuristic, the proposed method obtains a problem-specific schedule of heuristic solutions that collectively find many solutions at minimal cost. The authors formalize the learning task and propose an efficient algorithm for computing such a schedule. Compared to the default settings of a state-of-the-art academic MDP solver, this method can reduce the average primal integral by up to 49% on two classes of challenging instances."
SP:5a21f0a49731dcb1d68deb06a75138e8e9d514d5,This paper studies reinforcement learning in the setting where the learner receives binary feedback only once at the end of an episode. The authors propose an algorithm that achieves sublinear regret under the assumption that the trajectory labels are generated by an unknown parametric model and provide a statistically and computationally efficient algorithm. The algorithm is shown to be computationally and statistically efficient under the exploration assumption.
SP:e66bd9582058ba0f6091bb1042ce2ecfdaae1515,"This paper proposes a novel edge representation learning framework based on Dual Hypergraph Transformation (DHT), which transforms the edges of a graph into the nodes of a hypergraph. This dual hypergraph construction allows us to apply message-passing techniques for node representations to edges. After obtaining edge representations from the hypergraphs, we then cluster or drop edges to obtain holistic graph-level edge representations. Experiments are conducted to validate the effectiveness of the proposed method."
SP:e398873e29b05176e1d52dc6f86a59a4f405e6fd,"This paper studies the sufficiency of representations learned by mutual information maximization (MI) based representation learning methods in the context of reinforcement learning. In particular, the authors study two popular MI-based representation learning objectives, i.e., mutual information minimization and mutual information reduction, and show that they yield representations that are not sufficient for RL from a theoretical perspective. The authors also provide empirical evidence to corroborate their theoretical findings."
SP:50181f740910195d3a50dd7d7f8cbb1c476d730b,"This paper proposes Sparse Steerable Convolution (SS-Conv) for the task of 3D object pose estimation in 3D space. The main contribution of this paper is the introduction of a novel feature-steering module to improve the performance of steerable convolutional layers. The proposed method is evaluated on three tasks of pose estimation, including instance-level 6D pose estimation and size estimation. The results show the effectiveness of the proposed method."
SP:d746bfb200577c980d92727bb0b1a3c23e7bfdc5,"This paper proposes a dynamic token sparsification framework to prune redundant tokens progressively and dynamically based on the input. Specifically, the authors devise a lightweight prediction module to estimate the importance score of each token given the current features. The module is added to different layers to reduce redundant tokens hierarchically. To optimize the prediction module in an end-to-end manner, this paper proposes an attention masking strategy to differentiably prune a token by blocking its interactions with other tokens. The experimental results demonstrate the competitive trade-off between speed and accuracy."
SP:d0b6cde42b1cba5e6e3c7c5131426fd84adbd3d7,"This paper studies the problem of inference on the conditional mean E [Y | X] under the assumption that the features X are continuously distributed. The authors consider the case where the feature X is finite and continuous, where the support size of the distribution of X is smaller than the square of the sample size. They show that there are several regimes in between the finite setting and the continuous setting, where vanishing-width confidence intervals are achievable if and only if the effective support size (effectively) of the distributions of X are smaller than that of the support sizes of the samples."
SP:123952325765c040c3078fc7dca2b6d370e55590,"This paper proposes Representation Neutralization for Fairness (RNF), a method to reduce the discrimination of DNN models by only debiasing the classification head, even with biased representations as inputs. The authors leverage samples with the same ground-truth label but different sensitive attributes, and use their neutralized representations to train the classification heads of the DNN model. To address low-resource settings with no access to sensitive attribute annotations, the authors leverage a bias-amplified model to generate proxy annotations for sensitive attributes. Experimental results over several benchmark datasets demonstrate the effectiveness of the proposed method."
SP:210eb2c811f966bb1ac53932cacabbad9bb608fe,"This paper proposes a new convolutional neural network architecture called Bessel-CNN, which is invariant to all possible rotational angles by design. The method is based on the Bessel functions, which are well-known in physics and can be used to define a continuous set of possible rotation angles. Experiments are conducted to demonstrate the effectiveness of the proposed method. "
SP:ee51ecbd476d5b65903c942a62be89ff5d91698b,"This paper proposes a new algorithm for large-scale kernel ridge regression. The algorithm is based on partitioning with random projections and iterative optimization to reduce space and time complexity while provably maintaining the same statistical accuracy. In particular, constructing suitable partitions directly in the feature space rather than in the input space promotes orthogonality between the local estimators, thus ensuring that key quantities such as local effective dimension and bias remain under control. The authors also characterize the statistical-computational tradeoff of our model, and demonstrate the effectiveness of our method by numerical experiments on large scale datasets. "
SP:1f096d6fabd5b1fde43d06c552d46d87cd35cb4a,"This paper proposes a method for discrete communication between agents that is motivated by word embedding techniques from natural language processing. The authors argue that the current standard of using one-hot vectors as discrete communication tokens prevents agents from acquiring more desirable aspects of communication such as zero-shot understanding. They propose a neural agent architecture that enables them to communicate via discrete tokens derived from a learned, continuous space. They show in a decision theoretic framework that their technique optimizes communication over a wide range of scenarios. In self-play experiments, they validate that our trained agents learn to cluster tokens in semantically-meaningful ways, allowing them communicate in noisy environments where other techniques fail. They demonstrate that agents using our method can effectively respond to novel human communication and that humans can understand unlabeled emergent agent communication."
SP:8630ccc627534f9033bced04e2137a897ffef701,"This paper proposes to combine the strengths of convolutional networks and transformers. Specifically, the authors show that depthwise convolution and self-attention can be unified via simple relative attention, and vertically stacking convolution layers and attention layers in a principled way is surprisingly effective in improving generalization, capacity and efficiency. Experiments show that their CoAtNets achieve state-of-the-art performance under different resource constraints across various datasets."
SP:d3ecbeeffa5ab365743ba8653c6739f24742ee31,"This paper presents a new second-order oracle bound for the expected risk of a weighted majority vote. The bound is based on a novel parametric form of the Chebyshev-Cantelli inequality, which is amenable to efficient minimization. The authors also derive a new concentration of measure inequality, PAC-Bayes-Bennett, which combines the PAC bounding with Bennett’s inequality for empirical estimation. "
SP:5bac542a6532d43cf100e085398b4a4783719814,"This paper proposes a weakly supervised method for audio-visual video parsing. The proposed method exploits both the common and diverse event semantics across videos to identify audio or visual events. In addition, the method explores event co-occurrence across audio, visual, and audio- visual streams. The discovered supervisory signals across different videos and modalities can greatly facilitate the training with only video-level annotations. Quantitative and qualitative results demonstrate that the proposed method performs favorably against existing methods."
SP:8fd6a03c1794afa524328d45f4232eacf6f86693,"This paper proposes a personalized federated learning algorithm called QuPeD, which computes a compressed personalization loss for each client in a federated setting. The authors propose to use a relaxed optimization problem, where quantization values are also optimized over. Experiments are conducted to validate the effectiveness of the proposed algorithm."
SP:fca8b4f1e765cf1724a37f0ae9a7dac1cb79c8b1,"This paper proposes a new method for constrained clustering based on variational auto-encoder (VAE) that incorporates clustering preferences in the form of pairwise constraints, with varying degrees of certainty. The proposed method, DC-GMM, uncovers the underlying distribution of data conditioned on prior clustering preference, expressed as constraints. The authors provide extensive experiments to demonstrate the effectiveness of the proposed method."
SP:84379c0c881b7390ecc22fb398edfaf66d1af1ff,"This paper studies the problem of approximating the Neural Tangent Kernel (NTK) and the convolutional NTK (CNTK). The authors propose to approximate the NTK and CNTK matrices by sketching the polynomial expansions of arc-cosine kernels. The authors also prove a spectral approximation guarantee for NTK matrix, by combining random features (based on leverage score sampling) with a sketching algorithm. The proposed methods are evaluated on various large-scale regression and classification tasks. "
SP:fa2668083ff3bb592c29a4c6822ae96ff54d0dbe,This paper proposes a Multi-Range Transformer (MRT) to predict multi-person trajectory motion. The main idea is to use a local-range encoder to capture individual motion and a global range encoder for social interactions. The multi-range Transformer decoder takes a corresponding pose as a query which attends to both local and global-range features. Experiments show that the proposed method outperforms state-of-the-art methods on long-term 3D motion prediction and generates diverse social interaction.
SP:0a0e07af37c8fe8580639b1df62d27b6f63f8dee,"This paper proposes a method to automatically generate programs to guide reinforcement learning in long-horizon planning problems. The method uses a generative model to predict the unobserved parts of the world, and then synthesizes a program based on samples from this model in a way that is robust to its uncertainty. Experiments show that the proposed method outperforms non-program-guided approaches on a set of challenging benchmarks."
SP:5bb42b178b0d27da271bfa60e633fdac718638c4,"This paper studies the problem of causal imitation learning in sequential settings, where the imitator must make multiple decisions per episode. The authors develop a graphical criterion that is necessary and sufficient for determining the feasibility of causal imitation. They also provide an efficient algorithm for determining imitability and corroborate their theory with simulations. "
SP:85bd81f0c5b6ccbc421ebbaf6f5c72164bc70b7f,"This paper presents a slot-wise, object-based transition model that decomposes a scene into objects, aligns them (with respect to a slotwise object memory) to maintain a consistent order across time, and predicts how those objects evolve over successive frames. The model is trained end-to-end without supervision using transition losses at the level of the object-structured representation rather than pixels. The authors show that the combination of an objectlevel loss and correct object alignment over time enables the model to outperform a state-of-the-art baseline, and allows it to deal well with object occlusion and re-appearance in partially observable environments."
SP:f32eddbb5c33a8422c075579ff08aa9833338d44,"This paper studies the generalization guarantees of a generic importance sampling weighted ERM algorithm for using adaptively collected data to minimize the average of a loss function over a hypothesis class. The main contribution of this paper is a new maximal inequality that carefully leverages the importance sampling structure to obtain rates with the good dependence on the exploration rate in the data. For regression, the authors provide fast rates that leverage the strong convexity of squared-error loss. For policy learning, they provide regret guarantees that close an open gap in the existing literature whenever exploration decays to zero. "
SP:f549a0c231b71bae0acbed6e3afb41890ee89cd9,"reweighted regression. This paper proposes a novel and coherent scheme for reparametrizing the sample weights using a doubly non-negative matrix. When the weighting matrix is confined in an uncertainty set using either the log-determinant divergence or the Bures-Wasserstein distance, this paper shows that the adversarially reweighted estimate can be solved efficiently using first-order methods. Numerical experiments show that our reweighting strategy delivers promising results on numerous datasets."
SP:fe12e13602925b9400fd596a987755beb10aa3d1,"This paper proposes two gradient estimators for the categorical setting. The first is based on importance sampling and statistical couplings, while the second is a generalization of the DisARM estimator (Yin et al., 2020). The authors propose to reparameterize categorical variables as sequences of binary variables and use Rao-Blackwellization. The experiments show that the proposed estimators provide state-of-the-art performance. "
SP:e16fdf963ec2f9c0d79fa404e47e7862a5d6e922,"This paper proposes a new predictor-based neural architecture search method, called WeakNAS, that progressively shrinks the sampling space by learning a series of weak predictors that can connect towards the best architectures. The proposed method is based on the observation that the probability of sampling better architectures keeps increasing as the number of predictors increases. This paper proposes to sample a few well-performed architectures guided by the previously learned predictor and estimate a new better weak predictor to refine the ranking of sampling space. Extensive experiments demonstrate the effectiveness of the proposed method on NAS-Bench-101/201."
SP:8f74abb04037ba2e59dcf8320dc555b149f68ed8,"This paper proposes a novel intrinsic control method based on the Entropic Desired Dynamics for Intrinsic ConTrol (EDDICT) framework. EDDICT assumes a fixed additive latent dynamics, which results in tractable learning and an interpretable latent space. The authors show that the global consistency of the latent codes allows the agent to reliably reach more states in the long term while still optimizing a local objective. The proposed method is shown to be more interpretable and exploreable compared to prior intrinsic control methods."
SP:c731a78c3e7f98ccd0253b51a0d42bf8deeb71f9,"This paper proposes a fragment-based generative approach to generate molecules with high docking scores for drug design. The approach is based on the use of an RL agent to generate fragments of a molecule, which are then used to optimize the docking score of the generated molecule. The authors show that the generated molecules are more chemically realistic and have higher docking scores compared to the baselines. They also show that their approach outperforms baselines on both de-novo and scaffold-based approaches."
SP:b938bca513e7de1231212064caf8877a78d8b612,"This paper studies the problem of learning directed acyclic graphical models from observational data in general settings without specific distributional assumptions. The approach is information-theoretic and uses a local Markov boundary search procedure in order to recursively construct ancestral sets in the underlying graphical model. The authors show that for certain graph ensembles, a simple forward greedy search algorithm suffices to learn the Markov boundaries of each node. This substantially improves the sample complexity, which is at most polynomial in the number of nodes. This is then applied to learning the entire graph under a novel identifiability condition that generalizes existing conditions from the literature. "
SP:af08109d4c45dc9401efb0e63c22167e9da28adb,"This paper studies the problem of learning with differential privacy (DP) in the setting where each user holds m samples and the privacy protection is enforced at the level of each user’s data. The authors show that, as long as each user receives sufficiently many samples, we can learn any privately learnable class via an ("", )DP algorithm using only O(log(1/\sqrt{1/ )/"") users. For user-DP algorithms, they show that they can learn using O(d) users even in the local model, where d is the probabilistic representation dimension. A crucial component of their results is a generalization of global stability [BLM20] that allows the use of public randomness. "
SP:da4f21d107a7f442c4d3e3ec13bdb44b041e07cf,"This paper studies the effect of implicit parameterization of a linear function on the convergence of stochastic gradient descent (SGD) in the context of reinforcement learning. In particular, the authors consider the case where the parameterization is an implicit parameterized linear function that is parameterized by a latent Markov decision process (MDP). The authors show that, for a linear parametrization, gradient descent converges to global optima despite nonlinearity and non-convexity introduced by the implicit representation. They also provide convergence rates for both cases which allow them to identify conditions under which SGD with this implicit representation converges substantially faster than its explicit counterpart. Finally, they provide empirical results in some simple domains that illustrate the theoretical findings."
SP:992aa07d4f815d1c81f967374590eece933833b1,This paper proposes a method to refine Knowledge Graphs (KGs) by using PSL-KGI and type-supervised KG embeddings through iterative feedback. The proposed method is based on a co-training mode and uses PSL to refine KGs and KG-based embedding to reject noisy facts from KGs. Experiments show that the proposed method outperforms baselines on a range of KG benchmarks.
SP:676fc4a3041af22e8f20ccba7daa2a0b1f5d6af5,"This paper proposes a novel evaluation paradigm for Knowledge Base Completion (KBC) methods. The authors argue that consideration of binary predictions is essential to reflect the actual KBC quality. They construct a data set FB14k-QAQ with an alternative evaluation data structure: instead of single facts, they use KB queries, i.e., facts where one entity is replaced with a variable, and construct corresponding sets of entities that are correct answers. They randomly remove some of these correct answers from the data set, simulating the realistic scenario of real-world entities missing from a KB. They evaluate a number of state-of-the-art KB embeddings models on our new benchmark."
SP:83fe0a496a79bcf97ccba1c6d34b7d11e7d5c330,"This paper proposes a new dialog model, Alternating Roles Dialog Model (ARDM), which models each speaker separately and takes advantage of the large pre-trained language model. It requires no supervision from human annotations such as belief states or dialog acts to achieve effective conversations. ARDM outperforms or is on par with state-of-the-art methods on two task-oriented dialog datasets: CamRest676 and MultiWOZ. Moreover, ARDM can generalize to more challenging, non-collaborative tasks such as persuasion."
SP:b11c06b7c4ef1aa43c59f808a679425e302d158e,"This paper studies the problem of estimating the probability that the classification predicted by a deep neural network is correct (or in the top 5) on the test set. The authors show that the softmax values of the network are not estimates of the probabilities of class labels, but rather a measure of the ""implicit loss"". The authors prove that if an uncertainty measure is an implied loss, then low uncertainty means high probability of correct (top k) classification. The proposed method is simple to use on existing networks: they proposed confidence measures for Top k which can be evaluated by binning values on the tests set. "
SP:ab9666e15f2a0113d96cb4b47b1cbb30fa1f7982,"This paper studies the generalization and generalization properties of neural networks at large depth. The authors show that the spectrum of the neural tangent kernel (NTK) simplifies in the same way as that of the Neural Network Gaussian Process (NNGP) kernel. They show that NTK is a necessary condition for generalization across a range of architectures including Fully Connected Networks (FCNs) and Convolutional Neural Networks (CNNs). In particular, they show that there are large regions of hyperparameter space where networks can only memorize the training set in the sense they reach perfect training accuracy but completely fail to generalize outside the training data."
SP:d3470c35aae48bf92439a55fdb98ccf07100e567,"This paper proposes a graph convolutional neural network-based method for protein quality assessment (QA). The method is based on Graph Convolutional Networks (GCN) and is applied to the problem of protein QA. The authors claim that GCN is able to capture the benefits of previous QA methods including representation learning, geometric invariance, explicit modeling of sequential and 3D structure, simultaneous local and global scoring, and computational efficiency. Through extensive experiments, the authors show significant improvements over the state-of-the-art. "
SP:5188280131b58a35d3deda126a0754aea8fa6e58,"This paper studies the loss landscape of linear neural networks with different loss functions and different parameterizations. The functional space is either the set of all linear maps from input to output or a determinantal variety, i.e., a set of linear maps with bounded rank. The paper makes a distinction between pure critical points, which only depend on the functional space, and spurious critical points which arise from the parameterization. The analysis clearly illustrates that the absence of ""bad"" local minima is due to two distinct phenomena that apply in different settings: it is true for arbitrary smooth convex losses in the case of architectures that can express all linear map (“filling architectures”) but it holds only for the quadratic loss when the functional spaces is a deterministic variety. "
SP:ee71597ceab23eb4db1d6608f15f80ad51f7ff6d,"This paper proposes a general framework SEED (Sampling, Encoding, and Embedding Distributions) for inductive and unsupervised representation learning on graph structured objects. Instead of directly dealing with the computational challenges raised by graph similarity evaluation, given an input graph, the SEED framework samples a number of subgraphs whose reconstruction errors could be efficiently evaluated, encodes the subgraph samples into a collection of subGraph vectors, and employs the embedding of the subGraph vector distribution as the output vector representation for the input graph. By theoretical analysis, the authors demonstrate the close connection between SEED and graph isomorphism. The empirical study suggests the proposed framework is able to achieve up to 10% improvement."
SP:d9406fdf0a180a5efc6f15ba8739524665f0f9d2,"This paper proposes a new counterfactual regret minimization (CFR) algorithm, Lazy-CFR, which uses a lazy update strategy to avoid traversing the whole game tree in each round. Theoretical analysis shows that the regret is almost the same as the regret of the vanilla CFR and only needs to visit a small portion of the game tree. Empirical results show that the proposed algorithm is fast in practice."
SP:023aa3dca1cf7992b22993a7088e8a74c92bb47e,"This paper proposes a method for Unsupervised Domain Adaptation (UDA) based on Gaussian mixture distributions. The authors propose a Distribution Matching Prototypical Network (DMPN) to model the deep features from each domain as a gaussian mixture distribution. To learn both discriminative and domain invariant features, DMPN is trained by minimizing the classification loss on the labeled source data and the domain discrepancy losses together. Extensive experiments are conducted over two UDA tasks. "
SP:40be996e8bb86e887077b762b87c7c34a786ac98,"This paper proposes a conditional continuous normalizing flow (CNF) model that partitions the latent space into a class-specific supervised code and an unsupervised code that is shared among all classes for efficient use of labeled information. Since the partitioning strategy (slightly) increases the number of function evaluations (NFEs), this paper also employs gating networks to learn the error tolerances of its ordinary differential equation (ODE) solvers for better speed and performance. The authors show empirically that InfoCNF improves the test accuracy over the baseline while yielding comparable likelihood scores and reducing the NFEs on CIFAR10."
SP:97764e3393216106ff2ac3f550845acf4636119f,"This paper studies the convergence of TD learning for value function approximation in reinforcement learning with nonlinear functions trained with the temporal-difference (TD) learning algorithm under a certain scaling of the approximating function, leading to a regime called lazy training. In this regime the parameters of the model vary only slightly during the learning process, a feature that has recently been observed in the training of neural networks, where the scaling arises naturally, implicit in the initialization of their parameters. Both in the under- and over-parametrized frameworks, the authors prove exponential convergence to local, respectively global minimizers of the above algorithm in the lazy training regime. They then give examples of such convergence results in the case of models that diverge if trained with non-lazy TD learning, and in the example of neural network."
SP:c518e4030f12b0f59ad1d7c0fc0ebd313c68ef95,"This paper studies the problem of hypothesis verification as a reinforcement learning problem. Specifically, given a hypothesis about the dynamics of the world can take actions to generate observations which can help predict whether the hypothesis is true or false. The authors show that agents trained end-to-end with the reward fail to learn to solve this problem. In order to train the agents, the authors exploit the underlying structure in the majority of hypotheses – they can be formulated as triplets (pre-condition, action sequence, post-condition). Once the agents have been pretrained to verify hypotheses with this structure, the agents can be fine-tuned to verify more general hypotheses."
SP:6fa2f842b1bc993ed8024a3ce13dbd91529c61be,This paper studies the problem of predicting whether a given statement can be rewritten by other theorems in a fixed dimensional latent space. The authors propose to use a graph neural network to predict the latent embedding of a formula generated by some rewrite rule. The model is trained by predicting the latent representation of the resulting formula and then evaluated on the quality of the embeddings. The experiments show that graph neural networks can make non-trivial predictions about the rewrite-success of statements.
SP:a77ab500a5e7d4ea8430871d1e603941e92974fd,"This paper proposes a method for learning depth estimation from images. The method is based on a global-local network architecture, which is trained with sparse ground truth, i.e., a single pixel per image. The proposed method is evaluated on a variety of indoor scenes. The results show that the proposed method outperforms baselines in the sparse data regime."
SP:2afba5e24478da4e9d493887c7cf00e288cc0deb,"This paper proposes a method for learning a Transformer-based embedding model for hashed word embeddings. The proposed method is based on applying hash functions to map each id to multiple hash tokens in a much smaller space, similarly to a Bloom filter. The authors show that by applying a multi-layer Transformer to these Bloom filter digests, they are able to obtain models with high accuracy. They outperform models of a similar size without hashing and a much larger size trained using sampled softmax with the same computational budget."
SP:745dd86d7f7bba79a02d27922003b764b620f83e,"This paper tackles the problem of zero-shot 3D shape part discovery. The authors propose a learning-based agglomerative clustering framework which learns a grouping policy to progressively group small part proposals into bigger ones in a bottom-up fashion. At the core of their approach is to restrict the local context for extracting part-level features, which encourages the generalizability to unseen categories. On the PartNet dataset, the authors demonstrate that their method can transfer knowledge of parts learned from 3 training categories to 21 unseen testing categories without seeing any annotated samples."
SP:868fc6df740b04963442d5abcfe2f4845585cfc8,"This paper proposes a technique called ""neuron editing"" that learns how neurons encode an edit for a particular transformation in a latent space. The authors use an autoencoder to decompose the variation within the dataset into activations of different neurons and generate transformed data by defining an editing transformation on those neurons. By performing the transformation in the latent space, they encode fairly complex and non-linear transformations to the data with much simpler distribution shifts to the neuron’s activations. Their technique has the advantage of being generally applicable to a wide variety of data domains, modalities, and applications. "
SP:6dee6932e64fe47bb44dd42fc242fa9d89b8d89c,"This paper proposes a meta-learning method for few-shot image segmentation. The proposed method is based on first-order meta learning of initializations for deep neural networks that must produce dense, structured predictions given an arbitrary amount of training data for a new task. The authors propose a novel neural network architecture built for parameter efficiency and fast learning which they call EfficientLab. They also provide a formalization of the generalization error of meta learning algorithms, which they leverage to decrease error on unseen tasks, and a small benchmark dataset, FP-k, for the empirical study of how meta learning systems perform in both few and many-shot settings. "
SP:ec6f390f6d45fb79c33ae5d9c8a24cadb96fbd60,"This paper proposes a new method for semi-supervised few-shot learning. The proposed method is based on prototypical random walk networks (PRWN), which is a graph neural network with a random walk loss. The authors show that the proposed method outperforms the state-of-the-art in most of the experiments. "
SP:d12e687bd2ee9fa60554312e644bb0a6487974f1,"This paper proposes a self-supervised training objective, Contrastive Sensor Fusion (CSF), which uses a contrastive loss to train an encoder that can produce a shared representation from any subset of available channels across multiple sensors. The method uses a dataset of 47 million unlabeled coterminous image triplets to train the encoder to produce semantically meaningful representations from any possible combination of channels from the input sensors. Experiments show that the proposed method outperforms fully supervised ImageNet weights on a remote sensing classification task and improve as more sensors are fused."
SP:4d8e054f07006b4f896721b5c24da805727d2c22,"This paper studies the problem of retraining a pruned neural network after pruning. In particular, this paper focuses on weight re-winding and learning rate rewinding. Weight re-winding rewinds the unpruned weights to their values from earlier in training and retrains them from there using the original training schedule. Learning rate re-weighing trains the weights from their final values using the same learning rate schedule as the original one. This paper proposes a network-agnostic pruning algorithm that matches the accuracy and compression ratios of several state-of-the-art techniques. "
SP:3bb1c79f9482e09828eda45fbb2e654f37219365,"This paper studies the relationship between output margin and generalization in deep neural networks. The authors propose to analyze a new notion of margin, which they call the “all-layer margin”, and show that it has a clear and direct relationship with generalization for deep models. This enables the following concrete applications: 1) by analyzing the all layer margin, the authors obtain tighter generalization bounds for neural nets which depend on Jacobian and hidden layer norms and remove the exponential dependency on depth; 2) their neural net results easily translate to the adversarially robust setting, giving the first direct analysis of robust test error for deep networks; 3) they present a theoretically inspired training algorithm for increasing the alllayer margin. "
SP:3d44f27468087280e85dfb1fc7291db05179fe6d,"This paper studies the problem of knowledge-grounded dialogue generation under a low-resource setting. The authors propose a disentangled response decoder to isolate parameters that depend on knowledge-based dialogues from the entire generation model. The main contribution of this paper is to decompose the decoder into independent components, which can be estimated from large scale ungrounded dialogues and unstructured documents. The proposed method is evaluated on two benchmark datasets. "
SP:9b555f7fe743f5effdbdc8701ed519ce3159c4b0,"This paper proposes a new neural machine translation model (MGNMT) that combines the source-to-target translation model, the target to source translation model and the source to target translation model. The main idea is that both translation models and language models share the same latent semantic space, therefore both translation directions can learn from non-parallel data more effectively. Experiments show that the proposed MGNMT consistently outperforms existing approaches in a variety of language pairs and scenarios."
SP:d7a530a0ec4112095a58cef4cda9646f8ca6449d,"This paper analyzes the role of the entropy term in Soft Actor Critic (SAC) for the Mujoco benchmark. The authors show that the main contribution of entropy term is to maintain satisfactory exploration in the presence of bounded action spaces. Based on this insight, the authors propose a new algorithm that does not employ entropy maximization but nevertheless matches the sampling efficiency and robustness performance of SAC. The experimental results demonstrate a need to revisit the benefits of entropy regularization in DRL."
SP:545e8da553fcb47d84eaa044d8a4947d3cd3230e,"This paper studies the vulnerability of copyright detection systems to adversarial attacks. The authors propose to attack a neural network-based copyright detection system by modifying a well-known music identification method. They demonstrate the effectiveness of the proposed method by showing that the adversarial perturbation is able to fool a variety of existing systems, including the AudioTag copyright detector and YouTube’s Content ID system. The paper is well-written and easy to follow."
SP:b511822850da3bf1079a36ed6f5ad4db80fbc424,"This paper proposes a new metric learning approach to explain the visual similarity between two images by decomposing the final activation map of the two images. The proposed approach is based on point-to-point activation intensity between the images. It is shown that the proposed framework can be directly deployed to a large range of metric learning applications and provides valuable information for understanding the model. The experiments show its effectiveness on two potential applications, i.e. cross-view pattern discovery and interactive retrieval."
SP:67bf71219fe6bedec5f5525200e734638e4a6ca2,"This paper studies the problem of lifelong reinforcement learning in the continual lifelong learning setting. The authors propose a new algorithm, Adaptive Online Planning (AOP), that combines model-based planning with model-free learning. The main idea is to use the planner to estimate the uncertainty of the model-dependent components of the policy, which is then used to decide when to use more planning resources. The experiments show that AOP is able to reduce computation while achieving high performance in difficult tasks."
SP:11159cb878a436a5d4fc6edb4132f2cc3c1b3f72,"This paper proposes to replace the traditional softmax attention mechanism by two alternative sparsity-promoting transformations: sparsemax and total-variation Sparse Attention (TVMAX). With sparsemax, we obtain sparse attention weights, selecting relevant features. By selecting relevant groups of features, the TVMAX transformation improves interpretability. TVMAX outperforms the other compared attention mechanisms in terms of human rating."
SP:fb0c3ce3db6ad674ddc615bdc6203cdcbe42c804,"This paper proposes a generative model for predicting the evolution of dynamic graphs. Specifically, the authors use a graph neural network and a recurrent architecture to capture the temporal evolution patterns of dynamic graph. Then, they employ a generator to predict the topology of the graph at the next time step and construct a graph instance that corresponds to that topology. They evaluate the proposed model on several artificial datasets following common network evolving dynamics, as well as on real-world datasets."
SP:ff722957a1765c0568426ed88dd910a6b74054ef,"This paper proposes a method for imputing missing features and estimating the distribution of target assignments given incomplete data. The proposed method is based on a generator network that generates imputations that a discriminator network is tasked to distinguish. Then, a predictor network is trained using the imputed samples from the generator network to capture the classification uncertainties and make predictions accordingly. The method is evaluated on CIFAR-10 image dataset as well as three real-world tabular classification datasets."
SP:c051b0fe779d9e4131016970b7ba469b596f3009,"This paper studies the problem of off-policy estimation for long-horizon reinforcement learning. The authors formulate the problem as solving for the fixed point of a ""backward flow"" operator, and propose a new estimator that computes importance ratios of stationary distributions. The estimator is based on Reproducing Kernel Hilbert Spaces (RKHSs), and the authors analyze its asymptotic consistency and finite-sample generalization. Experiments on benchmarks verify the effectiveness of the proposed method."
SP:065c900843011a71b70ed35357a2f71fe83872a7,"This paper proposes a generative adversarial network (GAN) based method to model the latent prior distribution of a Gaussian mixture model (GMM). Specifically, the authors propose to use a GAN to compute the conditional likelihood p(x|k, \theta) as well as the responsibility probability p(k|x,\theta). The authors also propose a classifier that learns to categorize an image to Gaussians. Experiments are conducted to demonstrate the effectiveness of the proposed method."
SP:2da1608209058d214f8671062cc9eb0833ba4831,"This paper proposes a method for training large capacity neural networks with improved accuracy and lower dynamic computational cost by gating the deep-learning architecture on a fine-grained-level. Specifically, individual convolutional maps are turned on/off conditionally on features in the network. To achieve this, the authors introduce a new residual block architecture and introduce a generally applicable tool batch-shaping that matches the marginal aggregate posteriors of features in a neural network to a pre-specified prior distribution. The proposed method is evaluated on CIFAR-10 and ImageNet datasets for image classification, and Cityscapes for semantic segmentation."
SP:f90e9f0eb53f92601bdfa3f7bf86f71d037aad30," network pruning. This paper proposes a probabilistic importance inference approach for pruning DNNs. Specifically, they test the significance of the relevance of a connection in a DNN to the DNN’s outputs using a nonparemetric scoring test and keep only those significant ones. Experimental results show that the proposed approach achieves better lossless compression rates than existing techniques."
SP:64cbbb6a2f6847ef71cd5a23ba3e4cc5c815a56e,"This paper proposes a method for learning nested behavioral hierarchies of arbitrary depth, with actions of arbitrary length, by iteratively compressing action trajectories to learn nested behavior hierarchies. The learned temporally extended actions provide new action primitives that can participate in deeper hierarchies as the agent learns. The authors demonstrate the relevance of this approach for tasks with non-trivial hierarchical structure and show that the approach can be used to accelerate learning in recursively more complex tasks through transfer."
SP:e1ccfb3a684aef8a0fb36194eb16af1667811e81,This paper proposes a variational autoencoder (VAE) based generative model with a multi-modal energy-based decoder. The decoder is modeled as an energy based model (EBM) and the encoder is trained with variational inference. The authors show that the proposed model is able to generate conditional and unconditional samples. They also propose a variant of the model that can generate sets of examples.
SP:1130a391afa30d1e0fddadedd2a3aaa70a4cb751,"This paper proposes a new normalization technique, called cross-normalization, for off-policy temporal difference (TD) RL algorithms. The idea is to use a mixture of on- and off policy transitions to mitigate the divergence between policy distributions. The authors demonstrate the effectiveness of the technique on DDPG and TD3 on MuJoCo tasks. "
SP:f9cafaa5131176290fa069e6d24046c079cd9eea,"This paper proposes a method to learn discriminative features unbiased and invariant to the confounder(s). This is enabled by incorporating a new adversarial loss function that encourages a vanished correlation between the bias and learned features. The proposed method is evaluated on a synthetic, a medical diagnosis, and a gender prediction dataset. "
SP:783049ff463edd1283c058c6106a3e1f9a033df4,"This paper proposes a lightweight Transformer-based model, called Group-Transformer, that factorizes the calculation paths by grouped embedding operators. The authors also propose inter-group linear operators to prevent performance degradation from the group strategy. Experiments on enwik8 and text8 show the effectiveness of the proposed method."
SP:946c26d371297c88d0ac246257104099b4585edc,"This paper proposes a new objective function for training generative models with deep hierarchies of latent variables using Optimal Transport (OT). The objective function is based on the Wasserstein distance between two latent variables, which is recursively applied as the regularization divergence, allowing the stacking of WAEs for arbitrarily deep latents. The authors show that this approach enables the learning of smooth latent distributions even in deep latent hierarchies, which otherwise requires extensive model design and tweaking of the optimisation procedure to train. "
SP:309b47441d227ffa33f96f9f16f2addc607e5bb0,"This paper proposes an autoregressive video generation model based on a three-dimensional self-attention mechanism. The proposed model is based on block-local self attention, which can be implemented efficiently on TPUs. Experiments show that the proposed model achieves state-of-the-art results across a range of video generation benchmarks. The authors also present results on a large scale action recognition dataset."
SP:ad8fcdbc47a50dd2bf58aba2bc6cfe199e84dd4d,This paper proposes a generative model for zero-shot multi-label text classification. The key idea is to use the hierarchical structure of ICD codes to generate semantically meaningful features for zero shot codes without any labeled data. The paper also proposes a novel pseudo cycle generation architecture to guarantee the semantic consistency between the synthetic and real features by reconstructing the relevant keywords in input documents. Extensive experiments demonstrate the effectiveness of the proposed method.
SP:3ce82ae297e5759ab957babe9927062e7a71b0ba,"This paper proposes a self-supervised representation learning method to improve sample efficiency in reinforcement learning (RL). The authors propose a forward prediction objective for simultaneously learning embeddings of states and action sequences to capture the structure of the environment’s dynamics, enabling efficient policy learning. The authors demonstrate that the action embedding alone improves the sample efficiency and peak performance of model-free RL on control from low-dimensional states. The proposed method is evaluated on a simple family of goal-conditioned 2D control tasks."
SP:11ce1616e721340eea9e80dad7460c77355ac7d1,"This paper proposes a meta-learning framework that automatically extracts the cross-task relations and constructs the meta-knowledge graph. When a new task arrives, it can quickly find the most relevant structure and tailor the learned structure knowledge to the task-specific meta-learner. Experiments on toy regression and few-shot image classification show the effectiveness of the proposed method."
SP:37c209cd1c628b5c2f2b282fbeaf4bbf437c7670,"This paper proposes a plug-and-play language model (PPLM) that combines a pre-trained LM with one or more simple attribute classifiers that guide text generation without any further training of the LM. In the canonical scenario, the attribute models are simple classifiers consisting of a user-specified bag of words or a single learned layer. Sampling entails a forward and backward pass in which gradients from the attribute model push the LM’s hidden activations and thus guide the generation. Model samples demonstrate control over a range of topics and sentiment styles and extensive automated and human annotated evaluations show attribute alignment and fluency."
SP:12d0980bfea2de880905a0b87b40856969bb1c58,"This paper proposes a novel method for unsupervised representation learning based on denoising autoencoder. The proposed method is based on a Laplacian pyramid representation of the input data, which is generated by corrupting clean data in the gradient domain. In this way, the agent learns more robust representations that exploit the underlying data structures across multiple scales. Experiments on several visual benchmarks demonstrate that better representations can be learned with the proposed approach, compared to its counterpart with single-scale corruption."
SP:12afc1b259e51a31cbeb72366d2b93fbee1aafaa,"This paper studies the problem of robustness to text deletions in the context of natural language inference. The authors propose a novel technique for formal verification of this specification for models based on the popular decomposable attention mechanism by employing the efficient yet effective interval bound propagation (IBP) approach. Using this method we can efficiently prove, given a model, whether a particular sample is free from the under-sensitivity problem. They compare different training methods to address this problem, and compare metrics to measure it. "
SP:14257af9fe83522c6e5b5d6b0d68945b944e30fb,"This paper studies the problem of model-free off-policy deep reinforcement learning (RL) in continuous state and action spaces, where the replay memory only holds a finite number of transitions. The authors propose a simple Markov Decision Process (MDP) for which exact Q-values can be computed efficiently as more data comes in – resulting in a QGRAPH. They show that the Q-value for each transition in the simplified MDP is a lower bound of the q-value in the original continuous Q-learning problem. By using these lower bounds in TD learning, the proposed method is less prone to soft divergence and exhibits increased sample efficiency. "
SP:c92c97e47d8b218dfd009bbf61f5b3547b395f91,"This paper studies the problem of unsupervised domain adaptation, where the goal is to generalize the hypothesis trained in a source domain to an unlabeled target domain. One popular approach to this problem is to learn domain-invariant embeddings for both domains. In this paper, the authors study the effect of the embedding complexity on generalization to the target domain, and show that this complexity affects an upper bound on the target risk; this is reflected in experiments, too. The authors also provide a strategy that mitigates the sensitivity to the complexity, and achieves performance on par with or better than the best layer-dependent complexity tradeoff."
SP:f3f3c6fbae757836551b3f1ee54a7d1e040132b8,"This paper studies generalization error bounds for learning general non-convex objectives, which has attracted significant attention in recent years. The authors develop a new framework, termed Bayes-Stability, for proving algorithm-dependent generalisation error bounds. The new framework combines ideas from both PAC-Bayesian theory and the notion of algorithmic stability. They obtain new generalization bounds for stochastic gradient Langevin dynamics (SGLD) and several other noisy gradient methods (e.g., with momentum, mini-batch and acceleration, Entropy-SGD). Their result recovers (and is typically tighter than) a recent result in Mou et al. (2018) and improves upon the results in Pensia et al (2018). "
SP:a82fcd1d3196ddf078cfe8f4bc6f445d9d2bdc11,"This paper investigates the role of the hippocampus in continual learning in the context of continual learning of two different spatial navigation strategies. Specifically, the authors analyze population-level activity of hippocampal CA1 neurons of rodents learning to perform allocentric and egocentric spatial tasks. The results show that hippocampal neurons encode relevant task variables such as decisions, navigational strategies and reward location. The authors also show that a standard deep reinforcement learning model achieves similar average performance when compared to animal learning, but fails to mimic animals during task switching."
SP:51acf1f8108683dce543a1fb4a61fbd593f9b4cc,"This paper proposes a new policy optimization method for continuous action spaces. The main idea is to use bootstrapping to reduce the number of samples required to train the policy. This is done by using a few samples from the policy distribution and a new loss function based on the trajectories’ mean and standard deviation. Experiments show that the proposed method outperforms the baseline policy optimization algorithm, PPO. "
SP:1ce3bc4d31712886f7dcada5b5ae67c3c376819a,"This paper studies the lottery ticket hypothesis, which claims that neural networks contain sparse subnetworks, which, if appropriately initialized (the winning tickets), are capable of matching the accuracy of the full network when trained in isolation. This paper aims to answer the following open questions: can we find winning tickets with few data samples or few labels? Can we even obtain “good” tickets without supervision? This paper shows that winning tickets found in these scenarios are competitive with winning tickets generated on the full ImageNet dataset when evaluated on ImageNet classification task. "
SP:dbcebe5b73486885d9f4478b258047c02f8481a2,"This paper studies the problem of prediction undersensitivity in neural reading comprehension models. The authors propose a noisy adversarial attack which searches among semantic variations of comprehension questions for which a model still erroneously produces the same answer as the original question – and with an even higher probability. They show that, despite comprising unanswerable questions, SQuAD2.0 and NewsQA models are vulnerable to this attack and commit a substantial fraction of errors on adversarially generated questions. This indicates that current models—even where they can correctly predict the answer—rely on spurious surface patterns and are not necessarily aware of all information provided in a given comprehension question."
SP:5da870060778de460c1abe91562d6f3e707efef4,"This paper proposes a model-based approach to ensuring the safety of reinforcement learning agents. The proposed method learns a directed graph called the “inventive module” to capture all possible trajectories that can be followed by the agent. This graph allows the agent to efficiently traverse through the imagined environment without ever taking any action in reality. A baseline state, which can either represent a safe or an unsafe state, is taken as a human input, and the imaginative module is used to predict whether the current actions of the agent can cause it to end up in dangerous states in the future. Experiments are conducted on two gridworld environments and a self-driving car simulator."
SP:c2796f28fb067138303df8d424d646f4ada31558,This paper proposes a method to learn finite differences inspired by physics equations. The method leverages data-driven end-to-end learning to discover underlying dynamical relations between the spatial and temporal differences in given sequential observations. The authors demonstrate the superiority of PA-DGN in the approximation of directional derivatives and the prediction of graph signals on the synthetic data and the real-world climate observations from weather stations.
SP:db8ed4f4fc3967f5dd4d208d5d029730eb99e840,This paper studies the problem of training structured neural networks with nonsmooth regularization and constraints. The authors propose a proximal-type stochastic gradient descent (ProxSGD) algorithm to solve this problem. Theoretical analysis and numerical experiments are provided to demonstrate the effectiveness of the proposed algorithm. 
SP:2ca1f4da9faee79768764cda5d09d949cc942acc,"This paper proposes a novel lossy transform coding framework based on generative models equipped with an approximate latent posterior and shows that it is bits-back efficient (Hinton & Van Camp, 1993) and can also be optimized end-to-end. The authors propose a relative entropy coding algorithm to achieves bitsback efficiency, and they demonstrate the efficiency of their method by training a Probabilistic Ladder Network on the CLIC (2018) dataset and show that the rate-distortion curve of our method is competitive with the state-of-the-art on the Kodak dataset."
SP:788fd2b6956dd69bf7752d39ea21883947128c8a,"This paper proposes a new method for super-resolution (SR) based on C-JPG images. The proposed method is based on a two-stage SR pipeline. The first stage consists of two stages: the LR stage and the SR stage. The LR stage is a lossless SISR model. The SR stage is an encoder-decoder model that is trained on LR images and SR images. In the second stage, a cycle loss is added to ensure consistency between LR and SR stages. Experiments are conducted on CIFAR-10 and ImageNet to demonstrate the effectiveness of the proposed method."
SP:18dd92f2f55020be4f5a089b3b251327e47886f4,This paper presents a deep neural network architecture that is able to estimate a full probability surface of pass probabilities from single-location labels derived from high frequency spatio-temporal data of professional soccer matches. The network is trained by learning a feature hierarchy that produces predictions at different sampling levels that are merged together to preserve both coarse and fine detail. The proposed deep learning architecture can be easily adapted to solve many other related problems in sports analytics; this paper demonstrates this by extending the network to learn to estimate pass-selection likelihood.
SP:1ae31baf383fc520687b255d9cac14c3b040e253,"This paper proposes an inductive matrix completion method based on a graph neural network (GNN) that maps user and item embeddings to their corresponding ratings. The proposed method is based on 1-hop subgraphs around (user, item) pairs generated from the rating matrix. It achieves highly competitive performance with state-of-the-art transductive baselines. In addition, IGMC is inductive – it can generalize to users/items unseen during the training and can even transfer to new tasks. "
SP:c5cb1b50e17a69e88d5ae28848e265215162da1e,"This paper studies the unconstrained minimization of a smooth objective function in the setting where only function evaluations are possible. The authors propose and analyze stochastic zeroth-order method with heavy ball momentum. They show new complexity results for non-convex, convex and strongly convex functions. They test their method on a collection of learning to continuous control tasks on several MuJoCo environments with varying difficulty."
SP:a216cfc29937eb398ea98cb1aea3481c9aed8240,"This paper proposes Action Semantics Network (ASN), a neural network architecture for multi-agent reinforcement learning. The main idea is to model the influence of each agent’s action on the actions of other agents. This is done by considering the action semantics between agents. The proposed ASN can be easily combined with existing deep reinforcement learning (DRL) algorithms to boost their performance. Experimental results on StarCraft II micromanagement and Neural MMO show that ASN significantly improves the performance of state-of-the-art DRL approaches compared with several network architectures."
SP:efaf3a440dc17e05177832083ffbc23760ed7c97,"This paper proposes to exploit the low-rank structure of the state-action value function for both planning and deep reinforcement learning. Specifically, the authors propose to use Matrix Estimation (ME) techniques to leverage the global structures of the Q function. This leads to a more efficient planning procedure for classical control and a simple scheme that can be applied to value-based RL techniques to consistently achieve better performance on “low-rank” tasks. Extensive experiments on control tasks and Atari games confirm the efficacy of the proposed approach."
SP:430336893b247b7bd45687d78b0d0511a7369e87,"This paper proposes a new algorithm called Best-Action Imitation Learning (BAIL) for off-policy reinforcement learning in the batch reinforcement learning setting. BAIL first selects from the batch the actions it believes to be high-performing actions for their corresponding states; it then uses those state-action pairs to train a policy network using imitation learning. Although BAIL is simple, it achieves state-of-the-art performance on the Mujoco benchmark."
SP:94078964876667e8a5d9ae7728d779d5b91a576e,"This paper proposes DeepXML, a novel deep extreme multi-label learning algorithm for short text documents. The main idea is to learn word embeddings on head labels and transfer them through a novel residual connection to data impoverished tail labels. The authors also propose to increase the amount of negative training data available by extending state-of-the-art negative sub-sampling techniques and re-ranking the set of predicted labels to eliminate the hardest negatives for the original classifier. The proposed method is implemented efficiently by extending the highly scalable Slice algorithm for pretrained word embedding. "
SP:b1b1252d82fa1bea18309e0b0b894e0f28f48bc9,"This paper proposes a novel method to improve the Hamming distance between user and item hash codes in collaborative filtering. The proposed method is based on the self-masking technique, where the user hash code acts as a mask on the items (using the Boolean AND operation), such that it learns to encode which bits are important to the user, rather than the underlying item property that the bits represent. This allows a binary user-level importance weighting of each item without the need to store additional weights for each user. Experiments show that the proposed method outperforms state-of-the-art baselines on 4 datasets."
SP:80898d0f2b2c8dc3388fa9164e529eae36aa1b21,"This paper studies the problem of mode collapse in GANs. The authors propose a set of statistical tools to quantify the general mode collapse of GAN distributions. They also analyze possible causes of the mode collapse and propose two simple yet effective methods to calibrate the GAN learned distribution, without accessing either model parameters or the original training data. "
SP:e5b5dda2f024cfda10526e744aa035e0165af58a,"This paper studies the optimization and generalization of over-parameterized neural networks through coupling with higher-order terms in their Taylor series. The authors propose randomizing the neural networks, which allows them to escape their NTK and couple with quadratic models. They show that the optimization landscape of randomized two-layer networks are nice and amenable to escaping-saddle algorithms. They also prove concrete generalization and expressivity results on these randomized networks."
SP:cef7ea513eb3e42be4edf40e4ee1701a969bcbea,"This paper proposes a novel graph filter discriminative score (GFD) to evaluate the effectiveness of graph convolutional filters for the semi-supervised node classification task. The authors show that there is no single filter as a “silver bullet” that performs the best on all possible graphs, and graphs with different properties are in favor of different graph filters. Based on these findings, the authors propose Adaptive Filter Graph Neural Network (AFGNN) that can adaptively learn a proper filter for a specific graph using the GFD Score as guidance. Experiments show that the proposed model can find better filters and achieve better performance compared to existing GNNs, on both real-word and newly created benchmark datasets."
SP:3c5ec9dbcf914c8901e4e35f3c2a7df4707422ab,"This paper studies the problem of distributionally robust optimization (DRO) for overparameterized neural networks. In particular, the authors focus on the setting where the training data is overparametrized and the goal is to minimize the worst-case training loss over a set of atypical groups of the training set. The authors propose to use group DRO to solve this problem. The main idea is to use a regularization term that encourages the model to generalize better on groups for which the spurious correlation between a and y does not hold on average but not in such groups. The paper shows that this regularization can be used to improve the performance of the model on a variety of tasks, including natural language inference, object recognition, and image recognition."
SP:eb1ee2e0f7d8466a04b58508ecb3da7b667eecdf,"This paper proposes a local explanation method for black-box classifiers. The proposed method is based on a distribution controller on relevance scores, which is trained with a neural network to directly guide the distribution of relevance scores. In addition, a classification loss is introduced to optimize the proposed predictor. The experimental results demonstrate that the proposed method also outperforms other local explanation methods. "
SP:32ea7cbc47cbdb1f703f4e07c31ce90abe083424,"This paper proposes a method to train a neural network that can be used for image reconstruction and classification. The proposed method is based on lifting the training optimization problem by treating the result of top-K selection as a slack variable, resulting in a simple, yet effective, multi-stage training. The method is able to learn to detect recurring structures in the training dataset by learning to reconstruct images. It can also learn to localize structures when only knowledge on the occurrence of the object is provided, and outperforms the state-of-the-art."
SP:da1c5f6351d531482e90b86c3cceb52850c520de,"This paper proposes a neural program synthesis algorithm, AutoAssemblet, for generating assembly code that can be executed to execute a state change in the CPU and RAM. The authors propose a self-learning strategy for code generation learned via reinforcement learning. They adapt policy networks and value networks to reduce the breadth and depth of the Monte Carlo Tree Search, resulting in better synthesis performance. They also propose a multi-entropy policy sampling technique to alleviate online update correlations. Experiments are conducted to demonstrate the effectiveness of the method."
SP:0d4687fc36c02e27d1b95d532a3947589f92b1da,This paper studies the impact of model architecture on the speed of training in the context of gradient descent optimization. The authors use the ideas from prior work that shows gradient descent can be modeled as a first-order ODE and use ODE’s coefficient matrix H to characterize the convergence rate. They introduce a simple analysis technique that enumerates H in terms of all possible “paths” in the network. They show that changes in model architecture parameters reflect as changes in the number of paths and the properties of each path.
SP:3e3bc8f617df742a395e7d315ec3810a42071294,"This paper analyzes the relationship between wide neural networks (NNs) and interpolating kernel methods. The authors prove that a wide neural network is essentially a sum of two parts: the first is the minimum complexity solution of an interpolating kernels, while the second contributes to the test error only and depends heavily on the initialization. This decomposition has two consequences: (a) the second part becomes negligible in the regime of small initialization variance, which allows us to transfer generalization bounds from minimum complexity interpolating Kernel methods to NNs; (b) in the opposite regime, the generalization error of wide NNs increases significantly with the initialization variance. "
SP:b15ea009a36a0a76728dfc103d668d6781a8a99a,"This paper proposes a novel depth propagation method for stereo-based 3D object detection in autonomous vehicles. The method is based on the observation that stereo depth estimation is biased towards far-away objects, and proposes a depth propagation algorithm to diffuse the few exact measurements across the entire depth map. The proposed method is evaluated on the KITTI object detection benchmark and achieves state-of-the-art results."
SP:983d84502264633f3385d426c1d4601a0744ea9a,"This paper proposes an adversarial example detection method that can withstand norm-constrained white-box attacks. Inspired by one-versus-the-rest classification, in a K class classification problem, the authors train K base detectors where the i-th detector is trained to discriminate natural data of class i from adversarial examples perturbed from other classes. They further devise a generative approach to detect/classify adversarial samples by interpreting each base detector as an unnormalized density model of the class-conditional data."
SP:461e9308d050bc3dc7b35233452668bb31f5d491,"This paper proposes a novel intrinsic reward for exploration in model-free reinforcement learning. The proposed reward encourages the agent to take actions that lead to significant changes in its learned state representation. The authors show that this approach is more sample efficient than existing exploration methods, particularly for procedurally-generated MiniGrid environments. They also analyze the learned behavior as well as the intrinsic reward received by the agent."
SP:c002c20b5e8696588e029c0f65e88860418826c4,"This paper studies the problem of large-scale query-document retrieval in the context of Transformer-based embedding models. The authors propose a set of paragraph-level pre-training tasks to improve the performance of the embedding-based Transformer model. They show that with these tasks, the two-tower Transformer models with random initialization (No Pretraining) or the unsuitable token-level pretraining task (MLM) are no better than the robust IR baseline BM-25. "
SP:4e161e08a624f87633dfb49dfd46bd1665e15189,"This paper proposes a new graph convolution operation called bipartite Graph Convolution (GraphConv) to replace graph convolutions and pooling in graph neural networks (GNNs). The main idea is to split the graph into two parts, i.e., an input and an out graph. The out graph consists of the input graph and the out graph is the output graph.  The authors show that GraphConv can be used as a special case of GNNs with skip connections, strided convolutions, deconvolution, skip connections and skip connections. The authors also show that the proposed method can be applied to graph autoencoders and graph skip connection networks."
SP:9b9b6ee9014e5538442ba76d6059ed01f59ec8fb,This paper proposes a method to improve the few-shot classification performance of metric-based methods by using feature-wise transformation layers for augmenting the image features using affine transforms to simulate various feature distributions under different domains in the training stage. The authors further apply a learning-to-learn approach to search for the hyper-parameters of the feature transformation layers. Experiments show that the proposed method can improve the performance of the metrics-based few shot classification methods.
SP:df46627cb984a56bba36d510bfc52e00751e9107,"This paper proposes a novel convolutional neural network architecture for Lagrangian fluid simulation. The proposed architecture is based on spatial convolution, which is a simple extension of N-D convolution to the continuous domain. The authors show that their network architecture can simulate different materials, generalize to arbitrary collision geometries, and can be used for inverse problems. The experiments show that the presented approach outperforms a state-of-the-art graph-based framework."
SP:3e17f333cf07183969c02bb66afdd3ccbf25bb19,"This paper proposes a new ensemble method, called BatchEnsemble, to reduce the computational and memory cost of ensembles. The proposed method is parallelizable across devices and parallelizable within a device, where multiple ensemble members are updated simultaneously for a given mini-batch. The method is evaluated on CIFAR-10/100 classification with ResNet32 and WMT14 EN-DE/EN-FR translation, and out-of-distribution tasks. "
SP:a123a425ef3eb6188833d5a42e851bc3fa59df65,"This paper proposes a neural network-based solver for solving forward and inverse PDEs. The network is trained to minimize deviations of the learned function from the strong PDE solution and satisfy the boundary conditions. The resulting solution is an explicit smooth differentiable function with a known analytical form. The method is grid free, mesh free and shape free. The authors demonstrate their method on several free shape 2D systems with application to Electrical Impedance Tomography (EIT), diffusion and wave equations. "
SP:973d0ad0faadcf7298300f2758de9154205e7113,This paper analyzes the architecture of binarized neural networks (BNNs) and how it affects the performance of logic-based reasoners. The authors propose two modifications to the BNN architecture and the training procedure to get a simpler network for SAT solvers without sacrificing accuracy on the primary task. The experimental results demonstrate that the proposed method scales to larger deep neural networks compared to existing work for existential and probabilistic queries.
SP:ca985e758f195bd04fb9f24b290a83974d6d308b,"This paper studies the expressive power of graph neural networks falling within the message-passing framework (GNN). Two results are presented. First, GNN are shown to be Turing universal under sufficient conditions on their depth, width, node attributes, and layer expressiveness. Second, it is discovered that GNNmp can lose a significant portion of their power when their depth and width is restricted. The proposed impossibility statements stem from a new technique that enables the repurposing of seminal results from distributed computing and leads to lower bounds for an array of decision, optimization and estimation problems involving graphs."
SP:a98ae70a91850bbe624c307ba61d3daeb2494b82,"This paper proposes a localised generative flow (LGF) method for density estimation based on continuous bijections. The authors argue that flow-based density models are limited in their ability to learn target distributions with complicated topologies, and propose LGFs to address this problem. The LGFs are composed of stacked continuous mixtures of bijection, which enables each bijection to learn a local region of the target rather than its entirety. The proposed method is a generalization of existing normalising flow methods, which can be used without modification as the basis for an LGF model. Experiments are conducted on a variety of density estimation tasks. "
SP:3adc341dece170f428195e4dccadfb5f5daddf2d,"This paper studies the problem of vision-and-language navigation (VLN) in unseen environments. The authors claim that the performance gap between seen and unseen environments has been observed in the VLN tasks. They propose two ways to solve this problem: environment re-splitting and feature replacement. Experiments are conducted on R2R, R4R, and CVDN datasets. "
SP:298e0043e99f586d314fbd9d16fdc6ae885e1ebb,"This paper studies the problem of using implicit human feedback to accelerate and optimize the training of deep reinforcement learning (DRL) agents. Specifically, the authors propose to use the EEG data of a non-expert human observer to estimate the error-related event potentials (ErrP) for state-action pairs in an Atari-type environment. The implicit feedback is then used to augment the agent’s learning in the RL tasks. The authors show that the definition of ErrP is generalizable across different Atari-like environments (discrete grid-based navigation games, studied in this work) and demonstrate the effectiveness of their approach through experiments."
SP:a8395f8b877e1eebaef9ff2e8b4e488d55a74ef4,"This paper proposes a novel method for laconic classification, where the goal is to minimize the amount of information (aka. entropy) required in individual test images to maintain correct classification. Given a classifier and a test image, the paper proposes to compute an approximate minimal-entropy positive image for which the classifier provides a correct classification, becoming incorrect upon any further reduction. The paper proposes two complementary frameworks for computing the minimal entropy positive images of both human and machine classifiers. The experiments over the ILSVRC test-set show that machine classifier are more sensitive entropy-wise to reduced resolution (versus cropping or reduced colour for machines, as well as reduced resolution for humans) than humans. "
SP:81cec8f907d8fa0653b5bc08af1f59bfefd49619,This paper analyzes the robustness of different perturbation-based defenses for convolutional neural networks based on the instability assumption. The authors identify a family of defense techniques that are based on deterministic lossy compression algorithms and randomized perturbations to the input that all lead to similar gains in robustness. They provide a comprehensive experimental analysis of when and why these defenses work and potential mechanisms that could explain their effectiveness in different settings. 
SP:a136b98e0ed478144ce9dd26e2b6d611543124e8,"This paper proposes a method for self-supervised learning of 3D feature maps. The method is based on a neural network that takes a 2.5D video stream as input and maps it to a 3D space. The model is trained with a contrastive loss, which is a combination of contrastive regularization and a view-contrastive loss. Experiments show that the proposed method is able to learn 3D features useful for semi- and unsupervised object detection tasks."
SP:6fd61604a2eeb8a2cbbda6c40807cebef6d40f2f,"This paper studies the problem of unsupervised domain translation (UDT), i.e. finding meaningful correspondences between two domains, without access to explicit pairings between them. The authors define UDT in a rigorous, non-ambiguous manner, explore the implicit biases present in the approach and demonstrate the limits of the approaches. Specifically, they show that mappings produced by these methods are biased towards low energy transformations, leading them to cast UDT into an Optimal Transport (OT) framework by making this implicit bias explicit. This allows them to provide theoretical guarantees for existing methods, and also solve UDT problems where previous methods fail. Finally, making the link between the dynamic formulation of OT and CycleGAN, they propose a simple approach to solve the UDT, and illustrate its properties in two distinct settings."
SP:8bb3ce11ad773685f6e41d90db3e7a5481e5ba47,"This paper proposes a new regularization method, RotationOut, that randomly rotates the input of each layer of a neural network. The method is based on the idea of treating the input layer as an entire vector and introducing regularization by randomly rotating the vector. It can also be used in convolutional layers and recurrent layers with small modifications. The authors further use a noise analysis method to interpret the difference between R rotationOut and Dropout in co-adaptation reduction. Extensive experiments in vision and language tasks are conducted to show the effectiveness of the proposed method."
SP:37620ae8dc5683eb2843792e0aa4cbe6cba366f7,"This paper proposes a method to create universal adversarial perturbations (UAPs) for a given CNN in a data-free manner. The authors show that the adversary generation with full training data can be approximated to a formulation without data. This is realized through a sequential optimization of the adversary perturbation with the proposed dilate loss. Extensive experiments demonstrate that the proposed method has theoretical support, and achieves higher fooling rate. "
SP:2fd7d5507a8727db743dc89379a6f021d31ed39a,"This paper proposes a transferable neural architecture search (NAS) method based on meta-learning to adapt to a new task quickly through a few gradient steps. Specifically, T-NAS learns a meta-architecture that is more flexible than the existing NAS methods. In addition, to optimize the whole search network, the authors propose an efficient first-order approximation algorithm. Extensive experiments show the effectiveness of the proposed method."
SP:1314a79ba12474adb33ff31b3cb22bed25b94fb7,"This paper proposes a stochastic neural network (SE-SNN) architecture for discriminative learning by directly modeling activation uncertainty and encouraging high activation variability. Compared to existing SNNs, the proposed SE SNN is simpler to implement and faster to train, and produces state-of-the-art results on network compression by pruning, adversarial defense and learning with label noise. Experiments show that the proposed model has connections to VIB, Dropout, and non-informative activation priors."
SP:bd4935d4fcf33f60f22e0f2fd9f7dc8ddfab6d17,"This paper proposes a meta-learning algorithm for generating curiosity-inducing behavior. The algorithm is based on meta-learned programs, which are programs that are similar to those designed by humans in ML papers. The authors show that the proposed algorithm can generalize to different tasks more easily than previous meta-RL methods. The proposed algorithm is evaluated on grid navigation with image inputs, acrobot, lunar lander, ant and hopper. "
SP:6dff0f3a84809ae0ba9f58f36303597f1ba6dcc5,"This paper proposes a method for generating code given its surrounding code. The main idea is to model a program as an abstract syntax tree (AST) by decomposing it into a product of conditional probabilities over its nodes. The authors propose a neural model that computes these conditional probabilities by considering all AST paths leading to a target node. Unlike previous structural techniques that have severely restricted the kinds of expressions that can be generated in this task, this approach can generate arbitrary expressions in any programming language. "
SP:7fc60d6fd1cfcc135c34f9664d172d3fd1c0ae0a,"This paper studies the convergence of gradient descent methods for learning large neural networks. The authors show that the objective functions in learning neural networks are convex in the canonical model space. They also prove that the gradients between the original NN model space and the canonical space are related by a pointwise linear transformation, which is represented by the so-called disparity matrix. Finally, they show that gradient descent converges to a global minimum of zero loss provided that the disparity matrices maintain full rank. "
SP:78a536138570fe9b5d88350e4b16d598a7db1fe0,"This paper proposes interactive graph-based segmentation algorithms that enforce connectivity. The authors introduce an instance aware heuristic of a discrete Potts model, and a class-aware Integer Linear Programming (ILP) formulation that ensures global optimum. Both algorithms can take RGB, or utilize the feature maps from any DCNN, whether trained on the target dataset or not, as input. They present competitive semantic (and panoptic) segmentation results on the PASCAL VOC 2012 and Cityscapes dataset given initial scribbles."
SP:2eb90879ddbc39b6b5c05152784d6044d1940513,"This paper proposes a new adversarial defense method that uses a learned saliency model to detect adversarial perturbations in an image. The proposed method is based on the observation that the saliency maps of adversarial images differ from those of natural images. Based on this observation, the authors propose to learn a saliency map that captures the shifts in saliency due to the perturbation while also having a low computational cost. Then, a CNN is trained to distinguish between adversarial and natural images using salient pixels as its input. The method is evaluated on MNIST, CIFAR-10, and ASSIRA. "
SP:fe5510d05ff091a5f133f2dbcd1b23d8d58d2c3e,"This paper studies the problem of computing the probability that a given model is susceptible to adversarial attacks. The authors consider the case where the model is trained with gradient descent on MNIST and Fashion MNIST. They show how to compute global robustness with estimation error upper-bounded by $\mathcal{O}(1/\sqrt{T})$ for any $\epsilon$ selected a priori. They also show how concentration inequalities can be used to compute robustness. Finally, they use the methods to provide statistically sound analysis of the robustness/accuracy trade-off for a variety of neural networks architectures and training methods. "
SP:8f5616a1480b68c04b496ed498d237d5a7e87794,This paper studies the problem of robust reinforcement learning with Wasserstein constraint. The authors propose a novel algorithm based on the robust advantage actor-critic algorithm (WRAAC) to find the optimal policy with some extent of robustness to environmental dynamics. The proposed algorithm is evaluated on the Cart-Pole environment. 
SP:d85963f5f0f6b20cf08f2a7c169ae33a45db7de2,"This paper proposes a method to approximate mixed strategy Nash equilibria in multi-player continuous games, which always exist and include the pure ones as a special case. The authors propose to use the pushforward measure technique to represent a mixed strategy in continuous spaces. This allows them to generalize the Gradient-based Nikaido-Isoda (GNI) function to measure the distance between the players’ joint strategy profile and a Nash equilibrium. In numerical experiments, the proposed method consistently and significantly outperforms recent works on approximating Nash equilibrium for quadratic games, general blotto games and GAMUT games."
SP:280d85cd8164a268f9d496ae5f17189c50f30dc1,"This paper proposes a neural execution tree (NExT) framework to augment training data for text classification using natural language (NL) explanations. NExT transforms NL explanations into executable logical forms by semantic parsing and generalizes different types of actions specified by the logical forms for labeling data instances, which substantially increases the coverage of each NL explanation. Experiments on two NLP tasks (relation extraction and sentiment analysis) demonstrate its superiority over baseline methods."
SP:a9b5f7257dedd719cfe341fca275776734af1d98,"This paper extends the applicability of verified training to recurrent neural network architectures and more complex specifications that go beyond simple adversarial robustness, particularly specifications that capture temporal properties like requiring that a robot periodically visits a charging station or that a language model always produces sentences of bounded length. Experiments show that while models trained using standard training often violate desired specifications, our verified training method produces models that both perform well (in terms of test error or reward) and can be shown to be provably consistent with specifications. "
SP:3903680e07b676409e3cf6a1044b67291fe38630,"This paper studies the problem of generalization to visually diverse environments in deep reinforcement learning. The authors formalize the problem, illustrated the inefficiencies of standard domain randomization, and proposed a theoretically grounded method that leads to robust, low-variance policies that generalize well. They conducted several experiments in different environments of differing complexities to support their claims."
SP:c79046dc56b9ee9c926f87386046422ea134ae8d,"This paper studies the problem of deep metric learning (DML). The authors cast DML as a simple pairwise binary classification problem that classifies a pair of examples as similar or dissimilar. The authors propose a simple and effective framework to sample pairs in a batch of data for updating the model. The key to this framework is to define a robust loss for all pairs over a mini-batch of data, which is formulated by distributionally robust optimization. The flexibility in constructing the uncertainty decision set of the dual variable allows us to recover state-of-the-art complicated losses and also to induce novel variants. Empirical studies on several benchmark data sets demonstrate that the proposed method outperforms the existing methods."
SP:38420928e40ef80c0136ad607b9275f9ab1e0769,"This paper studies the problem of finding a local minimum in non-convex finite-sum minimization. The authors first prove that the trust region method with inexact gradient and Hessian estimation can achieve a convergence rate of order O(1/k) as long as those differential estimations are sufficiently accurate. Combining such result with a novel Hessian estimator, the authors propose a sample-efficient stochastic trust region (STR) algorithm that finds an approximate local minimum within $\sqrt{n/\delta}$. This improves the state-of-the-art result by a factor of O(n). The authors also develop Hessian-free STR algorithms that achieve the lowest runtime complexity."
SP:28a35b70b5e6915af28cacebc4ea50690c9534af,"This paper proposes Farkas layers, a method for training deep neural networks that ensures that at least one neuron is active at a given layer. The method is based on linear programming. The authors show that by simply adding one linearly dependent row to the weight matrix, they ensure that no neurons are dead. Experiments show that the proposed method can be used alone or in conjunction with different initialization methods. "
SP:1d325b148e3efe407241c1f1cbe8d17400499741,"This paper studies the problem of computing exact robustness certificates for deep classifiers with differentiable activation functions. The authors show that if the eigenvalues of the Hessian of the network are bounded, we can compute a robustness certificate in the l2 norm efficiently using convex optimization. Then, they derive a computationally efficient differentiable upper bound on the curvature of a deep network. Finally, they also use curvature bound as a regularization term during the training to boost its certified robustness against adversarial examples."
SP:33f6f5aa0d4655e5d75fe612e0eff05e579d45c5,"This paper proposes a new method for solving the linear inverse problem. The proposed method is based on the recently proposed Deep Image Prior (DIP) method, where the convolutional weights of the network are optimized to match the observed measurements. The authors show that this approach can be applied to solve any differentiable linear inverse problems, outperforming previous unlearned methods. Unlike various learned approaches based on generative models, the proposed method does not require pre-training over large datasets. A novel learned regularization technique, which incorporates prior information on the network weights, is proposed to reduce reconstruction error, especially for noisy measurements. "
SP:23c0f621e6041003b59bf0532130760694cf6a4a,"This paper proposes a general HRL framework TAIC for learning temporal abstraction from action sequences. The authors formulate the temporal abstraction problem as learning latent representations of action sequences and present a novel approach of regularizing the latent space by adding information-theoretic constraints. Specifically, the authors maximize the mutual information between the latent variables and the state changes. The learned abstraction allows us to learn new tasks on higher level more efficiently."
SP:4e54c9196ba1eb2b6a0b0eee41e4a6f3a9de72dd,"This paper proposes a novel layer-wise sampling strategy to sample the nodes layer by layer conditionally based on the factors of the bi-directional diffusion between layers. In this way, the authors potentially restrict the time complexity linear to the number of layers, and construct a mini-batch of nodes with high local bi directional influence (correlation). Further, they apply the self-attention mechanism to learn suitable weights for the sampled nodes, which allows the model to be able to incorporate both the first-order and higher-order proximities during a single layer propagation process without extra recursive propagation or skip connection. Extensive experiments on three large benchmark graphs demonstrate the effectiveness and efficiency of the proposed model."
SP:bb0af9c011ef982c34fcadb545f6b5771818e7fa,"This paper presents a new state-space model for unsupervised video prediction. The model is based on a combination of an image model and a dynamics model. The dynamics model is used for inference and the image model for training. The proposed model is evaluated on the task of SQAIR, where it is shown to outperform the state-of-the-art model-free and model-based RL baselines."
SP:e67b463bc0aec2345925d609fa521ea49df57fd9,This paper proposes an autoencoder model that is a fusion of VAE and GANs. The main idea is to replace the explicit likelihood of the VAE loss with an implicit likelihood by an adversarially trained discriminator. The discriminator is trained by minimizing the $\lambda$-Jeffreys divergence between the model distribution and the true data distribution. The proposed method is evaluated on CIFAR-10 and TinyImagent datasets. 
SP:87056d0147ddcaf5d78f6888b05161fbdbb3346c,"This paper studies the problem of adversarial attacks on Bayesian optimal classifiers. The authors show that the optimal classifier is not always robust to adversarial perturbations to the input image. They show that under certain conditions on the data distribution, adversarial examples can be made arbitrarily close to the optimal decision boundary. They also show that this can happen even when the classes are easy to separate, when the ideal classifier has a smooth decision surface, and when the data lies in low dimensions. Finally, they introduce new datasets of realistic images of faces and digits where the Bayes-Optimal classifier can be calculated efficiently and show that for some of these datasets the optimal classesifier is robust and for others it is vulnerable."
SP:a7b3a35e6a79084bdfd1e4a963dfa081279cd8bb,"This paper studies the impact of magnitude pruning on the accuracy of neural network models on different classes and images. The authors identify a subset of images as pruning identified exemplars (PIEs) which are more challenging for sparse and non-sparse models to generalize to. Removing PIE images from the test set greatly improves top-1 accuracy for both sparse models. These hard-to-generalize-to images tend to be mislabelled, of lower image quality, entail abstract representations, atypical examples or require fine-grained classification."
SP:4b17edaa7ec6201891433320d85f9a415656b763,"This paper proposes a novel reinforcement learning agent, KG-A2C, for interactive fiction games. The key idea is to use a combination of a knowledge graph-based state space and a template-based action space. The knowledge graph serves as a means for the agent to understand its surroundings, accumulate information about the game, and disambiguate similar textual observations, while the template provides a measure of structure that enables us to exploit that same knowledge graph for language generation. Together they constrain the vast space of possible actions into the compact space of sensible ones. Experiments show that the proposed agent achieves state-of-the-art performance on a large proportion of the games."
SP:b1784ecbb8f36eef9cae33d61ce60d80c2f9c38d,"This paper addresses the problem of negative diversity ignorance in maximum likelihood estimation (MLE) by introducing an extra Kullback-Leibler divergence term derived by comparing a data-dependent Gaussian prior and the detailed training prediction. The proposed D2GPo objective is defined over a prior topological order of tokens and is poles apart from the data-independent Gaussian regularization (L2 regularization) commonly adopted in smoothing the training of MLE. Experimental results show that the proposed method makes effective use of a more detailed prior in the data and has improved performance in typical language generation tasks, including supervised and unsupervised machine translation, text summarization, storytelling, and image captioning."
SP:7c29cb5a32b14e1392408dc5daba4cd35848bea9,"This paper studies the calibration of deep neural networks (DNNs). The authors propose to replace the widely used cross-entropy loss with focal loss, which allows us to learn DNNs that are already very well calibrated. The authors provide a thorough analysis of the factors causing miscalibration, and use the insights to theoretically justify the empirically excellent performance of focal loss. They perform extensive experiments on a variety of computer vision (CIFAR-10/100) and NLP (SST, 20 Newsgroup) datasets, and show that focal loss achieves state-of-the-art accuracy and calibration in almost all cases."
SP:cd6b8417ec8bcb773c78cff677bb0a76d6b3f6f3,"This paper proposes LiPopt, a polynomial optimization framework for computing tighter upper bounds on the Lipschitz constant of neural networks. The authors show how to use the sparse connectivity of a network to significantly reduce the complexity of computation. This is specially useful for convolutional as well as pruned neural networks, and the authors conduct experiments on networks with random weights and networks trained on MNIST, showing that their approach yields superior estimates, compared to baselines."
SP:31c9dc0dd8806daddc9cb48c56ec819577fe46cd,"This paper proposes a self-supervised learning approach for video features that results in significantly improved performance on downstream tasks (such as video classification, captioning and segmentation) compared to existing methods. The method extends the BERT model for text sequences to the case of sequences of real-valued feature vectors, by replacing the softmax loss with noise contrastive estimation (NCE). The authors also show how to learn representations from sequences of visual features and sequences of words derived from ASR (automatic speech recognition)."
SP:0f24424d10f1201dd25e8c56354e10afc9b2b11c,"This paper proposes a method to reduce the amount of data that needs to be transferred between clients during the inference phase of a neural network. Specifically, the authors propose a framework that learns to select the relevant parts of the input data for a given neural network and its task. The selection masks are trained jointly with the neural network to ensure that a good model performance is achieved while, at the same time, only a minimal amount of the data is selected. Experiments show that it is often possible to achieve a good accuracy with significantly less input data needed for inference."
SP:aa4fcf5b2cae05c5c6a903c24e4992b56655dee2,"This paper proposes a novel loss function for out-of-distribution (OOD) detection based on the Outlier Exposure (OE) technique. The proposed loss function consists of two regularization terms: the first minimizes the l1 norm between the output distribution of the softmax layer of a DNN and the uniform distribution, while the second minimises the Euclidean distance between the training accuracy and its average confidence in its predictions on the training set. Experiments are conducted on image classification and text classification tasks and show that the proposed method outperforms the Mahalanobis distance-based classifier."
SP:89bc528ef801182365ac279e8963803afccb391d,"This paper proposes an end-to-end deep learning model, called E2Efold, for RNA secondary structure prediction which can take into account the inherent constraints in the problem. The key idea is to directly predict the RNA base-pairing matrix, and use an unrolled algorithm for constrained programming as the template for deep architectures to enforce constraints. With comprehensive experiments on benchmark datasets, the authors demonstrate the superior performance of the proposed method."
SP:b68560cce8c64ebe0ca5e6534b3732c775d36452,"This paper studies the problem of learning a policy that can be transferred to a real-world environment. The authors propose to train agents in a virtual environment, where each agent takes turns to visit a different simulation of the environment, and each agent's simulation is different from the other agents' simulation. The goal of the agent is to learn a policy which can be applied to the real world environment.  The authors show that the policy learned in the simulated environment is better than the one learned by each agent individually. "
SP:bd1dc08b4fd9a5cc78d26d7eb7f05dbb4a629ab1,"This paper proposes a dialog generation model that learns a semantic latent space, on which representations of semantically related sentences are close to each other. This latent space is learned by maximizing correlation between the features extracted from prompt and responses. An additional autoencoder is trained, for recovering the full sentence from the latent space. Experimental results show that the proposed model eliminates the generic response problem, while achieving comparable or better coherence compared to baselines."
SP:ef0d5fd333ed60feb3946d24002e9a90642aea66,This paper proposes Gaussian light and shadow (GLAS) to explain the spatial impact of deep models by the feature perturbation inspired by light and shadows in nature. GLAS provides a useful coarseto-fine control benefiting from scalability of Gaussian mask. The authors also devised the ability to identify multiple instances through recursive GLAS. They prove the effectiveness of GLAS for fine-grained classification using the fine-Grained classification dataset. 
SP:d17ca20cc527c28ab7358cb5b14954e5fb56409f,"This paper proposes a method to remove pixel-wise and channel-wise correlations in convolutional neural networks (CNNs). The proposed method is based on the deconvolution operation, which removes pixel and channel correlations before the data is fed into each layer of the network. The authors show that the proposed method can be applied to 10 modern neural network models by replacing batch normalization within each layer. Extensive experiments are conducted to demonstrate the effectiveness of the method. "
SP:e1b0de9a36bf8359df368b7a55a7f23e99d88db7,"This paper studies the problem of quantizing the weights of GANs. The authors propose a novel quantization method based on EM algorithms, named QGAN, to reduce the quantization precision of the weights in the GAN model. They also propose a multi-precision quantization approach to find the lowest number of bits for quantizing GAN models to satisfy the quality requirement for generated samples. Experiments on CIFAR-10 and CelebA show that QGAN can quantize weights to even 1-bit or 2-bit representations with results of quality comparable to original models."
SP:58c4905f59f04a50b30d27c99521126a6455d38a,"This paper studies the convergence of the Hamiltonian gradient descent (HGD) algorithm for convex-concave problems that satisfy a novel “sufficiently bilinear” condition on the second-order derivatives of the objective function. In particular, the authors show that this condition is sufficient for HGD to achieve linear convergence in convex concave settings. They also prove convergence rates for stochastic HGD and for some parameter settings of the Consensus Optimization algorithm. "
SP:d8556b52272321a1415ac2d85bb12e88b51ee73a,"This paper studies the stability of the forward/backward process of ResNet. Specifically, the authors consider the ResNet block hl = φ(hl+1) + \tau(hl-1) where $\tau = 1/\sqrt{L}$ is a sharp value in characterizing the stability, where L is the number of residual blocks. The authors show that for standard initialization used in practice, the above sharp value is $\mathcal{1/\Omega}(L)$. The authors also show that if ResNet is properly over-parameterized, the gradient descent is guaranteed to find the global minima 1, which significantly enlarges the range of $\Omega \leq 1/L$. "
SP:cf70dc496825ece2f28fdf4f1a6f4316c69e0e48,"This paper proposes a method to train sparse neural networks with a fixed parameter count and a fixed computational cost throughout training, without sacrificing accuracy relative to existing dense-to-sparse training methods. The method updates the topology of the network during training by using parameter magnitudes and infrequent gradient calculations. This approach requires fewer floating-point operations (FLOPs) to achieve a given level of accuracy compared to prior techniques."
SP:d2d2b892518d54d0e63e26a056f2298be3be2610,"This paper proposes a method to control the generated images by searching directions in the latent space of a generative model along which we can move to control specific properties of the generated image like the position or scale of the object in the image. The method does not require human annotations and is particularly well suited for the search of directions encoding simple transformations such as translation, zoom or color variations. Experiments on GANs and variational auto-encoders demonstrate the effectiveness of the method."
SP:1c63389e972d4652fac831e9d11609cd3c3c371a,"This paper proposes a physics-as-inverse-graphics-based model for learning the dynamics of a physical system from video. The key idea is to use a differentiable physics engine to learn the parameters of the system, which can be used for long term video prediction and model-predictive control. The proposed method is evaluated on a variety of video datasets. The results show that the proposed method outperforms the baselines in terms of video prediction accuracy and model predictive control."
SP:c6b8b682bf3087a65cb2379700b8a0183853c2af,"This paper proposes a method for learning a classifier from noisy labels when a few clean labeled examples are given. The structure of clean and noisy data is modeled by a graph per class and Graph Convolutional Networks (GCN) are used to predict class relevance of noisy examples. For each class, the GCN is treated as a binary classifier learning to discriminate clean from noisy examples using a weighted binary cross-entropy loss function, and then a GCN-inferred “clean” probability is exploited as a relevance measure. Experimental results show that the proposed method outperforms the transductive approach (Douze et al., 2018) that is using the same additional data without labels."
SP:dd9c9a5dccbba5dd15b03ca6b314a9e153e95548,"This paper studies the problem of graph neural networks with edge features. The authors propose a new objective function called Edge Information Maximized Graph Neural Network (EIGNN) that maximizes the mutual information (MI) between edge features and message passing channels. The MI is reformulated as a differentiable objective via a variational approach. Theoretically, the authors show that the newly introduced objective enables the model to preserve edge information, and empirically corroborate the enhanced performance of MI-maximized models across a broad range of learning tasks including regression on molecular graphs and relation prediction in knowledge graphs."
SP:f1cf63d728da51b4f83eb50ef69e3788b3a5ed74,This paper proposes a method for verifying the properties of generative models. The method is based on a non-convex relaxation of the latent space of a generative model. The authors show that their method is faster and more precise than previous methods for the same networks. They also show that the method is deterministic and probabilistic. 
SP:2b0887dcf09249e8cee30d38163aeb9ef1e92b27,"This paper studies the problem of ""suspended animation"" in graph neural networks (GNNs). In particular, this paper identifies the problem when the model depth reaches the ""suspended animation limit"" and the model will not respond to the training data any more and become not learnable. To solve this problem, the authors introduce the GRESNET (Graph Residual Network) framework, which creates extensively connected highways to involve nodes’ raw features or intermediate representations throughout the graph for all the model layers. The authors prove the effectiveness of the introduced new graph residual terms from the norm preservation perspective, which will help avoid dramatic changes to the node’s representations between sequential layers. Detailed studies about the proposed framework for many existing GNNs, including GCN, GAT and LOOPYNET, will be reported in the paper with extensive empirical experiments."
SP:dc436ade4d04072de35a90e5e4a1bfebfddb04e9,"This paper proposes a semi-supervised method for face reconstruction from unlabelled and labeled face images. The proposed method is based on a convolutional neural network (CNN) to reconstruct the face shape, albedo, pose, lighting, and expression from a single image. A novel center loss is introduced to make sure that different facial images from the same person have the same identity shape. Besides, the proposed model disentangles identity, expression, pose and lighting representations, which improves the overall reconstruction performance and facilitates facial editing applications, e.g., expression transfer."
SP:f7bc06697b09e2d59ec06b2cbcf3c0828ece32ae,"This paper proposes a method for solving imitation learning problems when only partial knowledge about the transition kernel is available. Specifically, the authors propose to replace the unknown transition kernel with a synthetic kernel that simulates the transition of state components for which the transition model is known, and extract from demonstrations the state components of which the kernel is unknown. The next state is then stitched from the two components: s = {sr, su}. The authors describe in detail the recipe for building an eMDP and analyze the errors caused by its synthetic kernel. The experiments include imitation tasks in multiplayer games, where the agent has to imitate one expert in the presence of other experts for whom we cannot provide a transition model."
SP:82cce92821e8168ab4a6fd67573b66c1d17673b8,"This paper proposes a self-supervised reinforcement learning approach for learning to control states of interest without any external reward function. The authors formulate the intrinsic objective as rewarding the skills that maximize the mutual information between the context states and the states of the state of interest. They evaluate their approach for different simulated robotic manipulation tasks from OpenAI Gym and a navigation task in the Gazebo simulator. They show that their method is able to learn to manipulate the object, such as pushing and picking up, purely based on the intrinsic mutual information rewards."
SP:5db63d39cfd8132bec832ab64b8fbd403b3b8df0,"This paper proposes a novel trojan-based attack method for neural network (NN) trojaning attacks. The attack is programmable that the malicious misclassification target is not fixed and can be generated on demand even after the victim’s deployment. The authors demonstrate the attack method under the scenario described in the retraining tutorial from Tensorflow and MXNet, which uses pre-trained ImageNet models and replaces the FC layers for the Flower dataset and Caltech-256 dataset. "
SP:35ea626ee4dd1a7a368a660eb852192924966b7f,This paper proposes a novel few-shot regression algorithm for drug discovery. The proposed algorithm is based on deep kernel learning and a differentiable kernel algorithm. The algorithm learns to find the appropriate kernel for each task during inference. It outperforms the state-of-the-art algorithms on both toy and real-world drug discovery tasks. 
SP:91ca4c3ee07617356250bae9f4ef9799b3b134ff,"This paper proposes a framework to characterize which reasoning tasks a neural network can learn well, by studying how well its computation structure aligns with the algorithmic structure of the relevant reasoning process. The authors formally define this algorithmic alignment and derive a sample complexity bound that decreases with better alignment. This framework offers an explanation for the empirical success of popular reasoning models, and suggests their limitations. "
SP:a52aee8da5cf5acd2baf3c2a62cb679e13b18bd5,"This paper proposes a new metric called Fréchet Joint Distance (FJD) to evaluate conditional generative adversarial networks (cGANs). FJD measures the distance between joint distributions of images and conditioning. The authors claim that FJD is able to capture the desirable properties of image quality, conditional consistency, and intra-conditioning diversity. Experiments on a controllable synthetic dataset demonstrate the effectiveness of FJD. "
SP:fa822e8472efae17c7dfde8258057898383ecbbb,"This paper proposes a method to identify decision states, i.e., the parsimonious set of states where decisions meanfully affect the future states an agent can reach in an environment. The method is based on the VIC framework (Gregor et al., 2016), which maximizes an agent’s ‘empowerment’. The authors formulate a sandwich bound on the empowerment objective that allows identification of decision states. The decision states are discovered without extrinsic rewards – simply by interacting with the world. The experiments show that the proposed method yields decision states that align with human intuition across environments."
SP:a19a51df7e28a5d3380be4fba13842efbfe3efec,"This paper proposes a method to classify irregularly sampled time series with unaligned measurements, focusing on high scalability and data efficiency. The proposed method SEFT (Set Functions for Time Series) is based on recent advances in differentiable set function learning, extremely parallelizable, and scales well to very large datasets and online monitoring scenarios. The authors extensively compare their method to competitors on multiple healthcare time series datasets and show that it performs competitively while significantly reducing runtime."
SP:4ae89d64460b08749acc192004545c1fa8b7553b,"This paper proposes a new convolutional operation called Harmonic convolution (Harmonic Convolution) to model audio signal priors by explicitly utilizing the harmonic structure. This is done by engineering the kernels to be supported by sets of harmonic series, instead of by local neighborhoods. The experiments show that networks using the proposed method can reliably model audio priors and achieve high performance on unsupervised audio restoration tasks. "
SP:c81a2b3fd1c56b9b18e4a358e3ff8b40aea5256a,"This paper proposes a data echoing technique to reduce the total computation used by earlier pipeline stages and speed up training when computation upstream from accelerators dominates the training time. Data echoing reuses (or “echoes”) intermediate outputs from earlier pipeline stage in order to reclaim idle capacity. The authors investigate the behavior of different data echoing algorithms on various workloads, for various amounts of echoing, and for various batch sizes. In all settings, at least one data echoing algorithm can match the baseline’s predictive performance using less upstream computation."
SP:b4cf56d3fa7d65cacde33f17cd04bd5bbc52dd71,"This paper proposes a novel algorithm, Variational Intrinsic Successor FeatuRes (VISR), which learns controllable features that can be leveraged to provide enhanced generalization and fast task inference through the successor features framework. The main contribution of this paper is to combine the ideas of behavioral mutual information (BMI) and successor features (SF) to improve the performance of unsupervised few-step RL agents. The proposed method is evaluated on the full Atari suite and achieves human-level performance."
SP:83500230586a9134f910ad067b7233dc563dc1ba,"This paper analyzes the generalization properties of deep neural networks in the overparameterized regime. The authors show that generalization is due to three factors: (1) flat initialization, (2) curvature-based parametrization of the approximating function (breakpoints and deltaslopes), and (3) the role of gradient descent (GD) in preserving (i) and regularizing (ii). In particular, the global, rather than local, impact of breakpoints and delta-slopes helps regularize the approximations in the large gaps between training data."
SP:7225825e353b711a7d023f706fafe5e17e4e2fb2,This paper proposes a GAN-based method for image-to-image translation. The proposed method is based on the attention mechanism of the discriminator. The discriminator is equipped with an attention mechanism to estimate the probability that the input image is real and to create an attention map that highlights the critical features for prediction. This attention map is then used to guide the generator to produce more plausible and realistic images. The method is evaluated on a number of image transfer tasks.
SP:41c089ba65393174dae1dc136f79030a0a4fc532,"This paper studies the role of multiplicative interaction layers as primitive operations in neural networks. The authors show that such layers strictly enrich the representable function classes of neural networks and conjecture that multiplicative interactions offer a powerful inductive bias when fusing multiple streams of information or when conditional computation is required. They argue that they should be considered in many situation where multiple compute or information paths need to be combined, in place of the simple and oft-used concatenation operation. Finally, they back up their claims and demonstrate the potential of such layers by applying them in large-scale complex RL and sequence modeling tasks."
SP:5144391584e6d3825e12684b7c053e4e282cff2b,"This paper proposes a new algorithm for active learning with deep neural network models. The algorithm, Batch Active Learning by Diverse Gradient Embeddings (BADGE), samples groups of points that are disparate and high magnitude when represented in a hallucinated gradient space, a strategy designed to incorporate both predictive uncertainty and sample diversity into every selected batch. The experiments show that BADGE is robust to architecture choice, batch size, and dataset, generally performing as well as or better than the best baseline across different environmental conditions."
SP:ce6023b1e6bf45b071a6f5457b2575425ae03366,This paper proposes a novel feature-leveling method for self-explaining deep neural networks. The proposed method is based on a General Linear Model (GLM) layer that separates low level features from high level features on a per-layer basis to better utilize the GLM layer in the proposed architecture for interpretation. Experimental results show that the modified models are able to achieve competitive results comparing to main-stream architectures on standard datasets. 
SP:b70ceead1bf6c7dc684c74501716e7012b891022,"This paper proposes a method for training a classifier over a large number of classes, known as extreme classification. The method is based on a scalable approximation to the softmax loss function via a generalized form of negative sampling. By generating adversarial negative samples from an auxiliary model, the authors prove that we maximize the signal-to-noise ratio of the stochastic gradient estimate. The authors also show that, while the auxiliary model introduces a bias, we can remove the bias at test time."
SP:29b52fee83309268d9864f3b1fc3617948577d41,"This paper proposes a method for efficient exploration that leverages a low-dimensional encoding of the environment learned with a combination of model-based and model-free objectives. The proposed method uses intrinsic rewards that are based on a weighted distance of nearest neighbors in the low dimensional representational space to gauge novelty and leverage these intrinsic rewards for sample-efficient exploration with planning routines. One key element of the approach is that we perform more gradient steps in-between every environment step in order to ensure the model accuracy is high (and hence ensure an accurate novelty heuristic). Through this training scheme, the agent is also able to learn a meaningful representation of its state space in an extremely sample efficient manner."
SP:257c98dc1a9f3efcbf9544d9ee2ff524b000543d,"This paper studies the problem of few-shot classification and out-of-distribution (OOD) detection. The authors propose two new methods for OOD detection, LCBO and -MinDist, which are based on confidence scores. They show that existing confidence scores developed in the supervised setting (i.e., setting with a fixed number of classes) are not suitable when used with popular few shot classifiers. The proposed confidence scores substantially outperform the baselines on both OOD and OOD tasks."
SP:a3632b773143dfb3a8f104c6b658dfa1167d155b,"This paper proposes a generalized model of sequence generation that unifies decoding in directed and undirected neural sequence models. The proposed framework models the process of generation rather than the resulting sequence, and under this framework, the authors derive various neural sequence model as special cases, such as autoregressive, semi-autoregressive and refinement-based non-autorgressive models. This unification enables them to adapt decoding algorithms originally developed for directed sequence models to generate sequences directly from such models. They demonstrate this by evaluating various decoding strategies for a cross-lingual masked translation model (Lample and Conneau, 2019)."
SP:eca5e2be9831dfb79c4f5e633cbfadcfd2e00eb1,"This paper proposes a two-stage approach for the recognition of mathematical expressions (MEs). In the first stage, this method locates and recognizes the math symbols of input image by object detection algorithm. In the second stage, it translates math symbols with position information into LaTeX sequences by seq2seq model equipped with attention mechanism. The experimental results show that the proposed method significantly outperforms the end-to-end method."
SP:923fee8623da1569a7f54a57b4b326f29440b4c0,This paper proposes a vector quantization method to reduce the memory footprint of convolutional network architectures. The method is based on minimizing the loss reconstruction error for in-domain inputs. The authors validate their approach by quantizing a high performing ResNet-50 model to a memory size of 5 MB (20x compression factor) while preserving a top-1 accuracy of 76.1% on ImageNet object classification and by compressing a Mask R-CNN with a 26x factor.
SP:74850ad70241948f93fed95ba1f0ac11360437c1,"This paper proposes a transformer-based attention mechanism, called TP-Attention, which explicitly encodes the relations between each Transformer cell and the other cells from which values have been retrieved by attention. The TP-Transformer is based on Tensor-Product Representations (TP-PR) to better support the explicit representation of relation structure. The proposed method is evaluated on the Mathematics Dataset containing 56 categories of free-form math wordproblems. "
SP:d319df820c6630c409fab32097652a083e8f53ea,"This paper studies the problem of generalization in deep neural networks. The authors propose an optimization problem to learn a more general classification function by concatenating encodings of the input features and then train the classifier on the extended features. They derive a necessary and sufficient condition for generalization using a universal cognitive similarity metric, namely information distance, based on Kolmogorov complexity. Experiments demonstrate that a model trained on arbitrarily encoded input features is more robust to common corruptions and adversarial perturbations."
SP:b8e86f5e89330d81ba4967a7ed2dbfb56375d8a0,"This paper proposes a new graph pooling operation based on compressive Haar transforms, called HaarPooling. The algorithm is computed by following a chain of sequential clusterings of the input graph. The input of each pooling layer is transformed by the compressed Haar basis of the corresponding clustering. Experiments are conducted to demonstrate the effectiveness of the proposed method."
SP:17bea301d6718ef5f28864dd2445552b3cf65eeb,"This paper proposes a sample-based point-cloud decoder that maps a shape representation to a point feature distribution, allowing an arbitrary number of sampled features to be transformed into individual output points. The proposed method builds on PointNet’s principles to present the ‘NoiseLearn’ algorithm– a novel, simple, and effective point cloud decoding approach. The authors show that these sampling approaches are competitive with or outperform the MLP approach while using fewer parameters and providing better functionality."
SP:51d826ead5d1d9cb89d493ce4c39728651bbc57b,"This paper studies the effect of real-world noise on the performance of deep neural networks (DNNs) trained on noisy data. The authors propose a benchmark of real world noisy labels at 10 different noise levels. They show that DNNs generalize much better on real world noise. They also show that when networks are fine-tuned, ImageNet architectures generalize well on noise. Finally, they show that robust learning methods that work well on synthetic noise may not work as well on real noise."
SP:9873f78fb2821afdbb5551700e6ab6a0e8bcb9f0,"This paper proposes a new method for learning from rule-based supervision. The proposed method is based on denoising over-generalized rules via latent coverage variables, and training a classification model with a soft implication loss that jointly denoises the rules and labels. The method is evaluated on five different tasks. "
SP:6f2c656dbb7629f652a4291d6971625184d8118b,This paper proposes an efficient memory layer for GNNs that can jointly learn node representations and coarsen the graph. The authors also introduce two new networks based on this layer: memory-based GNN (MemGNN) and graph memory network (GMN) that can learn hierarchical graph representations. The experimental results show that the proposed models achieve state-of-the-art results in eight out of nine graph classification and regression benchmarks. 
SP:81bc52d734c86975d741b6482d65ca71a9d81620,"This paper analyzes the effect of initialization in deep linear networks on the convergence time of gradient descent. The authors prove that orthogonal initialization is superior to Gaussian initialization in terms of convergence time. They show that for deep networks, the width needed for efficient convergence to a global minimum is independent of the depth. The paper also shows how the benefits of a good initialization can persist throughout learning. "
SP:9f5d95fc89c2f0d59d04838aa180f3db67997dfa,This paper studies the problem of how to optimize the bit allocation of weights and activations for deep CNNs compression. The authors propose a Lagrangian-based method to solve the optimization problem. The method obtains excellent results on deep neural networks. It can compress deep CNN ResNet-50 down to 2 bits with only 0.7% accuracy loss. 
SP:7191d7b217a12b1bf9c47d790896a8227c14cc3d,"This paper proposes a new generative model called iWGAN, which is a combination of WGAN and variational auto-encoder (VAE). The authors provide a generalization error bound and a probabilistic interpretation of the proposed method. They also provide an iterative primal-dual optimization algorithm to solve the optimization problem. The proposed method is evaluated on both synthetic and real-world datasets. "
SP:cca6ae14fd0dd12352855e594acf7f3263bb1f24,"This paper extends the mention pair model of anaphoric annotation by Paun et al. (2018b) by using a nonparametric partially pooled structure (based on a stick-breaking process) to alleviate the effects of sparsity inherent in some crowdsourcing environments. Specifically, the authors use a Dirichlet process mixture based on the stick breaking process to approximate the hierarchical community profiles. The authors show, using a recently published large-scale crowdsourced anaphora dataset, that the proposed model performs better than its unpooled counterpart in conditions of data sparsity, and on par when enough observations are available."
SP:4295cae4a56a02eb21c486408c1bf37a7483cb49,"This paper proposes a hierarchical exploration method for reinforcement learning with intrinsic and extrinsic rewards. The intrinsic reward is modeled as a successor feature control (SFC) reward, which is general and not task-specific. This paper also introduces a new type of intrinsic reward SFC, which takes into account statistics over complete trajectories and thus differs from previous methods that only use local information to evaluate intrinsic motivation. The proposed method is evaluated on VizDoom, DeepMind Lab, and DeepMind Control Suite."
SP:9fa22eb03a79bce0fc1c8e84ae8640e010701eca,"This paper proposes a method for weakly supervised video moment retrieval, where the goal is to locate the video segment which is described by the sentence without having access to temporal annotations during training. The proposed method is comprised of a Frame-By-Word interaction module as well as a Word-Conditioned Visual Graph (WCVG). The authors also incorporate a novel application of positional encodings, commonly used in Transformers, to learn visual-semantic representations that contain contextual information of their relative positions in the temporal sequence through iterative message-passing. Comprehensive experiments on the DiDeMo and Charades-STA datasets demonstrate the effectiveness of the learned representations."
SP:27ac670353f34ee7a23bb7622f80c1dfbc0985e0,This paper proposes a method for image-guided re-rendering of reconstructed objects for virtual and augmented reality applications. The main contribution of this paper is the use of an object-specific deep neural network to synthesize the view-dependent appearance of the reconstructed object. The proposed method is a hybrid between classical image-based rendering and machine learning. Experiments are conducted on both synthetic and real-world datasets.
SP:257d124367b1da9a595dc11a9df750d6bade298e, the Laplace Approximation scheme for estimating the uncertainty of deep neural networks (DNNs) is proposed. The proposed method is based on the inverse formulation of the Multivariate Normal Distribution (MND) and uses a diagonal correction of the Kronecker-factored eigenbasis. The authors also propose a low-rank approximation of the eigen-basis that exploits spectral sparsification of DNNs. 
SP:2e03ceba4004b82f86f8349352a8ee4520e9c35d,"This paper proposes a new hashing algorithm, called Amortization hashing (AHash), which is a variant of One Permutation Hashing (OPH) that aims to reduce the number of bins in each bin. The authors argue that OPH has a drawback that the load of the bins (the number of elements in a bin) could be unbalanced, which leads to the existence of empty bins and false similarity computation. To address this issue, the authors propose a load-balanced hashing algorithm that can generate as few empty bins as possible. Experiments on real datasets validate the effectiveness of the proposed method."
SP:d73827ab98b0ff6bd92abfefea43a5f88ea40de2,This paper proposes a method for extracting features from periodic data by adding a graph structure to each data point and constructing a suitable machine learning architecture for graph data with cyclic permutation. The proposed method is based on a graph neural network. The paper shows that adding a certain structure to data is shown to be very effective for feature extraction. Simulation and experimental results illustrate its effectiveness.
SP:0df5ad333eb4ff9cca7f2d117909e2ce533a65d8," text generation systems have achieved significant progress in recent years, showing the ability to produce highly fluent text. However, the inherent lack of controllability in these systems allows them to hallucinate factually incorrect phrases that are unfaithful to the source, making them often unsuitable for many real world systems that require high degrees of precision. In this work, the authors propose a novel confidence oriented decoder that assigns a confidence score to each target position. This score is learned in training using a variational Bayes objective, and can be leveraged at inference time using a calibration technique to promote more faithful generation. Experiments on a structured data-to-text dataset – WikiBio (Lebret et al., 2016) show that the proposed method is more faithful than existing state-of-the-art approaches."
SP:03307deac29173b2968fbd08f95fc77eb1f82410,"This paper proposes a new pruning method called lookahead pruning (LAP) based on the observation that magnitude-based pruning indeed minimizes the Frobenius distortion of a linear operator corresponding to a single layer. Based on this observation, LAP extends the single layer optimization to a multi-layer optimization. The experimental results demonstrate that the proposed method consistently outperforms magnitude based pruning on VGG and ResNet architectures."
SP:dc80fdc75bc14ae19fe4ba9b85c35ce00b12856f,"This paper proposes Moniqua, a decentralized stochastic gradient descent algorithm that uses quantized communication to improve the convergence of decentralized SGD. The authors prove in theory that moniqua communicates a provably bounded number of bits per iteration, while converging at the same asymptotic rate as the original algorithm does with full-precision communication. They demonstrate empirically that the proposed algorithm converges faster with respect to wall clock time than other quantized decentralized algorithms. "
SP:86c61a658d07ab86e2d84cef7e480bf7a06e4ddb,"This paper studies the problem of partial models in reinforcement learning. The authors show that partial models can be causally incorrect if they are confounded by the observations they don’t model, and therefore lead to incorrect planning. To address this, the authors introduce a general family of partial model that are provably causally correct, yet remain fast because they do not need to fully model future observations. They also propose a simple, yet effective, modification to partial models so that they can still make correct predictions under changes in the behavior policy."
SP:c70479b2096a52584b242de58272ca8d8565feea,"This paper proposes a new VAE model that learns a succinct common representation of two correlated data variables for conditional and joint generation tasks. The proposed model is based on two information theoretic problems: distributed simulation and channel synthesis, in which the common information arises as the fundamental limit of the succinctness of the common representation. The paper decomposes the data variables into their common representation (e.g., a shared concept) and local representations that capture the remaining randomness. The utility of the proposed approach is demonstrated through experiments for joint and conditional generation with and without style control using synthetic data and real images. "
