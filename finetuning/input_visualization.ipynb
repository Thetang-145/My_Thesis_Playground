{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad73e7fc-37db-4fe8-833b-33428b7d8ca5",
   "metadata": {},
   "source": [
    "# Import data importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94e715e4-52ab-45d6-ba91-b98c3ce5678a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from common.data_importer import prepro_KGData, prepro_textData\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36e4c260-1436-478c-a4f7-b001e4affce2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_progress(curr, full, desc='', bar_size=30):    \n",
    "    bar = int((curr+1)/full*bar_size)\n",
    "    sys.stdout.write(f\"\\r{desc}[{'='*bar}{' '*(bar_size-bar)}] {curr+1}/{full}\")\n",
    "    sys.stdout.flush()\n",
    "    if curr+1==full: print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f5cc1f8-4087-4cf0-be74-3e90361d5f39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "        \n",
    "args = Namespace(\n",
    "    model='bart-large',\n",
    "    dataset='MuP',\n",
    "    # section=['abstract', 'conclusion'],\n",
    "    # section=['abstract', 'introduction-1', 'conclusion'],\n",
    "    section=['abstract', 'introduction-1'],\n",
    "    # section=['introduction-1'],\n",
    "    inputType='text',\n",
    "    bs=8, \n",
    "    max_input=512,\n",
    "    max_output=512,\n",
    "    num_epoch=5,\n",
    "    num_beams=4,\n",
    "    lr=1e-5,\n",
    "    fp=32,\n",
    "    opt=\"adam\",\n",
    "    prototype=None\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8619a56-f45d-4cc0-a120-06d06c614e52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading section input (train)[==============================] 8379/8379\n",
      "Loading summary (train)[==============================] 18934/18934\n"
     ]
    }
   ],
   "source": [
    "train_df, spacial_token = prepro_textData(args, \"train\", section=args.section, skip_null=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c89ae48-4b6c-4ea1-a74a-eaaf977a19d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading section input (val)[==============================] 1060/1060\n",
      "Loading summary (val)[==============================] 3604/3604\n"
     ]
    }
   ],
   "source": [
    "val_df, spacial_token = prepro_textData(args, \"val\", section=args.section, skip_null=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e135e141-bb67-4ec5-8452-b0ab3db97b0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We study the average CVloo stability of kernel ridge-less regression and derive corresponding risk bounds. We show that the interpolating solution with minimum norm minimizes a bound on CVloo stability, which in turn is controlled by the condition number of the empirical kernel matrix. The latter can be characterized in the asymptotic regime where both the dimension and cardinality of the data go to infinity. Under the assumption of random kernel matrices, the corresponding test error should be expected to follow a double descent curve. [SEP] Organization: In section 2, we introduce basic ideas in statistical learning and empirical risk minimization, as well as the notation used in the rest of the paper. In section 3, we briefly recall some definitions of stability. In section 4, we study the stability of interpolating solutions to kernel least squares and show that the minimum norm solutions minimize an upper bound on the stability. In section 5 we discuss our results in the context of recent work on high dimensional regression. We conclude in section 6.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['input_seq'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "276fef75-c41f-4c6d-99ad-9dfa28aeafe2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>input_seq</th>\n",
       "      <th>target_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>We study the average CVloo stability of kernel...</td>\n",
       "      <td>This paper investigates kernel ridge-less regr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:b80bc890180934092cde037b49d94d6e4e06fad9</td>\n",
       "      <td>The use of episodic memories in continual lear...</td>\n",
       "      <td>This paper presents a novel way of making full...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939</td>\n",
       "      <td>Existing Multi-Task Learning(MTL) strategies l...</td>\n",
       "      <td>This paper proposes a new framework that compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP:a1e2218e6943bf138aeb359e23628676b396ed66</td>\n",
       "      <td>This paper deals with the fuel optimization pr...</td>\n",
       "      <td>This work proposes a deep reinforcement learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66</td>\n",
       "      <td>Our work is concerned with the generation and ...</td>\n",
       "      <td>This paper proposes 3 deep generative models b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18929</th>\n",
       "      <td>SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695</td>\n",
       "      <td>Discovering the underlying mathematical expres...</td>\n",
       "      <td>This paper presents a RNN-RL based method for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18930</th>\n",
       "      <td>SP:4706017e6f8b958c7d0825fed98b285ea2994b59</td>\n",
       "      <td>Some conventional transforms such as Discrete ...</td>\n",
       "      <td>This paper proposes a new pointwise convolutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18931</th>\n",
       "      <td>SP:4706017e6f8b958c7d0825fed98b285ea2994b59</td>\n",
       "      <td>Some conventional transforms such as Discrete ...</td>\n",
       "      <td>This paper presents a new pointwise convolutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18932</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>Thanks to graph neural networks (GNNs), semi-s...</td>\n",
       "      <td>This paper proposes to model various uncertain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18933</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>Thanks to graph neural networks (GNNs), semi-s...</td>\n",
       "      <td>The authors proposed a Bayesian graph neural n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18931 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          paper_id   \n",
       "0      SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc  \\\n",
       "1      SP:b80bc890180934092cde037b49d94d6e4e06fad9   \n",
       "2      SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939   \n",
       "3      SP:a1e2218e6943bf138aeb359e23628676b396ed66   \n",
       "4      SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66   \n",
       "...                                            ...   \n",
       "18929  SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695   \n",
       "18930  SP:4706017e6f8b958c7d0825fed98b285ea2994b59   \n",
       "18931  SP:4706017e6f8b958c7d0825fed98b285ea2994b59   \n",
       "18932  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb   \n",
       "18933  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb   \n",
       "\n",
       "                                               input_seq   \n",
       "0      We study the average CVloo stability of kernel...  \\\n",
       "1      The use of episodic memories in continual lear...   \n",
       "2      Existing Multi-Task Learning(MTL) strategies l...   \n",
       "3      This paper deals with the fuel optimization pr...   \n",
       "4      Our work is concerned with the generation and ...   \n",
       "...                                                  ...   \n",
       "18929  Discovering the underlying mathematical expres...   \n",
       "18930  Some conventional transforms such as Discrete ...   \n",
       "18931  Some conventional transforms such as Discrete ...   \n",
       "18932  Thanks to graph neural networks (GNNs), semi-s...   \n",
       "18933  Thanks to graph neural networks (GNNs), semi-s...   \n",
       "\n",
       "                                              target_seq  \n",
       "0      This paper investigates kernel ridge-less regr...  \n",
       "1      This paper presents a novel way of making full...  \n",
       "2      This paper proposes a new framework that compu...  \n",
       "3      This work proposes a deep reinforcement learni...  \n",
       "4      This paper proposes 3 deep generative models b...  \n",
       "...                                                  ...  \n",
       "18929  This paper presents a RNN-RL based method for ...  \n",
       "18930  This paper proposes a new pointwise convolutio...  \n",
       "18931  This paper presents a new pointwise convolutio...  \n",
       "18932  This paper proposes to model various uncertain...  \n",
       "18933  The authors proposed a Bayesian graph neural n...  \n",
       "\n",
       "[18931 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac462cfd-7485-4806-8b1f-1ddfe681e1a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#comment this if you are not using puffer?\n",
    "os.environ['http_proxy'] = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d56f9c-c7ce-48df-bcd1-4035c0a0c412",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nopphawann/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "71d56790-36bd-440e-851f-00a783e681fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def get_token(sentence, get_len=True):\n",
    "    tokens = tokenizer.encode(\n",
    "        sentence, \n",
    "        padding='max_length', \n",
    "        # max_length=args.max_input, \n",
    "        truncation=True, \n",
    "        return_attention_mask=True,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    if get_len: return tokens.shape[1]\n",
    "    else: return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "47b3b45d-aaac-482a-a2c1-7f84726e5590",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cal_perc_tokens(df, col, perc=.95):\n",
    "    tokens_df = pd.DataFrame(df[col].apply(get_token))\n",
    "    return tokens_df.quantile(perc).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "efbdc518-653b-4f9f-8423-104e252a6ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "586.0"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_perc_tokens(val_df, \"input_seq\", perc=.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6e5b655-6e96-44e0-bb80-ed47e441237c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df[\"input_tokens\"] = train_df[\"input_seq\"].apply(get_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c7c0d3b-b9c9-4b6c-87f9-f7fce23d9302",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "input_tokens = pd.DataFrame(train_df[\"input_seq\"].apply(get_token))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3e3db11a-8bbf-49af-8116-3e1449a18088",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1035.5\n",
      "1014.0\n"
     ]
    }
   ],
   "source": [
    "train_tokens = cal_perc_tokens(train_df, \"input_seq\", perc=.95)\n",
    "val_tokens = cal_perc_tokens(val_df, \"input_seq\", perc=.95)\n",
    "print(train_tokens)\n",
    "print(val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0bb3ab42-d599-4f90-89a7-837dbb28c0ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_input = min(int(max(\n",
    "    cal_perc_tokens(train_df, \"input_seq\", perc=.95),\n",
    "    cal_perc_tokens(val_df, \"input_seq\", perc=.95)\n",
    ")), 1024)\n",
    "max_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9dbd755a-0246-48a4-873f-e735251dca36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=4 if max_input>950 else 8\n",
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d65cba0b-824f-4bbf-b0f4-ce4eec9b101e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>input_seq</th>\n",
       "      <th>target_seq</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>target_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>We study the average CVloo stability of kernel...</td>\n",
       "      <td>This paper investigates kernel ridge-less regr...</td>\n",
       "      <td>207.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:b80bc890180934092cde037b49d94d6e4e06fad9</td>\n",
       "      <td>The use of episodic memories in continual lear...</td>\n",
       "      <td>This paper presents a novel way of making full...</td>\n",
       "      <td>367.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939</td>\n",
       "      <td>Existing Multi-Task Learning(MTL) strategies l...</td>\n",
       "      <td>This paper proposes a new framework that compu...</td>\n",
       "      <td>358.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP:a1e2218e6943bf138aeb359e23628676b396ed66</td>\n",
       "      <td>This paper deals with the fuel optimization pr...</td>\n",
       "      <td>This work proposes a deep reinforcement learni...</td>\n",
       "      <td>372.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66</td>\n",
       "      <td>Our work is concerned with the generation and ...</td>\n",
       "      <td>This paper proposes 3 deep generative models b...</td>\n",
       "      <td>342.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>SP:18aaba3423e81e9437b509d1a5e24836ef5635f6</td>\n",
       "      <td>We undertake the problem of representation lea...</td>\n",
       "      <td>This paper defines a set of learnable basis fu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>SP:18aaba3423e81e9437b509d1a5e24836ef5635f6</td>\n",
       "      <td>We undertake the problem of representation lea...</td>\n",
       "      <td>A typical Wavelet Transform is built through t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3601</th>\n",
       "      <td>SP:3058e6bc5e8c62af325c214c9e1436d6cdf09204</td>\n",
       "      <td>Interest has been rising lately towards method...</td>\n",
       "      <td>This paper builds a new graph convolutional ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3602</th>\n",
       "      <td>SP:3058e6bc5e8c62af325c214c9e1436d6cdf09204</td>\n",
       "      <td>Interest has been rising lately towards method...</td>\n",
       "      <td>The authors propose using non-Euclidean spaces...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3603</th>\n",
       "      <td>SP:3058e6bc5e8c62af325c214c9e1436d6cdf09204</td>\n",
       "      <td>Interest has been rising lately towards method...</td>\n",
       "      <td>In this paper, the authors address representat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22535 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         paper_id  \\\n",
       "0     SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc   \n",
       "1     SP:b80bc890180934092cde037b49d94d6e4e06fad9   \n",
       "2     SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939   \n",
       "3     SP:a1e2218e6943bf138aeb359e23628676b396ed66   \n",
       "4     SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66   \n",
       "...                                           ...   \n",
       "3599  SP:18aaba3423e81e9437b509d1a5e24836ef5635f6   \n",
       "3600  SP:18aaba3423e81e9437b509d1a5e24836ef5635f6   \n",
       "3601  SP:3058e6bc5e8c62af325c214c9e1436d6cdf09204   \n",
       "3602  SP:3058e6bc5e8c62af325c214c9e1436d6cdf09204   \n",
       "3603  SP:3058e6bc5e8c62af325c214c9e1436d6cdf09204   \n",
       "\n",
       "                                              input_seq  \\\n",
       "0     We study the average CVloo stability of kernel...   \n",
       "1     The use of episodic memories in continual lear...   \n",
       "2     Existing Multi-Task Learning(MTL) strategies l...   \n",
       "3     This paper deals with the fuel optimization pr...   \n",
       "4     Our work is concerned with the generation and ...   \n",
       "...                                                 ...   \n",
       "3599  We undertake the problem of representation lea...   \n",
       "3600  We undertake the problem of representation lea...   \n",
       "3601  Interest has been rising lately towards method...   \n",
       "3602  Interest has been rising lately towards method...   \n",
       "3603  Interest has been rising lately towards method...   \n",
       "\n",
       "                                             target_seq  input_tokens  \\\n",
       "0     This paper investigates kernel ridge-less regr...         207.0   \n",
       "1     This paper presents a novel way of making full...         367.0   \n",
       "2     This paper proposes a new framework that compu...         358.0   \n",
       "3     This work proposes a deep reinforcement learni...         372.0   \n",
       "4     This paper proposes 3 deep generative models b...         342.0   \n",
       "...                                                 ...           ...   \n",
       "3599  This paper defines a set of learnable basis fu...           NaN   \n",
       "3600  A typical Wavelet Transform is built through t...           NaN   \n",
       "3601  This paper builds a new graph convolutional ne...           NaN   \n",
       "3602  The authors propose using non-Euclidean spaces...           NaN   \n",
       "3603  In this paper, the authors address representat...           NaN   \n",
       "\n",
       "      target_tokens  \n",
       "0              75.0  \n",
       "1              91.0  \n",
       "2              99.0  \n",
       "3              82.0  \n",
       "4             105.0  \n",
       "...             ...  \n",
       "3599            NaN  \n",
       "3600            NaN  \n",
       "3601            NaN  \n",
       "3602            NaN  \n",
       "3603            NaN  \n",
       "\n",
       "[22535 rows x 5 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([train_df, val_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa63562a-095d-4d72-ba8d-eecf7e67b94e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "580.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokens.quantile(.95).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6a1341c-6eec-49d3-9d52-7fae5cfdf5a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df[\"target_tokens\"] = train_df[\"target_seq\"].apply(get_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9bb402b1-f047-428f-b0fb-badd9c4ed738",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>input_seq</th>\n",
       "      <th>target_seq</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>target_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>We study the average CVloo stability of kernel...</td>\n",
       "      <td>This paper investigates kernel ridge-less regr...</td>\n",
       "      <td>207</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:b80bc890180934092cde037b49d94d6e4e06fad9</td>\n",
       "      <td>The use of episodic memories in continual lear...</td>\n",
       "      <td>This paper presents a novel way of making full...</td>\n",
       "      <td>367</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939</td>\n",
       "      <td>Existing Multi-Task Learning(MTL) strategies l...</td>\n",
       "      <td>This paper proposes a new framework that compu...</td>\n",
       "      <td>358</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP:a1e2218e6943bf138aeb359e23628676b396ed66</td>\n",
       "      <td>This paper deals with the fuel optimization pr...</td>\n",
       "      <td>This work proposes a deep reinforcement learni...</td>\n",
       "      <td>372</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66</td>\n",
       "      <td>Our work is concerned with the generation and ...</td>\n",
       "      <td>This paper proposes 3 deep generative models b...</td>\n",
       "      <td>342</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18929</th>\n",
       "      <td>SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695</td>\n",
       "      <td>Discovering the underlying mathematical expres...</td>\n",
       "      <td>This paper presents a RNN-RL based method for ...</td>\n",
       "      <td>287</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18930</th>\n",
       "      <td>SP:4706017e6f8b958c7d0825fed98b285ea2994b59</td>\n",
       "      <td>Some conventional transforms such as Discrete ...</td>\n",
       "      <td>This paper proposes a new pointwise convolutio...</td>\n",
       "      <td>333</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18931</th>\n",
       "      <td>SP:4706017e6f8b958c7d0825fed98b285ea2994b59</td>\n",
       "      <td>Some conventional transforms such as Discrete ...</td>\n",
       "      <td>This paper presents a new pointwise convolutio...</td>\n",
       "      <td>333</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18932</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>Thanks to graph neural networks (GNNs), semi-s...</td>\n",
       "      <td>This paper proposes to model various uncertain...</td>\n",
       "      <td>492</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18933</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>Thanks to graph neural networks (GNNs), semi-s...</td>\n",
       "      <td>The authors proposed a Bayesian graph neural n...</td>\n",
       "      <td>492</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18931 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          paper_id  \\\n",
       "0      SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc   \n",
       "1      SP:b80bc890180934092cde037b49d94d6e4e06fad9   \n",
       "2      SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939   \n",
       "3      SP:a1e2218e6943bf138aeb359e23628676b396ed66   \n",
       "4      SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66   \n",
       "...                                            ...   \n",
       "18929  SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695   \n",
       "18930  SP:4706017e6f8b958c7d0825fed98b285ea2994b59   \n",
       "18931  SP:4706017e6f8b958c7d0825fed98b285ea2994b59   \n",
       "18932  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb   \n",
       "18933  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb   \n",
       "\n",
       "                                               input_seq  \\\n",
       "0      We study the average CVloo stability of kernel...   \n",
       "1      The use of episodic memories in continual lear...   \n",
       "2      Existing Multi-Task Learning(MTL) strategies l...   \n",
       "3      This paper deals with the fuel optimization pr...   \n",
       "4      Our work is concerned with the generation and ...   \n",
       "...                                                  ...   \n",
       "18929  Discovering the underlying mathematical expres...   \n",
       "18930  Some conventional transforms such as Discrete ...   \n",
       "18931  Some conventional transforms such as Discrete ...   \n",
       "18932  Thanks to graph neural networks (GNNs), semi-s...   \n",
       "18933  Thanks to graph neural networks (GNNs), semi-s...   \n",
       "\n",
       "                                              target_seq  input_tokens  \\\n",
       "0      This paper investigates kernel ridge-less regr...           207   \n",
       "1      This paper presents a novel way of making full...           367   \n",
       "2      This paper proposes a new framework that compu...           358   \n",
       "3      This work proposes a deep reinforcement learni...           372   \n",
       "4      This paper proposes 3 deep generative models b...           342   \n",
       "...                                                  ...           ...   \n",
       "18929  This paper presents a RNN-RL based method for ...           287   \n",
       "18930  This paper proposes a new pointwise convolutio...           333   \n",
       "18931  This paper presents a new pointwise convolutio...           333   \n",
       "18932  This paper proposes to model various uncertain...           492   \n",
       "18933  The authors proposed a Bayesian graph neural n...           492   \n",
       "\n",
       "       target_tokens  \n",
       "0                 75  \n",
       "1                 91  \n",
       "2                 99  \n",
       "3                 82  \n",
       "4                105  \n",
       "...              ...  \n",
       "18929            184  \n",
       "18930             95  \n",
       "18931            137  \n",
       "18932            208  \n",
       "18933             84  \n",
       "\n",
       "[18931 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c412724-fe42-4f3b-ade9-0538847572ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>target_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18931.000000</td>\n",
       "      <td>18931.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>362.881306</td>\n",
       "      <td>133.761714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>145.867839</td>\n",
       "      <td>75.274041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>275.000000</td>\n",
       "      <td>89.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>340.000000</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>425.000000</td>\n",
       "      <td>154.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9187.000000</td>\n",
       "      <td>1299.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       input_tokens  target_tokens\n",
       "count  18931.000000   18931.000000\n",
       "mean     362.881306     133.761714\n",
       "std      145.867839      75.274041\n",
       "min       60.000000      29.000000\n",
       "25%      275.000000      89.000000\n",
       "50%      340.000000     114.000000\n",
       "75%      425.000000     154.000000\n",
       "max     9187.000000    1299.000000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0403fef-4572-41c4-a7dd-4066879a4c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[580.0, 266.0]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_df.quantile(.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c4021f9-0cf8-4b55-a561-2934511b10ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.75701230785484"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "stats.percentileofscore(train_df['input_tokens'],1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3dd03df-f710-4a26-b18d-dcdc3f82b5e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 2048.0)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkEAAAGxCAYAAABlfmIpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1+UlEQVR4nO3de3wU1f3/8fdu9sJFknAxN+USkSIgyNUYKdZKSlC+rVRaoaCiIigleMEvpbQCiq0gKlopBfWHQCuI9VGh1lIsBFGUGDHlIhdTtShUSWLFJIAmu8me3x9+d5ol4ZKQZLKZ1/Px2IfJzJndz9kJu2/PnJlxGWOMAAAAHMZtdwEAAAB2IAQBAABHIgQBAABHIgQBAABHIgQBAABHIgQBAABHIgQBAABHIgQBAABH8thdQFMQCoX02WefqU2bNnK5XHaXAwAAzoAxRkePHlVKSorc7tqP6xCCJH322Wfq2LGj3WUAAIA6OHTokM4///xab0cIktSmTRtJ37yJsbGxNlcDAADORGlpqTp27Gh9j9cWIUiyDoHFxsYSggAAiDJ1ncrCxGgAAOBIhCAAAOBIhCAAAOBIhCAAAOBIhCAAAOBIhCAAAOBIhCAAAOBIhCAAAOBIhCAAAOBIhCAAAOBIhCAAAOBIhCAAAOBIhCAAAOBIhCAAAOBIHrsLQHQyxigQCFi/+3w+uVwuGysCAKB2CEGok0AgoLFLt8rt8SpUEdTqO4bI7/fbXRYAAGeMEIQ6c3u8ivH67C4DAIA6YU4QAABwJEIQAABwJEIQAABwJEIQAABwJCZGw8Jp7wAAJyEEwcJp7wAAJyEEIQKnvQMAnII5QQAAwJEIQQAAwJEIQQAAwJEIQQAAwJEIQQAAwJEIQQAAwJEIQQAAwJEIQQAAwJEIQQAAwJEIQQAAwJEIQQAAwJG4dxhOiTvLAwCaK0IQTok7ywMAmitCEE6LO8sDAJoj5gQBAABHIgQBAABHIgQBAABHIgQBAABHIgQBAABHIgQBAABHIgQBAABH4jpBOGPGGJWXl0uS9V8AAKKVrSNBlZWVmjVrllJTU9WyZUt17dpVDz74oIwxVhtjjGbPnq3k5GS1bNlSGRkZ+uCDDyKe58iRIxo3bpxiY2MVHx+vCRMm6NixY43dnWYvVBHU+GW5uuH/va2bnnlToZA5/UYAADRRtoaghx9+WEuWLNFvf/tb7d+/Xw8//LAWLFigRYsWWW0WLFigJ598UkuXLlVubq5at26tzMxMlZWVWW3GjRunvXv3auPGjXrllVf0xhtvaNKkSXZ0qdkLXz3aHeO1uxQAAM6KrYfDtm3bpmuvvVYjRoyQJHXp0kXPP/+83nnnHUnfjAI98cQTuu+++3TttddKkn7/+98rMTFR69at05gxY7R//35t2LBB27dv18CBAyVJixYt0jXXXKNHH31UKSkp9nQOAAA0abaOBF1++eXKzs7WP//5T0nSrl279Oabb+rqq6+WJB04cEAFBQXKyMiwtomLi1NaWppycnIkSTk5OYqPj7cCkCRlZGTI7XYrNze3xtctLy9XaWlpxAMAADiLrSNBP//5z1VaWqqLLrpIMTExqqys1K9//WuNGzdOklRQUCBJSkxMjNguMTHRWldQUKCEhISI9R6PR+3atbPanGjevHl64IEH6rs7jlV1wrTP55PL5bK5IgAATs/WkaA//vGPWrVqlVavXq1//OMfWrlypR599FGtXLmyQV935syZKikpsR6HDh1q0Ndr7sITpscu3apAIGB3OQAAnBFbR4KmT5+un//85xozZowkqXfv3vrkk080b948jR8/XklJSZKkwsJCJScnW9sVFhaqb9++kqSkpCQVFRVFPG9FRYWOHDlibX8iv98vv9/fAD1yLrfHK7ebESAAQPSwdSToq6++ktsdWUJMTIxCoZAkKTU1VUlJScrOzrbWl5aWKjc3V+np6ZKk9PR0FRcXKy8vz2qzefNmhUIhpaWlNUIvAABANLJ1JOj73/++fv3rX6tTp07q1auXduzYoYULF+rWW2+VJLlcLt1999361a9+pW7duik1NVWzZs1SSkqKRo4cKUnq0aOHhg8frokTJ2rp0qUKBoPKysrSmDFjODMMAACclK0haNGiRZo1a5Z++tOfqqioSCkpKbr99ts1e/Zsq83PfvYzHT9+XJMmTVJxcbG+/e1va8OGDWrRooXVZtWqVcrKytLQoUPldrs1atQoPfnkk3Z0CQAARAmXqXp5ZocqLS1VXFycSkpKFBsba3c5tikvL9cN/+9txXh9qgwG9Nxtl0mStSzw1TG5Yrzy+v01/ux2u/TcbZcx3woA0CjO9vubG6gCAABHIgQBAABH4i7yqFHVCyACANAcEYJQo/AFEE0oqBhfK8XYXRAAAPWMEISTcnu8MpV2VwEAQMNgThAAAHAkQhAAAHAkQhAAAHAkQhAAAHAkQhAAAHAkQhAAAHAkQhAAAHAkQhAAAHAkQhAAAHAkQhAAAHAkQhAAAHAkQhAAAHAkQhAAAHAkQhAAAHAkQhAAAHAkQhAAAHAkQhAAAHAkQhAAAHAkj90FoPkzxigQCFi/+3w+uVwuGysCAIAQhEYQCAQ0dulWuT1ehSqCWn3HEPn9frvLAgA4HCEIjcLt8SrG67O7DAAALMwJAgAAjkQIAgAAjkQIAgAAjkQIAgAAjsTEaIeqeto6p6wDAJyIkSCHCp+2Pnbp1ohr+AAA4BSMBDmY2+O1uwQAAGzDSBAAAHAkQhAAAHAkQhAAAHAk5gQ5nDFG5eXlkmT9FwAAJyAEOVyoIqjxy3Ll8fkULDuuGF8rxdhdFAAAjYDDYbBubuqO4WwxAIBzEIIAAIAjEYIAAIAjMScI9abqJGuJ23EAAJo2QhDqTdVJ1qGKoFbfMUR+v9/usgAAqBEhyEGq3jS1oU6HD0+yBgCgqSMEOUj4pqluj9c6Hb6hcP0hAEBTRwhymPBITWWwYe8cz/WHAABNHWeHocFw/SEAQFNGCAIAAI5ECAIAAI5ECAIAAI7ExGg0qqpnjXExRQCAnRgJQqMKnzU2dulW65pFAADYgZEgNDq3xyu3mxEgAIC9GAkCAACORAgCAACORAgCAACORAgCAACORAgCAACORAgCAACORAgCAACORAgCAACORAgCAACORAgCAACORAgCAACORAgCAACORAgCAACORAgCAACORAgCAACOZHsI+vTTT3XDDTeoffv2atmypXr37q13333XWm+M0ezZs5WcnKyWLVsqIyNDH3zwQcRzHDlyROPGjVNsbKzi4+M1YcIEHTt2rLG7AgAAooitIejLL7/U4MGD5fV69be//U379u3TY489prZt21ptFixYoCeffFJLly5Vbm6uWrdurczMTJWVlVltxo0bp71792rjxo165ZVX9MYbb2jSpEl2dAkAAEQJj50v/vDDD6tjx45avny5tSw1NdX62RijJ554Qvfdd5+uvfZaSdLvf/97JSYmat26dRozZoz279+vDRs2aPv27Ro4cKAkadGiRbrmmmv06KOPKiUlpXE7BQAAooKtI0Evv/yyBg4cqB//+MdKSEhQv3799Mwzz1jrDxw4oIKCAmVkZFjL4uLilJaWppycHElSTk6O4uPjrQAkSRkZGXK73crNza3xdcvLy1VaWhrxAAAAzmJrCPrXv/6lJUuWqFu3bnr11Vc1efJk3XnnnVq5cqUkqaCgQJKUmJgYsV1iYqK1rqCgQAkJCRHrPR6P2rVrZ7U50bx58xQXF2c9OnbsWN9dAwAATZytISgUCql///566KGH1K9fP02aNEkTJ07U0qVLG/R1Z86cqZKSEutx6NChBn09VGeMUXl5ufUwxthdEgDAYWydE5ScnKyePXtGLOvRo4f+9Kc/SZKSkpIkSYWFhUpOTrbaFBYWqm/fvlaboqKiiOeoqKjQkSNHrO1P5Pf75ff766sbqINQRVDjl+XK4/MpVBHU6juGsE8AAI3K1pGgwYMHKz8/P2LZP//5T3Xu3FnSN5Okk5KSlJ2dba0vLS1Vbm6u0tPTJUnp6ekqLi5WXl6e1Wbz5s0KhUJKS0trhF6grtwer2K8Prk9XrtLAQA4kK0jQffcc48uv/xyPfTQQ7r++uv1zjvv6Omnn9bTTz8tSXK5XLr77rv1q1/9St26dVNqaqpmzZqllJQUjRw5UtI3I0fDhw+3DqMFg0FlZWVpzJgxnBkGAABOytYQNGjQIK1du1YzZ87U3LlzlZqaqieeeELjxo2z2vzsZz/T8ePHNWnSJBUXF+vb3/62NmzYoBYtWlhtVq1apaysLA0dOlRut1ujRo3Sk08+aUeXmhxjjAKBgKRvzooDAADfcBlmpKq0tFRxcXEqKSlRbGys3eXUq/Lyco1dulVuj1fBsuOK8bWS1+9X4KtjcsV4ZSqDcsV4I5bVZn19tK0MBvTcbZcxJwgAUCtn+/1t+20z0PCsuTcxzL0BACCMEAQAAByJEAQAAByJEAQAAByJEAQAABzJ1lPkgRNVPaXf5/PJ5XLZXBEAoLliJAhNSiAQ0NilWzV26VYrDAEA0BAYCUKTw200AACNgZEgAADgSIQgAADgSIQgAADgSIQgAADgSIQgAADgSIQgAADgSIQgAADgSIQgAADgSIQgAADgSIQgAADgSIQgAADgSIQgAADgSNxAFbYzxqi8vFySrP8CANDQCEGwXagiqPHLcuXx+RQsO64YXyu53S67ywIANHMcDkOT4PZ4FeP1yR3jtbsUAIBDEIIAAIAjEYIAAIAjEYIAAIAjEYIAAIAj1SkEXXDBBfriiy+qLS8uLtYFF1xw1kUBAAA0tDqFoI8//liVlZXVlpeXl+vTTz8966IAAAAaWq2uE/Tyyy9bP7/66quKi4uzfq+srFR2dra6dOlSb8UBAAA0lFqFoJEjR0qSXC6Xxo8fH7HO6/WqS5cueuyxx+qtOAAAgIZSqxAUCoUkSampqdq+fbs6dOjQIEUBAAA0tDrdNuPAgQP1XQcAAECjqvO9w7Kzs5Wdna2ioiJrhCjs2WefPevCAAAAGlKdQtADDzyguXPnauDAgUpOTpbLxc0uAQBAdKlTCFq6dKlWrFihG2+8sb7rAQAAaBR1uk5QIBDQ5ZdfXt+1AAAANJo6haDbbrtNq1evru9aAAAAGk2dDoeVlZXp6aef1qZNm9SnTx95vd6I9QsXLqyX4gAAABpKnULQ7t271bdvX0nSnj17ItYxSRoAAESDOoWg1157rb7rAAAAaFR1mhMEAAAQ7eo0EvTd7373lIe9Nm/eXOeCAAAAGkOdQlB4PlBYMBjUzp07tWfPnmo3VgUAAGiK6hSCHn/88RqX33///Tp27NhZFQQAANAY6nVO0A033MB9wwAAQFSo1xCUk5OjFi1a1OdTAgAANIg6HQ677rrrIn43xujw4cN69913NWvWrHopDAAAoCHVKQTFxcVF/O52u9W9e3fNnTtXw4YNq5fCAAAAGlKdQtDy5cvruw4AAIBGVacQFJaXl6f9+/dLknr16qV+/frVS1EAAAANrU4hqKioSGPGjNGWLVsUHx8vSSouLtZ3v/tdrVmzRueee2591ggAAFDv6nR22NSpU3X06FHt3btXR44c0ZEjR7Rnzx6VlpbqzjvvrO8aAQAA6l2dRoI2bNigTZs2qUePHtaynj17avHixUyMBgAAUaFOISgUCsnr9VZb7vV6FQqFzroonB1jjAKBgCSpvLzc5moaTtV++ny+U97PDgCAE9UpBF111VW666679PzzzyslJUWS9Omnn+qee+7R0KFD67VA1F4gENDYpVvl9ngVLDuuGF8rxdhdVAMI91OSVt8xRH6/3+aKAADRpE5zgn7729+qtLRUXbp0UdeuXdW1a1elpqaqtLRUixYtqu8aUQduj1cxXp/cMdVH7JoTt8crt6d59xEA0DDqNBLUsWNH/eMf/9CmTZv0/vvvS5J69OihjIyMei0OAACgodRqJGjz5s3q2bOnSktL5XK59L3vfU9Tp07V1KlTNWjQIPXq1Utbt25tqFrhIMYYlZeXWw9jjN0lAQCamVqNBD3xxBOaOHGiYmNjq62Li4vT7bffroULF2rIkCH1ViCcKVQR1PhlufL4fApVBJnzAwCod7UaCdq1a5eGDx9+0vXDhg1TXl7eWRcFSFXmNTHnBwDQAGoVggoLC2s8NT7M4/Ho888/P+uiAAAAGlqtQtB5552nPXv2nHT97t27lZycfNZFAQAANLRahaBrrrlGs2bNUllZWbV1X3/9tebMmaP/+Z//qbfiAAAAGkqtJkbfd999eumll/Stb31LWVlZ6t69uyTp/fff1+LFi1VZWalf/vKXDVIoAABAfapVCEpMTNS2bds0efJkzZw50zpt2eVyKTMzU4sXL1ZiYmKDFAoAAFCfan2xxM6dO2v9+vX68ssv9eGHH8oYo27duqlt27YNUR8AAECDqNMVoyWpbdu2GjRoUH3WAgAA0GjqdO+whjB//ny5XC7dfffd1rKysjJNmTJF7du31znnnKNRo0apsLAwYruDBw9qxIgRatWqlRISEjR9+nRVVFQ0cvUAACDaNIkQtH37dj311FPq06dPxPJ77rlHf/nLX/Tiiy/q9ddf12effabrrrvOWl9ZWakRI0YoEAho27ZtWrlypVasWKHZs2c3dhcAAECUsT0EHTt2TOPGjdMzzzwTMa+opKREy5Yt08KFC3XVVVdpwIABWr58ubZt26a3335bkvT3v/9d+/bt03PPPae+ffvq6quv1oMPPqjFixcrEAjY1SUAABAFbA9BU6ZM0YgRI6rdgT4vL0/BYDBi+UUXXaROnTopJydHkpSTk6PevXtHnJGWmZmp0tJS7d2796SvWV5ertLS0ogHAABwljpPjK4Pa9as0T/+8Q9t37692rqCggL5fD7Fx8dHLE9MTFRBQYHV5sRT8sO/h9vUZN68eXrggQfOsnoAABDNbBsJOnTokO666y6tWrVKLVq0aNTXnjlzpkpKSqzHoUOHGvX1AQCA/WwLQXl5eSoqKlL//v3l8Xjk8Xj0+uuv68knn5TH41FiYqICgYCKi4sjtissLFRSUpIkKSkpqdrZYuHfw21q4vf7FRsbG/EAAADOYlsIGjp0qN577z3t3LnTegwcOFDjxo2zfvZ6vcrOzra2yc/P18GDB5Weni5JSk9P13vvvaeioiKrzcaNGxUbG6uePXs2ep/Q8IwxKi8vtx4AANSVbXOC2rRpo4svvjhiWevWrdW+fXtr+YQJEzRt2jS1a9dOsbGxmjp1qtLT03XZZZdJkoYNG6aePXvqxhtv1IIFC1RQUKD77rtPU6ZMkd/vb/Q+oeEFAgGNXbpVbo9XwbLjivG1ktvtsrssAEAUsnVi9Ok8/vjjcrvdGjVqlMrLy5WZmanf/e531vqYmBi98sormjx5stLT09W6dWuNHz9ec+fOtbFq1Lfw6I/0zZl9bo9XMV6fKoNcBgEAUHdNKgRt2bIl4vcWLVpo8eLFWrx48Um3Cd/LDM1XqCKo8cty5fH5rNGfGLuLAgBEPduvEwScifDojzvGa3cpAIBmghAEAAAciRAEAAAcqUnNCcLZMcYoEAhw6jgAAGeAENSMhE8fr6wIMHkYAIDTIAQ1M26PV8YYu8sAAKDJY04QAABwJEIQAABwJEIQAABwJEIQAABwJEIQAABwJEIQAABwJEIQAABwJEIQAABwJEIQAABwJEIQAABwJEIQAABwJEIQAABwJEIQAABwJEIQAABwJEIQAABwJEIQAABwJEIQAABwJI/dBQD1yRijQCBg/e7z+eRyuWysCADQVBGC0KwEAgGNXbpVbo9XoYqgVt8xRH6/3+6yAABNECEIzY7b41WM12d3GQCAJo4QFOWqHv4pLy+3uZqmxRhjvSccFgMAnIgQFOWqHv4Jlh1XjK+V3SU1uqphp2oQDFUENX5ZrtxuF4fFAADVEIKagfDhn8pg4PSNm6Fw2PH4fFYQjPm/dW6PV243I0AAgOo4RR7NQjgIumO8dpcCAIgSjASh2at6uExifhAA4BuEIDR7VQ+Xcdo8ACCMEARH4LR5AMCJmBMEAAAciRAEAAAciRAEAAAciRAEAAAciRAEAAAciRAEAAAciRAEAAAciRAEAAAciRAEAAAciRAEAAAcidtmRCFjjAKBgCRF3BgUAACcOUJQFAoEAhq7dKvcHq+CZccV42ulGLuLAgAgynA4LEqFbwjqjvHaXQoAAFGJEAQAAByJEAQAAByJEAQAAByJEAQAAByJEAQAAByJEAQAAByJEAQAAByJEAQAAByJEAQAAByJEAQAAByJEAQAAByJEAQAAByJEAQAAByJEAQAAByJEAQAAByJEAQAAByJEAQAAByJEAQAAByJEAQAAByJEAQAABzJY3cBQGMyxqi8vNz63efzyeVy2VgRAMAuhCA4SqgiqPHLcuXx+RSqCGr1HUPk9/vtLgsAYANbD4fNmzdPgwYNUps2bZSQkKCRI0cqPz8/ok1ZWZmmTJmi9u3b65xzztGoUaNUWFgY0ebgwYMaMWKEWrVqpYSEBE2fPl0VFRWN2ZUGFx7BCD9Qd26PVzFen9wer92lAABsZOtI0Ouvv64pU6Zo0KBBqqio0C9+8QsNGzZM+/btU+vWrSVJ99xzj/7617/qxRdfVFxcnLKysnTdddfprbfekiRVVlZqxIgRSkpK0rZt23T48GHddNNN8nq9euihh+zsXr0KBAIau3Sr3B6vgmXHFeNrpRi7iwIAIIrZGoI2bNgQ8fuKFSuUkJCgvLw8XXHFFSopKdGyZcu0evVqXXXVVZKk5cuXq0ePHnr77bd12WWX6e9//7v27dunTZs2KTExUX379tWDDz6oGTNm6P7775fP57Ojaw0iPIJRGQzYXQoAAFGvSZ0dVlJSIklq166dJCkvL0/BYFAZGRlWm4suukidOnVSTk6OJCknJ0e9e/dWYmKi1SYzM1OlpaXau3dvja9TXl6u0tLSiAcAAHCWJhOCQqGQ7r77bg0ePFgXX3yxJKmgoEA+n0/x8fERbRMTE1VQUGC1qRqAwuvD62oyb948xcXFWY+OHTvWc28AAEBT12RC0JQpU7Rnzx6tWbOmwV9r5syZKikpsR6HDh1q8NcEAABNS5M4RT4rK0uvvPKK3njjDZ1//vnW8qSkJAUCARUXF0eMBhUWFiopKclq884770Q8X/jssXCbE/n9fk6LBgDA4WwdCTLGKCsrS2vXrtXmzZuVmpoasX7AgAHyer3Kzs62luXn5+vgwYNKT0+XJKWnp+u9995TUVGR1Wbjxo2KjY1Vz549G6cjaDZOvBSBMcbukgAADcTWkaApU6Zo9erV+vOf/6w2bdpYc3ji4uLUsmVLxcXFacKECZo2bZratWun2NhYTZ06Venp6brsssskScOGDVPPnj114403asGCBSooKNB9992nKVOmMNqDWqt6KQIupggAzZutIWjJkiWSpCuvvDJi+fLly3XzzTdLkh5//HG53W6NGjVK5eXlyszM1O9+9zurbUxMjF555RVNnjxZ6enpat26tcaPH6+5c+c2VjfQzIQvRQAAaN5sDUFncqihRYsWWrx4sRYvXnzSNp07d9b69evrszQAANDMNYmJ0YDdjDEKBALckgQAHIQQBOi/c4EqKwLckgQAHIIQBPwft8fL2WAA4CBN5mKJAAAAjYmRIDhW+JpAkpgLBAAORAiCY4Uqghq/LFcen0/BsuOK8bWyuyQAQCPicBgcLXxNIHeM1+5SAACNjBAEAAAciRAEAAAciRAEAAAciRAEAAAcibPDmjhu5wAAQMMgBDVx3M4BAICGQQiKAtzOAQCA+secIAAA4EiMBAEnUfW2GpLk8/nkcrlsrAgAUJ8IQcBJVL2tRqgiqNV3DJHf77e7LABAPSEEAacQvq0GAKD5YU4QAABwJEIQAABwJA6HAWeg6iTp8OUKXC4Xk6UBIIoRgoAzUHWSdLDsuFxur9xuF5OlASCKEYKAMxSeJF0ZDMgV800IAgBEL+YEAQAARyIEAQAARyIEAQAARyIEAQAARyIEAQAARyIEAQAARyIEAQAARyIEAQAARyIEAQAARyIEAQAARyIEAQAARyIEAQAARyIEAQAARyIEAQAARyIEAQAARyIEAQAARyIEAQAARyIEAQAARyIEAQAAR/LYXQCqM8YoEAhIksrLy22uBidjjLH2jzFGkuRyuSRJPp/P+hkA0DQRgpqgQCCgsUu3yu3xKlh2XDG+VnaXhBqEKoIavyxXHp9PwbLjcrm98vh8ClUEtfqOIfL7/XaXCAA4BUJQE+X2eBXj9akyGLC7FJxC1f3kivnmZwBAdGBOEAAAcCRGgoB6VnWuEHODAKDpIgQB9Sw8V8jlklbcmmbNDSIQAUDTQggCGoDb45Wp/O/EaSZLA0DTQwgCGlB44jQAoOlhYjQAAHAkRoKARlb1YpgSc4UAwC6EoCaCq0Q7R9WLYTJXCADsQwhqImq6SnSM3UWh3lQ9bb68vNyaK8Tp9ABgH0JQE8JVopuvE2+xEQ654eVut4sRIQBoZIQgoJGcLOS6PV65XJGHQRkVAoCGRwgCmoCqI0XMEwKAxkEIApoIrikEAI2L6wQBAABHYiTIZuFT4zktHgCAxkUIsln41PjKigCnxaMaLqwIAA2HENQEuD1eGWPsLgNNxInXFLpl+TtcWBEAGgAhCGhiarym0EkmTDNSBAB1RwiyAbfIwOmc6YUza7oFh8/nO+tgRLgC4ASEIBvUdIsM4HROdouNE0+tr497k3F/MwBOQAiyCbfIQG2FD5O5XNKKW9Pk9/tPOpJYl2sOnThCeeJzMDoEoLkhBAFRxO3xylTWfB+yqiNFYScuCweXqoEmvOx0N/FldAhAc0MIAqJQTSOJ4ZEiEwpWu0Grx/dN26ojSLcsf0eSIsLM6UYoz/aq1jWFr7PFCBWAumo2IWjx4sV65JFHVFBQoEsuuUSLFi3SpZdeandZFiZDozF8M1JUfVk42Jw4glT1xq0n+7uszQjT6YRHkySddiTpTAMTI1QA6qpZhKAXXnhB06ZN09KlS5WWlqYnnnhCmZmZys/PV0JCgt3lSap5MjQXRkRjO3Gkp8bT8U/Y5kxHmHy+b0aIwmHlZMElfF2s04Wo2gSmmkaoGnOEiNEoIDo1ixC0cOFCTZw4UbfccoskaenSpfrrX/+qZ599Vj//+c9tru6/mAyNpuhM/i7PZITJhIJyub3VDr1J1UNB1RB1qtEbt8d70ppOd8uZ010+IHyB0tOFtjPRnEejGuIQ5smev6Feoz6d7v1o6P5E2/vV1EV9CAoEAsrLy9PMmTOtZW63WxkZGcrJyWnQ1z7dHyOHwOAU4ZDkiql+6O1koSAcoqqOClUNJqf7N3Mmt5w51eUDgmXHawxtdf1SOdV8qcb+4qrP4BJ+z4wxpwy2Z/v8bo/3tOG5KTjd+9HQgbg5B247RH0I+s9//qPKykolJiZGLE9MTNT7779f4zbl5eURH7AlJSWSpNLS0lq9dnl5uW5++nXFeLyqrAjqqfGXRfwxlpeX6/aVbyvG41Wg7Ct5fC3l8foULP9KLrdHleX//dmEKqotq836hmrbHF63OfQhWl/XVAYVqgzq888/tyZklx8rVmVFMKLtmN+8Ko/Pp0DZV3K7PdbPHl9Lud0ua/sT//0Fy46rsiKoikBAleW+Gl/LHeO1lktSsOy43DHeiBrDNbjcrmr/js/0s+DE1zrZZ0FNnxX1Lfx6ks76taq+z+H9VJ99CD9/eJ80xGvUp9O9H1X7U9PfQn29fkM9f7Q5evSopP/+D1StmSj36aefGklm27ZtEcunT59uLr300hq3mTNnjpHEgwcPHjx48GgGj0OHDtUpQ0T9SFCHDh0UExOjwsLCiOWFhYVKSkqqcZuZM2dq2rRp1u/FxcXq3LmzDh48qLi4uAattykoLS1Vx44ddejQIcXGxtpdTqNwWp+d1l/JeX12Wn8l5/XZaf2Vat9nY4yOHj2qlJSUOr1e1Icgn8+nAQMGKDs7WyNHjpQkhUIhZWdnKysrq8Zt/H5/jcOHcXFxjvlDk6TY2FhH9VdyXp+d1l/JeX12Wn8l5/XZaf2Vatfnsxm8iPoQJEnTpk3T+PHjNXDgQF166aV64okndPz4cetsMQAAgBM1ixA0evRoff7555o9e7YKCgrUt29fbdiwodpkaQAAgLBmEYIkKSsr66SHv07H7/drzpw5jplh77T+Ss7rs9P6Kzmvz07rr+S8Pjutv1Lj99llTF3PKwMAAIhebrsLAAAAsAMhCAAAOBIhCAAAOJLjQ9DixYvVpUsXtWjRQmlpaXrnnXfsLqlO5s2bp0GDBqlNmzZKSEjQyJEjlZ+fH9HmyiuvlMvlinjccccdEW0OHjyoESNGqFWrVkpISND06dNVUVHRmF05Y/fff3+1/lx00UXW+rKyMk2ZMkXt27fXOeeco1GjRlW7qGY09bdLly7V+utyuTRlyhRJzWP/vvHGG/r+97+vlJQUuVwurVu3LmK9MUazZ89WcnKyWrZsqYyMDH3wwQcRbY4cOaJx48YpNjZW8fHxmjBhgo4dOxbRZvfu3RoyZIhatGihjh07asGCBQ3dtRqdqr/BYFAzZsxQ79691bp1a6WkpOimm27SZ599FvEcNf1dzJ8/P6JNU+mvdPp9fPPNN1frz/DhwyPaNJd9LKnGf9Mul0uPPPKI1Sba9vGZfB/V1+fzli1b1L9/f/n9fl144YVasWJF7Yqt03Wmm4k1a9YYn89nnn32WbN3714zceJEEx8fbwoLC+0urdYyMzPN8uXLzZ49e8zOnTvNNddcYzp16mSOHTtmtfnOd75jJk6caA4fPmw9SkpKrPUVFRXm4osvNhkZGWbHjh1m/fr1pkOHDmbmzJl2dOm05syZY3r16hXRn88//9xaf8cdd5iOHTua7Oxs8+6775rLLrvMXH755db6aOtvUVFRRF83btxoJJnXXnvNGNM89u/69evNL3/5S/PSSy8ZSWbt2rUR6+fPn2/i4uLMunXrzK5du8wPfvADk5qaar7++murzfDhw80ll1xi3n77bbN161Zz4YUXmp/85CfW+pKSEpOYmGjGjRtn9uzZY55//nnTsmVL89RTTzVWNy2n6m9xcbHJyMgwL7zwgnn//fdNTk6OufTSS82AAQMinqNz585m7ty5Efu96r/7ptRfY06/j8ePH2+GDx8e0Z8jR45EtGku+9gYE9HPw4cPm2effda4XC7z0UcfWW2ibR+fyfdRfXw+/+tf/zKtWrUy06ZNM/v27TOLFi0yMTExZsOGDWdcq6ND0KWXXmqmTJli/V5ZWWlSUlLMvHnzbKyqfhQVFRlJ5vXXX7eWfec73zF33XXXSbdZv369cbvdpqCgwFq2ZMkSExsba8rLyxuy3DqZM2eOueSSS2pcV1xcbLxer3nxxRetZfv37zeSTE5OjjEm+vp7orvuust07drVhEIhY0zz278nfmGEQiGTlJRkHnnkEWtZcXGx8fv95vnnnzfGGLNv3z4jyWzfvt1q87e//c24XC7z6aefGmOM+d3vfmfatm0b0ecZM2aY7t27N3CPTq2mL8gTvfPOO0aS+eSTT6xlnTt3No8//vhJt2mq/TWm5j6PHz/eXHvttSfdprnv42uvvdZcddVVEcuieR8bU/37qL4+n3/2s5+ZXr16RbzW6NGjTWZm5hnX5tjDYYFAQHl5ecrIyLCWud1uZWRkKCcnx8bK6kdJSYkkqV27dhHLV61apQ4dOujiiy/WzJkz9dVXX1nrcnJy1Lt374iLTGZmZqq0tFR79+5tnMJr6YMPPlBKSoouuOACjRs3TgcPHpQk5eXlKRgMRuzfiy66SJ06dbL2bzT2NywQCOi5557TrbfeKpfLZS1vbvu3qgMHDqigoCBin8bFxSktLS1in8bHx2vgwIFWm4yMDLndbuXm5lptrrjiCvl8PqtNZmam8vPz9eWXXzZSb+qmpKRELpdL8fHxEcvnz5+v9u3bq1+/fnrkkUciDhlEY3+3bNmihIQEde/eXZMnT9YXX3xhrWvO+7iwsFB//etfNWHChGrronkfn/h9VF+fzzk5ORHPEW5Tm+/wZnOxxNr6z3/+o8rKympXlU5MTNT7779vU1X1IxQK6e6779bgwYN18cUXW8vHjh2rzp07KyUlRbt379aMGTOUn5+vl156SZJUUFBQ4/sRXtfUpKWlacWKFerevbsOHz6sBx54QEOGDNGePXtUUFAgn89X7csiMTHR6ku09beqdevWqbi4WDfffLO1rLnt3xOFa6ypD1X3aUJCQsR6j8ejdu3aRbRJTU2t9hzhdW3btm2Q+s9WWVmZZsyYoZ/85CcR91S688471b9/f7Vr107btm3TzJkzdfjwYS1cuFBS9PV3+PDhuu6665SamqqPPvpIv/jFL3T11VcrJydHMTExzXofr1y5Um3atNF1110XsTya93FN30f19fl8sjalpaX6+uuv1bJly9PW59gQ1JxNmTJFe/bs0ZtvvhmxfNKkSdbPvXv3VnJysoYOHaqPPvpIXbt2bewyz9rVV19t/dynTx+lpaWpc+fO+uMf/3hGf/zRbNmyZbr66qsj7pzc3PYv/isYDOr666+XMUZLliyJWDdt2jTr5z59+sjn8+n222/XvHnzovJKw2PGjLF+7t27t/r06aOuXbtqy5YtGjp0qI2VNbxnn31W48aNU4sWLSKWR/M+Ptn3UVPh2MNhHTp0UExMTLXZ6IWFhUpKSrKpqrOXlZWlV155Ra+99prOP//8U7ZNS0uTJH344YeSpKSkpBrfj/C6pi4+Pl7f+ta39OGHHyopKUmBQEDFxcURbaru32jt7yeffKJNmzbptttuO2W75rZ/wzWe6t9sUlKSioqKItZXVFToyJEjUbvfwwHok08+0caNG097Z+20tDRVVFTo448/lhR9/T3RBRdcoA4dOkT8HTe3fSxJW7duVX5+/mn/XUvRs49P9n1UX5/PJ2sTGxt7xv8j7NgQ5PP5NGDAAGVnZ1vLQqGQsrOzlZ6ebmNldWOMUVZWltauXavNmzdXGxqtyc6dOyVJycnJkqT09HS99957ER8w4Q/dnj17Nkjd9enYsWP66KOPlJycrAEDBsjr9Ubs3/z8fB08eNDav9Ha3+XLlyshIUEjRow4Zbvmtn9TU1OVlJQUsU9LS0uVm5sbsU+Li4uVl5dntdm8ebNCoZAVCtPT0/XGG28oGAxabTZu3Kju3bs3ucMk4QD0wQcfaNOmTWrfvv1pt9m5c6fcbrd1yCia+luTf//73/riiy8i/o6b0z4OW7ZsmQYMGKBLLrnktG2b+j4+3fdRfX0+p6enRzxHuE2tvsPrNte7eVizZo3x+/1mxYoVZt++fWbSpEkmPj4+YjZ6tJg8ebKJi4szW7ZsiTiN8quvvjLGGPPhhx+auXPnmnfffdccOHDA/PnPfzYXXHCBueKKK6znCJ+SOGzYMLNz506zYcMGc+655zapU6iruvfee82WLVvMgQMHzFtvvWUyMjJMhw4dTFFRkTHmm1MwO3XqZDZv3mzeffddk56ebtLT063to62/xnxzBmOnTp3MjBkzIpY3l/179OhRs2PHDrNjxw4jySxcuNDs2LHDOhtq/vz5Jj4+3vz5z382u3fvNtdee22Np8j369fP5ObmmjfffNN069Yt4vTp4uJik5iYaG688UazZ88es2bNGtOqVStbTic+VX8DgYD5wQ9+YM4//3yzc+fOiH/X4bNjtm3bZh5//HGzc+dO89FHH5nnnnvOnHvuueamm25qkv09XZ+PHj1q/vd//9fk5OSYAwcOmE2bNpn+/fubbt26mbKyMus5mss+DispKTGtWrUyS5YsqbZ9NO7j030fGVM/n8/hU+SnT59u9u/fbxYvXswp8rW1aNEi06lTJ+Pz+cyll15q3n77bbtLqhNJNT6WL19ujDHm4MGD5oorrjDt2rUzfr/fXHjhhWb69OkR15ExxpiPP/7YXH311aZly5amQ4cO5t577zXBYNCGHp3e6NGjTXJysvH5fOa8884zo0ePNh9++KG1/uuvvzY//elPTdu2bU2rVq3MD3/4Q3P48OGI54im/hpjzKuvvmokmfz8/IjlzWX/vvbaazX+HY8fP94Y881p8rNmzTKJiYnG7/eboUOHVnsvvvjiC/OTn/zEnHPOOSY2Ntbccsst5ujRoxFtdu3aZb797W8bv99vzjvvPDN//vzG6mKEU/X3wIEDJ/13Hb42VF5enklLSzNxcXGmRYsWpkePHuahhx6KCAzGNJ3+GnPqPn/11Vdm2LBh5txzzzVer9d07tzZTJw4sdr/mDaXfRz21FNPmZYtW5ri4uJq20fjPj7d95Ex9ff5/Nprr5m+ffsan89nLrjggojXOBPcRR4AADiSY+cEAQAAZyMEAQAARyIEAQAARyIEAQAARyIEAQAARyIEAQAARyIEAQAARyIEAQAARyIEAaiTK6+8UnfffbfdZTQYl8uldevW2V0GgAZECAJQJy+99JIefPDBRn3N+++/X3379q3VNoQZACfjsbsAANGpXbt2dpcAAGeFkSAAdVL1cFiXLl300EMP6dZbb1WbNm3UqVMnPf3001bbjz/+WC6XS2vWrNHll1+uFi1a6OKLL9brr79utVmxYoXi4+MjXmPdunVyuVzW+gceeEC7du2Sy+WSy+XSihUrTlljly5dJEk//OEP5XK5rN8lacmSJeratat8Pp+6d++uP/zhD6d8rjlz5ig5OVm7d++WJL355psaMmSIWrZsqY4dO+rOO+/U8ePHI177VO9JIBBQVlaWkpOT1aJFC3Xu3Fnz5s07ZQ0A6hchCEC9eOyxxzRw4EDt2LFDP/3pTzV58mTl5+dHtJk+fbruvfde7dixQ+np6fr+97+vL7744oyef/To0br33nvVq1cvHT58WIcPH9bo0aNPuc327dslScuXL9fhw4et39euXau77rpL9957r/bs2aPbb79dt9xyi1577bVqz2GM0dSpU/X73/9eW7duVZ8+ffTRRx9p+PDhGjVqlHbv3q0XXnhBb775prKyss74PXnyySf18ssv649//KPy8/O1atWqiJAGoBHU6p7zAPB/vvOd75i77rrLGGNM586dzQ033GCtC4VCJiEhwSxZssQYY8yBAweMJDN//nyrTTAYNOeff755+OGHjTHGLF++3MTFxUW8xtq1a03Vj6k5c+aYSy65pFZ1SjJr166NWHb55ZebiRMnRiz78Y9/bK655pqI7V588UUzduxY06NHD/Pvf//bWjdhwgQzadKkiO23bt1q3G63+frrr40xp39Ppk6daq666ioTCoVq1R8A9YeRIAD1ok+fPtbPLpdLSUlJKioqimiTnp5u/ezxeDRw4EDt37+/0WoM279/vwYPHhyxbPDgwdVqueeee5Sbm6s33nhD5513nrV8165dWrFihc455xzrkZmZqVAopAMHDljtTvWe3Hzzzdq5c6e6d++uO++8U3//+98boqsAToEQBKBeeL3eiN9dLpdCodAZb+92u2WMiVgWDAbrpba6+t73vqdPP/1Ur776asTyY8eO6fbbb9fOnTutx65du/TBBx+oa9euVrtTvSf9+/fXgQMH9OCDD+rrr7/W9ddfrx/96EcN3ykAFkIQgEbz9ttvWz9XVFQoLy9PPXr0kCSde+65Onr0aMTk4p07d0Zs7/P5VFlZWavX9Hq91bbp0aOH3nrrrYhlb731lnr27Bmx7Ac/+IFWr16t2267TWvWrLGW9+/fX/v27dOFF15Y7eHz+c64ttjYWI0ePVrPPPOMXnjhBf3pT3/SkSNHatU/AHXHKfIAGs3ixYvVrVs39ejRQ48//ri+/PJL3XrrrZKktLQ0tWrVSr/4xS905513Kjc3t9rZX126dNGBAwe0c+dOnX/++WrTpo38fv8pX7NLly7Kzs7W4MGD5ff71bZtW02fPl3XX3+9+vXrp4yMDP3lL3/RSy+9pE2bNlXb/oc//KH+8Ic/6MYbb5TH49GPfvQjzZgxQ5dddpmysrJ02223qXXr1tq3b582btyo3/72t2f0XixcuFDJycnq16+f3G63XnzxRSUlJVU7Qw5Aw2EkCECjmT9/vubPn69LLrlEb775pl5++WV16NBB0jfXHXruuee0fv169e7dW88//7zuv//+iO1HjRql4cOH67vf/a7OPfdcPf/886d9zccee0wbN25Ux44d1a9fP0nSyJEj9Zvf/EaPPvqoevXqpaeeekrLly/XlVdeWeNz/OhHP9LKlSt144036qWXXlKfPn30+uuv65///KeGDBmifv36afbs2UpJSTnj96JNmzZasGCBBg4cqEGDBunjjz/W+vXr5XbzsQw0Fpc58SA8ANSzjz/+WKmpqdqxY0etr/gMAA2F/+UAAACORAgCELVWrVoVcZp61UevXr3sLg9AE8fhMABR6+jRoyosLKxxndfrVefOnRu5IgDRhBAEAAAcicNhAADAkQhBAADAkQhBAADAkQhBAADAkQhBAADAkQhBAADAkQhBAADAkQhBAADAkf4/TInGwOG7xHsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.histplot(train_df['input_tokens'])\n",
    "g.set(xlim=(0, 1024*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229670b5-d0aa-49f9-86fd-6a7b8420582d",
   "metadata": {},
   "source": [
    "# KG Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "494cb57d-736b-47c5-b5ce-fd462d89c740",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "ENT_TYPES = ['Task', 'Method', 'Metric', 'Material', 'OtherScientificTerm', 'Generic']\n",
    "# ENT_RANK = {\n",
    "#     'Task': 5, \n",
    "#     'Method': 4, \n",
    "#     'Metric': 3, \n",
    "#     'Material': 2, \n",
    "#     'OtherScientificTerm': 2, \n",
    "#     'Generic': 1\n",
    "# }\n",
    "REL_TYPES = {\n",
    "    'FEATURE-OF':   'Asym', \n",
    "    'PART-OF':      'Asym', \n",
    "    'USED-FOR':     'Asym', \n",
    "    'EVALUATE-FOR': 'Asym',\n",
    "    'HYPONYM-OF':   'Asym', \n",
    "    'COMPARE':      'Sym',\n",
    "    'CONJUNCTION':  'Sym',\n",
    "}\n",
    "ENT_TYPE_TOKENS = [f\"[{prefix}{ent_type}]\" for ent_type in ENT_TYPES for prefix in [\"\", \"/\"]]\n",
    "REL_TYPE_TOKENS = [f\"[{rel_type}]\" for rel_type in REL_TYPES.keys()]\n",
    "tokenizer.add_tokens(ENT_TYPE_TOKENS)\n",
    "tokenizer.add_tokens(REL_TYPE_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8b02d98-1d3d-49ec-ba0e-f392d8136da4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    model='bart-large',\n",
    "    dataset='arXiv',\n",
    "    # dataset='MuP',\n",
    "    section=['abstract'],\n",
    "    # section=['abstract', 'introduction'],\n",
    "    inputType='kg',\n",
    "    bs=8, \n",
    "    max_input=512,\n",
    "    max_output=512,\n",
    "    num_epoch=5,\n",
    "    num_beams=4,\n",
    "    lr=1e-5,\n",
    "    fp=32,\n",
    "    opt=\"adam\",\n",
    "    prototype=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f04c0cb-3e81-4c44-8707-70eec5c882a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_multifile(prepared_dir, data_split, suffix='', revised=True):\n",
    "    files = sorted(os.listdir(prepared_dir))\n",
    "    run_files = []\n",
    "    if revised:\n",
    "        for file in files:\n",
    "            filename = file.split(\".\")[0]\n",
    "            if filename[:-(2+len(suffix))]==f\"revised_{data_split}_\": \n",
    "                run_files.append(file)\n",
    "    else:\n",
    "        for file in files:\n",
    "            filename = file.split(\".\")[0]    \n",
    "            if filename[:-(2+len(suffix))]==f\"{data_split}_\" and filename[:-(2+len(suffix))]!=f\"revised_{data_split}_\": \n",
    "                run_files.append(file)\n",
    "    return run_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32dfb836-9826-4c7b-9da1-1e6992256aed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_KGdata(args, data_split, section):\n",
    "    main_path = str((Path().absolute()).parents[0])\n",
    "    data_dir = f\"{main_path}/PL-Marker/_scire_models/{args.dataset}/{section}/\"\n",
    "    if args.dataset=='arXiv' and data_split=='train':\n",
    "        run_files = get_multifile(data_dir, data_split, suffix=\"_re\",revised=True)\n",
    "    elif args.dataset=='MuP' and section in ['introduction', 'conclusion']:\n",
    "        run_files = [f\"revised_{data_split}_re.json\"]\n",
    "    else:\n",
    "        run_files = [f\"{data_split}_re.json\"]\n",
    "    json_list = []\n",
    "    num_files = len(run_files)\n",
    "    for i, filename in enumerate(run_files):\n",
    "        with open(data_dir+filename, 'r') as json_file:\n",
    "            json_list += list(json_file)\n",
    "        if isinstance(args.prototype, int): \n",
    "            if len(json_list)>=args.prototype: break\n",
    "    return [json.loads(json_str) for json_str in json_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4c7e932-e4b4-40f0-a430-1a043ca60f65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6436"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_null = False\n",
    "data_split = \"val\"\n",
    "sections = args.section\n",
    "\n",
    "how = 'inner' if skip_null else 'outer'\n",
    "for i, sec in enumerate(sections):\n",
    "    sec_df = pd.DataFrame(get_KGdata(args, data_split, sec))\n",
    "    sec_df.drop([\"ner\", \"relations\"], axis=1, inplace=True)\n",
    "    sec_df.rename(columns={\n",
    "        \"sentences\": f\"{sec}_sent\",\n",
    "        \"predicted_ner\": f\"{sec}_ner\",\n",
    "        \"predicted_re\": f\"{sec}_rel\"\n",
    "    }, inplace=True)\n",
    "    # input_dataset.append(sec_df)\n",
    "    if i==0:\n",
    "        input_dataset = sec_df.copy()\n",
    "    else:\n",
    "        input_dataset = pd.merge(input_dataset, sec_df, on=\"doc_key\", how=how)\n",
    "len(input_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f8e19f5-908c-48e8-8cf0-ab7728c5a118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def manage_confilt_ent(ent_list):\n",
    "    count_ent = {}\n",
    "    for ent_type in ENT_TYPES: count_ent[ent_type] = 0\n",
    "    for ent in ent_list: count_ent[ent] += 1\n",
    "    return max(count_ent, key=count_ent.get)\n",
    "\n",
    "def count_list(input_list):\n",
    "    count_dict = {}\n",
    "    for ele in input_list:\n",
    "        if ele in count_dict.keys(): count_dict[ele] += 1\n",
    "        else: count_dict[ele] = 1\n",
    "    return count_dict\n",
    "    \n",
    "def build_graph(data, sections):\n",
    "    ent_type_dict = {}\n",
    "    triple_list = []\n",
    "    \n",
    "    for sec in sections:\n",
    "        if not isinstance(data[f\"{sec}_sent\"], list): break\n",
    "        flatten_sent = [j for i in data[f\"{sec}_sent\"] for j in i]\n",
    "        flatten_ner  = [j for i in data[f\"{sec}_ner\"] for j in i]\n",
    "        flatten_re   = [j for i in data[f\"{sec}_rel\"] for j in i[1]]\n",
    "        # print(\" \".join(flatten_sent))\n",
    "\n",
    "        for ner in flatten_ner:\n",
    "            ent = \" \".join(flatten_sent[ner[0]:ner[1]+1])\n",
    "            if ent not in ent_type_dict.keys():\n",
    "                ent_type_dict[ent] = [ner[2]]\n",
    "            else:\n",
    "                ent_type_dict[ent].append(ner[2])\n",
    "        \n",
    "        for rel in flatten_re:\n",
    "            sub = \" \".join(flatten_sent[rel[0][0]:rel[0][1]+1])\n",
    "            obj = \" \".join(flatten_sent[rel[1][0]:rel[1][1]+1])\n",
    "            triple_list.append({\n",
    "                'subject':  \" \".join(flatten_sent[rel[0][0]:rel[0][1]+1]),\n",
    "                'relation': rel[2],\n",
    "                'object':   \" \".join(flatten_sent[rel[1][0]:rel[1][1]+1]),\n",
    "            })\n",
    "                            \n",
    "    for ent, ent_type in ent_type_dict.items():\n",
    "        if len(set(ent_type))>1:\n",
    "            ent_type_dict[ent] = manage_confilt_ent(ent_type)\n",
    "        else:\n",
    "            ent_type_dict[ent] = ent_type[0]\n",
    "    \n",
    "    return ent_type_dict, pd.DataFrame(triple_list).drop_duplicates()\n",
    "\n",
    "def add_entType(ent, ent_type):\n",
    "    return f\"[{ent_type}] {ent} [/{ent_type}]\"\n",
    "\n",
    "def graph2seq(ent_type_dict, triple_df, is_add_entType=True):\n",
    "    seq = \"\"\n",
    "    # triple_df = pd.DataFrame(triple_list).drop_duplicates()\n",
    "    triple_ent = []\n",
    "    \n",
    "    while len(triple_df)!=0:\n",
    "        count = count_list(list(triple_df['subject']))\n",
    "        sub = max(count, key=count.get)\n",
    "        sub_seq = add_entType(sub, ent_type_dict[sub]) if is_add_entType else sub\n",
    "        seq += f\"{sub_seq} \"            \n",
    "            \n",
    "        rel_obj = {}\n",
    "        for _, row in triple_df[triple_df['subject']==sub].iterrows():\n",
    "            triple_ent += [row['subject'], row['object']]\n",
    "            rel = row['relation']\n",
    "            obj_seq = add_entType(row['object'], ent_type_dict[row['object']]) if is_add_entType else row['object']\n",
    "            if rel not in rel_obj.keys():\n",
    "                rel_obj[rel] = [obj_seq]\n",
    "            else:\n",
    "                rel_obj[rel].append(obj_seq)\n",
    "            triple_df.drop(_, inplace=True)\n",
    "        seq += ', '.join([f\"[{rel}] {', '.join(objs)}\" for rel, objs in rel_obj.items()])\n",
    "        seq += '. '\n",
    "    free_ent = list(set(ent_type_dict)-set(triple_ent))\n",
    "    if is_add_entType: free_ent = [add_entType(ent, ent_type_dict[ent]) for ent in free_ent]\n",
    "    if len(free_ent)>0:\n",
    "        seq += '/n'\n",
    "        seq += ', '.join(free_ent)\n",
    "        seq += '.'\n",
    "\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e9586dd-0b14-4fa0-8404-634c71d40052",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_key                                                  0708.1996\n",
      "abstract_sent    [[ , we, study, the, phase, behavior, of, a, n...\n",
      "abstract_ner     [[[4, 5, Task], [8, 10, OtherScientificTerm], ...\n",
      "abstract_rel     [[0, [[[4, 5], [8, 10], 'FEATURE-OF'], [[17, 1...\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[OtherScientificTerm] strong anchoring [/OtherScientificTerm] [CONJUNCTION] [OtherScientificTerm] patterned substrate [/OtherScientificTerm], [FEATURE-OF] [Material] flat substrate [/Material]. [OtherScientificTerm] effective surface free energy function [/OtherScientificTerm] [USED-FOR] [OtherScientificTerm] patterned substrate [/OtherScientificTerm], [Generic] expression [/Generic]. [OtherScientificTerm] homogeneous state [/OtherScientificTerm] [CONJUNCTION] [OtherScientificTerm] hybrid aligned nematic state [/OtherScientificTerm], [PART-OF] [OtherScientificTerm] phase diagrams [/OtherScientificTerm]. [Task] phase behavior [/Task] [FEATURE-OF] [OtherScientificTerm] nematic liquid crystal [/OtherScientificTerm]. [OtherScientificTerm] patterned substrate [/OtherScientificTerm] [FEATURE-OF] [OtherScientificTerm] nematic liquid crystal [/OtherScientificTerm]. [Material] flat substrate [/Material] [FEATURE-OF] [OtherScientificTerm] nematic liquid crystal [/OtherScientificTerm]. [Generic] expression [/Generic] [USED-FOR] [OtherScientificTerm] effective free energy [/OtherScientificTerm]. [OtherScientificTerm] effective free energy [/OtherScientificTerm] [FEATURE-OF] [OtherScientificTerm] confined nematic liquid crystal [/OtherScientificTerm]. [OtherScientificTerm] nematic director [/OtherScientificTerm] [FEATURE-OF] [OtherScientificTerm] homogeneous state [/OtherScientificTerm]. [OtherScientificTerm] hybrid aligned nematic state [/OtherScientificTerm] [PART-OF] [OtherScientificTerm] phase diagrams [/OtherScientificTerm]. [Method] effective energy method [/Method] [USED-FOR] [OtherScientificTerm] energy barriers [/OtherScientificTerm]. /n[OtherScientificTerm] free energy functional [/OtherScientificTerm], [Method] bistable nematic device [/Method], [OtherScientificTerm] phase boundaries [/OtherScientificTerm], [OtherScientificTerm] local anchoring strength [/OtherScientificTerm], [Method] effective free energy method [/Method].'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, data in input_dataset.iterrows():\n",
    "    print(data)\n",
    "    ent_type_dict, triple_df = build_graph(data, sections)\n",
    "    seq = graph2seq(ent_type_dict, triple_df)\n",
    "    # print(data['abstract_sent'])\n",
    "    # flatten_sent = [j for i in data[f\"abstract_sent\"] for j in i]\n",
    "    break\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "216dae5f-460c-40bf-8a0e-4ae01b3c9aef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_key</th>\n",
       "      <th>sentences</th>\n",
       "      <th>abstract_ner</th>\n",
       "      <th>abstract_rel</th>\n",
       "      <th>introduction_ner</th>\n",
       "      <th>introduction_rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc</td>\n",
       "      <td>[[We, study, the, average, CVloo, stability, o...</td>\n",
       "      <td>[[[3, 5, Metric], [7, 11, Method], [15, 16, Ot...</td>\n",
       "      <td>[[0, [[[3, 5], [7, 11], 'FEATURE-OF']]], [1, [...</td>\n",
       "      <td>[[[0, 2, Method], [8, 10, Method], [22, 23, Ma...</td>\n",
       "      <td>[[0, [[[0, 2], [8, 10], 'USED-FOR']]], [1, [[[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP:b80bc890180934092cde037b49d94d6e4e06fad9</td>\n",
       "      <td>[[The, use, of, episodic, memories, in, contin...</td>\n",
       "      <td>[[[3, 4, OtherScientificTerm], [6, 7, Task], [...</td>\n",
       "      <td>[[0, [[[3, 4], [18, 19], 'USED-FOR'], [[3, 4],...</td>\n",
       "      <td>[[[12, 13, OtherScientificTerm], [26, 26, Gene...</td>\n",
       "      <td>[[0, []], [1, [[[60, 61], [63, 66], 'CONJUNCTI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939</td>\n",
       "      <td>[[Existing, Multi, -, Task, Learning(MTL, ), s...</td>\n",
       "      <td>[[[1, 6, Method], [8, 12, Method], [16, 17, Me...</td>\n",
       "      <td>[[0, [[[16, 17], [1, 6], 'USED-FOR'], [[8, 12]...</td>\n",
       "      <td>[[[3, 9, Method], [23, 24, Method]], [[26, 26,...</td>\n",
       "      <td>[[0, []], [1, [[[39, 40], [26, 26], 'PART-OF']...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP:a1e2218e6943bf138aeb359e23628676b396ed66</td>\n",
       "      <td>[[This, paper, deals, with, the, fuel, optimiz...</td>\n",
       "      <td>[[[5, 7, Task], [9, 11, Task], [13, 15, Method...</td>\n",
       "      <td>[[0, [[[5, 7], [9, 11], 'USED-FOR'], [[13, 15]...</td>\n",
       "      <td>[[[0, 2, Method], [5, 6, Method], [17, 17, Gen...</td>\n",
       "      <td>[[0, [[[5, 6], [0, 2], 'USED-FOR']]], [1, [[[5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66</td>\n",
       "      <td>[[Our, work, is, concerned, with, the, generat...</td>\n",
       "      <td>[[[6, 11, Task], [11, 11, Material], [16, 17, ...</td>\n",
       "      <td>[[0, [[[11, 11], [16, 17], 'HYPONYM-OF']]], [1...</td>\n",
       "      <td>[[[7, 9, Method], [11, 12, Material], [19, 23,...</td>\n",
       "      <td>[[0, [[[7, 9], [19, 23], 'USED-FOR'], [[11, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8018</th>\n",
       "      <td>SP:77d59e1e726172184249bdfdd81011617dc9c208</td>\n",
       "      <td>[[Quantum, machine, learning, methods, have, t...</td>\n",
       "      <td>[[[0, 3, Method], [9, 9, Task]], [[22, 24, Met...</td>\n",
       "      <td>[[0, [[[0, 3], [9, 9], 'USED-FOR']]], [1, []],...</td>\n",
       "      <td>[[[5, 7, Method], [22, 26, Task]], [[31, 31, G...</td>\n",
       "      <td>[[0, []], [1, [[[41, 42], [37, 38], 'USED-FOR'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8019</th>\n",
       "      <td>SP:e58dc2d21175a62499405b7f4c3a03b135530838</td>\n",
       "      <td>[[Trained, generative, models, have, shown, re...</td>\n",
       "      <td>[[[1, 2, Method], [8, 8, Generic], [10, 13, Ta...</td>\n",
       "      <td>[[0, [[[1, 2], [8, 8], 'USED-FOR'], [[8, 8], [...</td>\n",
       "      <td>[[[0, 3, Method], [9, 11, OtherScientificTerm]...</td>\n",
       "      <td>[[0, [[[23, 24], [26, 27], 'CONJUNCTION'], [[2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8020</th>\n",
       "      <td>SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695</td>\n",
       "      <td>[[Discovering, the, underlying, mathematical, ...</td>\n",
       "      <td>[[[3, 4, OtherScientificTerm], [13, 14, Task]]...</td>\n",
       "      <td>[[0, []], [1, []], [2, [[[36, 38], [40, 41], '...</td>\n",
       "      <td>[[[2, 5, OtherScientificTerm], [8, 9, Task], [...</td>\n",
       "      <td>[[0, [[[2, 5], [8, 9], 'PART-OF']]], [1, [[[19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8021</th>\n",
       "      <td>SP:4706017e6f8b958c7d0825fed98b285ea2994b59</td>\n",
       "      <td>[[Some, conventional, transforms, such, as, Di...</td>\n",
       "      <td>[[[2, 2, Generic], [5, 12, Method], [14, 19, M...</td>\n",
       "      <td>[[0, [[[5, 12], [14, 19], 'CONJUNCTION'], [[2,...</td>\n",
       "      <td>[[[1, 6, Method], [72, 72, Metric], [75, 75, G...</td>\n",
       "      <td>[[0, [[[78, 79], [95, 96], 'CONJUNCTION'], [[7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8022</th>\n",
       "      <td>SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb</td>\n",
       "      <td>[[Thanks, to, graph, neural, networks, (, GNNs...</td>\n",
       "      <td>[[[2, 7, Method], [9, 13, Method], [26, 27, Ma...</td>\n",
       "      <td>[[0, [[[2, 7], [9, 13], 'USED-FOR'], [[26, 27]...</td>\n",
       "      <td>[[[0, 1, OtherScientificTerm], [5, 6, OtherSci...</td>\n",
       "      <td>[[0, []], [1, [[[49, 49], [43, 45], 'HYPONYM-O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8023 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          doc_key   \n",
       "0     SP:4d08cdb2de2044bcb574a425b42963b83fbebfbc  \\\n",
       "1     SP:b80bc890180934092cde037b49d94d6e4e06fad9   \n",
       "2     SP:09f2fe6a482bbd6f9bd2c62aa841f995171ba939   \n",
       "3     SP:a1e2218e6943bf138aeb359e23628676b396ed66   \n",
       "4     SP:43e525fb3fa611df7fd44bd3bc9843e57b154c66   \n",
       "...                                           ...   \n",
       "8018  SP:77d59e1e726172184249bdfdd81011617dc9c208   \n",
       "8019  SP:e58dc2d21175a62499405b7f4c3a03b135530838   \n",
       "8020  SP:0d872fb4321f3a4a3fc61cf4d33b0c7e33f2d695   \n",
       "8021  SP:4706017e6f8b958c7d0825fed98b285ea2994b59   \n",
       "8022  SP:63ad3be1dae7ede5c02a847304072c1cbc91b1cb   \n",
       "\n",
       "                                              sentences   \n",
       "0     [[We, study, the, average, CVloo, stability, o...  \\\n",
       "1     [[The, use, of, episodic, memories, in, contin...   \n",
       "2     [[Existing, Multi, -, Task, Learning(MTL, ), s...   \n",
       "3     [[This, paper, deals, with, the, fuel, optimiz...   \n",
       "4     [[Our, work, is, concerned, with, the, generat...   \n",
       "...                                                 ...   \n",
       "8018  [[Quantum, machine, learning, methods, have, t...   \n",
       "8019  [[Trained, generative, models, have, shown, re...   \n",
       "8020  [[Discovering, the, underlying, mathematical, ...   \n",
       "8021  [[Some, conventional, transforms, such, as, Di...   \n",
       "8022  [[Thanks, to, graph, neural, networks, (, GNNs...   \n",
       "\n",
       "                                           abstract_ner   \n",
       "0     [[[3, 5, Metric], [7, 11, Method], [15, 16, Ot...  \\\n",
       "1     [[[3, 4, OtherScientificTerm], [6, 7, Task], [...   \n",
       "2     [[[1, 6, Method], [8, 12, Method], [16, 17, Me...   \n",
       "3     [[[5, 7, Task], [9, 11, Task], [13, 15, Method...   \n",
       "4     [[[6, 11, Task], [11, 11, Material], [16, 17, ...   \n",
       "...                                                 ...   \n",
       "8018  [[[0, 3, Method], [9, 9, Task]], [[22, 24, Met...   \n",
       "8019  [[[1, 2, Method], [8, 8, Generic], [10, 13, Ta...   \n",
       "8020  [[[3, 4, OtherScientificTerm], [13, 14, Task]]...   \n",
       "8021  [[[2, 2, Generic], [5, 12, Method], [14, 19, M...   \n",
       "8022  [[[2, 7, Method], [9, 13, Method], [26, 27, Ma...   \n",
       "\n",
       "                                           abstract_rel   \n",
       "0     [[0, [[[3, 5], [7, 11], 'FEATURE-OF']]], [1, [...  \\\n",
       "1     [[0, [[[3, 4], [18, 19], 'USED-FOR'], [[3, 4],...   \n",
       "2     [[0, [[[16, 17], [1, 6], 'USED-FOR'], [[8, 12]...   \n",
       "3     [[0, [[[5, 7], [9, 11], 'USED-FOR'], [[13, 15]...   \n",
       "4     [[0, [[[11, 11], [16, 17], 'HYPONYM-OF']]], [1...   \n",
       "...                                                 ...   \n",
       "8018  [[0, [[[0, 3], [9, 9], 'USED-FOR']]], [1, []],...   \n",
       "8019  [[0, [[[1, 2], [8, 8], 'USED-FOR'], [[8, 8], [...   \n",
       "8020  [[0, []], [1, []], [2, [[[36, 38], [40, 41], '...   \n",
       "8021  [[0, [[[5, 12], [14, 19], 'CONJUNCTION'], [[2,...   \n",
       "8022  [[0, [[[2, 7], [9, 13], 'USED-FOR'], [[26, 27]...   \n",
       "\n",
       "                                       introduction_ner   \n",
       "0     [[[0, 2, Method], [8, 10, Method], [22, 23, Ma...  \\\n",
       "1     [[[12, 13, OtherScientificTerm], [26, 26, Gene...   \n",
       "2     [[[3, 9, Method], [23, 24, Method]], [[26, 26,...   \n",
       "3     [[[0, 2, Method], [5, 6, Method], [17, 17, Gen...   \n",
       "4     [[[7, 9, Method], [11, 12, Material], [19, 23,...   \n",
       "...                                                 ...   \n",
       "8018  [[[5, 7, Method], [22, 26, Task]], [[31, 31, G...   \n",
       "8019  [[[0, 3, Method], [9, 11, OtherScientificTerm]...   \n",
       "8020  [[[2, 5, OtherScientificTerm], [8, 9, Task], [...   \n",
       "8021  [[[1, 6, Method], [72, 72, Metric], [75, 75, G...   \n",
       "8022  [[[0, 1, OtherScientificTerm], [5, 6, OtherSci...   \n",
       "\n",
       "                                       introduction_rel  \n",
       "0     [[0, [[[0, 2], [8, 10], 'USED-FOR']]], [1, [[[...  \n",
       "1     [[0, []], [1, [[[60, 61], [63, 66], 'CONJUNCTI...  \n",
       "2     [[0, []], [1, [[[39, 40], [26, 26], 'PART-OF']...  \n",
       "3     [[0, [[[5, 6], [0, 2], 'USED-FOR']]], [1, [[[5...  \n",
       "4     [[0, [[[7, 9], [19, 23], 'USED-FOR'], [[11, 12...  \n",
       "...                                                 ...  \n",
       "8018  [[0, []], [1, [[[41, 42], [37, 38], 'USED-FOR'...  \n",
       "8019  [[0, [[[23, 24], [26, 27], 'CONJUNCTION'], [[2...  \n",
       "8020  [[0, [[[2, 5], [8, 9], 'PART-OF']]], [1, [[[19...  \n",
       "8021  [[0, [[[78, 79], [95, 96], 'CONJUNCTION'], [[7...  \n",
       "8022  [[0, []], [1, [[[49, 49], [43, 45], 'HYPONYM-O...  \n",
       "\n",
       "[8023 rows x 6 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "796a6935-6d61-414c-af04-b044d35a0619",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8379, 1060)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg_ax_train = get_KGdata(args, \"train\", \"abstract\")\n",
    "kg_ax_val = get_KGdata(args, \"val\", \"abstract\")\n",
    "len(kg_ax_train), len(kg_ax_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "51cc40ae-07aa-49f0-93d9-2cd7cb317bd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def manage_confilt_ent(ent_list):\n",
    "    count_ent = {}\n",
    "    for ent_type in ENT_TYPES: count_ent[ent_type] = 0\n",
    "    for ent in ent_list: count_ent[ent] += 1\n",
    "    return max(count_ent, key=count_ent.get)\n",
    "\n",
    "def count_list(input_list):\n",
    "    count_dict = {}\n",
    "    for ele in input_list:\n",
    "        if ele in count_dict.keys(): count_dict[ele] += 1\n",
    "        else: count_dict[ele] = 1\n",
    "    return count_dict\n",
    "    \n",
    "def build_graph(data):\n",
    "    flatten_sent = [j for i in data[\"sentences\"] for j in i]\n",
    "    flatten_ner  = [j for i in data[\"predicted_ner\"] for j in i]\n",
    "    flatten_re   = [j for i in data[\"predicted_re\"] for j in i[1]]\n",
    "    # print(\" \".join(flatten_sent))\n",
    "    \n",
    "    ent_type_dict = {}\n",
    "    for ner in flatten_ner:\n",
    "        ent = \" \".join(flatten_sent[ner[0]:ner[1]+1])\n",
    "        if ent not in ent_type_dict.keys():\n",
    "            ent_type_dict[ent] = [ner[2]]\n",
    "        else:\n",
    "            ent_type_dict[ent].append(ner[2])\n",
    "    for ent, ent_type in ent_type_dict.items():\n",
    "        if len(set(ent_type))>1:\n",
    "            ent_type_dict[ent] = manage_confilt_ent(ent_type)\n",
    "        else:\n",
    "            ent_type_dict[ent] = ent_type[0]\n",
    "    \n",
    "    triple_list = []\n",
    "    for rel in flatten_re:\n",
    "        sub = \" \".join(flatten_sent[rel[0][0]:rel[0][1]+1])\n",
    "        obj = \" \".join(flatten_sent[rel[1][0]:rel[1][1]+1])\n",
    "        triple_list.append({\n",
    "            'subject':  \" \".join(flatten_sent[rel[0][0]:rel[0][1]+1]),\n",
    "            'relation': rel[2],\n",
    "            'object':   \" \".join(flatten_sent[rel[1][0]:rel[1][1]+1]),\n",
    "        })\n",
    "    return ent_type_dict, triple_list\n",
    "\n",
    "def add_entType(ent, ent_type):\n",
    "    return f\"[{ent_type}] {ent} [/{ent_type}]\"\n",
    "\n",
    "def graph2seq(ent_type_dict, triple_list, is_add_entType=True):\n",
    "    seq = \"\"\n",
    "    triple_df = pd.DataFrame(triple_list)\n",
    "    triple_ent = []\n",
    "    \n",
    "    while len(triple_df)!=0:\n",
    "        count = count_list(list(triple_df['subject']))\n",
    "        sub = max(count, key=count.get)\n",
    "        sub_seq = add_entType(sub, ent_type_dict[sub]) if is_add_entType else sub\n",
    "        seq += f\"{sub_seq} \"            \n",
    "            \n",
    "        rel_obj = {}\n",
    "        for _, row in triple_df[triple_df['subject']==sub].iterrows():\n",
    "            triple_ent += [row['subject'], row['object']]\n",
    "            rel = row['relation']\n",
    "            obj_seq = add_entType(row['object'], ent_type_dict[row['object']]) if is_add_entType else row['object']\n",
    "            if rel not in rel_obj.keys():\n",
    "                rel_obj[rel] = [obj_seq]\n",
    "            else:\n",
    "                rel_obj[rel].append(obj_seq)\n",
    "            triple_df.drop(_, inplace=True)\n",
    "        seq += ', '.join([f\"[{rel}] {','.join(objs)}\" for rel, objs in rel_obj.items()])\n",
    "        seq += '. '\n",
    "    free_ent = list(set(ent_type_dict)-set(triple_ent))\n",
    "    if is_add_entType: free_ent = [add_entType(ent, ent_type_dict[ent]) for ent in free_ent]\n",
    "    if len(free_ent)>0:\n",
    "        seq += '/n'\n",
    "        seq += ', '.join(free_ent)\n",
    "        seq += '.'\n",
    "\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "5f92ef1d-7d02-4703-85b3-c53ca3adbeac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================] 6436/6436\n"
     ]
    }
   ],
   "source": [
    "prepro_data = []\n",
    "for i, doc in enumerate(kg_ax_val):\n",
    "    print_progress(i, len(kg_ax_val), desc='', bar_size=30)\n",
    "    ent_type_dict, triple_list = build_graph(doc)\n",
    "    seq = graph2seq(ent_type_dict, triple_list)\n",
    "    prepro_data.append({\n",
    "        'doc_key': doc['doc_key'],\n",
    "        'input_seq': seq\n",
    "    })\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "93d89d4c-bb2e-4f33-8a75-69eae3380114",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'16 site cluster',\n",
       " 'anomalous finite size effects',\n",
       " 'calculations',\n",
       " 'cluster',\n",
       " 'nel type order',\n",
       " 'nonlinear sigma model analogy',\n",
       " 'nonmagnetic region'}"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_set =set(pd.DataFrame(triple_list)['subject'])\n",
    "obj_set = set(pd.DataFrame(triple_list)['object'])\n",
    "print(len(sub_set.union(obj_set)))\n",
    "print(len(set(ent_type_dict)))\n",
    "free_set = set(ent_type_dict) - (sub_set.union(obj_set))\n",
    "free_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "bffb9955-ed31-4694-b025-5ed2ecb101b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_key</th>\n",
       "      <th>sentences</th>\n",
       "      <th>ner</th>\n",
       "      <th>relations</th>\n",
       "      <th>predicted_ner</th>\n",
       "      <th>predicted_re</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0708.1996</td>\n",
       "      <td>[[ , we, study, the, phase, behavior, of, a, n...</td>\n",
       "      <td>[[], [], [], [], [], []]</td>\n",
       "      <td>[[], [], [], [], [], []]</td>\n",
       "      <td>[[[4, 5, Task], [8, 10, OtherScientificTerm], ...</td>\n",
       "      <td>[[0, [[[4, 5], [8, 10], 'FEATURE-OF'], [[17, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0709.1158</td>\n",
       "      <td>[[ , determining, the, scaling, relations, bet...</td>\n",
       "      <td>[[], [], [], [], [], [], [], [], []]</td>\n",
       "      <td>[[], [], [], [], [], [], [], [], []]</td>\n",
       "      <td>[[[3, 4, OtherScientificTerm], [6, 8, OtherSci...</td>\n",
       "      <td>[[0, [[[3, 4], [6, 8], 'FEATURE-OF'], [[13, 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1112.4795</td>\n",
       "      <td>[[ , we, show, how, to, control, spatial, quan...</td>\n",
       "      <td>[[], [], []]</td>\n",
       "      <td>[[], [], []]</td>\n",
       "      <td>[[[6, 8, OtherScientificTerm], [11, 17, Method...</td>\n",
       "      <td>[[0, [[[6, 8], [11, 17], 'FEATURE-OF'], [[30, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1012.5771</td>\n",
       "      <td>[[ , class,  , i, methanol, masers, are, belie...</td>\n",
       "      <td>[[], [], [], [], [], [], [], [], [], []]</td>\n",
       "      <td>[[], [], [], [], [], [], [], [], [], []]</td>\n",
       "      <td>[[[1, 5, OtherScientificTerm], [13, 16, OtherS...</td>\n",
       "      <td>[[0, [[[13, 16], [18, 21], 'FEATURE-OF'], [[13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1601.06075</td>\n",
       "      <td>[[ , nowadays, ,, scientific, challenges, usua...</td>\n",
       "      <td>[[], [], [], [], []]</td>\n",
       "      <td>[[], [], [], [], []]</td>\n",
       "      <td>[[[3, 4, Task], [7, 7, Generic], [20, 20, Othe...</td>\n",
       "      <td>[[0, [[[7, 7], [3, 4], 'USED-FOR']]], [1, [[[4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>hep-th0504088</td>\n",
       "      <td>[[ , we, give, a, formal, proof, that, the, sp...</td>\n",
       "      <td>[[], [], [], [], []]</td>\n",
       "      <td>[[], [], [], [], []]</td>\n",
       "      <td>[[[8, 11, OtherScientificTerm], [14, 15, Other...</td>\n",
       "      <td>[[0, [[[8, 11], [14, 15], 'FEATURE-OF'], [[46,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6432</th>\n",
       "      <td>1505.07898</td>\n",
       "      <td>[[ , we, consider, here, the, effects, of, ine...</td>\n",
       "      <td>[[], [], [], [], [], [], []]</td>\n",
       "      <td>[[], [], [], [], [], [], []]</td>\n",
       "      <td>[[[7, 7, OtherScientificTerm], [10, 10, Task],...</td>\n",
       "      <td>[[0, [[[7, 7], [10, 10], 'USED-FOR'], [[25, 28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6433</th>\n",
       "      <td>1607.05481</td>\n",
       "      <td>[[ , we, introduce, an, orbital, -, optimized,...</td>\n",
       "      <td>[[], [], [], [], []]</td>\n",
       "      <td>[[], [], [], [], []]</td>\n",
       "      <td>[[], [[28, 28, OtherScientificTerm], [33, 34, ...</td>\n",
       "      <td>[[1, [[[33, 34], [39, 43], 'USED-FOR'], [[33, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6434</th>\n",
       "      <td>1703.05742</td>\n",
       "      <td>[[ , we, have, been, developing, optical, reso...</td>\n",
       "      <td>[[], [], [], []]</td>\n",
       "      <td>[[], [], [], []]</td>\n",
       "      <td>[[[5, 7, Method], [9, 13, Task]], [[32, 34, Ot...</td>\n",
       "      <td>[[0, [[[5, 7], [9, 13], 'USED-FOR']]], [1, []]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6435</th>\n",
       "      <td>cond-mat9402061</td>\n",
       "      <td>[[ , we, have, performed, a, numerical, invest...</td>\n",
       "      <td>[[], [], [], [], [], [], [], [], [], [], []]</td>\n",
       "      <td>[[], [], [], [], [], [], [], [], [], [], []]</td>\n",
       "      <td>[[[9, 11, Task], [14, 17, Method], [20, 21, Ma...</td>\n",
       "      <td>[[0, [[[9, 11], [14, 17], 'FEATURE-OF'], [[20,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6436 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              doc_key                                          sentences  \\\n",
       "0           0708.1996  [[ , we, study, the, phase, behavior, of, a, n...   \n",
       "1           0709.1158  [[ , determining, the, scaling, relations, bet...   \n",
       "2           1112.4795  [[ , we, show, how, to, control, spatial, quan...   \n",
       "3           1012.5771  [[ , class,  , i, methanol, masers, are, belie...   \n",
       "4          1601.06075  [[ , nowadays, ,, scientific, challenges, usua...   \n",
       "...               ...                                                ...   \n",
       "6431    hep-th0504088  [[ , we, give, a, formal, proof, that, the, sp...   \n",
       "6432       1505.07898  [[ , we, consider, here, the, effects, of, ine...   \n",
       "6433       1607.05481  [[ , we, introduce, an, orbital, -, optimized,...   \n",
       "6434       1703.05742  [[ , we, have, been, developing, optical, reso...   \n",
       "6435  cond-mat9402061  [[ , we, have, performed, a, numerical, invest...   \n",
       "\n",
       "                                               ner  \\\n",
       "0                         [[], [], [], [], [], []]   \n",
       "1             [[], [], [], [], [], [], [], [], []]   \n",
       "2                                     [[], [], []]   \n",
       "3         [[], [], [], [], [], [], [], [], [], []]   \n",
       "4                             [[], [], [], [], []]   \n",
       "...                                            ...   \n",
       "6431                          [[], [], [], [], []]   \n",
       "6432                  [[], [], [], [], [], [], []]   \n",
       "6433                          [[], [], [], [], []]   \n",
       "6434                              [[], [], [], []]   \n",
       "6435  [[], [], [], [], [], [], [], [], [], [], []]   \n",
       "\n",
       "                                         relations  \\\n",
       "0                         [[], [], [], [], [], []]   \n",
       "1             [[], [], [], [], [], [], [], [], []]   \n",
       "2                                     [[], [], []]   \n",
       "3         [[], [], [], [], [], [], [], [], [], []]   \n",
       "4                             [[], [], [], [], []]   \n",
       "...                                            ...   \n",
       "6431                          [[], [], [], [], []]   \n",
       "6432                  [[], [], [], [], [], [], []]   \n",
       "6433                          [[], [], [], [], []]   \n",
       "6434                              [[], [], [], []]   \n",
       "6435  [[], [], [], [], [], [], [], [], [], [], []]   \n",
       "\n",
       "                                          predicted_ner  \\\n",
       "0     [[[4, 5, Task], [8, 10, OtherScientificTerm], ...   \n",
       "1     [[[3, 4, OtherScientificTerm], [6, 8, OtherSci...   \n",
       "2     [[[6, 8, OtherScientificTerm], [11, 17, Method...   \n",
       "3     [[[1, 5, OtherScientificTerm], [13, 16, OtherS...   \n",
       "4     [[[3, 4, Task], [7, 7, Generic], [20, 20, Othe...   \n",
       "...                                                 ...   \n",
       "6431  [[[8, 11, OtherScientificTerm], [14, 15, Other...   \n",
       "6432  [[[7, 7, OtherScientificTerm], [10, 10, Task],...   \n",
       "6433  [[], [[28, 28, OtherScientificTerm], [33, 34, ...   \n",
       "6434  [[[5, 7, Method], [9, 13, Task]], [[32, 34, Ot...   \n",
       "6435  [[[9, 11, Task], [14, 17, Method], [20, 21, Ma...   \n",
       "\n",
       "                                           predicted_re  \n",
       "0     [[0, [[[4, 5], [8, 10], 'FEATURE-OF'], [[17, 1...  \n",
       "1     [[0, [[[3, 4], [6, 8], 'FEATURE-OF'], [[13, 15...  \n",
       "2     [[0, [[[6, 8], [11, 17], 'FEATURE-OF'], [[30, ...  \n",
       "3     [[0, [[[13, 16], [18, 21], 'FEATURE-OF'], [[13...  \n",
       "4     [[0, [[[7, 7], [3, 4], 'USED-FOR']]], [1, [[[4...  \n",
       "...                                                 ...  \n",
       "6431  [[0, [[[8, 11], [14, 15], 'FEATURE-OF'], [[46,...  \n",
       "6432  [[0, [[[7, 7], [10, 10], 'USED-FOR'], [[25, 28...  \n",
       "6433  [[1, [[[33, 34], [39, 43], 'USED-FOR'], [[33, ...  \n",
       "6434  [[0, [[[5, 7], [9, 13], 'USED-FOR']]], [1, []]...  \n",
       "6435  [[0, [[[9, 11], [14, 17], 'FEATURE-OF'], [[20,...  \n",
       "\n",
       "[6436 rows x 6 columns]"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(kg_ax_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "737aeb5f-c4f0-422c-a7ae-489aa900768e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_key</th>\n",
       "      <th>input_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0708.1996</td>\n",
       "      <td>[OtherScientificTerm] strong anchoring [/Other...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0709.1158</td>\n",
       "      <td>[OtherScientificTerm] scaling relations [/Othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1112.4795</td>\n",
       "      <td>[OtherScientificTerm] spatial quantum correlat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1012.5771</td>\n",
       "      <td>[OtherScientificTerm] shock - excited environm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1601.06075</td>\n",
       "      <td>[Material] physics publications [/Material][CO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>hep-th0504088</td>\n",
       "      <td>[OtherScientificTerm] weak gauge - invariance ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6432</th>\n",
       "      <td>1505.07898</td>\n",
       "      <td>[Method] long wave approximation [/Method][FEA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6433</th>\n",
       "      <td>1607.05481</td>\n",
       "      <td>[OtherScientificTerm] local potential [/OtherS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6434</th>\n",
       "      <td>1703.05742</td>\n",
       "      <td>[Method] optical resonant cavities [/Method][U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6435</th>\n",
       "      <td>cond-mat9402061</td>\n",
       "      <td>[OtherScientificTerm] magnetic order parameter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6436 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              doc_key                                          input_seq\n",
       "0           0708.1996  [OtherScientificTerm] strong anchoring [/Other...\n",
       "1           0709.1158  [OtherScientificTerm] scaling relations [/Othe...\n",
       "2           1112.4795  [OtherScientificTerm] spatial quantum correlat...\n",
       "3           1012.5771  [OtherScientificTerm] shock - excited environm...\n",
       "4          1601.06075  [Material] physics publications [/Material][CO...\n",
       "...               ...                                                ...\n",
       "6431    hep-th0504088  [OtherScientificTerm] weak gauge - invariance ...\n",
       "6432       1505.07898  [Method] long wave approximation [/Method][FEA...\n",
       "6433       1607.05481  [OtherScientificTerm] local potential [/OtherS...\n",
       "6434       1703.05742  [Method] optical resonant cavities [/Method][U...\n",
       "6435  cond-mat9402061  [OtherScientificTerm] magnetic order parameter...\n",
       "\n",
       "[6436 rows x 2 columns]"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(prepro_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "e826ad7b-4210-44de-ac51-c69f37969655",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Material] physics publications [/Material][CONJUNCTION] [Material] us patents [/Material], [FEATURE-OF] [Generic] data [/Generic].[Generic] method [/Generic][USED-FOR] [Task] hiring and funding purposes [/Task], [COMPARE] [Generic] methods [/Generic].[Generic] approaches [/Generic][USED-FOR] [Task] scientific challenges [/Task].[OtherScientificTerm] interdisciplinarity [/OtherScientificTerm][FEATURE-OF] [OtherScientificTerm] research impact [/OtherScientificTerm].[OtherScientificTerm] bipartite interconnected multilayer networks of citations and disciplines [/OtherScientificTerm][USED-FOR] [Generic] method [/Generic].[Generic] data [/Generic][USED-FOR] [Generic] method [/Generic].[Material] us patents [/Material][FEATURE-OF] [Generic] data [/Generic].[Method] quantitative approach [/Method][USED-FOR] [Generic] method [/Generic].\n"
     ]
    }
   ],
   "source": [
    "ent_type_dict, triple_list = build_graph(kg_ax_val[4])\n",
    "seq = graph2seq(ent_type_dict, triple_list)\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "38c6d754-e501-4549-bca0-356264e3d2cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '[Material]', 'Ġphysics', 'Ġpublications', '[/Material]', '[CONJUNCTION]', '[Material]', 'Ġus', 'Ġpatents', '[/Material]', ',', '[FEATURE-OF]', '[Generic]', 'Ġdata', '[/Generic]', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(tokenizer.encode(seq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "3391f048-d88e-4a3c-ba5d-66b450e81941",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>relation</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>approaches</td>\n",
       "      <td>USED-FOR</td>\n",
       "      <td>scientific challenges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>interdisciplinarity</td>\n",
       "      <td>FEATURE-OF</td>\n",
       "      <td>research impact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bipartite interconnected multilayer networks o...</td>\n",
       "      <td>USED-FOR</td>\n",
       "      <td>method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>physics publications</td>\n",
       "      <td>CONJUNCTION</td>\n",
       "      <td>us patents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data</td>\n",
       "      <td>USED-FOR</td>\n",
       "      <td>method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>physics publications</td>\n",
       "      <td>FEATURE-OF</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>us patents</td>\n",
       "      <td>FEATURE-OF</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>quantitative approach</td>\n",
       "      <td>USED-FOR</td>\n",
       "      <td>method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>method</td>\n",
       "      <td>USED-FOR</td>\n",
       "      <td>hiring and funding purposes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>method</td>\n",
       "      <td>COMPARE</td>\n",
       "      <td>methods</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             subject     relation  \\\n",
       "0                                         approaches     USED-FOR   \n",
       "1                                interdisciplinarity   FEATURE-OF   \n",
       "2  bipartite interconnected multilayer networks o...     USED-FOR   \n",
       "3                               physics publications  CONJUNCTION   \n",
       "4                                               data     USED-FOR   \n",
       "5                               physics publications   FEATURE-OF   \n",
       "6                                         us patents   FEATURE-OF   \n",
       "7                              quantitative approach     USED-FOR   \n",
       "8                                             method     USED-FOR   \n",
       "9                                             method      COMPARE   \n",
       "\n",
       "                        object  \n",
       "0        scientific challenges  \n",
       "1              research impact  \n",
       "2                       method  \n",
       "3                   us patents  \n",
       "4                       method  \n",
       "5                         data  \n",
       "6                         data  \n",
       "7                       method  \n",
       "8  hiring and funding purposes  \n",
       "9                      methods  "
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(triple_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "f756ea0d-a6f2-49e2-8d93-e23a5fc688f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CONJUNCTION': 1, 'FEATURE-OF': 1}\n",
      "{'FEATURE-OF': 1}\n",
      "{'FEATURE-OF': 1}\n",
      "{'FEATURE-OF': 2}\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for idx, ele in enumerate(kg_ax_val):\n",
    "    ent_type_dict, triple_list = build_graph(ele)\n",
    "    # print(graph2seq(ent_type_dict, triple_list))\n",
    "    # break\n",
    "    if graph2seq(ent_type_dict, triple_list)>1:\n",
    "        print(idx)\n",
    "        break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b1ad0c5d-dd96-4b29-be99-d5a0772ed61d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physics publications\n",
      "FEATURE-OF\n",
      "CONJUNCTION\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[Material] physics publications [/Material]'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_type_dict, triple_list = build_graph(kg_ax_val[4])\n",
    "graph2seq(ent_type_dict, triple_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9810d3b9-b5aa-43a8-9ac4-6c50d3dcf27f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase behavior (Task) \tFEATURE-OF \tnematic liquid crystal (Othe)\n",
      "strong anchoring (Othe) \tCONJUNCTION \tpatterned substrate (Othe)\n",
      "patterned substrate (Othe) \tFEATURE-OF \tnematic liquid crystal (Othe)\n",
      "strong anchoring (Othe) \tFEATURE-OF \tflat substrate (Mate)\n",
      "flat substrate (Mate) \tFEATURE-OF \tnematic liquid crystal (Othe)\n",
      "expression (Gene) \tUSED-FOR \teffective free energy (Othe)\n",
      "effective free energy (Othe) \tFEATURE-OF \tconfined nematic liquid crystal (Othe)\n",
      "effective surface free energy function (Othe) \tUSED-FOR \tpatterned substrate (Othe)\n",
      "effective surface free energy function (Othe) \tUSED-FOR \texpression (Gene)\n",
      "homogeneous state (Othe) \tCONJUNCTION \thybrid aligned nematic state (Othe)\n",
      "nematic director (Othe) \tFEATURE-OF \thomogeneous state (Othe)\n",
      "homogeneous state (Othe) \tPART-OF \tphase diagrams (Othe)\n",
      "hybrid aligned nematic state (Othe) \tPART-OF \tphase diagrams (Othe)\n",
      "effective energy method (Meth) \tUSED-FOR \tenergy barriers (Othe)\n"
     ]
    }
   ],
   "source": [
    "for val in (kg_ax_val):\n",
    "    build_graph(val)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9061eb5f-5c48-4a3e-8cf3-7d1f8eda98ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'phase behavior': 'Task',\n",
       " 'nematic liquid crystal': 'OtherScientificTerm',\n",
       " 'flat substrate': 'Material',\n",
       " 'strong anchoring': 'OtherScientificTerm',\n",
       " 'patterned substrate': 'OtherScientificTerm',\n",
       " 'local anchoring strength': 'OtherScientificTerm',\n",
       " 'effective surface free energy function': 'OtherScientificTerm',\n",
       " 'expression': 'Generic',\n",
       " 'effective free energy': 'OtherScientificTerm',\n",
       " 'confined nematic liquid crystal': 'OtherScientificTerm',\n",
       " 'phase diagrams': 'OtherScientificTerm',\n",
       " 'homogeneous state': 'OtherScientificTerm',\n",
       " 'nematic director': 'OtherScientificTerm',\n",
       " 'hybrid aligned nematic state': 'OtherScientificTerm',\n",
       " 'free energy functional': 'OtherScientificTerm',\n",
       " 'effective free energy method': 'Method',\n",
       " 'phase boundaries': 'OtherScientificTerm',\n",
       " 'effective energy method': 'Method',\n",
       " 'energy barriers': 'OtherScientificTerm',\n",
       " 'bistable nematic device': 'Method'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_graph(kg_ax_val[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e270b6-7ccf-448e-8428-414c92375240",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "90b2dac5-9dd2-43ac-b224-991e0d8f2d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "3f118df1-b674-4b07-b68f-13d7eb109a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50265"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "8b2f08d9-61e7-441e-880b-fcb389d0b550",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[FEATURE-OF]', '[PART-OF]', '[USED-FOR]', '[EVALUATE-FOR]', '[HYPONYM-OF]', '[COMPARE]', '[CONJUNCTION]']\n"
     ]
    }
   ],
   "source": [
    "spacial_tokens = (REL_TYPE_TOKENS)\n",
    "print(spacial_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "9dcbd633-692c-4201-b882-41823a4c94b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50266"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens('[?]')\n",
    "# tokenizer.add_tokens(ENT_TYPE_TOKENS)\n",
    "# tokenizer.add_tokens(REL_TYPE_TOKENS)\n",
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "d1c40a71-3578-47f6-a942-ff7af2ae6f87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ġ',\n",
       " 'ou',\n",
       " 'ai',\n",
       " 'Ġnamed',\n",
       " 'Ġfriend',\n",
       " 'ĠNov',\n",
       " 'Ġdefense',\n",
       " 'ĠBritain',\n",
       " 'Ġentire',\n",
       " 'Ġtrading',\n",
       " 'Ġfailed',\n",
       " 'ĠEl',\n",
       " 'Ġclaims',\n",
       " 'Ġcomments',\n",
       " 'Ġbeat',\n",
       " 'ib',\n",
       " 'Ġbasis',\n",
       " 'ĠJones',\n",
       " 'Ġpresent',\n",
       " 'ĠBe']"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = 1437\n",
    "tokenizer.convert_tokens_to_ids('Ġ')\n",
    "tokenizer.convert_ids_to_tokens(range(ids,ids+20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
