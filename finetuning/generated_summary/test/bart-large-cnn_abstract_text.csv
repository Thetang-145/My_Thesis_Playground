paper_id,summary
SP:b19df5243359791fbaad005d6f13d7e9fdb0ff63,"This paper proposes a new approach for multi-agent role-based learning. The proposed approach first decomposes joint action spaces into restricted role action spaces by clustering actions according to their effects on the environment and other agents. Then, the role selector searches in a smaller role space and at a lower temporal resolution, while the role policies learn in significantly reduced primitive action-observation spaces. Finally, the proposed approach is evaluated on 9 of the 14 scenarios that comprise the challenging StarCraft II micromanagement benchmark."
SP:7deb61890d97422a0fe141ca807f968c70ab239a,"This paper studies the stochastic subgradient descent (SSGD) method applied to over-parameterized nonsmooth optimization problems that satisfy an interpolation condition. By leveraging the composite structure of the empirical risk minimization problems, the authors prove that SSGD converges, respectively, with rates O(1/ ) and O(log(1 / ) for convex and strongly-convex objectives when interpolation holds. These rates coincide with established rates for the SGD method. The analysis provides a partial explanation for the empirical observation that sometimes SGD and SSGD behave similarly for training smooth and nonsmoothed machine learning models."
SP:c7e0b3fedc0d0409d662dd612b529fdacad2b03e,"This paper proposes to use non-linear ""reservoir"" layers to replace regular transformer layers in machine translation and masked language modelling tasks. The authors show that the proposed method can improve the wall-clock compute time until convergence, as well as the overall performance on various machine translation tasks. "
SP:ba9f1d4738ec67a440346f3ac6c4cf35f7232077,This paper studies the connection between filter transform and group representation theory in steerable CNN. The authors show that filter transformed kernels can be used to convolve input/output features in different group representations. This interpretation helps complete the puzzle of steerable convolution theory and provides a novel and simple approach to implement steerable operators. Experiments on multiple datasets validate the effectiveness of the proposed approach.
SP:c1116fbb4d058eb6be195b5d13d19a55ba86b602,"This paper studies the problem of multimodal program synthesis where the goal is to find a program that satisfies user-provided constraints while also maximizing the program’s score with respect to a neural model. Specifically, the authors propose a top-down recurrent neural model that places distributions over abstract syntax trees conditioned on the NL input. This model not only allows for efficient search over the space of syntactically valid programs, but it also allows to leverage automated program analysis techniques for pruning the search space based on infeasibility of partial programs. The experimental results show that the proposed method substantially outperforms prior state-of-the-art techniques in terms of accuracy and explores fewer states during search."
SP:55e02d79146bbb42f1ab6d4fafa2db5ddbe599b0,"This paper proposes a method to predict the specificity landscape of a protein using a protein graph convolutional neural network (PGCN) based on the structure-based molecular interaction graph generated using the Rosetta energy function that describes the topology and energetic features, to determine the substrate specificity landscape. The proposed method is evaluated on the Hepatitic C virus and shows that the proposed method outperforms existing methods on classification tasks."
SP:7727eeb7b17ad94ddfa0cf24e64a9626d83a8876," has shown that double Q-learning is not fully unbiased and suffers from underestimation bias. In this paper, the authors show that under an approximate Bellman operator, the proposed approach may lead to multiple non-optimal fixed points. To address this issue, they propose an approximate dynamic programming to bound the target value. The proposed approach is evaluated on Atari benchmark tasks and shows significant improvement over baseline algorithms."
SP:1d630b69f95392a5ef3d7d580b523e077a3555a8,"This paper proposes a two-step training framework for deep generative models (DGMs) of high-dimensional natural images. The first step is to generate images in low-frequency bands by training a sampler in the wavelet domain and super-resolve these images back to the pixel-space with a novel wavelet super-resolution decoder network. Wavelet-based down-sampling method preserves more structural information than pixel-based methods, leading to significantly better generative quality of the low-resolution sampler (e.g., 64x64). Since the sampler and decoder can be trained in parallel and operate on much lower dimensional spaces than end-to-end models, the training cost is substantially reduced."
SP:b943a73b1ec34867371325748dc3a91ff4011947,This paper studies self-supervised learning for few-shot learning (FSL). The main contribution of this paper is the analysis of why SSL is suitable for FSL. The authors analyze the main difference between supervised training and self supervised training on FSL and obtain the upper bound for the gap between self supervised loss and supervised loss. They also propose potential ways to improve the test accuracy under the setting of self supervised FSL using the proposed methods. 
SP:bd552f98e6a447cefa6b1a9bbdf40bc6539fb643,"This paper studies the convergence properties of two-layer teacher-student neural networks. The authors prove that under the most basic settings, all student neurons must align with the teacher neuron at any local minima. They extend this result to more general cases, where the proof can be reduced to analyzing the properties of a special class of functions that we call Angular Distance (AD) function. Finally, they demonstrate that these properties can be easily verified numerically."
SP:0f62846913ec10b44ed32845770da0565479dc75,"This paper proposes Deep Adaptive Semantic Logic (DASL), a framework for learning deep neural networks that incorporates user-provided formal knowledge to improve learning from data. The authors provide formal semantics that demonstrate that our knowledge representation captures all of first order logic and that finite sampling from infinite domains converges to correct truth values. DASL’s representation improves on prior neuro-symbolic work by avoiding vanishing gradients, allowing deeper logical structure, and enabling richer interactions between the knowledge and learning components. Experiments on a toy problem and a visual relationship detection task demonstrate that the addition of commonsense knowledge improves performance by 10.7% in conditions of data scarcity."
SP:2f19259d65fab904c1b771244da3dcb2f8aa0c26,"This paper studies the convergence of feedforward residual neural networks (ResNets). The authors show that ResNets can express iterative solutions, but they do not learn them when trained conventionally on computer vision tasks. They then introduce regularizations to encourage iterative convergent computation and test whether this provides a useful inductive bias. To make the networks more iterative, they manipulate the degree of weight sharing across layers using soft gradient coupling. This new method provides a form of recurrence regularization and can interpolate smoothly between an ordinary ResNet and a “recurrent” ResNet (i.e., one that uses identical weights across layers and thus could be physically implemented with a recurrent network computing the successive stages iteratively across time). They also impose a Lipschitz constraint on the residual functions using spectral normalization."
SP:6c14506b8b2b06043409d912e6bf877651aaa665,"This paper proposes two new normalization methods for out-of-distribution (OOD) training. The main idea is to use attention to recalibrate the channel-wise mean and variance, while CrossNorm exchanges the statistics between feature maps. Extensive experiments on different domains (vision and language), tasks (classification and segmentation), and settings (supervised and semi-supervised) show their effectiveness."
SP:2774abdc11917321dd4994af0f0da1ff824bea03, in DeepMind Control Suite. This paper proposes to use a simple attention module in the convolutional encoder of an RL agent. The proposed module can extract interpretable task-relevant information such as agent locations and movements without the need for data augmentations or contrastive losses. Experiments on the widely benchmarked Deepmind Control Suite environments demonstrate the effectiveness of the proposed module.
SP:31a7051d08d19c01e11f1fac2f3041ed2fa28f15,"This paper proposes an extension of the GradNorm algorithm for multi-task learning. In particular, the authors propose Rotograd, an extension to GradNorm that dynamically homogenizes not only the gradient magnitudes but also their directions across tasks. For this purpose, it adds a layer of task-specific rotation matrices that aligns all the task gradients. The authors analyze the algorithm through the lens of game theory and provide theoretical guarantees on the algorithm stability and convergence. The experiments on several real-world datasets and network architectures show that the proposed method outperforms previous approaches for multitask learning."
SP:ac9ebd027b92527d9a87b13ad11d002d99a2b0f6,"This paper proposes a novel I2I translation constraint, called Minimal Geometry-Distortion Constraint (MGC), which promotes the consistency of geometry structures and reduce the unwanted distortions in translation by reducing the randomness of color transformation in the translation process. To facilitate estimation and maximization of MGC, the authors propose an approximate representation of mutual information called relative Squared-loss Mutual Information (rSMI) that can be efficiently estimated analytically. The authors demonstrate the effectiveness of their MGC on several benchmark datasets."
SP:92a38d7d18f07f68b8f93c61180e2cc1dddd21de,"This paper studies the effect of point sampling patterns in point cloud GANs. The authors show that sampling-insensitive discriminators (e.g. PointNet-Max) produce shape point clouds with point clustering artifacts, while sampling-over-sensitive discriminators fail to guide valid shape generation. They propose the concept of sampling spectrum to depict the different sampling sensitivities of discriminators. They further study how different evaluation metrics weigh the sampling pattern against the geometry and propose several perceptual metrics forming a sampling spectrum of metrics. Guided by the proposed sampling spectrum, they discover a middle-point sampling-aware baseline discriminator, Point-Mix, which improves all existing point cloud generators by a large margin on sampling-related metrics."
SP:16c4be3eb162bc81cb3343c2fc115eb8e926a5b5,This paper studies the adversarial robustness of Capsule Networks (CapsNets). The authors propose a novel vote attack where they attack votes of CapsNets directly. The vote attack is not only effective but also efficient by circumventing the routing process. Extensive experiments demonstrate the superior attack performance of the proposed attack method.
SP:dbd093dff7a38ba8882bb8119c34623ddaaf4cc6,"This paper proposes a meta-reinforcement learning algorithm that uses privileged information in the form of a task descriptor at train time to improve the learning of recurrent policies. The proposed method learns an informed policy (i.e., a policy receiving as input the description of the current task) that is used to both construct task embeddings from the descriptors, and to regularize the training of the recurrent policy through parameters sharing and an auxiliary objective. This approach significantly reduces the learning sample complexity without altering the representational power of RNNs, by focusing on the relevant characteristics of the task, and by exploiting them efficiently. "
SP:bd89d254fbf31db61db237d08ab42981e27c52df,"This paper proposes a method to learn an RL policy from offline data in the real-world sequential recommendation system (SRS). Instead of increasing the fidelity of models for policy learning, the authors propose learning to adapt to diverse simulators generated by the offline dataset. Experiments are conducted in synthetic environments and a real world ride-hailing platform to demonstrate the effectiveness of the proposed method."
SP:1a166b28cf684e0d5759bd629f6a53370d2bf11c,"This paper proposes a method to learn goal-reaching policies from scratch, without the need for expert demonstrations or a value function. The main idea is to leverage the property that any trajectory is a successful demonstration for reaching the final state in that same trajectory. The authors propose a simple algorithm in which an agent continually relabels and imitates the trajectories it generates to progressively learn goal reaching behaviors from scratch. Each iteration, the agent collects new trajectories using the latest policy, and maximizes the likelihood of the actions along these trajectories under the goal that was actually reached, so as to improve the policy. The paper shows that this iterated supervised learning procedure optimizes a bound on the RL objective, derive performance bounds of the learned policy and empirically demonstrate improved performance and robustness over current RL algorithms in several benchmark tasks."
SP:c306530164d677e670554eeba8203c66bb3d9f7a,"This paper proposes FastSpeech 2, a variant of the fastSpeech model for text-to-speech (TTS) that uses a teacher model for duration prediction and knowledge distillation to simplify the data distribution in output. The authors propose to directly train the model with ground-truth target instead of the simplified output from teacher model and introduce more variation information of speech (e.g., pitch, energy and more accurate duration) as conditional inputs in training and use predicted values in inference. Experimental results show that the proposed method achieves a 3x training speed-up over Fastspeech. "
SP:79e9fb20d383816f54738ce70d137131ebc10290,"This paper studies the problem of unsupervised dimension reduction (UDR) in the language of tempered distributions, i.e. an empirical probability density function pemp(x) is approximated by another tempered distribution q(x), whose support is in a k-dimensional subspace. The problem is reduced to the minimization of the distance between q and pemp, D(q, pemp), over a pertinent set of generalized functions. This infinite-dimensional formulation allows to establish a connection with another classical problem of data science — the sufficient dimension reduction problem (SDR). The authors introduce a nonnegative penalty function R(f) that “forces” the support of f to be k-diminishing. Then they present an algorithm for minimisation of I(f + \lambdaR(f), based on the idea of two-step iterative computation, briefly described as a) an adaptation to real data and to fake data sampled around a k dimensional subspace found at a previous iteration, b) calculation of a new k dimension. The method is demonstrated on 4 examples (3 UDR and 1 SDR)."
SP:93e54522e6c2b805905d21fc968fc40866f2898b,"This paper proposes Feature Contrastive Learning (FCL) to improve the trade-off between robustness and sensitivity in deep learning models. The paper introduces two notions: contextual feature utility and contextual feature sensitivity, and proposes a method that encourages the model to be more sensitive to the features that have higher contextual utility. Empirical results demonstrate that models trained with FCL achieve a better balance of robustness/sensitivity in the presence of noise."
SP:f03c50f15022c4f56ac2b3085354ffed38ad1145,"This paper proposes a novel method for imitation learning based on adversarial learning. The key idea is to learn a latent representation of the expert’s state using a discriminator network. This latent representation is regularized through mutual information constraints to incentivize learning only features that encode information about the completion levels of the task being demonstrated. This allows to obtain a shared feature space to successfully perform imitation while disregarding the differences between the expert's and the agent's domains. Empirically, the proposed method is able to efficiently imitate in a diverse range of control problems including balancing, manipulation and locomotive tasks."
SP:ef18f4188426bc01be309633b486884b0e7a81a4,"This paper studies the generalization of the lottery ticket hypothesis (LTH) by analyzing the geometric structure of the objective function and the sample complexity to achieve zero generalization error. It shows that the convex region near a desirable model with guaranteed generalization enlarges as the neural network model is pruned, indicating the structural importance of a winning ticket. Moreover, when the algorithm for training a pruned neural network is specified as an (accelerated) stochastic gradient descent algorithm, they theoretically show that the number of samples required for achieving zero generalisation error is proportional to number of the non-pruned weights in the hidden layer. Theoretical results are acquired from learning a pruning neural network of one hidden layer, while experimental results are further provided to justify the implications in pruning multi-layer neural networks."
SP:eed6cb2f8caed39f8295f4aeb6e044c2ac981c4d,"This paper proposes AutoLabel to automatically learn the labels for augmented data, based on the distance between the clean distribution and augmented distribution. AutoLabel is built on label smoothing and is guided by the calibration-performance over a hold-out validation set. The authors show that AutoLabel can be easily applied to existing data augmentation methods, including AugMix, mixup, and adversarial training. Experiments on CIFAR-10, Cifar-100 and ImageNet show that the proposed method can improve models’ accuracy and calibration performance."
SP:0d5017e1a405bf86e3bac40e6e59886d4bf48450,This paper proposes a novel self-supervised representation learning method based on a causal framework. The main idea is to use invariance constraints on the proxy classifiers employed during pretraining to improve the performance of the proposed method. The authors propose a new objective called Representation Learning via Invariant Causal Mechanisms (RELIC) that enforces invariant prediction of proxy targets across augmentations through an invariance regularizer which yields improved generalization guarantees. The experimental results show that RELIC significantly outperforms competing methods in terms of robustness and out-of-distribution generalization.
SP:8f80a6f79f78c6421857f392c9a5e98061d7eb60,This paper proposes a new method for object goal navigation. The proposed method is based on the Transformer Network (TNN) architecture. The main idea is to embed object and region features with their location cues as spatial-aware descriptors and then incorporate all the encoded descriptors through attention operations to achieve informative representation for navigation. Experiments on the artificial environment AI2-Thor demonstrate the effectiveness of the proposed method.
SP:3e7cbe3dff592ef371e48dd86be7719fc5343f17,This paper proposes a communication-computation efficient secure aggregation method for federated learning. The key idea is to design the topology of the secret-sharing nodes (denoted by the assignment graph G) as sparse random graphs instead of the complete graph corresponding to the existing secure aggregation solution. The authors provide theoretical guarantees on the reliability/privacy of the proposed scheme and provide extensive real-world experiments to show that the proposed method maintains the same levels of reliability and data privacy.
SP:00fae41e0eca0a1575cd7b2dcfabf0dc5c9c8b8a,This paper studies the problem of finding an incentive compatible auction that maximizes the expected revenue. The authors propose to use a time-independent Lagrangian to find the optimal auction. They also propose to amortize this process through the introduction of an additional neural network. They demonstrate the effectiveness of their approach by learning competitive or strictly improved auctions compared to prior work. 
SP:a0e8061beb5e9a6c631419861559d22b8d645cb4,"This paper proposes Bi-tuning, a general learning approach to fine-tune both supervised and unsupervised pre-trained representations to downstream tasks. The proposed approach is based on the idea that both the discriminative knowledge and the intrinsic structure of the downstream task can be useful for finetuning. To this end, the authors propose two heads: a classifier head with an improved contrastive cross-entropy loss to better leverage the label information in an instance-contrast way, and a projector head with a newly-designed categorical contrastive learning loss to fully exploit the intrinsic structures of data in a category-consistent way. Experiments on CUB and MNIST show the effectiveness of the proposed approach."
SP:87e5b552c13d73bd85249062a152c6c140e594a9,"This paper proposes a new measure for the robustness of classifiers called genuine adversarial accuracy (GAA) to measure the adversarial robustness without trading off accuracy on clean data and accuracy on the adversarially perturbed samples. The authors prove that a single nearest neighbor (1-NN) classifier is the most robust classifier according to GAA for given data and a norm-based distance metric when the class for each data point is unique. Based on this result, the authors suggest that using poor distance metrics might be one factor for the tradeoff between test accuracy and lp norm based robustness."
SP:2fda410b9281c5e253d385bc4382ec168bc161f3,"This paper studies the problem of dyadic fairness in graph neural networks. In particular, the authors propose a new algorithm, FairAdj, to learn a fair adjacency matrix with proper graph structural constraints for fair link prediction, and in the meanwhile preserve predictive accuracy as much as possible. Empirical validation demonstrates the effectiveness of the proposed algorithm in terms of various statistics. "
SP:b614e9fbec58e9efa7722d2ec4a60fc93d210f92,This paper proposes a method for generating synthetic data using disentanglement-based autoencoders. The proposed method is based on disentangled representation and regularization to guarantee the validity of exploration in latent space and achieve controllable synthesis. Experiments demonstrate that the proposed method can improve the performance of downstream tasks by synthesizing attribute-controllable augmented samples. The authors also demonstrate that DEAE can help to eliminate dataset bias.
SP:c934adb14926a00ef9c73c9773cb0b3a2669921e,"This paper proposes a new Bayesian memory allocation scheme that bridges the gap between episodic and semantic memory via a hierarchical latent variable model. The authors propose a novel differentiable block allocated latent memory. In contrast to the Kanerva Machine, they simplify the process of memory writing by treating it as a fully feed forward deterministic process, relying on the stochasticity of the read key distribution to disperse information within the memory. They demonstrate that this allocation scheme improves performance in memory conditional image generation."
SP:e63d7d8c581019e17585fb9c0eac33d6836e187d,"This paper studies the sample complexity and loss landscape of attention-based neural networks. The authors show that, under mild assumptions, every local minimum of the attention model has low prediction error, and attention models require lower sample complexity than models without attention. Experiments on various datasets validate the theoretical findings."
SP:f739d199fdee26f09994e3f9487aec1eab0f2e89,"This paper studies the problem of active inference in the context of reinforcement learning (RL) and proposes a novel approach to learn a prior preference from experts. The authors extend the concept of expected free energy (EFE), which is a core quantity in active inference, and claim that EFE can be treated as a negative value function. Motivated by this connection, the authors propose a simple but novel method for learning the prior preference of the agent. Experimental results show that the proposed method can be applied to the inverse RL problem."
SP:5592b79e49eba95c15103a3348f2bde57b60f2ab,"This paper proposes a data augmentation method to improve generalization in both adversarial and standard learning by using out-of-distribution (OOD) data that are devoid of the abovementioned issues. Theoretical analysis is provided to show how to improve the generalization theoretically using OOD data in each learning scenario and complement the theoretical analysis with experiments on Cifar-10, CIFAR-100, and a subset of ImageNet. The results indicate that undesirable features are shared even among image data that seem to have little correlation from a human point of view."
SP:3cac7a2c310165ed0de46d8e5546c3bfbd639158,"This paper proposes a new meta-RL method called Fast Linearized Adaptive Policy (FLAP) that learns a shared linear representation of the policy so that when adapting to a new task, it suffices to predict a set of linear weights. A separate adapter network is trained simultaneously with the policy such that during adaptation, we can directly use the adapter network to predict these linear weights instead of updating a meta-policy via gradient descent. The application of the separate feed-forward network not only speeds up the adaptation run-time significantly, but also generalizes extremely well to very different tasks that prior MetaRL methods fail to generalize to. Experiments on standard continuous-control metaRL benchmarks show FLAP presenting significantly stronger performance on out-of-distribution tasks with up to double the average return and up to 8X faster adaptation speed compared to prior methods."
SP:21a1bd4ada0723c96c0dbf7a142a2faf5defa4e3,"This paper proposes a federated kernel k-means algorithm to solve the optimization problem of kernel k under federated settings. The authors propose a distributed stochastic proximal gradient descent (DSPGD) algorithm to determine an approximate solution to the optimization problems of kernelk. To tackle the second challenge, a communication efficient mech anism (CEM) is designed to reduce the communication cost. Theoretical analysis shows that DSPGD with CEM converges with an O(1/T ) rate, where T is the number of iterations, and communication cost is un related to number of data samples. The experimental results show that the federated kerne l k-Means achieves the highest clustering quality with more than 60% in most cases."
SP:be568dd3fea51ce33a6d1e4b07dda5aee6342395,"This paper proposes CompOFA, an approach to reduce the training time of Once-For-All (OFA) by constraining the search space to models close to the accuracy-latency Pareto frontier. The authors propose to use compound relationships between model dimensions to build a design space smaller by several orders of magnitude. They show that even with simple heuristics they can achieve a 2x reduction in training time and 216x speedup in model search/extraction time compared to the state-of-the-art. They also show that this smaller design space is dense enough to support equally accurate models for a similar diversity of hardware and latency."
SP:04b84d26cf282dbb753cbf27f14c334f65d3f8ec,This paper studies the problem of meta-learning with adversarial samples. The authors propose an algorithm called ADML (ADversarial Meta-Learner) to optimize the initialization of a learning model in an adversarial manner. They show that the proposed algorithm is robust to adversarial attacks. They also show that ADML outperforms several other meta-learners in terms of accuracy and robustness on two image datasets.
SP:dfbaa6b53c4e8328d52666ad4641fc917bf0c0b3,"This paper proposes a data-driven framework for permutation selection based on self-attention networks in physical layer communication systems. In particular, the authors propose a method to select the permutation of the Bose-Chaudhuri-Hocquenghem (BCH) code. The authors show that the proposed method outperforms the baselines in terms of bit error rate. "
SP:c860a7b0952d708e7851c9bc4b63d246f64d1cba,", the paper proposes to perform unsupervised clustering prior to fine-tuning BERT for a target text classification task. The proposed method is based on the idea that if there is no labeled data for the target task, then BERT should be trained on predicting the cluster labels. The authors show that this additional classification step can significantly reduce the demand for labeled examples mainly for topical classification tasks."
SP:ea37f5882fd98dd4ce233077bb3069517d4ed4ea,This paper studies the problem of micro-data model-based reinforcement learning (MBRL) using a random shooting control agent. The authors compare the performance of a number of generative models on the problem. They find that the mixture density nets outperform all other models by a large margin when multimodality is not required. They also find that heteroscedasticity at training time improves predictions at longer horizons. 
SP:4e25ba3714d78ba59a0d8efbb65e0ef5201702f8,"This paper proposes an affine disentangled GAN that can explicitly disentangle affine transformations in a self-supervised and rigorous manner. The objective is inspired by InfoGAN, where an additional affine regularizer acts as the inductive bias. The affine transformation is derived by decomposing the affine matrix into separate transformation matrices and inferring the transformation parameters by maximum likelihood estimation. Experiments on MNIST, CelebA, and dSprites datasets demonstrate the effectiveness of the proposed method."
SP:121f8420cfb49c6d80b5ebb4051e85947182594a,-based contrastive learning is an important area of research in machine learning. This paper proposes a novel approach to improve the performance of unsupervised learning by using stronger augmentations in instance discrimination. The main idea is to minimize the distribution divergence between the weakly and strongly augmented images over the representation bank to supervise the retrieval of strongly augmented queries from a pool of candidates. The proposed method achieves top-1 accuracy on ImageNet with a standard ResNet-50 architecture with a single-layer classifier fine-tuned.
SP:af54e542223097c315ecd677d0b968e9a0b2a1d4,"This paper proposes a method to de-identify a patient's face using MRI scans. The proposed method is based on a 3D GAN architecture that takes a patient’s MRI scan as input and generates 3D volume in which the brain is not modified but the face has been de-identified. Compared to the classical removal-based techniques, the proposed method preserves privacy more reliably without adversely affecting downstream medical analyses on the brain including segmentation and age prediction."
SP:0ac3964bd2320341488476d60f57b75d2a79f92c,"This paper proposes a multi-head attention based global pooling layer that captures the interaction between nodes according to their structural dependencies. The proposed method is shown to satisfy both injectiveness and permutation invariance, such that it is at most as powerful as the Weisfeiler-Lehman graph isomorphism test. The experimental results show that GMT significantly outperforms state-of-the-art graph pooling methods on graph classification benchmarks with high memory and time efficiency."
SP:76848e7ac3e6709e92f6a6db60269cb5177495d1,"-based GNNs suffer from an over-squashing problem. This paper proposes a new explanation for this problem, which is based on the idea of a bottleneck. The paper argues that the bottleneck is caused by the exponential growth of the information in the graph, which causes the information to be aggregated into a fixed-size vector. The authors show that GAT, GGNN, GCN, and GIN are all susceptible to this problem. Finally, the paper shows that breaking the bottleneck improves the performance of these networks. "
SP:90d8fa381446923902e42b259392e5e975e6caa1,"This paper proposes a new domain adaptation method for cross-domain sentiment analysis. The proposed method is based on the notion of prototypical distribution, which induces large margins between different classes in an embedding space based on prototypical distributions across the domains. The authors show that the proposed method can reduce the effect of “domain shift” on the performance of a trained classifier in the target domain. "
SP:893fd7440b82f5da0d4c0944928810322eaee2f0,"This paper proposes a challenge task to evaluate the performance of NLI models on the presence of gender stereotypes using occupations. The challenge is to pair gender-neutral premise against gender-specific hypothesis. The authors propose to evaluate three models (BERT, RoBERTa, BART) trained on MNLI and SNLI data-sets. They find that three models are significantly prone to gender induced prediction errors. They also find that debiasing techniques such as augmenting the training dataset to ensure a gender-balanced dataset can help reduce such bias."
SP:a32ab755bd249c393b70938036ce8e810c0c439f,"This paper studies the variational intrinsic control (VIC) algorithm for finding the largest set of intrinsic options available to an agent. The authors show that the intrinsic reward used in the latter is subject to bias in stochastic environments, causing convergence to suboptimal solutions. To correct this behavior and achieve the maximal empowerment, they propose two methods respectively based on the transitional probability model and Gaussian mixture model."
SP:b4df2c4627a6d46c5100133e38c4bea20b296dd8,This paper studies the use of neural ensembling to improve sample efficiency in the low-data regime by using an ensemble of relatively small deep networks. The authors propose a simple yet effective technique that outperforms current state-of-the-art approaches for learning from small datasets. They compare different ensemble configurations to their deeper and wider competitors given a total fixed computational budget and provide empirical evidence of their advantage. 
SP:4a0ee01f4897efa81659f37ef0468ee8195bbc4f,This paper proposes Sparse Binary Neural Networks (SBNN) to improve the performance of quantized neural networks (BNNs) in the context of Internet of Things (IoT) devices. The authors propose to use positive 0/1 binary weights instead of the -1/1 weights in BNNs to reduce the number of operations and parameters at inference time. They show that SBNNs can achieve high compression rates and good generalization on MNIST and CIFAR-10 datasets.
SP:5be8539ad02595ad3c7a2d7afe8cbb3e9924467d,"This paper proposes a post hoc calibration method for predictive uncertainty. The proposed method uses outlier exposure to properly calibrate the model probabilities. The authors show that their method significantly improves on benchmark results (Ovadia et al., 2019) on a wide range of corrupted data. "
SP:ea503f67e38fce7dee9cc4996b55b8959911f030,"This paper studies the expressive power of graph neural networks and graph kernels from an empirical perspective. Specifically, it compares the graph representations and similarities produced by these algorithms against those generated by a wellaccepted, but intractable graph similarity function. The authors also investigate the impact of node attributes on the performance of the different models and kernels. The results reveal interesting findings. For instance, theoretically more powerful models do not necessarily yield higher-quality representations, while graph kernels are shown to be very competitive with graph neural network."
SP:0cf7b7d929f50e0b7f4fda5e1f68e5ade2f7c29b,"This paper proposes a method for self-supervised image animation, where the goal is to generate a video of a source image following the motion of a driving video. The authors propose to use the top-k percent occlusion masks of the foreground to regularize image animation. The proposed method is based on the idea that the inpainting of the source image is more difficult than that of the driving video due to the large differences in the pose of the two images. To this end, the authors propose a method called PriorityCut, which uses the occlusions to regularise the discriminator predictions on the warped source image. "
SP:60b535fc6cbc1a7a26ad53f706ebb17de346dc4f,"This paper studies the problem of learning disentangled representations of independent causal mechanisms (ICM). The authors propose to learn a model that disentangles each mechanism and approximates the groundtruth mechanisms from observational data. They provide sufficient conditions under which the mechanisms can be learned using a single self-supervised generative model with an unconventional mixture prior, simplifying previous methods. The authors prove the identifiability of their model w.r.t. the mechanisms in the self supervised scenario. They show that their approach is more robust to intervention, covariant shift and noise due to the disentanglement between the data generation processes."
SP:44d4e24428d043a69b40013919cda0e8e7bff99c,"This paper proposes a graph aligning approach to predict a molecular graph structure given a 2D image of a chemical compound (U) given a graph structure (W). The authors propose to learn f : U →W where we have a fully mediating representation V such that f factors into U → V → W. However, observing V requires detailed and expensive labels. The proposed approach generates rich or detailed labels given normal labels W. In this paper, the authors investigate the scenario of domain adaptation from the source domain where they have access to the expensive labels V to the target domain where only normal label W are available. The empirical results show that, using only 4000 data points, they obtain up to 4x improvement of performance after domain adaptation to target domain compared to pretrained model only on source domain. "
SP:ad906dd9a176cffd283593321ff6b9ad19595528," cooling systems can be viewed as an input-output monotonic problem. To solve this problem, the authors propose to use a neural network to model the physical behavior of the system. The proposed method is tested on a cooling system of a data center and shows the superiority of the proposed method."
SP:6cb65ee5d2926858570601eeeade24fe86c7f32f,"This paper proposes a causal spatio-temporal fusion transformer, named CausalTrans, to establish the collaborative causal effects of predictors on multiple forecasting targets, such as supply and demand in ride-sharing platforms. Specifically, the authors integrate the causal attention with the Conditional Average Treatment Effect (CATE) estimation method in causal inference. Moreover, they propose a novel and fast multi-head attention evolved from Taylor’s expansion instead of softmax, reducing time complexity from O(V) to O(v) where V is the number of nodes in a graph. The authors conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various model components, and the time efficiency of our causalTrans. "
SP:223980a1954d626d90ff54d8dc61b5d85a6b349c,-mix VAE is an unsupervised approach to jointly identify a mixture of discrete and continuous factors of variability. The authors propose a multi-agent framework to solve the problem. The proposed approach is evaluated on MNIST and dSprites datasets. The experimental results show the effectiveness of the proposed approach. 
SP:c982610ad28662c3bd13132abe1f7307d1a61b68,"This paper provides a generalization of the Wigner-Eckart theorem for spherical tensor operators to the case of group equivariant convolutional networks (GCNNs). The main contribution of this paper is to provide a general characterization of steerable kernel spaces for any compact group. The authors prove that steerable kernels are fully understood and parameterized in terms of generalized reduced matrix elements, ClebschGordan coefficients, and harmonic basis functions on homogeneous spaces. "
SP:7b2ea39069277ad0f4f79476a77ef84587a804d9,". This paper studies the effect of selective classification on the accuracy of different groups in the presence of spurious correlations. The authors study the margin distribution, which captures the model’s confidences over all predictions. They prove that whether selective classification monotonically improves or worsens accuracy is fully determined by the accuracy at full coverage (i.e., without any abstentions) and whether the distribution satisfies a property we call left-log-concavity. Motivated by their analysis, the authors train distributionally-robust models that achieve similar full-coverage accuracies across groups and show that selective classification uniformly improves each group on these models."
SP:f1d57ee27e901daf7e4e2b84139019e945818911,"This paper proposes a hierarchical nonnegative CANDECOMP/PARAFAC (CP) decomposition (hierarchical NCPD) model and a training method, Neural NCPD, for performing hierarchical topic modeling on multi-modal tensor data. The proposed method utilizes a neural network architecture and backpropagation to mitigate error propagation through hierarchical NCPD."
SP:b6ddc3a560aa7155e7e927bf5360bedc36586597,This paper proposes a new adversarial robustness certificate for graph neural networks. The key idea is to fuse multiple single-node certificates into a drastically stronger collective certificate. The proposed method is based on Graph Neural Networks and leverage their locality property – perturbations only affect the predictions in a close neighborhood – to fuse the predictions into a more robust certificate. 
SP:cc93dd2f68e415e2457166e78627865dc1b44697," GANs suffer from non-convergence problem, mode collapse and gradient explosion or vanishing. This paper proposes Quantile Regression GAN (QRGAN) in which quantile regression is adopted to minimize 1-Wasserstein distance between real and generated data distribution. QRGAN obtains an apparent improvement in the evaluation and comparison of Frechet Inception Distance (FID) for generation performance assessment compared to existing variants of GGANs."
SP:4ddb47ee77c374ae6c3e419412d92ca77260692e,This paper investigates relevance metrics for explaining the predictions made by machine learning models. The authors propose to use cosine similarity of the gradients of the loss as a metric to evaluate whether the relevance metrics satisfy the minimal requirements for similarity-based explanation. The experiments show that the proposed metric is better than other relevance metrics in terms of explaining the model predictions.
SP:6c2cbf2bc0f6dabe974e80ec1e82d2d12189906e,This paper proposes adding a low-rank global attention (LRGA) module to Graph Neural Networks (GNNs) to improve their generalization power. The authors show that adding the LRGA module to GNNs improves the generalization performance. They show that the proposed method aligns with the 2-FWL update step via polynomial kernels. They also show the sample complexity of the kernel’s feature map when learned with a randomly initialized two-layer MLP. 
SP:b4abdd28504b4c1de239eabd4e0e27d370efee71,This paper proposes a method to improve the calibration performance of convolutional neural networks (CNNs) by using objectness measures to improve their calibration performance. The proposed method is based on the idea of objectness and label smoothing during training. The main idea is to compute a smoothing factor that is adaptive based on relative object size within an image. Experiments are conducted on ImageNet-1K to demonstrate the effectiveness of the proposed method.
SP:5254658923e594294b69d124a8d004166852822a,This paper proposes a two-layer ReLU denoising network that is amenable to convex optimization. The main contribution of the paper is the introduction of a convex duality framework that makes the network amenable for convex optimisation. The proposed method is tested on MNIST and fastMRI datasets and shows its effectiveness. 
SP:085cad6bc143c8713580bddfaa71f06496dac314,"This paper proposes an end-to-end approach to synthesise speech from normalised text or phonemes. The authors propose to use a differentiable alignment scheme based on token length prediction to produce high fidelity audio through a combination of adversarial feedback and prediction losses constraining the generated audio to roughly match the ground truth in terms of its total duration and mel-spectrogram. The resulting model achieves a mean opinion score exceeding 4 on a 5 point scale, which is comparable to the state-of-the-art models relying on multi-stage training and additional supervision."
SP:01148cea55db606aa78d27e900818684a8bce9ab,"This paper proposes a non-parametric approach for node representation learning in the presence of missing attributes in attributed graphs. The key idea is to use the Wasserstein metric to represent node features in a lower-dimensional space, and then use diffusion to smooth the distribution representations of nodes with information from their local neighborhoods. This allows us to reduce the distortion caused by missing attributes and obtain integrated representations expressing information of both topology structure and attributes. The paper also proposes two algorithms based on it for node classification and matrix completion."
SP:aeeb5909f7123ef631f569b469af9715205c881f,"This paper proposes AMIGO, a meta-learning method for reinforcement learning in environments with sparse extrinsic rewards. The main idea is to train a goal-conditioned “student” policy in the absence of (or alongside) environment reward. The teacher learns to propose increasingly challenging goals that allow the student to learn general skills for acting in a new environment, independent of the task to be solved. The proposed method generates a curriculum of self-proposed goals which ultimately allows the agent to solve challenging procedurally-generated tasks where other forms of intrinsic motivation and state-of-the-art RL methods fail."
SP:3d05bc7dca97681cb582298e318b9b973841eed3,"This paper studies the problem of information retrieval from a dataset of files stored on a single server under both a user distortion and a user privacy constraint. The authors propose a data-driven framework by leveraging recent advancements in generative adversarial models which allows a user to learn efficient schemes in terms of download rate from the data itself. Learning the scheme is formulated as a constrained minimax game between a user which desires to keep the identity of the requested file private and an adversary that tries to infer which file the user is interested in under a distortion constraint. In general, guaranteeing a certain privacy level leads to a higher rate-distortion tradeoff curve, and hence a sacrifice in either download rate or distortion."
SP:3f9e2db00fc3dcd7a40588adcb638503ec10dc09,"This paper proposes a decoupled greedy learning method for graph neural networks (GNNs) that decouples the GNN into smaller modules and associates each module with greedy auxiliary objectives. This allows GNN layers to be updated during the training process without waiting for feedback from successor layers, thus making parallel GNN training possible. The proposed method achieves improved efficiency without significantly compromising model performances, which would be important for time or memory limited applications. The paper also proposes a lazy-update scheme during training to further improve its efficiency."
SP:5ecb1b288f7fc02aead4493f81640867bc349290,"This paper proposes a framework for answering complex queries on incomplete Knowledge Graphs. The main idea is to translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. The authors propose two solutions to the optimisation problem, including gradient-based and combinatorial search. In experiments, the proposed approach produces more accurate results than state-of-the-art methods without the need of training on a large and diverse set of complex queries."
SP:f04a522fd04c503754fdb8c52da68646d31271a4,"This paper studies the problem of verifying the robustness of neural networks with piecewise-linear activation functions. In particular, the authors propose to use geometric projections to find the decision boundaries within the regions around a given input. They show that the region around a point can be analyzed using simple geometric projections, thus admitting an efficient, highly-parallel GPU implementation that excels particularly for the `2 norm, where previous work has been less effective. Empirically, they find this approach to be far more precise than many approximate verification approaches, while at the same time performing multiple orders of magnitude faster than complete verifiers."
SP:5297651ff873f97c07b9c47ed3eff52251661844,"This paper proposes an approach for embedding objects in an affordance space, in which each dimension corresponds to an aspect of meaning shared by many actions, using text corpora. This embedding makes it possible to predict which verbs will be applicable to a given object, as captured in human judgments of affordance, better than a variety of alternative approaches. The dimensions learned are interpretable and correspond to typical patterns of interaction with objects. Finally, the dimensions can be used to predict a state-of-the-art mental representation of objects, derived purely from human judgements of object similarity."
SP:72b4f3b40c6c6fa2eb53e95ed9a10a4077ffa049,"This paper proposes a method for the emergence of individuality in multi-agent reinforcement learning (MARL) by learning a probabilistic classifier that predicts a probability distribution over agents given their observation and gives each agent an intrinsic reward of being correctly predicted by the classifier. The intrinsic reward encourages the agents to visit their own familiar observations, which makes the intrinsic reward signals stronger and in turn makes the agents more identifiable. Two regularizers are proposed to increase the discriminability of the classifiers. Empirical results show that the proposed method outperforms existing methods in a variety of multi agent cooperative scenarios."
SP:112509d6d3573a9d495d182fdfae6ec0327cddf5,"This paper proposes a method to improve the certified robustness of randomized smoothed classifiers. The proposed method, Smoothed WEighted Ensembling (SWEEN), is based on the idea of ensembling. The authors show that the optimal SWEEN model can be obtained from training under mild assumptions. They also develop an adaptive prediction algorithm to reduce the prediction and certification cost of SWEen models. Extensive experiments show the effectiveness of the proposed method."
SP:ea892e3d199ed6121279b20061a87f43afae8796,. The paper proposes a method to discover subtask hierarchy by learning from demonstration. The method is based on the inductive bias. The proposed method is evaluated on two tasks: Craft and Dial. The experiments show that the proposed method can achieve higher task decomposition performance. 
SP:cc6aa977ce561a2493ae74bb694205cd67c8d890,"This paper proposes a new approach for out-of-distribution (OOD) prediction from a single training data point. The proposed approach is based on a causal reasoning approach where the semantic and variation factors are modeled separately. The authors prove that under certain conditions, CSG can identify the semantic factor by fitting training data, and this semantic-identification guarantees the boundedness of OOD generalization error and the success of adaptation. Empirical results show that the proposed approach outperforms existing OOD prediction methods."
SP:be3f34a59e5e61dcdbc7cb085f031ba4a5a5b758,"This paper studies the problem of robust online learning in the setting where the reward distribution can be corrupted with probability $\mathcal{O}(\sqrt{0, 12)$, where $\Omega(0,12)$ is the noise rate of the adversary. In this setting, the authors propose an algorithm with near-optimal regret in three settings: stochastic multi-armed bandits, linear contextual bandits, and Markov Decision Processes (MDPs). The proposed algorithms are tested on synthetic and real-world datasets. "
SP:6d62a80aaebb2988df3953d4d7164e5a2fa1aa6d,"This paper proposes Rewriter-Evaluator, a novel framework for neural machine translation (NMT) that consists of a rewriter and an evaluator. At every pass, the rewriter produces a new translation to improve the past translation and the evaluators estimates the translation quality to decide whether to terminate the rewriting process. The authors propose a prioritized gradient descent (PGD) method to train the re-writer and the Evaluator jointly. Experiments on two translation tasks, Chinese-English and English-German, show that the proposed framework significantly improves the performance of NMT models and significantly outperforms previous baselines."
SP:9761fca8848868dfc9cacdab2537f8276ca76e0f,"This paper proposes a two-stage, cascaded strategy for calibrated adversarial refinement. In the first stage, the model explicitly model the data with a categorical likelihood, and in the second stage, an adversarial network is trained to sample from it an arbitrary number of coherent predictions. The model can be used independently or integrated into any black-box segmentation framework to facilitate learning of calibrated stochastic mappings. The authors demonstrate the utility and versatility of the approach by attaining state-of-the-art results on multigrader LIDC and a modified Cityscapes dataset."
SP:ce965758f1b795a56c02f45d6a8d06cb8bdf29cb,This paper proposes a new approach for dealing with contractive compressors. The main idea is to transform any contractive compressor into an induced unbiased compressor. Theoretical results show that the proposed approach leads to better communication complexity guarantees and fewer assumptions. Experiments on federated learning with partial participation show the effectiveness of the proposed method.
SP:4fd702490293e481c79614852ba27dd3ce9215a4,This paper proposes a new research framework for hyperparameter transfer across adjustments (HT-AA) to speed up the development of machine learning (ML) algorithms. The main contribution of the paper is the introduction of four simple baseline algorithms and eight benchmarks to demonstrate the effectiveness of the proposed method. The authors also provide python packages for the baselines and benchmarks. 
SP:e8f99bae5853de525450fcb8facd23cf973fc161,"This paper studies the effect of label representations on the performance of image classification models. The authors show that high dimensional, high entropy label representations are generally more useful because they provide a stronger error signal. They support this hypothesis with evidence from various label representations including constant matrices, spectrograms, shuffled spectrogram, Gaussian mixtures, and uniform random matrices of various dimensionalities. They also show that the features learned through these label representations exhibit more robustness under various adversarial attacks and better effectiveness with a limited amount of training data."
SP:4e8d924cba7367af0999b30d79250b4dc40413e1,"This paper proposes a method to improve the robustness of ensemble neural networks by using a single model's capacity to train multiple subnetworks that independently learn the task at hand. By ensembling the predictions made by the sub-networks, the proposed method improves model robustness without increasing the computational cost. The proposed method is evaluated on CIFAR10, Cifar100, ImageNet, and their out-of-distribution variants. "
SP:d2f1c23b67c6744101034dc5e1c70765a733b169,"This paper proposes a method to transfer intermediate knowledge obtained from one Convolutional Neural Network (CNN) to another by utilizing sparse representation learning. The proposed method first extracts sparse representations of the hidden features of the teacher CNN, which are then used to generate both pixellevel and image-level labels for training intermediate feature maps of the student network. The authors formulate SRM as a neural processing block, which can be efficiently optimized using stochastic gradient descent and integrated into any CNN in a plug-and-play manner. The experiments demonstrate that SRM is robust to architectural differences between the teacher and student networks and outperforms other KD techniques across several datasets."
SP:e8c0f43bd5debf6544f588cd3442dc3dd62d0eee,"This paper proposes a novel approach for learning representations of states in reinforcement learning. The authors propose a new metric called policy similarity metric (PSM) for measuring behavioral similarity between states. They also propose a contrastive representation learning procedure to embed any state similarity metric, which they instantiate with PSM to obtain policy similarity embeddings (PSEs1). They demonstrate that PSEs improve generalization on diverse benchmarks, including LQR with spurious correlations, a jumping task from pixels, and Distracting DM Control Suite."
SP:92f3b4942da9075440dda618f561a85f8fde5a5c,"This paper studies the problem of disentangling natural factors of variation in data (e.g. object shape vs pose) by learning to map each of these factors to distinct subspaces of a model’s latent representation. The authors show that this approach introduces topological defects (i.e. discontinuities in the encoder) for a broad family of transformations acting on images —encompassing simple affine transformations such as rotations and translations. Inspired by classical results from group representation theory, the authors propose an alternative, more flexible approach to disentanglement which relies on distributed equivariant operators, potentially acting on the entire latent space. They theoretically and empirically demonstrate the effectiveness of their approach. "
SP:ef0f58c462bc5dd1c7b78f562c42a4e17f0f252b,"This paper proposes a novel approach to estimate the functional connectivity of neurons in the Hawkes process. The authors propose to use auxiliary latent variables (Pólya-Gamma variables, latent marked Poisson processes and sparsity variables) to make functional connection weights in a Gaussian form, which allows for an efficient expectationmaximization (EM) algorithm to obtain the maximum a posteriori (MAP) estimate. Experimental results on synthetic and real data demonstrate the effectiveness of the proposed approach. "
SP:1156d3deac022829bda930ffcb081947609d972b,"This paper studies the gradient descent (GD) algorithm for two-layer neural network models. It shows that there are two distinctive phases in the GD dynamics in the under-parameterized regime: an early phase in which the dynamics follows closely that of the corresponding random feature model, followed by a late phase where the neurons are divided into two groups: a group of a few (maybe none) “activated” neurons that dominate the dynamics and a group “quenched’ neurons that support the continued activation and deactivation process. In particular, when the target function can be accurately approximated by a relatively small number of neurons, this quenching-activation process biases GD to picking sparse solutions. This neural network-like behavior is continued into the mildly over-parametrized regime, in which it undergoes a transition to a random featurelike behavior where the inner-layer parameters are effectively frozen during the training process. This is qualitatively different from the GD dynamic associated with the mean-field scaling where all neurons participate equally."
SP:9e81401a6f30c70d870a12cce0cf600557f92b80,"This paper studies the problem of constrained Markov decision process (CMDP) problems in which the agent has to maximize the expected return while satisfying a set of prescribed safety constraints. The authors propose a model to solve a CMDP problem by decomposing the CMDP into a pair of MDPs; reconnaissance MDP and planning MDP. In R-MDP, they train threat function, the Q-function analogue of danger that can determine whether a given state-action pair is safe or not. In P-PDP they train a reward-seeking policy while using a fixed threat function to determine the safeness of each action. With the help of generative model, they can efficiently train the threat function by preferentially sampling rare dangerous events. They also propose an efficient approximation method that can greatly reduce the difficulty of solving R-RDP."
SP:f1d4ac7d5516dd0df742e224c8c09c721d0d0886,"In this paper, the authors investigate the effect of the cross-entropy loss on the performance of neural networks trained with the square loss on a range of tasks. The authors argue that the cross entropy loss is not as good as the square one in terms of performance. They argue that there is little compelling empirical or theoretical evidence indicating a clear-cut advantage of cross entropy over square loss. They show that cross entropy seems to have a slight edge on computer vision tasks, while square loss seems to be less sensitive to the randomness in initialization. "
SP:915f1f0fc4850507c28c1d609239b41775863ebe,"This paper proposes a method for self-supervised reinforcement learning that learns to predict its own latent state representations multiple steps into the future. The proposed method, called Self-Predictive Representations (SPR), uses an exponential moving average of the agent’s parameters and makes predictions using a learned transition model. It further improves performance by adding data augmentation to the future prediction loss, which forces the agent to be consistent across multiple views of an observation. SPR achieves a median human-normalized score of 0.415 on Atari in a setting limited to 100k steps of environment interaction."
SP:983f01c170909c8c67fd3be25f121bd61bdd8307,"This paper proposes InstantEmbedding, an efficient method for generating single-node representations using local PageRank computations. The authors theoretically prove that their approach produces globally consistent representations in sublinear time. They demonstrate this empirically by conducting extensive experiments on real-world datasets with over a billion edges. They show that their method requires drastically less computation time and less memory than traditional methods including DeepWalk, node2vec, VERSE, and FastRP. "
SP:d11037b8fe2b10aee672ba82f69410b40181f0f9,"This paper proposes a method for graph coarsening based on graph neural networks (GNNs). The main idea is to learn a graph neural network to learn the Laplace operator on the coarse graph and the associated projection/lift operators. The proposed method is evaluated on both synthetic and real graphs. It is shown that the proposed method outperforms existing methods on various metrics such as reduction ratios, graph sizes, and graph types."
SP:0d680213339f0e2aedb0be4aeed51423706b8bf6,This paper proposes a geometric deep learning algorithm based on discrete-laplacian and implicit encoders to compute the acoustic properties of general 3D objects at interactive rates. It uses a point cloud approximation of each object and each point is encoded in a high-dimensional latent space. The proposed method can accurately estimate these acoustic properties for arbitrary topologies and takes less than 1ms per object on a NVIDIA GeForce RTX 2080 Ti GPU. The authors also prove that their learning method is permutation and rotation invariant and demonstrate high accuracy on objects that are quite different from the training data.
SP:afc33a782c43e3d4c5c4fbf047d0b1108bc30bae,"This paper proposes Risk Extrapolation (REx) as a method to reduce the risk across training and test domains in order to improve the robustness of the model to distributional shift. In particular, the authors propose a penalty on the variance of training risks (V-REx), and propose a simpler variant (REx-V) to recover the causal mechanisms of the targets, while also providing some robustness to changes in the input distribution (“covariate shift”). The authors show that REx is able to outperform Invariant Risk Minimization in situations where these types of distributional shifts co-occur."
SP:411d5bcf7698d534ad60f581d479ff74849ba4de,"This paper proposes a method for learning a neural operator for partial differential equations (PDEs). The proposed method is based on the Fourier neural operator, which learns the integral kernel directly in Fourier space, allowing for an expressive and efficient architecture. Experiments on Burgers’ equation, Darcy flow, and Navier-Stokes equation demonstrate the effectiveness of the proposed method. "
SP:41d268d0eac9b4c84baa156fb641aa6d3060b5a4,"This paper studies the implicit bias of gradient flow (i.e., gradient descent with infinitesimal step size) on linear neural network training. The authors propose a tensor formulation of neural networks that includes fully-connected, diagonal, and convolutional networks as special cases, and investigate the linear version of the formulation called linear tensor networks. With this formulation, they can characterize the convergence direction of the network parameters as singular vectors of the tensor defined by the network. They show that gradient flow on separable classification finds a stationary point of the `2/L max-margin problem in a “transformed” input space defined by a network. For underdetermined regression, they prove a global minimum which minimizes a norm-like function that interpolates between weighted `1 and `2 norms in the transformed input space. They also provide experiments that corroborate their analysis."
SP:e27907ef4a4e6e0f5841618fcaa7e7e0db443f91,"This paper studies the problem of optimizing slimmable networks from a multi-objective optimization lens. The authors propose a novel algorithm for optimizing both the shared weights and the width-multipliers for the sub-networks. The proposed method is evaluated on 15 network and dataset combinations and two cost objectives, i.e., FLOPs and memory footprint, to demonstrate the effectiveness of the proposed method compared to existing alternatives."
SP:cf59403abb6ca89ccee4f8e77e9a33d99e6a00f5,This paper studies the problem of federated semi-supervised learning (FSSL) where the clients have both labeled and unlabeled data (labels-at-client) and the server has only labeled data. The authors propose a novel method to tackle the problems of FSSL based on the location of the labeled data and propose FedMatch. FedMatch improves upon naive combinations of FedMatch with a new inter-client consistency loss and decomposition of the parameters for disjoint learning. The experimental results show that FedMatch outperforms both local and federated learning baselines.
SP:9457b6d430a2cd864d526d7e90bf3e1ab13d6df4,"This paper proposes a method for self-supervised learning on discrete event sequences generated by real-world users. The proposed method is based on contrastive learning, which is used for audio and computer vision domains. The authors show that the proposed method outperforms other methods on several downstream tasks. "
SP:385942a5bcee7384bb722a1669b541f2fac0cd36,"This paper proposes a new unsupervised parsing method that can induce dependency and constituency structure at the same time. To achieve this, the authors propose a new parsing framework that can jointly generates constituency tree and dependency graph. Then, they integrate the induced dependency relations into transformer, in a differentiable manner, through a novel dependency-constrained self-attention mechanism. Experimental results show that the proposed method can achieve strong results on unsupervisioned constituency parsing, un-supervised dependency parsing and masked language modeling."
SP:078966ff62775bba6031e47d374bda95f4a7dde3,This paper proposes a method to learn a metric between visual objects and scene graph nodes by incorporating information from both object features and relational features. Extensive experiments on Visual Genome (VG) and Visual Relation Detection (VRD) datasets verify that the proposed method post an improvement on scene graph grounding task over current state-of-the-art approaches. Further experiments on scene Graph Parsing task verify the grounding found by our model can reinforce the performance of the existing method.
SP:4644dbf7466b6234d8abf69995fdfb357efcc119," sliced fused Gromov Wasserstein (SFGWasserstein) has been proposed to reduce the inner discrepancy between the prior and aggregated posterior distributions. The authors propose a new relational discrepancy, named spherical sliced fused SFG (SSFG), that can find an important area of projections characterized by a von Mises-Fisher distribution. Then, they introduce two variants of SSFG to improve its performance. The first variant, named mixture spherical sliced SFG, replaces the vMF distribution by a mixture of von Mise-fisher distributions to capture multiple important areas of directions that are far from each other. The second variant, called power spherical slicedSFG, improves the sampling time in high dimension settings. Finally, the authors apply the new discrepancies to the RAE framework to achieve its new variants. "
SP:5ae2c0af82cac89a65f1cc38c43e2d05ea298901,". This paper proposes a method to speed up training for deep networks that contain repeated structures, such as the transformer module. In this paper, the authors first train such a deep network with the weights shared across all the repeated layers till some point, then stop weight sharing and continue training until convergence. The untying point is automatically determined by monitoring gradient statistics. The adaptive untying criterion is obtained from a theoretic analysis over deep linear networks. Empirical results show that the proposed method is able to reduce the training time of BERT by 50%."
SP:a51710551142316b67e2fccd969fea1ece35ba39,"This paper studies the relationship between adversarial transferability and the interaction inside adversarial perturbations. In particular, the authors prove a negative correlation between the transferability of adversarial attacks and the interactions inside the perturbation. They further show that the negative correlation can be regarded as a unified perspective to understand current transferability-boosting methods. Based on this, they propose to directly penalize interactions during the attacking process, which significantly improves the adversarial attack transferability."
SP:f1565319075c1442c2cb52d96443facb492c06c2," is a well-known problem in deep learning. However, there is a lack of understanding of its connections to neural network (hidden) representations and task semantics. In this paper, the authors study the effect of deeper layers on forgetting. They find that deeper layers are disproportionately responsible for forgetting, with sequential training resulting in an erasure of earlier task representational subspaces. They also show that maximal forgetting occurs for task sequences with intermediate similarity. "
SP:30d7532cdcf420bff3be6b92eea3d93bce59e6bd,"This paper proposes EarlyBERT, a pre-training and fine-tuning algorithm for BERT. The proposed method is inspired by the Early-Bird Lottery Tickets recently studied for computer vision tasks. The main contribution of the paper is to propose an efficient training algorithm to reduce the training time of BERT by reducing the self-attention and fully-connected sub-layers inside a transformer. Experiments on GLUE and SQuAD show that the proposed method achieves comparable performance to standard BERT with 35-45% less training time."
SP:c547f23ff6caaf5e9f35d258490b86ae0ac8ed03,"This paper studies the robustness of f-divergence measures for the problem of learning with noisy labels. The main contribution of the paper is to derive a new measure of robustness based on the variational variational difference (VAE). The authors show that the VAE is robust to label noise. The authors then propose a family of f divergences that are robust when the label noise is small enough. In addition, the authors propose two fixes to the VAEs that make them robust. "
SP:841888179dcdac901889c8d62cb5234311fe28f1,This paper proposes an ensemble-based weighted Bellman backup method for off-policy reinforcement learning. The proposed method re-weights the target Q-values based on uncertainty estimates from a Q-ensemble. The authors show that the proposed method stabilizes and improves learning on both continuous and discrete control tasks on both low-dimensional and high-dimensional environments. They also investigate the signal-to-noise aspect by studying environments with noisy rewards. 
SP:afc08f203562b841180811aef943bfb63a1659ea,"This paper proposes a method for predicting the uncertainty of a few-shot classification problem. The authors propose to measure the distributional mismatch between support and query sets via class-wise similarities. The proposed method is algorithm-agnostic and readily expanded to include a range of meta-learning models. Through extensive experiments including dataset shift, the authors show that their training strategy helps the model avoid being indiscriminately confident and thereby, produce calibrated classification results without the loss of accuracy."
SP:12ae325ea3bce1e60195afac7d85895d2d20c29c,"This paper proposes a novel method for video-text representation learning based on a generative model to naturally push related samples together. The key idea is to use a weighted combination of other support samples’ visual representations. This simple idea ensures that representations are not overly-specialized to individual samples, are reusable across the dataset, and results in representations that explicitly encode semantics shared between samples, unlike noise contrastive learning. The proposed method outperforms others by a large margin on MSR-VTT, VATEX, ActivityNet, and MSVD."
SP:8a71d8fad25a126aff01431cacf348c05de75667," pre-trained language models (PLMs) are used for Chinese NLP tasks. However, the vocabulary for these Chinese PLMs remain to be the one provided by Google Chinese Bert Devlin et al. (2018), which is based on Chinese characters. In this work, the authors propose a novel method, seg tok, to form the vocabulary of Chinese BERT, with the help of Chinese word segmentation (CWS) and subword tokenization. Then, they propose three versions of multi-vocabulary pretraining (MVP) to improve the models expressiveness. Experiments show that seg-tok improves the performances of Chinese PLM on sentence level tasks, it can also improve efficiency, and MVP improves PLMs’ downstream performance, especially it can improve SEG tok’s performances on sequence labeling tasks."
SP:b93ec7bc02b48068073ffe705f71d2643e663d51,"-GCN is a graph convolutional network (GCN) that is used for graph partitioning and distributed training. In this paper, the authors propose an unbiased boundary sampling strategy to enable efficient and scalable distributed GCN training while maintaining the full-graph accuracy. Empirical evaluations and ablation studies validate the effectiveness of the proposed method."
SP:2d4ba873d11e969ebd1fc31f9b5ab450c964d154,"This paper proposes a graph neural network (GNN) for quantum chemistry simulations. The proposed method is based on graph neural networks to estimate per-atom forces, which is a central capability for performing atomic simulations. It is shown that the proposed method reduces the estimation error of atomic forces by 30% compared to existing ML models, and generalizes well to out-of-distribution structures. Experiments are conducted on the large-scale catalyst dataset, OC20, where ForceNet is able to achieve 4x higher success rate than existing models."
SP:8bdcf4fe6abf4739d4732b7ea8538513135dcccc,"This paper studies the problem of fine-tuning neural networks. The authors provide a generalization bound for neural networks based on Rademacher complexity. They show that this bound has no dependence on the number of weights and compares favourably to other bounds when applied to convolutional networks. Inspired by this, the authors propose a simple yet effective algorithm that constrains the hypothesis class to a small sphere centred on the initial pre-trained weights, thus obtaining provably better generalisation performance than conventional transfer learning."
SP:3a3249e97ef2345ea2264de5ed8287e16687838e,"This paper studies the phenomenon of decoupling the hyperparameters for mask discovery (Hfind) and mask evaluation (Heval) in unstructured magnitude pruning on vision classification tasks. The authors show that certain Hfind values lead to models which have lower performance but generate masks with substantially higher eventual performance compared to using the same hyperparameter for both stages. They show that this phenomenon holds across a number of models, datasets, configurations, and also for one-shot structured pruning. They demonstrate that different Hfind value yield masks with materially different layerwise pruning ratios and that the decoupled find-eval phenomenon is causally mediated by these ratios."
SP:2d6f5d72b21675f74ff4cde4d16bfb36abd5795f,"This paper proposes a new metric, called m-coherence, to study the alignment of per-example gradients during training. This metric is based on the Coherent Gradients (CG) theory, which provides a simple, unified explanation for memorization and generalization in neural networks. The authors show that the proposed metric is more interpretable, cheaper to compute (O(m) instead of O(m)) and mathematically cleaner. "
SP:e7c5de9a475d0ba71bc79580e8436024fb2c6f59,"This paper considers the problem of generating sufficient statistics for implicit generative models where the likelihood function is intractable but sampling data from the model is possible. The authors propose to learn mutual information maximizing representations of the data with the help of deep neural networks. The infomax learning procedure does not need to estimate any density or density ratio. They apply their approach to both traditional approximate Bayesian computation and recent neural likelihood methods, boosting their performance on a range of tasks."
SP:c5997bf2348e94949684f45fbd418661e85220c1,"This paper proposes a novel unsupervised image-to-image translation model (TUNIT) that simultaneously learns to separate image domains and translate input images into the estimated domains. The proposed model achieves comparable or even better performance than the set-level supervised model trained with full labels, generalizes well on various datasets, and is robust against the choice of hyperparameters (e.g. pseudo domains)."
SP:0cd97e64e638cabbeea0fdef3e9c5b33f4000f72,This paper studies the effect of gradient descent on the implicit bias in function space of deep neural networks. The main contribution of the paper is the analysis of the curvature penalty function 1/ζ of the network parameters in terms of the probability distribution that is utilized to initialize the network. The authors show that the solution of training a width-n shallow ReLU network is within n-1/2 of the function which fits the training data and whose difference from initialization has smallest 2-norm of the weighted second derivative with respect to the input. They also show the generalization of the result to multivariate regression and different activation functions.
SP:8b885142facbb3b8db41ec9d83822cee81324694,"This paper studies the problem of weight decay for adaptive gradient methods. The authors show that the L2 regularization is unstable for all optimizers that use Momentum, such as stochastic gradient descent (SGD). They further propose the Stable Weight Decay (SWD) method to fix the unstable weight decay problem from a dynamical perspective. The proposed SWD method makes significant improvements over L2 and decoupled weight decay in experiments."
SP:a3206dc71e32ba1830895bf442d3840f3331a532,". This paper proposes a novel method to combine the strengths of both Translation Memory (TM) and neural machine translation (NMT). The authors treat the matched sentence pair of TM as the additional signal and apply one encoder enhanced by the pre-trained language model (PLM) to encode the TM information and source sentence together. The authors extend the sentence level retrieval method to the n-gram retrieval method that doesn’t need to calculate the similarity score. Further, the authors explore new methods to manipulate the information flow from TM to the NMT decoder. The proposed methods are evaluated on a mixed test set of multiple domains."
SP:72b43991a242872b2ceb1861e8ffbdf26c9f4818,"This paper studies the problem of learning deep convolutional networks from the perspective of rate reduction and (shift-invariant) classification. The authors show that the basic iterative gradient ascent scheme for maximizing the rate reduction of learned features naturally leads to a deep network, one iteration per layer. The network is constructed layer-by-layer in a forward propagation fashion. The experiments show that such a network can already learn a good discriminative deep representation without any back propagation training. Moreover, all linear operators of the so-derived network naturally become multi-channel convolutions when we enforce classification to be rigorously shift invariant."
SP:f8b02cf1b918b0956761829ec6ef9127596071ec,"This paper studies the implicit acceleration of gradient flow in over-parameterized two-layer linear models. The authors show that implicit acceleration emerges from a conservation law that constrains the dynamics to follow certain trajectories. More precisely, gradient flow preserves the difference of the Gramian matrices of the input and output weights and the amount of acceleration depends on both the magnitude of that difference (which is fixed at initialization) and the spectrum of the data. In addition, and generalizing prior work, the authors prove their results without assuming small, balanced or spectral initialization for the weights."
SP:e5f086c806be88d50e461a782b5b00124f4656fb,"This paper studies the problem of OOD sampling in LIME, a popular approach to explainable machine learning (ML) models. The authors show that the OOD problem is due to the rigidity of the perturbation procedure, and propose a new algorithm CLIME to solve this problem. CLIME is based on uniform sampling of user-defined subspaces, which allows the end-user the flexibility to delineate the precise subspace of the input domain to be explained. Experiments show that CLIME can be applied to any ML model, and extensive experiments demonstrate its versatility on real-world problems."
SP:b1d5ef15772e192eb8c8a0e65b3c21ee7c794295,"This paper proposes AMBERT (A Multi-grained BERT), a pre-trained language model on the basis of both fine-Grained and coarsegrained tokenization. The proposed model takes both the sequence of words (finegrained tokens) and sequence of phrases as input after tokenization, employs one encoder for processing the words and the other encoder to process the phrases, utilizes shared parameters between the two encoders, and finally creates a sequence of contextualized representations of the words. Experiments have been conducted on benchmark datasets for Chinese and English, including CLUE, GLUE, SQuAD and RACE. The results show that AMBERt outperforms the existing best performing models in almost all cases."
SP:fd1cfe80343d3789227d99d836a5674374a234f5, Transformer is a Transformer-based model for semantic parsing. The main contribution of this paper is the introduction of Long Short-Term Memory (LSTM) into the Self-Attention mechanism of the original Transformer to capture more local context of phrases. Experimental results show that the proposed model captures the detailed meaning better than Transformer and raises local context awareness.
SP:2056a65a7500d79465685af883083cd706277c1f,"This paper proposes a method to improve the robustness of deep neural networks (DNNs) to adversarial perturbations. Specifically, the authors propose a method called composite adversarial training (CAT) that integrates and optimizes multiple adversarial losses, leading to significant robustness improvement with respect to individual perturbation as well as their “compositions”. The proposed method is evaluated on a variety of datasets and models."
SP:006e5b9ac9a8eb7223843731488bfefbd8eb09bd,"This paper proposes a novel recurrent network architecture for learning abstract rules from high-dimensional sensory data. The proposed architecture is based on a recurrent network augmented with an external memory that enables a form of variable-binding and indirection. This binding mechanism allows symbol-like representations to emerge through the learning process without the need to explicitly incorporate symbol-processing machinery, enabling the ESBN to learn rules in a manner that is abstracted away from the particular entities to which those rules apply. The authors show that this architecture displays nearly perfect generalization of learned rules to novel entities given only a limited number of training examples."
SP:4171ce45966ac499f51450a19fb233934c0847f0,"This paper proposes a framework for translation between augmented natural language (AL) and structured language prediction tasks. The proposed framework is based on the idea that the task-relevant information can be easily extracted from the language. The authors propose a new framework, TANL, to solve many structured prediction language tasks including joint entity and relation extraction, nested named entity recognition, relation classification, semantic role labeling, event extraction, coreference resolution, and dialogue state tracking. They show that their approach can match or outperform task-specific models on all tasks, and in particular, achieves new state-of-the-art results on joint entity extraction (CoNLL04, ADE, NYT, and ACE2005 datasets), relation classification (FewRel and TACRED), and semantic roles labeling (coNLL-2005 and CoNLL2012). "
SP:8f1b2fc6829e0bdfcc981020b0dcf3e63a947910,". This paper studies the problem of unlabeled entity recognition in NER models, where the entities of a sentence may not be fully annotated. The authors propose a general approach, which can almost eliminate the misguidance brought by unlabeling entities. The key idea is to use negative sampling that, to a large extent, avoids training NER model with unlabelled entities. Experiments on synthetic datasets and real-world datasets show that the proposed approach is robust to unlabelED entity problem and surpasses prior baselines."
SP:dd76ece8d92a8a230a8b43033d8cb2368c677a94,"This paper proposes a novel acoustic word embedding called Acoustic Neighbor Embeddings where speech or text of arbitrary length are mapped to a vector space of fixed, reduced dimensions by adapting stochastic neighbor embedding (SNE) to sequential inputs. The Euclidean distance between coordinates in the embedding space reflects the phonetic confusability between their corresponding sequences. Compared to a triplet loss criterion, the proposed method is shown to have more effective gradients for neural network training. It also gives more accurate results with low-dimensional embeddings when the two encoder networks are used in tandem in a word recognition task and when the text encoder network is used standalone in an approximate phonetic matching task."
SP:9142189126b8612ac0acee6fe18a0cfcb70b6545,This paper studies the problem of learning a mean-field state and a stationary policy in a game where the goal is to find the Nash equilibrium of the state and the policy. The authors propose a fictitious play algorithm to solve this problem. The algorithm is based on gradient descent and proximal policy optimization. They prove that their algorithm converges to the Nash equilibria at a sublinear rate. 
SP:c498f8a199da1818fe64ed88b0825c5aad688aec,"This paper studies the problem of approximate probabilistic inference on the joint distribution defined by a normalizing flow model. Given a pre-trained flow model p(x) for some arbitrary partitioning of the variables x = (x1,x2), the authors show that this task is computationally hard for a large class of flow models. Motivated by this hardness result, the authors propose a framework for approximate Probabilistic Inference that trains a new generative model with the property that its composition with the given model approximates the target conditional distribution. By parametrizing this new distribution as another flow model, they can efficiently train it using variational inference and also handle conditioning under arbitrary differentiable transformations. Since the resulting approximate posterior remains a flow, it offers exact likelihood evaluation, inversion, and efficient sampling."
SP:1d0f27f61c9d32911b8bd15d6b82ef5eec644f0f,This paper proposes a new dataset for cell membrane segmentation based on Electron Microscopy (EM) dataset with multiple iterative annotations and uncompressed high-resolution raw data. The authors propose a new evaluation criterion called Perceptual Hausdorff Distance (PHD) to measure the quality of cell membrane segmentsation results. The paper shows that the current popular segmentation evaluation criteria are inconsistent with human perception. This interesting phenomenon is confirmed by a subjective experiment.
SP:8ca7aff87c82be69c9542550c814f52c9419ab0a,"This paper proposes a modular architecture for continual learning (CL) where the modules represent atomic skills that can be composed to perform a certain task. The learning algorithm leverages a task-driven prior over the exponential search space of all possible ways to combine modules, enabling efficient learning on long streams of tasks. The experiments show that this modular architecture and learning algorithm perform competitively on widely used CL benchmarks while yielding superior performance on the more challenging benchmarks."
SP:cc819c61f408e88f247eb87946187ccec3dad32e,"This paper proposes a meta-learning approach to generate synthetic meta-tasks using generative models. The idea is to generate pairs of in-class and out-of-class samples from the latent space in a principled way, allowing us to create synthetic classes forming the training and validation data of a meta task. The proposed approach, LASIUM, outperforms or is competitive with current unsupervised learning baselines on few-shot classification tasks on the most widely used benchmark datasets."
SP:b25771e5c214a352f74ba6196fbd88bca6c43c98,"This paper studies the injectivity of fully connected and convolutional ReLU layers and networks. The authors show that an expansivity factor of two is necessary and sufficient for injectivity by constructing appropriate weight matrices. They show that global injectivity with iid Gaussian matrices, a commonly used tractable model, requires larger expansivity between 3.4 and 10.5. They also characterize the stability of inverting an injective network via worst-case Lipschitz constants of the inverse. "
SP:a95a153d3fe9bcf535ebf8514f51d00df483f210,"This paper proposes a continuous conditional generative adversarial network (CcGAN) for image generation conditional on continuous, scalar conditions (termed regression labels). Existing conditional GANs are mainly designed for categorical conditions (e.g., class labels); conditioning on regression labels is mathematically distinct and raises two fundamental problems: (1) Since there may be very few (even zero) real images for some regression labels, minimizing existing empirical versions of cGAN losses often fails in practice; (2) Since regression labels are scalar and infinitely many, conventional label input methods such as combining a hidden map of the generator/discriminator with a one-hot encoded label are not applicable. The proposed CcGAN solves the above problems by (S1) reformulating existing empirical cGAN loss to be appropriate for the continuous scenario; and (S2) proposing a novel method to incorporate regression labels into the generator and the discriminator. The reformulation leads to two novel empirical discriminator losses, termed the hard vicinal discriminator loss (HVDL) and the soft vicinal adversarial loss (SVDL), respectively, and a novel empirical generator loss. "
SP:10dd09ab315870631d1451d200f2c87a023f8226,"This paper proposes an active learning algorithm for semi-supervised learning (SSL) and active learning (AL) to reduce the sample complexity of fully supervised learning (SL). The main contribution of the paper is to propose a new algorithm called ""CRC"" that aims to control the convergence rate of a classification network by actively querying instances to improve the rate of convergence upon inclusion to the labeled set. Experiments show that the proposed algorithm is able to achieve better performance using far less labeled samples than SL."
SP:7f3947c3fa5b09674507d8f3e10d9280376ecb94,"This paper proposes a federated learning method for training neural network models where the server orchestrates cooperation between a subset of randomly chosen devices in each round. The authors propose a dynamic regularizer for each device at each round, so that in the limit the global and device solutions are aligned. They demonstrate both through empirical results on real and synthetic data as well as analytical results that their scheme leads to efficient training, in both convex and non-convex settings. "
SP:a3fbb073b0e2371b20d5d9df6ab829673f90354f,"-based self-supervised learning methods are computationally challenging. In this paper, the authors propose to use intermediate contrastive losses to speed up contrastive learning. The authors show that the intermediate losses are a good surrogate of the final similarity between the input and output images. The proposed method is tested on ImageNet linear classification, SimCLR and SwAV."
SP:5b5e705ea1ee1b857e17e64d560a39052804949d,"This paper studies the global convergence and global optimality of actor-critic in the single-time-scales setting, where the actor and critic are updated simultaneously. Specifically, the critic update is obtained by applying the Bellman evaluation operator only once while the actor is updated in the policy gradient direction computed using the critic. The authors prove that the actor sequence converges to a globally optimal policy at a sublinear O(K−1/2) rate, where K is the number of iterations. Moreover, under the broader scope of policy optimization with nonlinear function approximation, the authors also prove that actorcritic with deep neural network finds the global optimal policy for the first time."
SP:26705a4dc305cce336f657c5937d1f5b4209548a,"This paper proposes to represent log files at a few levels of abstraction including field level, log level, and log sequence level. These representations are in vector format and serve as interfaces to downstream applications. The authors use a version of Transformer Networks (TNs) to encode numerical and textual information that is suitable for log embeddings. They show how a number of log processing applications can be readily solved with their representation."
SP:165c51a16f17fb8726e968f8b34742b62011d60e,"This paper proposes a mathematical analysis of convolutional neural networks (CNNs) based on wavelet decompositions. The main idea of the paper is to decompose the network into a sequence of wavelets, which are modulated by freely-trained mixture weights. The paper proposes three variants of wavelet packet decomposition: separable, 2D dual-tree real and complex wavelets. Experiments show that the proposed method can achieve the accuracy of AlexNet, but with a significantly lower number of parameters."
SP:d0a284da462584724ba6a3a48c9e986d391233f6,"This paper proposes an attention mechanism for both the players and the coach in a multi-agent multi-player team game, where the players have a partial view of the environment, while the coach has a complete view. The attention mechanism is based on a variational objective to regularize learning, and an adaptive communication method to let the coach decide when to communicate with different players. Experiments are conducted on resource collection tasks in a particle environment, and the proposed method is shown to generalize to new team compositions with varying number of heterogeneous agents."
SP:4eb662b527d556758aaa1a0b589495fcc337fad0,"This paper studies the effect of network architecture, depth and width on the accuracy of influence functions in deep learning with non-convex loss functions. The authors conduct extensive experiments on Iris, MNIST, CIFAR-10, and ImageNet to study the impact of network depth, network width, and model parameterization on the influence function. They find that influence functions are fairly accurate for shallow networks, while for deeper networks the estimates are often erroneous. They also find that for certain network architectures and datasets, training with weight-decay regularization is important to get high-quality influence estimates."
SP:5fea74a2031d097a99dacf613bedcb054b0c3831,"This paper studies the connection between the pretraining task of next word prediction and text classification. The main contribution of the paper is to prove that the classification tasks of interest can be reformulated as sentence completion tasks, thus making language modeling a meaningful pre-training task. The paper shows that language models that are -optimal in cross-entropy (log-perplexity) learn features that can linearly solve such classification tasks with O(sqrt(log(1/2)) error, thus demonstrating that doing well on language modeling can be beneficial for downstream tasks. "
SP:a67da438e9821010284416170c3699ae7ff96c99,"This paper proposes a new algorithm for membership inference attacks (MIA) to detect if data samples were used to train a neural network model. Unlike the traditional MIA approaches, addressing classification models, this paper addresses conditional image generation models (e.g. image translation). Due to overfitting, reconstruction errors are typically lower for images used in training. However, the authors observe that some images are ”universally” easy, and others are difficult. To overcome this, they propose to use a novel difficulty score that can be computed for each image, and its computation does not require a training set. "
SP:6fe23ebe09f2a4e42a21598f8e9c79edeca99863,"This paper proposes a differentiable architecture search method by formulating it into a distribution learning problem by treating the continuously relaxed architecture mixing weight as random variables, modeled by Dirichlet distribution. This formulation improves the generalization ability and induces stochasticity that naturally encourages exploration in the search space. To alleviate the large memory consumption of differentiable NAS, the authors propose a simple yet effective progressive learning scheme that enables searching directly on large-scale tasks, eliminating the gap between search and evaluation phases. Extensive experiments demonstrate the effectiveness of the proposed method."
SP:c590d0ed2487b42480b53fc077546a4a0bc27a78,"This paper proposes a new type of function approximator for low-dimensional but complex functions. In particular, the authors propose to use a multiplicative filter network to represent the function as a linear function over an exponential number of Fourier or Gabor basis functions. The authors show that the proposed method outperforms ReLU networks and sinusoidal activation networks on a range of tasks. "
SP:f5be855300f63c185a006834302bd4b033b56258,"This paper proposes a new meta-learning algorithm that uses a student network to explore the search space of task-specific models and a teacher network to take a “leap” toward the regions probed by the student network. The teacher network is trained to find a high-quality model and defines a lightweight computation graph for meta-gradients. The proposed algorithm is tested on few-shot learning, long-tailed classification, meta-attack, and meta attack. "
SP:0361e02d56b7d121cb5ede1cb582284cc18fc599,"This paper proposes a new algorithm for offline reinforcement learning based on behavior regularization. The authors propose to use an analytical upper bound on KL divergence as the behavior regularizor to reduce variance associated with sample based estimations. They also employ state-dependent Lagrange multipliers for the regularization term to avoid distributing KL divergence penalty across all states of the sampled batch. To prevent catastrophic performance degradation due to rare out-of-distribution actions, they add a gradient penalty term to the policy evaluation objective to penalize the gradient of the Q value w.r.t the out of distribution actions. The proposed algorithm outperforms the state-of the art model-free and model-based approaches."
SP:b2cfb380aa2a21f72f508b453cf5949257a5b4ec, of the proposed method. The authors propose a one-shot learning paradigm that trains both the original and the smaller networks together. The parameters of the smaller network are shared across both the architectures. They prove strong theoretical guarantees on the regularization behavior of the adjoint training paradigm. They complement their theoretical analysis by an extensive empirical evaluation of both the compression and regularisation behavior of adjoint networks. 
SP:dba40073f79143e5355d194aa16db9eee0267a5d,"This paper proposes an extension of the greedy exploration algorithm in reinforcement learning (RL) by introducing a temporal extension to the greedy algorithm. The authors argue that the main limitation of greedy exploration is its lack of temporal persistence, which limits its ability to escape local optima. To address this limitation, the authors propose a temporal-extended greedy algorithm that simply repeats the sampled action for a random duration. Experiments show that the proposed algorithm outperforms greedy exploration on a large set of domains."
SP:5efb581a368ace3bd085d48801a899559d6a43ef,"This paper studies the implicit regularization of gradient flow with infinitesimal initialization in matrix factorization. In particular, the authors show that gradient flow is equivalent to Greedy Low-Rank Learning under some reasonable assumptions. They also extend the results to the case where depth > 3 and show that the above convergence has a much weaker dependence over initialization magnitude. "
SP:7f997cf7a63a7330fc12fd525516080c91a3cb9b,"This paper proposes CAMEL, a two-stage framework for improving the robustness of classifiers in the presence of spurious bandages. First, CAMEL first models subgroup features within a class and learns semantic transformations between them, and then trains a classifier with data augmentations that deliberately manipulate sub group features. CAMEL uses a CycleGAN to learn the intra-class, inter-subgroup augmentations, and balances subgroup performance using a theoretically-motivated subgroup consistency regularizer, accompanied by a new robust objective. The authors demonstrate CAMEL’s effectiveness on 3 benchmark datasets, with reductions in robust error of up to 33% relative to the best baseline."
SP:de6cea1e35a0555175e17546a93422e9a96a511e,"This paper proposes a new classifier, named Rulebased Representation Learner (RRL), that automatically learns interpretable nonfuzzy rules for data representation. To train the non-differentiable RRL effectively, they project it to a continuous space and propose a novel training method, called Gradient Grafting, that can directly optimize the discrete model using gradient descent. An improved design of logical activation functions is also devised to increase the scalability of RRL and enable it to discretize the continuous features end-to-end. Experiments on 9 small and 4 large data sets show that RRL outperforms the competitive approaches."
SP:e36388a9452e557dd51bf0170bf2f9da22271a49,This paper proposes a new regret minimization algorithm for molecular property prediction. The proposed algorithm is based on invariant risk minimization (IRM) and extends IRM by recasting the simultaneous optimality condition in terms of predictive regret. This allows the predictor to compete against an oracle with hindsight access to held-out environments. Experiments show that the proposed algorithm significantly outperforms previous state-of-the-art baselines.
SP:cad3ed2fba57faf17a3e8899dc5a744d5358aa68,"This paper proposes a novel approach to perform cross-modal attention in text-vision BERT models. The proposed approach is based on the idea of cross-probe BERT, where both text and vision probes are used as input to the BERT model. The approach is evaluated on two public benchmarks and shows state-of-the-art performance and efficiency."
SP:51fd82de525fcb738fdeaeeae20fbb2cdf975f0c,This paper proposes a new type of Actor-Critic algorithm named forward-looking Actor (FORK) for actor-critic algorithms. FORK can be easily integrated into a model-free ActorCritic method. Experiments on six Box2D and MuJoCo environments with continuous state and action spaces demonstrate significant performance improvement for FORK.
SP:6e730239e6e8b43c4988dd61dca30f15dc039ef7,. This paper proposes a new aggregation method for federated learning. The proposed method is based on Bayesian inference. The authors propose a Bayesian model ensemble approach to aggregate local models into a global model. They show that an effective model distribution can be constructed by simply fitting a Gaussian or Dirichlet distribution to the local models. The empirical studies validate the effectiveness of the proposed method.
SP:3ac5f437fc349a33810d0645664d1c448528af74,This paper proposes a method for explaining (conveying) the probabilistic explanation of Bert models. The method is based on the idea of using a neural network to predict the output of the model. The authors propose to use the model as a proxy for the model’s output. The paper is written in the form of a double-blind review paper. 
SP:efa2343ead47263a0d09e1c17f9aa044605b9650,This paper provides a priori guarantees of finite-time convergence in a deterministic control theoretic setting. The authors formulate the supervised learning framework as a control problem where weights of the network are control inputs and learning translates into a tracking problem. An analytical formula for finite time upper bound on the settling time is provided under the assumptions of boundedness of input. The loss function is robust against input perturbations.
SP:7a0ded4b3b2d08d43765ff7b722da9b9863aabd6,This paper studies the problem of disentanglement of representations in machine learning. The authors propose to use the mutual information between each learned latent variable and the auxiliary variable to correctly identify informative latent variables. They show that the method taken by GIN for informative latent variable selection is not theoretically supported and can be disproved by experiments. They directly verify the improvement brought by their method in experiments on synthetic data. 
SP:0d9ba12bbf47b13a46c2225f9dc06878418daaea,"This paper proposes LiftPool, a bidirectional pooling method for image classification and semantic segmentation. The main idea is to decompose a feature map into various downsized sub-bands, each of which contains information with different frequencies. The proposed method is based on the classical Lifting Scheme from signal processing. Experiments show that the proposed method achieves better results on image classification tasks. "
SP:147239edceb17bade6ea5d3dca44e3a59998aa47,"This paper studies the problem of binary embedding of a high-dimensional dataset T into binary sequences in the cube {±1}. When T consists of well-spread (i.e., non-sparse) vectors, the embedding method applies a stable noise-shaping quantization scheme to Ax where A is a sparse Gaussian random matrix. The authors show that Euclidean distances among the elements of T are approximated by the `1 norm on the images of the cube under a fast linear transformation. This again contrasts with standard methods, where the Hamming distance is used instead. The method is both fast and memory efficient, with time complexity O(m) and space complexity $O(\sqrt{m})$ on well spread data and $O(n log n)$ on non-well-spread data."
SP:f65e229bca3904095743e7a501b1083cc60f1e22,"This paper proposes to use plasticity rules as a proxy for Gradient Descent (GD) to improve the generalization and robustness of artificial neural networks (ANNs). In particular, the authors propose to use GD to learn the plasticity rule parameters of RNNs. They show that the proposed method is able to generalize well from one task to another and converge with fewer updates. In addition, they show that GD can recover the performance of the perceptron algorithm and the multiplicative weights method."
SP:f435530146fa975cb27cd375a857df9bcbd87682,"This paper proposes a novel approach for visual question generation (VQG) that aims to generate human-like questions from an image and potentially other side information (e.g. answer type or the answer itself). The authors propose a novel learning paradigm to generate visual questions with answer-awareness and region-reference. To this end, they develop a simple methodology to self-learn the visual hints without introducing any additional human annotations. To capture these sophisticated relationships, they propose a new double-hints guided Graph-to-Sequence learning framework that first models them as a dynamic graph and learns the implicit topology end to end, and then utilize a graph to sequence model to generate the questions with double hints. The experiments on VQA2.0 and COCO-QA datasets demonstrate that the proposed model can significantly outperform existing state-of-the-art baselines by a large margin."
SP:53a26ce11647866d3f6ba8b84ca9f13106197a8d,"This paper studies the effect of optimally-tuned regularization on the double-descent phenomenon. Theoretical results show that for certain linear regression models with isotropic data distribution, optimal regularization achieves monotonic test performance as we grow either the sample size or the model size. Empirically, the paper shows that optimally tuned regularization can mitigate double descent for more general models."
SP:c193ccc74b987beaf8d53a29a8529a0af5e87742,"This paper proposes a spatial dependency network (SDN) for variational autoencoder (VAE) models. SDN is based on a sequential gating-based mechanism that distributes contextual information across 2-D space. The authors show that SDN improves the density estimation over baseline convolutional architectures and the state-of-the-art among the models within the same class. In addition, SDN can be applied to large images by synthesizing samples of high quality and coherence. "
SP:db91512a90e75675af03c2f197751c8526d6f5e9,"This paper studies the problem of off-policy reinforcement learning (RL) in the offline setting, where a fixed collection of interactions are provided and no further interactions are allowed. The authors propose a simplified version of BCQ (Fujimoto et al., 2018a) which removes a heuristic design choice and naturally restricts extracted policies to remain exactly within the support of a given behavior policy. They derive this simplified algorithm through the introduction of a novel backup operator, Expected-Max Q-Learning (EMaQ), which is more closely related to the resulting practical algorithm. In addition to the distribution support, EMaQ explicitly considers the number of samples and the proposal distribution, allowing them to derive new sub-optimality bounds which can serve as a novel measure of complexity for offline RL problems. In the offline RL setting – the main focus of this work – EMAQ matches and outperforms prior state-of-the-art in the D4RL benchmarks (Fu et al. 2020a). In the online RL setting, the authors demonstrate that EMaq is competitive with Soft Actor Critic (SAC). The key contributions of this paper are demonstrating the importance of careful generative model design for estimating behavior policies, and an intuitive notion of complexity."
SP:e2b80adeaa9208e0667a64a3f24661f77b48e487,"This paper proposes a new batch selection algorithm for improving model fairness. The proposed algorithm is based on bilevel optimization, where the inner problem is to select minibatch sizes for the purpose of improving the fairness of the model. The main contribution of the paper is to propose a batch selection method that does not require any modification to data preprocessing or model training. Experiments on synthetic and real-world datasets show that the proposed algorithm can achieve comparable or better performance compared to existing methods."
SP:72f26b850bb2258223c0fc71598e35ad07d690e6,"This paper studies the bounds on the Lipschitz constant of monotone deep equilibrium (DEQ) networks. The main contribution of this paper is to show that the monotonicity of the network can be bounded as a simple function of the strong-monotonicity parameter. In particular, the authors derive simple-yet-tight bounds on both the input-output mapping and the weight- output mapping defined by these networks, and demonstrate that they are small relative to those for comparable standard DNNs. They show that one can use these bounds to design monotonic DEQ models, even with multiscale convolutional structure. They also highlight how to use these bound to develop PAC-Bayes generalization bounds that do not depend on the network depth."
SP:bcfd4d7fd4590e3bc248a0a5422ce4b67db74a74,"This paper studies the problem of imitation learning and goal-conditioned reinforcement learning, where the goal is to learn to reach a given state. The authors propose a method that uses density estimation to estimate the density of the reward function. They show that the proposed method can be applied to both imitation learning (i.e., learning from expert data) and goal conditioned reinforcement learning (e.g., learning to reach the goal in a stochastic setting). They show the effectiveness of the method in both settings. "
SP:d57550b2f323b356d7e609acc35ee33039f376b4,This paper proposes a variational multi-task learning framework for simultaneously learning multiple related tasks. The main contribution of the paper is the introduction of Gumbel-softmax priors to condition the prior of each task on related tasks and the mixing weights are learned in a data-driven manner for each individual task. The posteriors over representations and classifiers are inferred jointly for all tasks and individual tasks are able to improve their performance by using the shared inductive bias. The experimental results demonstrate that the proposed method achieves state-of-the-art performance on four benchmark datasets.
SP:3ccdf8322f16c8a7bef82e32fad4c03969a510d1,"This paper proposes a systematic and unified benchmark, Long-Range Arena, specifically focused on evaluating model quality under long-context scenarios. The benchmark is a suite of tasks consisting of sequences ranging from 1K to 16K tokens, encompassing a wide range of data types and modalities such as text, natural, synthetic images, and mathematical expressions requiring similarity, structural, and visual-spatial reasoning. The authors systematically evaluate ten well-established long-range Transformer models (Reformers, Linformers,. Linear Transformers, Sinkhorn Transformers, Performers, Synthesizers, Sparse Transformers, and Longformers) on the newly proposed benchmark suite."
SP:e12e410c3335b76133ceda4c865b244fbbab8580,"This paper proposes a multilingual code summarization model based on combining source code and abstract syntax tree (AST) representation learning. The main contribution of the paper is to propose a new model that jointly learns on Context and Structure of source code. The proposed model uses only language-agnostic features, i.e., source code, and features that can be computed directly from the AST. Besides, the proposed model achieves state-of-the-art results on monolingual code summarisation on all five programming languages considered in this paper."
SP:f46e98d48f90071831f1c0069bf74a7993be6db8,"This paper proposes a reinforcement learning approach for audio-visual navigation. The key idea is to learn a set of waypoints that are dynamically set and learned end-to-end within the navigation policy, and an acoustic memory that provides a structured, spatially grounded record of what the agent has heard as it moves. The proposed approach is evaluated on two challenging datasets of real-world 3D scenes, Replica and Matterport3D. The experiments show that the proposed approach improves the state of the art by a substantial margin."
SP:23bfe317dcef00a91ea92389b3f39d9b93972454,"This paper studies the effect of weight initializations on the convergence of small convolutional networks trained to predict n steps of the two-dimensional cellular automaton Conway’s Game of Life. The authors show that networks of this architecture trained on this task rarely converge. They find that networks require substantially more parameters to consistently converge. Furthermore, they find that the initialization parameters that gradient descent converges to a solution are sensitive to small perturbations, such as a single sign change. Finally, they observe a critical value d0 such that training minimal networks with examples in which cells are alive with probability d0 dramatically increases the chance of convergence."
SP:1b5ba618d3e28d48f9205c0780f8288a08fa5392,"This paper proposes a new semi-supervised learning algorithm that considers not only the perturbed inputs but also the similarity among the inputs having the same label. The authors propose a new objective function, dubbed BatchMean Triplet loss, which has the advantage of computational efficiency while taking into account all input samples. The proposed algorithm achieves state-of-the-art performance across many standard SSL benchmarks with a variety of labeled data amounts."
SP:f3abccf4a2566ffbc821aba209fab15058639ad4,"This paper studies the problem of few-shot meta-learning in a sequential learning setting, where the tasks are presented in sequence. The authors propose a new meta-training algorithm for this setting, which is based on the idea of meta-adaptation. The proposed algorithm is evaluated on a set of sequential learning problems, and the authors show that the proposed algorithm achieves better performance than standard supervised methods on these problems."
SP:95cb420d92ec42e12a4bbb0e66224f1c498a7161,"This paper proposes a series of probes to test the sensitivity of Transformer representations to several kinds of structure in sentences. Each probe involves swapping words in a sentence and comparing the representations from perturbed sentences against the original. Three different types of perturbations are used: random permutations of n-grams of varying width, swapping of spans which do or do not form a syntactic phrase, and swapping of two adjacent words which do not break apart a phrase, to test sensitivity to local phrase structure. Results from the three probes collectively suggest that Transformers build sensitivity to larger parts of the sentence along their layers, and that hierarchical phrase structure plays a role in this process."
SP:cb27b27a6fefc192ad1c2bd083d13eb9e51a5c44,"This paper studies the few-shot image synthesis task for GAN with minimum computing cost. The authors propose a skip-layer channel-wise excitation module and a self-supervised discriminator trained as a feature-encoder. They show their model’s superior performance compared to the state-of-the-art StyleGAN2, when data and computing budget are limited."
SP:c0dbeb5d94b2388595cf7ad9675c55df0bac7f8e,"This paper proposes a novel dual algorithm for neural network bounding. The main idea is to use a linear program of size linear in the number of neurons in the network to verify the tightness of the relaxation of the neural network. The authors show that the proposed algorithm recovers the strengths of the new relaxation in the dual space: tightness and a linear separation oracle. The proposed algorithm also shares the benefits of previous dual approaches for weaker relaxations: massive parallelism, GPU implementation, low cost per iteration and valid bounds at any time. "
SP:56e3837417dbcce0d65338dc3aac4e1a20eb0df8," pre-trained language models (PTLM) have achieved impressive results in a range of natural language understanding (NLU) and generation (NLG) tasks. However, current pre-training objectives such as masked token prediction and masked span infilling (for T5-style PTLMs) do not explicitly model the relational commonsense knowledge about everyday concepts, which is crucial to many downstream tasks that need common sense to understand or generate. The authors propose both generative and contrastive objectives for learning common sense from the text, and use them as intermediate self-supervised learning tasks for incrementally pre-train PTLM (before task-specific fine-tuning on downstream datasets). Furthermore, they develop a joint pre- training framework to unify generative-and-contrastive objectives so that they can mutually reinforce each other. Extensive experimental results show that their method, concept-aware language model (CALM) can pack more common sense knowledge into the parameters of a pre- trained text-to-text transformer without relying on external knowledge graphs, yielding better performance on both NLU and NLG tasks."
SP:7ec69bdee021af506293c87a3b75bce1c40a03d7,"This paper proposes a method for unsupervised physical object discovery. The proposed method is based on a multi-scale pixel-based neural network that learns to segment observable and partially occluded objects of varying sizes, and infer properties of those objects. The method is evaluated on both synthetic and real-world scenes. "
SP:66997bc19a3ba6548fcf21f114e748bea95cad1c," image dataset. The paper proposes a novel training method called Increasing Margin Adversarial (IMA) Training to improve DNN robustness against adversarial noises. During training, the IMA method increases the margins of training samples by moving the decision boundaries of the DNN model far away from the training samples to improve robustness. The proposed method is evaluated on six publicly available datasets (including a COVID-19 CT image dataset) under strong 100-PGD white-box adversarial attacks. "
SP:276ffd59fbf49e3ee02756da8920218102214917,"-based knowledge distillation is an approach to derive compact models from bigger ones. However, it has been observed that a converged heavy teacher model is strongly constrained for learning a compact student network and could make the optimization subject to poor local optima. In this paper, the authors propose ProKT, a new model-agnostic method by projecting the supervision signals of a teacher model into the student’s parameter space. Such projection is implemented by decomposing the training objective into local intermediate targets with approximate mirror descent technique. Experiments on both image and text datasets show that the proposed ProKT consistently achieves the state-of-the-art performance."
SP:906dc21d6988953fcf57d63bbdd12973e5818d16,"-based channel pruning method is proposed to solve the problem of compression and acceleration of Convolutional Neural Networks (CNNs). The proposed method uses a hyper-structure network to generate the architecture of the main network, which can be optimized by regular backpropagation. The authors also use a regularization term to specify the computational resource of the compact network. Extensive experimental results on CIFAR-10 and ImageNet show that the proposed method is competitive with state-of-the-art methods."
SP:890fd9454596c051b0e9535baf73b1dd1fae67ca,"This paper proposes a method for learning to prove higher-order logic theorem in the presence of a large knowledge base of potential premises without learning from human proofs. The authors propose to augment the exploration of premises based on a simple tf-idf (term frequency-inverse document frequency) based lookup in a deep reinforcement learning scenario. The experiments show that their theorem prover trained with this exploration mechanism but no human proofs, dubbed DeepHOL Zero, outperforms provers that are trained only on human proof."
SP:88209417a8ad07e6103084e41709be900303ce5f,"This paper proposes MODALS (Modalityagnostic Automated Data Augmentation in the Latent Space) to augment data for any modality in a generic way. MODALS exploits automated data augmentation to fine-tune four universal data transformation operations in the latent space to adapt the transform to data of different modalities. The proposed method is evaluated on multiple datasets for text, tabular, time-series and image modalities and shows the effectiveness of MODALS."
SP:6d84670d321b0d584b097c630574bd748e85c9a2,"This paper studies the global convergence of three-layer neural networks in the mean-field regime. The main contribution of the paper is to prove a global convergence result for unregularized feedforward feedforward networks under stochastic gradient descent. The authors propose a new neural network embedding based on a neuronal embedding, which comprises of a fixed probability space that encapsulates neural networks of arbitrary sizes. The identified mean field limit is then used to prove global convergence guarantees under suitable regularity and convergence mode assumptions, which does not rely critically on convexity. "
SP:b90f893f927db9c439595fd119a565cf43c971f4,"This paper proposes a method for learning explanations of expert decisions by modeling their reward function in terms of preferences with respect to “what if” outcomes: Given the current history of observations, what would happen if we took a particular action? To learn these costbenefit tradeoffs associated with the expert’s actions, the authors integrate counterfactual reasoning into batch inverse reinforcement learning (BIRL) to learn the reward function and explain expert behavior. The authors show the effectiveness of their approach in recovering accurate and interpretable descriptions of behavior. "
SP:c92916780418bfa7f0796fd9766b6d28b9eea5ef,"This paper investigates the effect of using morphological information in graph neural networks (GNNs) for continuous control. The authors propose a transformer-based approach AMORPHEUS, which is based on the idea that GNNs do not benefit from the information encoded in the graph structure. The proposed method is evaluated on a number of continuous control tasks. The results show that the proposed method does not improve the performance of existing GNN-based methods that use the information from the graph."
SP:2cf58f5cac20dccdc2034ef60e8e46b7988ebd7d,"This paper proposes MoVie, a method for visual counting, which aims to predict the number of occurrences given a natural image and a query (e.g. a question or a category). Unlike most prior works that use explicit, symbolic models which can be computationally expensive and limited in generalization, this paper proposes a simple and effective alternative by revisiting modulated convolutions that fuse the query and the image locally. Following the design of residual bottleneck, the authors call their method MoVIE, short for Modulated Convolutional Bottlenecks. Movie shows strong performance on counting-specific VQA tasks while being more efficient and outperforming prior-art on difficult benchmarks."
SP:c64e77507e562f236cb69361b22fb1a7951ffb22,This paper proposes a model-targeted poisoning attack based on online convex optimization. The authors prove that the distance from the induced classifier to the target classifier is inversely proportional to the square root of the number of poisoning points. They also provide a lower bound on the minimum number of points needed to achieve a given target classifiers. The proposed attack is the first model-based poisoning attack that provides provable convergence. 
SP:a526023ec4cb839b83c574d31f59a9a67bc7af00,"This paper proposes a method for real-time point cloud point cloud applications that run on edge devices. The proposed method is based on the idea that aggregation-induced feature homogenization leads to a degradation of information entropy, and scale distortion hinders optimization and invalidates scale-sensitive structures. The authors propose to modulate the distribution before aggregation for the maximum information entropy and layer-wise scale recovery (LSR) to efficiently restore feature representation capacity. Extensive experiments show that the proposed method outperforms existing binarization methods by convincing margins."
SP:825b4d1db0c537a607655bb5b4bf221ec672c8af,"This paper proposes to augment the Transformer model by adding memory tokens to store non-local representations, creating memory bottleneck for the global information, and controlling memory update with dedicated layer. Experiments are conducted on machine translation and language modelling tasks and show that the presence of memory positively correlates with the model performance."
SP:f0fa1b7684bc605f6edd4813c44be20988fe8b4c,"This paper proposes Prototypical Contrastive Learning (PCL), an unsupervised representation learning method that bridges contrastive learning with clustering. Specifically, PCL introduces prototypes as latent variables to help find the maximum-likelihood estimation of the network parameters in an Expectation-Maximization framework. PCL outperforms state-of-the-art instance-wise contrastive methods on multiple benchmarks with substantial improvement in low-resource transfer learning."
SP:5342a5e1d87fd17b1a2efed967dbbfeafa440ee7,"This paper proposes an orthogonal multi-path (OMP) block to improve the robustness of deep neural networks against adversarial attacks. The proposed OMP block is based on the idea of orthogonality constraint, where the parameters of the paths are required to be orthonormal with each other. The authors show that the OMP blocks can improve the performance of neural networks in both white-box and black-box attacks."
SP:776df66274ed12449fde8dcef873a593980f397c,"This paper proposes a self-supervised graph attention network (SuperGAT) for noisy graphs. Specifically, SuperGAT learns to predict edges whose presence and absence contain the inherent information about the importance of the relationships between nodes. By encoding edges, the network learns more expressive attention in distinguishing mislinked neighbors. Experiments on 17 real-world datasets demonstrate that the recipe generalizes across 15 datasets of them and our models designed by recipe show improved performance over baselines."
SP:80a05296d6b1e4c6e9e2df01938c73029ff8487d,"This paper proposes a new method for DSMAD, called INS-DS (Introspective Diagnosis System), which consists of two modules: an inquiry module for proposing symptom-inquiries and an introspective module for deciding when to inform a disease. The proposed method is inspired by the introspective decision-making process of human, where the inquiry module first proposes the most valuable symptom inquiry, then the introspection module intervenes the potential responses of this inquiry and decides to inquire only if the diagnoses of these interventions vary. Extensive experimental results demonstrate that the proposed method achieves the new state-of-the-art under various experimental settings and possesses the advantages of reliability and robustness compared to other methods."
SP:10ae09d90d465125433a9b4f15b1405ab017920d,"This paper proposes a new regularization method for the Fine-Grained Visual Classification (FGVC) problem. The proposed method is based on the Batch Confusion Norm (BCN) regularization term. The BCN term is used to address the long-tailed and inter-class similarity problems in the FGVC problem. In particular, the authors propose to use BCN to alleviate the overfitting problem in the case of long-tail cases. The authors show that BCN can be used to improve the performance of FGVC models on several benchmark datasets."
SP:90f1e0fe1e9678d1e9a4dcb519d4e8fd61098ce0,This paper proposes a new method for inverse reinforcement learning based on Bayesian reward inference. The main idea is to learn an approximate posterior distribution over the reward that scales to arbitrarily complicated state spaces alongside an appropriate policy in a completely offline manner through a variational approach to the latent reward. Experiments are conducted on real medical data and classic control simulations to demonstrate the effectiveness of the method.
SP:ccd251d95c0a2d8dc5ad2a148ec29955e105e71e,"This paper proposes a method for learning counterfactual belief distributions for partially observable environments. The proposed method is based on an approximate auto-regressive belief distribution that is learned as a supervised task. In the multi-agent settings, the method uses a novel public-private model architecture for underlying policies in order to efficiently evaluate these policies during rollouts. In Hanabi, the proposed method obtains more than 60% of the benefit of exact search while reducing compute requirements by 35x."
SP:db408e6bfe69a9b3984f3b27ca92b802aa37af42,"This paper proposes Shoot Tree Search (STS), a variant of MCTS and random shooting. The main idea of STS is to use the bias-variance trade-off between depth and breadth of the search. The authors show that STS can get the best of both worlds consistently achieving higher scores. "
SP:5efc271ccc555fd9aa542548838170bd4c98e957,"This paper proposes a method for learning inductive bias from synthetic datasets. The authors propose a new pre-training method called LIME (Learning Inductive bias for Mathematical rEasoning) which is based on the idea that inductive biases can be encoded in the form of datasets. To this end, they design three synthetic tasks that are intended to require the model to have these three abilities: deduction, induction, and abduction. These synthetic tasks are designed in a way that they are devoid of mathematical knowledge to ensure that only the fundamental reasoning biases are learned from these tasks. The proposed method LIME significantly outperforms vanilla transformers on three large mathematical reasoning benchmarks."
SP:bb8e0b554d3b3314fa343c902d9e60f1a141ea30,"This paper studies the inductive bias of gradient descent for weight normalized smooth homogeneous neural nets, when trained on exponential or cross-entropy loss. The authors show that the gradient flow path with EWN is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. These results can be extended to hold for gradient descent via an appropriate learning rate. Experimental results on simple data sets and architectures support the claim."
SP:c71f9d2a602516865a0b103028186e83b52e5f00," GANs are known to suffer from mode collapse, in which some modes of the target distribution are ignored by the generator. The authors propose a novel training procedure that dynamically spawns additional discriminators to remember previous modes of generation. They show that their training scheme can be plugged in to existing GAN frameworks to mitigate mode collapse and improve standard metrics for GAN evaluation."
SP:52c48198c95826e042f9e5a512ef3265daaff882,". This paper proposes an approach to regularize BERT by pruning its attention heads based on a proxy score for head importance. Instead of relying on heuristics or rule-based policies, AUBER learns a pruning policy that determines which attention heads should or should not be pruned for regularization. Experimental results show that AUBer outperforms existing pruning methods by achieving up to 9.39% better accuracy."
SP:abcbbad146f1b0d5d579c215952c95e5499a378a,"This paper proposes a method for learning correspondence between two domains, i.e., simulation and real-world. The authors propose a cycle-consistency constraint to learn the correspondence between the two domains. The correspondence is learned using unpaired and randomly collected data from both domains. Once the correspondence is found, the authors propose to directly transfer the policy trained on one domain to the other without needing any additional fine-tuning on the second domain. Experiments are conducted on a variety of problem domains, both in simulation and on real robot."
SP:006434d56992836ab9420d7d4215bc70664de304,"This paper studies the problem of Shapley explainability in the context of machine learning. The authors show that the Shapley framework for explainability attributes a model’s predictions to its input features in a mathematically principled and model-agnostic way. In particular, the authors propose two solutions to Shapley explainedability that respect the data manifold. One solution, based on generative modelling, provides flexible access to data imputations; the other one directly learns the value-function, providing performance and stability."
SP:7cda6bccf08887c7cef66d0ac3ccefdea8f5d7c8,This paper proposes a method for learning the embeddings of the opponent’s actions and actions of the agent using a variational autoencoder (VAE). The VAE is trained to reconstruct the local actions and observations of the opponents based on the learned embedding. The proposed method is evaluated on a variety of multi-agent tasks and shows that the proposed method achieves comparable performance to an ideal baseline which has full access to the opponents’ information.
SP:c239bc531bcf7293032748af29a1b786e9d893dd," in contrastive learning. The authors propose Consistent Contrastive Learning (CO2) to address the issue of heterogeneous similarity between the query crop and each crop from other images, taking them as equally negative. CO2 is inspired by consistency regularization in semi-supervised learning on unlabeled data. Empirically, CO2 improves Momentum Contrast (MoCo) by 2.9% top-1 accuracy on ImageNet linear protocol, 3.8% and 1.1% on 1% and 10% labeled settings. It also transfers to image classification, object detection, and semantic segmentation tasks."
SP:d18bab21790713e2facb053c47298fc9079ab783,"This paper studies the last-iterate convergence of Optimistic Gradient Descent Ascent (OGDA) and Optimistic Multiplicative Weights Update (OMWU) for bilinear games over the probability simplex. The main contribution of this paper is to show that when the equilibrium of the game is unique, OGDA and OMWU converge with a learning rate whose value is set to a universal constant, improving the result of (Daskalakis & Panageas, 2019b) under the same assumption. The paper further extends the results to more general objectives and feasible sets for the projected OGDA algorithm, by introducing a sufficient condition under which OGDA exhibits concrete last- iterate convergence rates with a constant learning rate, whose value only depends on the smoothness of the objective function. Finally, the paper provides experimental results to support the theory."
SP:bbc7f77308b298c332a39747f693bc396f00a89f,"This paper proposes FedUV, a framework for training user verification models in federated setup where each user has access to the data of only one class and user embeddings cannot be shared with the server or other users. The authors propose to jointly learn a set of vectors and maximize the correlation of their instance embedding with a secret user-defined linear combination of those vectors. They show that choosing the linear combinations from the codewords of an error-correcting code allows users to collaboratively train the model without revealing their embedding vectors. The experimental results for user verification with voice, face, and handwriting data show that FedUV is on par with existing approaches, while not sharing the embedDings with other users or the server."
SP:40fa47cc0928e2925ef5ce6d808073f368ca2cd4,"This paper proposes a method to estimate the effective dimension of class manifolds (CMs) by computing their intersection with random affine subspaces of varying dimension. The authors provide a theory for the technique and verify that their theoretical predictions agree with measurements on real neural networks. Through extensive experiments, they leverage this method to show deep connections between the geometry of CMs, generalization, and robustness. They investigate how CM dimension depends on 1) the dataset, 2) architecture, 3) random initialization, 4) stage of training, 5) class, 6) ensemble size, 7) label randomization, 8) training set size and 9) model robustness to data corruption."
SP:09bce202ac7a750c3700a8ef3cd92cfe8ed00c39,This paper proposes a novel approach to the exploration-exploitation trade-off in Soft Actor-Critic (SAC). The key idea is to use the state prediction error to model the curiosity of the agent to increase the entropy temperature for unfamiliar states and decrease the target entropy for familiar states. Experiments on the MuJoCo benchmark show that the proposed approach significantly improves the sample efficiency.
SP:dce5eb20581a21c5de0a9fc07a8a79a1fbb28c71,"This paper proposes a meta-reinforcement learning algorithm that is both efficient and extrapolates well when faced with out-of-distribution tasks at test time. The proposed method is based on the observation that dynamics models can be adapted efficiently and consistently with off-policy data, more easily than policies and value functions. The authors propose to use the dynamics models to generate synthetic experience for the new task by generating synthetic experiences for the old task. The dynamics models are then used to continue training the policy and value function without meta-learning at all."
SP:34d78aa11f9d50baf75a9646a6f9128318c3389a,"This paper studies the problem of meta-learning in few-shot learning (FSL) where there are only a few available samples with sampling noise and label noise. The authors propose Eigen-Reptile (ER) that updates the meta-parameters with the main direction of historical taskspecific parameters to alleviate gradient noise. Furthermore, they propose Introspective Self-paced Learning (ISPL) that constructs a plurality of prior models to determine which sample should be abandoned. "
SP:a571bff9ffe4edafd7bc064c4d10609e6b981ce3,"This paper proposes a method to train deep neural networks to be robust to distributional shifts in the distribution of input images. The proposed method is based on adversarial perturbations of the mean and variance of the feature statistics of the input image. The authors show that the proposed method improves the performance of ResNet-50 on ImageNet-C, Stylized-ImageNet, and ImageNetInstagram over standard training practices."
SP:6a9c46bd3cf854299f360bff136e1d79d3edb2e4,This paper proposes Variance of Gradients (VoG) as a proxy metric for detecting outliers in the data distribution. The authors provide quantitative and qualitative support that VoG is a meaningful way to rank data by difficulty and to surface a tractable subset of the most challenging examples for human-in-the-loop auditing. Data points with high VoG scores are far more difficult for the model to learn and over-index on corrupted or memorized examples.
SP:074bfacc75837bb19049be8a2890e10de073dd8e,"This paper proposes a new method to improve the quality of generated samples by using the gradient flow of entropy-regularized f-divergences between the real and generated data distributions. The proposed method is based on the non-linear Fokker-Plank equation, which can be easily simulated by sampling from the equivalent McKean-Vlasov process. The authors show that the proposed method can be applied to GANs with vector-valued critics and other deep generative models such as VAEs and Normalizing Flows."
SP:74ecbc5a6d464bfa49337da9e0dd6a0fe714d4bb,"This paper presents a pre-training approach to unify the two mainstream Transformer architectures in both model architectures and pre-trained tasks. The proposed approach splits the standard Transformer block into several sub-modules trained with both innersequence and cross-sequence masked language modeling, and correspondingly reorganizes certain sub- modules for understanding and generation tasks during inference. Such a workflow not only ensures to train the most streamlined parameters necessary for two kinds of tasks, but also enables them to boost each other via sharing common sub-modules. The paper shows state-of-the-art results on various cross-lingual understanding tasks of the XTREME benchmark covering text classification, sequence labeling, question answering, and sentence retrieval. "
SP:3d177ad50727d1a2619b68ab8a897b79d8652beb,This paper proposes a novel intrinsic reward for reinforcement learning based on auditory event prediction. The authors propose to use K-means to discover the underlying auditory event clusters and train a neural network to predict the auditory events and use the prediction errors as intrinsic rewards to guide RL exploration. They first conduct an in-depth analysis of their module using a set of Atari games. They then apply their model to audio-visual exploration using the Habitat simulator and active learning using the ThreeDWorld (TDW) simulator. Experimental results demonstrate the advantages of using audio signals over vision-based models as intrinsic reward.
SP:014f6118ebe55ece6be23c3a10f12e4591e444b1,"This paper proposes an end-to-end framework to jointly learn a reliable representation and assign clusters to unlabelled data. To avoid overfitting the learnt embedding to labelled data, the authors extend the self-supervised representation learning by noise-contrastive estimation and extend it to jointly handle labelled and unlabelling data. In particular, they proposed using category discrimination on labelled data and cross-modal discrimination on multi-modality data to augment instance discrimination used in conventional contrastive learning approaches. They further employ Winner-Take-All (WTA) hashing algorithm on the shared representation space to generate pairwise pseudo labels for unlabels to better predict cluster assignments."
SP:4df640f502e88ddba2d7e183625231d70b083e82,"This paper proposes a method for weakly supervised segmentation of images with partial annotations such as image-level tags, object bounding boxes, labeled points and scribbles. The authors propose 4 types of contrastive relationships between pixels and segments in the feature space, capturing low-level image similarity, semantic annotation, co-occurrence, and feature affinity. The pixel-wise feature can be learned from training images with any partial annotations in a data-driven fashion. The proposed method outperforms Pascal VOC and DensePose on weakly-supervised segmentation tasks."
SP:f7d6099adb40a0ce2f8a3563dbd5207cf1fdea0f,"This paper proposes a simple but effective distillation strategy for unsupervised self-supervised learning. The proposed method, BINGO, is short for Bag of InstaNces aGgregatiOn, targets at transferring the relationship learned by the teacher to the student. The goal of distillation is to aggregate compact representations over the student with respect to instances in a bag. The method achieves new state-of-the-art performance on small scale models with linear evaluation on ImageNet."
SP:328866aad6544c81ded8980934df31dc4472435f,"This paper proposes GATSBI, a generative adversarial approach to simulation-based inference (SBI) in which we can generate samples, but not compute likelihoods. The authors propose to reformulate the variational objective in an adversarial setting to learn implicit posterior distributions, which is amortised across observations, works in high-dimensional posterior spaces and supports implicit priors. The proposed approach is evaluated on two SBI benchmark problems and on two high-dimension simulators. "
SP:2915e82097eae4eb8546dc500f32b3ec37e3766f,This paper studies the problem of identifying and estimating treatment effects (TEs) under limited overlap. The authors propose to use a generative prognostic model to model a prognostic score which is widely used in biostatistics and sufficient for TEs. The model is then learned as a new type of variational autoencoder (VAE). The TE error bounds are derived. The proposed method is compared with recent methods using synthetic datasets.
SP:ca358c9f36aac6e58ed1b3949c349d210c49a48e,"This paper proposes a framework for autonomous reinforcement learning (ARL) where the agent not only learns through its own experience, but also contends with lack of human supervision to reset between trials. The authors introduce a simulated benchmark EARL1 around this framework, containing a set of diverse and challenging simulated tasks reflective of the hurdles introduced to learning when only a minimal reliance on extrinsic intervention can be assumed. They show that standard approaches to episodic RL and existing approaches struggle as interventions are minimized, underscoring the need for developing new algorithms with a greater focus on autonomy."
SP:abe51d4a9817c08f0abde5da0bb8e6ca4e02e7cf," QA systems commonly use pre-trained language models (LMs) to access knowledge encoded in LMs together with elaborately designed modules based on Graph Neural Networks (GNNs) to perform reasoning over knowledge graphs (KGs). However, many problems remain open regarding the reasoning functionality of these GNN-based modules. To open the black box of GNN and investigate these problems, the authors dissect state-of-the-art GNN modules for QA and analyze their reasoning capability. They discover that even a very simple graph neural counter can outperform all the existing GNNs on CommonsenseQA and OpenBookQA, two popular QA benchmark datasets which heavily rely on knowledge-aware reasoning."
SP:3ea5a38e7fcd9111dcd299ad039b634e2781685f,"This paper proposes a method for Deep Neural Network (DNN) inference with near-optimal compression and much better performance during inference runtime. The key insight of the method leverages the concept of Succinct Data Structures, which supports fast queries directly on compressed representation without decompression. The proposed method first transforms DNN models as their proposed formulations in either Element-wise or Block-wise manner, so that the compressed representation can take advantage of. Finally, the method exploits the specialized execution pipelines for different model formulations, to retrieve relevant data for DNN inference. The experimental results show that, the proposed method keeps near optimal compression and achieves at least 8.7X/11.5X speedup on AlexNet/VGG-16 inference, compared with Huffman Coding."
SP:94c395afc794a9cc163e362078769ff83f3d20d0,"This paper proposes Network Augmentation (NetAug), a training method for improving the performance of tiny neural networks. The authors argue that training tiny models is different from training large models: rather than augmenting the data, we should augment the model, since tiny models tend to suffer from under-fitting rather than over-fitting due to limited capacity. To alleviate this issue, NetAug augments the network (reverse dropout) instead of inserting noise into the dataset or the network. It puts the tiny model into larger models and encourages it to work as a sub-model of larger models to get extra supervision, in addition to functioning as an independent model. At test time, only the tiny network is used for inference, incurring zero inference overhead."
SP:9c24549b980e415616f818acbf4cf680ef8edb52," point cloud sequence is an important data representation that provides flexible shape and motion information. However, it is prohibitively expensive to acquire point correspondence information across frames in real-world environments. In this paper, the authors propose a super-resolution generative adversarial network (GAN) for dynamic point cloud sequences without requiring point correspondence annotation. The proposed model, Temporal Point cloud Upsampling GAN (TPU-GAN), can implicitly learn the underlying temporal coherence from point clouds sequence, which in turn guides the generator to produce temporally coherent output. In addition, a learnable masking module is proposed to adapt upsampling ratio according to the point distribution. Experiments on two different domains: particles in the fluid dynamical system and human action scanned data demonstrate the effectiveness of the proposed method."
SP:67efe60ad37807505369b7852bc0abed29ffdda8,"-based pre-training is a well-known technique to improve the robustness and generalization of the encoder-only transformer. This paper proposes a new method that fully pre-trains an encoder only transformer and smoothly finetunes it for object detection via a task adapter. Inspired by the success of textual prompts in NLP, the proposed method treats query positional embeddings as visual prompts to help the model attend to the target area (prompting) and recognize the object. Experiments on the challenging COCO dataset demonstrate that our PT-DETR achieves competitive performance."
SP:a1f9897496303984fc7ad469222106b14b4a6233,"This paper proposes FedPAGE, a new local SGD algorithm for federated convex and nonconvex optimization. The main contribution of the paper is to improve the communication complexity of FedAvg by utilizing the recent optimal PAGE method (Li et al., 2021). The authors show that FedPAAGE uses much fewer communication rounds than previous local local methods for both federate convex (i.e., in the convex setting, the number of communication rounds is O(3/4 S), improving the best-known result O(N S) of SCAFFOLD (Karimireddy et al. 2020) by a factor of N, where N is the total number of clients, where S is the sampled subset of clients in each communication round, and is the target error, and where the communication cost is the same for each round. The authors also show that in the nonconformist setting, FedPAGave achieves O(\sqrt{NS}(N^2/3 S^2+S^2) in terms of communication cost, improving the previous state-of-the-art result $O(NS)$ of SCaFFOLD."
SP:81e74765abc6524edd8fdf9a3ba107d7bddaa04b,"This paper studies the decision boundary geometry of ANN classifiers by utilizing adversarial perturbations. The authors define adversarial subspaces, which are spanned by orthogonal directions of minimal perturbation to the decision boundaries from any given input sample. The decision boundary lies close to input samples in a large subspace, where the distance to the boundary grows smoothly and sub-linearly as one increases the dimensionality of the subspace. The geometry of the boundary is more curved within the adversary subspace than within a random subspace of equal dimensionality."
SP:af5c25ecf38c5c3f3387720bdc80c2c54c5699fe,. The paper proposes a two-stage weakly-supervised contrastive learning approach. The first stage is to cluster data according to its auxiliary information. The second is to learn similar representations within the same cluster and dissimilar representations for data from different clusters. The proposed approach is evaluated on synthetic and real-world datasets.
SP:0a92fcc52970201de4a66b1e76c93dbea9dfd3f1,"This paper studies the problem of estimating sparse parameters from observational data. The authors propose PLISA (Provable Learning-based Iterative Sparse recovery Algorithm) to learn algorithms automatically from data. PLISA is designed by unrolling a classic path-following algorithm, with some components being more flexible and learnable. With this structure, the authors theoretically show the improved recovery accuracy achievable by PLISA. Furthermore, they analyze the empirical Rademacher complexity of PLISA to characterize its generalization ability. "
SP:5064eda9ba27060af15e81b2b317b2e4558b0ac4,"This paper proposes a novel approach to learn a compact and decodable latent representation space for discrete-continuous hybrid action space. The proposed approach is based on an embedding table and conditional Variational Auto-Encoder (VAE) to embed the dependence between discrete action and continuous parameter via an embeddings table. To further improve the effectiveness, the action representation is trained to be semantically smooth through unsupervised environmental dynamics prediction. Finally, the agent then learns its policy with conventional DRL algorithms in the learned representation space and interacts with the environment by decoding the hybrid action embedding to the original action space and interacting with the environments. "
SP:5128bf712f6b197de113c7a371b4bec36f978eca,"This paper proposes SGEM, Stochastic Gradient with Energy and Momentum to solve a large class of general non-convex stochastic optimization problems, based on the AEGD method that originated in the work [AEGD: Adaptive Gradient Descent with Energy. arXiv:2010.05109]. SGEM incorporates both energy and momentum at the same time so as to inherit their dual advantages. The authors show that SGEM features an unconditional energy stability property, and derive energy dependent convergence rates in the general nonconveX setting, as well as a regret bound in the online convex setting. The experimental results show that the proposed method generalizes better or at least as good as SGDM in training some deep neural networks."
SP:11f49b0a975be87769be29e85d7e3924699cf2c9,"This paper proposes a method to improve the performance of Transformer-based autoregressive (AR) machine translation models. The proposed method is based on the Conditional Masked Language Model with Correction (CMLMC), which is an extension of the Transformer model. CMLMC is trained on raw data without distillation and achieves state-of-the-art NAR performance on multiple datasets."
SP:96f8ac3c6163e56d8ae1954a162bae01e6b58a0a,"This paper proposes WaveSense, a spiking neural network inspired by the WaveNet architecture. WaveSense uses simple neural dynamics, fixed time-constants and a simple feed-forward architecture and hence is particularly well suited for a neuromorphic implementation. The results show that the proposed network beats the state-of-the-art performance of CNNs and LSTMs."
SP:7f20a2e4e95f857140b87b0730360b3ff2f371f4,"This paper proposes a new algorithm, called Shifty, that provides high-confidence behavioral guarantees that hold under demographic shift. The proposed algorithm is based on the idea that the data used for training is not representative of what will be encountered in deployment, which is often untrue. The algorithm is evaluated on a real-world dataset of university entrance exams and subsequent student success. The experiments demonstrate that the algorithm is an effective tool for training models that are fair when demographic shift occurs."
SP:94f097921bee5fdc10ec2e7c901b2ddb876d9d41,"This paper proposes a neural network-based approach to solve stochastic dual dynamic programming (SDDP) problems. The main idea is to learn to map problem instances to a piece-wise linear value function within intrinsic low-dimension space, which is architected specifically to interact with a base SDDP solver, so that can accelerate optimization performance on new instances. The proposed approach is evaluated on synthetic and real-world process optimization problems. "
SP:3d9f5132f9ec3807dbca78462a459fd123a09b24,This paper proposes a new protocol for privacy-preserving next-token prediction for language models that were fine-tuned on a private corpus after pre-training on a public corpus. The main contribution of the paper is to propose a new privacy-guarantee based on group-differentially private prediction. The paper shows that the proposed method can prevent the leakage of information that is unique to any individual user in the private corpus via a relaxation of group differentially private predictions.
SP:7f524d186ea939309c7eeb843c62b6a4b4cfbc8a,"This paper proposes an unsupervised method to detect OOD samples using a k-NN density estimate with respect to a classification model’s intermediate activations on indistribution samples. The authors leverage a recent insight about label smoothing, which they call the Label Smoothed Embedding Hypothesis, and show that one of the implications is that the k-nn density estimator performs better as an OOD detection method both theoretically and empirically when the model is trained with label smoothed. The proposed method outperforms many OOD baselines. "
SP:aafbd6ada14cc59a272fe4bf95fac71fa18e57ab,"This paper proposes a novel approach to learning representations in a non-adversarial generative model. The proposed approach is based on an extension of the denoising score matching framework, which is used in GANs and VAEs to learn representations by directly transforming latent codes to data samples. In contrast, the introduced diffusion-based representation learning method relies on a new formulation of the Denoising Score Matching (DSM) objective and thus encodes information needed for denoizing. The authors show how this difference allows for manual control of the level of details encoded in the representation. They propose to learn an infinite-dimensional latent code which achieves improvements of state-of-the-art models on semi-supervised image classification. "
SP:8cfc837d5c10d539bbd098df7134c42e4830ba25,"This paper proposes a method for goal-conditioned reinforcement learning to solve long-term goal-reaching tasks by using graph planning to automatically generate a curriculum of intermediate states. The main contribution of the paper is to propose an algorithm to solve the distant goal reaching task by using planning at training time. The method is evaluated on long-range navigation and manipulation tasks, and it is shown to be more sample efficient than prior methods."
SP:ef3193842e06d4a6edb8a6a86ea5bc97ee5eaa4a,"This paper proposes to use displacement interpolation to improve the performance of mixup in the k-mixup setting. The main contribution of the paper is to extend the standard mixup to the k mixup setting, where the training data is generated by perturbing k-batches of training points in the direction of other training points. The authors show that the proposed method preserves the cluster and manifold structure of the data, and extend theory studying the efficacy of standard mix-up to k mix-ups. The empirical results show that training with k-Mixup further improves generalization and robustness across several network architectures."
SP:0fe6a9848026e5f6436a380199e27a9ad26cffed,This paper proposes a non-linear kernelized classification layer for deep networks to tackle the problem of model-efficient embedding learning. The authors show that the proposed layer optimizes over all possible radial kernel functions on the space of embeddings to learn an optimal nonlinear classifier. They then demonstrate the usefulness of this layer in learning more model efficient classifiers in a number of computer vision and natural language processing tasks.
SP:01ee8ec81619784788eb0ce9785098e437d17a7c,"This paper studies the problem of node representation learning in the context of graph neural networks (GNNs). The main contribution of the paper is a theoretical analysis that shows that both nodal features and graph structure lead to bias in the obtained representations. Based on this analysis, the authors propose a set of data augmentation methods to improve the fairness of GNN-based learning mechanisms. Extensive experiments on node classification and link prediction are carried out over real networks. The proposed methods are shown to improve fairness in terms of statistical parity and equal opportunity."
SP:7739dc9e37f7f1384f87d2e60281e5bb27fece99,"This paper studies the problem of estimating treatment effects from observational data in the presence of unmeasured confounders. In this paper, the authors propose a Confounder Balanced IV Regression (CB-IV) algorithm to jointly remove the bias from the unmeasureable confounder with IV regression and achieve better bias-variance trade-off in imbalanced treatment distributions due to the observed confoundsers by balancing for treatment effect estimation. The proposed algorithm consists of three main modules: (1) treatment regression: regressing the treatment with IVs and confounds like previous nonlinear IV methods for removing the confounding, (2) confoundER balancing: learning a balanced representation of confounds to eliminate the bias induced by the observed data, and (3) outcome regression. Extensive experiments demonstrate that CB-IV algorithm outperforms the state-of-the-art. "
SP:fdb68c39fce254b73310a3101b2fe97ba47e69fe,"This paper studies the performance of model-agnostic meta-learning (MAML) in a linear regression setting with a mixture of easy and hard tasks, where hardness is related to the rate that gradient descent converges on the task. The authors prove that MAML achieves substantial gain over NAL in terms of the hardness of the tasks, and that the optimal solutions of the hard tasks must be closely packed with the center far from the center of the easy tasks optimal solutions. They also provide numerical and analytical results suggesting that these insights apply to two-layer neural networks. "
SP:e8143c7880c16ee9ce7a544e0fd80f001b1b4f9f,"The paper proposes a method for semi-blind source separation in sparse BSS. The proposed method is based on the unfolding/unrolling of the Proximal Alternating Linearized Minimization (PALM) algorithm. In contrast to most existing unrolled algorithms, which assume a fixed known dictionary during the training and testing phases, this article further emphasizes on the ability to deal with variable mixing matrices (a.k.a. dictionaries). The proposed learned PALM algorithm thus enables to perform semi- blind source separation, which is key to increase the generalization of the learnt model in real-world applications. "
SP:7716315001949ab88c8a216302fe51bae872fc87,This paper proposes to use implicit self-attention to improve the performance of transformers on the task of language modeling. The authors propose a Legendre Memory Unit based model that exhibits an O(n) and $O(n lnn)$ dependency for memory and computation respectively. They show that for the same amount of training their model improves the loss over transformers about as much as transformers improve over LSTMs. They also show that adding global self attention complements their architecture and the augmented model improves performance even further.
SP:832f422b3554e89702e13c8c5690ee26f2289e3b,"This paper proposes a two-stage GAN based on the classical GAN objective with internal conditioning on a set of space keypoints. These keypoints have associated appearance embeddings that respectively control the position and style of the generated objects and their parts. The paper shows that LatentKeypointGAN provides an interpretable latent space that can be used to re-arrange the generated images by re-positioning and exchanging keypoint embedding, such as generating portraits by combining the eyes, and mouth from different images. The explicit generation of keypoints and matching images enables a new, GAN-based method for unsupervised keypoint detection."
SP:9206ae6e31077569313838504ef6daa89ad3b59c,". This paper studies the effect of layer normalization on the signal propagation of fully-connected neural networks. The authors show that increasing the depth leads to gradient explosion or representation shrinkage. They also show that the appearance of these problems is not restricted to a specific initialization scheme or a choice of activation function, but rather is an inherent property of the network architecture itself. "
SP:2177be818b5843c580c787f1b2d725154846feb6,"This paper proposes a line search method for finding optimal step sizes for stochastic gradient descent (SGD) based on the observation that the full-batch loss behaves locally parabolically in the direction of noisy update step directions. Based on this observation, the authors propose a line-search method that approximates the full batch loss with a parabola estimated over several mini-batches. Learning rates are derived from such parabolas during training. The proposed method outperforms SGD tuned with piece-wise constant learning rate schedule and other line search approaches for Deep Learning across models, datasets, and batch sizes on validation and test accuracy."
SP:62233782f9046c85617d9ccfe8427eae7d1c9da7,"This paper studies the problem of noise-contrastive estimation (NCE) in the setting of unnormalized probabilistic models. In particular, the authors prove that the performance of NCE suffers when the target and noise distributions are in a given exponential family. The authors propose a new NCE method called eNCE, which uses an exponential loss and addresses the landscape issues provably. "
SP:ceba6c1421b2d03863007fdaf029b8b946519c1b,"This paper studies the convergence of distributed SGD under Byzantine fault and Byzantine resilience. In particular, the authors show that existing results on the convergence under Byzantine faults are rendered invalid when honest workers enforce differential privacy. To circumvent this shortcoming, they revisit the theory of (α, f)-Byzantine resilience to obtain an approximate convergence guarantee. The paper also provides key insights on how to improve this guarantee through hyperparameter optimization."
SP:bc783f0c829f90931535e63687d13172879631b3,"This paper considers the problem of code editing with few exemplars. In this paper, the authors propose a novel deep learning approach to solve this code editing problem automatically. The learning approach combines edit representations extracted from support exemplars and compositionally generalizes them to the query code snippet editing via multi-extent similarities ensemble. The authors evaluate the proposed method on C# and Python datasets and show up to 8.6% absolute accuracy improvements compared to non-composition baselines."
SP:ca0c4bdb02f7d939fb6de38b6b446ced4b5984a0,"This paper proposes a generative model for generating high-level structure in sequence data. The authors propose to use relational constraints between different sub-components of an example (e.g., lines of a poem or measures of music) to guide the generative process. They propose a program synthesis algorithm that infers the relational constraints present in the training data, and then learn a model based on the resulting constraint data. In experiments, the authors show that their approach significantly improves over state-of-the-art in terms of capturing high level structure in the data, while performing comparably or better on low-level structures."
SP:692ae0c583a1585eff1a7d9c0d3b51b7879611cc,"This paper studies the problem of set-to-hypergraph prediction, where the goal is to infer the set of relations for a given set of entities. This is a common abstraction for applications in particle physics, biological systems and combinatorial optimization. The paper addresses two common scaling problems encountered in set to hypergraph tasks that limit the size of the input set: the exponentially growing number of hyperedges and the run-time complexity, both leading to higher memory requirements. The authors propose to predict and supervise the positive edges only, which changes the asymptotic memory scaling from exponential to linear. They also introduce a training method that encourages iterative refinement of the predicted hypergraph, which allows us to skip iterations in the backward pass for improved efficiency and constant memory usage. Finally, they combine both contributions in a single set tohypergraph model that enables them to address problems with larger input set sizes."
SP:e3481fb6d8d1aa45d6ed4a454e781f5a2c30c57e," in this paper is a post-processing method to mitigate bias of state-of-the-art models. It consists in learning a shallow neural network, called the Ethical Module, which transforms the deep embeddings of a pre-trained model to give more representation power to the discriminated subgroups. Its training is supervised by the von Mises-Fisher loss, whose hyperparameters allow to control the space allocated to each subgroup in the latent space. Besides being very simple, the resulting methodology is more stable and faster than most current methods of bias mitigation."
SP:3fb5dcc8b8fb731e09c14b16480cada1c7ccfaa7,"-based CIL methods have been shown to outperform the state-of-the-art in terms of performance on CIFAR-10, ImageNet-1k, and ImageNet Subset. This paper proposes to use placebos from a free image stream (e.g., Google Images) to compute the KD loss. The proposed method is simple and surprisingly effective even when there is no class overlap between the placebos and the old data. "
SP:506e0a888c03a955b708464eed3670c04baf4912,"This paper proposes a path auxiliary algorithm for sampling from discrete energy-based models (EBMs). The proposed algorithm uses a composition of local moves to efficiently explore large neighborhoods. The authors show that their algorithm outperforms other generic samplers on various discrete models for sampling, inference, and learning. The method can also be used to train deep EBMs."
SP:4b466277aa5561a80c48d5e72559de4ce95f228b,"This paper proposes Variational Predictive Routing (VPR), a neural probabilistic inference system that organizes latent representations of video features in a temporal hierarchy based on their rates of change, thus modeling continuous data as a hierarchical renewal process. By employing an event detection mechanism that relies solely on the system's latent representations (without the need of a separate model), VPR is able to dynamically adjust its internal state following changes in the observed features, promoting an optimal organisation of representations across the levels of the model’s latent hierarchy. Experiments on several video datasets demonstrate that VPR can detect event boundaries, disentangle spatiotemporal features across its hierarchy, adapt to the dynamics of the data, and produce accurate timeagnostic rollouts of the future."
SP:459ef2e6bd7638020955dbb4d8ae1098619f7b95,This paper proposes an end-to-end and single-stage method for image retrieval. The main idea is to first search by global features and then re-rank images using local feature matching using convolutional neural networks instead of RANSAC algorithm. Experiments on Revisited Oxford and Paris datasets validate the effectiveness of the proposed method. 
SP:487cc308a1e8ee078c54b2158bcae47e920e73f8,"This paper proposes RotoGrad, a multi-task learning algorithm that jointly homogenizes gradient magnitudes and directions across tasks while ensuring training convergence. The main contribution of this paper is to propose an algorithm that tackles the problem of negative transfer as a whole. In particular, the proposed algorithm is based on the idea of homogenizing the gradient magnitude and directions. The proposed method is evaluated on the CelebA and NYUv2 datasets, where it is shown to outperform existing methods."
SP:050cd8319d84a1bd8c2ccb930ba69b33c8fb6e60,This paper proposes a novel model fusion framework CLAFusion to fuse neural networks with a different number of layers via cross-layer alignment. The proposed method is based on dynamic programming to balance the number of neural networks before applying layer-wise model fusion. Experiments are conducted on CIFAR-10 dataset to show the effectiveness of the proposed method. 
SP:f764eae15cd083fdb4eb2af09ac64c2d878a454f,"-based RL methods have been shown to benefit from the implicit regularization effect of SGD in the offline RL setting. This paper studies the effect of this implicit regularizer in the temporal difference learning setting. Theoretical analysis shows that the derived regularizer favors degenerate solutions with excessive “aliasing”, in stark contrast to the supervised learning case. Experiments show that feature representations learned by a deep network value function trained via bootstrapping can indeed become degenerate, aliasing the representations for state-action pairs that appear on either side of the Bellman backup. To address this issue, the authors propose a simple and effective explicit regularizer, called DR3, that counteracts the undesirable effects of this implicitly regularizer. "
SP:6fd793b27123bf80504e2ad5957455b7ec311612,"This paper proposes HyperDQN, a variant of Randomized least-square value iteration (RLSVI) that uses a probabilistic hypermodel (i.e., meta model) to generate approximate posterior samples regarding the parameter of the Q-value function. The proposed method is evaluated on Atari games and SuperMario Bros. environments. The results show that the proposed method outperforms RLSVI in terms of the maximum human-normalized score."
SP:b428383660928374c953f659ea1e05852dbdcd6e,", the paper proposes to learn causal representation from observational data by regularizing the learning procedure with mutual information measures according to a hypothetical causal graph. The optimization involves a counterfactual loss, based on which the authors deduce a theoretical guarantee that the causality-inspired learning is with reduced sample complexity and better generalization ability. Extensive experiments show that the models trained on causal representations learned by the proposed approach is robust under adversarial attacks and distribution shift."
SP:1258c05a80a17949b50e6dae13deea1d2235f456,"-based federated learning is a powerful distributed learning scheme that allows numerous edge devices to collaboratively train a model without sharing their data. However, training is resource-intensive for edge devices, and limited network bandwidth is often the main bottleneck. Prior work often overcomes the constraints by condensing the models or messages into compact formats, e.g., gradient compression or distillation. In contrast, this paper proposes ProgFed, the first progressive training framework for efficient and effective Federated learning. It inherently reduces computation and two-way communication costs while maintaining the strong performance of the final models. Extensive results on a broad range of architectures, including CNNs (VGG, ResNet, ConvNets, and U-nets) and diverse tasks from simple classification to medical image segmentation show that the highly effective training approach saves up to 20% computation and up to 63% communication costs for converged models."
SP:8cdaa6e0dafd750ebdb5d7a4c1987a042400662f,"This paper studies the generalization of adversarial training through the lens of the adversarial Rademacher complexity. The main contribution of the paper is to provide an upper bound on the adversarially trained weight norms of deep neural networks. The upper bound is based on the existing bounds of standard Rademachers complexity of neural nets, but the upper bound also includes the product of weight norms. The authors provide experiments to show that the adversary trained weight norm is larger than the standard training weight norm."
SP:925d6bb051e9b384669fb695085b678c11f7c11a,"This paper proposes a differentiable kernel-based differential entropy estimator for differential entropy and mutual information. The main contribution of the paper is the introduction of a fully parameterized, differentiable, kernel based estimator of differential entropy. Experiments on synthetic data and real-world tasks demonstrate the effectiveness of the proposed method."
SP:d2f3beac855f0d72c13552fecb2bdb9d42195df3,"This paper proposes a simple soft-greedy operator, called resmax, that takes actions proportionally to their suboptimality gap: the residual to the estimated maximal value. The authors prove that resmax is a non-expansion for any fixed exploration hyperparameter, unlike the softmax policy which requires a state-action specific temperature to obtain a nonexpansion (called mellowmax). The authors empirically validate the effectiveness of resmax across a variety of environments in tabular and deep RL."
SP:792ae8808aa6902758146aef1548c975492b833c,This paper proposes a new method to control the learnability of a given dataset with a special key. The key is a class-wise perturbation that applies a universal transformation function on data samples of the same label. The proposed method is shown to be effective on visual classification tasks. 
SP:9af10703605e620e563241e2602a50b629f3d37a,". This paper proposes a method for handling missing features in graph machine learning applications that is based on minimization of the Dirichlet energy and leads to a diffusion-type differential equation on the graph. The discretization of this equation produces a simple, fast and scalable algorithm which is called Feature Propagation. The proposed method outperforms previous methods on seven common node-classification benchmarks and can withstand surprisingly high rates of missing features."
SP:cbaa3f1379fa99159899d79ccb479c0187403aca, in active learning is the process of training a model with limited labeled data by selecting a core subset of an unlabeled data pool to label. This paper introduces an integer optimization problem for selecting the core set that minimizes the discrete Wasserstein distance from the unlabelled pool. The paper shows that this problem can be tractably solved with a Generalized Benders Decomposition algorithm. Numerical results on several data sets show that the optimization approach is competitive with baselines and outperforms them in the low budget regime.
SP:4c72923f78ca6590dc11e10d1a2403076a583718,"This paper proposes a method to solve the de novo genome assembly problem by using a graph convolutional network to reconstruct the genome by finding a path through the assembly graph. The authors show that their method can compute scores from the lengths of the overlaps between the sequences and the graph topology which, when traversed with a greedy search algorithm, outperforms the greedy search over the overlap lengths only. This favourable result paves the way for the development of powerful graph machine learning algorithms that can solve the problem much quicker and possibly more accurately than human handcrafted techniques."
SP:24de906e4289c9073b6c55c747b0913b8df5e053,"-based meta-continual learning algorithms use meta-learning to learn how to continually learn. A recent state-of-the-art is Javed & White (2019) which incorporates experience replay (ER) into its meta-testing. However, the use of ER only in meta-training but not in metatraining suggests that the model may not be optimally meta-trained. In this paper, the authors propose to store the samples’ representations, instead of the samples themselves, into the replay buffer. This ensures the batch nature of ER does not conflict with the online-aware nature of OML. Moreover, they introduce a meta-learned Predictive Sample Selection to replace the widely used reservoir sampling to populate the replay buffers. This allows the most significant samples to be stored, rather than relying on randomness. Experimental results show that the proposed method outperforms the state of the art."
SP:3c78454f053f74930979a8054cd7c8a34b6fe63d,"This paper proposes a new method for multi-agent joint Q-learning based on centralized training with decentralized execution (CTDE). In particular, the authors formulate an explicit credit assignment problem where each agent gives its suggestion about how to weight individual Q-values to explicitly maximize the joint Q value. Theoretically, they give a gradient ascent solution for this problem and instantiate the core idea with deep neural networks and propose Explicit Credit Assignment Joint Q-Learning (ECAQ). Extensive experiments justify that ECAQ achieves interpretable credit assignment and superior performance compared to several advanced baselines."
SP:0d2b225ac697679d10df25f371b2a718d4949b42,"This paper studies the problem of adversarial robustness in the context of transductive learning. In particular, the authors propose an attack framework called Greedy Model Space Attack (GMSA) to attack the model space. GMSA is based on the idea of attacking model space for solving bilevel attack objectives. The authors show that GMSA, even with weak instantiations, can break previous Transductive-learning based defenses, which were resilient to previous attacks such as AutoAttack."
SP:e7024cae196fc5eb6a62d289a95d76b532b6a36c,"This paper studies the problem of batch normalization in the case where the entire dataset is normalized jointly. The authors propose to use batch normalisation as an approximation of the limiting case of batch renormalization. They show that this approximation removes the need to keep more than one example in memory at any given time, at the cost of a small factor increase in the training step computation, as well as a fully per-example training procedure, which removes the extra computation at a small drop in the final model accuracy. They further use their insights to improve batch renormization for very small minibatches. "
SP:4aa42984fcb0fd66936d668477b2719ef5c427d4,"This paper proposes a method to reduce the number of trainable parameters for fine-tuning GPT-3 by injecting rank decomposition matrices into each layer of the Transformer architecture. The proposed method, called Low-Rank Adaptation (LoRA), freezes the pretrained model weights and injects trainable rank decompositions matrices to each layer in the transformer architecture. Compared to Adam, the proposed method can reduce the size of the network by 10,000 times and the GPU memory requirement by 3 times. Experiments show that LoRA performs on-par or better than finetuning in model quality on several tasks."
SP:b77a00beb0802f47810b03d3c4aa24d92781414f,"This paper proposes a regular-constrained linear-chain conditional random field (CRF) that can enforce a broad class of constraints, including non-local ones, by specifying the space of possible output structures as a regular language L. RegCCRF has the same formal properties as a standard CRF, but assigns zero probability to all label sequences not in L. The authors prove that constrained training is never worse than constrained decoding, and show empirically that it can be substantially better in practice. They demonstrate a practical benefit on downstream tasks such as semantic role labeling."
SP:74c186a96c12adff178264aa84ace8d04dc7d725," measurement is a growing field with neural models providing state-of-the-art performance. However, these methods still require several preprocessing steps. These additional operations are often non-trivial to implement making replication and deployment difficult and can even have a higher computational budget than the “core” network itself. In this paper, the authors propose two novel and efficient neural models for camera-based physiological measurement called EfficientPhys that remove the need for face detection, segmentation, normalization, color space transformation or any other pre processing steps. Using an input of raw video frames, the proposed models achieve state of the art accuracy on three public datasets. They show that this is the case whether using a transformer or convolutional backbone."
SP:3003bab6e3f7e2e21cd6cf27ee7d483d877d9fb3,"This paper proposes HALP, a new approach to perform structural pruning. The proposed approach is based on a global resource allocation problem, aiming at maximizing the accuracy while constraining the latency under a predefined budget. In particular, HALP leverages latency lookup table to track the latency reduction potential and global saliency score to gauge the accuracy drop. The paper shows that HALP outperforms prior work on both classification and detection tasks, over varying networks on ImageNet and VOC datasets."
SP:c44d676c09c8e5a70d73b21b507b41a422fec809,"This paper proposes GraphEBM, a molecular graph generation method via energy-based models (EBMs) to perform permutation-invariant and multi-objective molecule generation. The authors propose to learn the energy function by contrastive divergence and generate samples by Langevin dynamics. To generate molecules with a specific desirable property, they propose a simple yet effective learning strategy, which pushes down energies with flexible degrees according to the properties of corresponding molecules. Further, they explore to use their method for generating molecules towards multiple objectives via compositional generation, which is practically desired in drug discovery."
SP:70e60fa5deef3e3ba77d05d0c3e0e7fbf396aa1d,This paper proposes a neural network-based approach for program synthesis. The idea is to train a neural model to learn a bottom-up search policy to find a program that satisfies a given specification. The neural model is trained on the data extracted from its own bottom up searches on training tasks. Experiments are conducted on string manipulation and logic programming tasks to demonstrate the effectiveness of the proposed approach.
SP:daa044ffefe80bae16b014f60061d941ed8c2ba6,". This paper proposes a method to replace the squared Bellman error with a functional regularizer. Unlike target networks, the functional regularization is explicit and enables us to use up-to-date parameters as well as control the regularization. This leads to a faster yet more stable training method. The proposed method is evaluated on Atari environments."
SP:dd174014d056a7d2bc86ee99119841eafa62ed52,"This paper studies the problem of designing graph neural networks (GNNs) that can be more expressive than the Weisfeiler Lehman test in distinguishing graph structures. The main contribution of this paper is to develop a new hierarchy of local isomorphism on neighborhood subgraphs. Then, the authors theoretically characterize how message-passing GNNs can be designed to be expressive. To elaborate this characterization, they propose a novel neural model, called GraphSNN, and prove that this model is strictly more expressive. The authors empirically verify the strength of their model on different graph learning tasks. "
SP:beb9ba0261e176bfc50e9bf5bed2b6169d388285,"This paper proposes a novel prediction interval (PI) method for uncertainty quantification. The proposed method is based on linear combinations of three NNs, each of which is independently trained using the standard mean squared error loss. The coefficients of the linear combinations are computed using root-finding algorithms to ensure tight PIs for a given confidence level. The authors theoretically prove that PI3NN can calculate PI for a series of confidence levels without retraining NNs and it completely avoids the crossing issue. Furthermore, the authors address OOD identification challenge by introducing an initialization scheme which provides reasonably larger PIs of the OOD samples than those of the in-distribution samples."
SP:4b44a834e2212bacb4c2d9408a81f1efc76a670b,This paper proposes a meta-learning method for online learning of deep neural networks. The proposed method is based on the idea of meta-training the network to adapt to changing tasks and input distributions simultaneously. The authors propose a fully online meta learning algorithm that does not require any ground truth knowledge about the task boundaries and stays fully online without resetting back to pretrained weights. The method is evaluated on Rainbow-MNIST and CIFAR-100 datasets and shows promising results.
SP:fbae35cb171b3a3eb7c5d4bc83881ed7c4a70aae,", this paper proposes a differentiable scaffolding tree (DST) method for molecular optimization. DST uses a learned knowledge network to convert discrete chemical structures to locally differentiable ones. The DST enables a gradient-based optimization on a chemical graph structure by back-propagating the derivatives from the target properties through a graph neural network (GNN). The empirical studies show that DST is both effective and sample efficient. "
SP:61b59899cf6ae442d9f8f5226e79708a4280cfb2, data is used to predict the response of a patient to a given test result. The authors propose a knowledge-augmented approach to predict a patient's response for a target lab result. They use a graph-based approach to model drug-lab interactions and diagnosis-lab interaction as graphs. They also take into consideration patients’ past lab responses to personalize the prediction. Experiments on real-world datasets demonstrate the effectiveness of the proposed solution.
SP:8623cebb515c4a736427449b46ad2cdf8b806b77,This paper studies the problem of open-set single domain generalization (OS-SDG) where the source and target domains do not have the same label space. The authors propose a cross-match approach to improve the performance of SDG methods on identifying unknown classes by leveraging a multi-binary classifier. CrossMatch generates auxiliary samples out of source label space by using an adversarial data augmentation strategy. They also adopt a consistency regularization on generated auxiliary samples between multibinary classifiers and the model trained by SDG models. The experimental results on benchmark datasets prove the effectiveness of CrossMatch.
SP:126f8ffb855aa22eda4d681a499953879ed3679e,"This paper studies the use of Wasserstein and Sinkhorn trust regions for policy optimization in reinforcement learning. The main contribution of the paper is to propose WPO and SPO based on the Lagrangian duality. Theoretically, the authors show that WPO guarantees a monotonic performance improvement over SPO, while SPO provably converges to WPO as the entropic regularizer diminishes. Experiments across tabular domains and robotic locomotion tasks further demonstrate the performance improvement of both approaches. "
SP:999eacf6500c87205584a3256d7ca45b3016fb1c,"This paper proposes a forgetting-and-relearn framework for learning neural networks. In this framework, the forgetting step selectively removes undesirable information from the model, and the relearning step reinforces features that are consistently useful under different conditions. The proposed framework unifies many existing iterative training algorithms in the image classification and language emergence literature and allows us to understand the success of these algorithms in terms of the disproportionate forgetting of undesirable information. The authors leverage this understanding to improve upon existing algorithms by designing more targeted forgetting operations."
SP:2789859517b6624730b14a7e010444a72d3dd3ed,"This paper proposes an extension of batch RL to the offline-online setting, where the agent has access to a batch of data to train on but is also allowed to learn during the evaluation phase in an online manner. This is an extension to batch RL, allowing the agent to adapt to new situations without having to precommit to a policy. The authors show that standard RL agents trained in this setting can outperform agents trained only offline or online, sometimes by a large margin."
SP:76625a25e770415599a34122110d61cb3b7e614c,"This paper studies the problem of domain generalization (DG) by learning to reduce domain shift with an episodic training procedure. In particular, the authors propose to learn to optimize Y-discrepancy between the unseen target domain and source domains only using source-domain samples. Theoretically, they give a PAC-style generalization bound for discrepancy-optimal meta-learning and further make comparisons with other DG bounds including ERM and domain-invariant learning. Empirically, the algorithm with DomainBed achieves state-of-the-art results on two DG benchmarks."
SP:6421a9759c766641fd8c128a249f1a9c5699d19c,This paper studies the effect of DNN-based best-first search and Monte Carlo tree search on the Sokoban domain. The authors show that the search space is exponential in terms of the number of sub-trees in the tree. They also show the existence of left heavy tails and propose an abstract tree model that can explain the appearance of these tails. The experiments show the critical role of the policy network as a powerful heuristic guiding the search. 
SP:84c415bc0f120d1997289f91661ff74e7297d3bd,This paper proposes a meta-imitation learning method for learning from video demonstrations from humans. The key idea is to use video demonstrations to train the meta-policy by translating the human videos into practical robot demonstrations and train the policy with adaptive loss based on the quality of the translated data. Experiments show that the proposed method achieves the comparable performance to the baseline on a set of vision-based tasks through watching a single video demonstration.
SP:fedf5c75e83d6ab41ef9d5daa9054ffe4e424ec2,". This paper studies the problem of over-parameterized deep networks trained using gradient-based optimizers. In particular, the authors study the effect of weight decay (WD) and hyperparameter tuning on the generalization performance of adaptive optimizers in the image classification domain. They show that, even with weight decay and normal hyper-parameters tuning, adaptive optimizer lag behind SGD."
SP:819df8d847a99f13ed5efdcabae8b464c12b464b,This paper proposes a method for learning partial and full equivariance in G-CNNs. The main idea is to learn a group-equivariant network that is able to learn the optimal level of equivariancy for each layer of the network end-to-end. The proposed method is based on the idea of group equivariant convolutional neural networks (G-CNN). The main contribution of the paper is to propose a family of networks that can learn the partial and the full equivariances from data at every layer. The method is applied to discrete and continuous groups.
SP:0c0ca9df96f1fa2eb8b83a47d0d5964590fef290,"This paper proposes an amortized Langevin dynamics (ALD) method for deep latent variable models. ALD replaces the datapoint-wise MCMC iterations with updates of an inference model that maps observations into latent variables. The authors prove that ALD has the target posterior as a stationary distribution under some assumptions, and ALD can be extended to sampling from an unconditional distribution such as an energy-based model, enabling more flexible generative modeling by applying it to the prior distribution of the latent variable. Based on ALD, the authors construct a new deep latent variables model named the Langevin autoencoder (LAE) that uses ALD for autoencoders-like posterior inference and sampling from the latent space EBM."
SP:5631097031c7e599bdeae64366ffa6e4558837c6,"This paper studies the problem of hypergraph reasoning in large domains, e.g., predicting the relationship between several entities based on the input facts. The authors propose Sparse and Local Neural Logic Machines (SpaLoc) to leverage the sparsity in hypergraph neural networks to represent the grounding of relationships such as parent and grandparent as sparse tensors and uses neural networks and finite-domain quantification operations to infer new facts. To enable training on large-scale graphs such as real-world knowledge graphs, SpaLoc makes training and inference-time sub-sampling of the input graphs. To remedy the information loss in sampled sub-graphs, the authors propose a novel sampling and label calibration paradigm based on an information-theoretic measure information sufficiency. The proposed model shows superior accuracy and efficiency on synthetic datasets compared with prior art."
SP:9657121b01c51f78c00d06b47d3e8d678dd85d54,"This paper proposes a new family of differentiable top-k cross-entropy classification losses, where k is assumed to be a positive integer, such as 1 or 5. The authors propose to draw k from a probability distribution for training. They show that relaxing k does not only produce better top-5 accuracies, but also makes models more robust, which leads to top-1 accuracy improvements. "
SP:cb3188f435c54a365890e20e4d582c250d919833,"This paper proposes a method for solving large-scale optimal transport (OT) problems at an unprecedented combination of speed and accuracy. The proposed method uses Douglas-Rachford splitting to solve the original OT problem directly instead of solving an approximate regularized problem, as many state-of-the-art techniques do. This allows us to provide sparse transport plans and avoid numerical issues of methods that use entropic regularization. The algorithm has the same cost per iteration as the popular Sinkhorn method, and each iteration can be executed efficiently, in parallel. In addition, the authors establish a linear convergence rate for the formulation of the OT problem."
SP:9a087cc734a3e7f3ab848bef5e2eff37fe40f303,"This paper proposes a framework for disentangling the performance gap between client data and unseen client data in federated learning. The framework is based on the idea that clients are drawn from a meta-distribution, and their data is drawn from local data distributions. The authors propose a semantic synthesis strategy that enables realistic simulation without naturally-partitioned data. The proposed framework is tested on synthetic and natural datasets."
SP:da0e8c89f343abfe500eb4c1968e418c2fb52ef6,This paper studies the performance of pre-trained language models (PLMs) under the zero-shot setting. The authors propose a simple multi-null prompting strategy to improve the performance on a few few-shot tasks. The proposed method is evaluated on 20 different datasets. The results show that the proposed method outperforms the state-of-the-art PLMs on the IMDB and Amazon datasets.
SP:9817dccb1a121058b23a2ef825ed339cf8b53674,". This paper proposes a method to improve the performance of the attention mechanism in image recognition tasks. The proposed method is based on a sharpener module, which aims to align the relevant parts of the encoded image with the target output. Experiments on synthetic handwritten digits and real-world scene text recognition datasets show that the proposed method outperforms the existing methods. "
SP:3913ed3b3cf6494368e3be6cacb637ff85f80ee6,This paper proposes a novel approach for learning to solve the vehicle routing problem. The proposed approach is based on deep reinforcement learning (DRL) to construct a complete tour plan from scratch while respecting an apriori fixed number of available vehicles. Experiments are conducted to demonstrate the effectiveness of the proposed approach. 
SP:594a813c0d0baa66738b9c8331370f861ad3c416,"This paper proposes a novel method for link prediction based on counterfactual inference. The idea is to learn the causal relationship between two sets of variables: (1) the observed graph structure (e.g., clustering effect) and (2) the existence of link between a pair of nodes. The authors propose a novel link prediction method that enhances graph learning by counterfactually inference. They propose a method that uses the learned graph representations as context, global graph structural properties as treatment, and link existence as outcome. They show that their method achieves state-of-the-art performance on link prediction."
SP:48a7e50451b887f55be17b2662aa11ce18791cc1,"This paper proposes a two-stage unsupervised feature selection method based on knowledge contrastive disTillation (SOFT) model that incorporates the second-order covariance matrix with the first-order data matrix for feature selection. In the first stage, a sparse attention matrix is learned to represent the second order relations between features. The second stage is to build a relational graph based on the learned attention matrix and perform graph segmentation. The experimental results on 12 public datasets show that SOFT outperforms classical and recent state-of-the-art methods."
SP:14bcae11aeede63f28d1b80c05ed18a01d3e3f3c,"This paper proposes a semi-supervised multi-modal variational autoencoder (MEME) that learns to combine information between modalities implicitly through mutual supervision. This formulation naturally allows learning from partially-observed data where some modalities can be entirely missing, which is something that most existing approaches either cannot handle, or do so to a limited extent. The authors demonstrate that MEME outperforms baselines on standard metrics across both partial and complete observation schemes on the MNIST-SVHN and CUB datasets."
SP:e834a52cadebe5f125ce491273b4ad1146beae3f,"This paper proposes Deep Explore Options, an extension of Explore Options to tackle complex visual problems. The main contribution of the paper is the introduction of J-PER, a new transitionselection algorithm based on the interest of multiple agents. The authors also propose to consider intrinsic reward learning as an auxiliary task, with a resulting architecture achieving 50% faster wall-clock speed and building a stronger, shared representation. "
SP:41578dd1a4bdb043b3d68afa5f9cebb3e14f3907,"This paper proposes a new method for learning Hamiltonian dynamical systems from data. The proposed method is based on a new metric, called stiffness-aware neural network (SANN), to quantify the stiffness of the dynamical system. SANN identifies and splits the training data into stiff and non-stiff portions based on the stiffness index. This classification along with a resampling technique allows to apply different time integration strategies such as step size adaptation to better capture the dynamics characteristics of the Hamiltonian vector fields. The authors evaluate SANN on complex physical systems including a three-body problem and billiard model."
SP:bfb0a059eeb6f40a18fbd20c0eec5037a64ca09e,"This paper studies the problem of multi-step computations, i.e., long addition and execution of arbitrary programs. The authors propose to train Transformers to perform such computations by asking them to emit intermediate computation steps into a “scratchpad”. They show that scratchpads dramatically improve the ability of language models to perform multi step computations. "
SP:e6c1a8b4bba287455dc9cf145b6bd1f04e2148a9,"This paper proposes a novel adversarial perturbation method based on deep image generators and a novel optimization objective. The authors show that the proposed method can generate targeted feature-level adversarial attacks at the ImageNet scale that are simultaneously interpretable, universal to any source image, and physically-realizable. These attacks can also reveal spurious, semantically-describable feature/class associations that can be exploited by novel combinations of natural objects. "
SP:873618263dc4246a39c44d0abfecfb5f688817e3,"This paper proposes to use reinforcement learning to solve simulated annealing (SA) problems. In particular, the authors propose to use a neural network to learn the neighbour proposal distribution and the temperature schedule. The proposed method is evaluated on a range of problems, including Rosenbrock’s function, the Knapsack problem, the Bin Packing problem, and the Travelling Salesperson problem. The results show that the proposed method outperforms baselines on these problems."
SP:cae31f7436920eb3946e3f5bca0ac88a73d7c3ec,"This paper studies the problem of non-stationarity in cooperative multi-agent reinforcement learning (MARL). In particular, the authors propose a new metric called the “δ-stability”, which is defined as the divergence between the KL-divergence of consecutive joint policies. The proposed metric is based on the trust-region decomposition network (TRD-Net) based on message passing to estimate the joint policy divergence more accurately. The authors show that the proposed metric improves the performance of the MAMT algorithm. "
SP:989b58167a15ae4fafbe27ff534d327991b6c4d7,"This paper proposes a self-supervised representation learning framework for audio-visual speech. The key idea is to use multi-stream video input to learn multi-modal hidden units. The proposed method is evaluated on the largest public lip-reading benchmark LRS3 (433 hours) with only 30 hours of labeled data, outperforming the former state-of-the-art approach (33.6%) trained with a thousand times more transcribed video data (31K hours) (Makino et al., 2019). The lip-reader WER is further reduced to 26.9% when using all 433 hours of labelled data from LRLS3."
SP:7c9eb8aa4a4dcb5965157d860e812d81654e3aa7,"This paper proposes a novel algorithm for combinatorial optimization on graphs. The main idea is to restrict the GNN to a single pre-processing step, before entering a fast-acting exploratory phase directed by a recurrent unit. Experiments show that the proposed algorithm achieves a new SOTA for RL algorithms on the Maximum Cut problem while also providing orders of magnitude improvement in speed and scalability."
SP:f741d980c9c560a21298e947f1605dcbab7ceeac,This paper studies the problem of training VAEs with discrete latent variables. The authors propose to use a variational variational autoencoder (VAE) with discrete latents to train discrete VAEs. The main idea is to use truncated posteriors in conjunction with evolutionary algorithms (using a recently proposed approach). The authors show how such a discrete variational method ties into gradient ascent for network weights and (B) uses the decoder network to select latent states for training. More conventional amortized training is more efficient than direct discrete optimization.
SP:deb189d37bd51b92762ce259a106d9a9e9d81ea4,"This paper proposes an unsupervised method based on counterfactual measures of blame to identify effects on the environment controlled by the agent. The proposed method, Controlled Effect Network (CEN), is evaluated in a wide range of environments showing that it can accurately identify controlled effects. Moreover, CEN’s capabilities as intrinsic motivator is demonstrated by integrating it in the state-of-the-art exploration method, achieving substantially better performance than action-prediction models."
SP:ea18d57904e25fd09ed0f6c9972029d78779a8a6,This paper proposes a structure-regularized pruning (SRP) method to improve the performance of image super-resolution (SR) networks. The main idea is to regularize the pruned structure to make sure the locations of pruned filters are aligned across different layers. The proposed method is evaluated on both lightweight and larger image SR networks. 
SP:0dee45001ae9600f485614dfe6874a516ac01db5,"This paper proposes a framework for few-shot learning that tackles large domain shift between base and novel categories. The first step of the framework trains a feature extracting backbone with the contrastive loss on the base category data. For the second step, a masking module is trained to select relevant features that are more suited to target domain classification. Finally, a classifier is fine-tuned along with the backbone such that the backbone produces features similar to the relevant ones. The proposed method is evaluated on a recently introduced cross-domain few shot learning benchmark."
SP:92aa611d71a8da597358330d84fddbb90de2cf4f,"This paper studies the generalization performance of neural networks trained by Bayesian inference and gradient descent. The authors propose a new technical tool to measure the average test error of the neural network–Gaussian process (NNGP) posterior. They show that the NNGP posterior is better than chance, corroborating the findings of Valle-Pérez et al. (2019) and underscoring the importance of architecture. They also show that test performance can be substantially improved by selecting a function with much larger margin than is typical under the NNGP posterior. "
SP:a0e3cf719a95bbc5aad2f663ba5a3169c316ee9b,"This paper proposes a new method for cross-lingual manifold mixup (X-Mixup) to improve the performance of target languages. The proposed method is based on the idea that the representation discrepancy between the source and target languages is the main cause of the performance gap between the two languages. To address this issue, the authors propose to calibrate the representation between the target and source languages. Experiments on the XTREME benchmark show that the proposed method achieves 1.8% performance gains on multiple text understanding tasks, compared with strong baselines, and reduces the cross language representation discrepancy significantly."
SP:19f8cd8f0c274b6141ba097d2ebb6d18af0986fd,"This paper studies the problem of Byzantine robust distributed or federated learning, where a central server wants to train a machine learning model over data distributed across multiple workers, but a fraction of these workers may deviate from the prescribed algorithm and send arbitrary messages. The authors propose a simple bucketing scheme that adapts existing robust algorithms to heterogeneous datasets at a negligible computational cost. They also theoretically and experimentally validate their approach, showing that combining bucketing with existing robust algorithm is effective against challenging attacks. "
SP:4d63513b9a1b9b9fc44a69b3d5679a8f48eb95e7,"This paper studies the relationship between disentanglement and multi-task learning based on hard parameter sharing. The authors perform a thorough empirical study of the representations obtained by neural networks trained on automatically generated supervised tasks. Using a set of standard metrics, the authors show that disentangling appears naturally during the process of multi- task neural network training."
SP:9851adb72e2918780f661f83f7da06eb866787be,"This paper proposes a framework for certifying the robustness of per-state actions and cumulative rewards under adversarial state perturbations in reinforcement learning. The authors propose a local smoothing algorithm that uses a policy derived from Q-functions smoothed with Gaussian noise over each encountered state to guarantee the robusts of actions taken along this trajectory. They also propose a global smoothing approach that makes use of adaptive search in order to obtain tight certification bounds for the reward. Finally, they use the proposed RL robustness certification framework to evaluate methods that have previously been shown to yield empirically robust RL, including adversarial training and several forms of regularization."
SP:78da3c97182ec1baf6a131740bf7c91a9afb2fd2,"This paper proposes a new approach to conformal prediction, which aims to output a precise set of promising prediction candidates that is guaranteed to contain a limited number of incorrect answers. The authors propose to trade coverage for precision by enforcing that the presence of incorrect candidates in the predicted conformal sets (i.e., the total number of false positives) is bounded according to a user-specified tolerance. Subject to this constraint, the algorithm then optimizes for a generalized notion of set coverage that allows for any number of true answers for a given query (including zero). The authors demonstrate the effectiveness of this approach across a number of classification tasks in natural language processing, computer vision, and computational chemistry."
SP:b126d2f3c397633745c8833e22ace93a2470e963,"This paper studies the effect of depth on the length of the output of a ReLU network. The authors prove that the expected length distortion does not grow with depth, and indeed shrinks slightly, for ReLU networks with standard random initialization. They also generalize this result by proving upper bounds for higher moments of the length distortion and for the distortion of higher-dimensional volumes. "
SP:b3b6d0512edfca461ea295ee8665f7f226c45d57,"This paper proposes SAFEty skill pRiors (SAFER), a behavioral prior learning algorithm that accelerates policy learning on complex control tasks, under safety constraints. SAFER learns to extract a safety variable from offline data that encodes safety requirements, as well as the safe primitive skills over abstract actions in different scenarios. In the inference stage, SAFER composes a safe and successful policy from the safety skills according to the inferred safety variable and abstract action. The authors demonstrate its effectiveness on several complex safety-critical robotic grasping tasks inspired by the game Operation, in which SAFER outperforms baseline methods in learning successful policies."
SP:a5dadb3ecc3caed3b9d9a68eda0d48a53c2d1ce2," image restoration is a challenging and ill-posed problem which also has been a long-standing issue. However, most of learning based restoration methods are proposed to target one degradation type which means they are lack of generalization. In this paper, the authors proposed a multi-branch restoration model inspired from the Human Visual System (i.e., Retinal Ganglion Cells) which can achieve multiple restoration tasks in a general framework. The experiments show that the proposed model, called CMFNet, has competitive performance results on four datasets, including image dehazing, deraindrop, and deblurring."
SP:263b386beee44b0b45b6f6dc3cf80d020500be62,"This paper proposes a novel approach for federated learning in which a model trained on a set of clients needs to be later evaluated on novel unlabeled clients at inference time. The proposed approach is based on a hypernetwork module and an encoder module. Specifically, the encoder network learns a representation for a client given its unlabelled data. That representation is fed to the hypernetwork that generates a personalized model for that client. Experiments show that the proposed approach generalizes better than existing FL and PFL methods."
SP:960d0a63a82593f6e72275b65f0501f0469d1924,-based generative model is used to visualize representations learned with self-supervised models. The authors show that SSL (backbone) representation are not really invariant to many data augmentation they were trained on. SSL projector embedding appear too invariant for tasks like classifications. SSL representations are more robust to small adversarial perturbation of their inputs. 
SP:398899e6c86b4a2a17dfa5c2f4478811f4331c1d,"This paper proves that the Fp sketch algorithm for frequency moments estimation is differentially private as is when p \in (0, 1). The algorithm uses only polylogarithmic space, exponentially better than existing DP baselines and only worse than the optimal non-private baseline by a logarithmically factor. The evaluation shows that the algorithm can achieve reasonable accuracy with differential privacy guarantee."
SP:3253b13851b5a3b5e3c8c6e24891db05903a4e57,"This paper proposes a reward-switching policy optimization method to find novel policies that are both locally optimal and sufficiently different from existing ones. To encourage the learning policy to consistently converge towards a previously undiscovered local optimum, RSPO switches between extrinsic and intrinsic rewards via a trajectory-based novelty measurement during the optimization process. Experiments show that the proposed method is able to discover a wide spectrum of strategies in a variety of domains, ranging from single agent particle-world tasks and MuJoCo continuous control to multi-agent stag-hunt games and StarCraftII challenges."
SP:e3ab3aa87ab023bd9949b99a17d4b6e26c1473c0,This paper proposes a method to find a fast diffusion model for any pre-trained diffusion model by differentiating through sample quality scores. The main contribution of the paper is the introduction of a new non-Markovian diffusion model called Generalized Gaussian Diffusion Models (GGDM) which is a family of flexible non-markovian samplers for diffusion models. The authors show that optimizing the degrees of freedom of GGDM by maximizing sample quality score via gradient descent leads to improved sample quality. The proposed method achieves strong results on unconditional image generation across various datasets.
SP:7a7506f2b5500a573c0cfb8b0822e5ea725c886a,"This paper proposes a novel approach to improve the accuracy of large language models (LLMs) by taking the embedding embeddings as input and output continuous prompts that are used to query the LLM. The approach is based on the idea that different users will query LLMs for the same information using different wording, but should receive the same, accurate responses regardless of the prompts. The authors propose a lightweight model called P-Adapters that sits between embedding layer and first attention layer of LLMs. They also investigate Mixture of Experts (MoE) models that learn a set of continuous prompts (“experts”) and select one to query. They show that PAdapters perform comparably to the more complex MoE models in extracting factual information from BERT and RoBERTa while eliminating the need for additional annotations. Finally, they investigate what makes a P-Adapter successful and conclude that access to LLM’s embedding of the original natural language prompt is a significant factor."
SP:35cdf71f027cc5168b55cc34c64bfb2f3087d6f5,This paper proposes a continuous classification of time series (CCTS) method to achieve the high-accuracy classification at every time. CCTS is a continual learning task with the unclear distribution division. The authors propose a novel Adaptive model training policy ACCTS to overcome two main problems: catastrophic forgetting and the overfitting. The proposed method is evaluated on four real-world datasets and shows better performance than all baselines.
SP:d9b74b749aa465496763d3a3a9bf3a53e800587e,"This paper proposes a memory-based language model that can read and memorize new data at inference time, thus acquiring new knowledge immediately. The paper proposes to use a kNN-based memory model to learn the representations of past inputs. The memory is not differentiable, but the authors propose to use an approximate kNN to perform the memory lookup. Experiments are conducted on a variety of benchmarks and tasks, including generic webtext, math papers, books, code, and formal theorems."
SP:7a1bbf86c3fdb8738aa826ca330493e857d050ba,This paper proposes a sampling scheme based on the Metropolis-hastings Monte Carlo algorithm to generate samples from masked language models (MLMs). The proposed approach is based on two energy parametrizations of the MLMs. The proposed method is tested on both open-ended unconditional generation and a conditional generation task of machine translation. 
SP:011626ba4fafee13d4a30e3f13c1df5b7071a7f1,"This paper proposes a novel reward function for learning a good data augmentation policy for NLP tasks. The proposed reward function is based on the idea that good augmentation should construct more diverse and challenging samples for providing informative training signals, while avoiding the risk of losing the semantics of original samples. To this end, the authors propose to jointly optimize a data augmentation policy while training the model, to construct the augmented samples with low confidence but a high semantic similarity with original ones. In addition, they introduce a sample re-weighting scheme to focus on difficult augmented samples after the original ones are learned confidently for more effective learning from the augmented ones. "
SP:69d41a862ea189f72d4e8af2854e27b95a91fa41,"This paper proposes a novel meta-RL algorithm for offline reinforcement learning. The proposed algorithm is based on the FOCAL algorithm, which is an extension of the SOTA algorithm. The key idea is to use intra-task attention and inter-task contrastive learning objectives to improve the robustness of task representation learning against sparse reward and distribution shift. Theoretical analysis and experiments are provided to demonstrate the effectiveness of the proposed algorithm. "
SP:ed86c60850d5c8302dcf1c2167db303e778fe681,The paper proposes a method to improve the accuracy of the belief model at test time. The method is based on a parametric sequential generative model (PGM) approach. The main contribution of the paper is that the authors propose a method called belief fine-tuning (BFT) that uses approximate dynamic programming to determine the model parameters at each time step. The authors show that BFT improves the performance of the model in the Hanabi game. 
SP:6150725599c10f0e26f0d7cb1fc04b5b227a4456,"This paper proposes Pixelated Butterfly, a new method for training neural networks with a fixed sparsity pattern based on flat block butterfly and low-rank matrices to sparsify most network layers (e.g., attention, MLP). The proposed method is 3x faster than butterfly and speeds up training to achieve favorable accuracy–efficiency tradeoffs. The paper is well written and easy to follow. "
SP:136e31054a55abca840f6478491972023c2296cb,"This paper proposes a novel conditional diffusion probabilistic model for score-based generative models. The main contribution of the paper is to propose a conditional diffusion model by explicitly modeling the class center in the forward and reverse process, which enables controllable generation and gets interpretability. The experimental results on CIFAR-10 show that the proposed method achieves competitive results compared with the state-of-the-art methods."
SP:fc2196f1f4ecd864398fed6640ff3f8b19870763," of domain generalization (DG) approaches often rely on the assumption of the existence of fixed domain-invariant features and common hypotheses learned from a set of training domains. The authors argue that this assumption could be overly strict and sub-optimal when source domains share little information or the target domains leverages information from selective source domains in a compositional way instead of relying on a unique invariant hypothesis across all source domains. Instead, the authors propose a LASSO method that explores diverse latent sub-spaces and learns individual hypotheses on those sub-space. The proposed method is evaluated on several well-known DG benchmarks and achieves state-of-the-art results."
SP:6e8e5bdeb77e3cafe1975da8411fb65118955d14,"This paper studies the kernel thinning (KT) algorithm of Dwivedi and Mackey (2021) which compresses a probability distribution more effectively than independent sampling by targeting a reproducing kernel Hilbert space (RKHS) and leveraging a less smooth squareroot kernel. The authors show that, for analytic kernels like Gaussian, inverse multiquadric, and sinc, target KT admits maximum mean discrepancy (MMD) guarantees comparable to or better than those of square-root KT without making explicit use of a square root kernel. They also prove that KT with a fractional power kernel yields better-than-Monte-Carlo MMD guarantees for non-smooth kernels, like Laplace and Matérn, that do not have square-roots. Finally, they establish that KT applied to a sum of the target and power kernels (a procedure we call KT+) simultaneously inherits the improved MMD guarantee of power KT and the tighter individual function guarantees of target KT."
SP:645c3f1864aa843d4899fc2406f694b5aab8460d,"This paper presents an open-source benchmark suite for the MAXIMUM INDEPENDENT SET problem, in both its weighted and unweighted variants. The suite offers a unified interface to various state-of-the-art traditional and machine learning-based solvers. The authors also conduct an in-depth analysis of the popular guided tree search algorithm by Li et al. [NeurIPS 2018] by re-implementing their algorithm with a focus on code quality and extensibility. They show that the graph convolution network used in the tree search does not learn a meaningful representation of the solution structure, and can in fact be replaced by random values. Thus, the results from the original publication are not reproducible."
SP:155ecd17d264a084b014abdfd0362146d8fb07e0,"This paper proposes Wavelet Compressed Convolution (WCC) for 1x1 convolutions. WCC is based on the Haar-wavelet transform, which is known for its effectiveness in image compression, and defines the convolution on the compressed activation map. By combining WCC with light quantization, WCC achieves compression rates equal to 2-bit and 1-bit with minimal degradation in image-to-image tasks."
SP:004865e6affad32403b7965493a53c8a7ffdda0a,"This paper studies the problem of learning in extensive-form games. The main contribution of the paper is the development of an accelerated learning algorithm for extensive form correlated equilibrium (EFCE) in multiplayer general-sum imperfect-information extensive form games. In this setting, the authors show that their algorithm is able to learn a correlated EFCE that is O(T 3/4) times faster than the best prior rate of $O(T 1/2)$, which is a significant improvement over the $O(\sqrt{T})$-approximate prior rate. The authors also propose to connect predictive regret minimization with the framework of -regret.  "
SP:ee545ff83df4d7ff256ac61fbe0eb0765f52f1d5,"This paper proposes a novel method to learn a discretization of continuous action spaces by leveraging the priors of demonstrations. The proposed method is evaluated on three different setups: RL with demonstrations, RL with play data –demonstrations of a human playing in an environment but not solving any specific task– and Imitation Learning. The experiments show that the proposed method consistently outperforms state-of-the-art continuous control methods on a variety of hard manipulation tasks."
SP:4b39279b98d6aa311bb49dd1384925f9d6f66c2d,"This paper studies the problem of domain generalization in semantic segmentation. The authors propose a novel adversarial style augmentation (AdvStyle) approach, which can dynamically generate hard stylized images during training and thus can effectively prevent the model from overfitting on the source domain. Experiments on two synthetic-to-real domains demonstrate that AdvStyle can significantly improve the model performance on unseen real domains and show that it can achieve the state of the art."
SP:4a2e6d70b383e4941e0bc44e7e82972b22e26792,"This paper proposes a novel approach for mid-air gesture recognition based on neuromorphic gesture analysis. The proposed approach consists of an event-based guided Variational Autoencoder (VAE) which encodes event- based data sensed by a Dynamic Vision Sensor (DVS) into a latent space representation suitable to compute the similarity of mid- air gesture data. The authors show that the Hybrid GuidedVAE achieves 87% classification accuracy on the DVSGesture dataset and it can encode the sparse, noisy inputs into an interpretable latent space representations, visualized through T-SNE plots. "
SP:2e66468a6b94177e54b0052b97713ee63902c278,"This paper proposes a novel approach to deep learning for tabular data. The proposed approach is based on a Hierarchical Table Ensemble (HTE) architecture, where the input data is represented by ferns, and the output is represented as a sparse representation of the input fern. The idea is to use an annealing mechanism to reduce the number of neurons in the network. The paper shows that the proposed approach outperforms existing methods on a number of datasets."
SP:b238db9252d83a13438bb747d70e635bb9945958,"This paper studies the problem of learning value functions from undirected state-only experience in discrete MDPs. The authors show that tabular Q-learning in discrete Markov decision processes (MDPs) learns the same value function under any arbitrary refinement of the action space. This theoretical result motivates the design of Latent Action Q-Learning or LAQ, an offline RL method that can learn effective value functions. The experiments in 5 environments ranging from 2D grid world to 3D visual navigation in realistic environments demonstrate the benefits of LAQ over simpler alternatives."
SP:108ebe9045a9e2b8b5aba8352733782462db8a81,"This paper proposes SWARM, a model-parallel training algorithm designed for swarms of poorly connected, heterogeneous unreliable devices. SWARM creates temporary randomized pipelines between available nodes that are rebalanced in case of failure. To further reduce the network usage of the approach, the authors develop several compression-aware architecture modifications and evaluate their tradeoffs. Finally, they combine their insights to train a large Transformer language model with 1.1B shared parameters with less than 400Mb/s network throughput."
SP:91d2f094d5481651b554f58aecc2a6207057a47c,"This paper proposes a method to bridge the gap between offline and online learning in decentralized multi-agent reinforcement learning. The proposed method is based on the idea of online transition correction (OTC) to improve the transition dynamics by modifying the sampling probabilities. The authors propose two types of distances, i.e., embedding-based and value-based distance, to measure the similarity between transitions, and further propose an adaptive rank-based prioritization to sample transitions according to the transition similarity. Empirical results show that OTC outperforms baselines in a variety of tasks."
SP:d0e650d568214481b07a0452ec606ccbf6d05410,This paper proposes a new quantization method for the forward and backward phase of the training of deep neural networks (DNNs). The authors propose a logarithmic unbiased quantization (LUQ) method to quantize both the forward phase and the backward phase to 4-bit. The proposed method achieves state-of-the-art performance on ResNet50 on ImageNet with a degradation of 1.18% and 0.64% after a single epoch of high precision fine-tuning combined with a variance reduction method.
SP:f2862d1f987164ed6c3c375cd8962e57c369373b,"This paper proposes a self-attention feature-selection mechanism to improve the performance of meta-learning in the presence of non-discriminative features. The proposed method is based on the fact that the number of features in a meta-learned classifier is exponential in number of task-relevant features. To address this problem, the authors propose to use a feature dilution mechanism that adaptively dilutes non-distinctive features. Experiments on synthetic and real-world few-shot learning tasks demonstrate the effectiveness of the proposed method. "
SP:e1e513fef25d29e17cdadd1b36d932a8ad8897cd,"This paper proposes to study the emergence of communication between agents using a continuous communication channel trained through reinforcement learning. The authors propose a simple messaging environment where a “speaker” agent needs to convey a concept to a ‘listener’ agent. The speaker is equipped with a vocoder that maps symbols to a continuous waveform, this is passed over a lossy continuous channel, and the Listener needs to map the continuous signal to the concept. Using deep Q-learning, the authors show that basic compositionality emerges in the learned language representations. They find that noise is essential in the communication channel when conveying unseen concept combinations. And they show that they can ground the emergent communication by introducing a caregiver predisposed to “hearing” or “speaking” English."
SP:0e6ff65ba4a3df35947d1b6f4d438612088d90a0,"This paper proposes BadPre, a backdoor attack on pre-trained NLP models. The key idea is that the adversary does not need prior information about the downstream tasks when implanting the backdoor to the model. When this malicious model is released, any downstream models transferred from it will also inherit the backdoor, even after the extensive transfer learning process. The authors further design a simple yet effective strategy to bypass a state-of-the-art defense. Experimental results indicate that BadPre can compromise a wide range of downstream NLP tasks in an effective and stealthy way."
SP:58d3ecb4a1906251e79ad883aa97cc2502642658,"This paper proposes an incremental skill discovery method for skill discovery, where skills are learned one after another in an incremental fashion. The proposed method is based on the idea that the skill learning must be able to adapt fast to new environment situations while not forgetting previously learned skills. Experiments show that the proposed method outperforms existing state-of-the-art skill discovery methods in both evolving and static environments. "
SP:2c6595408f5ec95537eaf555e5fe3d992b58c222,"This paper proposes a novel log-polar space convolution (LPSC) layer, where the convolution kernel is elliptical and adaptively divides its local receptive field into different regions according to the relative directions and logarithmic distances. The proposed LPSC not only naturally encodes local spatial structures, but also greatly increases the single-layer receptive field while maintaining the number of parameters. Experiments on different tasks and datasets demonstrate the effectiveness of the proposed method."
SP:7791f96b1eef277a9133975507a750d9e7c6b8ff,"This paper studies the trade-off between accuracy and information complexity of NNs. In particular, the authors propose an algorithm for the efficient approximation of the IIW-based information bottleneck (IIW) based on the PAC-Bayes theorem. The proposed algorithm, called PIB, is based on IIW compression of information stored in weights. The authors prove that IIW plays a key role in NNs generalization. Moreover, they propose an MCMC-based algorithm to sample from the optimal weight posterior characterized by PIB which fulfills the potential of IIW."
SP:a733847ade77ffbf38760fc79da17893dea8d53f,This paper studies data poisoning attacks that add imperceptible perturbations to training data to maximize the test error. It shows that the perturbation of advanced attacks are almost linear separable when assigned with the target labels of the corresponding samples. The paper further shows that linear separability is indeed the workhorse for recent attacks. It also suggests that the shortcut learning problem is more serious than previously believed as deep models heavily relies on shortcuts even if they are of an imperceptibly scale and mixed together with the normal features.
SP:7b50be406138ad01db3ee112899f622637896fe9,This paper proposes a new algorithm for offline policy evaluation based on importance weighted return. The main contribution of the paper is to provide a theoretical justification of the proposed algorithm through a better per-state-neighborhood normalization condition and show the limitation of previous attempts to this approach through an illustrative example. The experiments show the proposed method with less overfitting and better test performance compared with state-of-the-art batch reinforcement learning algorithms.
SP:c976752a55b9ff47dc63c95a9fd7b51a81e8a42e,"This paper presents a method for continual learning of how language is grounded in vision. Given a pre-trained multimodal embedding model, where language and images are projected in the same semantic space (in this case CLIP by OpenAI), CoLLIE learns a transformation function that adjusts the language embeddings when needed to accommodate new language use. Unlike traditional few-shot learning, the model does not just learn new classes and labels, but can also generalize to similar language use, and can efficiently learn and generalize from only a few examples with little interference with the model’s original zero-shot performance."
SP:d3371b322acfc321ee79a2e1b438d82644872fa4,"This paper proposes VLAF2, a novel method for novel object captioning (NOC) that leverages language knowledge from BERT and CLIP to generate novel object captions with improved fluency, fidelity, and adequacy. The proposed method is evaluated on the nocaps dataset, where it outperforms the state-of-the-art novel captioning models in all caption evaluation metrics. "
SP:9f3b6486662d80350d77a4b060d4a5b8b22a6130," for few-shot learning. This paper studies the phenomenon of neural collapse, which is the phenomenon that the features learned by overparameterized classification networks show an interesting clustering property, called neural collapse. The authors demonstrate both theoretically and empirically that neural collapse generalizes to new samples from the training classes, and – more importantly – to new classes as well. "
SP:624c95d9ce1ee4b66274e858e2da22bef6b052c7,"This paper proposes a deep point cloud reconstruction network consisting of two stages: 1) a 3D sparse stacked-hourglass network as for the initial densification and denoising, 2) a refinement via transformers converting the discrete voxels into 3D points. Extensive experiments demonstrate that the proposed network achieves state-of-the-art performance among the recent studies in the ScanNet, ICL-NUIM, and ShapeNetPart datasets."
SP:34a81ca65131576d4c14332a4e9eb3a4c344cab7,"This paper proposes PipeGCN, a method for distributed GCN training. The main idea is to use inter-partition communication to hide the communication overhead of communicating node features and feature gradients among partitions for every GCN layer in each training iteration. The paper provides a theoretical convergence guarantee and shows the convergence rate is close to that of the vanilla distributed GCNs training without staleness. Extensive experiments show that the proposed method can largely boost training throughput while achieving the same accuracy as its vanilla counterpart."
SP:8302d49558ee0f16392d623d4e604e92db10d041,"This paper studies the problem of test time robustification, i.e., using the test input to improve model robustness. The authors propose a simple approach that can be used in any test setting where the model is probabilistic and adaptable: when presented with a test example, perform different data augmentations on the data point and then adapt (all of) the model parameters by minimizing the entropy of the model’s average, or marginal, output distribution across the augmentations. Intuitively, this objective encourages the model to make the same prediction across different augmentations, thus enforcing the invariances encoded in these augmentations while also maintaining confidence in its predictions. The proposed approach achieves state-of-the-art results in the setting in which only one test point is available."
SP:a985de5e940ff3a4160b378201b8c02f68d1914a,"This paper proposes a new approach to model-based reinforcement learning (RL) based on a global lower bound on the expected return. The main idea is to jointly train the model and the policy, such that updates to either component of the network increase the lower bound. This joint optimization mends the objective mismatch in prior work. The resulting algorithm (MnM) is conceptually similar to a GAN, where a classifier distinguishes between real and fake transitions, the model is updated to produce transitions that look realistic, and the policies are updated to avoid states where the model predictions are unrealistic."
SP:a469fbcdc20b11dff4085b6fbc384e77f33cd37d,"This paper proposes an imitation learning method for partially-observed environments. The main idea is to learn a coarse-to-fine policy based on the instantaneous observation, and then refine it into a final action using historical information. The proposed method is evaluated on CARLA autonomous driving from images and MuJoCo continuous control tasks. "
SP:95c4533b5d1a865c4cc6a54615e7ad6357bdaad1,"This paper proposes a model-based meta-learning method called DyAd which can generalize across heterogeneous domains by partitioning them into different tasks. DyAd has two parts: an encoder which infers the time-invariant hidden features of the task with weak supervision, and a forecaster which learns the shared dynamics of the entire domain. The encoder adapts and controls the forecaster during inference using adaptive instance normalization and adaptive padding. Theoretically, the generalization error of such procedure is related to the task relatedness in the source domain, as well as the domain differences between source and target. Experiments are conducted on both turbulent flow and real-world ocean data forecasting tasks to demonstrate the effectiveness of DyAd."
SP:ec70553cb0c27e5349c1b8cce6bcaa96a83bf050,"This paper proposes a weakly supervised monocular 3D object detection method. The proposed method first generates 2D boxes on the image and uses the generated 2D box to select corresponding RoI LiDAR points as the weak supervision. Then, a network is trained to predict 3D boxes which can tightly align with associated RoI points. This network is learned by minimizing the newly-proposed 3D alignment loss between the 3D box estimates and the corresponding 3D points. Experiments show that the proposed method obtains 16.47 AP in KITTI."
SP:34217c6a8ca43b8eeb9ddc83d6f1f0af05918984,"This paper proposes a soft gradient-based subword tokenization module (GBST) that automatically learns latent subword representations from characters in a data-driven fashion. GBST enumerates candidate subword blocks and learns to score them in a position-wise fashion using a block scoring network. The paper also introduces a deep Transformer model that integrates GBST and operates on the byte level. Experiments on English GLUE, multilingual, and noisy text datasets show that GBST outperforms a series of competitive byte-level baselines while generally performing on par and sometimes outperforming subword-based models."
SP:d26d25f2ef23a89a2c139d0dd87c4c86fddcff5e,"-based backdoor detection method is proposed to detect backdoor attacks under the black-box hard-label scenario. The authors show that the objective of backdoor detection is bounded by an adversarial objective, which leads to a solution with highly skewed distribution. Based on this observation, the authors propose the adversarial extreme value analysis (AEVA) to detect backdoors. AEVA is based on the monte-carlo gradient estimation. The proposed method is shown to be effective in detecting backdoor attacks."
SP:c6dbca0ed0799b7fec21777606f6f809eb2d8c48,"This paper proposes a new uncertainty measure for in-distribution and out of distribution (OOD) uncertainty estimation. The proposed measure is based on the Kullback-Leibler divergence (KLoS) criterion, which captures class confusion and lack of evidence in a single score. The paper also proposes an auxiliary neural network, KLoSNet, to learn a refined criterion directly aligned with the evidential training objective. The experiments show that the proposed measure outperforms first-order and second-order uncertainty measures to simultaneously detect misclassifications and OOD samples."
SP:8b4f3916dca4e627931558e14836749bd4a6792f,"This paper studies a semi-supervised algorithm that learns a linear classifier over datadependent features which were obtained from unlabeled data. The authors show that the algorithm provably learns CNNs, under some natural distributional assumptions. Specifically, the distribution of patches in the input images has low-dimensional structure (e.g., when the patches are sampled from a low dimensional manifold). The authors provide a lower bound on the dependence of the algorithm on the dimension of the patch distribution."
SP:7f2f354d5cc1030bd97bd716aea8fe1d3af86b25,"This paper proposes a novel approach for face clustering based on Graph Convolutional Networks (GCN). The key idea is to use a graph-based approach to cluster faces by constructing clean graphs for GCNs. In particular, each face is transformed to a new structure space, obtaining robust features by considering face features of the neighbour images. Then, an adaptive neighbour discovery strategy is proposed to determine a proper number of edges connecting to each face image. Experiments on multiple public clustering datasets show that Ada-NETS significantly outperforms current state-of-the-art methods."
SP:a3bc8e26f55e78f07de081ca85865afd52b6ae4a,"This paper studies the problem of generalizable person re-identification (DG ReID) in a more realistic setting. The authors propose a simple yet efficient approach, Unit DRO, which minimizes the loss over a reweighted dataset where important samples (i.e., samples on which models perform poorly) will be upweighted and others will be downweighted. Empirical results show that the proposed method achieves superior performance on large-scale DG ReID and cross-domain ReID benchmarks compared to standard baselines."
SP:62c1f734b7f6c6e7d5114da6f37c9e3cdda73a23,"This paper proposes a simple yet effective method for improving the performance of graph neural networks (GNNs) by adding noise to the input graph and adding a noise correcting node-level loss. The proposed method is based on the idea that adding noise helps overfitting, and the noise correction loss helps ameliorate oversmoothing by encouraging diverse node latents. The paper shows that the proposed method can be applied to GNNs with non-spatial architectures on Open Graph Benchmark (OGB) datasets. "
SP:24a1b44f37f8eedbab2047fb84600a322d289f3b,"This paper proposes a novel approach to the set2vec problem, where the input is a mixture of i.i.d. samples from a mixture distribution, and the set embedding feed-forward network is defined as the maximum-a-posterior (MAP) estimate of the mixture which is approximately attained by a few ExpectationMaximization (EM) steps. The whole MAP-EM steps are differentiable operations with a fixed number of mixture parameters, allowing efficient auto-diff backpropagation for any given downstream task. Furthermore, the proposed mixture set data fitting framework allows unsupervised set representation learning naturally via marginal likelihood maximization aka the empirical Bayes. The experimental results show that the proposed approach outperforms the state-of-the-art on several tasks."
SP:b4f7b660b84fe7702fbcc8a96c192abc3a64f045,This paper proposes a novel contrastive feature selection method for unsupervised feature selection in contrastive analysis (CA) setting. The proposed method is based on the idea that the goal is to select a small number of informative features for use in unknown downstream tasks. The authors show that the proposed method outperforms existing state-of-the-art methods on a number of biomedical datasets.
SP:bc4f69f23aba2034cbf14cb31bdc7a991806bbf6,This paper studies the relationship between optimal early stopping time and model dimension and sample size of the dataset for certain linear regression models. Theoretical results show that the model dimension of the model often exceeds the number of features arising from data. The paper also shows that the optimal early-stopping time corresponds to the training process of deep neural network. Experiments are conducted to show the effect of early stopping on generalization. 
SP:ede87b50cd9c4a6533f17e3e5ddfaaeaaac71dcf,"This paper proposes a quasi-Newton method for the policy gradient algorithm with entropy regularization. In the case of Shannon entropy, the resulting algorithm reproduces the natural policy gradient (NPG) algorithm. For other entropy functions, this method results in new policy gradient algorithms. The authors provide a simple proof that all these algorithms enjoy the Newton-type quadratic convergence near the optimal policy. The proposed algorithm is shown to converge in single-digit iterations."
SP:3535504f7599b1f39239f7cd8e09acd40fa8fdf0,"This paper proposes a novel approach for text-based games (TBG) based on case-based reasoning to train agents and generalize out of the training distribution. The proposed approach is based on the idea that the agent should collect instances of positive experiences from the agent’s interaction with the world in the past and later reuses the collected experiences to act efficiently. The method can be applied in conjunction with any existing on-policy neural agent in the literature for TBGs. The experiments show that the proposed approach consistently improves existing methods, obtains good out-of-distribution generalization, and achieves new state of the art results on widely used environments."
SP:9a5dd0148a15dc5b4d2bc6762dfe8a8991f8866c,"This paper proposes a two-stage method to distill multiple word senses from a pre-trained contextual language model (BERT) by using attention over the senses of a word in a context and transferring this sense information to fit multi-sense embeddings in a skip-gram-like framework. Experiments on the contextual word similarity and sense induction tasks show that this method is superior to or competitive with state-of-the-art multi- sense embedding on multiple benchmark data sets, and experiments with an embedding-based topic model (ETM) demonstrates the benefits of using this multi-meaning embedding in a downstream application."
SP:e4cdba0fc7cd7f440d4436219f3959d8d5e2ad28,"This paper proposes to transfer the same architecture and pretrained weights of a neural net model to understand both images and 3D point-clouds. Specifically, the authors transfer the image-pretrained model to a point cloud model by inflating 2D convolutional filters to 3D convolutionsal filters and finetuning the inflated imagepretrained models (FIP). They find that models with minimal finetuned efforts — only on input, output, and batch normalization layers — can achieve competitive performance on 3d point cloud classification, beating a wide range of point cloud models that adopt task-specific architectures and use a variety of tricks."
SP:dc99c307931ae9c5d4a1b998dc94cfc6ac78d11f,", the paper proposes an energy-based learning objective to improve the performance of autoregressive generative models. The main idea is to use the energy score of the underlying network to estimate the energy scores for each time step. The paper shows that the proposed method can alleviate the exposure bias problem and increase temporal coherence by imposing a constraint which fits joint distributions at each time-step. Extensive empirical results are provided to demonstrate the effectiveness of the proposed approach."
SP:51e748c55bd4134047098559577fa3f37aa7433a,This paper presents a unified framework that connects Wasserstein distributional robustness with current state-of-the-art adversarial training (AT) methods. The main contribution of the paper is the introduction of a new loss function and a new series of risk functions. The authors show that standard AT methods are special cases of their counterparts in their framework. This connection leads to an intuitive relaxation and generalization of existing AT methods. Extensive experiments show that the proposed methods robustify further their standard AT counterparts in various settings.
SP:f192046ea8ad61bfc8e05a0ddb90a8bd15b4640b," time series. This paper proposes Bilinear Temporal-spectral Fusion (BTSF) for unsupervised representation learning for multivariate time series with sparse annotations. BTSF uses instance-level augmentation by simply applying dropout on the entire time series for better preserving global context and capturing long-term dependencies. Extensive experiments are conducted on three major practical tasks for time series such as classification, forecasting and anomaly detection, which is the first to evaluate on all three tasks."
SP:ef54840009afb095c67bbbc29a7824c20a375ee8,"This paper proposes an algorithm for automatically adjusting the learning rate during gradient descent. The proposed method is based on the idea of line-search, where learning rate is trained along with the model weights. The authors formulate first and second-order gradients with respect to learning rate as functions of consecutive weight gradients, leading to a cost-effective implementation. Extensive experimental evaluation is conducted, validating the effectiveness of the proposed method for a plethora of different settings."
SP:263c787361cd6d4443ce516d389c694d0fe44b28,"This paper proposes a meta-learning method for continual multi-task learning, where the goal is to achieve high reward over any sequence of tasks quickly. The proposed method is based on meta-training in an incremental fashion, over each task in a sequence, without revisiting prior tasks. The paper proposes two subroutines: learning a new task using RL and using the experience from RL to perform completely offline meta learning to prepare for subsequent task learning. The experiments show that the proposed method outperforms prior continual learning and off-policy meta-reinforcement methods."
SP:2bd729b7aa045bf74e31229c9e76e57af36e804b,"This paper proposes a new threat model for poisoned classifiers where one without knowledge of the original trigger would want to control the poisoned classifier. Under this threat model, they propose a test-time, human-in-the-loop attack method to generate multiple effective alternative triggers without access to the initial backdoor and the training data. They construct these alternative triggers by first generating adversarial examples for a smoothed version of the classifier, created with a procedure called Denoised Smoothing, and then extracting colors or cropped portions of adversarial images with human interaction. They demonstrate the effectiveness of their attack through extensive experiments on high-resolution datasets: ImageNet and TrojAI."
SP:e58ab0e3cff6b18013145a1a99cfa9da0a3d872f,"This paper studies the problem of unconditional GAN distillation, where the teacher and student model yield different outputs given the same input latent code. The authors propose a novel initialization strategy for the student model to ensure the output consistency to the maximum extent. They also propose a latent-direction-based distillation loss that preserves the semantic relations in latent space. Extensive experiments demonstrate the effectiveness of their approach in distilling StyleGAN2."
SP:2c2231743fa33b95828c6615263954ce1c05f95d,"This paper proposes a method for generating online approximations of offline algorithms by learning a multi-task learning model to simultaneously detect behavioral structures which have already occurred and predict those that may come next. The proposed method is tested on synthetic data and historical stock market data, where the contrast between explanation and prediction is particularly stark. "
SP:ee3a21d2fb8a073099aa200129a53c31f3b6561d,"This paper proposes a method to amortize the computation of the inducing points locations, as well as the parameters of the variational posterior approximation of Gaussian Processes (GPs). The inducing points are learned by considering them as parameters of an approximate posterior distribution q. The authors propose to use a neural network that receives the observed data as an input and outputs the inducing point locations and parameters of q. They evaluate their method in several experiments, showing that it performs similar or better than other state-of-the-art sparse GP approaches. "
SP:f20c99b441545047a16ae524cc2e317b2c3787a2,This paper studies the problem of decentralized deep learning in the presence of Byzantine and Sybil attacks. The authors propose a novel protocol for secure (Byzantinetolerant) decentralized training that emphasizes communication efficiency. They provide theoretical bounds for its resistance against Byzantine and sybil attacks and show that it has a marginal communication overhead. They conduct large-scale experiments on image classification and language modeling to demonstrate the effectiveness of the proposed protocol.
SP:93894f20ab2593e5237b6972fef9fe63e96af89a,"This paper proposes a method to learn a hierarchy of parameterized and “physics-explainable” SPH informed fluid simulators using both physics based parameters and Neural Networks as universal function approximators. The authors propose a mixed mode approach, mixing forward and reverse mode automatic differentiation with forward and adjoint based sensitivity analyses to efficiently perform gradient based optimization. They show that their physics informed learning method is capable of: (a) solving inverse problems over the physically interpretable parameter space, as well as over the space of Neural Network parameters; (b) learning Lagrangian statistics of turbulence; (c) combining Lagrangians trajectory based, probabilistic, and Eulerian field based loss functions; and (d) extrapolating beyond training sets into more complex regimes of interest."
SP:d11b81f9ab414fcf430a03cd70c2d3246b678474,"This paper proposes Mix-MaxEnt, an approach to regularize a single deterministic neural network to obtain improved accuracy and reliable uncertainty estimates. The proposed approach is based on the idea of generating between-cluster samples via the convex combination of two images from different classes and maximizing the entropy on these samples. Such a data-dependent regularization guides the maximum likelihood estimation to prefer the solution that maps out-of-distribution samples to high entropy regions (creating an entropy barrier) and is more robust to superficial input perturbations. The experiments on real-world datasets (CIFAR10 and CIFAR-100) using ResNet and Wide-ResNet architectures demonstrate the effectiveness of the proposed approach."
SP:365490b872464f00634dc7a50d024fceaf0a61ee,"This paper proposes a self-supervised auto-encoder-based method for animating images. The proposed method is based on the idea of linear navigation in the latent space. Specifically, the authors propose to learn a set of orthogonal motion directions simultaneously, and use their linear combination, in order to represent any displacement in the hidden space. The method is evaluated on three datasets: VoxCeleb, Taichi, and TED-talk. "
SP:86f9f89f84e117c86478b9afaf087f65524f5472,This paper proposes a meta-learning approach to generate additional tasks by randomly sampling a pair of tasks and interpolating the corresponding features and labels. The proposed approach is based on the idea of meta-regularization. Theoretical analysis is provided for both gradient-based and metric-based meta-training settings. Empirical results show that the proposed approach outperforms other state-of-the-art methods on 8 datasets.
SP:73d577e9c4f4af5e11a9e5bdb583ee0f50a315f5,This paper proposes a new approach for fair representation learning based on normalizing flows. The idea is to model the encoder as a normalizing flow trained to minimize the statistical distance between the latent representations of different groups. The main advantage of FNF is that its exact likelihood computation allows us to obtain guarantees on the maximum unfairness of any potentially adversarial downstream predictor. Experiments are conducted on a variety of datasets to demonstrate the effectiveness of the proposed approach.
SP:404d5643327f60f0f06f820033a56081f9e01900,This paper proposes a novel graph neural network (GNN) for subgraph isomorphism counting. The main contribution of the paper is to propose an edge-centric message-passing GNN based on edge-based message passing. The key idea is to learn a low-dimensional representation for both the query and the input graph in order to predict the number of isomorphisms on the input graphs. The proposed GNN is able to preserve fine-grained structural information by treating edges as first-class citizens. 
SP:5a94f18156ab2949c86de45fcf0de2e16977eebb,"This paper studies the problem of personalized federated learning where each client has their own personalized labels, which might not be compatible with others (even for the same class), and can be also possibly from a variety of multiple domains. The authors propose a novel method called Similarity Matching and Kernel Factorization (SimFed) which measures task-level similarity based on locally learned knowledge and matches the relevant ones for personalized knowledge reflection. SimFed also factorizes the model parameters into two basis vectors and the highly sparse masks to significantly reduce the dimensionlaity of parameter space for alleviating knowledge collapse and information loss when reflecting the heterogeneous knowledge. Experiments on both single and multi-domain datasets show that the proposed method outperforms the current state-of-the-art."
SP:97f30bea31eccef6c770fbce1e14fd6d2493a178,"This paper proposes a method to learn object-centric representations of scenes with multiple objects. The key idea is to distill explicit object dynamic representations (e.g., velocity) from raw video input and build a relation module that calculates object-pair interactions and applies it to the corresponding dynamic representations of objects. Experiments are conducted on video understanding and video prediction tasks. The results show that visual representations of ODDN perform better in answering questions around physical events in a video compared to representaions of previous scene representation methods."
SP:ba8e50d1fa9cb824fa3f76c0c691997cd151d760,"This paper studies the problem of graph neural networks (GNNs) that allow using positional features of nodes given by positional encoding (PE) techniques such as Laplacian Eigenmap, Deepwalk, etc.. GNNs with PE often get criticized because they are not generalizable to unseen graphs (inductive) or stable. This paper studies these issues in a principled way and proposes a provable solution, a class of GNN layers termed PEG with rigorous mathematical analysis. PEG uses separate channels to update the original node features and positional features simultaneously. Extensive link prediction experiments over 8 real-world networks demonstrate the advantages of PEG in generalization and scalability."
SP:cf448479f68c3194c1a9e11729bf70d7cc2ae8fd,"This paper proposes LaMer, a novel text style transfer framework based on large-scale language models. LaMer first mines the roughly parallel expressions in the non-parallel datasets with scene graphs, and then employs MLE training, followed by imitation learning refinement, to leverage the intrinsic parallelism within the data. On two benchmark tasks (sentiment & formality transfer and a newly proposed challenging task (political stance transfer), LaMer achieves qualitative advances in transfer accuracy, content preservation, and fluency. Further empirical and human evaluations demonstrate that LaMer can generate more readable and diverse expressions than previous models."
SP:8f7b2d1020d9e527118b8fb816760c13b0d0bfcb,"This paper studies the problem of multi-hop logical reasoning on hyper-relational knowledge graphs (KGs). The authors propose a method to answer such queries and demonstrate its effectiveness on a diverse set of query patterns. The proposed method is based on Graph Neural Networks and query embedding techniques. Besides, the authors show how to embed and answer the queries."
SP:5f8b58424a1a8eeb72217e75189d6f773a298a7a,"This paper proposes a method for learning to dynamically decide which configuration to try next, and for what budget. The authors propose a new surrogate for Gaussian Processes that embeds the learning curve dynamics and a new acquisition function that incorporates multi-budget information. The proposed method is evaluated on 50 datasets (Tabular, Image, NLP) and diverse neural networks (MLP, CNN/NAS, RNN)."
SP:99d3d94e3af5d2dc7b92c00ac1345d1d2dd0d15b,"This paper proposes a method to improve the performance of learned image compression. The main contribution of the paper is to introduce post-training quantization and make the model inference integer-arithmetic-only, which is much simpler than the existing training and fine-tuning based approaches. The proposed method further improves the discretization of the entropy parameters and extend the deterministic inference to fit Gaussian mixture models. "
SP:85d0df515e9e555f3ea1c21d607304dfaeae69c0,This paper proposes an unsupervised noise denoising network for FIB-SEM. The proposed network is based on Gated Recurrent Units (GRU) architecture. The network is trained to reconstruct and remove the noise by synthesizing the sequential data. Experiments on 3D electron microscopy data sets demonstrate the effectiveness of the proposed network.
SP:e6275b0b103fa90dcebcdd3d3c14c830c3402972,"This paper studies the label propagation in graph neural networks (GNNs). In particular, the authors propose to use a randomly-selected portion of the training labels as GNN inputs, concatenated with the original node features for making predictions on the remaining labels. This so-called label trick accommodates the parallel use of features and labels, and is foundational to many of the top-ranking submissions on the Open Graph Benchmark (OGB) leaderboard. The authors prove that under certain simplifying assumptions, the stochastic label trick can be reduced to an interpretable, deterministic training objective composed of two factors. The first is a data-fitting term that naturally resolves potential label leakage issues, while the second serves as a regularization factor conditioned on graph structure that adapts to graph size and connectivity. "
SP:b6cbc3661f9c440687c3dd01ee35a118c87db377,"This paper proposes to model machine theory of mind in a more flexible and symmetric scenario, where all agents can speak, listen, see other agents, and move freely through a grid world. The authors show that multi-agent deep reinforcement learning models that model the mental states of other agents achieve significant performance improvements over agents with no such ToM model. However, their best agents fail to achieve performance comparable to agents with access to the gold-standard mental state of other agent."
SP:f8ce83805eee46c6c196e8477bf10d8d7f7e0f46,"This paper proposes a novel method for zero-shot object detection based on the YCB Video Dataset, which contains 21 objects in various categories. In this paper, the authors propose a method for detecting daily objects in indoor scenes, where the objects’ size and environment are closely related to the manufacturing setup. The proposed method is a subset of unsupervised learning, and it aims to detect novel objects in the image with the knowledge learned from and only from seen objects. To the best of my knowledge, this is the first work to explore this problem."
SP:aa1dcd9217270010f16a00004facede942efea17,"This paper proposes an autoregressive latent video prediction model for video prediction. The proposed method is based on a high-fidelity image generator (VQ-GAN) with a causal transformer model, and introduces additional techniques of top-k sampling and data augmentation to further improve video prediction quality. The method achieves competitive performance to state-of-the-art approaches on standard video prediction benchmarks with fewer parameters and enables high resolution video prediction on complex and large-scale datasets."
SP:7f57896afd63bc869d2db6ddf7abbeaa71daae11,"This paper proposes to use Vision Transformers (ViTs) in GANs to improve the performance of ViT-based generative adversarial networks (GANs). The main contribution of the paper is to propose a new regularization method for ViT discriminators. The proposed method, ViTGAN, is evaluated on CIFAR-10, CelebA, and LSUN bedroom datasets. "
SP:bbae3afcaea0a2e54904cb8daaed7df4fe37da6e,"This paper studies the problem of image generative modeling with variational autoencoders (VAEs). The authors propose to decompose the task of VAEs into two steps: first, they first prioritize the modeling of visually perceptible information to achieve good sample quality, and then subsequently model the imperceptible information -- the bulk of the likelihood signal -- to achieve the good likelihoods. The authors show that VAEs can achieve competitive likelihoods without successful modeling of the visual perceptible bits. "
SP:bfed56018134ec66cde9a7e958df964d4cca3164,"This paper studies the problem of estimating the optimal reverse variance and optimal KL divergence of diffusion probabilistic models (DPMs). The authors show that the optimal variance and KL divergence have analytic forms w.r.t. its score function. They propose a training-free inference framework that estimates the analytic forms of the variance and the KL divergence using the Monte Carlo method and a pretrained score-based model. Further, they derive both lower and upper bounds of the optimal inverse variance and clip the estimate for a better result. Empirically, their analytic-DPM improves the log-likelihood of various DPMs and produces high-quality samples."
SP:3f935ba5784c3e86db72421426bc479061af1a4b," image classification is one of the most commonly used medical image classification tasks. In this paper, the authors investigate whether it is feasible to switch to transformer-based models for medical image diagnosis as well, or if we should keep working with CNNs – can we trivially replace CNNs with transformers? They consider this question in a series of experiments on several standard medical image benchmark datasets and tasks and show that, while CNNs perform better if trained from scratch, off-the-shelf vision transformers can perform on par with CNNS when pretrained on ImageNet, both in a supervised and self-supervised setting."
SP:a64e0535f268901e38fd51e027c612ebcdbae1a4,"This paper studies the problem of pretraining neural language models (NLMs) over a large corpus of text. It shows that the pretrained NLM can model much stronger dependencies between text segments that appeared in the same training example, than it can between different training examples. This result has two main implications. First, it formalizes the motivation behind a broad line of recent successful NLM training heuristics, proposed for the pretraining and fine-tuning stages, which do not necessarily appear related at first glance. Second, it indicates further improvements to be made in NLM pretraining for the benefit of Natural Language Understanding tasks."
SP:59066956fa2e423d5f2d2ea4f91c4ddf6afd4683,"This paper studies the problem of learning to optimize (L2O) using symbolic regression. The authors propose to use symbolic regression to improve the performance of L2O models. The main contribution of the paper is the introduction of a symbolic representation and analysis framework for learning to optimize. The proposed framework is based on symbolic regression, and the authors show that it can be used to learn learnable optimizers for large-scale optimization problems. "
SP:54dfeb363beee9959aecc9e0853ff06e43bd94e4,"This paper studies the problem of adversarial robustness in reinforcement learning (RL). In RL, an adversary can infer the defense strategy of the victim agent by observing the states, actions, etc. from previous time-steps and adapt itself to produce stronger attacks in future steps (e.g., by focusing more on states critical to the agent’s performance). The authors propose an efficient procedure, designed specifically to defend against an adaptive RL adversary, that can directly certify the total reward without requiring the policy to be robust at each time-step. The main theoretical contribution is to prove an adaptive version of the Neyman-Pearson Lemma – a key lemma for smoothing-based certificates – where the adversarial perturbation at a particular time can be a stochastic function of current and previous observations and states as well as previous actions. Building on this result, the authors propose policy smoothing where the agent adds a Gaussian noise to its observation at every time step before passing it through the policy function."
SP:e0f9add5fde18eaab0eeb2b10b14928acc8ec5b8,"This paper studies the problem of predicting the target domain accuracy using only labeled source data and unlabeled target data. The authors propose a method that learns a threshold on the model’s confidence and predicts the accuracy as the fraction of unlabelled examples for which model confidence exceeds that threshold. The proposed method outperforms previous methods across several model architectures, types of distribution shifts (e.g., synthetic corruptions, dataset reproduction, or novel subpopulations), and datasets (WILDS, ImageNet, BREEDS, CIFAR, and MNIST). In the experiments, ATC estimates target performance 2-4ˆ more accurately than prior methods. "
SP:e748bf6ee653087cae825df32a8546f9ccebfcf1,"This paper studies the problem of partial distribution matching (PDM) where point sets are regarded as discrete distributions and the goal is to partially match them. To handle large point sets, the authors propose a method for large scale PDM problem by utilizing the partial Wasserstein-1 (PW) discrepancy, which they show can be efficiently optimized. They theoretically derive the Kantorovich-Rubinstein duality for the PW discrepancy, and show its gradient can be explicitly computed. Based on these theoretical results, they propose a novel method, which approximates the discrepancy by a neural network and learns the transformation adversarially with the network. It also incorporates an efficient coherence regularizer for non-rigid transformations to avoid unrealistic deformations. Experiments on practical point set registration tasks show that the proposed method is robust, scalable and performs better than the state-of-the-art methods."
SP:f94f77696d100b2638fa2a6d82c8df47db3b6a36,"This paper proposes a novel meta-learning approach for hyperparameter optimization (HPO) meta-datasets. The proposed method is based on Deep Kernel Gaussian Process surrogate with Landmark Meta-features (DKLM) that can be jointly meta-trained on a set of source tasks and then transferred efficiently on a new (unseen) target task. The DKLM is designed to capture the similarity between hyper-parameter configurations with an end-to-end meta-feature network that embeds the set of evaluated configurations and their respective performance. As a result, the proposed DKLM can learn contextualized dataset-specific similarity representations for hyper parameter configurations. The experimental results demonstrate the effectiveness of the proposed method."
SP:e3c57f3589e8ab674644d900c14b3473cd71a23f,This paper proposes a method for deep generative models to be fingerprinted. The key idea is to generate a large population of models with distinct fingerprints that can be used for deep fake detection and attribution. The authors propose to use a 128-bit fingerprinting operation to generate more than 10 identifiable models. Experiments show the effectiveness of the proposed method. 
SP:73bffd1a0856b80d29f7a2b2b68be57882531f07,"This paper proposes a method to provide post-hoc explanations for model agnostic local explanations for black box models. The main contribution of the paper is to propose analogies as a new form of explanation in machine learning. The goal is to identify diverse analogous pairs of examples that share the same level of similarity as the input pair and provide insight into (latent) factors underlying the model’s prediction. The selection of analogies can leverage feature attributions, thus connecting the two forms of explanation while still maintaining complementarity. The paper proves that the analogy objective function is submodular, making the search for good-quality analogies efficient."
SP:6a3c4ae05d582f8896840483b08c735ced2976bc,"This paper studies the certified robustness of ensemble ML models. The authors prove that diversified gradient and large confidence margin are sufficient and necessary conditions for certifiably robust ensemble models under the model-smoothness assumption. They also provide the bounded model smoothness analysis based on the proposed Ensemble-before-Smoothing strategy. Inspired by the theoretical findings, they propose the lightweight Diversity Regularized Training (DRT) to train certified robust ensemble ML model. Extensive experiments show that DRT enhanced ensembles can consistently achieve higher certified L2-robustness than existing single and ensemble models."
SP:3002b29c27709780238876d8c3f81bbd6a0f8112,"This paper studies the expressive power of the message passing graph neural network (GNN) in terms of the number of subgraphs of size k. The authors propose a new pooling technique of local neighborhoods that allows different tradeoffs of computational cost and expressive power. First, the authors prove that this model can count subgraph k and thereby overcomes a known limitation of low-order GNNs. Second, they show how recursively pooling can exploit sparsity to reduce the computational complexity compared to the existing higher-order graph neural networks. More generally, they provide a (near) matching information-theoretic lower bound for counting subgraph with graph representations that pool over representations of derived (sub-)graphs. "
SP:5d0cbd84336caf5f31e1f98e11f6733230e4d792,"This paper studies the knowledge integration (KI) process in an information-theoretic view and shows that KI could be interpreted using a graph convolution operation. The authors propose a simple probe model called Graph Convolution Simulator (GCS) for interpreting knowledge-enhanced LMs and exposing what kind of knowledge is integrated into these models. They conduct experiments to verify that our GCS model can indeed be used to correctly interpret the KI process, and use it to analyze two typical KI methods: K-Adapter and ERNIE. They find that only a small amount of factual knowledge is captured in these models during integration."
SP:7e73948421e98307fceb69a316d8a4e7c4926cda,"This paper studies the effect of the adaptation learning rate in meta-learning with mixed linear regression. The authors propose a principled way to estimate optimal adaptation learning rates that minimize the population risk of MAML. They prove that compared with empirical risk minimization (ERM), MAMl produces an initialization with a smaller average distance to the task optima, consistent with previous practical findings."
SP:effbc85d89b1197d9c2abcaf5ff13864135dd6e1,"This paper studies the problem of source-free domain adaptation (SFDA) in which a model trained on labelled data in a source domain is adapted to unlabelled data in the target domain without access to the source-domain data during adaptation. The authors propose a method called Feature Restoration (FR) to address the issue of measurement shift, which is characterized by a change in measurement system. In the source domain, they store a lightweight and flexible approximation of the feature distribution under the source data, and adapt the feature-extractor such that the approximate feature distributions under the target data realigns with that saved on the source. They also propose a bottom-up training scheme for FR which boosts performance by preserving learnt structure in the later layers of a network. "
SP:7d63034ec7e6a4f178681ff2a49feb485cd47116,This paper proposes a method to propagate adversarial robustness among non-iid users in federated learning (FL). The proposed method is based on batch normalization statistics. The authors show that existing FL techniques cannot effectively propagate robustness from high-resource to low-resource users during the FL process. They propose a simple yet effective propagation approach that transfers robustness through batch-normalization statistics through carefully designed batch normalisation statistics. 
SP:42c7a79e58b6a9f776fa6ae928bd89c194f9303f,"This paper proposes a transformer-based approach for learning the network structure from observed game outcomes (equilibrium actions) without the knowledge of the utility function associated with the game, which is often unrealistic to obtain in real-world scenarios. To address this limitation, the authors propose a novel transformer-like architecture that correctly accounts for the symmetries of the problem and learns a mapping from equilibrium actions to network structure of the game without explicit knowledge of utility function. The authors test their method on three different types of network games using both synthetic and real data and demonstrate its effectiveness in network structure inference and superior performance over existing methods."
SP:1c7b9157cf8c06ca771da78895fc3af969b0fb85,"This paper proposes GraphANGEL, a novel relation prediction framework that predicts relations between each node pair by checking whether the subgraphs containing the pair are similar to other subgraph containing the considered relation. Each graph pattern explicitly represents a specific logical rule, which contributes to an inductive bias that facilitates generalization to unseen relation types and leads to more explainable predictive models. The proposed method consistently outperforms existing models in terms of heterogeneous graph based recommendation as well as knowledge graph completion."
SP:26ed25a7b42da2cf11b76a727102d8aa36d76657,"This paper studies few-shot learning in histology images. The authors propose to combine contrastive learning (CL) with latent augmentation (LA) to build a system that learns representations without manual labels, while LA transfers semantic variations of the base dataset in an unsupervised way. In experiments, the authors show that CL generalizes better than supervised learning for unseen classes, and LA brings consistent gains over baselines."
SP:badbe687258cd5c282ca167b1f6fbfc6b5400dbf," RNNs with continuous-time hidden states are a natural fit for modeling irregularly-sampled time series. These models, however, face difficulties when the input data possess long-term dependencies. The authors prove that similar to standard RNN, the underlying reason for this issue is the vanishing or exploding of the gradient during training. This phenomenon is expressed by the ordinary differential equation (ODE) representation of the hidden state, regardless of the ODE solver’s choice. They provide a solution by equipping arbitrary continuous time networks with a memory compartment separated from its timecontinuous state. This way, the continuous time dynamical flow within the RNN can be encoded to respond to inputs arriving at arbitrary time-lags while ensuring a constant error propagation through the memory path."
SP:4efd22f9122fa5856a9f4302eb6875fa0c414912," BERT has achieved remarkable performance on NLP tasks but is also computation and memory expensive. Unfortunately, the full binarization of BERT usually suffers a significant performance drop, and there is rare study addressing this problem. In this paper, the authors propose BiBERT, an accurate fully binarized BERT to eliminate the performance bottlenecks. The paper provides theoretical justification and empirical analysis to show that the severe performance drop can be mainly attributed to the information degradation and optimization direction mismatch respectively in the forward and backward propagation. Extensive experiments are conducted to show the effectiveness of the proposed method."
SP:619bd742e92bea6241852f5a9d2b7bacf13b393a,"This paper proposes a new approach for multi-person keypoint detection and instance association using Transformer. The key idea is to use the self-attention in Transformer to supervise the attention of the keypoints to be instance-aware. To this end, the authors propose to use instance masks to control the attention pattern. The proposed approach is evaluated on COCO and CIFAR-10 datasets. "
SP:14750819593136fc9ef4efd032ab6f94dc5f6a02,"This paper studies the problem of mean-variance optimization in reinforcement learning (RL) for sequential decision making under uncertainty. The main contribution of this paper is to train an agent to maximize the expected quadratic utility function, in which the maximizer corresponds to the Pareto efficient policy. The proposed approach does not suffer from the computational difficulties because it does not include gradient estimation of the variance. In experiments, the authors show the effectiveness of their proposed methods."
SP:f675b564b3a9c8626ce7944d752fa3e0d868428e,"This paper studies the problem of test-time domain adaptation for an autoencoder system whose channel is generatively-modeled using a mixture density network (MDN). The authors propose a fast and sample-efficient method for adapting the channel model without modifying the encoder and decoder neural networks, and adapting only the MDN channel model. The method utilizes feature transformations at the decoder to compensate for changes in the channel distribution, and effectively present to the decoders samples close to the source distribution. Experiments on simulated datasets and real mmWave wireless channels demonstrate that the proposed method can adapt the channel using very limited number of samples, and improve or maintain the error rate of the auto-encoder."
SP:77dc92137ea490d3e1b4b8ee1630dbe2ee0bddfa,"This paper studies the problem of abductive natural language inference (ALI) where the goal is to infer the most plausible explanation between the cause and the event. The authors argue that it is unnecessary to distinguish the reasoning abilities among correct hypotheses and similarly, all wrong hypotheses contribute the same when explaining the reasons of the observations. Based on the observation that the hypotheses are generally semantically related, the authors propose a novel interactive language model aiming at exploiting the rich interaction among competing hypotheses. The experimental results show that the proposed IMSL has achieved the highest performance on the RoBERTa-large pretrained model."
SP:17cd72df5fc19398f582d27516fd742b073f79e3,"This paper proposes a method for certifiable OOD detection using a standard classifier from first principles. In particular, the proposed method combines a certified OOD detector with a classifier to produce an OOD aware classifier. The proposed method achieves the best of two worlds: certifiably adversarially robust detection, even for OOD samples close to the in-distribution, without loss in either prediction accuracy or detection performance for non-manipulated OOD data. The method provably avoids the asymptotic overconfidence problem of standard neural networks."
SP:9c3756f13932236aff3e8104f4fa193dcc8fde2f," the paper proposes a new generalized transferable attack (GTA) problem where the attacker has a set of surrogate models trained on different datasets (with different label sets and image sizes), and none of them is equal to the dataset used by the victim model. The paper proposes Image Classification Eraser (ICE) to erase classification information for any encountered images from arbitrary dataset. Extensive experiments on Cifar-10, CIFAR-100, and TieredImageNet demonstrate the effectiveness of the proposed ICE on the GTA problem."
SP:2e0447c741a3f09be1095633d870200355211260," pre-trained language models suffer from the false negative issue where training is carried out on wrong data and leads to less efficiency and less robustness in the resulting PrLMs. To address this issue, this paper proposes a new pre-training method to counteract false negative predictions and encourage pre-train language models on true negatives, by correcting the harmful gradient updates subject to false negative prediction. Experimental results on GLUE and SQuAD benchmarks show that the proposed methods indeed bring about better performance together with stronger robustness."
SP:281bc59d639aa76d84921b3ec4ce1ee8f1ba5b51,"This paper proposes a novel semi-supervised learning approach for open-world settings where novel classes may appear in the unlabeled test data. The authors propose ORCA, an end-to-end approach that assigns instances to previously seen classes or forms novel classes by grouping similar instances without assuming any prior knowledge. The key idea in ORCA is to utilize uncertainty adaptive margin to circumvent the bias towards seen classes caused by learning seen classes faster than the novel classes. Extensive experiments on image classification datasets and a single-cell dataset demonstrate that ORCA consistently outperforms alternative baselines."
SP:6c572c4c21b01a0cf3fd9ef97fbb348ef4e405ae,"This paper proposes SLIM-QN, a light-stochastic quasi-Newton optimizer for training large-scale deep neural networks (DNNs). It addresses two key barriers in existing second-order methods: 1) the high computational cost of obtaining the Hessian matrix and its inverse in every iteration; 2) convergence instability due to stochastic training (e.g. L-BFGS). To tackle the first challenge, it uses the BFGS update rule that directly approximates the Hessians using past parameters and gradients. To achieve stable convergence, it introduces momentum in Hessian updates together with an adaptive damping mechanism. "
SP:4bffce00ebb02d2e676eec897647ac14c3344deb,"This paper proposes a systematic method called Locality-Sensitive Pruning (LSP) for graph pruning based on Locality Sensitive Hashing (LSH) to sparsify a graph so that similar local environments of the original graph result in similar environments in the resulting sparsified graph, which is an essential feature for graph-related tasks. Extensive experiments on synthetic and real-world datasets demonstrate the superiority of LSP. "
SP:c5e024f4e2079586298519ca868630efd7579eca,"This paper studies the problem of data augmentation in contrastive self-supervised learning, where the goal is to distinguish a sample’s augmentations (positives) from other samples (negatives). However, strong augmentations may change the sample-identity of the positives, while weak augmentation produces easy positives/negatives leading to nearly zero loss and ineffective learning. In this paper, the authors propose a simple adversarial augmentation method that can modify training data to be hard positives/Negatives without distorting the key information about their original identities. In particular, they decompose a sample x to be its variational auto-encoder (VAE) reconstruction plus the residual R(x) = x + G(x), where the residual retains most identity-distinctive information due to an information-theoretic interpretation of the VAE objective. They then adversarially perturb the residual by adding it back to the original VAE as an augmentation, which is sufficiently challenging for contrastive learning and meanwhile preserves the sample identity intact. They apply this “identity-disentangled adversarial augmentation (IDAA)” to different self-Supervised learning methods to improve their efficiency and generalization performance. "
SP:0991bc5f213bd8ab7572e2fed309e1b57a35835b,"This paper proposes a method to detect distributional shifts in machine learning models. In particular, the authors propose to use a sequence of time-uniform confidence sequences to detect harmful shifts while ignoring benign ones, and to allow continuous monitoring of model performance without increasing the false alarm rate. The proposed method is tested on simulated and real-world datasets. "
SP:1c7b954273e3a9cda333385b15a3e8ed3bf8178a,"This paper proposes to use neural implicit representations for appearance modeling with neural ordinary differential equations (ODEs) in order to obtain interpretable physical models directly from visual observations. The proposed model combines several unique advantages: (i) Contrary to existing approaches that require large training datasets, the proposed model is able to identify physical parameters from only a single video. (ii) The use of neural implicit representation enables the processing of high-resolution videos and the synthesis of photo-realistic imagery. (iii) The embedded neural ODE has a known parametric form that allows for the identification of interpretability physical parameters and (iv) long-term prediction in state space. (v) Furthermore, the model can be used to render novel scenes with modified physical parameters."
SP:51efd1451343f4994d857daa5490e299b812bc2d,". This paper considers the context-dependent reinforcement learning problem. The authors propose a Hierarchical Dirichlet Process (HDP) prior for model learning, which is arguably best-suited for Markov process modeling. They then derive a context distillation procedure, which identifies and removes spurious contexts in an unsupervised fashion. They argue that the combination of these two components allows to infer the number of contexts from data thus dealing with the context cardinality assumption. Finally, they find the representation of the optimal policy enabling efficient policy learning."
SP:ea167b126212b2092bc1190d7f8376bf7c54a888,"This paper presents a framework to train knowledge based multilingual language models (KMLMs) by generating synthetic sentences and reasoning-based multilingual training data using the Wikidata knowledge graphs. Then based on the intra-and inter-sentence structures of the generated data, the authors design pretraining tasks to facilitate knowledge learning. The pretrained KMLMs demonstrate significant performance improvements on a wide range of knowledge-intensive cross-lingual NLP tasks, including named entity recognition, factual knowledge retrieval, relation classification, and a new task designed by us, namely, logic reasoning."
SP:6c11cf29c90f923346372ba6f11452c36e69ad6d,"This paper proposes an approach to learn to act altruistically towards other agents by giving them more choice and thereby allowing them to better achieve their goals. The authors propose an algorithm that learns to increase the choices another agent has by preferring to maximize the number of states that the other agent can reach in its future. They evaluate their approach on three different multi-agent environments where another agent's success depends on the altruistic agent’s behaviour. They show that their unsupervised agents can perform comparably to agents explicitly trained to work cooperatively, and even outperform them."
SP:5dbc54201ba184266c5054f0d2944bd197bc307a,"This paper studies the phenomenon of double descent in finite-width neural networks. The main contribution of the paper is to derive the lower bound of the population loss and its lower bound. The lower bound is based on the spectrum of the Hessian at the optimum, and the authors show that it has a double descent behaviour at the interpolation threshold. The authors further investigate how the loss function affects double descent. "
SP:b485114712055f39a7afb951dbc3db482ff523fd,"This paper studies the asymptotic behavior of the graph neural tangent kernel (GNTK) in deep graph convolutional networks (GCNs). The main contribution of the paper is the analysis of the exponential decay of GNTK in the large depth of GCNs. The authors show that the GNTk can drop trainability of deep GCNs at an exponential rate in the optimization process. To address this issue, the authors propose Critical DropEdge, a connectivity-aware and graph-adaptive sampling method inspired by their theoretical insights on trainability. "
SP:25a92b3583afdc6892e59f1e769125d52c8011af,"This paper proposes a method for estimating second-order dynamics in cardiac recordings. The authors propose to use the second derivative of both the input frames and the target vital sign signals into the training procedure to better estimate left ventricle ejection time (LVET) intervals. In addition, they show that adding second-derivative inputs also improves performance when estimating second order dynamics."
SP:0a88d2fcbdfab3e196bf6b9c75adb1006ab87536,"This paper proposes to use symbolic mapping to help agents learn a compositional and symmetric language in complex settings like dialog games. Inspired by the theory that human language was originated from simple interactions, the authors hypothesize that language may evolve from simple tasks to difficult tasks. They propose a novel architecture called symbolic mapping as a basic component of the communication system of agent. They find that symbolic mapping learned in simple referential games can notably promote language learning in difficult tasks and explore vocabulary expansion, and show that agents can easily learn to use new symbols when the environment becomes more complex."
SP:89575be04cb33b41d7a0a7b62f9496c2838a1317,"This paper proposes a hierarchical modular approach to learn agents that navigate and manipulate objects in a divide-and-conquer manner for the diverse nature of the entailing tasks. Specifically, the policy operates at three levels of hierarchy. First, it first infer a sequence of subgoals to be executed based on language instructions by high-level policy composition controller (PCC). Then discriminatively control the agent’s navigation by a master policy by alternating between navigation policy and various independent interaction policies. Finally, it infer manipulation actions with the corresponding object masks using the appropriate interaction policy. The proposed approach achieves state-of-the-art performance on the challenging ALFRED benchmark."
SP:e2c8efe00db7baba2368f4f6a37815809b9e235e,"This paper proposes Nuisance-Randomized Distillation (NURD) to build predictive models that perform well regardless of the nuisance-label relationship. NURD first defines a nuisance-varying family, a set of distributions that differ only in the nuisance and the label relationship, and then introduces a new distribution, called nuisance-randomized distribution. Under this distribution, the authors prove that the representations in this set always perform better than chance, while representations outside of this set may not. The authors also show that the representation from this set that is most informative of the label under the nuisance distribution achieves the highest performance within the set on every distribution in the family."
SP:c75998b76f4e0510fc719d25959a10fc07db1c40,"This paper proposes OTTER (Optimal TransporT distillation for Efficient zero-shot Recognition), which uses online entropic optimal transport to find a soft image-text match as labels for contrastive learning. Based on pretrained image and text encoders, models trained with OTTER achieve strong performance with only 3M image text pairs. Compared with InfoNCE loss, label smoothing, and knowledge distillation, OTTER consistently outperforms these baselines in zero shot evaluation on Google Open Images (19,958 classes) and multi-labeled ImageNet 10K from Tencent ML-Images."
SP:e83cd70377542b5d187998e2e4a7ac070f453ed6,"This paper presents Pix2Seq, a simple and generic framework for object detection. Unlike existing approaches that explicitly integrate prior knowledge about the task, this paper casts object detection as a language modeling task conditioned on the observed pixel inputs. Object descriptions (e.g., bounding boxes and class labels) are expressed as sequences of discrete tokens and we train a neural net to perceive the image and generate the desired sequence. The proposed approach achieves competitive results on the challenging COCO dataset, compared to highly specialized and well optimized detection algorithms."
SP:abc9315f61929cc1c54dfef8ff83d7eac56ec2f2,"This paper proposes a symbolic distillation approach for visual reinforcement learning. The proposed approach is based on the idea of distilling the learned policy network into a symbolic policy, composed from geometric and numerical symbols and operators. The symbolic policy can be treated as discrete and abstracted representations of the policy network, but are found to be more interpretable, robust and transferable. Experiments show that the proposed approach can maintain the performance and denoise the CNN policy. "
SP:04e7e181aeb1244ae1c4837ad416aef93ea3ea32,This paper proposes a new method for image-to-image translation based on the StyleGAN2 framework. The main contribution of the paper is the use of a VQSN module for the generator for better pose-identity disentanglement. The paper also proposes a joint-training scheme with self-supervision methods for the GANInversion encoder and the generator. Experiments on various datasets show the effectiveness of the proposed method. 
SP:e51a7f45493064972585109f203a867e9828eb15,"-MLP proposes a multi-layer perceptron architecture to extract information from speech signals. The model splits feature channels into non-overlapped chunks and processes each chunk individually. These chunks are then merged together and further processed to consolidate the output. The proposed model is successfully evaluated on two tasks: keyword spotting and speech enhancement. In all experiments, the proposed model surpassed the transformer-based solutions."
SP:d708d3886f4abd4552d8ccb2096df7361c803b13,This paper studies the generalization error of transfer learning algorithms for binary classification problems. The main contribution of the paper is to provide a lower bound on the generalisation error of any transfer learning algorithm (regardless of its computational complexity) as a function of the amount of source and target samples. The lower bound depends on a natural notion of distance that can be easily computed on real world data sets. The authors also consider a more general setting where there are more than one source domains for knowledge transfer to the target task and develop new bounds on generalization errors in this setting. 
SP:f7511ba9ccad03233b34b1bf41bbac7361d20a57,"This paper proposes a probabilistic approach for the problem of shape completion of large-scale 3D scenes. The proposed approach is based on the generative model of GCA, which learns the multi-modal distribution and transforms the formulation to process large scale continuous geometry. The local continuous shape is incrementally generated as a sparse voxel embedding, which contains the latent code for each occupied cell. Experiments show that the proposed approach successfully generates diverse plausible scenes faithful to the input, especially when the input suffers from a significant amount of missing data."
SP:d22d8f074adbe8fb0f25fb8f8d96201b3159bf6b,This paper proposes to use temporal priors as a non-Markovian generalization of behavioral priors for guiding exploration in reinforcement learning. The authors propose to use a probabilistic mixture of policy and temporal prior to guide off-policy reinforcement learning in unseen downstream tasks. They provide empirical evidence that their approach improves upon strong baselines in long-horizon continuous control tasks under sparse reward settings.
SP:25e06c022ae8b3cbbb8db413d7b534a1a5c92391,"This paper proposes Graph-Network-based Scheduler (GNS) to learn a specific scheduling mechanism without restrictions to existing principles. By constructing a directed graph for the underlying neural network of the target problem, GNS encodes current dynamics with a graph message passing network and trains an agent to control the learning rate accordingly via reinforcement learning. The proposed scheduler can capture the intermediate layer information while being able to generalize to problems of varying scales. Besides, an efficient reward collection procedure is leveraged to speed up training."
SP:d73cb0471c1770607ad3e4621cfc5f170683dd8e,"This paper proposes a method for object-centric learning from 3D point clouds. The proposed method is based on the Chamfer Mixture Loss, which is used to model the spatial mixture model. The authors also propose an object-specification scheme that describes each object’s location relative to its local voxel grid cell. Experiments on the task of unsupervised scene decomposition show the effectiveness of the proposed method."
SP:3c57e921c1bf23e482551ceb71702931a7f07439,"This paper studies the problem of using large language models (LLMs) to learn to perform actions in an interactive environment. The authors propose a method to decompose high-level tasks into low-level plans (i.e., “make breakfast” and “open the fridge”) and use them to guide the LMs to take actionable steps in the environment. In particular, they propose a procedure that conditions on existing demonstrations and semantically translates the plans to admissible actions. Experiments on the VirtualHome environment show that the proposed method substantially improves executability over the LLM baseline. "
SP:e0159d1c9df2e657892a3a0c77549df4698d9a1a,"This paper proposes a method to generate samples from a uniform distribution derived from the Riemannian manifold learned by a VAE. In particular, the authors propose a new way of generating samples consisting in sampling from the uniform distribution deriving intrinsically from the learned manifold. The authors show that using these geometrical considerations can significantly improve the generation from the vanilla VAE which can now compete with more advanced VAE models on four benchmark datasets. Finally, they validate the method on a complex neuroimaging dataset combining both high dimensional data and low sample sizes."
SP:b4b8e1727f8617894f10f20365cb68de79f0e650,"This paper proposes Transformer with a Mixture of Gaussian Keys (Transformer-MGK), a novel transformer architecture that replaces redundant heads in transformers with a mixture of keys at each head. These mixtures of keys follow a Gaussian mixture model and allow each attention head to focus on different parts of the input sequence efficiently. Compared to its conventional transformer counterpart, Transformer- MGK accelerates training and inference, has fewer parameters, and requires less FLOPs to compute while achieving comparable or better accuracy across tasks. Experiments are conducted on the Wikitext103 and Long Range Arena benchmark."
SP:82731dcce233e748f63382e09b6224a513fe9689,"This paper proposes a new two-dimensional continuous environment in which the authors propose to fuse image and action related signals. The authors propose a minimalistic recurrent architecture, called Resetting Path Integrator (RPI), that can easily and reliably be trained to keep track of its position relative to its starting point during a sequence of movements. RPI updates its internal state using the (possibly noisy) self-motion signal, and occasionally resets it when the image signal is present. The internal state of this minimal model exhibits strong correlation with position in the environment due to the direct-inverse models, is stable across long trajectories through resetting, and allows for disambiguation of visually confusing positions in the environments through integration of past movement."
SP:1a27c397d1e73def5e724c5c6f25548975ba50fa,"This paper studies the effect of the structure of the input distribution on the performance of neural networks trained by gradient descent. In particular, the authors show that the success of the network relies on the emergence and improvement of effective features, which are learned among exponentially many candidates efficiently by exploiting the data (in particular, structure of input distribution). In contrast, no linear models on data-independent features of polynomial sizes can learn to as good errors. Furthermore, if the specific input structure is removed, then no polynomials algorithm can learn even weakly. "
SP:8ada73ed7eade9ebdeef376485e849c42575bc5f,"This paper studies the robustness of fixed feature extractors to adversarial examples generated by test-time adversaries. The main contribution of the paper is the analysis of how robust the classifier trained on top of the feature extractor can be. The authors propose a method for finding the collision between perturbed examples at deeper layers of the network. They show that for linear features extractors, they provide a closed-form expression for collision finding, while for arbitrary features, they propose a bespoke algorithm based on the iterative solution of a convex program that provably finds collisions. They utilize their bounds to identify the layers of robustly trained models that contribute the most to a lack of robustness. "
SP:874b5fa51924cbcceed490d98a0ea80f74586b32,"This paper proposes Expectile V-Learning (EVL), which learns the V-function instead of the Q-function to naturally keep the learning procedure within the offline dataset. The authors propose to interpolate between the optimal value learning and behavior cloning and introduce implicit planning along offline trajectories to enhance learned V-values and accelerate convergence. They provide theoretical analysis for the convergence properties of their proposed VEM method and empirical results in the D4RL benchmark show that the proposed method achieves superior performance in most tasks, particularly in sparse reward tasks."
SP:34f08d92681504490c2f739b0d08f79f9764b2f5,"This paper proposes a novel adversarial training framework that learns to reweight the loss associated with individual training samples based on a notion of class-conditioned margin, with the goal of improving robust generalization. Inspired by MAML-based approaches, the authors formulate weighted adversarial learning as a bilevel optimization problem where the upper-level task corresponds to learning a robust classifier, and the lower-level problem is learning a parametric function that maps from a sample’s multi-class margin to an importance weight. Extensive experiments demonstrate that the proposed method improves both clean and robust accuracy compared to related techniques and state-of-the-art baselines."
SP:3ad36be6b6900aabe43da043461cf178ce977082,"This paper proposes a new type of equivariant graph neural network, called steerable E(3) Equivariant Graph Neural Networks (SEGNNs), which is able to incorporate geometric and physical information in both the message and update functions. The main contribution of the paper is the introduction of steerable node attributes, which is a new class of activation functions for general use with steerable feature fields. Experiments on several tasks in computational physics and chemistry demonstrate the effectiveness of the proposed method."
SP:8928aa83f7ebd4e310f4fe1d01ff0eb0c96e4d2b,"This paper proposes a new differentiable physics model for differentiable fabrics for composite materials such as cloths, where the granularity of yarns and individual yarn physics and yarn-to-yarn interactions are modeled. To this end, the authors propose several differentiable forces, whose counterparts in empirical physics are indifferentiable, to facilitate gradient-based learning. They demonstrate the model’s explicability in learning meaningful physical parameters, versatility in incorporating complex physical structures and heterogeneous materials, data-efficiency in learning, and high-fidelity in capturing subtle dynamics."
SP:2c8358c095b10981d3015b9f6c75765419a9480d,"This paper studies the problem of transfer learning in the context of reinforcement learning. In particular, the authors propose a method for learning a transfer policy for a new task from a set of base tasks and a new set of tasks from an unknown distribution. The proposed method is based on the idea of logical composition in reinforcement learning, where the goal is to decide whether to learn a task-specific skill (e.g., to solve the new task) or to use existing skills to solve a base task. The authors show that the proposed method improves the transfer learning performance of the learned policy on the new tasks. They also provide theoretical results on the number of tasks that are necessary and sufficient for the agent to generalize over the new distribution."
SP:c85d71d05164d019cc32bf423e4c4fe20c169f41," in multivariate time series classification (MTSC). This paper proposes a distributed MTSC solution, LightWaveS, which is fast both during training and inference. The proposed method is based on a wavelet scattering transformation of the time series and distributed feature selection, and achieves accuracy comparable to the state-of-the-art ROCKET. Experiments on three datasets show the effectiveness of the proposed method."
SP:db43614ca016280a79448f44a97c81c8ff5ba981,"This paper proposes a method to train text encoders with an adversarial learning curriculum via a Mixture Of Signals from multiple auxiliary generators. The main encoder is trained as a discriminator to detect replaced tokens generated by auxiliary masked language models (MLMs). Different from ELECTRA which trains one MLM as the generator, this paper jointly trains multiple MLMs of different sizes to provide training signals at various levels of difficulty. The authors propose to learn mixture weights over the auxiliary MLMs’ outputs to maximize the discriminator loss by backpropagating the gradient from the discriminators via Gumbel-Softmax. "
SP:db3825633ab5d0671340390b23ab655838cc38b2,"This paper proposes an adaptive fine-tuning approach to improve the performance of a pre-trained language model on the fill-mask task using a small training dataset of existing facts from a knowledge graph. The authors show that the proposed approach outperforms all baselines, even by using significantly fewer training facts. They also show that even fewer training relations are needed to achieve high knowledge extraction quality."
SP:ae25d32714b2b9f7e02cc20f4a36252e20e78e4f," in this paper, the authors propose to learn knowledge base embeddings in different geometric spaces and apply manifold alignment to align the shared entities. The proposed approach is evaluated on the out-of-taxonomy entity typing task, where they aim to predict the types of the entities from the knowledge graph. Experimental results on two datasets based on YAGO3 demonstrate that their approach has significantly good performances, especially in low dimensions and on small training rates."
SP:9ab3bc525ee4a9c96518c43e4c43082655a7674f," for link prediction in temporal knowledge graphs. The authors propose a one-shot learning framework to solve this problem. The proposed method employs a self-attention mechanism to effectively encode temporal interactions between entities, and a network to compute a similarity score between a given query and a (one-shot) example. The experiments show that the proposed algorithm outperforms the state-of-the-art baselines for two well-studied benchmarks."
SP:91f92a40e12afd0702f07ae7f4175ecce57b7007,"This paper proposes a method for learning to solve tasks of increasing complexity by building on top of previously acquired knowledge. The authors propose to represent a solver for each task as a neural module that calls existing modules (solvers for simpler tasks) in a functional program-like manner. Lower modules are a black box to the calling module, and communicate only via a query and an output. A module for a new task learns to query existing modules and composes their outputs in order to produce its own output. The model effectively combines previous skill-sets, does not suffer from forgetting, and is fully differentiable. Experiments on a set of visual reasoning tasks demonstrate improved performance in all tasks by learning progressively."
SP:de33b02e7f2faec5bcae9a5516721aa1ef190572,"-based neural networks have become popular paradigms for designing deep convolutional neural networks (CNNs). In this paper, the authors propose Selective Convolutional Unit (SCU), a widely-applicable architectural unit that improves parameter efficiency of various modern CNNs with bottlenecks. During training, SCU gradually learns the channel-selectivity on the fly via the alternative usage of (a) pruning unimportant channels, and (b) rewiring the pruned parameters to important channels. The experimental results demonstrate that the SCU-based models without any postprocessing generally achieve both model compression and accuracy improvement compared to the baselines."
SP:2d80fa4bc440061be2234b5070503d3fa056baed,". The paper considers the problem of learning a binary classifier only from positive data and unlabeled data (PU learning). The proposed algorithm learns a scoring function that preserves the order induced by the class posterior under mild assumptions, which can be used as a classifier by setting an appropriate threshold. Through experiments, the method outperforms previous methods for PU learning on various real-world datasets."
SP:5f312626b0613d2e07c59214c5f00db208a98717,This paper proposes to use the cosine similarity between gradients of tasks as an adaptive weight to detect when an auxiliary loss is helpful to the main loss. The authors show that their approach is guaranteed to converge to critical points of the main task and demonstrate the practical usefulness of the proposed algorithm in a few domains.
SP:e270ae3eeb7ab4fa91ba37d4d68ce10f2fa0a3b5,"The paper proposes a geometric framework for analyzing the high-dimensional geometry of adversarial examples. The main contribution of the paper is to show that for low-dimensional data manifolds embedded in high dimensional space there are many directions off the manifold in which to construct an adversarial example. The paper also shows that adversarial training in balls around the data is sample inefficient, and provides sufficient sampling conditions under which nearest neighbor classifiers and ball-based adversarial learning are robust."
SP:e07d948a79d478ecd23a0a4406d4ddd3ac5e3be3,"This paper proposes a new representation learning algorithm for time series data. The authors propose to learn discrete representations of time series, which give rise to smooth and interpretable embeddings with superior clustering performance. They introduce a new way to overcome the non-differentiability in discrete representation learning and present a gradient-based version of the traditional self-organizing map algorithm that is more performant than the original. Furthermore, to allow for a probabilistic interpretation of the method, the authors integrate a Markov model in the representation space. This model uncovers the temporal transition structure, improves clustering and provides additional explanatory insights as well as a natural representation of uncertainty."
SP:5915ee71ea58dbdbafa31c1ad291d1e5940a0cf4,"This paper studies the properties of multidimensional probability distributions in the context of latent space prior distributions of implicit generative models. The authors show that the distribution mismatch can be eliminated completely by a proper choice of the latent probability distribution or using non-linear interpolations. They prove that there is a trade-off between the interpolation being linear, and the latent distribution having even the most basic properties required for stable training, such as finite mean. They also provide a general method of creating non- linear interpolations that is easily applicable to a large family of commonly used latent distributions."
SP:19b63ca635712f1509ca6e0141303c192f2709e0,"This paper proposes to use hyperbolic embeddings to learn the parameters of shallow neural networks in hyper-bolic space. The key idea is to use the embedding space more efficiently without increasing the number of parameters of the model. This is achieved by only changing the geometry of embedding of object representations. The proposed method shows improvements in generalization on neural machine translation on WMT’14 (English to German), learning on graphs (both on synthetic and real-world graph tasks) and visual question answering (CLEVR) tasks while keeping the neural representations compact."
SP:f6049e9f80a63c9306c1cebcb6b229aa6da44ddc,"This paper studies the problem of DNN fingerprinting attacks that exploit cache side-channels. The authors propose DeepRecon, an attack that reconstructs the architecture of the victim network using the internal information extracted via Flush+Reload, a cache side channel technique. They demonstrate that an attacker can accurately reconstruct two complex networks (VGG19 and ResNet50) having observed only one forward propagation. Based on the extracted architecture attributes, the attacker can build a meta-model that accurately fingerprints the architecture and family of the pretrained model in a transfer learning setting. "
SP:6a3dd89db6c24a1f98e8866ef0a4c1c2c1ec6635,"This paper proposes a hierarchical network model for video sequence prediction. The model is inspired by the feedforward, feedback and lateral recurrent circuits in the mammalian hierarchical visual system. It assumes that spatiotemporal memories are encoded in the recurrent connections within each level and between different levels of the hierarchy. Within each level, the feed-forward path and the feedback path intersect in a recurrent gated circuit that integrates their signals as well as the circuit’s internal memory states to generate a prediction of the incoming signal. The network learns by comparing the incoming signals with its prediction, updating its internal model of the world by minimizing the prediction errors at each level."
SP:fb74e57f35666742caf651e6da33b5defcf259a8,"This paper proposes a method to compute continuous embeddings for DNA sequences from raw RNA-seq data in a reference-free fashion. The authors show that their model captures information of both DNA sequence similarity as well as DNA sequence abundance in the embedding latent space. They confirm the quality of these vectors by comparing them to known gene sub-structures and report that the latent space recovers exon information from raw data from acute myeloid leukemia patients. Furthermore, this latent space allows the detection of genomic abnormalities such as translocations and patient-specific mutations."
SP:03aca6ff6a7f0ad2d5ccbcb15ed9536e305a9880,"This paper proposes a novel approach to model compression based on the architecture space. The proposed approach is based on learning a mapping from discrete architecture space to a continuous embedding and back. This embedding is jointly trained to regress accuracy and parameter count in order to incorporate information about the architecture’s effectiveness on the dataset. During the compression phase, the encoder first encodes the network and then performs gradient descent in continuous space to optimize a compression objective function that maximizes accuracy and minimizes parameter count. The final continuous feature is then mapped to a discrete architecture using the decoder."
SP:0511b5d10a90e3fe814e2d35208b4a987894ea62,"This paper proposes a new framework for learning to plan online and learn offline. The main idea is to use trajectory optimization to learn a global value function, and then use this value function to guide the agent to explore the world. The authors show that this approach can be combined with local model-based control, value function learning, and exploration to improve the performance of the agent. The proposed method is evaluated on humanoid locomotion and dexterous in-hand manipulation."
SP:771494fda4702cd8c7efbf225b19028f91b449b9,"This paper proposes a zero-shot and dual learning approach for neural machine translation (NMT) systems. The proposed approach is based on reinforcement learning, where the goal is to learn a model that is able to learn to translate the target language to a target language using only monolingual data. Experiments on the UN corpus show that the proposed approach outperforms the state-of-the-art unsupervised and semi-supervised NMT systems."
SP:1558dc03f99670f9ddccdca9c223a2baf962d438,"This paper studies the problem of information retrieval in the context of generative adversarial networks (GANs). The main contribution of the paper is the analysis of the proposed IRGAN framework, which is based on the framework for Information-Retrieval (IR). The paper argues that IRGAN's setup and baseline term steer the model away from an exact adversarial formulation, and this work attempts to point out certain inaccuracies in their formulation. The paper also proposes a co-training setup where two models are trained in a cooperative manner rather than adversarial fashion."
SP:6a13dda852ab075a3c0fb691476d6dc57919c729,This paper proposes to use Spike and Slab prior distributions in variational auto-encoders (VAEs) to model sparsity in the latent space of a VAE with a discrete mixture recognition function. The authors show that the proposed approach is computationally efficient for approximate posterior inference. They show that their approach is able to infer truly sparse representations with generally intractable non-linear probabilistic models. Experiments on MNIST and Fashion-MNIST show the effectiveness of the proposed method.
SP:06a22143186fa2948fbe324ccae96a62ff12064e,". This paper proposes a non-adversarial feature matching-based approach to train generative models. The proposed approach, Generative Feature Matching Networks (GFMN), leverages pretrained neural networks such as autoencoders and ConvNet classifiers to perform feature extraction. The experimental results demonstrate that the proposed approach can achieve state-of-the-art results for challenging benchmarks such as CIFAR10 and STL10."
SP:2d7cf2f07a27d6c8e304a1b47c25387ad2e4432d,"-based GNNs have revolutionized graph representation learning, but there is limited understanding of their representational properties and limitations. This paper presents a theoretical framework for analyzing the expressive power of graph neural networks to capture different graph structures. The results characterize the discriminative power of popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, and show that they cannot learn to distinguish certain simple graph structure. The authors then develop a simple architecture that is provably the most expressive among the class of GNN and is as powerful as the WeisfeilerLehman graph isomorphism test. The experimental results validate the theoretical findings on a number of graph classification benchmarks."
SP:51126f2dd37ce57d2614c9044ede1e43627f0829,This paper proposes a method for interpretable continual learning based on variational continual learning. The main idea is to use saliency maps to provide explanations of performed tasks and propose a new metric to assess the quality of the explanations. Experiments show that ICL achieves state-of-the-art results in terms of overall continual learning performance as measured by average classification accuracy. 
SP:27a565b3e5442b93d208652784051e640b0c1bfe,"This paper proposes a new evaluation framework for adversarial attacks on neural sequence-to-sequence (seq2seq) models taking meaning preservation into account and demonstrate that existing methods may not preserve meaning in general. Based on these findings, the authors propose new constraints for attacks on word-based MT systems and show, via human and automatic evaluation, that they produce more semantically similar adversarial inputs. Furthermore, they show that performing adversarial training with meaning-preserving attacks is beneficial to the model in terms of adversarial robustness without hurting test performance."
SP:54ddd8132bf9e4259d2c2d72b348d2bb5f9e227c,"This paper proposes a new approach for reinforcement learning that combines the policies using original rewards and inverse (negative) rewards. The proposed approach is based on deep Q-learning, double-Q-learning and on-policy actor-critic. The authors prove the convergence of the inverse policies. Experiments on OpenAI Gym show that the proposed approach can obtain rewards up to 63.8% more than the original policies."
SP:89a732b57934d08b937c93560f391b7758e54f8a,"This paper proposes a method to learn a hierarchical, disentangled object representation and a dynamics model for object parts from unlabeled videos. The model learns to recognize the object parts via a layered image representation, predict hierarchy via a structural descriptor that composes low-level concepts into a hierarchical structure, and model the system dynamics by predicting the future. Experiments on multiple real and synthetic datasets demonstrate that the proposed method works well on all three tasks: segmenting object parts, building their hierarchical structure and capturing their motion distributions."
SP:bb2a655d67bed9da43f0b8ec7d888b89c217d12e," of the proposed method, Deep Determinantal Generative Classifier (DDGC), which can obtain a more robust decision boundary under any softmax neural classifier pre-trained on noisy datasets. The main idea of DDGC is inducing a generative classifier on top of hidden feature spaces of the discriminative deep model. By estimating the parameters of the classifier using the minimum covariance determinant estimator, DDGC significantly improves the classification accuracy, with no re-training of the deep model nor changing its architectures. The experiments show that DDGC generalizes well from noisy labels, and also is robust against adversarial perturbations due to its large margin property."
SP:0fa525cc708470b757a60117cb608bb2feaa2c50,This paper proposes a method for learning subgoals in Hierarchical Reinforcement Learning (HRL) that does not require the acquisition of a model of the environment. The proposed method is based on incremental unsupervised learning over a small memory of the most recent experiences of the agent. The method is evaluated on two RL problems with sparse delayed feedback: a variant of the rooms environment and a game called Montezuma’s Revenge.
SP:e5861538bc8bb9165cb33299bbf12dd875abf976,This paper proposes a neural network architecture to solve the Circuit Satisfiability Problem (CSP) problem. The main contribution of the paper is to propose an end-to-end differentiable training procedure that mimics Reinforcement Learning and trains the model directly toward solving the SAT problem. Experiments show that the proposed method outperforms the NeuroSAT method in terms of generalization performance.
SP:ff3e5d44619df3825632b0b1a943add081364861,"This paper proposes a novel combination of cross-entropy method (CEM) and Twin Delayed Deep Deterministic Policy Gradient (TD3) to improve the sample efficiency of DDPG. CEM-RL is a combination of CEM and TD3, where TD3 is an off-policy deep RL algorithm and CEM is an ad hoc evolutionary algorithm. The proposed method is evaluated on a set of deep RL benchmarks. "
SP:78b2eb326695da0b0cc4ba39a9206d11644a5e32,This paper proposes a multi-variate LSTM recurrent neural network (IMV-LSTM) for multi-variable forecasting and interpretability. The proposed method is based on a mixture attention mechanism to quantify the temporal and variable importance in data. Extensive experiments on real datasets demonstrate the effectiveness of the proposed method. 
SP:1c26660569b579f060f7b4a31e321c6d2356b928,"This paper proposes feature smoothing, a simple data augmentation method with little computational overhead for adversarial attacks. The paper also proposes a unified framework to understand the connections and differences among different efficient methods by analyzing the biases and variances of decision boundary. The experiments on MNIST and CIFAR10 datasets explore different combinations of known regularization and data augmentations methods and show that feature smoothed with logit squeezing performs best for both adversarial and clean accuracy. "
SP:88d652f9e411dd3a2e9ad651d9011e579653c6aa,"This paper proposes a novel theoretical framework for deep neural networks with ReLU nonlinearity. The framework bridges data distribution with gradient descent rules, favors disentangled representations and is compatible with common regularization techniques such as Batch Norm. This framework is built upon teacher-student setting, by projecting the student’s forward/backward pass onto the teacher's computational graph. "
SP:7842bbe0e2324cfd732db8745550733ccc3dfcdc,"This paper proposes a modular architecture of neural networks with a Behavioral Module (BM) and corresponding end-to-end training strategy. This approach allows efficient learning of behaviors and preferences representation. This property is particularly useful for user modeling (as for dialog agents) and recommendation tasks, as allows learning personalized representations of different user states. The experiments also show network extendability through independent learning of new behavior patterns."
SP:300c391ff644b6889cd9ae27cf0d162dfcdd4451,"This paper proposes a differentiable formulation for the neuromodulation of plasticity. The paper shows that this formulation can be used to train neural networks with differentiable Hebbian plasticity to improve the performance of neural networks on both reinforcement learning and supervised learning tasks. In one task, the proposed method outperforms standard LSTMs on a benchmark language modeling task. "
SP:1ab5d94d31e99351433436c026799c8aa597bf73,". This paper proposes a new quantization method for deep neural networks. The proposed method is based on re-training the full precision model, followed by directly optimizing the corresponding binary model. The quantization training process takes no longer than the original training process. The authors also propose a new loss function to regularize the weights, resulting in reduced quantization error."
SP:0876b1d9a6d664808ca1ab15865679fbf638267e,"This paper proposes a method for the open-ended recombination of style of one image with the content of another. The method starts by constructing a content embedding using an existing deep metric-learning technique. This trained content encoder is incorporated into a variational autoencoder (VAE) paired with a to-be-trained style encoder. The VAE reconstruction loss alone is inadequate to ensure a decomposition of the latent representation into style and content. The authors propose an auxiliary loss, leakage filtering, which ensures that no style information remaining in the content representation is used for reconstruction and vice versa. The proposed method achieves state-of-the-art performance on few-shot learning tasks."
SP:d37e15cde7765fca87595a242f0a4511b3346d46,"This paper proposes a method to speed up deep RL training for problems that have the property of state-action permissibility (SAP). Two types of SAP are defined under SAP. The first type says that after an action at is performed in a state and the agent reaches the new state st+1, the agent can decide whether the action is permissible or not permissible in state st. The second type is that even without performing the action at in st, an agent can already decide whether at is permissible in st. An action is not permissible if the action can never lead to an optimal solution and thus should not be tried. The proposed method incorporates the proposed SAP property into two state-of-the-art deep RL algorithms to guide their state-actions exploration."
SP:20015d8b60e13300586b67c281858cbe28825c48,"This paper studies the behavior of deep autoencoders under the assumption of random weight-tied multilayer vanilla autoencoder. The authors provide an exact characterization in the limit of large dimensions, which reveals interesting phase transition phenomena when the depth becomes large. They also provide insights on pitfalls in training initialization practice, and demonstrate experimentally that it is possible to train a deep auto-encoder, even with the tanh activation and a depth as large as 200 layers."
SP:91764f80dbe2401ade38b35a8253ba05f0f86386,This paper proposes a new algorithm for black-box adversarial image generation. The key idea is to randomly pick a low frequency component of the discrete cosine transform (DCT) and either add or subtract it to the target image. The proposed algorithm can be used for both targeted and untargeted attacks. The paper shows that the proposed method can be implemented in less than 20 lines of PyTorch code. 
SP:fc20ae0fbf57a1ce489c04b85c7c2f4c93dc2450,"This paper proposes a new approach for option discovery in the context of hierarchical reinforcement learning. In particular, the authors propose a method to discover “landmark” sub-goals which are prototypical states of well connected regions. The sub-goal states are points from which a densely connected set of states are easily accessible. They propose a new model called Successor options that leverages Successor representations to achieve the same. They also design a novel pseudo-reward for learning the intra-option policies. Finally, they demonstrate the efficacy of their approach on a collection of grid worlds and on complex high dimensional environments like Deepmind-Lab."
SP:12a172c1e2892d016b37932acfc48dcb56874a89,"This paper studies the problem of domain division, which aims to segment instances drawn from different probabilistic distributions. The authors propose a domain division algorithm to split the testing instances into known, unknown and uncertain domains, and then conduct recognition tasks in each domain. Two statistical tools, namely, bootstrapping and KolmogorovSmirnov (K-S) Test, for the first time, are introduced to uncover and fine-tune the decision boundary of each domain, and the uncertain domain is newly introduced in the framework to adopt those instances whose domain labels cannot be predicted confidently. Extensive experiments demonstrate the state-of-the-art performance on OSL and G-ZSL benchmarks."
SP:28bcf7c6a4673e9ec2b4ebed09839d85188e0b2a,"This paper proposes a neural network for classification and regression, without the need to learn layout structures in the output space. The structure is defined by polar prototypes, points on the hypersphere of the output spaces. For classification, each class is described by a single polar prototype and they are a priori distributed with maximal separation and equal shares. For regression, training can be performed as a polar interpolation between two prototypes, arriving at a regression with higher-dimensional outputs. Experiments show that polar prototype networks benefit from large margin separation and semantic class structure."
SP:d1034342785d133cf8372b8624897963cc2ee83a,This paper studies the problem of RL in the setting where the state of the environment is already optimized for what humans want. The authors propose an algorithm based on Maximum Causal Entropy IRL (MCEI) to solve this problem. The algorithm is evaluated on a suite of proof-of-concept environments designed to show the effectiveness of the proposed algorithm. 
SP:417a4e0acee699b3e004ad30d0ecf533a9ed987e,"This paper proposes a method for learning the dependency structure between latent variables in deep latent variable models. The proposed method combines the complementary strengths of deep generative models and probabilistic graphical models. In particular, the latent variable space of a variational autoencoder (VAE) is expressed in terms of a Bayesian network with a learned, flexible dependency structure. The network parameters, variational parameters as well as the latent topology are optimized simultaneously with a single objective. Inference is formulated via a sampling procedure that produces expectations over latent variable structures and incorporates top-down and bottom-up reasoning over latent variables values."
SP:976dedab53e69610692a563382ada1dbb82c1e9d,"This paper studies the problem of learning a dynamical network for solving a dictionary learning problem. The authors propose to use spiking neurons to construct the network and show that the gradients for learning are provably computable by individual neurons. They show that by combining ideas of top-down feedback and contrastive learning, the network can be constructed and the true gradients can be obtained. They also provide a learning process, its rigorous mathematical analysis, and numerical results on the problem."
SP:f45117a6beaeb86a70b1380b4fac3cfba37fb892,This paper proposes a novel network for lane detection. The proposed network is based on the idea of using multiple encoder-decoders module in end-to-end ways and show the promising results for the lane detection task. The paper also proposes to rethink the evaluation methods of lane detection for the limitation of the popular methods based on IoU. 
SP:68b0a10ca06df74612d0753cc3f3ddddde806035,"This paper proposes a new approach for batch contextual bandit learning from logged bandit feedback. The proposed approach is based on the idea of estimating a maximum likelihood surrogate policy based on logged action-context pairs, and then using this surrogate policy as the proposal. The authors prove that the proposed approach MLIPS is asymptotically unbiased, and has a smaller non-asymptotic mean squared error than IPS. The empirical results on multi-label classification problems and a large-scale ad placement dataset demonstrate the effectiveness of MLIPS."
SP:8e0ed65c5dded23b34798499b2436b24422fd729,"This paper proposes a meta-learning approach for few-shot classification. The authors propose to learn how to create an individualized feature embedding specific to a given query image for better classifying. Specifically, they introduce a kernel generator as meta-learner to learn to construct feature embeddings for query images. The kernel generator acquires meta-knowledge of generating adequate convolutional kernels for different query images during training, which can generalize to unseen categories without fine-tuning. The proposed method shows competitive performance on Omniglot and miniImageNet."
SP:faa3f7ffdcfb6e3b8ec0421193dae3d9987b015c,"This paper proposes a population-based genetic algorithm (GA) for deep reinforcement learning (RL) problems. The authors show that the proposed algorithm, DeepGA, is able to evolve the weights of a DNN with a simple, gradient-free, population based genetic algorithm, and it performs well on hard deep RL problems, including Atari and humanoid locomotion. The DeepGA can evolve networks with over four million free parameters, the largest neural networks ever evolved with a traditional evolutionary algorithm. Additionally, the DeepGA is faster than ES, A3C, and DQN. "
SP:dfdbe3267a8160f24746884cdf5297993e424231,"This paper proposes a novel reward function for reinforcement learning based on episodic memory. The novelty bonus is based on how many steps it takes to reach the current observation from those in memory, which incorporates rich information about environment dynamics. Experiments on VizDoom, DMLab, and MuJoCo show that the proposed method outperforms ICM. "
SP:1e58a1c5344d1b5b7c8a40210a243700bd933d65,"This paper proposes a method for learning transition models in complex uncertain domains using relational rules. For any action, a rule selects a set of relevant objects and computes a distribution over properties of just those objects in the resulting state given their properties in the previous state. An iterative greedy algorithm is used to construct deictic references that determine which objects are relevant in any given state. Feed-forward neural networks are used to learn the transition distribution on the relevant objects’ properties. This strategy is demonstrated to be both more versatile and more sample efficient than learning a monolithic transition model in a simulated domain in which a robot pushes stacks of objects on a cluttered table."
SP:8ce00a3fedbf54a7f2c1ff414511cbb7d59b4597,"This paper proposes a new method for instance-wise feature selection based on the actor-critic approach. The proposed method consists of 3 neural networks, a selector network, a predictor network, and a baseline network, which are used to train the selector network. The selector network is trained using the actor critic approach. Experiments are conducted on synthetic and real data to demonstrate the effectiveness of the proposed method."
SP:b91d6c33349df0bb6cb7e1c5e9433f0d4744b4da,"This paper proposes a method to learn discriminative feature representations of patches based on label histograms in the source domain, through the construction of a disentangled space. With such representations as guidance, they then use an adversarial learning scheme to push the feature representations in target patches to the closer distributions in source ones. Extensive ablation studies and experiments are conducted on numerous benchmark datasets with various settings, such as synthetic-to-real and cross-city scenarios."
SP:00922af13a21464cbc4cd7b34c196dd4f86c9247,"This paper proposes two new algorithms for online learning based on the observation that the mini-batch of stochastic gradients in consecutive iterations do not change drastically and consequently may be predictable. Inspired by the similar setting in online learning literature, the authors propose two new optimistic algorithms for AMSGrad and Adam, respectively, by exploiting the predictability of gradients. The new algorithms combine the idea of momentum method, adaptive gradient method, and algorithms in OPTIMISTIC ONLINE LEARNING to speed up the training of deep neural nets in practice."
SP:52228b48f2776d57dd422edb33b82e247f056b75,"This paper proposes a new benchmark for image classifier robustness, IMAGENET-C, to evaluate the robustness of image classifiers to common corruptions and perturbations. The main contribution of this paper is the introduction of a new dataset IMAGenet-P, which enables researchers to benchmark a classifier’s robustness to common perturbation. Unlike previous robustness research, this benchmark evaluates performance on common corruption/perturbations and not worst-case adversarial perturbings. The authors also find that there are negligible changes in relative corruption robustness from AlexNet classifier to ResNet classifiers, and that a bypassed adversarial defense provides substantial common-perturbation robustness."
SP:20358ea0f769e6ea9222d8e35159d711ee1b20b2,"This paper shows that dropout training can be understood as performing MAP estimation concurrently for an entire family of conditional models whose objectives are lower bounded by the usual dropout objective. The family includes models that compute a power mean over the sampled dropout masks, and their less stochastic subvariants with tighter and higher lower bounds than the fully-stochastic objective. This discovery allows us to pick any model from this family after training, which leads to a substantial improvement on regularisation-heavy language modelling."
SP:ac1b950ad29429ae045bb5e53279014a6a0b9d2b,"This paper proposes a global soft filter pruning method to prune redundant filters of convolutional neural networks (CNNs). The proposed method is based on cumulative saliency based soft pruning strategy, which measures the global redundancy of the filter in the whole model by using the soft prune strategy. In addition, in the model recovery process after pruning, the authors propose to use the cumulative Saliency strategy to improve the accuracy of pruning. Experiments on MNIST and CIFAR-10 show that the proposed method achieves a much higher compression ratio compared with prior work."
SP:621e41d4199e333ec7f9d0936d4e34c918f39c11,"This paper proposes a cross-lingual document classification framework (CACO) between related language pairs. To best use limited training data, the transfer learning scheme exploits cross-language subword similarity by jointly training a character-based embedder and a word-based classifier. The embedder derives vector representations for input words from their written forms, and the classifier makes predictions based on the word vectors. CACO models trained under low-resource settings rival cross-Linguistic word embedding models trained on related language pair."
SP:544e421f9c747640d949f433e3091763508b7237,"This paper proposes a method for weakly-supervised temporal action localization. The proposed method is based on the marginalized average aggregation (MAA) module, which learns a set of latent discriminative probabilities in an end-to-end fashion. Theoretically, the authors prove that the MAA module successfully reduces the difference in responses between the most salient regions and the others. Moreover, they propose a fast algorithm to reduce the complexity of constructing MAA from O(2) to O(T). Extensive experiments on two large-scale video datasets show that the proposed method achieves a superior performance."
SP:9f98c9bac99003741dd14e093b54d692c0b0e8d8,This paper proposes a novel representation learning method based on the Holographic Reduced Representation (HRR) framework. The main idea is to use the reduced representation as a compositional representation for word-level and chunk-level representations. The proposed method is evaluated on a set of synthetic and real-world datasets.   
SP:5908b6acfed0e7c51e203c72eba907e6635e6c60,"This paper studies the problem of partially observable Markov decision processes (POMDPs) where the agent has an active role in its perception by selecting which observations to receive. Due to the combinatorial nature of such selection process, it is computationally intractable to integrate the perception decision with the planning decision. To prevent such expansion of the action space, the authors propose a greedy strategy for observation selection that aims to minimize the uncertainty in state. They develop a novel point-based value iteration algorithm that incorporates the greedy strategy to achieve near-optimal uncertainty reduction for sampled belief points. This in turn enables the solver to efficiently approximate the reachable subspace of belief simplex by essentially separating computations related to perception from planning. The proposed solver is evaluated on several robotic scenarios where the robot simultaneously performs active perception and planning."
SP:0adec4abec17b3aab0c6eb69d11925dc20544950,"This paper proposes a curriculum learning approach to address the problem of internal covariate shift in deep neural networks. The authors propose a curriculum loss that consists of two parts: an adaptive weight that mitigates large early punishment and an additional representation loss for low-weighted samples. The adaptive weight assigns small values to hard examples, reducing the influence of noisy gradients. The proposed representation loss aims to encourage their training by letting them learn a better representation from its superior neighbours."
SP:8b555b9f24044bc68c204169d6a37e262361d706,"This paper studies the problem of learning heuristics for combinatorial optimization problems. The authors propose a model based on attention layers with benefits over the Pointer Network and show how to train this model using REINFORCE with a simple baseline based on a deterministic greedy rollout, which they find is more efficient than using a value function. With the same hyperparameters, they learn strong heuristic for two variants of the Vehicle Routing Problem (VRP), the Orienteering Problem (OP) and (a stochastic variant of) the Prize Collecting TSP (PCTSP), outperforming a wide range of baselines and getting results close to highly optimized and specialized algorithms."
SP:efb76bcf1dbd9a9cf6b5db74b5d4256a9f9e9e73,This paper proposes a differentiable neural architecture search (DNAS) framework to efficiently explore its exponential search space with gradient-based optimization. Experiments on CIFAR-10 and ImageNet show the effectiveness of the proposed method. The proposed method can achieve 21.1x smaller model size or 103.9x lower computational cost.
SP:ea4173f8265bc50296de51c4ee7ecb6b8f78bec0,"This paper proposes a novel approach to model the dependence among the attention and output tokens across a predicted sequence. The proposed approach is based on a principled factorization of the joint distribution of the attention (i.e., the input and output) and output variables. The paper proposes two major changes: 1. The position where attention is marginalized is changed from the input to the output; 2. The attention propagated to the next decoding stage is a posterior attention distribution conditioned on the output. Empirical results show that the proposed approach achieves better BLEU score and alignment accuracy than existing attention models."
SP:987e2c14abc091d4d3ef9b48fb2046408eb1f59e,"This paper proposes a method to learn bi-directional image-to-image translation using a smoothness term over the sample graph to enforce consistent mappings during the translation. The proposed method, called HarmonicGAN, is based on the similarity-consistency property of samples and the self-consistent property of the samples. The authors show that the proposed method outperforms the state-of-the-art methods in a number of applications. "
SP:885a69003bad0e79cb2872a4e5c772191ad7e34f,"This paper studies the problem of exploding and vanishing gradient problem (EVGP) in recurrent neural networks. The authors propose a simple stochastic algorithm (h-detach) that is specific to LSTM optimization and targeted towards addressing this problem. Specifically, they show that when the weights are large, the gradient components through the linear path (cell state) in the computational graph get suppressed. Based on the hypothesis that these components carry information about long term dependencies (which they show empirically), their suppression can prevent LSTMs from capturing them. Their algorithm1 prevents gradients flowing through this path from getting suppressed, thus allowing the LSTm to capture such dependencies better. They show significant improvements in terms of convergence speed, robustness to seed and learning rate."
SP:9aaff3777321347d1194884af5690b0b5185eff9,"This paper studies the problem of training real binary weight networks (without layer-wise or filter-wise scaling factors) from scratch under the Bayesian deep learning perspective, meaning that the final objective is to approximate the posterior distribution of binary weights rather than reach a point estimation. The proposed method, named SnapQuant, has two intriguing features: (1) The posterior distribution is parameterized as a policy network trained with a reinforcement learning scheme. During the training phase, we generate binary weights on-the-fly since what we actually maintain is the policy network, and all the binary weights are used in a burn-after-reading style. At the testing phase, the authors can sample binary weight instances for a given recognition architecture from the learnt policy network. SnapQuant is evaluated with several visual recognition tasks including ImageNet."
SP:29d1f6d0661a51e56c59bbb106da56700fc22d9a,"This paper proposes a Bayesian nonparametric framework for federated learning with neural networks. Each data server is assumed to train local neural network weights, which are modeled through the framework. The authors then develop an inference approach that allows them to synthesize a more expressive global network without additional supervision or data pooling. They then demonstrate the efficacy of their approach on two popular image classification problems simulated from two popular datasets."
SP:ab1f2bd216635d63450688866c729a501bd7e9d0,"This paper studies the problem of learning in differentiable games with interdependent objectives. In particular, the authors propose a new algorithm called Stable Opponent Shaping (SOS) that interpolates between LOLA and a stable variant named LookAhead. They prove that SOS converges locally to equilibria and avoids strict saddles in all differentiable game. SOS inherits these essential guarantees while also shaping the learning of opponents and consistently either matching or outperforming LOLA experimentally."
SP:bdafb5fca09a775a8c92d2826d5dc977d28091c2,"This paper proposes an alarm system to set off alarms when the segmentation result is possibly unsatisfactory. The idea is to use shape feature as a strong prior information shared among different data to predict the qualities of segmentation results given different segmentation algorithms on different datasets. The shape feature is captured using the value of the loss function when the result is tested using a Variational Auto-Encoder(VAE). The VAE is trained using only the ground truth masks, therefore the bad segmentations results with bad shapes become the rare events for VAE and will result in large loss value. By utilizing this fact, the VAE can detect all kinds of shapes that are out of the distribution of normal shapes in ground truth (GT). Finally, the representation in the one-dimensional feature space is learned in the feature space to predict quality of segmentations. "
SP:60738395d9efe2b3fe3a00c542ebb4261e54386c,"This paper proposes a simple deep neural network (DNN) that can generate natural images from very few weight parameters. The DNN has a simple architecture with no convolutions and fewer weight parameters than the output dimensionality. This underparameterization enables the DNN to compress images into a concise set of network weights, which is on par with wavelet-based thresholding. Further, underparametrization provides a barrier to overfitting, allowing the network to have state-of-the-art performance for denoising."
SP:1c9bad3bd4d670172f65aa0304e9837ecafc6b3d,"This paper proposes an end-to-end neural network for program synthesis from natural language (NL) specifications to snippets of executable code. The proposed architecture relies exclusively on neural components, and is trained on abstract syntax trees, combined with a pretrained word embedding and a bi-directional multi-layer LSTM for processing of word sequences. The decoder features a doubly-recurrent LSTMs, for which the authors propose novel signal propagation schemes and soft attention mechanism. In contrast to other methods, it does not require post-processing of the resulting programs."
SP:d2ec231bb6153a303e5110e671dea14c2721e636,"This paper studies the robustness of deep neural networks against adversarial perturbations on MNIST. The authors propose a novel robust classification model that performs analysis by synthesis using learned class-conditional data distributions. They show that even the widely recognized and by far most successful L∞ defense by Madry et al. (1) has lower L0 robustness than undefended networks and is still highly susceptible to L2 perturbation, classifies unrecognizable images with high certainty, and performs not much better than simple input binarization. The results suggest that MNIST is far from being solved in terms of adversarial robustness.  The authors show that most adversarial examples are strongly perturbed towards the perceptual boundary between the original and adversarial class."
SP:91a24e7f4b952c37441feab4a7e8555014c856a4,"This paper proposes a method to control the spectra of the weight matrices of the discriminator in GANs. Specifically, the authors propose a reparameterization approach that allows us to directly manipulate spectra through various regularizers and constraints, without intensively computing singular value decompositions. Theoretical results show that the proposed method improves the generalization ability of the GAN."
SP:8115fd9b681198d62100c36794926fb57dc0a4f5,"This paper proposes an accelerated value iteration method for reinforcement learning. The proposed method is based on the Anderson acceleration technique. The main contribution of the paper is to propose a new value iteration algorithm, Anderson Accelerated Value Iteration (A2VI), which is an approximation of the policy evaluation by interpolating on historical data. A2VI is shown to be more efficient than the modified policy iteration, which is a classical approximate method for policy evaluation. The paper also proposes a deep Q-learning algorithm based on Anderson acceleration."
SP:bd79b0c0af778a36008a0c0cf2fb6393fd2789d4,"This paper proposes a novel method to solve the catastrophic forgetting problem in the class incremental learning scenario. The proposed method combines the strength of deep learning and support vector machine (SVM) to identify the support data from the old data, which are fed to the deep learning model together with the new data for further training. Two powerful consolidation regularizers are applied to stabilize the learned representation and ensure the robustness of the learned model. The experiments on various tasks show that the proposed method drastically outperforms the state-of-the-art incremental learning methods."
SP:d228d213f79716774043cea253305fecece659ec,"This paper conducts a comprehensive study of unit selectivity in AlexNet. The authors compare the performance of different measures of localist and class-conditional mean activity selectivity (CCMAS, precision, and top-class selectivity) on AlexNet and show that the most selective hidden units only respond strongly to a small minority of images from within a category. They also generate activation maximization (AM) images that maximally activated individual units and found that under (5%) of units in fc6 and conv5 produced interpretable images of objects, whereas fc8 produced over 50% images. "
SP:b9deae0392e0160b400d76c549d382e235196f8c,"This paper proposes Graph Neural Networks (GNNs) for solving community detection problems in a supervised learning setting. In particular, the authors propose to augment GNNs with the non-backtracking operator defined on the line graph of edge adjacencies. They show that, in a data-driven manner and without access to the underlying generative models, they can match or even surpass the performance of the belief propagation algorithm on binary and multiclass stochastic block models, which is believed to reach the computational threshold in these cases. In addition, they show that under certain simplifications and assumptions, the loss value at any local minimum is close to that of the global minimum."
SP:a9ed31090e55f6152fc31c7512af5d634cc7225a,"This paper studies the problem of online dictionary learning, where the data is represented as a linear combination of a few columns of a matrix known as a dictionary, and the sparse weights forming the linear combination are known as coefficients. Since the dictionary and coefficients, parameterizing the linear model are unknown, the corresponding optimization is inherently non-convex. To this end, the authors propose a simple Neurally plausible alternating Optimization-based Online Dictionary Learning algorithm, which recovers both dictionary and coefficient exactly at a geometric rate, when initialized appropriately. The proposed algorithm is also scalable and amenable for large scale distributed implementations in neural architectures."
SP:85232b72a2643d6dc81cf952ccbb95192032b7c5,"This paper proposes a new loss function and training scheme for learning binary hash codes with any differentiable model and similarity function. The proposed loss function improves over prior methods by using log likelihood loss on top of an accurate approximation for the probability that two inputs fall within a Hamming distance target. The novel training scheme obtains a good estimate of the true gradient by better sampling inputs and evaluating loss terms between all pairs of inputs in each minibatch. To fully leverage the resulting hash codes, the authors use multi-indexing. The authors demonstrate that these techniques provide large improvements to the similarity search tasks."
SP:3bd4ccff7f48380d2db8dff2c4ca515894a7f1db,"This paper proposes Graph HyperNetwork (GHN) to amortize the search cost of neural architecture search (NAS) by directly generating the weights by running inference on a graph neural network. GHN model the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, they randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast – they can search nearly 10x faster than other random search methods on CIFAR-10 and ImageNet."
SP:65ccf43cd4e033d22239069057f5200d49f33724,. This paper proposes a method to improve generative adversarial imitation learning by using additional information from non-expert demonstrations which are easier to obtain. The key idea of the method is to perform multiclass classification to learn discriminator functions where the discriminator is regarded as being drawn from an extra class. Experiments on continuous control tasks demonstrate that the proposed method learns better policies when the number of expert demonstrations is small.
SP:e8427949a98effbd37ce7604fa11f240e2342196,"This paper studies the problem of finding the posterior distribution of the inverse of the forward process of a neural network. In particular, the authors propose an approach called Invertible Neural Networks (INNs) to solve the inverse problem. The INNs are based on the notion of invertibility, which allows them to learn a model of the corresponding inverse process implicitly. The authors show that the INN provides the full posterior distribution over the parameters of the parameter space. They show that INNs can be used to find multi-modalities in parameter space, uncover parameter correlations, and identify unrecoverable parameters."
SP:75c9bb53bac29bdb390f9ba5707caee4ab1f5925," has been shown that using an ensemble of NNs trained with a proper scoring rule leads to results competitive to those of Bayesian NNs. This ensemble method can be understood as finite mixture model with uniform mixing weights. This paper builds on this mixture model approach and increase its flexibility by replacing the fixed mixing weights by an adaptive, input-dependent distribution (specifying the probability of each component) represented by an NN and by considering uncountably many mixture components. The resulting model can be seen as the continuous counterpart to mixture density networks and is therefore referred to as compound density networks. The proposed model results in better uncertainty estimates and is more robust to adversarial examples than previous approaches."
SP:e1e38289285c1b8fdb318e4f6d37a198a08787a2,"This paper studies the problem of model size reduction in deep neural networks. The authors propose to use a variational distribution over the weights instead of a deterministic one, which allows for more efficient coding schemes and consequently higher compression rates. In particular, following the classical bits-back argument, they encode the network weights using a random sample, requiring only a number of bits corresponding to the Kullback-Leibler divergence between the sampled variational distributions and the encoding distribution. The proposed method is shown to be close to the optimal information-theoretical lower bound, with respect to the employed variational family."
SP:ad70d8cf3a4558aab0d3b7155594464a3debd912,"This paper proposes ProxylessNAS, an architecture search method that directly learns the architectures for large-scale target tasks and target hardware platforms. It addresses the high memory consumption issue of differentiable NAS and reduce the computational cost (GPU hours and GPU memory) to the same level of regular training while still allowing a large candidate set. Experiments on CIFAR-10 and ImageNet demonstrate the effectiveness of directness and specialization."
SP:e5b70d43d301d1980fae02623ea711976b429c14,This paper proposes to use second-order penalties to penalize the Lagrangian of the objective function in non-convex settings. The authors argue that the second order penalty can be used to avoid the instability and potential lack of convergence associated with two-player min-max games. They also propose a method for efficiently computing the gradients associated with second order penalties in stochastic mini-batch settings. Experiments show that the proposed method performs well on a number of standard benchmarks.
SP:e4720b8e4efdb222c45eafd47fd8a7fbf15d881d,This paper presents a reweighted wake-sleep (RWS) algorithm for learning discrete latent variable models. The authors show that RWS outperforms previous state-of-the-art methods in learning discrete LV models. They also show that the RWS algorithm outperforms the current state of the art methods in terms of the number of particles in the model. 
SP:7459ae5b1d886e68930c4c9e21df508bc8ab3c9a,"This paper proposes a novel approach for structured output prediction. In particular, the authors propose to use truncated randomized search in the reward function to train structured prediction energy networks (SPENs), which provide efficient test-time inference using gradient-based search on a smooth, learned representation of the score landscape. SPENs have previously yielded state-of-the-art results in structured prediction tasks. "
SP:638c1bc09992029b78bd83f0127594dcccb96c06,"This paper proposes EffAcTS, an active learning based framework for robust policy search. The key idea is to sample a subset of the trajectories from a large batch of trajectories, and then select some subset of these trajectories to learn robust policies, such as the ones that result in the worst performance. The proposed method is evaluated on two continuous control tasks, where it outperforms EPOpt."
SP:491c239713a6489f0b1790ca26db54a1813c67ae,"This paper proposes a two-timescale network (TTN) architecture for learning nonlinear value function approximation in reinforcement learning. The main idea is to learn a linear representation of the value function with a nonlinear representation learned at a slower timescale. The authors prove convergence of the learned representation under the fast linear component and the slow linear component under potentially dependent features provided by the learned representations. The proposed method is evaluated on a variety of RL tasks, including policy evaluation and control. "
SP:327d606cf3813b00a009a7785e08ef9e11f89493,"This paper proposes a hybrid model-based and model-free approach, LEArning and Planning with Semantics (LEAPS), consisting of a multi-target sub-policy that acts on visual inputs, and a Bayesian model over semantic structures. When placed in an unseen environment, the agent plans with the semantic model to make high-level decisions, proposes the next sub-target for the sub-Policy to execute, and updates the model based on new observations. LEAPS outperforms strong baselines that do not explicitly plan using the semantic content."
SP:d7c26f43bc68d160095b1f50447528843d79edbd,". This paper proposes a multi-task perception-related basic knowledge and driving knowledge stepwisely. Specifically, segmentation map and depth map (pixel level understanding of images) are considered as what & where and how far knowledge for tackling easier drivingrelated perception problems before generating final control commands for difficult driving task. The results of experiments demonstrated the effectiveness of multitask perception knowledge for better generalization and accident explanation ability."
SP:b6bd98cc70fab97e1245cbb63a42ef89ab7e7ed5,"This paper studies the trade-off between adversarial robustness and standard generalization. The authors show that training robust models may not only be more resource-consuming, but also lead to a reduction of standard accuracy. They show that this tradeoff between the standard accuracy of a model and its robustness to adversarial perturbations provably exists even in a fairly simple and natural setting. They argue that this phenomenon is a consequence of robust classifiers learning fundamentally different feature representations than standard classifiers."
SP:9c9275d75cd95b1b82e0cbb1421e3d3ade1ce33a,"This paper proposes a method for gradient-based training of neural networks that uses only local learning rules and does not rely on neurons having a mechanism for back-propagating an error gradient. The authors propose Initialized Equilibrium Propagation, which trains a feedforward network to initialize the iterative inference procedure for Equilibrium propagation. After training, this network is used for inference. The experiments show that this network appears to work as well or better than the original version of Equilibrium propagate while requiring fewer steps to converge."
SP:ac9ea91eb465517de495477cf67bc94d5ed1b0cb,"This paper proposes a new zeroth-order stochastic optimization algorithm, ZO-signSGD, which enjoys the dual advantages of gradient-free operations and signSGD. The main contribution of this paper is to study the convergence rate of the proposed algorithm, which is shown to be O(d^d/\sqrt{T}^d) under some mild conditions, where d is the number of optimization variables and T is the total number of iterations. The authors also analyze the effects of different types of gradient estimators on the convergence of the algorithm and propose several variants of the ZO algorithm. The experiments on MNIST and CIFAR-10 demonstrate the superior performance of ZO on the generation of adversarial examples from black-box neural networks. "
SP:5f79b11777f6ef1d70c85418bfc2e4616dd7d960,". This paper proposes a new optimization method to reduce the computation efforts of convolutional neural networks. The main idea is to set a checkpoint in the multiply-accumulate (MAC) process to determine whether a filter could terminate early based on the intermediate result. Furthermore, a fine-tuning process is conducted to recover the accuracy drop due to the applied checkpoints. The experimental results show that the proposed method can save approximately 50% MAC operations with less than 1% accuracy drop for CIFAR-10 example model and Network in Network."
SP:7801e9c854ad7d960c0d24fda15597af6994c23f,"This paper studies the effect of temporal dependency in audio data to improve the robustness of ASR systems against adversarial attacks. In particular, the authors show that the temporal dependency of audio data can be exploited to gain discriminative power against audio adversarial examples and is resistant to adaptive attacks considered in the experiments. The authors also show that input transformation developed from image adversarial defense provides limited robustness improvement and is subtle to advanced attacks. "
SP:51830b811a8e39b4f0a5b7609df719e026fac6a1,This paper proposes a generative model that learns to generate images by means of composition. The key idea is to learn to identify and disentangle information corresponding to different objects at a representational level. Experiments on several multi-object image datasets demonstrate the effectiveness of the proposed method. 
SP:fb59990b8da0e95d8202383478a456667de60449,"This paper proposes a method for learning disentangled representations from a pool of unlabelled images. The goal is to learn a representation where a set of target factors are disentanglement from others. The only supervision comes from an auxiliary “reference set” that contains images where the factors of interest are constant. In order to address this problem, the authors propose reference-based variational autoencoders, a novel deep generative model designed to exploit the weak supervisory signal provided by the reference set. During training, they use the variational inference framework where adversarial learning is used to minimize the objective function."
SP:dbc1983d9b9d72aa14f8e8515d793d2bbde26c9c,"This paper proposes a method for continual online learning from an incoming stream of data, using deep neural network models. The proposed method uses stochastic gradient descent to update model parameters, and an expectation maximization algorithm with a Chinese restaurant process prior to develop and maintain a mixture of models to handle non-stationary task distributions. This allows for all models to be adapted as necessary, with new models instantiated for task changes and old models recalled when previously seen tasks are encountered again. Furthermore, the authors observe that meta-learning can be used to meta-train a model such that this direct online adaptation with SGD is effective, which is otherwise not the case for large function approximators. In this work, the proposed method is applied to model-based reinforcement learning, where adapting the predictive model is critical for control."
SP:5665e5f006f84927beb0440e145f476e02538077,This paper studies the problem of training an RL agent in a distributed RL setting. The authors propose to train the agent using a distributed prioritized experience replay approach. They show that this approach can improve the performance of the agent on Atari games. They propose to use a single network architecture and a fixed set of hyperparameters and show that it can achieve state-of-the-art performance on Atari.
SP:47ace37f31a46d5ee85c283e62ddb71a12f2c5c4,"This paper studies the problem of training sequential generative models for capturing coordinated multi-agent trajectory behavior, such as offensive basketball gameplay. The authors propose a hierarchical framework that can capture long-term coordination using intermediate variables in an interpretable and manipulatable way. The approach is inspired by recent work on leveraging programmatically produced weak labels, which they extend to the spatiotemporal regime. In addition to synthetic settings, the authors show how to instantiate their framework to effectively model complex interactions between basketball players and generate realistic trajectories of basketball gameplay over long time periods."
SP:1a90cdf028068528b0559e7d44bf26dda20310bd,"This paper presents a method for learning to integrate temporal information, from a learned dynamics model, with ambiguous visual information, with a learned vision model, in the context of interacting agents. The method is based on a graph-structured variational recurrent neural network (Graph-VRNN), which is trained end-to-end to infer the current state of the (partially observed) world, as well as to forecast future states. The authors show that their method outperforms various baselines on two sports datasets."
SP:8392f04b7265f665ba6d44d297bca245d44b4708,"This paper proposes a method for end-to-end training of a base neural network that integrates calls to existing black-box functions. The main idea is to use a differentiable neural network to approximate the black box function interface during the training process, and then replace the differentiable estimator with its external black box non-differentiable counterpart such that the base network output matches the input arguments of the blackbox function. The authors show that by leveraging the existing precise black- box function during inference, the integrated model generalizes better than a fully differentiable model, and learns more efficiently compared to RL-based methods."
SP:13fb86de763a0b34ac6fa34ea9dfbd1c476ce43e,This paper proposes a meta-learning algorithm that combines hierarchical Bayesian models over the parameters of an arbitrary function approximator such as a neural network. The authors propose a stochastic expectation maximization procedure to jointly estimate parameter initializations for gradient descent as well as a latent assignment of tasks to initializations. This approach better captures the diversity of training tasks as opposed to consolidating inductive biases into a single set of hyperparameters. The experiments demonstrate better generalization performance on the standard miniImageNet benchmark for 1-shot classification.
SP:a410144dbe19713a06c63da87d9fb58b999a7492,"This paper proposes a meta-augmentation method for image classification, where the auxiliary task is hierarchical sub-class image classification. The proposed method is self-supervised and general, and therefore offers a promising new direction towards automated generalisation. Experiments on three different CIFAR datasets show that MAXL outperforms baseline auxiliary learning methods, and is competitive even with human-defined sub-classes hierarchies."
SP:76248e1c914c60ce69de244fe7ec62488d01e161,"This paper presents a neural network based representation for open set recognition. In this representation instances from the same class are close to each other while instances from different classes are further apart, resulting in statistically significant improvement when compared to other approaches on three datasets from two different domains. "
SP:d4ee856bbf2dfb6390e5247086fec2e52dcb6858,"This paper studies the problem of learning low-precision networks for image classification. The authors show that the number of iterations required by stochastic gradient descent to achieve a given training error is related to the square of (a) the distance of the initial solution from the final plus (b) the maximum variance of the gradient estimates. They find that gradient noise due to quantization during training increases with reduced precision, and seek ways to overcome this noise. They propose to reduce solution distance by starting with pretrained fp32 precision baseline networks and fine-tuning, and to combat noise introduced by quantizing weights and activations during training, by using larger batches along with matched learning rate annealing."
SP:6bfdc37b346e6ddfa049e0414647f4beda8ede3f,"This paper proposes a method to learn to predict post-bounce trajectories and to infer the physical properties governing bouncing restitution and effective collision normals. To this end, the authors propose an end-to-end approach to learn the physics and visual properties of the scene. The authors propose a new dataset of 5K RGB-D videos of bouncing trajectories of a foam ball to probe surfaces of varying shapes and materials in everyday scenes including homes and offices. The proposed model learns from the collected dataset of real-world bounces and is bootstrapped with additional information from simple physics simulations."
SP:010bd055310c363d3cb0fbe0e11546de58220e15,"This paper studies the adversarial vulnerability of deep neural networks in the presence of adversarial perturbations. The authors show that the gradients of the training objective increases with the size of the input image. They prove that the `1-norm of these gradients grows as the square root of the image size, and that the network becomes increasingly vulnerable with growing image size. The proof relies on the network's weight distribution at initialization."
SP:5fa3ae057e55be6b71cc94a7dbfe31e54e1c536f,"This paper proposes an interactive agent modeling scheme by encouraging an agent to learn to probe. In particular, the probing agent learns to interact with the environment and with a target agent (i.e., a demonstrator) to maximize the change in the observed behaviors of that agent. Through probing, rich behaviors can be observed and are used for enhancing the agent modeling to learn a more accurate mind model of the target agent. The proposed approach consists of two learning processes: i) imitation learning for an approximated agent model and ii) pure curiosity-driven reinforcement learning to discover new behaviors that otherwise can not be observed. The experimental results show that the agent model learned by the proposed approach generalizes better in novel scenarios than the ones learned by passive observation, random probing, and other curiositydriven approaches do, and can be used to enhance performance in multiple applications including distilling optimal planning to a policy net, collaboration, and competition."
SP:3af184a5529d6ec2a0862efd1af80ef5b50d2952,. This paper proposes a modification to the neural network architecture that mimics the function of biological neuromodulators in order to enable the network to adjust its activation sensitivities in run-time based on their input patterns. This modification produces statistically significant improvements in the context of Convolutional Neural Networks and Long Short-Term Memory networks. 
SP:287a577834fd2820a939a1113b39146a22727491,"This paper proposes a neural analysis and synthesis (NANSY) framework that can manipulate voice, pitch, and speed of an arbitrary speech signal. NANSY does not require any labels associated with speech data such as text and speaker information, but rather uses a new set of analysis features, i.e., wav2vec feature and newly proposed pitch feature, Yingram, which allows for fully self-supervised training. Experiments on zero-shot voice conversion, pitch shift, and time-scale modification show the effectiveness of the proposed method."
SP:90f35ad1ec0c38b0817f5678ee2a5c4f0e08fb38,This paper studies the generalization properties of bilevel programming (BVP) in the context of hyperparameter optimization. The main contribution of the paper is to provide an expectation bound w.r.t. the validation set based on uniform stability. The paper also provides a bound for the classical cross-validation algorithm and shows that gradient-based algorithms can be better than cross validation under certain conditions. 
SP:42f52aec3a776d87daa5fd72b8e6325d12c88d63,"This paper proposes a novel knowledge distillation approach to facilitate the transfer of dark knowledge from a teacher to a student. The main idea is to learn the teacher models that are friendly to students and, consequently, more appropriate for knowledge transfer. The proposed algorithm learns the student branches jointly to obtain student-friendly representations. Experiments show that the proposed method outperforms the existing methods in terms of accuracy and convergence speed."
SP:e15a1c21229233fd97dc1dfa0a4ef48b69dc9f95,"This paper studies the problem of generalization to out-of-distribution (OOD) data. The main contribution of the paper is to provide a quantitative definition of what is OOD and what does it mean by saying an OOD problem is learnable. The authors also introduce a new concept of expansion function, which characterizes to what extent the variance is amplified in the test domains over the training domains, and therefore give a quantitative meaning of invariant features. Based on these, the authors prove OOD generalization error bounds and show that any OOD learning algorithm without a model selection module is incomplete. Extensive experiments on benchmark OOD datasets demonstrate that the proposed method has a significant advantage over baselines."
SP:37b04b9068d39bcf0a581eb8181d13cf1a8926bf,"This paper proposes a Variational Continual Bayesian Meta-Learning (VC-BML) algorithm for the online meta-learning setting, where tasks arrive sequentially and follow a non-stationary distribution. The proposed algorithm maintains a Dynamic Gaussian Mixture Model for meta-parameters, with the number of component distributions determined by a Chinese Restaurant Process (CPR). The authors propose a more robust posterior approximation method – structured variational inference for the sake of avoiding forgetting knowledge. Experiments show that the proposed algorithm is superior in transferring knowledge among diverse tasks and alleviating catastrophic forgetting in an online setting."
SP:776d5b02b8d3a8bbcc1f52706f3887c384cb149e,"This paper proposes a probabilistic method for solving ODE boundary value problems (BVPs), which are ODEs subject to left and right-hand side boundary conditions Ly(t0) = y0 and Ry(tmax) =  ymax. The authors propose a Gauss–Markov prior for BVPs, which allows computing a posterior distribution over the solution in linear time, at a quality and cost comparable to that of well-established, non-probabilistic methods. The proposed method further delivers uncertainty quantification, mesh refinement, and hyperparameter adaptation. "
SP:86aac0c6b75fdc12f84bba342934865616f866d4,"This paper studies the problem of learning a near-optimal policy in a reward-mixing Markov decision process (MDP) where the reward function is drawn from one of multiple possible reward models at the beginning of every episode, but the identity of the chosen reward model is not revealed to the agent. The authors provide a polynomial-time algorithm that finds an optimal policy after exploring $O(poly(H, S, A)$ episodes, where $H$ is the time horizon and $S, A$ are the number of states and actions respectively. This is the first efficient algorithm that does not require any assumptions in partially observed environments where the observation space is smaller than the latent state space."
SP:1a3c70ae9cf2a806d603f4b9e7ca6e10b720a956,This paper proposes a novel method to estimate the multi-cause treatment effect. The proposed method is based on augmenting the observational dataset with the estimated potential outcomes under single-cause interventions. It then performs covariate adjustment on the augmented dataset to obtain the estimator. The method is agnostic to the exact choice of algorithm in either step. The experimental results show the effectiveness of the proposed method.
SP:247bc6675cce89d51558537daf63dadb0c4307f8,"This paper proposes a multi-wavelet-based neural operator learning method for solving partial differential equations. The proposed method compresses the associated operator’s kernel using fine-grained wavelets. By explicitly embedding the inverse multiwavelet filters, the proposed method learns the projection of the kernel onto fixed multi wavelet polynomial bases. This allows learning the complex dependencies at various scales and results in a resolution-independent scheme. Experiments on the Korteweg-de Vries (KdV) equation, Burgers’ equation, Darcy Flow, and Navier-Stokes equation show the effectiveness of the proposed approach."
SP:1153785e6a016cfee2644952a772aa08927299b6,". This paper proposes to use the combination of sine functions to estimate the gradient of sign function in the Fourier frequency domain for training BNNs. The proposed approach does not affect the low-frequency information of the original sign function which occupies most of the overall energy, and high-frequency coefficients will be ignored to avoid the huge computational overhead. The experiments on several benchmark datasets and neural architectures illustrate that the binary network learned using the proposed method achieves the state-of-the-art accuracy."
SP:33b95ea8da4d30b8e8f9d3fe3acca023d4b8d831,This paper proposes to use multi-area RNNs with neuroscience-inspired architecture constraints to derive key features of multi- area computation. The authors show that incorporating multiple areas and Dale’s Law is critical for biasing the networks to learn biologically plausible solutions. They also show that output-relevant information is preferentially propagated between areas. These results suggest that cortex uses modular computation to generate minimal sufficient representations of task information.
SP:db3ced65d67e3373fb3936ec50f41c8ef010bbbe,This paper proposes structured attention graphs (SAGs) to represent sets of attention maps for an image by visualizing how different combinations of image regions impact the confidence of a classifier. An approach to computing a compact and representative SAG for visualization is proposed via diverse sampling. The authors conduct a user study comparing the use of SAGs to traditional saliency maps for answering counterfactual questions about image classifications. The results show that user accuracy is increased significantly when presented with SAG.
SP:f2b385bfd9ada0e26aa8829214b424f58582d9f7,"This paper studies how the choice of training objective affects the transferability of the hidden representations of convolutional neural networks trained on ImageNet. The authors show that many objectives lead to statistically significant improvements in ImageNet accuracy over vanilla softmax cross-entropy, but the resulting fixed feature extractors transfer substantially worse to downstream tasks. They find that differences among loss functions are apparent only in the last few layers of the network. They delve deeper into representations of the penultimate layer, finding that different objectives and hyperparameter combinations lead to dramatically different levels of class separation. The results suggest there exists a trade-off between learning invariant features for the original task and features relevant for transfer tasks."
SP:b66b5e24f68563e2e200eda660f0dbaff53efeff,"This paper proposes a method to learn a deep generative model of latent dynamics from data in which the set of observed variables changes at each time step. The proposed method is called selective backpropagation through time (SBTT) and it is based on the idea of learning a latent dynamics model that can be used to infer missing samples by combining observations with learned latent dynamics. The method is applied to sequential autoencoders and electrophysiological and calcium imaging data. It is shown that SBTT can achieve high-fidelity characterization of neural population dynamics with lower interface bandwidths. The authors also show that it can be further improved by using limited, highbandwidth sampling to pretrain dynamics models and then using SBTT to adapt these models for sparsely-sampled data."
SP:3513a83806e71006b86d60b779d8bd6bb87c3546,"This paper proposes a hierarchical approach to sequence-to-sequence learning with quasi-synchronous grammars where each node in target tree is transduced by a node in the source tree. Both the source and target trees are treated as latent and induced during training. The authors develop a neural parameterization of the grammar which enables parameter sharing over the combinatorial space of derivation rules without the need for manual feature engineering. They apply this latent neural grammar to various domains -- a diagnostic language navigation task designed to test for compositional generalization (SCAN), style transfer, and small-scale machine translation. "
SP:d06fc251f2a9287f7a2236a188349628d8f39d9a,"This paper proposes a new algorithm to solve Group Elastic Net for function-on-scalar feature selection, where a functional response is modeled against a very large number of potential scalar predictors. The proposed algorithm exploits the sparsity structure of the Augmented Lagrangian to greatly reduce computational burden. The paper also extends the proposed algorithm to the function on-scalear regression framework. Experiments are conducted on the Genome Wide Association Study on childhood obesity. "
SP:e0b53f76f3a6b756fedd09926f9cf034f89f4a5a,"This paper proposes a novel mixture model of multi-level marked point processes for identifying potential heterogeneity in the observed data. Specifically, the authors study a matrix whose entries are marked log-Gaussian Cox processes and cluster rows of such a matrix. An efficient semi-parametric Expectation-Solution (ES) algorithm combined with functional principal component analysis (FPCA) of point processes is proposed for model estimation. The effectiveness of the proposed framework is demonstrated through simulation studies and real data analyses."
SP:3aa213076f3e9f9838ac654517df2fe1fca33499,This paper proposes an online multi-task learning approach for adaptive nonlinear control. The key idea is to learn a shared representation of the dynamics of the system under the assumption that the dynamics can be well captured with some shared representation. The authors provide the first non-asymptotic end-to-end convergence guarantee for the proposed method. The proposed method is evaluated on inverted pendulum and 6-DoF drone control tasks.
SP:cb274c93a169b199ea09120ca02105a3f16b31c5,"This paper proposes a method for training neural networks with certifiable robustness guarantees. The main contribution of this paper is to improve the training schedule of interval bound propagation (IBP) based certified robust training methods. The authors identify two important issues in existing methods, namely exploded bounds at initialization, and the imbalance in ReLU activation states and improve IBP training. To mitigate these issues and conduct faster certified training with shorter warmup, the authors derive a new weight initialization method and propose to fully add Batch Normalization (BN) to each layer in the model, since they find BN can reduce the imbalance of ReLU activations. They also design regularization to explicitly tighten certified bounds and balance the activation states during wamrup. "
SP:18ffeb199a670fb2b1f4417b8653479001944dab,"This paper studies the problem of change point detection in the presence of adversarial perturbations. In particular, the authors propose to use the Huber-contamination framework, which allows the contamination distributions to be different at each time point. The authors show that the detection boundary is a function of the contamination proportion, and derive the minimax-rate optimal localisation error rate, quantifying the cost of accuracy in terms of contamination proportion. They also propose a computationally-feasible method, matching the lower bound under certain conditions, saving for logarithmic factors."
SP:d03617b5fc446768809cf015c9234b0c9386a690,"This paper studies the power of mini-batch stochastic gradient descent (SGD) and batch Gradient Descent (GD) on the empirical loss of a differentiable model or neural network. It shows that SGD and GD can always simulate learning with statistical queries (SQ), but their ability to go beyond that depends on the precision ρ of the gradient calculations relative to the minibatch size b (for SGD), and sample size m (for GD). With fine enough precision, namely when bρ is small enough, SGD can go beyond SQ learning and simulate any sample-based learning algorithm and thus its learning power is equivalent to that of PAC learning; this extends prior work that achieved this result for b = 1. In particular, with polynomially many bits of precision (i.e., when ρ is exponentially small), SGD or GD can both simulate PAC learning regardless of the mini batch size."
SP:1de2864fe2f53e25596a9bd2c61e2048e79296f6,"This paper studies the problem of generating a distribution over a set of N points that minimizes the Wasserstein distance to the distribution of the model distribution. This problem is non-convex in the sense that the unknowns are the positions of the atoms in the distribution. The authors show that a variant of Lloyd’s algorithm (in which Voronoi cells are replaced by Power cells) leads to configurations with small WSW error. This is surprising because, again, of the non convex nature of the problem, as well as the existence of spurious critical points, the authors provide explicit estimates for the convergence of this Lloyd-type algorithm, starting from a cloud of points that are sufficiently far from each other. "
SP:c3d364aeee55230a436c3ce4e8dc8310ee73959e,This paper proposes a dynamic self-attention method for video recognition. The proposed method leverages spatio-temporal relations in videos by dynamically generating relational kernels and aggregating relational contexts. Experiments show that the proposed method outperforms the state-of-the-art on the standard motion-centric benchmarks for video action recognition. 
SP:2c2530069d5cab485629090243da464d107feadd,"This paper studies the second-order mean field limit of multilayer neural networks. The authors derive a system of dynamical equations that captures the limiting fluctuation distribution. They demonstrate through the framework the complex interaction among neurons in this second order limit, the stochasticity with cross-layer dependency and the nonlinear time evolution inherent in the limiting fluctuations. A limit theorem is proven to relate quantitatively this limit to the fluctuation realized by large-width networks. "
SP:a3d927854d9d7fd39b8d05a79666810d585d5062,"This paper proposes a method to learn a dissipative bracket from metriplectic dynamical systems for learning irreversible dynamics with unknown a priori model form. The proposed method learns generalized Casimirs for energy and entropy guaranteed to be conserved and nondecreasing, respectively. The authors provide benchmarks for dissipative systems demonstrating learned dynamics are more robust and generalize better than either ""black-box"" or penalty-based approaches."
SP:32e8e83e06b1e9a4dad761334d5947c91bfd1853,"This paper proposes a sample selection-based algorithm for fair and robust training. The authors formulate a combinatorial optimization problem for the unbiased selection of samples in the presence of data corruption. They propose a greedy algorithm that is efficient and effective in practice. Experiments show that their algorithm obtains fairness and robustness that are better than or comparable to the state-of-the-art technique, both on synthetic and real datasets."
SP:991127729bf067fe27fdd7ed360aab39e4df5921,"This paper proposes periodic activation functions in Bayesian neural networks to establish a connection between the prior on the network weights and translation-invariant, stationary Gaussian process priors. The authors also show that this link goes beyond sinusoidal (Fourier) activations by also covering triangular wave and periodic ReLU activation functions. In a series of experiments, the authors show that periodic activation function obtain comparable performance for in-domain data and capture sensitivity to perturbed inputs in deep neural networks for out-of-domain detection."
SP:d61a2aecfea4612c473b4e6fd41f3dc2fcbb04a1,"This paper proposes to use an autoregressive model to learn to classify Markov Decision Processes (MDPs) for interactive code assignments. The agent is given a set of MDPs and the goal is to decide if the MDP should be classified as correct or broken. To this end, the authors propose to use the agent to sample differential trajectories from the input MDP that allows a classifier to determine membership: Play to Grade. The proposed method is evaluated on a dataset of 711,274 student submissions to a single assignment with hand-coded bug labels."
SP:daf99ad91613d6e11b13315ccbd1bbe25094ae4b,"This paper proposes a novel approach to interpret deep reinforcement learning (DRL) models. The key idea is to use a disentangled latent representation to capture the independent factors of variation for the objects and a mimic tree to extract the causal impact of the latent features on DRL action values. To jointly optimize both the fidelity and the simplicity of the mimic tree, the authors derive a novel Minimum Description Length (MDL) objective based on the Information Bottleneck (IB) principle. They also propose a Monte Carlo Regression Tree Search (MCRTS) algorithm that explores different splits to find the IB-optimal mimic tree. Experiments show that the proposed approach achieves strong approximation performance with significantly fewer nodes than baseline models."
SP:84560de78af979354fff83d1370d8675c1e9191f,"This paper proposes a Bayesian approach to model the structure of dynamic predictions over time. In particular, the authors propose to model predictions as a latent process of information flow, which is inferred from historical data. This approach preserves important properties of probability paths such as the martingale structure and appropriate amount of volatility and better quantifies future uncertainties around probability paths. The authors show that GLIM outperforms three popular baseline methods, producing better estimated posterior probability path distributions measured by three different metrics."
SP:0c4bfb44e0a353256692d5e5ae96f65c1a14363d,"This paper studies the problem of active pure exploration with fixed confidence in stochastic bandit environments. The goal of the learner is to answer a query about the environment with a given level of certainty while minimizing her sampling budget. For this problem, instance-specific lower bounds on the expected sample complexity reveal the optimal proportions of arm draws an Oracle algorithm would apply. The authors propose Frank-Wolfe-based Sampling (FWS), a simple algorithm whose sample complexity matches the lower bounds for a wide class of pure exploration problems. They apply FWS to various pure exploration tasks, including best arm identification in unstructured, thresholded, linear, and Lipschitz bandits. FWS is competitive compared to state-of-the-art algorithms."
SP:0947a0f08fba53d3c8af9b78dd64e6e10fc73e32,"This paper proposes a new approach for Bayesian optimization of combinatorial spaces using black-box function evaluations. The key idea is to define a novel structure-coupled kernel that explicitly integrates the structural information from decoded structures with the learned latent space representation for better surrogate modeling. The experiments on real-world benchmarks show that LADDER significantly improves over the BO over latent space method, and performs better or similar to state-of-the-art methods."
SP:37adabdc6615c5199a481553c8ccc06d57363614,"This paper studies the role of the representation of state-action value functions in regret minimization in finite-horizon Markov Decision Processes (MDPs) with linear structure. The authors first derive a necessary condition on the representation, called universally spanning optimal features (UNISOFT), to achieve constant regret in any MDP with linear reward function. This result encompasses the well-known settings of low-rank MDPs and, more generally, zero inherent Bellman error (also known as the Bellman closure assumption). They then demonstrate that this condition is also sufficient for these classes of problems by deriving a constant regret bound for two optimistic algorithms (LSVI-UCB and ELEANOR). Finally, they propose an algorithm for representation selection and prove that it achieves constant regret when one of the given representations, or a suitable combination of them, satisfies the UNISOFT condition."
SP:92566b664ab2f6ee9b73f29327aeef85d14ecf60,"This paper proposes a differentiable contact model that can capture contact mechanics: frictionless/frictional, as well as elastic/inelastic. This model can also accommodate inequality constraints, such as limits on the joint angles. The proposed model extends the scope of Lagrangian and Hamiltonian neural networks by allowing simultaneous learning of contact and system properties. Experiments are conducted on a series of challenging 2D and 3D physical systems with different coefficients of restitution and friction. The learned dynamics can be used as a differentiability physics simulator for downstream gradient-based optimization tasks."
SP:82d59a3609dfd458f90f23d4e477c8b497e9dc18,"This paper studies the Benevolent training hypothesis (BTH) which claims that the complexity of a neural network can be deduced by its training dynamics. The authors show that the Lipschitz constant close to the training data affects various aspects of the parameter trajectory, with more complex networks having a longer trajectory, bigger variance, and often veering further from their initialization. They also show that NNs whose 1st layer bias is trained more steadily (i.e., slowly and with little variation) have bounded complexity even in regions of the input space that are far from any training point. Finally, they show that steady training with Dropout implies a training and datadependent generalization bound that grows poly-logarithmically with the number of parameters."
SP:9b329c915fa8d4045c167c9df37a49ee314d190e,"This paper studies the problem of distribution-independent PAC learning of halfspaces in the Massart noise model with strongly polynomial sample complexity, i.e., independent of the bit complexity of the examples. The authors show that any distribution can be efficiently decomposed as a disjoint mixture of few distributions for which a Forster transform exists and can be computed efficiently. The main application of this result is to obtain the first polynomially-time algorithm for distribution independent PAC learning."
SP:e5229305af00067ae2dbabd903e585964aec8928,"This paper proposes a Bayesian optimisation-based adversarial attack method for graph classification models. The proposed method is black-box, query-efficient and parsimonious with respect to the perturbation applied. The authors empirically validate the effectiveness and flexibility of the proposed method on a wide range of graph classification tasks involving varying graph properties, constraints and modes of attack. "
SP:4999e5664383066fdacd14be6242c7b83f85f3dd,"This paper studies the problem of online label shift adaptation in the online setting, where the test-time label distribution is continually changing and the model must dynamically adapt to it without observing the true label. In this setting, the authors show that the lack of true label does not hinder estimation of the expected test loss, which enables the reduction of online labels shift adaptation to conventional online learning. Informed by this observation, they propose adaptation algorithms inspired by classical online learning techniques such as Follow The Leader (FTL) and Online Gradient Descent (OGD) and derive their regret bounds. They empirically verify their findings under both simulated and real world label distribution shifts and show that OGD is particularly effective and robust to label shift scenarios."
SP:806515ae07fb1c9d02773592005d53d4158ef102,"This paper proposes a method for detecting and localizing gradual changes in the distribution of a sequence of time-ordered observations. The main contribution of this paper is to propose a general method that does not require a specific data generating model, a particular data type, or prior knowledge about which features of the distribution are subject to change. The proposed method possesses proven theoretical guarantees for both detection and localization."
SP:7a3c8a7b17ecab19361d36e1d3d73fa35b71214c,"This paper proposes a novel algorithm for blind source separation (BSS) based on ICA neural networks. The authors propose a novel objective function for ICA from which they derive a biologically plausible NN, including both the neural architecture and the synaptic learning rules. The proposed algorithm relies on modulating synaptic plasticity by the total activity of the output neurons. "
SP:22f8b517a3df65144412938f5891c463d7bae0ab,"This paper studies the structure of the space of solutions associated with various tasks. The authors first study a simple two-neuron network on a task that leads to multiple solutions. They trace the nature of the final solution back to the network’s initial connectivity and identify discrete dynamical regimes that underlie this diversity. They then examine three neuroscience-inspired tasks: Delayed discrimination, Interval discrimination, and Time Reproduction. For each task, they find a rich set of solutions. One layer of variability can be found directly in the neural activity of the networks. An additional layer is uncovered by testing the trained networks’ ability to extrapolate, as a perturbation to a system often reveals hidden structure. Furthermore, the authors introduce a tool to derive the reduced dynamics of networks by generating a compact directed graph describing the essence of the dynamics with regards to behavioral inputs and outputs."
SP:9b08a0f547ead3b59077a43b1052c6d46a0730f6,This paper proposes a new method for arbitrary conditional density estimation. The main idea is to learn a conditional density estimator that can simultaneously estimate the distribution p(xu | xo) for all possible subsets of unobserved features xu and observed features xo. The proposed method is based on the one-dimensional conditional conditionals. The authors show that the proposed method achieves state-of-the-art performance on a number of benchmarks.
SP:f2b14f5854e6aa6922795d1d2051b7402486cef6," in single image super-resolution (SISR). This paper proposes a new adaptive weighted loss for SISR to train deep networks focusing on challenging situations such as textured and edge pixels with high uncertainty. Specifically, the paper introduces variance estimation characterizing the uncertainty on a pixel-by-pixel basis into SIsR solutions so the targeted pixels in a high-resolution image (mean) and their corresponding uncertainty (variance) can be learned simultaneously. The paper shows that such uncertainty-driven loss can achieve better results than MSE or L1 loss for a wide range of network architectures."
SP:9997583f40fa648adf57bb4fc34228f357be0cf1,"This paper proposes a generalization bound for PAC-Bayesian generalization bounds for adversarial robustness. The main contribution of the paper is to provide a general bound for the risk of a hypothesis over all the possible perturbations. The authors propose to use the PACBayesian framework to bound the averaged risk on the perturbation for majority votes (over the whole class of hypotheses). The authors show that the bound is generalizable to any kind of attacks (i.e., the adversarial attacks) and that it is tight."
SP:90b72e8dc41584e38f25dff9fb2853f5b11dc8fa,"This paper proposes a probabilistic entity representation model (PERM) to encode entities as a multivariate Gaussian density with mean and covariance parameters to capture its semantic position and smooth decision boundary, respectively. The authors also define the closed logical operations of projection, intersection, and union that can be aggregated using an end-to-end objective function. The proposed PERM significantly outperforms the state-of-the-art methods on various public benchmark KG datasets on standard evaluation metrics. "
SP:b6184c9732dbb7eba7c20cae8869d975c428efe4,"This paper proposes a new algorithm for gradient-based hyperparameter optimization for few-shot meta-learning. The proposed algorithm is based on forward-mode differentiation with sharing (FDS), which tackles memory scaling issues and gradient degradation issues by sharing hyperparameters that are contiguous in time. The authors provide theoretical guarantees about the noise reduction properties of their algorithm, and demonstrate its efficiency empirically by differentiating through 10 gradient steps of unrolled optimization. "
SP:9c3a326e5ee4e862923d3bf9415f32a077db8534,This paper proposes a method to improve the performance of neural sequence models by adding logical reasoning to them. The authors propose to use a symbolic reasoning module to decide whether to accept or reject a generation from a neural sequence model. The proposed method is based on the idea that human reasoning is an interplay between two systems: the intuitive and associative (System 1) and the deliberative and logical (System 2) systems. The paper proposes to use neural inference to mediate between the neural System 1 and the logical System 2. Experiments are conducted on story generation and grounded instruction-following.
SP:d77d046095e4c8336c0c76ac48cb046923230753,"This paper studies the problem of off-policy evaluation (OPE) in continuous treatment settings. In OPE, one aims to estimate the mean outcome under a new treatment decision rule using historical data generated by a different decision rule. To handle continuous treatments, the authors develop a novel estimation method for OPE using deep jump learning. The key ingredient of their method lies in adaptively discretizing the treatment space using deep discretization, by leveraging deep learning and multiscale change point detection. The method is further justified by theoretical results, simulations, and a real application to Warfarin Dosing."
SP:4d085e57286fdd36143108a002d16914222c239a,"This paper proposes a continuous-time variational inference algorithm for Markov jump processes. The authors propose to use a Gaussian process approximation on the diffusion level with posterior inference for the Markov Jump Process. By minimizing the path-wise Kullback-Leibler divergence they obtain Bayesian latent state estimates for arbitrary points on the real axis and point estimates of unknown system parameters, utilizing variational expectation maximization."
SP:d1f396e691f9d331adfb7b694a99c50e8004331f,"This paper studies the effect of the spikiness of the spectrum of sensing matrices on the performance of the expectation propagation algorithm (EP) in the context of nonlinear inverse problems. In particular, the authors propose a notion for the spiky spectrum of A and show the importance of this measure in the performance for EP. They show that spikier spectrums are better for EP, while in 1-bit compressed sensing problems, less spiky (flatter) spectrums offer better recoveries. "
SP:ee66604d4da9fd04826e90ccbb94f0499eba4c63,"This paper proposes Dual Progressive Prototype Network (DPPN) to address the problem of cross-domain transferability and category discriminability in Generalized Zero-Shot Learning (GZSL). In particular, DPPN constructs two types of prototypes that record prototypical visual patterns for attributes and categories, respectively. With attribute prototypes, the network alternately searches attribute-related local regions and updates corresponding attribute prototypes to progressively explore accurate attribute-region correspondence. With category prototypes, it further projects category prototypes into multiple spaces to progressively repel visual representations from different categories. Experiments on four benchmarks demonstrate the effectiveness of the proposed method."
SP:61eb6297568c3f6869fbb03eaf6a21260de5466c,"-based approach is proposed to remove the defocus blur from a single image. The authors propose a pixel-wise Gaussian kernel mixture (GKM) model to represent spatially variant blur kernels in an efficient linear parametric form, with higher accuracy than existing models. Then, a deep neural network is developed by unrolling a fixed-point iteration of the GKM-based deblurring. Extensive experiments show that the proposed method outperforms existing defocus-blur methods."
SP:18bf447c90935c373e5ec4cdfbbf8f2a273d2edb,This paper proposes a cross guidance contrastive learning approach for self-supervised video representation learning (SSVRL). The authors propose to use RGB frames and motion vectors from compressed videos on-the-fly to capture mutual information between the two input streams. The proposed method is evaluated on two downstream tasks and achieves state-of-the art performance.
SP:8c7b1d976d9758cd534c565ec31a23f97892e503,"This paper studies the problem of asymptotic overconfidence of ReLU Bayesian neural networks (BNNs) with infinite ReLU features. The authors show that the output variance of a BNN with finitely many features is quadratic in the distance from the data region. Meanwhile, Bayesian linear models converge, in the infinite-width limit, to a particular Gaussian process (GP) with a variance that grows cubically so that no overconfidence can occur. This paper extends finite ReLU BNNs with infinite reLU features via the GP and shows that the resulting model is maximally uncertain far away from the training data while the BNN’s predictive power is unaffected near the data."
SP:e77276f61626e896f6a985296f1d832129242cdf,"This paper studies the problem of finding the best-arm-identification bandit algorithm in a sequential setting where the goal is to find the best estimate of the asymptotic variance in as few samples as possible. The main contribution of the paper is to provide a finite-sample confidence bounds for estimating the variance of the best arm in the bandit setting. The bounds are based on the LUCB algorithm, and the authors show that they can be used in combination with the SOTA algorithm. The authors also provide an empirical study on artificially generated data to validate their results."
SP:471361588bfc6c6033631509d1e43e77fd9721ce,"This paper studies the problem of variance reduction in stochastic gradient descent, where the variance of the gradient is reduced by taking a moving average over all history gradients. The paper shows that adding back the previous step’s compression error does not fully compensate the compression error. The authors propose ErrorCompensatedX, which uses the compression errors from the previous two steps to achieve the same asymptotic convergence rate with the training without compression. They also provide a unified theoretical analysis framework for this class of variance reduced algorithms, with or without error compensation."
SP:3b7ff0dc668cac2191d95fcc4dc6e0335dec3206,This paper proposes a method to generate multi-grained explanations for graph neural networks (GNNs) by pre-training and fine-tuning. The main idea is to pre-train GNNs in a global way and then fine-tune them in a local way. The method is evaluated on both synthetic and real-world datasets. 
SP:9b5a62d3a2b27bc60da28980e9fb0ecdff1215c0,"This paper proposes a novel method to generate robust counterfactual explanations on GNNs by explicitly modelling the common decision logic of GNN on similar input graphs. The explanations are naturally robust to noise because they are produced from common decision boundaries of a GNN that govern the predictions of many similar input graph. Moreover, the explanations are also counterfactually robust because removing the set of edges identified by an explanation from the input graph changes the prediction significantly. Exhaustive experiments on many public datasets demonstrate the superior performance of our method."
SP:4edb870786c9cea2c6075359cb4e79b02a8e2f5f,"This paper proposes a method to decompose and transfer voice style through a novel information bottleneck and adversarial feedback. The proposed method is based on a self-supervised representation learning approach, where the proposed information bottleneck can decompose the content and style with only a small loss of content information. Also, the discriminator is decomposed into a content discriminator and a style discriminator, which enable the model to achieve better generalization to the voice style of the converted speech. The experimental results show the superiority of the proposed method. "
SP:9fbb0c6beb3f8f88972f13dcf0e1fe7db03233c7," 3D object tracking in point clouds is still a challenging problem due to the sparsity of LiDAR points in dynamic environments. This paper proposes a Siamese voxel-to-BEV tracker, which can significantly improve the tracking performance in sparse 3D point clouds. Specifically, it consists of a Siamee shape-aware feature learning network and a Voxel to BEV target localization network. Extensive evaluation on the KITTI and nuScenes datasets shows that the proposed method significantly outperforms the current state-of-the-art methods by a large margin."
SP:8b788c78680a54c453a04f4551436763ee57585e,"This paper proposes a novel positional encoding method based on learnable Fourier features for multi-dimensional positional encoding. Instead of hard-coding each position as a token or a vector, this paper proposes to represent each position in a multi-layer perceptron as a learnable feature mapping, modulated with a multi layer perceptron. The proposed method is evaluated on several public benchmark tasks and shows that it outperforms existing methods by both improving the accuracy and allowing faster convergence."
SP:d2ac1b6381315bce4449f09bd519f33a2a42d714,"This paper studies the problem of learning the causal MAG of a system from observational data in the presence of latent variables and selection bias. The key idea of this paper is to learn the structure efficiently and recursively. This allows us to reduce both the number of required conditional independence (CI) tests and the size of the conditioning sets. The authors provide an upper bound on the required CI tests in the worst case, which is the tightest bound in the literature. They also provide a lower bound. "
SP:49a4912ce457f5f5ec62c44fa10444af8075fabf,"This paper proposes a batch Thompson Sampling framework for stochastic multi-arm bandit and linear contextual bandit with finitely many arms. The proposed algorithm achieves the same (asymptotic) regret bound of a fully sequential one while carrying out only O(log T) batch queries. To achieve this exponential reduction, the batch policy dynamically determines the duration of each batch in order to balance the exploration-exploitation trade-off. Experiments show that dynamic batch allocation dramatically outperforms natural baselines."
SP:653a519e3c799c25e0d0b4240322642040b121a3,"This paper studies the problem of domain adaptation (DA) and domain generalization (DG) in the multi-source setting. The main contribution of the paper is the development of a new upper bound for the target generalization loss. The upper bound is based on the definition of two kinds of domain-invariant representations. The authors further study the pros and cons of enforcing learning each type of representation. Finally, they conduct experiments to inspect the trade-off of these representations for offering practical hints regarding how to use them in practice. "
SP:2a7bee950cd07494d59dfee60ac2e86cc0e481b1,"This paper proposes a method for lightweight image super-resolution (SR) networks. The proposed method is based on aligned structured sparsity learning (ASSL), which introduces a weight normalization layer and applies L2 regularization to the scale parameters for sparsity. To align the pruned filter locations across different layers, the authors propose a sparsity structure alignment penalty term, which minimizes the norm of soft mask gram matrix. The authors apply the proposed method to train efficient image SR networks with smaller model size and lower computation than state-of-the-art methods."
SP:e9830bb9e7d3ddc3bd1c2994590fdb5d8f3668be,This paper proposes a novel method for multi-agent reinforcement learning with Curiosity-driven exploration. The main idea is to use prediction errors of individual Q-values as intrinsic rewards for coordinated exploration and utilize episodic memory to exploit explored informative experience to boost policy training. Experiments on the StarCraft II micromanagement benchmark show the effectiveness of the proposed method.
SP:c7e33d479575c88e22282ee6fd4f978bcd3c06ed,"This paper studies the problem of list-decodable linear regression, where an adversary can corrupt a majority of the examples. The goal is to output a small list of hypothesis vectors such that at least one of them is close to the target regression vector. The main result is a Statistical Query (SQ) lower bound of d for this problem. The SQ lower bound qualitatively matches the performance of previous algorithms."
SP:7b258252a9063514348f5fa8d9c85afd85748747,This paper proposes a model for predicting the patient health status and disease progression over time. The model is based on a system of ODEs with machine-learned neural networks to fully describe the dynamics of the system and to link the expert and latent variables to observable quantities. Experiments on synthetic data as well as real-world intensive care data of COVID-19 patients show the effectiveness of the model.
SP:3ea9e86e5755ef84d28e3163c60531ace5d62e3a,"This paper studies the problem of few-shot representation learning in the context of meta-learning, where the goal is to find a good representation for each task. The authors propose a MAML-like algorithm that learns a representation for all the tasks, and provide a theoretical analysis of the performance of the proposed algorithm. They show that the proposed method outperforms a frozen representation learning algorithm in the worst-case setting, where there is no information about the target task."
SP:8ba5a2ac80f7c53f81ad008e96c033ecad14ac0d,"This paper proposes Grammar-Based Grounded Lexicon Learning (G2L2), a lexicalist approach to learn a compositional and grounded meaning representation of language from grounded data, such as paired images and texts. At the core of the approach is a collection of lexicon entries, which map each word to a syntactic type and a neuro-symbolic semantic program. Given an input sentence, the proposed approach first looks up the lexicon entry associated with each token, then derives the meaning of the sentence as an executable program by composing lexical meanings based on syntax. The recovered meaning programs can be executed on grounded inputs. To facilitate learning in an exponentially growing compositional space, the authors introduce a joint parsing and expected execution algorithm, which does local marginalization over derivations to reduce the training time. "
SP:16c458651815813efdcbe8ba1205bbddbe3e4e68,"This paper proposes a stochastic Newton algorithm for homogeneous distributed stochiastic convex optimization, where each machine can calculate the gradients of the same population objective and the Hessian-vector products. The authors show that their algorithm can reduce the number, and frequency, of required communication rounds compared to existing methods without hurting performance, by proving convergence guarantees for quasi-self-concordant objectives (e.g., logistic regression)."
SP:d7e479d59f82d4c55372a68ca7b4516f2871f346,"This paper proposes a new measure of point cloud similarity based on Chamfer Distance (CD) and Earth Mover’s Distance (EMD) to evaluate the similarity between two point clouds. The proposed measure, called density-aware Chamfer distance (DCD), is more computationally efficient than CD and has a bounded value range. The authors also propose a novel point discriminator module that estimates the priority for another guided downsampling step and it achieves noticeable improvements under DCD together with competitive results for both CD and EMD."
SP:e4b302009520770814ff2c096020b779a9fc38fe,"This paper studies the problem of knowledge distillation, a popular technique for training a small student network to emulate a larger teacher model, such as an ensemble of networks. The authors show that there often remains a surprisingly large discrepancy between the predictive distributions of the teacher and the student. They identify difficulties in optimization as a key reason for why the student is unable to match the teacher. They also show how the details of the dataset used for distillation play a role in how closely the student matches the teacher — and that more closely matching the teacher paradoxically does not always lead to better student generalization."
SP:895c7e03f9e4dadb94be1f39d61bf0b5e1533f4f,"This paper studies the problem of computing the coreset of a k-decision tree (k-tree) for a given matrix D of N entries (labels), where the loss is the sum of squared differences over every label in D and its assigned label by t. Given an error parameter $\epsilon$, the paper shows that a coreset C of D is a small summarization that approximates this loss to every such tree, up to a multiplicative factor of 1/\sqrt{1/\varepsilon}. In particular, the optimal k-tree of C is a (1 + \epsilone)-approximation to the optimal tree of D. The paper provides the first algorithm that outputs such a (k, ε)-coreset for every such matrix D, and its construction takes O(Nk) time. "
SP:f3ece96b15ec06d703925df2061ed9694ec3bca5,"This paper studies the problem of Top-m identification for misspecified linear bandit models under a fixed error rate of $\delta$ where $m$ is the number of arms in the bandit model. The authors derive a tractable lower bound on the sample complexity of any $d$-correct algorithm for the general Top-M identification problem. They show that knowing the scale of the deviation from linearity is necessary to exploit the structure of the problem and propose an algorithm that is both practical and adapts to the amount of misspecification. They also derive an upper bound to its sample complexity which confirms this adaptivity and that matches the lower bound when $delta = 0. Finally, they evaluate their algorithm on both synthetic and real-world data, showing competitive performance with respect to existing baselines."
SP:e71c5e39b8d8d1640d6de2352ac51ddd52eea89d,"This paper proposes a method to learn disentangled graph representations with self-supervised learning for graph neural networks (GNNs). The key idea is to first identify the latent factors of the input graph and derive its factorized representations. Then, the authors propose a novel factor-wise discrimination objective in a contrastive learning manner to force the representations to independently reflect the expressive information from different latent factors. Extensive experiments on both synthetic and real-world datasets demonstrate the superiority of the proposed method."
SP:0a7edbbdabab11273689c40c517001eb46491113,This paper studies the problem of estimating the robustness of a trained network to input uncertainties with a stochastic simulation inspired by the field of Statistical Reliability Engineering. The robustness assessment is cast as a statistical hypothesis test: the network is deemed as locally robust if the estimated probability of failure is lower than a critical level. The procedure is based on an Importance Splitting simulation generating samples of rare events. Theoretical guarantees are derived that are nonasymptotic w.r.t. sample size. Experiments tackling large scale networks outline the efficiency of the method making a low number of calls to the network function.
SP:c1db485ff1ff9573daa421e167225654babb55ac,"This paper proposes a polynomial neural network (PNN) for two-variable conditional generation. The main contribution of the paper is the introduction of CoPE, which is an extension of polynomials to two- variable conditional generation tasks. CoPE is evaluated in five tasks (class-conditional generation, inverse problems, edges-to-image translation, image to image translation, attribute-guided generation, and super-resolution) on eight datasets. The experimental results show that CoPE outperforms existing PNNs on all five tasks."
SP:5a75bc7a3ea0ce971cfceebbc1c2434e3aa2584d,"This paper proposes a new neural network MMD statistic based on neural tangent kernel (NTK) based two-sample test. Theoretically, the authors show that the NTK-MMD statistic has a connection with the MMD statistics. This connection enables them to develop a computationally efficient and memory-efficient approach to compute MMD and perform NTK based 2-sample tests towards addressing the long-standing challenge of memory and computational complexity of MMD. "
SP:1df2ffbbe56b8018067820980b93af2a8b57f891,"This paper studies the problem of learning the minimum necessary information required by a neural network D(x) from an image x to accurately predict its class. The authors propose to use a variational autoencoder (VAE) to extract the class-dependent information as x − G(x), where the former competes with the latter in decomposing x so the latter retains only necessary information for classification in x-G(x). They apply it to both clean images and their adversarial images and discover that the perturbations generated by adversarial attacks mainly lie in the class dependent part x - G(X). The decomposition results also provide novel interpretations to classification and attack models. Inspired by these observations, they propose to conduct adversarial detection and adversarial defense respectively on x-D(X) and G(Y) and show that they consistently outperform the results on the original x."
SP:2789874561620ba7894c4672f935056bb911e919,"The paper proposes a federated Thompson sampling (FTS) algorithm for Bayesian optimization (BO) with differential privacy (DP) in the federated learning (FL) setting. The proposed algorithm is based on a general framework for adding DP to iterative algorithms. The authors propose to use the general DP framework to handle different parameter vectors, as well as the technique of local modeling for BO, to further improve the utility of their algorithm through distributed exploration (DE). The resulting differentially private FTS with DE (DP-FTS-DE) algorithm is endowed with theoretical guarantees for both the privacy and utility and is amenable to interesting theoretical insights about the privacy-utility trade-off. They also use real-world experiments to show that the proposed algorithm achieves high utility (competitive performance) with a strong privacy guarantee (small privacy loss) and induces a tradeoff between privacy and privacy."
SP:be7d6b81736a2c3f89abd8771b41b18802e88832,"This paper proposes a multi-label active learning (ML-AL) approach to learn a Gaussian process-Bayesian Bernoulli Mixture model (GP-BM) to accurately quantify a data sample’s overall contribution to a correlated label space and choose the most informative samples for cost-effective annotation. In particular, the BM encodes label correlations using a BayesianBernoulli mixture of label clusters, where each mixture component corresponds to a global pattern of label correlations. The BM is further integrated with a predictive GP to connect data features as an effective inductive bias and achieve a feature-component-label mapping. A principled sampling function is designed accordingly to naturally capture both the feature uncertainty (through GP) and label covariance (through BM) for effective data sampling. The model also outputs a predictive distribution that provides both the label prediction and their correlations in the form of a label covariances matrix. A novel auxiliary variable based variational inference algorithm is developed to tackle the non-conjugacy introduced along with the mapping process for efficient end-to-end posterior inference."
SP:2b7270b0370c193300bcbbb5fb0a4101b3329d99,This paper proposes to use a polar coordinate system to improve the end-to-end latency of lidar perception models by using multi-scale padding from neighboring sectors: preceding sector from the current scan and/or the following sector from past scan. The proposed method improves the core polar convolutional architecture by introducing feature undistortion and range stratified convolutions. Experimental results on the nuScenes dataset show significant improvements over other streaming based methods.
SP:7ae2c5b7d9c8a6c8f4a353606aa419929c47f31b,"This paper studies the problem of learning with structured latent variables in deep learning. The authors propose to use the Gumbel-Max trick to define distributions over structured domains, which avoids the differentiable surrogates by leveraging the score function estimators for optimization. In particular, they highlight a family of recursive algorithms with a common feature we call stochastic invariant. The feature allows us to construct reliable gradient estimates and control variates without additional constraints on the model. In experiments, they consider various structured latent variable models and achieve results competitive with relaxation-based counterparts."
SP:415d363c66a6967c1daca9dc02001b85bf7f0752,"This paper proposes GainTuning, a method to adaptively and selectively adjust the training parameters of CNNs for image denoising. The main idea is to use a single multiplicative scaling parameter (the Gain) of each channel in the convolutional layers of the CNN to optimise the network. The proposed method is shown to improve the performance of the network on standard image-denoising benchmarks. The method is also applied to synthetic data to reconstruct the structure of catalytic nanoparticles."
SP:90afa1102683b456bc72a54abef466326827546a,This paper proposes a new architecture for panoptic segmentation (a.k.a. simultaneous semantic and instance segmentation) consisting of a convolutional neural network and an asymmetric multi-way cut problem solver. The latter solves a combinatorial optimization problem that elegantly incorporates semantic and boundary predictions to produce a pan-optic labeling. The formulation allows to directly maximize a smooth surrogate of the panopti quality metric by backpropagating the gradient through the optimization problem. Experimental evaluation on Cityscapes and COCO datasets shows the effectiveness of the proposed architecture.
SP:1952e174d9ec7b83ad1d394ece7fe77ea1f6d78d,"This paper proposes Recursive Bayesian Networks (RBNs), which generalizes and unifies PCFGs and DBNs, combining their strengths and containing both as special cases. RBNs define a joint distribution over tree-structured Bayesian networks with discrete or continuous latent variables.  The main challenge lies in performing joint inference over the exponential number of possible structures and the continuous variables. The authors provide two solutions: 1) for arbitrary RBN, they generalize inside and outside probabilities from PCFG to the mixed discrete-continuous case, which allows for maximum posterior estimates of the continuous latent variable via gradient descent, while marginalising over network structures. 2) for Gaussian RBNS, they additionally derive an analytic approximation of the marginal data likelihood (evidence) and marginal posterior distribution, allowing for robust parameter optimisation and Bayesian inference. "
SP:5f29b169d3e4bbaeeec85e1aeebe2094fae4be6e,"This paper proposes a new method for constrained backpropagation (CBP) based on pseudo-Lagrange multiplier method to obtain the optimal set of weights that satisfy a given set of constraints. The main contribution of the paper is the use of a Lagrangian function (loss function plus constraint function) as its objective function. The proposed method outperforms the state-of-the-art methods on ImageNet, e.g., with binary weights. "
SP:3ddf8e2e108fb261bb23aec8a27a25aba7523dc1,"This paper studies the problem of active learning for Gaussian process classification (GPC). The main contribution of the paper is to propose an efficient active learning algorithm for EER-based active learning with GPC. Specifically, the authors derive the joint predictive distribution of label pairs as a one-dimensional integral, as a result of which the computation of the acquisition function avoids retraining the GPC for each query, remarkably reducing the computational overhead. The authors also derive the gradient chain rule to efficiently calculate the gradient of acquisition function. The experiments clearly demonstrate the computational efficiency of the proposed algorithms. "
SP:fa1fac04cd4ccb1f3eaf80807db09f9683ce6b50,"This paper studies the effect of unbounded gradients in continuous variational autoencoders (VAE) on the regularization of VAE models. The main result is that if the ultimate goal is to simultaneously avoid over-regularization (high reconstruction errors, sometimes referred to as posterior collapse) and under-regularisation (excessive latent dimensions are not pruned from the model), then an autoencoder-based energy function with infinite gradients around optimal representations is provably required. This result suggests that heuristic modifications to or constraints on the VAE energy function may at times be ill-advised, and large gradients should be accommodated."
SP:2611cfd6e0696a57d061687993cef1fe5c95999d,"This paper studies the bandit problem with graph feedback in the setting of graph feedback. The authors propose the fractional weak domination number and the k-packing independence number capturing upper bound and lower bound for the regret respectively. They show that the two notions are inherently connected via aligning them with the linear program of the weakly dominating set and its dual — the fractionally vertex packing set respectively. Based on this connection, they utilize the strong duality theorem to prove a general regret upper bound O (δ∗ log |V |) 1 3 T 2 3 ) and a lower bound $O(\sqrt{O}/\gamma)$ where $\gamma$ is the integrality gap of the dual linear program. They also show that for several special families of graphs, they can get rid of the (log |V 1 3 factor and establish optimal regret."
SP:e50dec57af337839cbde4b65fb7b431785fda44d,"This paper proposes to use neighbourhood reference distributions to improve the interpretability of Shapley values. The authors show that the Nadaraya-Watson estimator, a well-studied kernel regressor, can be expressed as a self-normalised importance sampling estimator. Empirically, they observe that Neighbourhood Shapley Values identify meaningful sparse feature relevance attributions that provide insight into local model behaviour, and increase on-manifold explainability and robustness to the construction of adversarial classifiers."
SP:35bdeb78f9fe74e754177fb54b48e7399dc8590d,"This paper proposes PlayVirtual, which augments cycle-consistent virtual trajectories to enhance the data efficiency for RL feature representation learning. PlayVirtual predicts future states in a latent space based on the current state and action by a dynamics model and then predicts the previous states by a backward dynamics model, which forms a trajectory cycle. Based on this, the authors augment the actions to generate a large amount of virtual state-action trajectories. The proposed method achieves the state-of-the-art performance on the Atari and DeepMind Control Suite benchmarks."
SP:ca09e472cbcf2ac8c8c9b192a87df2ed59218210,"This paper proposes a framework to study the relationship between network architecture and robustness to noisy labels. The authors propose a new metric to measure the robustness of a network by the predictive power of its representations, which is the test performance of a linear model trained on the learned representations using a small set of clean labels. They hypothesize that a network is more robust to noise labels if its architecture is more aligned with the target function than the noise. They provide both theoretical and empirical evidence across various neural network architectures and different domains."
SP:903727fe028684623a8ccadec210e641ecffc685,"This paper proposes a novel method for learning a reward function from a set of examples of successful outcomes. The authors propose to learn a value function from transitions and successful outcomes, without learning an intermediate reward function. They show that their method satisfies a new data-driven Bellman equation, where examples take the place of the typical reward function term. Experiments show that the proposed method outperforms prior methods that learn explicit reward functions."
SP:39ccbd5909a1d7ed212fe92d8d6843c2c70dfe1f,"This paper studies differentially private stochastic optimization in convex and non-convex settings. In the convex case, the authors focus on the family of non-smooth generalized linear losses (GLLs). Their algorithm for the l2 setting achieves optimal excess population risk in near-linear time, while the best known differential private algorithms for general convex losses run in superlinear time. For the l1-case with smooth losses and polyhedral constraint, they provide the first nearly dimension independent rate, Õ ( log d (nε)1/3 ) in linear time. They obtain a linear-time algorithm with rate Á ( 1 n1/4 + d 1/6 (nepeta)2/5 ) for the constrained l2-case. Finally, they extend all their results above for the non convex l2 case to the lp setting with only polylogarithmic (1 < p < 2)."
SP:99a476f71e6901aefe281f11fb72ff78265a5b6e,"This paper studies the cooperative bandit problem in three real-world communication scenarios: (1) message-passing over stochastic time-varying networks, (2) instantaneous reward sharing over a network with random delays, and (3) message passing with adversarially corrupted rewards, including byzantine communication. For each of these environments, the authors propose decentralized algorithms that achieve competitive performance, along with near-optimal guarantees on the incurred group regret as well. "
SP:d3e896a65470f2439bc7753b4f66e152306b2d6f, of quantization in vision transformers. This paper proposes a novel quantization algorithm to reduce the memory storage and computational cost of vision transformer. The proposed algorithm is based on a ranking loss that aims to keep the relative order of the self-attention results after quantization. The effectiveness of the proposed method is verified on several benchmark models and datasets and outperforms the state-of-the-art posttraining quantization algorithms.
SP:aa6b1328585b5916267a3ff4f9119e7aa4ce2bb5,"This paper studies the convergence rate of double Q-learning in the case of constant learning rate. In particular, the authors show that synchronous double-Q-learning attains an accurate global optimum with a time complexity of $O(\sqrt{L}(1-\gamma)$ where $L$ is the cardinality of the state-action space, $\gamma$ the discount factor, and $L(d)$ is a parameter related to the sampling strategy for asynchronous double-q-learning. The authors also show that the synchronous algorithm attains a global optimum of $\Omega(L)$ while the asynchronous algorithm achieves $O(L^2)$ time complexity. These results improve the existing convergence rate by an order of magnitude."
SP:04fd4d83717c4f7e1a4b5651a59200151f33411d,"This paper proposes a new semi-supervised OOD detection method, called Structure-Keep Unzipping (STU), which learns a new representation space in which OOD samples could be separated well. The main contribution of this paper is to propose a new algorithm for OOD classification and detection based on the structure-keep unzipping method. The proposed method is evaluated on a variety of benchmarks and compared with existing methods."
SP:6bf8b94483b26033795b0eda9649518027f5e1c2," is a simple but effective approach for visual grounding tasks. The authors propose a transformer architecture where two modalities are fused in a visual-lingual encoder. In the decoder, the model learns to generate contextualized lingual queries which are then decoded and used to directly regress the bounding box and produce a segmentation mask for the corresponding referred regions. Extensive experiments and ablations illustrate that the model benefits greatly from contextualized information and multi-task training."
SP:29b552b36696c9bda72f3ab4f31605d98880fd6b,"This paper studies multiclass boosting in the setting where the weak learner is agnostic to the classification loss and the booster is an agnostic PAC learner with respect to the standard classification loss. The goal of the overall boosting algorithm is to learn a combination of weak hypotheses by repeatedly calling the weak learners. The authors study the resources required for boosting, especially how they depend on the number of classes k, for both the booster and weak learners, and show that the boosting algorithm itself only requires O(log k) samples, as well as analyzing a variant of AdaBoost for our setting. They also prove a trade-off between number of oracle calls and the resources needed of the learner."
SP:f63b050773871338c48b778c362172e4b72477a4,". This paper proposes an embedding-based approach in which embeddings of pixels are clustered in a differentiable fashion using a stochastic stick-breaking process. Similar to iterative refinement, this clustering procedure also leads to randomly ordered object representations, but without the need of initialising a fixed number of clusters a priori. This is used to develop a new model, GENESIS-V2, which can infer a variable number of object representations without using RNNs or iterative refining. The proposed method is evaluated on synthetic and real-world datasets."
SP:408deb9e5577ee7118b836fee77135df641fe545,This paper proposes a method for online conformal inference where the data generating distribution is allowed to vary over time in an unknown fashion. The main contribution of the paper is to propose an adaptive approach to form prediction sets in an online setting where the distribution shift is allowed. The proposed method is based on the idea of learning a single parameter whose optimal value is varying over time and must be continuously re-estimated. The method is tested on two real world datasets and finds that its predictions are robust to visible and significant distribution shifts.
SP:e6e5b1e2428abcf1a163ec1cce15cd299f9a544f,"This paper proposes a pose-level inference strategy that is free of bounding box detection and keypoint grouping. Instead of inferring individual keypoints, the Pose-level Inference Network (PINet) directly infers the complete pose cues for a person from his/her visible body parts. PINet relies on discriminative body parts to differentiate overlapped persons, and applies visual body cues to infer the global pose cues. Experiments on several crowded scenes pose estimation benchmarks demonstrate the superiority of PINet."
SP:e76f048c3dccffcb8bcc6a66f6165fc19d175610, the Bellman operator for S-rectangular robust Markov decision processes with L-constrained rectangular ambiguity sets. The proposed algorithm combines a novel homotopy continuation method with a bisection method to solve the problem in quasi-linear time. The algorithm improves on the cubic time required by leading general linear programming methods.
SP:c4af66a64a5c2bd58ca2e29dbc4b27d5bf4b63b8,This paper studies the problem of online knapsack problem with very weak predictions. The main contribution of the paper is to derive online algorithms that attain the best possible competitive ratio for any fixed prediction. The paper also extends the results to more general settings such as generalized one-way trading and two-stage online Knapsack. The results show that even seemingly weak predictions can be utilized effectively to improve the performance of online algorithms.
SP:1d478d4fa3f5df0ded963ef164325667fd744dbb,"This paper proposes a new model-based episodic memory of trajectories to address the limitations of episodic control. The memory estimates trajectory values, guiding the agent towards good policies. Based on the memory, the authors construct a complementary learning model via a dynamic hybrid control. Experiments demonstrate that the proposed model allows significantly faster and better learning than other strong reinforcement learning agents across a variety of environments."
SP:551174c1266b5f4b6aaf5432a4c713386f90898c,"This paper proposes DP-SSL, a semi-supervised learning method that uses data programming (DP) to generate probabilistic labels for unlabeled data. The proposed method is based on multiple-choice learning (MCL) based approach to automatically generate LFs from scratch in SSL style. With the noisy labels produced by the LFs, a label model is designed to resolve the conflict and overlap among the labels, and finally infer probabilistically labels. Extensive experiments on four standard SSL benchmarks show that the proposed method achieves better classification performance on test sets than existing SSL methods."
SP:d1d6a40a8bde62a21da4fc18a076e344c84ab0d0,"This paper proposes a multi-view pose transformer (MVPT) for estimating multi-person 3D poses from multiple images. MVPT represents skeleton joints as learnable query embeddings and let them progressively attend to and reason over the multiview information from the input images to directly regress the actual 3D joint locations. To improve the accuracy of such a simple pipeline, MVP presents a hierarchical scheme to concisely represent query embedding of multi- person skeleton joints and introduces an inputdependent query adaptation approach. The proposed method also introduces a novel geometrically guided attention mechanism, called projective attention, to more precisely fuse the cross-view information for each joint. Experiments show that the proposed method outperforms state-of-the-art methods on several benchmarks while being much more efficient."
SP:2e147bd5321e25bb27d2531fd58c46460a1e5320,"This paper studies the problem of finding the supports of sparse vectors from a family of unknown sparse vectors, where each vector has at most k non-zero elements. In the first problem, a sequence of noisy responses is used to learn the support of all vectors from the family. The second problem is to design queries such that all sparse vectors in the family can be approximately reconstructed based on the error-free responses. The main contribution of the paper is to prove the existence of learning algorithms that work without any assumptions."
SP:e3388e479a825be429f3a878e2c4d8b05903ff10,"This paper studies the bandit changepoint detection problem, where sensing actions (or sensors) are sequentially chosen, and only measurements corresponding to chosen actions are observed. The authors derive an information-theoretic lower bound on the detection delay for a general class of finitely parameterized probability distributions. They then propose a computationally efficient online sensing scheme, which seamlessly balances the need for exploration of different sensing options with exploitation of querying informative actions. They derive expected delay bounds for the proposed scheme and show that these bounds match the information theory lower bound at low false alarm rates, establishing optimality of the proposed method."
SP:268260e9452ba2bc57e50a6b7b3328233137ac9b,"This paper proposes a new algorithm for solving stochastic nested optimization problems. The main contribution of the paper is to provide a tighter analysis of SGD-type algorithms for solving nested problems. In particular, the proposed algorithm is based on the ALternating Stochastic Gradient dEscenT (ALSET) algorithm. The paper shows that under certain regularity conditions, the new algorithm can achieve an-stationary point of the nested problem with O(2) samples in total. The proposed algorithm can also be applied to the min-max and reinforcement learning problems."
SP:82ad52361bc5b2c421f1dc6b76e1a5520570fc6c,"This paper proposes a Siamese Sampling and Reasoning (SiaSamRea) approach for video question answering. The key idea is to use siamese sampling mechanism to generate sparse and similar clips from the same video, and a novel reasoning strategy for integrating the interdependent knowledge between contextual clips into the network. The reasoning strategy contains two modules: (1) siamee knowledge generation to learn the inter-relationship among clips; (2) siamesese knowledge reasoning to produce the refined soft label by propagating the weights of inter-relation to the predicted candidates of all clips. Extensive experiments demonstrate that the proposed approach achieves state-of-the-art performance on five VideoQA benchmarks."
SP:160022e2cd61159da92f92e85520b7062a337a8d,"This paper proposes a simple approach to reduce the computational and memory complexity of a large class of structured models. The key idea is to view the central inference step as a matrix-vector product and using a low-rank constraint, we can trade off model expressivity and speed via the rank. Experiments on language modeling, polyphonic music modeling, unsupervised grammar induction, and video modeling show that the proposed approach matches the accuracy of standard models at large state spaces while providing practical speedups."
SP:238592ad73927194cdf0c0cf9ae2e48ca86e182c,"This paper proposes Sample Average Uncertainty (SAU) as a simple and efficient uncertainty measure for contextual bandits. SAU is a frequentist approach that directly estimates the uncertainty of the outcomes based on the value predictions. The authors show theoretically that the uncertainty measure estimated by SAU asymptotically matches the uncertainty provided by Thompson Sampling, as well as its regret bounds. They show empirically that SAU-based exploration outperforms current state-of-the-art deep Bayesian bandit methods on several real-world datasets at modest computation cost."
SP:ffc5b18f7e18607b2934e5aa199e7542005d79f4,"This paper proposes a method to learn embeddings for videos of animals performing repeated behaviors. The approach is based on disentangling the dynamic behavioral factors (pose) from time-invariant, non-behavioral nuisance factors (context) in a deep autoencoder, and exploit the temporal structures of pose dynamics. The proposed method is evaluated on downstream tasks such as fine-grained behavioral motif generation and behavior decoding."
SP:bf78a450e4aad6b87fdeb8ec0d68adaaff7b595b,"This paper proposes DMTET, a deep 3D conditional generative model that can synthesize high-resolution 3D shapes using simple user guides such as coarse voxels. It marries the merits of implicit and explicit 3D representations by leveraging a novel hybrid 3D representation. Compared to the current implicit approaches, which are trained to regress the signed distance values, the proposed method directly optimizes for the reconstructed surface, which enables us to synthesize finer geometric details with fewer artifacts. The core of DMTet includes a deformable tetrahedral grid that encodes a discretized signed distance function and a differentiable marching tetrahedra layer that converts the implicit signed distance representation to the explicit surface mesh representation. This combination allows joint optimization of the surface geometry and topology as well as generation of the hierarchy of subdivisions using reconstruction and adversarial losses defined explicitly on the surface mesh."
SP:2bc0bd6aa2a12691b16145f0d23542c4c86e3a44,"This paper proposes sliced mutual information (SMI) as a surrogate measure of statistical dependence. SMI is defined as an average of MI terms between one-dimensional random projections. The authors show that SMI preserves many of the structural properties of classic MI, while gaining scalable computation and efficient estimation from samples. Furthermore, SMI can grow as a result of deterministic transformations. This enables leveraging SMI for feature extraction by optimizing it over processing functions of raw data to identify useful representations thereof."
SP:e220b348901b476c2afd95f97630fb5400582f40,"This paper proposes a two-step lookahead constrained Bayesian optimization acquisition function (2-OPT-C) for both sequential and batch settings. The main contribution of the paper is to propose a novel likelihoodratio-based unbiased estimator of the gradient of the two step optimal acquisition function that does not use the reparameterization trick for more efficient derivative-based optimization of non-myopic acquisition functions in the unconstrained setting, like sample average approximation and infinitesimal perturbation analysis, do not extend: constraints introduce discontinuities in the sampled acquisition function surface. In numerical experiments, the proposed method typically improves query efficiency by 2x or more over previous methods, and some cases up to 10x."
SP:51fbd861422647912f275b48861ea3c4812afdc8,"This paper proposes Multi-Dimensional Distributional Distributional DQN (MD3QN) to model the joint return distribution from multiple reward sources. The main contribution of this paper is to extend distributional reinforcement learning (RL) to multi-dimensional reward functions. The authors prove the convergence for the joint distributional Bellman operator and build an empirical algorithm by minimizing the Maximum Mean Discrepancy between joint return distributions and its Bellman target. In experiments, the proposed method outperforms previous RL methods in the control setting."
SP:1f85c93d6bbfd65bf497c92c9cd534d799753097,This paper proposes a method for learning to deform a 3D template mesh to a target object. The method is based on the flow-based ODE framework. The key idea is to train the model over a set of diffeomorphic transformations. The proposed method is evaluated on the task of brain cortical surface reconstruction. 
SP:2f31d9cf4ad17ad08344439ca0aef7ec91944545,"This paper studies the problem of data deletion in the non-convex setting. In this setting, the authors propose a general reduction from deletion guarantees against adaptive sequences to deletion guarantees for non-adaptive sequences, using differential privacy and its connection to max information. They show in theory how prior work for non convex models fails against adaptive deletion sequences, and use this intuition to design a practical attack against the SISA algorithm of Bourtoule et al. [2021] on CIFAR-10, MNIST, Fashion-MNIST."
SP:7150006590e268ab732c9be6c9048f67a377f956,"This paper studies the problem of risk-averse Bayes-adaptive reinforcement learning in Markov decision processes (MDPs). In particular, the authors study the conditional value at risk (CVaR) of the total return in MDPs. They show that a policy optimising CVaR in this setting is risk averse to both the epistemic uncertainty due to the prior distribution over MDP’s and the aleatoric uncertainty. They reformulate the problem as a two-player stochastic game and propose an approximate algorithm based on Monte Carlo tree search and Bayesian optimisation. The experiments demonstrate that their approach significantly outperforms baseline approaches for this problem."
SP:a94f39406f73d7483ddd744ed2f03c78b8bc5d44,"This paper studies the behavior of shallow ReLU networks trained with the logistic loss via gradient descent on binary classification data where the underlying data distribution is general, and the (optimal) Bayes risk is not necessarily zero. In this setting, it is shown that gradient descent with early stopping achieves population risk arbitrarily close to optimal in terms of not just logistic and misclassification losses, but also calibration, meaning the sigmoid mapping of its outputs approximates the true underlying conditional distribution arbitrarily finely. Moreover, the necessary iteration, sample, and architectural complexities of this analysis all scale naturally with a certain complexity measure of the true conditional model. The paper also shows that any univariate classifier satisfying a local interpolation property is inconsistent."
SP:a9c786cbb61e1f10f3542161b13e43a1a68ab34d," social media. This paper proposes a method for coordinated group detection based on neural temporal point process. The proposed method is based on the Gibbs distribution of group assignment based on how consistent an assignment is to the account embedding space and the prior knowledge. To address the challenge that the distribution is hard to be efficiently computed and sampled from, the authors design a theoretically guaranteed variational inference approach to learn a mean-field approximation for it. Experimental results on a real-world dataset show the effectiveness of the proposed method compared to state-of-the-art model in both unsupervised and semi-supervised settings."
SP:b5c6e967a26a02861db2ecd620e9061db0c03e59,"This paper studies the problem of binary classification of two disjoint smooth curves on the unit sphere. The authors prove that when the network depth is large relative to certain geometric properties that set the difficulty of the problem, and the network width and number of samples are polynomial in the depth, randomly-initialized gradient descent quickly learns to correctly classify all points on the two curves with high probability. This is the first generalization guarantee for deep networks with nonlinear data that depends only on intrinsic data properties. The analysis proceeds by a reduction to dynamics in the neural tangent kernel (NTK) regime, where network depth plays the role of a fitting resource in solving the classification problem. "
SP:8f6bee3be43df6b6e80804974014caaafe08c49e,"This paper proposes ReACGAN, an auxiliary classifier GAN with softmax cross-entropy loss (ACGAN). The main contribution of this paper is two-fold. First, the authors identify that gradient exploding in the classifier can cause an undesirable collapse in early training. Second, they propose the Data-to-Data Cross-Entropy Loss (D2D-CE) to exploit relational information in the data-labeled dataset. The experimental results show the effectiveness of the proposed method. "
SP:080e80746a87228b156408ff649ab7a17f44e92d,"This paper proposes an extensive-form double oracle algorithm for two-player zero-sum games that is guaranteed to converge to an approximate Nash equilibrium linearly in the number of infostates. Unlike PSRO, which mixes best responses at the root of the game, XDO mixes best response at every infostate. The authors also introduce Neural XDO (NXDO), where the best response is learned through deep RL. In tabular experiments on Leduc poker, the authors show that XDO achieves an approximation of Nash equilibrium in a number of iterations an order of magnitude smaller than PSRO. "
SP:bda04facef4f34679fc4e17b8ea1aae74c3d649f,"This paper proposes a permutation-invariant variational autoencoder for graph-level unsupervised representation learning. The proposed model indirectly learns to match the node order of input and output graph, without imposing a particular node order or performing expensive graph matching. The authors demonstrate the effectiveness of their proposed model for graph reconstruction, generation and interpolation and evaluate the expressive power of extracted representations for downstream graph level classification and regression."
SP:e17ea6aeba78c9dfc25596d8b35a2a4f1f1f6763,"This paper proposes a method to decouple the depth and scope of graph neural networks (GNNs) by first extracting a localized subgraph as the bounded-size scope, and then applying a GNN of arbitrary depth on top of the subgraph. A properly extracted subgraph consists of a small number of critical neighbors, while excluding irrelevant ones. The GNN, no matter how deep it is, smooths the local neighborhood into informative representation rather than oversmoothing the global graph into “white noise”. Empirically, on seven graphs (with up to 110M nodes) and six backbone GNN architectures, the proposed method achieves significant accuracy improvement with orders of magnitude reduction in computation and hardware cost."
SP:4890f251db559a0a572afc66e0c1f899b577d9ff,"-like affine-coupling models are a widely used class of latent-variable generative models with a tractable likelihood. In this paper, the authors show that any log-concave distribution can be approximated using well-conditioned affine coupling flows. The authors also show that underdamped Langevin dynamics (a stochastic differential equation often used to sample from Gibbs measures) and Hénon maps (a structured dynamical system that appears in the study of symplectic diffeomorphisms) can be used to train affine couplings. "
SP:5ffa81488ed1092deb89bd5e150fa146325057ce,"This paper studies the problem of coupons allocation in the online e-commerce market. The authors propose a budget constrained offline reinforcement learning and evaluation with λ-generalization (BCORLE(λ)) framework. Specifically, the proposed method can help enterprises develop a coupons allocation policy which greatly improves users’ retention rate on the platform while ensuring the cost does not exceed the budget. The proposed method is evaluated on the simulation platform and real-world scenarios."
SP:6b04cc7b4e45b9e65a1d34c15e3f75a2ef27d601,"This paper studies the problem of source-free domain adaptation (SFDA) where the source pretrained model is adapted to the target domain in the absence of source data. The authors propose a method based on the observation that target data might no longer align with the source domain classifier, but still forms clear clusters. They capture this intrinsic structure by defining local affinity of the target data and encourage label consistency among data with high local affinity. They observe that higher affinity should be assigned to reciprocal neighbors, and propose a self regularization loss to decrease the negative impact of noisy neighbors. They also consider expanded neighborhoods with small affinity values. The experimental results verify that the inherent structure of target features is an important source of information for domain adaptation."
SP:ac1bf04ff782e5892a0bc5fe5949848ca8e731c2,"This paper proposes an end-to-end Euclidean embedding for learning representations from set-structured data. The proposed method is based on the idea of treating elements of a set as samples from a probability distribution and using a sliced-Wasserstein distance for embedding them. The method is evaluated on a variety of set-based tasks, including point-cloud, graph, and image classification tasks, and shows superior performance over existing set representation learning approaches."
SP:6cb2f0cbc076f8680cb00411790629f8e1478053,"This paper proposes a family of recurrent neural networks (RNNs) that can be formulated using stochastic bilevel optimization (SBO) to solve the lower and upper-level optimization for learning hidden states and their hyperparameters, respectively. The authors prove that under mild conditions there is no vanishing or exploding gradient in training SBO-RNN. Empirically, they demonstrate their approach with superior performance on several benchmark datasets, with fewer parameters, less training data, and faster convergence."
SP:d3a4300e21ca215334f256f0467a428470548fe4,"This paper studies the online problem of minimizing power consumption in systems with multiple power-saving states. The authors propose a learning-augmented online algorithm that makes decisions based on (potentially inaccurate) predicted lengths of the idle periods. The algorithm’s performance is near-optimal when predictions are accurate and degrades gracefully with increasing prediction error, with a worst-case guarantee almost identical to the optimal classical online algorithm for the problem."
SP:22aba6284123af0ecd6605ee4e89b351bd7e10a3,"This paper studies the problem of multi-source transfer learning in the setting where the source and target tasks are linearly combined for learning the target task. The authors propose a transferability measure based on the sample size, model complexity, and the similarities between the target and source tasks. They also propose an alternating iterative algorithm to implement their theoretical results for training deep neural networks in multi- source transfer learning tasks. Finally, experiments on image classification tasks show that their approach outperforms existing transfer learning algorithms in multi source and few-shot scenarios."
SP:0fb8dcf15e0d43547d566fdba7bc70b3bb600005,"This paper proposes a method for visual search based on the observation that in some search tasks, finding a target among distractors can be easier than finding the target among the distractors. The authors propose a model that takes a target and a search image as inputs and produces a sequence of eye movements until the target is found. The model integrates eccentricity-dependent visual recognition with target-dependent top-down cues. It is shown that the model provides a plausible mechanism for search asymmetry. "
SP:f0cc968ea9da4884dcdaf6d0c75ea9f1511bdfc3,"This paper studies the problem of certifiable robustness, i.e., the robustness of a model to adversarial perturbations. In particular, the authors study the loss landscape of linear relaxation-based methods. They find that the current state-of-the-art method often has a landscape with favorable optimization properties, and propose a new method with the desired properties. The proposed method achieves a decent performance under a wide range of perturbation."
SP:a158f8772a9dada059ffd1d6d7838ed40d8483da,"This paper studies the problem of online linear regression in the stochastic setting. The authors derive high probability regret bounds for online ridge regression and the forward algorithm. The main contribution of this paper is to propose the use of forward algorithm in lieu of ridge due to its enhanced bounds and robustness to the regularization parameter. Moreover, the authors explain how to integrate it in algorithms involving linear function approximation to remove a boundedness assumption without deteriorating theoretical bounds. Finally, numerical experiments are provided to show the effectiveness of the proposed algorithm."
SP:17ff9a2133aebf2d1b1787e8efc49d709389c0e7,This paper proposes a two-time-scale variant of the extragradient (EG) method for nonconvex-nonconcave problems. The main contribution of the paper is to propose a new variant of EG with an anchoring technique. The proposed method is based on the existing EG+ and EAG methods. The authors show that the proposed method has a fast O(1/k) rate on the squared gradient norm for smooth structured nonconformity problems. 
SP:4e38973033de24fc183c6112e1146f8eef0ddaea,"This paper studies the problem of uniformity testing for statistical data that consists of rankings over m items, where the alternative class is restricted to Mallows models. The authors show that uniform distribution can be distinguished from Mallows model with O(m 1/2) samples based on simple pairwise statistics, which allows us to test uniformity using only two samples, if m is large enough. They also consider uniformity test with central and local differential privacy (DP) constraints. They present a central DP algorithm that requires O(max{1/1/0, 1/p m}), where $p$ is the privacy budget parameter. They show that their algorithm is straightforward to apply to local DP scenario, since it works with binary statistics that is extracted from the ranking data."
SP:99a835191a3ba8372e391b6d3316e9b68e543295,"This paper studies a general greedy score-based algorithm for learning directed acyclic graphs (DAGs). The main contribution of the paper is to show that the recent polynomial-time algorithms for learning DAG models are a special case of this algorithm. This observation suggests new score functions and optimality conditions based on the duality between Bregman divergences and exponential families. Finally, the authors provide extensive experiments suggesting that this algorithm indeed optimizes the score in a variety of settings."
SP:b60989706296b963b6671c01f22384978a334be1,This paper proposes a neural architecture dilation algorithm to improve the adversarial robustness of the backbone CNNs that have a satisfactory accuracy. Theoretical analyses on the standard and adversarial error bounds naturally motivate the proposed neural architecture. Experimental results on real-world datasets and benchmark neural networks demonstrate the effectiveness of the proposed algorithm to balance the accuracy and robustness.
SP:77ed765e911a4e5f2bfba13cbd2403500a5d05e6,"This paper studies the problem of reward-free reinforcement learning with linear function approximation for episodic Markov decision processes (MDPs). In this setting, the agent interacts with the environment and collects samples without the reward in the exploration phase. In the planning phase the agent is given a specific reward function and uses samples collected from the Exploration phase to learn a good policy. The authors propose a new provably efficient algorithm called UCRL-RFE under the Linear Mixture MDP assumption, where the transition probability kernel of the MDP can be parameterized by a linear function over certain feature mappings defined on the triplet of state, action, and next state. They show that to obtain an $\epsilon$-optimal policy for arbitrary reward function, UCRLRFE needs to sample at most Õ(H5d2ε−2) episodes during the exploring phase. The upper bound matches the lower bound in terms of the dependence on $H$ and $d$. "
SP:28563ba0975f56ddb662cd46e85de78bb6024d36,"This paper proposes a method for forecasting future events in a data stream of events with seasonal patterns that evolve over time. The proposed method is based on the Shifting Seasonal Matrix Factorization (SSMF) approach, which can adaptively learn multiple seasonal patterns (called regimes) as well as switching between them. The method is evaluated on three real-world data streams and shows that the proposed method outperforms state-of-the-art baselines. "
SP:e4bb07033001be4d04695ef058f426d49fe440be,"This paper proposes a novel neural network architecture for solving the assignment problem. The proposed architecture is based on the idea of feature-weaving, where the network is stacked to model frequent communication between elements in a parameter-efficient way to solve the combinatorial problem of assignment. The experimental results show its impressive performance among the learning-based baselines. "
SP:8a559e21d45661eef427b310e5fe8488d5749137,"This paper studies the impact of various self-supervised learning proxy tasks on different architectures and threat models for 3D point clouds with adversarial training. Specifically, the authors study MLP-based (PointNet), convolution-based DGCNN, and transformer-based PCT architectures. Through extensive experimentation, they demonstrate that appropriate applications of self-Supervision can significantly enhance the robustness in 3d point cloud recognition, achieving considerable improvements compared to the standard adversarial learning baseline."
SP:657c5a1114c0d054b9e767d85990bbbb0492912d,This paper considers the problem of computing iterative projections of close-by points over submodular base polytopes. The authors propose a toolkit to speed up the computation of projections using both discrete and continuous perspectives. They also adapt the away-step Frank-Wolfe algorithm to use this information and enable early termination. The theoretical results show orders of magnitude reduction in runtime in preliminary computational experiments.
SP:8dae43d6b5cebb7ef6c39437d997b390c2380536,"This paper studies the problem of learning the natural parameters of a k-parameter minimal exponential family from i.i.d. samples in a computationally and statistically efficient manner. The main contribution of this paper is to propose a new estimator that is consistent as well as asymptotically normal under mild conditions. In particular, the authors provide finite sample guarantees to achieve an (`2) error of α in the parameter estimation with sample complexity O(poly(k/alpha) and computational complexity $O(\sqrt{k}/\alpha)$. The authors also show that, at the population level, their method can be viewed as the maximum likelihood estimation of a re-parametrization of the same class of exponential family."
SP:4f9ddb697e86356fb293ef34a69ca3702c4e8164,"This paper proposes a differentiable renderer for inverse graphics. The main contribution of the paper is to propose a hybrid renderer that combines rasterization and ray-tracing. The renderer is based on a combination of two differentiable methods: (1) a spherical basis function to approximate light transport, and (2) a path tracing based renderer. Experiments are conducted on synthetic and real data to demonstrate the effectiveness of the proposed method."
SP:6ac1c8556e7131939cc582f513bc9921470e1b09,"This paper proposes a differentiable training method that imposes implicit constraints to the shape of the probability map by minimizing the expectation of the localization error. To approximate the expectation, the authors introduce a continuous formulation of the output distribution and develop a new differentiable sampling process. They show that the proposed method can seamlessly replace the conventional soft-argmax operation on various localization tasks."
SP:478c05c90090f9d80b72ac352c488073b45a5d8b," graph contrastive learning (GCL) has emerged to learn generalizable representations from contrastive views. However, it is still in its infancy with two concerns: 1) changing the graph structure through data augmentation may mislead the message passing scheme, as such graph changing action deprives the intrinsic graph structural information, especially the directional structure in directed graphs, and 2) since GCL usually uses predefined contrastive view with hand-picking parameters, it does not take full advantage of the contrastive information provided by data augmentations, resulting in incomplete structure information for models learning. In this paper, the authors design a directed graph data augmentation method called Laplacian perturbation and theoretically analyze how it provides contrastive info without changing the directed graph structure. Moreover, they present a directed Graph Contrastive Learning framework, which dynamically learns from all possible contrastive images generated by Laplastic perturbations. Then, they train it using multi-task curriculum learning to progressively learn from multiple easy-to-difficult contrastive points. Experiments on various benchmarks reveal the dominance over the state-of-the-art approaches."
SP:85b383d2f722f7bff438840e423f5cb4c67d5980,"This paper proposes the Symbolic Interactive Language Grounding benchmark (SILG), which unifies a collection of diverse grounded language learning environments under a common interface. It consists of grid-world environments that require generalization to new dynamics, entities, and partially observed worlds (RTFM, Messenger, NetHack), as well as symbolic counterparts of visual worlds that require interpreting rich natural language with respect to complex scenes (ALFWorld, Touchdown). In addition, the authors propose the first shared model architecture for RL on these environments, and evaluate recent advances such as egocentric local convolution, recurrent state-tracking, entity-centric attention, and pretrained LM using SILG."
SP:23c8db56f59f778fe812a5dd161f7a1f21c3cdba,"This paper proposes a sparse version of the Vision Transformer network that is scalable and competitive with the largest dense networks. The authors propose an extension to the routing algorithm that can prioritize subsets of each input across the entire batch, leading to adaptive per-image compute. This allows V-MoE to trade-off performance and compute smoothly at test-time. Finally, the authors demonstrate the potential of the proposed network to scale vision models and train a 15B parameter model that attains 90.35% on ImageNet."
SP:c5235f41dfb8b5cc478f11c5d5e0ab0b8676871e,"This paper studies the problem of training narrow neural networks with fewer than n neurons when the activation is smooth. The authors prove that as long as the width m > 2n/d (where d is the input dimension), there exists at least one global minimizer with zero training loss. They also identify a nice local region with no local-min or saddle points and show that gradient descent can stay in this nice region. Finally, they consider a constrained optimization formulation where the feasible region is the nice region and prove that every KKT point is a nearly-global minimizer. "
SP:0be529f5254afd59dcfa6b34a359c7037e7a8323,"This paper proposes a continuous mean-covariance bandit (CMCB) model to explicitly take into account option correlation. In CMCB, the agent’s objective is to achieve the best trade-off between reward and risk, measured with option covariance. To capture different reward observation scenarios in practice, the authors consider three feedback settings, i.e., full-information, semi-information and full-bandit feedback. They propose novel algorithms with optimal regrets (within logarithmic factors), and provide matching lower bounds to validate their optimalities. The experimental results also demonstrate the superiority of their algorithms."
SP:472a90bb175b0286765c5a47b040e1a58f594a05,"This paper proposes a non-commutative extension of Lee-Seung’s Multiplicative Update (MMU) algorithm for computing Positive Semidefinite (PSD) factorization of a data matrix X. The PSD factorization task generalizes the Nonnegative Matrix Factorization (NMF) problem in which we seek a collection of r-dimensional non-negative vectors {ai} and {bj} satisfying the condition Xij = tr(AiBj) for all i \in [m, j\in [n]. The proposed algorithm ensures that updates remain PSD by congruence scaling with the matrix geometric mean of appropriate PSD matrices and it retains the simplicity of implementation."
SP:83abd6d149d88cc6e96cbc4d488e4fe9dc2a4fcb,This paper proposes a meta-learning approach for domain generalization (DG) by disentangling domain-specific and domain-invariant features in a unified framework. The key insight is to disentangle features in the latent space while jointly learning both domain invariant and domainspecific features. The proposed approach is evaluated on MNIST and Background-Colored-MNIST datasets.
SP:4191474c75e2fedf514f0f3001a67a047eb74c30,"This paper proposes a new method to improve the sample quality of generative models. The proposed method is based on a series of ablations. The authors show that the ablations improve sample quality on unconditional image synthesis and conditional image synthesis. They further show that using classifier guidance improves sample quality with a simple, compute-efficient method."
SP:fe3cab08596cde4c14ecf6fca8d0f95b02bab229,"This paper proposes a novel approach to improve few-shot learning by using out-of-distribution samples to improve the performance of the classifier. The key idea is to maximize the distance from prototypes to the out of distribution samples while minimizing that to the in-sample samples. The proposed approach is simple to implement, agnostic to feature extractors, lightweight without any additional cost for pre-training, and applicable to both inductive and transductive settings. Extensive experiments on various standard benchmarks demonstrate that the proposed method consistently improves the performance on pretrained networks."
SP:b1f65724926f136979829b7a6c870bc31f38f591,"This paper studies the problem of prioritized sampling in reinforcement learning. In particular, the authors propose ReMERN and ReMERT, two methods to compute the prioritization weight for the Bellman update. The main contribution of the paper is to provide theoretical justification for previous criteria of TD error, recentness, and corrective feedback. The authors also propose two new methods for the prioritisation weight, namely Re-MERN, which learns an error network, and Re-mERT, which exploits the temporal ordering of states. The proposed methods outperform previous methods in MuJoCo, Atari and Meta-World."
SP:601ebf30b3c6aa35fcef49633aa8eb0acd0f2c66,This paper studies the problem of sequential prediction with expert advice in a nonstationary environment with long-term memory guarantees in the sense of Bousquet and Warmuth [4]. The authors propose a linear-time algorithm that improves on the best known regret bounds [27]. This algorithm incorporates a relative entropy projection step. This projection is advantageous over previous weight-sharing approaches in that weight updates may come with implicit costs as in for example portfolio optimization.
SP:b2439973063e827b3cbe92306a2fdee3286b6b44,"This paper studies the problem of contextual linear bandits, where the learner is given a set of possible actions, and the goal is to learn a hidden value w. The authors propose two algorithms for this problem, which achieve regret O(d log T) and exp(O(dlog d), respectively. They also propose an algorithm for a variant of this problem where we are allowed to provide a list of several recommendations. Finally, the authors provide a novel algorithm for the case where we only learn the identity of the best action. "
SP:abe83c7e0bcf4829742609d709637e2f84d8a4d9,This paper proposes a method for composing machine learning operators into pipelines. The authors introduce a small set of orthogonal combinators to compose machinelearning operators into a pipeline. They also propose a translation scheme from pipelines and associated hyperparameter schemas to search spaces for AutoML optimizers. The paper presents an open-source sklearn-compatible AutoML library and evaluates it with a user study.
SP:0d7f1cae577ed598048b64617e85ca6bd5c6d7fa," meta-learning is a popular approach for learning neural network weights that generalize well from small datasets. This paper studies the effect of the meta-learned weights on the generalization performance of the network. Specifically, the authors propose to learn a weight initialization such that a small number of weight changes results in low generalization error. They show that the learning algorithm decides which weights to change, i.e., by learning where to learn. They find that patterned sparsity emerges from this process, with the pattern of sparsity varying on a problem-by-problem basis. This selective sparsity results in better generalization and less interference in a range of few-shot and continual learning problems. "
SP:05037e1850003a725a466b64d3e32aa2aed458fb,"This paper proposes a new method for multi-view learning based on additive Gaussian noise. The authors propose to use joint diagonalization after Multiset CCA to solve this problem. They show that the proposed method ShICA-J leads to improved results while being very fast to fit. They further propose to leverage non-Gaussianity of the components using a maximum-likelihood method, which is both more accurate and more costly. Finally, ShICA comes with a principled method for shared components estimation."
SP:44dd1faa1813c433fd7581d05cae3df440bfb93e,"This paper studies the problem of multi-agent reinforcement learning with human co-players in a two-player collaborative cooking simulator. The authors propose a novel approach called Fictitious Co-Play (FCP) to train agents that collaborate well with human partners without using human data. FCP is based on the idea that the best response to a population of self-play agents and their past checkpoints taken throughout training should be used to train the agent partner. They show that FCP outperforms SP, PP, and BCP when paired with novel agent and human partners. "
SP:21c84bd720b1e90ea0f88fbf8fd24dbcb49b547c,"This paper proposes FACMAC, a new multi-agent actor-critic method for cooperative multiagent reinforcement learning in both discrete and continuous action spaces. Unlike MADDPG, FACMAC learns a centralised but factored critic, which combines per-agent utilities into the joint action-value function via a non-linear monotonic function, as in QMIX. The proposed method also employs a nonmonotonic factorisation and empirically demonstrate that its increased representational capacity allows it to solve some tasks that cannot be solved with monolithic, or monotonically factored critics."
SP:1c8351b8a6cdf1212840388e19a596729b3bfda4,"This paper proposes a novel Hopfield network architecture for long-term memory. The key-value network is based on the three-factor plasticity rules. The network is trained using meta-learning. The proposed network is tested on auto-associative memory, continual recall, hetero-association, and sequence learning tasks. "
SP:7ad6da2c63859d64970e9b35326e9ceab48add47,"This paper studies the problem of pairwise learning, where the loss function depends on a pair of instances. The authors propose stochastic and online gradient descent methods to solve the problem. The main contribution of this paper is to develop novel stability results, optimization, and generalization error bounds for both convex and nonconvex as well as both smooth and nonsmooth problems. They also introduce novel techniques to decouple the dependency of models and the previous instance in both the optimization and the generalization analysis."
SP:cb11dacc930d71a616ee2fbe4acfae030f9dca59,"This paper proposes REDO, a class-agnostic framework to REconstruct the Dynamic Objects from RGBD or calibrated videos. Compared to prior work, the problem setting is more realistic yet more challenging for three reasons: 1) due to occlusion or camera settings an object of interest may never be entirely visible, but the aim is to reconstruct the complete shape; 2) the authors aim to handle different object dynamics including rigid motion, non-rigid motion, and articulation; 3) they aim to reconstruct different categories of objects with one unified framework. To address these challenges, the authors develop two novel modules. First, they introduce a canonical 4D implicit function which is pixel-aligned with aggregated temporal visual cues. Second, they develop a 4D transformation module which captures object dynamics to support temporal propagation and aggregation. They study the efficacy of REDO in extensive experiments on synthetic RGBD video datasets SAIL-VOS 3D and DeformingThings4D++, and on real-world video data 3DPW."
SP:8ae97752e74b4395774575009031abcb6ba5cea7,This paper provides a non-asymptotic analysis of linear stochastic approximation (LSA) algorithms with fixed stepsize. The analysis is based on new results regarding moments and high probability bounds for products of matrices which are shown to be tight. The authors also establish polynomial concentration bounds with order depending on the stepsize and show that no Gaussian or exponential bounds can hold.
SP:86c1e937755e35efafecc09dfe2606ffb1653a41,"This paper extends the options framework for temporal abstraction in reinforcement learning from discounted Markov decision processes (MDPs) to average-reward MDPs. The authors propose general convergent off-policy inter-option learning algorithms, intra-option algorithms for learning values and models, as well as sample-based planning variants of their learning algorithms. The algorithms and convergence proofs extend those recently developed by Wan, Naik, and Sutton. The proposed algorithms are evaluated on a continuing version of the Four-Room domain."
SP:7e4e1e20e7c253d02c6ae58457fb30029f130f0c,"This paper proposes an auxiliary self-supervised task for visual transformers (VTs) to learn spatial relations within an image. The proposed task encourages the VTs to learn the spatial relations in an image and makes the training much more robust when training data is scarce. This task is used jointly with the standard (supervised) training and it does not depend on specific architectural choices, thus it can be easily plugged in the existing VTs. Experiments show that the proposed task can improve (sometimes dramatically) the final accuracy of the proposed method."
SP:0132ef17585e293b23e9dc45189c0989d829b52a,"This paper proposes a new method for label-free alignment of hierarchical datasets using hyperbolic Procrustes analysis (HPA). HPA consists of three components: translation, scaling, and rotation based on the Riemannian geometry of the Lorentz model. The authors analyze the proposed components, highlighting their useful properties for alignment. The efficacy of HPA, its theoretical properties, stability and computational efficiency are demonstrated in simulations. In addition, HPA is demonstrated on three batch correction tasks involving gene expression and mass cytometry data."
SP:3580ac64f09e3021de5d4c92411bcc0f3c5d10f3,"This paper studies the trade-off between accuracy for a population of interest (“sum query”) vs. accuracy for its component sub-populations (‘point queries’). Compared to differentially private query answering systems that are not required to produce microdata, accuracy can degrade by a logarithmic factor. The authors show lower bounds for pure, approximate, and concentrated differential privacy. They propose mitigation strategies and create a collection of benchmark datasets that can be used for public study."
SP:c0e64dc8acfaed3e4d7745af12fd34003d0e5017,"This paper proposes a method to train a path-planner and an RL agent on a curriculum of tree-structured sub-tasks. The planner recursively decomposes a long-horizon task to a tree of sub-task sequences in a top-down manner, whose layers construct coarse-to-fine sub- task sequences as plans to complete the original task. The planning policy is trained to minimize the RL agent’s cost of completing the sequence in each layer from top to bottom layers, which gradually increases the sub- tasks and thus forms an easy to hard curriculum for the planner. Next, a bottom-up traversal of the tree trains RL agent from easier sub-Tasks with denser rewards on bottom layers to harder ones on top layers and collects its cost to train the planner in the next episode. CO-PILOT repeats this mutual training for multiple episodes before switching to a new task."
SP:9911693a04a300b5a93634fb0267ef83e5489d77,"This paper proposes a Bayesian framework for generating local explanations along with their associated uncertainty. The proposed framework is based on Bayesian versions of LIME and KernelSHAP which output credible intervals for the feature importances. The resulting explanations are highly consistent and stable. The authors carry out a detailed theoretical analysis that leverages the aforementioned uncertainty to estimate how many perturbations to sample, and how to sample for faster convergence."
SP:5efb4b81bd37c70640e8768e9dfb5bba14a0cfb8,This paper studies the problem of unordered heavy tails in Adder Neural Networks (ANNs) and proposes a novel method to tackle the problem. The authors propose to use an angle-based constraint on the distribution parameters to encourage high diversity of tails. Experiments on several benchmarks and comparison with other distributions demonstrate the effectiveness of proposed approach. 
SP:cbccb65457564992d534504c0d060da44cafce8c,"This paper studies the phenomenon of gradient starvation in over-parameterized neural networks. Gradient starvation occurs when the cross-entropy loss is minimized by capturing only a subset of features relevant for the task, despite the presence of other predictive features that fail to be discovered. This paper provides a theoretical explanation for the emergence of such feature imbalances in neural networks using tools from Dynamical Systems theory. The authors identify simple properties of learning dynamics during gradient descent that lead to this imbalance, and prove that such a situation can be expected given certain statistical structure in training data. Based on their proposed formalism, the authors develop a novel but simple regularization method aimed at decoupling feature learning dynamics, improving accuracy and robustness in cases hindered by gradient starvation."
SP:8f6fe37cb0a332b66e10cc00261a44622841c8c6,"This paper studies the relationship between humans and AI agents in Hanabi, a cooperative card game with both rule-based and learning-based agents. In addition to the game score, the authors also quantify subjective measures of the human’s perceived performance, teamwork, interpretability, trust, and overall preference of AI teammate. They find that humans have a clear preference toward a rule based AI teammate (SmartBot) over a state-of-the-art learning based AI agent (Other-Play) across nearly all subjective metrics, and generally view the learning based agent negatively. This result has implications for future AI design and reinforcement learning benchmarking."
SP:2a05e333fc1a14057515ef3addde9a40152373db,"This paper proposes a novel approach for visual question generation (VQG) based on double-hints based VQG, which can be cast as a weakly supervised learning problem with noises. The key rationale is that the salient visual regions of interest can be viewed as a constraint to improve the generation procedure for producing high-quality questions. The proposed method outperforms the state-of-the-art approaches by a large margin on two benchmark datasets."
SP:15756d6ef47b39ded404acea2135c93bd5ee1062,"This paper proposes Generalized Data Weighting (GDW) to simultaneously mitigate label noise and class imbalance by manipulating gradients at the class level. Specifically, GDW unrolls the loss gradient to class-level gradients by the chain rule and reweights the flow of each gradient separately. Extensive experiments in various settings verify the effectiveness of GDW."
SP:7a8f56a01bec51ebf70d9ff689005a62cccfe5c6,"This paper proposes a novel task to learn the meaning of spatio-temporal descriptions of behavioral traces of an embodied agent. This is achieved by training a truth function that predicts if a description matches a given history of observations. The descriptions involve time-extended predicates in past and present tense as well as spatiotemporal references to objects in the scene. To study the role of architectural biases in this task, the authors train several models including multimodal Transformer architectures. The latter implement different attention computations between words and objects across space and time. They test models on two classes of generalization: 1) generalization to randomly held-out sentences; 2) generalisation to grammar primitives."
SP:3d4a9d439bc84c3b0e6600f6985a23bdf95cd67f,"This paper proposes Prototypical Cross-Attention Network (PCAN) for online multiple object tracking and segmentation. PCAN first distills a space-time memory into a set of prototypes and then employs cross-attention to retrieve rich information from the past frames. To segment each object, PCAN adopts a prototypical appearance module to learn the contrastive foreground and background prototypes, which are then propagated over time. Extensive experiments demonstrate that PCAN outperforms current video instance tracking and video segmentation competition winners on both Youtube-VIS and BDD100K datasets."
SP:1175ad16382b349ab1a39895150172d266abe571,"This paper studies the effect of gradient flow on the approximation of gradient descent in deep learning. The authors show that gradient flow trajectories are well approximated by gradient descent over deep neural networks with homogeneous activations. They show that the gradient flow trajectory has favorable curvature, suggesting that it can be approximated with gradient descent. They prove that gradient descent with conventional step size is indeed close to gradient flow over deep linear neural networks. "
SP:b8412e9ce82ce92125fe7cd3aff7bea8b906d16e,"This paper considers a stochastic multi-armed bandit problem with delayed impact of actions. In this setting, actions taken in the past impact the arm rewards in the subsequent future. This paper generalizes the bandit setting to encode the dependency of this “bias” due to the action history during learning. The goal is to maximize the collected utilities over time while taking into account the dynamics created by the delayed impacts of historical actions. The authors propose an algorithm that achieves a regret of Õ(KT 2/3) and show a matching regret lower bound of ⌦(KT2/3), where K is the number of arms and T is the learning horizon."
SP:9c1d678dff5f609197dc3cfb67b841827f4a439a,This paper proposes an end-to-end video instance segmentation method for video segmentation based on transformers. The proposed method is based on the idea of using memory tokens to encode the context within the input clip. The key idea is to use the memory tokens as a means of conveying information as well as summarizing each frame scene. The features of each frame are enriched and correlated with other frames through exchange of information between the precisely encoded memory tokens. Experiments show that the proposed method achieves state-of-the-art performance (AP 42.6 on YouTube-VIS 2019 val set using the offline inference) while having a considerably fast runtime (89.4 FPS).
SP:6c922eaa358f6fb9771690b1240e4f6f08a35b69,"This paper proposes a method for graph embedding based on residual2vec, which is based on the idea that random walks can be biased due to the structural properties of graphs. Specifically, the authors propose to use random graphs in the embedding process to debias the bias of random walks. The authors show that the proposed method improves link prediction and clustering performance and allows to explicitly model salient structural properties in graph embeddings."
SP:851eac96135b577a5014166edcb43db6a190cf4b,"This paper studies the problem of estimating the power sum functional of a discrete distribution under local differential privacy. In this setting, the initial data x1, xn are supposed i.i.d. and distributed according to an unknown discrete distribution p = (p1,..., pK). Only α-locally differentially private (LDP) samples z1, zn are publicly available, where the term ‘local’ means that each zi is produced using one individual attribute xi. The paper shows the behavior of the quadratic risk for estimating the functionals of the discrete distribution as a function of K, n and α. In the non-interactive case, the paper shows two plug-in type estimators that are similar to the MLE analyzed by Jiao et al. in the multinomial model. However, due to the privacy constraint the rates are slower and similar to those obtained in the Gaussian model by Collier et al [9]."
SP:a0408b54f88a26479f33f36bb27e0a675f637ccd,"This paper studies the problem of online multiclass classification in the setting where the learner’s feedback is determined by an arbitrary directed graph. The authors prove a surrogate regret bound that holds both in expectation and with high probability for a large class of surrogate losses. In the full information case, they show that GAPPLETRON achieves a constant surrogate regret of order BK. They also prove a general lower bound of order max {BK, \sqrt{T} } showing that their upper bound is not significantly improvable. Experiments on synthetic data show that the proposed algorithm is competitive with known baselines."
SP:490262589efce6fb10b913431ec6db8d4e5b2dec,This paper studies the problem of explainable clustering in the setting where each node in the decision tree splits the data points with a threshold cut in a single dimension (feature) and each of the k leaves corresponds to a cluster. The authors propose an algorithm that achieves a lower bound of O(log k) for the k-medians objective and O(k log k) lower bound for k-means objective. This improves over the previous best upper bounds of $O(k)$ and $O(\sqrt{k})$ for the two objectives. The algorithm is remarkably simple and the algorithm is oblivious to the number of data points.
SP:6a9e47be710ddaf386bffc54d003d7dc2b67fdc3,"This paper proposes a multilingual pre-trained language model (PrLM) that supports both explicit universal dependency parsing and implicit language modeling. Syntax in terms of universal dependency parse serves as not only pre-training objective but also learned representation in the model. The model outperforms two popular multilingual PrLM, multilingual-BERT and XLM-R, on cross-lingual natural language understanding (NLU) benchmarks and linguistic structure parsing datasets."
SP:94f4b65214a648cbc84f13beba45a825e2e9901a," problem. This paper proposes a new transformer architecture for solving vehicle routing problems (VRPs). The key idea is to learn embeddings for node and positional features separately, instead of fusing them together as done in existing ones, so as to avoid potential noises and incompatible correlations. The positional features are embedded through a novel cyclic positional encoding (CPE) method to allow Transformer to effectively capture the circularity and symmetry of VRP solutions (i.e., cyclic sequences). The authors train DACT using Proximal Policy Optimization and design a curriculum learning strategy for better sample efficiency. They apply DACT to solve the traveling salesman problem (TSP) and capacitated vehicle routing problem (CVRP). "
SP:e5c8680d8da9e7548fcb9bb5c073848eb80e1dd0,"This paper proposes a method to compute the exact Bayes error of generative models learned using normalizing flows. The method relies on the invertible property of the normalizing flow, which states that the error is invariant under invertibility. The authors show that they can compute this exact error by computing it for Gaussian base distributions using Holmes-Diaconis-Ross integration. Moreover, they show that by varying the temperature of the learned flow models, they can generate synthetic datasets that closely resemble standard benchmark datasets, but with almost any desired Bayes errors. They use their approach to conduct a thorough investigation of state-of-the-art classification models, and find that in some — but not all — cases, these models are capable of obtaining accuracy very near optimal."
SP:2896679f0472522bc3334178cd7574494cf12b7b,"This paper proposes Grad Init, a heuristic-based method for initializing neural networks. Grad Init is based on a simple heuristic: the norm of each network layer is adjusted so that a single step of SGD or Adam with prescribed hyperparameters results in the smallest possible loss value. This adjustment is done by introducing a scalar multiplier variable in front of each parameter block, and then optimizing these variables using a simple numerical scheme. Gradinit accelerates the convergence and test performance of many convolutional architectures, both with or without skip connections, and even without normalization layers. It also improves the stability of the original Transformer architecture for machine translation."
SP:f69731403592fa5bdd4ca327708582d615aa131c,"This paper proposes a new approach for estimating disease progression using longitudinal data using linear mixed-effect models. The proposed approach is based on learning the push-forward of the Euclidean metric by a diffeomorphism, which is estimated iteratively as the composition of radial basis functions belonging to a reproducible kernel Hilbert space. The authors show that the proposed approach improves the forecasting of imaging and clinical biomarkers in the Alzheimer’s Disease Neuroimaging Initiative (ADNI) cohort."
SP:438e906f52c4c0538956b51a2270b3ac498b27a8,"This paper proposes a routing-by-memory mechanism for existing CNN architectures. In each stage of the network, they introduce parallel Procedural Units (PUs). A PU consists of a memory head and a procedure. For an intermediate feature, we search its closest memory and forward it to the corresponding procedure in both training and testing. In this way, different procedures are tailored to different features and therefore tackle them better."
SP:d240173080cd3647dbaa5173a6422396f226775b,"This paper studies the equivariance of polynomial functions under certain symmetries of physical laws. The authors show that it is simple to parameterize polynomials that are equivariant under these symmetry-enforcing constraints. The key observation is that nonlinear O(d)-equivariant functions can be universally expressed in terms of a lightweight collection of scalars -- scalar products and scalar contractions of the scalar, vector, and tensor inputs. The paper provides numerical experiments to demonstrate the effectiveness of the proposed method."
SP:72c0f47566904deb27d8157da30807ec1d6b5685, bbox regression is a fundamental problem in computer vision. The paper proposes a new family of IoU-based losses that have a power IoU term and an additional power regularization term with a single power parameter. The authors analyze properties such as order preservingness and loss/gradient reweighting. Experiments on multiple object detection benchmarks and models demonstrate the effectiveness of the proposed loss function.
SP:397125177d7007316d67194ec00d5dc57b44ac79,"This paper studies the problem of imitation learning in a Markov decision process (MDP) setting where the reward function is not given, but demonstrations from experts are available. The main contribution of this paper is to propose a method to learn a policy that is distributionally robust against noisy demonstrations based on an adversarial construction. The proposed method is based on the idea of Maximum Entropy Inverse Reinforcement Learning (MIRL) and can be seen as a framework that maximizes a generalized concept of entropy. The authors develop a novel approach to transform the objective function into a convex optimization problem over a polynomial number of variables for a class of loss functions that are additive over state and action spaces. Experiments on synthetic data and a highway driving environment show the effectiveness of the proposed method."
SP:58f220bbbed8d3e0633b408fca3b6838c4ad323d,"This paper proposes a general post-processing algorithm for individual fairness (IF) in the setting where the learner only has access to the predictions of the original model and a similarity graph between individuals guiding the desired fairness constraints. The proposed algorithm is a graph smoothing problem corresponding to graph Laplacian regularization that preserves the desired “treat similar individuals similarly” interpretation. The theoretical results demonstrate the connection of the new objective function to a local relaxation of individual fairness. Empirically, the proposed algorithm correct individual biases in large-scale NLP models such as BERT while preserving accuracy."
SP:ef791aa29decd839e7e583c9d1f71e8309ca87ef,"This paper proposes a novel approach for the cross-domain Text-to-SQL task. The key idea is to use the graph structure to provide a unified encoding model for both the natural language question and the database schema. Based on the proposed unified modeling, a structure-aware aggregation method is further devised to learn the mapping between the question-graph and the query-schema-graph. The proposed approach is evaluated on the Spider benchmark and achieves 3rd place."
SP:a2fa25a4539a38af61a0993f65ecc14339f26c2e,"This paper studies the problem of learning stochastic computations graphs with multiple sequential discrete components. The authors show that it is challenging to optimize the parameters of these models, mainly due to small gradients and local minima. They then propose two new strategies to overcome these challenges. First, they show that increasing the scale parameter of the Gumbel noise perturbations during training improves the learning behavior. Second, they propose dropout residual connections specifically tailored to stochastically, discrete-continuous computation graphs. "
SP:bb3ec363e90269db4a2ba99d8107cb56f86e68f0,"This paper studies the robustness of Bayesian neural networks (BNNs) to covariate shift. The authors show that BNNs with high-fidelity approximate inference via full-batch Hamiltonian Monte Carlo achieve poor generalization under covariances shift. They also show that the same issue does not affect many approximate inference procedures, or classical maximum a-posteriori (MAP) training. Finally, the authors propose novel priors that improve BNN robustness to many sources of covariates shift."
SP:f86ec7042e9b73ae071704a6d3ed17d7e3da1b75,"This paper studies the problem of few-shot meta-learning in the out-of-distribution (OOD) setting, where the training and test tasks are not sampled from the same underlying task distribution. The authors identify that most existing few shot classification benchmarks instead reflect OOD evaluation, as they use disjoint sets of train (base) and test (novel) classes for task generation. This discrepancy is problematic because meta-learners that perform better on existing OOD datasets may perform significantly worse in the ID setting. In addition, in the OOD setting, even though current FSL benchmarks seem befitting, the authors highlight concerns in 1) reliably performing model selection and 2) consistently comparing the performance of different methods. To address these concerns, they provide suggestions on how to construct FSL benchmark to allow for ID evaluation as well as more reliable OOD evaluations."
SP:371f77148b4f00a929f7c118b1bb7c5a6238d264,"This paper studies the problem of open rule induction in the context of language model (LM) based rule generation. The authors argue that the current LM-based methods are “learning rules from rules”, which limits these methods to only produce “canned” rules whose patterns are constrained by the annotated rules, while discarding the rich expressive power of LMs for free text. Therefore, in this paper, the authors propose the open rules induction problem, which aims to induce open rules utilizing the knowledge in LMs. Besides, they propose the Orion (open rule induction) system to automatically mine open rules from LMs without supervision of annotated rule. They conducted extensive experiments to verify the quality and quantity of the inducted open rules."
SP:8be2e0ea4a83fe32a4859f456007a829e5e9270a,This paper proposes Implicit Constraint Q-learning (ICQ) for multi-agent offline RL. ICQ is based on the idea of using implicit constraints to reduce the extrapolation error of the agent’s Q-value function. The proposed method is evaluated on the StarCraft II offline game.  
SP:1939b24b68970c33ca16ce238deed257f76d009e,This paper proposes a method to train adversarial examples that are robust to non-uniform perturbations. The proposed method is based on the fact that the features of the data distribution are correlated with the importance of the features. The authors show that the proposed approach is more robust to real-world attacks than uniform perturbation. 
SP:417b30930b245667d777e5d90ee80dd41546760e,"This paper studies generalized self-concordant loss functions (GSC) and shows that Tikhonov regularization can be used to improve the convergence rate of the excess risk for GSCs. The main contribution of the paper is to show that the proposed method can achieve faster convergence rates than the existing methods. In particular, the authors propose an iterated version of the iterated regularization scheme, which is related to the proximal point method in optimization and overcomes the limitation of the classical Tikhanov regularisation."
SP:1caeee4f00b52fe356ff4e5dd004d0203e838370," of the Deformable Butterfly (DeBut) layer. The DeBut layer is based on the butterfly matrices and can be applied to various input-output dimensions. The paper proposes to use DeBut as a drop-in replacement of standard fully connected and convolutional layers and demonstrate its superiority in homogenizing a neural network and rendering it favorable properties such as light weight and low inference complexity, without compromising accuracy. "
SP:d345ce1d7afc367ee1a9fb68d50ff1b2219f02cb,. This paper proposes MetA Reusable Knowledge (MARK) to address the problem of catastrophic forgetting. The proposed method is based on a common knowledge base (KB) that is used to learn new tasks and also enriched with new knowledge as the model learns new tasks. A metalearning approach is proposed to incrementally enrich the KB to foster weight reusability among tasks and a set of trainable masks provides the key mechanism to selectively choose from the KB relevant weights to solve each task. 
SP:722c52467e384058f8fdffa254d0e8db47440a64,This paper proposes a data-driven framework for scheduling primal heuristics in exact MIP solvers for mixed-integer programming (MIP). The authors propose to learn a schedule of primal heuristic that collectively find many solutions at minimal cost. They propose an efficient algorithm for computing such a schedule and show that it can reduce the average primal integral by up to 49% on two classes of challenging MIP problems.
SP:5a21f0a49731dcb1d68deb06a75138e8e9d514d5,"This paper studies the problem of reinforcement learning in the setting where the learner receives binary feedback only once at the end of an episode. In this setting, the trajectory labels are generated by an unknown parametric model, and the authors provide a statistically and computationally efficient algorithm that achieves sublinear regret. "
SP:e66bd9582058ba0f6091bb1042ce2ecfdaae1515,"This paper proposes a novel edge representation learning framework based on Dual Hypergraph Transformation (DHT), which transforms the edges of a graph into the nodes of a hypergraph. This dual hypergraph construction allows us to apply message-passing techniques for node representations to edges. After obtaining edge representations from the hypergraphs, we then cluster or drop edges to obtain holistic graph-level edge representations. The proposed method is validated on several graph datasets for graph representation and generation performance, on which our method largely outperforms existing graph representation learning methods. Moreover, the proposed method also outperforms state-of-the-art graph pooling methods on graph classification."
SP:e398873e29b05176e1d52dc6f86a59a4f405e6fd,"This paper studies the sufficiency of mutual information maximization (MI) based objectives for learning representations of data in the context of reinforcement learning. In particular, the authors study two popular MI-based objectives and show that two of them can yield insufficient representations given mild and common assumptions on the structure of the MDP. They corroborate their theoretical results with empirical experiments on a simulated game environment with visual observations."
SP:50181f740910195d3a50dd7d7f8cbb1c476d730b," for 3D object semantic analysis. This paper proposes Sparse Steerable Convolution (SS-Conv) to address the shortcoming of steerable convolution with sparse tensors, while strictly preserving the property of SE(3)-equivariance. The proposed pipeline based on SS-conv outperforms existing methods on almost all the metrics evaluated by the three tasks. Ablation studies also show the superiority of our SS-conv over alternative convolutions in terms of both accuracy and efficiency."
SP:d746bfb200577c980d92727bb0b1a3c23e7bfdc5,"This paper proposes a dynamic token sparsification framework to prune redundant tokens progressively and dynamically based on the input. Specifically, a lightweight prediction module is added to different layers to estimate the importance score of each token given the current features. To optimize the prediction module in an end-to-end manner, they propose an attention masking strategy to differentiably prune a token by blocking its interactions with other tokens. By hierarchically pruning 66% of the input tokens, their method greatly reduces 31% to 37% FLOPs and improves the throughput by over 40%."
SP:d0b6cde42b1cba5e6e3c7c5131426fd84adbd3d7,"This paper studies the problem of inference on the conditional mean E [Y |X] under the assumption that the features X are continuous. In the continuous setting, the authors show that any confidence interval for E [X |Y] must have non-vanishing width, even as sample size tends to infinity. At the other extreme, if X takes only a small number of possible values, then inference on E is trivial to achieve. The authors study the problem in settings in between these two extremes. They find that there are several distinct regimes in between the finite setting and continuous setting where vanishing-width confidence intervals are achievable if and only if the effective support size of the distribution of X is smaller than the square of the sample size."
SP:123952325765c040c3078fc7dca2b6d370e55590,"This paper proposes Representation Neutralization for Fairness (RNF) to reduce the discrimination of DNN models by only debiasing the classification head, even with biased representations as inputs. To this end, the authors leverage samples with the same ground-truth label but different sensitive attributes, and use their neutralized representations to train the class-specific classification head of the DNN model. To address low-resource settings with no access to sensitive attribute annotations, they leverage a bias-amplified model to generate proxy annotations for sensitive attributes. Experimental results on several benchmark datasets demonstrate the effectiveness of the proposed method."
SP:210eb2c811f966bb1ac53932cacabbad9bb608fe,"This paper proposes a new type of convolutional layer that takes advantage of Bessel functions, well known in physics, to build Bessel-CNNs (B-CNN) that are invariant to all the continuous set of possible rotation angles by design. The proposed B-CNN is based on the Bessel function, which is well-known in physics and can be used for image analysis. "
SP:ee51ecbd476d5b65903c942a62be89ff5d91698b,"This paper proposes a new large-scale solver for kernel ridge regression. The proposed method combines partitioning with random projections and iterative optimization to reduce space and time complexity while provably maintaining the same statistical accuracy. In particular, constructing suitable partitions directly in the feature space rather than in the input space promotes orthogonality between the local estimators, thus ensuring that key quantities such as local effective dimension and bias remain under control. The experimental results demonstrate the effectiveness of the proposed method."
SP:1f096d6fabd5b1fde43d06c552d46d87cd35cb4a,"This paper proposes a method for learning to communicate among agents via discrete tokens in reinforcement learning. The proposed method is inspired by word embedding techniques from natural language processing. The authors show that the proposed method outperforms one-hot communication in a wide range of scenarios. They also show that their method can learn to cluster tokens in semantically-meaningful ways, allowing them to communicate in noisy environments where other techniques fail."
SP:8630ccc627534f9033bced04e2137a897ffef701,".  The paper proposes a new architecture called CoAtNets, which is a hybrid model of deep convolutional and self-attention networks. The main contribution of the paper is to propose to combine the strengths from both architectures. The authors show that the proposed architecture can achieve state-of-the-art performance under different resource constraints across various datasets. "
SP:d3ecbeeffa5ab365743ba8653c6739f24742ee31,"This paper proposes a new second-order oracle bound for the expected risk of a weighted majority vote. The bound is based on a novel parametric form of the Chebyshev-Cantelli inequality, which is amenable to efficient minimization. The authors also derive a new concentration of measure inequality which combines PAC-Bayesian bounding with Bennett’s inequality. They provide an empirical evaluation demonstrating the new bounds can improve on the work of Masegosa et al."
SP:5bac542a6532d43cf100e085398b4a4783719814,"This paper proposes a weakly supervised audio-visual video parsing method. The proposed method exploits both the common and diverse event semantics across videos to identify audio or visual events. In addition, the proposed method explores event co-occurrence across audio, visual, and audio- visual streams to localize segments of target events while excluding irrelevant ones. The discovered supervisory signals across different videos and modalities can greatly facilitate the training with only video-level annotations."
SP:8fd6a03c1794afa524328d45f4232eacf6f86693,"This paper proposes QuPeD, a federated learning algorithm for learning quantized and personalized models. The authors propose to learn quantized models through a relaxed optimization problem, where quantization values are also optimized over. For personalization, they formulate a compressed personalization framework by introducing knowledge distillation loss for local client objectives collaborating through a global model. They develop an alternating proximal gradient update for solving this compressed personalisation problem, and analyze its convergence properties. Numerically, the proposed algorithm outperforms FedAvg and local training of clients in various heterogeneous settings."
SP:fca8b4f1e765cf1724a37f0ae9a7dac1cb79c8b1,"This paper proposes a novel framework for constrained clustering that is intuitive, interpretable, and can be trained efficiently in the framework of stochastic gradient variational inference (SGVI). The proposed model (DC-GMM) uncovers the underlying distribution of data conditioned on prior clustering preferences, expressed as pairwise constraints. These constraints guide the clustering process towards a desirable partition of the data by indicating which samples should or should not belong to the same cluster. The proposed method shows superior clustering performances and robustness compared to state-of-the-art deep constrained clusters methods on a wide range of data sets."
SP:84379c0c881b7390ecc22fb398edfaf66d1af1ff,"This paper proposes a near input-sparsity time approximation algorithm for the Neural Tangent Kernel (NTK) by sketching the polynomial expansions of arc-cosine kernels. The sketch for the convolutional version of NTK can transform any image using a linear runtime in the number of pixels. Furthermore, the authors prove a spectral approximation guarantee for the NTK matrix, by combining random features (based on leverage score sampling) of the arc-Cosine kernels with a sketching algorithm. "
SP:fa2668083ff3bb592c29a4c6822ae96ff54d0dbe,This paper proposes a multi-person 3D motion trajectory prediction method based on multi-range Transformers. The proposed method consists of a local-range encoder for individual motion and a global-range decoder for social interactions. The model is evaluated on long-term motion prediction and generates diverse social interactions by automatically dividing the persons into different interaction groups.
SP:0a0e07af37c8fe8580639b1df62d27b6f63f8dee,"This paper proposes a new approach for long-horizon planning problems that uses a generative model to predict the unobserved parts of the world and then synthesizes a program based on samples from this model in a way that is robust to its uncertainty. The authors show that their approach significantly outperforms non-program-guided approaches on a set of challenging benchmarks, including a 2D Minecraft-inspired environment where the agent must complete a complex sequence of subtasks to achieve its goal."
SP:5bb42b178b0d27da271bfa60e633fdac718638c4,"This paper studies the problem of causal imitation learning in sequential settings, where the imitator must make multiple decisions per episode. The authors develop a graphical criterion that is necessary and sufficient for determining the feasibility of causal imitation learning. Finally, they provide an efficient algorithm for determining imitability and corroborate their theory with simulations."
SP:85bd81f0c5b6ccbc421ebbaf6f5c72164bc70b7f,"This paper proposes a slot-wise, object-based transition model that decomposes a scene into objects, aligns them (with respect to slot-level object memory) to maintain a consistent order across time, and predicts how those objects evolve over successive frames. The model is trained end-to-end without supervision using transition losses at the level of the object-structured representation rather than pixels. The authors show that the combination of an objectlevel loss and correct object alignment over time enables the model to outperform a state-of-the-art baseline, and allows it to deal well with object occlusion and re-appearance in partially observable environments."
SP:f32eddbb5c33a8422c075579ff08aa9833338d44,"This paper studies the problem of using adaptively collected data to minimize the average of a loss function over a hypothesis class and provides first-of-their-kind generalization guarantees and fast convergence rates. The main contribution of the paper is a new maximal inequality that carefully leverages the importance sampling structure to obtain rates with the good dependence on the exploration rate in the data. For regression, the authors provide fast rates that leverage the strong convexity of squared-error loss. For policy learning, the regret guarantees close an open gap in the existing literature whenever exploration decays to zero, as is the case for bandit-collected data."
SP:f549a0c231b71bae0acbed6e3afb41890ee89cd9,"This paper proposes a novel reweighting strategy for kernel-reweighted regression by reparametrizing the sample weights using a doubly non-negative matrix. The authors show that when the weighting matrix is confined in an uncertainty set using either the log-determinant divergence or the Bures-Wasserstein distance, they show that the adversarially reweighted estimate can be solved efficiently using first-order methods. Numerical experiments on several datasets demonstrate the effectiveness of the proposed method."
SP:fe12e13602925b9400fd596a987755beb10aa3d1,This paper proposes a novel estimator for categorical gradient estimators based on importance sampling and statistical couplings. The main idea is to reparameterize categorical variables as sequences of binary variables and Rao-Blackwellization. Experiments show that the proposed estimator outperforms the state-of-the-art in terms of performance. 
SP:e16fdf963ec2f9c0d79fa404e47e7862a5d6e922,This paper proposes a new approach for neural architecture search (NAS) based on weak predictors. The proposed approach is based on the idea that the probability of finding the best architecture is increasing as the number of predictors increases. The authors propose to use a set of weaker predictors to guide the search path towards the high-performance sub-space through a series of coarse-to-fine iterations. The experiments show that the proposed approach outperforms the state-of-the-art (SOTA) predictor-based NAS methods. 
SP:8f74abb04037ba2e59dcf8320dc555b149f68ed8,"This paper proposes a method for learning a global coordinate system of latent codes that can be used to predict future states. The method is based on the Entropic Desired Dynamics for Intrinsic ConTrol (EDDICT) framework, which assumes a fixed additive latent dynamics. EDDICT is shown to be tractable and interpretable. Experiments are conducted on Montezuma’s Revenge, where the proposed method outperforms other state-of-the-art methods."
SP:c731a78c3e7f98ccd0253b51a0d42bf8deeb71f9,This paper proposes a novel approach to generate pharmacochemically acceptable molecules with large docking scores. The authors propose a fragment-based generative RL with Explorative Experience replay for Drug design (FREED) that constrains the generated molecules to a realistic and qualified chemical space and effectively explores the space to find drugs by coupling the fragment generation method and a novel error-prioritized experience replay (PER). The authors show that their model performs well on both de novo and scaffold-based schemes and achieves state-of-the-art performance on two of three targets in terms of the docking scores of the generated molecule.
SP:b938bca513e7de1231212064caf8877a78d8b612,This paper studies the problem of learning directed acyclic graphical models from observational data in general settings without specific distributional assumptions. The main contribution of the paper is to study the sample complexity of learning the graph ensembles. The authors show that a simple forward greedy search algorithm (i.e. without a backward pruning phase) suffices to learn the Markov boundary of each node in the graph. This is then applied to the entire graph under a novel identifiability condition that generalizes existing conditions from the literature. They also establish finite-sample guarantees for recovering Markov boundaries from data. 
SP:af08109d4c45dc9401efb0e63c22167e9da28adb,"This paper considers the setting where each user has a single sample and the privacy protection is enforced at the level of each user’s data. In this setting, the authors show that, as long as each user receives sufficiently many samples, we can learn any privately learnable class via an ("", )DP algorithm using only O(log(1/\sqrt{1/2/3/4}) users. The authors also show that in the local model, where d is the probabilistic representation dimension, they show a nearly-matching lower bound on the number of users required. A crucial component of their results is a generalization of global stability that allows the use of public randomness. "
SP:da4f21d107a7f442c4d3e3ec13bdb44b041e07cf,"This paper studies the effect of implicit representations of value functions on the convergence rate of SGD in reinforcement learning. In particular, the authors show that for a linear parametrization, gradient descent converges to global optima despite nonlinearity and non-convexity introduced by the implicit representation. In addition, they derive convergence rates for both cases which allow them to identify conditions under which stochastic gradient descent with this implicit representation converges substantially faster than its explicit counterpart. Finally, they provide empirical results in some simple domains that illustrate the theoretical findings."
SP:992aa07d4f815d1c81f967374590eece933833b1,"This paper proposes a method to improve the performance of knowledge graph (KG) embeddings for the task of KG refinement. The proposed method is based on PSL-KGI, which is a type-supervised KG embedding method. The authors show that the proposed method can improve the quality of the KG by using the knowledge graph embedding. The method is evaluated on several KG benchmarks and shows improved performance. "
SP:676fc4a3041af22e8f20ccba7daa2a0b1f5d6af5,"This paper proposes a novel evaluation paradigm for knowledge base completion (KBC) based on binary predictions. The authors propose a new data set FB14k-QAQ with an alternative evaluation data structure: instead of single facts, they use KB queries, i.e., facts where one entity is replaced with a variable, and construct corresponding sets of entities that are correct answers. They randomly remove some of these correct answers from the data set, simulating the realistic scenario of real-world entities missing from a KB. This way, they can explicitly measure a model’s ability to handle queries that have more correct answers in the real world than in the KB, including the special case of queries without any valid answer. "
SP:83fe0a496a79bcf97ccba1c6d34b7d11e7d5c330," models can be used to generate human-like responses in dialog systems. This paper proposes a simple and effective framework, Alternating Roles Dialog Model (ARDM), which models each speaker separately and takes advantage of the large pretrained language model. It requires no supervision from human annotations such as belief states or dialog acts to achieve effective conversations. ARDM outperforms or is on par with state-of-the-art methods on two popular task-oriented dialog datasets: CamRest676 and MultiWOZ. Moreover, ARDM can generalize to more challenging, non-collaborative tasks such as persuasion."
SP:b11c06b7c4ef1aa43c59f808a679425e302d158e,"This paper studies the problem of estimating the probability that the classification predicted by a deep neural network is correct (or in the Top 5) on the test set. The authors prove that if an uncertainty measure is an implied loss, then low uncertainty means high probability of correct classification. The paper proposes a confidence measure for Top k which can be evaluated by binning values on the Test set. "
SP:ab9666e15f2a0113d96cb4b47b1cbb30fa1f7982,"This paper studies the generalization properties of neural networks at large depths. The main contribution of the paper is to show that in the wide network limit, random networks before training are Gaussian processes governed by a kernel known as the Neural Network Gaussian Process (NNGP) kernel. The authors show that at large depth, the spectrum of the NNGP kernel simplifies considerably and becomes “weakly data-dependent”, and that gradient descent training of wide neural networks is described by the Neural Tangent Kernel (NTK) that is related to the NNGP kernel. In the large depth limit, they show that the spectrum for NTK simplifies in much the same way as that of NNNGP. By analyzing this spectrum, they arrive at a precise characterization of trainability and a necessary condition for generalization across a range of architectures including Fully Connected Networks (FCNs) and Convolutional Neural Networks (CNN)."
SP:d3470c35aae48bf92439a55fdb98ccf07100e567,"This paper proposes a graph-based method to estimate the quality of protein models. The proposed method is based on Graph-based Representation Learning (GRAPHQA), which is a graph based method for estimating the structure of proteins. The authors show that the proposed method outperforms the state-of-the-art for both hand-engineered and representation-learning approaches, as well as carefully evaluating the individual contributions of the components. "
SP:5188280131b58a35d3deda126a0754aea8fa6e58,"This paper studies the problem of finding the critical locus of the loss function of a linear neural network in the landscape of linear networks with different loss functions and different parameterizations. In particular, the authors consider the case where the functional space is either the set of all linear maps from input to output space or a determinantal variety, i.e., a set of linear maps with bounded rank. The authors show that the absence of “bad” local minima in the loss landscape is due to two distinct phenomena that apply in different settings: it is true for arbitrary smooth convex losses in the case of architectures that can express all linear map (filling architectures) but it holds only for the quadratic loss when the function space is a determinantsal variety (“non-filling architecture”). Without any assumption on the architecture, smooth conveX losses may lead to landscapes with many bad minima."
SP:ee71597ceab23eb4db1d6608f15f80ad51f7ff6d,"This paper proposes a general framework SEED (Sampling, Encoding, and Embedding Distributions) for inductive and unsupervised representation learning on graph structured objects. Instead of directly dealing with the computational challenges raised by graph similarity evaluation, given an input graph, the proposed SEED framework samples a number of subgraphs whose reconstruction errors could be efficiently evaluated, encodes the subgraph samples into a collection of sub graph vectors, and employs the embedding of the sub graph vector distribution as the output vector representation for the input graph. By theoretical analysis, the authors demonstrate the close connection between SEED and graph isomorphism. The empirical study shows that SEED can achieve up to 10% improvement over competitive baseline methods."
SP:d9406fdf0a180a5efc6f15ba8739524665f0f9d2,"This paper studies the problem of counterfactual regret minimization (CFR) in the context of zero-sum extensive games with imperfect information. The main contribution of this paper is to propose Lazy-CFR, a CFR algorithm that adopts a lazy update strategy to avoid traversing the whole game tree in each round. The authors prove that the regret of Lazy CFR is almost the same as that of the vanilla CFR and only needs to visit a small portion of the game tree and is provably faster than CFR. Empirical results show that the proposed algorithm is fast in practice."
SP:023aa3dca1cf7992b22993a7088e8a74c92bb47e,"This paper proposes a novel method for Unsupervised Domain Adaptation (UDA) based on explicit feature distribution modeling for UDA. In particular, the authors propose Distribution Matching Prototypical Network (DMPN) to model the deep features from each domain as Gaussian mixture distributions. In DMPN, they propose two new domain discrepancy losses with probabilistic interpretations. The first one minimizes the distance between the corresponding Gaussian component means of the source and target data. The second one minimises the pseudo negative log likelihood of generating the target features from source feature distribution. To learn both discriminative and domain invariant features, the proposed method is trained by minimizing the classification loss on the labeled source data and the domain discrepancy loss together. Extensive experiments are conducted over two UDA tasks. "
SP:40be996e8bb86e887077b762b87c7c34a786ac98,"-based continuous normalizing flows (CNFs) have been shown to be effective for image generation and downstream predictive tasks. However, CNFs are inefficient due to the high dimensional latent code generated by the model, which needs to be of the same size as the input data. In this paper, the authors propose InfoCNF, an efficient conditional CNF that partitions the latent space into a class-specific supervised code and an unsupervised code that is shared among all classes for efficient use of labeled information. Since the partitioning strategy (slightly) increases the number of function evaluations (NFEs), the authors also employ gating networks to learn the error tolerances of its ordinary differential equation (ODE) solvers for better speed and performance. Experiments on CIFAR-10 and time-series data show the effectiveness of the proposed method."
SP:97764e3393216106ff2ac3f550845acf4636119f,"This paper studies the approximation of the value function for infinite-horizon discounted Markov Reward Processes (MRP) with nonlinear functions trained with the Temporal-Difference (TD) learning algorithm. The authors consider this problem under a certain scaling of the approximating function, leading to a regime called lazy training. In this regime the parameters of the model vary only slightly during the learning process, a feature that has recently been observed in the training of neural networks. Both in the under-and over-parametrized framework, the authors prove exponential convergence to local, respectively global minimizers of the above algorithm in the lazy training regime. They then give examples of such convergence results in the case of models that diverge if trained with non-lazy TD learning, and in the cases of neural network."
SP:c518e4030f12b0f59ad1d7c0fc0ebd313c68ef95,This paper proposes a method to train an agent to generate observations that can be used to predict whether a given hypothesis is true or false. The agent is trained to take an action to generate an observation that can help predict whether the hypothesis is false or true. The agents are trained using reinforcement learning. The main contribution of the paper is to formulate the problem of hypothesis verification as a reinforcement learning problem. The paper shows that agents trained end-to-end with the reward fail to learn to solve this problem. 
SP:6fa2f842b1bc993ed8024a3ce13dbd91529c61be,"This paper studies the problem of approximate reasoning in a fixed-dimensional latent space. The authors propose to use graph neural networks to predict whether a statement can be rewritten by other theorems. This is done by predicting the embedding of a formula generated by some rewrite rule in the latent space, and then performing sequences of rewrite steps both in formula space and in latent space and comparing the quality of embeddings of the resulting formulas to their predicted embedding. The experiments show that graph neural network can make non-trivial predictions about the rewrite-success of statements even when they propagate predicted latent representations for several steps."
SP:a77ab500a5e7d4ea8430871d1e603941e92974fd,"This paper proposes a method for learning depth from images and very sparse depth measurements, just a few pixels per image. To learn from such extremely sparse supervision, the authors propose a specialized global-local network architecture. Experiments on several datasets show that the proposed model can learn monocular dense depth estimation when trained with very sparse ground truth, even a single pixel per image, and the global parameters extracted by the network are predictive of the metric agent motion."
SP:2afba5e24478da4e9d493887c7cf00e288cc0deb,"This paper proposes a method for learning Bloom filter-based word embeddings using a multi-layer Transformer network. The proposed method is based on the idea of word pieces in natural language models. The key idea is to use hash functions to map each id to multiple hash tokens in a much smaller space, similarly to a Bloom filter. The authors show that the proposed method outperforms models of a similar size without hashing and, to a large degree, models of larger size trained using sampled softmax with the same computational budget. "
SP:745dd86d7f7bba79a02d27922003b764b620f83e, of learning 3D parts for objects in unseen categories. The authors propose a learning-based agglomerative clustering framework which learns a grouping policy to progressively group small part proposals into bigger ones in a bottom-up fashion. They demonstrate that their method can transfer knowledge of parts learned from 3 training categories to 21 unseen testing categories without seeing any annotated samples.
SP:868fc6df740b04963442d5abcfe2f4845585cfc8,"This paper proposes a method for generating data that is not generated from the source distribution but from a second source distribution where the target distribution is unknown. The method is based on learning how neurons encode an edit for a particular transformation in a latent space. The authors use an autoencoder to decompose the variation within the dataset into activations of different neurons and generate transformed data by defining an editing transformation on those neurons. By performing the transformation in the latent space, they encode fairly complex and non-linear transformations to the data with much simpler distribution shifts to the neuron’s activations. "
SP:6dee6932e64fe47bb44dd42fc242fa9d89b8d89c,"This paper proposes a meta-learning approach for few-shot image segmentation. In particular, the authors propose an extension of FOMAML and Reptile to the task of segmentation and propose EfficientLab, a neural network architecture for parameter efficiency and fast learning. The authors also propose a formalization of the generalization error of meta learning algorithms, which they leverage to decrease the error on unseen tasks. Finally, they propose a small benchmark dataset, FP-k, for the empirical study of how meta learning systems perform in both few and many-shot settings."
SP:ec6f390f6d45fb79c33ae5d9c8a24cadb96fbd60,This paper proposes a new semi-supervised few-shot learning method based on Prototypical Networks (PN) to learn representations that are compact and well-separated. The main contribution of the paper is to propose a novel random walk loss for the network. The proposed method is based on a graph-based approach. The paper shows that the proposed method outperforms the state-of-the-art in most of the benchmarks. 
SP:d12e687bd2ee9fa60554312e644bb0a6487974f1,"This paper proposes Contrastive Sensor Fusion (CSF), a new self-supervised training objective to learn representations of every possible combination of sensors from multiple sources. The proposed method uses information common across multiple sensors and bands by training a single model to produce a representation that remains similar when any subset of its input channels is used. CSF uses a dataset of 47 million unlabeled coterminous image triplets to train an encoder to produce semantically meaningful representations from any possible combinations of channels from the input sensors. These representations outperform fully supervised ImageNet weights on a remote sensing classification task."
SP:4d8e054f07006b4f896721b5c24da805727d2c22,"This paper presents a network-agnostic network pruning algorithm that matches the accuracy and compression ratios of several state-of-the-art network-specific pruning algorithms. The main contribution of the paper is the introduction of a new method for weight rewinding, which trains the unpruned weights from their final values using the same learning rate schedule as the original training schedule. The proposed method outperforms fine-tuning in terms of accuracy and accuracy ratio."
SP:3bb1c79f9482e09828eda45fbb2e654f37219365,"This paper studies the relationship between output margin and generalization in deep neural networks. The main contribution of the paper is the analysis of the all-layer margin, which is a new notion of margin for deep networks. In particular, the authors show that the all layer margin has a clear and direct relationship with generalization for deep models. The authors also provide a theoretically inspired training algorithm for increasing the alllayer margin. "
SP:3d44f27468087280e85dfb1fc7291db05179fe6d,". This paper proposes a disentangled response decoder to isolate parameters that depend on knowledge-grounded dialogues from the entire generation model. The major part of the model can be learned from a large number of ungrounding dialogues and unstructured documents, while the remaining small parameters can be well fitted using the limited training examples. Empirical results on two benchmarks indicate that with only 1/8 training data, the proposed model can achieve the state-of-the-art performance and generalize well on out of domain knowledge."
SP:9b555f7fe743f5effdbdc8701ed519ce3159c4b0,"This paper proposes a mirror-generative neural machine translation model (MGNMT) that simultaneously integrates the source to target translation model, the target to source translation model and two language models. Both translation models and language models share the same latent semantic space, therefore both translation directions can learn from non-parallel data more effectively. Experiments show that the proposed MGNMT consistently outperforms existing approaches in a variety of language pairs and scenarios."
SP:d7a530a0ec4112095a58cef4cda9646f8ca6449d,"This paper studies the effect of the entropy term in Soft Actor Critic (SAC) on the performance of Deep Reinforcement Learning (DRL) algorithms on Mujoco. The authors show that SAC’s entropy term mainly addresses the bounded nature of the action spaces, and propose a simple non-uniform sampling method for selecting transitions from the replay buffer during training. The proposed method outperforms SAC and achieves state-of-the-art performance on continuous control tasks."
SP:545e8da553fcb47d84eaa044d8a4947d3cd3230e,"This paper studies the vulnerability of industrial copyright detection systems to adversarial attacks. Specifically, the authors propose to use a neural network based system to identify the source of a piece of music. They show that this system can be attacked by a simple gradient-based method. The authors show that the proposed method is able to fool a number of industrial systems, including the AudioTag copyright detector and YouTube's Content ID system. "
SP:b511822850da3bf1079a36ed6f5ad4db80fbc424,"This paper proposes a method for visualizing the relationship between two images. The idea is to decompose the final activation map of each image into a set of point-to-point activation maps. These maps are then used to generate a map of the intensity between the two images, which is then used as a measure of the similarity between them. The authors show that the proposed method can be applied to a wide range of metric learning applications. "
SP:67bf71219fe6bedec5f5525200e734638e4a6ca2,"This paper studies the problem of online lifelong learning in a continual learning setting. The authors propose a new algorithm called Adaptive Online Planning (AOP) that combines model-based planning with model-free learning. They show that AOP is able to learn and adapt quickly, but require prohibitive levels of computational resources under constrained computation limits, which requires the agent to understand both its own performance and the current state of the environment: knowing that its mastery over control in the current dynamics is poor, the agent should dedicate more time to planning. By measuring the performance of the planner and the uncertainty of the model free components, AOP can call upon more extensive planning only when necessary, leading to reduced computation times. "
SP:11159cb878a436a5d4fc6edb4132f2cc3c1b3f72,"This paper proposes to replace the traditional softmax attention mechanism by two alternative sparsity-promoting transformations: sparsemax and Total-variation Sparse Attention (TVMAX). With sparsemax, we obtain sparse attention weights, selecting relevant features. By selecting relevant groups of features, the TVMAX transformation improves interpretability. TVMAX outperforms the other compared attention mechanisms in terms of humanrated caption quality and attention relevance."
SP:fb0c3ce3db6ad674ddc615bdc6203cdcbe42c804,"This paper proposes a model for predicting the evolution of dynamic graphs. The model is based on a graph neural network and a recurrent network to capture the temporal evolution patterns of dynamic graph topology. Then, a generative model is used to predict the topology of the graph at the next time step and constructs a graph instance that corresponds to that topology at that time step. The authors evaluate the proposed model on several artificial datasets following common network evolving dynamics, as well as on real-world datasets."
SP:ff722957a1765c0568426ed88dd910a6b74054ef,"This paper proposes a method for imputing missing features and estimating the distribution of target assignments given incomplete data. The proposed method is based on a generator network to generate imputations that a discriminator network is tasked to distinguish. Following this, a predictor network is trained using the imputed samples to capture the classification uncertainties and make predictions accordingly. The experimental results show the effectiveness of the proposed method in generating imputations and providing estimates for the class uncertainties in a classification task when faced with missing values."
SP:c051b0fe779d9e4131016970b7ba469b596f3009,"This paper proposes a novel approach for off-policy estimation for long-horizon problems. The main contribution of the paper is to formulate the problem as solving for the fixed point of a certain operator. The authors propose a new estimator based on Reproducing Kernel Hilbert Spaces (RKHSs) that computes importance ratios of stationary distributions, without knowledge of how the data are collected. They analyze its asymptotic consistency and finite-sample generalization."
SP:065c900843011a71b70ed35357a2f71fe83872a7,"This paper proposes a GAN-based approach for Gaussian mixture model (GMM) where each of the modes is associated with a Gaussian distribution. The authors propose to compute the conditional likelihood p(x|k, θ) and the responsibility probability p(k|x, \theta) in the latent space z instead of x. The proposed approach is based on the GAN framework. "
SP:2da1608209058d214f8671062cc9eb0833ba4831,"This paper proposes a method to train large capacity neural networks with significantly improved accuracy and lower dynamic computational cost by gating the deep-learning architecture on a fine-grained-level. Individual convolutional maps are turned on/off conditionally on features in the network. To achieve this, the authors introduce a new residual block architecture and introduce a generally applicable tool batch-shaping that matches the marginal aggregate posteriors of features in a neural network to a pre-specified prior distribution. The authors present results on CIFAR-10 and ImageNet datasets for image classification, and Cityscapes for semantic segmentation."
SP:f90e9f0eb53f92601bdfa3f7bf86f71d037aad30,". This paper proposes a probabilistic importance inference approach for pruning DNNs. Specifically, they test the significance of a connection in a DNN to the DNN’s outputs using a non-paremetric scoring test and keep only those significant ones. The proposed approach achieves better lossless compression rates than existing techniques."
SP:64cbbb6a2f6847ef71cd5a23ba3e4cc5c815a56e,"This paper proposes a method to learn nested behavioral hierarchies of arbitrary depth, with actions of arbitrary length. The learned temporally extended actions provide new action primitives that can participate in deeper hierarchies as the agent learns. The proposed method is evaluated on tasks with non-trivial hierarchical structure and shows that it can be used to accelerate learning in recursively more complex tasks through transfer."
SP:e1ccfb3a684aef8a0fb36194eb16af1667811e81,"This paper proposes Hierarchical Bayes Autoencoder (HBAE), a probabilistic generative model that uses an energy-based model for the decoder. The proposed model is trained using variational inference to recover latent codes conditioned on inputs. The authors propose to use an adversarial approximation where a conditional generator is trained to match the EBM distribution. During inference time, the HBAE consists of two sampling steps: first a latent code for the input is sampled, and then this code is passed to the conditional generator to output a stochastic reconstruction. In both single image and set cases, the proposed model generates plausible variations consistent with the input data, and generates realistic unconditional samples."
SP:1130a391afa30d1e0fddadedd2a3aaa70a4cb751," normalization techniques have been shown to improve the performance of off-policy temporal difference (OTD) methods. This paper proposes a new normalization technique called cross-normalization, which is an extension of batch normalization that re-centers data for two different distributions, as present in TD methods. The authors show that the proposed normalization improves the performance on a range of MuJoCo tasks."
SP:f9cafaa5131176290fa069e6d24046c079cd9eea,"This paper proposes an adversarial training strategy to learn discriminative features unbiased and invariant to the confounder(s). This is enabled by incorporating a new adversarial loss function that encourages a vanished correlation between the bias and learned features. The proposed method is applied to synthetic data, medical images, and a gender classification (Gender Shades Pilot Parliaments Benchmark) dataset. The results show that the learned features by the proposed method not only result in superior prediction performance but also are uncorrelated with the bias."
SP:783049ff463edd1283c058c6106a3e1f9a033df4," for character-level language modeling. In this paper, the authors propose a lightweight model, called GroupTransformer, that factorizes the calculation paths by grouped embedding operators. Additionally, Group-Transformer employs inter-group linear operators to prevent performance degradation from the group strategy. The experimental results show that the proposed model has better performance on two benchmark tasks, enwik8 and text8."
SP:946c26d371297c88d0ac246257104099b4585edc,This paper proposes Optimal Transport (OT) for training generative models with hierarchical-latent-variable structures. Theoretical analysis is provided to show that OT can be used to train a generative model without the need for complex inference and optimisation schemes. Experiments on MNIST and CIFAR-10 show the effectiveness of the proposed method. 
SP:309b47441d227ffa33f96f9f16f2addc607e5bb0,This paper presents an autoregressive video generation model based on a three-dimensional self-attention mechanism. The authors show that the proposed model outperforms state-of-the-art video generation models on several benchmark datasets. They also show that their model produces continuations of high fidelity and realism on Kinetics.
SP:ad8fcdbc47a50dd2bf58aba2bc6cfe199e84dd4d,This paper proposes a generative model for zero-shot ICD coding. The proposed method is based on the idea of generating semantically meaningful features by exploiting ICD code hierarchical structure and a novel cycle architecture that reconstructs the relevant keywords. Extensive experiments demonstrate the effectiveness of the proposed method on the public MIMIC-III dataset.
SP:3ce82ae297e5759ab957babe9927062e7a71b0ba,This paper proposes a method to learn embeddings of states and action sequences simultaneously to improve sample efficiency in reinforcement learning (RL). The authors propose a forward prediction objective to simultaneously learn the state and action embedding. The proposed method is evaluated on goal-conditioned continuous control from pixel observations in only 1-2 million environment steps. The results show that the proposed method improves the sample efficiency of model-free RL on control from low-dimensional states.
SP:11ce1616e721340eea9e80dad7460c77355ac7d1," meta-learning is an important problem in machine learning. This paper proposes an approach to address the problem of task heterogeneity by a learned meta-knowledge graph. The proposed approach is motivated by the way of knowledge organization in knowledge bases, and it automatically extracts the cross-task relations and constructs the meta- knowledge graph. Experiments on 2D toy regression and few-shot image classification demonstrate the superiority of the proposed approach."
SP:37c209cd1c628b5c2f2b282fbeaf4bbf437c7670,"This paper proposes a new approach to control the generation of text by using a transformer-based language model (LMs) trained on large text corpora. The proposed approach is based on a combination of a pre-trained LM and an attribute classifier to guide the text generation. The approach is evaluated on a variety of topics and sentiment styles, and extensive automated and human evaluations show attribute alignment and fluency."
SP:12d0980bfea2de880905a0b87b40856969bb1c58,"This paper proposes a novel unsupervised learning approach for learning representations with unlabeled data. The proposed approach is based on denoising autoencoders, where the noisy input data is generated by corrupting clean data in the gradient domain. The paper shows that the proposed approach can be generalized to span multiple scales with a Laplacian pyramid representation of the input data. Experiments on several visual benchmarks demonstrate that better representations can be learned with the proposed method compared to its counterpart with single-scale corruption."
SP:12afc1b259e51a31cbeb72366d2b93fbee1aafaa,"This paper studies the problem of under-sensitivity in the context of natural language inference by ensuring that models do not become more confident in their predictions as arbitrary subsets of words from the input text are deleted. The authors develop a novel technique for formal verification of this specification for models based on the popular decomposable attention mechanism by employing the efficient yet effective interval bound propagation (IBP) approach. Using this method we can efficiently prove, given a model, whether a particular sample is free from the under-Sensitivity problem. The experiments on the SNLI and MNLI datasets show that IBP training leads to a significantly improved verified accuracy."
SP:14257af9fe83522c6e5b5d6b0d68945b944e30fb,"This paper studies the problem of model-free off-policy deep reinforcement learning (RL). The authors propose a simple Markov Decision Process (MDP) for which exact Q-values can be computed efficiently as more data comes in – resulting in a QGRAPH. They show that the Q-value for each transition in the simplified MDP is a lower bound of the lower bound for the same transition for the original continuous Q-learning problem. By using these lower bounds in TD learning, the authors show that their method is less prone to soft divergence and exhibits increased sample efficiency."
SP:c92c97e47d8b218dfd009bbf61f5b3547b395f91,"This paper studies the effect of the embedding complexity on the generalization to the target domain. In particular, the authors show that the complexity affects an upper bound on the target risk; this is reflected in experiments, too. Next, they specify their theoretical framework to multilayer neural networks and develop a strategy that mitigates sensitivity to the embeddings complexity, and empirically achieves performance on par with or better than the best layer-dependent complexity tradeoff."
SP:f3f3c6fbae757836551b3f1ee54a7d1e040132b8,"This paper studies generalization error bounds for learning general non-convex objectives. The authors propose a new framework, Bayes-Stability, that combines PAC-Bayesian theory and the notion of algorithmic stability. They obtain new data-dependent generalization bounds for stochastic gradient Langevin dynamics (SGLD) and several other noisy gradient methods (e.g., momentum, mini-batch and acceleration, Entropy-SGD). Their result recovers (and is typically tighter than) a recent result in Mou et al. (2018) and improves upon the results in Pensia et al (2018)."
SP:a82fcd1d3196ddf078cfe8f4bc6f445d9d2bdc11,"This paper investigates the role of the hippocampus in continual continual learning in the context of continual learning of two different spatial navigation strategies. Specifically, the authors analyze the activity of 612 hippocampal CA1 neurons of rodents learning to perform allocentric and egocentric spatial tasks. The results show that the neurons in the hippocampus encode relevant task variables such as decisions, navigational strategies and reward location. The authors compare this hippocampal features with standard reinforcement learning algorithms, highlighting similarities and differences."
SP:51acf1f8108683dce543a1fb4a61fbd593f9b4cc,This paper proposes a tree search based policy optimization method for continuous environments. The main contribution of the paper is to propose a new loss function based on the mean and standard deviation of the trajectories’ trajectories. The paper also proposes to use a pre-trained policy to bootstrapping the tree search with a low MCTS branching factor and few simulations. The proposed method significantly improves the policy on nearly all the environments. 
SP:1ce3bc4d31712886f7dcada5b5ae67c3c376819a,"This paper studies the lottery ticket hypothesis, which claims that neural networks contain sparse subnetworks that, if appropriately initialized (the winning tickets), are capable of matching the accuracy of the full network when trained in isolation. However, the properties of winning tickets are not well understood, especially the importance of supervision in the generating process. In this paper, the authors aim to answer the following open questions: can we find winning tickets with few data samples or few labels? can we even obtain “good” tickets without supervision? The authors find that winning tickets found in these scenarios are competitive with winning tickets generated on the full ImageNet dataset when evaluated on ImageNet classification task."
SP:dbcebe5b73486885d9f4478b258047c02f8481a2,"This paper studies the problem of prediction undersensitivity in the context of adversarial reading comprehension models. The authors propose a noisy adversarial attack that searches among semantic variations of comprehension questions for which a model still erroneously produces the same answer as the original question – and with an even higher probability. They show that – despite comprising unanswerable questions – SQuAD2.0 and NewsQA models are vulnerable to this attack and commit a substantial fraction of errors on adversarially generated questions. This indicates that current models—even where they can correctly predict the answer —rely on spurious surface patterns and are not necessarily aware of all information provided in a given comprehension question. They experiment with both data augmentation and adversarial training as defense strategies: both are able to substantially decrease a model’s vulnerability to undersensitivity attacks on held out evaluation data. Finally, they demonstrate that adversarial robust models generalise better in a biased data setting with a train/evaluation distribution mismatch; they are less prone to overly rely on predictive cues only present in the training set and outperform a conventional model in the biased setting by up to 11% F1."
SP:5da870060778de460c1abe91562d6f3e707efef4,"This paper proposes a model-based approach to ensuring the safety of the agent while making sure that the agent does not cause any unnecessary disruptions to its environment. The proposed approach learns the transition dynamics of the environment and generate a directed graph called the imaginative module. This graph encapsulates all possible trajectories that can be followed by the agent, allowing the agent to efficiently traverse through the imagined environment without ever taking any action in reality. Experiments on two gridworld environments and a self-driving car simulator demonstrate that the proposed approach to safety visits unsafe states significantly less frequently than a baseline."
SP:c2796f28fb067138303df8d424d646f4ada31558,"This paper proposes a method to learn finite differences inspired by physics equations. The authors propose a novel architecture, Physics-aware Difference Graph Networks (PA-DGN), which leverages data-driven end-to-end learning to discover underlying dynamical relations between the spatial and temporal differences in given sequential observations. They demonstrate the superiority of the proposed method in the approximation of directional derivatives and the prediction of graph signals on synthetic data and real-world climate data."
SP:db8ed4f4fc3967f5dd4d208d5d029730eb99e840,"This paper studies the problem of training structured neural networks with nonsmooth regularization and constraints. The authors formulate training as a constrained nonsmoothed nonconvex optimization problem, and propose a convergent proximal-type stochastic gradient descent (ProxSGD) algorithm. They show that under properly selected learning rates, with probability 1, every limit point of the sequence generated by the proposed Prox SGD algorithm is a stationary point. Finally, extensive numerical tests are conducted to demonstrate the flexibility of the proposed algorithm."
SP:2ca1f4da9faee79768764cda5d09d949cc942acc,"This paper proposes an end-to-end differentiable compression framework for lossy image compression. The proposed method is based on a non-deterministic compression codec. The decoder maps the input image to a distribution in continuous space from which a sample can be encoded with expected code length being the relative entropy to the encoding distribution, i.e. it is bitsback efficient. The method is trained using standard gradient-based optimizers. Experiments on the CLIC 2018 dataset show that the proposed method outperforms the state-of-the-art on low bitrates."
SP:788fd2b6956dd69bf7752d39ea21883947128c8a,"This paper studies the problem of super resolution (SR) from compressed JPG (C-JPG) images. The authors propose a novel SR structure with two specifically designed components, as well as a cycle loss. First, they propose a functional sub-model to recover information for C-jPG images, instead of the perspective of noise elimination in traditional SR approaches. They further integrate cycle loss into SR solver to build a hybrid loss function for better SR generation. Experiments show that their approach achieves outstanding performance among state-of-the-art methods."
SP:18dd92f2f55020be4f5a089b3b251327e47886f4,. This paper proposes a neural network architecture to estimate a full surface of pass probabilities from single-location labels derived from high frequency spatio-temporal data of professional soccer matches. The network is able to perform remarkably well from low-level inputs by learning a feature hierarchy that produces predictions at different sampling levels that are merged together to preserve both coarse and fine detail. The proposed deep learning architecture can be easily adapted to solve many other related problems in sports analytics.
SP:1ae31baf383fc520687b255d9cac14c3b040e253,"This paper proposes an inductive matrix completion model without using side information. The main idea is to train a graph neural network (GNN) based on 1-hop subgraphs around (user, item) pairs generated from the rating matrix and maps them to their corresponding ratings. IGMC achieves competitive performance with state-of-the-art transductive baselines. In addition, IGMC is inductive – it can generalize to users/items unseen during the training and can even transfer to new tasks. "
SP:c5cb1b50e17a69e88d5ae28848e265215162da1e,"This paper considers the problem of unconstrained minimization of a smooth objective function in R in the setting where only function evaluations are possible. The authors propose a momentum version of the stochastic zeroth-order method with heavy ball momentum. They show new complexity results for non-convex, convex and strongly convex functions. They also propose SMTP with importance sampling which they call SMTP_IS and provide convergence analysis of this method."
SP:a216cfc29937eb398ea98cb1aea3481c9aed8240,"This paper proposes Action Semantics Network (ASN), a neural network architecture for multi-agent systems (MASs) where each agent makes individual decisions but all of them contribute globally to the system evolution. The main contribution of this paper is to propose a network architecture that explicitly represents such action semantics between agents. The proposed network can be easily combined with existing deep reinforcement learning (DRL) algorithms to boost their performance. Experimental results on StarCraft II micromanagement and Neural MMO show ASN significantly improves the performance of state-of-the-art DRL approaches compared with several network architectures."
SP:efaf3a440dc17e05177832083ffbc23760ed7c97,"This paper proposes to exploit the low-rank structure of the state-action value function, i.e., Q function, for both planning and deep RL. Specifically, the authors propose to use Matrix Estimation (ME) techniques to leverage the low rank structure in Q function. This leads to a more efficient planning procedure for classical control, and additionally, a simple scheme that can be applied to value-based RL techniques to consistently achieve better performance on “low-rank” tasks. Extensive experiments on control tasks and Atari games confirm the efficacy of the proposed approach."
SP:430336893b247b7bd45687d78b0d0511a7369e87,"This paper proposes a new algorithm for off-policy reinforcement learning in the batch setting. The proposed algorithm is based on best-action imitation learning (BAIL), which does not involve maximizing Q functions over the action space. BAIL first selects from the batch the actions it believes to be high-performing actions for their corresponding states; it then uses those state-action pairs to train a policy network using imitation learning. The algorithm achieves state-of-the-art performance on the Mujoco benchmark."
SP:94078964876667e8a5d9ae7728d779d5b91a576e, in deep extreme multi-label learning. This paper proposes a novel architecture that splits training of head and tail labels. The proposed DeepXML increases accuracy by (a) learning word embeddings on head labels and transferring them through a novel residual connection to data impoverished tail labels; (b) increasing the amount of negative training data by extending state-of-the-art negative sub-sampling techniques; and (c) re-ranking the set of predicted labels to eliminate the hardest negatives for the original classifier. 
SP:b1b1252d82fa1bea18309e0b0b894e0f28f48bc9,"This paper proposes an end-to-end trainable variational variational hashing-based collaborative filtering approach that uses the novel concept of self-masking: the user hash code acts as a mask on the items (using the Boolean AND operation), such that it learns to encode which bits are important to the user, rather than the user’s preference towards the underlying item property that the bits represent. This allows a binary user-level importance weighting of each item without the need to store additional weights for each user. The proposed method achieves significant gains of up to 12% in NDCG."
SP:80898d0f2b2c8dc3388fa9164e529eae36aa1b21,"This paper proposes a new metric for quantitatively measuring the mode collapse of GANs. The main contribution of the paper is the introduction of a set of statistical tools that are broadly applicable to quantitatively measure mode collapse. The authors propose two simple yet effective “black-box” methods to calibrate the GAN learned distribution, without accessing either model parameters or the original training data. The paper shows that the proposed metrics consistently show strong mode collapse on several state-of-the-art GAN models."
SP:e5b5dda2f024cfda10526e744aa035e0165af58a,"This paper studies the problem of training over-parametrized neural networks that are beyond the NTK regime but are still governed by the Taylor expansion of the network. The authors propose to use the randomization of two-layer neural networks to escape NTK and couple them with quadratic models. They show that the optimization landscape of randomized two layer networks is nice and amenable to escaping saddle algorithms. They prove concrete generalization and expressivity results on these randomized networks, which lead to sample complexity bounds that match NTK."
SP:cef7ea513eb3e42be4edf40e4ee1701a969bcbea,"This paper studies the problem of semi-supervised node classification using graph convolutional neural networks (GNNs). The main contribution of the paper is the introduction of Graph Filter Discriminant Score (GFD) to evaluate the effectiveness of GNNs for a given graph in terms of node classification. The paper shows that there is no single filter as a “silver bullet” that performs the best on all possible graphs, and graphs with different properties are in favor of different graph convolutionsal filters. Based on these findings, the paper proposes Adaptive Filter Graph Neural Network (AFGNN), a simple but powerful model that can adaptively learn data-specific filters. Experiments on both synthetic and real-world benchmark datasets show that AFGNN can achieve state-of-the-art performance across all the datasets."
SP:3c5ec9dbcf914c8901e4e35f3c2a7df4707422ab,"This paper studies the problem of distributionally robust optimization (DRO) for overparameterized neural networks. The authors propose to use group DRO to improve the worst-case performance of overparametrized neural networks on atypical groups of the data. In particular, the authors show that under the assumption that the training loss is vanishing, they show that the model with vanishing average training loss also has vanishing worst case training loss. Instead, the poor worst case performance arises from poor generalization on some groups. To address this issue, they propose to add a regularization term to the training of the network to improve its worst-group generalization performance. They also propose a stochastic optimization algorithm, with convergence guarantees, to efficiently train group DRo models. "
SP:eb1ee2e0f7d8466a04b58508ecb3da7b667eecdf,This paper proposes a new local explanation method for black-box classifiers. The proposed method is based on the idea of distribution controllers to guide the distribution of relevance scores of features according to their contributions. The authors propose to use the classification loss to optimize the proposed predictor. The experimental results demonstrate that the proposed method outperforms other local explanation methods in terms of faithfulness and explainability.
SP:32ea7cbc47cbdb1f703f4e07c31ce90abe083424,"This paper proposes a method for image reconstruction and classification problems that involve detection of multiple object instances, without any supervision regarding their whereabouts. The network learns to extract the most significant K patches, and feeds these patches to a task-specific network – e.g., auto-encoder or classifier – to solve a domain specific problem. The challenge in training such a network is the non-differentiable top-K selection process. To address this issue, the authors propose a simple, yet effective, multi-stage training. The method is able to learn to detect recurring structures in the training dataset by learning to reconstruct images. It can also learn to localize structures when only knowledge on the occurrence of the object is provided."
SP:da1c5f6351d531482e90b86c3cceb52850c520de,"This paper proposes AutoAssemblet, a neural program synthesis algorithm based on reinforcement learning. The main idea is to use reinforcement learning to learn a policy network and a value network to generate a sequence of code that matches the current state of the machine. The value network is learned to reduce the breadth and depth of the Monte Carlo Tree Search. The policy network is trained using a multi-entropy policy sampling technique to alleviate online update correlations. Experiments show that the proposed method outperforms several baselines on a number of tasks."
SP:0d4687fc36c02e27d1b95d532a3947589f92b1da,This paper studies the impact of model architecture on the speed of training in the context of gradient descent optimization. The authors use the ideas from prior work that shows gradient descent can be modeled as a first-order ODE and use ODE’s coefficient matrix H to characterize the convergence rate. They introduce a simple analysis technique that enumerates H in terms of all possible “paths” in the network. They show that changes in model architecture parameters reflect as changes in the number of paths and the properties of each path. They believe their analysis technique is useful in reasoning about more complex model architecture modifications.
SP:3e3bc8f617df742a395e7d315ec3810a42071294,"This paper studies the effect of initialization on the generalization performance of wide ReLU networks trained with squared loss. The authors show that the test error of wide NNs increases significantly with the initialization variance, while still interpolating the training data perfectly. They also provide a novel criterion to identify good initialization strategies. "
SP:b15ea009a36a0a76728dfc103d668d6781a8a99a,"This paper proposes a new pseudo-LiDAR method to improve the performance of stereo depth estimation for 3D object detection. The main contribution of this paper is to adapt the stereo network architecture and loss function to be more aligned with accurate depth estimation of faraway objects. The authors propose a depthpropagation algorithm, guided by the initial depth estimates, to diffuse these few exact measurements across the entire depth map. They show on the KITTI object detection benchmark that their combined approach yields substantial improvements in depth estimation and stereo-based object detection — outperforming the previous state-of-the-art detection accuracy by 40%."
SP:983d84502264633f3385d426c1d4601a0744ea9a,"This paper proposes an adversarial example detection method that can withstand norm-constrained white-box attacks. Inspired by one-versus-the-rest classification, in a K class classification problem, they train K base detectors where the i-th detector is trained to discriminate natural data of class i from adversarial examples perturbed from other classes. They further devise a generative approach to detect/classify adversarial samples by interpreting each base detector as an unnormalized density model of the classconditional data. They provide comprehensive evaluation of the proposed method and demonstrate their competitive performances and compelling properties."
SP:461e9308d050bc3dc7b35233452668bb31f5d491,". This paper proposes an intrinsic reward that encourages the agent to take actions that lead to significant changes in its learned state representation. The proposed method is evaluated on procedurally-generated tasks in MiniGrid, as well as on tasks with high-dimensional observations used in prior work. The experiments demonstrate that this approach is more sample efficient than existing exploration methods, particularly for procedurally generated MiniGrid environments."
SP:c002c20b5e8696588e029c0f65e88860418826c4,"This paper studies the problem of large-scale query-document retrieval, where the goal is to return the set of relevant documents (e.g., paragraphs containing the answer) from a large document corpus. This problem is often solved in two steps: the retrieval phase first reduces the solution space, returns a subset of candidate documents, and the scoring phase then re-ranks the documents. The retrieval phase requires to be highly efficient, returning candidates in time sublinear to the number of documents. In this paper, the authors conduct a comprehensive study on the embedding-based retrieval models. They show that the key ingredient of learning a strong embedding based Transformer model is a set of pre-training tasks. With adequately designed paragraph-level pretraining tasks, the Transformer models can remarkably improve over the widely-used BM-25 as well as embedding models without Transformers."
SP:4e161e08a624f87633dfb49dfd46bd1665e15189,"This paper proposes a new graph neural network architecture called BiGraphNet that replaces graph convolution and pooling in hierarchical networks with a single parametric bipartite graph convolutions operation. The proposed architecture is general enough to subsume existing graph neural networks as its special cases and supports multi-graph aggregation leading to a class of flexible and adaptable network architectures. The authors demonstrate that the proposed architecture can be used to build efficient architectures such as graph skip connections, and graph autoencoders. "
SP:9b9b6ee9014e5538442ba76d6059ed01f59ec8fb,"This paper proposes a method for few-shot classification under domain shift for metric-based methods. The main idea is to use feature-wise transformation layers for augmenting the image features using affine transforms to simulate various feature distributions under different domains in the training stage. To capture variations of the feature distributions in different domains, the authors further apply a learning-to-learn approach to search for the hyper-parameters of the features. The authors conduct extensive experiments and ablation studies under the domain generalization setting using five few-shots classification datasets: mini-ImageNet, CUB, Cars, Places, and Plantae."
SP:df46627cb984a56bba36d510bfc52e00751e9107,"This paper proposes a continuous convolutional network for Lagrangian fluid simulation. The authors propose to use spatial convolutions as the main differentiable operation that relates particles to their neighbors. They show that their network architecture can simulate different materials, generalizes to arbitrary collision geometries, and can be used for inverse problems. They demonstrate that their continuous convolutions outperform prior formulations in terms of accuracy and speed."
SP:3e17f333cf07183969c02bb66afdd3ccbf25bb19,"This paper proposes BatchEnsemble, an ensemble-based method to reduce the computational and memory cost for training and testing neural networks. The proposed method is based on the Hadamard product of a shared weight matrix among all members and a rank-one matrix per member. The method is parallelizable across devices, where one device trains one member, and parallelizable within a device, where multiple ensemble members are updated simultaneously for a given mini-batch. The authors show that the proposed method outperforms the state-of-the-art on CIFAR-10, Cifar-100, WMT14 EN-DE/EN-FR translation, and OOD tasks. "
SP:a123a425ef3eb6188833d5a42e851bc3fa59df65,This paper proposes a neural network-based PDE solver for both forward and inverse problems. The network is trained to minimize deviations of the learned function from the strong PDE solution and satisfy the boundary conditions. The resulting solution in turn is an explicit smooth differentiable function with a known analytical form. This framework enables the solution of high order non-linear PDEs. This setting is flexible in the sense that regularizers can be tailored to specific problems.
SP:973d0ad0faadcf7298300f2758de9154205e7113,This paper studies the performance of BNNs for SAT solvers. The main contribution of the paper is to propose a new BNN architecture and training procedure to improve SAT solver's performance. The proposed method is based on a BNN-based architecture and a new training procedure. The paper shows that the proposed method improves performance on both existential and probabilistic queries compared to existing work.
SP:ca985e758f195bd04fb9f24b290a83974d6d308b,"This paper studies the expressive power of graph neural networks falling within the message-passing framework (GNNmp). Two results are presented. First, GNNmp are shown to be Turing universal under sufficient conditions on their depth, width, node attributes, and layer expressiveness. Second, it is discovered that GNNMP can lose a significant portion of their power when their depth and width is restricted. The proposed impossibility statements stem from a new technique that enables the repurposing of seminal results from distributed computing and leads to lower bounds for an array of decision, optimization, and estimation problems involving graphs."
SP:a98ae70a91850bbe624c307ba61d3daeb2494b82,"This paper proposes localised generative flows (LGFs) to learn target distributions with complicated topologies. LGFs are composed of stacked continuous mixtures of bijections, which enables each bijection to learn a local region of the target rather than its entirety. Unlike normalising flows, LGFs do not permit exact computation of log likelihoods, but they propose a simple variational scheme that performs well in practice."
SP:3adc341dece170f428195e4dccadfb5f5daddf2d,"This paper studies the problem of Vision-and-Language Navigation (VLN) in unseen environments. The authors propose two methods to investigate the performance gap between seen and unseen environments: environment re-splitting and feature replacement. They find that the low-level visual appearance conveyed by ResNet features directly affects the agent model and contributes to this environment bias in results. They explore several kinds of semantic representations which contain less low level visual information, hence the agent learned with these features could be better generalized to unseen testing environments. "
SP:298e0043e99f586d314fbd9d16fdc6ae885e1ebb,"This paper studies the problem of how to use implicit human feedback to accelerate and optimize the training of a DRL algorithm. In this paper, the authors propose to use an electroencephalogram (EEG) to capture the implicit feedback of a human observer watching an agent learning to play several different Atari-games using an EEG cap, and then decoding the signals appropriately and using them as an auxiliary reward function to accelerate the agent's learning of the game. The authors demonstrate the feasibility of capturing the error-potential of an observer watching the agent and using it as a reward function for the agent. They also show that the definition of the implicit reward function is generalizable across different environments."
SP:a8395f8b877e1eebaef9ff2e8b4e488d55a74ef4,"This paper proposes a novel method for laconic classification, where the goal is to minimize the amount of information (aka. entropy) required in individual test images to maintain correct classification. Given a classifier and a test image, we compute an approximate minimal-entropy positive image for which the classifier provides a correct classification, becoming incorrect upon any further reduction. The notion of entropy offers a unifying metric that allows to combine and compare the effects of various types of reductions (e.g., crop, colour reduction, resolution reduction) on classification performance, in turn generalising similar methods explored in previous works. The authors propose two complementary frameworks for computing the minimal-Entropy positive images of both human and machine classifiers, in experiments over the ILSVRC test-set, they find that machine classifier are more sensitive entropy-wise to reduced resolution (versus cropping or reduced colour for machines, as well as reduced resolution for humans) and support recent results suggesting a texture bias in the I LSVRC-trained models used in the experiments. They also find, in the evaluated setting, that humans classify the minimum entropy positive images with higher precision than machines classify those of humans."
SP:81cec8f907d8fa0653b5bc08af1f59bfefd49619,This paper studies the effect of perturbations on the robustness of convolutional neural networks in the presence of adversarial examples. The authors identify a family of defense techniques that are based on the instability assumption. They show that deterministic lossy compression algorithms and randomized perturbation to the input can all lead to similar gains in robustness. They also provide a comprehensive experimental analysis of when and why these defenses work and potential mechanisms that could explain their effectiveness.
SP:a136b98e0ed478144ce9dd26e2b6d611543124e8,"This paper proposes a method to learn 3D feature maps of a scene from a moving camera. The proposed method is based on a neural network that takes as input 2.5D color and depth video streams captured by a camera and uses them to generate 3D features maps of the scene by disentangling the scene content from the motion of the camera. These feature maps are then projected to novel viewpoints to predict and match against target views. The authors propose contrastive prediction losses to replace the standard color regression loss, and show that this leads to better performance on complex photorealistic data. "
SP:6fd61604a2eeb8a2cbbda6c40807cebef6d40f2f,"This paper studies the problem of unsupervised domain translation (UDT) in the context of image-to-image translation. The authors show that existing methods are biased towards low energy transformations, leading them to cast UDT into an Optimal Transport (OT) framework by making this implicit bias explicit. This allows them to provide theoretical guarantees for existing methods, and also to solve UDT problems where previous methods fail. Finally, making the link between the dynamic formulation of OT and CycleGAN, the authors propose a simple approach to solve the UDT problem. "
SP:8bb3ce11ad773685f6e41d90db3e7a5481e5ba47,"This paper proposes a novel regularization method, RotationOut, for neural networks. The idea is to treat the input layer as an entire vector and introduce regularization by randomly rotating the vector. The proposed method can be used in convolutional layers and recurrent layers with small modifications. Extensive experiments in vision and language tasks are conducted to show the effectiveness of the proposed method."
SP:37620ae8dc5683eb2843792e0aa4cbe6cba366f7,"This paper proposes a data-free method to create Universal Adversarial Perturbations (UAPs) for a given CNN in a data free manner. The authors show that the adversary generation with full training data can be approximated to a formulation without data. This is realized through a sequential optimization of the adversarial perturbation with the proposed dilate loss. Extensive experiments demonstrate that the proposed method not only has theoretical support, but achieves higher fooling rate than the existing data free work."
SP:2fd7d5507a8727db743dc89379a6f021d31ed39a,"This paper proposes a transferable neural architecture search (NAS) method based on meta-learning. The main idea is to learn a meta-architecture that is able to adapt to a new task quickly through a few gradient steps, which makes the transferred architecture suitable for the specific task. The proposed method achieves state-of-the-art performance in few-shot learning and comparable performance in supervised learning but with 50x less searching cost."
SP:1314a79ba12474adb33ff31b3cb22bed25b94fb7,"This paper proposes a simple and effective stochastic neural network architecture for discriminative learning by directly modeling activation uncertainty and encouraging high activation variability. Compared to existing SNNs, the proposed SE-SNN is simpler to implement and faster to train, and produces state-of-the-art results on network compression by pruning, adversarial defense and learning with label noise."
SP:bd4935d4fcf33f60f22e0f2fd9f7dc8ddfab6d17,"This paper proposes a meta-RL approach for meta-learning in the context of curiosity. In particular, the authors propose to use neural networks as the outer loop of a meta RL algorithm, where the inner loop is the reinforcement learning algorithm. The outer loop is composed of two parts: an outer loop that learns to adapt the reward signal and an inner loop that performs reinforcement learning using the adapted reward signal. Experiments are conducted on grid navigation with image inputs, acrobot, lunar lander, ant and hopper. "
SP:6dff0f3a84809ae0ba9f58f36303597f1ba6dcc5,"This paper proposes a new approach for Any-Code-to-Code Generation (AnyC2C) that leverages the strict syntax of programming languages to model a code snippet as a tree – structural language modeling (SLM). The proposed approach estimates the probability of the program’s abstract syntax tree (AST) by decomposing it into a product of conditional probabilities over its nodes. The authors propose a neural model that computes these conditional probabilities by considering all AST paths leading to a target node. Unlike previous structural techniques that have severely restricted the kinds of expressions that can be generated in this task, the approach can generate arbitrary expressions in any programming language. "
SP:7fc60d6fd1cfcc135c34f9664d172d3fd1c0ae0a,"This paper studies the problem of learning large-scale neural networks (NN) in a non-convex setting. The main contribution of the paper is to prove that the objective functions in learning NNs are convex in the canonical model space, and that the gradients between the original NN model space and the canonical space are related by a pointwise linear transformation, which is represented by the so-called disparity matrix. The authors prove that gradient descent methods surely converge to a global minimum of zero loss provided that the disparity matrices maintain full rank. If this full-rank condition holds, the learning of NNs behaves in the same way as normal convex optimization."
SP:78a536138570fe9b5d88350e4b16d598a7db1fe0,"This paper proposes an interactive graph-based segmentation algorithm based on a discrete Potts model and a class-aware integer linear programming (ILP) formulation that ensures global optimum. Both algorithms can take RGB, or utilize the feature maps from any DCNN, whether trained on the target dataset or not, as input. They present competitive semantic (and panoptic) segmentation results on the PASCAL VOC 2012 and Cityscapes dataset given initial scribbles. They also demonstrate that their interactive approach can reach 90.6% mIoU on VOC validation set with just 3 correction scribbles and can be used inside any weakly supervised learning framework on new datasets."
SP:2eb90879ddbc39b6b5c05152784d6044d1940513,"This paper proposes to use a learned saliency model to detect adversarial images. The proposed method is based on the idea that the saliency map of an image can be used as a real-time defense against adversarial perturbations. To this end, the authors propose to use the learned model to capture the shifts in saliency due to the perturbation. This allows saliency models to be used effectively as an adversarial defense. Further, they propose a novel defense: a CNN that distinguishes between adversarial and natural images using salient pixels as its input. They show that the proposed method outperforms existing methods on MNIST, CIFAR-10, and ASSIRA."
SP:fe5510d05ff091a5f133f2dbcd1b23d8d58d2c3e,"This paper studies the problem of global adversarial robustness, i.e., the probability that the prediction at any point sampled from the (unknown) input distribution is susceptible to adversarial attacks. In particular, the authors show that the global robustness can be computed by using concentration inequalities. They show that for any point in the input distribution, the probability of the prediction being susceptible to attack is upper-bounded by an upper bound of $O(\sqrt{0}^2)$ for any $O(0)$ selected a priori. The authors then show that this upper bound can be used to compute the robustness with a lower bound of $\Omega(1)$. The authors also provide a theoretical analysis of the trade-off between robustness and accuracy for a variety of neural networks architectures and training methods. "
SP:8f5616a1480b68c04b496ed498d237d5a7e87794,"This paper studies the problem of robust reinforcement learning, where the goal is to find the optimal policy with some extent of robustness to environmental dynamics. The authors propose to use Wasserstein distance to measure the disturbance to the reference transition kernel. They show that this measure can be used to reduce the infinite-dimensional optimization problem to a finite-dimensional risk-aware problem. Then, they show that optimal robust policies exist and provide a sensitivity analysis for the perturbations, and then design a novel robust learning algorithm. The effectiveness of the proposed algorithm is verified in the Cart-Pole environment."
SP:d85963f5f0f6b20cf08f2a7c169ae33a45db7de2,"This paper proposes a method to approximate mixed strategy Nash equilibria in multi-player continuous games, which always exist and include the pure ones as a special case. The authors propose to use the pushforward measure technique to represent a mixed strategy in continuous spaces. This allows them to generalize the Gradient-based Nikaido-Isoda (GNI) function to measure the distance between the players’ joint strategy profile and a Nash equilibrium. The proposed method is shown to converge to a stationary Nash equilibrium under the convexity assumption on payoff functions, the same popular setting as in previous studies."
SP:280d85cd8164a268f9d496ae5f17189c50f30dc1,"This paper proposes a method to augment training data for text classification using natural language explanations (NL explanations) by transforming NL explanations into executable logical forms by semantic parsing. The method generalizes different types of actions specified by the logical forms for labeling data instances, which substantially increases the coverage of each NL explanation. Experiments on two NLP tasks (relation extraction and sentiment analysis) demonstrate its superiority over baseline methods."
SP:a9b5f7257dedd719cfe341fca275776734af1d98,"This paper studies the problem of verifying the robustness of recurrent neural networks (RNNs) trained on a set of specifications. These specifications can be more complex than simple adversarial robustness. For example, a robot needs to visit a charging station or a language model needs to produce a bounded length of sentences. The authors propose to train RNNs on these specifications and show that the trained RNN is robust to perturbations of the input features. "
SP:3903680e07b676409e3cf6a1044b67291fe38630,This paper studies the problem of visual domain randomization in reinforcement learning. The authors propose a regularization method where the agent is only trained on one variation of the environment and its learned state representations are regularized during training to minimize the Lipschitz constant of the policy’s state representation. They show that the proposed method leads to more efficient and robust learning than standard domain randomisation while achieving equal generalization scores.
SP:c79046dc56b9ee9c926f87386046422ea134ae8d,"This paper studies the problem of imbalanced data pairs in deep metric learning (DML). The authors propose a simple and effective framework to sample pairs in a batch of data for updating the model. The key to this framework is to define a robust loss for all pairs over a mini-batch of data, which is formulated by distributionally robust optimization. The flexibility in constructing the uncertainty decision set of the dual variable allows us to recover state-of-the-art complicated losses and also to induce novel variants. Empirical studies on several benchmark data sets demonstrate that the proposed method outperforms the state of the art results."
SP:38420928e40ef80c0136ad607b9275f9ab1e0769,"This paper studies the problem of finding a local minimum in non-convex finite-sum minimization. The authors prove that the trust region method with inexact gradient and Hessian estimation can achieve a convergence rate of order O(1/k) as long as those differential estimations are sufficiently accurate. Combining such result with a novel Hessian estimator, the authors propose a sample-efficient stochastic trust region (STR) algorithm that finds an approximate local minimum within $\sqrt{n/\epsilon}$. This improves the state-of-the-art result by a factor ofO(n) and also develops Hessian-free STR algorithms that achieve the lowest runtime complexity."
SP:28a35b70b5e6915af28cacebc4ea50690c9534af,"This paper proposes Farkas layers, a geometrically motivated method for training deep neural networks without batch normalization or weight initialization. The proposed method is based on linear programming, where the goal is to ensure that at least one neuron is active at a given layer of the network. The authors show that the proposed method outperforms baselines in terms of training capacity on several datasets. "
SP:1d325b148e3efe407241c1f1cbe8d17400499741,"This paper studies the problem of computing exact robustness certificates for deep classifiers with differentiable activation functions in two steps. First, the authors show that if the eigenvalues of the Hessian of the network are bounded, we can compute a robustness certificate in the l2 norm efficiently using convex optimization. Second, they derive a computationally efficient differentiable upper bound on the curvature of a deep network. Finally, they propose a curvature bound as a regularization term to boost the certified robustness against adversarial examples."
SP:33f6f5aa0d4655e5d75fe612e0eff05e579d45c5,"This paper proposes a method for compressed sensing recovery using untrained deep generative models. The method is based on the recently proposed Deep Image Prior (DIP), wherein the convolutional weights of the network are optimized to match the observed measurements. The authors show that this approach can be applied to solve any differentiable linear inverse problem, outperforming previous unlearned methods. They further introduce a novel learned regularization technique, which incorporates prior information on the network weights. This reduces reconstruction error, especially for noisy measurements."
SP:23c0f621e6041003b59bf0532130760694cf6a4a,"This paper proposes TAIC, a hierarchical reinforcement learning method that learns the temporal abstraction from past experience or expert demonstrations without task-specific knowledge. The authors formulate the problem as learning latent representations of action sequences and present a novel approach of regularizing the latent space by adding information-theoretic constraints. The learned abstraction allows us to learn new tasks on higher level more efficiently. The proposed method shows significant speedup in convergence over benchmark learning problems."
SP:4e54c9196ba1eb2b6a0b0eee41e4a6f3a9de72dd," to scale GCN to larger graphs and deeper layers due to the over-expansion of neighborhoods across layers. The authors propose a novel layer-wise sampling strategy to sample the nodes layer by layer conditionally based on the factors of the bi-directional diffusion between layers. In this way, they potentially restrict the time complexity linear to the number of layers and construct a mini-batch of nodes with high local bi-irectional influence (correlation). Further, they apply the self-attention mechanism to flexibly learn suitable weights for the sampled nodes. Extensive experiments on three large benchmark graphs demonstrate the effectiveness and efficiency of the proposed model."
SP:bb0af9c011ef982c34fcadb545f6b5771818e7fa,"This paper presents STOVE, a state-space model for videos that explicitly reasons about objects and their positions, velocities, and interactions. It is constructed by combining an image model and a dynamics model in compositional manner and improves on previous work by reusing the dynamics model for inference, accelerating and regularizing training. It outperforms previous unsupervised models, and even approaches the performance of supervised baselines. The authors also demonstrate the strength of the model as a simulator for sample efficient model-based control in a task with heavily interacting objects."
SP:e67b463bc0aec2345925d609fa521ea49df57fd9,This paper proposes a new variational autoencoding model that combines the best properties of VAE and generative adversarial networks (GAN). The main contribution of the paper is to propose to use an implicit likelihood to train the VAE model with an adversarially trained discriminator. The proposed model achieves the state-of-the-art trade-off between generation and reconstruction quality on CIFAR-10 and TinyImagent.
SP:87056d0147ddcaf5d78f6888b05161fbdbb3346c,"This paper studies the problem of adversarial attacks on the Bayes-Optimal classifier for certain class distributions, while for others the optimal classifier is robust to such attacks. The authors show that under certain conditions on the data distribution under which all points can be made arbitrarily close to the optimal decision boundary and show that this can happen even when the classes are easy to separate, when the ideal classifier has a smooth decision surface and when the data lies in low dimensions. They introduce new datasets of realistic images of faces and digits where the Bayesian classifier can be calculated efficiently. They show that for some of these datasets the optimal classes are robust and for others it is vulnerable to adversarial examples. In systematic experiments with many such datasets, they find that standard CNN training consistently finds a vulnerable classifier while large-margin methods often find a robust classifier with the exact same training data."
SP:a7b3a35e6a79084bdfd1e4a963dfa081279cd8bb,". This paper studies the effect of sparsity on the performance of neural network pruning. The authors propose a new term, pruning identified exemplars (PIEs), which they term as hard-to-generalize-to images. They show that PIEs tend to be mislabelled, of lower image quality, entail abstract representations, atypical examples or require fine-grained classification. They find that removing PIE images from the test-set greatly improves top-1 accuracy for both sparse and non-sparse models."
SP:4b17edaa7ec6201891433320d85f9a415656b763,This paper proposes a novel approach for learning to play interactive fiction games in which the agent interacts with the world purely through natural language. The key idea is to build a dynamic knowledge graph and use it to guide the agent to explore and generate actions using a template-based action space. Experiments show that the proposed approach outperforms the state-of-the-art in a wide range of IF games.
SP:b1784ecbb8f36eef9cae33d61ce60d80c2f9c38d,This paper proposes a new loss function for maximum likelihood estimation (MLE) based on a data-dependent Gaussian prior (D2GPo) that is poles apart from the data-independent L2 regularization (L2-regularization) commonly used in smoothing the training of MLE. The proposed loss function is based on the Kullback-Leibler divergence term (KL-Divergence) between the predicted sequence and the ground-truth sequence. The authors show that the proposed loss improves the performance of the model on a variety of language generation tasks. 
SP:7c29cb5a32b14e1392408dc5daba4cd35848bea9,"This paper proposes to replace the cross-entropy loss with focal loss to improve the calibration of deep neural networks (DNNs). The authors show that focal loss preserves the confidence of the model’s correct predictions, which is extremely desirable for downstream tasks. They provide a thorough analysis of the factors causing miscalibration, and use the insights from this to theoretically justify the empirically excellent performance of focal loss. They perform extensive experiments on a variety of computer vision (CIFAR-10/100) and NLP (SST, 20 Newsgroup) datasets, and with a wide variety of different network architectures."
SP:cd6b8417ec8bcb773c78cff677bb0a76d6b3f6f3,"This paper proposes LiPopt, a polynomial optimization framework for computing increasingly tighter upper bounds on the Lipschitz constant of neural networks. The authors show how to use the sparse connectivity of a network, to significantly reduce the complexity of computation. This is specially useful for convolutional as well as pruned neural networks, and the authors conduct experiments on networks with random weights and networks trained on MNIST. "
SP:31c9dc0dd8806daddc9cb48c56ec819577fe46cd,"This paper proposes a self-supervised learning approach for video features that results in significantly improved performance on downstream tasks (such as video classification, captioning and segmentation) compared to existing methods. The method extends the BERT model for text sequences to the case of sequences of real-valued feature vectors by replacing the softmax loss with noise contrastive estimation (NCE). The authors also show how to learn representations from sequences of visual features and sequences of words derived from ASR (automatic speech recognition) and show that such cross-modal training (when possible) helps even more."
SP:0f24424d10f1201dd25e8c56354e10afc9b2b11c,"This paper proposes a simple yet effective framework that allows to select certain parts of the input data needed for the subsequent application of a given neural network. Both the associated selection masks as well as the neural network are trained simultaneously such that a good model performance is achieved while, at the same time, only a minimal amount of data is selected. During the inference phase, only the parts selected by the masks have to be transferred between the server and the client. The experiments indicate that it is often possible to significantly reduce the amount of the data needed to be transfer without affecting the model performance much."
SP:aa4fcf5b2cae05c5c6a903c24e4992b56655dee2,This paper proposes a novel loss function for out-of-distribution (OOD) detection based on the Outlier Exposure (OE) technique. The proposed loss function is based on a Mahalanobis distance-based classifier. The paper shows that the proposed loss is able to achieve state of the art results in OOD detection both on image and text classification tasks.
SP:89bc528ef801182365ac279e8963803afccb391d," of E2Efold is an end-to-end deep learning model for RNA secondary structure prediction. The key idea is to directly predict the RNA base-pairing matrix, and use an unrolled algorithm for constrained programming as the template for deep architectures to enforce constraints. The experiments on benchmark datasets demonstrate the superior performance of the proposed method."
SP:b68560cce8c64ebe0ca5e6534b3732c775d36452,This paper studies the problem of learning a collective policy that can be transferred to the real-world environment. The authors propose to train agents to play a series of virtual episodes in which each agent takes part in a simulation of the environment. Each agent is trained to learn a policy that maximizes the performance of all the agents in the simulation. The goal is to train the policy so that it can be used in the real world.  
SP:bd1dc08b4fd9a5cc78d26d7eb7f05dbb4a629ab1," for dialog generation. This paper proposes a dialog generation model that learns a semantic latent space, on which representations of semantically related sentences are close to each other. This latent space is learned by maximizing correlation between the features extracted from prompt and responses. An additional autoencoder is trained, for recovering the full sentence from the latent space. Experimental results show that the proposed model eliminates the generic response problem, while achieving comparable or better coherence compared to baselines."
SP:ef0d5fd333ed60feb3946d24002e9a90642aea66,This paper proposes Gaussian light-and-shadow (GLAS) to estimate the spatial impact of deep models by the feature perturbation inspired by light and shadow in nature. GLAS provides a useful coarseto-fine control benefiting from scalability of Gaussian mask. It also devised the ability to identify multiple instances through recursive GLAS. The paper shows that GLAS has state-of-the-art performance at high speed (about 0.5 sec per 224×224 image) via the ImageNet Large Scale Visual Recognition Challenge.
SP:d17ca20cc527c28ab7358cb5b14954e5fb56409f," of the paper. The paper proposes a method to remove pixel-wise and channel-wise correlations before the data is fed into each layer of the network. The proposed method can be efficiently calculated at a fraction of the computational cost of a convolution layer. Extensive experiments show that the network deconvolution operation is able to deliver performance improvement on the CIFAR-10, Cifar-100, MNIST, Fashion-MNIST, Cityscapes, and ImageNet datasets."
SP:e1b0de9a36bf8359df368b7a55a7f23e99d88db7,"This paper proposes a novel quantization method for GANs based on EM algorithms, named QGAN. The authors propose a multi-precision algorithm to find an appropriate quantization precision of GAN models given image qualities requirements. Experiments on CIFAR-10 and CelebA show that QGAN can quantize weights in GAN to even 1-bit or 2-bit representations with results of quality comparable to original models."
SP:58c4905f59f04a50b30d27c99521126a6455d38a,"This paper studies the last-iterate convergence of Hamiltonian gradient descent (HGD) for convex-concave min-max optimization problems. The main contribution of the paper is to prove that HGD converges to a linear solution in a variety of more general settings than the bilinear and convex strongly concave settings. In particular, the authors show that the HGD algorithm achieves linear convergence in a number of settings, including convex convex problems that satisfy a novel “sufficiently-bilinear” condition. They also prove convergence rates for stochastic HGD and for some parameter settings of the Consensus Optimization algorithm of Mescheder et al (2017)."
SP:d8556b52272321a1415ac2d85bb12e88b51ee73a,"This paper studies the stability of the forward/backward process of ResNet. Specifically, the authors consider the ResNet block hl = φ(hl−1 + τ · g(hl+1)$ where φ is ReLU activation and $\tau$ is a scalar. They show that for standard initialization used in practice, the stability is guaranteed for $1/\sqrt{L}$ where L is the number of residual blocks. They also show that if ResNet is properly over-parameterized, the gradient descent is guaranteed to find the global minima 1, which significantly enlarges the range of $\epsilon$ in previous work."
SP:cf70dc496825ece2f28fdf4f1a6f4316c69e0e48,"This paper proposes a method to train sparse neural networks with a fixed parameter count and a fixed computational cost throughout training, without sacrificing accuracy relative to existing dense-to-sparse training methods. The method updates the topology of the network during training by using parameter magnitudes and infrequent gradient calculations. The authors show that this approach requires fewer floating-point operations (FLOPs) to achieve a given level of accuracy compared to prior techniques. They demonstrate state-of-the-art sparse training results with ResNet-50, MobileNet v1 and MobileNetv2 on the ImageNet-2012 dataset, WideResNets on the CIFAR-10 dataset and RNNs on WikiText-103 dataset."
SP:d2d2b892518d54d0e63e26a056f2298be3be2610,"This paper proposes a method to find meaningful directions in the latent space of any generative model along which we can move to control specific properties of the generated image like the position or scale of the object in the image. The method does not require human annotations and is particularly well suited for the search of directions encoding simple transformations such as translation, zoom or color variations. Experiments are conducted on GANs and variational auto-encoders."
SP:1c63389e972d4652fac831e9d11609cd3c3c371a,"This paper proposes a physics-as-inverse-graphics approach to perform unsupervised physical parameter estimation of systems from video, where the differential equations governing the scene dynamics are known, but labeled states or objects are not available. This framework allows us to perform long term extrapolative video prediction, as well as vision-based model-predictive control. The proposed approach significantly outperforms related methods in long-term future frame prediction of systems with interacting objects (such as ball-spring or 3-body gravitational systems), due to its ability to build dynamics into the model as an inductive bias. The paper also shows that the controller’s interpretability provides unique capabilities in goal-driven control and physical reasoning for zero-data adaptation."
SP:c6b8b682bf3087a65cb2379700b8a0183853c2af,"This paper proposes a graph convolutional network-based method for few-shot learning from noisy data. The proposed method is based on the idea that a graph is used to model the structure of clean and noisy data, and the graph is then used to predict the class relevance of noisy examples. For each class, the GCN is treated as a binary classifier learning to discriminate clean from noisy examples using a weighted binary cross-entropy loss function. Each noisy example is weighted by its relevance when learning a classifier for the end task. Experimental results show that the proposed method outperforms the transductive approach (Douze et al., 2018) that is using the same additional data without labels."
SP:dd9c9a5dccbba5dd15b03ca6b314a9e153e95548,This paper proposes a new objective for graph neural networks (GNNs) that maximizes the Mutual Information (MI) between edge features and message passing channels. The MI is reformulated as a differentiable objective via a variational approach. The paper shows that the proposed objective can preserve edge information and improves the performance of MI-maximized models across a range of learning tasks.
SP:f1cf63d728da51b4f83eb50ef69e3788b3a5ed74,This paper proposes a new verifier for verifying the properties of generative networks. The proposed method is based on a deterministic and probabilistic abstract interpretation of the latent space of the generative network. The authors show that the proposed method can verify interesting interpolations in the network’s latent space. 
SP:2b0887dcf09249e8cee30d38163aeb9ef1e92b27,"This paper studies the problem of suspended animation in graph neural networks (GNNs). In this paper, the authors propose GRESNET (Graph Residual Network) to solve the problem. The proposed method is based on the graph residual network (GRESNET) framework. The main contribution of the paper is the introduction of GRESnet, which is a graph residual neural network (GRSN) based on spectral graph convolutional operator (GCPO). The authors show that the proposed method can solve the suspended animation problem with existing GNNs. The authors also show the effectiveness of the introduced new graph residual terms from the norm preservation perspective."
SP:dc436ade4d04072de35a90e5e4a1bfebfddb04e9,"This paper proposes a semi-supervised approach to reconstructing 3D geometry shape, albedo, and lighting from a single image. The proposed method is based on the idea of learning a nonlinear parametric model using convolutional neural networks (CNN) to regress the face shape and texture directly. The authors propose a novel center loss to make sure that different facial images from the same person have the same identity shape and lighting. Besides, the proposed model disentangles identity, expression, pose, and lightings representations, which improves the overall reconstruction performance and facilitates facial editing applications, e.g., expression transfer."
SP:f7bc06697b09e2d59ec06b2cbcf3c0828ece32ae,"This paper proposes a method for imitation learning when the transition kernel is unknown. The authors propose to replace the unknown transition kernel with a synthetic kernel that simulates the transition of state components for which the transition kernels is known (s) and extracts from demonstrations the state components that the transition is unknown (su). The next state is then stitched from the two components: s = {s, su}. The authors analyze the errors caused by the synthetic kernel and show that the proposed method outperforms the simulation-free alternative. "
SP:82cce92821e8168ab4a6fd67573b66c1d17673b8,This paper proposes a self-supervised reinforcement learning approach for learning to control states of interest without any external reward function. The authors formulate the intrinsic objective as rewarding the skills that maximize the mutual information between the context states and the state of interest. They evaluate their approach for different simulated robotic manipulation tasks from OpenAI Gym and a navigation task in the Gazebo simulator. They show that their method is able to learn to manipulate the object purely based on the intrinsic mutual information rewards.
SP:5db63d39cfd8132bec832ab64b8fbd403b3b8df0,"This paper proposes a new attack method for neural network (NN) trojaning attacks. The proposed method is based on the idea that the malicious misclassification target is not fixed and can be generated on demand even after the victim’s deployment. The authors show that the proposed attack method outperforms existing studies in capability, generality, and stealthiness. "
SP:35ea626ee4dd1a7a368a660eb852192924966b7f,This paper proposes a novel few-shot regression algorithm for drug discovery. The proposed algorithm is based on deep kernel learning. The authors propose to use a deep network to learn a kernel function and a differentiable kernel algorithm to find the appropriate kernel for each task during inference. They show that the proposed algorithm outperforms the state-of-the-art algorithms on both toy and real-world drug discovery tasks.
SP:91ca4c3ee07617356250bae9f4ef9799b3b134ff,"This paper proposes a framework to characterize which reasoning tasks a network can learn well, by studying how well its computation structure aligns with the algorithmic structure of the relevant reasoning process. The authors derive a sample complexity bound that decreases with better alignment. This framework offers an explanation for the empirical success of popular reasoning models, and suggests their limitations. "
SP:a52aee8da5cf5acd2baf3c2a62cb679e13b18bd5,"This paper proposes a new metric, called Fréchet joint distance (FJD), to measure the distance between joint distributions of images and conditioning distributions. The proposed metric is based on the idea of the joint distance between the joint distribution of the image and the conditioning distribution. The authors show that FJD can be used as a promising single metric for cGAN benchmarking and model selection. Experiments are conducted on a controllable synthetic dataset."
SP:fa822e8472efae17c7dfde8258057898383ecbbb,"This paper studies the problem of learning to identify ‘decision states’, i.e., the parsimonious set of states where decisions meaningfully affect the future states an agent can reach in an environment. The authors propose to use the VIC framework, which maximizes an agent’s ‘empowerment’ and formulate a sandwich bound on the empowerment objective that allows identification of decision states. Unlike previous work (Goyal et al. 2019), the decision states are discovered without extrinsic rewards – simply by interacting with the world. The results show that the decision state is often interpretable and leads to better exploration on downstream goal-driven tasks in partially observable environments."
SP:a19a51df7e28a5d3380be4fba13842efbfe3efec,"This paper proposes a novel method for classifying irregularly sampled time series with unaligned measurements, focusing on high scalability and data efficiency. The method SEFT (Set Functions for Time Series) is based on recent advances in differentiable set function learning, extremely parallelizable, and scales well to very large datasets and online monitoring scenarios. The proposed method is evaluated on multiple healthcare time series datasets and shows that it performs competitively while significantly reducing runtime."
SP:4ae89d64460b08749acc192004545c1fa8b7553b,"This paper proposes to use harmonic series to model audio signals by explicitly utilizing the harmonic structure. This is done by engineering the kernels to be supported by sets of harmonic series, instead of by local neighborhoods as convolutional kernels. They show that networks using Harmonic Convolution can reliably model audio priors and achieve high performance on unsupervised audio restoration. They also achieve better generalization performance for supervised musical source separation."
SP:c81a2b3fd1c56b9b18e4a358e3ff8b40aea5256a,"This paper proposes a method to reduce the total computation used by earlier pipeline stages and speeds up training whenever computation upstream from accelerators dominates the training time. Data echoing reuses (or “echoes”) intermediate outputs from earlier pipeline stage in order to reclaim idle capacity. The authors investigate the behavior of different data echoing algorithms on various workloads, for various amounts of echoing, and for various batch sizes. They find that at least one data echoing algorithm can match the baseline’s predictive performance using less upstream computation."
SP:b4cf56d3fa7d65cacde33f17cd04bd5bbc52dd71,"This paper proposes a successor feature-based method for learning to generalize beyond the finite set of behaviors being explicitly learned. The main contribution of this paper is to combine the successor features framework with the Variational Intrinsic Successor FeatuRes (VISR) algorithm, which learns controllable features that can be leveraged to provide enhanced generalization and fast task inference. Experiments on Atari games demonstrate the effectiveness of the proposed method. "
SP:83500230586a9134f910ad067b7233dc563dc1ba,"This paper studies the generalization properties of deep neural networks (DNNs) using a functional view of these networks. Theoretical (in shallow) and experimentally probing properties of DNNs reveal insights into the effect of standard initializations, the value of depth, the underlying loss surface, and the origins of generalization. One key result is that generalization results from smoothness of the functional approximation, combined with a flat initial approximation. This smoothness increases with number of units, explaining why massively overparameterized networks continue to generalize well."
SP:7225825e353b711a7d023f706fafe5e17e4e2fb2,"This paper proposes a GAN-based approach for image-to-image translation. The proposed approach is based on an attention mechanism, where the discriminator is trained to estimate the probability that the input image is real, and the generator is trained with an attention map that highlights the critical features for such prediction. This attention map then assists the generator to produce more plausible and realistic images. Experiments on several image transfer tasks demonstrate the superiority of the proposed approach."
SP:41c089ba65393174dae1dc136f79030a0a4fc532,"This paper studies the role of multiplicative interaction layers as a unifying framework to describe a range of classical and modern neural network architectural motifs, such as gating, attention layers, hypernetworks, and dynamic convolutions. The authors show that such layers strictly enrich the representable function classes of neural networks. They conjecture that multiplicative interactions offer a particularly powerful inductive bias when fusing multiple streams of information or when conditional computation is required. They argue that they should be considered in many situation where multiple compute or information paths need to be combined, in place of the simple and oft-used concatenation operation. Finally, they back up their claims and demonstrate their claims by applying them in large-scale complex RL and sequence modelling tasks."
SP:5144391584e6d3825e12684b7c053e4e282cff2b,"This paper proposes a new algorithm for batch active learning with deep neural network models. The proposed algorithm, called BADGE, samples groups of points that are disparate and high magnitude when represented in a hallucinated gradient space, which is designed to incorporate both predictive uncertainty and sample diversity into every selected batch. Crucially, BADGE trades off between uncertainty and diversity without requiring any hand-tuned hyperparameters."
SP:ce6023b1e6bf45b071a6f5457b2575425ae03366,"-based self-explaining models are models that reveal decision making parameters in an interpretable manner so that the model reasoning process can be directly understood by human beings. In this paper, the authors propose a novel feature leveling architecture that isolates low level features from high level features on a per-layer basis to better utilize the GLM layer in the proposed architecture for interpretation. Experimental results show that the modified models are able to achieve competitive results comparing to main-stream architectures on standard datasets while being more self explainable."
SP:b70ceead1bf6c7dc684c74501716e7012b891022," for extreme classification. In this paper, the authors propose a simple training method for drastically enhancing the gradient signal by drawing negative samples from an adversarial model that mimics the data distribution. The authors provide a mathematical proof that this adversarial sampling minimizes the gradient variance while any bias due to non-uniform sampling can be removed. The experimental results on large scale data sets show a reduction of the training time by an order of magnitude relative to several competitive baselines."
SP:29b52fee83309268d9864f3b1fc3617948577d41,This paper proposes a new approach for efficient exploration that leverages a low dimensional encoding of the environment learned with a combination of model-based and model-free objectives. The approach uses intrinsic rewards that are based on a weighted distance of nearest neighbors in the low dimensional representational space to gauge novelty and leverage these intrinsic rewards for sample-efficient exploration with planning routines in representational spaces. One key element of the approach is that we perform more gradient steps in-between every environment step in order to ensure the model accuracy. The proposed approach is tested on a number of maze tasks as well as a control problem and shows that it is more sample efficient compared to strong baselines.
SP:257c98dc1a9f3efcbf9544d9ee2ff524b000543d,This paper studies the problem of out-of-distribution detection in the few-shot classification setting. The authors propose two new methods for this task and investigate their performance. They establish benchmark datasets based on four popular few shot classification datasets. They show that the proposed methods outperform the baselines on the benchmark datasets.
SP:a3632b773143dfb3a8f104c6b658dfa1167d155b,"This paper proposes a generalized model of sequence generation that unifies decoding in directed and undirected sequence models. The proposed framework models the process of generation rather than a resulting sequence, and under this framework, various neural sequence models are treated as special cases, such as autoregressive, semi-autoregressive and refinement-based non-autororegressive models. This unification enables the authors to adapt decoding algorithms originally developed for directed sequence models to undirectED models. They demonstrate this by evaluating various decoding strategies for a cross-lingual masked translation model. "
SP:eca5e2be9831dfb79c4f5e633cbfadcfd2e00eb1,"This paper proposes a two-stage approach to solve the problem of MEs recognition in real-world scenes. In the first stage, the proposed method locates and recognizes the math symbols of input image by object detection algorithm, and in the second stage, it translates math symbols with position information into LaTeX sequences by seq2seq model equipped with attention mechanism. The experiments show that the proposed approach significantly outperforms the end-to-end method."
SP:923fee8623da1569a7f54a57b4b326f29440b4c0,-based quantization is an approach to reduce the memory footprint of convolutional neural networks. The authors propose a vector quantization method that aims to preserve the quality of the reconstruction of the network outputs rather than its weights. The method only requires a set of unlabelled data at quantization time and allows for efficient inference on CPU by using bytealigned codebooks to store the compressed weights. They validate their approach by quantizing a high performing ResNet-50 model to a memory size of 5 MB while preserving a top-1 accuracy of 76.1% on ImageNet object classification and by compressing a Mask R-CNN with a 26x factor.
SP:74850ad70241948f93fed95ba1f0ac11360437c1,This paper proposes a novel attention mechanism for the Transformer architecture. The attention mechanism is based on the Tensor Product Representation (TPR) model. The authors propose to use TPR to encode the relations between each Transformer cell and the other cells from which values have been retrieved by attention. The proposed method is evaluated on the Mathematics Dataset with 56 categories of free-form math word problems.
SP:d319df820c6630c409fab32097652a083e8f53ea,"This paper studies the problem of generalization when the training and test sets are not sufficiently representative of the empirical sample set, i.e., when samples are drawn from an underrepresented or unrepresented subset during inference. To address this problem, the authors reformulate a learning algorithm as a procedure for searching for a source code that maps input features to classes. They derive a necessary and sufficient condition for generalization using a universal cognitive similarity metric, namely information distance, based on Kolmogorov complexity, and formulate an optimization problem to learn a more general classification function. To achieve this end, they extend the input features by concatenating encodings of them, and then train the classifier on the extended features."
SP:b8e86f5e89330d81ba4967a7ed2dbfb56375d8a0,"This paper proposes a new graph pooling operation based on compressive Haar transforms, called HaarPooling. The proposed method is based on following a chain of sequential clusterings of the input graph. The input of each pooling layer is transformed by the compressed Haar basis of the corresponding clustering. The authors show that the proposed method achieves state-of-the-art performance on diverse graph classification problems."
SP:17bea301d6718ef5f28864dd2445552b3cf65eeb,"This paper studies sample-based point-cloud decoders that map a shape representation to a point feature distribution, allowing an arbitrary number of sampled features to be transformed into individual output points. The authors develop three sample based decoder architectures and compare their performance to each other and show their improved effectiveness over feedforward architectures. In addition, they investigate the learned distributions to gain insight into the output transformation."
SP:51d826ead5d1d9cb89d493ce4c39728651bbc57b,"This paper studies the effect of real-world noise on the performance of deep neural networks (DNNs) in a controlled setting. The authors conduct a large-scale study across a variety of noise levels and types, architectures, methods, and training settings. They show that DNNs generalize much better on real world noise. They also show that when networks are fine-tuned, ImageNet architectures generalize well on noisy data. Finally, they show that robust learning methods that work well on synthetic noise may not work as well on real-life noise."
SP:9873f78fb2821afdbb5551700e6ab6a0e8bcb9f0,"This paper proposes a method for learning rules from human supervision. The proposed method is based on a rule-exemplar approach, where a set of human examples are used to train the model. The idea is that the human examples can be used to jointly denoise the rules and train the network. The network is trained using a soft-implicit loss over the coverage and label variables. Experiments show that the proposed method outperforms existing methods on five tasks."
SP:6f2c656dbb7629f652a4291d6971625184d8118b, GNNs are a class of deep models that operate on data with arbitrary topology represented as graphs. This paper proposes a memory-based GNN (MemGNN) and graph memory network (GMN) that can learn hierarchical graph representations. The experimental results show that the proposed models achieve state-of-the-art results in eight out of nine graph classification and regression benchmarks. 
SP:81bc52d734c86975d741b6482d65ca71a9d81620,"This paper studies the effect of initialization in deep linear networks on the convergence of the network. The authors show that for deep networks, the width needed for efficient convergence to a global minimum with orthogonal initializations is independent of the depth, whereas for Gaussian initializations it scales linearly in the depth. The results demonstrate how the benefits of a good initialization can persist throughout learning, suggesting an explanation for the recent empirical successes found by initializing very deep non-linear networks according to the principle of dynamical isometry."
SP:9f5d95fc89c2f0d59d04838aa180f3db67997dfa,"This paper studies the problem of how to optimize the bit allocation of weights and activations for deep CNNs compression. The authors propose a Lagrangian-based method to solve the optimization problem. They show that the additivity of output error caused by quantization holds for deep neural networks which are continuously differentiable in the layers. Based on this observation, they formulate the optimal bit allocation problem in a joint framework and propose a very efficient method. The proposed method obtains excellent results on deep neural network. "
SP:7191d7b217a12b1bf9c47d790896a8227c14cc3d,"This paper proposes a novel inference WGAN model, which is a principled framework to fuse auto-encoders and WGANs. The iWGAN jointly learns an encoder network and a generative network using an iterative primal dual optimization process. The authors establish the generalization error bound of the iwGAN and provide a rigorous probabilistic interpretation of the model under the framework of maximum likelihood estimation. The empirical experiments show that the proposed iwgan model greatly mitigates the symptom of mode collapse, speeds up the convergence, and is able to provide a measurement of quality check for each individual sample."
SP:cca6ae14fd0dd12352855e594acf7f3263bb1f24,"This paper proposes a new approach for crowdsourced anaphoric annotation. The proposed approach is based on a nonparametric partially pooled structure (based on a stick breaking process) to alleviate the effects of sparsity inherent in some crowdsourcing environments. The paper shows that the proposed model performs better than its unpooled counterpart in conditions of sparseness and on par when enough observations are available. The model is also more resilient to different crowdsourcing setups, and, further provides insights into the community of workers. "
SP:4295cae4a56a02eb21c486408c1bf37a7483cb49,"This paper proposes a method for sparse reward reinforcement learning that uses intrinsic and extrinsic reward signals to accelerate exploration and stabilize learning. The authors introduce successor feature control (SFC) which is general and not task-specific. They evaluate their proposed intrinsic drive (SID) agent using three different environments with pure visual inputs: VizDoom, DeepMind Lab and DeepMind Control Suite. The results show a substantially improved exploration efficiency with SFC and hierarchical usage of the intrinsic drives."
SP:9fa22eb03a79bce0fc1c8e84ae8640e010701eca," of weakly-supervised video moment retrieval. This paper proposes a novel method to learn the latent representations of the video and the sentence. The proposed method is based on a frame-by-word interaction module and a Word-conditioned Visual Graph (WCVG). The proposed approach also incorporates a novel application of positional encodings, commonly used in Transformers, to learn visual-semantic representations. "
SP:27ac670353f34ee7a23bb7622f80c1dfbc0985e0,"This paper proposes a method for image-guided re-rendering of reconstructed objects for virtual and augmented reality applications (e.g., virtual showrooms, virtual tours & sightseeing, the digital inspection of historical artifacts). A core component of the approach is the handling of view-dependent effects. Specifically, an object-specific deep neural network is directly trained to synthesize the view-independent appearance of an object. As input data we are using an RGB video of the object. This video is used to reconstruct a proxy geometry via multi-view stereo. Based on this 3D proxy, the appearance of a captured view can be warped into a new target view as in classical image-based rendering. This warping assumes diffuse surfaces, in case of views with specular highlights, it leads to artifacts. To this end, the paper proposes EffectsNet, a deep network that predicts view-dependant effects. It is able to convert observed images to diffuse images, which are projected into other views. In the target view, our pipeline reinserts the new view- dependent effects. To composite multiple reprojected images to a final output, we learn a composition network that outputs photo-realistic results. Experiments are conducted on synthetic and real data."
SP:257d124367b1da9a595dc11a9df750d6bade298e," in this paper, the authors propose a sparse representation of model uncertainty for deep neural networks (DNNs) that relies on an inverse formulation of Multivariate Normal Distribution (MND): an information form. They show that the model uncertainty can be estimated in this form using a scalable Laplace Approximation scheme, which involves a diagonal correction of the Kronecker-factored eigenbasis. As this makes the inversion of the information matrix intractable an operation that is required for a full Bayesian analysis, they further devise a novel low-rank approximation of this eigen-basis that exploits spectral sparsity of DNNs. Both theoretical analysis and empirical evaluations over various benchmarks show the superiority of their approach over existing methods."
SP:2e03ceba4004b82f86f8349352a8ee4520e9c35d,"This paper proposes a new method for Minwise Hashing (MH) based on load-balanced hashing to reduce the number of empty bins in the MinHash. The proposed method is based on the idea that the load of the bins (the number of elements in a bin) could be unbalanced, which leads to the existence of empty bin and false similarity computation. The authors propose to balance the load so as to generate as few empty bins as possible. Experiments on real datasets validate the effectiveness of the proposed method."
SP:d73827ab98b0ff6bd92abfefea43a5f88ea40de2,This paper proposes a method for extracting features from phase shift data by adding a graph structure to each data point and constructing a suitable machine learning architecture for graph data with cyclic permutation. The proposed method is evaluated on a number of synthetic and real-world datasets. 
SP:0df5ad333eb4ff9cca7f2d117909e2ce533a65d8,"This paper proposes a novel method to generate text that is more faithful to the source text. The key idea is to use a variational Bayes objective to learn a confidence score for each target position in the text. This score is learned in training using a VBA objective, and can be leveraged at inference time using a calibration technique to promote more faithful generation. Experiments on a structured data-to-text dataset – WikiBio (Lebret et al., 2016) – show that the proposed method is able to produce more faithful text than existing state-of-the-art approaches."
SP:03307deac29173b2968fbd08f95fc77eb1f82410,"This paper proposes a simple pruning method based on magnitude-based pruning. The proposed method is based on the observation that the Frobenius distortion of a linear operator corresponding to a single layer is minimised by a single-layer optimization. Based on this observation, the authors propose lookahead pruning by extending the single layer optimization to a multi-layer optimisation. Experiments are conducted on VGG and ResNet networks to demonstrate the effectiveness of the proposed method."
SP:dc80fdc75bc14ae19fe4ba9b85c35ce00b12856f,"This paper proposes Moniqua, a decentralized decentralized SGD algorithm that uses quantized communication to communicate a provably bounded number of bits per iteration, while converging at the same asymptotic rate as the original algorithm does with full-precision communication. The authors prove in theory that moniqua communicates a provable number of bit per iteration. They demonstrate empirically that MoniquA converges faster with respect to wall clock time than other quantized decentralized algorithms. "
SP:86c61a658d07ab86e2d84cef7e480bf7a06e4ddb,"This paper studies the problem of learning a partial model for reinforcement learning. In particular, the authors propose a family of partial models that are provably causally correct, yet remain fast because they do not need to fully model future observations. They show that partial models can be causally incorrect because they are confounded by the observations they don't model, and can therefore lead to incorrect planning. To address this, they introduce a general family of models that is provably correct and fast. "
SP:c70479b2096a52584b242de58272ca8d8565feea,"This paper proposes a variational autoencoder (VAE) model that learns a succinct common representation of two correlated data variables for conditional and joint generation tasks. The proposed model is based on two information theoretic problems, distributed simulation and channel synthesis, in which Wyner’s common information arises as the fundamental limit of the succinctness of the common representation. Experimental results show that the proposed model outperforms existing VAE variants and the variational information bottleneck method."
