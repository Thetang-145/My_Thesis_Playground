paper_id,summary
SP:7f4b788b00a2a10bcd60351c3e04c8f597101e96,This paper proposes sqSGD (selective quantized stochastic gradient descent) for federated learning under local differential privacy constraints. The authors propose a new gradient-based gradient-subsampling method sqSgd to improve the communication efficiency and privacy of FL algorithms. The proposed method is based on a novel privacy-preserving quantization scheme that uses a constant number of bits per dimension per client. Experiments are conducted on benchmark datasets to demonstrate the effectiveness of the proposed method.
SP:632666b52c7c551d67fbbe70c06ed589c3a5e187,"This paper proposes a self-attention network (SAN) method to incorporate prior knowledge related to language representation from the beginning of training. In particular, the authors propose a simple and general representation method to introduce the prior knowledge into SANs. Specifically, they package the source sentence to a continuous space matrix, which allows SANs to utilize the prior prior knowledge from the start of training, thereby better performing language representation in a universal way compatible with neural networks. The authors also apply it to one prior word frequency knowledge for monolingual data and other prior translation lexicon knowledge for the bilingual data, respectively."
SP:e3e728837f26acb9da283a42c219b6c3b3e131cb,"This paper proposes a Bayesian Stackelberg Markov game (BSG) framework to model the dynamics of a sequential Moving Target Defense (MTD) system. The authors argue that existing models are inadequate in sequential settings when there is incomplete information about a rational adversary and yield sub-optimal movement strategies. To address these concerns, the authors propose a unifying game-theoretic model, called the Bayesian STACKELBERG Markov Game (BSMG), that can model uncertainty over attacker types and the nuances of an MTD system. In addition, they propose a new Bayesian Q-learning (BSS-Q) approach that can learn the optimal movement policy for BSMGs within a reasonable time. "
SP:97911e02bf06b34d022e7548beb5169a1d825903,"This paper proposes a VAE-based framework for disentangled representation learning. The framework is based on the assumption that entangled representations are unique in their own ways, and the disentanglement representations are “alike” (similar up to a signed permutation transformation). In the proposed VAE ensemble, each model not only maintains its original objective, but also encodes to and decodes from other models through pair-wise linear transformations between the latent reprere sentations. The authors show both theoretically and experimentally that the proposed framework encourages the linear transformations connecting the VAEs to be trivial transformations, aligning the latent representations of different models to be aligned. "
SP:59f9de3ebe4a04d2fc8778d8e3415bf85efb7822,This paper proposes a zero-shot approach to automated machine learning (AutoML) that predicts a high-quality model for a supervised learning task and dataset in real-time without fitting a single model. The method uses a transformer-based language embedding to represent datasets and algorithms using their free-text descriptions and a meta-feature extractor to represent the data. The authors train a graph neural network in which each node represents a dataset to predict the best machine learning pipeline for a new test dataset. The proposed method generalizes to new datasets and new sets of datasets.
SP:0f74dff929a4908405ebfa8e60fe1860eec6364f,"This paper analyzes the role of gradient descent in the failure of neural networks to achieve compositional generalization. The authors show that the optimization process imposes a bias towards non-compositional solutions. This is caused by gradient descent, trying to use all available and redundant information from input, violating the conditional independence property of compositionality. Based on this finding, the authors suggest that compositionality learning approaches considering only model architecture design are unlikely to achieve complete compositionality, which is the main contribution of this paper."
SP:f99a1b2dbcb7a7b30dbfcfc60668e94b4ad53410,"This paper proposes a new method for entity alignment based on knowledge graph (KG) representation learning. The proposed method is based on the observation that the representation discrepancy between two potentially-aligned entities is implicitly bounded by a predefined margin in the scoring function for embedding learning. However, such a margin cannot guarantee to be tight enough for alignment learning. To mitigate this problem, the authors propose a new approach that explicitly learns KG-invariant and principled entity representations, while preserving the original infrastructure of existing methods. Experiments are conducted to verify the effectiveness of the proposed method."
SP:0e42de72d10040289283516ec1bd324788f7d371,This paper proposes a method to reduce the computational cost of the PhlatCam camera. The proposed method is based on a Co-design framework that jointly optimizes the model parameters and architectures of the camera and the CNN model. The method is evaluated on four different tasks and six datasets. 
SP:493afcfa3fd64967785928ba3acecf3ffa6ce579,"This paper proposes a temporal matrix factorization model for learning the average developmental path and structured variations of individuals in the social network over their entire lives. The method yields interpretable embeddings that are biologically plausible and consistent over time, which allows comparing individuals regardless of when or in which colony they lived. This method provides a quantitative framework for understanding behavioral heterogeneity in complex social systems applicable in fields such as behavioral biology, social sciences, neuroscience, and information science."
SP:08ae056f269c731b92b5a3d59e18f9ccfc0b703c,"This paper proposes a data augmentation pipeline for image reconstruction from under-sampled linear measurements in medical imaging. The proposed pipeline is based on the Data Augmentation (DA) method for classification problems. The authors demonstrate the effectiveness of the proposed pipeline by showing that for some problem regimes, DA can achieve comparable performance to the state-of-the-art on the fastMRI dataset while using significantly fewer training data."
SP:3fdaae674a2b9d437a43d32778437dc7df9c1686,"This paper proposes a deep repulsive clustering (DRC) algorithm of ordered data for effective order learning. DRC is based on the order-identity decomposition (ORID) network to divide the information of an object instance into an order-related feature and an identity feature. Then, it group object instances into clusters according to their identity features using a repulsive term. Moreover, it estimates the rank of a test instance, by comparing it with references within the same cluster. Experimental results on facial age estimation, aesthetic score regression, and historical color image classification show that the proposed algorithm can cluster ordered data effectively and yield excellent rank estimation performance."
SP:a5775441639529d61b7fee4b4298fd82a0c93bb5,"This paper proposes a simple yet effective episode-level exploration method for procedurally-generated environments. Motivated by how humans distinguish good exploration behaviors by looking into the entire episode, the authors introduce RAPID, a simple, yet effective episodic exploration method. The proposed method regards each episode as a whole and gives an episodic Exploration Score from both per-episode and long-term views. Those highly-scored episodes are treated as good exploration behavior and are stored in a small ranking buffer. The agent then imitates the episodes in the buffer to reproduce the past good exploration behaviours. Experiments on several procedurally generated MiniGrid environments, a first-person-view 3D Maze navigation task from MiniWorld, and several sparse MuJoCo tasks demonstrate the effectiveness of the proposed method."
SP:30024ac5aef153ae24c893a53bad93ead2526476,"This paper proposes Isometric Propagation Network (IPN) for zero-shot learning (ZSL). The key challenge is how to align the representations in the two spaces. Specifically, IPN learns to propagate the class representations on an auto-generated graph within each space. In contrast to only aligning the resulted static representation, this paper regularizes the two dynamic propagation procedures to be isometric in terms of the two graphs’ edge weights per step by minimizing a consistency loss between them. "
SP:1d7c174f4f7a0eb26edceecc117f9af1528802e5,"This paper proposes HyperGrid Transformer, a new Transformer architecture that leverages task-conditioned hyper networks for controlling its feed-forward layers. Specifically, the authors propose a decomposable hypernetwork that learns grid-wise projections that help to specialize regions in weight matrices for different tasks. They conduct an extensive set of experiments on GLUE and SuperGLUE to demonstrate the effectiveness of the proposed method."
SP:d957241c02163c1c5bc03a688aa4a2eb486fb9f1,"This paper studies the effect of different image quality on the performance of the task of ""learning to steer"" for autonomous driving. The authors first analyze how different attributes of image quality affect the performance on the steering task for autonomous vehicles, as quantified by mean accuracy (MA). Then, they propose an effective and efficient training method to improve the generalization of the model for learning-based steering under multiple perturbations. They show that their approach is able to enhance the learning outcomes up to 48%."
SP:2df9ba21f72e041f80c7bc9ecfe89353f172b058,"This paper proposes Deep Constraint Completion and Correction (DC3) to solve constrained optimization problems with hard constraints. Specifically, this method enforces feasibility via a differentiable procedure, which implicitly completes partial solutions to satisfy equality constraints and unrolls gradient-based corrections to satisfy inequality constraints. The authors demonstrate the effectiveness of DC3 in both synthetic optimization tasks and the real-world setting of AC optimal power flow."
SP:61a0163b21dc8f92dd699c1e154f53d30c80b2fe,This paper proposes a new regularization method for deep neural network pruning. The main idea is to grow the penalty factor of the regularization term to a larger and larger size as the number of weights goes to infinity. The authors also propose a growing penalty scheme to exploit the Hessian information for more accurate pruning without knowing the values of the weights. Experiments on CIFAR-10 and ImageNet show that the proposed method outperforms existing methods. 
SP:7b2bf0e36c926d1ed5ab9593a11e4ebce49df6ba,"This paper studies the role of planning in MuZero, a recently proposed model-based reinforcement learning algorithm. The authors evaluate the performance of MuZero on a variety of environments, including control tasks, Atari, and 9x9 Go. They find that planning is most useful in the learning process, both for policy updates and for providing a more useful data distribution. They also find that using shallow trees with simple Monte-Carlo rollouts is as performant as more complex methods, except in the most difficult reasoning tasks. "
SP:96afc34acb196af0b37f66ca9c89ae22ee7b6521,"This paper proposes a method to extend the value iteration networks (VINs) to the case of discrete, continuous, and unknown MDPs. The method is based on a combination of contrastive self-supervised learning, graph representation learning, and neural algorithmic reasoning to alleviate the limitations of VINs. Experiments show that the proposed method outperforms the baselines when the underlying MDP is discrete, fixed, and known. "
SP:b0fa24ad48e7e60d6899bd799adcd03473cadd6e,"This paper studies the inductive bias of neural networks for learning read-once DNFs under uniform distribution with a convex network. The authors show empirically that the learned neurons are aligned with the terms of the DNF, despite the fact that there are many zero-error networks that do not have this property. They show that this risk can be minimized by multiple networks: from ones that memorize data to ones that compactly represent DNF. Then, they use a computer assisted proof to prove that GD is biased towards unique global minima that recover the terms. Finally, they derive a DNF reconstruction method and show that it works in broader settings."
SP:6e600bedbf995375fd41cc0b517ddefb918318af,"This paper proposes a method for learning a dynamic state-transition graph for reinforcement learning. The key idea is to construct a dynamic graph on top of the state transitions in the replay buffer based on historical trajectories and develop an attention strategy on the map to select an appropriate goal direction, which decomposes the task of reaching a distant goal state into a sequence of easier tasks. The authors also leverage graph structure to sample related trajectories for efficient value learning. Experiments show that the proposed method can outperform the state-of-the-art algorithms in terms of sample efficiency."
SP:80c62de18a6a7433c9728fe0d731f733bb89e898,"This paper proposes a method for prioritizing training levels in procedurally generated environments to improve sample efficiency and generalization performance of RL agents trained and evaluated on procedurally-generated environments. The authors propose a general framework for estimating the future learning potential of a level given the current state of the agent’s policy. They find that temporal-difference (TD) errors, while previously used to selectively sample past transitions, also prove effective for scoring a level's future learning capacity when the agent replays (that is, revisits) that level to generate entirely new episodes of experiences from it. They report significantly improved sample-efficiency and generalisation on the majority of Procgen Benchmark environments as well as two challenging MiniGrid environments."
SP:fd92d766a7721a411ff8c422bec18391d028fa78,"This paper proposes a method to adapt auxiliary gradients using a decomposition built from the span of the primary task Jacobian. This decomposition allows a flexible re-weighting of the auxiliary task components and give rise to a family of training strategies. The authors leverage insights from randomized linear algebra and automatic differentiation to scale the approach to large deep networks. Experiments in multitasking, pretraining and domain transfer over vision and text classification task demonstrate the empirical benefit of the framework."
SP:8eb8c34e56de137bfc32ea0fd8cd94e4bff5907d,"This paper studies the problem of one-shot word-object binding in a simulated 3D environment, where the agent is trained with a dual-coding external memory. The agent is shown to be able to manipulate a novel object in the environment, after being introduced to the object via visual perception and language (“This is a dax”). This is achieved by combining short-term, within-episode knowledge of the object with long-term lexical and motor knowledge. The authors show that, under certain training conditions and with a memory writing mechanism, the agent generalizes to novel exemplars within the same ShapeNet category, and is effective in settings with unfamiliar numbers of objects. They also show how dual-Coding memory can be exploited as a signal for intrinsic motivation, stimulating the agent to seek names for objects that may be useful later."
SP:9bd3d99bce743d356eb18692ef93365c78e5fcec,"This paper studies the problem of class-imbalance in the context of few-shot learning. Specifically, the authors study the impact of class imbalance in the support set imbalance, the effect of different imbalance distributions (linear, step, random), and effect of rebalancing techniques (over-sampling, feature transfer) on the performance of several popular few shot learning methods. The authors show that the performances of these methods always drop, by up to 18.0% for optimization-based methods, although feature-transfer and metric based methods generally suffer less. They also show that strategies used to mitigate imbalance in supervised learning can be adapted to the few shot case resulting in better performances."
SP:2a9cbbe3661d2f02f71472d0111f22a739412226,"This paper studies the expressiveness of graph convolutional neural networks (GCNs). The authors argue that the common approach of stacking multiple GC layers may not provide an optimal exploitation of topological information because of the strong coupling of the depth of the network with the size of the topological receptive fields. To address this issue, the authors propose a new GCN architecture that decouples the representation for each node at a different topological distance. The authors prove that their method is more expressive than the most common convolution operators and linear stacking."
SP:b0a6873eb4bbf5cdc4a5dfa08782225ae91fc589,"This paper proposes Sim2SG, a method for sim-to-real transfer for scene graph generation on unlabeled real-world datasets. It decomposes the domain gap into appearance, label, prediction and prediction discrepancies between the two domains, and uses pseudo statistic based self-learning and adversarial techniques to handle these discrepancies. The experiments demonstrate significant improvements over baselines both qualitatively and quantitatively."
SP:ccc72f26d0637476d01671c147b5cb5d30fa8c2d,"This paper proposes Randomized Ensembled Double Q-Learning (REDQ), a model-free algorithm for continuous action reinforcement learning (DRL) with a high update-to-data (UTD) ratio. The algorithm is based on an ensemble of double Q-functions and in-target minimization across a random subset of Q functions from the ensemble. Experimental results show that the proposed algorithm is as good as or better than the state-of-the-art model-based algorithm for MuJoCo."
SP:c424d050996a7f383d2f12418dfdcea90d94ea65,"This paper proposes a new neural network architecture that is invariant under permutation of the features. The proposed architecture, called DIDA, inherits the NN properties of universal approximation, and its robustness with respect to Lipschitz-bounded transformations of the input distribution is established. Experiments are conducted on two tasks: patch identification and performance model learning."
SP:3e5d5b61dceca85c444b3d0d06577229c3146664,"This paper proposes a graph learning method based on graph Laplacian-like matrix in graphical Lasso to learn sparse undirected graphs from high-dimensional input data. The proposed method is based on the spectral graph densification (GDP) method, which is a generalization of GDD with a graph-Laplacians-like precision matrix. The authors show that the proposed method can be used for manifold learning, spectral clustering (SC) and dimensionality reduction."
SP:7e6c73a642a8b3d64156c1d0ecf11f84e7222a22,This paper proposes a method to learn a goal-conditioned policy in an unsupervised manner. The main idea is to learn an abstract-level policy conditioned on a latent variable to optimize a discriminator and discover diverse states that are further rendered into perceptually-specific goals. The learned discriminator serves as an intrinsic reward function for the policy to imitate the trajectory induced by the abstract level policy. Experiments on a variety of robotic tasks demonstrate the effectiveness and efficiency of the proposed method.
SP:bdf293bf2118a927cbec6b96be03bfcad0243640,This paper studies the problem of policy switching in reinforcement learning. The authors propose a new policy switching criterion based on feature distance between the deployed policy and the underlying Q-network. The proposed criterion is evaluated on a medical treatment environment and a collection of the Atari games. 
SP:d06bef9ee5e9bdda1571478b6a8a7a2d3ab42f1b,This paper proposes a homotopy-based algorithm for solving large-scale non-convex optimization problems. The proposed algorithm is based on SGD with homotopic gradient descent (H-SGD). Theoretical analysis is provided to show that the proposed algorithm has a global linear rate of convergence to a neighborhood of a minimum while maintaining fast and inexpensive iterations. Empirical results are also provided to support the theoretical analysis.
SP:195d090d9df0bda33103edcbbaf300e43f4562be,"This paper proposes a meta-learning approach for the task of shape completion, i.e., estimating the 3D shape of real-world objects from sparse point clouds. The key idea is to use an encoder that describes the posterior distribution of a latent representation conditioned on the sparse point cloud. The proposed method is based on the Bayesian approach of Maeda et al. (Maeda et al., 2020) whose posterior estimate behaves asymptotically well with respect to the size of contextual dataset. The authors combine their method with Implicit Geometrical Regularization (IGR) and demonstrate its efficacy on two benchmark datasets (ShapeNet and ICL-NUIM)."
SP:ca637a2692cf2424d1ec5c7d2051c7881a5816f4,This paper proposes a channel-wise activation suppressing (CAS) training strategy to improve the robustness of deep neural networks. The authors highlight two new characteristics of adversarial examples: 1) activation magnitudes are higher than that of natural examples; and 2) the channels are activated more uniformly by adversarial example than natural examples. The proposed CAS is a simple but generic training strategy that can be easily plugged into different defense methods to further improve their robustness. Empirical results show that CAS training strategy can consistently improve adversarial robustness and can be incorporated into existing defense methods.
SP:a50e9aeb17340b141f7b88d522911a5c9229f7d3,"This paper provides a non-asymptotic analysis of overparametrized single-hidden layer linear networks with random initialization. The authors show that the squared loss converges exponentially at a rate that depends on the level of imbalance of the initialization. They show that large hidden layer width, together with (properly scaled) random initialization, implicitly constrains the dynamics of the network parameters to be close to a low-dimensional manifold. In turn, minimizing the loss over this manifold leads to solutions with good generalization, which correspond to the min-norm solution."
SP:7341f8e456c0b80a59595f1cc145b776add3db3f,This paper studies the approximation properties of deep neural networks with ReLU activations. The authors show that the kernel functions of deep networks have essentially the same approximation properties as their shallow two-layer counterpart. This highlights the limitations of the kernel framework for understanding the benefits of such deep architectures. The main theoretical result relies on characterizing such eigenvalue decays through differentiability properties of kernel function. 
SP:3dd495394b880cf2fa055ee3fe218477625d2605,"This paper studies the problem of minimizing the overestimation bias in reinforcement learning. Specifically, the authors propose to use a weight factor to adjust the influence of two independent critics, and use the combined value of weighted critics to update the policy. Then the updated policy is involved in the update of the weight factor, in which the authors provide theoretical and experimental guarantees for future policy improvement. The authors evaluate their method on a set of classical control tasks and show that the proposed algorithms are more computationally efficient and stable than several existing algorithms."
SP:a7f72a5f99f2e3e1a643e9bb83bf0416a859ec06,"This paper studies the inverse reinforcement learning (IRL) problem, where the goal is to recover the reward functions from expert demonstrations. The authors propose to use the Monte Carlo expectation-maximization (MCEM) method to estimate the parameter of the probability distribution as the first solution to the SIRL problem. The solution is succinct, robust, and transferable for a learning task and can generate alternative solutions to the IRL problem. Experiments on the object world show the effectiveness of the proposed method."
SP:ee628e3ddc01de3f915b04834245c2250015e4d0,"This paper provides a unified theoretical analysis of self-training with deep networks for semi-supervised learning, unsupervised domain adaptation, and unsupervisory learning. The authors propose a simple but realistic “expansion” assumption, which states that a low-probability subset of the data must expand to a neighborhood with large probability relative to the subset. They also assume that neighborhoods of examples in different classes have minimal overlap. They prove that under these assumptions, the minimizers of population objectives based on self training and input-consistency regularization will achieve high accuracy with respect to ground-truth labels. "
SP:daa229d78712808420aad4c50604fc28fd2a4aba,"This paper proposes a method for long-term video prediction based on a hierarchical model with a general structure representation (i.e., dense semantic label map) and a variational sequence model to predict the motion and content change in this label space. The method predicts future frames by first estimating a sequence of semantic structures and then translating the structures to pixels by videoto-video translation. The proposed method is evaluated on three challenging datasets involving car driving and human dancing. "
SP:e50b1931800daa7de577efd3edca523771227b3f,"This paper proposes a new graph neural network (GNN) architecture called Iterated Function System (IFS) which is based on the iterative function system (IFS). The key idea of IFS is to use a pair of affine transformations to characterize the process of message passing between graph nodes and assign an adjoint probability vector to them to form an IFS layer with probability. After embedding in the latent space, the node features are sent to IFS layers for iterating, and then obtain the high-level representation of graph nodes. The paper also analyzes the geometric properties of IGNNS from the perspective of dynamical system. "
SP:89d65999a0600ec4f81daf6232fb5897676b3ce3,"This paper proposes a geometric graph generative adversarial network (GG-GAN) for graph generation, which is a Wasserstein GAN that is permutation equivariant and can be used to generate graphs of size tens of thousands of nodes. The main contributions of the paper are three-fold: 1. The authors propose a new geometric graph generator that is based on the geometric connection between nodes and edges based on a similarity function. 2. The proposed generator is able to model complex relations, 3. The generator is capable of fully exploiting the latent distribution."
SP:4f9388c18e44995fb1c6830256c520ff47a2e6ee,"This paper proposes an unsupervised method EXPLAINN to mine noise-robust rules of the form X → Y, where X and Y are sets of neurons in different layers. The method is based on the minimum description length principle to identify the best set of rules as the one that best compresses the activation data. Extensive evaluation shows that the rules give clear insight in how networks perceive the world: they identify shared, resp. class-specific traits, compositionality within the network, and locality in convolutional layers. "
SP:fc75d8d62ac5cc4cdde1b923ae54659a0dfba28b,"This paper studies the problem of policy optimization in the fixed-dataset setting. The authors provide a unified framework for the study of algorithms in this regime. They show that for naııve approaches, the possibility of erroneous value overestimation leads to a difficult-to-satisfy requirement: in order to guarantee that we select a policy which is near-optimal, we may need the dataset to be informative of the value of every policy. To avoid this, algorithms can follow the pessimism principle, which states that we should choose the policy which acts optimally in the worst possible world, and derive families of algorithms which follow this principle. "
SP:363661edd15a06a800b51abc1541a3191311ee0e,"This paper proposes a memory-efficient ALF Integrator (MALI) method to estimate the gradient of a Neural ODE. The method is based on the asynchronous leapfrog (ALF) solver, which has a constant memory cost w.r.t. number of solver steps in integration similar to the adjoint method, and guarantees accuracy in reverse-time trajectory (hence accuracy in gradient estimation). The authors validate MALI in various tasks: on image recognition tasks, to their knowledge, the proposed method is the first to enable feasible training of a neural ODE on ImageNet and outperform a well-tuned ResNet, while existing methods fail due to either heavy memory burden or inaccuracy. For time series modeling, the authors demonstrate the effectiveness of their method."
SP:45b6d522ed9a2ecda2db0a3d45688ed3b0f32875,"This paper proposes a methodology to compare complex scene conditional generation models, and provides an in-depth analysis that assesses the ability of each model to (1) fit the training distribution and hence perform well on seen conditionings, (2) to generalize to unseen conditionings composed of seen object combinations, and (3) generalizing to unseen conditions composed of unseen object combinations. The paper shows that recent methods are able to generate recognizable scenes given seen conditions, and exploit compositionality to generalise to unseen conditioned conditionings. However, all methods suffer from noticeable image quality degradation when asked to generate images from unseen conditions. Through an extensive evaluation, the paper identifies the advantages of different pipeline components, and finds that encouraging compositionality through instance-wise spatial conditioning normalizations increases robustness to both types of unseen conditions, using semantically aware losses such as the scene-graph perceptual similarity helps improve some dimensions of the generation process, and enhancing the quality of generated masks."
SP:77bce8c5d383f6be82ebc694bf66fb1a408ad751,"This paper studies the expressive power of Graph Augmented Multi-Layer Perceptron (GA-MLP) and Graph Neural Network (GNN). The authors show that GA-MLPs with suitable operators can distinguish almost all non-isomorphic graphs, just like the Weisfeiler-Lehman (WL) test and GNNs. However, by viewing them as node-level functions and examining the equivalence classes they induce on rooted graphs, the authors prove a separation in expressive power that grows exponentially in depth. The authors also demonstrate via community detection experiments, demonstrating that GNN has higher flexibility in learning."
SP:5c0783e92017fc808ebd44a7d1aa7f6b92baacd8,"This paper proposes an Actor-Learner Distillation (ALD) procedure that transfers learning progress from a large capacity learner model to a small capacity actor model. ALD is a continual form of policy distillation (PDD) that leverages a continual distillation procedure to compress, online, a larger “learner model” towards a tractable “actor model’’. In particular, ALD focuses on the distributed RL setting applied to partially-observable environments, where the authors aim to exploit the transformer model's superior sample-efficiency while still having parity with the LSTM model's computational-efficiency during acting. On challenging memory environments where the transformer has a clear advantage over LSTMs, the authors demonstrate that ALD provides substantially improved sample efficiency."
SP:ccd59c3acb3d0886030451bbaea68fb83ef4dfa5,This paper proposes a Universal Representation Transformer (URT) layer that meta-learns to leverage universal features for few-shot image classification by dynamically re-weighting and composing the most appropriate domain-specific representations. The URT layer on top of a universal representation’s pre-trained backbones sets a new state-of-the-art performance on Meta-Dataset. It achieves top-performance on the highest number of data sources compared to competing methods. The authors analyze variants of URT and visualize the attention score heatmaps.
SP:beaa3dfef4bdf3d8fea64d4cf86911f45edd2873,"This paper studies the problem of unsupervised progressive learning (UPL) in a non-stationary stream of unlabeled data in which the number of object classes increases with time. To solve the UPL problem, the authors propose an architecture that involves an online clustering module, called Self-Taught Associative Memory (STAM). The proposed architecture is based on a combination of clustering, novelty detection, forgetting outliers, and storing prototypical representations rather than specific examples. Experiments are conducted to demonstrate the effectiveness of the proposed method."
SP:f7a8e5a580524d54f4a0cd08bd3cb0a0a074528b,"This paper studies the generalization gap between decentralized and centralized training of deep learning models. The authors identify the changing consensus distance between devices as a key parameter to explain the gap between centralized and decentralized training. They show that when the consensus distance does not grow too large, the performance of centralized training can be reached and sometimes surpassed. They highlight the intimate interplay between network topology and learning rate at the different training phases and discuss the implications for communication efficient training schemes. "
SP:08ab81a53ae0b51b214442f2f9d6edca0df9118c,This paper proposes a novel method for sequence representation learning based on the analogy between synchronized trajectories produced by dynamical systems and the distance between similar sequences processed by a siamese recurrent neural network. The authors propose a new neural network model that implements this coupling with a new gate integrated into the classical Gated Recurrent Unit architecture. This model is able to simultaneously learn a similarity metric and the synchronization of unaligned multi-variate sequences in a weakly supervised way. The experiments show that introducing such a coupling improves the performance of the Siamese GRU architecture on an activity recognition dataset.
SP:e32bb6044bcb26cad3b0161db19170d726c40fae,"This paper studies the effect of codistillation (codistillation) on the performance of distributed models trained with SGD. In particular, the authors focus on the case where two different models are trained with different batch sizes and different learning rate schedules. The authors show that under the same batch size and learning rate schedule, the performance is comparable to that of parallel SGD while using a much weaker synchronization mechanism. The main contribution of the paper is that the authors provide empirical evidence that codistill is a regularizer. "
SP:cd03bc0b12cf44e9d538d274de7dfe44acdb1e35,"This paper studies the generalization properties of SGD in deep neural networks. The authors show that SGD converges to a heavy-tailed stationary distribution with infinite variance, depending on the structure of the Hessian of the loss at the minimum and the choices of the algorithm parameters $\eta$ and $\beta$. The authors prove this result in the setting of quadratic optimization and show that even in a simple linear regression problem with independent and identically distributed Gaussian data, the iterates can be heavy-tailored. They further characterize the behavior of the tails with respect to algorithm parameters, the dimension, and the curvature. Finally, the authors translate their results into insights about the behavior in deep learning."
SP:89f995142f8a2fcdc8c7b9f2e2cd1a4f75df3226,"In this paper, the authors study the impact of bandpass filtering on the performance of GCNs for community detection. They empirically show that most of the necessary and used information for nodes classification is contained in the low-frequency domain, and thus contrary to Euclidean graph (e.g., images), high-frequencies are less crucial to the community detection task. They also show that it is possible to obtain accuracies at a state-of-the-art level with simple classifiers that rely only on a few low frequencies. "
SP:7fc7e37c699a1bb738c65f0c6fa983203c6fd067,"This paper proposes a self-supervised approach to learn a task-specific latent graph structure and a graph neural network (GNN) from data. The authors claim that the space of possible graph structures grows super-exponentially with the number of nodes and so the taskspecific supervision may be insufficient for learning both the structure and the GNN parameters. To solve this problem, the authors propose the Simultaneous Learning of Adjacency and GNN Parameters with Self-supervision, or SLAPS, a method that provides more supervision for inferring a graph structure. The experiments show that SLAPS scales to large graphs with hundreds of thousands of nodes. "
SP:8f8e1fa4cd025fc056a60c0b6ba9915e8617447f,"This paper proposes a novelty detection method for continual learning. The novelty detection method is based on the network confusion caused by training incoming data as a new class. In addition, a class-imbalance term is added to the novelty detection to further improve the performance of the proposed method. The proposed method is evaluated on a variety of image classification benchmarks."
SP:1d242517748c52f2be8f0613316cda3a54d1d2f7,"This paper proposes a new multi-task environment, called HazardWorld, where the goal is to optimize reward while not violating constraints specified in free-form text. The authors propose a modular architecture that can interpret and adhere to such textual constraints while learning new tasks. The model consists of a constraint interpreter that encodes textual constraints into spatial and temporal representations of forbidden states, and a policy network that uses these representations to produce a policy achieving minimal constraint violations during training. The experimental results show that the proposed method achieves higher rewards (up to 11x) and fewer constraint violations (by 1.8x) compared to existing approaches."
SP:bc9f37b4622868a92f9812d2ea901def79229d41,"This paper proposes a few-shot semantic edge detection method based on semantic segmentation. The proposed method is based on a segmentation module in low resolution and utilizes segmentation masks to generate attention maps. The attention maps are applied to multi-scale skip connection to localize the semantically related region. In addition, a new regularization method is proposed based on multi-split matching. Experiments are conducted on two new datasets, FSE-1000 and SBD-5."
SP:5e99fee48137d3d3d88017a02f7285ce35dce970,"This paper proposes a method for generating causal explainable explanations for GNNs. The proposed method, Causal Screening, incrementally selects a graph feature (i.e., edge) with large causal attribution, which is formulated as the individual causal effect on the model outcome. As a model-agnostic tool, it can be used to generate faithful and concise explanations for any GNN model. Experiments on three graph classification datasets demonstrate the effectiveness of the proposed method."
SP:5b3d76b9e67bc39a813979b5d232a59f597d257d,"This paper proposes a new measure, prunability, which is the smallest fraction of the network’s parameters that can be kept while pruning without adversely affecting its training loss. The authors show that this measure is highly predictive of the generalization performance across a large set of convolutional networks trained on CIFAR-10. They also show that their measure is similar to – but more predictive than – existing flatness-based measures."
SP:835d01ee91523fb29595cae8339dfe49de7d3a7c,"This paper proposes an unsupervised discrete representation learning method for long-term planning. The method learns a sequence of abstract states for a low-level model-predictive controller to follow. In the experiments, the authors show that the proposed method is able to solve unseen long-horizon tasks. "
SP:2e31a542a7a60b1d425d95dd26e62374ba799cb8,"This paper proposes bit-level sparsity quantization (BSQ) to tackle the mixed-precision quantization from a new angle of inducing bit level sparsity. The authors consider each bit of quantized weights as an independent trainable variable and introduce a differentiable bit-sparsity regularizer. BSQ can induce all-zero bits across a group of weight elements and realize the dynamic precision reduction, leading to a mixed precision quantization scheme of the original model. The method enables the exploration of the full mixed precision space with a single gradient-based optimization process."
SP:9b8ae88357e03447c73c792ff5c173ddc3d365e7,This paper studies the robustness of quantized neural networks against gradient-based adversarial attacks. The authors show that quantized networks suffer from gradient vanishing issues and show a fake sense of robustness. They propose a simple temperature scaling approach to mitigate this issue while preserving the decision boundary. Experiments on CIFAR-10/100 datasets with multiple network architectures demonstrate that their temperature scaled attacks obtain near-perfect success rate.
SP:16dddbe1432e4ffbf4b2a9180bf3c67495bd9e81,"This paper proposes a novel recurrent neural network (RNN) model, called ProtoryNet, which is inspired by the prototype theory in modern linguistics. The proposed method makes a prediction by finding the most similar prototype for each sentence in a text sequence and feeding an RNN backbone with the proximity of each of the sentences to the prototypes. Experiments conducted on multiple public data sets reveal that the proposed method is more interpretable and more accurate than the current state-of-the-art prototype-based method."
SP:ac8a9afa6e87f9c36d080c2e7085c4e096af64ff,"This paper proposes a new hidden Markov model (HMRNN) that is a special case of recurrent neural networks (RNNs). The authors prove that each HMRNN has the same likelihood function as a corresponding discrete-observation HMM. The authors also show that the parameter estimates are numerically close to those obtained from via the Baum-Welch algorithm, validating their theoretical equivalence. Finally, the authors demonstrate that the proposed model can be combined with other neural networks to improve parameter estimation, using an Alzheimer’s disease dataset."
SP:6355337707f1dd373813290e26e9c0a264b993f9,"This paper proposes a new method for analyzing single-cell RNA-Seq data of Drosophila T4/T5 neurons. The method is based on factorized linear discriminant analysis (FLDA), which is motivated by multi-way analysis of variance (ANOVA) and seeks a linear transformation that varies highly with one specific factor but not with the others. The authors also introduce a sparse variant of the method, which constrains the number of genes contributing to each linear projection. Experiments show that FLDA can identify new genes related to the phenotypes."
SP:28e61a4f51f9f7283397d6336ea114375ae6a004,This paper proposes a new method for generating saliency maps for interpretability. The saliency map is considered as a random variable and the posterior distribution over it is computed by minimizing the ELBO. The proposed method is evaluated on the pixel perturbation benchmark to show the effectiveness of the method.
SP:01acd8b88768d86bcf21b8c20a930d706c5645a7,"This paper proposes a neural debiasing method for pretrained text encoders. The authors propose a fair filter (FairFil) network, which takes the original sentence embeddings as input and outputs the debiased sentence embedding. To train the fair filter, the authors use a multi-view contrastive learning framework, which maximizes the mutual information between each sentence and its augmentation. The augmented sentence is generated by replacing sensitive words in the original sentences with words in a similar semantic but different bias directions. To further eliminate bias from sensitive words, the paper also proposes a regularizer, which minimizes the minimization of the shared information between the de-biased embedding and the corresponding sensitive words. The experiments show that the proposed FairFil outperforms Sent-Debias (Liang et al., 2020) in terms of fairness and representativeness."
SP:f2f505d3f07ca3bb2f16f6f6f5d00fee98da6531,"This paper proposes a randomized smoothing-based method to improve the robustness of neural networks against adversarial perturbations. In particular, the proposed method assigns different noise levels to different samples during training and testing. Specifically, the authors propose a pretrain-to-finetune framework that first pretrains a model and then adjusts the noise levels for higher performance based on the model’s outputs. For certification, they carefully allocate specific robust regions for each test sample. Experiments are conducted on CIFAR-10 and MNIST datasets to demonstrate the effectiveness of the method."
SP:692c7b9f6d982bbc5a22e566296a97e8a530b87c,"This paper proposes a variational autoencoder-based method for unsupervised data recovery from corrupted data. The proposed method is motivated by the observation that the posterior distribution of clean data given corrupted data is not always the same as that of the clean data. To address this issue, the authors propose to use a reduced entropy condition approximate inference method to approximate the posterior distributions of clean and corrupted samples. The authors show that their method recovers accurate posteriors of clean values, allowing the exploration of the manifold of possible reconstructed data and hence characterising the underlying uncertainty. The method is evaluated on a variety of data recovery tasks, including imputation and de-noising."
SP:4b7d050f57507166992034e5e264cccab3cb874f,"This paper proposes Multi-hop Attention Graph Neural Network (MAGNA) to incorporate multi-hop context information into attention computation, enabling long-range interactions at every layer of the GNN. To compute attention between nodes that are not directly connected, MAGNA diffuses the attention scores across the network, which increases the “receptive field” for every layer. Experimental results on node classification and knowledge graph completion benchmarks show that MAGNA achieves state-of-the-art results."
SP:36310d761deb19e71c8a57de19b48f857707d48b,"This paper proposes a new multi-task multitask test to evaluate the ability of text models to learn and apply knowledge encountered during pretraining. The test covers 57 tasks including elementary mathematics, US history, computer science, law, and more. The authors find that while most recent models have near random-chance accuracy, the very largest GPT-3 model improves over random chance by almost 20 percentage points on average. However, on every one of the 57 tasks, the best models still need substantial improvements before they can reach expert accuracy."
SP:7d7d34ba6e9fb36f2658cf4be44b137cdd73d34c,"This paper proposes a pre-training approach for table semantic parsing. The authors propose to construct synthetic question-SQL pairs over high-quality tables via a synchronous context-free grammar (SCFG). They pre-train GRAPPA on the synthetic data to inject important structural properties commonly found in table semantic parsers into the pre-trained language model. They also include masked language modeling (MLM) on several existing table-and-language datasets to regularize the model’s ability to represent real-world data. When incorporated with strong base semantic parsing models, the proposed method achieves new state-of-the-art results on four popular semantic parsing tasks."
SP:ebbb25902804b4f9f4985311c5debe2ef0ad7c7c,"This paper studies the least-square support vector machine multi-task learning (LS-SVM MTL) method in the limit of large (p) and numerous (n) data. By a random matrix analysis applied to a Gaussian mixture data model, the performance of MTL is shown to converge, as n, p→∞, to a deterministic limit involving simple (small-dimensional) statistics of the data. The authors prove that the standard MTL LS-SVMs algorithm is in general strongly biased and may dramatically fail (to the point that individual single-task MTL methods may outperform the MTL approach, even for quite resembling tasks): their analysis provides a simple method to correct these biases, and that they reveal (ii) the sufficient statistics at play in the method, which can be efficiently estimated. The latter result is exploited to automatically optimize the hyperparameters without resorting to any cross-validation procedure. Experiments on popular datasets demonstrate that the proposed method is computationally-efficient and outperforms sometimes much more elaborate state-of-the-art methods."
SP:2be727b1333122fef3abfd2f7c576d2fc467893f,"This paper proposes a conditional neural process with group equivariance (EquivCNP) that is permutation invariant and group-equivariant. The authors give a decomposition theorem for permutation-invariant permutation and group invariant maps, which leads them to construct EquivCNPs with an infinite-dimensional latent space to handle group symmetries. Experiments are conducted on a 1D regression task and a 2D image completion task. "
SP:a54b0358a0a2900f76a2da7a0a99348805c8d66a,"This paper proposes a text generation method based on off-policy learning from expert demonstrations. The key idea is to use an importance weighting method to upweight confident tokens and downweight unconfident ones in the reference during training, avoiding optimization issues faced by prior RL approaches that rely on online data collection. Experiments on summarization, question generation, and machine translation show that the proposed method outperforms autoregressive models."
SP:e77eca51db362909681965092186af2e502aaedc,"This paper proposes an information propagation (InfoPro) loss that encourages local modules to preserve as much useful information as possible, while progressively discard task-irrelevant information. The authors derive a feasible upper bound as a surrogate optimization objective, yielding a simple but effective algorithm. Extensive experiments validate that InfoPro is capable of achieving competitive performance with less than 40% memory footprint compared to E2E training."
SP:21e44dddd20db1768de0dab869f8b0d3d5a598b7,"This paper proposes a novel sampling strategy to improve the expressive power of GNNs. The sampling strategy is based on diverse neighborhoods, i.e., rooted sub-graphs, and the representation of the target node is obtained by aggregating the representations of diverse neighborhoods obtained using any GNN model. Experiments are conducted at multi-class node classification task on three benchmark datasets and multi-label node classification."
SP:e9a8956f067a55b794508ac69f93b4b0290a664c,"This paper investigates the effect of network and file corruptions on video model robustness. The authors find that these corruptions significantly decrease performance on benchmark tasks like action recognition and multi-object tracking. They propose a corruption-aware defense baseline, Bit-corruption Augmented Training (BAT), which incorporates knowledge of network corruptions directly. Experiments show that BAT can improve performance by up to 7.1% accuracy, and outperforms corruption-agnostic baselines (OOD detection and AT) at a wide range of corruption levels."
SP:35f77a7dcce3f6e09db0db9d22207a6da1fdbe5c,"This paper proposes a new method for learning representations of time-varying graphs. The method is based on the skip-gram embedding approach, which can be used to perform implicit tensor factorization on different tensor representations. The proposed method is evaluated on time-resolved face-to-face proximity data, showing that the learned representations outperform state-of-the-art methods when used to solve downstream tasks such as network reconstruction. "
SP:bac0a2d3478dd277cb1ceafedd7fff64e107a222,"This paper proposes a new self-supervised training task for language models for formal mathematical formulas. The task is based on the skip-tree task, where the goal is to predict the type of a given statement. The paper also proposes several evaluation tasks, including inferring types, inferring missing assumptions, and completing equalities. The authors show that models trained on the proposed task show surprisingly strong mathematical reasoning abilities. "
SP:808f6d3af382876f5518e8e3a14ea73cc59c0a2b,"This paper studies the problem of imbalanced gradients in adversarial robustness. The authors propose a novel method to attack the imbalanced gradient problem by decomposing the margin loss into individual terms and then exploring the attackability of these terms separately via a two-stage process. They examine 12 state-of-the-art defense models, and find that models exploiting label smoothing easily cause imbalance gradients, and on which our MD attacks can decrease their PGD robustness (evaluated by PGD attack) by over 23%. For 6 out of the 12 defenses, our attack can reduce the robustness of these defenses by at least 9%."
SP:2180e15ad0bbecc98e043b41f6525d2a8061d304,"This paper presents an incremental graph-to-sequence neural network system for proving semantic equivalence between two programs. The system is based on graph neural networks (GNNs) and is trained on a rich symbolic language for linear algebra expressions. The paper shows that the system achieves 93% average true positive coverage on 10,000 test cases while ensuring zero false positives by design. "
SP:19e32803278a7ad2be5343187468cd2e26335bc8,"This paper proposes a multimodal bidirectional Transformer architecture for self-supervised learning of contextualized audio-visual representation from unlabeled videos. The authors propose to decompose the Transformer into modality specific and modality-shared parts so that the model learns the dynamics of each modality both individually and together, and propose a novel parameter sharing scheme based on low-rank approximation. They also propose a negative sampling approach based on an instance similarity measured on the CNN embedding space that our model learns together with the Transformers. "
SP:a5c22c090413ef4448db8e7f5b39332b3db6c73f,This paper proposes an online contextualized few-shot learning (OC-FSL) paradigm for machine learning that emulates a human or artificial agent interacting with a physical world. The authors propose a new dataset based on large scale indoor imagery that mimics the visual experience of an agent wandering within a world. They convert popular FSL approaches into online versions and propose a contextual prototypical memory model that can make use of spatiotemporal contextual information.
SP:9c87f7778b8ee5d3e65fb1204b8067f12aac94e1,"This paper studies the problem of training GNNs on temporal graphs. The authors systematically analyze these issues by incrementally training and evaluating GNN models in a sliding window over temporal graphs, and show that no more than 50% of the GNN’s receptive field is necessary to retain at least 95% accuracy compared to training over a full graph. They experiment with three representative GNN architectures and two scalable GNN techniques, on three new datasets. "
SP:dce0bbc266a9ac746f0db5099836fa57a3055f4a,This paper proposes a self-constraint term to regularize the representation feature space by comparing representation similarity across different pairs of states. The proposed method is based on the observation that the behavior of a rational agent would have certain relationship with general cross-state features or patterns. Experiments are conducted on the OpenAI ProcGen benchmark to demonstrate the effectiveness of the proposed method.
SP:3dda3d53fdc4bd8045db22cac740322e31e67bcf,"This paper studies adversarial attacks on GNNs in a restricted near-black-box setting. The authors formulate the problem of adversarial attack as an optimization problem to maximize the mis-classification rate. They draw a connection between this problem and influence maximization based on a linear threshold model. Based on this connection, they develop effective and efficient near black-box attack strategies. The experiments verify the effectiveness of the proposed strategies."
SP:fca0583b19bd08f59fdb0e46f86a4b27495dd0df,This paper studies the problem of learning causal DAGs with a low-rank assumption. The authors propose to exploit a low rank assumption regarding the (weighted) adjacency matrix of a DAG causal model to mitigate this problem. They demonstrate how to adapt existing methods for causal structure learning to take advantage of this assumption and establish several useful results relating interpretable graphical conditions to this assumption. They also provide empirical evidence for the utility of their low rank adaptations. 
SP:f2c8172adcb82ed1c0e047ffed65412f3f1c1ac7,"This paper proposes a differentiable joint optimization solution for efficient end-to-end AutoML (DiffAutoML) that performs co-optimization of neural architectures, training hyper-parameters and data augmentation policies in an end- to-end fashion without the need of model retraining. Experiments show that DiffAutoML achieves state-of-the-art results on ImageNet compared with end to end AutoML algorithms."
SP:1ab30867e0bd8b6b65fad602cd80bada70b3f1ec,"This paper proposes a method for estimating the uncertainty of a regression model from a Normal-Wishart distribution. The proposed method is based on a prior network that predicts the parameters of the distribution and a distribution distillation method that distills an ensemble of ensembles of regression models into a single model. The method is evaluated on synthetic data, selected UCI datasets and two monocular depth estimation tasks."
SP:fe2aa4706defcac74e529d0cc3e1622d77451eca,This paper proposes a Bayesian online meta-learning framework to tackle the catastrophic forgetting and the sequential few-shot tasks problems. The framework incorporates MAML into a Bayes online learning algorithm with Laplace approximation or variational inference. The experimental evaluations demonstrate that the proposed framework can effectively prevent catastrophic forgetting.
SP:89d2765946e70455105a608d998c3b900969cb8d,This paper studies the expressive power of graph neural networks (GNNs) with respect to the number of subgraphs of size k. The authors propose a new pooling technique of local neighborhoods that allows different tradeoffs of computational cost and expressive power. They show that this model can count subgraph of size $k$ and thereby overcomes a known limitation of low-order GNNs. They also provide an information-theoretic lower bound on the complexity of a general class of GNN that can count (induced) substructures with at most k vertices.
SP:c43f5deb340555d78599a3496318514a826b1aae,"This paper analyzes the behavior of MWU, OMWU, and FTRL in bimatrix games and multi-player games. The main contribution of this paper is to analyze the volume-changing behavior of these algorithms on the cumulative payoff space. The analysis is based on decomposing the game into the zero-sum part and the coordination part. The authors show that MWU is Lyapunov chaotic almost everywhere in the cumulative reward space. "
SP:0cf756ba6b172f9b29e84945c093dfd89ae62803,This paper proposes an adaptive algorithm for deep learning based on marginal regret bound minimization. The main idea is to design a proximal function that maximizes the marginal regret of the gradient of the loss function at each time step. The authors show that the proposed algorithm converges faster than existing adaptive algorithms and achieves marginal optimality in the long term. They also show that their algorithm is more general and converge faster than other adaptive algorithms. 
SP:b6b594fc555bd12b33f156970f0665e2bf793484,"This paper proposes a new framework for policy gradient style reinforcement learning (RL) algorithms with mean-variance control. The framework is based on the expected quadratic utility maximization (EQUM) which is a common objective of risk management in finance and economics. The proposed framework has several interpretations, such as reward-constrained variance minimization and regularization, as well as agent utility maximisation. In experiments, the authors demonstrate the effectiveness of the proposed method in benchmark setting of RL and financial data."
SP:bf9d66f713b6502d274143c6273b2d071a0c045e,"This paper proposes a novel auxiliary learning method called AuxiLearn, which is based on implicit differentiation. The authors propose a unified approach for combining multiple loss terms and for learning novel auxiliary tasks from the data alone. They also provide a theoretical observation on the capacity of auxiliary learning and show that the key quantity for determining beneficial auxiliaries is the Newton update. Finally, they show that implicit differentiation can play a significant role in automating auxiliary learning setups."
SP:3070fd64f8eb4d7ece6521cb975fd1fe64d6329f,This paper proposes a new measure of uncertainty for detecting out-of-distribution sentences in Neural Machine Translation. The measure is based on the dropout uncertainty of a Transformer model trained with dropout approximate inference. The authors show that their measure is able to identify when a given sentence is given to the model instead of German. 
SP:d5a1d9596b8329312533b3a0047c815f8e71a201,"This paper studies the effect of random shuffling and reinitialization on the accuracy of pruning neural networks at initialization. The authors compare SNIP (Lee et al. 2019), GraSP (Wang et al., 2020), SynFlow (Tanaka et al, 2020), and magnitude pruning (de Jorge et al 2020). They show that, unlike magnitude prune after training, randomly shuffling the weights these methods prune within each layer or sampling new initial values preserves or improves accuracy. This property suggests broader challenges with the underlying pruning heuristics, the desire to prune at initialization, or both."
SP:1f6b266021da24bbf02b5a47f2b5eb23b4912166,"This paper proposes Fed-Learning, a federated learning protocol that can defend against both a semi-honest server and Byzantine malicious clients. The authors propose to use a robust mean estimator called FilterL2 to robustly aggregate the possibly contaminated updates and secure aggregation to protect the privacy of the clients. They propose to split the clients into shards, securely aggregate each shard’s updates and run the robust estimator on the updates from different shards. The evaluation shows that FED-LEARNING consistently achieves optimal or close-to-optimal performance under three attacks."
SP:9f89ff90b203d86a569e3d5148546942f5bf2093,"This paper proposes a new benchmark for offline model-based optimization (MBO) problems. The benchmark consists of a suite of offline MBO tasks with a unified evaluation protocol and reference implementations of recent methods. The proposed benchmark includes diverse and realistic tasks derived from real-world problems in biology, material science, and robotics. The authors provide a comprehensive evaluation of existing methods under identical assumptions and show that the simple baseline method of learning an objective value predictor and performing gradient ascent on its input outperforms several prior MBO methods in the benchmark."
SP:073958946c266bf760d1ad66bd39bc28a24c8521,"This paper proposes a self-supervised generative model for multi-modal multimodal data. The proposed model is based on a mixture-of-product-of experts (MoPoE-VAE) model, which is a generalization of MVAE and MMVAE. The authors show that the proposed model achieves better performance than the baselines on a variety of tasks. "
SP:98004554447b82b3d2eb9724ec551250eec7a595,"This paper proposes a new Bayesian optimization method called Prior-guided Bayesian Optimization (PrBO) that allows users to inject their knowledge into the optimization process in the form of priors about which parts of the input space will yield the best performance, rather than BO’s standard priors over functions (which are much less intuitive for users). PrBO then combines these priors with BO's standard probabilistic model to form a pseudo-posterior used to select which points to evaluate next. The authors show that PrBO is around 12x faster than state-of-the-art methods without user priors and 10,000 times faster than random search on a common suite of benchmarks."
SP:e0e9cd5f39a60b5db1c4363ffdc2c593300ef43a,"This paper proposes to use binary neural networks to reduce the computational cost of deep generative models. Specifically, the authors propose a new class of binary weight normalization, and provide insights for architecture designs of these binarized generative model. The authors demonstrate that two state-of-the-art models, the ResNet VAE and Flow++ models, can be binarised effectively using these techniques. "
SP:7e9a83552c0ff001d3090a5a7162013b5dc6f47f,"This paper proposes a model-based robust training paradigm for deep learning that provides robustness with respect to models of natural variation. Specifically, the authors propose a paradigm shift from perturbation-based adversarial robustness to model based robust deep learning. The authors show that their method can provide robustness against natural, out-of-distribution data, against multiple simultaneous distributional shifts, and against domains entirely unseen during training. "
SP:011dab90d225550e77235cbec1615e583ae3297e,"This paper studies the optimization of CNNs with ReLU activations. The authors introduce exact convex optimization formulations with a polynomial complexity with respect to the number of data samples, number of neurons, and data dimension. They first prove that two-layer CNNs can be globally optimized via an `2 norm regularized convex program. They then show that multi-layer circular CNN training problems with a single ReLU layer are equivalent to an `1 norm regularization. They also extend these results to three-layer networks with two ReLU layers. "
SP:98760a3b1a5058a485a5a1ed1b778c1d4fb2ff22,"This paper studies the problem of interpretable learning from demonstration as an optimisation problem over a probabilistic generative model. The latent variables in this model are explicitly aligned with high-level notions and concepts that are manifested in a set of demonstrations. They show that such alignment is best achieved through the use of labels from the end user, in an appropriately restricted vocabulary, in contrast to the conventional approach of the designer picking a prior over the latent variables. Their approach is evaluated in the context of two table-top robot manipulation tasks performed by a PR2 robot. "
SP:e171d8c4eadf73852734c0fb8a74a69d80969e4b,"This paper proposes a method for reducing the overfitting of large pre-trained language models on low-resource tasks. The authors propose to use Variational Information Bottleneck (VIB) to suppress irrelevant features when fine-tuning on low resource target tasks, and show that their method successfully reduces overfitting. Moreover, the authors show that the VIB model finds sentence representations that are more robust to biases in natural language inference datasets, and thereby obtains better generalization to out-of-domain datasets."
SP:a1ab99bee74a0a1310537beced0d89dc1e5ad7be,"This paper proposes a method to recover 3D shape from a single 2D image using an off-the-shelf 2D GAN. The method is based on an iterative strategy that explores and exploits diverse viewpoint and lighting variations in the GAN image manifold to refine the underlying object shape. The proposed method does not require 2D keypoint or 3D annotations, or strong assumptions on object shapes (e.g. shapes are symmetric), yet it successfully recovers 3D shapes with high precision. "
SP:eac0679dfee4dae78c1e515f8b325c9523b795dc,"This paper proposes a multi-expert model called RIDE for long-tail recognition. RIDE is based on a distribution-aware diversity loss and a dynamic expert routing module. The proposed method is evaluated on CIFAR-100-LT, ImageNet-LT and iNaturalist. "
SP:f4d0e821de6830722a3458fd40d8d6793a107827,"This paper analyzes the effectiveness of different pruning criteria for channel pruning in CNNs. The authors find that there are two blind spots in the existing methods for pruning CNNs: (1) Similarity: There are some strong similarities among several primary pruning metrics that are widely cited and compared, resulting in similar pruned structures. (2) Applicability: The filters’ Importance Score measured by some prune criteria are too close to distinguish the network redundancy well. Based on these observations, the authors propose and verify an assumption called CWDA, which reveals that the well-trained convolutional filters in each layer approximately follow a Gaussian-alike distribution."
SP:eadb827653b2e1b608bb923d5549089cb2482d90,"This paper proposes a pre-trained transformer-based model called GraphCodeBERT that uses data flow to model the semantic structure of code. Specifically, the authors propose two new structure-aware pre-training tasks: one is to predict code structure edges, and the other is to align representations between source code and code structure. The proposed model is evaluated on four tasks, including code search, clone detection, code translation, and code refinement. "
SP:2c7a128e19cd2d39b0ca1b946b01604c3f7cead5,"This paper proposes a method to improve the accuracy of regression models that are trained on skewed data. The method is based on a semi-supervised learning framework with an adversarial network to force the distribution of the regression output to resemble the assumed true distribution. The authors created skewed datasets by selecting data that exceeded a certain threshold from four real-world datasets (pLogP, Diamond, House, Elevators) and evaluated the proposed approach using these skewed datasets. The proposed approach reduced the root mean squared error (RMSE) of regression model derived using each of the four datasets compared to the regression model that had been trained using only the skewed dataset."
SP:fee1e40275fa743aa6ad011ae742b3ea3fd137df,"This paper studies the problem of out-of-distribution generalization. The authors argue that the extraction ability does not transfer naturally, because the extraction network suffers from the divergence of distributions. To address this problem, the authors propose to use an auxiliary reconstruction network with regularized hidden representations as input, and optimize the representations during inference. The proposed approach significantly improves accuracy, showing more than a 20% absolute increase in various experiments compared with baselines."
SP:ffab573a977c819e86601de74690c29a39c264cd,"This paper proposes a poisoning algorithm for deep policy-gradient online reinforcement learning (RL) algorithms. The authors propose a generic poisoning framework for online RL via a comprehensive investigation of heterogeneous poisoning models in RL. They propose a strategic poisoning algorithm called Vulnerability-Aware Adversarial Critic Poison (VA2C-P), which works for on-policy deep RL agents, closing the gap that no poisoning method exists for policy-based RL agents. They also introduce a novel metric, stability radius in RL, that measures the vulnerability of RL algorithms. Experiments on multiple deep RL agent and multiple environments show that our poisoning algorithm successfully prevents agents from learning a good policy or teaches the agents to converge to a target policy."
SP:06ebd437ff2d1b5068f7a651716d3c1a60c2a001,"This paper proposes Dynamic Tensor re-materialization (DTR), a dynamic checkpointing algorithm for neural networks. DTR is a greedy algorithm for checkpointing that is parameterized by an eviction policy and supports dynamic models. The authors prove that DTR can train an N-layer linear feedforward network on an $\Omega(\sqrt{N})$ memory budget with only O(N) tensor operations. In simulation, DTR closely matches the performance of optimal static checkpointing in simulated experiments. "
SP:20efc610911443724b56f57f857060d0e0302243,"This paper proposes a new task to predict whether each token in the output sequence is hallucinated conditioned on the source input, and collects new manually annotated evaluation sets for this task. The authors also introduce a novel method for learning to model hallucination detection, based on pretrained language models fine tuned on synthetic data that includes automatically inserted hallucinations. Experiments on machine translation and abstract text summarization demonstrate the effectiveness of the proposed approach."
SP:3d0d026888cf87073df5bd74edd986f15351ff5a,"This paper proposes a NAS-based method for conditional GANs. The search space contains regular and class-modulated convolutions, where the latter is designed to introduce class-specific information while avoiding the reduction of training data for each class generator. The proposed method follows a weight-sharing pipeline with mixed-architecture optimization so that the search cost does not grow with the number of classes. To learn the sampling policy, a Markov decision process is embedded into the search algorithm and a moving average is applied for better stability. Experiments on CIFAR-10 and Cifar-100 demonstrate the effectiveness of the proposed method."
SP:8cdf6e8af07daaec6680c2bed6c1787a53580584,This paper proposes a new method for estimating the average causal effect of a given treatment. The proposed method is based on orthogonality constraints on the treatment assignment. Theoretical guarantees are provided to show that the resulting estimator is asymptotically normal. The method is evaluated on a variety of causal inference benchmarks. 
SP:77ec2512837df5c0a94000602dc2ef5c03fe41dd,"This paper studies the role and expressive power of affine parameters in BatchNorm, a popular feature normalization technique that normalizes activations and then applies a learned affine transform. To isolate the contribution of these parameters from that of the learned features they transform, the authors investigate the performance achieved when training only these parameters and freezing all weights at their random initializations. They find that $\gamma$ and $\beta$ have noteworthy expressive power in their own right and that this expressive power results from their particular position as a per-feature coefficient and bias. They demonstrate that sufficiently deep ResNets reach 82% and 32% accuracy in this configuration."
SP:6683ceea773ff6d7fb613e503c583bb2979c7e89,"This paper proposes a test-time adaptation method based on test entropy minimization (tent1). Tent estimates normalization statistics and optimizes channel-wise affine transformations to update online on each batch. Tent reduces generalization error for image classification on corrupted ImageNet and CIFAR-10/100 and reaches a new state-of-the-art error on ImageNet-C. Tent handles source-free domain adaptation on digit recognition from SVHN to MNIST/MNIST-M/USPS, on semantic segmentation from GTA to Cityscapes, and on the VisDA-C benchmark."
SP:ed544ee661580592063aa17aee8924cc99919130,"This paper proposes a method to estimate the uncertainty of a recurrent neural network (RNN) using stochastic discrete state transitions over recurrent timesteps. The uncertainty of the model can be quantified by running a prediction several times, each time sampling from the recurrent state transition distribution, leading to potentially different results if the model is uncertain. The proposed method can learn deterministic and probabilistic automata from data, learn well-calibrated models on real-world classification tasks, improve the performance of out-of-distribution detection, and control the exploration-exploitation trade-off in reinforcement learning."
SP:a38c523196f68a90b5db45671f9dbd87981a024c,"This paper studies the problem of privacy-preserving deep learning. The authors propose a stochastic differential equation principled residual perturbation to inject Gaussian noise into each residual mapping of ResNets. Theoretically, the authors prove that the proposed method guarantees differential privacy (DP) and reduces the generalization gap for DL. Empirically, they show that the method outperforms DPSGD in both membership privacy protection and maintaining the DL models' utility."
SP:9cbe32c1317889d6a3ec1b0798112d9b82cc7f67,"This paper proposes an extension of BERT, called Length-Adaptive Transformer, that can be used to train a large-scale transformer once and use it for various inference scenarios without re-training it. To do so, they train a transformer with LengthDrop, a structural variant of dropout, which stochastically determines the length of a sequence at each layer. They then use a multi-objective evolutionary search to find a length configuration that maximizes the accuracy and minimizes the computational complexity under any given computational budget. They also extend the applicability of PoWER-BERT beyond sequence level classification into token-level classification such as span-based question-answering."
SP:e5b4098ea22a5da2b9659219dc24f885c493a011,"This paper studies the expressiveness of graph neural networks (GNNs) by exploring powerful aggregators. The authors reformulate aggregation with the corresponding aggregation coefficient matrix, and then systematically analyze the requirements of aggregation coefficient matrices for building more powerful aggregator and even injective aggregator. Based on the theoretical analysis, the authors develop two GNN layers, ExpandingConv and CombConv, which achieve state-of-the-art performance on a variety of graph tasks. "
SP:4dd6fb8e5a356af270d3b296ce3d50ae5753513c,This paper proposes a disentangled representation learning method based on the topological similarity of conditional sub-manifolds in the learned representation. The method showcases both unsupervised and supervised variants. Experiments are conducted to demonstrate the effectiveness and applicability of the proposed method. 
SP:ef1ee7b77e1c2fb3d76db27049a3bce42760d14e,"This paper proposes a method to make training examples unlearnable for deep learning models. The proposed method is based on adding noise to the training examples to reduce the error of one or more of the training example(s) close to zero, which can trick the model into believing there is “nothing” to learn from these examples. The noise is restricted to be imperceptible to human eyes, and thus does not affect normal data utility. The authors empirically verify the effectiveness of error-minimizing noise in both sample-wise and class-wise forms. "
SP:4e8a835174f20df36d3d8d27fbcbbf2c68490032,"This paper proposes Nondeterministic MuZero (NDMZ), an extension of MuZero for nondeterministic, two-player, zero-sum games of perfect information. It formalizes chance as a player in the game and incorporates the chance player into the MuZero network architecture and tree search. Experiments show that NDMZ is capable of learning effective strategies and an accurate model of the game dynamics."
SP:73ae9c167dac3d92788a08891b0831f3e4997140,"This paper introduces Hindsight off-policy option learning (HO2), an option learning algorithm that uses an actor-critic algorithm for robust and efficient option learning. HO2 infers option and action probabilities for trajectories in hindsight, and performs critic-weighted maximum-likelihood estimation by backpropagating through the inference procedure. The authors demonstrate that HO2 outperforms existing option learning methods and that both action and temporal abstraction provide strong benefits, particularly in more demanding simulated robot manipulation tasks. "
SP:f79d9722256fb6b258bc1310bf1f6fb842303a0a,This paper proposes a novel functional form of the Bellmane equation to optimize for the maximum reward achieved at any time step in an episode. The authors introduce the corresponding evaluation and optimality operators and proved the convergence of Q-learning algorithm. The proposed max-Bellman formulation can be applied to deep reinforcement learning algorithms by demonstrating state-of-the-art results on the task of de novo drug design across several reward functions and metrics.
SP:bd4b1781448def4327214c78f07538d285119ef9,"This paper proposes Contextual HyperNetwork (CHN), an auxiliary model that generates parameters for extending the base model to a new feature by utilizing both existing data as well as any observations and/or metadata associated with the new feature. At prediction time, the CHN requires only a single forward pass through a neural network, yielding a significant speed-up when compared to re-training and fine-tuning approaches. The experiments show that this system obtains improved few-shot learning performance for novel features over existing imputation and meta-learning baselines."
SP:8e4677cc6071a33397347679308165c10dca2aae,"This paper proposes a method to perform Bayesian inference over a subset of the weights of a deep neural network while keeping all other weights as point estimates. The method is based on first training a point estimate, and then infering a full covariance Gaussian posterior approximation over a subnetwork. The authors propose a selection procedure to maximally preserve posterior uncertainty. Empirical results show that the proposed method is more expressive and retains more uncertainty than crude approximations over the full network."
SP:be361952fe9de545f68b8a060f790d54c6755998,"This paper proposes a method for learning embeddings of states and actions for reinforcement learning. The key idea is to use a model of the environment to learn the embedding of the state and action space, and then use a generic architecture to learn a policy. The proposed method can be applied to both discrete and continuous domains. Experiments show that the proposed method outperforms baselines in both discrete/continuous domains."
SP:ebb6bffcc4c2129e09ef5561c19df43c42ad18c0,"This paper proposes a method for learning views for unsupervised representation learning. The method is based on a generative model that generates views by generating and then adding an $\ell_p$-bounded perturbation to the input, and is trained adversarially with respect to the main encoder network. Experiments are conducted on image, speech, and wearable sensor modalities. "
SP:ef7735be9423ad53059505c170e75201ca134573,"This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. The authors demonstrate how different existing detection approaches fail to detect certain types of outliers. They utilize these insights to develop a novel integrated OOD detection approach that uses multiple attributes corresponding to different types of outlier. The experiments on CIFAR10, SVHN and MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5 are conducted."
SP:33920ec7ffefe3c1525cd5d4d53a851210d519da,"This paper proposes a hierarchical VAE model that is capable of generating samples with high likelihood. The authors argue that VAEs can represent autoregressive models when they are sufficiently deep. The proposed model is evaluated on CIFAR-10, ImageNet, FFHQ, and FFHQ-256. The results show that the proposed model achieves higher likelihoods, uses fewer parameters, generates samples thousands of times faster, and is more easily applied to high resolution images."
SP:0a4e6c8017a1294fe2424799a0048d58eaf04cb3,This paper proposes a new method for contrastive representation learning. The authors propose to sample negative samples from a conditional distribution around the positive samples in order to approximate the partition function. They show that this approach is more biased but also has a lower variance compared to the standard contrastive learning approach. They evaluate their method on four image classification tasks and show that their method outperforms the baselines.
SP:613a0e2d8cbe703f37c182553801be7537333f64,This paper proposes a new data leakage attack to recover batch data from the shared aggregated gradients in federated learning. The proposed method is called catastrophic data leakage in Federated Learning (CAFE) and it can recover large-scale private data with high data recovery quality. Experiments on both vertical and horizontal FL settings have validated the effectiveness of the proposed method. 
SP:ce229295081ff04b26f33829f2c3396b90897b5d,"This paper proposes a neural relational inference model for dynamic relations in multi-agent trajectories. The proposed model is based on the DYAMNIC model, which is a deep generative model that can reason about changing relations over time. The authors conduct extensive experiments using a simulated physics system to study the performance of DYARI in handling various dynamic relations. They perform ablative study to understand the effect of dynamic and inference period, training scheme, and model design choice."
SP:9f4b77d39f1deca28324fb637a0a77e89976baa8,"This paper proposes an inductive collaborative filtering framework that learns a hidden relational graph among users from the rating matrix. The key advantage of the proposed method is the capability for inductively computing user-specific representations using no feature, with good scalability and superior expressiveness compared to other feature-driven inductive models. Extensive experiments demonstrate that the proposed model achieves state-of-the-art performance for inductive learning."
SP:9f9e9b0e37e59267d8516ab914bd619c53fbc9ec,"This paper proposes a multi-stage method for disentangled representation learning (DR) based on variational autoencoder (VAE) and generative adversarial networks (GAN). The main idea is to learn independent and correlated latent variables in two separate stages of training, i.e. independent latent variables are learned in the first stage and correlated variables are learnt in the second stage. The authors show that the proposed method improves the reconstruction quality of existing DR methods while maintaining the same level of disentangling."
SP:e398873e29b05176e1d52dc6f86a59a4f405e6fd,"This paper studies the sufficiency of representations learned by mutual information maximization (MI) based representation learning methods in the context of reinforcement learning. In particular, the authors study two popular MI-based representation learning objectives, i.e., mutual information minimization and mutual information regularization, from a theoretical perspective. The authors show that these objectives do not necessarily yield representations that are sufficient for RL from a sufficiency perspective. They also show that two of these objectives can yield insufficient representations given mild and common assumptions on the structure of the MDP. Finally, empirical experiments on a simulated game environment validate the theoretical findings."
SP:881185782a9ec32fcbab14b42b78bf94edeba4b0,"This paper studies the convex semi-infinite dual of the two-layer vector-output ReLU neural network training problem. In particular, the authors show that the non-convex neural network learning problem is equivalent to a finite-dimensional convex copositive program. The authors also provide the first algorithms for provably finding the global minimum of the vector output neural networks training problem, which are polynomial in the number of samples for a fixed data rank. "
SP:8613b2fcfd076d3e28a9940bad0c490a6557c10c,"This paper proposes a method for learning disentangled, object-centric scene representations from vision and language. The method builds upon recent advances in unsupervised object segmentation, notably MONet and Slot Attention. The key idea is to learn to associate the learned representations to concepts, i.e., words for object categories, properties, and spatial relationships, from language input. Experiments show that the integration of LORL consistently improves the performance of MONet/Slot Attention on two datasets."
SP:5e73b99c9942dd85bf70a65ad3e3c6a45d69b66b,"This paper proposes a method for Knowledge Graph Completion (KGC) based on rule-based reasoning (RBR) and embedding. RBR is a general framework that combines the advantages of reasoning based on rules and the state-of-the-art models of embedding (e.g., translation-based embedding) to solve KGC. In particular, the authors propose to use a rule based RBR to find the most reasonable explanation for a given triplet to obtain higher prediction accuracy. Empirical results show that EM-RBR achieves better performance compared with previous models on FB15k, WN18, and a new dataset. "
SP:19b74093512c4e5f8c504e96c590ac1eb7e2ce9b,"This paper proposes a method to combine declarative and procedural knowledge in the context of next-state prediction. The method is based on an attention mechanism, which is used to determine which object files to update, the selection of schemata, and the propagation of information between object files. The proposed method is evaluated on a variety of tasks, including a challenging physics benchmark. "
SP:42a3c0453ab136537b5944a577d63412f3c22560,This paper proposes a neural module network (NMN) architecture for video-grounded language tasks. The proposed architecture consists of two modules: entity and action modules. The entity module is responsible for identifying entity references in the video and the action module is used to extract visual cues from the video. Experiments are conducted on the video QA and dialogues tasks.
SP:126ce41b7f44975e5962f8bcb43f61bf2ed315c4,"This paper proposes two variations of the Policy-Space Response Oracles (PSRO) algorithm, which is a general algorithmic framework for learning policies in multiagent systems by interleaving empirical game analysis with deep reinforcement learning (Deep RL). The first method, Mixed-Oracles, transfers knowledge from previous iterations of Deep RL, requiring training only against the opponent’s newest policy. The second method is Mixed-Opponents, which constructs a pure-strategy opponent by mixing existing strategy's action-value estimates, instead of their policies. The experiments show that these algorithms substantially reduce the amount of simulation during training required by PSRO while producing equivalent or better solutions."
SP:33e0b6099b32a6a2c0f2c7a8caa57ba2935d8b00,"This paper presents a non-attentive Tacotron, which replaces the attention mechanism in the Tacoton 2 text-to-speech model with an explicit duration predictor. The duration predictor enables both utterance-wide and per-phoneme control of duration at inference time. When accurate target durations are scarce or unavailable in the training data, this paper proposes a method using a fine-grained variational auto-encoder to train the duration predictor in a semi-supervised or unsupervised manner."
SP:ab9532306d294f85db84b9419ce826f046a7d95e,This paper proposes a method to estimate the bird’s eye view layout from a pair of stereo images. The proposed method is based on inverse perspective mapping (IPM) to map the input images and their features to the bird's eye view. The method is evaluated on the KITTI and CARLA simulator.
SP:3a151e18a5e623e9bf6e39a6065bfba1d5156fc1," GNNs suffer from a drop in performance when training deeper networks, which may be caused by vanishing gradients, over-parameterization, and over-smoothing. This paper proposes a novel relation-aware GNN architecture based on the Graph Attention Network that uses gated skip connections to improve long-range modeling between nodes and uses a more scalable vector-based approach for parameterizing relations. The proposed method significantly outperforms several commonly used GNN variants when used in deeper configurations and stays competitive to existing architectures in a shallow setup."
SP:f9906d99f6ae5e32dda548bdccce9ae92d25b205,"This paper proposes a method to identify minimal regions in an input that are most relevant for a neural network’s prediction. The method uses Integrated Gradient Information (IGI) to focus on a subset of neurons in the first layer, which allows the method to scale to large networks. The corresponding SMT constraints encode the minimal input mask discovery problem such that after masking the input, the activations of the selected neurons are still above a threshold. After solving for the minimal masks, the method scores the mask regions to generate a relative ordering of the features within the mask. This produces a saliency map which explains “where a model is looking” when making a prediction."
SP:fc96fe4d0eeb0723bb7e4c9120c77981fc14731c,"This paper proposes a method for robust 3D pose estimation with neural networks. The key idea is to use a generative model of neural feature activations at each vertex on a dense 3D mesh and use differentiable rendering to estimate the 3D object pose by minimizing the reconstruction error between NeMo and the feature representation of the target image. To avoid local optima in the reconstruction loss, the feature extractor is trained to maximize the distance between the individual feature representations on the mesh using contrastive learning. Experiments on occluded-PASCAL3D+ and ObjectNet3D show that NeMo is much more robust to partial occlusion and unseen pose compared to standard deep networks."
SP:bde5b5b05d4a10634bd21a90cf0d8d22e2cda22d,"This paper proposes an approach for feature compatible learning without inheriting old classifier and training data, i.e., Non-Inherent Feature Compatible Learning (NIPCL). The approach requires only features extracted by the old model’s backbone and new training data and makes no assumption about the overlap between old and new data. The authors propose a unified framework for NIPCL, and extend it to handle the case where the old models is a black-box. Experiments on ImageNet ILSVRC 2012 and Places365 show the effectiveness of the proposed approach."
SP:a9aa11e7ee77d9f6957266e4ad822c7dc0f82354,"This paper studies the effectiveness of using gradient norm as a model selection criterion in hyperparameter optimization. The authors propose to use an accelerated approximation (Goodfellow, 2015) of gradient norm that only computes the loss gradient in the Fully-Connected Layer (FC Layer) of DNNs with significantly reduced computation cost (200-20,000 times faster). The empirical studies clearly find that the use of approximated gradient norm, as one of the hyper-parameter search objectives, can select the models with lower generalization error, but the efficiency is still low (marginal accuracy improvement but with high computation overhead). The authors also show that the bandit-based or population-based algorithms, such as BOHB, perform poorer with gradient norm objectives, since the correlation between gradient norm and generalisation error is not always consistent across phases of the training process."
SP:13359456defb953dd2d19e1f879100ce392d6be6,"This paper proposes an autoregressive method for entity retrieval. The key idea is to generate unique entity names, left to right, token-by-token, in an auto-regressive fashion, conditioned on the context. The method is evaluated on entity disambiguation, entity linking, and document retrieval tasks."
SP:9dfb808ce4c045c45436b35ceb03bc6fe6ed9745,"This paper considers the problem of routing users through a network with unknown congestion functions over an infinite time horizon. On each time step t, the algorithm receives a routing request and must select a valid path for each edge e in the selected path. The algorithm incurs a cost ce = fe(x t e) + \eta t e, where x t e is the flow on edge e at time t, fe is the congestion function, and $\eta$ is a noise sample drawn from an unknown distribution. The routing requests are supplied adversarially. The authors present an algorithm with cumulative regret O(\sqrt{T}) where the regret is defined as the difference between the total cost incurred by our chosen path and the minimum cost among all valid paths. They also validate their algorithm empirically using graphs from New York City road networks."
SP:580ac3b74951bef5d5772e4471b01a805ff3dd68,"This paper proposes Pointwise mutual information (PMI) based masking strategy, which jointly masks a token n-gram if it exhibits high collocation over the corpus. PMI-Masking motivates, unifies, and improves upon prior more heuristic approaches that attempt to address the drawback of random uniform token masking, such as whole-word mask, entity/phrase masking and random-span masking. Experiments are conducted to demonstrate the effectiveness of the proposed method."
SP:038cdd2df643edccb16dfd72e6eb123f6a6c0839,"This paper studies the problem of partially-conditioned variational inference in sequential latent variable models with the evidence lower bound (ELBO). In this setting, the posterior of the variational posterior is often only partially conditioned, while the true posterior depends on the entire sequence of observations. This paper analyzes the emerging conditioning gap and the resulting suboptimality for sequential amortised inference models. The authors show that the ELBO objective forces partially conditioned amortized posteriors to approximate products of smoothing posteriors instead. They demonstrate these theoretical findings in three scenarios: traffic flow, handwritten digits, and aerial vehicle dynamics. "
SP:f2574c0d6cdec78389fa1301d6a10976d1756279,"This paper studies the generalization properties of a simple combination of divide-and-conquer technique and random features for distributed kernel ridge regression. The authors show that the simple combination can achieve the same statistical accuracy as the exact KRR in expectation requiring only $O(D^2/\sqrt{D}$ memory and time. Then, they derive generalization bounds in probability to capture the learning performance for a single trail. Finally, they propose an effective communication strategy to further improve the performance of DKRR-RF."
SP:129872706a12d89f0886c2ad0fd4083d0632343c,"This paper proposes a new method for neural architecture search (NAS) based on RandomNAS. The main idea is to use a proxy search space (PS) that is only a small subset of the search space to improve RandomNAS’s search efficiency while keeping a good correlation for the top-performing architectures. The paper shows that existing RandomNAS can rank a set of architectures uniformly sampled from the entire search space, that correlates well with its ground-truth ranking. However, if we only focus on the top performing architectures (such as top 20% according to the ground truth) in the GS, such a correlation drops dramatically. This paper proposes an efficient way to Evolve the Proxy Search Space (EPS) to address this problem. In the experiments, the authors demonstrate that EPS can achieve a near-optimal performance on NASBench201."
SP:27701f374d0b7e8b269d9133d6c3a10bca03b548,"This paper proposes PERIL, a method to combine imitation learning with meta-reinforcement learning. The main idea is to learn a representation of a new task by conditioning on both demonstrations, and further exploration. The proposed method is evaluated on a set of meta-RL benchmarks under sparse rewards."
SP:118758f563fa6e9e46d52a6f250005c06cf2f19f,"This paper studies the inductive bias of overparameterized CNNs in a novel setup and provides theoretical and empirical support that SGD exhibits good generalization performance. The authors empirically identify a novel phenomenon of SGD in the setting, where the dot-product between the learned pattern detectors and their detected patterns are governed by the pattern statistics in the training set. They prove that if a learning algorithm satisfies PSI then its sample complexity is O(d log(d)) where d is the filter dimension. They perform experiments with overparametrized CNNs on a variant of MNIST with nonorthogonal patterns."
SP:a051b615da3a99562d2cd2dfbec5cd78af98d9b4,This paper studies the problem of document classification under topic modeling assumptions. The authors prove that contrastive learning is capable of recovering a representation of documents that reveals their underlying topic posterior information to linear models. They apply this procedure in a semi-supervised setup and demonstrate empirically that linear classifiers with these representations perform well in document classification tasks with very few training examples.
SP:8d011d4a77ced1f8cd849181d5293420f161ffd3,"This paper proposes a contrastive loss for multimodal generative models. The main idea is to use contrastive losses to encourage the generative model to distinguish between ""related"" and ""unrelated"" multi-modal samples. The authors show that the proposed loss is effective in reducing the amount of data needed to train the model by exploiting the distinction between related and unrelated samples. "
SP:3a0d3f1d63cd57b0613c40176e694435ed3eee50,"This paper proposes an energy-based prior to improve the generative quality of VAEs. The proposed method is based on a reweighting factor that is trained by contrasting samples from the aggregate posterior with samples from a base prior. The authors show that the proposed method can be applied to any VAE to increase its prior’s expressivity. Experiments are conducted on MNIST, CIFAR-10, CelebA 64, and CelebA HQ 256 datasets. "
SP:86b813ac0f5211a7c45884451f59f3ebaeeb4b83,"This paper studies the inverse reinforcement learning (IRL) problem under strongly convex policy regularizers. The authors propose a new regularized IRL algorithm, called Regularized Adversarial Inverse Reinforcement Learning (RAIRL), which generalizes adversarial IRL (AIRL, Fu et al. (2018)). Theoretical analysis and empirical results are provided to support the effectiveness of the proposed algorithm. "
SP:6f4a520cdc9901c2c87a7e887ce2535ad0b36f69,"This paper proposes CLSR, a language-specific routing method for multilingual neural machine translation (MNMT). CLSR employs hard binary gates conditioned on token representations to dynamically select LS or shared paths. By manipulating these gates, CLSR can schedule LS capacity across sub-layers in MNMT subject to the guidance of translation signals and budget constraints. Experiments with Transformer on OPUS-100 and WMT datasets show that: 1) MNMT is sensitive to both the amount and the position of LS modeling: distributing 10%-30% LS computation to the top and/or bottom encoder/decoder layers delivers the best performance; and 2) one-to-many translation benefits more from CLSR compared to many to many translation."
SP:1e932b21e9557b1bbc1950c4e1701f5a3ecf50df,"This paper proposes a Wasserstein distributional normalization (WDN) algorithm to handle noisy labels for accurate classification. In particular, the authors split the data into uncertain and certain samples based on small loss criteria. To impose geometric constraints on the uncertain samples, they normalize them by normalizing them into the 2-Wasserstein ball centered on certain samples. The proposed WDN is highly compatible with existing classification methods, meaning it can be easily plugged into various methods to improve their accuracy significantly. "
SP:e0029422e28c250dfb8c62c29a15b375030069e8,"This paper proposes a method for quantifying the uncertainty of deep neural network classifiers. The method is based on the Platt scaling of the probability of the true label to be 90% with a user-specified probability. The algorithm is simple and fast, but provides a formal finite-sample coverage guarantee for every model and dataset. Experiments are conducted on both Imagenet and ImageNet with ResNet-152 and ResNets."
SP:bf93641cbeaaa147ad0307de694e20adc23c290a,This paper proposes a method to compute Wasserstein-2 barycenter based on input convex neural networks and cycle-consistency regularization to avoid introducing bias. The authors provide theoretical analysis on error bounds as well as empirical evidence of the effectiveness of the proposed approach in low-dimensional qualitative scenarios and high-dimensional quantitative experiments.
SP:39aae6a094f7141bee6d4fa78be03fd20cf12b13,"This paper studies the problem of training a deep neural network to separate two low-dimensional submanifolds of the unit sphere. The authors show that when the depth of the network is large relative to certain geometric and statistical properties of the data, the network width grows as a sufficiently large polynomial in L, and the number of i.i.d. samples from the manifolds is polynomially large in L. Then, gradient descent rapidly learns to classify the two manifolds perfectly with high probability. "
SP:c5afd0a7485aa8dc732f6fa90d81a85a8bb51b3c,"This paper proposes a simple off-policy reinforcement learning algorithm called advantage-weighted regression (AWR), which consists of two standard supervised learning steps: one to regress onto target values for a value function, and another to regress into weighted target actions for the policy. The method is simple and general, can accommodate continuous and discrete actions, and can be implemented in just a few lines of code. The authors provide a theoretical motivation for AWR and analyze its properties when incorporating off policy data from experience replay. They evaluate AWR on a suite of standard OpenAI Gym benchmark tasks, and show that it achieves competitive performance."
SP:54da307c1f9aac020ae7e3c439653765dbd8b3fe,"This paper proposes WaveQ, a novel method for quantizing neural networks. The main idea is to use a parametrized sinusoidal regularizer to find the quantized weights and learn the bitwidth of the layers by making the period of the regularizer a trainable parameter. In addition, the sinusoid regularizer itself is designed to align its minima on the quantization levels. Experiments are conducted to show the effectiveness of the method."
SP:84ced6627d1dc3e78c9ffc726174e76db5f77795,This paper proposes a data augmentation method for neural machine translation (NMT) by randomly replacing words or mixup with their aligned alternatives in another language when training. The proposed method is simple yet effective and can be extremely useful when extra in-domain monolingual data is limited. The experimental results show that the proposed method can obtain remarkable BLEU score improvement over the strong baselines.
SP:c1890bcafac6ac8fd5a3d2ff2dd1c37b71865a5a,This paper proposes a real-time contribution measurement method for federated learning. The contribution of each agent is defined as the difference between the average contribution of the current round and the previous round. The authors show that the proposed method is more sensitive to both data quantity and data quality under the premise of maintaining real time. 
SP:b766979b4d3b15a039db4e5eebd8353521aea4bb,This paper studies the problem of learning Bayesian networks with adversarially corrupted samples. The authors propose a nearly linear time algorithm for this problem with a dimension-independent error guarantee. The algorithm and analysis are considerably simpler than those in previous work. They achieve this by establishing a direct connection between robust learning of Bayes networks and robust mean estimation.
SP:b3d507bd8fe8876f3a4f7696bc0483d0052484c8,"This paper proposes LatCo, an algorithm for long-horizon planning in model-based reinforcement learning. LatCo is based on the idea of collocation-based planning and adapts it to the image-based setting by leveraging probabilistic latent variable models, resulting in an algorithm that optimizes trajectories over latent variables. The experiments show that LatCo outperforms prior work on visual control tasks with sparse rewards and long-term goals. "
SP:cfe57a61dc20207b64b7fff45f7cb33126dce558,"This paper studies the effect of data curation on the performance of Bayesian neural networks (BNNs) for image classification. The authors propose a generative model to describe the process of data-curation and show that it can explain the improved performance of tempering or cold posteriors in BNNs. They also show that with increasing label noise, the cold posterior effect disappears and eventually reverses. "
SP:4ebd3874ecea94ed9d0ca7b2fb13bf246b556938,"This paper studies the speed-accuracy tradeoff between autoregressive and non-autoregressive neural machine translation (AR) models. The authors argue that the speed disadvantage of AR models has been overestimated in three aspects: suboptimal layer allocation, insufficient speed measurement, and lack of knowledge distillation. They provide a complexity analysis and identify an optimal layer allocation strategy that leads to better speed-quality tradeoffs. "
SP:ce8cf444681a8e38408c6485029fe42b89a1f172,"This paper investigates epoch-wise double descent, i.e., the test error of a DNN also shows double descent as the number of training epochs increases. Specifically, the authors extend the bias-variance analysis to epoch-wide double descent and show that the variance also contributes the most to the zero-one loss. Inspired by this result, they propose a novel metric, optimization variance (OV), to measure the diversity of model updates caused by the stochastic gradients of random training batches drawn in the same iteration. OV can be estimated using samples from the training set only but correlates well with the (unknown) test error. It can be used to predict the generalization ability of a neural network when the zero one loss is used in test, and hence early stopping may be achieved without using a validation set."
SP:8d8b738c676938952e62a6b2aea42e79518ece06,"This paper studies the adversarial robustness of model-agnostic meta-learning (MAML) in the context of few-shot learning. In particular, the authors propose a robust regularization term that promotes robustness-promoting regularization in MAML. The authors show that robustifying the meta-update stage is sufficient to make robustness adapted to the task-specific fine-tuning stage even if the latter uses a standard training protocol. They also provide a justification on the acquired robustness adaptation by peering into the interpretability of neurons’ activation maps. Finally, extensive experiments are conducted to demonstrate the effectiveness of the proposed methods."
SP:1fdce0afe8fd8c082f62f1a4b9823830d81860e8,"This paper studies the problem of tuning the step size for quadratic loss in the learning-to-learn setting. The authors show that if the meta-objective is simply the loss of the last iteration, then the polynomial-bounded meta-gradient is not polynomially bounded and can explode/vanish. They also show that when the number of samples is small and the noise is large, train-by-validation approach generalizes better. Finally, they show that a similar phenomenon appears even for learned optimizers parametrized by neural networks."
SP:c8a9ab50888585b58369c4fb425be1170c96c14d,"This paper proposes a graph view-consistent learning network (GVCLN) to solve the node classification problem in the case of low label rate. GVCLN adopts a dual-view structure to view consistent learning. Two loss functions are designed besides a supervised loss. The supervised loss uses the known labeled set, while a view consistent loss is applied to the two views to obtain the consistent representation and a pseudo-label loss is designed by using the common high-confidence predictions. Experiments have been done on the three citation network datasets of Cora, Citeseer, and PubMed."
SP:9c8619d2c0df81c1222ba28cecbacc42408d0019,"This paper studies the problem of learning a neural network to predict the dynamics of a physical system. In particular, the authors focus on the case where the underlying dynamics of the system can be inferred from the data directly. The authors propose a method to find the appropriate cyclic coordinates, i.e. lower-dimensional subspaces of the phase space, which can be obtained via canonical transformations of the Hamiltonian. They show that such coordinates can be searched for automatically with appropriate loss functions which naturally arise from Hamiltonian dynamics. They test their method on standard classical physics systems using synthetic and experimental data where their network identifies the conserved quantities in an unsupervised way and find improved performance on predicting the dynamics. "
SP:d1e78b1759eef8fc16e5b7ad7f0e290e9dc5dea0,This paper proposes a novel graph neural network (GNN) architecture for learning on graphs with heterogeneous tabular node features. The main idea is to use a GBDT-based decision tree (GBDT) to model heterogeneous features and a GNN to model the graph structure. The GNN is then used to refine the predictions using relational information. Experiments show that the proposed method outperforms the state-of-the-art in terms of accuracy and training time. 
SP:9f9dbff2fe7defd41b9ed1a6c9dcad07e932dea7,"This paper studies the role of the train-validation split in meta-learning in the linear centroid setting. The authors show that the splitting method converges to the optimal prior as expected, whereas the non-splitting method does not in general without structural assumptions on the data. The paper also shows that if the data are generated from linear models (the realizable regime), both the splitting and non-Splitting methods converge to the common best prior. "
SP:bb566eda95867f83a80664b2f685ad373147c87b,"This paper proposes a method to extract hard-confident examples from noisy training data by leveraging the memorization effect of deep neural networks. Specifically, the method alternately updates the confident examples and refine the classifier. The extracted confident examples in the previous round can be exploited to learn a better classifier and help identify better (and hard) examples. Empirical results on benchmark-simulated and real-world label-noise data illustrate the effectiveness of the proposed method."
SP:ca57b693e5eff372c872f42d66b18b8aa1d07c87,"This paper studies the problem of data poisoning attacks on machine learning models. In particular, the authors study the robustness of kNN and radius nearest neighbor (rNN) algorithms. They show that the intrinsic majority vote mechanism in these algorithms provides certified robustness guarantees against general poisoning attacks. Moreover, they derive a better lower bound of certified accuracy for rNN via jointly certifying multiple testing examples. "
SP:6cfe70be8ac34d6f61009e7e583e537e9adeb648,"This paper studies batch size selection problem for training graph neural network with SGD method. The authors propose a metric that combines both the variance of gradients and compute time for each mini-batch. They theoretically analyze how batch-size influence such a metric and propose the formula to evaluate some rough range of optimal batch size. The experimental results show that in contrast to conventional deep learning models, GNNs benefit from large batch sizes."
SP:30d97322709cd292a49f936c767099f11b0e2913,This paper proposes a method to detect misclassification errors in neural network classifiers. The method is based on a Gaussian process model that is trained on top of the original NN classifier. The proposed method is evaluated on UCI datasets and a large-scale deep learning architecture. 
SP:131b3da98f56d3af273171f496b217b90754a0a7,"This paper proposes a method to train an information retrieval module for downstream tasks, without using pairs of queries and documents as annotations. The approach is inspired by knowledge distillation, where the retriever module corresponds to the student model and the reader module corresponding to the teacher model. In particular, the authors use the cross-attention scores, from a sequenceto-sequence reader, to obtain synthetic targets for the retrieval module. They show that iteratively training the reader and retriever leads to better performance on competitive question answering benchmarks."
SP:a516fff3cabc13cea1b8ed07dbf9eb1acb7dbb0e,"This paper studies the use of formal languages to specify constraints in constrained Markov decision processes by specifying them in formal languages as a step towards using safety methods from software engineering and controller synthesis. Constraint states are used to augment the underlying MDP state and to learn a dense cost function, easing the problem of quickly learning joint MDP/constraint dynamics. The authors empirically evaluate the effect of these methods on training a variety of RL algorithms over several constraints specified in Safety Gym, MuJoCo, and Atari environments."
SP:e18cfc1502c4087422d3baf655c244d4f3924a76,"This paper proposes a cascading decision tree model to improve the comprehensibility of classifications. The key insight is to separate the notion of a decision path and an explanation path, and instead of having one monolithic decision tree, the authors build several smaller decision subtrees and cascade them in sequence. The cascading subtrees are designed to specifically target explanations for positive classifications, and each subtree identifies the smallest set of features that can classify as many positive samples as possible, without misclassifying any negative samples. The authors evaluate their algorithm on standard datasets, as well as new real-world applications and find that their model shortens the explanation depth by over 40.8% for positive classification."
SP:0508336b2ec032b9b98a1039e94ea223f3987cec,"This paper analyzes the effect of network width on the performance of neural networks with random random sparsity patterns in the weight tensors. The authors show that network width is the determining factor for good performance, while the number of weights is secondary, as long as the model achieves high training accuarcy. They analyze this effect in the framework of Gaussian process kernels and find that the distance between the sparse finite-width model kernel and the infinite-width kernel at initialization is indicative of model performance."
SP:92e5a610ed13ada6d25d433b03ac06fa5eebd963,"This paper proposes a joint pre-training framework, JAKET, to model both the knowledge graph and language. The knowledge module and language module provide essential information to mutually assist each other. The language module generates context-aware initial embeddings for entities and relations in the graph. Experiments on several knowledge-aware NLP tasks show that the proposed framework achieves superior performance by effectively leveraging knowledge in language understanding."
SP:1db95a377f3d5ed129aa0511f840f647375e3528,"This paper proposes an unsupervised learning method for learning autoregressive orderings. The method is based on variational inference, where the latent variable is the order by which the sequence was naturally generated. The authors propose a policy gradient algorithm to optimize the encoder of the variational objective, and an encoder architecture that conditions on training examples to output autore progressive orders. Experiments are conducted on image captioning, code generation, text summarization, and machine translation tasks. "
SP:1c310f02acda4aa14e4d043c8d6de8c94a8ecf44,This paper proposes a general doubly variance reduction scheme that can accelerate sampling-based sampling methods under the memory budget. The authors show that the induced variance can be decomposed into node embedding approximation variance (zeroth-order variance) during forward propagation and layerwise-gradient variance during backward propagation. They theoretically analyze the convergence of the proposed scheme and show that it enjoys an O(1/T) convergence rate. Experiments are conducted to validate the effectiveness of the scheme.
SP:02e100a9ad4eedab8cba043d3726f022bc09a3af,"This paper proposes a method for training a conditional adversarial generator on a single training image to perform image manipulation. The generator is trained to map between a primitive representation of the image (e.g. edges and segmentation) to the image itself. At manipulation time, the generator allows for making general image changes by modifying the primitive input representation and mapping it through the network. The proposed method is based on thin-plate-spline augmentations. Experiments are conducted to demonstrate the effectiveness of the proposed method."
SP:4d7c1e30fa8eb3e7c67a4ec3bccc5d3ef713a773,This paper proposes a method for maximum common subgraph (MCS) detection. The method is based on a graph neural network (GNN) and a deep Q-network (DQN). The DQN is trained using reinforcement learning to improve the performance of the GNN. The proposed method is evaluated on synthetic and real-world large graph pairs. 
SP:581c6d218e75b0df808bc2c83c8731a94e94a5b3,"This paper proposes an end-to-end trainable deep network architecture to convert a 3D point cloud into a wireframe model. The network takes as input an unordered set of 3D points sampled from the surface of some object, and outputs a sparse set of corner points linked by line segments. The architecture gradually builds up the model: It starts by encoding the points into feature vectors, it identifies a pool of candidate vertices, then prunes those candidates to a final set of corners vertices and refines their locations. Next, the corners are linked with an exhaustive set of candidate edges, which is again pruned to obtain the final wireframe. The authors validate the proposed model on a publicly available synthetic dataset for which the ground truth wireframes are accessible, as well as a new real-world dataset. "
SP:3e0fd62d9815d7de5e5139a1d6d2e80eea917154,"This paper studies stochastic gradient methods in the setting where the noise level is changing over iterations. The authors show that under certain assumptions on the noise levels, adaptive gradient methods can achieve faster convergence than SGD by applying online noise estimation and using adaptive step sizes. The main contribution of the paper is the analysis of the convergence rate of adaptive methods under the assumption that the noise variation is known.  "
SP:71c4e6ab911962d730461eda0f2d72d810fc017c,"This paper proposes a novel method for augmenting neural machine translation (NMT) with prior word alignment information. Specifically, the authors propose to use the prior alignment information from an automatic word aligner to improve the translation performance of the NMT system. To do so, they propose an enhancement learning model that can learn how to directly replace specific source words with their target counterparts according to prior alignment. The proposed model is then inserted into a neural MT model and augments MT input with the additional target information from the learning model in an effective and efficient way. Experiments are conducted on English-Korean, English-to-German, and English-Romanian translation tasks."
SP:c26255a8ad441f11cfbe18fd6dad14773aca4a2b,"This paper proposes a new benchmark for testing RL algorithms in environments with varying degrees of hardness. The authors define a collection of toy MDPs that are controllable in terms of a variety of different hardness factors, including delayed rewards, rewardable sequences, sparsity of rewards, stochasticity, image representations, irrelevant features, time unit, and action range. These environments can be run in as little as 30 seconds on a single core of a laptop. They show that these benchmarks present substantial challenges to current RL algorithms. "
SP:e8cbe62252aa671a6deaf12b97063063dfc6d1b0,"This paper proposes a quantile regularization method to calibrate regression models. The proposed method is based on the idea of quantile calibration (Kuleshov et al., 2018), which is a black-box regularizer that can be used with any probabilistic regression model. The authors provide a detailed formal analysis of the side-effects of Isotonic Regression when used for regression calibration. They provide empirical results demonstrating that their approach improves calibration for regression models trained on diverse architectures that provide uncertainty estimates."
SP:9c71ab8dcc433b59d9da3f0db377b74a369112bc,"This paper proposes a method for learning a dense 3D map and 6-DoF localisation and reconstruction in spatial environments as approximate Bayesian inference in a deep state-space model. The approach leverages both learning and domain knowledge from multiple-view geometry and rigid-body dynamics. This results in an expressive predictive model of the world, often missing in current state-of-the-art visual SLAM solutions. The combination of variational inference, neural networks and a differentiable raycaster ensures that our model is amenable to end-to-end gradient-based optimisation. The proposed method is evaluated on realistic unmanned aerial vehicle flight data."
SP:bacb279ab6d1997bf44b7b2af583f29679219c36,This paper proposes a method for leveraging textual descriptions to improve generalization of control policies to new scenarios. The method is end-to-end differentiable and can learn a latent grounding of entities and dynamics from text to observations using environment rewards as the only source of supervision. Empirical results on a newly developed multi-task game framework with crowdsourced text manuals demonstrate that EMMA shows strong generalization performance and robust grounding.
SP:d90da59c651ae3e97af1cf85f3ab1f12cd56d149,This paper proposes an actor-critic-based policy gradient method for policy optimization. The proposed method is based on a new state-value function approximation that learns the value of the states (resp. state-action pairs) relative to their mean value rather than the absolute value. The authors prove the theoretical consistency of the new gradient estimator and observe dramatic empirical improvement across a variety of continuous control tasks and algorithms.
SP:62d79bf04817bba3fdffb2c0c9209923a8428533,"This paper studies the effect of depth on the generalization performance of deep neural networks. The authors introduce local and global labels as abstract but simple classification rules. They show that the locality of the relevant feature for a given classification rule plays a key role; their experimental results suggest that deeper networks are better for local labels, whereas shallower is better for global labels. They also compare the results of finite networks with those of the neural tangent kernel (NTK), which is equivalent to an infinitely wide network with a proper initialization and infinitesimal learning rate."
SP:9f8a9299ee67b9c707b241ce84cf41f4917ef735,"This paper studies few-shot learning via representation learning, where one uses T source tasks with n1 data per task to learn a representation in order to reduce the sample complexity of a target task for which there is only n2(n1) data. Specifically, the authors focus on the setting where there exists a good common representation between source and target, and their goal is to understand how much a sample size reduction is possible. First, they study the case where this common representation is low-dimensional and provide a risk bound of $\tilde{O}(dk n1T + k n2)$ for the linear representation class. Then, they extend this result to handle a general representation function class and obtain a similar result. Finally, they demonstrate the advantage of representation learning in both high-dimensional linear regression and neural networks and show that representation learning can fully utilize all n1 T samples from source tasks."
SP:e29ce50c1c28f9264613736b6c2d20afc4f312c1,This paper proposes a new approach to study the robustness of neural networks to perturbations to semantic features. The authors leverage these features to obtain provably robust neighborhoods defined using robust features and adversarial examples defined by perturbing weak features. They evaluate their approach with PCA features. 
SP:e3fdb96a8c321a86b136e765abe796019d6f9c7a,"This paper proposes a method for multi-task learning in reinforcement learning (RL) that automatically clusters tasks into related subsets. The method is inspired by the expectation-maximization algorithm and is able to find clusters of related tasks and uses these to improve sample complexity. The proposed method is intuitive, simple to implement and orthogonal to other multi- task learning algorithms. The authors show its performance on simple discrete tasks, simple continuous control tasks, complex bipedal walker tasks and Atari games."
SP:b3805eb7114391ed15d5806b1c3eb383bff44250,"This paper proposes a self-supervised representation learning framework for learning generalizable representations for non-stationary time series. The proposed method is motivated by the medical field, where the ability to model the dynamic nature of time series data is especially valuable for identifying, tracking, and predicting the underlying patients’ latent states in settings where labeling data is practically impossible. The method is evaluated on clustering and classification tasks for multiple datasets."
SP:60b2ea4624997d6ccf862742fb9eb21b819d7eb1,"This paper proposes a modular neural network architecture for multi-task learning, transfer learning, continual learning, and domain adaptation. The proposed method is based on modular computation and modular networks, which allows soft weight sharing between tasks with only a small increase in the number of parameters. The authors show that their method leads to interpretable self-organization of modules in case of multi- task learning, multi-source domain adaptation and transfer learning and achieves competitive results."
SP:cae669c631e11fe703bf6cb511404866b19f474a,"This paper studies the problem of posterior collapse in VAEs. The authors claim that the variance parameter regularizes the VAE and affects its smoothness, which is the magnitude of its gradient. An inappropriate choice of this parameter causes oversmoothness and leads to posterior collapse. This paper proposes AR-ELBO, which stands for adaptively regularized ELBO (Evidence Lower BOund). It controls the strength of regularization by adapting the variance parameters and thus avoids oversmoothing the model. Experiments on MNIST and CelebA datasets show the effectiveness of the proposed method."
SP:cb3c10afbdd8a49cdc23e3ea71ea46ab27253b85,This paper proposes a VAE-based generative model that is able to capture both local data features and global features among batches of data samples. The model is based on a mixture model in the local or data-dependent space and a global Gaussian latent variable. The authors show that the induced latent global space captures interpretable disentangled representations with no user-defined regularization in the evidence lower bound (as in beta-VAE and its generalizations). The model performs domain alignment to find correlations and interpolate between different databases. 
SP:33792375012ff9dcffab598cc8fe5ebc71c98af4,This paper proposes a self-supervised representation learning method that uses human interaction and attention cues to learn a visual embedding. The authors collect a dataset of human interactions capturing body part movements and gaze in their daily lives. The experiments show that the learned representation outperforms a visual-only state-of-the-art method MoCo on a variety of downstream tasks. 
SP:6873a5e80e6142983c9bbd22931bfded7eed2f59,"This paper studies the effect of negative pretraining on the generalization performance of a pre-trained neural network on a target task. The authors propose three interventions to remove and fix the negative pre-training effect: 1) changing the learning rate after pretraining, 2) increasing the discretization of data distribution changes from start to target task instead of “jumping” to the target task, and 3) resetting the network biases to larger values. Experiments are conducted on MNIST, CIFAR-10, MNIST-2, and ImageNet. "
SP:5d27e5a301ed4f224fb2baecad77006a9fbb2189,This paper studies the problem of finding safe spots for adversarially trained classifiers on CIFAR-10 and ImageNet. The authors propose a bi-level optimization algorithm that can find safe spots on over 90% of the correctly classified images. They also propose a novel safe spot inducing model training scheme and a new out-of-distribution detection algorithm which achieves the state of the art results on near distribution outliers. The experiments show that the safe spots can enhance both empirical and certified robustness. 
SP:1350ab543b6a5cf579827835fb27011751cc047f,"This paper proposes a point spatio-temporal (PST) convolution to disentangle space and time in point cloud sequences. A spatial convolution is employed to capture the local structure of points in the 3D space, and a temporal convolution are used to model the dynamics of the spatial regions along the time dimension. Furthermore, the proposed PST convolution can be incorporated into a deep network, namely PSTNet, to extract features of point cloud sequence in a hierarchical manner. Extensive experiments on widely-used 3D action recognition and 4D semantic segmentation datasets demonstrate the effectiveness of PSTNet."
SP:a808583e924f85ec847c6b2597bae5c3eeec0ca7,"This paper proposes AdaSpeech, an adaptive TTS system for high-quality and efficient customization of new voices. To handle different acoustic conditions, they model the acoustic information in both utterance-level and phoneme-level. To better trade off the adaptation parameters and voice quality, they introduce conditional layer normalization in the mel-spectrogram decoder for efficient adaptation with few parameters while high voice quality. Experiments are conducted on VCTK and LJSpeech datasets."
SP:66f56cc202aed1382a342e13ecfe0c5af87f6fee,"This paper analyzes the impact of different choices of optimizers, activation functions, and regularizers on the gradient flow of training sparse neural networks. The authors show that weight decay, data augmentation, batch normalization, and non-saturating activation functions can hurt the optimization of sparse networks. They also show that batch normalisation is critical to training sparse networks, more so than dense networks. "
SP:d9f17344cd266b16a70c37d891b2c64a6d454908,"Label Propagation (LPA) and Graph Convolutional Neural Networks (GCN) are both message passing algorithms on graphs. Both solve the task of node classification but LPA propagates node label information across the edges of the graph, while GCN propagates and transforms node feature information. This paper studies the relationship between LPA and GCN in terms of two aspects: (1) feature/label smoothing where we analyze how the feature of one node is spread over its neighbors; and (2) feature-label influence of how much the initial feature/labels of one nodes influences the final feature and label of another node. Based on the theoretical analysis, this paper proposes an end-to-end model that unifies GCN and LPA for node classification. In the unified model, edge weights are learnable, and the LPA serves as regularization to assist the GCN to learn proper edge weights that lead to improved classification performance. Experiments on real-world graphs show that the proposed model shows superiority over state-of-the-art GCN-based methods."
SP:c5883e3a59e6575eff044251b38175a6ed024034,"This paper studies the generalization error of CNNs. The authors consider the case where the ground truth label generating function (LGF) is generated by a function within another function space, which they call the generator space. The generalization gap depends on the R-Complexity of both the classifier and the generator function spaces. This paper proposes a new measure of complexity between function spaces (classifier and generator), called co-complexity, which leads to tighter bounds on the generalisation error in this setting. "
SP:9bb36be61f1d4db88d806092219eba39bf1b99db,"This paper proposes a novel post-training quantization (PTQ) framework, BRECQ, which pushes the limits of bitwidth in PTQ down to INT2 for the first time. The main idea is to reconstruct the basic building blocks in neural networks and reconstruct them one-by-one. In addition, mixed precision technique is incorporated in the framework by approximating the inter-layer and intra-layer sensitivity. Extensive experiments on various handcrafted and searched neural architectures are conducted for both image classification and object detection tasks."
SP:3035318ac36cad693a5e4ee7bed43db8df6fb492,This paper studies the effect of dataset size and label noise on the calibration of deep neural networks. The authors show that label noise and class imbalance have a large impact on the accuracy of the network. They also show that small dataset sizes can lead to poor calibration. They motivate their findings by considering the geometry of the cross-entropy loss and utilizing recent results on network expressivity.
SP:17d90f9d3f5891ac56f5ed6375a21d0c1517fd62,This paper studies the problem of emergent communication between agents in a 3D environment. The authors propose a method to learn a communication protocol that can be used to coordinate the actions of two agents. The communication protocol is based on an energy-based implicit structure that is shared between the agent and the partner. The agent is trained to communicate with the partner in a non-uniform manner. The paper shows that the proposed method is able to generalize to novel partners in a self-play setting. 
SP:5ba686e2eef369fa49b10ba3f41f102740836859,"This paper proposes a meta-modeling approach for uncertainty quantification in sequential deep recurrent neural networks (DNNs). The proposed approach is based on a combination of meta-learning and meta-training, where the meta-trainable features are added to the base DNN. The authors show that the proposed approach outperforms baselines on both drift-free and non-drift-free sequential regression tasks."
SP:0a58694abd6898a925b1d917ad2a68eefd0567e9,"This paper proposes two unbalanced Gromov-Wasserstein (UGW) divergences: one based on a quadratic homogeneous divergence and the other based on an upper-bounding relaxation. The first is a positive and definite divergence based on relaxation of the mass conservation constraint using a novel type of quadratically-homogeneous divergence. The second is a distance between mm-spaces up to isometries based on the conic lifting. The authors prove that UGW is a reasonnable proxy of a distance, and provide a scalable, GPU-friendly algorithm to compute UGW."
SP:47dcefd5515e772f29e03219c01713e2403643ce,"This paper proposes a novel pruning method, called all-alive pruning (AAP), to eliminate dead connections and make all weights in the subnetwork trainable. The main idea is that dead connections do not contribute to model capacity regardless of pruning methods. To this end, the authors propose a simple yet effective method, which is applicable to iterative pruning, one-shot pruning and dynamic pruning. The experimental results show that the proposed method consistently improves the accuracy of saliency-based pruning with different model architectures at high compression ratios."
SP:9eb7b946e00085b89844c485bcd94a392146d2b7,This paper proposes a method for semantic image editing. The proposed method is based on a GAN-based approach to learn a latent space and latent-space transformations. The method is evaluated on both synthetic and real-world datasets. The results show that the proposed method achieves state-of-the-art performance.
SP:d9d9d5ade0253be2733d8b035f755ebf82e7e18b,"This paper proposes a novel Gumbel-Softmax-based GAN for discrete sequence generation. The main contribution of this paper is the use of Feature Statistics Alignment (FSA) to regularize the discriminator. Specifically, FSA forces the mean statistics of the fake data distribution to approach that of real data as close as possible in a finite-dimensional feature space. Experiments on synthetic and real benchmark datasets show the superior performance in quantitative evaluation. "
SP:3ffa34b54779998f473f4e9a52287bcd0485cec8,"This paper studies the problem of reward progressivity in reinforcement learning. In particular, the authors propose a method called Spectral DQN, which decomposes the reward into frequencies such that the high frequencies only activate when large rewards are found. This allows the training loss to be balanced so that it gives more even weighting across small and large reward regions. Experiments show that the proposed method outperforms the state-of-the-art value-based reinforcement learning methods in two domains with reward progressiveness. "
SP:bff215c695b302ce31311f2dd105dace06307cfc,"This paper introduces a notion of “useful information” in the representation learned by a deep network, and uses it to study how optimal representations for the task emerge during training. They show that the implicit regularization coming from training with Stochastic Gradient Descent with a high learning-rate and small batch size plays an important role in learning minimal sufficient representations. In particular, they find that semantically meaningful but ultimately irrelevant information is encoded in the early transient dynamics of training, before being later discarded. They also evaluate how perturbing the initial part of training impacts the learning dynamics and the resulting representations."
SP:c175ea892c831c2d0c38aded9b5e86d25b86545c,"This paper studies the problem of non-convex-strongly-concave min-max optimization. The authors propose an algorithm called SREDA-Boost, which is based on the variance reduction algorithm proposed by Luo et al. (Luo et al., 2020) to solve such a problem. The main contribution of this paper is to show that the convergence of the proposed algorithm does not depend on the initialization accuracy and stepsize of the algorithm. Instead, the authors propose a zeroth-order variance reduced algorithm ZO-SREDA, which has less restrictive initialization requirement and an accuracy-independent (and much bigger) stepsize."
SP:c1617e79182c6d06c611ced9d892d7b2da5fd9eb,"This paper studies the problem of few-shot object detection. The authors show that the generalization gap between seen and unseen classes can be closed by increasing the number of object categories used during training. The paper also shows that the effect is caused by the total number of categories and not the training samples, and that it holds for different models, backbones and datasets. "
SP:a472784ddb36f88e6e468f282fbd7ad74f8f7d75,"This paper proposes a method for single-view implicit surface reconstruction from a single RGB image. The proposed method is based on a differentiable gradient sampler to sample the spatial gradient from a feature map, which is then used to backpropagate the loss on spatial gradients to the feature maps, thus allowing training on large-scale scenes without dense 3D supervision. The method is evaluated on ShapeNet and ScannetV2 datasets."
SP:b89ec0b50475bfb23399719ca36aa137b389fbf6,"This paper proposes a simple training strategy called “Pseudo-to-Real” for high-memory footprint-required large models. It is compatible with large models with architecture of sequential layers. The authors demonstrate a practice of pretraining unprecedented 10-trillion-parameter model, an order of magnitude larger than the state-of-the-art, on solely 512 GPUs within 10 days. They also provide a technique, Granular CPU offloading, to manage CPU memory for training large model and maintain high GPU utilities."
SP:cd1e11b270f74d5dca9efd9fe1903c0a24bcba12,"This paper considers the problem of training energy-based generative models (EBMs) with non-convex neural networks. In particular, the authors consider the case where the energy of the neural network is overparametrized. The authors derive a dual formulation of the variational principles of EBMs that can be used to train EBMs with shallow overparameterized neural network energies, both in the active (aka feature-learning) and lazy regimes. In the active regime, this dual formulation leads to a training algorithm in which one updates concurrently the particles in the sample space and the neurons in the parameter space of the energy at a faster rate. They also consider a variant of this algorithm where the particles are sometimes restarted at random samples drawn from the data set, and show that performing these restarts at every iteration step corresponds to score matching training."
SP:4ff82f679a321ed61e02c50d5997c4e179441a0e,This paper studies differentially private convex ERM in the unconstrained case and gives the first tight lower bounds for approximate-DP ERM for general loss functions. The authors also give an $\Omega(\sqrt{p}(n)$ lower bound for the constrained case. The main contribution of this paper is to introduce a novel biased mean property for DP-ERM by using fingerprinting codes. 
SP:c4b4914d64e76427435bee0da345fe33b1db7d27,"This paper proposes a proximal gradient type algorithm to compute the gradient flow of a function over the space of probability densities with respect to the Wasserstein metric. The main contribution of this paper is the use of a variational formulation of the objective function, which makes it possible to realize the JKO proximal map through a primal-dual optimization. The proposed method covers all the classical gradient flows including the heat equation and the porous medium equation. The authors demonstrate the performance and scalability of their algorithm with several numerical examples."
SP:01f652a6b323db3585376a3a8e975a73ec4fed0b,"This paper proposes a meta-feature based approach to automatically select an ML algorithm and its hyper-parameter configuration most appropriate to the dataset at hand. The proposed approach, MetaBu, learns new meta-features via an Optimal Transport procedure, aligning the manually designed meta features with the space of distributions on the hyperparameter configurations. Experiments on the OpenML CC-18 benchmark demonstrate that using MetaBu meta features boosts the performance of state-of-the-art AutoML systems, AutoSkLearn (Feurer et al. 2015) and Probabilistic Matrix Factorization (Fusi et al., 2018). Furthermore, the inspection of MetaBu's topology gives some hints into when an ML algorithms does well."
SP:e789c71cef2094ff2bac51b523ca912f1f04c2c9,"This paper proposes a method for federated learning with heterogeneous clients. The proposed method is based on a split-mix strategy that learns a set of base sub-networks of different sizes and robustness levels, which are aggregated on-demand according to inference requirements. Experiments are conducted on CIFAR-10 and ImageNet datasets. "
SP:0fd50d89ffec376d136aa915c9c4e6ae281f5014,"This paper proposes a new algorithm for a class of nonconvex-nonconcave minimax problems. The algorithm is based on the so-called weak Minty variational inequality (MVI) and is applicable to constrained and regularized problems, and involves an adaptive stepsize allowing for potentially larger stepsizes. The proposed algorithm also converges globally even in settings where the underlying operator exhibits limit cycles. "
SP:af22742091277b726f67e7155b412dd35f29e804,"This paper studies the problem of contextual bandit, where each context-action pair is associated with a raw feature vector, but the specific reward generating function is unknown. The authors propose a novel learning algorithm Neural-LinUCB, which transforms the feature vector using the last hidden layer of a deep ReLU neural network (deep representation learning), and uses an upper confidence bound (UCB) approach to explore in the last linear layer (shallow exploration). The authors prove that under standard assumptions, the proposed algorithm achieves $\sqrt{T}$ regret, where T is the learning time horizon. "
SP:a9a2c21110e00f19882d27bef0063c422a15e576,This paper proposes a Shapley-inspired algorithm to categorize and rank training action sets for reinforcement learning. The algorithm uses a Monte Carlo simulation to reduce the exponential-time shapley computations. The effectiveness of the algorithm is demonstrated using a cloud infrastructure resource tuning case study. 
SP:0e0adc42f6025034d341dc9c17b3f6251afebc2f,"This paper studies the problem of estimating PAC prediction sets in the presence of covariate shift. The authors propose a novel approach to construct probably approximately correct (PAC) prediction sets when the covariate distribution is covariate shifted from the source distribution to the target distribution. The main contribution of this paper is to propose an algorithm to estimate the importance weights that encode how the probabilities of the training examples change under covariate shifts. The proposed method is evaluated on two datasets, DomainNet and ImageNet. "
SP:0c522ffa2c90eb88296ad0c7999200a72b8755e2,"This paper studies the generalization error of iterative semi-supervised learning (SSL) algorithms that iteratively generate pseudo-labels for a large amount of unlabelled data to progressively refine the model parameters. The authors propose an information-theoretic approach to understand the behaviour of the generalisation error using the binary Gaussian mixture model (bGMM). The theoretical results suggest that when the class conditional variances are not too large, the upper bound on the generalizability error decreases monotonically with the number of iterations, but quickly saturates. Extensive experiments are conducted on several benchmark datasets such as the MNIST and CIFAR datasets. "
SP:570149eb8fb97928f94312e40bdc48dfe9885848,"This paper proposes a model-free reinforcement learning method to generate multi-step plans for exploration. The main idea is to use a generative model to generate a plan for a sequence of future steps in order to maximize the expected return in the current time step. The authors argue that this is more effective than a single-step exploration strategy, which is inefficient due to its single step nature. Experiments are conducted on several continuous control tasks to demonstrate the effectiveness of the proposed method. "
SP:ce6a93847209a0926ed0be5190378a3f61db1935,This paper presents a framework of multi-mode deep matrix and tensor factorization methods to exploit the full nonlinearity of the data in matrices and tensors. The authors provide theoretical analysis for why and when nonlinear DMF outperforms linear DMF in matrix completion. They also propose a new matrix factorization method called two-mode nonlinear matrix factorisation (M2DMTF) to exploit full non-linearity in the data. The experiments on synthetic data and real datasets show that the proposed methods have much higher recovery accuracy.
SP:931661154975d94fc5ba1bc89d7a7fdf643df8f2,"This paper proposes a method to explain the behavior of a structured output model. The authors focus on one of the outputs as the target and try to find the most important features utilized by the structured model to decide on the target in each locality of the input space. They introduce an energy-based training process for the interpreter function, which effectively considers the structural information incorporated into the model to be explained. The effectiveness of the proposed method is confirmed using a variety of simulated and real data sets."
SP:cf9b6963c32d8689f7203dd41b17461676d08739,"This paper proposes a method for risk-sensitive reinforcement learning based on policy gradients. The method is based on a policy gradient estimate for a broad class of CDF-based objectives. The authors show how to achieve an asymptotically consistent estimate of the policy gradient for such objectives via sampling, and how to incorporate variance reduction measures to facilitate effective on-policy learning. They use the resulting algorithm to train agents with different “risk profiles” in penalty-based formulations of six OpenAI Safety Gym environments, observing that moderate emphasis on improvement in training scenarios where the agent performs poorly both increases the accumulation of positive rewards and decreases the frequency of incurred penalties."
SP:fa405481f36da10f8ca8d9d5c066458236806a12,"This paper proposes a Bayesian active learning framework for simulating large-scale, spatiotemporal, age-structured epidemic models. The proposed method is based on a neural process model to mimic the simulator dynamics. The model automatically infers the latent process which describes the intrinsic uncertainty of the simulator. This also gives rise to a new acquisition function based on the latent information gain. The authors provide theoretical analysis and demonstrate that their approach reduces sample complexity compared with random sampling in high dimension. "
SP:fdabafe7d5ca2239a241eba04e1f16cb1ac2316b,"This paper studies the problem of differentially private (DP) training of large pre-trained models for NLP tasks. The authors show that the performance drop can be mitigated by (1) the use of large pretrained models, (2) hyperparameters that suit DP optimization, and (3) fine-tuning objectives aligned with the pretraining procedure. The paper also proposes a memory saving technique that allows clipping in DP-SGD to run without instantiating per-example gradients for any linear layer in the model. The technique enables privately training Transformers with almost the same memory cost as non-private training."
SP:33008c957718d546ecb2d7b8800ef5b03700ace4,"This paper proposes a method for learning a policy to modify the skeletal structure and joint attributes of a robotic agent. The method is based on learning a conditional policy that first applies a sequence of transform actions to modify an agent’s skeletal structure, and then applies control actions under the new design. To handle a variable number of joints across designs, the authors use a graph-based policy where each graph node represents a joint and uses message passing with its neighbors to output joint-specific actions. Experiments show that the proposed method outperforms prior methods in terms of convergence speed and final performance."
SP:46e8c6a9d7729e5112b3c9f8ff91d9557ea524c1,"This paper proposes a method to accelerate inference and training of coordinate-based MLPs for implicit neural representations by proposing a new split MLP architecture, called CoordX. The initial layers are split to learn each dimension of the input coordinates separately. The intermediate features are then fused by the last layers to generate the learned signal at the corresponding coordinate point. The authors demonstrate a speedup of up to 2.92x compared to the baseline model for image, video, and 3D shape representation and rendering tasks."
SP:3ea7edab6ae65758b99615be07b7778188a6ff9f,"This paper proposes a method for learning object-centric representations of visual scenes without relying on annotations. The method learns to decompose a scene into multiple objects, with each object having a structured representation that disentangles its shape, appearance and 3D pose. To impose this structure, the authors use recent advances in neural 3D rendering. Each object representation defines a localized neural radiance field that is used to generate 2D views of the scene through a differentiable rendering process. The model is subsequently trained by minimizing a reconstruction loss between inputs and corresponding rendered scenes. The authors empirically show that INFERNO discovers objects in a scene without supervision. They validate the interpretability of the learned representations by manipulating inferred scenes and showing the corresponding effect in the rendered output. Finally, they demonstrate the usefulness of our 3D object representations in a visual reasoning task using the CATER dataset."
SP:05c61145f3fc9486728aca19c4543065fe04e99c,"This paper proposes a method to evaluate the importance of subgraphs in GNN explainability. The authors argue that a distribution shift exists between the full graph and the subgraph, causing the out-of-distribution (OOD) problem. To mitigate it, the authors propose a deconfounding evaluation framework that exploits the front-door adjustment to measure the causal effect of the explanatory subgraph on the model prediction. Specifically, they devise a generative model to generate plausible surrogates that conform to the data distribution. Empirical results demonstrate the effectiveness of the proposed method."
SP:bb74fef9222f227343909f3936f1a8cd2322bbeb,"This paper investigates whether pretrained models are better active learners, capable of asking for example labels that disambiguate between the possible tasks a user may be trying to specify. The authors show that finetuning pre-trained models with data acquired through simple uncertainty sampling achieves the same accuracy with up to 6x fewer labels compared to random sampling. Moreover, the examples chosen by these models are preferentially minority classes or informative examples where the spurious feature and class label are decorrelated. Notably, gains from active learning are not seen in unpretrained models, which do not select such examples."
SP:f5e9fc0b1b6a41e43ba4dd0cfd99d5ec7008eedf,"This paper proposes a pre-trained graph edit model for automatically detecting and fixing bugs and code quality issues in Java programs. The proposed model is based on a multi-head graph encoder and an autoregressive tree decoder to perform graph edit actions for automated program repair. The model is evaluated on the Patches in the Wild Java benchmark, using both abstract and concrete code."
SP:c7b724c671def2800694fcc2625fa48d98c7cfe6,"This paper proposes a new method for Federated Adversarial training (FAT) that relaxes the inner-maximization of the adversarial training into a lower bound friendly to Federated Learning. Specifically, the authors propose to use an alpha-weighted relaxation to relax the inner optimization of FAT. The authors also provide a theoretical analysis about the effect of the α-weighting mechanism and its effect on the convergence of FAT, and conduct extensive experiments to understand the characteristics of the proposed method."
SP:ff3c787512035e2af20778d53586752852196be9,"This paper proposes a data programming-based method for lifelong machine learning (LML) that can be applied to existing supervised and semi-supervised continual learning (SSL) methods. The proposed method, called Mako, is a wrapper tool that mounts on top of supervised LML frameworks, leveraging data programming. The main contribution of this paper is that it addresses the issue of expensive labels at the task-level, which is a common problem in LML. The authors show that the proposed method achieves similar performance, in terms of per-task accuracy and resistance to catastrophic forgetting, as compared to fully labeled data. "
SP:447df6679b2880def833d4f444bf10e61cdf0e1c,"This paper studies adversarial examples for adversarial example detection that must simultaneously satisfy two constraints: (1) be misclassified by the model and (2) be detected as non-adversarial. The authors propose two methods to generate adversarial samples that avoid this problem by orthogonalizing the gradients when running standard gradient-based attacks. They use their technique to evade four state-of-the-art detection defenses, reducing their accuracy to 0% while maintaining a 0% detection rate. "
SP:5eef907024017849303477eed92f317438c87a69,"This paper proposes a novel energy-based treatment for cooperative games with a theoretical justification by the maximum entropy principle. By conducting mean-field variational inference of the energy based model, the authors recover classical game-theoretic valuation criteria through conducting one-step fixed point iteration for maximizing the ELBO objective. This observation verifies the rationality of existing criteria, as they are all attempting to decouple the correlations among players. The authors define the valuation with the best conceivable decoupling error as the Variational Index."
SP:1257373629c8584c001b69677ebd73e5f0c20d08,"This paper proposes a new method for estimating epistemic uncertainty, i.e., the uncertainty about the generalization error of a given model. The method is based on using a second neural network to predict the errors of the first neural network, and then subtracting the aleatoric uncertainty, which is a measure of model bias or misspecification. The authors argue that this estimator is useful in interactive learning environments arising in active learning or reinforcement learning. Experiments on sequential model optimization and reinforcement learning tasks demonstrate the effectiveness of the proposed method."
SP:fd3c33c9237d0f1e33d896858a46c48da2216fe3,"This paper proposes a block Givens coordinate descent (GCD) algorithm to learn a rotation matrix in the context of end-to-end trainable product quantization (PQ) based embedding indexes. Based on geometric intuitions from Lie group theory, in particular the special orthogonal group SO(n), the authors propose a family of block GCD algorithms to learn rotation matrix that are provably convergent on any convex objectives. Compared to the state-of-the-art SVD method, the GCD algorithm is much more parallelizable, reducing runtime by orders of magnitude on modern GPUs, and converges more stably according to the convergence analysis. The proposed algorithm is also applicable to other scenarios in any neural network training."
SP:6ec2c8456ab95f7d028d00b591dab3eadc549eb8,"This paper proposes a two-stage neural framework to learn visual analogies from Raven’s Progressive Matrices. The first stage is a multi-task visual relationship encoder to extract constituent concepts from raw visual input in the source domain, and the second stage is an analogy inference engine to reason compositionally about the inferred relation in the target domain. Experiments show that the proposed method is able to generalize systematically to novel target domains."
SP:0e8c3a3dba649d496292b41228801feb8507d3b4,"This paper proposes Self-GenomeNet, a self-supervised method for learning a representation of nucleotide-level genomic data. The proposed method learns and parameterizes the latent space by leveraging the reverse-complement of genomic sequences. During the training procedure, the authors force the framework to capture semantic representations with a novel context network on top of features extracted by an encoder network. The network is trained with an unsupervised contrastive loss. Extensive experiments with different datasets show that the proposed method outperforms state-of-the-art deep learning methods."
SP:2af5c866ed17f156b406153d3261baaa42cf95fb,"This paper proposes a steerable feed-forward learning-based approach that consists of spherical decision surfaces and operates on point clouds. Focusing on 3D geometry, they derive a 3D steerability constraint for hypersphere neurons, which are obtained by conformal embedding of Euclidean space and have recently been revisited in the context of learning representations of point sets. Exploiting the rotational equivariance, they show how our model parameters are fully steerable at inference time. They use a synthetic point set and real-world 3D skeleton data to show how the proposed spherical filter banks enable making equivariant and invariant class predictions for known point sets in unknown orientations."
SP:14330a1a1c33ec18de096ffb038ba06f04c7dccb,This paper studies the continual learning of pre-trained language models (PLMs) and continual learning methods (CL methods) in the context of NLP. The authors compare the performance of 5 different PLMs and 4 CL methods on 3 different continual learning benchmarks in two different incremental settings. They also conduct a layer-wise and task-wise analysis to dissect PLMs’ performance characteristics in a detailed manner. 
SP:adb11a3bd1af2b68720f8f1b48639e31f65295fd,"This paper studies the problem of model poisoning attacks in federated learning. In particular, the authors propose a new parameter server named SESSERACT, which assigns a reputation score to the participating clients based on their behavior during the training phase and then takes a weighted contribution of the clients. They show that TESSerACT provides robustness against even a white-box version of the attack. "
SP:2047e943d2337d4fc6b0a269f43c7dfbd8ed9141,"This paper proposes a neural net debiasing method for estimating linear effects defined by linear functionals of high dimensional or non-parametric regression functions. The proposed method is based on learning the Riesz representation of the linear functional using Neural Nets and Random Forests. In particular, the authors propose a multi-tasking Neural Net debiased method with stochastic gradient descent minimization of a combined RiesZ representer and regression loss, while sharing representation layers for the two functions. They also propose a Random Forest method which learns a locally linear representation for the linear function. Experiments show that the proposed method outperforms state-of-the-art methods for the average treatment effect functional."
SP:96e1da163020441f9724985ae15674233e0cfe0d,"This paper studies the problem of decentralized multi-agent reinforcement learning with average reward. In this problem, a set of N agents work cooperatively to maximize the global average reward through interacting with their neighbors over a communication network. The authors consider a practical MARL setting, where the rewards and actions of each agent are only known to itself, and the knowledge of joint actions of the agents is not assumed. They propose a mini-batch Markovian sampled actor-critic algorithm and analyze its finite-time convergence and sample complexity. They show that the sample complexity of this algorithm matches that of the state-of-the-art single-agent actor critic algorithms."
SP:8475e89f143c727e33147b652c2d0b3cdb420382,"This paper studies the role of data augmentation in contrastive learning. In particular, the authors propose a new definition of contrastive loss that does not rely on the conditional independence assumption. Instead, they argue that different samples from the same class could be bridged together with aggressive data augmentations, and thus simply aligning the positive samples (augmented views of the same sample) could make contrastive learn cluster intra-class samples together. The authors also show that their theory aligns well with existing contrastive methods on both synthetic and real-world datasets."
SP:b491314336c503b276e34e410cf461cb81294890,"This paper proposes a general speech restoration (GSR) task that attempts to remove multiple distortions simultaneously. The authors propose a generative framework to address the GSR task. VoiceFixer consists of an analysis stage and a synthesis stage to mimic the speech analysis and comprehension of the human auditory system. Experiments are conducted with additive noise, room reverberation, low-resolution, and clipping distortions. "
SP:c80a7392ec6147395a664734601fb389a1eb4470,This paper proposes a method for multivariate time series forecasting based on tensor networks. The main idea is to use a tensor network based on the idea of low-rank approximation to model the variable space. The tensor components are shared to ensure the translation invariance of the network. An N-order residual connection approach is proposed to improve the ability to model long-term sequences. Experimental results verify the effectiveness of the proposed method.
SP:0a92939e6a1c88bfeb4fd1dea9ee7be4fd60d967,This paper proposes a variant of SCO algorithms with sparse moving averages for GNN training. The main idea is to store the moving averages of the aggregated features of all nodes in the graph in the most recent iteration. The authors show that their algorithm preserves the convergence rate of the original SCO algorithm when the buffer size satisfies certain conditions. The experiments validate the theoretical results and show that the proposed algorithm outperforms the traditional Adam SGD for training GNNs.
SP:72e0cac289dce803582053614ec9ee93e783c838,This paper proposes Circulant MinHash (C-MinHash) which uses two independent random permutations in a circulant manner to approximate the Jaccard (resemblance) similarity in massive binary (0/1) data. The authors prove that using only two independent permutations leads to uniformly smaller variance than that of the classical MinHash with K independent permutation. Experiments are conducted to show the effectiveness of the proposed method.
SP:d254b38331b6b6f30de398bae09380cd5c951698,"This paper proposes a novel adversarial training scheme for multiple norm robustness. The proposed method is based on geometric considerations of the different lp-balls and can achieve adversarial robustness against the union of different threat models. Moreover, the authors show that using the proposed E-AT scheme one can fine-tune with just 3 epochs any lp robust model and achieve multiple norm adversarial performance on CIFAR-10."
SP:4c2928f6772664d63c02c29f913b476e1c932983,"This paper proposes a safe multi-task learning (SMTL) model, which consists of a public encoder shared by all the tasks, private encoders, gates, and private decoders. Specifically, each task has a private encoder, a gate, and a private decoder, where the gate is to learn how to combine the private encode and the public decoder for the downstream task. To reduce the storage cost during the inference stage, a lite version of SMTL is proposed to allow the gate to choose either the public encoder or the decoder. Experiments on several benchmark datasets demonstrate the effectiveness of the proposed methods."
SP:c4cee0d44198559c417750ec4729d26b41061929,"This paper analyzes the partition function of energy-based sequence models backed by expressive parametric families. The authors show that the partition functions of such models are uncomputable and inapproximable, which makes model selection difficult and undecidable. Specifically, they show that there exist pathological EBM sequence models that have uncomputable partition functions, which cannot be approximated well under stochastic estimates, and do not have asymptotic estimates that have any good guarantees. Furthermore, they argue that model selection is impossible for expressive model families, and discuss why common estimation methods fail."
SP:f1eb66f24a14808d404f9ad9773ef4288efa060e,"This paper proposes a new family of distance metrics, called augmented sliced Wasserstein distances (ASWDs), constructed by first mapping samples to higher-dimensional hypersurfaces parameterized by neural networks. It is derived from a key observation that (random) linear projections of samples residing on these hypersurfaced would translate to much more flexible nonlinear projections in the original sample space, so they can capture complex structures of the data distribution. The ASWD adaptively updates the hypersurface used to slice compared distributions by learning from data. The paper also provides the condition under which the ASWD is a valid metric and show that this can be obtained by an injective neural network architecture."
SP:ff2433f2de48d4ed8017e27bd6cf606845cdea9e,This paper proposes a method to improve coordination and performance of multi-agent reinforcement learning (MARL) agents. The proposed method is based on an agent generator that learns to construct intrinsic rewards online that coordinate the agents’ joint exploration and joint behaviour. The generator is trained using a combination of reinforcement learning and switching controls. The authors prove that the method converges to a solution that learns an intrinsic reward function that improves the performance of MARL agents. 
SP:9eadc19f7f712c488cf50d091f372092f6352930,"This paper proposes a new multi-hop QA model, called DOCHOPPER, which is based on a hierarchical attention mechanism. The main idea of the model is to update the query at each step of the QA process by using a compact neural representation of the query. The model is evaluated on four different QA tasks and achieves state-of-the-art results. "
SP:4e79b326bbda5d1509e88869dde9886764366d41,"This paper proposes a semi-supervised learning method for extracting refined labels (e.g. vocal characteristics) from known initial labels. The method is validated by applying Label Refining on recordings from the MassEffect 3 video game. Experiments show that, using a subsidiary corpus, it is possible to bring out interesting voice characteristics without any a priori knowledge."
SP:9c399331a3b4a55d7e1ff9298f82a38b75b4f87d,"This paper proposes a new distributed learning framework for multi-task learning. The key idea is to use a task-agnostic Vision Transformer and task-specific heads and tails at client sides to learn a translation from its own task to a common representation, while the Transformer body learns global attention between the features embedded in the representation. An alternating training strategy is proposed to enable decomposition between the task specific and common representation. Experiments on four different image processing tasks show the effectiveness of the proposed method."
SP:249a72ef4e9cf02221243428174bb749068af6b2,"This paper studies the problem of reward hacking in reinforcement learning. The authors construct four RL environments with misspecified rewards. They investigate reward hacking as a function of agent capabilities: model capacity, action space resolution, observation space noise, and training time. They find instances of phase transitions: capability thresholds at which the agent’s behavior qualitatively shifts, leading to a sharp decrease in the true reward. To address this, they propose an anomaly detection task for aberrant policies and offer several baseline detectors."
SP:1c8d06fe0b2a79d5d0c0f317692c2ee869d1cc0c,"This paper proposes a f-divergence f-TVO that generalizes TVO by replacing KL divergence with arbitary differeitiable f divergence. The main contribution of this paper is to introduce a deformed χ-geometry perspective for TVO, which is the deformed geodesic between the variational posterior distribution and the true posterior distribution. Experiments on VAE and Bayesian neural network show that the proposed f -TVO performs better than the f-VI. "
SP:d4ce49411198fe65b8f4c2d80af222e0732a4728,"This paper studies the interplay between different reinforcement learning tools in the continuous control setting. The authors conduct a comprehensive empirical analysis of multiple RL tools from the RL toolbox applied to the OpenAI Gym MuJoCo setting. They show how existing tools can be brought together in a novel way, giving rise to the Ensemble Deep Deterministic Policy Gradients (ED2) method to yield state-of-the-art results on continuous control tasks from OpenAI gym. "
SP:21819b54433fa274657d9fe418f66407eee83eeb,"This paper studies the problem of fair supervised learning under the Equalized Loss (EL) fairness notion, which requires the prediction error/loss to be the same across different demographic groups. By imposing EL constraint, the learning problem can be formulated as a non-convex optimization problem, and the authors introduce a number of algorithms that find the global optimal solution. The optimal solution can be found by solving a sequence of convex constrained optimization problems. The authors also introduce a simple algorithm for finding a sub-optimal solution. Experiments are conducted to validate the theoretical results."
SP:336c1b8a7f293a78dfab18e7b454b0ec39822293,"This paper revisits systematic generalization from the perspective of meaningful learning. The authors propose to reassess models’ compositional skills conditioned on the semantic connections between new and old concepts. In experiments, following the meaningful learning principle, they augment a training dataset in either an inductive or deductive manner to exposure such semantic links to models. Their observations on SCAN, as well as two real-world datasets on semantic parsing, suggest that modern sequenceto-sequence models, including RNNs, CNNs, and Transformers, can successfully one-shot generalize to novel concepts and compositions through semantic linking."
SP:5d758b9125e716c92dde5cfcc8aad67adbd30ba0,"This paper proposes a novel method for 3D shape representation learning using multi-scale wavelet decomposition. The method decomposes 3D shapes into sub-bands components at multiple scales and all scales form a decomposition tree in a principled manner rooted in multi-resolution wavelet analysis. Specifically, the authors propose Adaptive Wavelet Transformer Network (AWT-Net) that firstly generates approximation or detail wavelet coefficients per point, classifying each point into high or low sub-band components, using lifting scheme at multiple scale recursively and hierarchically. Then, AWT-net exploits Transformers that regard the features from different but complementary components as two holistic representations, and fuse them with the original shape features with different attentions. The wavelets coefficients can be learned without direct supervision on coefficients, and the network is fully differentiable. Extensive experiments demonstrate the effectiveness of the proposed method."
SP:b89c04e2f8e94c7d0c3686edac835a86fab2d528,"This paper studies the problem of finetuning a pre-trained language model for natural language generation tasks. The authors propose a combination of lightweight and full fine-tuning methods to achieve strong out-of-distribution (OOD) and in-domain (ID) performance. They show that an ensemble of lightweight finetuned models achieves the best of both worlds: performance matching the better of full and lightweight fine tuning, both ID and OOD. They also show that they can achieve similar improvements using a single model instead of two with their proposed cocktail finetune method. "
SP:28fe2b3deb6a8f24f26d48240da38d280673b8f2,"This paper proposes an active learning approach to improve the performance of weakly supervised models. The approach is based on data programming, a framework for learning from weak supervision that generates probabilistic training labels from simple yet imperfect heuristics (labelling functions) obtained a priori from domain experts. The key idea is to iteratively update the parameters of the individual expert labelling functions in the weak supervision model. Experiments on multiple real-world medical classification datasets show that the proposed approach can substantially improve the accuracy of probabilistically labeled labels used to train downstream classifiers with as few as 30 queries to experts."
SP:f663a1e64155f1d4c890a6fefae596f67ef3cb11,"This paper studies the problem of training a classification model with group annotated training data. The authors propose a new algorithm called Common Gradient Descent (CGD) that explicitly encourages learning of features that are shared across various groups. The key insight is that while Group-DRO focuses on groups with worst regularized loss, focusing instead, on groups that enable better performance even on other groups, could lead to learning of shared/common features, thereby enhancing minority performance beyond what is achieved by Group DRO. Empirically, the proposed algorithm matches or achieves better performance compared to strong contemporary baselines including ERM and GroupDRO on standard benchmarks. "
SP:faad5fe1eefbcc2e24638383d0bde7ad7975ff4e,"This paper proposes a bivariate explanation method to explain black-box models. The main idea is to use a directed graph to capture feature interactions in black box models, which are represented as directed graphs. The proposed method is based on two concepts of redundancy between features, denoted as mutual redundancy and directional redundancy. Experiments are conducted to demonstrate the effectiveness of the proposed method. "
SP:c8a4254e6fc2d2e7d1d41a76bb64f78f22a8639d,"This paper proposes Policy Extraction through decision Trees (POETREE), a novel framework for interpretable policy learning, compatible with fully-offline and partially-observable clinical decision environments, and builds probabilistic tree policies determining physician actions based on patients’ observations and medical history. The authors propose to grow decision trees incrementally during optimization to adapt their complexity to the modelling task, and learn a representation of patient history through recurrence, resulting in decision tree policies that adapt over time with patient information. This policy learning method outperforms the state-of-the-art on real and synthetic medical datasets."
SP:5630707c9d0d9e21fce2efddef874e373bfed026,This paper proposes a multi-agent reinforcement learning (MARL) approach to automatically search for the optimal data augmentation policy for patches of an image. The approach is based on the observation of the joint optimal policy of each agent. The proposed method is evaluated on a variety of image classification and object detection tasks.
SP:bb2a13a4d366140fc0c3e941c354cc674f6a904f,"This paper proposes a method to mitigate the adversarial vulnerability of adversarial examples. The method is based on causal reasoning. The authors construct a causal graph to model the generation process of an adversarial example and define adversarial distribution to formalize the intuition of the attack. They show that the spurious correlation between labels and style variables is important for understanding and mitigating the vulnerability. Based on this observation, they propose a defense method to reduce the vulnerability by eliminating the difference between the natural and adversarial distributions. Extensive experiments demonstrate the efficacy of the proposed method."
SP:9f09449a47464efb5458d0732df7664865558e6f,"This paper proposes to enforce a low-rank filter subspace by decomposing convolutional filters within each network layer over a small set of filter atoms. Then, it performs continual learning with filter atom swapping. In other words, it learns for each task a new filter sub space for each CNN layer, i.e., hundreds of parameters as filter atoms, but keeps subspace coefficients shared across tasks. The effectiveness of this simple scheme for continual learning is illustrated both empirically and theoretically. The proposed atom swapping framework further enables flexible and efficient model ensemble with members selected within task or across tasks to improve the performance."
SP:b806dd540708b39c10d3c165ea7d394a02376805,"This paper analyzes the variance collapse of Stein variational gradient descent (SVGD) in high dimensions. The authors show that SVGD suffers from the curse of dimensionality in the proportional asymptotic limit, i.e., when the number of particles $n$ and dimensions $d$ diverge at the same rate. They show the exact equilibrium variance of SVGD and MMD-descent for high-dimensional isotropic Gaussians under certain conditions on the converged particles. "
SP:3721f1b12d87e95f5aa4c977a1714d5c54cb70f7,"This paper studies the effect of adversarial training (AT) with noisy labels on the robustness of a point. The authors show that the number of projected gradient descent (PGD) steps to successfully attack a point (i.e., find an adversarial example in its proximity) is an effective measure of its robustness. They also show that AT with strong smoothing effects suffers less from NL (without NL corrections) than standard training. "
SP:2bcf42173d9d82fb3e517405deba4aa3d6f9d8d6,"This paper proposes a new statistical method, called Robustness Measurement and Assessment (RoMA), to measure the expected robustness of a neural network model. Specifically, RoMA determines the probability that a random input perturbation might cause misclassification. The method allows us to provide formal guarantees regarding the expected frequency of errors that a trained model will encounter after deployment. The approach can be applied to large-scale, black-box neural networks, which is a significant advantage compared to recently proposed verification methods."
SP:6ba17dd4b31a39478abd995df894447675f2f974,"This paper proposes a hierarchical chunking model (HCM) that learns chunks from non-i.i.d sequential data with a hierarchical structure. HCM starts out learning an atomic set of chunks to explain the sequence and gradually combines them into increasingly larger and more complex chunks, thereby learning interpretable hierarchical structures. The output of the model is a dynamical graph that is a trace of the evolving representation. The resulting representations are easy to interpret, and flexibly reusable (e.g. we can choose to re-use specific parts). "
SP:625e3908502fd5be949bb915116ed7569ba84298,"This paper studies the problem of accelerating non-linear non-convex optimization problems. The authors show that reparametrizing the optimization variables as the output of a neural network can lead to significant speedup. They show that to obtain the maximum speed up, the neural network architecture needs to be a specially designed graph convolutional network (GCN). The aggregation function of the GCN is constructed from the gradients of the loss function and reduces to the Hessian in early stages of the optimization. "
SP:80346eeafb0a6d1d556c304a3f8753aff037469b,"This paper proposes SVMnet, a method based on a layered structure of Support Vector Machine (SVM) ensembles for non-parametric image classification. By utilizing the quick learning of SVMs compared to neural networks, the proposed method can reach higher accuracy than deep convolutional neural networks (DCNNs) when the training set is small. Experimental results show that while “conventional” DCNNs are often tested on relatively large datasets such as MNIST or ImageNet, in many real-world problems a very large number of clean labeled samples that can be used for training is not available."
SP:a18f4697f350a864866dac871f581b8fc67e8088,"This paper proposes a communication-efficient distributed GNN training technique named Learn Locally, Correct Globally (LLCG) to reduce the communication and memory overhead. The proposed method first trains a GNN on its local data by ignoring the dependency between nodes among different machines, then sends the locally trained model to the server for periodic model averaging. However, ignoring node dependency could result in significant performance degradation. To solve the performance degradation, the authors propose to apply Global Server Corrections on the server to refine the locally learned models. Theoretical analysis shows that naively applying periodic parameter averaging leads to a residual error and current solutions to this issue impose huge communication overheads. Instead, this proposal tackles these problems by applying correction on top of locally learned model to infuse the global structure of the graph back into the network and avoid any costly communication. Extensive experiments on real-world datasets show that LLCG can significantly improve the efficiency without hurting the performance."
SP:6805f2245484fc91b5c13aa5f09e5478b810f97f,"This paper proposes a unified and end-to-end model approach for anytime pixel-level recognition. A cascade of “exits” is attached to the model to make multiple predictions and direct further computation. The authors redesign the exits to account for the depth and spatial resolution of the features for each exit. To reduce total computation, and make full use of prior predictions, they develop a novel spatially adaptive approach to avoid further computation on regions where early predictions are already sufficiently confident. Their full model with redesigned exit architecture and spatial adaptivity enables anytime inference, achieves the same level of final accuracy, and even significantly reduces total computation."
SP:1a75aaef7ba0d2de5804514f0de39d9c769f419b,"This paper proposes a bootstrapping approach to bootstrap stochastic processes with neural networks. The proposed approach is based on a meta-learning framework, where a generator function is learned to generate the bootstrap distribution of random functions by injecting multiple random weights into the encoder and the loss function. Experiments are conducted on Bayesian optimization and contextual multi-armed bandit to demonstrate the effectiveness of the approach."
SP:34e1b51ff5d524490332aed51b9c411209c89a20,"This paper proposes a multi-modal self-supervised pre-training framework for large-scale genome data. Specifically, the authors take the 1d sequence of genome data and a 2d matrix of (transcription factors × regions) as the input. They pre-train their model on the ATAC-seq dataset with 17 million genome sequences. They evaluate their GeneBERT on regulatory downstream tasks, including promoter classification, transaction factor binding sites prediction, disease risk estimation, and splicing sites prediction."
SP:841b12443d0274e34b78940f220b17d36798899b,This paper proposes a new method for out-of-distribution (OOD) detection based on the geodesic (Fisher-Rao) distance between the underlying data distributions. The discriminator is able to combine confidence scores from the logits outputs and the learned features of a deep neural network. The proposed method is evaluated on a variety of network architectures and datasets.
SP:2fdca838ac3453e44cff395f1b760d839a5813bf,"This paper studies the expressivity of representations constrained by group equivariance. The authors show that the fraction of separable dichotomies is determined by the dimension of the space that is fixed by the group action. They show how this relation extends to operations such as convolutions, element-wise nonlinearities, and global and local pooling. Finally, they test their theory on intermediate representations of randomly initialized and fully trained convolutional neural networks."
SP:47889067620e5ac2e304681769af9d1d930f6d2b,"This paper proposes a method to explain the model's misclassification of a test sample in terms of concepts (e.g., a zebra is misclassified as a dog because of its faint stripes). The method is based on two ideas: counterfactual explanations and concept activation vectors. The authors validate their approach on well-known pretrained models, showing that it explains the models’ mistakes meaningfully. In addition, for new models trained on data with spurious correlations, CCE accurately identifies the spurious correlation as the cause of model mistakes from a single misclassified test sample."
SP:4aa5f00830fda36b6ca2f53d88c3a8a963058ec0,"This paper proposes a modification to kernel point convolutional neural networks (KPConv) to improve the efficiency and quality of KPConv. Specifically, the authors propose to use a depthwise kernel to reduce resource consumption and re-calibrate the contribution of kernel points towards each neighbor point via Neighbor-Kernel attention to improve representation power. In addition, they utilize Inverted Residual Bottleneck (IRB) to craft a design space and employ a predictor-based Neural Architecture Search (NAS) approach to automate the design of efficient 3D networks based on the proposed module. Experiments and ablation study over 3D classification and 3D semantic segmentation benchmarks verify the effectiveness of the proposed method."
SP:bf7d2e765c435a943ec9257cfa43d070a64c2b67,"This paper studies the problem of adversarial training from a data quality perspective. Specifically, the authors propose to measure the data quality based on the learning behaviors of the data during adversarial learning and find that low-quality data may not be useful and even detrimental to the adversarial robustness. They then design controlled experiments to investigate the interconnections between data quality and problems in adversarial train. They find that when low- quality data is removed, robust overfitting and robustness overestimation can be largely alleviated; and the robustness-accuracy trade-off becomes less significant."
SP:99a36b28752bfc101877bfd0da436e6fb19c69d3,"This paper analyzes the number of neurons and training parameters that a neural network needs to approximate multivariate functions of bounded second mixed derivatives (Korobov functions). The authors prove upper bounds on these quantities for shallow and deep neural networks, drastically lessening the curse of dimensionality. Their bounds hold for general activation functions, including ReLU. They also show that these bounds nearly match the minimal number of parameters any continuous function approximator needs. "
SP:a0112febb28e518e87142e7cbb7e3586d06cae0b,This paper investigates the role of population size in language emergence in the speaker-listener Lewis game. The authors argue that the current population-based models may actually be too simplistic as they assume homogeneous communities. They show that this simplification is a potential root cause of the experimental difference between neural observations and the socio-linguistic literature. They also show that the relative training speed of agents may be an underestimated factor in shaping languages.
SP:462112ea1a59ab8101ed9d908c5d838edeb844ca,"This paper proposes a method to improve the performance of GNNs on heterophilic graphs. The proposed method is based on the GPR-GNN model, which is a polynomial filter-based GNN with additional polynomials that adapt to low and high-frequency components. The authors show that the proposed method outperforms the existing methods on several graph classification tasks. "
SP:903545b1b340ec5c13070e0f25f550c444de4124,This paper proposes a novel graph shortest distance embedding method called Betweenness Centrality-based Distance Resampling (BCDR) to improve the graph embedding for the shortest distance representation with two components. The first is betweenness centrality (BC)-based random walk to accommodate long-distance correlation on graphs by covering a wider range of nodes under the intrinsic graph metric. The second is a distance resampling strategy to preserve shortest distances during the mapping from graph to the embedding space via reconstructing a global distance matrix. The experimental evaluation indicates that BCDR possesses a better capacity than existing graph embeddings methods to extract distance structure from original graphs.
SP:13db440061fed785f05bb41d0767225403ecf7a1,"This paper proposes a new continual learning (CL) problem called Continual Knowledge Learning (CKL) to address the problem of catastrophic forgetting and reliably acquire new knowledge while preserving invariant knowledge. The authors construct a new benchmark and metric to quantify the retention of time-invariant world knowledge, the update of outdated knowledge, and the acquisition of new knowledge. They adopt applicable recent methods from literature to create several strong baselines. Through extensive experiments, they find that CKL exhibits unique challenges that are not addressed in previous CL setups, where parameter expansion is necessary to reliably retain and learn knowledge simultaneously."
SP:639fd88482330389019fb5be7446a909b99a8609,"This paper proposes a stochastic algorithm for decision tree induction. The algorithm is based on splitting the leaf nodes into a split and two leaf nodes until a certain stopping criterion is reached. It is shown that the proposed algorithm is faster than conventional exhaustive search by several orders of magnitude. The authors also show that the algorithm minimizes an upper bound for the criterion. Finally, the algorithm is applied to the task of training Haar trees."
SP:7f2640f18294519a5abb1daaa226800d2377a5e0,"This paper proposes a new learning rate scheduler for SGD on quadratic objectives with skewed Hessian spectrums. The authors show that the proposed eigencurve scheduler can achieve minimax optimal convergence rates (up to a constant) when the eigenvalue distribution of the underlying Hessian matrix is skewed, which is quite common in practice. The paper also shows that the optimal shape of the proposed schedulers resembles that of cosine decay for some problems, which sheds light to the success of cosines decay for such situations. "
SP:8cfafcf0de6de33a8fd298593eeea82376b4697a,"This paper studies the problem of offline model-based reinforcement learning (MBRL) with a learned dynamics model. In this paper, the authors compare a variety of uncertainty heuristics in the offline MBRL literature, including pessimistic MDPs that use the model uncertainty to penalize the agent’s reward. The authors also propose a new evaluation protocol based on Bayesian optimization to evaluate the impact of different hyperparameters on the performance of MBRL.   "
SP:3833662cf92249d83e65a1200f9e2890b5b23e95,"This paper proposes a method for prioritized experience replay (PER) based on model-augmented reinforcement learning (MbRL). The main idea is to use the TD-error as an auxiliary feature to improve the quality of the experience replay. The authors argue that the TD error is often overestimated or under-estimated by the critic network, which makes it ineffective to learn to predict Q-values by sampled experiences based heavily on TD error. Motivated by this motivation, the authors propose a new feature called Model-Aware Critic Network (MaCN) to estimate not only the Q-value but also the environment behavior via weight sharing, where environment behavior is useful to predict the value. The proposed MaPER is evaluated on a variety of off-policy MfRL algorithms and shows promising results. "
SP:0db83e057c21ac10fe91624876498d8456797492,This paper proposes a method to train agents to drive in a simulated driving environment with the help of a human expert. The human expert can take over the control and demonstrate to the agent how to avoid probably dangerous situations or trivial behaviors. The agent is trained using the data collected from the trial-and-error exploration and human’s partial demonstration to train a high-performing agent. The experiments show that HACO achieves a substantially high sample efficiency in the safe driving benchmark.
SP:7fda4f67daf3eb27cdfafe8f8a3f8d719da956c3,"This paper proposes Dual Meta Imitation Learning (DMIL), a hierarchical meta imitation learning method where the high-level network and sub-skills are iteratively meta-learned with model-agnostic meta-learning. DMIL uses the likelihood of state-action pairs from each sub-skill as the supervision for the adaptation, and use the adapted high level network to determine different data set for each sub skill adaptation. The authors theoretically prove the convergence of the iterative training process and establish the connection between DMIL and the Expectation-Maximization algorithm. Empirically, the proposed method achieves state-of-the-art few-shot imitation learning performance on the meta-world benchmark."
SP:fb0efa670729796471a7a562b231172103bb8749,This paper proposes a node embedding compression method that compresses the embeddings of each node in a graph. The method is based on a hashing-based coding scheme that generates compositional codes for compactly representing nodes in graph datasets. The proposed coding scheme outperforms the prior embedding compressing method which uses a random coding scheme in almost all experiments. 
SP:15c243829ed3b2505ed1e122bd499089f8a862da,"This paper studies the problem of learning invariant representations using domain adversarial training (DAL) from a game-theoretic perspective. The authors show that standard optimizers in DAL can violate the asymptotic convergence guarantees of the gradient-play dynamics, requiring careful tuning and small learning rates. Based on this observation, the authors propose to replace existing optimizers with higher-order ODE solvers, which are more stable and allow for higher learning rates, leading to noticeable improvements in terms of the transfer performance and the number of training iterations. The experiments show that the proposed method outperforms strong baselines."
SP:0ecbaf1770642b6ac5c9786ba2d18408310fc225,"This paper proposes a new regularizer, iFlood, to prevent overfitting of machine learning models. Specifically, the authors propose to use an instance-level regularizer to enforce the training loss on the under-fitted instances to be smaller than the over-fitted ones. The authors also theoretically show that the design of the regularizer can be intrinsically connected with removing the noise or bias in training data, which makes it suitable for a variety of applications to improve the generalization performance of learned models. Experiments are conducted on both image classification and language understanding tasks to demonstrate the effectiveness of the proposed regularizer."
SP:e6622975c9889cf6d3357ab439c2e268c4f4200e,"This paper proposes Value Function Spaces (VFS), a hierarchical reinforcement learning (HR) method that uses low-level skills as action abstractions for long-horizon planning. The key idea of VFS is to use the value functions corresponding to each lower-level skill to capture the affordances of the scene, thus forming a representation that compactly abstracts task relevant information and robustly ignores distractors. Empirical evaluations for maze-solving and robotic manipulation tasks demonstrate that VFS improves the performance of the method. "
SP:6adcd2a71ce70922c4cbe155d49f105964faee8f,"This paper proposes Top-n, a non-exchangeable one-shot probabilistic generative model for set and graph generation. The main idea is to replace i.i.d. generation in VAEs and GANs with Top-N, which is a deterministic, deterministic model that learns to select the most relevant points from a trainable reference set. The paper provides a new definition of equivariance and shows that exchangeability is in fact unnecessary in VAE/GANs. Experiments are conducted to demonstrate the effectiveness of the proposed method. "
SP:f1f1df92e3e7c6b3b9e326a78a708c0d5d990c83,"This paper studies the statistical limits of deep learning techniques for solving elliptic PDEs from random samples using the Deep Ritz Method (DRM) and Physics-Informed Neural Networks (PINNs). To simplify the problem, this paper focuses on the Schrödinger equation on a hypercube with zero Dirichlet boundary condition, which is applied in quantummechanical systems. The authors establish upper and lower bounds for both methods, which improve upon concurrently developed upper bounds for this problem via a fast rate generalization bound. They also propose a modified version of deep ritz method that achieves minimax optimal bounds over Sobolev spaces. Empirically, following recent work which has shown that the deep model accuracy will improve with growing training sets according to a power law, the authors show similar-behavior of dimension dependent power law for deep PDE solvers."
SP:80614db60d27a48c3c1b1882844e298666b798d4,"This paper analyzes the relationship between robustness and generalization in the context of domain generalization. The authors provide sufficient conditions for this phenomenon considering different factors that could affect both, such as norm of the last layer, Jacobian norm, and data augmentations (DA). They show that robustness induced by adversarial training is a by-product of such function class regularization. They conduct extensive experiments to verify their theoretical findings and show several counterexamples."
SP:4d49bcb069a76f108c0e2de50750827f45eb5676,This paper studies the problem of memorization in meta-learning from a causal perspective. The authors identify the root cause of the memorization problem as a spurious correlation in the label space and propose a novel causal intervention principle to debias the spurious correlation. They also propose a new deconfounder approach based on the principle of front-door adjustment and demonstrate its effectiveness on four benchmark datasets. 
SP:adfe205b335cf87bd4e470efd9f72bb639a4451c,"This paper proposes a novel reinforcement learning algorithm called ODITS to address the challenging ad hoc teamwork problem. Instead of limiting teammates into a finite set of predefined types, ODITS automatically learns latent variables of teammates’ behaviors to infer how to cooperate with new teammates effectively. To overcome partial observability, they introduce an information-based regularizer to derive proxy representations of the learned variables from local observations. Extensive experimental results show that ODITS significantly outperforms various baselines in widely used ad-hoc teamwork tasks."
SP:7b04b45c4dd237d69321d280dcdcbc89fb362015,"This paper proposes a method for imputation of missing values in high-dimensional data. The method is based on the Expectation-Maximization (EM) algorithm with a normalizing flow (NF) model, which maps the data space to a latent space via an online version of the EM algorithm. The proposed method is evaluated on both multivariate and image datasets. "
SP:a151ae8afae0a073b0df83a74fd084dfe3753a48,"This paper studies deep neural networks with rectified linear units (ReLUs) and extends the recently developed dual view in which the computation is broken path-wise to show that learning in the gates is more crucial, and learning the weights given gates is characterised analytically via the neural path kernel (NPK) which depends on inputs and gates. The authors show that convolution with global pooling and skip connection provide respectively rotational invariance and ensemble structure to the NPK. They propose a novel interpretable counterpart of DNNs with ReLUs namely deep linearly gated networks (DLGN): the pre-activations to the gates are generated by a deep linear network, and the gates can be applied as external masks to learn the weights in a different network. The DLGN is not an alternative architecture per se, but a disentanglement and an interpretable re-arrangement of the computations in a DNN with ReLU."
SP:5676944f4983676b5ad843fdb190bf029ad647bb,"This paper proposes Dynamic Token Normalization (DTN), a new normalization technique for Vision Transformer (ViT) to capture both long-range dependencies and local positional context. The authors claim that the ordinary LN makes tokens at different positions similar in magnitude because it normalizes embeddings within each token. To tackle this problem, DTN is built on a unified formulation and thus can represent various existing normalization methods. Experiments show that the transformer equipped with DTN consistently outperforms baseline model with minimal extra parameters."
SP:7a04efbf835c238bbdf70a8b8decee4ec2907a3a,"This paper proposes two methods to measure the spectral bias in modern image classification neural networks. The first method measures the frequency of the learned function. The second method is based on the label noise methodology of Rahaman et al. (2019) to study spectral bias through the input space. The authors show that larger models learn high frequencies more readily than smaller ones, but many forms of regularization, both explicit and implicit, inhibit the learning of high frequencies. They also explore the connections between function frequency and image frequency."
SP:9ef61f2064db8ac3b01b16694a744b274bdbbe83,"This paper studies the problem of mode-switching, non-monolithic exploration for reinforcement learning. The authors propose a method to switch between exploration and exploration at sub-episodic time-scales. They also propose practical algorithmic components that make the switching mechanism adaptive and robust. Finally, they report a promising and detailed analysis on Atari, using two-mode exploration and switching. "
SP:c44d3749d8883fae7eb2a6378417fca28d25a4c9,"This paper proposes a new initialization scheme for the k-median problem in the general metric space. The proposed method is based on the construction of metric embedding tree structure of the data. From the tree, the authors propose a novel and efficient search algorithm for good initial centers that can be used subsequently for the local search algorithm. The method, named the HST initialization, can also be easily extended to the setting of differential privacy (DP) to generate private initial centers. Theoretically, the proposed method can achieve lower error than the existing initialization method in the non-DP setting. Empirically, experiments are conducted to demonstrate the effectiveness of the proposed methods."
SP:84c9eb6623e7950585d80a664dd51b3ecc356dea,"This paper proposes a new video prediction model, named FitVid, which is based on variational autoencoder to predict the future frames of a video conditioned on the observed past and potentially future actions. The authors argue that the inefficient use of parameters in the current video prediction models is the main reason for the low quality predictions. To alleviate the issue of overfitting, the authors propose using a set of existing image augmentation techniques that prevent overfitting in video prediction settings, leading to state-of-the-art results across a range of prediction benchmarks."
SP:6eb5ce1d85928a3af759d75016089c535941d0b0,"This paper studies the influence of data structure on the generalization performance of a machine learning algorithm such as a neural network on the structure of the data distribution. The authors study an exactly solveable model of stochastic gradient descent (SGD) which predicts test loss when training on features with arbitrary covariance structure. They solve the theory exactly for both Gaussian features and arbitrary features and show that the simpler Gaussian model accurately predicts the test loss of nonlinear random-feature models and deep neural networks trained with SGD on real datasets such as MNIST and CIFAR-10. The optimal batch size at a fixed compute budget is typically small and depends on the feature correlation structure, demonstrating the computational benefits of small batch sizes."
SP:a530dd966911e387a90e3cbf9f51c8cab6152723,"This paper studies the behavior of SGD in toy landscapes with non-convex loss and multi-minima. In particular, the paper considers discrete-time SGD close to saddle points, where the noise is due to minibatch sampling, and the learning rate is held constant throughout training. The paper shows that, with specific choices of learning rate and specific model (specifically SGD may converge to local maxima, SGD might only escape saddle points arbitrarily slowly, and SGd may prefer sharp minima over flat ones), SGD can converge to the saddle point, and AMSGrad may converge to local minima. "
SP:22d01913b78ef447b064c65a646fa301b861d3f7,This paper proposes a new method for hyperparameter optimization in meta-learning. The proposed method is based on distilling the second-order term of the hyperparameters into a single Jacobian-vector product (JVP) and minimizing the distance between the JVP and the true second order term. The JVP is parameterized as a function of the true JVP. The authors demonstrate the effectiveness of the proposed method on two different meta learning methods and three benchmark datasets. 
SP:a64b26faef315c3ece590322291bab198932c604,"This paper proposes a new meta-learning method for few-shot image classification and cold-start recommendation. The proposed method is based on a clustering-aware meta-learner that learns task-specific embeddings from both features and the learning path. In particular, the proposed method first performs rehearsed task learning from the common initialization, and collects a set of geometric quantities that adequately describe the learning paths. Then, the learned embedding is used to abstract the path representation optimized for the downstream clustering and modulation. Experiments on two real-world application domains demonstrate the superiority of CTML over state-of-the-art baselines."
SP:f7a7c81ed2b6e9eb958b8b751deed8166622540c,This paper proposes an ensemble-based semi-supervised novelty detection (SSND) method that only utilizes a mixture of unlabeled ID and OOD samples to achieve good detection performance on near OOD data. The proposed method relies on regularization to promote diversity on the out-of-distribution data while preserving agreement on ID data. Extensive experiments are conducted to demonstrate the effectiveness of the proposed method. 
SP:a0ee0e08b4bb578836fd5e0781e8713f254569fb,"This paper proposes Latent Variable Sequential Set Transformer (AutoBot) to model time-evolution of sequential sets using discrete latent variables. The encoder is a stack of interleaved temporal and social multi-head self-attention modules which alternately perform equivariant processing. The decoder can produce either the trajectory of one ego-agent or a distribution over the future trajectories for all agents in the scene. For the single-agent prediction case, the model achieves top results on the global nuScenes vehicle motion prediction leaderboard, and produces strong results for the Argoverse vehicle prediction challenge."
SP:e253d49bbfadb76b2f7c4e7cdd1cc33d0cebc3e7,This paper presents a user study on two interpretable image classification methods: concept-based and counterfactual explanations. The authors create a synthetic dataset to test whether users can identify the relevant set of attributes compared to the ground-truth. The results show that the baseline explanation method outperformed the concept based explanation method. The paper also provides an open-source dataset.
SP:6495caf14ebb8b9c3cbf50a5f05ec1eb600864fe,"This paper proposes a new method to defend against backdoor data poisoning attacks. The proposed method is based on self-expansion of the training data. The authors show that for a poisoned dataset satisfying mild compatibility properties, they show that an ensemble of weak learners fit to self expanding sets successfully removes the poisoned data. Empirical results show that the proposed method outperforms previous defenses. "
SP:f0ad7cbc190113bb4612b7beca98d07aeff661fd,"This paper proposes a method for multi-label text classification (MLTC) that uses latent label representations to model label correlations implicitly. Specifically, the proposed method concatenates a set of latent labels (instead of actual labels) to the text tokens, inputs them to BERT, then maps the contextual encodings of these latent labels to actual labels cooperatively. The method is conceptually simple but quite effective. It improves the state-of-the-art results on two widely used benchmark datasets by a large margin."
SP:6e54083a06942f2c41e1796a9f911d3dd9bab0cc,"This paper studies the approximation properties of convolutional kernels. The authors show that the RKHS consists of additive models of interaction terms between patches, and that its norm encourages spatial similarities between these terms through pooling layers. They also provide generalization bounds which illustrate how pooling and patches yield improved sample complexity guarantees when the target function presents such regularities. "
SP:7bee8d65c68765cbfe38767743fec27981879d34,"The Neural Tangent Kernel (NTK) is the outer product of the neural network Jacobians, defined as $\tilde{O}(x1, x2) = \text{@f(\theta, x1) - f(x2)$ where $\theta_1$ is the NTK. The NTK can be computed analytically and is useful for understanding training and generalization of NN architectures. Unfortunately, the finite width NTK is notoriously expensive to compute, which severely limits its practical utility. This paper provides the first in-depth analysis of the compute and memory requirements for NTK computation in finite width networks. The authors also propose two algorithms that change the exponent of the computed NTK to improve its efficiency."
SP:1df605fc5fc828304f7b836724d8fd6c233ff80c,"This paper studies the problem of offline constrained reinforcement learning, where the goal is to find a policy that maximizes the expected return while satisfying cost constraints. The authors propose an algorithm, called COptiDICE, which estimates the stationary distribution corrections of the optimal policy with respect to returns, while constraining the cost upper bound, with the goal of yielding a cost-conservative policy for actual constraint satisfaction. Experiments are conducted to demonstrate the effectiveness of the proposed method."
SP:5a10c13eb78d26a25dac74601419deb68c53cb75,This paper proposes a novel parallel training scheme for Gated recurrent units (GRUs) based on a multigrid reduction in time (MGRIT) solver. The key to achieving speedup is a hierarchical correction of the hidden state to accelerate end-to-end communication in both the forward and backward propagation phases of gradient descent. Experimental results on the HMDB51 dataset demonstrate that the new parallel training method achieves up to 6.5x speedup over a serial approach.
SP:fb935a5c44d7df6958d39ab1ef877956df08994e,"This paper proposes a neural network architecture that learns a common embedding from multiple subjects in an experiment while retaining the ability to decode to individual raw fMRI signals. The authors assume that while noise varies significantly between individuals, true responses to stimuli will share common, low-dimensional features between subjects which are jointly discoverable. They show that their learned common space represents an extensible manifold (where new points not seen during training can be mapped), improves the classification accuracy of stimulus features of unseen timepoints, and improves cross-subject translation of fMRI signal."
SP:95ed80753116005f1f7bae24c855d350f4af85a1,"This paper proposes a new benchmark for out-of-distribution detection and anomaly segmentation. The main contribution of this paper is the introduction of a new dataset of anomalous species, a new multi-label anomaly detection dataset, and a new segmentation dataset. The authors also propose a new detector based on the maximum logit, MaxLogit, for multi-class, multi-labels, and segmentation tasks. The experiments show that the proposed detector outperforms prior methods in all of these tasks."
SP:abbab40e40ef09c8dccd16661af3c2a4461ebb1a,"This paper studies the structure of tournaments that arise out of d dimensional representations. The authors show that the tournament classes have forbidden configurations which must necessarily be union of flip classes, a novel way to partition the set of all tournaments. They further characterize rank 2 tournaments completely by showing that the associated forbidden flip class contains just 2 tournaments. This insight allows them to solve the minimum feedback arc set problem on this tournament class."
SP:d39765dcc8950d4fc1d43e4c167208736578882e,"This paper proposes a novel neural process with stochastic attention mechanism to improve the prediction accuracy of Neural Processes (NPs). In particular, the authors propose a new regularization term that encourages the embedding of the target dataset to be different from that of the context dataset. The authors show that the proposed method can be explained from the perspective of information theory. Experiments are conducted on 1D regression, predator-prey model, and image completion tasks."
SP:f6e7229b653a5a56a2993864cdb70809f5b6f9b4,"This paper proposes Proto-Trex, a transformer-based LMs model that uses prototype networks to explain the reasoning process behind the network’s decisions. The main idea is to use prototype networks directly incorporated into the model architecture and hence explain the decision making process of the LM. In addition, the paper proposes an interactive prototype learning setup to incorporate human knowledge with the consideration of knowledge certainty. Experiments show that the proposed model performs on par with several language models. "
SP:60ba9cb4c42cecde6379ec0279434dece822a2b1,"This paper proposes Trust Region Gradient Projection (TRGP) for continual learning to facilitate the forward knowledge transfer based on an efficient characterization of task correlation. TRGP uses a notion of ‘trust region’ to select the most related old tasks for the new task in a layer-wise and single-shot manner, using the norm of gradient projection onto the subspace spanned by task inputs. Then, a scaled weight projection is proposed to cleverly reuse the frozen weights of the selected old tasks in the trust region. Extensive experiments show that TRGP achieves significant improvement over related state-of-the-art methods."
SP:25414fe1c6203f9b623c5317a4ffaba478085c4c,"This paper proposes a generalization bound based on the length of the optimization trajectory of the gradient flow algorithm after convergence. The authors show that, with a proper initialization, gradient flow converges following a short path with an explicit length estimate. They further show applications of Theorem 1 and Theorem 2 to obtain generalization bounds on underdetermined linear regression, kernel regression, and overparameterized two-layer ReLU neural networks. "
SP:a9e5d81f7ba88f4052730f255cf48cb40ed80942,"This paper analyzes adversarial robustness from the perspective of spatial frequencies. The authors show that adversarial examples are neither in high-frequency nor in low-frequency components, but are simply dataset dependent. The frequency-based explanation for the commonly observed accuracy-robustness trade-off is based on the frequency constraints. "
SP:5d94dbfd10dc2ef86415853cc41f414a24962d4f," of heterophily in graph neural networks (GNNs). This paper first shows that not all cases of homophily are harmful for GNNs with aggregation operation. Then, it proposes a new metrics based on a similarity matrix which considers the influence of both graph structure and input features on GNN. The metrics demonstrate advantages over the commonly used homophile metrics by tests on synthetic graphs. Finally, the authors propose the Adaptive Channel Mixing (ACM) framework to adaptively exploit aggregation, diversification and identity channels in each GNN layer. "
SP:fd4ab1cb777b541c22a923c1c86d82ac1d8384fd,"This paper proposes a deep reinforcement learning approach for solving the traveling salesman problem (TSP). The main idea is to use a graph neural network (GNN), a multi-layer perceptron (MLP), and an attention mechanism to solve the TSP. The proposed method is evaluated on random and realistic TSPs. "
SP:8aa471b92e2671d471107c087164378f45fb204f,"This paper proposes a new method for federated learning with synthetic data. Specifically, each client pretrains a local generative adversarial network (GAN) to generate synthetic data, which are uploaded to the parameter server (PS) to construct a global shared synthetic dataset. The PS is responsible for generating and updating high-quality labels for the global dataset via pseudo labeling with a confident threshold before each global aggregation. A combination of the local private dataset and labeled synthetic dataset leads to nearly identical data distributions among clients, which improves the consistency among local models and benefits the global aggregation process. Extensive experiments demonstrate the effectiveness of the proposed method."
SP:7656b0bd5eb7e46359d8111e5534a07744f5d7ae,"This paper proposes a simple training method to improve the certified robustness of smoothed classifiers. The main idea is to use the ""accuracy under Gaussian noise"" as an easy-to-compute proxy of adversarial robustness for each input. This proxy is used to differentiate the training objective depending on this proxy to filter out samples that are unlikely to benefit from the worst-case (adversarial) objective. The experiments show that the proposed method outperforms existing state-of-the-art training methods."
SP:8fdfed1c38ae00a0063ab41f72fa26826f5f4570,"This paper studies the problem of packing the Wikipedia pre-trained BERT pre-training dataset. The authors show that at sequence length 512 padding tokens represent in excess of 50% of the Wikipedia dataset used for pretraining BERT, removing all padding can achieve a 2x speed-up in terms of sequences/sec. To exploit this characteristic of the dataset, the authors develop and contrast two packing algorithms. Both algorithms rely on the assumption that sequences are interchangeable and therefore packing can be performed on the histogram of sequence lengths, rather than per sample. This transformation of the problem leads to algorithms which are fast and have linear complexity in dataset size. "
SP:460d4cc1a5c01e34abe37d9eb1b74dd3734b1d55,"This paper proposes an adaptive tree search algorithm that can find high-scoring outputs under translation models that make no assumptions about the form or structure of the search objective. This algorithm enables the exploration of new kinds of models that are unencumbered by constraints imposed to make decoding tractable, such as autoregressivity or conditional independence assumptions. When applied to autoregressive models, our algorithm has different biases than beam search has, which enables a new analysis of the role of decoding bias in autorgressive models. Empirically, this paper shows that our adaptive tree-search algorithm finds outputs with substantially better model scores compared to beam search. "
SP:ff7b9e6ff5303f8a4f0321d06d9d9573e4853c5f,"This paper proposes an energy based model (EBM) for anomaly detection and localization that allows fast adaptation to new tasks. Specifically, the EBM is an energy-based model with an adaptive sparse coding layer, of which the dictionary is directly formed by normal features of a target task. The authors adopted episodic meta-learning to extract common knowledge across tasks, which has the effect of enabling few-shot adaptation. They also introduced smooth shrinkage functions, sparse coding with large receptive fields, and learning by inpainting to improve and accelerate the training."
SP:801a61d01d3b159f301013b182150a80fbfe8fa2,"This paper studies the problem of misinformation in question answering (QA) systems. The authors create a large-scale dataset for this problem, CONTRAQA, which contains over 10K human-written and model-generated contradicting pairs of contexts. They show that QA models are vulnerable under contradicting contexts brought by misinformation. To defend against such threat, they build a misinformation-aware QA system as a counter-measure that integrates question answering and misinformation detection in a joint fashion."
SP:7effe51275b9b2e14b3e099533e410e09f5b7c5a,"This paper proposes Gromov-Wasserstein Imitation Learning (GWIL), a method for cross-domain imitation that uses optimal transport distances to align and compare states between the different spaces of the agents. The authors show that GWIL can learn optimal behaviors with a single demonstration from another domain without any proxy tasks in non-trivial continuous control settings. The paper also provides a theoretical analysis of the case where GWIL preserves optimality. "
SP:9ec000cd9c15e3c9988a41921c465b42e7d41877,"This paper proposes a new self-supervised learning method called Hierarchical Cross Contrastive Learning (HCCL) to further distill the information mismatched by the conventional contrastive loss. HCCL uses a hierarchical projection head to project the raw representations of the backbone into multiple latent spaces and then compares latent features across different levels and different views. Experiments are conducted on classification, detection, segmentation, and few-shot learning tasks."
SP:943b0a3f94ba270bb7c0dc1e1f363e53bc5cf8ae,"This paper studies the problem of finding Nash equilibria in a multi-agent meta-game with heterogeneous agents. The authors propose a framework for learning Nash equilibrium policies for a meta game over agent types. The framework is based on deep reinforcement learning (DRL). The authors show that DRL can find stable solutions that are Nash-equilibria for the meta game using a structured learning curricula and efficient GPU-only simulation and training. They demonstrate their approach in real-business-cycle models with 100 worker-consumers, 10 firms, and a government who taxes and redistributes. "
SP:f885c992df9c685f806a653398736432ba38bd80,"This paper proposes a method to prevent model stealing attacks by requiring users to complete a proof-of-work (PoW) before they can read the model’s predictions. The PoW is based on the fact that the original model predictions in a PoW are given in a proof of work (POW) form. The authors propose to calibrate the effort required to complete the PoW to each query, so that this only introduces a slight overhead for regular users (up to 2x). To achieve this, the authors use tools from differential privacy to measure the information revealed by a query. "
SP:39845a353e75e2f854c3dc649db3817d89ad9875,"This paper proposes a Multi-Resolution Continuous Normalizing Flow (MRCNF) method for generative models of images. The main contribution of this paper is to introduce a transformation between resolutions that allows for no change in the log likelihood. The authors show that this approach yields comparable likelihood values for various image datasets using orders of magnitude fewer parameters than the prior methods, in significantly less training time, using only one GPU."
SP:d09c2fad308249261a9742505e4ccaed2b3578b3,"Label noise is pervasive in real-world datasets, which encodes wrong correlation patterns and impairs the generalization of deep neural networks (DNNs). It is critical to find efficient ways to detect the corrupted patterns. In this paper, given good representations, the authors propose a universally applicable and training-free solution to detect noisy labels. Intuitively, good representations help define “neighbors” of each training instance, and closer instances are more likely to share the same clean label. Based on the neighborhood information, the first one uses “local voting” via checking the noisy label consensuses of nearby representations. The second one is a ranking-based approach that scores each instance and filters out a guaranteed number of instances that are likely to be corrupted, again using only representations. "
SP:ae81e2a23bf6042bf8b04ba41b957bb625268b7e,"This paper studies the problem of adversarial training of reinforcement learning agents in the presence of strong adversaries. In particular, the authors propose a novel adversarial learning algorithm, called Policy Adversarial Actor Director (PA-AD), where an actor and a ""director"" are jointly trained to find the optimal policy perturbation directions. The actor is trained to craft state perturbations for a given policy direction, and the director learns to propose the best policy perturbing directions. Experiments are conducted on several MuJoCo and Atari games."
SP:f7b7dfafb03090a2c940ba738234a6c80bd5ad0e,"This paper proposes a novel policy seeking algorithm, Interior Policy Differentiation (IPD), which is based on the interior point method commonly used in the constrained optimization literature. Specifically, the authors propose a new metric to evaluate the difference between policies. The proposed method is evaluated on several continuous control benchmarks. "
SP:82b7860146bf3f772bdcd5b448d62136ff6d5177,"This paper proposes a method to remove reverberation from the audio signal from a speaker's speech. The method is based on a multi-modal modeling approach and a novel reverb-visual matching loss. A large-scale dataset is developed to demonstrate the effectiveness of the proposed method. Experiments are conducted on speech enhancement, speech recognition, and speaker identification tasks."
SP:7abf578ef0d3b67d87437bdd1cff129f72c102c6,"This paper proposes Attention with Linear Biases (ALiBi) which is an extension of the position embedding method of Vaswani et al. (2017) to transformers. ALiBi does not add positional embedding to word embeddings; instead, it biases query-key attention scores with a penalty that is proportional to their distance. The authors show that this method trains a 1.3 billion parameter model on input sequences of length 1024 that extrapolates to input sequences with length 2048, achieving the same perplexity as a sinusoidal embedding model trained on inputs of length 2048."
SP:45ba2709aca444f50a133d71f33be9d2c1f887e8,"This paper studies the multi-objective online convex optimization problem in the unconstrained max-min form. In particular, the authors propose a new algorithm, Multi-Objective Online Convex Optimization (MMOMMD-II), which computes the composite gradient using either the vanilla min-norm solver or a newly designed L1-regularized min-Norm solver. The authors also derive regret bounds of both variants and verify the effectiveness of the proposed algorithm. "
SP:d07fd26d0cb245e1fd1343472dd3c8300c39752a,"This paper studies the problem of continual learning with generative replay. The authors propose to use the generated data as negative examples (or antagonists) to learn the new classes, especially when the learning experiences are small and contain examples of just one or few classes. The proposed approach is validated on complex class-incremental and data-increasingmental continual learning scenarios (CORe50 and ImageNet-1000) composed of high-dimensional data and a large number of training experiences. "
SP:ec18e1450dd918b1ca95e301bc9262e072d77b52,"This paper proposes an inductive graph partitioning (IGP) framework to alleviate the NP-hardness of graph partition (GP) problem. The proposed framework first conducts the offline training of a dual graph neural network on historical graph snapshots to capture properties of the system. The trained model is then generalized to newly generated graphs for fast high-quality online GP without additional optimization, where a better trade-off between quality and efficiency is achieved. IGP is also a generic framework that can capture the permutation invariant GP ground-truth of historical snapshots. Experiments on a set of benchmarks demonstrate the effectiveness of the proposed method."
SP:ad28c185efd966eea1f44a6ff474900812b4705a,"This paper proposes a hierarchical generative model for graph generation. The proposed method is based on the Multi-Resolution Equivariant Graph Variational Autoencoder (MGN) framework, which is end-to-end permutation equivariant with respect to node ordering. The key idea of MGVAE is learning to construct a series of coarsened graphs along with a hierarchy of latent distributions in the encoding process while learning to decode each latent into the corresponding graph at every resolution level. The experiments show that having a flexible clustering procedure from MGN enables MGVAEs to detect, reconstruct and finally generate important graph substructures."
SP:29e2e1daa6a32ef71ad225bd2fc27e33dece86c5,"This paper proposes a general framework for nonlinear ICA, in which the mixing function is assumed to be a volume-preserving transformation, and the conditions on the sources can be much looser. The authors provide an insightful proof of the identifiability of the proposed framework. The experiments on both synthetic and real-world data verify the theory. "
SP:288ce587a277299765bdd4cea75a8c23e12de2b0,"This paper proposes a new graph convolutional network architecture, called BankGCN, which decomposes multi-channel signals on arbitrary graphs into subspaces and shares adaptive filters to represent information in each subspace. The filters of all subspace differ in frequency response and together form a filter bank. The filter bank and the signal decomposition permit to adaptively capture diverse spectral characteristics of graph data for target applications with a compact architecture. Experiments are conducted on node classification and graph classification tasks."
SP:3abcd0700eaf11d964c280d996a1dd4f34280b1c,"This paper proposes a new supervised pre-training method based on leave-one-out k-nearest-neighbor (LOOK) classifier for better downstream transferring. Compared with self-supervised pretraining, LOOK efficiently leverages the label information, and at the same time alleviate the problem of upstream over-fitting in existing supervised pretraining methods, which ignores intraclass difference semantic features that are valuable for transferring. Extensive empirical studies demonstrated that LOOK has better transferrability for downstream tasks than the existing methods for supervised and self-training."
SP:2b3916ba24094c286117126e11032820f8c7c50a,This paper proposes a method to generate realistic facial details from a single image that are consistent with any desired target expression. The proposed method is based on a neural rendering network that is trained using augmented wrinkle loss and Detailed Shading loss. The rendering network is trained in a way that ensures that the rendered facial details are consistent across different views and expressions. The method is evaluated using a large scale in-the-wild image dataset and a much smaller video dataset. 
SP:c7c50c44fdafb15b962e04d713cac309e57bc54b,This paper proposes an attention-driven variational autoencoder (ADVAE) model for unsupervised disentanglement of syntactic roles. The model is based on a deep probabilistic generative generative model with attention. The authors propose an evaluation protocol based on attention maxima for the encoder and on latent variable perturbations for the decoder. Experiments on the SNLI dataset show that the proposed model is able to disentangle syntactic role better than sequence VAEs and Transformer VAEs. 
SP:57ace99a05a76b7d7427619cb6881fc87d74160f,"This paper proposes a novel multi-agent reinforcement learning algorithm that aims to improve the exploration and coordination in a team of agents. Specifically, agents are rewarded for contributing to a more diversified team behavior by employing proper intrinsic motivation functions. The authors introduce a novel framework, where at each timestep, an agent simulates counterfactual rollouts of its policy and, through a sequence of computations, assesses the gap between other agents’ current behaviors and their targets. Actions that minimize the gap are considered highly influential and are rewarded. The proposed method is evaluated on a set of challenging tasks with sparse rewards."
SP:66784b2f0f08680057670dfea49a4ae88f7a2b38,"This paper proposes a method for post-hoc editing of large pre-trained language models. The main idea is to use a low-rank decomposition of the gradient to make the parameterization tractable. The proposed method can be trained on a single GPU in less than a day even for 10 billion+ parameter models. Once trained, the proposed method enables rapid application of new edits to the pre-training model."
SP:ea9a6880083555a89f5ed22dca21ba2dc109c1a2,"This paper proposes a physics-aware neural network for learning spatiotemporal advection-diffusion processes. The proposed method is based on combining the learning abilities of artificial neural networks with physical and structural knowledge from numerical simulation by modeling the constituents of partial differential equations (PDEs) in a compositional manner. Results on Burger's, diffusion-sorption, and diffusion-reaction PDEs demonstrate the effectiveness of the proposed method."
SP:d369e2144544908fbcaaa53aab9555d71080ced8,"This paper presents a neuroimaging study of human brain representations of code. The authors analyze recordings from functional magnetic resonance imaging (fMRI) studies of people comprehending Python code. They discover brain representations, in different and specific regions of the brain, that encode static and dynamic properties of code such as abstract syntax tree (AST)-related information and runtime information. They also map brain representations to representations of a suite of ML models that vary in their complexity. "
SP:ab5a8934846776a7be7d0ac1973d41fd6aae89fc,"This paper presents Translatotron 2, a neural direct speech-to-speech translation model, which consists of a speech encoder, phoneme decoder, mel-spectrogram synthesizer, and an attention module that connects all the previous three components. The authors also propose a new method for retaining the source speaker’s voice in the translated speech. Experiments are conducted on three different datasets, including multilingual S2ST."
SP:296102e60b842923c94f579f524fa1147328ee4b,"This paper studies the problem of attribute-based few-shot learning of semantic concepts. The authors propose a method called Few-Shot Attribute Learning (FSAL) to learn the attributes that are not present in the training set. To do so, the authors introduce three new datasets, Celeb-A, Zappos-50K, and ImageNet-with-attribute labels, which are used to create learning episodes. They find that supervised learning with training attributes does not generalize well to new test attributes, whereas self-supervised pre-training brings significant improvement. They also experiment with random splits of the attribute space and find that predictability of test attributes provides an informative estimate of a model's generalization ability. "
SP:0f69e20b9f97439d19e7a93144c8d877cedcd714,"This paper proposes a gradient-based method for sampling from unnormalized distributions. The method is based on the Wasserstein gradient flow of relative entropy, which is characterized by an ODE system with velocity fields depending on the density ratios of the density of evolving particles and the target density. To sample with REGS, the authors propose a nonparametric approach to estimate the density ratio using neural networks. Extensive simulation studies on challenging multimodal 1D and 2D mixture distributions and Bayesian logistic regression on real datasets demonstrate that the REGS outperforms the state-of-the-art sampling methods."
SP:a69b894166482ccd7a3a9db53e0f5a7e6ecff89a,"This paper proposes a quantum neural network (QNN) framework to classify larger, realistic images using quantum systems. The approach relies on a novel encoding mechanism that embeds images in quantum states while necessitating fewer qubits than prior work. The framework is able to classify images that are larger than previously possible, up to 16x16 for the MNIST dataset on a personal laptop, and obtains accuracy comparable to classical neural networks with the same number of learnable parameters. "
SP:acf3825e96d1b7c66cdc339fc5de77330b8e8e90,This paper proposes a federated learning method for face recognition. The proposed method is based on differentially private local clustering (DPLC) to distill sanitized clusters from local class centers and a consensus-aware recognition loss to encourage global consensuses among clients. The privacy guarantee of the proposed framework is proved. Experiments are conducted on IJB-B and IJBC datasets to demonstrate the effectiveness of the method.
SP:408d9e1299ee05b89855df9742b608626692b40d,"This paper proposes a new method for transfer learning, called Head-to-Toe Probing (HEAD2TOE), that selects features from all layers of the source model to train a classification head for the target-domain. The proposed method is based on linear probing. The authors show that the proposed method outperforms fine-tuning on the Visual Task Adaptation Benchmark. "
SP:d6f11fb32851f97af287f962f83220d27a8bc76a,"This paper proposes an object-oriented text dynamics (OOTD) model that enables planning algorithms to solve decision-making problems in text domains. OOTD predicts a memory graph that dynamically remembers the history of object observations and filters object-irrelevant information. To improve the robustness of dynamics, the authors identify the objects influenced by input actions and predicts beliefs of object states with independent parameterized transition layers. The authors develop variational objectives under the object-supervised and self-supervision settings to model the stochasticity of predicted dynamics. Empirical results show that the proposed model significantly outperforms model-free baselines in terms of sample efficiency and running scores."
SP:3e5ac4add9ab8a986fdf027b6e6a7d59698b3031,"This paper studies the problem of cost-sensitive hierarchical classification, where a label taxonomy has a cost sensitive loss associated with it, which represents the cost of (wrong) predictions at different levels of the hierarchy. This paper proposes a method that breaks the hierarchical learning problem into layer-by-layer learning-to-abstain sub-problems. The authors prove that there is a bijective mapping between the original hierarchical costsensitive loss and the set of layer-wise abstaining losses under symmetry assumptions. They employ the distributionally robust learning framework to solve the learning to abstain problems in each layer. They conduct experiments on large-scale bird dataset as well as on cell classification problems."
SP:7997a1b59ef2fc0127c3fff02d191f5d655168f8,This paper proposes a method to learn a group of synperiodic filter banks to achieve a better time-frequency resolution trade-off. The proposed method is based on a Transformer-like backbone network with two parallel soft-stitched branches to learn semantic identity label and spatial location representation semi-independently. Experiments on both direction of arrival estimation task and the physical location estimation task show that the proposed method outperforms existing methods.
SP:8bc53935566be2b70403f4b46fe94686d5eae1a1,"This paper studies the problem of unsupervised domain adaptation, where the goal is to shift the model towards the target distribution rather than learning domain invariant representations. The authors hypothesize that having access to samples from intermediate distributions, and samples being annotated with the amount of change from the source distribution, self-training can be successfully applied on gradually shifted samples to adapt the model. In the case where (i) does not hold, they observe that iterative self training falls short. They propose a method called GIFT (Gradual Interpolation of Features toward Target), a method that creates virtual samples from the intermediate distributions by interpolating representations of examples from source and target domains. Their analysis of various synthetic distribution shifts shows that in the presence of iterative selftraining naturally forms a curriculum of samples which helps the model to adapt better to the target domain."
SP:862d6d76692aee384adc70fd845f0b89cfda93d3,"This paper presents a method for multi-modal video-text embedding learning. The authors propose a method that learns representations from videos, titles and comments, which are abundant on the internet. Specifically, the authors propose an attention-based mechanism that allows the model to disregard text with irrelevant content. They demonstrate that, by using comments, their method is able to learn better, more contextualised representations, while also achieving competitive results on standard video and text retrieval benchmarks."
SP:a35eb46f391e1a1e347e7243245ca69f4c0f129f,"This paper studies the problem of unsupervised skill learning. The authors propose an exploration bonus that penalizes the discriminator for not having seen enough training data to produce accurate and confident skill classifications, leading to a low intrinsic reward for the agent and effective penalization of the sort of exploration needed to actually maximize the objective. To solve this problem, the authors derive an information gain auxiliary objective that involves training an ensemble of discriminators and rewarding the policy for their disagreement. They demonstrate empirically that DISDAIN improves skill learning both in a tabular grid world (Four Rooms) and the 57 games of the Atari Suite."
SP:4eafae76b923b75534cd28e6e04774ea69e3c2d1,"This paper proposes a molecular graph generation framework based on the construction of a spanning tree and the residual edges. The authors also propose a transformer architecture with tree-based relative positional encodings for realizing the tree construction procedure. Experiments on QM9, ZINC250k, and MOSES benchmarks verify the effectiveness of the proposed framework. "
SP:3a19340d6af65e3f949dda839a6d233369891c46,"This paper analyzes the neural tangent kernel (NTK) of polynomial neural networks (PNNs). The NTK of PNNs is known to have a spectral bias towards low-frequency functions. This paper shows that a recently proposed parametrization of the PNN family, the $\rho$-Net family, speeds up the learning of the higher frequencies. The authors verify the theoretical bias through extensive experiments. "
SP:ebed8b8a25cead3629832c2ba52caf0059971d3d,"This paper proposes a Peek-a-boo (PaB) algorithm for training sparse neural networks. The authors define a new class of subnetworks in randomly initialized NNs called ""disguised subnetwork"", which are not only ""hidden"" in the random networks but also can only be ""unmasked"" with certain transformations on weights. They argue that the unmasking process helps to relax the quality requirement on the sparse subnetwork mask so that the expensive edge-popup algorithm can be replaced with more efficient alternatives. Experiments are conducted on ResNet18, ResNet-50, and WideResNet-28."
SP:fa9e46f1dc70dbe87ff53a6b8dd5419c14b40ef3,This paper proposes a general unified framework to enhance the robustness of GNNs against adversarial attacks by jointly cleaning the perturbed graph and denoising the features of data. The authors propose a General Unified Graph Neural Network (GUGNN) framework to jointly clean the graph and features of the data. They further extend it by introducing two operations and develop a robust GNN model(R-RUGUGNN). Experiments on four real-world datasets demonstrate that R-RugUGNN improves the overall robustness.
SP:fcb14510ef8541f320ef1c3cab4c0c017e2e15b9,"This paper proposes a method to learn the texture mapping for a 3D surface and apply it to document image unwarping. The method learns a continuous bijective mapping between 3D position and 2D texture-space coordinates, which can be plugged into a differentiable rendering pipeline and trained using multi-view images and rendering loss. Experiments show that the proposed method can reconstruct high-frequency textures for arbitrary document shapes in both synthetic and real scenarios. "
SP:28ac9848fb69d1c59fd751fbeee9a4ac799db897,"This paper proposes Adaptive Region Pooling (ARP), a novel downsampling operation that makes the network only focus on a smaller but more critical region, and simultaneously increase the resolution of sub-sampled feature. ARP owns a trade-off mechanism that allows users to actively balance the scale of receptive field and the granularity of feature. Also, without any learning-based parameters, ARP provides the network a stabler training process and an earlier convergence."
SP:8648453f5a7c5e9b99a8fdbaa340f4e2b4d048d0,"This paper studies the problem of out-of-distribution (OOD) generalization for graph-structured data. The authors formulate the OOD problem for node-level prediction on graphs and develop a new domain-invariant learning approach, named Explore-to-Extrapolate Risk Minimization, that facilitates GNNs to leverage invariant graph features for prediction. The key difference to existing invariant models is that they design multiple context explorers (specified as graph editers) that are adversarially trained to maximize the variance of risks from multiple virtual environments. Such a design enables the model to extrapolate from a single observed environment which is the common case for node level prediction. "
SP:870cd8794f7ff48fbed71c2abc9fb7dad51bd343,"This paper proposes a meta-learning approach to select data augmentations for contrastive learning of time series data. The proposed approach is based on an information-aware approach, InfoTS, that adaptively selects optimal time series augmentations. Experiments are conducted on time series forecasting and classification tasks. "
SP:6bc677d060ba4ab09f6da61458680e7a7976644b,"This paper studies the universality of winning tickets in the lottery ticket hypothesis (LTH). The authors show that iterative magnitude pruning, the method used for discovering winning tickets, is a renormalization group scheme. This opens the door to a wealth of existing numerical and theoretical tools, some of which they leverage here to examine winning ticket universality in large scale lottery ticket experiments, as well as sheds new light on the success iterative magnitudes pruning has found generally in machine learning. "
SP:59ce2e6c3674157d6fa990316812d0823c1ec586,"This paper studies the performance gap between cross-attention (CA) and dual-encoder (DE) models in the context of neural re-ranking. The authors show theoretically that with a sufficiently large encoder size, DE models can capture a broad class of scores without cross attention. They show empirically that on real-world problems, the gap between CA and DE models may be due to the latter overfitting to the training set. To mitigate this behaviour, the authors propose a distillation strategy that focuses on preserving the ordering amongst documents, and confirm its efficacy on benchmark neural reranking datasets."
SP:679e57a2027ff1855e5dc80bd3ec91f6489cc747,"This paper studies the role of importance sampling (IS) in the context of policy evaluation and policy optimization. In particular, the authors show that IS can be used as a performance improvement tool, with the advantage of implicitly enforcing a trust region. Based on this insight, they propose Policy Optimization via Optimal Policy Evaluation (PO2PE), a novel policy evaluation algorithm, which uses variance minimization as an inner loop. Experiments are conducted on a variety of continuous control tasks."
SP:b169c94c8fcc4f13cafdbafbe18eb26cb471ea0b," of Graph Neural Networks (GNNs) for modeling atomic simulations has the potential to revolutionize catalyst discovery, which is a key step in making progress towards the energy breakthroughs needed to combat climate change. However, the GNNs that have proven most effective for this task are memory intensive as they model higher-order interactions in the graphs such as those between triplets or quadruplets of atoms, making it challenging to scale these models. In this paper, the authors introduce Graph Parallelism, a method to distribute input graphs across multiple GPUs, enabling them to train very large GNN with hundreds of millions or billions of parameters. They empirically evaluate their method by scaling up the number of parameters of the recently proposed DimeNet++ and GemNet models by over an order of magnitude. On the large-scale Open Catalyst 2020 (OC20) dataset, these graph-parallelized models lead to relative improvements of 1) 15% on the force MAE metric on the S2EF task and 2) 21% on AFbT metric for predicting relaxed structures (IS2RS task)."
SP:352c177d89b9460acee0c78364e6d9c153c6a93c,"This paper proposes Time Control (TC), a language model that learns a representation that maps the dynamics of how text changes in a document to dynamics of a stochastic process of interest. The model learns to map coherent text to smooth Brownian bridge trajectories. The authors show that Time Control improves performance on text infilling and discourse coherence. "
SP:56a74403d4471cd95641dc669f5eac89a2c93144,"This paper proposes a method for learning object-centric representation from single 2D images by learning to predict future scenes in the presence of moving objects. The proposed method treats objects as latent causes whose function to an agent is to facilitate efficient prediction of the coherent motion of their parts in visual input. The model learns to explicitly infer objects’ locations in 3D environment in addition to segmenting objects. In addition, the network learns a latent code space where objects with the same geometric shape and texture/color frequently group together."
SP:244f5d31ec93b7a4bfc4b257ee6cdd5cfdb18a38,This paper proposes a VAE-based method for learning a disentangled representation from real spatio-temporal data for mobility forecasting. The proposed method is based on disentangling the spatial and temporal components of the data. The authors show that their method is able to achieve state-of-the-art performance on multiple datasets. They also show that removing the non-informative features from the learned representation can improve the performance of the model.
SP:cf781d756cf0bed5f7cdeb94be49e6d4409eeda4,This paper proposes a new deep learning framework for probabilistic interpolation of irregularly sampled time series. The proposed method is based on a temporal VAE architecture with a heteroscedastic output layer to propagate uncertainty due to input sparsity. The authors evaluate the proposed model on both synthetic and real data sets. The results show that the proposed method outperforms a variety of baseline models and recent approaches.
SP:80b8488b5a7c29014b0fefbc16698afac42250a0,"This paper studies the modularity of deep neural networks. The authors propose two measures of modularity, i.e., importance and coherence, to measure the importance of different parts of a neural network. The importance measure is based on the fact that a subset of neurons in a network is crucial to its performance, while the coherence measure measures how well the neurons associate with features of the input. The two measures are used to partition a graph representation of the network’s neurons with edges determined either by network weights or correlations of activations. "
SP:0d7cbb544bc39203c9c18b4fee56fc94cbe78375,"This paper investigates the lottery ticket hypothesis to find lightweight speech recognition models that are robust to various noise existing in speech; transferable to fit the open-world personalization; and compatible with structured sparsity. The authors conducted extensive experiments on CTC, RNN-Transducer, and Transformer models, and verified the existence of highly sparse “winning tickets” that can match the full model performance across those backbones. They obtained winning tickets that have less than 20% of full model weights on all backbones, while the most lightweight one only keeps 4.4% weights. Those winning tickets generalize to structured structured sparse with no performance loss, and transfer exceptionally from large source datasets to various target datasets."
SP:cb9530f5517f1092513c200b3f32e55420fdd768,"This paper proposes to replace the widely used random weight initialization with a fully deterministic initialization scheme ZerO, which initializes residual networks with only zeros and ones. By augmenting the standard ResNet architectures with a few extra skip connections and Hadamard transforms, ZerO allows us to start the training from zero and ones entirely. This has many benefits such as improving reproducibility (by reducing the variance over different experimental runs) and allowing network training without batch normalization. Extensive experiments demonstrate that ZerO achieves state-of-the-art performance over various image classification datasets, including ImageNet, suggesting that random weights may be unnecessary for modern network initialization."
SP:16618b226e42a07095dcf9204ce4c0e3b2ed8bd8,"This paper proposes a minimax formulation for removing backdoors from a given poisoned model based on a small set of clean data. This formulation encompasses much of prior work on backdoor removal. The authors propose the Implicit Backdoor Adversarial Unlearning (I-BAU) algorithm to solve the minimax. They theoretically analyze its convergence and the generalizability of the robustness gained by solving minimax on clean data to unseen test data. In their evaluation, the authors compare I-BaU with six state-of-art backdoor defenses on eleven backdoor attacks over two datasets and various attack settings."
SP:7260bd50f600a481ec7710792b63f518218e0eaf,"This paper studies the question of whether random permutation-based SGD is optimal for strongly convex functions with smooth second derivatives. The authors show that the convergence of SGD with random permutations is exponentially faster than with-replacement sampling for strongly-convex functions, but not for general functions. They also show that for quadratic functions, there are easy-to-construct permutations that lead to accelerated convergence compared to random. "
SP:39062dbbe9a30a7b47fa51179c15db34a3380a0b,"This paper proposes an automated normalizing flow (NF) architecture search method to find the optimal sequence of transformation layers from a given set of unique transformations with three folds. First, a mixed distribution is formulated to enable efficient architecture optimization originally on the discrete space without violating the invertibility of the resulting NF architecture. Second, the mixture NF is optimized with an approximate upper bound which has a more preferable global minimum. Third, a block-wise alternating optimization algorithm is proposed to ensure efficient optimization of deep flow models."
SP:d2656ae0259accc5207234fc4206f6f7be9598d9,"This paper proposes a self-supervised representation learning method based on intrinsic dimension and cluster learnability. Intrinsic dimension is defined as the TwoNN intrinsic dimension (ID) of the dataset in representation space. Cluster learnability (CL) is defined in terms of the learning speed of a KNN classifier trained to predict K-means cluster labels for held-out representations. The paper collects 30 state-of-art checkpoints and shows that ID and CL can be combined to predict downstream classification performance better than the existing techniques based on contrastive losses or pretext tasks, while having no requirements on data augmentation, model architecture or human labels. "
SP:4f5c00469e4425751db5efbc355085a5e8709def,"This paper proposes to use segmentation priors for black-box adversarial attacks to improve the imperceptibility of adversarial examples. Specifically, the authors use a salient object segmentation model to produce such saliency maps with no need for any information other than the input image. Experiments show that the proposed method can achieve better performance with little reduction in query efficiency."
SP:779821ed85084f8bf1b29d8822b312989b186ee9,This paper proposes a novel transformer-based molecular graph encoder-decoder architecture for the task of molecule-to-molecule retrosynthesis and reaction outcome prediction. The proposed Graph2SMILES model combines the power of Transformer models for text generation with the permutation invariance of molecular graph embeddings that mitigates the need for input-side SMILES data augmentation. The authors show that the proposed architecture improves the top-1 accuracy of the Transformer baselines by 1.7% and 1.9% for the USPTO_480k and USPto_STEREO datasets respectively.
SP:ce3cde67564679a8d9a0539f1e12551390b91475,"This paper studies the problem of automatic disease diagnosis with reinforcement learning (RL) methods in task-oriented dialogues setting. Inspired by offline consultation process, this paper proposes to integrate a hierarchical policy of two levels into the dialogue policy learning. The high level policy consists of a master model that is responsible for triggering a low level model, while the low level policy consist of several symptom checkers and a disease classifier. Experimental results on both self-constructed real-world and synthetic datasets demonstrate that the proposed method achieves higher accuracy and symptom recall in disease diagnosis."
SP:bd9cb543b5f199ab45e1bf8609c683f12ceb7659,"This paper proposes a federated learning framework called Self-supervised Federated Learning (SSFL) to address two challenges: data heterogeneity and label deficiency at the edge. The authors analyze the compatibility of various centralized self-supervision methods in FL setting and demonstrate that SimSiam networks perform the best with the standard FedAvg algorithm. To address the data heterogeneity, the authors propose a series of algorithms including perFedAvg, Ditto, and local fine-tuning, and propose a novel personalized federated self supervised learning algorithm, Per-SSFL, which balances personalization and consensus by carefully regulating the distance between the local and global representations of data. Experiments are conducted on a synthetic non-I.I.D. dataset based on CIFAR-10 and GLD-23K. "
SP:8ff52b027a3c2a464b2c2fedb768c092b0fc6ca5,"This paper derives a general form of PDEs for the design of ResNet-like neural networks. The authors first formulate DNN as an adjustment operator applied on the base classifier. Then based on several reasonable assumptions, the authors show that the adjustment operator for Resnet-like DNN is the solution operator of a PDE. They show that several effective networks can be interpreted by their general form and design a training method motivated by PDE theory to train DNN models for better robustness and less chance of overfitting. Theoretically, they prove that the robustness of DNN trained with our method is certifiable and our training method reduces the generalization gap for DNN."
SP:d44f0ebc2847695ecb4ed0bb3df61d6cd8cc6a40,"This paper studies the expressivity of emergent languages in referential games. The authors propose a hypothesis about the factors that influence the expressiveness of languages, and show empirically that it is a trade-off between the complexity and the unpredictability of the context that the language is used in. They also show that using the contrastive loss proposed by Chen et al. (2020a) can alleviate this problem. "
SP:892558b9f4fb53ed5ca2a7ee440b7d728b1886d6,"This paper proposes a new exploration strategy for sequential reinforcement learning. The exploration strategy is based on the Sample Average Uncertainty (SAU), a recently proposed uncertainty measure for exploration in bandit problems. The authors extend SAU from the bandit setting to the sequential RL setting and propose two exploration strategies, i.e., $\delta$-exploration and \delta_2 exploration, which can be used as drop-in replacements for -greedy action selection in Q-learning and DQN, resulting in effective and computationally efficient learning and superior empirical performance over the common-greedy baseline."
SP:2f6e266b03939c96434834579999707d3268c5d6,"This paper proposes an implicit neural representation-based generative adversarial network (GAN) for video generation. The key idea is to use the implicit neural representations (INR) of video to model the dynamics of the generated video. Specifically, the generator is an INR-based video generator and the discriminator is a GAN-based motion discriminator. Experiments show that the proposed method outperforms the baselines in terms of video synthesis, video extrapolation, and video generation quality."
SP:878325384328c885ced7af0ebf31bbf79287c169,"This paper studies the problem of multi-label multi-winner voting, which is the task of revealing k-hot binary vectors that satisfy a bounded differential privacy guarantee. This task has been understudied in the machine learning literature despite its prevalence in many domains such as healthcare. The authors propose three new privacy-preserving mechanisms: Binary, \tau, and Powerset voting. They empirically compare their techniques with DPSGD on large real-world healthcare data and standard multilabel benchmarks. "
SP:2488d3697a4ea732526b3ef11fbbd93e27d42e81,"This paper proposes a method to transfer the implicit step size schedule from a tuned optimizer to a new optimizer, while preserving empirical performance. The method is based on the idea of learning rate grafting, which combines the update rules of two different optimizers, forming a single grafted update rule. The authors show that a well-performing optimizer M can transfer its performance to D via grafting its sequence of implicit step-size schedules. This provides a robust plug-and-play baseline for optimizer comparisons, leading to reductions to the computational cost of optimizer hyperparameter search. "
SP:83b82c145f446c1a29e863362c6ceed018e93e2b,"This paper studies the problem of online reinforcement learning in sparse reward settings with suboptimal behavior policies. The authors propose an algorithm called Learning Online with Guidance Offline (LOGO) that combines a policy improvement step with an additional policy guidance step by using offline demonstration data. The key idea is that by obtaining guidance from not imitating the offline data, LOGO orients its policy in the manner of the sub-optimal policy, while being able to learn beyond and approach optimality. Theoretical analysis of the algorithm is provided, and a lower bound on the performance improvement in each learning episode is also provided. Empirical results demonstrate the effectiveness of the proposed algorithm."
SP:cf857736e3dc01325948488c791cbafc24b1c0fe,"This paper proposes a two-stage method to extract the Pareto optimal solution set for multi-objective constrained optimization problems. The first stage is based on a neural network to extract a weak front, while the second stage is a low-cost filter to obtain the strong front. The authors show that the proposed method is computationally efficient and scales well with increasing dimensionality of design variable space, objective functions, and constraints w.r.t.  OR methods. "
SP:0085e0bb1a265a3925540fbc4873aae60b8d01ce,"This paper studies the problem of knowledge distillation, i.e., learning a consolidated image feature representation from a collection of related task-specific teachers that transfer well on novel recognition tasks. This differs from traditional distillation in which a student model is trained to emulate the input/output functionality of a teacher. The authors show that a simple multi-head, multi-task distillation method using an unlabeled proxy dataset and adding a generalist teacher is sufficient to consolidate representations from task specific teacher(s) improves downstream performance, outperforming the teacher (or best of all teachers) and the strong baseline of ImageNet pre-trained features."
SP:ab0d024d4060235df45182dab584c36db16d8e31,"This paper proposes a generalization of conformal prediction to multiple learnable parameters by considering the constrained empirical risk minimization (ERM) problem of finding the most efficient prediction set subject to valid empirical coverage. Conformal prediction is a powerful technique for learning prediction sets with valid coverage, yet by default its conformalization step only learns a single parameter, and does not optimize the efficiency over more expressive function classes. In this paper, the authors propose a meta-algorithm generalizes existing conformal Prediction algorithms, and show that it achieves approximate valid population coverage and near-optimal efficiency within class. Experiments show that the algorithm is able to learn valid prediction sets and improve the efficiency significantly over existing approaches."
SP:f6b88e1fa1a84d82302d960c6a596fc2ba320bf5,"This paper proposes a reinforcement learning based approach to query object localization, for which an agent is trained to localize objects of interest specified by a small exemplary set. The proposed method enables test-time policy adaptation to new environments where the reward signals are not readily available, and outperforms fine-tuning approaches that are limited to annotated images. Experiments on a corrupted MNIST, the CU-Birds, and the COCO datasets demonstrate the effectiveness of the proposed method."
SP:0b23c5683b72dac05a7436cf3b49bd76263801d9,"This paper proposes QuadTree Attention to reduce the computational complexity of vision transformers from quadratic to linear. QuadTree attention builds token pyramids and computes attention in a coarse-to-fine manner. At each level, the top K patches with the highest attention scores are selected, such that at the next level, attention is only evaluated within the relevant regions corresponding to these top K patch. The experimental results demonstrate that quadtree attention achieves state-of-the-art performance in various vision tasks."
SP:63bcbaf0c5644aaba863cf60fa10db763f382ee8,"This paper proposes a method for learning termination conditions of options by maximizing the mutual information between options and termination states. The authors derive a scalable approximation of this MI maximization via gradient ascent, yielding the InfoMax Termination Critic (IMTC) algorithm. The experiments demonstrate that IMTC significantly improves the diversity of learned options without extrinsic rewards, combined with intrinsic rewards. "
SP:79da8f6cacc8386e02bab32154e7eaefbe2c683c,"This paper proposes a new method for open-world object detection. The proposed method is based on semantic topology, i.e. assigning all object instances from the same category to their corresponding pre-defined nodes in the semantic space, including the ‘unknown’ category. This constraint builds up discriminative feature representations and consistent relationships among objects, thus enabling the detector to distinguish unknown objects out of the known categories, as well as making learned features of known objects undistorted when learning new categories incrementally. Extensive experiments are conducted to demonstrate the effectiveness of the proposed method."
SP:97f618558f4add834e5930fd177f012a753247dc,"This paper studies the problem of choosing a subset of samples to train a deep neural network for classification. The authors propose to use matroids, an algebraic structure that generalizes linear independence in vector spaces, to formulate constraints on predicted class labels and decision boundaries. They also propose an efficient greedy algorithm with constant approximation guarantees. They outperform competing baselines on standard classification datasets and long-tailed datasets."
SP:e0432ff922708c6c6e59124d27c1386605930346,"This paper proposes an adaptive inference strategy for semantic segmentation that adjusts the model to the test sample before producing the final prediction. The authors use Instance-adaptive Batch Normalization (IaBN) to modify normalization layers by combining the feature statistics acquired at training time with those of the test samples. They also introduce a test-time training (TTT) approach Seg-TTT, which adapts the model parameters to a test sample using a self-supervised loss. The experimental results show that the proposed method outperforms the baseline and attain a new state-of-the-art."
SP:427100edad574722a6525ca917e84f817ff60d7e,This paper proposes a novel method for anomaly detection in tabular data. The proposed method is based on a contrastive loss that learns a mapping between samples of the same class and samples of a different class. The mapping is learned by minimizing the mutual information between each sample and the part of the sample that is masked out. The method is evaluated on a variety of tabular datasets. 
SP:7782a99e3c41ff523c0c56bfbe399c855a77acf2,This paper proposes a VAE-based method for neuropsychiatric functional connectivity (FC) classification. The method is based on learning a low-dimensional embedding space that preserves the diagnostic attributes of represented disorders. The authors propose a conditional variational auto-encoder (VAE-VAE) to learn the optimal embedding. The proposed method is evaluated on two datasets and compared with several baselines. 
SP:b3feb15b01e519e5b2e28b1c4a144056c493e2bc,"This paper proposes a new architecture for quantum neural networks based on a variational quantum circuit (VQC). The architecture consists of a tensor train network (TTN) for feature extraction and tensor product encoding (TPE) for quantum embedding. The authors provide theoretical analysis of the QTN for embedding in terms of the representation power of input features, and show that QTN enables an end-to-end parametric model pipeline from the generation of quantum embeddings to the output measurement. Experiments on the MNIST dataset demonstrate the advantages of the proposed architecture over other approaches."
SP:c4b03a1b477ac94438d63beb29ef86d77acf1b1e,"This paper proposes a method to construct low-dimensional manifolds where each point corresponds to a neural network model, and two points are nearby if the corresponding neural networks enact similar high-level computational processes. The proposed method, called DYNAMO, takes as input a collection of pre-trained neural networks and outputs a meta-model that emulates the dynamics of the hidden states as well as the outputs of any model in the collection. The specific model to be emulated is determined by a model embedding vector that the meta model takes as inputs. The authors apply the proposed method to both RNNs and CNNs, and find that the resulting model embeddings spaces enable novel applications: clustering of neural networks on the basis of their high level computational processes in a manner that is less sensitive to reparameterization; model averaging of several neural networks trained on the same task to arrive at a new, operable neural network with similar task performance; and semi-supervised learning via optimization on the model embeding space."
SP:29a42fdae15b9da955513f71e3100ebd0146a28a,"This paper proposes a method for constraint-based learned physical simulation. The method is based on a graph neural network as the constraint function and gradient descent as a constraint solver. The proposed method is tested on a variety of challenging physical domains, including simulated ropes, bouncing balls, colliding irregular shapes and splashing fluids. The results show that the proposed method achieves better or comparable performance to top learned simulators. "
SP:db07c2c0afdf27692dc504c9c54387c20211d469,"This paper proposes a new reinforcement learning algorithm, EDO-CS, which uses a clustering-based selection method to select policies from a population of policies. The clustering is based on the observation that policies are divided into several clusters based on their behaviors, and a high-quality policy is selected from each cluster for reproduction. Experiments are conducted on a variety of continuous control tasks and show that the proposed method outperforms the baselines."
SP:e51123a76713f1a1031d252e092985bd9b298fdf,"This paper studies a distributed linear stochastic approximation algorithm with Markovian noise and general consensus-type interaction. The interconnection structure among the agents is described by a time-varying directed graph. The paper derives finite-time bounds on the mean-square error, defined as the deviation of the output of the algorithm from the unique equilibrium point of the associated ordinary differential equation. The equilibrium point can be any unspecified convex combination of the local equilibria of all the agents in the absence of communication."
SP:f7f96d545a907887396393aba310974f4d3f75ff,"This paper proposes Graph Mechanics Network (GMN) which is equivariant and constraint-aware. The core of GMN is that it represents, by generalized coordinates, the forward kinematics information (positions and velocities) of a structural object. In this manner, the geometrical constraints are implicitly and naturally encoded in the forward Kinematics. Moreover, the authors have developed a general form of orthogonality-equivariant functions, given that the dynamics of constrained systems are more complicated than the unconstrained counterparts. Extensive experiments show that GMN outperforms the state-of-the-art GNNs in terms of prediction accuracy, constraint satisfaction and data efficiency."
SP:ee0b94238c3fde59cb8b67a687b77984fe7d3454,"This paper studies the problem of federated learning with partial model personalization. The authors propose two federated optimization algorithms for training partially personalized models, where the shared and personal parameters are updated either simultaneously or alternately on each device, but only the shared parameters are communicated and aggregated at the server. They provide convergence analysis of both algorithms for minimizing smooth nonconvex functions, providing theoretical support of them for training deep learning models. The experiments on real-world image and text datasets demonstrate that the proposed algorithms can obtain most of the benefit of full model personalisation with a small fraction of personalized parameters and the alternating update algorithm often outperforms the simultaneous update algorithm."
SP:eb54e84275266d8909fcbfe1589da1c4396c3164,"This paper proposes a novel contrastive learning framework for unsupervised learning of object representations, called CLTT, which simulates viewing sequences as they might be experienced by an infant while interacting with objects and avoids arbitrary augmentation operations. Instead, positive pairs are formed by successive views in such unsegmented viewing sequences, which allows us to control over the temporal structure of the input. The authors develop a new data set using a near-photorealistic training environment based on ThreeDWorld (TDW) and demonstrate that CLTT allows linear classification performance that approaches that of the fully supervised setting if subsequent views are sufficiently likely to stem from the same object."
SP:2fb4af247b5022710b681037faca2420207a507a,"This paper studies the problem of goal-directed planning under a deterministic transition model. The authors extend AlphaZero with Hindsight Experience Replay (HER) to tackle the problem. They provide a scheme that does not involve computationally heavy tree re-weighting procedures or high additional computational costs. They demonstrate the effectiveness of the proposed approach through an extensive empirical evaluation in several simulated domains, including a novel application to quantum compiling domain."
SP:e2d33c7331db7f52b84ad1018152564d91a9f126,This paper proposes Recursive Gradient Optimization (RGO) for continual learning. RGO consists of an iteratively updated optimizer that modifies the gradient to minimize forgetting without data replay and a virtual Feature Encoding Layer (FEL) that represents different network structures with only task descriptors. Theoretical derivation and experimental results show that RGO is the optimal approach under the current-task-first principle and quadratic loss estimation for fixed capacity networks.
SP:511226b467019dcd85e9ebf8b9b56f8f1b3ef889,"This paper studies the properties and applications of aligned generative models. The authors empirically analyze aligned models and provide answers to important questions regarding their nature. They find that the child model’s latent spaces are semantically aligned with those of the parent, inheriting incredibly rich semantics, even for distant data domains such as human faces and churches. Then, equipped with this better understanding, they leverage aligned models to solve a diverse set of tasks such as image-to-image translation, zero-shot vision tasks, and cross-domain image morphing."
SP:0e13f831c211626195c118487f2fff36a6e293f6,"This paper proposes a novel Gromov-Wasserstein (GW) divergence based on optimal transport (OT) between two graphs. The authors argue that the conservation of mass is detrimental for tasks such as graph dictionary or partition learning, and propose to relax it by proposing a new semi-relaxed GW divergence. They also propose an efficient solver for the corresponding optimization problem. Experiments are conducted to demonstrate the effectiveness of the proposed divergence."
SP:d6d144be11230070ae9395db70b7c7743540bad4,"This paper proposes a new method to model systematic suboptimality of human behavior. The method is based on Boltzmann policy distribution (BPD), which is a prior over human policies and adapts via Bayesian inference to capture systematic deviations by observing human actions during a single episode. The BPD is difficult to compute and represent because policies lie in a high-dimensional continuous space, but the authors leverage tools from generative and sequence models to enable efficient sampling and inference. The authors show that the BPD enables prediction of human behaviour and human-AI collaboration equally as well as imitation learning-based human models while using far less data."
SP:401ef5fe2022e926b0321258efac1f369f186ace,"This paper proposes a data-free quantization method for deep neural networks. The main idea is to decompose and approximate the Hessian-based optimization objective into three diagonal sub-items, which have different areas corresponding to three dimensions of weight tensor: element-wise, kernel-wise and output channel-wise. Then, a progressive algorithm is proposed to minimize the CASE directly and significantly improve accuracy than other DFQ methods. Finally, without fine-tuning and synthetic datasets, the proposed method accelerates the data free quantization process to a sub-second level."
SP:fa4bc3f6ad3f2a0113a930fb49d68660d63910e8,This paper proposes a novel neural network architecture for time series segmentation. The proposed method is based on a bi-pass architecture that combines LSTM and CNN-based 1D-encoder-decoder. The main contribution of this paper is the introduction of a step-wise segmentation module that can handle long-term dependencies between sub-sequences and is insensitive to label changing frequency. The experiments show that the proposed method outperforms baselines on two time-series datasets.
SP:8ad1b170f0392a132a3816c9cd28fb7332343e65,"This paper proposes a decomposition based explanation method (DEGREE) for GNNs. By decomposing the information generation and aggregation mechanism of GNN, DEGREE allows tracking the contributions of specific components of the input graph to the final prediction. Based on this, a subgraph level interpretation algorithm is proposed to reveal complex interactions between graph nodes that are overlooked by previous methods. Experiments are conducted on node classification and graph classification tasks to demonstrate the effectiveness of the proposed method."
SP:b28a9d1ad4c539d07d53e39376cbd76024d7745c,"This paper proposes a new downsampling layer, called DiffStride, that learns the size of a cropping mask in the Fourier domain to perform resizing in a differentiable way. The proposed method is based on a 2D version of an attention window with learnable size proposed by Sukhbaatar et al. (2019) for language modeling. Experiments on audio and image classification tasks show the effectiveness of the proposed method."
SP:54cdc6fe43ed138231f26daf699119f2a16473d0,"This paper proposes a novel smoothing method for softly local multi-output classifiers. The proposed method is based on randomized smoothing, i.e. randomly smoothing different outputs using different non-i.i.d. smoothing distributions matching the model’s locality. The authors also propose a variance smoothing algorithm for efficiently certifying smoothed models on discrete data. Experiments on image segmentation and node classification tasks demonstrate that localized smoothing can offer a better robustness-accuracy trade-off than existing random smoothing techniques."
SP:aacc31e83886c4c997412a1e51090202075eda86,"This paper proposes a new normalizing flow architecture, called Embedded-Model Flows (EMF), which is an extension of the normalizing flows (NF) framework. The main idea of EMF is to convert differentiable probabilistic models into equivalent bijective transformations. The authors also introduce gated structured layers, which allow bypassing the parts of the models that fail to capture the statistics of the data. Empirical results show that EMFs can induce desirable properties such as multimodality, hierarchical coupling and continuity. "
SP:825a254c0725008143b260ead840ae35f9f096d1,"This paper investigates the ability of large pre-trained language models (GPT-2 and GPT-3) to learn to map a conceptual domain (e.g., direction or colour) onto a grounded world representation given only a small number of examples. The authors show a model what the word “left” means using a textual depiction of a grid world, and assess how well it can generalize to related concepts, for example, “right”, in a similar grid world. They show that although smaller models struggle to perform this mapping, the largest model can not only learn to ground the concepts that it is explicitly taught, but appears to generalise to several instances of unseen concepts as well."
SP:702029739062693e3f96051cbb38f20c53f2a223,"This paper studies the problem of shaped rewards in emergent language. The authors show that shaped rewards can bias the semantics of the learned language, significantly change the entropy of the language, and mask the potential effects of other environmental variables of interest. The paper uses a simple sender-receiver navigation game to demonstrate how shaped rewards introduce biases in the learning process. "
SP:146ef14e569e10172a7dc602acd3fadf2c3bef8b,"This paper proposes an unsupervised cross-lingual learning method, called importance-weighted domain alignment (IWDA), that performs representation alignment, prior shift estimation, and correction. The main contribution of this paper is the observation that invariance of the feature representations strongly correlates with transfer performance, and distributional shift in class priors between data in the source and target languages negatively affects performance. Based on these observations, the authors propose a representation alignment method called IWDA, which is based on importance weighted domain alignment. Experiments are conducted to demonstrate the effectiveness of the proposed method."
SP:461ed47339e08dafea90a7c015d2f20e534daeb7,"This paper proposes Bootstrapped Meta-Gradient (BMG), a meta-learning algorithm that first bootstraps a target from the meta-learner, then optimizes the meta learner by minimising the distance to the bootstrapped target under a pseudo-metric. The authors show that BMG can guarantee performance improvements and show that the metric can control meta-optimization. They achieve a new state-of-the-art result for model-free agents on the Atari ALE benchmark and demonstrate that it yields both performance and efficiency gains in multi-task meta learning. Finally, they explore how bootstrapping opens up new possibilities and find that it can meta-learn efficient exploration in an $\epsilon$-greedy Q-learning agent."
SP:49435d70bf8e16d5dbf34577cf8d3a5b21b1f25a,"This paper studies the generalization ability of model-based reinforcement learning agents in the context of procedural generalization. Specifically, the authors focus on MuZero, a model-free agent, and evaluate its performance on both procedural and task generalization in Procgen and Meta-World. They identify three factors for procedural generalisation: planning, self-supervised representation learning, and procedural data diversity, and show that by combining these techniques, they achieve state-of-the-art generalization performance and data efficiency on Procgen. However, they find that these factors do not always provide the same benefits for task generalisation in Meta-world, indicating that transfer remains a challenge."
SP:ba80e35d452d894181d51624183b60541c0f3704,"This paper proposes a graph deconvolution network (GDN) to learn the graph structure from observed and latent graphs. The authors formulate the graph learning task as a network inverse (deconvolution) problem and propose an unrolled and truncated proximal gradient iterations to arrive at a parameterized neural network architecture that they call Graph Decomposed Neural Network (GDN). GDN can learn a distribution of graphs in a supervised fashion, and perform link prediction or edge-weight regression tasks by adapting the loss function. Since layers directly operate on, combine, and refine graph objects (instead of node features), GDN is inherently inductive and can generalize to larger-sized graphs after training. Experiments on synthetic and real datasets demonstrate the effectiveness of GDNs for the task. "
SP:91fd4189bf04aca4ccd1288ec8459e1edb29d378,"This paper proposes a reinforcement learning algorithm for reward shaping. The algorithm is based on a two-player Markov game between a reward shaping agent (Shaper) and a controller (controller). The controller is responsible for selecting which states to add shaping rewards and their optimal values, while the Shaper learns the optimal policy for the task using these shaped rewards. The authors prove that the algorithm learns to construct a shaping-reward function that is tailored to the task, thus ensuring efficient convergence to high performance policies. Experiments show that the proposed algorithm outperforms baselines in sparse reward environments."
SP:20abe4d70152590c3c44fcb50c5d0293e25874ff,"This paper studies the problem of robustness in vertical federated learning (VFL). In particular, the authors propose a novel robust training and inference framework that recovers the underlying uncorrupted features with provable guarantees and thus sanitizes the model against a vast range of backdoor attacks. The authors also propose a robust inference procedure to defend against a variety of targeted or untargeted attacks (e.g., adversarial and missing feature attacks). "
SP:3fbc5ebb4c598e849b3ecbb2886289e20bf1ea14,"This paper investigates the use of contrastive learning to improve the unsupervised retrieval performance of dense neural network based retrieval methods. The authors show that the proposed method outperforms BM25 on 8 out of 14 datasets on the BEIR benchmark. They also show that when a few thousands examples are available, fine-tuning their model on these leads to strong improvements compared to BM25. Finally, when used as pre-training before fine tuning on the MS MARCO dataset, their method obtains state-of-the-art results."
SP:ed4e2896dc882bd089f420f719da232d706097c5,This paper analyzes the tradeoff between fine-tuning and linear probing in the context of out-of-distribution (OOD) transfer. The authors show that linear probing (LP-FT) can achieve better ID and OOD accuracy than fine tuning (FT) when the pretrained features are good and distribution shift is large. The paper also provides a theoretical analysis of the trade-off between the two methods. 
SP:96f4f90488c15167d85261a883cd70fc15e06bb9,"This paper studies the problem of learning to discover novel classes (L2DNC). In this problem, we are given labeled data from seen classes and unlabeled data from unseen classes, and we train clustering models for the unseen classes. This paper demystifies assumptions behind the problem and finds that high-level semantic features should be shared among the seen and unseen classes and can be theoretically solvable under certain assumptions. Based on this finding, this paper proposes a meta-learning-based methodology to solve the problem. The proposed method significantly reduces the amount of unlabeling data needed for training and makes it more practical."
SP:262a5aaa4e675b2aac6bd14d3aa007bf411ce550,"This paper studies the problem of model-based reinforcement learning in POMDPs, where the agent has access to both online and offline data. The authors propose a method for learning a latent-based causal transition model that explains both the interventional and observational regimes, and then inferring the standard POMD transition model via deconfounding using the recovered latent variable. They prove their method is correct and efficient in the sense that it attains better generalization guarantees due to the offline data (in the asymptotic case) and demonstrate its effectiveness empirically."
SP:bcb4e7e5c137edf04a9ea2fde014b0984c6ef89b,This paper proposes a method to train a retriever to retrieve passages from a text corpus to provide additional context to a text generation system. The retriever is trained jointly with the generator by maximizing the evidence lower bound (ELBo) in expectation over the posterior distribution Q of passages given the input and the target output. The generator is also trained with an additional guide retriever that is allowed to retrieve relevant passages during training. Experiments on the Wizard of Wikipedia dataset show that the retriever finds passages with higher relevance in the top-10 and the generator’s responses are more grounded in the retrieved passage.
SP:bec15075409c71f98f3698bc35e34eeb4862d94f,"This paper proposes a graph neural network (GNN) based approach for influence estimation and influence maximization. The main idea is to use a GNN to estimate the influence of each node in a graph, and then use the GNN's predictions to optimize the influence spread. The GNN is trained on small simulated graphs and then applied to large graphs. The experiments show that the proposed approach outperforms baselines in terms of influence estimation. "
SP:0c55b1f5e544e1e9510a12981107ae6c9f1eeb2e,This paper proposes a novel active learning approach for domain adaptation based on a localized discrepancy between the labeled and unlabeled distributions. The authors derive generalization error bounds for such active learning strategies in terms of Rademacher average and localized discrepancy for general loss functions which satisfy a regularity condition. A practical Kmedoids algorithm that can address the case of large data set is inferred from the theoretical bounds. Numerical experiments show that the proposed algorithm is competitive against other state-of-the-art active learning techniques in the context of domain adaptation.
SP:f63c10ba7d6f5ef1c167faa8a221b3ab5cc06006,"This paper proposes a variational approximation for Bayesian neural networks based on a desingularization map. The authors show that the posterior distribution over the parameters of a singular model is asymptotically a mixture of standard forms, and show that a generalized gamma mean-field variational family, following desingularity, can recover the leading order term of the model evidence. Affine coupling layers are employed to learn the desingulization map, effectively rendering the proposed methodology a normalizing flow with the generalized gamma as the source distribution. "
SP:9ba33d09bd68d8598e2aff428ecca5060922a4dc,"This paper studies the problem of domain generalization (DG). The authors propose a generalization bound for DG based on the Rademacher complexity of the model. The authors conjecture that existing methods’ efficacy or lack thereof is a variant of the standard empirical risk-predictor complexity trade-off, and demonstrate that their performance variability can be explained in these terms. This analysis suggests that domain generalisation should be achieved by simply performing regularised ERM with a leave-one-domain-out cross-validation objective."
SP:b1f622cbc827e880f98de9e99eca498584efe011,"This paper studies the problem of maximum n-times coverage, which is a generalization of the multi-set multi-cover problem and is NP-complete, and is not submodular. The authors introduce two new practical solutions based on integer linear programming (ILP) and sequential greedy optimization (SGD) to solve the problem. The proposed method is applied to the pan-strain COVID-19 vaccine design and is shown to be superior to 29 other published designs. "
SP:11ad277db038a77d5935e7504cc640e74bfc4efe,"This paper proposes a new initialization method for weight initialization in spiking neural networks. The authors first derive an asymptotic formula for the response curve of spiking neurons, which approximates the actual neuron response distribution. Then, the authors propose an initialization method based on the slant-asymptote to overcome gradient vanishing. Finally, experiments with different coding schemes in classification tasks on the MNIST and CIFAR-10 dataset show that the proposed method can improve the training speed and the model accuracy compared with other SNN initialization methods."
SP:f7e8602b40b37f26277e3f44f60a11f879978986,"This paper proposes a federated learning algorithm called FedTEM, which learns a mixture model to infer the mode of each client, while training a network with multiple light-weight branches specializing at different modes. The main idea is to model the distribution shift with a mixture of distributions that gradually changes between daytime and nighttime modes. Experiments for image classification on EMNIST and CIFAR show that the proposed algorithm can effectively mitigate the impact of distribution shift and significantly improve the final model performance."
SP:e38efcfcf63f0488b6e20a74a86b78aad1ead363,"This paper proposes a method for pruning deep neural networks (DNs) based on the spline theory. The authors show that a DN’s spline mappings exhibit an early-bird (EB) phenomenon, which is related to the lottery ticket hypothesis of DNs. Based on this insight, the authors propose a pruning strategy that focuses on a tiny fraction of DN nodes whose corresponding spline partition regions actually contribute to the final decision boundary. Extensive experiments on four networks and three datasets validate the effectiveness of the proposed method."
SP:64ce86f8bd8572f699809c808aea8364fbbe4ef3,"This paper studies the problem of fair representation learning from a bi-level optimization perspective, where the representation is learned in the outer-level and invariant optimal group predictors are updated in the inner-level. The authors propose an implicit path alignment algorithm, which only relies on the solution of inner optimization and the implicit differentiation rather than the exact optimization path. The proposed method is evaluated on tabular, computer vision and NLP datasets."
SP:9bd0a519881297066ee60ccf62ee27e4c109047d,"This paper presents an empirical study of reinforcement learning via supervised learning (RvS) methods, which solve RL problems via conditional imitation learning. The authors show that RvS methods can match or exceed the best prior methods across a range of different offline RL benchmarks, including datasets with little or no optimal data. The most important design decisions boil down to carefully choosing model capacity and choosing which information to condition on (e.g., goals or rewards). The experiments find that more complex design choices, such as the large sequence models and value-based weighting schemes used in prior work, are often not necessary."
SP:af89e1cdd2b39df9982ca5cd9446ec66a4d317f2,"This paper proposes a method of map induction to model the exploration behavior of humans. The method is based on a Hierarchical Bayesian framework. The authors propose a new task, Map Induction Task, to study the behavior of human exploration. They show that their method is able to predict human exploration behavior better than a naive, non-inductive, POMDP. "
SP:cccdcc95c4177b5531bad23b662060fdd0d88849,This paper proposes a method to learn the probabilistic factors used for inference by a nonparametric belief propagation algorithm. The authors propose to replace each crafted factor with a differentiable neural network enabling the factors to be learned using an efficient optimization routine from labeled data. The method learns to maintain a set of marginal posterior samples using end-to-end training. Experiments are conducted on two simulated tracking tasks and on a real-world hand pose tracking tasks in challenging noisy environments.
SP:76e858a6ef79a3bd861803395e25d7f65fd29a00,"This paper proposes a graph-based generative model for molecule generation that does not require a fixed scaffold to be present in the generated molecule. This is possible because it is not conditioned on the generation history. The proposed method is evaluated on unconstrained and scaffold-constrained optimization tasks, and outperforms state-of-the-art methods while being an order of magnitude faster to train and sample from."
SP:318b3c294a475960c13a4914b035fd3a2ea84661,"This paper studies the problem of imitation learning with deterministic experts. The authors show that imitation learning can be done by reduction to reinforcement learning with a stationary reward. Theoretical analysis both certifies the recovery of expert reward and bounds the total variation distance between the expert and the imitation learner, showing a link to adversarial imitation learning. Experiments on continuous control tasks confirm that our reduction works well in practice."
SP:fd1a9b4c5ee36159286f4a35fa93ed0c23120906,"This paper analyzes the effect of reweighting algorithms on the worst-case worst-group performance of a given model. The authors prove that under certain assumptions, the overparameterized model always converges to the same ERM interpolator that fits all training samples. Then, the authors analyze whether adding regularization helps fix the issue, and prove that for regularization to work, it must be large enough to prevent the model from achieving small training error. "
SP:318ace9202e42d1d278eb79fe1853138e1d00a06,"This paper proposes a method to model bounded rationality in multi-agent reinforcement learning (MARL). The proposed method is based on the Rational Inattention (RI) model, which models the cost of cognitive information processing using mutual information. The authors show that using the proposed method yields a rich spectrum of new equilibrium behaviors that differ from those found under rational assumptions. For instance, some forms of a Principal’s inattention can increase Agent welfare due to increased compensation, while other forms can decrease Agent welfare."
SP:100c91da177504d89f1819f4fdce72ebcf848902,"This paper proposes a phase-oriented adversarial attack for audio adversarial attacks. Specifically, the authors leverage the spectrogram consistency of short-time Fourier transform (STFT) to adversarially transfer phase perturbations to the adjacent frames of magnitude spectrogram and dissipate the energy patterns in spectrogram. The authors also propose a weighted loss function to improve the imperceptibility of the attack. Experiments on the LibriSpeech dataset demonstrate the effectiveness of the proposed attack."
SP:713c57555a88d922516f42e7ff0ddd5bfbd90a24,"This paper analyzes a generalized version of DirectPred, called DirectSet(alpha) and shows that it learns a desirable projection matrix and reduces the sample complexity on downstream tasks. The paper also shows that weight decay acts as an implicit threshold that discard the features with high variance under augmentation, and keep the feature with low variance. Inspired by the analysis, the paper proposes a simpler and more efficient algorithm DirectCopy, which achieves comparable or better performance than the original DirectPred algorithm on various datasets."
SP:8433900e40c5c5df1f003dd1d4fb08c7aafd51f8,"This paper proposes a novel method called Long Expressive Memory (LEM) for learning long-term sequential dependencies. LEM is gradient-based, it can efficiently process sequential tasks with very long term dependencies, and it is sufficiently expressive to be able to learn complicated input-output maps. To derive LEM, the authors consider a system of multiscale ordinary differential equations, as well as a suitable time-discretization of this system. They derive rigorous bounds to show the mitigation of the exploding and vanishing gradients problem, a well-known challenge for gradient based recurrent sequential learning methods. They also prove that LEM can approximate a large class of dynamical systems to high accuracy. The empirical results, ranging from image and time-series classification through dynamical system prediction to keyword spotting and language modeling, demonstrate that the proposed method outperforms state-of-art recurrent neural networks, gated recurrent units, and long short-term memory models."
SP:dbf896dd31627b27f0a902c716aff940e5ab7ac2,"This paper proposes a geometric deep learning architecture that is rotation and permutation-equivariant. The proposed architecture is composed of a set of products of terms from the geometric algebra and reductions over those products using an attention mechanism. The geometric algebra provides valuable mathematical structure by which to combine vector, scalar, and other types of geometric inputs in a systematic way to account for rotation invariance or covariance, while attention yields a powerful way to impose permutation equivariance. The authors demonstrate the usefulness of these architectures by training models to solve sample problems relevant to physics, chemistry, and biology."
SP:5a6099feb5da2c35f99d4d76c7e0ff3cd3e9c196,"This paper proposes a method to solve the order fulfillment problem, which is a combinatorial optimization problem in supply chain management. The problem is formulated as a tripartite graph and a graph attention mechanism is proposed to learn the best assignment policy through the proposed edge-feature-embedded graph attention. The model is size-invariant for problem instances of any scale and it can address cases that are completely unseen during training. Experiments show that the proposed method substantially outperforms the baseline heuristic method in optimality."
SP:7f7f8245914ecc5b00570916bbcdb6c9b49d26de,"This paper proposes a dialogue summarization task based on the DialSum dataset. The authors propose a novel framework consisting of a CODC inference module leveraging external knowledge from WordNet and a knowledge attention module aggregating the inferred knowledge into a neural summarization model. To evaluate the inference capability of different methods, the authors also propose a new evaluation metric based on COCO. Experiments suggest that current automatic evaluation metrics of natural language generation may not be enough to understand the quality of out-of-context inference in generation results, and the proposed summarisation model can provide statistically significant improvements on both CODI and CIDEr."
SP:e1591b266d6c329c6c07f4e5234253249ab1db8c,"This paper studies the problem of learning entity embeddings that are able to capture semantic dependencies between entities. The authors focus on the setting where the embedding of an entity is obtained by pooling its embedding with its associated attributes. In particular, the authors study the theoretical limitations of different embedding strategies, rather than their ability to effectively learn attribute dependencies in practice. They first show a number of negative results, revealing that some of the most popular embedding models are not able to represent even basic Horn rules. However, they also find that some embedding methods are capable of modelling both monotonic and non-monotonic attribute dependencies. "
SP:794cca5205d667900ceb9a1332b6272320752ef4,"This paper studies the performance of transformer-based models on different reasoning tasks, including mathematical reasoning, commonsense reasoning, and logical reasoning. The authors point out successes and limitations, of both empirical and theoretical nature. They show that when the model is explicitly given all the information required to perform deductive reasoning, such as facts and rules, the models can easily learn logical reasoning, but when this information is stated only implicitly in the text or in the supervision, they struggle. "
SP:3a16ffa27e7ef0684e6d0f3ee744787aef108a07,"This paper introduces the compositional problem graph as a generalization framework to relate tasks of different complexity in terms of problems with shared subproblems. The authors propose a compositional recursive learner, a framework for learning algorithmic procedures for composing representation transformations, producing a learner that reasons about what computation to execute by making analogies to previously seen problems. They show on a symbolic and a high-dimensional domain that their compositional approach can generalize to more complex problems than the learner has previously encountered."
SP:7f91f3805bd643e3b796e885b00f88a77aa49d15,This paper proposes Integral Pruning (IP) to reduce the computation cost of DNNs by pruning both weights and activations. The main idea is to learn dynamic activation masks by attaching activation pruning to weight pruning after static weight masks are well trained. Experiments on various network models with different activation functions and on different datasets show substantial reduction in MACs by the proposed method.
SP:d34277109f713f78abd3b911c7a38baf18c8c8c1,"This paper proposes a new method for feature selection based on GANs. The method is based on the KnockoffGAN framework. The main contribution is to modify the discriminator used in the GAN framework in such a way that the generator learns to generate knockoffs satisfying the necessary swap condition, which requires that when a feature and its knockoff are swapped, the joint distribution remains unchanged. The authors also propose a method for maximizing the power of the model using Mutual Information Neural Estimation (MINE) and investigate a regularization method to improve the stability of training."
SP:7bf79b020c2cafaced61f2595ad17e8238c3dc5d,"This paper proposes a spatial-Winograd pruning method to improve the Winograd-domain weight sparsity without changing the network structure. The spatial-domain weights are pruned in a structured way, which efficiently transfers the spatial-domains sparsity into the winograd domain and avoids the need for the retraining step. The authors also propose to use an importance factor matrix to adjust the gradients of the pruned weights. Experiments are conducted on CIFAR-10, Cifar-100, and ImageNet."
SP:35e050c84f55f30b5a958128fa5bdaa1cb3f7e90,"This paper proposes Adversarially Learned Mixture Model (AMM), a generative model for unsupervised or semi-supervised clustering. AMM is the first adversarially optimized method to model the conditional dependence between inferred continuous and categorical latent variables. Experiments on the MNIST and SVHN datasets show that the AMM allows for semantic separation of complex data when little or no labeled data is available."
SP:c65ea3a1cc796e65465e8b4dc05ae103316e2cb3,"This paper proposes a gradient estimator that is unbiased, exhibits low variance, and has low computational complexity. The estimator is based on the augment-REINFORCE-merge (ARM) estimator. The variance reduction is achieved by merging two expectations via common random numbers. Experiments are conducted on variational inference and maximum likelihood estimation for discrete latent variable models with one or multiple stochastic layers. "
SP:c54ee7a7d321a487257d2554c7e689967cf0ceaa,This paper proposes a modular probabilistic programming language (MXFusion) that includes a new type of re-usable building blocks (probabilistic modules) to improve modularity of the language. These modules are designed to be able to represent more sophisticated probababilistic models such as Bayesian nonparametric models as fundamental building blocks. The authors demonstrate the power and convenience of these modules with various examples of Gaussian process models. 
SP:b65eb92fcbea57626721a156be6e6cbbad3c071c,"This paper proposes a method to prune a given network at initialization. The method is based on a saliency criterion based on connection sensitivity that identifies structurally important connections in the network for the given task. This eliminates the need for both pretraining and the complex pruning schedule while making it robust to architecture variations. After pruning, the sparse network is trained in the standard way. Experiments are conducted on MNIST, CIFAR-10, and Tiny-ImageNet."
SP:986b9781534ffec84619872cd269ad48d235f869,This paper analyzes the behavior of beam search for neural sequence synthesis. The authors find that increasing the beam width leads to sequences that are disproportionately based on early and non-greedy decisions. They propose two methods to constrain the search and show that constrained beam search effectively eliminates the problem of beam-search degradation. 
SP:b2a8f5c3a417390582f26981fe0c81c16d2bb07d,"This paper proposes Backplay, a method to improve the sample efficiency of model-free reinforcement learning by using a single demonstration to construct a curriculum for a given task. The idea is to start the agent near the end of the demonstration and move the starting point backwards during the course of training until we reach the initial state. The method is evaluated on a grid world and a four-player zero-sum game. "
SP:426c98718b2dbad640380ec4ccb2b656958389bc,"This paper proposes a multi-layer pruning method (MLPrune) to automatically decide appropriate compression ratios for all layers of a neural network. The authors use an efficient approximation of the Hessian as the pruning criterion, based on a Kronecker-factored Approximate Curvature (K-FAC) method. Experiments show that the proposed method outperforms previous state-of-the-art by a large margin."
SP:b97549a4c1f4b2407f97576fed46c25cbf669009,"This paper presents a method to visualize and understand GANs at the unit, object, and scene-level. The authors first identify a group of interpretable units that are closely related to object concepts using a segmentation-based network dissection method. Then, they quantify the causal effect of these interpretable unit by measuring the ability of interventions to control objects in the output. They examine the contextual relationship between these units and their surroundings by inserting the discovered object concepts into new images. Finally, they provide open source interpretation tools to help researchers and practitioners better understand their GAN models."
SP:252c20661ef36f8c32f7412db315747925d3a3d0,"This paper studies the relationship between parameter and function distances between neural networks. The authors show that it is possible to calculate the distances between functions in a L-Himalayan space. Then, they show that the two distances are nontrivial related. Finally, they propose a learning rule for supervised learning that constrains how much a network’s function can change any one update. "
SP:f6cb7efaef82aff9849c8e157bfe5db5092a6271,"This paper proposes a deep neural network framework for learning Markovian stochastic dynamics from biological data. The framework is trained as a deep generative Markov model whose next state is a probability distribution based on the current state. It is well-suited to the idiosyncrasies of biological data, including noise, sparsity, and the lack of longitudinal measurements in many types of systems. It can be trained using probability distributions derived from the data in any way, such as trajectories derived via dimensionality reduction methods, and does not require longitudinal measurements. The experiments show the advantage of learning deep models over shallow models such as Kalman filters and hidden Markov models."
SP:4828e4160b70ea11e364b48db24cb68cdf86edfc,This paper proposes a graph Laplacian-based generative adversarial network (GAN) architecture for unsupervised learning of images. The key idea is to use an approximate linear map and a spectral clustering theory on the dimension reduced spaces. The proposed method can also classify the images by using the estimated number of classes. 
SP:d5f5f6a83f0290415ea94b3740a95360a8fa16e3,This paper proposes a method to learn permutation-invariant representations of sets. The method is based on a permutation optimisation module that learns how to permute a set end-to-end. The permuted set is then processed to learn a set representation that is permutation invariant. The authors demonstrate the effectiveness of the proposed method on a variety of tasks. 
SP:cf74c553bae2b1194beaba4df1545d35e66aa5b3,"This paper proposes Projective Subspace Networks (PSNets), a novel approach for few-shot learning that employs nonlinear embeddings and modeling via affine subspaces. In particular, each class is represented by the subspace formed by all its examples, meaning that each classes is modeled by the span of its samples. Experiments are conducted on supervised and semi-supervised classification tasks."
SP:d7544bc4a0ae3237daa207e789a522363fb5170d,"This paper proposes a meta-learning method called CAML that partitions the model parameters into two parts: context parameters that serve as additional input to the model and are adapted on individual tasks, and shared parameters that are meta-trained and shared across tasks. At test time, the context parameters are updated with one or several gradient steps on a task-specific loss that is backpropagated through the shared part of the network. Compared to approaches that adjust all parameters on a new task (e.g., MAML), CAML can be scaled up to larger networks without overfitting on a single task, is easier to implement, and saves memory writes during training and network communication at test time for distributed machine learning systems."
SP:8a5e86b6770a3c08f861fbf682296dc3a6c02204,"This paper proposes a framework where the user controls what characteristics of the data they share (utility) and what they want to keep private (secret), without necessarily asking the utility provider to change its existing machine learning algorithms. The authors first analyze the space of privacy-preserving representations and derive natural information-theoretic bounds on the utility-privacy trade-off when disclosing a sanitized version of data X. They present explicit learning architectures to learn privacy preserving representations that approach this bound in a data-driven fashion. They describe important use-case scenarios where the utility providers are willing to collaborate with the sanitization process. "
SP:6b0e9a8f0c046a767dce8790489b3e90e12e2c46,"This paper proposes a progressive augmentation (PA) method to improve the stability of GAN training. The main idea is to gradually increase the task difficulty of the discriminator by progressively augmenting its input space, thus enabling continuous learning of the generator. The experimental results demonstrate the effectiveness of the proposed approach on multiple benchmarks."
SP:c210982ccdd134d4b293dbe144990398eefe1a86,This paper proposes a rotation-equivariant convolutional neural network (RNN) model of primary visual cortex (V1) to identify common features that are shared by many V1 neurons and are pooled sparsely to predict neural activity. The RNN is trained on responses of a population of 6000 neurons to natural images recorded in mouse V1 using two-photon imaging. The experiments show that the RNN outperforms a regular CNN with the same number of feature maps and reveals a number of common features. 
SP:f17090812ace9c83d418b17bf165649232c223e3,"This paper studies the problem of distributed training of convolutional neural networks. The authors propose a simple algorithm called SIGNSGD, which is a special case of distributed ADAM. Theoretically, the authors show that the algorithm converges to a stationary point with a convergence rate of $\mathcal{O}(1/\sqrt{T})$ when the number of workers is sufficiently large. They also show that this algorithm is robust to adversarial perturbations. Finally, they show that their algorithm is competitive with SGD in terms of convergence rate. "
SP:0ceece0754a1fe9c46a978bb2854932905685fa4,"This paper proposes a GAN-based approach to generate realistic stock market data. The authors model the order stream as a stochastic process with finite history dependence, and employ a conditional Wasserstein GAN to capture history dependence of orders in a stock market. The generated data is evaluated with various statistics such as the distribution of price and quantity of orders, inter-arrival times, and the best bid and best ask evolution over time."
SP:ba66503753b3c57781b435c55c47fc9f69450e65,"This paper studies the problem of reinforcement learning in the presence of noisy rewards. The authors propose an unbiased reward estimator aided robust RL framework that enables RL agents to learn in noisy environments while observing only perturbed rewards. This framework draws upon approaches for supervised learning with noisy data. Extensive experiments on different DRL platforms show that policies based on the estimated surrogate reward can achieve higher expected rewards, and converge faster than existing baselines."
SP:0e62f75b81b696bf794932d0ceee60e9f665f1da,"This paper studies the effect of network structure (depth and width) on halting time and shows that larger models,wider models in particular, take fewer training steps to converge. They design simple experiments to quantitatively characterize the effects of overparametrization on weight space traversal. Results show that halting time improves when growing model’s width for three different applications, and the improvement comes from each factor: the distance from initialized weights to converged weights shrinks with a power-law-like relationship, the average step size grows with a Power-law relationship, and gradient vectors become more aligned with each other during traversal during training. "
SP:40e210d36298e2eafd06d9dc45312ea4fd586ade,"This paper proposes a primal-dual framework for learning algorithms for online combinatorial optimization problems. Specifically, the authors introduce the concept of adversarial distributions (universal and high-entropy training sets), which are distributions that encourage the learner to find algorithms that work well in the worst case. The authors test their new ideas on the AdWords problem, the online knapsack problem, and the secretary problem. Their results indicate that the models have learned behaviors that are consistent with the optimal algorithms for these problems derived using the primal dual framework."
SP:b99732087f5a929ab248acdcd7a943bce8671510,"This paper re-examines several domain-specific components that modify the agent’s objective and environment interface. The authors investigated whether the performance deteriorates when all these fixed components are replaced with adaptive solutions from the literature. They found that performance sometimes decreased with the adaptive components, as one might expect when comparing to components crafted for the domain, but sometimes adaptive components performed better. Then, they compared the learning performance of the two systems on a different set of continuous control problems, without additional tuning of either system. "
SP:47b0c8a984480eb353b36fd877d9775213fb1a5f,"This paper proposes a self-monitoring agent for Vision-and-Language Navigation (VLN) task. The agent is equipped with a visual-textual co-grounding module to locate the instruction completed in the past, the instruction required for the next action, and the next moving direction from surrounding images, and a progress monitor to ensure the grounded instruction correctly reflects the navigation progress. The proposed method is evaluated on a standard benchmark and analyzed through a series of ablation studies."
SP:7e70c97e9b7b182e974b071c93baafef8b11cf90,This paper proposes two techniques to improve the performance of neural program synthesis from input-output examples. The first is execution-guided synthesis and the second is synthesizer ensemble. The authors claim that the main drawback of existing approaches is that the semantic information is greatly under-utilized and propose two simple yet principled techniques to leverage this information. Experiments on the Karel dataset show that the proposed techniques can boost the accuracy from around 77% to more than 90%.
SP:dc7dfc1eec473800580dba309446871122be6040,"This paper analyzes the properties of batch normalization (BN) in the context of ordinary least squares (OLS). The authors show that BN has interesting properties, including a scaling law, convergence for arbitrary learning rates for the weights, acceleration effects, as well as insensitivity to the choice of learning rates. The authors also demonstrate numerically that these findings are not specific to the OLS problem and hold qualitatively for more complex supervised learning problems. "
SP:9984d73a1fcfce932cfcafb4d200f70b07723bf3,"This paper provides a new theoretical perspective of data noising in recurrent neural network language models (Xie et al., 2017). They show that each variant of data-noising is an instance of Bayesian recurrent neural networks with a particular variational distribution (i.e., a mixture of Gaussians whose weights depend on statistics derived from the corpus such as the unigram distribution). They use this insight to propose a more principled method to apply at prediction time and propose natural extensions to data noizing under the variational framework. "
SP:f4a914d3df1a5a21a7365ba78279420f39210884,This paper proposes a novel method for classifier-agnostic saliency map extraction. The proposed method is based on finding a saliency mapping that works for all possible classifiers weighted by their posterior probabilities. A practical algorithm is proposed to simultaneously train a classifier and the saliency maps using stochastic gradient descent. Experiments on the ImageNet dataset show that the proposed method outperforms existing weakly-supervised localization techniques.
SP:df038354c6a7638116a98d150aa4a8f5f2b0a2da,"This paper proposes a knowledge flow method to transfer knowledge from multiple deep nets to a new deep net model, called the student. The student is independent of the teachers and can be trained on entirely different tasks with different output spaces. The method is evaluated on a variety of supervised and reinforcement learning tasks, outperforming fine-tuning and other methods."
SP:a72072879f7c61270d952f06d9ce995e8150632c,This paper proposes a method to learn a compact dynamical model of a complex dynamical system. The main idea is to perform a soft-clustering of the data and learn its dynamics to produce a compact model while still ensuring the original objectives of causal inference and accurate predictions. The authors cast the model construction as a maximization of the compression of the state variables such that the predictive ability and causal interdependence (relatedness) constraints between the original data streams and the compact model are closely bounded. They provide theoretical guarantees concerning the convergence of the proposed learning algorithm. 
SP:2b03b7ea1264c2671d29e8fa5f3a828412ea7996,"This paper proposes a variational autoencoder (VAEAC) that can be conditioned on an arbitrary subset of observed features and then sample the remaining features in a single shot. The features may be both real-valued and categorical. Training of the model is performed by stochastic variational Bayes. The experimental evaluation on synthetic data, as well as feature imputation and image inpainting problems shows the effectiveness of the proposed approach and diversity of generated samples."
SP:f46f0cb43274fb20cba91ef7318305f668bc6928,"This paper proposes a method to reduce the memory footprint of neural network training by approximating the activations with lower-precision approximations during the forward and backward pass of SGD. The method is based on uniform quantization (UQ), which quantizes the floating point activations in the forward pass to a lower precision, which is then used during the backward pass. Experiments are conducted on CIFAR-10 and ImageNet to demonstrate the effectiveness of the proposed method."
SP:6ad33c6fbdee78c13d9190601637e07d20fe024f,"This paper proposes a novel GAN-based method for face completion. The proposed method is based on a coarse-to-fine attentive module network, which is trained progressively from low resolution to high resolution with conditional vectors encoding controllable attributes. A conditional version of the model allows users to control the properties of generated images explicitly with attribute vectors and landmarks. The experimental results show that the proposed method outperforms state-of-the-art face completion methods."
SP:a300122021e93d695af85e158f2b402d21525bc8,"This paper proposes a method to analyze the precision required for partial sum accumulations in GEMM functions in deep learning. The authors propose an analytical method to predict the precision needed for partial sums in deep neural networks. The method is based on the observation that a bad choice for accumulation precision results in loss of information that manifests itself as a reduction in variance in an ensemble of partial sums. They derive a set of equations that relate this variance to the length of accumulation and the minimum number of bits needed for accumulation. They apply their analysis to three benchmark networks: CIFAR-10 ResNet 32, ImageNet ResNet 18 and ImageNet AlexNet. In each case, with accumulation precision set in accordance with the proposed equations, the networks successfully converge to the single precision floating-point baseline. "
SP:3a1655a2efdf0246f459b6f82a2948aafc7438a9,"This paper studies the risk convergence and asymptotic weight matrix alignment of gradient flow and gradient descent when applied to deep linear networks on linearly separable data. In particular, it shows that the risk converges to 0, the normalized weight matrix is aligned across layers, and the linear function induced by the network — the product of its weight matrices — converges in the same direction as the maximum margin solution. The paper also shows that for the logistic loss (binary cross entropy), more can be said. "
SP:868dd531fe7886b0260295d25b75cc6d6d28f12d,"This paper proposes a method to improve the performance of a sequence-to-sequence (Seq2Seq) neural network neural network model for multi-turn dialogue scenario by modifying the state-of-the-art hredGAN architecture to simultaneously capture utterance attributes such as speaker identity, dialogue topic, speaker sentiments and so on. The proposed system, phredGAN, has a persona-based HRED generator (PHRED) and a conditional discriminator. Experiments on two conversational datasets, the Ubuntu Dialogue Corpus (UDC) and TV series transcripts from the Big Bang Theory and Friends show the effectiveness of the proposed method."
SP:017b66d6262427cca551ef50006784498ffc741d,"This paper proposes a goal-driven collaborative task that contains language, vision, and action in a virtual environment as its core components. Specifically, the authors develop a Collaborative image-Drawing game between two agents, called CoDraw. The game involves two players: a Teller and a Drawer. The Teller sees an abstract scene containing multiple clip art pieces in a semantically meaningful configuration, while the Drawer tries to reconstruct the scene on an empty canvas. The two players communicate via two-way communication using natural language. The authors collect the CoDraw dataset of ∼10K dialogs consisting of ∼138K messages exchanged between human agents. They define protocols and metrics to evaluate the effectiveness of learned agents on this testbed. "
SP:d5126851b9e75b49522d953ee2b253e3e6c836ba,"This paper proposes a new approach to learning neural random fields with an inclusive-divergence minimized auxiliary generator for continuous data. The authors show that the proposed approach can be flexibly used in unsupervised/supervised image generation and semi-supervised classification, and empirically show that it represents the best-performed random fields in these tasks. The paper is well-written and easy to follow. However, the novelty of the paper is limited."
SP:0841febf2e95da495b41e12ded491ba5e9633538,"This paper proposes a meta-learning approach for adversarial attacks on graph neural networks for node classification that perturb the discrete graph structure. The main idea is to use meta-gradients to solve the bilevel problem underlying training-time attacks, essentially treating the graph as a hyperparameter to optimize. The experiments show that small graph perturbations consistently lead to a strong decrease in performance for graph convolutional networks, and even transfer to unsupervised embeddings."
SP:beb54248806f7a68beb60167c3dbbd45b34dad83,This paper proposes a new autoencoder model based on the Cramer-Wold distance between samples and distributions. The proposed model is based on a kernel called CramerWold kernel and has a simple closed-form in the case of normal prior. Experiments are conducted on MNIST and CIFAR-10 datasets. 
SP:57538c4cac6a4510a0c79e6da3deffae4d6c3b91,"This paper studies the problem of few-shot few-class classification in the context of supervised learning and meta-learning. The authors propose MahiNet, a neural network architecture that uses a convolutional neural network (CNN) to extract features, and integrates a memory-augmented attention module with a multi-layer perceptron (MLP) to produce the probabilities over coarse and fine classes. The MLP extends the linear classifier and the attention module extends a KNN classifier, both together targeting the “few-shot” problem. Different training strategies are proposed to improve the performance of the model. Two new benchmark datasets are proposed for MCFS classification. "
SP:ae9b6f7f2bd29ad1d24c4acbe1ecd345fcd6a081,"This paper proposes a recurrent neural network model for speed reading. The model consists of a recurrent LSTM and two agents: one that can skip words when reading, and another that can jump ahead after reading a word. The authors show that the proposed model achieves the best overall floating point operations (FLOP) reduction (hence is faster), while keeping the same accuracy or even improving it compared to a vanilla L STM that reads the whole text."
SP:9be782b532e64c6aad140531a17fbba1dd3342cd,"This paper proposes a nonlinear radial basis convolutional feature transformation method to improve the robustness of deep neural networks against adversarial perturbations. The proposed method is based on learning the Mahalanobis distance function to map the input features from the same class into tight clusters. In such a space, the clusters become compact and well-separated, which prevents small adversarial attacks from forcing a sample to cross the decision boundary. The method is evaluated on three publicly available image classification and segmentation data-sets."
SP:b08dc82d5098474ddd68ab13003013ee6e7ba989,"This paper proposes a novel method for temporal exploration in deep reinforcement learning. The proposed method is based on a dropout-based method for sampling subnetworks from the same neural network. The subnetwork is sampled through dropout at the beginning of episodes, used to explore the environment with diverse and consistent behavior patterns and updated through simultaneous gradient back-propagation. Two factors, gradients’ alignment with the objective and KL constraint in policy space, are discussed to guarantee NADPEx policy’s stable improvement. Experiments are conducted on the Mujoco benchmark for continuous control. "
SP:304930c105cf036ab48e9653926a5f61879dfea6,"This paper proposes a new metric, the nonlinearity coefficient (NLC), to measure the sensitivity of the output of a neural network to small changes in the input. The NLC is defined as the Frobenius norm of the Jacobian of the input data and the global variability of the network’s outputs. The authors show empirically that the NLC, computed in the randomly initialized state, is a powerful predictor of test error and is essential for attaining an optimal test error, at least in fully-connected feedforward networks. "
SP:17d8dc884e15131636a8c2490085ce42c05433c1,"This paper studies the phenomenon of bias amplification in classifiers, where a machine learning model learns to predict classes with a greater disparity than the underlying ground truth. The authors demonstrate that bias amplification can arise via an inductive bias in gradient descent methods that results in the overestimation of the importance of moderately-predictive “weak” features if insufficient training data is available. This overestimation gives rise to feature-wise bias amplification, a previously unreported form of bias that can be traced back to the features of a trained model. Based on this observation, the authors develop two new feature selection algorithms that are designed to mitigate bias amplification. They demonstrate their effectiveness on both linear classifiers and deep neural networks."
SP:2b84207c0015dba126d4ef4a89ef9cc29656f2f8,"This paper analyzes the generalization properties of neural networks from a margin-based perspective. The authors show that for multi-layer feedforward relu networks, the global minimizer of a weakly-regularized cross-entropy loss has the maximum normalized margin among all networks, and that increasing the over-parametrization improves the normalized margin and generalization error bounds for deep networks. In the case of two-layer networks, an infinite-width neural network enjoys the best generalization guarantees. Finally, this infinite-neuron viewpoint is also fruitful for analyzing optimization."
SP:91459c66bb597751ffce8410e283ce3f094bdd5f,This paper proposes a novel method to control the location of arbitrary objects within an image by adding an object pathway to both the generator and the discriminator. The object pathway focuses solely on the individual objects and is iteratively applied at the locations specified by the bounding boxes. The global pathway focuses on the image background and the general image layout. The experiments show that through the use of the object pathway we can control object locations within images and can model complex scenes with multiple objects at various locations.
SP:fbfe2c90a70a6adf39fa4d4a3c28f6b5adbc6c06,"This paper proposes a model-based reinforcement learning algorithm, called SOLAR, which is based on learning a latent representation of the dynamics of the state space conditioned on the current policy. The key idea is to learn a PGM that is able to predict the dynamics given the data from the current state space. The method is evaluated on a variety of simulated and real-world robotic manipulation tasks. "
SP:9a4c7d9df6685347e75e0ae72928225b7622a73c,"This paper proposes a method for policy evaluation and policy search in POMDPs. The proposed method is based on counterfactual inference, i.e. taking actions that were not actually taken. The method is evaluated on a simple grid-world task.   "
SP:9371d08e2b3a821e40cc9d4757c22f6cdb731b6a,"This paper analyzes the relationship between adversarial robustness and decision surface geometry in neural networks. The authors show that the geometry property of decision surface in input space correlates well with robustness against adversarial attacks. Based on this observation, the authors propose a robustness indicator that can evaluate a neural network’s intrinsic robustness property without testing its accuracy under adversarial perturbations. Then, a robust training method is proposed to enhance the robustness of the network against adversarially perturbed inputs."
SP:6f94f59bc936a11d95ded7309dc2458fee6d2595,This paper proposes an end-to-end DNN training framework that provides quantitative energy consumption guarantees via weighted sparse projection and input masking. The key idea is to formulate the training as an optimization problem in which the energy budget imposes a previously unconsidered optimization constraint. The authors integrate the quantitative DNN energy estimation into the training process to assist the constrained optimization. They prove that an approximate algorithm can be used to efficiently solve the optimization problem.
SP:7f07f3fa8a10b48bb380a7c84bc012ce3541122b,"This paper proposes a Bayesian policy optimization algorithm for continuous Bayesian adaptive Markov Decision Processes (BAMDPs). The authors formulate the problem of model uncertainty as a continuous Bayes-adaptive Markov decision process where an agent maintains a posterior distribution over latent model parameters given a history of observations and maximizes its expected long-term reward with respect to this distribution. The authors propose a new policy network architecture that encodes the belief distribution independently from the observable state. The proposed algorithm, Bayesian Policy Optimization (BPO), builds on recent policy optimization algorithms to learn a universal policy that navigates the exploration-exploitation trade-off to maximize the Bayesian value function. The experiments show that BPO significantly outperforms algorithms that address model uncertainty without explicitly reasoning about belief distributions and is competitive with state-of-the-art POMDP solvers."
SP:3823faee83bc07a989934af5495dafd003c27921,"This paper proposes a unified framework for building unsupervised representations of entities and their compositions, by viewing each entity as a histogram (or distribution) over its contexts. This enables us to take advantage of optimal transport and construct representations that effectively harness the geometry of the underlying space containing the contexts. The method captures uncertainty via modelling the entities as distributions and simultaneously provides interpretability with the optimal transport map, hence giving a novel perspective for building rich and powerful feature representations. Empirical results on tasks such as sentence similarity and word entailment detection demonstrate the effectiveness of the proposed framework."
SP:9ce5b80147ea2c7d0711ec98e31f4bbb5eac534e,"This paper studies the problem of planning in MuJoCo. The authors propose to use a dynamics model to predict the next state, given the current state and a sequence of actions. They show that the dynamics model is more accurate than a single-step dynamics model that predicts the next time step given the state and an action. They also show that their model is able to provide more accurate predictions over long time horizons.  "
SP:da14205470819495a3aad69d64de4033749d4d3e,"This paper proposes a method to reduce the accumulated quantization error in neural networks. The proposed method, precision highway, is an end-to-end high-precision information flow, which can be applied to both feedforward and feedback networks and enable ultra-low precision in deep neural networks, by keeping high precision activation from the input to output of the network with small computation costs. The experiments show that the proposed method outperforms the state-of-the-art methods in the 3- and 2-bit quantization of ResNet-18/50 and LSTM."
SP:0355b54430b39b52df94014d78289dd6e1e81795,"This paper proposes a general method for image restoration. The problem is formulated as a constrained optimization problem, and its objective is to maximize a posteriori probability of latent variables, and the constraint is that the image generated by these latent variables must be the same as the degraded image. The authors use a generative adversarial network (GAN) as the density estimation model, and propose a first-order iterative algorithm to solve the optimization problem in the proposed method. The proposed algorithm is well-suited to solve constrained optimization problems."
SP:2feef921a0563d52fde1c074da754f73e6cabef8,"This paper proposes a novel method for knowledge distillation from few samples. The proposed method is based on adding a 1x1 conv-layer at the end of each block in the student-net and aligning the block-level outputs between ""teacher"" and ""student"" by estimating the parameters of the added layer with limited samples. Experiments are conducted to show the effectiveness of the proposed method."
SP:ca491b166bd8bf1a7c71657471a2f58b7fd36609,"This paper proposes a novel metric, H-score, to evaluate the performance of transferred representations from one task to another in classification problems. Inspired by a principled information theoretic approach, the proposed metric has a direct connection to the asymptotic error probability of the decision function based on the transferred feature. This formulation of transferability can further be used to select a suitable set of source tasks in task transfer learning problems or to devise efficient transfer learning policies. Experiments using both synthetic and real image data show that the proposed transferability metric is meaningful in practice, and it can generalize to inference problems beyond classification."
SP:c6884b04001bd0d43aa47e2d72ebbe2bbc89ab3d,"This paper proposes to add a planning phase to neural machine translation (NMT) to control the global sentence structure ahead of translation. The approach learns discrete structural representations to encode syntactic information of target sentences. During translation, we can either let beam search to choose the structural codes automatically or specify the codes manually. Experiments show that the translation performance remains intact by learning the codes to capture pure structural variations."
SP:51810c5f8d40d9ec40469349f1612bf2eefe9aad,"This paper proposes a new loss function for GANs. The proposed loss function is based on a discriminator that estimates the probability that the given real data is more realistic than a randomly sampled fake data, on average. This discriminator is called a ""relativistic discriminator"" (RGAN). The authors also propose a variant of this loss function, which is called the ""raD"" loss function. The authors show empirically that the proposed RGANs and RaD are more stable and generate more realistic samples. "
SP:8df1599919dcb3329553e75ffb19059f192542ea,This paper proposes Parameter Generation and Model Adaptation (PGMA) to address the problem of catastrophic forgetting in continual learning. The proposed approach learns to build a model with two sets of parameters. The first set is shared by all tasks learned so far and the second set is dynamically generated to adapt the solver to suit each test example in order to classify it. Extensive experiments have been carried out to demonstrate the effectiveness of the proposed approach.
SP:1342b6e11d1ccf04ee95b63d8b7a88b184dee43e,This paper proposes a new method for predicting the future behavior of agents in multi-agent reinforcement learning (RL) environments. The proposed method is based on graph neural networks (GNs) that are trained to predict the forward dynamics of the environment. The authors show that the proposed method outperforms baselines on the task of predicting the agent’s future behavior. They also show that embedding RFM modules inside agents results in a faster learning system. 
SP:f2f01c7c4fb68c25d6e5ac56cbf79615ed1ee9ee,"This paper proposes a meta-IRL method for few-shot learning for reward functions of new tasks. The main idea is to leverage data from previous tasks to effectively learn deep neural network reward functions from raw pixel observations for new tasks, from only a handful of demonstrations. The proposed method is based on the observation that demonstrations from other tasks can be used to constrain the set of possible reward functions by learning a “prior” that is specifically optimized for the ability to infer expressive reward functions. The authors demonstrate that their method can efficiently recover rewards from images for novel tasks and provide intuition as to how our approach is analogous to learning a prior."
SP:4c2f45c7fd0cac662a33be602985cf360b45fe4d,"This paper proposes a meta-learning method called VERSA, which is based on the ML-PIP framework for few-shot learning. The main contribution of the paper is the introduction of a new amortized amortization network for the task-specific parameters in a single forward pass through the inference network. The proposed method is evaluated on a few benchmark datasets. "
SP:44e0f63ffee15796ba6135463134084bb370627b,"This paper proposes a method to learn a linear CRF-based model for the task of semantic segmentation of images. The proposed method is based on a combination of a convolutional neural network (CNN) and a linear-chain CRF (CRF). The CNN is used to capture the visual features of the images, while the CRF is used for the contextual features. The model is trained with batch normalization. Experiments are conducted on a dataset of images from a retail store. "
SP:18be2cb182761b64fa232c1b7d1899882e5bcf15,"This paper proposes a generative adversarial network (GAN) to generate high-fidelity and locally-coherent audio by modeling log magnitudes and instantaneous frequencies with sufficient frequency resolution in the spectral domain. The authors demonstrate that GANs are able to outperform strong WaveNet baselines on automated and human evaluation metrics, and efficiently generate audio several orders of magnitude faster than their autoregressive counterparts. "
SP:0c0f078c208600f541a76ecaae49cf9a98588736,"This paper studies the problem of verifying the robustness of neural networks to adversarial perturbations. The authors formulate verification of piecewise-linear neural networks as a mixed integer program, and show that their verifier is two to three orders of magnitude quicker than the state-of-the-art. They achieve this computational speedup via tight formulations for non-linearities, as well as a novel presolve algorithm that makes full use of all information available. The computational speed up allows them to verify properties on convolutional and residual networks with over 100,000 ReLUs. "
SP:dc48dbfb8f4f25d3ceb7be607e8f2e0bc8f99f14,"This paper proposes a novel approach to regularizing the learning in reinforcement learning. The authors propose to enforce information asymmetry between the policy and the default policy. Specifically, the authors restrict the amount of information the policy receives in order to force it to learn reusable behaviors that help the policy learn faster. They also discuss the connection to information bottleneck approaches and the variational EM algorithm. Empirical results are provided to support the effectiveness of the proposed approach."
SP:08a6a48b05e2c00d77a73413cbba52cda08e184c,"This paper proposes FLOWQA, a multi-turn model for conversational machine comprehension. The main idea is to use FLOW to incorporate intermediate representations generated during the process of answering previous questions, through an alternating parallel processing structure. Compared to approaches that concatenate previous questions/answers as input, FLOW integrates the latent semantics of the conversation history more deeply. The proposed model shows superior performance on two recently proposed conversational challenges. The effectiveness of FLOW also shows in other tasks."
SP:fbb7bb8b4f75715f139c702750b28e7e87aa0e1f,"This paper proposes a generative model for predicting future edits to Python source code. The model is based on a two-headed attention network, which is composed of an attention module and a pointer module. The attention module is trained on a synthetic dataset and a large-scale dataset of fine-grained edits from thousands of Python developers. Experiments show that the proposed model is able to predict future edits with high accuracy."
SP:dbb06f953788696f65013765f0a4e6967444fa0f,"This paper proposes a meta-learning method for multi-class classification. The proposed method is based on learning a binary classifier for pairwise similarity prediction. The authors formulate this approach, present a probabilistic graphical model for it, and derive a surprisingly simple loss function that can be used to learn neural network-based models. Experiments on supervised, unsupervised cross-task, and semi-supervised settings demonstrate the effectiveness of the proposed method."
SP:c5c84ea1945b79b70521e0b73f762ad643175020,"This paper studies the problem of interpreting quantifier statements in the context of a visual scene. Specifically, the authors focus on the question of how to interpret the statement “most” in a visual context. To this end, they design experiments to replicate experiments from psycholinguistics where the same question was investigated for humans. Focusing on the FiLM visual question answering model, their experiments indicate that a form of approximate number system emerges whose performance declines with more difficult scenes as predicted by Weber’s law. Moreover, they identify confounding factors, like spatial arrangement of the scene, which impede the effectiveness of this system."
SP:0fb732fe65ef1081b046a6aa6e1972e40cfdc247,"This paper proposes a variational inference approach to learn hyperparameters of DistMult and ComplEx embedding models for link prediction in relational knowledge graphs. The authors argue that knowledge graphs should be treated within a Bayesian framework because even large knowledge graphs typically contain only few facts per entity, leading effectively to a small data problem where parameter uncertainty matters. They introduce a probabilistic reinterpretation of the DistMult (Yang et al., 2015) and Complex (Trouillon et al. 2016) models and employ variational inferential inference to estimate a lower bound on the marginal likelihood of the data. They find that the main benefit of the Bayesian approach is that it allows for efficient, gradient based optimization over hyperparameter, which would lead to divergences in a non-Bayesian treatment."
SP:5ff0668b433a190d87d5833d8b2a8ca04daa299c,"This paper proposes a new algorithm for online dimension reduction. The algorithm is based on the sliced inverse regression (SIR) algorithm, which is able to update the subspace of significant factors with intrinsic lower dimensionality fast and efficiently when new observations come in. The authors also refine the algorithm by using an overlapping technique and develop an incremental overlapping SIR algorithm. Experiments are conducted on two real-world datasets to validate the effectiveness of the proposed method."
SP:4d5b993c6be6e55bdf98eca9a3b23a1bab5d2499,This paper proposes a multimodal factorization model (MFM) for multi-modal representation learning. The MFM decomposes the representation into two sets of independent factors. The discriminative factors are shared across all modalities. The modality-specific factors are unique for each modality and contain the information required for generating data. The experimental results show that the proposed MFM achieves state-of-the-art or competitive performance on six multimodality datasets.
SP:cae76d3c3da91e50fe29cc3b6e204bb3e0793d7e,"This paper proposes a meta-learning approach for adaptive text-to-speech (TTS) with few data. During training, a multi-speaker model is learned using a shared conditional WaveNet core and independent learned embeddings for each speaker. The aim of training is not to produce a neural network with fixed weights, which is then deployed as a TTS system. Instead, the aim is to generate a network that requires few data at deployment time to rapidly adapt to new speakers. The authors introduce and benchmark three strategies: (i) learning the speaker embedding while keeping the waveNet core fixed, (ii) fine-tuning the entire architecture with stochastic gradient descent, and (iii) predicting the embedding with a trained neural network encoder. The experiments show that these approaches are successful at adapting the multi speaker neural network to new speaker, obtaining state-of-the-art results in both sample naturalness and voice similarity with merely a few minutes of audio data from new speaker."
SP:e80d6118fc3b9ff3195fea2f6adac88e59d350c2,This paper studies the robustness of GANs. The authors show that the depth functions that lead to statistically optimal robust estimators can all be viewed as variational lower bounds of the total variation distance in the framework of f-learning. This connection opens the door of computing robust estimator using tools developed for training GAN. 
SP:861c5336fda684e5bdd8a05f0af10dd442bf5339,"This paper presents a method to represent a scene as a symbolic program, where each program represents a collection of objects, attributes, and their relations. The program is represented as a set of symbolic programs, each of which represents a pair of objects and their relation. The authors propose a model that infers such scene programs by exploiting a hierarchical, object-based scene representation. Experiments show that the proposed method works well on synthetic data and transfers to real images."
SP:a8df2aa6870a05f8580117f433e07e70a5342930,"This paper proposes a time-gated LSTM-based recurrent neural network (RNN) architecture with a Gaussian-Gated Time Gate (g-LSTM) for reducing state updates. The time gate controls when a neuron can be updated during training, enabling longer memory persistence and better error-gradient flow. Because the time gate limits the updates of the neuron state, the number of computes needed for the network update is also reduced. By adding a computational budget term to the training loss, the network further reduces the computational budget by at least 10x. Finally, a temporal curriculum learning schedule is proposed to speed up the convergence time of the network on long sequence tasks."
SP:e39bcc2ee6db054f0f1d8e8d04291a78488886ae,"This paper proposes a simple method to detect out-of-distribution samples in deep neural networks. The proposed method is based on computing averages of low-order statistics at the batch normalization layers of the network and then use them as features in a linear classifier. This procedure is much simpler and efficient than current state of the art methods, and outperforms them by a large margin in the traditional ID/OOD fitting task."
SP:827f95cdefae78e38a9c4b5718fcf294606a1989,"This paper studies the problem of model recovery of a one-hidden-layer neural network with sigmoid activations, where the goal is to recover the weight vectors of the neural network. The authors prove that under Gaussian inputs, the empirical risk function using cross entropy exhibits strong convexity and smoothness uniformly in a local neighborhood of the ground truth, as soon as the sample complexity is sufficiently large. This implies that if initialized in this neighborhood, which can be achieved via the tensor method, gradient descent converges linearly to a critical point without requiring a fresh set of samples at each iteration. "
SP:2b4a39b997934ccf0e6b5fcb4d1e62253592b05f,"This paper proposes feature boosting and suppression (FBS), a new method to predictively amplify salient convolutional channels and skip unimportant ones at run-time. FBS introduces small auxiliary connections to existing convolution layers. It preserves the full network structures and accelerates convolution by dynamically skipping unimportant input and output channels. Experiments show that FBS can respectively provide 5x and 2x savings in compute on VGG-16 and ResNet-18."
SP:2b1813a3cc39d6e1eba546b456bf8d1f9cc8657c,"This paper studies the training objective of GANs from the mixed Nash equilibrium perspective. The authors propose a novel two-player GAN framework based on the infinite-dimensional two player game and prove convergence rates to the mixed NE. Then, they propose a procedure to reduce their novel prox methods to simple sampling routines, leading to practically efficient algorithms. Finally, they provide experimental evidence that their approach outperforms methods that seek pure strategy equilibria, such as SGD, Adam, and RMSProp."
SP:79ece684e3c4aca516b4ec41aa8fcb7d86449784,"This paper proposes a method for multi-task learning with deep neural networks. The proposed method is based on patching a small set of parameters that will specialize to each task, instead of fine-tuning the last layer or the entire network. The authors show that learning a set of scales and biases is sufficient to convert a pre-trained network to perform well on qualitatively different problems (e.g. converting a Single Shot MultiBox Detection (SSD) model into a 1000-class image classification model while reusing 98% of parameters of the SSD feature extractor). The authors also show that re-learning existing low-parameter layers (such as depth-wise convolutions) while keeping the rest of the network frozen also improves transfer-learning accuracy significantly."
SP:82b8270b33110e50b5914246f3ca75d3bdbffb6e,"This paper proposes a new normalization method, called mode normalization (MN), which is an extension of batch normalization to more than a single mean and variance. The proposed method first assigns samples in a mini-batch to different modes via a gating network, and then normalizes each sample with estimators for its corresponding mode. The experimental results show that the proposed method outperforms BN and other widely used normalization techniques in several experiments."
SP:034c3bc2b2fe4991f56f168ea7b4b552c500b9ad,"This paper studies the lottery ticket hypothesis, which states that dense, randomly-initialized, feed-forward networks contain subnetworks (winning tickets) that, when trained in isolation, reach test accuracy comparable to the original network in a similar number of iterations. The winning tickets we find have won the initialization lottery: their connections have initial weights that make training particularly effective. The paper shows that sparse pruning is the only method for finding winning tickets. "
SP:08c662296c7cf346f027e462d29184275fd6a102,"This paper proposes a self-supervised reinforcement learning method that uses an attentive dynamics model (ADM) to discover controllable elements of the observations, which are often associated with the location of the character in Atari games. The ADM is trained to predict the actions taken by the agent. The learned contingency information is used as a part of the state representation for exploration purposes. The proposed method is evaluated on a set of challenging Atari games and achieves impressive results."
SP:614f742a75039b1509343d53e0fb4a6d4088ab3e,"This paper proposes HyperGAN, a generative adversarial network that learns to generate all the parameters of deep neural networks. HyperGAN first transforms low dimensional noise into a latent space, which can be sampled from to obtain diverse, performant sets of parameters for a target architecture. The generator is then trained with conventional maximum likelihood (classification/regression) on the parameters it generates, and an adversarial regularization keeps it from collapsing onto only one mode. Experiments on MNIST and CIFAR-10 show that HyperGAN can learn to generate parameters which solve the MNIST dataset with competitive performance to fully supervised learning, while learning a rich distribution of effective parameters. "
SP:230b3e008e687e03a8b914084b93fc81609051c0,This paper studies the problem of training VAEs with discrete valued latent variables. The authors propose a differentiable estimator for the evidence lower bound (ELBO) based on importance sampling. Theoretical analysis is provided to show that the variance of the estimator approaches zero when the latent variables are Bernoulli or Categorically distributed. Experiments are conducted to validate the effectiveness of the proposed method.
SP:153fe1172e689b345729c0c848cfb38bdae0e5f7, adversarial attacks. This paper proposes to use a pre-trained Boltzmann machine for adversarial training. The method is evaluated on the MNIST dataset. The authors show that the adversarial robustness of the proposed method is correlated with the generative performance of the underlying Boltzman machine.
SP:40ade446aa4a700cb1519b9115e8d6cdf33db4a4,"This paper studies the impact of small changes in the size and location of the visible region of a minimal image on human and DNN recognition accuracy. The authors show that a drop in human recognition accuracy due to changes of the region is a common phenomenon between humans and existing state-of-the-art deep neural networks (DNNs), and are much more prominent in DNNs. They also show that this phenomenon is independent from previous works that have reported lack of invariance to minor modifications in the object location in the DNN. The results thus reveal a new failure mode of DNN that also affects humans to a much lesser degree."
SP:8ab0bb3eb38958d607fe6b6ebbd921b8abdf149d,"This paper proposes a multi-agent reinforcement learning method for self-interested agents. In particular, the authors consider a scenario where each agent has its own preferences (preferences, intentions, skills, etc.) and can not be dictated to perform tasks they do not want to do. To solve this problem, they train a super agent (i.e., the manager) to manage these agents by first inferring their minds based on both current and past observations and then initiate contracts to assign suitable tasks to workers and promise to reward them with corresponding bonuses so that they will agree to work together. The proposed method is evaluated in two environments, resource collection and crafting."
SP:50a5e5227932ff1196706f53fb82f1785da45e2a,"This paper proposes a new recurrent neural network (RNN) architecture for time-series. The proposed architecture is based on a recurrent LSTM (TLSTM) that is able to handle sparse and dense features, as well as time features at the sequential level. The authors also introduce two types of static (whole sequence level) features, one related to time and one not, which are combined with the encoder output. The experiments show that the proposed framework can improve performance compared to standard RNNs."
SP:f2c3dd2b485d6307847c759a5609b7ebe24b7058,"This paper presents a top-down neural network model for representing propositional formulas. The model is based on a feedforward neural network recursively built for the given formula in a topdown manner. The results of this network are then processed by two recurrent neural networks. One of the interesting aspects of this model is how propositional atoms are treated. For example, the model is insensitive to their names, it only matters whether they are the same or distinct. "
SP:845ae21e5758a8aabfa610c291fdcc5f61af7748,"This paper studies the problem of curriculum learning in the context of training CNNs. Specifically, the authors propose a new method of sampling mini-batches with a gradually increasing level of difficulty to improve the speed of learning and improve the final accuracy of the trained network. The authors first define the difficulty of a training image using transfer learning from some competitive “teacher” network trained on the Imagenet database, showing improvement in learning speed and final performance for both small and competitive networks, using the CIFAR-10 and Cifar-100 datasets. They then suggest a bootstrap alternative to evaluate the difficulties of points using the same network without relying on a ”teacher network”, thus increasing the applicability of their suggested method."
SP:b33a6a1fe4bbae422ba001cbe656f31d07a62025,"This paper proposes a general PAC-Bayesian framework to provide a generalization bound on a deterministic and uncompressed neural network. The authors show that if on training data, the interactions between the weight matrices satisfy certain conditions that imply a wide training loss minimum, these conditions also generalize to the interaction between the matrices on test data, thereby implying a wide test loss minimum. They then apply their general framework in a setup where we assume that the pre-activation values of the network are not too small (although we assume this only on the training data). In this setup, they provide a bound on the original (deterministic, uncompressed) network that does not scale with product of the spectral norms of the weights matrices. "
SP:d0533cb69d938d4128d17b1a6d8aeb8d1ca6e3fd,This paper proposes a new training method for vector quantized autoencoder (VQ-VAE) based on the Expectation Maximization (EM) algorithm. The main idea is to use EM to train a discrete latent variable model and then combine it with a sequence-level knowledge distillation method to improve the performance of the model. The experiments show that the proposed method is able to outperform the vanilla VAE model while being 3.3 times faster at inference time.
SP:60628f7db9cfcac3f0dbe6ce0b2a161310525ba0,"This paper proposes a multi-view learning framework for learning sentence representations in an unsupervised fashion. The authors propose a generative objective and a discriminative objective to learn the representation of the input sentence. In the first framework, an RNN-based encoder is used to encode the sentence, while in the second framework, a simple linear model is used as the encoder. Experiments are conducted on three large unlabelled corpora to show the effectiveness of the proposed framework."
SP:f5da908b5f6c19a059d2447b9cda15af5e12dc55,"This paper proposes an online distributed optimization method called Anytime Minibatch (AMB) to mitigate the impact of stragglers in distributed optimization. In AMB, each node is given a fixed time to compute the gradients of as many data samples as possible. Workers then get a fixed communication time to average their minibatch gradients via several rounds of consensus, which are then used to update primal variables via dual averaging. The authors provide a convergence analysis and analyze the wall time performance. Numerical results show that AMB is up to 1.5 times faster in Amazon EC2."
SP:f167ad4bb1e140f692ec71c8baf0a59bff7bbc6f,This paper presents a novel approach to reinforcement learning that leverages a task-independent intrinsic reward function trained on peripheral pulse measurements that are correlated with human autonomic nervous system responses. The authors claim that such reward functions can circumvent the challenges associated with sparse and skewed rewards in reinforcement learning settings and can help improve sample efficiency. They test this in a simulated driving environment and show that it can increase the speed of learning and reduce the number of collisions during the learning stage.
SP:2db0ece25ebfb4d5e3aa8eb145964ce4be19409f,This paper proposes an extension of Neural Processes (NP) to the context-conditioned regression setting. The main idea is to add a self-attention mechanism to the decoder of the original NP to improve the prediction accuracy. The proposed method is evaluated on 1D function regression and 2D image regression tasks. 
SP:26535b26a3178050d8aae56b7c9669c9d2408ac8,"This paper studies the problem of meta-reinforcement learning in the context of gradient-based meta-learning. The authors provide a theoretical analysis of the credit assignment problem in meta-policy search and propose ProMP, an algorithm that uses the low variance curvature (LVC) as a surrogate objective to estimate the gradient of the policy update. The proposed method is evaluated on a variety of continuous control tasks. "
SP:be5f2c827605914206f5645087b94a50f59f9214,"This paper presents a neural network architecture that is able to solve SAT problems after being trained as a classifier to predict satisfiability. The proposed method is based on a message-passing neural network (MNT) architecture, which is trained on a set of randomly generated SAT problems. The paper shows that the proposed method can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. "
SP:a99fddee87b684b2783ef3a21f8c15c19631953b,This paper proposes a method to train a policy for autonomous driving via imitation learning that is robust enough to drive a real vehicle. The authors propose to augment the imitation loss with additional losses that penalize undesirable events and encourage progress. They show that the proposed method can handle complex situations in simulation and demonstrate the model driving a car in the real world.
SP:f5be102f16ed9ac70a2e9e2580111226fb0d8b71,"This paper proposes a method to select a subset of training data to reduce the training time of large deep models while maintaining the predictive performance. The proposed method first trains a small proxy model to estimate the utility of individual training data points, and then select the most informative ones for training the large target model. Experiments are conducted on CIFAR-10 and SVHN to demonstrate the effectiveness of the proposed method."
SP:4332dfe46b715595e9f1dd3f6a79b82a646b4c23,"This paper proposes a new planning algorithm for continuous control tasks based on Monte-Carlo Monte Carlo (MCMC) and Bayesian smoothing. The main idea is to view the planning problem as a probabilistic inference problem over future optimal trajectories, and to use sampling methods to estimate the posterior distribution. The authors also propose a method to combine model-free and model-based reinforcement learning for planning based on the SMC perspective. Experiments are conducted on Mujoco to demonstrate the effectiveness of the proposed method."
SP:d3e4e2c267fd9ae536ab1816d5c1ba8e8fec19be,"This paper studies the relationship between adversarial robustness and the input data distribution. The authors show that adversarial training is sensitive to the input distribution, unlike clean accuracy. Even a semantics-preserving transformations on the data distribution can cause a significantly different robustness for the adversarial trained model that is both trained and evaluated on the new distribution. Empirical investigations confirm the finding."
SP:a49fd0479a977c8fb45199210f9ff7dd2c0dabaf,"This paper proposes a new normalization technique called Equilibrium normalization (EquiNorm), which is a normalization that works in weight space and still uses a form of batch statistics unlike previous weight space approaches. The authors show that EquiNorm results in very rapid convergence, even more so than BatchNorm, however as they will show in their experiments, this also results in a tendency to overfit. "
SP:8188f15c8521099305aa8664e05f102ee6cea402,"This paper proposes a novel method to detect mislabeled examples in the training of deep neural networks. The proposed method is based on the observation that the implicit regularization effect of stochastic gradient descent with large learning rates can be leveraged to identify examples with high loss statistics and discard them on the fly. This leads to ON-THE-FLY DATA DENOISING (ODD), a simple yet effective algorithm that is robust to mislabeling examples while introducing almost zero computational overhead. Empirical results demonstrate the effectiveness of ODD on several datasets containing artificial and real-world mislabelled examples."
SP:fbf023a772013e6eca62f92982aecf857c16a428,"This paper provides a theoretical analysis of the pretraining and downstream tasks with an underlying latent variable generative model of text — the downstream classifier must recover a function of the posterior distribution over the latent variables. They analyze head tuning (learning a classifier on top of the frozen pretrained model) and prompt tuning in this setting. They show that under certain non-degeneracy conditions on the HMM, simple classification heads can solve the downstream task. They also show that prompt tuning obtains good downstream performance when our nondegenerate conditions are relaxed, whereas head tuning performs poorly."
SP:217c4205a99f9b37283137826c4be6ab9bfb4e8e,"This paper studies the problem of out-of-distribution generalization in the domain generalization setting. The authors propose a new notion of transferability, which they define as the difference and connection with common discrepancy measures between domains, such as total variation and Wasserstein distance. They then prove that our transferability can be estimated with enough samples and give a new upper bound for the target error based on the transferability. Finally, they propose an algorithm for learning transferable features and test it over various benchmark datasets."
SP:46f5874c8cbdb0832e92adcea85ca8a1b9ddc28a,"This paper studies the expressivity of reward as a way to capture tasks that we would want an agent to perform. The authors frame this study around three abstract notions of “task” that might be desirable: (1) a set of acceptable behaviors, (2) a partial ordering over behaviors, or (3) an ordering over trajectories. Their main results prove that while reward can express many of these tasks, there exist instances of each task type that no Markov reward function can capture. They then provide a polynomial-time algorithms that construct a reward function that captures tasks of each of these types, and correctly determine when no such reward function exists. An empirical study corroborates and illustrates their theoretical findings."
SP:9d8b57d60a0e59f9d9a90605094e8ef895f1c7de,"This paper studies the problem of generalization in reinforcement learning. The authors show that generalization to unseen test conditions from a limited number of training conditions induces implicit partial observability, effectively turning even fully-observed MDPs into POMDPs. Based on this observation, the authors recast the generalization problem in RL as solving the induced partially observed Markov decision process, which they call the epistemic decision process (POMDP). The authors demonstrate the failure modes of algorithms that do not appropriately handle this partial observable problem, and suggest a simple ensemble-based technique for approximately solving the partially observed problem. Empirically, the proposed algorithm LEEP achieves significant gains in generalization over current methods on the Procgen benchmark suite."
SP:10de45510320b7ddb7ffb18b33e67f7cad609418,"This paper studies the problem of estimating the Hessian matrix of value functions for model-agnostic meta-reinforcement learning. The authors propose a unified framework for estimating higher-order derivatives of the value functions based on off-policy evaluation. The proposed framework unifies a number of prior approaches and elucidates the bias and variance trade-off of Hessian estimates. This framework also opens the door to a new family of estimates, which can be implemented with auto-differentiation libraries, and lead to performance gains in practice."
SP:54a60315416c6e304f59741490c335fb1e2ce95d,"This paper studies the problem of federated learning with a central server. The authors propose a new algorithm that performs bidirectional compression and achieves the same convergence rate as algorithms using only uplink (from the local workers to the central server) compression. The main contribution of this paper is to design MCM, an algorithm such that the downlink compression only impacts local models, while the global model is preserved. The convergence of the proposed algorithm is proved. "
SP:6b19f16c429ffa7f613b57d082bde3794a8e29e0,"This paper studies the problem of ‘stress testing’, i.e., perturbing irrelevant parts of the input data and seeing if model predictions change. The authors introduce counterfactual invariance as a formalization of the requirement that changing irrelevant parts should not change model predictions. They connect counterfactually invariance to out-of-domain model performance, and provide practical schemes for learning counterfactuality invariant predictors. "
SP:6ff26839a14991597555ead4c82eb6ddb61e4dbc,"This paper proposes Adaptive Pseudo Augmentation (APA) to alleviate the problem of discriminator overfitting in training GANs with limited data. APA employs the generator itself to augment the real data distribution with generated images, which deceives the discriminator adaptively. Extensive experiments demonstrate the effectiveness of APA in improving synthesis quality in the low-data regime. "
SP:0f3fcffb6dfbf344bd5ef73c3f6d3d84d2f13887,"This paper proposes a method for causal inference between pairs of event variables in multivariate recurrent event streams by extending Rubin’s framework for the average treatment effect (ATE) and propensity scores to multivariate point processes. The authors theoretically justify their point process causal framework and show how to obtain unbiased estimates of the proposed measure. They conduct an experimental investigation using synthetic and real-world event datasets, where the proposed method is shown to exhibit superior performance against a set of baseline pairwise causal association scores."
SP:5db39fbba518e24a22b99c8256491295048ec417,"This paper studies the relationship between residual connections in the message passing of GNNs and their vulnerability to abnormal node features. The authors analyze possible reasons to understand this phenomenon and propose a simple, efficient, interpretable, and adaptive message passing scheme, leading to a novel GNN with Adaptive residual, AirGNN1. Extensive experiments under various abnormal feature scenarios demonstrate the effectiveness of the proposed algorithm."
SP:66c5acd36a5fb74478d3f5ecaffc8479868dbe81,"This paper proposes a variational Bayesian Optimistic Sampling (VBOS) algorithm for online sequential decision problems. The main idea is to define a set of Bayesian ‘optimistic’ policies which, in the stochastic multi-armed bandit case, includes the Thompson sampling policy. The authors provide a new analysis showing that any algorithm producing policies in the optimistic set enjoys Bayesian regret for a problem with A actions after T rounds. They extend the regret analysis for optimistic policies to bilinear saddle-point problems which include zero-sum matrix games and constrained bandits as special cases."
SP:c1b7b550b9f90bd5e9bf5218e22d1977ed1686a5,"This paper studies the convergence analysis and rates of variance reduction under without-replacement sampling orders for composite finite-sum minimization. The authors develop a damped variant of Finito called Prox-DFinito and establish its convergence rates with random reshuffling, cyclic sampling, and shuffling-once, under both convex and strongly convex scenarios. These rates match full-batch gradient descent and are state-of-the-art compared to the existing results for without replacement sampling with variance reduction. "
SP:35c14ef59d9ed68f3f6e3a8cac95fdf3216a9d8f,"This paper studies the convergence of policy optimization methods for the REPS objective in reinforcement learning. In particular, the authors provide convergence rates of $O(1/\epsilon^2)$ for accelerated gradient descent on the dual of the KL-regularized max-return LP in the case of a known transition function with convergence rate. For the unknown case, they propose a biased stochastic gradient descent method relying on samples from behavior policy and show that it converges to an optimal policy with rate $O(\sqrt{1/8})$. "
SP:3945d1fb07900d63b7706ca0bce5e451ebfe476b,"This paper studies the vulnerability of deep neural networks (DNNs) for 3D point cloud processing. The authors propose a method to disentangle the overall model vulnerability into the sensitivity to the rotation, the translation, the scale, and local 3D structures. Besides, they also propose metrics to evaluate the spatial smoothness of encoding 3D structure, and the representation complexity of the DNN. Based on such analysis, experiments expose representation problems with classic DNNs and explain the utility of the adversarial training."
SP:81db7f494ca61d3586adb505bf5d2e6e9e2c2bd0,"This paper proposes a neural network-based auction mechanism that is able to capture human preferences for fairness constraints in auction design. The proposed method is an extension of RegretNet, which is an existing neural network based auction mechanism. The main contribution of this paper is to introduce a new metric to evaluate an auction allocation’s adherence to socially desirable constraints and demonstrate that it is competitive with current state-of-the-art neural-network based auction designs. The authors validate their approach through human subject research."
SP:ee24606a968ab17b7827e7f3982af11636f6a2ee,"This paper studies the problem of personalized supervised learning with user-level differential privacy. The authors formulate the problem as a linear regression problem with each user’s regression vector lying in a common, unknown low-dimensional subspace. They provide algorithms that exploit popular non-private approaches in this domain like the Almost-No-Inner-Loop (ANIL) method, and give strong user level differential privacy guarantees for their general approach. They also establish a general, information-theoretic upper bound via an exponential mechanism-based algorithm. "
SP:3925fc528de17b8b2e93808f5440ea0503895b75,"This paper proposes a new benchmark for visual question answering, Adversarial VQA (AdVQA), which is a human-adversarial multimodal dataset designed to accelerate the progress on Visual Question Answering. The dataset consists of a set of questions and answers, where each question and answer is asked by a human annotator to find a question in the dataset where the model’s predicted answer is incorrect. The authors show that a wide range of state-of-the-art models perform poorly when evaluated on these examples. They also provide an analysis of the collected adversarial examples and provide guidance on future research directions."
SP:04f90c10f4ceca0dace727ad875265ce405fff9f,"This paper studies the role of heterogeneous cell types in the medial entorhinal cortex (MEC). The authors show that heterogeneous MEC cells are just as reliable in their response patterns as the more stereotypical cell types, suggesting that they have a coherent functional role. Then, they evaluate a spectrum of candidate models in terms of their ability to describe the response profiles of both stereotypical and heterogeneous cells. They find that recently developed task-optimized neural network models are substantially better than traditional grid cell-centric models at matching most MEC neuronal response profiles — including those of grid cells themselves — despite not being explicitly trained for this purpose."
SP:57f9812fa5e7d0c66d412beb035301684d760746,"This paper studies the problem of learning from expert demonstrations in the context of reinforcement learning with KL-regularized reinforcement learning (RL). The authors show empirically that the pathology occurs for commonly chosen behavioral policy classes and demonstrate its impact on sample efficiency and online policy performance. Finally, the authors propose to use non-parametric behavioral reference policies to remedy the pathology and demonstrate the effectiveness of their approach on a variety of tasks."
SP:cb38b58054581db865d8c2a4065f062724ca0a5e,"This paper studies the learning curve exponents of a teacher-student framework for kernel regression with neural tangent kernels. In particular, the authors consider the case where the input x is a d-dimensional input and xi denotes the i-th t-dimensional patch of x, xi = (xi,..., xi+t-1). i ranges in a subset P of {1,..., d}. The gi’s and g are random functions of t variables whose smoothness is controlled by some exponent αt. The goal is to compute the asymptotic decay of the error of a student kernel performing regression on such data, and to relate the corresponding exponent beta to the locality of the target function. The paper shows that, even in large dimension d, a function can be learned efficiently if it can be expressed as a sum of constituent functions each depending on a smaller number of variables t, by performing regression with a kernel that entails such a compositional structure with s-dimensional constituents. The learning curve exponent is independent of d and governed by s if s < t, optimal for s= t and null if s< t. "
SP:7e35e4e610e75c922f2b5219ce625e417f010eeb,"This paper proposes a method to train a VAE-like model with a variational autoencoder (VAE) based on a deterministic training procedure. The method is motivated by the fact that VAEs have a strong prior assumption that the latent representations learned by the model follow a simple uni-modal Gaussian distribution. The authors propose a simple and end-to-end trainable deterministic learning framework, that efficiently shapes the latent space of the model during training and utilizes the capacity of expressive multimodal latent distributions. The proposed training procedure provides direct evidence if the latent distribution adequately captures complex aspects of the encoded data. "
SP:6232d8738592c9728feddec4462e61903a17d131,This paper proposes an autoencoder-based self-supervised adversarial detection method that disentangles input images as class features and semantic features by disentangling autoencoders with a discriminator network. The discriminator is trained over correctly paired class/semantic features to reconstruct benign and adversarial examples. The proposed method is evaluated on CIFAR-10 and ImageNet under different adversarial attacks. 
SP:e9d9ad4fb9dc3cb25f7282c0979a8ccb252f692a,"This paper presents a method to model the brain's representation of syntactic structure. The method is based on embedding syntactic features in a contextual word embedding space and using these embeddings and fMRI recordings of participants reading a natural text to learn the brain representation of syntax. The authors show that their syntactic embedding-based features explain additional variance in the brain activity of various parts of the language system, even after controlling for complexity metrics that capture processing load. They also show that regions well-predicted by syntactic feature are distributed in the language systems and are not distinguishable from those processing semantics."
SP:b4ad4632cd55a85b5403e936c4bd828e484473f7,"This paper proposes a method for controllable image generation based on energy-based models (EBMs). The authors propose a novel EBM formulation to represent the joint distribution of data and attributes together, and show how sampling from it is formulated as solving an ordinary differential equation (ODE) given a pre-trained generator. Sampling with ODEs is done efficiently in the latent space and is robust to hyperparameters. Experimental results show that the proposed method outperforms the state-of-the-art in both conditional sampling and sequential editing. "
SP:f5bf6d43bcc90a3bc5f2157fcc041f18224f95e0,"This paper studies the problem of federated linear contextual bandits, where each client faces K-armed stochastic bandits coupled through common global parameters. The authors propose Fed-PE, a collaborative algorithm to cope with the heterogeneity across clients without exchanging local feature vectors or raw data. The proposed algorithm relies on a novel multi-client G-optimal design, and achieves near optimal regret for both disjoint and shared parameter cases with logarithmic communication costs. Experiments are conducted on both synthetic and real-world datasets. "
SP:d3ff3012c614638c8d86322cfe461a9383f082ab,This paper proposes a new offline model-based offline RL algorithm called COMBO. The main idea is to regularize the value function for out-of-support state-action tuples by penalizing the Q-values evaluated on such tuples. The authors show that COMBO achieves a conservative Q-function that is less conservative than prior model-free offline RL methods and guarantees a safe policy improvement. Experiments are conducted to demonstrate the effectiveness of the proposed method.
SP:ca6f11ed297290e487890660d9a9a088aa106801,"This paper studies the effect of local elasticity on the training dynamics of deep neural networks. Specifically, the authors study the impact of back-propagation on the features of samples from different classes when training neural networks using stochastic gradient descent (SGD). Specifically, they model the evolution of features during deep learning training using a set of SDEs that each corresponds to a training sample. Each SDE contains a drift term that reflects the impact on features of an input sample. The main finding of the paper is that if the SDE is locally elastic (i.e., the impact is more significant on samples from the same class as the input) then features of the training data become linearly separable, meaning vanishing training loss; otherwise, the features are not separable regardless of how long the training time is. Moreover, an analysis of our SDE shows that the emergence of a simple geometric structure called the neural collapse of the features."
SP:a1cb0ca55bc919125f4dad5bcc6e0ad6c2527c1e,"This paper proposes a framework for learning to synthesize a program that can solve a given task. The authors propose to first learn a program embedding space that continuously parameterizes diverse behaviors in an unsupervised manner, and then search over the learned program embeddings space to yield a policy that maximizes the return for a given problem. The experiments show that the proposed framework outperforms DRL and program synthesis baselines."
SP:4be92f235a78f030c4f09c920dc41eab0ba69aa8,"This paper analyzes the physics-informed neural network (PINN) method for learning differential equations. The authors show that the soft regularization in PINNs, which involves PDE-based differential operators, can introduce a number of subtle problems, including making the problem more ill-conditioned. They also show that these possible failure modes are not due to the lack of expressivity in the NN architecture, but that the PINN’s setup makes the loss landscape very hard to optimize. They then describe two promising solutions to address these failure modes. "
SP:cfd501bca783590a78305f0592f537e8f20bce27,"This paper proposes Cycle Self-Training (CST), a self-training method for unsupervised domain adaptation (UDA) that explicitly enforces pseudo-labels to generalize across domains. CST cycles between a forward step and a reverse step until convergence. In the forward step, CST generates target pseudo-label with a source-trained classifier, and then updates the shared representations to make the target classifier perform well on the source data. The authors also introduce the Tsallis entropy as a confidence-friendly regularization to improve the quality of target pseudo labels. They analyze CST theoretically under realistic assumptions, and provide hard cases where CST recovers target ground truth, while both invariant feature learning and vanilla self training fail."
SP:af51c83f2f16cbbd4eb087adb978d7dc1c2d7d76,"This paper proposes a new method for structured pruning of neural networks. The proposed method is based on discriminative masking, where a discriminator is trained to select which neurons should be refined and which ones should be pruned during the training process. The authors show that the proposed method can be applied to a variety of tasks, including dimensionality reduction, recommendation system, graph representation learning, and structured network pruning for image classification. They also theoretically show that their method is related to minimizing the L0 norm of the discriminator. "
SP:f831d25830efa88434b43e900241a5ad81119360,"This paper proposes a self-attention-based architecture called Neural Interpreter that can be applied on arbitrary set-valued inputs or representations. The input is routed through a sequence of functions in a way that is end-to-end learned. The proposed architecture can flexibly compose computation along width and depth, and lends itself well to capacity extension after training. Experiments are conducted on image classification and visual abstract reasoning on Raven Progressive Matrices. "
SP:b78c78fd0b10a94466c049e97c59a56ea5455df6," of reinforcement learning. This paper proposes a new method called Behavior Transfer (BT) that leverages pre-trained policies for exploration and that is complementary to transferring neural network weights. The experiments show that, when combined with large-scale pre-training in the absence of rewards, existing intrinsic motivation can lead to the emergence of complex behaviors. "
SP:8f0eb77f64b185627b7a82005e0b9e368197c8cd,"This paper proposes PiRank, a new class of differentiable surrogates for ranking, which employ a continuous, temperature-controlled relaxation to the sorting operator based on NeuralSort. The authors show that PiRank exactly recovers the desired metrics in the limit of zero temperature and further propose a divide-and-conquer extension that scales favorably to large list sizes, both in theory and practice. Empirically, the authors demonstrate the role of larger list sizes during training and show that piRank significantly improves over comparable approaches on publicly available internet-scale learning-to-rank benchmarks."
SP:c4d1c99a2d53e90336c7e110738bc1eb8a38f3b4,"This paper proposes a reinforcement learning algorithm for the problem of estimating the ground-state energy of a variational quantum entanglement. The algorithm is based on a curriculum learning approach, where the learner is encouraged to explore the space of possible economic circuits to find the one that yields the most accurate ground state energy estimate. The method is evaluated on the LiH energy estimation problem, showing state-of-the-art results."
SP:4fc9a0b34192e1b3587c8e2128851c6aebddd26b,"This paper studies the problem of transductive few-shot learning. The authors argue that the class-balanced setting is unrealistic, as it assumes that the marginal label probability of the testing samples is known and fixed to the uniform distribution. In fact, in realistic scenarios, the unlabeled query sets come with arbitrary and unknown label marginals. To address this issue, the authors propose to model the marginal probabilities of the classes as Dirichlet-distributed random variables, which yields a principled and realistic sampling within the simplex. Empirically, they show that the proposed method outperforms state-of-the-art methods across several data sets, models and settings."
SP:eb760d20f3820827c41358ff191d22f4fb78847e,"This paper proposes a patch-based patch-by-patch inference scheduling to reduce the memory usage for tiny deep learning by up to 8x. The authors also propose receptive field redistribution to shift the receptive field and FLOPs to the later stage and reduce the computation overhead. They automate the process with neural architecture search to jointly optimize the neural architecture and inference scheduling, leading to MCUNetV2. "
SP:b147639f58dd3197beb928c609d636e853c6bdd6,"This paper studies the problem of finding an optimal mechanism that maximizes the utility of the principal in the face of a self-interested strategic agent in an unstructured dynamic environment. The authors provide an efficient algorithm for computing optimal mechanisms, with or without payments, under different individual-rationality constraints, when the time horizon is constant. The algorithm is based on a sophisticated linear program formulation, which can be customized in various ways to accommodate richer constraints. For environments with large time horizons, the authors show that the optimal utility is hard to approximate within a certain constant factor, complementing the algorithmic result."
SP:1c9c01a77aee3bf00e33bffd6be9ec49d2e5ba29,"In this paper, the authors study the problem of neural architecture search (NAS) for graph neural networks (GNNs). The authors propose a differentiable architecture search method, called GASSO, which allows differentiable search of the architecture with gradient descent and is able to discover graph neural architectures with better performance through employing graph structure learning as a denoising process in the search procedure. The authors conduct theoretical analysis and measurement study with experiments to discover that gradient based NAS methods tend to select proper architectures based on the usefulness of different types of information with respect to the target task. "
SP:1ff7a4f6f2ef647b7a9d224f8250b46b7935359a,"This paper studies the problem of fair clustering, i.e. a clustering problem where a dataset is partitioned into clusters that consist of nearby points in a metric space. The authors consider two fairness objectives: the group utilitarian objective and the group egalitarian objective, as well as the group leximin objective. They derive fundamental lower bounds on the approximation of the utilitarian and egalitarian objectives and introduce algorithms with provable guarantees for them. They further derive impossibility results for other natural fairness objectives. "
SP:581faa3e1fd39ddefc2740985fa8f94cacdf2b64,"This paper studies the limitations of edge independent random graph models, in which each edge is added to the graph independently with some probability. The authors prove that subject to a bounded overlap condition, edge independent models are inherently limited in their ability to generate graphs with high triangle and other subgraph densities. They complement their negative results with a simple generative model that balances overlap and accuracy, performing comparably to more complex models in reconstructing many graph statistics."
SP:0d77c22df0830cb675b11ad883d014e3a1933c8e,"This paper studies the effect of the choice of ReLU(0) in [0,1] for a neural network on backpropagation and training. In particular, the authors investigate the importance of the ReLU activation function for different precision levels (16, 32, and 64 bits) on various networks (fully connected, VGG, ResNet) and datasets (MNIST, CIFAR10, SVHN, and ImageNet). They observe considerable variations of backprop-like outputs which occur around half of the time in 32 bits precision. The effect disappears with double precision, while it is systematic at 16 bits. For vanilla SGD training, the choice ReLU($0) = 0 seems to be the most efficient. "
SP:73e6281bf556a6ae92bdcf8d68e6e8973bc8b56b,"This paper proposes a method called Robust Predictable Control (RPC) for learning policies that use few bits of information. The main idea is to jointly optimize a latent space model and a policy to be self-consistent, such that the policy avoids states where the model is inaccurate. The authors show that their method achieves better compression than prior methods and learns policies that are robust and generalize well to new tasks."
SP:dff08f0b290f3d138fd0299933052f3dc363b2d3,"This paper proposes a new transformer-based architecture for graph representation learning. The proposed method is based on a learned positional encoding (LPE) that can take advantage of the full Laplacian spectrum to learn the position of each node in a given graph. This LPE is then added to the node features of the graph and passed to a fully-connected Transformer. By leveraging the full spectrum of the Laplace spectrum, the proposed model is theoretically powerful in distinguishing graphs, and can better detect similar sub-structures from their resonance. The experimental results show that the proposed method outperforms other attention-based models by a wide margin."
SP:f2bee0c4a6c558970538b422e5e36750447cd9bc,"This paper studies the problem of two-alternative elections where each voter receives a private signal that is correlated to the state variable. The authors propose a mechanism that aggregates and aggregates the private signals from the voters, and outputs the alternative that is favored by the majority. In particular, voters truthfully reporting their signals forms a strong Bayes Nash equilibrium (where no coalition of voters can deviate and receive a better outcome). "
SP:0823bd0dbb8045648e81a4c93e9782069cf2c605,"This paper analyzes the rank of the Hessian of a neural network. The authors show that the rank is proportional to the width of the layers, which is a result of the structure of the network. They show that this is the case for deep linear networks and show that it is also true for rectified networks and hyperbolic tangent networks. They also show that their results are faithful as an estimate of the numerical Hessian rank. "
SP:24cdcb12fca34680d8b34bc61c51b9003368228a,"This paper proposes a new metric to quantify the disentanglement of linear disentangled representations (LSBD). The metric is based on the notion of linear symmetry-based disentangling (LSD) and the authors also propose a method to learn LSBD representations based on this metric. The authors demonstrate the utility of their metric by showing that common VAE-based methods don’t learn LSD representations, LSBD-VAE as well as other recent methods can learn LSDD representations. "
SP:374bfeb067fcea966c97e1721d65cd9d03d26ed3,"This paper proposes a constrained optimisation framework for deep state-space models (DSSMs) to learn the underlying dynamics of observed sequence data. The authors propose a general Lagrangian formulation of the sequential ELBO on the basis of distortion and rate, and extend the empirical Bayes prior (VHP) and the associated optimisation algorithm introduced in the context of VAEs to DSSMs. Then, the authors introduce the extended Kalman VAE (EKVAE), which combines amortised variational inference with classic Bayesian filtering/smoothing to model dynamics more accurately than RNN-based DSSM. The experimental results show that the proposed method outperforms previous models w.r.t. prediction accuracy. "
SP:15ed638782cc0398df38ec49eed5c5ca9962d3b9,"This paper proposes a method for generating counterfactual explanations for black-box classifiers. The method is based on deep model inversion, where a generator is trained to generate explanations for a given query image. Different from previous methods, the authors propose to use different image priors and manifold consistency constraints, along with a progressive optimization strategy, to learn a CF generator on-the-fly to synthesize highly-plausible explanations. Experiments on natural image and medical image classifiers demonstrate the effectiveness of the proposed method."
SP:e536acfe82bb5e41fa61929d44dad0b8f7c5ab19,"This paper studies the problem of identifying regions of decision-maker disagreement in the decision-making process. The authors propose a causal inference algorithm to find the region where the assignment of decision maker has a large causal effect on the decision. The algorithm is based on maximizing an empirical objective, and the authors provide a generalization bound for its performance. In a semi-synthetic experiment, they show that their algorithm recovers the correct region of disagreement accurately compared to baselines. Finally, they apply their algorithm to real-world healthcare datasets, recovering variation that aligns with existing clinical knowledge."
SP:8fa76926a21fb41c5c9fd357246c06a42ae26b9f,"This paper proposes a token-based generative model for image synthesis. The key idea is to use a Transformer-based token generator to model the style and content of an image. Specifically, the token generator takes as input a sequence of latent tokens to predict the visual tokens for synthesizing an image, i.e., the style tokens and the content tokens from the latent space. The token generator is able to control the image synthesis by assigning the styles to the content token by attention mechanism with a transformer. Experiments are conducted on FFHQ and LSUN CHURCH to demonstrate the effectiveness of the proposed method."
SP:fa34d40d07c0f154a69841b241a2743fe721f95c,"This paper studies the effect of ridge regularization on the robust risk of linear regression and logistic regression. In particular, the authors show that, even in the absence of noise, avoiding interpolation through ridge regularisation can significantly improve generalization. The authors prove this phenomenon for the overparameterized linear models, and hence provide the first theoretical result on robust overfitting. "
SP:09f080f47db81b513af26add851822c5c32bb94e,"This paper proposes a self-supervised method for learning dense correspondences between 3D shapes of the same category. The method is based on a canonical point autoencoder (CPAE) that encodes an arbitrarily ordered point cloud to a canonical primitive, e.g., a sphere, and decodes the primitive back to the original input instance shape. The proposed method can handle unaligned input point clouds within a certain rotation range. Experiments on 3D semantic keypoint transfer and part segmentation transfer show that the proposed method outperforms state-of-the-art methods."
SP:8f28988012f8dca74c90316f7feeda15d49af2c5,"This paper proposes a new method for domain generalization (DG) called Stochastic Weight Averaging Densely (SWAD) to find flatter minima and suffers less from overfitting than does the vanilla SWA by a dense and overfit-aware stochastic weight sampling strategy. SWAD shows state-of-the-art performances on five DG benchmarks, namely PACS, VLCS, OfficeHome, TerraIncognita, and DomainNet, with consistent and large margins of +1.6% averagely on out of domain accuracy. The authors also compare SWAD with conventional generalization methods, such as data augmentation and consistency regularization methods to verify that the remarkable performance improvements are originated from by seeking flat minima, not from better in-domain generalizability."
SP:5068e491ee0ae7282cd98ef966b471389e2ab069,"This paper provides a large-scale study of performance predictors for neural architecture search (NAS) by analyzing 31 techniques ranging from learning curve extrapolation, to weight-sharing, to supervised learning, to zero-cost proxies. They test a number of correlation and rank-based performance measures in a variety of settings, as well as the ability of each technique to speed up predictor-based NAS frameworks. Their results act as recommendations for the best predictors to use in different settings, and they show that certain families of predictors can be combined to achieve even better predictive power."
SP:c883fe9c7f4a5f950340ac79b6d7194278b1a1eb,"This paper studies the privacy of posterior sampling from a Dirichlet posterior distribution. In particular, this paper focuses on the case where the posterior distribution is Dirichlets. The privacy guarantee is based on the notion of truncated concentrated differential privacy (tCDP), which is a special case of the truncated convex combination of differential privacy. The paper provides privacy guarantees for two special cases of the posterior sampling, i.e., private normalized histogram publishing and private normalized normalized histograms. "
SP:aaea75b9c614f77e8025922780f9a8dd9c9d4aab,"This paper proposes a new algorithm to compute random walks efficiently and locally at the same time. The authors show that their algorithm is both memory and round efficient, and yields an efficient parallel local clustering algorithm. Finally, the authors provide experimental results to demonstrate the effectiveness of their algorithm. "
SP:5739081ab7aaf71d389705c28f14a316fbb0a728,"This paper analyzes the typical learning performance of the L1-regularized linear regression (`1-LinR) for Ising model selection using the replica method from statistical mechanics. For typical random regular graphs in the paramagnetic phase, an accurate estimate of the typical sample complexity is obtained. Moreover, the paper provides an efficient method to accurately predict the nonasymptotic behavior of `1- LinR for moderate M,N. "
SP:9d6202ab0010166f383d6d064aebe02ae97a1dfc,"This paper studies the fuzzy k-means problem, which is a generalization of the well-known soft k means problem. The authors propose a semisupervised active clustering framework, where the learner is allowed to interact with an oracle (domain expert), asking for the similarity between a certain set of chosen items. They prove that having a few of such similarity queries enables one to get a polynomial-time approximation algorithm to an otherwise conjecturally NP-hard problem. In particular, they provide algorithms for fuzzy clustering in this setting that ask O(poly(k) log n) similarity queries and run with polynomially time complexity, where n is the number of items."
SP:a8057c4708dceb4f934e449080043037a70fabf7,This paper proposes a self-consistency-based reinforcement learning algorithm to improve model-based RL by encouraging a learned model and value function to be self-convergent. The proposed algorithm is based on the idea of learning a model that is consistent with the environment and a value function that is also consistent with this model. The algorithm is evaluated in both tabular and function approximation settings and is shown to improve policy evaluation and control. 
SP:cd01ab8f03cfb1bb067478ca82944d3a42826ca4,"This paper studies the sampling strategy for few-shot episodic training. The authors propose a sampling strategy based on the difficulty of the episodes. They show that sampling uniformly over episode difficulty outperforms other sampling schemes, including curriculum and easy-/hard-mining. They demonstrate the efficacy of their method across popular few-Shot learning datasets, algorithms, network architectures, and protocols."
SP:b31b1ee7067d4da70916986ba13e80bb14e2fdfe,"This paper studies the problem of logistic regression bandit, where the user selects one of two outcomes, i.e., ‘click’ or ‘no click’, and the learner aims to maximize the profit over a user that can select one of these outcomes. The authors consider a multinomial logit (MNL) model to model the probability of each one of K+1 2 possible outcomes. For this problem, the authors propose an upper confidence bound (UCB)-based algorithm that achieves regret O(dK p T) with small dependency on problem-dependent constants that can otherwise be arbitrarily large and lead to loose regret bounds. "
SP:0eaf058ed224464f6682cbbd80f716c89759f467,"This paper proposes a max-min entropy framework for reinforcement learning (RL) to overcome the limitation of the soft actor-critic (SAC) algorithm implementing the maximum entropy RL in model-free sample-based learning. The proposed method aims to learn to visit states with low entropy and maximize the entropy of these low-entropy states to promote better exploration. For general Markov decision processes (MDPs), an efficient algorithm is constructed under the proposed max-max entropy framework. Numerical results show that the proposed algorithm yields drastic performance improvement over the current state-of-the-art RL algorithms."
SP:19107a648d3d23403a8693b065ee842833a0b893,"This paper studies the problem of learning the time evolution of discrete sets of items (e.g., genetic mutations) in a continuous-time Markov chain. The authors show that the learning task is generally underspecified in the usual setting of cross-sectional data, and propose an approximate likelihood maximization method that can scale to hundreds of items and is orders of magnitude faster than previous methods. Experiments on synthetic and real cancer data demonstrate the effectiveness of the proposed method."
SP:68dfc737a8ea591da2c7fe048a5b8995c89e1fec,"This paper proposes a new self-supervised pretraining framework for document understanding, called UDoc. UDoc is designed to support most document understanding tasks, extending the Transformer to take multimodal embeddings as input. Each input element is composed of words and visual features from a semantic region of the input document image. It learns a generic representation by making use of three losses, encouraging the representation to model sentences, learn similarities, and align modalities. Extensive empirical analysis demonstrates that UDoc learns better joint representations and leads to improvements in downstream tasks."
SP:de6c4c1a418d1ebadc294d77dda18612c163d9c0,"This paper studies the problem of clustering a dataset of n points, where the goal is to find k centers such that the objective is minimized, while respecting the individual fairness constraint that every point v has a center within a distance at most r(v). The authors show that by modifying known LP rounding techniques, one gets a worst-case guarantee on the objective which is much better than in MV20, and empirically, this objective is extremely close to the optimal. "
SP:feb4664dfd5066cff582f6b4f9b17c6169049ceb,"This paper studies the problem of graph partitioning and correlation clustering. The authors propose a polynomial-time Gaussian sampling-based algorithm for these two problems that uses O(n + |E|) memory and nearly achieves the best existing approximation guarantees. For dense graphs arriving in a stream, the authors eliminate the dependence on $E$ in the storage complexity at the cost of a slightly worse approximation ratio. "
SP:cfd6cf88a823729c281059e179788248238a6ed7,"This paper proposes a motion-aware unit (MAU) to capture reliable inter-frame motion information by broadening the temporal receptive field of the predictive units. The MAU consists of two modules, the attention module and the fusion module. The attention module aims to learn an attention map based on the correlations between the current spatial state and the historical spatial states. Based on the attention map, the historical temporal states are aggregated to an augmented motion information (AMI). In this way, the predictive unit can perceive more temporal dynamics from a wider receptive field. Moreover, an information recalling scheme is employed into the encoders and decoders to help preserve the visual details of the predictions."
SP:07fa7cd4344d77a6e0f180d4f251cc8356b5202f,"This paper studies the problem of learning a two-layer neural network function approximation of the Q function in the context of deep reinforcement learning. In particular, the authors focus on the case where the function approximation is a neural network with ReLU and polynomial activation functions. The authors provide a sample-efficient algorithm in the generative model setting under the completeness condition. In the deterministic case, the sample complexity scales linearly in the algebraic dimension. In stochastic transition setting, the algorithm works for either policy complete or policy Bellman complete. "
SP:cac881243abde92a28c110f5bd84d115ed189bda,"This paper proposes a new benchmark for out-of-distribution generalization of deep metric learning (DML) models. The benchmark is based on a systematic construction of train-test data splits of increasing difficulty. The authors show that generalization performance degrades consistently with increasing problem difficulty for all DML methods. However, certain concepts underlying the approaches are shown to be more robust to shifts than others. "
SP:bacff3685476855a32549d03095375649fd89df2,"This paper proposes a meta-learning approach to automatically select a good outlier detection algorithm and its hyperparameter(s) (collectively called a model) for an unsupervised outlier model selection (UOMS) problem. The proposed method is based on meta-training on a large database of outlier models. To capture task similarity within the framework, the authors introduce specialized metafeatures that quantify outlying characteristics of a dataset. Extensive experiments show that selecting a model by METAOD significantly outperforms no model selection. "
SP:bf1c45ef27953acab2195d54c8197d360c1e8190,"This paper proposes a surrogate objective function for solving linear and semi-definite negative quadratic programming problems with soft linear and non-negative hard constraints. This framework gives the theoretical bounds on constraints’ multipliers, and derives the closed-form solution with respect to predictive parameters and thus gradients for any variable in the problem. Experiments are conducted on three applications: synthetic linear programming, portfolio optimization, and resource provisioning. "
SP:41a9806ee6c0c84e046b7de79eb54dfe00de6995,"This paper introduces Dropout Graph Neural Networks (DropGNNs), a new GNN architecture that aims to overcome the limitations of standard GNN frameworks. In DropGNN, a GNN is executed multiple times on the input graph, with some of the nodes randomly and independently dropped in each of these runs. Then, the results of these dropout runs are combined to obtain the final result. The authors prove that the Dropout GNN can distinguish various graph neighborhoods that cannot be separated by message passing GNNs. They also derive theoretical bounds for the number of runs required to ensure a reliable distribution of dropouts, and prove several properties regarding the expressive capabilities and limits of the dropout graph neural network. Finally, they validate their theoretical findings on expressiveness."
SP:090dc0471d54e237f423034b1e1c46a510202807,"This paper proposes a Dual-stream network (DS-Net) to fuse local and global pattern features for image classification. Specifically, this paper proposes an Intra-scale Propagation module to process two different resolutions in each block and an Inter-Scale Alignment module to perform information interaction across features at dual scales. In addition, the authors also design a Dual Stream Feature Pyramid Network (DSFPN) to further enhance contextual information for downstream dense predictions. The proposed DS-Net outperforms DeiT-Small by 2.4% in terms of top-1 accuracy on ImageNet-1k."
SP:9dd460c3506a9a508b92baa63dff6b487e0eeca0,"This paper proposes a new framework, Visual Reasoning with Differentiable Physics (VRDP) that can jointly learn visual concepts and infer physics models of objects and their interactions from videos and language. This is achieved by seamlessly integrating three components: a visual perception module, a concept learner, and a differentiable physics engine. The visual representation module parses each video frame into object-centric trajectories and represents them as latent scene representations. The concept learNER grounds visual concepts (e.g., color, shape, and material) from these object-based representations based on the language, thus providing prior knowledge for the physics engine to infer physical properties, such as mass, restitution, and velocity, by fitting the simulated trajectories into the video observations. Experiments on CLEVRER and Real-Billiards show that VRDP outperforms state-of-the-art dynamic reasoning methods."
SP:c511066c38f9793bacb4986c564eafa36e032f39," of submodular information measures (SIMs) as acquisition functions for active learning. The authors propose SIMILAR (Submodular Information Measures based actIve LeARning), a unified active learning framework based on SIMs. The proposed method is evaluated on CIFAR-10, MNIST, and ImageNet. "
SP:c141dc29b487ebfaa20ee50786886b0383d938bc,"This paper studies identity tests for ranking data that is generated from a Mallows model in the asymptotic and non-asymptotic settings. The authors consider the case when the central ranking is known, and devise two algorithms for testing the spread parameter. The first one is obtained by constructing a Uniformly Most Powerful Unbiased (UMPU) test for the asymetric setting and then converting it into a sample-optimal identity test. The second one is derived from an optimal learning algorithm and is sample optimal for a wide range of parameters. Experiments are conducted to show the effectiveness of the proposed tests."
SP:4c00bcc561832b581f479905b5e3310aeb3bdce2,"This paper proposes a method to synthesize a video of a human performance from sparse multi-view cameras. The proposed method is based on a temporal transformer that aggregates tracked visual features based on the skeletal body motion over time. Moreover, a multiview transformer is proposed to perform cross-attention between the temporally-fused features and the pixel-aligned features at each time step to integrate observations on the fly from multiple views. Experiments on the ZJU-MoCap and AIST datasets show that the proposed method significantly outperforms recent generalizable neural radiance fields methods on unseen identities and poses."
SP:5495d9168a8770eb2493e2d2bb6b68423e82b9e6,"This paper proposes a neural architecture search method to search the search space of vision transformers. The search is guided by the E-T Error computed using a weight-sharing supernet. The authors also provide design guidelines of general vision transformer with extensive analysis according to the space searching process. The experiments on ImageNet verify the proposed automatic search space design method can improve the effectiveness of design space, thus boosting the performance of searched architectures."
SP:c77b83c667a9b63fe15582336a77a34e96fd667b,"This paper studies the problem of learning linear threshold functions (LTFs) in the learning from label proportions (LLP) framework. In this setting, the learning is on a collection of bags of feature-vectors with only the proportion of labels available for each bag. The authors provide an algorithm that satisfies an LTF that satisfies at least (2/5)-fraction of the bags if all the bags are non-monochromatic (i.e., bags of size two with different labeled feature vectors). For the special case of OR over the d-dimensional boolean vectors, the authors give an algorithm which achieves an additional $\Omega(1/d)$ factor in accuracy for the two cases. "
SP:2eb193c76355aac08003c9b377895202fd3bd297,"This paper presents a method to create surrogate benchmarks for neural architecture search (NAS) that provide the full training information for each architecture, rather than just the final validation accuracy. The authors use singular value decomposition and noise modeling to create the surrogate benchmarks. They demonstrate the power of using the training information by introducing a learning curve extrapolation framework to modify single-fidelity algorithms, showing that it leads to improvements over popular single fidelity algorithms. "
SP:6ed1637ac697821931f685db0d476b9f7b56971a,"This paper proposes SimplEx, a method for providing post-hoc explanations of latent representations of a given model. The method is based on the use of a corpus of examples, which are decomposed into a mixture of latent features that are relevant for the model to relate them to the test example. The authors also propose Integrated Jacobians, a generalization of Integrated Gradients that makes the contribution of each corpus feature explicit in the latent space decomposition. SimplEx is evaluated on a variety of tasks, including mortality prediction and image classification. "
SP:c8f82ec90f891d7394933483b7f926155ac363ef,"This paper proposes a transformer-based visual embedding method for Vision-Language Pre-Training (VLP). The authors argue that CNNs have limitations in visual relation learning due to local receptive field’s weakness in modeling long-range dependencies. They propose a metric named Inter-Modality Flow (IMF) to measure the interaction between vision and language (i.e., inter-modality). They also design a novel masking optimization mechanism named Masked Feature Regression (MFR) in Transformer to further promote the intermodality learning."
SP:ecc173185ec28d0ef75c60df260ac4faba059f61,"This paper studies the problem of estimating the rate of information leakage of an iterative randomized learning algorithm when the internal state of the algorithm is private. The authors study this problem for noisy gradient descent algorithms and model the dynamics of Rényi differential privacy loss throughout the training process. The analysis traces a provably tight bound on the divergence between the pair of probability distributions over parameters of models trained on neighboring datasets. They prove that the privacy loss converges exponentially fast, for smooth and strongly convex loss functions, which is a significant improvement over composition theorems."
SP:acb1e0dc8d6ef5607e7d3ec9893b5364b9a6e831,"This paper proposes a reinforcement learning-based method to speed up the convergence rate of a first-order method quadratic program solver. The main idea is to use RL to learn a policy to adapt the internal parameters of the solver to allow for fewer iterations and faster convergence. The proposed method, RLQP, outperforms existing methods by up to 3x. The experiments show that the proposed method generalizes well to previously unseen problems with varying dimension and structure from different applications."
SP:eb68e98d9baf9118381d25d4b2da030a6f78577f,"This paper studies the asymptotic behavior of a deep linear network. The authors show that the convergence rate of the network's parameters is exponentially faster along directions corresponding to the larger principal components of the data, at a rate governed by the singular values. They term this convergence pattern the Principal Components bias (PC-bias) and show how it streamlines the order of learning of both linear and non-linear networks, more prominently at earlier stages of learning. They also compare their results to the spectral bias."
SP:1598bad835a657e56af3261501c671897b7e9ffd,"This paper proposes an approach to train a model with backdoor-poisoned data. The authors argue that backdoor attacks are more effective than clean attacks because they are easier and faster to learn than clean examples. Based on this observation, the authors propose a two-stage gradient ascent mechanism for standard training to help isolate backdoor examples at an early training stage, and to break the correlation between backdoor examples and the target class at a later training stage. The proposed method is evaluated on several benchmark datasets against backdoor attacks."
SP:6c0b7cb37e285cb9342f049d7b61af4565fe01fd,"This paper proposes a new generative implicit model for 3D-aware image synthesis. The key insight is that an accurate 3D shape should also yield a realistic rendering under different lighting conditions. This is achieved by modeling illumination explicitly and performing shading with various lighting conditions, which are derived by feeding the synthesized images to a discriminator. To reduce the additional computational burden of calculating surface normals, the authors further devise an efficient volume rendering strategy via surface tracking, reducing the training and inference time by 24% and 48% respectively. Experiments on multiple datasets show that the proposed approach achieves photorealistic 3D aware image synthesis while capturing accurate underlying 3D shapes."
SP:4b3dad77d79507c512877867dfea6db87a78682d,"This paper proposes a scalable quasi-Bayesian procedure for instrumental variable regression. The method is based on the recently proposed kernelized IV model. The authors derive the quasi-posterior and analyze its theoretical properties, and derive a scalable algorithm for approximate inference. Empirical evaluations show that the proposed method scales to large and high-dimensional datasets. "
SP:fd0d72d0689f170f8157dc7f79deb01348e414b3,"This paper presents Cross-lingual Open-Retrieval Answer Generation (CORA), the first unified many-to-many question answering (QA) model that can answer questions across many languages, even for ones without language-specific annotated data or knowledge sources. The authors introduce a new dense passage retrieval algorithm that is trained to retrieve documents across languages for a question. They also propose a multilingual autoregressive generation model that answers directly in the target language without any translation or in-language retrieval modules as used in prior work. The experiments show that CORA substantially outperforms the previous state of the art on multilingual open QA benchmarks across 26 languages, 9 of which are unseen during training."
SP:aa4d44b283ef4fea4335847c89fc7b5874169850,"This paper studies the effect of ERM on the out-of-distribution generalization of deep neural networks trained with Empirical Risk Minimization (ERM). Specifically, this paper investigates whether the domain adaptation theory of Ben-David et al. (2007) explains the performance of ERMs. The authors find that this theory does not provide a tight explanation of the generalization observed across a large number of ERm models trained on three popular domain generalization datasets. This motivates them to investigate other possible measures, that, however, lack theory, which could explain generalization in this setting."
SP:340c5353a63884b49cfdc46ddb6153b28b2e894f,This paper studies backdoor data poisoning attacks for classification problems. The authors propose a theoretical framework under which one can discuss backdoor data-poisoning attacks and analyze the statistical and computational issues surrounding these attacks. They identify a parameter they call memorization capacity that captures the intrinsic vulnerability of a learning problem to a backdoor attack. This allows them to argue about the robustness of several natural learning problems to backdoor attacks. 
SP:4c925cde6e5b9813946452fdd6b47816e2490f49,"This paper analyzes the effect of width and depth on the performance of deep Gaussian processes (Deep GP) when the number of hidden units increases. The authors show that depth accentuates a model’s non-Gaussianity, while width makes models increasingly Gaussian. They find a “sweet spot” that maximizes test performance before the limiting GP behavior prevents adaptability, occurring at width = 1 or width = 2 for nonparametric Deep GP, and a width of 1 or 2 often achieves the best performance. Experiments confirm that width can become harmful to model fit and performance."
SP:3f74dc3dc2cb444b3097aae1288dad5355e9a4d4,"This paper studies the problem of federated learning in which a group of clients periodically coordinate with a central server to train a statistical model. The authors propose a general algorithmic framework called FedLin to tackle some of the key challenges intrinsic to FL, namely objective heterogeneity, systems heterogeneity, and infrequent and imprecise communication. Their framework is motivated by the observation that under these challenges, various existing FL algorithms suffer from a fundamental speed-accuracy conflict: they either guarantee linear convergence but to an incorrect point, or convergence to the global minimum but at a sub-linear rate, i.e., fast convergence comes at the expense of accuracy. In contrast, when the clients’ local loss functions are smooth and strongly convex, the authors show that FedLin guarantees linear convergence to global minimum, despite arbitrary objective and systems heterogeneity. They also establish matching upper and lower bounds on the convergence rate of FedLin that highlight the effects of infrequent, periodic communication. "
SP:29f44f2f7d0e9748eed6732ed19ca3335acb04e3,"This paper proposes a novel method to approximate the Sliced-Wasserstein distance (SW) based on the concentration of measure phenomenon. The authors show that under mild assumptions, one-dimensional projections of a high-dimensional random vector are approximately Gaussian. Based on this observation, they develop a simple deterministic approximation for SW. The method does not require sampling a number of random projections, and is therefore both accurate and easy to use compared to the usual Monte Carlo approximation. "
SP:7d5ec55a01247b65e4a8f1973d448214585d6baa,"This paper proposes a method to study the relationship between different representations learned by different language models. The method is based on a transfer learning approach, where the encoder and decoder of a language model are trained on different NLP tasks (e.g., translation, word embeddings, syntactic and semantic tasks, and language tagging tasks). The main contribution of the paper is the introduction of a low-dimensional representation embedding space, which is then used to measure the similarity between different language representations. The paper shows that this representation space can be used to predict how well each representation maps to human brain responses to natural language stimuli. "
SP:698d6c344fe94ea4ec3ce54601f5976d82d00b85,"This paper proposes Diffusion-Decoding models with Contrastive representations (D2C) for training unconditional variational autoencoders (VAEs) for few-shot conditional image generation. D2C uses a learned diffusion-based prior over the latent representations to improve generation and contrastive self-supervised learning to improve representation quality. It can adapt to novel generation tasks conditioned on labels or manipulation constraints, by learning from as few as 100 labeled examples. On conditional generation from new labels, it achieves superior performance over state-of-the-art VAEs and diffusion models."
SP:36d11071cbf989e1f02232d39f52a42e781a5b2b,"This paper studies self-supervised learning in the context of contrastive learning. In contrast to prior work, the authors propose a novel graph-based augmentation graph to decompose the data augmentation into sub-graphs, which are then used to define a spectral contrastive loss. The authors show that the proposed loss is equivalent to a linear-probe-based loss on the graph, and provide theoretical guarantees on the performance of the learned representations on linear classification tasks. Empirically, the proposed method is shown to outperform several baselines on standard benchmarks."
SP:ae4bc7f2a00feb13e458ab17804c06709374ceee,"This paper studies the parameterized complexity of Bayesian Network Structure Learning (BNSL), a classical problem that has received significant attention in empirical but also purely theoretical studies. The authors follow up on previous works that have analyzed the complexity of BNSL w.r.t. the so-called superstructure of the input. They show that a different kind of parameterization—notably by the size of a feedback edge set—yields fixed-parameter tractability. They further show that this result can be strengthened to a localized version of the feedback edge sets, and provide corresponding lower bounds that complement previous results to provide a complexity classification of the problem. Finally, they show how their results can be extended to the closely related problem of Polytree Learning."
SP:3dc67f04c04466b0fe5aebb01c7578cd24caee0c,"This paper studies active learning in the streaming setting for binary classification. The authors propose a novel active learning algorithm that leverages pseudo-labels to minimize the number of label requests, and trains a model to optimize a surrogate loss on a set of labeled and weak-labeled points. The algorithm jointly admits two crucial properties: theoretical guarantees in the general agnostic setting and a strong empirical performance. The theoretical analysis shows that the algorithm attains favorable generalization and label complexity bounds, while the empirical study on 18 real-world datasets demonstrate that the proposed algorithm outperforms standard baselines."
SP:0e5812d8ed33d5b6d9d59dbb2312c7b1c9363f3d,"This paper proposes a new measure of complexity called Kolmogorov growth (KG) that can be used to derive new generalization error bounds that only depend on the final choice of the classification function. Based on KG, the authors propose a novel way of regularizing neural networks by constraining the network trajectory to remain in the low KG zone during training. Minimizing KG while learning is akin to applying the Occam's razor to neural networks. The proposed approach, called network-to-network regularization (N2N), leads to clear improvements in the generalization ability of classifiers."
SP:d5608d3317c2b246375eb14006b9e6a6026e0ab6,"This paper proposes a new self-supervised learning method called VICReg (Variance-Invariance-Covariance Regularization) that aims to avoid the collapse of representations with a variance preservation term and maximizing the information content of the representation with a covariance regularization term. The proposed method is based on two regularization terms: (1) a term that maintains the variance of each embedding dimension above a threshold, and (2) another term that decorrelates each pair of variables. Experiments show that the proposed method outperforms the baselines on several downstream tasks."
SP:bc8a9fcf7de41f1a1b0c6d0fc3fdcac5c5f87613,"This paper proposes Information Directed Reward Learning (IDRL), a general active reward learning approach for learning a model of the reward function from expensive feedback with the goal of finding a good policy rather than uniformly reducing the model’s error. IDRL can use arbitrary Bayesian reward models and arbitrary types of queries, making it more general than existing methods. It achieves similar or better performance with significantly fewer queries by shifting the focus from reducing the reward approximation error to improving the policy induced by the reward model. "
SP:d88f2bb3ed48deb04fae1b8f008ca69d8566819f,"This paper proposes a method to predict parameters of a neural network in a single forward pass. The method is based on graph neural networks (GNNs) and is able to predict performant parameters in a fraction of a second, even on a CPU. The authors introduce a large-scale dataset of diverse computational graphs of neural architectures and use it to explore parameter prediction on CIFAR-10 and ImageNet. "
SP:8b233a2a5049ccda84e8840b97b800ffc5862e16,"This paper provides a closed form expression for the distortion-perception (DP) function for the mean squared-error (MSE) distortion and the Wasserstein-2 perception index. The authors prove that the DP function is always quadratic, regardless of the underlying distribution. In the Gaussian setting, they further provide a closed-form expression for such estimators. For general distributions, they show how these estimators can be constructed from the estimators at the two extremes of the tradeoff. "
SP:60ce257ca7c1dbbc88e4f36bad40f7eeb133368a,"This paper proposes a novel model architecture for the representation learning of text-based graphs. The main idea is to use GNN layers nested alongside the transformer blocks of the language model to fuse the text embedding and the graph aggregation. In addition, a progressive learning strategy is introduced, where the model is successively trained on manipulated data and original data to reinforce its capability of integrating information on graph. Extensive experiments are conducted on three large-scale benchmark datasets to validate the effectiveness of the proposed method. "
SP:199a281592df47d71c57fdcbd24b40a0b0de9d76,"This paper studies the problem of learning under user-level differential privacy constraints. In particular, the authors consider the following problems: mean estimation, empirical risk minimization, stochastic convex optimization, and learning hypothesis classes with finite metric entropy. They show that the privacy cost decreases as O(1/\sqrt{m}/n) as users provide more samples. In contrast, when increasing the number of users n, the privacy costs decrease at a faster rate. The authors also provide lower bounds showing the minimax optimality of their algorithms."
SP:ad5b98e656cac6eb931f80d852c397d117cf1609,"This paper proposes a self-consistent Gaussian Process (GPs) framework to study the effect of feature learning in finite neural networks. Specifically, the authors consider DNNs trained with noisy gradient descent on a large training set and derive a GPs-based framework that accounts for strong finite-DNN and feature learning effects. The authors also show that a sharp transition between a feature learning regime and a lazy learning regime in this model can be identified. "
SP:231655b9fad6c76eb0ff1ba305ed421f5c293623,"This paper analyzes the role of noise in the emergence of compositional communication in signaling games. The authors show that inductive biases on both the training framework and the data are needed for the compositionality to emerge. They also show that compositionality spontaneously arises in the signaling games, where agents communicate over a noisy channel. Finally, they empirically verify that a certain range of noise levels, dependent on the model and the training data, promotes compositionality."
SP:9d326254d77a188baf5bde39229c09b3966b5418,"This paper presents ResMLP, a multi-layer neural network architecture for image classification. The architecture consists of a linear layer, a two-layer feed-forward network, and a residual layer. The network is trained with a self-supervised self-training strategy and a data augmentation strategy. The proposed method is evaluated on ImageNet. "
SP:6dabaca9a77620b7c4019bf5f9c2a88628fc691c,"This paper studies the problem of multi-class classification, where a stream of adversarially chosen queries arrive and must be assigned a label online. Unlike traditional bounds which seek to minimize the misclassification rate, this paper focuses on minimizing the total distance from each query to the region corresponding to the correct label. The authors show that one can achieve a loss that is independent of the total number of queries. They also show that learning general convex sets requires an almost linear loss per query. "
SP:5c0114535065d5125349f00bafdbccc911461ede,"This paper proposes a method for knowledge transfer based on a regularization term in our loss function, supervising the sequence of required reasoning operations. They provide a theoretical analysis based on PAC-learning, showing that such program prediction can lead to decreased sample complexity under mild hypotheses. They also demonstrate the effectiveness of this approach experimentally on the GQA dataset."
SP:40fd96105e77063de4a07d4b36fe19385434c533,"This paper studies the problem of simulating a universal Turing machine with RNNs. The authors propose a new memory module, which is composed of fixed-precision neurons and growing memory modules. They prove that a RNN with growing memory module is Turing-complete, and extend this result to other stack-augmented RNN architectures. They also analyze the relationship between the number of neurons and the precision of an RNN. "
SP:3f33489b98ba6145fd4e334669493f15a63455f4,This paper analyzes the under-coverage bias of quantile regression. The authors show that the quantile function learned by quantile-regression suffers from an inherent under-covering bias. The main reason for this bias is a high-dimensional parameter estimation error that is not implied by existing theory. Experiments on simulated and real data verify the theory. 
SP:ecb9c7c11dfb450d8e76504d42309b1888023d26,"This paper proposes a reinforcement learning-based method for memory allocation in the context of class-incremental learning (CIL). The main idea is to use reinforcement learning (RL) to learn a policy that allocates memory for different classes. The RL policy is trained on pseudo CIL tasks and then applied to target tasks. The proposed method is evaluated on CIFAR-100, ImageNet-Subset, and ImageNet. "
SP:1137ed24393a24f24e9a36e1586e6924a55d627e,"This paper studies the problem of speeding up SGD by parallelizing it across multiple workers. In this paper, the authors propose a Local SGD scheme that communicates less overall by communicating less frequently as the number of iterations grows. Their analysis shows that this can achieve an error that scales as 1/(NT ) with a number of communications that is completely independent of T. In particular, they show that \Omega(N) communications are sufficient. "
SP:8a78fee6173dc6639dfd9e33a10d0c8432a08512,"This paper studies the Online Lazy Gradient Descent for optimisation on a strongly convex domain. The algorithm is known to achieve $O(\sqrt{N})$ regret against adversarial opponents. This paper shows that the algorithm is universal in the sense that it also achieves $O(log(N)$ expected regret against i.i.d. This improves upon the more complex metaalgorithm of Huang et al. [20] that only gets $\sqrt(N^3)$ regret. The paper also shows that, unlike for the simplex domain, order bounds for pseudo-regret and expected regret are equivalent for strongly-convex domains. "
SP:59e7ff1cdee42c9623615f6105c0e0f44e7b75a5,"This paper analyzes the Bures-Wasserstein (BW) geometry for Riemannian optimization on the symmetric positive definite (SPD) matrix manifold. The authors show that the BW metric has a linear dependence on SPD matrices in contrast to the quadratic dependence of the Affine-Invariant (AI) geometry. They also show that several popular cost functions, which are known to be geodesic convex under the AI geometry, are also geodesics convex in the BW geometry. Extensive experiments on various applications support the findings."
SP:1f835a54c74d396ae2e8620b01bed0ec53646f3a,"This paper introduces Dynaboard, an evaluation-as-a-service framework for hosting benchmarks and conducting holistic model comparison, integrated with the Dynabench platform. The platform evaluates NLP models directly instead of relying on self-reported metrics or predictions on a single dataset. This allows users to interact with uploaded models in real time to assess their quality, and permits the collection of additional metrics such as memory use, throughput, and robustness, which – despite their importance to practitioners – have traditionally been absent from leaderboards. On each task, models are ranked according to the Dynascore, a novel utility-based aggregation of these statistics, which users can customize to better reflect their preferences."
SP:44dc6a69f5d65ca0b271177ac67d1beb12a154a0,"This paper proposes a neural network-based method for automatic video dubbing (AVD) based on text-to-speech (TTS) model. The key idea is to use the lip movement in the video to control the prosody of the generated speech. In addition, an image-based speaker embedding (ISE) module is developed for the multi-speaker setting, which enables Neural Dubber to generate speech with a reasonable timbre according to the speaker’s face. Experiments on the chemistry lecture single speaker dataset and LRS2 multi speaker dataset show that the proposed method can generate speech audios on par with state-of-the-art TTS models."
SP:24ea12428bd675459f0509aa7cee821fa236382e,This paper proposes a new federated learning framework based on Vision Transformer (ViT) for collaborative learning in medical imaging. The proposed framework is based on the Federated Split Task-Agnostic (FESTA) framework to leverage the benefit of ViT to simultaneously process multiple CXR tasks including the diagnosis of COVID-19. Experiments show that the proposed framework can achieve performance comparable to data-centralized training. 
SP:2065a8cb8b53140569b64fca1f00f7230f1ae2cc,"This paper proposes a differentiable point-to-mesh representation for 3D surface reconstruction. The main contribution of this paper is the use of a Poisson Surface Reconstruction (PSR) layer that allows for a GPU-accelerated fast solution of the indicator function given an oriented point cloud. The differentiable PSR layer allows to efficiently and differentiably bridge the explicit 3D point representation with the 3D mesh via the implicit indicator field, enabling end to end optimization of surface reconstruction metrics such as Chamfer distance. This duality between points and meshes hence allows us to represent shapes as oriented point clouds, which are explicit, lightweight and expressive. "
SP:76b64e6b104818ed26e9331d134df0125d84291c,"This paper studies the problem of recovering the representation of a pre-trained representation learning network that operates on clean images, like CLIP. The authors propose a supervised inversion method that uses a contrastive objective to obtain excellent representations for highly corrupted images. Using a linear probe on the robust representations, the proposed method achieves a higher accuracy than end-to-end supervised baselines when classifying images with various types of distortions, including blurring, additive noise, and random pixel masking."
SP:ca846ae9653fa843a6a64ce7361d44a0c31c5990,"This paper studies the problem of structural credit assignment in neural networks. The authors formalize training a neural network as a finite-horizon reinforcement learning problem and discuss how this facilitates using ideas from reinforcement learning like off-policy learning. They show that the standard on-policy REINFORCE approach, even with a variety of variance reduction approaches, learns suboptimal solutions. They introduce an off-Policy approach, to facilitate reasoning about the greedy action for other agents and help overcome stochasticity in other agents. They conclude that these networks of agents can be more robust to correlated samples when learning online."
SP:7aa09356b2c85d54933c0d0d89a3f8fe2e37b27b,"This paper proposes to use a self-supervised predictive loss function to capture the functional specialization of the ventral and dorsal pathways of the visual system of mice. Specifically, the authors propose to use an ANN to model both the dorsal and ventral pathways of mouse visual system. The authors show that the proposed method outperforms other models in fitting mouse visual cortex. "
SP:fa11c4da16c01c6a3449f15b25a6e4e228ebbf4a,"This paper introduces TopicNet, a deep hierarchical topic model that can inject prior structural knowledge as an inductive bias to influence the learning of the topic hierarchy. TopicNet represents each topic as a Gaussian-distributed embedding vector, projects the topics of all layers into a shared embedding space, and explores both the symmetric and asymmetric similarities between Gaussian embedding vectors to incorporate prior semantic hierarchies. Experiments on widely used benchmarks show that TopicNet outperforms related deep topic models on discovering deeper interpretable topics and mining better document representations."
SP:b7ad495901eb2f73a8a26aa5c9325908451cfe09,This paper proposes a novel self-supervised pretraining method called Selective Object COntrastive learning (SoCo) for the task of object detection. The key idea is to use selective search bounding boxes as object proposals. The pretraining network architecture incorporates the same dedicated modules used in the detection pipeline (e.g. FPN) and the pretraining is equipped with object detection properties such as object-level translation invariance and scale invariance. Experiments on two-stage and single-stage detectors demonstrate the generality and extensibility of SoCo.
SP:b4dcb19fd97a906ed37e6af407260f0dedbbd402,"This paper presents a learning-augmented local search framework to solve large-scale vehicle routing problems (VRPs). The method iteratively improves the solution by identifying appropriate subproblems and delegating their improvement to a black box subsolver. At each step, spatial locality is leveraged to consider only a linear number of subproblem instances, rather than exponential. The method accelerates state-of-the-art VRP solvers by 10x to 100x while achieving competitive solution qualities for VRPs with sizes ranging from 500 to 3000."
SP:f5c80f76cb1e651fd808e7da4bfe6fdfd75b7155,"This paper proposes a method for Bayesian continual learning based on active forgetting. Specifically, the authors propose to actively forget the old knowledge that limits the learning of new tasks to improve the performance of continual learning. The method is inspired by the active forgetting mechanism of biological neural networks. The proposed method is evaluated on several continual learning tasks and achieves state-of-the-art performance. "
SP:a5945ec13e2f362df03b42511d44827ef081f4c3,"This paper analyzes the convergence of prior-guided ZO optimization algorithms under a greedy descent framework with various gradient estimators. The authors provide a convergence guarantee for the prior guided random gradient-free (PRGF) algorithms and a new accelerated random search (ARS) algorithm that incorporates prior information, together with a convergence analysis. The theoretical results are confirmed by experiments on several numerical benchmarks as well as adversarial attacks."
SP:ef18f4188426bc01be309633b486884b0e7a81a4,"This paper provides a theoretical analysis of the lottery ticket hypothesis (LTH) which states that learning on a properly pruned network (the winning ticket) improves test accuracy over the original unpruned network. This paper analyzes the performance of training a pruned neural network by analyzing the geometric structure of the objective function and the sample complexity to achieve zero generalization error. It shows that the convex region near a desirable model with guaranteed generalization enlarges as the neural network model is pruned, indicating the structural importance of a winning ticket. Moreover, it shows that when the algorithm for training a Pruned Neural Network is specified as an (accelerated) stochastic gradient descent algorithm, the number of samples required for achieving zero generalisation error is proportional to the size of the non-pruned weights in the hidden layer. "
SP:3ef8660de61a1a73858934fcf8edfec104133ae7,"This paper studies the query release problem, where the goal is to generate a sanitized version of a sensitive dataset, subject to differential privacy, that approximately preserves the answers to a large collection of statistical queries. The authors propose a framework that unifies a long line of iterative algorithms in the literature and propose two new methods. The first method, generative networks with the exponential mechanism (GEM), circumvents computational bottlenecks in algorithms such as MWEM by optimizing over generative models parameterized by neural networks, which capture a rich family of distributions while enabling fast gradient-based optimization. The second method, private entropy projection (PEP), can be viewed as an advanced variant of MWEM that adaptively reuses past query measurements to boost accuracy."
SP:d789e92c1e4f6a44de373210cd732198a6f809be,"This paper proposes a simple mask classification model that predicts a set of binary masks, each associated with a single global class label prediction, for semantic and instance-level segmentation tasks. The key insight of this paper is that mask classification is sufficiently general to solve both semantic-and-instance-level semantic and panoptic segmentation task in a unified manner using the exact same model, loss, and training procedure. The proposed mask classification-based method simplifies the landscape of effective approaches to semantic and Panoptic semantic segmentation and shows excellent empirical results."
SP:3aee15083ee1c0a75fedd67a50f9d729bf5ee411,"This paper extends the work of Daniely and Schacham (2020) on adversarial examples on random undercomplete two-layer ReLU neural networks to the overcomplete case, where the number of neurons is larger than the dimension (yet also sub-exponential in the dimension). In particular, the authors show that a single gradient descent step is sufficient to find adversarial perturbations. The authors also show this result for any subexponential width random neural network with smooth activation function. "
SP:220db9ed147bbe67de5d82778720a1549656e48d,"This paper proposes a score-based generative model (LSGM) based on the variational autoencoder (VAE) framework. The LSGM is based on variational lower bound on the likelihood of the latent space. The authors propose a new score-matching objective for training the LSGM and a new parameterization of the score function that allows the SGM to focus on the mismatch of the target distribution with respect to a simple Normal distribution. The proposed LSGM achieves state-of-the-art FID score of 2.10 on CIFAR-10, outperforming all existing generative results on this dataset. "
SP:d681e4e28c03f610acf6817a9e57db0c41c196b4,"This paper proposes a new explanation for the performance gap between neural networks and neural tangent kernels in the context of image classification. Specifically, the authors prove that for a simple data distribution with sparse signal amidst high-variance noise, a simple convolutional neural network trained using stochastic gradient descent simultaneously learns to threshold out the noise and find the signal. On the other hand, the corresponding kernel, with a fixed set of predetermined features, is unable to adapt to the signal in this manner. Experiments on CIFAR-10 and MNIST show that as the background noise increases in intensity, the performance of a CNN’s performance stays relatively robust, whereas the corresponding neural tangency kernel sees a notable drop in performance. "
SP:c347796244fcf9b5de19c68bcc5c811b7448217d,"This paper studies the problem of decentralized decentralized machine learning over a network where the training data is distributed across n agents, each of which can compute stochastic model updates on their local data. The agent’s common goal is to find a model that minimizes the average of all local loss functions. While gradient tracking (GT) algorithms can overcome a key challenge, namely accounting for differences between workers’ local data distributions, the known convergence rates for GT algorithms are not optimal with respect to their dependence on the mixing parameter p (related to the spectral gap of the connectivity matrix). The authors provide a tighter analysis of the GT method in the stochastastic strongly convex, convex and non-convex settings. They improve the dependency on p from O(p-2) to O(\p-1/c-1) in the noiseless case and from O($p-3/2$) to $O(\p^{-1$/2}/3$ in the general case. This improvement was possible due to a new proof technique."
SP:24d637e8c3489bfe50b17bf684097776ad6ee485,"This paper studies the regret of UCB in the stochastic multi-armed bandit problem. The authors show that the arm-sampling rates under UCB are asymptotically deterministic, regardless of the problem complexity. The paper also provides the first complete process-level characterization of the MAB problem in the conventional diffusion scaling. "
SP:43c8bcc93aa034965fa6d959d44b529ffc110cc7,"This paper studies the problem of cross-domain cold-start recommendation (CDCSR), where the goal is to leverage the information from a source domain to improve the recommendation performance of a target domain. The authors propose DisAlign, a framework that utilizes both rating and auxiliary representations from the source domain. Specifically, they first propose Stein path alignment for aligning the latent embedding distributions across domains, and then further propose its improved version, i.e., proxy Stein path, which can reduce the operation consumption and improve efficiency. Empirical studies on Douban and Amazon datasets demonstrate the effectiveness of the proposed method."
SP:729c3e22a6f0170bdc8e1f511812dc9e9a4fd4a8,"This paper proposes a simple yet computationally efficient architecture for image classification that replaces the self-attention layer in vision transformers with a 2D discrete Fourier transform, an element-wise multiplication between frequency-domain features and learnable global filters. The proposed method is based on a global filter network that learns long-term spatial dependencies in the frequency domain with log-linear complexity. The experiments on ImageNet verify the effectiveness of the proposed method."
SP:e278079529d6da9e2ea26b47730dbc1256ffe2db,"This paper studies the problem of predicting trustworthiness on a large-scale dataset. The authors observe that the trustworthiness predictors trained with prior-art loss functions, i.e., the cross entropy loss, focal loss, and true class probability confidence loss, are prone to view both correct predictions and incorrect predictions to be trustworthy due to overfitting. To improve the generalizability of the oracles, the authors propose a steep slope loss to separate the correct predictions from the incorrect predictions by two slide-like curves that oppose each other. The proposed loss is evaluated with two representative deep learning models, namely Vision Transformer and ResNet, as trustworthiness predictions."
SP:c5704a709f318c6e9a5c716e5e7f250acccf46a8,"This paper analyzes adversarial robustness from the perspective of linear components, and finds that there exist some statistical properties for comprehensively robust models. Specifically, robust models show obvious hierarchical clustering effect on their linearized sub-networks, when removing or replacing all non-linear components (e.g., batch normalization, maximum pooling, or activation layers). Based on these observations, the authors propose a novel understanding of adversarially robustness and apply it on more tasks including domain adaption and robustness boosting. Experimental evaluations demonstrate the rationality and superiority of our proposed clustering strategy."
SP:590b67b1278267e966cf0b31456d981441e61bb1,"This paper proposes a method for learning end-to-end reconstruction operators based on unpaired training data for ill-posed inverse problems. The proposed method combines the classical variational framework with iterative unrolling and essentially seeks to minimize a weighted combination of the expected distortion in the measurement space and the Wasserstein-1 distance between the distributions of the reconstruction and the ground-truth. More specifically, the regularizer in the variational setting is parametrized by a deep neural network and learned simultaneously with the unrolled reconstruction operator. The variational problem is then initialized with the output of reconstruction network and solved iteratively till convergence. "
SP:115d679338ab35829dbc594472d13cc02be5ed4c,"This paper proposes a contrastive loss to align the image and text representations BEfore Fusing (ALBEF) through cross-modal attention, which enables more grounded vision and language representation learning. In addition, a self-training method is proposed to improve learning from noisy web data by learning from pseudo-targets produced by a momentum model. The authors provide a theoretical analysis of ALBEF from a mutual information maximization perspective, showing that different training tasks can be interpreted as different ways to generate views for an image-text pair. The proposed method achieves state-of-the-art performance on multiple downstream vision language tasks."
SP:e5323a171f40c109722a7ea0aebdcd53c151b72d,"This paper studies the offline policy evaluation (OPE) with MDPs, where the goal is to estimate the utility of given decision making policies based on static datasets. The authors study the behavior of a simple existing OPE method called the linear direct method (DM) under the unrealizability assumption. They obtain an asymptotically exact characterization of the OPE error in a doubly robust form. Leveraging this result, they also establish the nonparametric consistency of the tile-coding estimators under quite mild assumptions."
SP:b45f6966fcc07f3a33f70a57e72507b16fc7bb24,This paper studies the non-smooth convex stochastic convex optimization problem with non-sub-Gaussian (heavy-tailed) noise. The authors provide the first high-probability convergence results with a logarithmic dependence on the confidence level for convex convex problems with noise distribution that is not sub-gaussian. They also propose novel stepsize rules for two methods with gradient clipping.  
SP:a22a893e25ce739dc757861741014764e78aa820,"This paper studies the long-term forecasting problem of time series, which is a pressing demand for real-world applications. The authors propose the Autoformer as a decomposition architecture by embedding the series decomposition block as an inner operator, which can progressively aggregate the longterm trend part from intermediate prediction. Besides, they design an efficient Auto-Correlation mechanism to conduct dependencies discovery and information aggregation at the series level, which contrasts clearly from the previous self-attention family. The Autoformer achieves state-of-the-art accuracy on six benchmarks, covering five practical applications."
SP:eeb2c3348de291c5eacac5d9de7b6b84ca030ad5,"This paper presents a dataset of cryptic crossword clues as a new benchmark for NLP systems that seek to process compositional language in more creative, human-like ways. The dataset is composed of two parts: a definition and a wordplay cipher requiring character-level manipulations. The authors show that three non-neural approaches and T5, a state-of-the-art neural language model, do not achieve good performance on the dataset and propose a curriculum approach, in which the model is first fine-tuned on related tasks such as unscrambling words. "
SP:7693974b70806d9b67920b8ddd2335afc4883319,"This paper analyzes the internal representation structure of ViTs and CNNs on image classification benchmarks. It finds striking differences between the two architectures, such as ViT having more uniform representations across all layers. The authors explore how these differences arise, finding crucial roles played by self-attention, which enables early aggregation of global information, and ViT residual connections, which strongly propagate features from lower to higher layers. Finally, the authors study the effect of (pretraining) dataset scale on intermediate features and transfer learning."
SP:dfd740399e48b946f02efdec823b8975a900f6a3,"This paper studies Thompson Sampling (TS) with approximation oracle to solve combinatorial multi-armed bandit (CMAB) problems. The authors provide a problem-dependent regret lower bound of order $\Omega(log T/2)$ to quantify the hardness of TS to solve CMAB problems with greedy oracle, where T is the time horizon and is some reward gap. They also provide an almost matching regret upper bound. These results are the first theoretical results of TS with approximation/approximation oracle. "
SP:3ca7fdaba9793a61a1f9d264a551fe895e55dd99,"This paper studies the problem of federated learning in a game-theoretic framework. In particular, the authors focus on the question of how far from optimal optimal federating coalitions are in practice. The authors provide an efficient algorithm to calculate an optimal partition of federating players into federating coalition, and show that for some regions of parameter space, all federating arrangements are optimal (Price of Anarchy equal to 1). However, they show that this is not true for all settings: there exist examples of stable arrangements with higher cost than optimal. Finally, they give the first constant-factor bound on the performance gap between stability and optimality. "
SP:17088db004fbf4902c5c3d53e387d1b68f4d69a5,"This paper proposes a self-supervised capsule architecture for 3D point clouds. The proposed method computes capsule decompositions of objects through permutation-equivariant attention. The method is able to learn a canonicalization operation that enables object-centric reasoning. The experiments show that the proposed method outperforms the state-of-the-art in reconstruction, canonicalization, and unsupervised classification."
SP:34cc3466ff7786968f437007b6af7d9ffd4decc7,"This paper proposes a conformal method to compute prediction intervals for nonparametric regression that can automatically adapt to skewed data. The method uses black-box machine learning algorithms to estimate the conditional distribution of the outcome using histograms, and translates their output into the shortest prediction intervals with approximate conditional coverage. The resulting prediction intervals provably have marginal coverage in finite samples, while asymptotically achieving conditional coverage and optimal length if the model is consistent. Numerical experiments with simulated and real data demonstrate improved performance compared to state-of-the-art alternatives."
SP:d39075aff611dd54574e7ee1a1aeacce83fdf532,This paper studies the effect of invariance enforced by feature averaging on the generalization of kernel ridge regression. The authors build on the function space perspective of Elesedy and Zaidi [8] to derive a strictly non-zero generalization benefit of incorporating invariance when the target is invariant to the action of a compact group. They show that generalization is governed by a notion of effective dimension that arises from the interplay between the kernel and the group. The action of the group induces an orthogonal decomposition of both the reproducing kernel Hilbert space and its kernel.
SP:97fac361b69ed5871a60dc40e51900747a453df9,"This paper proposes a new neural network architecture, called Decodable Neural Network (DecNN), that uses a generative model to constrain neural network activations to “decode” back to inputs. The authors claim that this design enables a form of compositionality in neural networks, where one can recursively compose DecNN with itself to create an ensemble-like model with uncertainty. In the experiments, the authors demonstrate applications of this uncertainty to out-of-distribution detection, adversarial example detection, and calibration — while matching standard neural networks in accuracy."
SP:3f10ca1e7f8fef6cb0c5957ec2f0689fb9bed753,"This paper studies the convergence of plug-in estimators of optimal transport between two probability distributions $\mu$ and $\nabla \in \mathbb{R}^d$ under smoothness assumptions. The authors propose a new stability estimate for barycentric projections which proceeds under minimal smoothness assumption and can be used to analyze general plug estimators. They provide rates of convergence for the natural discretediscrete and semi-discrete estimators and then use the same stability estimate to show that, under additional smoothness conditions of Sobolev type or Besov type, kernel smoothed or wavelet based plug-based estimators respectively speed up the rate of convergence and mitigate the curse of dimensionality suffered by the natural discrete/semi-discretes estimators in the paper. "
SP:573fbdbe5857c4aace1dfc27e25b8d65a18c9b96,"This paper studies the problem of dataset distillation, i.e., distilling large datasets into significantly smaller yet highly performant ones. To this end, the authors propose a distributed kernel-based meta-learning framework to achieve state-of-the-art results using infinitely wide convolutional neural networks. The authors show that using only 10 datapoints (0.02% of original dataset), they obtain over 65% test accuracy on CIFAR10 image classification task, a dramatic improvement over the previous best test accuracy of 40%. The authors also perform some preliminary analyses of our distilled datasets to shed light on how they differ from naturally occurring data."
SP:9837e0c68887cc1382aefd0ead01f72cde199e0d,"This paper proposes an open-set semi-supervised learning (OSSL) approach called OpenMatch, which unifies FixMatch with novelty detection based on one-vs-all (OVA) classifiers. The OVA-classifier outputs the confidence score of a sample being an inlier, providing a threshold to detect outliers. Another key contribution is an open set soft-consistency regularization loss, which enhances the smoothness of the OVA classifier with respect to input transformations and improves outlier detection. OpenMatch achieves state-of-the-art performance on three datasets."
SP:eb86d33d5d47f1cfe2c66ca2c9f852229e32a32f,"This paper proposes Latent Explorer Achiever (LEXA), an agent for unsupervised RL that explores its environment, learns to achieve the discovered goals, and solves image-based tasks in a zero-shot way. By planning for novelty in imagination, LEXA prospectively explores to discover meaningful behaviors in substantially more diverse environments than considered by prior work. Further, the agent is able to solve challenging downstream tasks specified as images without any supervision such as rewards or demonstrations."
SP:2db4aba9a370df67f786157f18cbaa4167c6a46d,"This paper proposes a method to reduce the number of parameters in a Transformer model by decomposing a matrix into two smaller matrices. The decomposition is done by reshaping and reordering matrix dimensions prior to the decomposition and is equivalent to a sum of Kronecker products with an efficient implementation. The authors prove that stacking multiple linear layers decomposed this way increases the expressiveness of the network, unlike stacking multiple low-rank layers factorized in the standard way, which can only map into a subspace of dimensionality equal to the rank. Empirically, the authors show that this decomposition can reduce the size of a simple encoder-decoder Transformer to as little as 4 million parameters."
SP:0ff862542ada5b664d615c26e7a4a95b6cbe540e,"This paper proposes a Transformer-based code summarization model that incorporates path encoding into the attention module of the transformer architecture. Specifically, the paper proposes to encode both the pairwise path between tokens of source code and the path from the leaf node to the tree root for each token in the syntax tree in the source code. The paper shows that the two kinds of path encoding methods (absolute and relative path encodings) can be integrated into the unified Transformer framework. The experimental results show that the proposed method outperforms strong baselines. "
SP:727bcd651b11b7d84dd2c2d535cc85402f9117d4,"This paper proposes a Transformer-based generator for high-resolution image generation based on Generative Adversarial Networks (GANs). The authors propose a multi-Axis Blocked Self-Attention module to reduce the quadratic complexity of self-attention operation in the low-resolution stages of the generative process. In addition, the authors also propose a self-modulation component based on cross attention to further improve the performance. The proposed HiT achieves state-of-the-art FID scores of 30.83 and 2.95 on unconditional ImageNet 128x128 and FFHQ 256x256."
SP:41a6753bc56eb16040600666a859294ae36cfa9c,This paper studies the query complexity of learning geodesically convex halfspaces on graphs. The main contribution of this paper is to provide an upper bound on query complexity which is linear in the treewidth and the minimum hull set size but only logarithmic in the diameter. The paper also provides tight lower bounds along well-established separation axioms and identify the Radon number as a central parameter of the query complexities and the VC dimension. The authors provide evidence that ground-truth communities in real-world graphs are often convex and empirically compare with other active learning algorithms.
SP:e880db33ba8c305ef1808a02325e2d2b7da95e68,"This paper proposes a low-fidelity (LoFi) video encoder optimization method for temporal action localization (TAL). The key idea is to reduce the mini-batch composition in terms of temporal, spatial or spatio-temporal resolution so that jointly optimizing the video encoders and TAL head becomes operable under the same memory conditions of a mid-range hardware budget. Experiments show that the proposed LoFi optimization approach can significantly enhance the performance of existing TAL methods."
SP:f79e91e469a70b219cd4a2116d5f389842f265ec,"This paper studies M-estimators with gradient-Lipschitz loss function regularized with convex penalty in linear models with Gaussian design matrix and arbitrary noise distribution. The authors provide general formulae for the derivatives of regularized M-Estimators where differentiation is taken with respect to both y and X. They also characterize the distribution of the residual ri = yi-xi beta^* in the intermediate high-dimensional regime where dimension and sample size are of the same order. Finally, they propose a novel adaptive criterion to select the tuning parameters of regularization parameters of the estimator."
SP:be53bc4c064402489b644332ad9c17743502d73c,"This paper proposes a new beam search algorithm for summarizing text. The key idea is to use a global scoring mechanism to calibrate beam search on the premise of global awareness. Specifically, a global protocol is proposed based on the attention distribution to stipulate how a global optimal hypothesis should attend to the source. Extensive experiments on nine datasets show that the global-aware inference significantly improves state-of-the-art summarization models. "
SP:4c7d14ab3304cfbf083815aa6e6d9c0e0a5fba6f,"This paper proposes a new self-attention mechanism, called Gauge Equivariant Transformer (GET), which uses a multi-head self attention mechanism to incorporate both position-based and content-based information. The main contribution of this paper is the introduction of gauge equivariance to self attention. The authors also propose a novel method to parallel transport the feature vectors in cyclic groups. Experiments are conducted on the SHREC and Human Body Segmentation datasets."
SP:19cd64baeb7db11b5ec066e6f8ccb4bc576d3588,"The paper proposes a method for unsupervised learning of finite mixture models. The method is based on expectation maximization and Metropolis-Hastings algorithm. The main idea is to evaluate only a small number of, stochastically sampled, components, thus substantially reducing the computational cost. Experiments are conducted on both synthetic and real-data settings."
SP:aae8847c5e52d14820967ab39770ab4ae16df59c,"This paper proposes a method for sparse training of deep neural networks. The authors formulate the training process as a continuous minimization problem under global sparsity constraint. They separate the optimization process into two steps, corresponding to weight update and structure parameter update. For the former step, they use the conventional chain rule, which can be sparse via exploiting the sparse structure, while for the latter step they propose a variance reduced policy gradient estimator, which only requires two forward passes without backward propagation, thus achieving completely sparse training. They prove that the variance of the estimator is bounded. Experiments on real-world datasets demonstrate the effectiveness of the proposed method."
SP:e0aa68ab03a3ef396b0dc4be4190b328d72cfab0,"This paper proposes a novel importance sampling method for non-equilibrium orbits. The proposed method is based on an invertible map T, which is used to sample points from the forward and backward orbits through points sampled from a proposal distribution ρ. The authors provide unbiased estimators of the normalizing constant Z and self-normalized IS estimator of expectations under π. They also propose a novel MCMC sampler which combines multiple IS estimates of Z and an iterated sampling-importance resampling mechanism to sample from π using T chosen as a discrete-time integrator of a conformal Hamiltonian system."
SP:506dca4f64f837e32958c3c43a0c68f194a36bb3,"This paper studies the problem of large-scale mini-batch set encoding. The authors propose a scalable and efficient attention-based set encoding mechanism called Slot Set Encoder (SSE) that is amenable to mini- batch processing of sets and capable of updating set representations as data arrives. The proposed method adheres to the required symmetries of permutation invariance and equivariance as well as maintaining MBC for any partition of the input set. Extensive experiments on various tasks such as image reconstruction, point cloud classification and dataset encoding demonstrate the effectiveness of the proposed method."
SP:b2eafdb24fa081ae8b37525d70fb4bc2d54518dc,"This paper presents an algorithm for action exploration and equilibrium approximation in games with combinatorial action spaces. This algorithm simultaneously performs value iteration while learning a policy proposal network. A double oracle step is used to explore additional actions to add to the policy proposals. At each state, the target state value and policy for the model training are computed via an equilibrium search procedure. Using this algorithm, the authors train an agent, DORA, completely from scratch for a popular two-player variant of Diplomacy and show that it achieves superhuman performance. The authors also extend their methods to full-scale no-press Diplomacy. "
SP:1ce1cef9988a07ccd2175a718b29ad23bc779429,"This paper studies the problem of multi-head attention in multilingual and multi-domain sequence modeling. The authors show that non-selective attention sharing is sub-optimal for achieving good generalization across all languages and domains, and propose attention sharing strategies to facilitate parameter sharing and specialization. The proposed method is evaluated in various tasks including speech recognition, text-to-text and speech to text translation. "
SP:69c522cea4a150624bc709e1c12c0f65183c1b2a,"This paper studies the effect of covariate shift on the generalization error of random feature regression under covariate shifts. The authors provide an exact asymptotic analysis of the test error, bias, and variance for random feature kernel regression when the covariate distribution is covariate shifted. The analysis is motivated by random matrix theory and shows that hard shifts imply increased error. The paper also provides a linear relationship between the in-distribution and out-of distribution generalization performance."
SP:ff1b7a7a6295e8f40f3b5df5f6950ca9d33603e0,"This paper studies the sensitivity of Thompson Sampling (TS) with a misspecified prior in the context of Bayesian meta-learning. The authors prove that the expected reward of TS with a well-specified prior is at most $\tilde{O}(H\epsilon^2)$ different from that of TS when the prior is not well-specifed. This result does not require the prior to have any parametric form and is independent of the cardinality or structure of the action space. In addition, the authors show that the bound is tight up to universal constants in the worst case. "
SP:3477b64480ed638b1c4e1f8aa73fc2e77666c89a,"This paper studies the sample and query complexity of the PAC-learning model and the Equivalence-Query-learning (EQ) model. In the PAC model, all samples are provided at the beginning of the learning process, while in the EQ model the samples are acquired through an interaction between a teacher and a learner, where the teacher provides counterexamples to hypotheses given by the learner. The authors prove an exponential separation for the sample/query complexity between the two models. They also discuss how their result relates to adversarial robustness. "
SP:7520cc1203bb06bbe432e7cc679892e95258ed99,"This paper studies the problem of scalable model selection for transfer learning. The authors formalize this task as “Scalable Diverse Model Selection” and propose several benchmarks for evaluating on this task. They find that existing model selection and transferability estimation methods perform poorly here and analyze why this is the case. They then introduce simple techniques to improve the performance and speed of these algorithms. Finally, they iterate on existing methods to create PARC, which outperforms all other methods."
SP:dcdb9c88f61ac3caf3da8255a7953c753cf048d1,"This paper proposes a method for learning low-dimensional binary codes (LLC) for instances and classes. The method does not require any side-information, like annotated attributes or label meta-data, and learns extremely low dimensional binary codes. The learnt codes are super-efficient while still ensuring nearly optimal classification accuracy for ResNet50 on ImageNet-1K. They demonstrate that the learnt codes capture intrinsically important features in the data, by discovering an intuitive taxonomy over classes. They further quantitatively measure the quality of our codes by applying it to the efficient image retrieval as well as out of distribution (OOD) detection problems."
SP:07def8c80d05f86402ce769313480b30cd99af43,"This paper proposes Generalized Depthwise-Separable (GDWS) convolution, which is a post-training approximation of a standard 2D convolution. GDWS improves the throughput of a pre-trained network on real-life hardware while preserving its robustness. It is scalable to large problem sizes since it operates on pre-training models and doesn't require any additional training. Experiments are conducted on CIFAR-10, SVHN, and ImageNet datasets."
SP:9e4d04b22ce4f986aabb747a42f40c827073e39e,"This paper proposes a method for retrosynthesis prediction based on a graph-based semi-template-based model. The model first predicts the set of graph edits transforming the target into incomplete molecules called synthons. Next, the model learns to expand synthons into complete molecules by attaching relevant leaving groups. This decomposition simplifies the architecture, making its predictions more interpretable, and also amenable to manual correction. The proposed method achieves a top-1 accuracy of 53.7% on the USPTO-50k dataset."
SP:772277d969c95924755113c86663fb0e009f24cc,"This paper proposes a Bayesian formulation of the deconditioning problem for statistical downscaling of low-resolution spatial fields with high-resolution (HR) information. The authors propose a conditional mean embedding estimator for multiresolution data. They show that this solution can be viewed as a two-staged vector-valued kernel ridge regressor and show that it has a minimax optimal convergence rate under mild assumptions. Finally, they demonstrate its proficiency in a synthetic and a real-world atmospheric field downscaled problem, showing substantial improvements."
SP:59cfeb59cecac51fecff8f8ceb0266fc6ac22a05,This paper proposes a neural architecture search (NAS) method for sparse prediction. The authors propose a distilled search space to cover the desired architectures with fewer parameters. They also propose a progressive search algorithm for efficient search on the space. Experiments on three real-world benchmark datasets show promising results of the proposed method.
SP:23a2171eab71c4fd3754791ca2aac9be87411cdb,"This paper studies regularization methods for fine-tuning a pre-trained model for transfer learning. The authors provide a PAC-Bayes generalization bound that depends on the distance traveled in each layer during fine tuning and the noise stability of the fine tuned model. Based on the analysis, they propose a regularized self-labeling method that interpolates between regularization and self-labelling methods, including (i) layer-wise regularization, (ii) self label-correction and label-reweighting to correct mislabeled data points (that the model is confident) and reweight less confident data points. They validate their approach on an extensive collection of image and text data sets using multiple pretrained model architectures."
SP:f2a77f93bdc0401bbd6162a16fba25b9f90530e2,"This paper studies the multi-armed bandit best-arm identification problem, where the goal is to identify the arm from among finitely many that has the smallest CVaR, VaR, or weighted sum of the two. The authors propose an optimal $\delta$-correct algorithm that acts on general arms, including heavy-tailed distributions, and matches the lower bound on the expected number of samples needed, asymptotically. The algorithm requires solving a non-convex optimization problem in the space of probability measures, that requires delicate analysis. "
SP:765942c86da1594b33268df6d0d15c682bc7eaa6,"This paper proposes a new vision transformer architecture called ViTAE, which is based on spatial pyramid reduction modules to embed the input image into tokens with rich multi-scale context by using multiple convolutions with different dilation rates. The proposed architecture is able to learn intrinsic scale invariance IB and robust feature representation for objects at various scales. Experiments on ImageNet as well as downstream tasks prove the superiority of the proposed architecture. "
SP:5e3572a386f890c5864437985cf63b13844f338f,"This paper proposes Robust Informative Fine-Tuning (RIFT), a novel adversarial fine-tuning method from an information-theoretical perspective. In particular, RIFT encourages an objective model to retain the features learned from the pre-trained model throughout the entire fine tuning process, whereas a conventional one only uses pre-training weights for initialization. Experimental results show that RIFT consistently outperforms the state-of-the-arts on two popular NLP tasks: sentiment analysis and natural language inference."
SP:167a8b7e0173bffc5f08a9c2f378fe7bdf837da3,"This paper proposes a stochastic Anderson mixing (SAM) method for non-convex optimization problems. The main contribution of this paper is to introduce damped projection and adaptive regularization to the classical Anderson mixing. Theoretically, the authors show that the convergence of SAM is almost sure to stationary points and the worst-case iteration complexity. Moreover, the complexity bound can be improved when randomly choosing an iterate as the output. To further accelerate the convergence, they incorporate a variance reduction technique into the proposed SAM. Finally, they apply the SAM method to train various neural networks including CNN, ResNets, WideResNet, ResNeXt, DenseNet and LSTM."
SP:fe9c80cc5615705ef844d59b56413779c8d54a06,"This paper proposes a novel stochastic algorithm for solving linear inverse problems with additive white Gaussian noise. The proposed method is based on annealed Langevin dynamics and Newton’s method, and uses a pre-trained minimum mean squared error (MMSE) Gaussian denoiser. The authors show that the proposed method can produce samples of high quality from the posterior distribution of the unknown given the measurements, while guaranteeing their validity with respect to the given data. "
SP:b04caddcb2dc9e9b365a76fdbf3d3eb4efcdffd9,This paper proposes a new framework to detect drug traffickers on Instagram. The framework is based on a heterogeneous graph (HG) and a relation-based graph convolutional neural network (R-GCN) to learn node representations over the built HG. A self-supervised module and a knowledge distillation module are further designed to exploit unlabeled data for improving the model. Extensive experiments on real-world data collected from Instagram demonstrate the effectiveness of the proposed method.
SP:242da1384f48260d58a0e7949438611c05079197,This paper studies the question of whether the class of functions that are exactly representable by a neural network with ReLU activations and a given architecture is strictly increased by adding more layers (with no restrictions on size). This question has potential impact on algorithmic and statistical aspects because of the insight it provides into the neural hypothesis class. The authors also present upper bounds on the sizes of neural networks required to represent functions in these neural hypothesis classes. 
SP:8d5741aedf3125e0e790a58ec3ce81a4e2ea4dcb,"This paper proposes a general framework of min-max optimization over multiple domains that can be leveraged to improve the design of different types of adversarial attacks. In particular, given a set of risk sources, minimizing the worst-case attack loss can be reformulated as a min-min problem by introducing domain weights that are maximized over the probability simplex of the domain set. The authors showcase this unified framework in three attack generation problems – attacking model ensembles, devising universal perturbation under multiple inputs, and crafting attacks resilient to data transformations. Extensive experiments demonstrate that the approach leads to substantial attack improvement over the existing heuristic strategies as well as robustness improvement over state-of-the-art defense methods trained to be robust against multiple perturbations types. "
SP:9dcb74bfdbc4aa1e27f5d2adb6d2abf475e9324d,"This paper studies the problem of sparse tensor principal component analysis (SSTM) with i.i.d. Gaussian entries, where the goal is to recover the k-sparse unit vector x \in R. The authors propose a family of algorithms that interpolates between a simple polynomial-time algorithm and the exponential-time exhaustive search algorithm for the sparse regime of k \leq \sqrt{\sqrt{n}$. For any 1\leq k, their algorithms recovers the sparse vector for signal-tonoise ratio in time $\mathcal{O}(k/t)$, capturing the state-of-the-art guarantees for the matrix settings (in both the polynomially time and sub-exponential time regimes). Their results extend to the case of r distinct k sparse signals with disjoint supports, with guarantees that are independent of the number of spikes. "
SP:660137b0f84e47c06dc2bee1c95b299c67e4cb67,"This paper proposes a progressive progressive encoding (SAPE) scheme for input signals of multilayer-perceptron (MLP) networks. SAPE gradually unmasks signal components with increasing frequencies as a function of time and space. The progressive exposure of frequencies is monitored by a feedback loop throughout the neural optimization process, allowing changes to propagate at different rates among local spatial portions of the signal space. Experiments on a variety of domains and applications demonstrate the effectiveness of the proposed SAPE."
SP:b03063fa82d76db341076e5f282176f4c007a202,"This paper studies the problem of finding the quantal response equilibrium of two-player matrix games with entropy regularization. The authors show that the last iterates of two policy-extragradient methods (PU and OMWU) are guaranteed to converge linearly to the QRE at a linear rate. The convergence rate is independent of the size of the state and action spaces up to logarithm factors. In addition, by controlling the knob of entropy regularisation, the proposed algorithms can also find an approximate Nash equilibrium of the unregularized matrix game at a sublinear rate. "
SP:862223b8bd4c275f96c7e41c92daaa2ca2906194,"This paper proposes an implicit transformer super-resolution network (ITSRN) for SCISR. Specifically, pixel values at query coordinates are inferred from image features at key coordinates by the proposed implicit transformer and an implicit position encoding scheme is proposed to aggregate similar neighboring pixel values to the query one. Extensive experiments show that the proposed ITSRN outperforms several competitive continuous and discrete SR methods for both compressed and uncompressed SCIs."
SP:3751625929b707ced417c3eb10064e4917866048,This paper proposes a method for learning interventional distributions using sumproduct networks (SPNs) that are over-parameterized by neural networks. The method is motivated and illustrated by a structural causal model inspired by personal health. The empirical evaluation shows that the proposed method is able to precisely estimate the conditioned variables and outperform generative baselines. 
SP:c857ff674ca05c1d949337cb885f056b82d981d6,"This paper proposes a new factor analysis method for functional magnetic resonance imaging (fMRI) data. The proposed method is based on a Markovian neural network (MNN) and a discrete latent state-space embedding. The MNN is used to capture temporal dynamics of neural processes, and the latent embedding is used for clustering fMRI data in its low dimensional temporal embedding with regard to subject and cognitive state variability. Experiments are conducted on both synthetic and real-world fMRI datasets."
SP:855dcaa42868a29a14619d63221169495ed5dd54,"This paper proposes a new generative model based on continuous normalizing flows (CNFs) for learning densities for complex geometries described via manifolds, such as spheres, tori, and other implicit surfaces. The density is parameterized as the source density minus the divergence of a neural network (NN). The divergence is a local linear differential operator, easy to approximate and calculate on manifolds. Unlike other CNFs, MF does not require invoking or backpropagating through an ODE solver during training. Theoretically, the authors prove that MF constitutes a universal density approximator under suitable assumptions. Empirically, they demonstrate for the first time the use of flow models for sampling from general curved surfaces and achieve significant improvements in density estimation, sample quality, and training complexity. "
SP:545554de09d17df77d6169a5cc8f36022ecb355c,"This paper studies the problem of unsupervised representation learning in the context of non-linear mixing. The authors propose an approach based on independent component analysis (ICA) to recover the identifiability of the latent code that generates the data, given only observations of mixtures thereof. The approach is motivated by considering independent causal mechanisms, i.e., each source independently influencing the mixing process, which gives rise to a framework which the authors term independent mechanism analysis.  The authors provide theoretical and empirical evidence that their approach circumvents a number of nonidentifiability issues arising in nonlinear blind source separation. "
SP:7df49c554d6c9fca370f049279ef7324b6f79de9, distribution. The authors propose a method to approximate the log likelihood of an unnormalized target distribution by using an Annealed Importance Sampling (AIS) like procedure with an Uncorrected Hamiltonian MCMC (UHA). The authors show that UHA leads to tight and differentiable lower bounds on logZ. They show empirically that their method yields better performances than other competing approaches. 
SP:b0bf070e8d7eefdfc45f236e9ecb9edfb4816e0a,"This paper proposes a local Lipschitz bound for training neural networks for certified robustness. The main idea is to remove the redundant rows and columns corresponding to the constant activation outputs in the weight matrix. The authors also propose to clip activation functions (e.g., ReLU and MaxMin) with a learnable upper threshold and a sparsity loss to assist the network to achieve an even tighter local bound. Experiments are conducted on MNIST, CIFAR-10 and TinyImageNet to demonstrate the effectiveness of the proposed method."
SP:f6314bfd897cb996de2eaabf0d3037f41da467f3,"This paper studies the problem of conformal Bayesian predictive intervals. Conformal predictive intervals are defined by Bayesian posterior predictive distributions, which characterize subjective beliefs on outcomes of interest conditional on predictors, conditional on model parameters. The authors propose a scalable MC method for producing conformal posterior predictive intervals with finite sample calibration guarantees. The proposed method is based on re-weighting the posterior samples of model parameters using an importance sampling algorithm. The experiments show that the proposed method outperforms existing methods."
SP:1e86c162b8e8d652a0590b66aa5f7c363955cc5b,"This paper proposes a method for solving inverse problems with denoising denoisers. The proposed method is based on a potential-driven denoiser, which is a neural network that is trained with a loss function that is parameterized by a scalar-valued deep neural network. The authors show that the proposed method converges to stationary points of an underlying objective function. The paper also provides theoretical guarantees for the convergence of the method. Finally, the method is evaluated on a variety of image classification tasks."
SP:da92e936f88b3842ca82c2914413b129ca35890f,"This paper proposes a method to generate music that is in-sync with human body movements. The method is based on extracting skeleton keypoints from a video and using a sequence of models to translate them to generate a rhythmic sound. In particular, the method first infers the music beat and the style pattern from body keypoints per each frame to produce the rhythm. Next, it implements a transformer-based model to generate the hits of drum instruments and implements a U-net based model for generating the velocity and the offsets of the instruments. Additional types of instruments are added to the soundtrack by further conditioning on generated drum sounds. "
SP:0f7ff312a242a553dc9ecf35b421e58fb2d50a26,This paper proposes a simple one-step algorithm for offline reinforcement learning. The algorithm is based on a constrained policy improvement using an on-policy Q estimate of the behavior policy. This algorithm is shown to outperform iterative approaches on a large portion of the D4RL benchmark. The authors argue that the performance is due to the high variance inherent in doing off-policy evaluation and magnified by the repeated optimization of policies against those estimates. They also hypothesize that a combination of favorable structure in the environment and behavior policy is responsible.
SP:0346eba4f587acbe3492d039066f1737360fd870,"This paper studies the problem of low-rank and nonsmooth matrix optimization under the generalized strict complementarity (GSC) assumption. The authors prove that the extragradient method, when initialized with a warm-start point, converges to an optimal solution with rate $O(1/t)$ while requiring only two low rank SVDs per iteration. They also give a precise trade-off between the rank of the SVD and the radius of the ball in which we need to initialize the method. Finally, they support their theoretical results with empirical experiments on several tasks."
SP:d39f1d77d9919f897ccf82958b71be8798523923," treatment effects (CATEs) for structured treatments (e.g., graphs, images, texts). Given a weak condition on the effect, the authors propose a generalized Robinson decomposition (GRD) which isolates the causal estimand (reducing regularization bias), allows one to plug in arbitrary models for learning, and possesses a quasi-oracle convergence guarantee under mild assumptions. In experiments with small-world and molecular graphs, the proposed method outperforms prior work in CATE estimation."
SP:eeb42a1e48857f976a647eb8d86d25c9012962d5,"This paper studies the problem of causal effect identification, i.e., determining whether a causal effect is computable from a combination of qualitative assumptions about the underlying system (e.g., a causal graph) and distributions collected from this system. The authors first characterize the relationships between certain graphically-driven formulae and matrix multiplications. Then, they extend the spectrum of proxy variable based identification conditions and propose novel intermediary criteria based on the pseudo-inverse of a matrix. Finally, they devise a causal identification algorithm, which accepts as input a collection of marginal, conditional, and interventional distributions, integrating enriched matrix-based criteria into a graphical identification approach."
SP:db15860d08418f6bc792c2ade2eade32840a12b8,"This paper proposes Dual Curriculum Design (DCD), a variant of Unsupervised Environment Design (UED) where the free parameters of an underspecified environment are automatically adapted during training to the agent’s capabilities, leading to the emergence of diverse training environments. The authors cast Prioritized Level Replay (PLR), an empirically successful but theoretically unmotivated method that selectively samples randomly-generated training levels, as UED. They argue that by curating completely random levels, PLR, too, can generate novel and complex training levels for effective training. This insight reveals a natural class of UED methods that they call DCD. DCD includes both PLR and a popular UED algorithm, PAIRED, as special cases and inherits similar theoretical guarantees. This connection allows them to develop novel theory for PLR with a robustness guarantee at Nash equilibria. "
SP:9ed528da4b67f22678303cfd975aafe678db6411,"This paper studies the multi-armed bandit problem in the shuffle model with a distribution-dependent regret of $O(\sqrt{a} + k \log T \log 1/\delta^2)$, where $a$ is the suboptimality gap of the arm a and $k$ the total number of arms. The main contribution of this paper is to provide a differentially private algorithm for the MAB problem with a regret that matches the regret of the best known algorithms for the centralized model. The algorithm is batched with a private binary summation mechanism for the shuffling model."
SP:de2523a5fdebda3573f1063447a7818bf3ed6333,"This paper proposes a new notion of calibration called threshold calibration, which is exactly the condition required to ensure that decision loss is predicted accurately for threshold decisions. The authors provide an efficient algorithm which takes an uncalibrated forecaster as input and provably outputs a threshold-calibrated predictor. The procedure allows downstream decision makers to confidently estimate the loss of any threshold decision under any threshold loss function. Empirically, threshold calibration improves decision loss prediction without compromising the quality of the decisions in two real-world settings: hospital scheduling decisions and resource allocation decisions."
SP:f55160db59c6f3e85f6e1ea0ec32c1a0982fbc48,"This paper proposes a general method to construct centroid approximation for the distribution of maximum points of a random function (a.k.a. argmax distribution), which finds broad applications in machine learning. The method optimizes a set of centroid points to compactly approximate the arg max distribution with a simple objective function. Theoretically, the argmax centroid method can be shown to minimize a surrogate of Wasserstein distance between the ground-truth argmin distribution and the centroids approximation under proper conditions. The authors demonstrate the applicability and effectiveness of the proposed method on a variety of real-world multitask learning applications, including few-shot image classification, personalized dialogue systems and multi-target domain adaptation."
SP:ef342e3c6a16e898a49b700a9fd4f0ea6a069dcc,"This paper studies the problem of multi-objective reinforcement learning (MORL) where the preferences are given in an adversarial manner. The authors formalize this problem as an episodic learning problem on a Markov decision process, where transitions are unknown and a reward function is the inner product of a preference vector. They consider two settings. In the online setting, the agent receives a (adversarial) preference every episode and proposes policies to interact with the environment. They provide a model-based algorithm that achieves a nearly minimax optimal regret bound. Furthermore, they consider preference-free exploration, i.e., the agent first interacts with the environments without specifying any preference and then is able to accommodate arbitrary preference vector up to error. "
SP:aa84981dd503ec34d9f06aa6e5f680e267f82b04,"This paper studies the problem of generating explanations for dialogue response generation. The authors propose a local explanation of response generation (LERG) method, which is based on the mutual interaction of segments in input and output sentences. Specifically, LERG views the sequence prediction as uncertainty estimation of a human response and then creates explanations by perturbing the input and calculating the certainty change over the human response. Experiments are conducted to show the effectiveness of the proposed method."
SP:965413b1726617006317bbbec55673dd5d21812a,"This paper studies the convergence of the error-compressed gradient compression method Katyusha, which is a variant of the original Katyusha algorithm. The authors show that the convergence rate of Katyusha can be accelerated by using the error compensation mechanism in conjunction with the acceleration mechanism employed in loopless Katyusha (L-Katyusha). The convergence rate is shown to be faster than previous error compensated gradient compression methods. "
SP:27c58dad7fa7743a8ff56fad863aa0dae823dccb,"This paper proposes a neuron-astrocyte liquid state machine (NALSM) to improve the performance of the LSM by self-organizing the dynamics around a critical branching factor that is associated with the edge-of-chaos. The method is based on the observation that astrocytes, a long-neglected non-neuronal brain cell, modulate synaptic plasticity and brain dynamics, tuning brain networks to the vicinity of the computationally optimal critical phase transition between order and chaos. The authors demonstrate that NALSM achieves better performance on MNIST and N-MNIST datasets without the need for data-specific hand-tuning."
SP:64ccd697d3c11d7d8947ef1b06c61d94b6a2e575,"This paper proposes a method for semi-supervised node classification based on topology-imbalance. The authors claim that the topology imbalance is a unique source of imbalance from the asymmetric topological properties of the labeled nodes, i.e., labeled nodes are not equal in terms of their structural role in the graph (topology imbalance). Based on this observation, the authors propose an influence conflict detection–based metric Totoro to measure the degree of graph topological imbalance and propose a model-agnostic method ReNode to re-weight the influence of labeled nodes adaptively based on their relative positions to class boundaries. Extensive experiments demonstrate the effectiveness and generalizability of the proposed method."
SP:ec12f0a05db75ac15ad22b34cdc2a0142bc2c72f,"This paper studies the problem of estimating the partition of the lattice induced by the constancy regions of the unknown signal, using the DCART method proposed by [14]. The authors prove that, under appropriate regularity conditions on the shape of the partition elements, a DCART-based procedure consistently estimates the underlying partition at a rate of order $\sigma^2k \log(N)/k$, where k is the minimal number of rectangular sub-graphs obtained using recursive dyadic partitions supporting the signal partition, σ is the noise variance, and $\kappa$ is the smallest magnitude of the signal difference among contiguous elements of the rectangular partition. The authors also show that under stronger assumptions, the method attains a sharper estimation error of order σ log(N/k) independent of k, which is minimax rate optimal. "
SP:3c65b3e69a024431cafdc1b4bfbccd432de69faf,"This paper proposes Counterfactual Maximum Likelihood Estimation (CMLE) to reduce the spurious correlations caused by observed confounders in observational data. The authors give theoretical analysis on the underlying general Structural Causal Model (SCM) and propose to perform maximum likelihood estimation (MLE) on the interventional distribution instead of the observational distribution. Two different upper bounds of the expected negative log-likelihood are derived and two general algorithms, Implicit CMLE and Explicit CMLE, for causal predictions of deep learning models using observational data are proposed. Experiments are conducted on both simulated data and two real-world tasks: Natural Language Inference (NLI) and Image Captioning. The results show that CMLE methods outperform the regular MLE method in terms of out-of-domain generalization performance and reducing spurious correlations."
SP:c5a59c8d6db0f5491721aaaef182609c360930d3,"This paper studies the problem of multi-task learning in the multi-objective optimization setting, where the objective is to minimize the average loss across all tasks. The authors propose a new algorithm called CAGrad, which maximizes the worst local improvement of any task’s loss in a neighborhood of the average gradient. The algorithm is shown to be a special case of the regular gradient descent (GD) and the multiple gradient descent algorithm (MGDA) as special cases. Experiments show that the proposed algorithm outperforms the state-of-the-art gradient manipulation methods on a series of supervised learning and reinforcement learning tasks."
SP:000cbfda2e26fdcfee50a628799a73b6886cfccc,"This paper studies the problem of few-shot learning in the context of language models. Specifically, the authors study how language models can identify simple algorithmic concepts from small witness sets. In particular, they explore how several GPT architectures, program induction systems, and humans perform in terms of the complexity of the concept and the number of additional examples, and how much their behaviour differs. The paper is well organized and easy to follow."
SP:ba01895bf1aa07a0630b8c41fc0e91effb34b4cf,"This paper proposes a novel method of distilling feature representation into robust and non-robust features using Information Bottleneck. Specifically, it injects noise variation to each feature unit and evaluates the information flow in the feature representation to dichotomize feature units based on the noise variation magnitude. Through comprehensive experiments, the distilled features are highly correlated with adversarial prediction, and they have human-perceptible semantic information by themselves. "
SP:ed67b2664359799a11cebb9eaba6da74ff1dd977,"This paper studies the phenomenon of support vector proliferation in support vector machine (SVM) and minimum Euclidean norm least squares regression (MORL). The authors prove a super-linear lower bound on the dimension (in terms of sample size) required for support vectors proliferation in independent feature models. They further identify a sharp phase transition in Gaussian feature models, bound the width of this transition, and give experimental support for its universality. Finally, they hypothesize that this phase transition occurs only in much higher-dimensional settings in the l1 variant of the SVM and present a new geometric characterization of the problem that may elucidate this phenomenon."
SP:99f226a63902863c429cb7baefab09626d13921e,"This paper studies the problem of best policy identification (BPI) in Markov Decision Processes (MDPs), where the agent sequentially selects actions and, from the resulting system trajectory, aims to identify the best policy as fast as possible. The authors propose a problem-dependent lower bound on the average number of steps required before a correct answer can be given with probability at least 1-\delta. They also provide the first algorithm with an instance-specific sample complexity in this setting. "
SP:de4a0f5a464aa3311445cc25c4915cf0c4d975c3,"This paper proposes Cone Embeddings (ConE), a geometry-based query embedding model that can handle all the FOL operations, including conjunction, disjunction, and negation. ConE represents entities and queries as Cartesian products of two-dimensional cones, where the intersection and union of cones naturally model the conjunction and disjunctions operations. Experiments demonstrate that ConE significantly outperforms existing state-of-the-art methods on benchmark datasets."
SP:773b5b6d31e6899da395933eb7f9e25a6e50c406,"This paper studies the problem of control of stochastic nonlinear systems with separable cost and constraints in the state and input variables. The authors propose a novel numerical scheme for implementation of the corresponding value iteration (VI) algorithm in the conjugate domain. Detailed analyses of the convergence, time complexity, and error of the proposed algorithm are provided. "
SP:7cd593ccba4830f3383a92ef6266224cc7699706,"This paper presents a self-supervised multimodal representation learning framework based on Transformers. Specifically, the authors propose a VideoAudio-Text Transformer (VATT) that takes raw signals as inputs and extracts multimodals representations that are rich enough to benefit a variety of downstream tasks. The authors train VATT end-to-end from scratch using multimodality contrastive losses and evaluate its performance by the downstream tasks of video action recognition, audio event classification, image classification, and text to video retrieval. The results show that the convolution-free VATT outperforms state-of-the-art ConvNet-based architectures in the downstream task."
SP:97f533426dce73d27768dd7afc2ddf035cf21e61,"This paper proposes a kernelized version of self-attention, which replaces the softmax structure with a Gaussian kernel to stabilize the model training and adapts the Nyström method to a non-positive semidefinite matrix to accelerate the computation. The authors provide theoretical analysis by showing that the matrix approximation error of the proposed method is small in the spectral norm. Experiments on the Long Range Arena benchmark show that the proposed model is sufficient in getting comparable or even better performance than the full self attention while requiring fewer computation resources."
SP:a6f1094a4c9f38df38c9710b9dcd6299f430fae2,This paper proposes a data augmentation method for policy cloning. The main idea is to augment the data of an expert policy with data from a student policy. The augmented policy cloning (APC) method is based on the idea that the student policy should be invariant to perturbations of the expert policy in a region around the expert trajectories. The paper shows that the APC method can be used to improve the data efficiency of policy cloning for high-degree of freedom (DoF) control problems.
SP:3660d1d4a8e8f281880781ba32df7b678b705f9c,"This paper proposes a method to improve the robustness of deep neural networks by designing objects that are robust to out-of-distribution (OOD) perturbations. The method is based on the observation that deep networks are sensitive to small changes in the shape and texture of the objects. The authors show that the resulting unadversarial objects are more robust to distributional shifts and corruptions. The proposed method is evaluated on CIFAR-10, ImageNet-C, and robustness-based benchmarks."
SP:4c12852373f5f113bd47dce3e2434c5e7d61a202,"This paper investigates the problem of data augmentation in off-policy reinforcement learning. The authors identify two problems, i.e. high-variance Q-targets, and propose a simple yet effective technique for stabilizing this class of algorithms under augmentation. The experimental results show that the proposed method improves stability and sample efficiency of ConvNets and Vision Transformer-based architectures."
SP:f8ca9d92c45adc4512381035856b445029e3080a,"This paper studies the problem of federated learning (FL) where multiple worker nodes (WNs) build a joint model by using local data. The authors consider a class of stochastic algorithms where the WNs perform a few local updates before communication. They show that when both the WN's and the server's directions are chosen based on a certain momentum estimator, the algorithm requires O(3/2) samples and O(1) communication rounds to compute an $\epsilon$-stationary solution. This is the first FL algorithm that achieves such near-optimal sample and communication complexities simultaneously. "
SP:bd3eecb81a17af010f2d3555434990855c1810f2,"This paper studies the generalization ability of stochastic gradient Langevin dynamics (SGLD) with isotropic noise. The authors propose to optimize the information-theoretical generalization bound by manipulating the noise structure in SGLD. They prove that with constraint to guarantee low empirical risk, the optimal noise covariance is the square root of the expected gradient covariance if both the prior and the posterior are jointly optimized. "
SP:19fbd1a381598538662417a4a1885ba4ac04f5f8," video compression methods have demonstrated great promise in catching up with traditional video codecs in their rate-distortion (R-D) performance. How2 ever, existing learned video compression schemes are limited by the binding of 3 the prediction mode and the fixed network framework. To break this limitation, this paper proposes a versatile video compression framework (VLVC) framework that uses one model to support all possible prediction modes. Specifically, to realize versatile compression, the proposed VLVC first builds a motion compensation module that applies multiple 3D motion vector fields (i.e., voxel flows) for weighted trilinear warping in spatial-temporal space. "
SP:ba790fdcf2deef1a1b5e1961c7c4a28dd0218420,"This paper studies a generalization of the Online Mirror Descent (OMD) algorithm, called Multi-Task OMD (MT-OMD), which operates by sharing updates between tasks. The authors prove that the regret of the proposed algorithm is of order \sqrt{1 + \sigma^2(N-1) + \tilde{T}(N - 1)^2, where $\sigma$ is the task variance according to the geometry induced by the regularizer, N is the number of tasks, and T is the time horizon. This improves upon the NT bound obtained by running independent OMDs on each task. Experiments are conducted on several real-world datasets. "
SP:75f80e4e7836a7575e60de7f055820c6c7065fcb,"This paper studies the underdamped Langevin diffusion (ULD) with strongly convex potential consisting of finite summation of N smooth components, and proposes an efficient discretization method, which requires O(N + d 1 3N^2 / \epsilon^2 3 ) gradient evaluations to achieve $\�-error$ for approximating d-dimensional ULD. The authors also prove a lower bound of gradient complexity as $\Omega(N+d 1 3 N^2/\epsilon^2)$, which indicates that their method is optimal in dependence of dependence of N, $\�, and d. Experiments on both synthetic and real-world data show that the proposed method consistently outperforms existing ULD approaches."
SP:22822f378c3fbc15b77eb736194b1ce7f0585072,This paper proposes a method for continual learning that combines weight regularization with a trust region based optimization procedure. The trust region is constructed from an approximate posterior distribution over the parameters given previous tasks. This trust region encourages parameter updates to be in the null space of previously acquired tasks while maintaining convergence to a maximum of the Bayesian approximate posterior. The proposed method is evaluated on both feedforward and recurrent networks.
SP:26de056be14962312c759be5d284ef235d660f9c,"Normalizing flows are invertible neural networks with tractable change-of-volume terms, which allow optimization of their parameters to be efficiently performed via maximum likelihood. However, data of interest are typically assumed to live in some (often unknown) low-dimensional manifold embedded in a high-dimensional ambient space. Injective flows aim to fix this discrepancy by learning distributions on manifolds, but the resulting volume-change term becomes more challenging to evaluate. This paper proposes two methods to calculate the gradient of this term with respect to the parameters of the model, relying on careful use of automatic differentiation and techniques from numerical linear algebra. Both approaches perform end-to-end nonlinear manifold learning and density estimation for data projected onto this manifold."
SP:395dae632dab83f3f61bdf67eabe4d351492798c,"This paper proposes Latent Equilibrium, a new framework for inference and learning in neural networks with slow components. The key idea is to leverage the ability of biological neurons to phase-advance their output with respect to their membrane potential. This principle enables quasi-instantaneous inference independent of network depth and avoids the need for phased plasticity or computationally expensive network relaxation phases. The authors derive disentangled neuron and synapse dynamics from a prospective energy function that depends on a network’s generalized position and momentum. "
SP:b937901e3230b14e36975fbab0658a52bdac4977,"This paper proposes a new method to improve the expressiveness of GNNs. The key idea is to learn a subgraph around each node and apply a base GNN to each subgraph. The whole graph representation is then obtained by pooling these subgraph representations. The authors provide a rigorous theoretical analysis showing that NGNN is strictly more powerful than 1-WL. In particular, the authors prove that the proposed method can discriminate almost all r-regular graphs, where 1-wL always fails."
SP:7b8284aa82022ce73802bfc57238b0d82031b226,"This paper proposes nested variational inference (NVI), a method to learn proposals for nested importance samplers by minimizing an forward or reverse KL divergence at each level of nesting. NVI is applicable to many commonly-used importance sampling strategies and provides a mechanism for learning intermediate densities, which can serve as heuristics to guide the sampler. The authors apply NVI to (a) sample from a multimodal distribution using a learned annealing path, (b) learn heuristic that approximate the likelihood of future observations in a hidden Markov model, and (c) perform amortized inference in hierarchical deep generative models. The experiments show that optimizing nested objectives leads to improved sample quality in terms of log average weight and effective sample size."
SP:f3792f82b28727a7a198c6eac9511391d2045a5f,"This paper studies the problem of certified zeroth-order Lipschitz optimization of a function f defined on a compact subset X of R, with the additional constraint that algorithms must certify the accuracy of their recommendations. The authors characterize the optimal number of evaluations of f to find and certify an approximate maximizer of f at accuracy $\varepsilon$. Under a weak assumption on X, this optimal sample complexity is shown to be nearly proportional to the integral $\IoX dx/(max(f)− f(x) + \epsilon)$. The authors also show that a certified version of the computationally tractable DOO algorithm matches these packing and integral bounds. "
SP:6e8134eeaf524db765a6186f3de74e936243f8d4,"This paper proposes an adversarial attack on uncertainty estimation of deep neural networks (DNNs). The attack is based on perturbing the loss function of the DNN with a small perturbation. The attack can be applied in both black-box and white-box settings. Experiments show that the attack is able to cause severe uncertainty estimation damage, with larger magnitudes resulting in unusable uncertainty estimates."
SP:c5a5bf6e0bdebf5170c8fe3fedd2f3438e39cd21,"This paper studies the problem of community detection in dynamic networks. In particular, the authors propose a new stochastic block model (StSBM) based on the streaming belief-propagation (STREAMBP) algorithm. The authors prove that voting algorithms have fundamental limitations in the StSBM. They also prove that STREAMBP is optimal in certain regimes. Finally, they validate their theoretical findings on synthetic and real data."
SP:b1163857a6b06047c3531ab762642fcbed6dd294,"This paper studies the representation cost induced by regularizers on linear predictors. The authors focus on linear neural networks as parameterizations of linear predictor and identify the representation costs of certain sparse linear ConvNets and residual networks. They also study the reverse problem, identifying which regularizers induced by l2 regularization can be represented by simple l2-regularization and designing the parameterizations that do so."
SP:c9c7fc5288e24a54531b7063c028d307279fe2ef,This paper proposes a non-parametric approach for reasoning over knowledge graphs. The approach is based on finding multiple graph path patterns that connect similar source entities through the given relation. The method achieves state-of-the-art performance on the NELL-995 and FB-122 datasets. The authors also demonstrate that the proposed method is robust in low data settings.
SP:f63e4ed39d577b50eab4f4b6d08ef912a69840ef,"This paper presents a transformer-based entity linking model that combines a Transformer architecture with large scale pre-training from Wikipedia links. The model achieves the state-of-the-art performance on two commonly used entity linking datasets: CoNLL and TAC-KBP. The authors also provide detailed analyses to understand what design choices are important for entity linking, including choices of negative entity candidates, transformer architecture, and input perturbations. "
SP:eaeee88e0717cda8d6f3d8ff83ebe594eba44f29,"This paper proposes an ensemble active learning (AL) method for training large ensembles of deep neural networks (DNNs) with large labeled datasets. The proposed method is based on ensemble Active Learning (AL), where the ensemble is composed of a large number of DNNs (hundreds of models) and the goal is to find a subset of training samples that are most likely to be useful for the training of the ensemble. This is done by using the ensemble to estimate the uncertainty of each sample in a dataset, and then choosing only the highest uncertainty samples for training. Experiments are conducted on CIFAR-10, Cifar-100 and ImageNet to show the effectiveness of the proposed method."
SP:4a1cce61f12c68846c507130bd055b3444ac8101,This paper proposes a new routing algorithm for Capsule networks. The proposed algorithm is based on inverted dot-product attention. The authors also propose a concurrent iterative routing method to improve the performance of the proposed algorithm. Experiments are conducted on CIFAR-10/100 and DiverseMultiMNIST datasets. 
SP:99ca283c579152bc44b19c21392aeb7f6b76231b,"This paper proposes a method for optimizing hyperparameters in deep neural networks by sampling non-local paths in the joint hyperparameter/model-parameter space. The main idea is to use a temperature-like quantity to map the hyper-parameters to an effective temperature, which can be used to control the level of correlated noise in training. The method is based on the parallel tempering technique of statistical physics. The experiments show that the proposed method can improve the performance of neural networks trained with dropout and learning rate optimization."
SP:beba754d96cc441712a5413c41e98863c8abf605,"This paper analyzes the effect of reinforcement learning (RL) in the context of machine translation (MT) tasks. The authors show that REINFORCE, a popular RL method for MT, does not optimize the expected reward, and show that other methods take an infeasibly long time to converge. They also show that RL practices in MT are likely to improve performance only where the pre-trained parameters are already close to yielding the correct translation. "
SP:366b68d2490ea7569c74dc66ec0f83daa029ddd9,"This paper considers the problem of estimating the Q-values of optimal value functions with closed-form characterizations of the asymptotic variances. The main contribution of this paper is the construction of confidence regions for Q-value and optimal value function, which can be used to construct policies to minimize their estimation errors. This paper also provides a policy exploration strategy that relies on estimating the relative discrepancies among the Q estimates. Numerical experiments show superior performances of the exploration strategy than other benchmark approaches."
SP:d922459581c3295ff315fda6e59b9f7e9147f22d,"This paper proposes a new recommendation method based on the minimum description length (MDL) principle to improve the efficiency of the recommendation process. Specifically, the MDL principle is used to learn compact and informative binary codes from the content data. The authors also propose a new marketing strategy through mining potential users by a generative step. Extensive experiments on two public datasets show the advantages for recommendations in various settings."
SP:c2a5551f229211c9aa4c43686b517fcde82bbccf,"This paper proposes Adversarial Inductive Transfer Learning (AITL), a method for addressing discrepancies in input and output spaces between source and target domains. AITL utilizes adversarial domain adaptation and multi-task learning to address these discrepancies. The motivation is to bridge the gap between large pre-clinical pharmacogenomics datasets (e.g. cancer cell lines) and clinical data (i.e. patients) with drug response outcome is very limited, creating a need for transfer learning. To address the input space discrepancy, the authors propose to use a feature extractor to learn features for target and source samples. The output space discrepancy is addressed by the multi- task subnetwork, which has one shared layer and separate classification and regression towers, and assigns binary labels (called cross-domain labels) to the source samples and assigns class-wise discriminators to the target samples to regularize the learned features."
SP:a27f975266e990b2ab4a0ab8db1588e945d0300a,This paper proposes a method to improve the sample complexity of model-free policy gradient methods by using a stochastic dynamics model to estimate the next state prediction from the distribution predicted by the dynamics model. The proposed method is based on randomized anchored MAP that results in an ensemble of neural networks providing a true Baysian uncertainty estimate. The influence of the ensemble of dynamics models on the policy update is controlled by adjusting the number of virtually performed rollouts in the next iteration according to the ratio of the real and virtual total reward. The experimental results show that the proposed method outperforms the baselines.
SP:2aaddb6dda434b49487857d99c9d143e2f54d350,This paper proposes a method to detect adversarial examples using a class-conditional reconstruction of the input. The method is based on the observation that CapsNet performs better than convolutional networks in the presence of adversarial perturbations. The authors then propose a new adversarial attack based on this observation and show that it is able to fool the proposed method with a much smaller success rate than a standard attack. They also show that the success of the reconstructive attack is highly related to the visual similarity between the source and target classes.
SP:da88bfbe3f59ce1a24522aa5e74c9472b079664a,This paper studies the effect of initialization and activation function on the neural tangent kernel (NTK) as the network depth increases. The authors show that only an initialization on the Edge of Chaos (EOC) leads to an invertible NTK for deep neural networks. They also show that the smoothness of the activation function plays a major role in the behavior of NTK. The paper also provides experiments illustrating the theoretical results.
SP:dd59b897384c52c20d62be73fc33184c8c226f4b," different views of the same sentence are mapped to close representations, while views from other sentences are mapped further. By contrasting different linguistic views, the authors aim at building embeddings which better capture semantic and are less sensitive to the sentence outward form. The model parameters are learned using a discriminating objective as proposed in Logeswaran & Lee (2018)."
SP:980babd58fc2ea5f40bb22b3a9a09737f14f3f18,"This paper proposes FinBERT, a language model based on BERT for financial sentiment classification. The model is pre-trained on a financial corpus and fine-tuned for sentiment analysis (FinBERT). This work is the first application of BERT to finance to the best of the knowledge and one of the few that experimented with further pre-training on a domain-specific corpus. The authors conducted extensive experiments with BERT, investigating the effects of further pretraining and several training strategies. The results show the effectiveness of pre- trained language models for a down-stream task."
SP:31c9c3a693922d5c3448e80ade920391dce261f9,"This paper proposes a method for singing voice generation without pre-assigned scores and lyrics, in both training and inference time. The authors propose three singing schemes with different input conditions: free singer, accompanied singer, and solo singer. They also propose a BEGAN based architecture that uses GRUs and grouped dilated convolutions to learn to generate singing voices in an adversarial way. The evaluation shows that the audio quality of the generated voices still leave much room for improvement."
SP:99d41c8285fd0270ff16e915ef03187a0a7005b0,"This paper proposes a novel adversarial defense technique that leverages a latent high order factorization of the network. Randomization is applied in the latent subspace, therefore resulting in dense reconstructed weights, without the sparsity or perturbations typically induced by the randomization. The approach can be easily integrated with any arbitrary neural architecture and combined with techniques like adversarial training. Empirical results demonstrate the effectiveness of the proposed method."
SP:762729b64c1c1494de0f7410ea3662da61e93b6d,"This paper proposes a novel graph attention network (GATN) based method for time series forecasting. The GATN consists of a graph attention module and a graph transformer module. The attention module is based on the Geng et al. (2019) GAT, while the transformer module is inspired by the atrous attention module proposed by Child et al (2019). The proposed method is evaluated on a ride-hailing dataset and shows promising results."
SP:81d7c60d0d12eb268d7edeebe86422991a1d4997,"This paper analyzes the deep Q-network (DQN) algorithm from both algorithmic and statistical perspectives. In particular, the authors focus on the fitted Q iteration (FQI) algorithm with deep neural networks, which is a slight simplification of DQN that captures the tricks of experience replay and target network used in DQNs. Under mild assumptions, they establish the algorithmic rates of convergence for the action-value functions of the iterative policy sequence obtained by FQI. The statistical error characterizes the bias and variance that arise from approximating the action value function using deep neural network. The algorithmic error converges to zero at a geometric rate. As a byproduct, their analysis provides justifications for the techniques of experience-replay and target-network, which are crucial to the empirical success of deep QN."
SP:a558ffa1706ef78893528c8c23e2295a79824d2f,"This paper proposes a new attention mechanism, called PhraseTransformer, which uses hypernodes to represent phrases in attention. The authors argue that the phrases play an important role in attention and propose a more realistic representation than the weighted sum of individual words, i.e. semantics = alpha1Emb(That) + alpha2Emb(’s) + · · ·+ αnEmb(her). The experiments show the effectiveness of the proposed method on the translation task."
SP:622b0593972296a95b630a4ece1e959b60fec56c,"This paper presents a modular neural network architecture called MAIN that learns algorithms given a set of input-output examples. MAIN consists of a neural controller that interacts with a variable-length input tape and learns to compose modules together with their corresponding argument choices. Unlike previous approaches, MAIN uses a general domain-agnostic mechanism for selection of modules and their arguments. The paper also uses a memoryless controller with a length-invariant self-attention based input tape encoding to allow for random access to tape locations."
SP:d668cc809e4f6b5f3330cf75cb5f71693a123c07,This paper proposes a Monte Carlo Deep Neural Network arithmetic (MCDA) technique to quantify the sensitivity of neural networks to quantization in floating point arithmetic. MCDA is based on Monte Carlo Arithmetic to the inference computation and analyzes the relative standard deviation of the neural network loss. The method makes no assumptions regarding the underlying parameter distributions. The authors evaluate their method on pre-trained image classification models on the CIFAR-10 and ImageNet datasets. 
SP:eda1d368aa3b4d806020c4c430a173d1ddd13d0d,"This paper studies the problem of objective mismatch in model-based reinforcement learning (MBRL). In particular, the authors point out that the objective mismatch between training the forward dynamics model w.r.t. the likelihood of the one-step ahead prediction, and the overall goal of improving performance on a downstream control task. The authors propose an initial method to mitigate the mismatch issue by reweighting dynamics model training. "
SP:63c452f2b2cbfeea0b45831bd7dc1ac26883fd9f," adversarial examples. This paper presents a targeted blackbox transfer-based adversarial attack methodology that achieves state-of-the-art success rates for ImageNet classifiers. The presented attacks leverage learned class-wise and layer-wise intermediate feature distributions of modern DNNs. The authors find the optimal attack transfer layers have feature distributions that are class-specific and highly-separable, but are not overly-correlated with the whitebox model output."
SP:a7a2ded35804c381603a1196c7f7893fdf796c05,"This paper proposes a new approach to compare policies using Wasserstein distances (WDs) in a newly defined latent behavioral space. The authors show that by utilizing the dual formulation of the WD, they can learn score functions over trajectories that can be in turn used to lead policy optimization towards (or away from) (un)desired behaviors. Combined with smoothed WDs, this dual formulation allows them to devise efficient algorithms that take stochastic gradient descent steps through WD regularizers. They incorporate these regularizers into two on-policy algorithms, Behavior-Guided Policy Gradient (BGPG) and Behavioural Guided Evolution Strategies (BGS), which are shown to outperform existing methods in a variety of challenging environments."
SP:ef1c6403597c3a6083c1ad4256449325ac99416c,"This paper proposes an adaptive learning rate for interpolation with gradient descent (ALI-G) algorithm, which uses a single constant hyper-parameter to compute the learning rate and does not require a decay schedule. The authors provide convergence guarantees for ALI-g in the stochastic convex setting. The paper also provides experiments on a variety of architectures and tasks."
SP:6e24a1e0aff73db6ae8558f114b644965e287e36,"This paper studies the role of bottom-up, horizontal, and top-down connections in the learning of perceptual grouping. Specifically, the authors evaluate TD+H-CNNs with different combinations of the three types of connections on two tasks: low-level ""Gestalt"" vs. high-level object cues for perceptual grouping and segmentation. The authors show that a model with a combination of these connections is better able to learn to form perceptual groups than a model that only relies on bottom up connections."
SP:7a0db1e8804defc5c04e0f4dd345272c6df1ff77,"This paper proposes a new regularizer for weight pruning that is differentiable almost everywhere and scale-invariant. The regularizer is inspired by the Hoyer measure (the ratio between `1 and `2 norms) used in traditional compressed sensing problems. The authors show that enforcing DeepHoyer regularizers can produce even sparser neural network models than previous works, under the same accuracy level. "
SP:5ec05ac5d72e8e0b39b15a0cd7b2f5a64e861024,"This paper studies the problem of optimizing strongly convex functions. The authors propose a variant of Adam that achieves a data-dependent $O(\log T)$ regret bound. The main idea is to maintain a faster decaying yet under controlled step size for exploiting strong convexity. In addition, under a special configuration of hyperparameters, the proposed SAdam reduces to SC-RMSprop, a recently proposed variant of RMSprop for strongly-convex functions, for which the authors provide the first-ever logarithmic regret bound in this setting. Empirical results are provided to demonstrate the effectiveness of the proposed algorithm."
SP:9f89501e6319280b4a14b674632a300805aa485c,"This paper proposes a lightweight BERT-based model, called BlockBERT, which uses sparse block structures to reduce the memory consumption and training time. The proposed method is based on self-attention, which is an extension of the BERT model. The authors conduct experiments on several benchmark question answering datasets with various paragraph lengths to demonstrate the effectiveness of the proposed method. "
SP:0f04fc2e7966f4ba53909654fc0e8b90fc405f2a," pruning. This paper studies the effect of pruning on the generalization of neural networks. The authors show that pruning's effect on generalization relies more on the instability it generates (defined as the drops in test accuracy immediately following pruning) than on the final size of the pruned model. They demonstrate that even the pruning of unimportant parameters can lead to such instability and show similarities between pruning and regularizing by injecting noise, suggesting a mechanism for pruning-based generalization improvements that is compatible with the strong generalization recently observed in over-parameterized networks."
SP:dba3f5ec3af2a4a67ed4fc36b0f37fe556354177,This paper proposes a neural architecture search algorithm with reinforcement learning (NASES) that searches in an embedding space by using architecture encoders and decoders. The main idea is to use a pretrained architecture decoder and a pretraining architecture simulator in the first stage and provide the compression rate between the embedding size and testing loss. Experiments on CIFAR-10 show that the performance of the final architecture network using the NASES procedure is comparable with other popular NAS approaches for the image classification task.
SP:e2e5bebccc76a51df3cb8b64572720da97174604,This paper proposes a homotopy training algorithm to solve optimization problems arising from neural networks. The proposed method starts with several decoupled systems with low dimensional structure and tracks the solution to the high dimensional coupled system. The decoupling systems are easy to solve due to the low-dimensional structure but can be connected to the original system via a continuous homotopic path guided by the HTA. The authors have proved the convergence of HTA for the non-convex case and existence of the solution path for the convex case. The HTA has provided a better accuracy on several examples including VGG models on CIFAR-10.
SP:5d9517fa62cd97b94ff45f645e100a8ad631e281,"This paper proposes a transformer-based deep reinforcement learning model with tensor products of value vectors. The key idea is to use the 2-simplicial attention, which is a form of higher-dimensional attention that generalizes the dot-product attention. The authors show that this architecture is a useful inductive bias for logical reasoning in the context of reinforcement learning."
SP:f66721bf3eccf2e36444c2c41303e97745f10f0e,"This paper proposes a method for semi-supervised pose estimation with limited labeled and unlabelled data. The proposed method is based on the Conditional Variational Autoencoder (CVAE) framework, which is an extension of the work of Kingma et al. (2014). The paper shows that the proposed method can be trained with a dataset of labelled and unlabeled images, and achieves comparable performance to that of a fully supervised pose estimation method."
SP:87dc93d26ad5ad4a8dccde1780b5b127f391cfd6,"This paper proposes a curriculum learning approach to scale up multi-agent reinforcement learning (MARL) by progressively increasing the population of training agents in a stage-wise manner. Specifically, the authors propose to use an evolutionary approach to fix an objective misalignment issue throughout the curriculum: agents successfully trained in an early stage with a small population are not necessarily the best candidates for adapting to scaled populations with scaled populations. The proposed method maintains multiple sets of agents in each stage, performs mix-and-match and fine-tuning over these sets and promotes the set of agents with the best adaptability to the next stage. The authors implement EPC on a popular MARL algorithm, MADDPG and empirically show that the approach consistently outperforms baselines by a large margin as the number of agents grows exponentially."
SP:0ea5b3247ce031f25b98cf7d42bd4290020fbed2,"This paper presents a graph-based approach to diagrammatic reasoning problems in the style of Raven Progressive Matrices (RPM). The approach is based on graph neural networks and multiplex graphs to capture relations present in the reasoning task. The authors show that the proposed approach outperforms WReN, the previous state-of-the-art model, by a considerable margin. "
SP:9bcb840f867f1a7108aa22a7bb14c348fda52eb0,This paper proposes an adaptive noise MCMC algorithm that estimates and is able to sample from the posterior of a neural network. The method dynamically adjusts the amount of momentum and noise applied to each parameter update in order to compensate for the use of stochastic gradients. The authors use a ResNet architecture without batch normalization to test ATMC on the Cifar10 benchmark and the large scale ImageNet benchmark. ATMC outperforms a strong optimization baseline in terms of both classification accuracy and test log-likelihood.
SP:8cf0614f0fbd3756453304703d00776cfc9a4b9f,"This paper proposes a method to identify winning tickets (small but critical subnetworks) for dense, randomly initialized networks, that can be trained alone to achieve a comparable accuracy to the original network in a similar number of iterations. However, the identification of these winning tickets still requires the costly train-prune-retrain process, which limits their practical benefits. This paper discovers for the first time that the winning tickets can be identified at a very early training stage, which they term as Early-Bird (EB) tickets, via low-cost training schemes (e.g., early stopping and low-precision training) at large learning rates. Furthermore, they propose a mask distance metric to identify EB tickets with a low computational overhead, without needing to know the true winning tickets that emerge after the full training. Finally, they leverage the existence of EB tickets and the proposed mask distance to develop efficient training methods, which are achieved by first identifying EB tickets via low cost schemes, and then continuing to train merely the EB tickets towards the target accuracy."
SP:8aeece75c839643a02d2b3b5f3aca7cb76cf1d35," the vulnerability of neural networks grows with the input dimension. Inspired by the observation that the intrinsic dimension of image data is much smaller than its pixel space dimension, this paper proposes Embedding Regularized Classifier (ER-Classifier), which improves the adversarial robustness of the classifier through embedding regularization. Experimental results on several benchmark datasets show that the proposed framework achieves state-of-the-art performance."
SP:efd68097f47dbfdd0208573071686a62240d1b12,"This paper proposes an end-to-end model for jointly learning entity recognition (NER) and relation extraction (RE) tasks. The model is based on a pre-trained transformer-based language model. The main contributions of the paper are as follows: (1) The model does not rely on any handcrafted features (e.g. templated questions) or external NLP tools (i.e. dependency parsers). (2) It is fast to train, converging in approximately 1 hour or less on a single GPU for all datasets used in this study. (3) It matches or exceeds state-of-the-art performance on 5 datasets across 3 domains. "
SP:8fd4f3f8615c0a7a76ec7bfe996d2ead803f7828,"This paper proposes a neural network-based method to solve the problem of finding a Euclidean representation of an input x, y, z, where x is the input x and y is the output z. The problem is formulated as a triplet comparison problem, where the goal is to find an embedding of x,y,z that maximizes the similarity between x and z. This problem has been studied in a sub-community of machine learning by the name “Ordinal Embedding”. Previous approaches to the problem are painfully slow and cannot scale to larger datasets. The proposed approach is significantly faster than available methods, and can scale to real-world large datasets."
SP:12e7f417a7ef1ccafccff5ffb3f8f11cd2c05b20,"This paper proposes a meta-learning method for data value estimation. The main idea is to use a deep neural network to estimate the value of each datum in the training set, and then use a reinforcement learning approach to train a value estimator. The proposed method is evaluated on corrupted sample discovery, domain adaptation, robust learning, and robust learning."
SP:e2c3374629cfd654b7b35e88507e65646d70470e,"This paper studies the effect of initialization on the variance of the per-layer Jacobian norm of a neural network at the beginning of training. The authors study three types of architectures: vanilla networks, ResNets and dense networks. They show that while the variance is exponential in depth for ResNet and polynomial for DenseNets, there exists an initialization strategy for both, such that the norm is preserved through arbitrary depths, preventing exploding or decaying gradients in deep networks. "
SP:4463645f1a9abfbf472935d9eb3342919aa4e0f4,"This paper proposes a reinforcement learning-based method for optimizing compilers for neural networks. The main idea is to use reinforcement learning to learn to quickly adapt to a previously unseen design space for code optimization, both accelerating the search and improving the output performance. The authors also propose an adaptive sampling algorithm that not only focuses on the costly samples (real hardware measurements) on representative points but also uses a domain-knowledge inspired logic to improve the samples itself. Experiments with real hardware shows that CHAMELEON provides 4.45x speed up in optimization time over AutoTVM, while also improving inference time of the modern deep networks by 5.6%."
SP:df8483206bb88debeb24b04eb31e016368792a84,"This paper studies the problem of certified robustness for top-k predictions. The authors derive a tight certified radius in the $\ell_2$ norm for randomized smoothing with Gaussian noise. They also show that generalizing the certified radius from top-1 to top-K predictions faces significant technical challenges. Finally, they demonstrate the effectiveness of their method on CIFAR10 and ImageNet."
SP:84a83ee258d5bc613b7d73045477018b8a56c56d,"This paper analyzes the relationship between the gradient signal-to-noise ratio (GSNR) of parameters of deep neural networks (DNNs) and generalization performance. The GSNR of a parameter is defined as the ratio between its gradient’s squared mean and variance over the data distribution, over the training distribution. The authors show a quantitative relationship between model parameters’ GSNr and the generalization gap. This relationship indicates that larger GSNRs during training process leads to better generalisation performance. "
SP:fb726f0fea2ed1a009b3aacf74ac149bcf988cdd,"This paper proposes an embedding-based framework for reasoning over queries with logical disjunctions in massive and incomplete Knowledge Graphs (KGs). The main idea is to transform queries into a Disjunctive Normal Form (DNF) and embed each conjunctive query into a box, and output entities closest to their nearest boxes. The authors show that queries can be embedded as boxes (i.e., hyper-rectangles), where a set of points inside the box corresponds to the set of answer entities of the query. Their approach is capable of handling all types of EPFO queries scalably and accurately."
SP:c8bbdbf038ddec801c931ae9399b8c16b08428bc,"This paper studies the convergence of gradient estimators for strongly convex, convex and non-convex optimization problems. The authors show that consistent estimators of the gradient converge to the same convergence rate as unbiased estimators. The paper also shows that the convergence rate of the consistent estimator is the same as that of the unbiased estimator. Finally, the authors provide experiments on synthetic and real-world data to validate the theoretical results."
SP:d53ee573b8083ecf891d4d560eb8a54c30c5cb3a,"This paper proposes a method to train a once-for-all (OFA) network that supports diverse architectural settings by decoupling training and search, to reduce the cost. It can quickly get a specialized sub-network by selecting from the OFA network without additional training. To efficiently train OFA networks, it also proposes a novel progressive shrinking algorithm, a generalized pruning method that reduces the model size across many more dimensions than pruning (depth, width, kernel size, and resolution). It can obtain a surprisingly large number of subnetworks (> 10) that can fit different hardware platforms and latency constraints while maintaining the same level of accuracy as training independently."
SP:1be944b5f82d33ab1feb5639792a4c06b8f0c85a,"This paper proposes an extension of Neural Module Networks (NMNs) to answer questions that require symbolic reasoning. Specifically, the authors define probabilistic modules that propagate uncertainty about symbolic reasoning operations in a way that is end-to-end differentiable. They also propose an unsupervised auxiliary loss to help extract arguments associated with the events in text. The experiments are conducted on 21,800 questions from the recently proposed DROP dataset."
SP:319922e4a316a9b9e76504f806d30ea3bffa3f99,"This paper studies the problem of network pruning from a signal propagation perspective. In particular, the authors consider the connection sensitivity as a form of gradient, which is used to characterize initialization conditions to ensure reliable connection sensitivity measurements, which in turn yields effective pruning results. Moreover, they analyze the signal propagation properties of the resulting pruned networks and introduce a simple, data-free method to improve the trainability of the pruned network. Experiments are conducted to show the effectiveness of the method."
SP:d5899cba36329d863513b91c2db57675086abc49,"In this paper, the authors study the problem of training sparse neural networks. The authors propose a new initialization scheme for training sparse networks by pruning the dense and convolutional layers of the network at initialization time. They evaluate different topologies and show that seemingly similar topologies can often have a large difference in attainable accuracy. Then, they derive a data-free heuristic that can evaluate a topology independently from the dataset the network will be trained on. They then derive a set of requirements that make a good topology and arrive at a single topology that satisfies all of them."
SP:b05a6a0f05dcc63a7e17233f20c49c465c46d194,"This paper studies the initialization of recurrent neural networks (RNNs) on long sequence tasks. The authors propose a novel initialization scheme based on the mean field theory of signal propagation in LSTMs and GRUs. In particular, the authors derive the time scales for signal propagation as well as the spectral properties of the state-to-state Jacobians. By optimizing these quantities in terms of the initialization hyperparameters, they derive a new initialization scheme that eliminates or reduces training instabilities. Experiments are conducted to demonstrate the effectiveness of the proposed initialization scheme."
SP:7b65eb83b0d3149f788ab11b1ab9057b440ddd57, image data has high intra-class diversity and inter-class similarity. This paper proposes a siamese network to improve the discriminative power of convolutional neural networks on a pair of neighboring scene images. It exploits semantic coherence between this pair to enrich the feature vector of the image for which we want to predict a label. Empirical results show that this approach provides a viable alternative to existing methods.
SP:99c10e038939aa88fc112db10fe801b42360c8dc,"This paper proposes a self-supervised monocular depth estimation method that leverages semantic information from a fixed pretrained semantic segmentation network to guide the generation of multi-level depth features via pixel-adaptive convolutions. The monodepth network learns semantic-aware geometric representations that can disambiguate photometric ambiguities. Furthermore, the authors introduce a two-stage training process that resamples training data to overcome a common bias on dynamic objects resulting in predicting them at infinite depths. Experiments on challenging real-world data show that the proposed architecture consistently improves the performance of different monodepsth architectures."
SP:e98ec7fd9c27eabd7f5bf3429f984034c2d355a2,"This paper studies the problem of label-flipping attacks, a type of data poisoning attack where an adversary relabels a small number of examples in a training set in order to degrade the performance of the resulting classifier. The authors propose a strategy to build linear classifiers based on deep features that are certifiably robust against a strong variant of the attack where the adversary can target each test example independently. In other words, for each test point, the classifier makes a prediction and includes a certification that its prediction would be the same had some number of training labels been changed adversarially. Their approach leverages randomized smoothing, a technique that has previously been used to guarantee test-time robustness to adversarial manipulation of the input to a classifier, and they obtain these certified bounds with no additional runtime cost over standard classification."
SP:795cdeb7e4f7285f2c1ac9b9a0fbac3039201ed5,"This paper proposes to use differential privacy to improve the performance of outlier detection and novelty detection, with an extension to detect poisoning samples in backdoor attacks. Differential privacy has been proposed to avoid leaking any individual’s information, when aggregated analysis is performed on a given dataset. It is typically achieved by adding random noise, either directly to the input dataset, or to intermediate results of the aggregation mechanism. In this paper, the authors demonstrate that applying differential privacy can improve the utility of Outlier detection, Novelty detection, and backdoor poisoning attacks for machine learning models. The authors provide a theoretical analysis on how differential privacy helps with the detection and conduct extensive experiments to validate the effectiveness."
SP:a5f0e531afd970144169823971d2d039bff752fb,"This paper studies the calibration of uncertainty prediction for regression tasks. The authors show that the existing definition for calibration of a regression uncertainty (Kuleshov et al., 2018) has severe limitations in distinguishing informative from non-informative uncertainty predictions. They propose a new definition that escapes this caveat and an evaluation method using a simple histogram-based approach inspired by reliability diagrams used in classification tasks. They also propose a simple scaling-based calibration that preforms well in their experimental tests."
SP:c422afd1df1ac98e23235830585dd0d45513064c,"This paper proposes a new Transformer-based language model called HUBERT, which uses Tensor-Product Representations (TPRs) to disentangle semantic and structural information in BERT's representations. The authors claim that BERT is unable to effectively transfer knowledge across NLP tasks, even if the two tasks are fairly closely related. To solve this problem, the authors propose a decomposition layer on top of BERT which disentangles symbols from their roles in the representations. Experiments are conducted on GLUE and HANS datasets to show the effectiveness of the proposed method."
SP:117b19c4163cb3d08eda6bc7af0d48ed815b519e,This paper proposes a multi-agent reinforcement learning method that combines Hierarchical Reinforcement Learning (HRL) and Multi-Agent Reinforcement learning (MARL). The main contribution of this paper is a partial parameter sharing approach where the lower level of the hierarchy is shared enabling learning using decentralized methods. The proposed method is evaluated on the Pursuit and Soccer environments. 
SP:928640a19b0a0b1e1dc0d1b07cc99e1d51a4d817,"This paper proposes a graph embedding method to improve the performance of graph neural networks (GNNs). The proposed method is based on the observation that GNNs cannot distinguish two graphs if their difference is not in their local structures. In particular, the authors show that if the nodes/edges of the given graph are not labeled/attributed or the labels/attributes do not make the GNN aware of the role of the nodes in the structure of the graph, then GNN can fail to infer the topological structure of graph. Motivated by the success of deep networks in analyzing point-cloud data, this paper proposes an approach in which a geometrical representation of graph is provided to GNN. The spatial representation is computed by graph embeddings method which encodes the topology of graph into the spatial distribution of the embedding vectors. A new graph pooling method is proposed and it is shown that the proposed method achieves competitive or better results in comparison with state-of-the-art methods."
SP:465adf302cd8b7e6b449271a91d1d2fad844aa4d,"This paper proposes frequency pooling (F-pooling) for CNNs, which is an alternative to max pooling, average pooling and stride pooling. The authors provide a formal definition of shift-equivalent when down sampling is involved and propose a strict shift equivalent and anti-aliasing pooling method. Experiments on CIFAR-100 and a subset of ImageNet demonstrate the effectiveness of the proposed method. "
SP:77f0f3779f9bdeb75ea5744ab494942a4943117b,"This paper proposes a method to improve the generalization ability of deep RL agents by introducing a randomized (convolutional) neural network that randomly perturbs input observations. It enables trained agents to adapt to new domains by learning robust features invariant across varied and randomized environments. The authors also consider an inference method based on the Monte Carlo approximation to reduce the variance induced by this randomization. They demonstrate the superiority of their method across 2D CoinRun, 3D DeepMind Lab exploration and 3D robotics control tasks."
SP:31772a9122ec998c7c829bc4813f6147cdc30145,"This paper proposes an explanation method for image similarity models, where a model’s output is a score measuring the similarity of two inputs rather than a classification. In this task, an explanation depends on both of the input images, so standard methods do not apply. The authors propose a method that pairs a saliency map identifying important image regions with an attribute that best explains the match. They find that their explanations provide additional information not typically captured by saliency maps alone, and can also improve performance on attribute recognition."
SP:50f9dcac485552f2925839151da4dd8d82e35fcc,"This paper proposes WaveFlow, a flow-based generative model for raw audio that is trained with maximum likelihood without density distillation and auxiliary losses. The authors show that WaveFlow can synthesize high-fidelity speech and obtain comparable likelihood as WaveNet, while only requiring a few sequential steps to generate very long waveforms. In particular, WaveFlow has 5.91M parameters and can generate speech 42.6x faster than real-time on a GPU."
SP:963e85369978dddcd9e3130bc11453696066bbf3,This paper proposes a new graph generative adversarial network (GAN) model that transforms the input graphs into their target output graphs. The proposed method consists of a graph translator and a conditional graph discriminator to classify the target graphs by conditioning on input graphs while training. Extensive experiments have been conducted on both synthetic and real-world datasets to demonstrate the effectiveness and efficiency of the proposed model.
SP:962caffd236630c4079bfc7292403c1cc6861c3b,"This paper proposes a new neural sequence modeling unit called Meta Gated Recursive Controller. The proposed unit is characterized by recursive parameterization of its gating functions, i.e., gating mechanisms of METAGROSS are controlled by instances of itself, which are repeatedly called in a recursive fashion. This can be interpreted as a form of meta-gating and recursively parameterizing a recurrent model. Experiments on recursive logic tasks (sorting, tree traversal, logical inference), sequential pixel-by-pixel classification, semantic parsing, code generation, machine translation and polyphonic music modeling demonstrate the effectiveness of the proposed approach."
SP:d03aa0318f0d24a5b7c7817dfc7fba47ebec11cd,"This paper proposes a self-supervised learning method for speech recognition. The main idea is to use a strong language model to provide a learning signal given unlabeled speech. The proposed method is motivated by how humans learn to recognize speech, the proposed method can be applied to other sequence transduction tasks including machine translation (Sennrich et al., 2016) and text summarization (Nallapati et al, 2016). "
SP:e6af249608633f1776b608852a00946a5c09a357,"This paper studies the problem of fair and robust model training in the presence of data poisoning. The authors propose a generative adversarial network (GAN) framework called FR-GAN, which uses two discriminators: a fairness discriminator that predicts the sensitive attribute from classification results and a robustness discriminator to distinguish examples and predictions from a clean validation set. They show that the proposed framework is robust to the poisoning and can be adjusted to maintain reasonable accuracy and fairness even if the validation set is too small. "
SP:6306417f5a300629ec856495781515c6af05a363,This paper presents a method for learning point clouds in a Lagrangian-Lagrangian world space using a static background grid and a moving particle grid. The method is motivated by the natural flow phenomena in fluid mechanics. The proposed method is evaluated on various point cloud classification and segmentation problems. 
SP:0561a2174d7334e078a49ae8859a36e4d74f9b5b,"This paper proposes a new lens for studying gradient clipping, namely, robustness: informally, one expects clipping to mitigate the effects of noise, since one does not overly trust any single sample. The authors prove that for the common problem of label noise in classification, standard gradient clipping does not in general provide robustness. On the other hand, they show that a simple variant of gradient clipping is robust, and is equivalent to suitably modifying the underlying loss function. "
SP:414b06d86e132357a54eb844036b78a232571301,"This paper proposes SAIL, a state-based imitation learning algorithm that uses state alignment from both local and global perspective. The state alignment is achieved by a policy update objective that is regularized by the policy update loss. The authors show that SAIL outperforms the state-of-the-art in the MuJoCo environment. "
SP:91761d68086330ce378507c152e72218ed7b2196,This paper proposes an extension of stochastic gradient descent (SGD) called deep gradient boosting (DGB). The key idea of DGB is that back-propagated gradients inferred using the chain rule can be viewed as pseudo-residual targets of a gradient boosting problem. Thus at each layer of a neural network the weight update is calculated by solving the corresponding boosting problem using a linear base learner. The resulting weight update formula can also be seen as a normalization procedure of the data that arrives at each layers during the forward pass. When implemented as a separate input normalization layer (INN) the new architecture shows improved performance on image recognition tasks.
SP:7709a8b907c5642479e7b6fb0b362efc4ead63ce,"This paper proposes PC-DARTS, a differentiable architecture search method that performs operation search in a subset of channels while bypassing the held out part in a shortcut. The key idea is to randomly sample a proportion of channels for operation search, so that the framework is more memory efficient and, consequently, a larger batch size can be used for higher stability. Experiments on CIFAR-10 and ImageNet demonstrate the effectiveness of the proposed method."
SP:724870046e990376990ba9f73d63d331f61788d7,This paper proposes an actor-critic algorithm that combines deep reinforcement learning (DRL) and deterministic policy gradients (DDPG) to solve control tasks. The key idea is to use a differentiable simulator to estimate the gradient of the policy and use this information to improve the convergence rate of both the actor and the critic. Experiments are conducted on a variety of control tasks and show that the proposed method outperforms DDPG and MPC.
SP:be0202a28bcca68edb0abe4d1c0ba1af265211e3,This paper proposes a method to learn a task-agnostic world graph that can be used to improve the sample efficiency of reinforcement learning agents. The key idea is to use the learned world graph to guide the agent's exploration towards task-relevant waypoints and regions. The proposed method is evaluated on a suite of maze tasks and shows that using world graphs significantly accelerates RL.
SP:e8a3a0f77dab336ce50c9dc941f7350173916e04,This paper proposes a method for reverse engineering neural networks. The main idea is to use discretized layers to make the network interpretable without disordering the function blocks. The authors also introduce an end-to-end PathNet structure through this discretization by considering function blocks as neural networks and connect them to the appropriate neural networks to obtain the target function. 
SP:b7f4fda6497a1c20fd57f029be5f1b2e2780e227,"This paper proposes a self-supervised goal-conditioned imitation learning algorithm for learning goal-reaching policies from scratch. The key observation is that sub-optimal trajectories generated by a suboptimal policy can still serve as optimal examples for other tasks. Based on this observation, the authors propose a simple algorithm to learn policies without any demonstrations, user-provided reward functions, or complex reinforcement learning methods. The proposed algorithm simply maximizes the likelihood of actions the agent actually took in its own previous rollouts conditioned on the goal being the state that it actually reached. Theoretical analysis shows that this method optimizes a lower bound on the probability that the agent reaches the desired goal. Empirical results show that the proposed algorithm is able to learn goal reaching behaviors from scratch without the need for an explicit reward function or expert demonstrations."
SP:1c7cf7417825208feac9fe3b3488a51ad1e72270,"This paper proposes a new asynchronous stochastic gradient descent algorithm, Zeno++, which is robust to Byzantine failures of the workers. The key idea is to estimate the descent of the loss value after the candidate gradient is applied, where large descent values indicate that the update results in optimization progress. The authors prove the convergence of the algorithm under Byzantine failures. Experimental results show that Zeno+ outperforms existing approaches."
SP:d16ed9bd4193d99774840783347137e938955b87,"This paper proposes two new adversarial attacks that manipulate semantically meaningful image-based visual descriptors - color and texture - in order to generate effective and photorealistic adversarial examples. The first attack is based on controlling the amount of texture that gets added to the victim image by controlling the texture weight coefficient (alpha) and the second attack uses cross-layer statistics to control the color weight coefficient. The authors show that these two attacks are effective against JPEG compression, feature squeezing and adversarially trained models. They also show that the proposed methods can effectively be applied to both image classification and image captioning tasks on complex datasets."
SP:f4f7dd96b7865fe2d4c6bddf82875f0c9377c3b4,This paper proposes a method for few-shot learning of entity recognition. The method is based on a controller that is trained to execute an optimal sequence of read and write operations on an external memory with the goal of leveraging diverse activations from the past and provide accurate predictions. The controller is trained by minimizing the entropy of the memory. The paper shows that the controller is able to learn to control the sparse memory. Experiments on the Stanford Task-Oriented Dialogue dataset demonstrate the effectiveness of the method.
SP:2e9235485b79d0b22ec8b565b19bfa26804ccbe1,"This paper presents a method for learning primitive primitives from demonstrations. The method is based on the observation that primitive primitive decomposition should be simple and coherent. To this end, the authors propose to jointly learn the underlying motor primitives and recompose these primitives to form the original demonstration. The authors show that the learned primitive space captures the shared motions required across diverse skills, and that these motor programs can be adapted and composed to further perform specific tasks."
SP:c7c37aeebec7f33c1015f1fa3dd2a36d7b437d1c,"This paper proposes a method for single-episode policy transfer in a family of MDPs with different dynamics. The key idea is to use a probe policy and an inference model to estimate latent variables of test dynamics, which are then used as input to a universal control policy. This modular approach enables integration of state-of-the-art algorithms for variational inference or RL. In addition, the approach does not require access to rewards at test time, allowing it to perform in settings where existing adaptive approaches cannot. "
SP:f2f1aff9a5b91d748b24fee0155367f650401aab,"This paper presents an empirical study of two- and three-head neural networks for two-player reinforcement learning in the game of Hex. The main contribution of the paper is to compare the performance of the two-head network and the three-headed network. The paper shows that the three head network is compatible with the zero-style closed loop learning paradigm, and the new architecture also enables faster search and yields better performance."
SP:89d6d55107b6180109affe7522265c751640ad96,This paper proposes a novel method for policy transfer in reinforcement learning. The proposed method is based on adapting the source policy to learn to solve a target task with significant transition differences and uncertainties. The authors show that their method leads to a significantly reduced sample complexity of transferring the policies between the tasks. 
SP:626021101836a635ad2d896bd66951aff31aa846,This paper studies the problem of scale equivariance in convolutional neural networks. The authors introduce a general theory for building scale-equivariant convolution networks with steerable filters. They develop scale-convolution and generalize other common common blocks to be scale-Equivariant. They demonstrate the computational efficiency and numerical stability of the proposed method. 
SP:6316f750b8c69e55e61926c34e3ba5acbd7228ad,"This paper proposes an unpaired shape completion framework that can be applied directly on raw partial scans to obtain clean and complete point clouds. At the core of the algorithm is an adaptation network acting as a generator that transforms latent code encodings of raw point scans, and maps them to latent codes of complete object scans. The two latent spaces regularize the problem by restricting the transfer problem to respective data manifolds. The proposed method is evaluated qualitatively on several real-world datasets (ScanNet, Matterport3D, KITTI) and quantitatively on 3D-EPN shape completion dataset."
SP:270c679b322f69a943bf7f6b938dc1bf663d3c6f,"This paper studies the problem of generating fake data using generative adversarial networks. The authors cast the problem as a maximin game, characterize the optimal strategy for both attacker and authenticator in the general case, and provide the optimal strategies in closed form for the case of Gaussian source distributions. Their analysis reveals the structure of the optimal attack and the relative importance of data collection for both authenticator and attacker. Based on these insights, they design practical learning approaches and show that they result in models that are more robust to various attacks."
SP:a7e7619667892806a6f4038cbe4b1c6cd0eec0ed,"This paper proposes a new adversarial training method for adversarial learning. The proposed method is motivated by the fact that the high dimensional distribution is poorly represented by limited data samples. The authors define a sensible adversary which is useful for learning a defense model and keeping a high natural accuracy simultaneously. They theoretically show that the Bayes rule is the most robust multi-class classifier with the 0-1 loss under the sensible adversary. They propose a novel and efficient algorithm that trains a robust model with sensible adversarial examples, without a significant drop in natural accuracy. "
SP:9ca0b8d270e3fea3ba8f88c8f1ba50d8a8f7e4b8,This paper proposes an online knowledge distillation method that transfers not only the knowledge of the class probabilities but also that of the feature map using the adversarial training framework. The proposed method trains multiple networks simultaneously by employing discriminators to distinguish feature map distributions of different networks. The discriminators and networks are trained concurrently in a minimax twoplayer game. Experiments are conducted to demonstrate the effectiveness of the proposed method.
SP:e43fc8747f823be6497224696adb92d45150b02d,This paper proposes a new word embedding model for sentiment word embeddings. The proposed model is based on the homomorphism-based objective function. The authors propose to use the maximum likelihood estimator and the Bayesian estimator to determine the parameters of the model. Experiments show that the proposed model significantly outperforms the baseline methods in sentiment analysis.
SP:72d32a2ae382f63e055ab3eafcc9276b10fba985,"This paper proposes a two-phase training strategy for the noisy training data. The first phase retrieves an initial set of true-labeled samples as many as possible, and the second phase, “learning from a maximal safe set,” completes the rest training process only using the true labels with high precision. The experiments show that the proposed method significantly outperforms four state-of-the-art methods in test error under existence of real-world noise."
SP:8316872d8b388587bf25f724c80155b25b6cb68e,"This paper proposes a method to generalize action space generalization in reinforcement learning. The method is based on representation learning over a collection of data samples reflecting the diverse properties of that action. The authors also propose a reinforcement learning architecture which works over these action representations, and propose regularization metrics essential for enabling generalization. Experiments are conducted to demonstrate the generalizability of the proposed method and policy."
SP:f534d51192eaacc6cb6bfd365e6d959d9dd498b2,"This paper proposes two methods for storing word embedding matrix during training and inference in a highly efficient way. The first method, word2ket, is based on a two-dimensional complex unit-norm vector, that is, an element from the set C2. The second method is word2kXS, based on the word2vec and GloVe embeddings. The authors show that the proposed method achieves a 100-fold or more reduction in the space required to store the embedding vectors with almost no relative drop in accuracy in practical NLP tasks."
SP:3df499068ffe6c995457c2174f987cb0ae3c2551,This paper proposes a method for imitation learning that learns a policy conditioned on a behavioral description of a state-action pair. The behavioral description is defined as a low-dimensional representation of a high-dimensional behavioral space. The method is tested on the build-order planning problem in StarCraft II. The results show that the learned policy can be effectively manipulated to express distinct behaviors. 
SP:db15d3cc3e95173ca6d4fd88313d89a739d1c910,"This paper studies the lottery ticket hypothesis, which suggests that small, sparsified neural networks can be trained as long as the network is initialized properly. In this paper, the authors investigate the structure of the winning ticket, i.e., the weight magnitude of a model, under stochastic gradient descent (SGD) optimization. They find that a model saturates early but not too early under SGD, and conjecture that pruning a premature model causes the loss of capability in learning complex patterns, leading to accuracy degradation. Based on these insights, they identify the early winning tickets for various ResNet architectures on both CIFAR10 and ImageNet, achieving state-of-the-art accuracy at a high pruning rate without expensive iterative pruning."
SP:06d2a46282e34302050e81a1be8a2627acb159ee,"This paper proposes an unknown-aware deep neural network (UDN) to tackle the problem of rejecting unknown objects. The key idea of UDN is to enhance existing CNNs to support a product operation that models the product relationship among the features produced by convolutional layers. This way, missing a single key feature of a target class will greatly reduce the probability of assigning an object to this class. UDN uses a learned ensemble of these product operations, which allows it to balance the contradictory requirements of accurately classifying known objects and correctly rejecting unknowns in one network structure. To further improve the performance at detecting unknowns, an information-theoretic regularization strategy is proposed to further enhance its unknown rejection capacity."
SP:fa3e729469e74cac44745008fe65c01cc97c9820,This paper proposes a method for variational inference for deep neural networks. The main idea is to use a coarse approximation of the posterior over the parameters of the model and iteratively refine it. The authors show that the refined posterior is a better approximation to the posterior than the initial variational distribution. Experiments are conducted on UCI regression and CIFAR10.
SP:8e20d28a2a3a6f8f0b6a29a09a10fb8c7a011e86,"This paper proposes a method for contextual categorical sequence generation based on a policy gradient estimator that uses a set of correlated Monte Carlo (MC) rollouts for variance control. The MC rollouts are random and adaptive to model uncertainty; those rollouts naturally become baselines for each other, and hence are combined to effectively reduce gradient variance. The authors also demonstrate the use of correlated MC rollout for binary-tree softmax models to reduce the high generation cost in large vocabulary scenarios by decomposing each categorical action into a sequence of binary actions. The proposed method is evaluated on two tasks: neural program synthesis and image captioning."
SP:ab51af66e626b1b03bbf0de7a5237370e941925c,"This paper proposes a stochastic goal recognition control (S-GRC) problem with two main stages: (1) deceptive opponent modeling based on maximum entropy regularized Markov decision processes (MDPs) and (2) goal recognition under proactively static interdiction. The authors propose to use the worst case distinctiveness (wcd) as a measure of the nondistinctive path without revealing the true goals, the task of S-G RC is to interdict a set of actions that improve or reduce the wcd. The experiments demonstrate that the proposed approach control the goal recognition process based on opponent’s deceptive behavior."
SP:e9d173bdf0b650fd093226cfb4607032c905cf61,"The paper proposes a method to reduce the computational cost of training GANs. The method is inspired by the Coreset-selection in active learning, which computes a large batch of samples from the prior and then compresses that batch using Coreset selection. To create effectively large batches of ‘real’ images, they create a cached dataset of Inception activations of each training image, randomly project them down to a smaller dimension, and then use Coresetselection on those projected activations at training time. They conduct experiments showing that this technique substantially reduces training time and memory usage for modern GAN variants, that it reduces the fraction of dropped modes in a synthetic dataset, and that it allows GAN to reach a new state-of-the-art in anomaly detection."
SP:f174ef07670a31a3ce647910c59040a19ea52d7a,"This paper studies the information plane of recurrent neural networks (RNNs) trained with maximum likelihood. The authors show that RNNs are sub-optimal in this plane. Instead of optimally compressing past information, they extract additional information that is not relevant for predicting the future. They show how constraining past information by injecting noise into the hidden state can improve the ability of RNN to extract predictive information for both maximum likelihood and contrastive loss training. "
SP:f87a75fa12ddeb7538c4522d025e679f2c6dd237,"This paper proposes a method to mitigate the delusional bias in Q-learning by training Q-approximators with labels that are “consistent” with the underlying greedy policy class. The authors introduce a simple penalization scheme that encourages Q-labels used across training batches to remain (jointly) consistent with the expressible policy class, and propose a search framework that allows multiple Q approximators to be generated and tracked, thus mitigating the effect of premature (implicit) policy commitments. Experimental results demonstrate that these methods can improve the performance of Q-Learning in a variety of Atari games."
SP:827b0d2e2e3cf434c02b7f221bb9b2e0388e48b8,"This paper proposes a generative latent variable model, called SPACE, that provides a unified probabilistic modeling framework that combines the best of spatial-attention and scene-mixture approaches. SPACE can explicitly provide factorized object representations for foreground objects while also decomposing background segments of complex morphology. SPACE also resolves the scalability problems of previous methods by incorporating parallel spatial attention and thus is applicable to scenes with a large number of objects without performance degradations."
SP:73d7d614378cbb6a8d7347dca790675674e0eadb,"This paper proposes a depthwise separable convolution (FALCON) method to compress convolutional neural networks. FALCON is derived by interpreting existing convolution methods based on depthwise convolution using EHP, our proposed mathematical formulation to approximate the standard convolution kernel. This interpretation leads to developing a generalized version rank-k fALCON, which further improves the accuracy while sacrificing a bit of compression and computation reduction rates. Experiments are conducted on CIFAR-10 and ImageNet to demonstrate the effectiveness of the method."
SP:35d45ed014320d8dff22f3531f805d15fa91dafb,"This paper proposes several improvements to Batch Normalization (BN) in order to improve its generalization performance. The main contributions of the paper are as follows: 1. A method for reasoning about the current example in inference normalization statistics, fixing a training vs. inference discrepancy; 2. Recognizing and validating the powerful regularization effect of Ghost BatchNormalization for small and medium batch sizes; 3. Exploring the effect of weight decay regularization on the scaling and shifting parameters; 4. A new normalization algorithm for very small batch sizes by combining the strengths of Batch and Group Normalization."
SP:39d187474524c6b7de1ce6fd811ec53edae0a8fc,"This paper studies the problem of differentially private federated learning with generative models. Specifically, the authors propose a federated generative adversarial network (GAN) model that is trained with DP-FedAvg. The authors show that the proposed model can be used to identify and fix various data issues, such as outliers, misclassifications, and misclassification. The proposed method is based on GANs with differential privacy guarantees, and is evaluated on text and image datasets."
SP:1931ec4c3cd0dbb411cf1bc0f9776b7e26e3ad78,This paper proposes a method for generating long range diverse and distinctive behaviors to achieve a specific goal. The method is based on a memory bank that is used to retrieve motion references that are provided as source material to a deep network. The synthesis is performed by the deep network that controls the style of the provided motion material and modifies it to become natural. Experiments on skeleton datasets with diverse motion show that the proposed method outperforms existing parametric and non-parametric baselines.
SP:3a09bdf2e5a17d271f890fd28113202afb9ae761,"This paper studies hierarchical explanation of neural network predictions. The authors identify two desirable properties for informative hierarchical explanations of predictions, namely the non-additivity and context-independent importance. They propose a formulation to quantify context independent importance of words and phrases that satisfies the properties above. They revisit the prior line of works on contextual decomposition algorithms, and propose Sampling and Contextual Decomposition (SCD) algorithm and Sampling & Occlusion (SOC) algorithm. Experiments on multiple datasets and models show that the explanation algorithms generate informative hierarchical explanation, help to extract classification rules from models, and enhance human trust of models."
SP:9ec1740e58d1b07a6b1c6130ec7e23c370efb701,This paper proposes a novel saliency map method for deep convolutional neural networks (CNNs) that is much more efficient than popular gradient methods. It is also quantitatively similar and better in accuracy. The technique works by measuring information at the end of each network scale which is then combined into a single saliency maps. The proposed method is at least 97x faster than Guided Backprop and much more accurate. 
SP:7f11fa931f4085f7227cc870eba4a3aac4b1bf42,"This paper proposes a non-autoregressive text generation model that explicitly models the position of generated words. Specifically, the position is modeled as a latent variable, and training with heuristic searched positions with MC algorithms. Experiments on machine translation and paraphrase generation tasks show the effectiveness of the proposed method."
SP:e1c40112901b6ff905ae0e221fd3df4f545acd08,"This paper proposes Random Path Generative Adversarial Network (RPGAN), a generative adversarial network (GAN) with random paths in the latent space. The main idea is to use random routing as a source of stochasticity in the generator network to capture the different factors of variation in the generated images. The authors show that the random path GAN is able to capture factors of variations in different generator layers, thus providing their natural interpretability. The paper also shows that the RPGAN model also provides competitive generation quality and allows efficient incremental learning. "
SP:1fec5468baaccb4a956399a829b62ac47494a6ac,"This paper proposes DeepSphere, a spherical convolution method based on a graph representation of the sampled sphere. The method is based on graph Laplacian-based graph convolution, which is more efficient than spherical convolutions, but is not exactly equivariant. The authors provide theoretical analysis of how equivariance is affected by the underlying graph with respect to the number of vertices and neighbors. Experiments show state-of-the-art performance and demonstrates the efficiency and flexibility of this formulation."
SP:ae544fa9abd539e0c2e77fdb5541f5c5194feb9f,"This paper studies the problem of learning representation invariant representations for domain adaptation. The authors argue that the search for invariance favors the compression of representations, which may have a bad impact on adaptability of representations expressed as a minimal combined domain error. By considering the risk of compression, the authors show that weighting representations can align representation distributions without impacting their adaptability. This supports the claim that representation invariance is too strict a constraint. "
SP:39126802d517f93bdcbc47708a6aa1ed13bf2800,"This paper presents a method for learning to infer user interface attributes from images. The method is based on a black box rendering engine and a set of attributes it supports (e.g., colors, border radius, shadow or text properties). The authors generate a suitable synthetic training dataset and train specialized neural models to predict each of the attribute values. To improve pixel-level accuracy, the authors also use imitation learning to train a neural policy that refines the predicted attribute values by learning to compute the similarity of the original and rendered images in their attribute space, rather than the difference of pixel values."
SP:1c5d31363faf2b8c43f2698ad426bfffcc02ad03,"This paper studies the problem of robust transfer learning, in which the goal is to produce a model that is not only accurate but also adversarially robust. The authors claim that robust networks contain robust feature extractors. By training classifiers on top of these feature extractor, they produce new models that inherit the robustness of their parent networks. They then consider the case of “fine tuning” a network by re-training end-to-end in the target domain. When using lifelong learning strategies, this process preserves the robusts of the source network while achieving high accuracy. "
SP:06a047ae70a1a25dc6e8f317d6e492e211ad17ce,"This paper proposes a neural iterated learning (NIL) algorithm to encourage the emergence of a more structured type of language in a multi-agent communication game. The authors propose a probabilistic model of NIL and provide an explanation of why the advantage of compositional language exist. The experiments confirm their analysis, and also demonstrate that the emerged languages largely improve the generalizing power of the neural agent communication."
SP:add48154b31c13f48aef740e665f23694fa83681,"This paper proposes Adversarial Variational Inference and Learning (AdVIL) to perform inference and learning in a general Markov random field (MRF). AdVIL employs two variational distributions to approximately infer the latent variables and estimate the partition function of an MRF, respectively. The two distributions are approximated by a minimax optimization problem, which is solved by stochastic gradient descent (SGD). The authors prove a convergence result for the proposed method. Empirical results are provided on various undirected generative models. "
SP:b875f6417663e43dded41b6a6f1b9ab49ad954a2,"This paper proposes a reinforcement learning method that uses an indicator reward function for goal-conditioned reinforcement learning. The reward function is based on the indicator reward, which is a reward function that is only given when the robot’s observation exactly matches a target goal observation. The authors show that by relabeling the original goal with the achieved goal to obtain positive rewards, they can learn with this reward function even in continuous state spaces. They also propose two methods to further speed up convergence with indicator rewards: reward balancing and reward filtering. They show comparable performance between their method and an oracle which uses the ground-truth state for computing rewards. "
SP:8ae78a6640be13e511242eab64101f74ebc4b30a,This paper studies the problem of robustness verification of self-attention layers of Transformers. The authors propose a new method to verify the robustness of the model. The main contribution of the paper is that the proposed method is based on a modified version of the Interval Bound Propagation (IBP) algorithm. The key idea of the method is to leverage the cross-position and cross-nonlinearity of the attention mechanism of the transformer to obtain tighter bounds on the prediction error. Quantitative and qualitative analyses are provided to justify the effectiveness of the proposed algorithm.
SP:92cb7b1e88f3c8883ae6123c19e1ba24622464e6,"This paper proposes a method to learn entity-level knowledge using a zero-shot fact completion task. Specifically, the authors propose a weakly supervised pretraining objective, which explicitly forces the model to incorporate knowledge about real-world entities. The proposed method is evaluated on four entity-related question answering datasets (i.e., WebQuestions, TriviaQA, SearchQA and Quasar-T) with an average of 2.7 F1 improvements and a standard fine-grained entity typing dataset ( FIGER) with 5.7 accuracy gains. "
SP:4395d6f3e197df478eee84e092539dc370babd97,"This paper tackles the problem of discovering novel classes in an image collection given labelled examples of other classes. The authors propose to leverage the information contained in the labelled images in order to learn a general-purpose clustering model and use the latter to identify the new classes in the unlabelled data. They propose to use self-supervised learning to train the representation from scratch on the union of labelled and unlabeled data, and use rank statistics to transfer the model’s knowledge of the labelled classes to the task of clustering the unllabeled images. The proposed method is evaluated on standard classification benchmarks and outperforms current methods for novel category discovery."
SP:068c4e93c135968aef2637d2bfcba727a3c0f001,"This paper proposes a new method for visual planning based on topological memory. The proposed method is based on a contrastive predictive coding approach, where the energy function is learned using a conditional VAE model that generates hallucinated samples for building the connectivity graph. The experiments show that the proposed method outperforms state-of-the-art data-driven approaches such as visual foresight and the original SPTM."
SP:907d92896eda706e1526debb5a87b41bb1e978e0,"This paper proposes an iterative greedy algorithm that adversarially filters out data points to identify a reduced dataset with more realistic problem distributions and considerably less spurious biases. The authors claim that the real world problems consist of a great deal of long-tail problems, and existing benchmarks are overly populated with a great many similar (thus non-tail) problems, which in turn, leads to a major overestimation of true AI performance. To address this challenge, this paper proposes a novel framework of Adversarial Filters to investigate model-based reduction of dataset biases."
SP:82777947d2377efa897c6905261f5375b29a4c19,"This paper proposes a new method for few-shot learning based on prototypical networks. The main idea is to introduce a null class, which is centered around a zero centroid, and enforce centering with batch normalization. The authors also propose a novel Gaussian layer for distance calculation in a prototypical network, which takes the support examples’ distribution rather than just their centroid into account. Experiments on Omniglot and MiniImageNet demonstrate the effectiveness of the proposed method."
SP:4a6df2b39643f548dab806a0b128fe5a3ce4dadc,"This paper proposes GraphZoom, a multi-level framework for improving both accuracy and scalability of unsupervised graph embedding algorithms. The proposed method first performs graph fusion to generate a new graph that effectively encodes the topology of the original graph and the node attribute information. This fused graph is then repeatedly coarsened into much smaller graphs by merging nodes with high spectral similarities. The experiments show that the proposed method can substantially increase the classification accuracy and significantly accelerate the entire graph embeddings process by up to 40.8x."
SP:e33a92e3a6acc668fa2022237e6d947b2eb8bd76,"This paper proposes to predict pixels relatively, by predicting new pixels relative to previously generated pixels (or pixels from the conditioning context, when available). The authors show that this form of prediction fare favorably to its absolute counterpart when used independently, but their coordination under an unified probabilistic model yields optimal performance. Experiments on multiple benchmarks for unconditional image generation, image colorization, and super-resolution indicate that the presented mechanism leads to improvements in terms of likelihood compared to the absolute prediction counterparts."
SP:4224604c2650710cdf5be3ab8acc67c891944bed,"This paper studies the problem of estimating the stationary distribution of the transition operator of a Markov chain. The authors propose a novel algorithm called GenDICE, which is based on estimating a ratio that corrects for the discrepancy between the empirical and stationary distributions. The proposed method is proved to be consistent under general conditions, provides an error analysis, and demonstrates strong empirical performance on benchmark problems, including off-line policy evaluation and offline PageRank."
SP:235998cafe7b558b6f6cf6c49b689ce84004af5d,"This paper proposes a method for training models that are less sensitive to spurious patterns in natural language processing. Given documents and their initial labels, they task humans with revising each document so that it (i) accords with a counterfactual target label; (ii) retains internal coherence; and (iii) avoids unnecessary changes. Interestingly, on sentiment analysis and natural language inference tasks, classifiers trained on original data fail on their counterfactually-revised counterparts and vice versa."
SP:b720eb5b6e44473a9392cc572af89270019d4c42,"This paper analyzes the spatial frequency and orientation selective filters of pre-trained deep convolutional neural networks (CNNs) in terms of perceptual quality. The authors show that spatial frequencies have lower contrast masking thresholds in human visual perception and a definite and strong orientation selectivity are important attributes of deep CNN channels that deliver better perceptual quality features. Experiments are conducted on VGG-16, AlexNet, ShuffleNet, and SqueezeNet."
SP:e2c726a1c3e3ecbec198c4dd804a4298aacec3ad,"This paper proposes a graph energy neural network (GENN) to explicitly model link type correlations between link labels (e.g., DDI types). The authors formulate the DDI prediction task as a structure prediction problem, and introduce a new energy-based model where the energy function is defined by graph neural networks. Experiments on two real world DDI datasets demonstrated that GENN is superior to many baselines without consideration of link-type correlations."
SP:1f2a27579404aa165303789fdce9b3ed54f7b0c6,This paper proposes a self-supervised method vq-wav2vec to learn discrete representations of audio segments through a wav2vec-style context prediction task. The algorithm uses either a Gumbel-Softmax or online k-means clustering to quantize the dense representations. Discretization enables the direct application of algorithms from the NLP community which require discrete inputs. Experiments show that BERT pretraining achieves a new state of the art on TIMIT phoneme classification and WSJ speech recognition.
SP:f9c5b74b8bea5161d33676d9290d7b9d7e81d7b6,"This paper proposes an actor-critic framework for collaborative filtering on implicit data. The critic learns to approximate the ranking scores, which in turn improves the traditional MLE-based nonlinear LVMs with the learned ranking-critical objectives. Experimental results on three large-scale datasets demonstrate the effectiveness of the proposed method."
SP:2444a83ae08181b125a325d893789f074d6db8ee,"This paper proposes a multi-step off-policy reinforcement learning method based on truncated Q-learning and shifted Q-functions. The authors show that the combination of these short-and long-term predictions is a representation of the full return, leading to the Composite Q-Learning algorithm. They show the efficacy of the proposed method in the tabular case and compare it with TD3, Model-based Value Expansion and TD3(∆) on simulated robot tasks."
SP:64564b09bd68e7af17845019193825794f08e99b,"This paper proposes a reinforcement learning system for dexterous manipulation tasks. The system is based on a three-fingered robotic arm, which is able to perform dexterous manipulations with a single hand. The proposed system is evaluated on a set of dexterous robotic manipulation tasks, where it is shown to outperform ablations and prior work.  "
SP:ee4d59fa9487ecdcd663a4a7833689d1754aac7c,"This paper studies the problem of adversarial robust generalization. The authors show that with a sufficiently large amount of unlabeled data, adversarial generalization can be achieved with adversarially robust training. The main contribution of this paper is the analysis of the expected robust risk decomposition theorem, which shows that the stability part of the risk decomposes into two parts: the prediction stability part and the accuracy part. The stability part does not depend on any label information, and thus, it can be optimized using unlabelled data. The paper also shows that for a specific Gaussian mixture problem illustrated by Schmidt et al. (2018), adversarial training can be almost as easy as the standard generalization in supervised learning if a large enough amount of unlabeled data is provided. "
SP:8d92aa968c590a352cb34c9fa1dbe77dff19519f,"This paper studies the problem of policy optimization in reinforcement learning. The authors propose a family of advantage estimates based on the order statistics over the path ensemble, which allows one to flexibly drive the learning process in a promotion focus or a prevention focus. The advantage estimators are incorporated into three widely used actor-critic algorithms including A2C, TRPO and PPO. The effectiveness of the proposed method is demonstrated by extensive experiments. "
SP:2162408ce2a3267724b5f8f0abec41d4dc714220,"This paper proposes precision gating (PG), an end-to-end trainable dynamic dual-precision quantization technique for deep neural networks. PG computes most features in low precision and only a small proportion of important features in a higher precision to preserve accuracy. The proposed approach is applicable to a variety of DNN architectures and significantly reduces the computational cost of execution with almost no accuracy loss. Experiments indicate that PG achieves excellent results on CNNs, including static compressed mobile-friendly networks such as ShuffleNet."
SP:0c2c9b80c087389168acdd42af15877fb499449b,"This paper proposes a new problem called wildly unsupervised domain adaptation (WUDA), where classifiers have to be trained with noisy labeled data from source domain (SD) and unlabeled data from target domain (TD). The authors show that WUDA ruins all UDA methods if taking no care of label noise in SD, and propose a new framework called ""Butterfly"" which maintains four models (e.g., deep networks) simultaneously, where two take care of all adaptations (i.e., noisy to clean, labeled to unlabeled, and SD-to-TD-distributional) and then the other two can focus on classification in TD. The authors conduct experiments on simulated and real-world datasets to demonstrate the effectiveness of the proposed method."
SP:f3cc10ce2f77aeb2a6a3bae5631602452c14d403,"This paper proposes a model-free off-policy actor-critic algorithm for image-based reinforcement learning. The main idea is to use an autoencoder to learn a latent representation of an image, and use an auxiliary decoder to reconstruct the original image. The decoder is trained end-to-end with the learned representation. The proposed method is evaluated on a variety of continuous control tasks. "
SP:917bc9151a5829e97efd9bd0d0b2a3d1771b3265,"This paper proposes a new dropout technique, called multi-sample dropout, for accelerating training and improving generalization of deep neural networks. The key idea is to create multiple dropout samples at the dropout layer while the original dropout creates only one dropout sample. This technique can be easily implemented without implementing a new operator by duplicating a part of the network after dropout while sharing the weights among the duplicated fully connected layers. Experiments on image classification tasks demonstrate the effectiveness of the proposed method."
SP:5ad4b9e837e08d995b545b0b2734bc8fa4fafc43,"This paper proposes a Label Sensitive Gate (LSG) training strategy for CNNs that forces each filter to extract features mainly from only one or a few classes. The LSG training encourages top convolutional filters to focus on fewer classes, which implies its feature map can localize a class better. Experiments demonstrate the effectiveness of the proposed method. "
SP:c9a512b6bc59aacbec2d5608284e29a7746172cf,This paper proposes a communication-aware Q-function factorization method for multi-agent reinforcement learning. The proposed method is based on two information-theoretic regularizers: mutual information maximization and entropy minimization. The authors show how to optimize these regularizers in a way that is easily integrated with existing value function factorization methods such as QMIX. Empirical results on the StarCraft unit micromanagement benchmark demonstrate the effectiveness of the proposed method.
SP:562f1a50f80d760a4be35095cd795cdb0f69a890,"This paper proposes a new type of problem called Programming Puzzles and a framework for generating a large set of hard problems that can both expose the weaknesses of existing solvers and which can be used in a GAN-like setup to train better solvers. The authors propose an adaptive problem generator that can be targeted at any given puzzle solver(s). They evaluate their puzzle generation on state-of-the-art neural and symbolic solvers, and establish the puzzle domain as suitable for teaching machines to program."
SP:627b515cc893ff33914dff255f5d6e136441d2e2,"This paper proposes a method to decompose a policy into a set of primitive policies and a meta-policy. The primitive policies are trained by minimizing the expected return of the standard RL objective, which is distributed to the primitives according to their participation in the policy. The paper proposes to use an information-theoretic mechanism for enabling this decentralized decision: each primitive chooses how much information it needs about the current state to make a decision and the primitive that requests the most information about the state acts in the environment. Experiments show that the proposed method outperforms both flat and hierarchical policies in terms of generalization."
SP:4d135a76ab151dd0adcf92c5ed8d3c717d256520,This paper proposes a method for learning a latent state representation from rewards. The method is based on learning a reward prediction model and then planning in the latent state-space. The authors show that their method is able to learn a concise representation similar to that of model-free DRL algorithms while maintaining high sample efficiency by planning with model-base algorithms. They demonstrate their method in the multi-pendulum and multi-cheetah environments. 
SP:03c61ba3d6fe01bd0bc3469cd408c370527d9d69,"This paper proposes two parameter reduction techniques to reduce the memory consumption and increase the training speed of BERT. The first method is based on a self-supervised loss that focuses on modeling inter-sentence coherence, and the second method is a combination of the two. The authors show that the proposed methods lead to models that scale much better compared to the original BERT model. "
SP:5dd50f3e6cef6b82192a1d37b35469dc7fb443ce,"This paper proposes a transformer-based architecture for multi-task learning with spatio-temporal data. The proposed architecture is based on the Transformer architecture, but with a spatial dimension of the input in addition to the hidden states corresponding to the temporal input sequence. The authors claim that the proposed architecture enables a single model to support tasks with multiple input modalities as well as asynchronous multi task learning. Experiments are conducted to demonstrate the effectiveness of the proposed model."
SP:6c8e2dd1d6224dffb95dbf729b159f00bfb05721,This paper proposes a new method for quantifying the uncertainty of predictions made by deep neural networks. The method is based on the use of higher-order influence functions (HOIFs) of the trained model parameters to construct a jackknife (leave-one-out) estimator of predictive confidence intervals. Experiments show that the proposed method outperforms Bayesian neural networks with respect to discriminative performance and provides better frequentist coverage.
SP:057a035c4eeeb5fe985b20d0266126d66d9d243f,"This paper proposes a GAN-based method for video synthesis and video prediction. The proposed method is based on the Dual Video Discriminator GAN (DVD-GAN), which is trained on the Kinetics-600 dataset. The main idea is to decompose the discriminator of the GAN into a discriminator and a generator, and use the generator to generate video samples of higher complexity and fidelity than previous work. The experimental results show that the proposed method achieves new state-of-the-art FID and Inception Distance for Kinetics600 and UCF-101 datasets."
SP:a89ee8eb2f60d9d522993a57d656f0ef726d86d6,"This paper studies the problem of few-shot learning when even base classes images are limited in number. To address this problem, the authors use a pre-trained network on a large-scale dataset and a very simple spatial attention mechanism that does not require any training on the base or novel classes. The experiments show that even when the domain gap is large between the dataset used for pre-training and the base/novel class domains, it is still possible to get significant benefit from base class training even with a few examples."
SP:d236f0b38414442af00b9be5e5d39e138f0069a2,"The paper proposes a method for generating structured objects that satisfy structural constraints. These constraints are assumed to be logical constraints, i.e., molecules must be chemically valid, game maps must guarantee reachability of the goal, and so on. The method is based on an adversarial network that penalizes the generator whenever it outputs invalid structures. The authors show that the proposed method can generate valid structures that are both high-quality and novel. "
SP:110f0b86431f0a93cf48e08fe445e32172a37eae,"This paper proposes a new activation function called Symmetric piecewise linear units (S-APL), which is a learnable activation function based on Adaptive Piecewise Linear units (APL) and is able to approximate any zero-centered continuous non-linearity in a closed interval. The authors hypothesize that these activation functions go through two distinct stages: 1) adding gradient information and 2) adding expressive power. Finally, the authors show that the use of S-apL activations can significantly increase the robustness of deep neural networks to adversarial attacks."
SP:4787aff0fb84beb13cde0d40c32d3a743d8e4082,"This paper proposes to use a Dirichlet-based deep learning model to enrich the output of a classification black-box with a measure of uncertainty to improve the trustability of the resulting system. The proposed method is based on a probabilistic neural network that works in parallel to the black box classifier and uses a reparameterization trick on the Dirichlets to capture the distribution on the multinomial parameters of the classifier's output. Based on the resulting uncertainty measure, the authors advocate for a rejection system that selects the more confident predictions, discarding those more uncertain, leading to an improvement in trustability. Experiments are conducted on NLP and computer vision datasets."
SP:1207bf6cf93737d63e1a7cc1ff3a99bf9d6098f9,"This paper proposes to use blockwise adaptive stepsize instead of coordinate-wise adaptivity to adapt the stepsize for each parameter block in Adagrad. Theoretical analysis is provided to show that the proposed method has comparable regret in online convex learning and convergence rate for optimizing nonconvex objective as its counterpart with coordinatewise adaptive stepsize, but is better up to some constant. Experiments are conducted on synthetic datasets, image classification and language modeling. "
SP:0334d79349e9fb8ca32751b7ad29f82e00a5381c,"This paper proposes a new video dataset, called CATER, to test the ability to recognize compositions of object movements that require long-term reasoning. The authors claim that current video datasets are plagued with implicit biases over scene and object structure that can dwarf variations in temporal structure. To address this problem, the authors build a video dataset with fully observable and controllable object and scene bias, and which truly requires spatiotemporal understanding in order to be solved. The dataset is rendered synthetically using a library of standard 3D objects, and tests the ability of the model to recognize composition of object movement that requires long term reasoning. In addition to being a challenging dataset, CATER also provides a plethora of diagnostic tools to analyze modern spatio-temporal video architectures by being completely observable. "
SP:b637c75acbe9d0152384b632f2e92a0d248cb720," GANs are a powerful family of models that learn an underlying distribution to generate synthetic data. Many existing studies of GAN focus on improving the realness of the generated image data for visual applications, and few of them concern about improving the quality of generated data for training other classifiers. This paper proposes a Boundary-Calibration GAN (BCGANs) that leverage the boundary information from a set of pre-trained classifiers using the original data. In particular, the authors introduce an auxiliary boundary-calibration loss (BC-loss) into the generator to match the statistics between the posterior distributions of original data and generated data with respect to the boundaries of the pre-train classifier. The BC-loss is provably unbiased and can be easily coupled with different GAN variants to improve their model compatibility. Experimental results demonstrate that BCGANs not only generate realistic images like original GAN but also achieves superior model compatibility than the original GGANs."
SP:93616e31fa1dc64d130c0c44cbb73c0412b24a97,"This paper proposes a new adversarial training method based on a generic learning-to-learn (L2L) framework. Specifically, instead of applying the existing hand-designed algorithms for the inner problem, this paper learns an optimizer, which is parametrized as a convolutional neural network. At the same time, a robust classifier is learned to defense the adversarial attack generated by the learned optimizer. The experiments over CIFAR-10 and CIFar-100 datasets demonstrate that the proposed method outperforms existing adversarial learning methods in both classification accuracy and computational efficiency."
SP:0a66c3540383c76689258d2fffe0571ed944c1e7,"This paper studies the problem of constraint-based inverse reinforcement learning (IRL) in the Markov Decision Process (MDP) setting. The authors propose an algorithm that iteratively estimates the Maximum Likelihood Constraint to best explain observed behavior. The algorithm is based on the Maximum Entropy IRL framework, which allows us to reason about the likelihood of an expert agent’s demonstrations given our knowledge of an MDP. The proposed algorithm is evaluated on simulated and real-world data. "
SP:2a5fba69a6287b87a19bcd745d2e4326bbb723de,"This paper proposes a deep recurrent neural network architecture that approximates known visual cortical circuits (Mély et al., 2018). The authors show that this architecture, which they refer to as the γ-Net, learns to solve contour detection tasks with better sample efficiency than state-of-the-art feedforward networks, while also exhibiting a classic perceptual illusion, known as the orientation-tilt illusion. Correcting this illusion significantly reduces the accuracy by driving the network to prefer low-level edges over high-level object boundary contours. Overall, this paper suggests that the orientation tilt illusion is a byproduct of neural circuits that help biological visual systems achieve robust and efficient contour discovery."
SP:4f094a3f7eeb302738c2b482fbaca56e34ac6a99,"This paper proposes a context-aware CNN (or conCNN) that enforces the semantics context constraints in the CNN-based object detector by leveraging the popular conditional random field (CRF) model in CNN. In particular, the proposed conCNN features a context aware module that naturally models the mean-field inference method for CRF using a stack of common CNN operations. The experiments using COCO datasets showcase that conCNN improves the average precision of object detection by 2 percentage points while only introducing negligible extra training overheads."
SP:74d63293d2f8a41a14743bfcd8939fca5e804fdb, the use of different normalization statistics during training and inference (mini-batch statistics for training and moving average of these values at inference) is the main cause of this adversarial vulnerability in the BatchNorm layer. Experiments on various neural network architectures and datasets show the effectiveness of the proposed RobustNorm (RobustNorm) and experimentally show that it is not only resilient to adversarial perturbation but also inherit the benefits of Batchnorm layer.
SP:f16d3e61eda162dfee39396abbd594425f47f625,"This paper studies the problem of training deep neural networks with noisy labels. The authors propose two regularization methods: (i) regularization by the distance between the network parameters to initialization, and (ii) adding a trainable auxiliary variable to the network output for each training example. Theoretically, they prove that gradient descent training with either of these two methods leads to a generalization guarantee on the clean data distribution despite being trained using noisy labels, and the generalization analysis relies on the connection between wide neural network and neural tangent kernel (NTK). The generalization bound is independent of the network size, and is comparable to the bound one can get when there is no label noise. Experimental results verify the effectiveness of these methods."
SP:67335658ec9de6ba3fa352ca4de073ac51f2f703,This paper proposes to improve the performance of CNN-GP and Convolutional Neural Tangent Kernel (CNTK) by using a new operation called Local Average Pooling (LAP) that preserves efficient computability of the kernel and inherits the spirit of standard data augmentation using pixel shifts. This idea is inspired by global average pooling (GAP) and is equivalent to full translation data augmentations. Extensive experiments on CIFAR-10 and Fashion-MNIST demonstrate the effectiveness of the proposed method.
SP:4ffab7f7f9fc09fdf59602228d231c6f6330fb98,"This paper proposes a method for combining model-free Q-learning with model-based Monte-Carlo Tree Search (MCTS). The key idea is to use a learned prior over state-action values is used to guide MCTS, which estimates an improved set of state action values. The new Q-estimates are then used in combination with real experience to update the prior. This effectively amortizes the value computation. Experiments on physical reasoning tasks and Atari demonstrate the effectiveness of the proposed method."
SP:ab451cc0ec221864a5da532eceba0f021f30def4,"This paper proposes a novel neural network architecture to perform stereoscopic view synthesis at arbitrary camera positions along the X-axis, or “Deep 3D Pan”, with “t-shaped” adaptive kernels equipped with globally and locally adaptive dilations. The proposed network architecture, the monster-net, is devised with a novel t-shaped adaptive kernel, which can incorporate global camera shift into and handle local 3D geometries of the target image’s pixels for the synthesis of naturally looking 3D panned views when a 2D input image is given. Extensive experiments were performed on the KITTI, CityScapes, and our VICLAB STEREO indoors dataset to prove the efficacy of the proposed method."
SP:e308cf28f7bd5d8e6c36517e2845298ccd401f5d,"This paper analyzes the variational auto-encoder (VAE) from an information theoretic perspective. The authors show that the optimal generative model is the one optimising the capacity-constrained InfoMax (CCIM), a theoretical objective learning the maximal informative model while maintaining bounded the network capacity. The theoretical assumptions are confirmed by the empirical experiments. "
SP:ef4a0c82cc364b797fba0ba86a91d9945b66a193,"This paper studies the problem of learning node embeddings that capture information about a node from the local distribution over node attributes around it, as observed over random walks following an approach similar to Skip-gram. The authors propose two approaches: pooled (AE) and multi-scale (MUSAE) approaches. They prove that these algorithms implicitly factorize probability matrices of features appearing in the neighbourhood of nodes. Experiments show that their algorithms are robust, computationally efficient and outperform comparable models on social, web and citation network datasets."
SP:70d92189aedeb4148b61b987d97a3c15898dd834,"This paper studies the phase transitions in the Information Bottleneck (IB) objective. The authors define the phase transition as a qualitative change of the IB loss landscape and show that the transitions correspond to the onset of learning new classes. Based on this definition, the authors derive a formula that provides a practical condition for IB phase transitions and draw its connection with the Fisher information matrix for parameterized models. Finally, an algorithm for discovering phase transition points is proposed. Experiments on MNIST and CIFAR10 show the effectiveness of the proposed method."
SP:fecfd5e98540e2d146a726f94802d96472455111,This paper proposes a new advantage estimation method based on importance sampling. The main idea is to use the independence property between current action and future state to reduce the variance of the advantage estimation. The proposed advantage estimator is based on an importance sampling approach and is shown to have low variance even when the Monte-Carlo return signal yields a large variance. Experiments demonstrate that the proposed method achieves higher sample efficiency compared with existing advantage estimation methods in complex environments.
SP:f0d84396e0ede7969d3f3f55549d214f20daf1b0,"This paper proposes a bias reduction method for policy evaluation. The method is based on density ratio estimation and value function estimation. The bias vanishes when either the density ratio or value function estimate is perfect. In general, when either of them is accurate, the bias can also be reduced. Both theoretical and empirical results show that the proposed method yields significant advantages."
SP:73f8dddb09333a739c609cc324a1e813d29f8874,"This paper proposes a novel Metric-Softmax loss for few-shot classification. The Metric Softmax loss is trained against the whole label set and learns more discriminative feature than episodic training. In the second stage, a task-adaptive transformation is proposed to adapt the classifier to each task setting very fast within a few tuning epochs. Experiments show that the proposed method outperforms current state-of-the-arts on mini-ImageNet and CUB-200-2011 benchmarks."
SP:cde2a84c463cdab9b19fcbdaf1cfe20d0187dcfa,"This paper proposes a data-driven approach to improve the accuracy of numerical solvers by learning a correction function. The proposed method utilizes an advanced numerical scheme with a fine simulation resolution to acquire reference data, then employs a neural network that infers a correction to move a coarse thus quickly obtainable result closer to the reference data. The authors demonstrate two variants to achieve this goal in the context of fluids: a supervised version with an optimization algorithm for acquisition of temporally constrained correction data and an unsupervised version with a differentiable PDE solver that allows us to take into account temporal information when training."
SP:e6534cd49bdc266dbeb111682ad37ef9d666e31e,"This paper proposes a method for online continual compression. The proposed method is based on a modular autoencoder architecture, which consists of a series of discrete autoencoders, each equipped with their own memory. This modularity has several advantages: 1) moderate compressions are quickly available early in training, which is crucial for remembering the early tasks, 2) as more data needs to be stored, earlier data becomes more compressed, freeing memory, 3) unlike previous methods, this approach does not require pretraining, even on challenging datasets. "
SP:4ada8234990b4dbcdecb6bafeb6f509263661ae8,"This paper proposes a neural network-based method for multi-label learning. The proposed method is based on a bidirectional representation learning approach where the label dependency is also integrated and deep convolutional networks that handle image data. The model scales linearly in the number of instances and trains deep neural networks that encode both input data and output labels, then, obtains a metric space for testing data. Experiments on a number of datasets demonstrate the effectiveness of the proposed method."
SP:d81a0edd94cc0b32734c42f1fb65d7070f963f86,"This paper analyzes the learning rate of asynchronous stochastic gradient descent (SGD) using dynamical stability analysis. The authors show that the degree of delay interacts with the learning rates, to change the set of minima accessible by an asynchronous SGD algorithm. They derive closed-form rules on how learning rate can be changed, while keeping the accessible set the same. Specifically, for high delay values, they find that learning rate should be inversely proportional to the delay. They also extend this analysis to include momentum. "
SP:05587c2ba9ff9bf3574604a60f614dd807c95e22,"This paper proposes a reinforcement learning algorithm HiMo, which learns a value function in hindsight that receives future observations as an additional input. The key idea is to determine which features of the future trajectory provide useful information to predict the associated return. This provides us with tractable prediction targets that are directly relevant for a task, and can thus accelerate learning of the value function. Experiments on Atari games demonstrate the effectiveness of the proposed method."
SP:6388fb91f2eaac02d9406672760a237f78735452,"This paper proposes a novel rewiring operation for graph neural networks (GNNs) that can be used to generate adversarial examples by performing re-wiring operations for the task of graph classification. More specifically, the authors treat the process of applying a series of reweiring operations to a given graph as a discrete Markov decision process (MDP) and use reinforcement learning to learn how to make these decisions. Experiments on real-world graphs demonstrate the effectiveness of the proposed algorithm."
SP:233b12d422d0ac40026efdf7aab9973181902d70,"This paper studies the problem of denoising neural networks for inverse problems. The authors propose a novel bagging scheme to prevent the encoder-decoder CNN from converging to a trivial identity mapping. The proposed method is based on the SURE unbiased risk estimator (SURE), which is an unbiased estimator of the prediction error of a denoiser. However, the computation of the divergence term in SURE is difficult to implement in a neural network framework, and the condition to avoid trivial identity maps is not well defined. To solve this problem, the authors propose to use a close form expression of the unbiased SURE estimator for prediction error. The close form representation leads to a novel bootstrap and aggregation scheme to avoid the neural network from converges to an identity mapping so that it can enhance the performance. Experimental results show that the proposed algorithm provides consistent improvement in various inverse problems, suggesting that the convergence term can be neglected if a proper batch normalization is used."
SP:978555e8eced096b92b37a91fc16b60f7d99c2b6,This paper proposes a Bayesian meta-learning method for imbalanced few-shot classification tasks. The main idea is to use a variational inference framework to learn to balance the effects of meta-adaptive learning and task-specific learning. The proposed method is evaluated on a variety of imbalanced task and class-imbalanced datasets.  
SP:2395947721c4a337701a7c61cd4ba5c0e38fcc9b,"This paper proposes a method for imitation learning that does not require learning a reward function. The main idea is to provide the agent with an incentive to match the demonstrations over a long horizon, by encouraging it to return to demonstrated states upon encountering new, out-of-distribution states. This is achieved by giving the agent a constant reward of +1 for matching the demonstrated action in a demonstrated state, and a constant-reward of r = 0 for all other behavior. The proposed method can be implemented with any standard Q-learning or off-policy actor-critic algorithm. Empirically, the authors show that SQIL outperforms BC and achieves competitive results compared to GAIL."
SP:37a4825aaeb899187b957d9ed9ae657617f4a055,"This paper proposes a method to learn a Lagrangian representation for dynamic point clouds. The proposed method is based on a super-resolution method with a truncation approach to flexibly adapt the size of the generated positions. The authors show that their method works for large, deforming point sets from different sources to demonstrate the flexibility of their approach."
SP:af54d04f219d381208c049b8a9c59b8cdd1783e0,"This paper proposes an end-to-end optimizer (OT-SI) based on optimal transport (OT) to learn the cost function for aligning two datasets. The cost function is learned using a small amount of side information which is often available. The side information captures subset correspondence, i.e. certain subsets of points in the two data sets are known to be related. The proposed method is evaluated on image, marriage-matching and single-cell RNA-seq datasets."
SP:fc86b06a367f6790c76b89ec3bfe4cb8627c540a," data. This paper proposes a novel method to detect anomalies in large datasets under a fully unsupervised setting. The key idea is to learn the representation underlying normal data. To this end, the authors leverage the latest clustering technique suitable for handling high dimensional data. They train an autoencoder from the normal data subset, and iterate between hypothesizing normal candidate subset based on clustering and representation learning. Experimental results on several public benchmark datasets show that the proposed method outperforms state-of-the-art unsupervisory techniques and is comparable to semi-supervised techniques."
SP:9e831d3595c15ca34cadb3c4a5b02230593b4ccb,"This paper proposes Projection-Based Constrained Policy Optimization (PCPO), an iterative method for learning policies that optimize a reward function while satisfying constraints due to considerations of safety, fairness, or other costs. The first step performs a local reward improvement update, while the second step reconciles any constraint violation by projecting the policy back onto the constraint set. The authors theoretically analyze PCPO and provide a lower bound on reward improvement, and an upper bound on constraint violation, for each policy update. They further characterize the convergence of PCPO based on two different metrics: L norm and Kullback-Leibler divergence. "
SP:068a0bb2497373acad5f70e66c61b71465b2de3d,"This paper analyzes the inner mechanism of word embedding. The authors show that the embedding can be viewed as a low-rank transformation from the word-context co-occurrence space to the embeddings space, which will preserve the relative distances among words. Furthermore, the authors provide a theoretical explanation for this behavior, and derive a method to automatically find its optimal value. The experiments on real datasets verify the analysis."
SP:b2d099c78b48aab509ab64027ca49e9a47079fc0,"This paper proposes X-Forest, a method to improve the efficiency and accuracy of similarity measurement for clustering tasks. The method is based on the Random Projection Tree (RP) tree, which is a tree-based clustering algorithm. The proposed method is evaluated on three real-world datasets.  "
SP:77b8bed08af8be8af0c65a72a6e22cfb02645d02,"This paper proposes a hybrid method for inference based on Markov chain Monte Carlo (MCMC) and variational inference (VI). The main idea is to reduce the approximation bias by increasing the number of MCMC steps, generate independent samples, and tune MCMC hyperparameters by optimising an objective function that directly quantifies the bias of the resulting samples. The proposed method is evaluated on synthetic examples and deep generative models."
SP:64f2744e938bd62cd47c1066dc404a42134953da,This paper proposes a method for treatment effect estimation from observational data with missing covariates. The method is based on a variational autoencoder (VAE) that is adapted to the missing values. The authors show that the VAE can be used as a pre-processing step prior to causal inference or as a multiple imputation strategy to take into account the variability due to missing data. Numerical experiments are conducted to demonstrate the effectiveness of the proposed method.
SP:971d0d94adf5113ee1bef8df9ea7dbd508cf4cbc,"This paper presents a neural architecture search algorithm to construct compact reinforcement learning policies, by combining ENAS (Vinyals et al. 2015; Pham et al., 2018; Zoph & Le, 2017) and ES (Salimans et al,. 2017) in a highly scalable and intuitive way. By defining the combinatorial search space of NAS to be the set of different edge-partitionings (colorings) into same-weight classes, the authors represent compact architectures via efficient learned edge partitionings. For several RL tasks, the learned colorings translate to effective policies parameterized by as few as 17 weight parameters, providing > 90% compression over vanilla policies and 6x compression over state-of-the-art compact policies."
SP:18aaba3423e81e9437b509d1a5e24836ef5635f6,This paper proposes a novel method for learning representations of time-series using a Group Transform (GT) approach. The GT is a generalization of the Wavelet Transform (WT) and the Short-Time Fourier Transform (STFT) based on a subset of invertible maps on the space of strictly increasing and continuous functions. The authors also propose a parameterization of such a non-linear map such that its sampling can be optimized for a specific loss and signal. Experiments are conducted on bird detection and haptics classification. 
SP:3058e6bc5e8c62af325c214c9e1436d6cdf09204,"This paper proposes a generalization of graph convolutional networks (GCN) to (products of) constant curvature spaces. The authors introduce a unified formalism that can interpolate smoothly between all geometries of constant curvatures, leveraging gyro-barycentric coordinates that generalize the classic Euclidean concept of the center of mass. Empirically, the authors show that the proposed method outperforms Euclideans GCNs in the tasks of node classification and distortion minimization for symbolic data."
