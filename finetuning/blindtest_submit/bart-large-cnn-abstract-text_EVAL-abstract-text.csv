paper_id,summary
SP:b19df5243359791fbaad005d6f13d7e9fdb0ff63,"This paper proposes a method for role-based multi-agent learning in the context of StarCraft II. The main idea is to learn a role selector based on action effects and a role policy based on the role selector. The role selector searches in a smaller role space and at a lower temporal resolution, while the role policies learn in significantly reduced primitive action-observation spaces. The proposed method is evaluated on 9 of the 14 scenarios that comprise the challenging StarCraft II micromanagement benchmark and achieves rapid transfer to new environments with three times the number of agents."
SP:7deb61890d97422a0fe141ca807f968c70ab239a,"This paper studies the behavior of stochastic subgradient descent (SSGD) method applied to over-parameterized nonsmooth optimization problems that satisfy an interpolation condition. By leveraging the composite structure of the empirical risk minimization problems, the authors prove that SSGD converges, respectively, with rates O(1/ ) and O(log(1 / ) for convex and strongly-convex objectives when interpolation holds. These rates coincide with established rates for the stochastically gradient descent (SGD) method. The analysis provides a partial explanation for the empirical observation that sometimes SGD and SSGD behave similarly for training smooth and nonsmoothed machine learning models."
SP:c7e0b3fedc0d0409d662dd612b529fdacad2b03e,"This paper proposes a method to improve the performance of Transformer models by replacing some of the layers in the original transformer layers with non-linear ""reservoir"" layers. The authors show that the proposed method is able to reduce the wallclock compute time until convergence, as well as improve the overall performance on various machine translation and (masked) language modelling tasks. The paper is well-written and well-motivated. "
SP:ba9f1d4738ec67a440346f3ac6c4cf35f7232077,This paper studies steerable convolutional kernels in the context of group representation theory. The authors show that filter transformed kernels can be used to convolve input/output features in different group representations. This interpretation helps complete the puzzle of steerable CNN theory and provides a novel and simple approach to implement steerable operators. Experiments are performed on multiple datasets to verify the feasibility of the proposed approach.
SP:c1116fbb4d058eb6be195b5d13d19a55ba86b602,"This paper proposes an optimal neural synthesis approach for multimodal program synthesis, where the goal is to find a program that satisfies user-provided constraints while maximizing the program’s score with respect to a neural model. Specifically, the paper proposes a top-down recurrent neural model that places distributions over abstract syntax trees conditioned on the NL input. This model not only allows for efficient search over the space of syntactically valid programs, but it also allows to leverage automated program analysis techniques for pruning the search space based on infeasibility of partial programs with respect the user”s constraints. The experimental results on a multimodel synthesis dataset (STRUCTUREDREGEX) show that the proposed method substantially outperforms prior state-of-the-art techniques in terms of accuracy."
SP:55e02d79146bbb42f1ab6d4fafa2db5ddbe599b0,"This paper proposes a protein graph convolutional neural network (PGCN) to predict the substrate specificity landscape of a protease enzyme, which is the set of all sequence motifs that are recognized/cut by the enzyme. The proposed method is based on a structure-based molecular interaction graph generated using the Rosetta energy function that describes the topology and energetic features, to determine substrate specificity. The authors use the PGCN to recapitulate and predict the specificity of the NS3/4 protease from the Hepatitic C virus. They compare the performance of the proposed method with existing machine learning models and show that its performance in classification tasks is equivalent or better."
SP:7727eeb7b17ad94ddfa0cf24e64a9626d83a8876,"This paper studies the problem of underestimation bias in double Q-learning. Double Q-Learning is a classical method for reducing overestimation bias, which is caused by taking maximum estimated values in the Bellman operation. In this paper, the authors show that such underestimation biases may lead to multiple non-optimal fixed points under an approximate Bellman operator. To address this issue, they propose a simple but effective approach as a partial fix. The proposed method leverages an approximate dynamic programming to bound the target value. The experimental results on Atari benchmark tasks demonstrate the effectiveness of the proposed method."
SP:1d630b69f95392a5ef3d7d580b523e077a3555a8,"This paper proposes a two-step training framework for deep generative models (DGMs) of high-dimensional natural images. The first step is to generate images in low-frequency bands by training a sampler in the wavelet domain and then super-resolve these images back to the pixel-space with a novel wavelet super-resolution decoder network. Wavelet-based down-sampling method preserves more structural information than pixel-based methods, leading to significantly better generative quality of the low-resolution sampler (e.g., 64x64). Since the sampler and decoder can be trained in parallel and operate on much lower dimensional spaces than end-to-end models, the training cost is substantially reduced. On ImageNet 512x512, the proposed model achieves a Fréchet Inception Distance (FID) of 10.59 – beating the baseline BigGAN model – at half the compute (256 TPU-v3 cores)."
SP:b943a73b1ec34867371325748dc3a91ff4011947,"This paper analyzes why self-supervised learning (SSL) is suitable for few-shot learning (FSL). The authors first analyzed the supervised FSL methods and explained why SSL is suitable to FSL. Then, the authors analyzed the main difference between supervised training and self supervised training on FSL and obtained the bound for the gap between the self supervised loss and the supervised loss. Finally, they proposed potential ways to improve the test accuracy under the setting of self supervised learning."
SP:bd552f98e6a447cefa6b1a9bbdf40bc6539fb643,"This paper studies the convergence of neural networks with finite width. The authors prove that under the most basic settings, all student neurons must align with the teacher neuron at any local minima near the initialization. They extend this result to more general cases, where the proof can be reduced to analyzing the properties of a special class of functions that the authors call Angular Distance (AD) function. Finally, they demonstrate that these properties can be easily verified numerically."
SP:0f62846913ec10b44ed32845770da0565479dc75,"This paper proposes a method for learning deep neural networks that incorporate formal knowledge to improve learning from data. The method is based on a neural network architecture that learns a representation of the input data, which is then used to generate a model that is trained on the learned representation. The authors provide formal semantics that demonstrate that their knowledge representation captures all of first order logic and that finite sampling from infinite domains converges to correct truth values. The paper also demonstrates that their representation improves on prior neuro-symbolic work by avoiding vanishing gradients, allowing deeper logical structure, and enabling richer interactions between the knowledge and learning components."
SP:2f19259d65fab904c1b771244da3dcb2f8aa0c26,"This paper studies the problem of learning iterative solutions in feedforward residual neural networks (ResNets). The authors define three indices of iterative convergence and show that, even though ResNets can express iterative solution, they do not learn them when trained conventionally on computer vision tasks. They then introduce regularizations to encourage iterative convergent computation and test whether this provides a useful inductive bias. To make the networks more iterative, they manipulate the degree of weight sharing across layers using soft gradient coupling. They also impose a Lipschitz constraint on the residual functions using spectral normalization to make them more convergent."
SP:6c14506b8b2b06043409d912e6bf877651aaa665,"This paper proposes two new normalization methods for out-of-distribution (OOD) training. The first method, SelfNorm, uses attention to recalibrate statistics (channel-wise mean and variance), while the second method, CrossNorm, exchanges statistics between feature maps. Experiments on different domains (vision and language), tasks (classification and segmentation), and settings (supervised and semi-supervised) show the effectiveness of both methods."
SP:2774abdc11917321dd4994af0f0da1ff824bea03,This paper proposes to augment the attention module in the convolutional encoder of an RL agent with a simple attention module. The proposed module is a simple extension of the attention mechanism in the attention layer of the CNN. The authors show that the proposed module can extract interpretable task-relevant information such as agent locations and movements without the need for data augmentations or contrastive losses. Experiments on the DeepMind Control Suite environments demonstrate that their proposed module extracts interpretable information without the use of contrastive loss. The experiments also show that their module can significantly improve the sampleefficiency and final performance of the agents.
SP:31a7051d08d19c01e11f1fac2f3041ed2fa28f15,"This paper proposes an extension of the GradNorm algorithm for multitask learning. The main idea is to add a rotation matrix to the gradient of the gradient for each task, which is added to the original GradNorm layer. The paper provides theoretical analysis on the stability and convergence of the proposed method. The experiments on several real-world datasets and network architectures show that the proposed Rotograd outperforms previous approaches."
SP:ac9ebd027b92527d9a87b13ad11d002d99a2b0f6,"This paper proposes a novel I2I translation constraint, called Minimal Geometry-Distortion Constraint (MGC), which promotes the consistency of geometry structures and reduce the unwanted distortions in translation by reducing the randomness of color transformation in the translation process. To facilitate estimation and maximization of MGC, the authors propose an approximate representation of mutual information called relative Squared-loss Mutual Information (rSMI) that can be efficiently estimated analytically. The experimental results demonstrate the effectiveness of the proposed MGC on several benchmark datasets."
SP:92a38d7d18f07f68b8f93c61180e2cc1dddd21de,"This paper studies the effect of point sampling patterns in point cloud GANs. The authors propose a sampling spectrum to depict the different sampling sensitivities of discriminators. They further study how different evaluation metrics weigh the sampling pattern against the geometry and propose several perceptual metrics. They discover a middle-point sampling-aware baseline discriminator, PointNet-Mix, which improves all existing point cloud generators by a large margin on sampling related metrics."
SP:16c4be3eb162bc81cb3343c2fc115eb8e926a5b5,This paper investigates the adversarial robustness of Capsule neural networks (CapsNets) and proposes a novel vote attack to attack the votes of CapsNets directly instead of using multi-step attack methods designed for CNNs. The proposed method is based on the observation that adversarial examples can manipulate the votes from primary capsules. The authors propose a vote attack that bypasses the expensive routing mechanism of the traditional CNN attack method. The experimental results show that the proposed vote attack is effective and efficient by circumventing the routing process.
SP:dbd093dff7a38ba8882bb8119c34623ddaaf4cc6,"This paper proposes a method for meta-reinforcement learning in the online adaptation setting, where the agent must explore to identify its particular characteristics and then exploit this information for collecting reward. The authors propose a new algorithm that uses privileged information in the form of a task descriptor at train time to improve the learning of recurrent policies. The proposed method learns an informed policy (i.e., a policy receiving as input the description of the current task) that is used to both construct task embeddings from the descriptors, and to regularize the training of the recurrent policy through parameters sharing and an auxiliary objective. This approach significantly reduces the learning sample complexity without altering the representational power of RNNs, by focusing on the relevant characteristics of the task, and by exploiting them efficiently. The experimental results show that the proposed method outperforms vanilla RNN, Thompson sampling and the task-inference approaches to meta reinforcement learning."
SP:bd89d254fbf31db61db237d08ab42981e27c52df,"This paper proposes a method to learn an RL policy from offline data in the real-world sequential recommendation system (SRS). Instead of increasing the fidelity of models for policy learning, this paper learns to adapt to diverse simulators generated by the offline dataset. Experiments are conducted in synthetic environments and a real world ride-hailing platform. The results show that the method overcomes the distortion problem and produces robust recommendations in the unseen real world."
SP:1a166b28cf684e0d5759bd629f6a53370d2bf11c,"This paper proposes an imitation learning algorithm for goal-reaching reinforcement learning. The main idea is to leverage the property that any trajectory is a successful demonstration for reaching the final state in that same trajectory. The authors propose a simple algorithm in which an agent continually relabels and imitates the trajectories it generates to progressively learn goal reaching behaviors from scratch. Each iteration, the agent collects new trajectories using the latest policy, and maximizes the likelihood of the actions along these trajectories under the goal that was actually reached, so as to improve the policy. "
SP:c306530164d677e670554eeba8203c66bb3d9f7a,"This paper proposes a new method for non-autoregressive text to speech (TTS) models, FastSpeech 2, which addresses the one-to-many mapping problem in TTS by directly training the model with ground-truth target instead of the simplified output from teacher, and introducing more variation information of speech (e.g., pitch, pitch, energy and more accurate duration) as conditional inputs in training and use predicted values in inference. Experimental results show that the proposed method can achieve a 3x training speed-up over the original fastSpeech model."
SP:79e9fb20d383816f54738ce70d137131ebc10290,"This paper studies the unsupervised dimension reduction problem (UDR) in the language of tempered distributions. The authors reformulate the problem of approximating an empirical probability density function pemp(x) by another tempered distribution q(x), whose support is in a k-dimensional subspace, as the minimization of the distance between q and pemp, D(q, pemp) over a set of generalized functions. This formulation allows to establish a connection with another classical problem of data science — the sufficient dimension reduction (SDR) problem. In order to reduce an optimization problem over distributions to an optimization problems over ordinary functions, the authors introduce a nonnegative penalty function R(f) that “forces” the support of f to be k-diminishing. Then they present an algorithm for minimization I(f + \lambda) + \rhoR(f), based on the idea of two-step iterative computation, which is briefly described as an adaptation to real data and to fake data sampled around a k dimensional subspace found at a previous iteration, and b) calculation of a new k-dimension subspace."
SP:93e54522e6c2b805905d21fc968fc40866f2898b,"This paper proposes Feature Contrastive Learning (FCL) to improve the robustness of deep neural networks. The authors propose two notions: contextual feature utility and contextual feature sensitivity, and propose a method that encourages the model to be more sensitive to features that have higher contextual utility. Experiments on MNIST and CIFAR-10 show that the proposed method achieves a better balance of robustness and sensitivity."
SP:f03c50f15022c4f56ac2b3085354ffed38ad1145,"This paper proposes a new method for imitation learning based on adversarial imitation learning. The main idea is to learn a latent representation of a task using a discriminator network, which is trained with adversarial examples. The discriminator is regularized with mutual information constraints to encourage the discriminator to learn only features that encode information about the completion levels of the task being demonstrated. This allows to obtain a shared feature space to successfully perform imitation while disregarding the differences between the expert's and the agent's domains. Empirically, the proposed method is able to efficiently imitate in a diverse range of control problems including balancing, manipulation and locomotive tasks while being robust to various domain differences in terms of both environment appearance and agent embodiment."
SP:ef18f4188426bc01be309633b486884b0e7a81a4,"This paper studies the lottery ticket hypothesis (LTH) which states that learning on a properly pruned network (the winning ticket) improves test accuracy over the original unpruned network. The paper provides a theoretical analysis of the performance of training a pruned neural network by analyzing the geometric structure of the objective function and the sample complexity to achieve zero generalization error. It shows that the convex region near a desirable model with guaranteed generalization enlarges as the neural network model is pruned, indicating the structural importance of a winning ticket. The number of samples required for achieving zero generalisation error is proportional to the number of non-pruned weights in the hidden layer. The theoretical results are acquired from learning a pruning neural network of one hidden layer, while experimental results are further provided to justify the implications in pruning multi-layer neural networks."
SP:eed6cb2f8caed39f8295f4aeb6e044c2ac981c4d,"This paper proposes AutoLabel to automatically learn the labels for augmented data, based on the distance between the clean distribution and augmented distribution. AutoLabel is built on label smoothing and is guided by the calibration-performance over a hold-out validation set. The authors show that AutoLabel can be easily applied to existing data augmentation methods, including AugMix, mixup, and adversarial training. Experiments on Cifar-10, CIFAR-100 and ImageNet show that the proposed method can improve models’ accuracy and calibration performance, especially under distributional shift."
SP:0d5017e1a405bf86e3bac40e6e59886d4bf48450,"This paper proposes a novel self-supervised representation learning method based on a causal framework. The authors propose a novel objective, Representation Learning via Invariant Causal Mechanisms (RELIC), that enforces invariant prediction of proxy targets across augmentations through an invariance regularizer which yields improved generalization guarantees. Further, the authors generalize contrastive learning and provide an alternative theoretical explanation for the success of these methods. Empirically, RELIC significantly outperforms competing methods in terms of robustness and out-of-distribution generalization on ImageNet, while also outperforming these methods on Atari achieving above human-level performance on 51 out of 57 games."
SP:8f80a6f79f78c6421857f392c9a5e98061d7eb60,"This paper proposes a visual transformer network (VTNet) for object goal navigation. The main idea is to learn a spatial-aware representation of the scene, which can be used to guide the agent towards a target object based on observations of the agent. In particular, the authors propose a pre-training scheme to associate the visual representations with navigation signals, and thus facilitate navigation policy learning. Experiments on the artificial environment AI2-Thor demonstrate that VTNet significantly outperforms state-of-the-art methods in unseen testing environments."
SP:3e7cbe3dff592ef371e48dd86be7719fc5343f17,"This paper proposes a communication-computation efficient secure aggregation method for federated learning. The key idea is to design the topology of the secret-sharing nodes (denoted by the assignment graph G) as sparse random graphs instead of the complete graph corresponding to the existing secure aggregation solution. Theoretical guarantees on the reliability/privacy of the proposed scheme are provided, and extensive real-world experiments are conducted to demonstrate that the proposed method can maintain the same levels of reliability and data privacy while using only 50% of the resources."
SP:00fae41e0eca0a1575cd7b2dcfabf0dc5c9c8b8a,This paper proposes a novel approach to the problem of designing an incentive-compatible auction that maximizes expected revenue. The main contribution of this paper is the introduction of a time-independent Lagrangian that allows for a single metric to compare the performance of two auctions. The paper also proposes to amortize the inner maximization loop by adding an additional neural network to the optimization procedure. The experimental results show that the proposed method outperforms the existing methods.
SP:a0e8061beb5e9a6c631419861559d22b8d645cb4,"This paper proposes Bi-tuning, a general learning approach to finetune both supervised and unsupervised pre-trained representations to downstream tasks. The authors propose two heads: a classifier head with an improved contrastive cross-entropy loss to better leverage the label information in an instance-contrastive way, and a projector head with a newly-designed categorical contrastive learning loss to fully exploit the intrinsic structure of data in a category-consistent way. The experiments show that the proposed method achieves state-of-the-art results for fine-tuneing tasks on CUB in low-data regime."
SP:87e5b552c13d73bd85249062a152c6c140e594a9,This paper studies the problem of adversarial robustness of classifiers. The authors argue that standard adversarial accuracy fails to properly measure the robustness and propose a new measure called genuine adversarial error (GAE) which measures the adversarially perturbed samples without trading off accuracy on clean data and accuracy on the adversarial samples. They prove that a single nearest neighbor (1-NN) classifier is the most robust classifier according to GAE for given data and a norm-based distance metric.
SP:2fda410b9281c5e253d385bc4382ec168bc161f3,"This paper studies the problem of dyadic fairness in the context of link prediction in graph neural networks. The authors propose a new algorithm, FairAdj, to learn a fair adjacency matrix with proper graph structural constraints for fair link prediction, and in the meanwhile preserve predictive accuracy as much as possible. Empirical validation demonstrates that the proposed method delivers effective dyadic fairness in terms of various statistics and at the same time enjoys a favorable fairness-utility tradeoff."
SP:b614e9fbec58e9efa7722d2ec4a60fc93d210f92,"This paper proposes a disentangled exploration autoencoder (DEAE) that uses disentanglement and regularization to improve the quality of exploration in latent space and achieve controllable synthesis. The encoder first turns the input sample into a disenangled latent code, then explores the latent code space through directed interpolation. To aid the interpolated latent code in successfully outputting a meaningful sample, after the decoder, DEAE regularizes the output by ’reusing’ the encoder to force the obtained latent representation to maintain perfect disentangling. Experiments demonstrate that DEAE can improve the performance of downstream tasks by synthesizing attribute-controllable augmented samples."
SP:c934adb14926a00ef9c73c9773cb0b3a2669921e,"This paper proposes a new Bayesian memory allocation scheme that bridges the gap between episodic and semantic memory via a hierarchical latent variable model. The authors take inspiration from traditional heap allocation and extend the idea of locally contiguous memory to the Kanerva Machine, enabling a novel differentiable block allocated latent memory. They simplify the process of memory writing by treating it as a fully feed forward deterministic process, relying on the stochasticity of the read key distribution to disperse information within the memory. The experimental results demonstrate that this allocation scheme improves performance in memory conditional image generation."
SP:e63d7d8c581019e17585fb9c0eac33d6836e187d,"This paper studies the sample complexity and loss landscape of attention-based neural networks. Theoretical results show that, under mild assumptions, every local minimum of the attention model has low prediction error, and attention models require lower sample complexity than models without attention. Experiments on various datasets validate the theoretical findings."
SP:f739d199fdee26f09994e3f9487aec1eab0f2e89,"This paper studies the problem of active inference in the context of reinforcement learning. The authors extend the concept of expected free energy (EFE), which is a core quantity in active inference, and claim that EFE can be treated as a negative value function. Motivated by the prior preference and a theoretical connection, the authors propose a simple but novel method for learning a prior preference from experts. Experimental results of prior preference learning show the possibility of using EFE-based rewards and its application to an inverse RL problem."
SP:5592b79e49eba95c15103a3348f2bde57b60f2ab,"This paper proposes a data augmentation method to improve generalization in both adversarial and standard learning by using out-of-distribution (OOD) data that are devoid of the abovementioned issues. Theoretical analysis is provided to show how to improve the generalization theoretically using OOD data in each learning scenario and complement the theoretical analysis with experiments on CIFAR-10, Cifar-100, and a subset of ImageNet. The authors also present the advantages of the proposed method through comparison with other data augmentations methods, which can be used in the absence of unlabeled-in- distribution data."
SP:3cac7a2c310165ed0de46d8e5546c3bfbd639158,"This paper proposes a new meta-RL method called Fast Linearized Adaptive Policy (FLAP), which is based on the idea of learning a shared linear representation of the policy so that when adapting to a new task, it suffices to predict a set of linear weights. A separate adapter network is trained simultaneously with the policy such that during adaptation, FLAP can directly use the adapter network to predict these linear weights instead of updating a meta-policy via gradient descent. The application of the separate feed-forward network not only speeds up the adaptation run-time significantly, but also generalizes extremely well to very different tasks that prior MetaRL methods fail to generalize to. Experiments on standard continuous-control metaRL benchmarks show FLAP presenting significantly stronger performance on out-of-distribution tasks."
SP:21a1bd4ada0723c96c0dbf7a142a2faf5defa4e3,"This paper proposes a federated kernel k-means algorithm to solve the optimization problem of kernel k means under federated settings. The authors propose a distributed stochastic proximal gradient descent (DSPGD) algorithm to determine an approximate solution to the optimization problems of kernelk means, and a communication efficient mech anism (CEM) is designed to reduce the communication cost. Theoretical analysis shows that DSPGD with CEM converges with an O(1/T) rate, where T is the number of iterations, and communication cost is not related to number of data samples. The clustering quality of the federated k means algorithm approaches that of the standard kernel k mean algorithm with a(1 +    ) approximate ratio. The experimental results show that the proposed federated kerne l k means achieves the highest clustering performance with the communication costs reduced by more than 60% in most cases."
SP:be568dd3fea51ce33a6d1e4b07dda5aee6342395,"This paper proposes CompOFA, a method to reduce the search space of Once-For-All (OFA) by constraining search to models close to the accuracy-latency Pareto frontier. The authors propose to use compound relationships between model dimensions to build a design space smaller by several orders of magnitude. They demonstrate that even with simple heuristics they can achieve a 2x reduction in training time and 216x speedup in model search/extraction time compared to the state-of-the-art."
SP:04b84d26cf282dbb753cbf27f14c334f65d3f8ec,"This paper proposes a meta-learning algorithm, ADML (Adversarial Meta-Learner), which leverages clean and adversarial samples to optimize the initialization of a learning model in an adversarial manner. The authors claim that the proposed algorithm is robust to adversarial attacks, and that it sheds light on tackling the cases with limited and even contaminated samples. The experimental results on MiniImageNet and CIFAR100 show that ADML outperforms several representative meta learning algorithms in the cases involving adversarial attack mechanisms."
SP:dfbaa6b53c4e8328d52666ad4641fc917bf0c0b3,This paper proposes a method to improve the performance of decoding error correction codes for Bose-Chaudhuri-Hocquenghem (BCH) codes. The authors propose a data-driven framework for permutation selection that combines domain knowledge with machine learning concepts such as node embedding and self-attention. The results show that the proposed method can improve the bit error rate of BCH codes compared to the existing methods.
SP:c860a7b0952d708e7851c9bc4b63d246f64d1cba,"This paper proposes to perform an unsupervised classification task prior to fine-tuning BERT for a target text classification task. Specifically, as such an intermediate task, the authors perform an additional clustering, training BERT on predicting the cluster labels. The authors test this hypothesis on various data sets, and show that this additional classification step can significantly reduce the demand for labeled examples mainly for topical classification tasks."
SP:ea37f5882fd98dd4ce233077bb3069517d4ed4ea,"This paper studies the problem of micro-data model-based reinforcement learning (MBRL) in the context of a random shooting environment. The authors compare a variety of generative models on the Acrobot environment, including a mixture density model, a deterministic model, and a probabilistic model. They find that the mixture density models outperform the deterministic models by a large margin. They also find that heteroscedasticity at training time, perhaps acting as a regularizer, improves predictions at longer horizons. The paper also proposes metrics and an experimental protocol to evaluate the various models."
SP:4e25ba3714d78ba59a0d8efbb65e0ef5201702f8,"This paper proposes an affine disentangled GAN that can explicitly disentangle affine transformations in a self-supervised and rigorous manner. The affine regularizer is derived by decomposing the affine matrix into separate transformation matrices and inferring the transformation parameters by maximum likelihood estimation. The features learned by ADIS-GAN are axis-aligned and scalable, where transformations such as rotation, horizontal and vertical zoom, and skew can be explicitly selected and learned. Experiments are conducted on MNIST, CelebA, and dSprites."
SP:121f8420cfb49c6d80b5ebb4051e85947182594a,"This paper proposes a method for instance discrimination-based contrastive learning based on representation learning. The main idea is to minimize the distribution divergence between the weakly and strongly augmented images over the representation bank to supervise the retrieval of strongly augmented queries from a pool of candidates. The proposed method achieves top-1 accuracy of 76.2% on ImageNet with a standard ResNet-50 architecture with a single-layer classifier fine-tuned. Moreover, the proposed method outperforms the previous self-supervised and supervised methods on both the transfer learning and object detection tasks."
SP:af54e542223097c315ecd677d0b968e9a0b2a1d4,"This paper proposes a method for de-identifying the face of a patient using MRI scans. The proposed method is based on a conditional GAN architecture that takes a patient’s MRI scan as input and generates a 3D volume in which the brain is not modified but the face has been de-identified. Compared to the classical removal-based techniques, the proposed method preserves privacy more reliably without adversely affecting downstream medical analyses on the brain, including segmentation and age prediction."
SP:0ac3964bd2320341488476d60f57b75d2a79f92c,"This paper proposes a multi-head attention based global pooling layer for hierarchical graph pooling. The proposed method is based on a multiset encoding problem with auxiliary information about the graph structure, and proposes a Graph Multiset Transformer (GMT) which captures the interaction between nodes according to their structural dependencies. The paper shows that GMT satisfies both injectiveness and permutation invariance, such that it is at most as powerful as the Weisfeiler-Lehman graph isomorphism test. The experimental results show that GMT significantly outperforms state-of-the-art graph pooler methods on graph classification benchmarks with high memory and time efficiency, and obtains even larger performance gain on graph reconstruction and generation tasks."
SP:76848e7ac3e6709e92f6a6db60269cb5177495d1,"This paper studies the problem of over-squashing in graph neural networks (GNNs) and proposes a new explanation for this problem. The paper argues that GNNs are susceptible to a bottleneck when aggregating messages across a long path. This bottleneck causes the over-Squashing of exponentially growing information into fixed-size vectors, which causes the GNN to fail to propagate messages originating from distant nodes and perform poorly when the prediction task depends on long-range interaction. In this paper, the authors demonstrate that the bottleneck hinders popular GNN models such as GCN, GGNN, GCN-GIN, and GGNN-GAT. The authors also show that prior work, which extensively tuned GNN model of long range problems, suffer from oversquashing, and that breaking the bottleneck improves their state-of-the-art results without any tuning or additional weights."
SP:90d8fa381446923902e42b259392e5e975e6caa1,"This paper proposes a new method for cross-domain sentiment analysis based on prototypical distribution. The method is based on the idea of prototypical embedding space, which is trained to be domain-agnostic by matching the data distributions across the domains. The authors show that the proposed method can reduce the effect of “domain shift” on the performance of a trained classifier in the target domain. Theoretical and empirical analysis are provided to demonstrate that the method is effective."
SP:893fd7440b82f5da0d4c0944928810322eaee2f0,"This paper proposes an evaluation methodology to measure the gender bias in NLI models. The authors propose a challenge task to evaluate the presence of gender stereotypes using occupations. They evaluate three models (BERT, RoBERTa, BART) trained on MNLI and SNLI data-sets and show that three models are significantly prone to gender induced prediction errors. They also find that debiasing techniques such as augmenting the training dataset to ensure a gender-balanced dataset can help reduce such bias in certain cases."
SP:a32ab755bd249c393b70938036ce8e810c0c439f,"This paper studies variational intrinsic control (VIC), an unsupervised reinforcement learning method for finding the largest set of intrinsic options available to an agent. The authors show that the intrinsic reward used in the original work by Gregor et al. (2016) is subject to bias in stochastic environments, causing convergence to suboptimal solutions. To correct this behavior and achieve the maximal empowerment, the authors propose two methods based on the transitional probability model and Gaussian mixture model. The experimental results demonstrate the effectiveness of the proposed methods."
SP:b4df2c4627a6d46c5100133e38c4bea20b296dd8,"This paper studies the problem of image classification in the low-data regime with few labeled examples per class. The authors propose to use an ensemble of relatively small deep neural networks to improve sample efficiency. The proposed method is based on the idea of neural ensembling, which is a simple yet effective technique that outperforms current state-of-the-art approaches for learning from small datasets. The experimental results show that the proposed method can outperform current state of the art approaches. "
SP:4a0ee01f4897efa81659f37ef0468ee8195bbc4f,"This paper proposes Sparse Binary Neural Networks (SBNN), a novel method for reducing the number of operations in quantized neural networks (BNNs) by using positive 0/1 binary weights instead of the -1/1 weights used in state-of-the-art BNNs. The authors claim that the proposed SBNN is able to achieve a high compression factor and reduce the operations and parameters at inference time. The proposed method is evaluated on both linear and convolutional networks over MNIST and CIFAR-10 datasets. The experiments confirm that SBNNs can achieve high compression rates and good generalization, while further reducing the operations of BNN."
SP:5be8539ad02595ad3c7a2d7afe8cbb3e9924467d,"This paper proposes a post hoc calibration method for predicting predictive uncertainty for deep learning models on corrupted data. The proposed method is based on the Brier score, which is a measure of uncertainty that measures the difference between the predicted error rate and the actual error rate of the model. The authors propose to use this measure as a surrogate for the class membership probabilities of the classifier. The method is evaluated on corrupted MNIST, CIFAR-10, and MNIST-100 datasets."
SP:ea503f67e38fce7dee9cc4996b55b8959911f030,"This paper studies the expressive power of graph neural networks and graph kernels from an empirical perspective. Specifically, the authors compare the graph representations and similarities produced by these algorithms against those generated by a wellaccepted, but intractable graph similarity function. The authors also investigate the impact of node attributes on the performance of the different models and kernels. The results reveal interesting findings."
SP:0cf7b7d929f50e0b7f4fda5e1f68e5ade2f7c29b,"This paper proposes a data augmentation method for self-supervised image animation. The proposed method, named PriorityCut, is based on the idea of using top-k percent occlusion masks to regularize the inpainting of the source image and the driving video. The authors claim that the proposed method is more effective than CutMix, which is an existing method that inpaints the inpainted regions of the driving image to improve the quality of the original source image. The main contribution of this paper is to propose a method that takes into account the difficulty of the hard-to-inpainting regions. "
SP:60b535fc6cbc1a7a26ad53f706ebb17de346dc4f,"This paper proposes a method for learning disentangled representations of independent causal mechanisms (ICM) by learning a model that disentangles each mechanism and approximates the groundtruth mechanisms from observational data. The authors provide sufficient conditions under which the mechanisms can be learned using a single self-supervised generative model with an unconventional mixture prior, simplifying previous methods. Moreover, they prove the identifiability of their model w.r.t. the mechanisms in the self supervised scenario. They compare their approach to disentangling representations on various downstream tasks, showing that their approach is more robust to intervention, covariant shift, and noise due to the disentanglement between the data generation processes."
SP:44d4e24428d043a69b40013919cda0e8e7bff99c,This paper proposes a self-labeling approach for predicting molecular graph structures from 2D images of a chemical compound. The authors propose a graph aligning approach that generates rich or detailed labels given normal labels W in the target domain. The proposed method is evaluated on the Maybridge dataset and compared to the state-of-the-art on the original source domain. 
SP:ad906dd9a176cffd283593321ff6b9ad19595528,This paper proposes a method to train a neural network to estimate the energy consumption of a chiller plant. The method is based on the observation that the input to the neural network is monotonic and the output of the network can be viewed as an input-output monotonicity problem. The authors propose to train the network on the input of the chiller system and then train the model on the outputs of the model. The proposed method is evaluated on a cooling system of a data center and compared to the existing methods.
SP:6cb65ee5d2926858570601eeeade24fe86c7f32f,"This paper proposes a new method for multi-horizon, multi-task and multi-target forecasting based on causal attention. The authors propose to use the Conditional Average Treatment Effect (CATE) estimation method in causal inference. They also propose a novel and fast multi-head attention evolved from Taylor’s expansion instead of softmax, reducing the time complexity from O(V) to $O(V), where V is the number of nodes in a graph. They conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various model components, and the time efficiency of their CausalTrans framework."
SP:223980a1954d626d90ff54d8dc61b5d85a6b349c,"This paper proposes an unsupervised method for jointly identifying a mixture of discrete and continuous factors of variability that can help unravel complex phenomena. The proposed method is based on a multi-agent VAE framework that utilizes multiple interacting autoencoding agents. The individual agents operate on augmented copies of training samples to learn mixture representations, while being encouraged to reach consensus on the categorical assignments. The authors provide theoretical justification to motivate the use of a multi agent framework, and formulate it as a variational inference problem. The experimental results on MNIST and dSprites show that the proposed method achieves state-of-the-art categorical assignment while preserving interpretability of continuous factors."
SP:c982610ad28662c3bd13132abe1f7307d1a61b68,"This paper provides a general characterization of steerable kernel spaces for group equivariant convolutional neural networks (GCNNs). The paper is motivated by the analogy between the constraints underlying steerable kernels on the one hand and spherical tensor operators from quantum mechanics on the other hand. In particular, the paper generalizes the famous Wigner-Eckart theorem for spherical tensors to the case of group-equivariant kernels. The paper also provides a characterization of generalized reduced matrix elements, ClebschGordan coefficients, and harmonic basis functions on homogeneous spaces."
SP:7b2ea39069277ad0f4f79476a77ef84587a804d9,"This paper studies the effect of selective classification on accuracy disparities between different groups in the presence of spurious correlations. The authors study the margin distribution, which captures the model’s confidences over all predictions, for symmetric margin distributions. They prove that selective classification monotonically improves or worsens accuracy is fully determined by the accuracy at full coverage (i.e., without any abstentions) and whether the distribution satisfies a property we call left-log-concavity. Motivated by their analysis, the authors train distributionally-robust models that achieve similar full-coverage accuracies across groups and show that they uniformly improve each group on these models."
SP:f1d57ee27e901daf7e4e2b84139019e945818911,"This paper proposes a hierarchical nonnegative CANDECOMP/PARAFAC (CP) decomposition (hierarchical NCPD) model and a training method, Neural NCPD, for performing hierarchical topic modeling on multi-modal tensor data. The proposed method utilizes a neural network architecture and backpropagation to mitigate error propagation through hierarchical NCPD. "
SP:b6ddc3a560aa7155e7e927bf5360bedc36586597,This paper proposes a new adversarial robustness certificate for graph neural networks (GNNs) that is based on the notion of collective robustness. The key idea is to fuse multiple single-node certificates into a stronger collective certificate that is guaranteed to remain stable under perturbation. The authors propose to use the locality property of GNNs to leverage their locality property. The proposed method is evaluated on the Citeseer dataset and shows that the proposed method can increase the number of certifiable feature perturbations from 7 to 351.
SP:cc93dd2f68e415e2457166e78627865dc1b44697,"This paper proposes Quantile Regression GAN (QRGAN), a novel method to improve the performance of GANs. The main idea is to use quantile regression to minimize the 1-Wasserstein distance between the real and generated data distribution. The authors also analyze the output space of discriminator and gradients of fake samples to see if the discriminator guides the generator well. QRGAN is shown to be more robust against mode collapse problem than LSGAN, WGAN, and WGAN."
SP:4ddb47ee77c374ae6c3e419412d92ca77260692e,"This paper investigates relevance metrics for explaining the predictions made by machine learning models. The authors evaluate relevance metrics on three different tasks: (1) comparing the cosine similarity of the gradients of the loss, (2) comparing cosine similarities of the gradient of the log-likelihood of the model, and (3) comparing similarity metrics of the classifier. They find that cosine-similarity of gradients is the best metric for explaining model predictions. They also find that some metrics perform poorly in their tests and analyze the reasons of their failure. "
SP:6c2cbf2bc0f6dabe974e80ec1e82d2d12189906e,"This paper proposes adding a low-rank global attention (LRGA) module to Graph Neural Networks (GNNs) for improving their generalization power. The authors show that adding the LRGA module to a specific family of expressive GNNs provides algorithmic alignment to a powerful graph isomorphism test, namely the 2-Folklore Weisfeiler-Lehman (2-FWL) algorithm. In more detail, the authors consider the recent Random Graph Neural Network (Sato et al., 2020) framework and prove that it is universal in probability; (ii) show that RGNN augmented with LRGA aligns with polynomial kernels; and (iii) bound the sample complexity of kernel’s feature map when learned with a randomly initialized two-layer MLP."
SP:b4abdd28504b4c1de239eabd4e0e27d370efee71,"This paper proposes an adaptive label smoothing method to improve the calibration performance of convolutional neural networks (CNNs) on ImageNet-1K. The proposed method is based on the idea of objectness, which is a measure of the relative size of an object in an image. The authors propose to compute a smoothing factor that is adaptive based on relative object size within an image, which allows the model to produce confidences that are grounded in the size of the object being classified instead of relying on context to make the correct predictions. Experiments are conducted on classification and transfer learning tasks to demonstrate the effectiveness of the proposed method."
SP:5254658923e594294b69d124a8d004166852822a,"This paper proposes a dual dual network for inverse image reconstruction. The dual network is a two-layer fully-convolutional ReLU denoising network that is amenable to convex optimization. In particular, the authors propose to train the dual network with weight decay regularization and piecewise linear filtering. Experiments on MNIST and fastMRI datasets confirm the efficacy of the proposed dual network."
SP:085cad6bc143c8713580bddfaa71f06496dac314,"This paper presents an end-to-end speech synthesis model that learns to synthesise speech from normalised text or phonemes. The authors propose a differentiable alignment scheme based on token length prediction and adversarial feedback to produce high fidelity audio. The proposed model achieves a mean opinion score exceeding 4 on a 5 point scale, which is comparable to state-of-the-art models relying on multi-stage training and additional supervision."
SP:01148cea55db606aa78d27e900818684a8bce9ab,This paper proposes a method for node representation learning for attributed graphs with missing attributes. The proposed method is based on a decomposition of the attribute matrix into discrete distributions in a lower-dimensional space equipped with the Wasserstein metric. The authors propose to smooth the distribution representations of nodes with information from their local neighborhoods. This allows them to reduce the distortion caused by missing attributes and obtain integrated representations expressing information of both topology structure and attributes.
SP:aeeb5909f7123ef631f569b469af9715205c881f,"This paper proposes a meta-learning method for goal-conditioned reinforcement learning (RL) in the absence of extrinsic rewards. In particular, the authors propose to use adversarial training as an intrinsic motivation for the teacher to generate a curriculum of self-proposed goals for the student policy. The teacher learns to propose increasingly challenging goals that allow the student to learn general skills for acting in a new environment, independent of the task to be solved. The authors show that their method generates a natural curriculum of goals that ultimately allows the agent to solve challenging procedurally-generated tasks where other intrinsic motivation and state-of-the-art RL methods fail."
SP:3d05bc7dca97681cb582298e318b9b973841eed3,"This paper studies the problem of information retrieval from a dataset of files stored on a single server under both a user distortion and a user privacy constraint. Specifically, a user requesting a file from the dataset should be able to reconstruct the requested file with a prescribed distortion, and in addition, the identity of requested file should be kept private from the server with a specified privacy level. The paper proposes a data-driven framework by leveraging recent advancements in generative adversarial models which allows a user to learn efficient schemes in terms of download rate from the data itself. The proposed model can be seen as an extension of the well-known concept of private information retrieval by allowing for distortion in the retrieval process and relaxing the perfect privacy requirement. In general, guaranteeing a certain privacy level leads to a higher rate-distortion tradeoff curve, and hence a sacrifice in either download rate or distortion."
SP:3f9e2db00fc3dcd7a40588adcb638503ec10dc09,"This paper proposes a decoupled greedy learning method for graph neural networks (GNNs) that decouples the GNN into smaller modules and associates each module with greedy auxiliary objectives. This allows GNN layers to be updated during the training process without waiting for feedback from successor layers, thus making parallel GNN training possible. The paper also proposes a lazy-update scheme during training to further improve its efficiency. Empirical results show that the proposed method achieves improved efficiency without significantly compromising model performances, which is important for time or memory limited applications."
SP:5ecb1b288f7fc02aead4493f81640867bc349290,"This paper proposes a method for answering complex queries on incomplete Knowledge Graphs. The proposed method is based on a pre-trained neural link predictor, which is trained to predict the truth value of each query atom. The method is evaluated on a variety of knowledge graph datasets, and the proposed method outperforms the state-of-the-art models trained on millions of generated queries. "
SP:f04a522fd04c503754fdb8c52da68646d31271a4,"This paper proposes a method for checking the local robustness of neural networks with piecewise-linear activation functions. The method is based on the observation that the decision boundaries within a set of convex polyhedral regions around a given input can be analyzed using simple geometric projections. The authors show that the proposed method can be implemented in parallel on the GPU. The proposed method is shown to be far more precise than approximate verification approaches, while at the same time performing multiple orders of magnitude faster than complete verifiers, and scaling to much deeper networks."
SP:5297651ff873f97c07b9c47ed3eff52251661844,"This paper proposes an approach for embedding objects in an affordance space, in which each dimension corresponds to an aspect of meaning shared by many actions, using text corpora. This embedding makes it possible to predict which verbs will be applicable to a given object, as captured in human judgments of affordance, better than a variety of alternative approaches. Furthermore, the dimensions learned are interpretable, and that they correspond to typical patterns of interaction with objects. The dimensions can be used to predict a state-of-the-art mental representation of objects, derived purely from human judgements of object similarity."
SP:72b4f3b40c6c6fa2eb53e95ed9a10a4077ffa049,"This paper proposes a method for the emergence of individuality (EOI) in multi-agent reinforcement learning (MARL) that learns a probabilistic classifier that predicts a probability distribution over agents given their observation and gives each agent an intrinsic reward of being correctly predicted by the classifier. The intrinsic reward encourages the agents to visit their own familiar observations, which makes the intrinsic reward signals stronger and in turn makes the agents more identifiable. Two regularizers are proposed to increase the discriminability of the classifiers. Empirical results show that EOI outperforms existing methods in a variety of MARL scenarios."
SP:112509d6d3573a9d495d182fdfae6ec0327cddf5,"This paper proposes a new method to improve the certified robustness of randomized smoothed classifiers. The proposed method, Smoothed WEighted Ensembling (SWEEN), is based on the ensembling generality of smoothed smoothing. Theoretical analysis shows that the optimal SWEEN model can be obtained from training under mild assumptions. The authors also develop an adaptive prediction algorithm to reduce the prediction and certification cost of the proposed model. Extensive experiments show that the proposed method outperforms the state-of-the-art candidate models by a large margin."
SP:ea892e3d199ed6121279b20061a87f43afae8796,This paper proposes a method to discover subtask hierarchy by learning from demonstration. The method is based on the inductive bias of learning from demonstrations. The proposed method is evaluated on two tasks: Craft and Dial. The experiments show that the proposed method can achieve higher task decomposition performance under both unsupervised and weakly supervised settings.
SP:cc6aa977ce561a2493ae74bb694205cd67c8d890,"This paper proposes a causal semantic generative model (CSG) for out-of-distribution (OOD) prediction. The proposed model is based on the causal invariance principle, with a novel design in variational Bayes for both efficient learning and easy prediction. In particular, the authors prove that under certain conditions, CSG can identify the semantic factor by fitting training data, and this semantic-identification guarantees the boundedness of OOD generalization error and the success of adaptation. Empirical study shows improved OOD performance over prevailing baselines."
SP:be3f34a59e5e61dcdbc7cb085f031ba4a5a5b758,"This paper studies the problem of online learning with adversarially corrupted rewards. In particular, the authors consider the case where the adversarial reward can be arbitrarily corrupted with probability $\mathcal{P}^2$. The authors propose to design algorithms with small regret over a period of time steps, while the algorithm observes corrupted rewards, and require its regret to be small with respect to the true uncorrupted reward distribution. They build upon recent advances in robust estimation for unsupervised learning problems to design robust online algorithms with near optimal regret in three different scenarios: stochastic multi-armed bandits, linear contextual bandits, and Markov Decision Processes (MDPs). They provide empirical evidence regarding the robustness of their proposed algorithms."
SP:6d62a80aaebb2988df3953d4d7164e5a2fa1aa6d,"This paper proposes Rewriter-Evaluator, a method for improving the performance of neural machine translation (NMT) models. It consists of a rewriter and an evaluator. At every pass, the rewriter produces a new translation to improve the past translation and the evaluators estimates the translation quality to decide whether to terminate the rewriting process. The authors also propose a prioritized gradient descent (PGD) method to train the evaluation and rewriter jointly. The experiments on two translation tasks, Chinese-English and English-German, show that the proposed framework significantly improves the performances of NMT models."
SP:9761fca8848868dfc9cacdab2537f8276ca76e0f,"This paper proposes a method for learning a calibrated adversarial model for semantic segmentation. The proposed method is based on a two-stage approach, where the first stage models the data with a categorical likelihood, and the second stage uses an adversarial network to sample from it an arbitrary number of coherent predictions. The model can be used independently or integrated into any black-box segmentation framework to facilitate learning of calibrated stochastic mappings. The authors demonstrate the utility and versatility of the approach on the multigrader LIDC dataset and a modified Cityscapes dataset."
SP:ce965758f1b795a56c02f45d6a8d06cb8bdf29cb,"This paper proposes a new method for dealing with contractive compressors. The main idea is to transform any contractive compressor into an induced unbiased compressor. Theoretical analysis and experimental results are provided to show that the proposed method is better than the existing compressed communication with error feedback (EF) method, which is the only known technique that can deal with the error induced by such compressors such as Top-K or PowerSGD. Experimental results are also provided for federated learning with partial participation."
SP:4fd702490293e481c79614852ba27dd3ce9215a4,"This paper proposes a new research framework for hyperparameter transfer across adjustments (HT-AA) to speed up the development of machine learning (ML) algorithms. The authors provide four simple baseline algorithms and eight benchmarks changing various aspects of ML algorithms, their hyperparameters search spaces, and the neural architectures used. The best baseline, on average and depending on the budgets for the old and new HPO, reaches a given performance 1.2-3.6x faster than a prominent HPO algorithm without transfer."
SP:e8f99bae5853de525450fcb8facd23cf973fc161,"This paper studies the effect of label representations on the performance of image classification models. The authors propose to use high dimensional, high entropy label representations, which they argue are more useful because they provide a stronger error signal. In particular, the authors propose constant matrices, spectrograms, shuffled spectrogram, Gaussian mixtures, and uniform random matrices of various dimensionalities. The experiments are conducted on the standard image classification task, where they show that high dimensional labels achieve comparable accuracy to text (categorical) labels, but features learned through our label representations exhibit more robustness under various adversarial attacks and better effectiveness with a limited amount of training data."
SP:4e8d924cba7367af0999b30d79250b4dc40413e1,"This paper proposes a method for ensemble neural networks (ENsembling) that uses a single model to train multiple subnetworks that independently learn the task at hand. The authors show that the benefits of using multiple predictions can be achieved ‘for free’ under the single model’s forward pass. In particular, they show that, using a multi-input multi-output (MIMO) configuration, one can utilize the capacity of a single network to train several subnetwork to improve model robustness without increasing compute. They observe a significant improvement in negative log-likelihood, accuracy, and calibration error compared to previous methods."
SP:d2f1c23b67c6744101034dc5e1c70765a733b169,"This paper proposes a method to transfer intermediate knowledge obtained from one Convolutional Neural Network (CNN) to another by utilizing sparse representation learning. The proposed method first extracts sparse representations of the hidden features of the teacher CNN, which are then used to generate both pixellevel and image-level labels for training intermediate feature maps of the student network. The authors formulate SRM as a neural processing block, which can be efficiently optimized using stochastic gradient descent and integrated into any CNN in a plug-and-play manner. The experiments demonstrate that SRM is robust to architectural differences between the teacher and student networks, and outperforms other KD techniques across several datasets."
SP:e8c0f43bd5debf6544f588cd3442dc3dd62d0eee,"This paper proposes a novel representation learning method for reinforcement learning that leverages the sequential structure in reinforcement learning to improve generalization. Specifically, the authors introduce a theoretically motivated policy similarity metric (PSM) for measuring behavioral similarity between states. The authors also present a contrastive representation learning procedure to embed any state similarity metric, which they instantiate with PSM to obtain policy similarity embeddings (PSEs1). The authors demonstrate that PSEs can improve the generalization on diverse benchmarks, including LQR with spurious correlations, a jumping task from pixels, and Distracting DM Control Suite."
SP:92f3b4942da9075440dda618f561a85f8fde5a5c,"This paper studies the problem of disentangling affine transformations in deep neural networks. The authors show that disentanglement can lead to discontinuities in the encoder for a broad family of transformations such as rotations and translations. To address this problem, the authors propose an alternative, more flexible approach to disentangle these transformations which relies on distributed equivariant operators, potentially acting on the entire latent space. Theoretical and empirical results are provided to demonstrate the effectiveness of the proposed disentangled affine transformation."
SP:ef0f58c462bc5dd1c7b78f562c42a4e17f0f252b,"This paper proposes a method to estimate the temporal dynamics of neural spike trains using the Hawkes process. The method is based on the Pólya-Gamma variables, latent marked Poisson processes, and sparsity variables, which are augmented to make functional connection weights in a Gaussian form, which allows for a simple iterative algorithm with analytical updates. The authors demonstrate the accuracy and efficiency performance of their algorithm on synthetic and real data. In the experiments, the authors show that their algorithm can estimate temporal dynamics and reveal the interpretable functional connectivity underlying neural spike train."
SP:1156d3deac022829bda930ffcb081947609d972b,"This paper studies the gradient descent (GD) algorithm for training two-layer neural network models. It shows that there are two phases in the dynamics in the under-parameterized regime: an early phase in which the GD dynamics follows closely that of the corresponding random feature model, followed by a late phase where the neurons are divided into two groups: a group of a few (maybe none) “activated” neurons that dominate the dynamics and another group of quenched neurons that support the continued activation and deactivation process. In particular, when the target function can be accurately approximated by a relatively small number of neurons, this quenching-activation process biases GD to picking sparse solutions. This neural network-like behavior is continued into the mildly over-parametrized regime, in which it undergoes a transition to a random featurelike behavior where the inner-layer parameters are effectively frozen during the training process. This seems to provide a clear mechanism for ""implicit regularization"""
SP:9e81401a6f30c70d870a12cce0cf600557f92b80,"This paper proposes a method to solve constrained Markov decision process (CMDP) problems by decomposing the CMDPs into a pair of MDPs; reconnaissance MDP and planning MDP. In R-MDP, the authors train threat function, the Q-function analogue of danger that can determine whether a given state-action pair is safe or not. In P-PDP, they train a reward-seeking policy while using a fixed threat function to determine the safeness of each action. With the help of generative model, they can efficiently train the threat function by preferentially sampling rare dangerous events. In addition, they also present an efficient approximation method for threat function that can greatly reduce the difficulty of solving R-RDP."
SP:f1d4ac7d5516dd0df742e224c8c09c721d0d0886,"This paper argues that the cross-entropy loss is not as good as the square loss for classification tasks. The authors argue that there is little compelling evidence indicating a clear-cut advantage to the cross entropy loss. They argue that the performance on nearly all non-vision tasks can be improved, sometimes significantly, by switching to square loss. Furthermore, training with square loss appears to be less sensitive to the randomness in initialization. "
SP:915f1f0fc4850507c28c1d609239b41775863ebe,"This paper proposes a method for self-supervised reinforcement learning in the context of Atari games. The method is based on the idea of self-predictive representations (SPR), which is an exponential moving average of the agent’s parameters and a learned transition model for future state prediction. The authors also propose to add data augmentation to the future prediction loss, which forces the representations to be consistent across multiple views of an observation. The proposed method achieves a median human-normalized score of 0.415 on Atari in a setting limited to 100k steps of environment interaction, which represents a 55% relative improvement over the state-of-the-art."
SP:983f01c170909c8c67fd3be25f121bd61bdd8307,"This paper proposes InstantEmbedding, an unsupervised representation learning method for graph embeddings. The main idea is to use local PageRank computation to compute the embedding vector for each node in a given graph. The paper theoretically proves that the proposed method can produce representations that are globally consistent in sublinear time. Empirical results on real-world datasets with over a billion edges demonstrate the effectiveness of the proposed algorithm."
SP:d11037b8fe2b10aee672ba82f69410b40181f0f9,"This paper proposes an unsupervised method for graph coarsening based on graph neural networks (GNNs) to improve the quality of the coarsened graph. The authors propose a framework for measuring the quality and show that depending on the goal, we need to carefully choose the Laplace operator on the coarse graph and associated projection/lift operators. The paper also proposes to parametrize the edge weight assignment map with GNNs and train it to improve coarsens quality. The experiments on both synthetic and real networks demonstrate that the proposed method significantly improves the quality compared to existing methods. The proposed method generalizes to graphs of larger size (25× of training graphs) and is adaptive to different losses (differentiable and non-differentiable)."
SP:0d680213339f0e2aedb0be4aeed51423706b8bf6,"This paper proposes a method to estimate the acoustic properties of 3D objects based on discrete-laplacian and implicit encoders. The authors use a point cloud approximation of each object, and each point is encoded in a high-dimensional latent space. The proposed method can accurately estimate these acoustic properties for arbitrary topologies and takes less than 1ms per object on a NVIDIA GeForce RTX 2080 Ti GPU. The learning method is permutation and rotation invariant and demonstrate high accuracy on objects that are quite different from the training data."
SP:afc33a782c43e3d4c5c4fbf047d0b1108bc30bae,"This paper proposes Risk Extrapolation (REx) as a form of robust optimization over a perturbation set of extrapolated domains (MMREx), and propose a penalty on the variance of training risks (V-REx). The authors prove that variants of REx can recover the causal mechanisms of the targets, while also providing some robustness to changes in the input distribution (“covariate shift”). The proposed method is able to outperform Invariant Risk Minimization in situations where these types of shift co-occur."
SP:411d5bcf7698d534ad60f581d479ff74849ba4de,"This paper proposes a neural operator for solving partial differential equations (PDEs) in Fourier space. The proposed method is based on the Fourier neural operator (Fourier operator) which learns the mapping from any functional parametric dependence to the solution of the PDE. The authors propose to parameterize the integral kernel of the integral of the solution as a Fourier operator, which allows for an expressive and efficient architecture. Experiments on Burgers’ equation, Darcy flow, and Navier-Stokes equation demonstrate the effectiveness of the proposed method. It is up to three orders of magnitude faster compared to traditional PDE solvers."
SP:41d268d0eac9b4c84baa156fb641aa6d3060b5a4,"This paper studies the implicit bias of gradient flow on linear neural network training. The authors propose a tensor formulation of neural networks that includes fully-connected, diagonal, and convolutional networks as special cases, and investigate the linear version of the formulation called linear tensor networks. With this formulation, the convergence direction of the network parameters can be characterized as singular vectors of the tensor defined by the network. For separable classification, the authors show that gradient flow finds a stationary point of the `2/L max-margin problem in a “transformed” input space. For underdetermined regression, they prove a global minimum which minimizes a norm-like function that interpolates between weighted `1 and `2 norms in the transformed input space, and provide experiments that corroborate their analysis."
SP:e27907ef4a4e6e0f5841618fcaa7e7e0db443f91,"This paper proposes a method for optimizing slimmable neural networks. The main idea is to optimize the width multipliers for different layers of the network. The authors propose to use a multi-objective optimization lens to optimize both the shared weights and the width-multipliers for the sub-networks. The proposed method is evaluated on 15 network and dataset combinations and two types of cost objectives, i.e., FLOPs and memory footprint, to demonstrate the effectiveness of the proposed method."
SP:cf59403abb6ca89ccee4f8e77e9a33d99e6a00f5,"This paper studies the problem of federated semi-supervised learning (FSSL) in the setting where the data obtained at the client-side often comes without any accompanying labels. The authors study two scenarios of FSSL based on the location of the labeled data. The first scenario considers a conventional case where clients have both labeled and unlabeled data (labels-at-client), and the second scenario considers the more challenging case, where the labelled data is only available at the server. They propose a novel method to tackle the problems, which they refer to as Federated Matching (FedMatch). FedMatch improves upon naive combinations of local federated learning and semi supervised learning approaches with a new inter-client consistency loss and decomposition of the parameters for disjoint learning. The experimental validation of FedMatch in the two different scenarios is extensive and the results show that FedMatch outperforms both local local semi supervised learning and baselines."
SP:9457b6d430a2cd864d526d7e90bf3e1ab13d6df4,"This paper proposes a self-supervised learning method for discrete event sequences. The method is based on contrastive learning, which is an extension of contrastive methods for audio and computer vision. The authors show that the proposed method can be applied to the discrete event sequence domain in a self supervised setting. The proposed method is evaluated on several public datasets and showed that it can outperform other methods on different downstream tasks."
SP:385942a5bcee7384bb722a1669b541f2fac0cd36,"This paper proposes a method for unsupervised parsing of natural language grammars. The main idea is to combine the dependency grammar and constituency grammar in the same model. The authors propose a new parsing framework that can jointly generate constituency tree and dependency graph, and integrate the induced dependency relations into transformer, in a differentiable manner, through a dependency-constrained self-attention mechanism. Experimental results show that the proposed method can achieve strong results on unsupervisory constituency parsing, unsuper supervised dependency parsing and masked language modeling at the same time."
SP:078966ff62775bba6031e47d374bda95f4a7dde3,This paper proposes a method for learning the mapping between scene graph nodes and visual objects under weak supervision. The proposed method learns a metric among visual objects and scene graph node by incorporating information from both object features and relational features. Extensive experiments on Visual Genome (VG) and Visual Relation Detection (VRD) datasets verify that the proposed method post an improvement on scene graph grounding task over current state-of-the-art approaches. Further experiments on scene graphs parsing task verify the grounding found by the proposed model.
SP:4644dbf7466b6234d8abf69995fdfb357efcc119,"This paper proposes two variants of sliced fused Gromov Wasserstein (SFG) to improve the performance of relational regularized autoencoder (RAE) framework. The first variant, called mixture spherical sliced fused gromov wasserstein, replaces the vMF distribution by a mixture of von Mises-Fisher distributions to capture multiple important areas of directions that are far from each other. The second variant, named power spherical sliced fg, is a power spherical distribution that improves the sampling time in high-dimensional settings. The experimental results on latent manifold structure, image generation, and reconstruction demonstrate the effectiveness of the proposed SSFG variants."
SP:5ae2c0af82cac89a65f1cc38c43e2d05ea298901,"This paper proposes an adaptive untying criterion to speed up training for deep networks with repeated structures, such as the transformer module. The authors first train such a deep network with the weights shared across all the repeated layers till some point, then stop weight sharing and continue training until convergence. The untying point is automatically determined by monitoring gradient statistics. Empirical results show that the proposed method is able to reduce the training time of BERT by 50%."
SP:a51710551142316b67e2fccd969fea1ece35ba39,"This paper studies the adversarial transferability and the interaction inside adversarial perturbations. The authors show that the transferability of adversarial attacks is negatively correlated with the interaction between adversarial and non-adversarial components of the perturbation. To this end, the authors propose to penalize interactions during the attacking process, which significantly improves the adversarially transferable attack."
SP:f1565319075c1442c2cb52d96443facb492c06c2,"This paper studies the problem of forgetting in deep neural networks (DNNs) in the context of task semantic similarity. The authors show that deeper layers of DNNs are disproportionately responsible for forgetting, with sequential training resulting in an erasure of earlier task representational subspaces. To mitigate this forgetting, the authors propose several methods to stabilize these deeper layers, but show diversity on precise effects, with some increasing feature reuse while others store task representations orthogonally, preventing interference. They also provide an analytic argument and empirical picture relating forgetting to task semantic similarities, where they find that maximal forgetting occurs for task sequences with intermediate similarity."
SP:30d7532cdcf420bff3be6b92eea3d93bce59e6bd,"This paper proposes a method for pre-training and fine-tuning BERT, which is inspired by the early-Bird Lottery Tickets (EBT) algorithm for computer vision tasks. The authors propose to reduce the self-attention and fully-connected sub-layers inside a transformer in BERT by using structured winning tickets in the early stage of BERT training. The proposed method is evaluated on GLUE and SQuAD downstream tasks and achieves comparable performance to standard BERT."
SP:c547f23ff6caaf5e9f35d258490b86ae0ac8ed03,"This paper studies the robustness of f-divergence measures in the context of label noise. The authors derive a new family of f divergence measures that are robust to label noise and show that they can be used as metrics for the problem of learning with noisy labels. In particular, the authors show that the proposed measure is a linear combination of the variational difference defined on the clean distribution and a bias term introduced due to the noise. In addition to the theoretical results, the paper also provides experimental results on MNIST and CIFAR-10."
SP:841888179dcdac901889c8d62cb5234311fe28f1,This paper proposes an ensemble-based weighted Bellman backup method for off-policy deep reinforcement learning. The authors propose to re-weight the target Q-values based on uncertainty estimates from a Q-ensemble. The proposed method is evaluated on both continuous and discrete control tasks on both low-dimensional and high-dimensional environments. The experiments show that the proposed method stabilizes and improves the performance of existing algorithms such as Soft Actor-Critic and Rainbow DQN.
SP:afc08f203562b841180811aef943bfb63a1659ea,"This paper proposes a meta-training method for few-shot classification. The authors propose to train a class-wise similarity measure between support and query sets in the meta-learning setting. The proposed method is algorithm-agnostic and can be easily extended to a range of meta learning models. The experiments show that the proposed method can help the model avoid being indiscriminately confident, and thereby produce calibrated classification results without the loss of accuracy."
SP:12ae325ea3bce1e60195afac7d85895d2d20c29c,"This paper proposes a method for video-text representation learning based on a generative model. The authors argue that noise contrastive learning (NCL) encourages dissimilar representations even for samples that are semantically related. To address this issue, the authors propose to use a weighted combination of other support samples’ visual representations. The proposed method is evaluated on MSR-VTT, VATEX, ActivityNet, and MSVD for video to text and text to video retrieval."
SP:8a71d8fad25a126aff01431cacf348c05de75667,"This paper proposes a novel method, seg tok, to form the vocabulary of Chinese BERT, with the help of Chinese word segmentation (CWS) and subword tokenization. The authors also propose three versions of multi-vocabulary pretraining (MVP) to improve the models expressiveness. Experiments show that seg-tok improves the performance of Chinese PLMs on sentence level tasks, and MVP improves the downstream performance on sequence labeling tasks."
SP:b93ec7bc02b48068073ffe705f71d2643e663d51,This paper proposes an unbiased boundary sampling strategy for distributed training of graph convolutional networks (GCN) in order to reduce the memory and communication cost of distributed GCN training while maintaining the full-graph accuracy. The proposed method is based on the idea of partitioning the graph into subgraphs and then sampling the boundary nodes of each subgraph based on an unbiased sampling strategy. The authors evaluate the proposed method on a variety of benchmark datasets and show that it can significantly reduce the communication cost and memory usage while keeping the same accuracy. 
SP:2d4ba873d11e969ebd1fc31f9b5ab450c964d154,"This paper presents a graph neural network (GNN) based model for quantum chemistry simulations. The model is based on graph neural networks (GANs) that use 3D molecular structure to estimate per-atom forces, which is a central capability for performing atomic simulations. In particular, the authors propose a message-passing architecture, expressive message passing architecture, non-linear activation functions, and model scaling in terms of network depth and width. The authors show that the proposed model reduces the estimation error of atomic forces by 30% compared to existing ML models, and generalizes well to out-of-distribution structures. The experiments are conducted on the large-scale catalyst dataset, OC20."
SP:8bdcf4fe6abf4739d4732b7ea8538513135dcccc,"This paper proposes a new generalization bound for neural networks based on Rademacher complexity for convolutional networks, which is based on the distance between the weights of the network and the original weights. The authors show that this bound has no direct dependence on the number of weights and compares favourably to other bounds when applied to CNNs. This bound is highly relevant for fine-tuning, because providing a network with a good initialisation based on transfer learning means that learning can modify the weights less, and hence achieve tighter generalization. Inspired by this, the authors develop a simple yet effective finetuning algorithm that constrains the hypothesis class to a small sphere centred on the initial pre-trained weights, thus obtaining provably better generalisation performance than conventional transfer learning. Empirical evaluation shows that their algorithm works well, corroborating their theoretical results."
SP:3a3249e97ef2345ea2264de5ed8287e16687838e,"This paper studies the phenomenon of ""decoupled find-eval phenomenon"" in unstructured magnitude pruning on vision classification tasks. The authors propose to decouple the hyperparameters for mask discovery (Hfind) and mask evaluation (Heval) and show that the decoupled Hfind values lead to models which have lower performance, but generate masks with substantially higher eventual performance compared to using the same hyperparameter for both stages. They show that this phenomenon holds across a number of models, datasets, configurations, and also for one-shot structured pruning. Finally, they demonstrate that different layerwise pruning ratios are causally mediated by these ratios."
SP:2d6f5d72b21675f74ff4cde4d16bfb36abd5795f,"This paper proposes a new metric, called m-coherence, to study the alignment of per-example gradients during training. The metric is based on gradient diversity, which is a quantity previously used in some theoretical bounds. The authors show that m-Coherence is more interpretable, cheaper to compute (O(m) instead of O(m)) and mathematically cleaner than gradient diversity. They also show that the most surprising result of the paper is that memorization is not as strong as expected when training with random labels."
SP:e7c5de9a475d0ba71bc79580e8436024fb2c6f59,"This paper considers the problem of how to automatically construct statistics for implicit generative models where the evaluation of the likelihood function is intractable but sampling data from the model is possible. The idea is to frame the task of constructing sufficient statistics as learning mutual information maximizing representations of the data with the help of deep neural networks. The infomax learning procedure does not need to estimate any density or density ratio. The authors apply their approach to both approximate approximate Bayesian computation and recent neural likelihood methods, boosting their performance on a range of tasks."
SP:c5997bf2348e94949684f45fbd418661e85220c1,This paper proposes a new unsupervised image-to-image translation model (TUNIT) that simultaneously learns to separate image domains and translate input images into the estimated domains. TUNIT is trained with a set-level supervised model trained with full labels. Experimental results show that the proposed model achieves comparable or better performance than the set level supervised model. The proposed model generalizes well on various datasets and is robust against the choice of hyperparameters.
SP:0cd97e64e638cabbeea0fdef3e9c5b33f4000f72,"This paper studies the implicit bias of gradient descent training of wide neural networks and the corresponding implicit bias in function space. The authors show that the solution of training a width-n shallow ReLU network is within n-1/2 of the function which fits the training data and whose difference from initialization has smallest 2-norm of the weighted second derivative with respect to the input. The curvature penalty function 1/ζ is expressed in terms of the probability distribution that is utilized to initialize the network parameters, and they compute it explicitly for various common initialization procedures such as asymmetric initialization with a uniform distribution and cubic spline interpolation. The result generalizes to multivariate regression and different activation functions and the training trajectories are captured by trajectories of spatially adaptive smoothing splines with decreasing regularization strength."
SP:8b885142facbb3b8db41ec9d83822cee81324694,This paper studies the problem of weight decay in deep neural networks. The authors argue that the L2 regularization and decoupled weight decay are not identical to weight decay for adaptive gradient methods such as Adaptive Momentum Estimation (Adam) and proposed Adam with Decoupled Weight Decay (AdamW). They further propose the stable weight decay (SWD) method to fix the unstable weight decay problem from a dynamical perspective. The proposed SWD method makes significant improvements over L2-regularization and AdamW in the experiments.
SP:a3206dc71e32ba1830895bf442d3840f3331a532,This paper proposes a novel method to combine the strengths of both Translation Memory (TM) and Neural Machine Translation (NMT). The authors treat the matched sentence pair of TM as the additional signal and apply one encoder enhanced by the pre-trained language model (PLM) to encode the TM information and source sentence together. The authors extend the sentence level retrieval method to the n-gram retrieval method and explore new methods to manipulate the information flow from TM to the NMT decoder. The experimental results demonstrate that the proposed methods can significantly improve the translation quality and show strong adaptation for an unknown or new domain.
SP:72b43991a242872b2ceb1861e8ffbdf26c9f4818,"This paper presents a theoretical analysis of convolutional neural networks based on rate reduction and shift-invariant classification. In particular, the authors show that the basic iterative gradient ascent scheme for maximizing the rate reduction of learned features naturally leads to a deep network, one iteration per layer, and that the architectures, operators (linear or nonlinear), and parameters of the network are all explicitly constructed layer-by-layer in a forward propagation fashion. The authors also show that such a network can already learn a good discriminative deep representation without any back propagation training. Moreover, all linear operators of the so-derived network naturally become multi-channel convolutions when we enforce classification to be rigorously shift invariant. Finally, the derivation also indicates that the derived network is significantly more efficient to learn in the spectral domain."
SP:f8b02cf1b918b0956761829ec6ef9127596071ec,"This paper studies the implicit acceleration of gradient flow in over-parameterized two-layer linear models. The authors show that implicit acceleration emerges from a conservation law that constrains the dynamics to follow certain trajectories. More precisely, gradient flow preserves the difference of the Gramian matrices of the input and output weights and the amount of acceleration depends on both the magnitude of that difference (which is fixed at initialization) and the spectrum of the data. In addition, and generalizing prior work, the authors prove their results without assuming small, balanced or spectral initialization for the weights."
SP:e5f086c806be88d50e461a782b5b00124f4656fb,"This paper proposes a new approach to explainable AI, CLIME, which is based on uniform sampling of user-defined subspaces of the input domain. The authors argue that LIME’s explanations can be unstable and are susceptible to adversarial attacks as a result of out-of-distribution (OOD) sampling. To resolve this issue, the authors propose a theoretically sound framework based on logical constraints, which allows the end-user the flexibility to delineate the precise subspace to be explained. For testing the quality of generated explanations, they develop an efficient estimation algorithm that is able to certifiably measure the true value of metrics such as fidelity up to any desired degree of accuracy, which can help build trust in the generated explanations."
SP:b1d5ef15772e192eb8c8a0e65b3c21ee7c794295,"This paper proposes a novel pre-trained language model, AMBERT (A Multi-grained BERT), which takes both the sequence of words (finegrained tokens) and sequence of phrases as input after tokenization, and employs one encoder for processing the sequences of words and the other encoder (coarse) for processing phrases. The authors propose a sequence of contextualized representations of the words and contextualized representation of the phrases. Experiments have been conducted on benchmark datasets for Chinese and English, including CLUE, GLUE, SQuAD and RACE, and the results show that the proposed model outperforms the existing best performing models in almost all cases."
SP:fd1cfe80343d3789227d99d836a5674374a234f5," Transformer is a Transformer-based model that can be used for semantic parsing. This paper proposes a new Transformer architecture that is capable of learning the phrase dependencies in the sentence. The main idea is to incorporate Long Short-Term Memory (LSTM) into the Self-Attention mechanism of the original Transformer to capture more local context of phrases. Experimental results show that the proposed model captures the detailed meaning better than Transformer, raises local context awareness and achieves strong competitive performance on Geo, MSParS datasets and leads to SOTA performance on Atis dataset in methods using Neural Network."
SP:2056a65a7500d79465685af883083cd706277c1f,"This paper proposes a method for improving the robustness of deep neural networks (DNNs) against adversarial perturbations. Specifically, the authors propose a new adversarial training method, CAT, which combines and optimizes multiple adversarial losses to improve robustness to individual perturbation as well as their compositions. The proposed method is evaluated on a variety of datasets and models, and it is shown to outperform existing adversarial defense methods by large margins."
SP:006e5b9ac9a8eb7223843731488bfefbd8eb09bd,"This paper proposes a method for learning abstract rules from high-dimensional data. The method is based on a recurrent network augmented with an external memory that enables a form of variable-binding and indirection. This binding mechanism allows symbol-like representations to emerge through the learning process without the need to explicitly incorporate symbol-processing machinery, enabling the ESBN to learn rules in a manner that is abstracted away from the particular entities to which those rules apply. The authors show that this architecture displays nearly perfect generalization of learned rules to novel entities given only a limited number of training examples."
SP:4171ce45966ac499f51450a19fb233934c0847f0,"This paper proposes a new framework, Translation between Augmented Natural Language (TANL), to solve many structured prediction language tasks including joint entity and relation extraction, nested named entity recognition, relation classification, semantic role labeling, event extraction, coreference resolution, and dialogue state tracking. Instead of tackling the problem by training task-specific discriminative classifiers, the authors frame it as a translation task between augmented natural languages, from which the task-relevant information can be easily extracted. The proposed TANL can match or outperform task specific models on all tasks, and in particular, achieves new state-of-the-art results on joint entity extraction (CoNLL04, ADE, NYT, and ACE2005 datasets), relation classification (FewRel and TACRED), and semantic roles labeling (Co-NLL-2005 and CoNLL2012)."
SP:8f1b2fc6829e0bdfcc981020b0dcf3e63a947910,"This paper studies the problem of unlabeled entity recognition in NER models. The authors propose a general approach to address this problem, which can almost eliminate the misguidance brought by unlabelled entities. The key idea is to use negative sampling that, to a large extent, avoids training NER model with unlabeling entities. Experiments on synthetic datasets and real-world datasets show that the proposed model is robust to unlabelED entity problem and surpasses prior baselines."
SP:dd76ece8d92a8a230a8b43033d8cb2368c677a94,"This paper proposes a novel acoustic word embedding called Acoustic Neighbor Embeddings where speech or text of arbitrary length are mapped to a vector space of fixed, reduced dimensions by adapting stochastic neighbor embedding (SNE) to sequential inputs. The Euclidean distance between coordinates in the embedding space reflects the phonetic confusability between their corresponding sequences. Two encoder neural networks are trained: an acoustic encoder that accepts speech signals in the form of frame-wise subword posterior probabilities obtained from an acoustic model and a text encoder network that accepts text in the forms of subword transcriptions. Compared to a triplet loss criterion, the proposed method is shown to have more effective gradients for neural network training. Experimentally, it gives more accurate results with low-dimensional embeddings when the two encoder networks are used in tandem in a word (name) recognition task, and standalone in an approximate phonetic matching task."
SP:9142189126b8612ac0acee6fe18a0cfcb70b6545,"This paper proposes a reinforcement learning algorithm for stationary mean-field games, where the goal is to learn a pair of state and stationary policy that constitutes the Nash equilibrium. The authors propose a fictitious play algorithm that alternatively updates the mean field state and the policy via gradient descent and proximal policy optimization, respectively. The algorithm is in stark contrast with previous literature which solves each single-agent reinforcement learning problem induced by the iterates mean- field states to the optimum. Furthermore, the authors prove that their algorithm converges at a sublinear rate."
SP:c498f8a199da1818fe64ed88b0825c5aad688aec,"This paper studies the problem of probabilistic inference on the joint distribution defined by a normalizing flow model. Given a pre-trained flow model p(x), we wish to estimate p( x2 | x1) for some arbitrary partitioning of the variables x = (x1,x2). This task is computationally hard for a large class of flow models. Motivated by this hardness result, this paper proposes a framework for approximate probablistic inference. Specifically, it trains a new generative model with the property that its composition with the given model approximates the target conditional distribution. By parametrizing this new distribution as another flow model, it can efficiently train it using variational inference and handle conditioning under arbitrary differentiable transformations. Since the resulting approximate posterior remains a flow, it offers exact likelihood evaluation, inversion, and efficient sampling. Empirical evidence demonstrates the flexibility of the proposed method on a variety of inference tasks with applications to inverse problems."
SP:1d0f27f61c9d32911b8bd15d6b82ef5eec644f0f,"This paper proposes a new evaluation criteria for cell membrane segmentation based on perception distance. The paper presents a new dataset called U-RISC, which is the largest annotated Electron Microscopy (EM) dataset for the Cell membrane with multiple iterative annotations and uncompressed high-resolution raw data. The authors also propose a new criterion called Perceptual Hausdorff Distance (PHD) to measure the quality of the cell segmentation results. Experiments are conducted to show that PHD is consistent with human perception."
SP:8ca7aff87c82be69c9542550c814f52c9419ab0a,This paper proposes a modular architecture for continual learning (CL) and a learning algorithm for long-term learning. The authors propose a new suite of benchmarks to evaluate the effectiveness of the proposed method. The proposed method is based on the modular architecture and a task-driven prior over the exponential search space of all possible ways to combine modules. The experiments show that the proposed algorithm can outperform the state-of-the-art on several benchmarks. 
SP:cc819c61f408e88f247eb87946187ccec3dad32e,"This paper proposes a method for generating synthetic meta-tasks for unsupervised meta-learning using generative models. The authors propose a generative model that generates pairs of in-class and out-of-class samples from the latent space in a principled way, allowing them to create synthetic classes forming the training and validation data of a meta-task. The proposed method, LASIUM, is evaluated on few-shot classification tasks on the most widely used benchmark datasets."
SP:b25771e5c214a352f74ba6196fbd88bca6c43c98,"This paper studies the injectivity of fully connected and convolutional ReLU layers and networks. The authors show that an expansivity factor of two is necessary and sufficient for injectivity by constructing appropriate weight matrices. They show that global injectivity with iid Gaussian matrices, a commonly used tractable model, requires larger expansivity between 3.4 and 10.5. They also characterize the stability of inverting an injective network via worst-case Lipschitz constants of the inverse. "
SP:a95a153d3fe9bcf535ebf8514f51d00df483f210,"This paper proposes a continuous conditional generative adversarial network (CcGAN) for image generation conditional on continuous, scalar conditions (termed regression labels). The authors propose to reformulate existing empirical cGAN losses to be appropriate for the continuous scenario, and propose a novel method to incorporate regression labels into the generator and the discriminator. The proposed CcGAN is able to generate diverse, high-quality samples from the image distribution conditional on a given regression label. The experiments on the Circular 2-D Gaussians, RC-49, and UTKFace datasets show that the proposed model substantially outperforms cGAN."
SP:10dd09ab315870631d1451d200f2c87a023f8226,"This paper proposes an active learning (AL) algorithm for semi-supervised learning (SSL) that aims to reduce the sample complexity of deep learning by querying unlabeled instances to be annotated by a human-in-the-loop. The authors argue that the annotation efficiency brought by AL algorithms that seek diversity on labeled samples can be improved upon when using SSL as the training scheme. They propose an AL algorithm that instead focuses on controlling the convergence rate of a classification network by actively querying instances to improve the rate of convergence upon inclusion to the labeled set. They name this AL scheme convergence rate control (CRC), and their experiments show that a combination of AL and SSL can quickly achieve high performance using far less labeled samples than SL."
SP:7f3947c3fa5b09674507d8f3e10d9280376ecb94,This paper proposes a federated learning method for distributed training of neural network models. The authors propose a dynamic regularizer for each device at each round of training to ensure that the global and device solutions are aligned. The proposed method is evaluated on both convex and non-convex data and compared with a variety of existing methods. The results show that the proposed method can achieve better performance than the existing methods on both real and synthetic data.
SP:a3fbb073b0e2371b20d5d9df6ab829673f90354f,"This paper proposes a new algorithm for self-supervised representation learning based on contrastive learning. The main idea is to truncate the back-propagation and update only a part of the parameters for each gradient descent update. The authors also propose to use the intermediate contrastive losses to filter easy regions for each image, which further reduces the computational cost. The proposed algorithm is evaluated on ImageNet linear classification and other downstream tasks."
SP:5b5e705ea1ee1b857e17e64d560a39052804949d,"This paper studies the global convergence and global optimality of actor-critic, one of the most popular families of reinforcement learning algorithms. The authors focus on the more practical single-timescale setting, where the actor and critic are updated simultaneously. Specifically, in each iteration, the critic update is obtained by applying the Bellman evaluation operator only once while the actor is updated in the policy gradient direction computed using the critic. Moreover, the authors consider two function approximation settings: linear or deep neural networks. For both cases, they prove that the actor sequence converges to a globally optimal policy at a sublinear O(K−1/2) rate, where K is the number of iterations."
SP:26705a4dc305cce336f657c5937d1f5b4209548a,"This paper proposes to represent log files at three levels of abstraction: field level, log level, and log sequence level. The representation for each level can be computed from the previous level. These representations are in vector format and serve as interfaces to downstream applications. The authors use a version of Transformer Networks (TNs) to encode numerical and textual information that is suitable for log embeddings. They show how a number of log processing applications can be solved with their representation."
SP:165c51a16f17fb8726e968f8b34742b62011d60e,"This paper presents a theoretical analysis of wavelet decompositions of convolutional layers in deep neural networks (CNNs). The main idea is to decompose the convolution layers into a sequence of wavelets, which are modulated by a mixture of mixture weights. The authors show that the wavelets can be decomposed into 2D dual-tree wavelets and 2D wavelets. They evaluate the proposed wavelets on the AlexNet architecture for image classification, and show that they can achieve the accuracy rate of standard AlexNet with a significantly lower number of parameters."
SP:d0a284da462584724ba6a3a48c9e986d391233f6,"This paper proposes a coach-player framework to tackle the problem of coordination in multi-agent teams, where agents with different capabilities may join or leave “on the fly” without altering the team’s overarching goals. Inspired by real-world team sports, the authors assume that the players only have a partial view of the environment, while the coach has a complete view. Specifically, they propose an attention mechanism for both the players and the coach; 2) incorporate a variational objective to regularize learning; and 3) design an adaptive communication method to let the coach decide when to communicate with different players. They validate their methods on resource collection tasks in the Multi-agent particle environment, and demonstrate zero-shot generalization to new team compositions with varying numbers of heterogeneous agents."
SP:4eb662b527d556758aaa1a0b589495fcc337fad0,"This paper studies the influence function of neural networks in the context of deep learning with non-convex loss functions. In particular, the authors study the effect of network architecture, depth and width, as well as the extent of model parameterization and regularization techniques have strong effects on the accuracy of influence functions. They find that influence estimates are fairly accurate for shallow networks, while for deeper networks the estimates are often erroneous. The authors also show that for certain network architectures and datasets, training with weight-decay regularization is important to get high-quality influence estimates."
SP:5fea74a2031d097a99dacf613bedcb054b0c3831,"This paper studies the connection between the pretraining task of next word prediction and text classification tasks. The authors propose to reformulate the classification tasks of interest as sentence completion tasks, and show that language models that are optimal in cross-entropy (log-perplexity) learn features that can linearly solve such classification tasks with O(sqrt(\sqrt{O}) error, thus demonstrating that doing well on language modeling can be beneficial for downstream tasks. They experimentally verify various assumptions and theoretical findings, and also use insights from the analysis to design a new objective function that performs well on some classification tasks, which can be used to design new language models."
SP:a67da438e9821010284416170c3699ae7ff96c99,"This paper proposes a new algorithm for membership inference attacks (MIA) that is based on the reconstruction error of an image generation model. The reconstruction error is used to detect if data samples were used to train a neural network model. However, the authors observe that reconstruction error alone is less effective at discriminating between difficult images used in training and easy images that were never seen before. To overcome this, they propose to use a novel difficulty score that can be computed for each image, and its computation does not require a training set. The proposed algorithm is shown to achieve high MIA accuracy on an extensive number of benchmarks."
SP:6fe23ebe09f2a4e42a21598f8e9c79edeca99863,"This paper proposes a differentiable architecture search method by formulating it into a distribution learning problem. The authors treat the continuously relaxed architecture mixing weight as random variables, modeled by Dirichlet distribution. This formulation improves the generalization ability and induces stochasticity that naturally encourages exploration in the search space. To alleviate the large memory consumption of differentiable NAS, the authors propose a simple yet effective progressive learning scheme that enables searching directly on large-scale tasks, eliminating the gap between search and evaluation phases. Extensive experiments demonstrate the effectiveness of the proposed method."
SP:c590d0ed2487b42480b53fc077546a4a0bc27a78,"This paper proposes a new neural network architecture for function approximators for low-dimensional-but-complex functions. In particular, the authors propose a multiplicative filter network that combines sinusoidal and Gabor wavelet functions. The authors show that the proposed network can be viewed as a linear function approximation over an exponential number of Fourier or Gabor basis functions, and that it can be used to represent complex functions such as signed distance functions or neural radiance fields. Empirical results are provided to demonstrate the effectiveness of the proposed method."
SP:f5be855300f63c185a006834302bd4b033b56258,"This paper proposes a new meta-learning algorithm for few-shot learning, long-tailed classification, and meta-attack. The main idea is to use a student network to explore the search space of task-specific models (e.g., by more than ten steps), and a teacher network to take a “leap” toward the regions probed by the student network. The teacher network is trained to arrive at a high-quality model but also defines a lightweight computation graph for meta-gradients. The proposed algorithm is generic and can be applied to four different meta learning algorithms over three tasks."
SP:0361e02d56b7d121cb5ede1cb582284cc18fc599,"This paper proposes a behavior regularization method for offline reinforcement learning. The main idea is to use an analytical upper bound on KL divergence as the behavior regularizor to reduce variance associated with sample based estimations. The authors also employ state-dependent Lagrange multipliers for the regularization term to avoid distributing KL divergence penalty across all states of the sampled batch. To prevent catastrophic performance degradation due to rare out-of-distribution actions, the authors also add a gradient penalty term to the policy evaluation objective to penalize the gradient of the Q value w.r.t the out of distribution actions. The experimental results show that the proposed method BRAC+ outperforms the existing offline RL algorithms."
SP:b2cfb380aa2a21f72f508b453cf5949257a5b4ec,This paper proposes Adjoined networks as a training approach that can regularize and compress any CNN-based neural architecture. The proposed method trains both the original and the smaller networks together. The parameters of the smaller network are shared across both the architectures. The authors prove strong theoretical guarantees on the regularization behavior of the adjoint training paradigm. The theoretical analysis is complemented by an extensive empirical evaluation of both the compression and regularisation behavior of adjoint networks. 
SP:dba40073f79143e5355d194aa16db9eee0267a5d,"This paper proposes a temporal extension of the greedy exploration algorithm in reinforcement learning (RL). The authors argue that the main limitation of greedy exploration is its lack of temporal persistence, which limits its ability to escape local optima. To address this limitation, the authors propose a temporally extended form of greedy that simply repeats the sampled action for a random duration. Experiments show that the proposed temporal extension can improve exploration on a large set of domains."
SP:5efb581a368ace3bd085d48801a899559d6a43ef,"This paper studies the implicit regularization of gradient flow with infinitesimal initialization in the case of depth-2 matrix factorization. In particular, the authors show that for the case where the depth is deeper than 2, gradient flow is equivalent to a heuristic rank minimization algorithm, Greedy Low-Rank Learning. The authors also extend the results to the case when the depth goes to 3, and show that the convergence has a much weaker dependence over initialization magnitude."
SP:7f997cf7a63a7330fc12fd525516080c91a3cb9b,"This paper proposes a method for improving the robustness of classifiers against spurious spurious bandages. The method is based on the idea of model patching, which first models subgroup features within a class and learns semantic transformations between them, and then trains a classifier with data augmentations that deliberately manipulate sub group features. The proposed method, CAMEL, uses a CycleGAN to learn the intra-class, inter-subgroup augmentations, and balances subgroup performance using a theoretically-motivated subgroup consistency regularizer, accompanied by a new robust objective. Experiments on 3 benchmark datasets demonstrate the effectiveness of the proposed method."
SP:de6cea1e35a0555175e17546a93422e9a96a511e,"This paper proposes a method for learning interpretable nonfuzzy rules for data representation in rule-based models. The proposed method is based on the idea of learning a non-differentiable classifier that can project the discrete model to a continuous space and train it using gradient descent. The authors propose a novel training method, Gradient Grafting, that can directly optimize the discrete classifier. An improved design of logical activation functions is also devised to increase the scalability of RRL and enable it to discretize the continuous features end-to-end. Experiments on 9 small and 4 large data sets show that RRL outperforms the state-of-the-art methods."
SP:e36388a9452e557dd51bf0170bf2f9da22271a49,"This paper proposes a new regret minimization algorithm for molecular property prediction. The proposed algorithm is based on invariant risk minimization (IRM) and extends it to structured environments. The main idea is to replace the simultaneous optimality condition in IRM with predictive regret, which is a representation that enables the predictor to compete against an oracle with hindsight access to held-out environments. Experiments show that the proposed algorithm outperforms previous state-of-the-art baselines."
SP:cad3ed2fba57faf17a3e8899dc5a744d5358aa68,"This paper proposes a novel architecture for cross-probe BERT, which is based on the idea of cross-modal attention. The authors propose to use a combination of text and vision probes to perform the attention. This is a very interesting idea, and the experimental results show that the proposed method outperforms the state-of-the-art."
SP:51fd82de525fcb738fdeaeeae20fbb2cdf975f0c,This paper proposes a new Actor-Critic algorithm named forward-looking Actor (FORK) for actor-critic algorithms. The main idea of FORK is to use a forward-looker actor which can be integrated into a model-free ActorCritic. Experimental results on six Box2D and MuJoCo environments with continuous state and action spaces demonstrate that FORK can bring significant performance improvement to the state-of-the-art algorithms.
SP:6e730239e6e8b43c4988dd61dca30f15dc039ef7,"This paper proposes a Bayesian aggregation algorithm for federated learning. The main idea is to aggregate local models into a global model, which has been shown challenging when users have non-i.i.d. data. The authors propose to combine higher-quality global models and combine them via Bayesian model Ensemble, leading to much robust aggregation. They show that an effective model distribution can be constructed by simply fitting a Gaussian or Dirichlet distribution to the local models."
SP:3ac5f437fc349a33810d0645664d1c448528af74,This paper presents a new method for explaining the performance of binary classification models in the context of double-blind review. The method is based on the idea that the model should be able to explain the results of a single blind review of a binary classification model. The paper is well-written and well-motivated. It is well organized and easy to follow. The authors have done a good job of explaining their method to the reader.
SP:efa2343ead47263a0d09e1c17f9aa044605b9650,This paper provides a priori upper bound on the settling time of deep neural networks based on the Lyapunov analysis of the loss function. The authors derive the upper bound using the analysis of finite-time control of non-linear systems. The main contribution of this paper is to provide an analytical formula for finite- time upper bound under the assumptions of boundedness of input and robustness against input perturbations. The paper is well-written.
SP:7a0ded4b3b2d08d43765ff7b722da9b9863aabd6,"This paper proposes a method for learning disentangled representations of latent variables. The authors argue that the GIN method for disentanglement is not theoretically supported and can be disproved by experiments. Instead, the authors propose to use the mutual information between each learned latent variables and the auxiliary variable to correctly identify informative latent variables, and show the improvement of the proposed method in experiments on synthetic data and real data."
SP:0d9ba12bbf47b13a46c2225f9dc06878418daaea,"This paper proposes a new pooling operation for convolutional neural networks. The proposed method is based on the classical Lifting scheme from signal processing. The key idea is to decompose a feature map into various downsized sub-bands, each of which contains information with different frequencies. The authors propose two variants of the proposed method, namely, LiftDownPool and LiftUpPool. The first one is a backward-up-pooling operation, while the second one is an up-up pooling method. Experiments are conducted on image classification and semantic segmentation tasks. "
SP:147239edceb17bade6ea5d3dca44e3a59998aa47,"This paper proposes a binary embedding method to transform a high-dimensional dataset T into binary sequences in the cube {±1}. The key idea is to use a stable noise-shaping quantization scheme to quantize a sparse Gaussian random matrix A into a binary sequence. The authors show that Euclidean distances among the elements of T are approximated by the `1 norm on the images of the cube. The proposed method is both fast and memory efficient, with time complexity O(m) and space complexity $m$ on well-spread data, and $O(n log n)$ on data with Walsh-Hadamard matrix."
SP:f65e229bca3904095743e7a501b1083cc60f1e22,"This paper proposes to use plasticity rules as a proxy for Gradient Descent (GD) to improve the generalization and robustness of artificial neural networks (ANNs). In particular, the authors argue that the plasticity rule can be learned by GD on the rule parameters of RNNs. The authors provide both empirical and theoretical evidence for this hypothesis. In their experiments, they show that plasticity-rule-based plasticity networks can generalize well and are robust to adversarial perturbations. They also show that GD can be used to recover the perceptron algorithm and multiplicative weights method for the last layer of a classification network."
SP:f435530146fa975cb27cd375a857df9bcbd87682,"This paper proposes a method for visual question generation (VQG) that aims to generate human-like questions from an image and potentially other side information (e.g. answer type or the answer itself). To address these limitations, the authors propose a novel learning paradigm to generate visual questions with answer-awareness and region-reference. In particular, they aim to ask the right visual question with Double Hints textual answers and visual regions of interest, effectively mitigating the existing one-to-many mapping issue. To this end, they develop a simple methodology to self-learn the visual hints without introducing any additional human annotations. Furthermore, to capture these sophisticated relationships, they propose a new double-hints guided Graph-To-Sequence learning framework that first models them as a dynamic graph and learns the implicit topology end to end, and then utilize a graph to sequence model to generate the questions with double hints. The experiments on VQA2.0 and COCO-QA datasets demonstrate that the proposed model can significantly outperform existing state-of-the-art baselines by a large margin."
SP:53a26ce11647866d3f6ba8b84ca9f13106197a8d,"This paper studies the double descent phenomenon, which is the phenomenon of test performance that is non-monotonic in quantities such as the sample size and model size. The authors prove that optimally-tuned `2 regularization can achieve monotonic test performance as we grow either the sample or the model size in linear regression models with isotropic data distribution. Theoretical results are provided for linear regression and neural networks. Empirical studies are also provided to demonstrate the effectiveness of the proposed regularization."
SP:c193ccc74b987beaf8d53a29a8529a0af5e87742,"This paper proposes a spatial dependency network (SDN) to improve generative modeling by better exploiting spatial regularities and coherence in images. The authors propose a novel neural network for building image generators (decoders) and apply it to variational autoencoders (VAEs) by augmenting the decoder of a hierarchical VAE by spatial dependency layers. They show that SDN can improve density estimation over baseline convolutional architectures and the state-of-the-art among the models within the same class. In a vanilla VAE setting, they find that a powerful SDN decoder also improves learning disentangled representations, indicating that neural architectures play an important role in this task."
SP:db91512a90e75675af03c2f197751c8526d6f5e9,"This paper proposes EMaQ (Expected-Max Q-Learning) for offline reinforcement learning, which is a simplified version of BCQ (Fujimoto et al., 2018a). The main idea is to use the expected-max Q-learning operator (EMaQ) to constrain learned policies to remain close to the given dataset of interactions. The authors also derive a new sub-optimality bound for EMaq that explicitly considers the number of samples and the proposal distribution, which can serve as a novel measure of complexity for offline RL problems. Empirical results on the D4RL benchmark show that EMAQ outperforms prior state-of-the-art in the offline RL setting. In the online RL setting, the authors demonstrate that EMa Q is competitive with Soft Actor Critic."
SP:e2b80adeaa9208e0667a64a3f24661f77b48e487,"This paper proposes a batch selection algorithm for improving model fairness in machine learning models. The proposed algorithm is based on batch optimization with an outer optimizer that selects minibatch sizes to improve model fairness. The inner optimizer is the standard training algorithm, while the outer optimiser is a variant of batch selection. The authors propose to use batch selection as an outer optimization problem, and propose a new batch selection method called FairBatch. The main contribution of the paper is that the proposed algorithm does not require any modification to data preprocessing or model training. The experiments conducted both on synthetic and benchmark real data demonstrate that the algorithm can achieve comparable performance while achieving comparable (or even greater) performance against the state of the art."
SP:72f26b850bb2258223c0fc71598e35ad07d690e6,"This paper studies the bounds on the Lipschitz constant of monotone deep equilibrium (DEQ) networks. The authors show that the monotonicity of the network can be expressed as a function of the strong monotonity of the input-output mapping and the weight output mapping, and derive simple-yet-tight bounds on both of them. They also show how to use these bounds to develop PAC-Bayes generalization bounds that do not depend on the depth of the networks and avoid the exponential depth dependence of comparable DNN bounds."
SP:bcfd4d7fd4590e3bc248a0a5422ce4b67db74a74,"This paper proposes a method for imitation learning and goal-conditioned reinforcement learning. The main idea is to use density estimation to estimate the probability of reaching a given state, and then use this estimate to train an agent to reach a goal state. The paper is well-written and well-motivated, and the experimental results show that the proposed method can be applied to both imitation learning as well as goal conditioned reinforcement learning, where it can circumvent the problem of sparse rewards while addressing hindsight bias in stochastic domains."
SP:d57550b2f323b356d7e609acc35ee33039f376b4,"This paper proposes a variational multi-task learning (VMTL) framework for multi-tasks learning. The main idea is to use Gumbel-softmax priors to condition the prior of each task on related tasks. Each prior is represented as a mixture of variational posteriors of other related tasks and the mixing weights are learned in a data-driven manner for each individual task. The posteriors over representations and classifiers are inferred jointly for all tasks and individual tasks are able to improve their performance by using the shared inductive bias. The experimental results demonstrate that VMTL is able to tackle challenging multi- task learning with limited training data well, and it achieves state-of-the-art performance on four benchmark datasets consistently surpassing previous methods."
SP:3ccdf8322f16c8a7bef82e32fad4c03969a510d1,"This paper proposes a systematic and unified benchmark, Long-Range Arena, specifically focused on evaluating model quality under long-context scenarios. The benchmark is a suite of tasks consisting of sequences ranging from 1K to 16K tokens, encompassing a wide range of data types and modalities such as text, natural, synthetic images, and mathematical expressions requiring similarity, structural, and visual-spatial reasoning. The paper systematically evaluate ten well-established long-range Transformer models on the newly proposed benchmark suite. The proposed benchmark paves the way towards better understanding this class of efficient Transformer model, facilitates more research in this direction, and presents new challenging tasks to tackle."
SP:e12e410c3335b76133ceda4c865b244fbbab8580,This paper proposes a multi-language code summarization model that combines source code (context) and abstract syntax tree (AST) representation learning. The main idea is to combine source code and AST representation learning in the same model. The model is trained on monolingual code and multi-lingual code. The authors show that the proposed model outperforms the state-of-the-art on all five programming languages considered in this paper.
SP:f46e98d48f90071831f1c0069bf74a7993be6db8,"This paper proposes a reinforcement learning method for audio-visual navigation in 3D scenes. The proposed method is based on the idea of waypoints that are dynamically set and learned end-to-end within the navigation policy, and an acoustic memory that provides a structured, spatially grounded record of what the agent has heard as it moves. Experiments are conducted on Replica and Matterport3D datasets and show that the proposed method outperforms the state-of-the-art."
SP:23bfe317dcef00a91ea92389b3f39d9b93972454,"This paper investigates how weight initializations affect the performance of small convolutional networks trained to predict n steps of the two-dimensional cellular automaton Conway’s Game of Life. The authors show that networks of this architecture trained on this task rarely converge. They find that networks require substantially more parameters to consistently converge. Furthermore, they find that the initialization parameters that gradient descent converges to a solution are sensitive to small perturbations, such as a single sign change. Finally, they observe a critical value d0 such that training minimal networks with examples in which cells are alive with probability d0 dramatically increases the chance of convergence."
SP:1b5ba618d3e28d48f9205c0780f8288a08fa5392,"This paper proposes a new semi-supervised learning method that considers not only the perturbed inputs but also the similarity among the inputs having the same label. The authors propose a new objective function, dubbed BatchMean Triplet loss, which has the advantage of computational efficiency while taking into account all input samples. The proposed method achieves state-of-the-art performance across many standard SSL benchmarks with a variety of labeled data amounts."
SP:f3abccf4a2566ffbc821aba209fab15058639ad4,"This paper studies the problem of meta-learning in the context of few-shot meta-training, where the goal is to learn new tasks from a small, fixed number of examples from a set of previous tasks. The authors consider the problem in a sequential learning setting, where tasks are presented in sequence. They extend previous meta-Learning algorithms to handle the variable-shot settings that naturally arise in sequential learning: from many-shot learning at the start, to zero-shot training towards the end. On sequential learning problems, they find that meta- learning solves the full task set with fewer overall labels and achieves greater cumulative performance, compared to standard supervised methods."
SP:95cb420d92ec42e12a4bbb0e66224f1c498a7161,"This paper presents a series of probes designed to test the sensitivity of Transformer representations to several kinds of structure in sentences. Each probe involves swapping words in a sentence and comparing the representations from perturbed sentences against the original. The authors experiment with three different perturbations: (1) random permutations of n-grams of varying width, (2) swapping of two spans which do or do not form a syntactic phrase, and (3) swapping two adjacent words which do not break apart a phrase, to test sensitivity to local phrase structure. Results from the three probes collectively suggest that Transformers build sensitivity to larger parts of the sentence along their layers, and that hierarchical phrase structure plays a role in this process."
SP:cb27b27a6fefc192ad1c2bd083d13eb9e51a5c44,"This paper proposes a method for few-shot image synthesis task for GAN with minimum computing cost. The authors propose a skip-layer channel-wise excitation module and a self-supervised discriminator trained as a feature-encoder. The model converges from scratch with just a few hours of training on a single RTX-2080 GPU, and has a consistent performance, even with less than 100 training samples."
SP:c0dbeb5d94b2388595cf7ad9675c55df0bac7f8e,"This paper proposes a dual dual algorithm for neural network bounding. The main idea is to use a linear program of size linear in the number of neurons instead of a piecewise linear program, which is usually the case. The authors argue that this choice of linear program is a weakness of the employed relaxation, which comes at the cost of exponentially many constraints and thus currently lacks an efficient customised solver. To address this issue, the authors propose a dual algorithm that realises the full potential of the new relaxation by operating on a small active set of dual variables. The proposed dual algorithm shares the benefits of previous dual approaches for weaker relaxations: massive parallelism, GPU implementation, low cost per iteration and valid bounds at any time."
SP:56e3837417dbcce0d65338dc3aac4e1a20eb0df8,"This paper proposes a method for augmenting pre-trained language models with concept-centric commonsense knowledge. Specifically, the authors propose both generative and contrastive objectives for learning common sense from the text, and use them as intermediate self-supervised learning tasks for incrementally pre-training PTLMs (before task-specific fine-tuning on downstream tasks). The authors also develop a joint pretraining framework to unify generative-contrastive objectives so that they can mutually reinforce each other. Extensive experimental results show that the proposed method, concept-aware language model (CALM), can pack more commonsens knowledge into the parameters of a pre- trained text-to-text transformer without relying on external knowledge graphs, yielding better performance on both NLU and NLG tasks."
SP:7ec69bdee021af506293c87a3b75bce1c40a03d7,"This paper proposes a method for unsupervised physical object discovery. The method is based on the idea that physics, especially object interactions, facilitates disentangling of 3D geometry and position of objects from video. The proposed method uses both multi-scale pixel cues and physical motion cues to accurately segment observable and partially occluded objects of varying sizes and infer properties of those objects. The model reliably segments objects on both synthetic and real scenes. The discovered object properties can be used to reason about physical events."
SP:66997bc19a3ba6548fcf21f114e748bea95cad1c,"This paper proposes a method for improving the robustness of deep neural networks (DNNs) against adversarial attacks. Specifically, the authors propose to increase the margins of training samples by moving the decision boundaries of the DNN model far away from the training samples to improve robustness. The proposed method is evaluated on six publicly available datasets (including a COVID-19 CT image dataset) under strong 100-PGD white-box adversarial attack and the proposed method significantly improved classification accuracy on noisy data while keeping a relatively high accuracy on clean data."
SP:276ffd59fbf49e3ee02756da8920218102214917,"This paper proposes ProKT, a knowledge distillation method for deep neural networks. The main idea is to project the supervision signals of a teacher model into the student’s parameter space by decomposing the training objective into local intermediate targets with approximate mirror descent technique. The proposed method could be less sensitive with the quirks during optimization which could result in a better local optima. Experiments on both image and text datasets show that the proposed ProKT consistently achieves the state-of-the-art performance."
SP:906dc21d6988953fcf57d63bbdd12973e5818d16,"This paper proposes a channel pruning method to solve the problem of compression and acceleration of Convolutional Neural Networks (CNNs). The proposed method uses a hyper-structure network to generate the architecture of the main network, which can be optimized by regular backpropagation. The authors also use a regularization term to specify the computational resource of the compact network. Extensive experimental results on CIFAR-10 and ImageNet show that the proposed method is competitive with state-of-the-art methods."
SP:890fd9454596c051b0e9535baf73b1dd1fae67ca,"This paper presents a method for learning a theorem prover that can be used to prove a higher-order logic theorem in the presence of a large knowledge base of potential premises without learning from human proofs. The method is based on the exploration of premises based on a simple tf-idf (term frequency-inverse document frequency) based lookup in a deep reinforcement learning scenario. The experiments show that the algorithm trained with this exploration mechanism but no human proofs, dubbed DeepHOL Zero, outperforms provers that are trained only on human proofs and approaches the performance of a prover trained by a combination of imitation and reinforcement learning."
SP:88209417a8ad07e6103084e41709be900303ce5f,"This paper proposes MODALS (Modalityagnostic Automated Data Augmentation in the Latent Space) to augment data for any modality in a generic way. MODALS exploits automated data augmentation to fine-tune four universal data transformation operations in the latent space to adapt the transform to data of different modalities. Experiments on multiple datasets for text, tabular, time-series and image modalities demonstrate the effectiveness of MODALS."
SP:6d84670d321b0d584b097c630574bd748e85c9a2,"This paper studies the global convergence of three-layer neural networks in the mean-field regime. The authors propose a neuronal embedding, which consists of a fixed probability space that encapsulates neural networks of arbitrary sizes. They prove a global convergence guarantee under suitable regularity and convergence mode assumptions, which does not rely critically on convexity. The result is shown to hold at any finite training time (not necessarily at convergence) via an algebraic topology argument."
SP:b90f893f927db9c439595fd119a565cf43c971f4,"This paper proposes a method for learning explanations of expert decisions by modeling their reward function in terms of preferences with respect to “what if” outcomes: Given the current history of observations, what would happen if we took a particular action? To learn these costbenefit tradeoffs associated with the expert’s actions, the authors integrate counterfactual reasoning into batch inverse reinforcement learning. This offers a principled way of defining reward functions and explaining expert behavior, and also satisfies the constraints of real-world decision-making where active experimentation is often impossible (e.g. in healthcare). Additionally, by estimating the effects of different actions, Counterfactuals readily tackle the off-policy nature of policy evaluation in the batch setting and can naturally accommodate settings where the expert policies depend on histories of observations rather than just current states."
SP:c92916780418bfa7f0796fd9766b6d28b9eea5ef,"This paper presents a series of ablations on existing methods that show that morphological information encoded in the graph does not improve their performance. Motivated by the hypothesis that any benefits GNNs extract from the graph structure are outweighed by difficulties they create for message passing, the authors propose AMORPHEUS, a transformer-based approach. The experiments show that the proposed method is able to outperform GNN-based methods that use the morphologically information to define the message passing scheme."
SP:2cf58f5cac20dccdc2034ef60e8e46b7988ebd7d,"This paper proposes a method for visual counting, which aims to predict the number of occurrences given a natural image and a query (e.g. a question or a category). Unlike most prior works that use explicit, symbolic models which can be computationally expensive and limited in generalization, the authors propose a simple and effective alternative by revisiting modulated convolutions that fuse the query and the image locally. Following the design of residual bottleneck, they call their method MoVie, short for Modulated ConVolutional bottlenecks. The authors demonstrate strong performance for counting: 1) advancing the state of the art on counting-specific VQA tasks while being more efficient; 2) outperforming prior-art on difficult benchmarks like COCO for common object counting; 3) helped to secure the first place of 2020VQA challenge when integrated as a module for ‘number-related questions’ in generic models."
SP:c64e77507e562f236cb69361b22fb1a7951ffb22,"This paper proposes a model-targeted poisoning attack that can target a desired model based on online convex optimization. The authors prove that the distance from the induced classifier to the target classifier is inversely proportional to the square root of the number of poisoning points. They also provide a lower bound on the minimum number of poisoned points needed to achieve a given target model. In experiments, the authors show that the proposed attack can either match or outperform the best state-of-the-art attacks in terms of attack success rate and distance to target."
SP:a526023ec4cb839b83c574d31f59a9a67bc7af00,"This paper proposes a method to improve the performance of binarized models for real-time point cloud applications that run on edge devices. The authors argue that aggregation-induced feature homogenization that leads to a degradation of information entropy, and scale distortion that hinders optimization and invalidates scale-sensitive structures. They propose Entropy-Maximizing Aggregation (EMA) to modulate the distribution before aggregation for the maximum information entropy and Layer-wise Scale Recovery (LSR) to efficiently restore feature representation capacity. Extensive experiments show that BiPointNet outperforms existing binarization methods by convincing margins, at the level even comparable with the full precision counterpart."
SP:825b4d1db0c537a607655bb5b4bf221ec672c8af,This paper proposes a few modifications to the Transformer architecture to improve the performance of the model. The main idea is to add a memory module to the self-attention layer of the transformer architecture to store non-local information about the context of the input sequence. The authors show that adding the memory module can improve the model's ability to process a global context. Experiments are conducted on a variety of language modeling tasks and machine translation tasks. 
SP:f0fa1b7684bc605f6edd4813c44be20988fe8b4c,"This paper proposes Prototypical Contrastive Learning (PCL), an unsupervised representation learning method that bridges contrastive learning with clustering. Specifically, PCL introduces prototypes as latent variables to help find the maximum-likelihood estimation of the network parameters in an Expectation-Maximization framework. PCL iteratively performs E-step as finding the distribution of prototypes via clustering and M-step is optimizing the network via contrastive learn. The paper proposes ProtoNCE loss, a generalized version of the InfoNCE losses for contrastive loss, which encourages representations to be closer to their assigned prototypes."
SP:5342a5e1d87fd17b1a2efed967dbbfeafa440ee7,"This paper proposes an orthogonal multi-path (OMP) block to improve the robustness of deep neural networks against adversarial attacks. The proposed OMP block is based on the idea of orthogonality constraint, where the parameters of the paths are orthogonic with each other. The authors propose to use forward learning and backward correction to learn features that are appropriate for all the paths and hence are expected to be robust. Experiments are conducted on CIFAR-10 and ImageNet and show that the proposed method can improve the performance of neural networks in both white-box and black-box attacks."
SP:776df66274ed12449fde8dcef873a593980f397c,"This paper proposes a self-supervised graph attention network (SuperGAT) for noisy graphs. Specifically, the authors exploit two attention forms compatible with a self supervised task to predict edges, whose presence and absence contain the inherent information about the importance of the relationships between nodes. By encoding edges, SuperGAT learns more expressive attention in distinguishing mislinked neighbors. The experiment on 17 real-world datasets demonstrates that the recipe generalizes across 15 datasets of them, and our models designed by recipe show improved performance over baselines."
SP:80a05296d6b1e4c6e9e2df01938c73029ff8487d,"This paper proposes an agent for DSMAD, which aims to learn an agent that mimics the behavior of a human doctor, i.e. inquiring symptoms and informing diseases. The proposed agent consists of two modules: an inquiry module for proposing symptom-inquiries and an introspective module for deciding when to inform a disease. The authors propose two evaluation metrics to validate the reliability and robustness of DSMAD methods. Extensive experimental results demonstrate that INS-DS achieves the new state-of-the-art under various experimental settings."
SP:10ae09d90d465125433a9b4f15b1405ab017920d,"This paper proposes an adaptive batch-wise regularization based on the proposed Batch Confusion Norm (BCN) to address the natural world distribution of fine-grained and long-tailed properties of visual classification. The BCN term can alleviate possible overfitting due to exploring image features of fine details. More importantly, BCN can learn to exert proper distribution of confusion strength over tailed and head categories to improve classification performance. The experimental results show the effectiveness of the proposed method on several benchmark datasets."
SP:90f1e0fe1e9678d1e9a4dcb519d4e8fd61098ce0,This paper proposes a Bayesian imitation learning method for inverse reinforcement learning. The main idea is to jointly learn an approximate posterior distribution over the reward that scales to arbitrarily complicated state spaces alongside an appropriate policy in a completely offline manner through a variational approach to the latent reward. The proposed method is evaluated on real medical data alongside classic control simulations and compared with focused offline imitation learning algorithms. The experimental results show that the proposed method can achieve state-of-the-art performance on a variety of tasks.
SP:ccd251d95c0a2d8dc5ad2a148ec29955e105e71e,"This paper proposes a method for learning counterfactual belief distributions for partially observable environments. The method is based on an auto-regressive belief distribution that is learned as a supervised task. The proposed method is evaluated on Hanabi, where it is shown to outperform the state-of-the-art in terms of performance on the Hanabi benchmark. "
SP:db408e6bfe69a9b3984f3b27ca92b802aa37af42,"This paper proposes a new algorithm for tree search that aims to balance depth and breadth of the search. The proposed algorithm is based on a combination of MCTS and random shooting. The authors show that the proposed algorithm can be seen as an interpolation between two celebrated search mechanisms: MCTs and Random Shooting. It also lets the user control the bias-variance trade-off, akin to TD(n), but in the tree search context. The experimental results show that STS can get the best of both worlds consistently achieving higher scores."
SP:5efc271ccc555fd9aa542548838170bd4c98e957,"This paper proposes a new pre-training method for inductive bias in neural networks. The authors propose to train a transformer network on a set of synthetic tasks that are designed to require the model to have deduction, induction, and abduction abilities. These synthetic tasks are designed in a way that they are devoid of mathematical knowledge to ensure that only the fundamental reasoning biases can be learned from these tasks. This defines a new method called LIME (Learning Inductive bias for Mathematical rEasoning), which is based on the idea that inductive biases are encoded in the form of datasets. Experiments show that LIME significantly outperforms vanilla transformers on three different mathematical reasoning benchmarks."
SP:bb8e0b554d3b3314fa343c902d9e60f1a141ea30,"This paper studies the inductive bias of gradient descent for weight normalized smooth homogeneous neural nets, when trained on exponential or cross-entropy loss. The authors show that the gradient flow path with exponential weight normalization (EWN) is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. These results can be extended to hold for gradient descent via an appropriate adaptive learning rates. Experimental results on simple data sets and architectures support the claim on sparse EWN solutions, even with SGD."
SP:c71f9d2a602516865a0b103028186e83b52e5f00,"This paper studies the mode collapse problem in generative adversarial networks (GANs) and proposes a novel training procedure that dynamically spawns additional discriminators to remember previous modes of generation. The authors claim that mode collapse is caused by the discriminator’s inability to maintain classification accuracy on previously seen samples, a phenomenon called Catastrophic Forgetting in continual learning. Motivated by this observation, the authors introduce a new training procedure to dynamically generate additional discriminator to remember the previous generation. Experiments on several datasets show that the proposed method can mitigate mode collapse and improve standard metrics."
SP:52c48198c95826e042f9e5a512ef3265daaff882,"This paper proposes a method to regularize BERT by pruning attention heads based on a proxy score for head importance. The paper proposes to use reinforcement learning to automatically prune attention heads from BERT. Instead of relying on heuristics or rule-based policies, AUBER learns a pruning policy that determines which attention heads should or should not be pruned for regularization. The experimental results show that the proposed method outperforms existing pruning methods by achieving up to 9.39% better accuracy."
SP:abcbbad146f1b0d5d579c215952c95e5499a378a,"This paper proposes a method for learning correspondence between two different domains, i.e., sim-to-real and real-world. The method is based on a cycle-consistency constraint on the dynamics of the two domains, which is used to train a policy on one domain and then transfer it to the other domain. The paper is well-written and well-motivated, and the experiments show that the proposed method is able to achieve state-of-the-art results on both simulated and real robotic tasks."
SP:006434d56992836ab9420d7d4215bc70664de304,"This paper studies the problem of using Shapley explainability in the context of machine learning. In particular, the authors argue that the Shapley framework for explainability attributes a model’s predictions to its input features in a mathematically principled and model-agnostic way. The authors demonstrate the drawbacks of this assumption and develop two solutions that respect the data manifold. One solution, based on generative modelling, provides flexible access to data imputations; the other directly learns Shapley value-function, providing performance and stability."
SP:7cda6bccf08887c7cef66d0ac3ccefdea8f5d7c8,"This paper proposes a new method for opponent modelling based on variational autoencoders. The proposed method is based on learning an embedding of the agent’s actions and actions of the opponent based on the observed world state, chosen actions, and received rewards. The embeddings are used to augment the decision policy which is trained via deep reinforcement learning. Experiments are conducted on a variety of multi-agent tasks and show that the proposed method achieves comparable performance to an ideal baseline which has full access to opponent’S information."
SP:c239bc531bcf7293032748af29a1b786e9d893dd,"This paper proposes Consistent Contrastive Learning (CO2), a method for unsupervised contrastive learning on unlabeled images. The authors propose to regularize the contrastive loss to encourage consistency between crops from the same image and crops from other images. This is inspired by consistency regularization in semi-supervised learning. The method is evaluated on image classification, object detection, and semantic segmentation tasks, and it is shown to outperform MoCo."
SP:d18bab21790713e2facb053c47298fc9079ab783,"This paper studies the last-iterate convergence of Optimistic Gradient Descent Ascent (OGDA) and Optimistic Multiplicative Weights Update (OMWU) for bilinear games over the probability simplex. The authors show that when the equilibrium is unique, OGDA converges exponentially fast with a learning rate whose value is set to a universal constant, improving the result of (Daskalakis & Panageas, 2019b) under the same assumption. They also extend the results to more general objectives and feasible sets for the projected OGDA algorithm, by introducing a sufficient condition under which OGDA exhibits concrete last iterate convergence rates with a constant learning rate. Finally, they provide experimental results to further support their theory."
SP:bbc7f77308b298c332a39747f693bc396f00a89f,"This paper proposes a method for training user verification models in federated setup, where each user has access to the data of only one class and user embeddings cannot be shared with the server or other users. The authors propose to jointly learn a set of vectors and maximize the correlation of their instance embedding with a secret user-defined linear combination of those vectors. They show that choosing the linear combinations from the codewords of an error-correcting code allows users to collaboratively train the model without revealing their embedding vectors. The experimental results for user verification with voice, face, and handwriting data are presented."
SP:40fa47cc0928e2925ef5ce6d808073f368ca2cd4,"This paper proposes a method to estimate the effective dimension of class manifolds (CMs) by computing their intersection with random affine subspaces of varying dimension. The authors provide a theory for the technique and verify that their theoretical predictions agree with measurements on real neural networks. Through extensive experiments, the authors leverage this method to show deep connections between the geometry of CMs, generalization, and robustness."
SP:09bce202ac7a750c3700a8ef3cd92cfe8ed00c39,"This paper proposes a novel approach to explore more in an unfamiliar state, while less in a familiar state, in order to better understand the environment more efficiently. Specifically, the authors propose to use the state prediction error to model curiosity, which is added to the target entropy to increase the entropy temperature for unfamiliar states and decrease the entropy for familiar states. The experiments on the MuJoCo benchmark show that the proposed CAT-SAC significantly improves the sample efficiency, outperforming the advanced model-based / model-free RL baselines."
SP:dce5eb20581a21c5de0a9fc07a8a79a1fbb28c71,"This paper proposes a meta-reinforcement learning algorithm that is both efficient and extrapolates well when faced with out-of-distribution tasks at test time. The proposed method is based on the observation that dynamics models can be adapted efficiently and consistently with off-policy data, more easily than policies and value functions. The dynamics models are used to generate synthetic experience for the new task, which can then be used to continue training policies and values for out of distribution tasks. "
SP:34d78aa11f9d50baf75a9646a6f9128318c3389a,"This paper studies the problem of meta-learning for few-shot learning (FSL) in the context of sampling noise and label noise. The paper proposes two methods to address these two challenges. First, the paper proposes Eigen-Reptile (ER) that updates the meta-parameters with the main direction of historical taskspecific parameters to alleviate gradient noise. Second, Introspective Self-paced Learning (ISPL) that constructs a plurality of prior models to determine which sample should be abandoned. Experiments on different tasks demonstrate that the proposed methods outperform or achieve highly competitive performance compared with the state-of-the-art methods."
SP:a571bff9ffe4edafd7bc064c4d10609e6b981ce3,"This paper proposes a new adversarial training method for image classification models that is robust to distributional shifts. The proposed method is based on adversarial batch normalization (Adversarial Batch Normalization (AdvBN), which is a variant of batch normalisation (BNN) that is used to train deep neural networks. The authors show that AdvBN improves the performance of ResNet-50 on ImageNet-C, Stylized-ImageNet, and ImageNetInstagram over standard training practices. In addition, AdvBN can also improve generalization on semantic segmentation."
SP:6a9c46bd3cf854299f360bff136e1d79d3edb2e4,This paper proposes Variance of Gradients (VoG) as a proxy metric for detecting outliers in the data distribution. The authors provide quantitative and qualitative support that VoG is a meaningful way to rank data by difficulty and to surface a tractable subset of the most challenging examples for human-in-the-loop auditing. Data points with high VoG scores are far more difficult for the model to learn and over-index on corrupted or memorized examples.
SP:074bfacc75837bb19049be8a2890e10de073dd8e,"This paper proposes a new method for improving the quality of generated samples in deep generative models. The proposed method is based on the gradient flow of entropy-regularized f-divergences between the real and the generated data distributions. The gradient flow takes the form of a non-linear Fokker-Plank equation, which can be easily simulated by sampling from the equivalent McKean-Vlasov process. Compared to existing works that focus on specific GAN variants, the proposed method can be applied to GANs with vector-valued critics and even other deep models such as VAEs and Normalizing Flows. Empirical results on multiple synthetic, image, and text datasets demonstrate the effectiveness of the method."
SP:74ecbc5a6d464bfa49337da9e0dd6a0fe714d4bb,"This paper proposes a new pre-training method for cross-lingual understanding and generation tasks. The main idea is to split the standard Transformer block into several sub-modules trained with both innersequence and cross-sequence masked language modeling, and reorganize certain sub- modules for understanding and generating tasks during inference. The proposed method achieves state-of-the-art results on the XTREME benchmark covering text classification, sequence labeling, question answering, and sentence retrieval tasks."
SP:3d177ad50727d1a2619b68ab8a897b79d8652beb,"This paper proposes a novel intrinsic reward mechanism for reinforcement learning based on auditory event prediction. The authors propose to use K-means to discover underlying auditory event clusters and train a neural network to predict the auditory events and use the prediction errors as intrinsic rewards to guide RL exploration. The method is evaluated on Atari games, Habitat simulator, and TDW."
SP:014f6118ebe55ece6be23c3a10f12e4591e444b1,"This paper proposes an end-to-end framework to jointly learn a reliable representation and assign clusters to unlabelled data. To avoid over-fitting the learnt embedding to labelled data, the authors take inspiration from self-supervised representation learning by noise-contrastive estimation and extend it to jointly handle labelled and unlabeled data. The proposed method is evaluated on large-scale multi-modal video benchmarks Kinetics-400 and VGG-Sound, and image benchmarks CIFAR10, Cifar100 and ImageNet."
SP:4df640f502e88ddba2d7e183625231d70b083e82,"This paper proposes a method for weakly supervised segmentation of images with partial annotations such as image-level tags, object bounding boxes, labeled points and scribbles. The authors propose 4 types of contrastive relationships between pixels and segments in the feature space, capturing low-level image similarity, semantic annotation, co-occurrence, and feature affinity. The pixel-wise feature can be learned from training images with any partial annotations in a data-driven fashion. Experiments on Pascal VOC and DensePose show that the proposed method outperforms existing methods."
SP:f7d6099adb40a0ce2f8a3563dbd5207cf1fdea0f,This paper proposes a distillation strategy for unsupervised self-supervised learning based on bag of instances (BINGO) which is short for Bag of InstaNces aGgregatiOn. BINGO aims at transferring the relationship learned by the teacher to the student. The goal of distillation is to aggregate compact representations over the student with respect to instances in a bag. The proposed method achieves new state-of-the-art performance on small scale models with linear evaluation on ImageNet.
SP:328866aad6544c81ded8980934df31dc4472435f,"This paper proposes GATSBI, a generative adversarial approach to simulation-based inference (SBI) for high-dimensional simulators. The authors reformulate the variational objective in an adversarial setting to learn implicit posterior distributions, which is amortised across observations, and works in high dimensional posterior spaces and supports implicit priors. The proposed method is evaluated on two SBI benchmark problems and on two high dimensional simulators and shows that it can return well-calibrated posterior estimates even in high dimensions. On a model for wave propagation on the surface of a shallow water body, the authors show that the proposed method performs better than a state-of-the-art SBI approach."
SP:2915e82097eae4eb8546dc500f32b3ec37e3766f,This paper proposes a generative prognostic model for the identification and estimation of treatment effects (TEs) under limited overlap. The model uses a latent variable to model a prognostic score which is widely used in biostatistics and sufficient for TEs. The authors prove that the latent variable recovers a prognostic score and the model identifies individualized treatment effects. The proposed model is then learned as a new type of variational autoencoder (VAE) and the TE error bounds are derived that enable representations balanced for treatment groups conditioned on individualized features.
SP:ca358c9f36aac6e58ed1b3949c349d210c49a48e,"This paper proposes a framework for autonomous reinforcement learning (ARL) where the agent is not only learning through its own experience, but also contends with lack of human supervision to reset between trials. The authors introduce a simulated benchmark EARL1 around this framework, containing a set of diverse and challenging simulated tasks reflective of the hurdles introduced to learning when only a minimal reliance on extrinsic intervention can be assumed. They show that standard approaches to episodic RL and existing approaches struggle as interventions are minimized, underscoring the need for developing new algorithms for reinforcement learning with a greater focus on autonomy."
SP:abe51d4a9817c08f0abde5da0bb8e6ca4e02e7cf,This paper investigates the reasoning capability of Graph Neural Networks (GNNs) in question answering systems. The authors propose a simple graph neural counter that can be used to perform reasoning over knowledge graphs. The paper shows that existing knowledge-aware GNN modules may only carry out some simple reasoning such as counting. It remains a challenging open problem to build comprehensive reasoning modules for knowledge-powered QA systems.
SP:3ea5a38e7fcd9111dcd299ad039b634e2781685f,"This paper proposes a three-stage compression method for Deep Neural Network (DNN) models. The first step is to transform DNN models in Element-wise or Block-wise manner, and then compresses transformed models using Succinct Data Structures. The second stage is to retrieve relevant data for DNN inference from the compressed representation without decompression. Finally, the third stage is the execution pipelines for different model formulations. The experimental results show that, the proposed method keeps near-optimal compression and achieves at least 8.7X/11.5X speedup on AlexNet/VGG-16 inference, compared with Huffman Coding."
SP:94c395afc794a9cc163e362078769ff83f3d20d0,"This paper proposes a new training method for improving the performance of tiny neural networks. The authors argue that training tiny models is different from training large models: rather than augmenting the data, we should augment the model, since tiny models tend to suffer from under-fitting rather than over-fitting due to limited capacity. To alleviate this issue, NetAug augments the network (reverse dropout) instead of inserting noise into the dataset or the network. It puts the tiny model into larger models and encourages it to work as a sub-model of larger models to get extra supervision, in addition to functioning as an independent model. The experimental results demonstrate the effectiveness of NetAug on image classification and object detection."
SP:9c24549b980e415616f818acbf4cf680ef8edb52,"This paper proposes a generative adversarial network (GAN) for dynamic point cloud sequences without requiring point correspondence annotation. The proposed model, Temporal Point cloud Upsampling GAN (TPU-GAN), can implicitly learn the underlying temporal coherence from point cloud sequence, which in turn guides the generator to produce temporally coherent output. In addition, a learnable masking module is proposed to adapt upsampling ratio according to the point distribution. Experiments on two different domains: particles in the fluid dynamical system and human action scanned data demonstrate the effectiveness of the proposed method."
SP:67efe60ad37807505369b7852bc0abed29ffdda8,"This paper proposes a method for fully pre-training an encoder-only transformer for object detection. The proposed method is inspired by the success of textual prompts in NLP, which treat query positional embeddings as visual prompts to help the model attend to the target area (prompting) and recognize the object. The task adapter leverages self-attention to model the contextual relation between object query embedding. Experiments on the challenging COCO dataset demonstrate that the proposed PT-DETR achieves competitive performance and generalization to small-size datasets."
SP:a1f9897496303984fc7ad469222106b14b4a6233,"This paper proposes FedPAGE, a new local SGD algorithm for federated learning. The main idea is to use the optimal PAGE algorithm to reduce the communication cost of the local gradient descent algorithm. The authors show that the communication costs are much lower than SCAFFOLD in both convex and nonconvex settings. In the convex setting, the number of communication rounds is O(3/4 S), which is a factor of 3/4 of the best known result of Karimireddy et al. (2020). The authors also show that in the non-conveX case, the communication rounds are O(N^3/3 S^2/3) instead of O(NS/3/S^2) which is the state-of-the-art result."
SP:81e74765abc6524edd8fdf9a3ba107d7bddaa04b,"This paper studies the decision boundary geometry of ANN classifiers in the presence of adversarial attacks. The authors define adversarial subspaces, which are spanned by orthogonal directions of minimal perturbation to the decision boundaries from any given input sample. The decision boundary lies close to input samples in a large subspace, where the distance to the boundary grows smoothly and sub-linearly as one increases the dimensionality of the subspace. The geometry of the boundary is more curved within the adversarial space than within a random subspace of equal dimensionality."
SP:af5c25ecf38c5c3f3387720bdc80c2c54c5699fe,"This paper proposes a two-stage weakly-supervised contrastive learning approach for representation learning. The first stage is to cluster data according to its auxiliary information, and the second stage aims to learn similar representations within the same cluster and dissimilar representations for data from different clusters. The proposed method is evaluated on synthetic and real-world datasets, and compared with several baseline representation learning methods that do not leverage auxiliary data information."
SP:0a92fcc52970201de4a66b1e76c93dbea9dfd3f1,This paper proposes a new algorithm for sparse estimation based on unrolling a path-following algorithm. The authors provide a theoretical analysis of the performance of the proposed algorithm and show that it is able to recover sparse parameters from observational data. They also provide a generalization bound for the algorithm based on the Rademacher complexity analysis. 
SP:5064eda9ba27060af15e81b2b317b2e4558b0ac4,"This paper proposes a method to learn a compact and decodable latent representation space for the discrete-continuous hybrid action space. The method is based on a VAE-based approach to embedding the discrete action and continuous parameter into an embedding table and conditional Variational Auto-Encoder (VAE). The action representation is trained to be semantically smooth through unsupervised environmental dynamics prediction. Finally, the agent learns its policy with conventional DRL algorithms in the learned representation space and interacts with the environment by decoding the hybrid action embeddings to the original action space and using it to learn the policy. The results demonstrate the superiority of HyAR when compared with previous baselines."
SP:5128bf712f6b197de113c7a371b4bec36f978eca,"This paper proposes SGEM, Stochastic Gradient Descent with Energy and Momentum (SGEM) to solve a large class of general non-convex stochastic optimization problems. SGEM incorporates both energy and momentum at the same time so as to inherit their dual advantages. The authors show that SGEM features an unconditional energy stability property, and derive energy-dependent convergence rates in the general nonconveX setting and a regret bound in the online convex setting. The experimental results show that the proposed SGEM converges faster than AEGD and generalizes better than SGDM in training some deep neural networks."
SP:11f49b0a975be87769be29e85d7e3924699cf2c9,"This paper proposes a Conditional Masked Language Model with Correction (CMLMC) for non-autoregressive (NAR) machine translation models. NAR models have achieved state-of-the-art results on several machine translation datasets, but they still lag behind their autoregressive counterparts. This paper investigates possible reasons behind this performance gap, namely, the indistinguishability of tokens, and mismatch between training and inference. To address these problems, CMLMC proposes to use a conditional masked language model with correction. Empirically, the paper shows that the proposed method can outperform existing NAR-based models when trained on raw data without distillation."
SP:96f8ac3c6163e56d8ae1954a162bae01e6b58a0a,"This paper proposes WaveSense, a spiking neural network inspired by the WaveNet architecture. WaveSense uses simple neural dynamics, fixed time-constants and a simple feed-forward architecture and hence is particularly well suited for a neuromorphic implementation. The authors test the capabilities of this model on several datasets for keyword-spotting. The results show that the proposed network beats the state of the art of other neural networks and reaches near state-of-the-art performance."
SP:7f20a2e4e95f857140b87b0730360b3ff2f371f4,"This paper proposes a new algorithm, called Shifty, that is designed to address the problem of demographic shift in social applications. The algorithm is based on the idea that the data used for training is not representative of what will be encountered in deployment, which is known as demographic shift. The authors show that their algorithm is able to provide high-confidence behavioral guarantees that hold under demographic shift, and they evaluate their algorithm on a real-world dataset of university entrance exams and show that the learned models avoid bias."
SP:94f097921bee5fdc10ec2e7c901b2ddb876d9d41,"This paper proposes a neural model for solving multi-stage stochastic dual dynamic programming (SDDP) problems. The main idea is to train a neural network to map problem instances to a piece-wise linear value function within intrinsic low-dimension space, which is architected specifically to interact with a base SDDP solver, so that it can accelerate optimization performance on new instances. The proposed Neural Stochastic Dual Dynamic Programming (ν-SDDP), continually self-improves by solving successive problems. Experiments are conducted on synthetic and real-world process optimization problems."
SP:3d9f5132f9ec3807dbca78462a459fd123a09b24,"This paper proposes a privacy-preserving next-token prediction protocol for language models that were fine-tuned on a private corpus after pre-training on a public corpus. The authors show that the proposed method, called SUBMIX, limits the leakage of information that is unique to any individual user in the private corpus via a relaxation of group differentially private prediction. SubMIX admits a tight, data-dependent privacy accounting mechanism, which allows it to thwart existing data-extraction attacks while maintaining the utility of the language model."
SP:7f524d186ea939309c7eeb843c62b6a4b4cfbc8a,"This paper proposes an unsupervised method to detect out-of-distribution (OOD) samples using a k-NN density estimate with respect to a classification model’s intermediate activations on indistribution samples. The authors leverage a recent insight about label smoothing, which they call the Label Smoothed Embedding Hypothesis, and show that one of the implications is that the k-nn density estimator performs better as an OOD detection method both theoretically and empirically when the model is trained with label smoothed. Finally, the authors show that their proposal outperforms many OOD baselines and provide new finite-sample high-probability statistical results."
SP:aafbd6ada14cc59a272fe4bf95fac71fa18e57ab,"This paper proposes a new representation learning method for semi-supervised image classification. The proposed method is based on the idea of denoising autoencoders, which can be seen as a multi-scale autoencoder. In contrast, the proposed method uses a new formulation of the denoizing score matching objective and thus encodes information needed for denoisation. The authors demonstrate how this difference allows for manual control of the level of details encoded in the representation. In addition, the authors show how adversarial training in diffusion-based models can improve sample quality and improve sampling speed using a new approximation of the prior."
SP:8cfc837d5c10d539bbd098df7134c42e4830ba25,"This paper proposes a method for goal-conditioned reinforcement learning that learns a curriculum of intermediate states for reaching distant goals. The method is based on the idea of planning a sequence of waypoints using graph planning, while the M-step aims to learn a policy to reach those waypoints. Unlike prior methods that combine goal-conditional RL with graph search, the proposed method performs planning only during training and not testing, significantly decreasing the compute costs of deploying the learned policy. Empirically, the method is able to solve very long horizons manipulation and navigation tasks, which prior goalconditioned methods such as graph search fail to solve."
SP:ef3193842e06d4a6edb8a6a86ea5bc97ee5eaa4a,"This paper proposes a new regularization method for training deep neural networks called k-mixup, which is a variant of standard mixup (Zhang et al., 2018). Standard mixup is a data augmentation approach that trains models on weighted averages of random pairs of training points. The authors argue that the original mixup can lead to poor regularization when distributions are clustered or supported on an embedded manifold. To address this issue, the authors propose to use displacement interpolation, i.e. interpolation under the Wasserstein metric, to perturb k-batches of training data in the direction of other k-batch instances in the training set. They demonstrate theoretically and in simulations that k-Mixup preserves cluster and manifold structures, and extend theory studying the efficacy of mixup to the k- mixup case. The empirical results show that training with k- Mixup further improves generalization and robustness across several network architectures and benchmark datasets of various modalities."
SP:0fe6a9848026e5f6436a380199e27a9ad26cffed,This paper proposes a nonlinear kernelized classification layer for deep networks to tackle the problem of using the embeddings produced by a lightweight network more effectively with a non-linear classification layer. The authors theoretically show that their classification layer optimizes over all possible radial kernel functions on the space of embedding vector space to learn an optimal nonlinear classifier. They then demonstrate the usefulness of this layer in learning more model-efficient classifiers in a number of computer vision and natural language processing tasks.
SP:01ee8ec81619784788eb0ce9785098e437d17a7c,"This paper analyzes the sources of bias in node representations obtained via Graph Neural Networks (GNNs) in terms of both nodal features and graph structure. Based on this analysis, two data augmentation methods are proposed to reduce the intrinsic bias in the obtained representations. Extensive experiments on node classification and link prediction are carried out over real networks in the context of graph contrastive learning. The proposed augmentation strategies can improve the statistical parity and equal opportunity, while providing comparable utility to state-of-the-art contrastive methods."
SP:7739dc9e37f7f1384f87d2e60281e5bb27fece99,"This paper proposes a new method for estimating treatment effects from observational data in the presence of unmeasured confounders. The proposed method consists of three main modules: treatment regression, confounder balancing, and outcome regression. The treatment regression consists of regressing the treatment with IVs and confoundering in the first stage, and then learning a balanced representation of the confounded variables in the second stage. Theoretical analysis is provided to show that the proposed method is also effective under the multiplicative assumption rather than the additive separability assumption. Extensive experiments demonstrate that CB-IV algorithm outperforms the state-of-the-art methods."
SP:fdb68c39fce254b73310a3101b2fe97ba47e69fe,"This paper analyzes model-agnostic meta-learning (MAML) in a linear regression setting with a mixture of easy and hard tasks, where hardness is related to the rate that gradient descent converges on the task. The authors prove that in order for MAML to achieve substantial gain over NAL, (i) there must be some discrepancy in hardness among the tasks, and (ii) the optimal solutions of the hard tasks must be closely packed with the center far from the center of the easy tasks optimal solutions. They also give numerical and analytical results suggesting that these insights apply to two-layer neural networks. Finally, they provide few-shot image classification experiments that support their insights for when MAMM should be used and emphasize the importance of training MAMl on hard tasks in practice."
SP:e8143c7880c16ee9ce7a544e0fd80f001b1b4f9f,"This paper proposes an unrolled version of the Proximal Alternating Linearized Minimization (PALM) algorithm for sparse source separation (BSS). The proposed method leverages the data-driven knowledge stemming from realistic simulations or ground-truth data by learning both PALM hyperparameters and variables. The paper further emphasizes on the ability to deal with variable mixing matrices (a.k.a. dictionaries) which enables to perform semi-blind source separation, which is key to increase the generalization of the learnt model in real-world applications. The proposed LPALM outperforms other unrolled source separation methods in the semi blind setting."
SP:7716315001949ab88c8a216302fe51bae872fc87,"This paper proposes a novel attention module called implicit self-attention for transformers. The authors argue that transformers exhibit impressive scaling, but their performance hinges on processing large amounts of data, and their computational and memory requirements grow quadratically with sequence length. Motivated by these considerations, the authors propose a Legendre Memory Unit based model that exhibits an O(n) and O(N lnn) dependency for memory and computation respectively. They show that for the same amount of training their model improves the loss over transformers about as much as transformers improve over LSTMs. They also demonstrate that adding global self attention complements their architecture and the augmented model improves performance even further."
SP:832f422b3554e89702e13c8c5690ee26f2289e3b,"This paper proposes LatentKeypointGAN, a two-stage GAN that generates keypoint embeddings for image generation. The keypoints are generated using a GAN-based encoder-decoder architecture, where the encoder encodes the image as a set of keypoints, and the decoder decodes the appearance embedding of each keypoint, which is used to control the position and style of the generated objects and their parts. The paper demonstrates that the generated keypoints can be used to re-arrange the generated images by re-positioning and exchanging keypoints embedding, such as generating portraits by combining the eyes, and mouth from different images. In addition, the paper proposes a new method for unsupervised keypoint detection."
SP:9206ae6e31077569313838504ef6daa89ad3b59c,"This paper studies the problem of representation shrinkage in fully-connected neural networks with layer normalization using the mean field formalism. The authors show that increasing the depth of the network can lead to gradient explosion or representation shrinkages. They also show that the appearance of these problems is not restricted to a specific initialization scheme or a choice of activation function, but rather is an inherent property of the fully-connections architecture itself. They show that many popular normalization techniques fail to mitigate these problems, and propose a method to guide the choice of initialization variances."
SP:2177be818b5843c580c787f1b2d725154846feb6,"This paper proposes a line search method for finding the optimal step size for SGD. The main idea is to approximate the full-batch loss with a parabola estimated over several mini-batches. The learning rates are derived from such parabolas during training. The experiments show that the proposed method outperforms SGD tuned with a piece-wise constant learning rate schedule and other line search approaches for Deep Learning across models, datasets, and batch sizes."
SP:62233782f9046c85617d9ccfe8427eae7d1c9da7,"This paper studies the problem of noise-contrastive estimation (NCE) in the context of unnormalized probabilistic models. In particular, the authors propose a new method called eNCE, which uses an exponential loss and a normalized gradient descent algorithm to address the landscape issues of the original NCE. The authors prove that the landscape of the loss landscape is flat when the target and noise distributions are in a given exponential family. The paper is well-written and well-motivated."
SP:ceba6c1421b2d03863007fdaf029b8b946519c1b,"This paper studies the convergence of distributed SGD under Byzantine fault (DP) and Byzantine resilience (BR) in the context of parameter-server architecture. In particular, the authors consider the case where a fraction of the workers are malicious (Byzantine) and the other fraction are honest (DP). The authors show that the integration of standard practices in DP and BR is not straightforward, and show that many existing results on the convergence under Byzantine faults, especially those relying on Byzantine resilience, are rendered invalid when honest workers enforce DP. To circumvent this shortcoming, the paper revisits the theory of (alpha, f)-BR to obtain an approximate convergence guarantee. The paper also provides insights on how to improve this guarantee through hyperparameter optimization."
SP:bc783f0c829f90931535e63687d13172879631b3,"This paper proposes a method for code editing with few exemplars. The method is based on the composition of the support and query code snippets into abstract syntax trees, which are then used to compose the query code snippet editing via multi-extent similarities ensemble. The authors evaluate the proposed method on C# and Python datasets and show up to 8.6% absolute accuracy improvements compared to non-composition baselines."
SP:ca0c4bdb02f7d939fb6de38b6b446ced4b5984a0,"This paper proposes a generative model for generating high-level structure in a sequence of sequences. The authors propose to use relational constraints between different subcomponents of an example (e.g., lines of a poem or measures of music) to guide the generative process. The proposed model consists of two parts: (i) one model to generate a realistic set of relational constraints, and (ii) a second model that generates realistic data satisfying these constraints. For model (i), the authors propose a program synthesis algorithm that infers the relational constraints present in the training data, and then learn a model based on the resulting constraint data. The experimental results show that the proposed model significantly improves over state-of-the-art in terms of capturing high level structure in the data, while performing comparably or better in the terms of low level structure."
SP:692ae0c583a1585eff1a7d9c0d3b51b7879611cc,"This paper proposes a new method for set-to-hypergraph prediction. The main idea is to train a neural network to predict and supervise the positive edges of the hypergraph. The authors propose to change the asymptotic memory scaling from exponential to linear. They also introduce a training method that encourages iterative refinement of the predicted hypergraph, which allows them to skip iterations in the backward pass for improved efficiency and constant memory usage. Finally, they combine both contributions in a single model that enables them to address problems with larger input set sizes."
SP:e3481fb6d8d1aa45d6ed4a454e781f5a2c30c57e,"This paper proposes a post-processing method to mitigate bias of state-of-the-art models. It consists in learning a shallow neural network, called the Ethical Module, which transforms the deep embeddings of a pre-trained model to give more representation power to the discriminated subgroups. Its training is supervised by the von Mises-Fisher loss, whose hyperparameters allow to control the space allocated to each subgroup in the latent space. Besides being very simple, the resulting methodology is more stable and faster than most current methods of bias mitigation."
SP:3fb5dcc8b8fb731e09c14b16480cada1c7ccfaa7,"This paper proposes a new method for class-incremental learning (CIL) based on placebos. Specifically, the authors propose to use a placebos-based evaluation function to evaluate the quality of candidate images from a free image stream. The authors also propose a reinforcement learning algorithm to sample pseudo CIL tasks from the data in the 0-th phase and train the model on these pseudo tasks. The experimental results show that the proposed method can outperform existing KD-based methods on ImageNet-1k and ImageNet Subset. "
SP:506e0a888c03a955b708464eed3670c04baf4912,"This paper proposes a path auxiliary algorithm for sampling from discrete energy-based models (EBMs). The main idea is to use a composition of local moves to efficiently explore large neighborhoods in EBMs. The authors also propose a fast version of their algorithm that only queries the evaluation of energy function twice for each proposal via linearization of the energy function. Empirically, they show that their path auxiliary algorithms considerably outperform other generic samplers on various discrete models for sampling, inference, and learning. "
SP:4b466277aa5561a80c48d5e72559de4ce95f228b,"This paper proposes Variational Predictive Routing (VPR), a neural probabilistic inference system that organizes latent representations of video features in a temporal hierarchy based on their rates of change, thus modeling continuous data as a hierarchical renewal process. VPR is able to detect event boundaries, disentangle spatiotemporal features across its hierarchy, adapt to the dynamics of the data, and produce accurate timeagnostic rollouts of the future. The proposed approach integrates insights from neuroscience and introduces a framework with high potential for applications in model-based reinforcement learning, where flexible and informative state-space rollouts are of particular interest."
SP:459ef2e6bd7638020955dbb4d8ae1098619f7b95,"This paper proposes a new method for image retrieval that combines global and local features. The proposed method is an end-to-end and single-stage pipeline, which is based on convolutional neural networks (CNNs) and spatial and channel attention. The method is evaluated on the Revisited Oxford and Paris datasets and achieves state-of-the-art performance."
SP:487cc308a1e8ee078c54b2158bcae47e920e73f8,"This paper proposes RotoGrad, a multi-task learning algorithm that jointly homogenizes gradient magnitudes and directions across tasks while ensuring training convergence. The main contribution of this paper is to address the problem of negative transfer, which is the issue of gradient disparities in gradient magnitude and directions when optimizing the shared network parameters. The authors propose a new algorithm that aims to solve this problem jointly by homogenizing gradient magnitude and directions. The proposed algorithm is evaluated on a variety of multi-label classification and computer vision tasks in the NYUv2 dataset. The experimental results show that the proposed algorithm outperforms competing methods."
SP:050cd8319d84a1bd8c2ccb930ba69b33c8fb6e60,"This paper proposes a method to fuse heterogeneous neural networks via cross-layer alignment. The proposed method is based on the idea of model fusion via optimal transport (OTFusion), which uses soft neuron association to unify different pre-trained networks to save computational resources. However, OTFusion requires the input networks to have the same number of layers. To address this issue, the authors propose a novel model fusion framework, named CLAFusion, to fuse neural networks with a different number of hidden layers. The authors propose to use dynamic programming to balance the number of neural networks before applying layer-wise model fusion. Experiments on CIFAR-10 show that the proposed method achieves a more favorable performance compared to the individual networks trained on heterogeneous data without the need for any retraining."
SP:f764eae15cd083fdb4eb2af09ac64c2d878a454f," in this paper is a theoretical analysis of the effect of implicit regularization in deep reinforcement learning (RL) methods. Specifically, the authors show that the implicit regularizer of SGD is harmful in the offline RL setting, leading to poor generalization and degenerate feature representations. To address this issue, they derive the form of this implicit regularized regularizer and, inspired by this derivation, propose a simple and effective explicit regularizer, called DR3, that counteracts the undesirable effects of this implied regularizer. Experiments show that DR3 substantially improves performance and stability, alleviating unlearning in Atari 2600 games and D4RL domains."
SP:6fd793b27123bf80504e2ad5957455b7ec311612,"This paper proposes HyperDQN, an exploration method for deep reinforcement learning (RL) based on Randomized least-square value iteration (RLSVI) with a probabilistic hypermodel (i.e., meta-model) that outputs the parameter of the base model. The hypermodel can generate approximate posterior samples regarding the parameters of the Q-value function, which can be used to select exploration sequences. The proposed method is evaluated on the Atari suite and SuperMarioBros, where it outperforms several exploration bonus methods."
SP:b428383660928374c953f659ea1e05852dbdcd6e,"This paper proposes to learn causal representation from observational data by regularizing the learning procedure with mutual information measures according to a hypothetical causal graph. The authors propose a counterfactual loss, based on which they deduce a theoretical guarantee that the causality-inspired learning is with reduced sample complexity and better generalization ability. Extensive experiments show that the models trained on causal representations learned by the proposed method is robust under adversarial attacks and distribution shift."
SP:1258c05a80a17949b50e6dae13deea1d2235f456,"This paper proposes ProgFed, a progressive training framework for federated learning. It is based on gradient compression and distillation. The authors provide theoretical analysis of the convergence rate of the proposed method and show that it converges at the same asymptotic rate as standard training on full models. Experiments are conducted on a variety of architectures, including CNNs, Resnets, ConvNets, and U-nets, and diverse tasks from simple classification to medical image segmentation."
SP:8cdaa6e0dafd750ebdb5d7a4c1987a042400662f,This paper studies the generalization of adversarial training through the lens of the adversarial Rademacher complexity of deep neural networks. The main contribution of this paper is to provide an upper bound on the adversarially trained weight norms of deep networks. This upper bound is based on the standard analysis of the Rademan complexity of two-layer neural networks up to two layers. The upper bound also includes the product of weight norms. Experiments on MNIST and CIFAR-10 show that the proposed upper bound can explain the poor generalization performance of the trained models. 
SP:925d6bb051e9b384669fb695085b678c11f7c11a,"This paper proposes a differentiable kernel-based estimator for differential entropy. The proposed estimator is based on a kernel based estimator (KNIFE) that is parameterized by a kernel kernel. The authors show that the proposed method can be used to estimate conditional differential entropy and mutual information. Experiments are conducted on a variety of tasks, including visual domain adaptation, textual fair classification, and textual fine-tuning. "
SP:d2f3beac855f0d72c13552fecb2bdb9d42195df3,"This paper proposes a new soft-greedy operator, called resmax, that takes actions proportionally to their suboptimality gap: the residual to the estimated maximal value. It is simple to use and ensures coverage of the state-space, but focuses exploration more on potentially promising actions like softmax. It does not concentrate probability as quickly as softmax, and so better avoids overemphasizing sub-optimal actions that appear high-valued during learning. The authors prove that resmax is a non-expansion for any fixed exploration hyperparameter, unlike the softmax policy which requires a state-action specific temperature to obtain a nonexpansion (called mellowmax)."
SP:792ae8808aa6902758146aef1548c975492b833c,"This paper proposes a new method for controlling the model’s learnability on a specific dataset with a special key. In particular, the authors propose adversarial invertible transformation, that can be viewed as a mapping from image to image, to slightly modify data samples so that they become “unlearnable” by machine learning models with negligible loss of visual features. Meanwhile, one can unlock the learnability of the dataset and train models normally using the corresponding key. The proposed learnability lock leverages class-wise perturbation that applies a universal transformation function on data samples of the same label. This ensures that learnability can be easily restored with a simple inverse transformation while remaining difficult to be detected or reverse-engineered. The experimental results demonstrate the effectiveness of the proposed method on visual classification tasks."
SP:9af10703605e620e563241e2602a50b629f3d37a," for Graph Neural Networks (GNNs) that assume that node or edge features of the graph are available. In many real-world applications, however, features are only partially available. This paper proposes a general approach for handling missing features in graph machine learning applications that is based on minimization of the Dirichlet energy and leads to a diffusion-type differential equation on the graph. The discretization of this equation produces a simple, fast and scalable algorithm which is called Feature Propagation. The proposed method outperforms previous methods on seven common node-classification benchmarks and can withstand surprisingly high rates of missing features."
SP:cbaa3f1379fa99159899d79ccb479c0187403aca,"This paper studies the problem of active learning, which is the process of training a model with limited labeled data by selecting a core subset of an unlabeled data pool to label. The core set is selected by minimizing the discrete Wasserstein distance between the labeled data set and the unlabelled data set. The paper proposes a Generalized Benders Decomposition algorithm to solve this problem. The proposed method is based on unsupervised learning of latent features that can be obtained from unlabeled data. The experimental results show that the proposed method outperforms baselines in the low budget regime."
SP:4c72923f78ca6590dc11e10d1a2403076a583718,This paper proposes a method for de-novo genome assembly based on graph convolutional neural networks. The method is based on the idea of using a graph neural network to reconstruct the genome by finding a path through the assembly graph. The authors show that their method is able to find the correct path in the fraction of time required for the state-of-the-art de novo genome assemblers. The paper is well-written and well-motivated.
SP:24de906e4289c9073b6c55c747b0913b8df5e053,"This paper proposes a meta-learning method for continual learning. The main idea is to use experience replay (ER) in meta-testing and meta-training to improve continual learning representations. The authors propose to store the samples’ representations, instead of the samples themselves, into the replay buffer. This ensures the batch nature of ER does not conflict with the online-aware nature of OML. Moreover, the authors introduce Predictive Sample Selection to replace the widely used reservoir sampling to populate the replay buffers. Experimental results on a number of real-world meta-continual learning benchmark data sets demonstrate that the proposed method outperforms the state-of-the-art."
SP:3c78454f053f74930979a8054cd7c8a34b6fe63d,"This paper proposes a method for multi-agent joint Q-learning based on centralized training with decentralized execution (CTDE). The authors formulate an explicit credit assignment problem where each agent gives its suggestion about how to weight individual Q-values to explicitly maximize the joint Q value. Theoretically, the authors give a gradient ascent solution for this problem. Empirically, they instantiate the core idea with deep neural networks and propose Explicit Credit Assignment Joint Q-Learning (ECAQ) to facilitate multi agent cooperation in complex problems. Extensive experiments justify that ECAQ achieves interpretable credit assignment and superior performance compared to several advanced baselines."
SP:0d2b225ac697679d10df25f371b2a718d4949b42,"This paper studies adversarial robustness of transductive-learning-based defenses. The authors propose a new attack framework called Greedy Model Space Attack (GMSA) that can be used as a baseline to evaluate the effectiveness of adversarial defenses. GMSA is based on the idea of attacking model space for solving bilevel attack objectives, and the authors show that GMSA can break previous defenses, which were resilient to previous attacks, such as AutoAttack. On the other hand, the authors report a somewhat surprising empirical result of “transductive adversarial training”: Adversarially retraining the model using fresh randomness at the test time gives a significant increase in robustness against attacks."
SP:e7024cae196fc5eb6a62d289a95d76b532b6a36c,"This paper studies the problem of batch normalization, which is a popular technique for speeding up the training of neural networks. In particular, the authors consider the case where the entire dataset is normalized jointly, and explore other ways to approximate the gradient from this limiting case. The authors propose two methods: (1) an approximation that removes the need to keep more than one example in memory at any given time, at the cost of a small factor increase in the training step computation, and (2) a fully per-example training procedure which removes the extra computation at a small drop in the final model accuracy. They further use their insights to improve batch renormalization."
SP:4aa42984fcb0fd66936d668477b2719ef5c427d4,"This paper proposes a method for reducing the number of trainable parameters in language model fine-tuning. The main idea is to freeze the pretrained model weights and inject the trainable rank decomposition matrices into each layer of the Transformer architecture. The authors compare the proposed method with Adam and show that it can reduce the total number of parameters by 10,000 times and the GPU memory requirement by 3 times. They also provide an empirical investigation into rank-deficiency for language model adaptation."
SP:b77a00beb0802f47810b03d3c4aa24d92781414f,"This paper proposes a regular-constrained linear-chain conditional random field (RegCCRF) that can enforce a broad class of constraints, including nonlocal ones, by specifying the space of possible output structures as a regular language L. RegCCRF has the same formal properties as a standard CRF, but assigns zero probability to all label sequences not in L. The authors prove that constrained training is never worse than constrained decoding, and show empirically that it can be substantially better in practice. They demonstrate a practical benefit on downstream tasks such as semantic role labeling."
SP:74c186a96c12adff178264aa84ace8d04dc7d725,"This paper proposes two neural models for camera-based physiological measurement called EfficientPhys that remove the need for face detection, segmentation, normalization, color space transformation or any other preprocessing steps. The proposed models achieve state-of-the-art accuracy on three public datasets. The authors also evaluate the latency of the proposed networks and show that their most light weight network also achieves a 33% improvement in efficiency."
SP:3003bab6e3f7e2e21cd6cf27ee7d483d877d9fb3,"This paper proposes Hardware-Aware Latency Pruning (HALP) that formulates structural pruning as a global resource allocation optimization problem, aiming at maximizing the accuracy while constraining latency under a predefined budget. The paper leverages latency lookup table to track latency reduction potential and global saliency score to gauge accuracy drop. This makes the problem solvable via an augmented knapsack solver, enabling HALP to surpass prior work in pruning efficacy and accuracy-efficiency trade-off."
SP:c44d676c09c8e5a70d73b21b507b41a422fec809,"This paper proposes GraphEBM, a molecular graph generation method via energy-based models (EBMs) to perform permutation-invariant and multi-objective molecule generation. The authors propose to learn the energy function by contrastive divergence and generate samples by Langevin dynamics. To generate molecules with a specific desirable property, the authors propose a simple yet effective learning strategy, which pushes down energies with flexible degrees according to the properties of corresponding molecules. The experimental results on random, single, and multi objective generation tasks demonstrate the effectiveness of the proposed method."
SP:70e60fa5deef3e3ba77d05d0c3e0e7fbf396aa1d,"This paper proposes a method for bottom-up program synthesis, where the goal is to find programs that satisfy a given specification. The authors propose to use a neural model to guide the search policy, which is trained on a set of previously searched programs. The neural model is trained to learn how to combine previously explored programs into new programs, taking into account the search history and partial program executions. The proposed method is evaluated on string manipulation and logic programming tasks, where it is shown to outperform the state-of-the-art."
SP:daa044ffefe80bae16b014f60061d941ed8c2ba6,"This paper proposes to replace the standard squared Bellman error in deep reinforcement learning with a functional regularizer. The proposed method is based on the idea of target networks, where the target network is used to stabilize training by using an additional set of lagging parameters. The authors argue that target networks can inhibit the propagation of newly-encountered rewards which may ultimately slow down training. To address this issue, the authors propose to use an explicit regularizer that allows to use up-to-date parameters as well as control the regularization. This leads to a faster yet more stable training method. The experimental results show that the proposed method outperforms target-network based methods in terms of both sample efficiency and performance."
SP:dd174014d056a7d2bc86ee99119841eafa62ed52,"This paper proposes a new approach to designing graph neural networks (GNNs) that is more expressive than the Weisfeiler Lehman test in distinguishing graph structures. Specifically, the authors propose a new hierarchy of local isomorphism on neighborhood subgraphs, which allows for a message-passing aggregation scheme of GNNs to be more expressive. The authors also propose a novel neural model, called GraphSNN, and prove that this model is strictly more expressive in distinguishing graphs. The experimental results on different graph learning tasks demonstrate the effectiveness of the proposed method."
SP:beb9ba0261e176bfc50e9bf5bed2b6169d388285,"This paper proposes a novel prediction interval (PI) method for uncertainty quantification, which addresses three major issues with the state-of-the-art PI methods. First, existing PI methods require retraining of neural networks (NNs) for every given confidence level and suffer from the crossing issue in calculating multiple PIs. Second, they usually rely on customized loss functions with extra sensitive hyperparameters for which fine tuning is required to achieve a well-calibrated PI. Third, the authors usually underestimate uncertainties of out of distribution (OOD) samples leading to over-confident PI. The proposed PI3NN method calculates PIs from linear combinations of three NNs, each of which is independently trained using the standard mean squared error loss."
SP:4b44a834e2212bacb4c2d9408a81f1efc76a670b,"This paper proposes a meta-learning method for online learning of deep neural networks. The main idea is to meta-train the model to adapt to changing tasks and input distributions and meta-training the model in order to adapt more quickly in the future. The authors propose a fully online meta learning (FOML) algorithm, which does not require any ground truth knowledge about the task boundaries and stays fully online without resetting back to pretrained weights. The experiments show that FOML was able to learn new tasks faster than the state-of-the-art online learning methods on Rainbow-MNIST, and CIFAR100 datasets."
SP:fbae35cb171b3a3eb7c5d4bc83881ed7c4a70aae,"This paper proposes a differentiable scaffolding tree (DST) method for molecular optimization. DST uses a learned knowledge network to convert discrete chemical structures to locally differentiable ones. In particular, DST enables a gradient-based optimization on a chemical graph structure by back-propagating the derivatives from the target properties through a graph neural network (GNN). The experiments show that DST is both effective and sample efficient."
SP:61b59899cf6ae442d9f8f5226e79708a4280cfb2,This paper proposes a knowledge-augmented approach to predict the response of a patient to a target lab test result. The approach is based on the idea of learning a graph representation of the drug-lab interaction and the diagnosis-lab interactions as graphs. The proposed method is evaluated on two real-world datasets and compared with two baselines. The results show that the proposed method outperforms the baselines in terms of accuracy.
SP:8623cebb515c4a736427449b46ad2cdf8b806b77,This paper proposes an open-set single-domain generalization (OS-SDG) method for domain generalization. The authors propose a CrossMatch approach to improve the performance of SDG methods on identifying unknown classes by leveraging a multi-binary classifier. CrossMatch generates auxiliary samples out of source label space by using an adversarial data augmentation strategy. They also adopt a consistency regularization on generated auxiliary samples between multibinary classifiers and the model trained by SDG models. Experimental results on benchmark datasets prove the effectiveness of CrossMatch on enhancing the performance.
SP:126f8ffb855aa22eda4d681a499953879ed3679e,"This paper proposes two extensions of trust-region methods based on Kullback-Leibler divergence for policy optimization in reinforcement learning, namely Wasserstein Policy Optimization (WPO) and Sinkhorn Policy Optimisation (SPO). The main idea is to directly optimize the policy distribution and derive their close-form policy updates based on the Lagrangian duality. Theoretically, they show that WPO guarantees a monotonic performance improvement, and SPO provably converges to WPO as the entropic regularizer diminishes. Experiments across tabular domains and robotic locomotion tasks demonstrate the performance improvement of both approaches."
SP:999eacf6500c87205584a3256d7ca45b3016fb1c,"This paper proposes a forget-and-relearn framework for improving the learning trajectory of neural networks. The idea is that the forgetting step selectively removes undesirable information from the model, and the relearning step reinforces features that are consistently useful under different conditions. The forgetting step is a combination of two steps: (1) removing undesirable information, and (2) re-training the model with the relearned features. The authors provide a unified analysis of existing iterative training algorithms in the image classification and language emergence literature, and show that the success of these algorithms in terms of the disproportionate forgetting of undesirable information. They leverage this understanding to improve upon existing algorithms by designing more targeted forgetting operations."
SP:2789859517b6624730b14a7e010444a72d3dd3ed,"This paper proposes an offline-online setting where the agent has access to a batch of data to train on but is also allowed to learn during the evaluation phase in an online manner. This is an extension to batch RL, allowing the agent to adapt to new situations without having to precommit to a policy. The authors show that standard RL agents trained in an offline or online manner can outperform agents trained only offline or offline-only."
SP:76625a25e770415599a34122110d61cb3b7e614c,"This paper studies the problem of domain generalization (DG) by learning to reduce domain shift with an episodic training procedure. In particular, the authors propose to learn to optimize Y-discrepancy between the unseen target domain and source domains only using source-domain samples. Theoretically, they give a PAC-style generalization bound for discrepancy-optimal meta-learning and further make comparisons with other DG bounds including ERM and domain-invariant learning. Empirically, the algorithm with DomainBed achieves state-of-the-art results on two DG benchmarks. The theoretical results also shed light on a bilevel optimization algorithm for DG."
SP:6421a9759c766641fd8c128a249f1a9c5699d19c,"This paper studies the role of policy and value networks in best-first search for Sokoban planning problems in the context of deep reinforcement learning (DNN) based search algorithms. The authors propose an abstract tree model to explain the existence of left heavy tails and propose an algorithm to avoid exploring exponentially large sub-trees. The experiments show the importance of the policy network as a guiding heuristic guiding the search, which can lead to left heavy tail with polynomial scaling by avoiding exploring exponentially sized sub-Trees. "
SP:84c415bc0f120d1997289f91661ff74e7297d3bd,"This paper proposes a method for meta-imitation learning from video demonstrations from humans. The method is based on the idea of meta-learning from human demonstrations, which is similar to human imitation learning. The main difference is that the method only relies on human videos and does not require robot demonstration, which facilitates data collection and is more in line with human imitation behavior. Experiments show that the proposed method achieves comparable performance to the baseline on fast learning a set of vision-based tasks through watching a single video demonstration."
SP:fedf5c75e83d6ab41ef9d5daa9054ffe4e424ec2,"This paper studies the problem of over-parameterized deep neural networks trained using gradient-based optimizers. The authors argue that, without appropriately tuned regularization, such networks have the tendency to make output scores (logits) and network weights large, causing training loss to become too small and the network to lose its adaptivity (ability to move around and escape regions of poor generalization) in the weight space. Adaptive optimizers like Adam, being aggressive at optimizing the train loss, are particularly affected by this."
SP:819df8d847a99f13ed5efdcabae8b464c12b464b,"This paper proposes a method for group equivariant convolutional neural networks (G-CNNs) that is able to learn partial and full equivariances from data at every layer end-to-end. In particular, the authors propose a family of G-CNN models that can learn partial equivariance when necessary, and full-equivariance if not necessary. The method is evaluated on MNIST, 6/9 classification, and natural image classification. "
SP:0c0ca9df96f1fa2eb8b83a47d0d5964590fef290,"This paper proposes an amortized Langevin dynamics (ALD) method for deep latent variable models. ALD replaces the datapoint-wise MCMC iterations with updates of an inference model that maps observations into latent variables. The authors prove that ALD has the target posterior as a stationary distribution under some assumptions, and can be extended to sampling from an unconditional distribution such as an energy-based model, enabling more flexible generative modeling by applying it to the prior distribution of the latent variable. Based on ALD, the authors construct a new deep latent variables model named the Langevin autoencoder (LAE) which uses ALD for autoencoders-like posterior inference and sampling from the latent space EBM."
SP:5631097031c7e599bdeae64366ffa6e4558837c6,"This paper proposes a novel method for hypergraph reasoning based on neural networks and finite-domain quantification operations. The proposed method is motivated by the observation that in logical reasoning, logical rules usually apply locally (e.g., only three people are involved in a grandparent rule), and sparsely (e,g., the grandparent relationship is sparse across all pairs of people in the world). To leverage the sparsity in hypergraph neural networks, the proposed method represents the grounding of relationships such as parent and grandparent as sparse tensors and uses neural networks to infer new facts based on the input. The authors also introduce a sparsification loss to regularize the number of hyperedges in intermediate layers of a SpaLoc model. To enable training on large-scale graphs such as real-world knowledge graphs, SpaLoc makes training and inference-time sub-sampling of the input graphs. To remedy the information loss in sampled sub-graphs, the authors propose a novel sampling and label calibration paradigm based on an information-theoretic measure information sufficiency."
SP:9657121b01c51f78c00d06b47d3e8d678dd85d54,"This paper proposes to relax the top-k classification accuracy, where k is conventionally a positive integer, such as 1 or 5. The authors propose to draw k from a probability distribution for training, and propose a new family of differentiable top k cross-entropy classification losses. They find that relaxing k does not only produce better top-5 accuracies, but also makes models more robust, which leads to top-1 accuracy improvements."
SP:cb3188f435c54a365890e20e4d582c250d919833,"This paper proposes a new method for solving large-scale optimal transport (OT) problems at an unprecedented combination of speed and accuracy. The proposed method is based on the Douglas-Rachford splitting technique, which tackles the original OT problem directly instead of solving an approximate regularized problem, as many state-of-the-art techniques do. This allows to provide sparse transport plans and avoid numerical issues of methods that use entropic regularization. The algorithm has the same cost per iteration as the popular Sinkhorn method, and each iteration can be executed efficiently, in parallel. In addition, the authors establish a linear convergence rate for the formulation of the OT problem and provide an efficient GPU implementation."
SP:9a087cc734a3e7f3ab848bef5e2eff37fe40f303,"This paper proposes a framework for disentangling performance gaps in federated learning. The main idea is to separate performance gaps from unseen client data (out-of-sample gap) from performance gap from unseen clients distributions (participation gap). The authors propose a dataset synthesis strategy that enables realistic simulation without naturally-partitioned data. The authors observe and explain differences in behavior across natural and synthetic federated datasets, indicating that dataset synthesis can be important for realistic simulations."
SP:da0e8c89f343abfe500eb4c1968e418c2fb52ef6,"This paper studies the few-shot prompt-based language modeling in the zero-shot setting. The authors propose a simple multi-null prompting strategy to improve the performance of pre-trained language models (PLMs) in the few shot setting. In particular, the authors use 3 models from the most popular BERT family to launch the empirical study on 20 different datasets. They are surprised to find that a simple Multi-Null Prompting (without manually/automatically created prompts) strategy can yield very promising results on a few widely-used datasets, e.g., 86.59%(±0.59) accuracy on the IMDB dataset, and 86.22% (±2.71) accuracy  on the Amazon dataset, which outperforms manually created prompts without engineering in achieving much better and stable performance. However, they also observe some limitations of PLMs under the zero shot setting, particularly for the language understanding tasks (e.g. GLUE)."
SP:9817dccb1a121058b23a2ef825ed339cf8b53674,This paper proposes a method to improve the performance of the attention mechanism in image recognition tasks. The proposed method is based on a sharpener module that aims to align the relevant parts of the encoded image with the target output. The authors claim that the proposed method can improve the alignment and interpretability of attention mechanism. Experiments on synthetic handwritten digits and real-world scene text recognition datasets show that their approach outperforms the mainstream methods such as soft and hard attention.
SP:3913ed3b3cf6494368e3be6cacb637ff85f80ee6,"This paper proposes a reinforcement learning-based approach for vehicle routing problems. The proposed method is based on the idea of learning a tour plan for a fixed number of vehicles. The authors propose a supervised learning framework that constructs a complete tour plan from scratch while respecting an apriori given number of available vehicles. In addition, the authors propose an efficient post-processing scheme to improve the performance of the learned tour plan. Experiments are conducted on a real-world vehicle routing problem and show the effectiveness of the proposed method."
SP:594a813c0d0baa66738b9c8331370f861ad3c416,"This paper proposes a novel method for link prediction based on counterfactual inference. The idea is to learn the causal relationship between two sets of variables: the observed graph structure (e.g., clustering effect) and the existence of link between a pair of nodes. The proposed method learns representations from both the observed and counterfactually links. Experiments on benchmark datasets show that the proposed method achieves state-of-the-art performance on link prediction."
SP:48a7e50451b887f55be17b2662aa11ce18791cc1,"This paper proposes a two-stage unsupervised feature selection method based on knowledge contrastive disTillation (SOFT) model that incorporates the second-order covariance matrix with the first-order data matrix for feature selection. In the first stage, SOFT learns a sparse attention matrix that can represent second order relations between features, and in the second stage, it builds a relational graph based on the learned attention matrix and performs graph segmentation for feature selector. Experimental results on 12 public datasets show that SOFT outperforms classical and recent state-of-the-art methods, which demonstrates the effectiveness of SOFT."
SP:14bcae11aeede63f28d1b80c05ed18a01d3e3f3c,"This paper proposes a semi-supervised multi-modal variational autoencoder (MEME) that combines information between modalities implicitly through mutual supervision. The idea is to use a semisupervised VAE to model the joint distribution over heterogeneous data (e.g. vision, language), while also capturing a shared representation across such modalities. This formulation naturally allows learning from partially-observed data where some modalities can be entirely missing. The authors demonstrate that MEME outperforms baselines on standard metrics across both partial and complete observation schemes on the MNIST-SVHN (image–image) and CUB (image-text) datasets."
SP:e834a52cadebe5f125ce491273b4ad1146beae3f,"This paper proposes Deep Explore Options, an extension of Explore Options to tackle complex visual problems. Explore Options is an alternative to the widespread method of a weighted sum of rewards, where the agent calls an intrinsically motivated agent in order to observe and learn from interesting behaviors in the environment. The authors propose to use intrinsic reward learning as an auxiliary task, with a resulting architecture achieving 50% faster wall-clock speed and building a stronger, shared representation. The experiments are conducted on Atari Suite, following a benchmarking study to ensure fairness. "
SP:41578dd1a4bdb043b3d68afa5f9cebb3e14f3907,This paper proposes a new method for learning Hamiltonian dynamical systems from data. The authors propose a new neural network architecture called stiffness-aware neural network (SANN) that splits the training data into stiff and non-stiff portions based on a stiffness-awareness index. The proposed method is evaluated on a three-body problem and a billiard model and shows that SANN is more stable and can better preserve energy when compared with the state-of-the-art methods.
SP:bfb0a059eeb6f40a18fbd20c0eec5037a64ca09e,"This paper presents a method for training Transformer-based language models to perform multi-step computations. In particular, the authors train Transformers to emit intermediate computation steps into a “scratchpad” and show that this improves the performance of language models on long addition and execution of arbitrary programs. The paper is well-written and well-motivated, and the experimental results are interesting."
SP:e6c1a8b4bba287455dc9cf145b6bd1f04e2148a9,"This paper proposes a novel adversarial attack method that uses deep image generators to generate adversarial perturbations that are interpretable, universal to any source image, and physically-realizable. The authors also propose a novel optimization objective for the adversarial attacks, which they call featurefool attacks. They show that the proposed method can be used to generate targeted feature-level attacks at the ImageNet scale that are simultaneously interpretable and universal to all source images, and can also reveal spurious, semantically-describable feature/class associations that can be exploited by novel combinations of natural objects."
SP:873618263dc4246a39c44d0abfecfb5f688817e3,"This paper proposes a reinforcement learning-based algorithm for simulated annealing (SA) based on reinforcement learning. Specifically, the authors propose to learn the proposal distribution of the proposed temperature anneal schedule for a given problem. The proposed method is evaluated on a variety of problems including Rosenbrock’s function, the Knapsack problem, the Bin Packing problem, and the Travelling Salesperson problem. It is shown that the proposed method outperforms the state-of-the-art baselines on these problems."
SP:cae31f7436920eb3946e3f5bca0ac88a73d7c3ec,"This paper studies the problem of non-stationarity in cooperative multi-agent reinforcement learning (MARL). The authors propose a new metric, called the “δ-stability”, which measures the divergence of the joint policies of the agents. The authors show that the divergence is bounded by the KL-divergence of consecutive joint policies, and propose a trust-region decomposition network (TRD-Net) based on message passing to estimate the joint policy divergence more accurately. The proposed algorithm MAMT can approximately constrain the consecutive joint joint policies’ divergence to satisfy the $\delta-stationary” metric. The experimental results show the effectiveness of the proposed algorithm."
SP:989b58167a15ae4fafbe27ff534d327991b6c4d7,"This paper proposes a self-supervised representation learning framework for audio-visual speech. The proposed method, AV-HuBERT, learns a multi-modal representation of audio and visual speech, which can be used for both lip-reading and speech recognition tasks. The method is evaluated on the LRS3 lip reading dataset, where it achieves 32.5% WER with only 30 hours of labeled data, outperforming the previous state-of-the-art approach (33.6%) trained with a thousand times more transcribed video data (31K hours) (Makino et al., 2019). The lip reading WER is further reduced to 26.9% when using all the labeled data from LRS2 and combined with self-training. On the audio-only speech recognition dataset, the proposed method achieves a 40% relative WER reduction."
SP:7c9eb8aa4a4dcb5965157d860e812d81654e3aa7,"This paper proposes a novel reinforcement learning algorithm for combinatorial optimisation on graphs. The main idea is to restrict the GNN to a single pre-processing step, before entering a fast-acting exploratory phase directed by a recurrent unit. Experiments on the Maximum Cut problem show that the proposed algorithm ECORD achieves a new SOTA for RL algorithms on the maximum cut problem, while also providing orders of magnitude improvement in speed and scalability."
SP:f741d980c9c560a21298e947f1605dcbab7ceeac,"This paper proposes to train VAEs with discrete latents by using a variational variational autoencoder (VAE) with truncated posteriors and evolutionary algorithms. In particular, the authors propose to train the VAE with discrete latent variables by optimizing the weights of the encoder and decoder separately. The authors show that the proposed method is more efficient than amortized VAE training, and that it is competitive in zero-shot learning. They also show that VAE can be trained without sampling approximation and reparameterization."
SP:deb189d37bd51b92762ce259a106d9a9e9d81ea4,"This paper proposes a method to identify controllable aspects of the environment using counterfactual measures of blame. The proposed method, Controlled Effect Network (CEN), is an unsupervised method based on Counterfactual Measures of Blame (CMB) to identify effects on the environment controlled by the agent. CEN is evaluated in a wide range of environments showing that it can accurately identify controlled effects. Moreover, the authors demonstrate CEN’s capabilities as intrinsic motivator by integrating it in the state-of-the-art exploration method, achieving substantially better performance than action-prediction models."
SP:ea18d57904e25fd09ed0f6c9972029d78779a8a6,"This paper proposes a pruning method for lightweight image super-resolution networks (SRNets). The proposed method is based on the idea of structure-regularized pruning (SRP), which imposes regularization on the pruned structure to make sure the locations of pruned filters are aligned across different layers. To transfer the expressive power in the unimportant filters to the rest of the network, the authors employ L2 regularization to drive the weights towards zero so that eventually their absence will cause minimal performance degradation. The authors apply SRP to train efficient image SR networks, resulting in a lightweight network SRPN-L and a very deep one SRPN."
SP:0dee45001ae9600f485614dfe6874a516ac01db5,"This paper proposes a novel method for few-shot learning based on contrastive learning and feature selection. The idea is to train a feature extracting backbone with the contrastive loss on the base category data and a masking module to select relevant features that are more suited to target domain classification. Finally, a classifier is fine-tuned along with the backbone such that the backbone produces features similar to the relevant ones. The proposed method is evaluated on a recently introduced cross-domain few shot learning benchmark. The experimental results demonstrate that the proposed method outperforms all meta-learning approaches and produces competitive results against recent cross- domain methods."
SP:92aa611d71a8da597358330d84fddbb90de2cf4f,"This paper studies the generalization properties of neural networks trained by Bayesian inference and finite width networks trained with gradient descent. The authors propose a new technical tools to both analytically bound and consistently estimate the average test error of the neural network–Gaussian process (NNGP) posterior. This error is found to be already better than chance, corroborating the findings of Valle-Pérez et al. (2019) and underscoring the importance of architecture. Further, this paper finds that test performance can be substantially improved by selecting a function with much larger margin than is typical under the NNGP posterior."
SP:a0e3cf719a95bbc5aad2f663ba5a3169c316ee9b,"This paper proposes a method for cross-lingual manifold mixup (X-Mixup) that adaptively calibrates the representation discrepancy and gives compromised representations for target languages. Experiments on the XTREME benchmark show that X-mixup achieves 1.8% performance gains on multiple text understanding tasks, compared with strong baselines, and reduces the crosslingual representation discrepancy significantly."
SP:19f8cd8f0c274b6141ba097d2ebb6d18af0986fd,"This paper studies the problem of Byzantine robust distributed federated learning, where the data distribution is heterogeneous (i.e., not iid). The authors propose a new attack method, bucketing, to circumvent the existing Byzantine robust defenses. The main idea is to adapt existing robust algorithms to the heterogeneous data distribution. The authors prove the convergence of the proposed bucketing algorithm under the assumption that the data is not identical. They also provide theoretical analysis of the convergence rate of bucketing and show that it converges to a state-of-the-art rate. Finally, they show that bucketing can be combined with existing algorithms to defend against Byzantine robust attacks."
SP:4d63513b9a1b9b9fc44a69b3d5679a8f48eb95e7,"This paper studies the relationship between disentanglement and multi-task learning based on hard parameter sharing. The authors perform a thorough empirical study of the representations obtained by neural networks trained on automatically generated supervised tasks. Using a set of standard metrics, the authors show that disentangled representations appear naturally during the process of multi- task neural network training."
SP:9851adb72e2918780f661f83f7da06eb866787be,"This paper proposes a framework of certifying robust policies (CROP) for reinforcement learning against adversarial state perturbations, which provides state level robustness certification and the first certification for cumulative rewards. Specifically, the authors propose a local smoothing algorithm that uses a policy derived from Q-functions smoothed with Gaussian noise over each encountered state to guarantee the robustness of actions taken along this trajectory. They also propose a global smoothing method for certifying the cumulative reward under adversarial attacks. Finally, they evaluate methods that have previously been shown to yield empirically robust RL, including adversarial training and several forms of regularization, on three representative Atari games."
SP:78da3c97182ec1baf6a131740bf7c91a9afb2fd2,"This paper proposes a new approach to conformal prediction, which aims to output a precise set of promising prediction candidates that is guaranteed to contain a limited number of incorrect answers. The authors propose to trade coverage for precision by enforcing that the presence of incorrect candidates in the predicted conformal sets (i.e., the total number of false positives) is bounded according to a user-specified tolerance. Subject to this constraint, the proposed algorithm then optimizes for a generalized notion of set coverage that allows for any number of true answers for a given query (including zero). The authors demonstrate the effectiveness of this approach across several classification tasks in natural language processing, computer vision, and computational chemistry."
SP:b126d2f3c397633745c8833e22ace93a2470e963,"This paper studies the effect of depth and depth depth on the length of the output curve of a ReLU network. The authors prove that the expected length distortion does not grow with depth, and indeed shrinks slightly, for ReLU networks with standard random initialization. They also generalize this result by proving upper bounds both for higher moments of the length distortion and for the distortion of higher-dimensional volumes. The theoretical results are corroborated by experiments."
SP:b3b6d0512edfca461ea295ee8665f7f226c45d57,"This paper proposes SAFEty skill pRiors (SAFER), a behavioral prior learning algorithm that accelerates policy learning on complex control tasks, under safety constraints. SAFER learns to extract a safety variable from offline data that encodes safety requirements, as well as the safe primitive skills over abstract actions in different scenarios. In the inference stage, SAFER composes a safe and successful policy from the safety skills according to the inferred safety variable and abstract action. The proposed method is evaluated on several complex safety-critical robotic grasping tasks inspired by the game Operation, in which SAFER outperforms baseline methods."
SP:a5dadb3ecc3caed3b9d9a68eda0d48a53c2d1ce2,"This paper proposes a multi-branch neural network architecture for image restoration. The proposed architecture is based on the Retinal Ganglion Cells (RGC) model, which is inspired by the human visual system. The authors show that the proposed architecture can achieve state-of-the-art results on four image restoration tasks, including image dehazing, deraindrop, deblurring, and deblurring. The experiments are conducted on four datasets, and the proposed method is evaluated on three restoration tasks."
SP:263b386beee44b0b45b6f6dc3cf80d020500be62,"This paper proposes a new federated learning method, called IT-PFL-HN, which is based on a hypernetwork module and an encoder module. The idea is that the encoder network learns a representation for a client given its unlabeled data. The representation is fed to the hypernetwork that generates a personalized model for that client. The proposed method is evaluated on four benchmark datasets and compared with the state-of-the-art."
SP:960d0a63a82593f6e72275b65f0501f0469d1924,This paper presents a method for visualizing representations learned by self-supervised models. The method is based on a conditional diffusion based generative model (RCDM). The authors show that the generated images are not always invariant to the data augmentation they were trained on. They also show that SSL representations are more robust to small adversarial perturbations of their inputs.
SP:398899e6c86b4a2a17dfa5c2f4478811f4331c1d,"This paper studies the problem of differentially private streaming algorithms for frequency moments estimation. The main contribution of this paper is to prove that Fp sketch, a well-celebrated streaming algorithm for frequency moment estimation, is differentially privacy as is when p \in (0, 1). The authors show that the algorithm is exponentially better than existing DP baselines and only worse than the optimal non-private baseline by a logarithmic factor. The evaluation shows that the proposed algorithm can achieve reasonable accuracy with differential privacy."
SP:3253b13851b5a3b5e3c8c6e24891db05903a4e57,"This paper proposes a reward-switching policy optimization (RSPO) method for finding novel policies that are both locally optimal and sufficiently different from existing ones. The authors propose to switch between extrinsic and intrinsic rewards via a trajectory-based novelty measurement during the optimization process to encourage the learning policy to consistently converge towards a previously undiscovered local optimum. Experiments show that RSPO is able to discover a wide spectrum of strategies in a variety of domains, ranging from single agent particle-world tasks and MuJoCo continuous control to multi-agent stag-hunt games and StarCraftII challenges."
SP:e3ab3aa87ab023bd9949b99a17d4b6e26c1473c0,This paper proposes a method for fast sampling for diffusion models. The main idea is to use gradient-based gradient descent to search for the best sample quality of the diffusion model. This is achieved by optimizing the degrees of freedom of diffusion models by maximizing sample quality scores via gradient descent. The method is evaluated on unconditional image generation on the LSUN dataset.
SP:7a7506f2b5500a573c0cfb8b0822e5ea725c886a,"This paper proposes a new model, called P-Adapters, which is a lightweight model that sits between the embedding layer and the first attention layer of Large Language Models (LLMs). The P-adapters take LLM embeddings as input and output continuous prompts that are used to query the LLM. The authors also investigate Mixture of Experts (MoE) models that learn a set of continuous prompts (“experts”) and select one of them as the prompt to query. They show that the PAdapters show between 12-26% absolute improvement in precision and 36-50% improvement in consistency over a baseline of only using natural language queries."
SP:35cdf71f027cc5168b55cc34c64bfb2f3087d6f5,"This paper proposes a method for continuous classification of time series (CCTS) based on adaptive multi-distribution extraction policy. The authors define CCTS as a continual learning task with the unclear distribution division and propose a novel Adaptive model training policy ACCTS to overcome two main problems: catastrophic forgetting and overfitting. In addition, the authors also propose an importance-based replay policy that only replays the important samples adaptive to the contribution of data to the model. Experiments on four real-world datasets show that the proposed method can classify more accurately than all baselines."
SP:d9b74b749aa465496763d3a3a9bf3a53e800587e,"This paper proposes a memory-based language model that can read and memorize new data at inference time, thus acquiring new knowledge immediately. The authors propose a kNN-based approach to memorize the internal representations of past inputs. They demonstrate that an approximate kNN lookup into the memory improves language modeling across various benchmarks and tasks, including generic webtext (C4), math papers (arXiv), books (PG-19), code (Github), and formal theorems (Isabelle). They show that the performance steadily improves when they increase the size of memory up to 131k tokens."
SP:7a1bbf86c3fdb8738aa826ca330493e857d050ba,"This paper proposes a sampling scheme based on Metropolis-Hastings Monte Carlo algorithm to generate samples from the same masked language modeling (MLM) objective. The authors interpret MLMs as energy-based sequence models and propose two energy parametrizations derived from the trained MLMs. The proposed sampling scheme is based on the Metropolis–hastings sampling scheme. The paper shows that the proposed sampling algorithm can generate samples with better quality than other recently proposed undirected generation approaches (Wang and Cho, 2019; Ghazvininejad et al., 2019). "
SP:011626ba4fafee13d4a30e3f13c1df5b7071a7f1,"This paper proposes a novel reward function for learning data augmentation policy for NLP tasks. The authors propose to jointly optimize a data augmentation policy while training the model, to construct the augmented samples with low confidence but a high semantic similarity with original ones. In addition, they introduce a sample re-weighting scheme to focus on difficult augmented samples after the original ones are learned confidently for more effective learning from the augmented ones. The learning-based augmentation outperforms the state-of-the-art augmentation schemes on various text classification tasks and GLUE benchmark by successfully discovering the effective augmentations for each task."
SP:69d41a862ea189f72d4e8af2854e27b95a91fa41,This paper proposes a novel meta-learning algorithm for offline reinforcement learning. The authors propose to use contrastive learning and intra-task attention to improve the robustness of task representation learning against sparse reward and distribution shift. Theoretical analysis and experiments are presented to demonstrate the superior performance of the proposed algorithm compared to model-free methods.
SP:ed86c60850d5c8302dcf1c2167db303e778fe681,"This paper proposes a method for modeling the belief state of a partially observable Markov system, given sample-access to its dynamics model. The authors propose an inference-time improvement framework for parametric sequential generative modeling methods called belief fine-tuning (BFT). BFT leverages approximate dynamic programming in the form of fine-tuneing to determine the model parameters at each time step. It can improve the accuracy of the belief model at test time because it specializes the capacity of the model to the space of local observations. BFT enables, for the first time, approximate public belief state search in imperfect-information games where the number of possible information states is too large."
SP:6150725599c10f0e26f0d7cb1fc04b5b227a4456,"This paper proposes a new method for sparsifying neural networks. The proposed method, Pixelated Butterfly, is based on flat block butterfly and low-rank matrices to sparsify most network layers (e.g., attention, MLP). The paper also proposes two variants of butterfly matrices (block and flat) to take advantage of modern hardware. Experiments on ImageNet classification and WikiText-103 language modeling tasks show that the proposed method can train up to 2.5x faster than dense MLP-Mixer, Vision Transformer, and GPT-2 medium with no drop in accuracy."
SP:136e31054a55abca840f6478491972023c2296cb,"This paper proposes a novel conditional diffusion probabilistic model for conditional image generation. The proposed method is based on the class clustering phenomenon. The authors propose to explicitly model the class center in the forward and reverse process, which enables controllable generation and gets interpretability. They also provide another direction for faster sampling and more analysis of their method. The experimental results on CIFAR-10 show that the proposed method achieves competitive results compared with the state-of-the-art methods."
SP:fc2196f1f4ecd864398fed6640ff3f8b19870763,"-based domain generalization (DG) approaches often rely on the assumption of fixed domain-invariant features and common hypotheses learned from a set of training domains. The authors argue that this assumption could be overly strict and sub-optimal when source domains share little information or the target domains leverages information from selective source domains in a compositional way instead of relying on a unique invariant hypothesis across all source domains. Instead, the authors propose a LASSO method that explores diverse latent sub-spaces and learns individual hypotheses on those sub-space. Moreover, the latent subspaces are formed by the label-informative features captured in source domains, which allows us to project target examples onto appropriate sub-Spaces while preserving crucial label-information features for the label prediction task. Empirical evaluation on several well-known DG benchmarks shows that the proposed method achieves state-of-the-art results."
SP:6e8e5bdeb77e3cafe1975da8411fb65118955d14,"This paper studies the kernel thinning (KT) algorithm of Dwivedi and Mackey (2021) which compresses a probability distribution more effectively than independent sampling by targeting a reproducing kernel Hilbert space (RKHS) and leveraging a less smooth squareroot kernel. The authors show that KT applied directly to the target RKHS yields tighter, dimension-free guarantees for any kernel, any distribution, and any fixed function in the RkHS. They show that, for analytic kernels like Gaussian, inverse multiquadric, and sinc, target KT admits maximum mean discrepancy (MMD) guarantees comparable to or better than those of square-root KT without making explicit use of a square root kernel. They also prove that KT with a fractional power kernel yields better-than-Monte-Carlo MMD guarantees for non-smooth kernels, like Laplace and Matérn, that do not have square-roots. Finally, they establish that KT+ can be applied to a sum of target and power kernels (a procedure called KT+) simultaneously inherits the improved MMD guarantee of power KT and the tighter individual function guarantees of target KT."
SP:645c3f1864aa843d4899fc2406f694b5aab8460d,"This paper presents an open-source benchmark suite for the NP-hard MAXIMUM INDEPENDENT SET problem, in both its weighted and unweighted variants. The suite offers a unified interface to various state-of-the-art traditional and machine learning-based solvers. The authors conduct an in-depth analysis of the popular guided tree search algorithm by Li et al [NeurIPS 2018], testing various configurations on small and large synthetic and real-world graphs. They extend the analysis to compare the tree search implementations to other solvers, showing that the classical algorithmic solvers often are faster, while providing solutions of similar quality. Additionally, the authors analyze a recent solver based on reinforcement learning and observe that for this solver, the GNN is responsible for the competitive solution quality."
SP:155ecd17d264a084b014abdfd0362146d8fb07e0,"This paper proposes Wavelet Compressed Convolution (WCC) for 1x1 convolutional neural networks. The main idea is to use a hardware-friendly Haar-wavelet transform, known for its effectiveness in image compression, and define the convolution on the compressed activation map. By combining WCC with light quantization, the authors achieve compression rates equal to 2-bit and 1-bit with minimal degradation in image-to-image tasks."
SP:004865e6affad32403b7965493a53c8a7ffdda0a,"This paper studies the problem of learning dynamics for extensive-form correlated equilibrium (EFCE) in multiplayer general-sum imperfect-information extensive form games. The authors propose an accelerated learning algorithm for EFCE, which is based on the idea of optimistic regret minimization. The proposed algorithm is evaluated on a set of multiplayer games, where the authors show that their algorithm is able to achieve an O(T 3/4)-approximate state-of-the-art performance. This is a significant improvement over the best prior rate of $O(T 1/2)$."
SP:ee545ff83df4d7ff256ac61fbe0eb0765f52f1d5,"This paper proposes a method to learn a discretization of continuous action spaces by leveraging the priors of demonstrations. The main idea is to learn the discrete action space by discretizing the action-value function in a way that is similar to that of dynamic programming based methods. The method is evaluated on three different settings: (1) simulated demonstrations, (2) simulated play data, (3) imitation learning, and (4) continuous control tasks. The results show that the proposed method outperforms the state-of-the-art continuous control methods."
SP:4b39279b98d6aa311bb49dd1384925f9d6f66c2d,This paper proposes an adversarial style augmentation (AdvStyle) method for domain generalization in semantic segmentation. The idea is to dynamically generate hard stylized images during training and thus prevent the model from overfitting on the source domain. Experiments on two synthetic-to-real semantic segmentations benchmarks demonstrate that AdvStyle can significantly improve the model performance on unseen real domains and show that it can achieve the state-of-the-art.
SP:4a2e6d70b383e4941e0bc44e7e82972b22e26792,"This paper proposes a novel method for mid-air gesture recognition. The method is based on a hybrid VAE-VAE architecture that encodes event-based gesture data into a latent space representation, which is then used to compute the similarity between the input gesture and the latent space of a Dynamic Vision Sensor (DVS) sensor. The proposed method is evaluated on the DVSGesture dataset and it is shown that it can encode the sparse, noisy inputs into an interpretable latent representation, visualized through T-SNE plots."
SP:2e66468a6b94177e54b0052b97713ee63902c278,"This paper proposes a method for training sparse hierarchical table ensembles for tabular data. The method is based on ferns (oblivious decision trees), which is an extension of fern-based decision trees. The main idea is to use an annealing mechanism to gradually reduce the number of nodes in the fern tree. The paper shows that the proposed method is able to achieve better performance than the state-of-the-art in classification and regression tasks, while having a much lower computational complexity."
SP:b238db9252d83a13438bb747d70e635bb9945958,"This paper proposes a method for learning value functions from undirected state-only experience (i.e. state transitions without action labels). The authors first theoretically characterize the applicability of tabular Q-learning in discrete Markov decision processes (MDPs) and show that it can learn the same value function under any arbitrary refinement of the action space. This theoretical result motivates the design of Latent Action Q-Learning (LAQ), an offline RL method that can learn effective value function from state only experience. The authors show that LAQ can recover value functions that have high correlation with value functions learned using ground truth actions. The experiments in 5 environments ranging from 2D grid world to 3D visual navigation in realistic environments demonstrate the benefits of LAQ over simpler alternatives."
SP:108ebe9045a9e2b8b5aba8352733782462db8a81,"This paper proposes SWARM Parallelism, a model parallelism method for training large models in a distributed manner. The main idea of SWARM is to train a model in a swarms of poorly connected, heterogeneous unreliable devices. The authors propose to use randomized pipelines between available nodes that are rebalanced in case of failure. To further reduce the network usage, the authors develop several compression-aware architecture modifications and evaluate their tradeoffs. Experiments are conducted on a large Transformer language model on a swarm of preemptible T4 GPUs with less than 400Mb/s network throughput."
SP:91d2f094d5481651b554f58aecc2a6207057a47c,"This paper proposes an online transition correction (OTC) method for offline decentralized multi-agent reinforcement learning. The authors argue that the transition dynamics in offline experiences do not accord with the transitions dynamics in online execution, which creates severe errors in value estimates, leading to uncoordinated and suboptimal policies. To address this issue, the authors propose two types of distances, i.e., embedding-based and value-based distance, to measure the similarity between transitions, and propose an adaptive rank-based prioritization to sample transitions according to the transition similarity. Empirical results show that OTC outperforms baselines in a variety of tasks."
SP:d0e650d568214481b07a0452ec606ccbf6d05410,This paper proposes a method for quantizing the forward and backward phase of neural network training. The authors propose a logarithmic unbiased quantization (LUQ) method to quantize both the forward phase and the backward phase to 4-bit. The proposed method achieves state-of-the-art results on ResNet50 on ImageNet with a degradation of only 0.64% after a single epoch of high precision fine-tuning combined with a variance reduction method. A reference implementation is provided in the supplementary material.
SP:f2862d1f987164ed6c3c375cd8962e57c369373b,"This paper proposes a self-attention feature-selection mechanism for meta-learning in the presence of task-irrelevant features. The authors show that threshold meta-learners, such as Prototypical Networks, require an embedding dimension that is exponential in the number of task relevant features to emulate these functions. In contrast, attentional classifiers such as Matching Networks are polythetic by default and are able to solve these problems with a linear embedding dimensions. To address this challenge, the authors propose to adaptively dilute non-discriminative features. They demonstrate the effectiveness of their approach in meta learning Boolean functions, and synthetic and real-world few-shot learning tasks."
SP:e1e513fef25d29e17cdadd1b36d932a8ad8897cd,"This paper proposes a method to study emergent communication between agents in a multi-agent reinforcement learning setting. The authors use a simple messaging environment where a speaker agent needs to convey a concept to a listener agent. The speaker is equipped with a vocoder that maps symbols to a continuous waveform, and the listener needs to map the continuous signal to the concept. The communication channel is a lossy continuous channel, which is used to train a Q-learning agent that maps the speaker’s concept to the listener. The experiments show that the speaker is able to learn compositionality in the learned language representations, and that noise is essential in the communication channel when conveying unseen concept combinations."
SP:0e6ff65ba4a3df35947d1b6f4d438612088d90a0,This paper proposes a novel backdoor attack against pre-trained NLP models. The key idea is to use a pre-defined trigger word in the input text that causes model misprediction. The authors also propose a simple yet effective strategy to bypass a state-of-the-art defense. Experimental results indicate that their approach can compromise a wide range of downstream NLP tasks in an effective and stealthy way.
SP:58d3ecb4a1906251e79ad883aa97cc2502642658,"This paper proposes an incremental skill discovery method for skill discovery, where skills are learned one after another in an incremental fashion. The idea is to learn skills in a way that allows the agent to adapt fast to new environments while not forgetting previously learned skills. The proposed method is evaluated in both evolving and static environments and compared to several state-of-the-art skill discovery methods. The experimental results show that the proposed method outperforms the existing methods on both skill quality and downstream tasks."
SP:2c6595408f5ec95537eaf555e5fe3d992b58c222,"This paper proposes a novel log-polar space convolution (LPSC) layer, where the convolution kernel is elliptical and adaptively divides its local receptive field into different regions according to the relative directions and logarithmic distances. The proposed LPSC not only naturally encodes local spatial structures, but also greatly increases the single-layer receptive field while maintaining the number of parameters. Experiments on different tasks and datasets demonstrate the effectiveness of the proposed method."
SP:7791f96b1eef277a9133975507a750d9e7c6b8ff,"This paper studies the role of the information bottleneck (IIW) in the generalization ability of neural networks (NNs). The authors propose an algorithm for the efficient approximation of IIW based on the PAC-Bayes theorem. The authors also propose an MCMC-based algorithm to sample from the optimal weight posterior characterized by PIB, which fulfills the potential of the IIW in enhancing NNs in practice. "
SP:a733847ade77ffbf38760fc79da17893dea8d53f,"This paper studies data poisoning attacks, which add imperceptible perturbations to training data to maximize the test error. The authors show that the perturbation of advanced attacks are almost linear separable when assigned with the target labels of the corresponding samples. They further confirm that linear separability is indeed the workhorse for recent attacks. The paper also shows that the shortcut learning problem is more serious than previously believed as deep models heavily relies on shortcuts even if they are of an imperceptibly scale and mixed together with the normal features. It also suggests that feature extractors can be a powerful defense."
SP:7b50be406138ad01db3ee112899f622637896fe9,This paper proposes a new algorithm for offline policy evaluation based on importance sampling. The main idea of the paper is to use a per-state-neighborhood normalization condition to reduce the overfitting of the importance weighted return. The paper provides a theoretical justification of the proposed algorithm through a better per-states-narrowhood condition and shows the limitation of previous attempts to this approach through an illustrative example. The experiments show the proposed method with less overfitting and better test performance compared with state-of-the-art batch reinforcement learning algorithms.
SP:c976752a55b9ff47dc63c95a9fd7b51a81e8a42e,"This paper presents CoLLIE, a model for continual learning of how language is grounded in vision. The model learns a transformation function that adjusts the language embeddings when needed to accommodate new language use. Unlike traditional few-shot learning, the model does not just learn new classes and labels, but can also generalize to similar language uses. The authors verify the model’s performance on two different tasks of continual learning and show that it can efficiently learn and generalize from only a few examples."
SP:d3371b322acfc321ee79a2e1b438d82644872fa4,"This paper proposes VLAF2, a novel method for novel object captioning (NOC) that aims to improve the fluency, fidelity, and adequacy of the captions produced by BERT, CLIP, and other existing NOC models. The key idea is to leverage the intrinsic language knowledge from such popular models to reward captions with precise and rich visual content associated with novel images. Experiments are conducted on the nocaps dataset to validate the effectiveness of the proposed method."
SP:9f3b6486662d80350d77a4b060d4a5b8b22a6130,"This paper studies the phenomenon of neural collapse, which is the phenomenon that the features learned by overparameterized classification networks show an interesting clustering property, called neural collapse. The authors show that neural collapse generalizes to new samples from the training classes, and – more importantly – to new classes as well, allowing foundation models to provide feature maps that work well in transfer learning and, specifically, in the few-shot setting. The paper is well-written and well-motivated."
SP:624c95d9ce1ee4b66274e858e2da22bef6b052c7,"This paper proposes a deep point cloud reconstruction network consisting of two stages: 1) a 3D sparse stacked-hourglass network as for the initial densification and denoising, 2) a refinement via transformers converting the discrete voxels into 3D points. In particular, the proposed module called amplified positional encoding is designed to differently amplify the magnitude of positional encoding vectors based on the points’ distances for adaptive refinements. Extensive experiments demonstrate that the proposed network achieves state-of-the-art performance among the recent studies in the ScanNet, ICL-NUIM, and ShapeNetPart datasets."
SP:34a81ca65131576d4c14332a4e9eb3a4c344cab7,"This paper proposes PipeGCN, a new method for distributed GCN training. The main idea is to use inter-partition communication to hide the communication overhead of communicating node features and feature gradients among partitions for every GCN layer in each training iteration. The paper also provides a theoretical convergence guarantee and shows that the convergence rate of the proposed method is close to that of the vanilla distributed GCNs training without staleness. Furthermore, a smoothing method is proposed to further improve the convergence of the method. Extensive experiments show that the proposed pipeline can largely boost training throughput while achieving the same accuracy as its vanilla counterpart and outperforming existing full-graph training methods."
SP:8302d49558ee0f16392d623d4e604e92db10d041,"This paper studies the problem of test-time adaptation, i.e., using the test input to improve model robustness. The authors propose a simple approach that can be used in any test setting where the model is probabilistic and adaptable: when presented with a test example, perform different data augmentations on the data point, and then adapt (all of) the model parameters by minimizing the entropy of the model’s average, or marginal, output distribution across the augmentations. Intuitively, this objective encourages the model to make the same prediction across different augmentations, thus enforcing the invariances encoded in these augmentations and maintaining confidence in its predictions. The experimental results show that this approach achieves accuracy gains of 1-8% over standard model evaluation and also generally outperforms prior augmentation and adaptation strategies."
SP:a985de5e940ff3a4160b378201b8c02f68d1914a,"This paper proposes a method for jointly training the model and the policy in a model-based reinforcement learning (RL) setting. The main idea is to jointly train both the policy and the model, such that updates to either component increase a lower bound on expected return. This joint optimization mends the objective mismatch in prior work. The proposed algorithm (MnM) is conceptually similar to a GAN, where a classifier distinguishes between real and fake transitions, the model is updated to produce transitions that look realistic, and the policies are updated to avoid states where model predictions are unrealistic."
SP:a469fbcdc20b11dff4085b6fbc384e77f33cd37d,"This paper proposes a method for imitation learning in partially-observable environments. The authors propose to combine behavioral cloning from single observations and observation history, and propose a coarse-to-fine imitation model that combines the advantages of both methods. The proposed method is evaluated on CARLA autonomous driving from images and various MuJoCo continuous control tasks. The experimental results show that the proposed method outperforms the baselines."
SP:95c4533b5d1a865c4cc6a54615e7ad6357bdaad1,"This paper proposes a model-based meta-learning method called DyAd for dynamics forecasting. The model consists of two parts: an encoder which infers the time-invariant hidden features of the task with weak supervision, and a forecaster which learns the shared dynamics of the entire domain. The encoder adapts and controls the forecaster during inference using adaptive instance normalization and adaptive padding. Theoretically, the authors prove that the generalization error of such procedure is related to the task relatedness in the source domain, as well as the domain differences between source and target. Experiments on both turbulent flow and real-world ocean data forecasting tasks demonstrate that DyAd outperforms state-of-the-art approaches."
SP:ec70553cb0c27e5349c1b8cce6bcaa96a83bf050,"This paper proposes a method for weakly supervised monocular 3D object detection. The proposed method first generates 2D boxes on the image and then uses them to select corresponding RoI LiDAR points as the weak supervision. Then, a network is trained to predict 3D boxes which can tightly align with associated RoI points. This network is learned by minimizing the 3D alignment loss between the 2D box estimates and the corresponding corresponding LiDar points. Experiments on KITTI show that the proposed method outperforms the state-of-the-art methods."
SP:34217c6a8ca43b8eeb9ddc83d6f1f0af05918984,"This paper proposes a new model inductive bias that learns a subword tokenization end-to-end as part of the model. To this end, the authors introduce a soft gradient-based subword-based module (GBST) that automatically learns latent subword representations from characters in a data-driven fashion. GBST enumerates candidate subword blocks and learns to score them in a position-wise fashion using a block scoring network. The authors also introduce a deep Transformer model that integrates GBST and operates on the byte level. Experiments on English GLUE, multilingual, and noisy text datasets show that the proposed model outperforms a series of competitive byte-level baselines while generally performing on par and sometimes outperforming subword based models."
SP:d26d25f2ef23a89a2c139d0dd87c4c86fddcff5e,"This paper proposes a method to detect backdoor attacks in black-box hard-label settings where only the final output label of the target network is available. The authors show that the objective of backdoor detection is bounded by an adversarial objective, which leads to a singularity in the adversarial map of a backdoor-infected example, which they call adversarial singularity phenomenon. Based on this observation, the authors propose an approach called adversarial extreme value analysis (AEVA) to detect backdoors in black box neural networks. AEVA is based on the monte-carlo gradient estimation. Experimental results show the effectiveness of AEVA in detecting backdoor attacks under the black box hard label scenarios."
SP:c6dbca0ed0799b7fec21777606f6f809eb2d8c48,"This paper proposes a new uncertainty measure, Kullback-leibler divergence (KLoS) for class-probability simplex, which combines in-distribution and OOD uncertainty measures. KLoS is a class-wise divergence measure that does not require OOD training data. The paper also proposes an auxiliary neural network, KloSNet, to learn a refined criterion directly aligned with the evidential training objective. Experiments are conducted on CIFAR-10 and ImageNet, and the proposed method is shown to be more robust to OOD data."
SP:8b4f3916dca4e627931558e14836749bd4a6792f,"This paper studies a semi-supervised method for learning convolutional neural networks (CNNs) from unlabeled data. The authors show that the algorithm provably learns CNNs, under some natural distributional assumptions. Specifically, they show that if the distribution of patches in the input images has low-dimensional structure (e.g., when the patches are sampled from a low dimensional manifold), then the algorithm can efficiently learn CNNs. They also provide a lower bound that shows that the dependence of the algorithm on the dimension of the patch distribution is essentially optimal."
SP:7f2f354d5cc1030bd97bd716aea8fe1d3af86b25,"This paper proposes a novel algorithm for face clustering based on Graph Convolutional Networks (GCN). The main idea of the paper is to train a GCN to cluster faces by constructing clean graphs for GCNs. In particular, each face is transformed to a new structure space, obtaining robust features by considering face features of the neighbour images. Then, an adaptive neighbour discovery strategy is proposed to determine a proper number of edges connecting to each face image. Experiments on multiple public clustering datasets show that Ada-NETS significantly outperforms current state-of-the-art methods, proving its superiority and generalization."
SP:a3bc8e26f55e78f07de081ca85865afd52b6ae4a,"This paper proposes a new method for generalizable person re-identification (DG ReID) based on distributionally robust optimization (DRO). The authors argue that the convex condition of KL DRO may not hold for overparameterized neural networks and apply KL DRo fails to generalize under distribution shifts in real scenarios. Instead, the authors propose a simple yet efficient approach, Unit DRO, which minimizes the loss over a reweighted dataset where important samples (i.e., samples on which models perform poorly) will be upweighted and others will be downweighted. Empirical results show that the proposed method achieves superior performance on large-scale DG ReID and cross-domain ReID benchmarks compared to standard baselines."
SP:62c1f734b7f6c6e7d5114da6f37c9e3cdda73a23,"This paper proposes a novel noise-based regularizer for GNNs to improve the training of graph neural networks (GNNs). Specifically, the authors propose to add noise to the input graph and add a noise correcting node-level loss. The authors show that adding noise helps overfitting, and the noise correction loss helps ameliorate oversmoothing by encouraging diverse node latents. Experiments are conducted on the Open Graph Benchmark (OGB) dataset to demonstrate the effectiveness of the proposed method."
SP:24a1b44f37f8eedbab2047fb84600a322d289f3b,"This paper proposes a new approach to the set2vec problem, which is the task of extracting a vector representation from an input set comprised of a variable number of feature vectors. The authors propose to use the maximum-a-posterior (MAP) estimate of the mixture distribution which is approximately attained by a few ExpectationMaximization (EM) steps. The whole MAP-EM steps are differentiable operations with a fixed number of mixture parameters, allowing efficient auto-diff backpropagation for any given downstream task. Furthermore, the proposed mixture set data fitting framework allows unsupervised set representation learning naturally via marginal likelihood maximization aka the empirical Bayes. Compared to OTKE, this approach provides more flexible set embedding as well as prior-induced model regularization."
SP:b4f7b660b84fe7702fbcc8a96c192abc3a64f045,"This paper proposes a method for unsupervised feature selection in contrastive analysis (CA) where the goal is to select a small number of informative features for use in unknown downstream tasks. The proposed method, CFS (Contrastive Feature Selection), is based on the idea of contrastive feature selection (CFS), which is an extension of the contrastive contrastive learning (CFL) method. CFS is evaluated on a semi-synthetic dataset and four real-world biomedical datasets, and it consistently outperforms previous state-of-the-art methods designed for standard feature selection scenarios."
SP:bc4f69f23aba2034cbf14cb31bdc7a991806bbf6,"This paper studies the relationship between early stopping and model dimension and sample size of the dataset for linear regression models. Theoretical results show that the optimal early stopping time corresponds to the training process of a deep neural network. The paper also shows that the early stopping can help mitigate double descent in various settings. Experiments are conducted on MNIST, CIFAR-10, and ImageNet. "
SP:ede87b50cd9c4a6533f17e3e5ddfaaeaaac71dcf,This paper proposes a quasi-Newton method for policy gradient algorithms with entropy regularization. The main idea is to regularize the entropy of the policy gradient algorithm with Shannon entropy. The authors show that the proposed algorithm can be viewed as an extension of the natural policy gradient (NPG) algorithm. They also provide a simple proof that all the proposed algorithms enjoy the Newton-type quadratic convergence near the optimal policy.
SP:3535504f7599b1f39239f7cd8e09acd40fa8fdf0,"This paper proposes a novel method for text-based games (TBG) based on case-based reasoning. The authors propose to train an agent that learns a case-by-case reasoner that takes in the past experience and uses it to guide the agent to act efficiently. The agent is trained using a neural network that is trained on the current state of the game, and then the agent is used to learn a new state-of-the-art policy for the next state. The proposed method is evaluated on a variety of TBG environments, and the authors show that the proposed method outperforms existing methods in terms of generalization and sample efficiency."
SP:9a5dd0148a15dc5b4d2bc6762dfe8a8991f8866c,"This paper proposes a two-stage method to distill multiple word senses from a pre-trained language model (BERT) by using attention over the senses of a word in a context and transferring this sense information to fit multi-sense embeddings in a skip-gram-like framework. The authors demonstrate an effective approach to training the sense disambiguation mechanism in their model with a distribution over word senses extracted from the output layer embedding of BERT. Experiments on the contextual word similarity and sense induction tasks show that this method is superior to or competitive with state-of-the-art multi- sense embedding on multiple benchmark data sets, and experiments with an embedding-based topic model (ETM) demonstrates the benefits of using this multisense embedding in downstream application."
SP:e4cdba0fc7cd7f440d4436219f3959d8d5e2ad28,This paper presents a method to transfer a pretrained image-pretrained model to a point-cloud model by inflating 2D convolutional filters to 3D convolutionsal filters and finetuning the inflated imagepretrained models (FIP). The authors evaluate the performance of the method on few-shot point cloud classification and show that it can achieve competitive performance on 3D point cloud. The authors also show that the method can speed up the training of point cloud models by up to 11.1x.
SP:dc99c307931ae9c5d4a1b998dc94cfc6ac78d11f,"This paper proposes a method for training autoregressive generative models that takes advantage of the energy-based learning objective. The proposed method is motivated by the observation that chain-style conditional models suffer from exposure bias and lack of long-range coherence. To address this issue, the authors propose a constraint which fits joint distributions at each time step. The authors also propose importance sampling to train the entire model efficiently without requiring an MCMC process. Extensive experiments are conducted to demonstrate the effectiveness of the proposed method."
SP:51e748c55bd4134047098559577fa3f37aa7433a,"This paper presents a unified framework that connects Wasserstein distributional robustness with current state-of-the-art adversarial training (AT) methods, including PGD-AT and TRADES. In particular, the authors introduce a new Wasserstein cost function and a new series of risk functions, with which they show that standard AT methods are special cases of their counterparts in their framework. This connection leads to an intuitive relaxation and generalization of existing AT methods and facilitates the development of a new family of distributional AT-based algorithms. Extensive experiments show that the distributional distributional adversarial robustness AT algorithms robustify further their standard AT counterparts in various settings."
SP:f192046ea8ad61bfc8e05a0ddb90a8bd15b4640b,"This paper proposes a novel method for unsupervised representation learning for multivariate time series. The proposed method is based on the idea of bilinear temporal-spectral fusion (BTSF), which is an iterative method to incorporate temporal and spectral information into the representation learning. The method is evaluated on three tasks: classification, forecasting and anomaly detection. "
SP:ef54840009afb095c67bbbc29a7824c20a375ee8,"This paper proposes an algorithm for automatically adjusting the learning rate during gradient descent. The learning rate is optimized via an extra extra gradient descent step, justified by an analysis that exploits the structure of neural networks. The authors formulate first and second-order gradients with respect to learning rate as functions of consecutive weight gradients, leading to a cost-effective implementation. Extensive experimental evaluation is conducted, validating the effectiveness of the proposed method for a plethora of different settings."
SP:263c787361cd6d4443ce516d389c694d0fe44b28,This paper proposes a meta-learning method for continual multi-task reinforcement learning. The main idea is to train a policy over a sequence of tasks without revisiting any of the previous tasks during the meta-training phase. This is achieved by using a two-step approach: 1) learning a new task using RL and 2) using the experience from RL to perform offline meta learning to prepare for the next task. The method is evaluated on a variety of continuous control tasks and compared to several baselines.
SP:2bd729b7aa045bf74e31229c9e76e57af36e804b,"This paper proposes a new threat model for poisoned classifiers, where one without knowledge of the original trigger would want to control the poisoned classifier. Under this threat model, they propose a test-time, human-in-the-loop attack method to generate multiple effective alternative triggers without access to the initial backdoor and the training data. They construct these alternative triggers by first generating adversarial examples for a smoothed version of the classifier, created with a procedure called Denoised Smoothing, and then extracting colors or cropped portions of adversarial images with human interaction. They demonstrate the effectiveness of their attack through extensive experiments on high-resolution datasets: ImageNet and TrojAI."
SP:e58ab0e3cff6b18013145a1a99cfa9da0a3d872f,"This paper studies the problem of unconditional GAN distillation. The authors propose a novel initialization strategy for the student model, which can ensure the output consistency to the maximum extent. They also propose a latent-direction-based distillation loss to further enhance the semantic consistency between the teacher and student model. Extensive experiments demonstrate the effectiveness of their approach in distilling StyleGAN2."
SP:2c2231743fa33b95828c6615263954ce1c05f95d,"This paper proposes a method for generating online approximations of offline algorithms based on a multi-task learning model. The model is trained to simultaneously detect behavioral structures which have already occurred and predict those that may come next. The method is evaluated on both synthetic data and historical stock market data, where the contrast between explanation and prediction is particularly stark."
SP:ee3a21d2fb8a073099aa200129a53c31f3b6561d,"This paper proposes a method to amortize the computation of the inducing points locations and the parameters of the variational posterior approximation of Gaussian Processes (GP). The inducing points are learned by considering them as parameters of an approximate posterior distribution q. The authors propose to use a neural network that receives the observed data as an input and outputs the inducing point locations and parameters of q. They evaluate their method in several experiments, showing that it performs similar or better than other state-of-the-art sparse variational GP approaches."
SP:f20c99b441545047a16ae524cc2e317b2c3787a2,"This paper proposes a protocol for decentralized training of deep learning models in the presence of Byzantine and Sybil attacks. The main idea is to train a neural network in a decentralized manner, where each network member is responsible for sending updates to the other network members. The authors propose a new protocol for secure decentralized training that emphasizes communication efficiency. Theoretical analysis is provided to show that the proposed protocol is robust to Byzantine attacks. Experiments on image classification and language modeling are conducted to show the effectiveness of the proposed method."
SP:93894f20ab2593e5237b6972fef9fe63e96af89a,"This paper presents a method for learning a physics-based model for smoothed particle hydrodynamics (SPH) simulation. The method is based on the idea of learning a hierarchy of parameterized and “physics-explainable” SPH-based models, which are parameterized by physics based parameters and Neural Networks as universal function approximators. In particular, the authors propose a mixed mode approach, mixing forward and reverse mode automatic differentiation with forward and adjoint based sensitivity analyses to efficiently perform gradient based optimization. They show that their physics-informed learning method is capable of solving inverse problems over the physically interpretable parameter space, as well as over the space of Neural Network parameters; learning Lagrangian statistics of turbulence; combining Lagrangians trajectory based, probabilistic, and Eulerian field based loss functions; and extrapolating beyond training sets into more complex regimes of interest."
SP:d11b81f9ab414fcf430a03cd70c2d3246b678474,"This paper proposes Mix-MaxEnt, a method to regularize a single deterministic neural network to obtain improved accuracy and reliable uncertainty estimates. The idea is simple: instead of adding a cross-entropy loss, the authors propose to add an entropy maximization regularizer corresponding to the predictive distribution in the regions of the embedding space between the class clusters. This is achieved by synthetically generating between-cluster samples via the convex combination of two images from different classes and maximizing the entropy on these samples. Experiments on real-world datasets (CIFAR-10 and Cifar-100) using ResNet and Wide-ResNet architectures demonstrate that the proposed method consistently provides much improved classification accuracy, better calibrated probabilities for in-distribution data, and reliable uncertainties estimates."
SP:365490b872464f00634dc7a50d024fceaf0a61ee,"This paper proposes a self-supervised auto-encoder-based method for animating still images. The proposed method is based on the idea of linear displacement of codes in the latent space. The authors propose to learn a set of orthogonal motion directions simultaneously, and use their linear combination, in order to represent any displacement of the latent codes. The method is evaluated on three datasets: VoxCeleb, Taichi, and TED-talk, and compared with several state-of-the-art methods."
SP:86f9f89f84e117c86478b9afaf087f65524f5472,"This paper proposes a meta-learning method called task interpolation (MLTI) to generate additional tasks by randomly sampling a pair of tasks and interpolating the corresponding features and labels. The authors provide theoretical analysis of the proposed method under both gradient-based and metric-based meta-training settings. Theoretical analysis shows that MLTI corresponds to a data-adaptive meta-regularization and further improves the generalization. Experiments on eight datasets from diverse domains including image recognition, pose prediction, molecule property prediction, and medical image classification show that the proposed general MLTI framework is compatible with representative meta learning algorithms and consistently outperforms other state-of-the-art strategies."
SP:73d577e9c4f4af5e11a9e5bdb583ee0f50a315f5,"This paper proposes a new method for fair representation learning based on normalizing flows. In particular, the authors propose to model the encoder as a normalizing flow which is trained to minimize the statistical distance between the latent representations of different groups. The main advantage of this approach is that exact likelihood computation allows us to obtain guarantees on the maximum unfairness of any potentially adversarial downstream predictor. The authors evaluate the effectiveness of FNF in enforcing various group fairness notions, as well as other attractive properties such as interpretability and transfer learning on a variety of challenging real-world datasets."
SP:404d5643327f60f0f06f820033a56081f9e01900,"This paper proposes a graph neural network (GNN) for subgraph isomorphism counting. The main idea is to learn a low-dimensional representation for both the query and the input graph in order to predict the number of isomorphisms on the query graph. The proposed method is based on edge-centric message passing scheme, where messages on edges are propagated and aggregated based on the edge adjacency. At the graph level, the proposed method modulates the graph representation conditioned on each query individually to improve their matching. The experimental results show that COUNT-GNN achieves superior performance in comparison to the state-of-the-art baselines."
SP:5a94f18156ab2949c86de45fcf0de2e16977eebb,"This paper proposes a method for federated learning where each client can have their own personalized labels, which might not be compatible with others (even for the same class), and can be also possibly from a variety of multiple domains. The authors study two essential challenges of the agnostic personalized personalized learning, which are (1) Label Heterogeneity where local clients learn from the same single domain but labeling schemes are not synchronized with others and (2) Domain Heterogeneous where the clients learns from the different datasets which can be semantically similar or dissimilar to each other. To tackle these problems, the authors propose a novel method, namely Similarity Matching and Kernel Factorization (SimFed), which measures task-level similarity based on locally learned knowledge and matches the relevant ones for personalized knowledge reflection. SimFed factorizes the model parameters into two basis vectors and the highly sparse masks to significantly reduce the dimensionlaity of parameter space for alleviating knowledge collapse and information loss when reflecting the heterogeneous knowledge. Empirical results on both single and multi-domain datasets show that SimFed outperforms the current state-of-the-art."
SP:97f30bea31eccef6c770fbce1e14fd6d2493a178,"This paper proposes a method to learn object-centric representations of scenes with multiple objects by distilling explicit object dynamic representations (e.g., velocity) from raw video input. The method is based on object Dynamics Distillation Network (ODDN) which distills explicit object dynamics representations (i.e., velocity, velocity, etc.) from raw videos. The relation module calculates object-pair interactions and applies it to the corresponding dynamic representations of objects. Experiments are conducted on video understanding and video prediction. The results show that visual representations of ODDN perform better in answering reasoning questions around physical events in a video compared to representaions of the previous scene representation methods."
SP:ba8e50d1fa9cb824fa3f76c0c691997cd151d760,"This paper proposes a new graph neural network (GNN) architecture based on positional encoding (PE) techniques. In particular, the authors propose a new GNN layer called positional encoding layer (PEG) that allows using positional features of nodes given by positional encoding techniques such as Laplacian Eigenmap, Deepwalk, etc. The proposed PEG layer uses separate channels to update the original node features and positional features simultaneously. PEG imposes permutation equivariance w.r.t. the original nodes features and rotation equivariant w.rt. the positional features. Extensive experiments over 8 real-world networks demonstrate the advantages of PEG in generalization and scalability."
SP:cf448479f68c3194c1a9e11729bf70d7cc2ae8fd,"This paper proposes a novel method for text style transfer based on large-scale language models. The main idea is to leverage the intrinsic parallelism within the data. The model first mines the roughly parallel expressions in the non-parallel datasets with scene graphs, and then employs MLE training, followed by imitation learning refinement. The proposed method is evaluated on two benchmark tasks (sentiment & formality transfer and political stance transfer) and a newly proposed challenging task (political stance transfer), and achieves qualitative advances in transfer accuracy, content preservation, and fluency."
SP:8f7b2d1020d9e527118b8fb816760c13b0d0bfcb,"This paper studies the problem of multi-hop logical reasoning on hyper-relational knowledge graphs (KGs). The authors propose a method to embed and answer such queries and demonstrate in their experiments that qualifiers improve QA on a diverse set of query patterns. The proposed method is based on recent advancements in Graph Neural Networks and query embedding techniques. Besides that, the authors also propose a new method to answer queries and show that the proposed method can be used in conjunction with existing approaches for approximate query answering."
SP:5f8b58424a1a8eeb72217e75189d6f773a298a7a,"This paper proposes a method for hyperparameter optimization in the gray-box setting. The method is based on Bayesian optimization with a multi-budget search mechanism. The main idea is to learn to dynamically decide which configuration to try next, and for what budget. The authors propose a new surrogate for Gaussian Processes that embeds the learning curve dynamics and a new acquisition function that incorporates multi- budget information. The experimental results show that the proposed method outperforms the state-of-the-art methods on 50 datasets."
SP:99d3d94e3af5d2dc7b92c00ac1345d1d2dd0d15b,"This paper proposes a post-training quantization method to improve the performance of learned image compression. The authors propose to use integer arithmetic-only quantization to make the model inference integer-arithmetic-only, which is much simpler than the existing training and fine-tuning based approaches. They further improve the discretization of the entropy parameters and extend the deterministic inference to fit Gaussian mixture models. The proposed method can infer in a cross-platform consistent manner."
SP:85d0df515e9e555f3ea1c21d607304dfaeae69c0,"This paper proposes an unsupervised noise reconstruction and removal network for denoising scanning electron microscopy images. The network is based on gated recurrent units, which reconstructs and removes the noise by synthesizing the sequential data. The proposed method is evaluated on 3D scanning electron microscope data sets and shows comparable performance compared to supervised methods."
SP:e6275b0b103fa90dcebcdd3d3c14c830c3402972,"This paper studies the label trick in graph neural networks (GNNs). The authors show that label trick can be viewed as an interpretable, deterministic training objective composed of two factors. The first is a data-fitting term that naturally resolves potential label leakage issues, while the second serves as a regularization factor conditioned on graph structure that adapts to graph size and connectivity. The authors then leverage this perspective to motivate a broader range of label trick use cases, and provide experiments to verify the efficacy of these extensions."
SP:b6cbc3661f9c440687c3dd01ee35a118c87db377,"This paper proposes to model machine theory of mind (ToM) in a more flexible and symmetric multi-agent environment where all agents can speak, listen, see other agents, and move freely through a grid world. The authors propose to use a deep reinforcement learning model that models the mental states of other agents. They show that the proposed model can improve the performance of agents with access to other agents’ mental states, while the best agents fail to achieve performance comparable to agents without access to the gold-standard mental state."
SP:f8ce83805eee46c6c196e8477bf10d8d7f7e0f46,"This paper proposes a novel method for zero-shot object detection, which aims to detect novel objects in the image with the knowledge learned from and only from seen objects. The proposed method is based on the idea of unsupervised object detection. The authors propose to use the YCB Video Dataset, which contains 21 objects in various categories, to train the network. The method is evaluated on two tasks: (1) detecting daily objects in indoor scenes, and (2) detecting objects in outdoor scenes. "
SP:aa1dcd9217270010f16a00004facede942efea17,This paper proposes an autoregressive latent video model for video prediction. The proposed method is based on an image generator model and a causal transformer model. The model is trained with a top-k sampling and data augmentation method. The experimental results show that the proposed method achieves competitive performance to state-of-the-art models with fewer parameters.
SP:7f57896afd63bc869d2db6ddf7abbeaa71daae11,"This paper proposes to use Vision Transformers (ViTs) to train generative adversarial networks (GANs) for image generation. The authors propose several regularization techniques for training GANs with ViTs. Specifically, the authors propose two regularization methods for ViT discriminators and ViT generators. The first regularization method is based on the self-attention regularization. The second regularization technique is based off of the latent and pixel mapping layers. Experiments on CIFAR-10, CelebA, and LSUN bedroom show that the proposed method can achieve comparable performance to the leading CNN-based GAN models."
SP:bbae3afcaea0a2e54904cb8daaed7df4fe37da6e,"This paper proposes to decompose the task of image generative modeling explicitly into two steps: 1) modeling the visually perceptible information to achieve good sample quality, and 2) model the imperceptible information, which is the bulk of the likelihood signal, to achieve a good likelihood signal. The authors propose a variational autoencoder model that first models the visual perceptible bits, and then models the other bits to achieve the good likelihoods. The paper is well-written and well-motivated. The experimental results show that the proposed approach can be applied to VAEs."
SP:bfed56018134ec66cde9a7e958df964d4cca3164,"This paper proposes a training-free method for estimating the reverse variance and KL divergence of a DPM using Monte Carlo methods and a score-based model. The authors show that both the reverse and KL divergences have analytic forms w.r.t. its score function. To correct the potential bias caused by the score based model, the authors derive both lower and upper bounds of the optimal variance and clip the estimate for a better result. Empirically, the proposed method improves the log-likelihood of various DPMs, produces high-quality samples, and enjoys a 20-80x speed up."
SP:3f935ba5784c3e86db72421426bc479061af1a4b,"This paper proposes to use vision transformers (ViTs) as an alternative to CNNs for medical image classification tasks. The authors evaluate the performance of ViTs on several standard medical image benchmark datasets and tasks. They show that ViTs can perform on par with CNNs when pretrained on ImageNet, both in a supervised and self-supervised setting."
SP:a64e0535f268901e38fd51e027c612ebcdbae1a4,"This paper studies the problem of pretraining neural language models (NLMs) over a large corpus of text. The authors show that the pretrained NLM can model much stronger dependencies between text segments that appeared in the same training example, than it can between text segment in different training examples. This theoretically motivated degree of freedom for “pretraining example design” indicates new training schemes for self-improving representations. "
SP:59066956fa2e423d5f2d2ea4f91c4ddf6afd4683,"This paper proposes a symbolic regression-based method for learning to optimize (L2O) models. The main idea of the method is to use symbolic regression to improve the interpretability and scalability of L2O models. In particular, the authors propose a holistic symbolic representation and analysis framework for L2o, which yields a series of insights for learnable optimizers. The authors also propose a lightweight model that can be meta-trained on large-scale problems and outperform human-designed and tuned optimizers, and their codes will be released upon acceptance."
SP:54dfeb363beee9959aecc9e0853ff06e43bd94e4,"This paper studies the problem of adversarial robustness in the context of reinforcement learning. The authors propose a policy smoothing method to defend against an adaptive RL adversary. The main contribution of the paper is to prove an adaptive version of the Neyman-Pearson Lemma for smoothing-based certificates, where the adversarial perturbation at a particular time can be a stochastic function of current and previous observations and states as well as previous actions. Based on this result, the authors propose to add a Gaussian noise to its observation at each time-step before passing it through the policy function. The proposed method is evaluated on Cartpole, Pong, Freeway and Mountain Car environments."
SP:e0f9add5fde18eaab0eeb2b10b14928acc8ec5b8,"This paper proposes a method for predicting the target accuracy of a model trained on labeled source data and unlabeled target data. The method is based on the idea of average thresholded confidence (ATC), which is a method that learns a threshold on the model’s confidence and predicts the accuracy as the fraction of unlabelled examples for which the model confidence exceeds that threshold. The authors evaluate the proposed method on a variety of datasets and model architectures, and show that it outperforms previous methods across several model architectures and types of distribution shifts."
SP:e748bf6ee653087cae825df32a8546f9ccebfcf1,"This paper studies the problem of partial distribution matching (PDM) registration, where the goal is to recover a transformation that matches one set to the other. The authors propose a method for large scale PDM problem by utilizing the partial Wasserstein-1 (PW) discrepancy, which they show can be efficiently optimized. Specifically, they theoretically derive the Kantorovich-Rubinstein duality for the PW discrepancy, and show its gradient can be explicitly computed. Based on these theoretical results, they propose a novel method, which approximates the partial PW discrepancy by a neural network, and learns the transformation adversarially with the network. It also incorporates an efficient coherence regularizer for non-rigid transformations to avoid unrealistic deformations. Experiments on practical point set registration tasks show that the proposed method is robust, scalable and performs better than the state-of-the-art methods."
SP:f94f77696d100b2638fa2a6d82c8df47db3b6a36,This paper proposes a meta-learning method for hyperparameter optimization (HPO) in the context of transfer learning. The proposed method is based on Deep Kernel Gaussian Process surrogate with Landmark Meta-features (DKLM) that can be jointly meta-trained on a set of source tasks and then transferred efficiently on a new (unseen) target task. The DKLM is an end-to-end meta-feature network that embeds the set of evaluated configurations and their respective performance and learns contextualized dataset-specific similarity representations for hyper-parameter configurations. Experiments are conducted on a wide range of HPO meta-datasets and demonstrate the empirical superiority of the proposed method.
SP:e3c57f3589e8ab674644d900c14b3473cd71a23f,"This paper proposes a new method for generating fakes for deep generative models that can be detected and attributed to a source. The key idea is to generate a large population of models with distinct fingerprints, which can then be used to identify the source of the fakes. The authors propose to use a 128-bit fingerprinting operation to generate more than 10 identifiable models. The proposed method is evaluated on a variety of datasets and compared to the state of the art methods."
SP:73bffd1a0856b80d29f7a2b2b68be57882531f07,"This paper proposes a method to provide model-agnostic local explanations for black box models that output similarity between two inputs. The authors first provide a method that provides feature attributions to explain the similarity between a pair of inputs as determined by a black box similarity learner. Then, the authors propose analogies as a new form of explanation in machine learning. The goal is to identify diverse analogous pairs of examples that share the same level of similarity as the input pair and provide insight into (latent) factors underlying the model’s prediction. The selection of analogies can leverage feature attribution, thus connecting the two forms of explanation while still maintaining complementarity. They prove that their analogy objective function is submodular, making the search for good-quality analogies efficient."
SP:6a3c4ae05d582f8896840483b08c735ced2976bc,"This paper analyzes the certified robustness of ensemble ML models, and provides sufficient and necessary conditions of robustness for different ensemble protocols. The authors prove that diversified gradient and large confidence margin are sufficient conditions for certifiably robust ensemble models under the model-smoothness assumption. They also provide the bounded model smoothness analysis based on the proposed Ensemble-before-smoothing strategy. Inspired by the theoretical findings, the authors propose the lightweight Diversity Regularized Training (DRT) to train certified-robust ensemble models. Extensive experiments show that DRT enhanced ensembles can consistently achieve higher certified L2 robustness than existing single-model and ensemble models, demonstrating the state-of-the-art certified L1 robustness."
SP:3002b29c27709780238876d8c3f81bbd6a0f8112,"This paper studies the expressive power of graph neural networks (GNNs) in the context of message passing. In particular, the authors propose a new pooling technique of local neighborhoods that allows different tradeoffs of computational cost and expressive power. First, they prove that this model can count subgraphs of size k, and thereby overcomes a known limitation of low-order GNNs. Second, they show how recursive pooling can exploit sparsity to reduce the computational complexity compared to the existing higher-order Graph Neural Networks (GNNs). More generally, they provide a (near) matching information-theoretic lower bound for counting subGraphs with graph representations that pool over representations of derived (sub-)graphs."
SP:5d0cbd84336caf5f31e1f98e11f6733230e4d792,"This paper presents an information-theoretic view of the knowledge integration (KI) process from an information theoretic point of view. The authors propose a simple probe model called Graph Convolution Simulator (GCS) for interpreting knowledge-enhanced LMs and exposing what kind of knowledge is integrated into these models. The proposed GCS model can be used to interpret the KI process and analyze two typical KI methods: K-Adapter and ERNIE. They find that only a small amount of factual knowledge is captured in these models during integration. While K- adapter is better at integrating simple relational knowledge, complex relational knowledge is better integrated better in ERNie. They further find that while K-Adapters struggles to integrate time-related knowledge, it successfully integrates knowledge of unpopular entities and relations."
SP:7e73948421e98307fceb69a316d8a4e7c4926cda,"This paper studies the effect of the adaptation learning rate in meta-learning with mixed linear regression. The authors propose a principled way to estimate optimal adaptation learning rates that minimize the population risk of MAML. They also interpret the underlying dependence between the optimal learning rate and the input data. Finally, they prove that compared with empirical risk minimization (ERM), MAMl produces an initialization with a smaller average distance to the task optima, consistent with previous practical findings."
SP:effbc85d89b1197d9c2abcaf5ff13864135dd6e1,"This paper proposes a method for source-free domain adaptation (SFDA) that aims to adapt a model trained on labelled data in a source domain to unlabelled data in the target domain without access to the source-domain data during adaptation. The authors propose Feature Restoration (FR) which aims to extract features with the same semantics from the target data as were previously extracted from the source, rather than extracting new ones. They also propose a bottom-up training scheme for FR which boosts performance by preserving learnt structure in the later layers of a network. They demonstrate that BUFR outperforms existing SFDA methods on real and synthetic data."
SP:7d63034ec7e6a4f178681ff2a49feb485cd47116,This paper proposes a method to propagate adversarial robustness in federated learning (FL) from high-resource users that can afford adversarial training (AT) to low resource users that cannot afford it during the FL process. The authors propose a simple yet effective propagation approach that transfers robustness through carefully designed batch-normalization statistics. The experiments show that the proposed method is effective in improving FL robustness even when only a small portion of users afford AT during learning.
SP:42c7a79e58b6a9f776fa6ae928bd89c194f9303f,"This paper proposes a transformer-based method for network games, which learns a mapping from the equilibrium actions to the network structure of the game without explicit knowledge of the utility function. The proposed method is evaluated on three different types of network games using both synthetic and real-world data, and demonstrate its effectiveness in network structure inference and superior performance over existing methods."
SP:1c7b9157cf8c06ca771da78895fc3af969b0fb85,"This paper proposes GraphANGEL, a method for relation prediction in heterogeneous graphs. The main idea is to learn a latent representation for each node in a graph, which is then used to predict the relation between a given node and a subgraph based on the similarity of the two subgraphs. The method is evaluated on heterogeneous graph based recommendation and knowledge graph completion tasks, and the proposed method is compared with several baselines."
SP:26ed25a7b42da2cf11b76a727102d8aa36d76657,"This paper studies few-shot learning in histology images. The authors propose to use contrastive learning (CL) with latent augmentation (LA) to build a few shot learning system. The main idea is to learn representations without manual labels, while LA transfers semantic variations of the base dataset in an unsupervised way. The experiments show that the proposed method generalize better than supervised learning for histology image in unseen classes, and that LA brings consistent gains over baselines."
SP:badbe687258cd5c282ca167b1f6fbfc6b5400dbf,"This paper proposes a novel RNN-based model for irregularly sampled time series. The authors show that the gradient of the RNN is vanishing or exploding during training, which can be explained by the ordinary differential equation (ODE) representation of the hidden state. To solve this problem, the authors propose to add a memory compartment to the R-NN to separate the time-continuous state from the memory of the memory. This allows the model to respond to inputs arriving at arbitrary time-lags while ensuring a constant error propagation through the memory path. Experiments are conducted on time series with long-term dependencies."
SP:4efd22f9122fa5856a9f4302eb6875fa0c414912,"This paper proposes BiBERT, a new method for fully binarized BERT. The main idea is to use a Bi-Attention structure for maximizing representation information statistically and a DirectionMatching Distillation (DMD) scheme to optimize the full binarization of BERT accurately. The experiments show that the proposed method outperforms both the straightforward baseline and existing state-of-the-art quantized bERTs with ultra-low bit activations."
SP:619bd742e92bea6241852f5a9d2b7bacf13b393a,"This paper presents a new method to solve keypoint detection and instance association by using Transformer. Specifically, the self-attention in Transformer measures dependencies between any pair of locations, which can provide association information for keypoints grouping. However, the naive attention patterns are still not subjectively controlled, so there is no guarantee that the keypoints will always attend to the instances to which they belong. To address this issue, the authors propose a novel approach of supervising self attention by using instance masks to supervise self attention to be instance-aware. The experiments on the COCO multi-person keypoints detection challenge and person instance segmentation task demonstrate the effectiveness and simplicity of the proposed method."
SP:14750819593136fc9ef4efd032ab6f94dc5f6a02,"This paper proposes a method to train an agent to maximize the expected quadratic utility function, which corresponds to the Pareto efficient policy. The method is based on gradient estimation of the variance term of the policy, which does not suffer from the computational difficulties of gradient estimation. The authors evaluate the proposed method on a variety of tasks and show that it outperforms the state-of-the-art."
SP:f675b564b3a9c8626ce7944d752fa3e0d868428e,"This paper studies the problem of test-time domain adaptation of an autoencoder system that is trained using a mixture density network (MDN). The authors propose a fast and sample-efficient method for adapting the channel model without modifying the encoder and decoder neural networks, and adapting only the MDN channel model. The proposed method utilizes feature transformations at the decoder to compensate for changes in the channel distribution, and effectively present to the decoders samples close to the source distribution. Experimental evaluation on simulated datasets and real mmWave wireless channels demonstrate that the proposed method can adapt the channel using very limited number of samples, and improve or maintain the error rate of the auto-encoder under changing channel conditions."
SP:77dc92137ea490d3e1b4b8ee1630dbe2ee0bddfa,"This paper proposes a new model for the abductive natural language inference task (αNLI) where the goal is to infer the most plausible explanation between the cause and the event. The authors argue that it is unnecessary to distinguish the reasoning abilities among correct hypotheses and similarly, all wrong hypotheses contribute the same when explaining the reasons of the observations. Instead, they propose to group instead of ranking the hypotheses and design a structural loss called “joint softmax focal loss” in this paper. The experimental results show that their IMSL has achieved the highest performance on the RoBERTa-large pretrained model, with ACC and AUC results increased by about 1% and 5% respectively."
SP:17cd72df5fc19398f582d27516fd742b073f79e3,"This paper proposes a method for certifiably adversarially robust out-of-distribution (OOD) detection and classification. The method is based on a combination of a classifier with an OOD detector and a standard classifier from first principles. The classifier is trained to be OOD aware, and the detector is trained with a standard OOD classifier. The authors show that the proposed method can detect OOD samples even if they are close to the in-district distribution, without loss in either prediction accuracy or detection performance for non-manipulated OOD data."
SP:9c3756f13932236aff3e8104f4fa193dcc8fde2f,"This paper proposes a new generalized transferable attack (GTA) problem where the attacker has a set of surrogate models trained on different datasets (with different label sets and image sizes), and none of them is equal to the dataset used by the victim model. The paper then proposes a novel method called Image Classification Eraser (ICE) to erase classification information for any encountered images from arbitrary dataset. Extensive experiments on Cifar-10, CIFAR-100, and TieredImageNet demonstrate the effectiveness of the proposed ICE on the GTA problem. Furthermore, the paper shows that existing transfer attack methods can be modified to tackle the GTA, but with significantly worse performance compared with ICE."
SP:2e0447c741a3f09be1095633d870200355211260,"This paper proposes a counter-false-negative pre-training method for discriminative pre-trained language models (PrLMs) that aims to prevent false negative predictions. The authors propose to train the model on negative samples instead of positive ones, and train the discriminator on the true negative samples. The proposed method is evaluated on GLUE and SQuAD benchmarks, and compared with the existing methods."
SP:281bc59d639aa76d84921b3ec4ce1ee8f1ba5b51,This paper proposes an open-world semi-supervised learning method for the problem of class distribution mismatch between labeled and unlabeled data. The authors propose an end-to-end approach that assigns instances to previously seen classes or forms novel classes by grouping similar instances without assuming any prior knowledge. The key idea in ORCA is to utilize uncertainty adaptive margin to circumvent the bias towards seen classes caused by learning seen classes faster than the novel classes. Experiments on image classification datasets and a single-cell dataset demonstrate that ORCA consistently outperforms alternative baselines.
SP:6c572c4c21b01a0cf3fd9ef97fbb348ef4e405ae,"This paper proposes a second-order method for training large-scale deep neural networks (DNNs). The main idea is to use the BFGS update rule that directly approximates the Hessian inverse using past parameters and gradients, without explicitly constructing the Hessians matrix and then computing its inverse. To achieve stable convergence, the authors introduce momentum in Hessian updates together with an adaptive damping mechanism. The authors provide rigorous theoretical results on the convergence of SLIM-QN in a stochastic setting and demonstrate that it has much less compute and memory overhead compared to existing second order methods."
SP:4bffce00ebb02d2e676eec897647ac14c3344deb,"This paper proposes a systematic method called Locality-Sensitive Pruning (LSP) for graph pruning based on Locality Sensitive Hashing. LSP aims to sparsify a graph so that similar local environments of the original graph result in similar environments in the resulting sparsified graph, which is an essential feature for graph-related tasks. Extensive experiments on synthetic and real-world datasets demonstrate the superiority of LSP."
SP:c5e024f4e2079586298519ca868630efd7579eca,"This paper proposes an adversarial data augmentation method for contrastive self-supervised learning. The authors propose to decompose a sample x to be its variational auto-encoder (VAE) reconstruction plus the residual R(x) = x + G(x), where the residual retains most identity-distinctive information due to an information-theoretic interpretation of the VAE objective. They then adversarially perturb the residual and add it back to the original VAE as an augmentation. They apply this “identity-disentangled adversarial augmentation (IDAA)” to different self supervised learning methods and show that IDAA consistently improves both the efficiency and generalization performance on multiple benchmark datasets."
SP:0991bc5f213bd8ab7572e2fed309e1b57a35835b,"This paper proposes a method for detecting distribution shifts in machine learning models. The authors argue that a sensible method for firing off a warning has to both (a) detect harmful shifts while ignoring benign ones, and (b) allow continuous monitoring of model performance without increasing the false alarm rate. To this end, they design simple sequential tools for testing if the difference between source (training) and target (test) distributions leads to a significant increase in a risk function of interest, like accuracy or calibration. They demonstrate the efficacy of the proposed framework through an extensive empirical study on a collection of simulated and real datasets."
SP:1c7b954273e3a9cda333385b15a3e8ed3bf8178a,This paper proposes a method to model the dynamics of physical systems from a single video. The method is based on neural implicit representations for appearance modeling and neural ordinary differential equations (ODEs) for long-term prediction in state space. The authors show that their method can recover the metric length of the pendulum from the monocular video (relative error to true length is less than 2.5%). The authors also show that the proposed method is able to render novel scenes with modified physical parameters.
SP:51efd1451343f4994d857daa5490e299b812bc2d,"This paper proposes a method for context-dependent reinforcement learning in the context-independent setting, which is characterized by an unknown finite number of not directly observable contexts, abrupt (discontinuous) context changes occurring during an episode, and Markovian context evolution. The authors propose to use a Hierarchical Dirichlet Process (HDP) prior for model learning, and derive a context distillation procedure, which identifies and removes spurious contexts in an unsupervised fashion. They then find the representation of the optimal policy enabling efficient policy learning using off-the-shelf RL algorithms. Finally, they demonstrate empirically (using gym environments cart-pole swing-up, drone, intersection) that their approach succeeds where other methods of other frameworks fail."
SP:ea167b126212b2092bc1190d7f8376bf7c54a888,"This paper proposes a pretraining framework for knowledge based multilingual language models (KMLMs). The pretraining consists of generating synthetic sentences and reasoning-based multilingual training data using the Wikidata knowledge graphs. The pretrained KMLMs demonstrate significant performance improvements on a wide range of knowledge-intensive cross-lingual NLP tasks, including named entity recognition, factual knowledge retrieval, relation classification, and a new task designed by the authors, namely, logic reasoning."
SP:6c11cf29c90f923346372ba6f11452c36e69ad6d,"This paper proposes a method for learning to act altruistically towards other agents by giving them more choice and thereby allowing them to better achieve their goals. The authors propose to learn to increase the choices another agent has by preferring to maximize the number of states that the other agent can reach in its future. They evaluate their approach on three different multi-agent environments where another agent’s success depends on the altruistic agent. They show that their unsupervised agents can perform comparably to agents explicitly trained to work cooperatively, in some cases even outperforming them."
SP:5dbc54201ba184266c5054f0d2944bd197bc307a,"This paper studies the phenomenon of double descent in neural networks. The authors derive a lower bound for the population loss of a neural network based on the influence function, and show that the lower bound is related to the spectrum of the Hessian at the optimum of the network. They further investigate how the loss function affects double descent, and uncover interesting properties of neural networks and their Hessian spectrum near the interpolation threshold."
SP:b485114712055f39a7afb951dbc3db482ff523fd,"This paper studies the asymptotic behavior of the graph neural tangent kernel (GNTK) in deep GCNs. The authors show that the GNTK is exponential in the depth of the network, which is a result of the over-smoothing problem of deep GCN. They also show that residual connection-based techniques are only able to mildly mitigate the exponential decay of trainability. To address this issue, the authors propose Critical DropEdge, a connectivity-aware and graph-adaptive sampling method, inspired by the theoretical insights on trainability and propose a new sampling method based on the drop-edge technique. Experimental results show the effectiveness of the proposed method."
SP:25a92b3583afdc6892e59f1e769125d52c8011af,This paper proposes a method for estimating the second-order dynamics of a video of a heart beat. The authors propose to use the second derivative of both the input frames and the target vital sign signals into the training procedure to estimate the left ventricle ejection time (LVET) intervals. The method is evaluated on a set of cardiac recordings of a patient's heart beat and shows that it is better able to estimate LVET intervals compared to a baseline method.
SP:0a88d2fcbdfab3e196bf6b9c75adb1006ab87536,"This paper proposes to use symbolic mapping to help agents learn a compositional and symmetric language in complex settings like dialog games. Inspired by the theory that human language was originated from simple interactions, the authors hypothesize that language may evolve from simple tasks to difficult tasks. They propose a novel architecture called symbolic mapping as a basic component of the communication system of agent. They find that symbolic mapping learned in simple referential games can notably promote language learning in difficult tasks and explore vocabulary expansion, and show that agents can easily learn to use new symbols when the environment becomes more complex."
SP:89575be04cb33b41d7a0a7b62f9496c2838a1317,"This paper proposes a hierarchical modular approach to learn agents that navigate and manipulate objects in a divide-and-conquer manner for the diverse nature of the entailed tasks. Specifically, the policy operates at three levels of hierarchy. First, a sequence of subgoals to be executed based on language instructions by high-level policy composition controller (PCC). Then discriminatively control the agent’s navigation by a master policy by alternating between navigation policy and various independent interaction policies. Finally, the manipulation actions with the corresponding object masks using the appropriate interaction policy."
SP:e2c8efe00db7baba2368f4f6a37815809b9e235e,"This paper proposes Nuisance-randomized distillation (NURD), a method for training models that perform well regardless of the nuisance-label relationship between the label and the nuisance variable. The authors first define a family of distributions that differ only in the nuisance and label relationship. Then, they introduce a set of representations that are independent of the label under the nuisance distribution. They prove that the representations in this set always perform better than chance, while representations outside of this set may not. They evaluate NURD on several tasks including chest X-ray classification where, using non-lung patches as the nuisance, they produce models that predict pneumonia under strong spurious correlations."
SP:c75998b76f4e0510fc719d25959a10fc07db1c40,"This paper proposes OTTER (Optimal TransporT distillation for Efficient zero-shot Recognition), which uses online entropic optimal transport to find a soft image-text match as labels for contrastive learning. Based on pretrained image and text encoders, models trained with OTTER achieve strong performance with only 3M image text pairs. Compared with InfoNCE loss, label smoothing, and knowledge distillation, OTTER consistently outperforms these baselines in zero-shots evaluation on Google Open Images (19,958 classes) and multi-labeled ImageNet 10K (10032 classes)."
SP:e83cd70377542b5d187998e2e4a7ac070f453ed6,"This paper presents Pix2Seq, a simple and generic framework for object detection. Unlike existing approaches that explicitly integrate prior knowledge about the task, this paper casts object detection as a language modeling task conditioned on the observed pixel inputs. Object descriptions (e.g., bounding boxes and class labels) are expressed as sequences of discrete tokens, and we train a neural net to perceive the image and generate the desired sequence. The approach is based mainly on the intuition that if a neural network knows about where and what the objects are, we just need to teach it how to read them out. Beyond the use of task-specific data augmentations, the approach makes minimal assumptions about the tasks, yet it achieves competitive results on the challenging COCO dataset, compared to highly specialized and well optimized detection algorithms."
SP:abc9315f61929cc1c54dfef8ff83d7eac56ec2f2,"This paper proposes a method for distilling the learned policy network into a symbolic policy, which is composed of geometric and numerical symbols and operators. The proposed method is based on a policy regression algorithm called RoundTourMix, which distills the symbolic rules as teacher-student. The symbolic policy can be treated as discrete and abstracted representations of the policy network, but are found to be more interpretable, robust and transferable. Experiments on six different environments show that the proposed symbolic policy achieves compelling or even higher scores than the CNN based RL agents."
SP:04e7e181aeb1244ae1c4837ad416aef93ea3ea32,"This paper proposes a method for image-to-image translation that aims to disentangle the pose-identity disentanglement of the generated images. The authors propose a joint-training scheme with self-supervision methods for the GANInversion encoder and the generator. The VQSN module automatically learns to encode the shaping and composition information from the commonly shared objects inside the training-set images. Moreover, the latent-space reducing feature is leveraged to improve the performance of the model. The experimental results show that the proposed method achieves better synthesis image quality and disentangling scores."
SP:e51a7f45493064972585109f203a867e9828eb15,"This paper proposes a multi-layer perceptron (MLP) architecture for speech processing. The model splits feature channels into non-overlapped chunks and processes each chunk individually. These chunks are then merged together and further processed to consolidate the output. The proposed model is evaluated on two tasks: keyword spotting and speech enhancement. In all experiments, speech-MLP achieves better performance with fewer parameters lower GFLOPS."
SP:d708d3886f4abd4552d8ccb2096df7361c803b13,This paper provides a lower bound on the generalization error of transfer learning algorithms for binary classification problems. The lower bound is based on a natural notion of distance that can be easily computed on real world data sets. The authors also consider a more general setting where there are more than one source domains for knowledge transfer to the target task and develop new bounds on generalization errors in this setting. The experiments on real image classification and action recognition data sets demonstrate that the proposed lower bounds are indicative of the difficulty of knowledge transfer between different pairs of source/target tasks.
SP:f7511ba9ccad03233b34b1bf41bbac7361d20a57,"This paper proposes a probabilistic method for 3D scene generation based on generative cellular auto-encoders. The method is based on the generative Cellular Automata (GCA) model, which learns the multi-modal distribution and transforms the formulation to process large-scale continuous geometry. The local continuous shape is incrementally generated as a sparse voxel embedding, which contains the latent code for each occupied cell. Experiments show that the model successfully generates diverse plausible scenes faithful to the input, especially when the input suffers from a significant amount of missing data."
SP:d22d8f074adbe8fb0f25fb8f8d96201b3159bf6b,This paper proposes temporal priors as a non-Markovian generalization of behavioral priors for guiding exploration in reinforcement learning. The authors propose a probabilistic mixture of policy and temporal prior to accelerate off-policy reinforcement learning in unseen downstream tasks. They provide empirical evidence that their approach improves upon strong baselines in long-horizon continuous control tasks under sparse reward settings.
SP:25e06c022ae8b3cbbb8db413d7b534a1a5c92391,This paper proposes a method to learn a scheduling mechanism for learning rate scheduling in deep neural networks. The proposed method is based on graph-network-based reinforcement learning (GNN). The authors propose a directed graph message-passing network that encodes the current dynamics with a graph message passing network and trains an agent to control the learning rate accordingly via reinforcement learning. The authors evaluate the proposed method on Fashion-MNIST and CIFAR-10 for image classification and GLUE for language understanding.
SP:d73cb0471c1770607ad3e4621cfc5f170683dd8e,"This paper proposes a method for unsupervised object-centric learning from point clouds. The method is based on the Chamfer Mixture Loss (PML) loss, which is used to model the spatial mixture model of a point cloud. The paper also proposes an object-specification scheme that describes each object’s location relative to its local voxel grid cell. The proposed method is evaluated on the task of scene decomposition, where it is shown that the proposed method can detect and segment an unknown number of objects from a 3D point cloud and is able to perform well."
SP:3c57e921c1bf23e482551ceb71702931a7f07439,"This paper proposes a method for grounding high-level tasks, expressed in natural language, to a chosen set of actionable steps (i.e. “open fridge”). The authors show that if pre-trained LMs are large enough and prompted appropriately, they can effectively decompose high level tasks into low-level plans without any further training. However, the plans produced naively by LLMs often cannot map precisely to admissible actions. To address this issue, the authors propose a procedure that conditions on existing demonstrations and semantically translates the plans into admissible actionable actions. The proposed method is evaluated in the recent VirtualHome environment and shows that the resulting method substantially improves executability over the baseline."
SP:e0159d1c9df2e657892a3a0c77549df4698d9a1a,"This paper proposes a new VAE-based generative model that is based on the Riemannian manifold of the latent space of a VAE. In particular, the authors propose a new way to generate samples consisting in sampling from the uniform distribution deriving intrinsically from the manifold learned by the VAE model. The authors also show that the proposed method is robust in the low data regime which is known as very challenging for deep generative models. Finally, they validate the method on a complex neuroimaging dataset combining both high dimensional data and low sample sizes."
SP:b4b8e1727f8617894f10f20365cb68de79f0e650,This paper proposes to replace redundant heads in transformers with a mixture of Gaussian keys at each head in order to improve the performance of multi-head attention. The key idea is to use a Gaussian mixture model to replace the redundant heads. The proposed method is evaluated on the Wikitext-103 and Long Range Arena benchmark and shows comparable or better performance compared to the baseline transformers.
SP:82731dcce233e748f63382e09b6224a513fe9689,"This paper proposes a method for integrating image-based and action-based information for navigation in a two-dimensional continuous environment. In particular, the authors propose to use a direct-inverse model of environment dynamics to fuse image and action related signals, allowing reconstruction of the action relating the two successive images, as well as prediction of the new image from its current value and the action. The authors propose a minimalistic recurrent architecture, called Resetting Path Integrator (RPI), that can easily and reliably be trained to keep track of its position relative to its starting point during a sequence of movements. RPI updates its internal state using the (possibly noisy) self-motion signal, and occasionally resets it when the image signal is present. The internal state of this minimal model exhibits strong correlation with position in the environment due to the direct inverse models, is stable across long trajectories through resetting, and allows for disambiguation of visually confusing positions in the environments through integration of past movement, making it a prime candidate for a cognitive map."
SP:1a27c397d1e73def5e724c5c6f25548975ba50fa,"This paper studies the problem of feature learning in neural networks, where the labels are determined by a set of class relevant patterns and the inputs are generated from these patterns along with some background patterns. The authors prove that neural networks trained by gradient descent can succeed on these problems. The success relies on the emergence and improvement of effective features, which are learned among exponentially many candidates efficiently by exploiting the data (in particular, the structure of the input distribution). In contrast, no linear models on data-independent features of polynomial sizes can learn to as good errors. Furthermore, if the specific input structure is removed, no polynomials algorithm in the Statistical Query model can learn even weakly. The results provide theoretical evidence showing that feature learning depends strongly on the input structure and leads to the superior performance."
SP:8ada73ed7eade9ebdeef376485e849c42575bc5f,"This paper studies the robustness of feature extractors to adversarial attacks. The authors propose a method for finding adversarial collisions between features extracted from a fixed feature extractor and a classifier trained on top of it, which can then be used to provide a lower bound on the classifier's robustness. The lower bound relies on the effectiveness of the method used to find collisions between pairs of perturbed examples at deeper layers. The upper bound is based on the iterative solution of a convex program that provably finds collisions between two points in the input space."
SP:874b5fa51924cbcceed490d98a0ea80f74586b32,"This paper proposes Expectile V-Learning (EVL), a method for offline reinforcement learning that learns the V-function instead of the Q-function to naturally keep the learning procedure within the offline dataset. The authors also propose implicit planning along offline trajectories to enhance learned V-values and accelerate convergence. Empirical results on the D4RL benchmark show that the proposed method achieves superior performance in most tasks, particularly in sparse-reward tasks."
SP:34f08d92681504490c2f739b0d08f79f9764b2f5,"This paper proposes a novel adversarial training framework that learns to reweight the loss associated with individual training samples based on a notion of class-conditioned margin, with the goal of improving robust generalization. Inspired by MAML-based approaches, the authors formulate weighted adversarial learning as a bilevel optimization problem where the upper-level task corresponds to learning a robust classifier, and the lower-level tasks corresponds to learn a parametric function that maps from a sample’s multi-class margin to an importance weight. Extensive experiments demonstrate that the proposed method improves both clean and robust accuracy compared to related techniques and state-of-the-art baselines."
SP:3ad36be6b6900aabe43da043461cf178ce977082,"This paper proposes a method for steerable equivariant graph neural networks (SEGNNs) that can incorporate geometric and physical information in both the message and update functions. Specifically, the authors define steerable node attributes and non-linear message aggregation. The authors also propose a new class of activation functions for general use with steerable feature fields. Experiments are conducted on several tasks in computational physics and chemistry."
SP:8928aa83f7ebd4e310f4fe1d01ff0eb0c96e4d2b,"This paper proposes a new differentiable physics model for differentiable fabrics for composite materials such as cloths. The authors propose several differentiable forces, whose counterparts in empirical physics are indifferentiable, to facilitate gradient-based learning. They demonstrate their model’s explicability in learning meaningful physical parameters, versatility in incorporating complex physical structures and heterogeneous materials, data-efficiency in learning, and high-fidelity in capturing subtle dynamics."
SP:2c8358c095b10981d3015b9f6c75765419a9480d,"This paper proposes a method for transfer learning in the context of reinforcement learning, where the goal is to learn a policy for a new task that maximizes the performance of the learned policy on the new task. The method is based on the idea of logical composition in reinforcement learning. In particular, the authors consider the case where the agent has access to a set of base tasks and a new set of tasks, and the goal of the agent is to decide whether it should learn a task-specific skill (e.g. a new skill) or not. The authors provide theoretical analysis of the transfer learning problem, and provide bounds on the necessary and sufficient number of tasks that need to be learned throughout an agent’s lifetime to generalise over a distribution. The paper also provides experimental results in a series of experiments, where they show that the proposed method can be used to learn new tasks with sub-logarithmic learning rates. They also demonstrate that as a side effect of their approach, an agent can produce an interpretable Boolean expression of its understanding of the current task."
SP:c85d71d05164d019cc32bf423e4c4fe20c169f41,"This paper proposes a distributed method for multivariate time series classification (MTSC) based on wavelet scattering. The main idea is to use wavelets to reduce the number of channels used in the original random convolutional kernel (ROCKET) method, which is a popular method for MTSC. The authors show that by using wavelets, they can use only 2,5% of the features of the original RKHS method and achieve comparable accuracy. They also show that the proposed method can scale well with more nodes and large channels."
SP:db43614ca016280a79448f44a97c81c8ff5ba981,"This paper proposes a method for pretraining text encoders with an Adversarial learning curriculum via a Mixture Of Signals from multiple auxiliary generators. The main encoder is trained as a discriminator to detect replaced tokens generated by auxiliary masked language models (MLMs). Different from ELECTRA which trains one MLM as the generator, the authors jointly train multiple MLMs of different sizes to provide training signals at various levels of difficulty. The authors propose to learn mixture weights over the auxiliary MLMs’ outputs to maximize the discriminator loss by backpropagating the gradient from the discriminators via Gumbel-Softmax. For better pretraining efficiency, they propose to assemble multiple auxiliary models into one unified auxiliary model."
SP:db3825633ab5d0671340390b23ab655838cc38b2,"This paper proposes an adaptive fine-tuning method for relational fact extraction from pre-trained language models by a clozestyle sentence serving as a query. The authors propose to use a small training dataset of existing facts from a knowledge graph to train a language model on the standard fill-mask task using a small number of facts from the knowledge graph. They evaluate the performance of the proposed method on a variety of datasets and compare it with the standard prompt-based methods. The results show that the proposed approach outperforms all baselines, even by using significantly fewer training facts. "
SP:ae25d32714b2b9f7e02cc20f4a36252e20e78e4f,"This paper proposes a representation learning framework for knowledge base embeddings in different geometric spaces and applies manifold alignment to align the shared entities. The proposed method is evaluated on the out-of-taxonomy entity typing task, where the goal is to predict the types of entities from the knowledge graph. The authors evaluate the proposed method on two datasets based on YAGO3 and demonstrate that their approach has significantly good performances."
SP:9ab3bc525ee4a9c96518c43e4c43082655a7674f," is a one-shot learning framework for link prediction in temporal knowledge graphs. The proposed method employs a self-attention mechanism to effectively encode temporal interactions between entities, and a network to compute a similarity score between a given query and a (one-shot) example. The experiments show that the proposed algorithm outperforms the state-of-the-art baselines for two well-studied benchmarks."
SP:91f92a40e12afd0702f07ae7f4175ecce57b7007,This paper proposes a method for learning a model for visual reasoning tasks. The model is based on a neural network architecture that learns to query existing modules and composes their outputs in order to produce its own output. The method is evaluated on a set of visual reasoning benchmarks and compared with a baseline model. The authors show that their model is more interpretable than an attention-based baseline. 
SP:de33b02e7f2faec5bcae9a5516721aa1ef190572,"This paper proposes a method for improving the efficiency of deep convolutional neural networks (CNNs) with bottlenecks. In particular, the authors propose a method called Selective Convolutional Unit (SCU) that gradually learns the channel-selectivity on-the-fly via the alternative usage of (a) pruning unimportant channels, and (b) rewiring the pruned parameters to important channels. The authors demonstrate that the SCU-based models without any postprocessing generally achieve both model compression and accuracy improvement compared to the baselines, consistently for all tested architectures."
SP:2d80fa4bc440061be2234b5070503d3fa056baed,"This paper studies the problem of learning a binary classifier only from positive data and unlabeled data (PU learning). The authors propose a method to partially identify the classifier. The proposed algorithm learns a scoring function that preserves the order induced by the class posterior under mild assumptions, which can be used as a classifier by setting an appropriate threshold. The authors show that the proposed algorithm outperforms previous methods for PU learning on various real-world datasets."
SP:5f312626b0613d2e07c59214c5f00db208a98717,"This paper proposes a method to detect when an auxiliary loss is helpful to the main loss by using cosine similarity between gradients of tasks as an adaptive weight. The authors show that their approach is guaranteed to converge to critical points of the main task and demonstrate the practical usefulness of the proposed algorithm in a few domains: multi-task supervised learning on subsets of ImageNet, gridworld, and reinforcement learning on Atari games."
SP:e270ae3eeb7ab4fa91ba37d4d68ce10f2fa0a3b5,"This paper proposes a geometric framework to analyze the high-dimensional geometry of adversarial examples in machine learning models. In particular, the authors show that for low-dimensional data manifolds, there are many directions off the manifold in which to construct adversarial example. The authors also show that adversarial training in balls around the data is sample inefficient, and provide sufficient sampling conditions under which nearest neighbor classifiers and ball-based adversarial learning are robust."
SP:e07d948a79d478ecd23a0a4406d4ddd3ac5e3be3,"This paper proposes a new representation learning method for time series data. The authors propose to learn discrete representations of time series using a gradient-based self-organizing map algorithm and a Markov model in the representation space. The proposed method is evaluated on three datasets: Fashion-MNIST, a chaotic Lorenz attractor system, and a challenging real-world medical time series application on the eICU data set. The results show that the proposed method achieves better clustering performance and interpretability."
SP:5915ee71ea58dbdbafa31c1ad291d1e5940a0cf4,"This paper investigates the properties of multidimensional probability distributions in the context of latent space prior distributions of implicit generative models. The authors show that the distribution mismatch can be eliminated completely by a proper choice of the latent probability distribution or using non-linear interpolations. They prove that there is a trade-off between the interpolation being linear, and the latent distribution having even the most basic properties required for stable training, such as finite mean. They also provide a general method of creating non- linear interpolations, that is easily applicable to a large family of commonly used latent distributions."
SP:19b63ca635712f1509ca6e0141303c192f2709e0,"This paper proposes to use hyperbolic embeddings for the attention mechanism of deep neural networks. The main idea is to learn the parameters of a shallow neural network in a Euclidean space, where the number of objects grows exponentially for any semantic distance from the query. The authors propose to use the embedding space more efficiently by only changing the geometry of embedding of object representations. The proposed method shows improvements in generalization on neural machine translation on WMT’14 (English to German), learning on graphs (both on synthetic and real-world graph tasks) and visual question answering (CLEVR) tasks while keeping the neural representations compact."
SP:f6049e9f80a63c9306c1cebcb6b229aa6da44ddc,"This paper studies the problem of cache side-channel attacks that extract the architecture information of deep neural networks (DNNs). The authors propose two attacks: DeepRecon, an attack that reconstructs the architecture of the victim network using the internal information extracted via Flush+Reload, a cache side channel technique. The authors also demonstrate that an attacker can build a meta-model that accurately fingerprints the architecture and family of the pretrained model in a transfer learning setting. Finally, the authors propose and evaluate new framework-level defense techniques that obfuscate our attacker’s observations."
SP:6a3dd89db6c24a1f98e8866ef0a4c1c2c1ec6635,"This paper proposes a hierarchical network model for video sequence prediction. The model is inspired by the feedforward, feedback and lateral recurrent circuits in the mammalian hierarchical visual system. It assumes that spatiotemporal memories are encoded in the recurrent connections within each level and between different levels of the hierarchy. Within each level, the feed-forward path and the feedback path intersect in a recurrent gated circuit that integrates their signals as well as the circuit’s internal memory states to generate a prediction of incoming signals. The network learns by comparing the incoming signals with its prediction, updating its internal model of the world by minimizing the prediction errors at each level of the hierarchical hierarchy in the style of predictive self-supervised learning. Experiments show that hierarchical interaction in the network introduces sensitivity to memories of global movement patterns even in the population representation of the units in the earliest level."
SP:fb74e57f35666742caf651e6da33b5defcf259a8,"This paper proposes a method to compute continuous embeddings for DNA sequences from raw RNA-seq data in a reference-free fashion. The proposed method is based on a neural network architecture that computes a latent embedding space for DNA sequence similarity and DNA sequence abundance. The authors show that their model captures information of both DNA sequences similarity as well as DNA sequences abundance in the embedding latent space. They confirm the quality of these vectors by comparing them to known gene sub-structures and report that the latent space recovers exon information from raw RNSeq data from acute myeloid leukemia patients. Furthermore, this latent space allows the detection of genomic abnormalities such as translocations and patient-specific mutations."
SP:03aca6ff6a7f0ad2d5ccbcb15ed9536e305a9880,"This paper proposes a method for model compression based on the architecture of the network. The authors propose to use a 1-D CNN encoder/decoder to learn a mapping from discrete architecture space to a continuous embedding and back. This embedding is jointly trained to regress accuracy and parameter count in order to incorporate information about the architecture’s effectiveness on the dataset. During the compression phase, they first encode the network and then perform gradient descent in continuous space to optimize a compression objective function that maximizes accuracy and minimizes parameter count. The final continuous feature is then mapped to a discrete architecture using the decoder. Experiments are conducted on CIFAR-10/100, FMNIST and SVHN and achieve a greater than 20x compression."
SP:0511b5d10a90e3fe814e2d35208b4a987894ea62,"This paper proposes a method for planning online and learning offline, where the agent has an internal model and needs to continually act and learn in the world. The method is based on the synergistic relationship between local model-based control, global value function learning, and exploration. The authors study how local trajectory optimization can cope with approximation errors in the value function, and how approximate value functions can help reduce the planning horizon and allow for better policies beyond local solutions. Finally, trajectory optimization is used to perform temporally coordinated exploration in conjunction with estimating uncertainty in value function approximation. This exploration is critical for fast and stable learning of value function."
SP:771494fda4702cd8c7efbf225b19028f91b449b9,"This paper proposes a zero-shot dual learning method for neural machine translation (NMT). The method is based on reinforcement learning, where the goal is to learn a model that can be used for both zero shot and dual learning. The model is trained on English-French and English-Spanish, and is evaluated on the UN corpus and the newstest 2014 dataset. The results show that the proposed method outperforms the LSTM-based unsupervised NMT system proposed in (Lample et al., 2018b), on the en-to-en task, while on the fr-toen task it outperforms both LSTMs and Transformers-based models."
SP:1558dc03f99670f9ddccdca9c223a2baf962d438,"This paper studies the problem of information-retrieval (IR) in the context of GANs. The authors point out that the proposed IRGAN framework is not exactly adversarial, and propose a co-training setup where the two models are trained in a cooperative manner. The paper also proposes a new baseline term for IRGAN, which is based on the information retrieval framework. The main contribution of the paper is the analysis of the loss curves of IRGAN and the proposed co-learning setup."
SP:6a13dda852ab075a3c0fb691476d6dc57919c729,"This paper proposes a variational auto-encoder (VAE) based approach to model sparsity in the latent space of a VAE with a Spike and Slab prior distribution. The authors derive the evidence lower bound using a discrete mixture recognition function, thereby making approximate posterior inference as computational efficient as in the standard VAE case. The proposed approach is evaluated on MNIST and Fashion-MNIST and shows improved classification accuracy and significantly increased robustness to the number of latent dimensions."
SP:06a22143186fa2948fbe324ccae96a62ff12064e,"This paper proposes a non-adversarial feature matching-based approach to train generative models. The proposed method, Generative Feature Matching Networks (GFMN), leverages pretrained neural networks such as autoencoders and ConvNet classifiers to perform feature extraction. The experimental results demonstrate that the proposed method can achieve state-of-the-art results for challenging benchmarks such as CIFAR10 and STL10."
SP:2d7cf2f07a27d6c8e304a1b47c25387ad2e4432d,"This paper studies the expressive power of graph neural networks (GNNs) in the context of graph classification tasks. The authors provide a theoretical analysis of the expressive properties of GNNs, and show that the discriminative power of popular GNN variants such as Graph Convolutional Networks and GraphSAGE cannot learn to distinguish certain simple graph structures. Then, the authors propose a simple architecture that is provably the most expressive among the class of Graph Neural Networks and is as powerful as the Weisfeiler-Lehman graph isomorphism test. Empirical results on several graph classification benchmarks validate the theoretical findings."
SP:51126f2dd37ce57d2614c9044ede1e43627f0829,"This paper proposes a method for interpretable continual learning (ICL) based on variational variational continual learning. The main idea is to use saliency maps to provide explanations of previously performed tasks and propose a new metric to assess the quality of the explanations. Experiments show that ICL achieves state-of-the-art results in terms of overall continual learning performance as measured by average classification accuracy, and also as measured qualitatively and quantitatively using the proposed metric."
SP:27a565b3e5442b93d208652784051e640b0c1bfe,"This paper proposes a new evaluation framework for adversarial attacks on neural sequence-to-sequence models taking meaning preservation into account. Specifically, the authors propose a new constraint for attacks on word-based machine translation systems and show, via human and automatic evaluation, that they produce more semantically similar adversarial inputs. Furthermore, they show that performing adversarial training with meaning-preserving attacks is beneficial to the model in terms of adversarial robustness without hurting test performance."
SP:54ddd8132bf9e4259d2c2d72b348d2bb5f9e227c,"This paper proposes to combine the policies using original rewards and inverse (negative) rewards to improve the performance of reinforcement learning algorithms. In particular, the authors propose to use deep Q-learning, double-Q-learning and on-policy actor-critic as the policies. The authors show that the proposed policies are competitive with the original policies and help the original policy correct its mis-actions. The experiments on OpenAI gym show the effectiveness of the proposed methods."
SP:89a732b57934d08b937c93560f391b7758e54f8a,"This paper proposes a method for learning a hierarchical, disentangled object representation and a dynamics model for object parts from unlabeled videos. The model learns to recognize the object parts via a layered image representation, predict hierarchy via a structural descriptor that composes low-level concepts into a hierarchical structure, and model the system dynamics by predicting the future. Experiments on multiple real and synthetic datasets demonstrate that the proposed method works well on all three tasks: segmenting object parts, building their hierarchical structure and capturing their motion distributions."
SP:bb2a655d67bed9da43f0b8ec7d888b89c217d12e,"This paper proposes Deep Determinantal Generative Classifier (DDGC), which is a generative classifier on top of a discriminative deep model. The main idea is to use the minimum covariance determinant estimator (MCE) to estimate the parameters of the classifier. The proposed method is evaluated on CIFAR-10 dataset with noisy labels and adversarial perturbations. The experimental results show that the proposed method can improve the classification accuracy."
SP:0fa525cc708470b757a60117cb608bb2feaa2c50,"This paper proposes an incremental unsupervised method for subgoal discovery in Hierarchical Reinforcement Learning (HRL). The proposed method is based on incremental learning over a small memory of the most recent experiences of the agent. The method learns subgoals and skills together, based on experiences in the environment. The authors demonstrate the efficiency of their method on two RL problems with sparse delayed feedback."
SP:e5861538bc8bb9165cb33299bbf12dd875abf976,"This paper proposes a neural architecture for solving Circuit Satisfiability problems. The architecture is based on a rich embedding architecture that encodes the problem structure, and an end-to-end differentiable training procedure that mimics Reinforcement Learning and trains the model directly toward solving the SAT problem. The experimental results show the superior out-of-sample generalization performance of the proposed method compared to the recently developed NeuroSAT method."
SP:ff3e5d44619df3825632b0b1a943add081364861,"This paper proposes a combination of cross-entropy method (CEM) and Twin Delayed Deep Deterministic Policy Gradient (TD3) to improve the sample efficiency of off-policy deep reinforcement learning (RL) algorithms. In particular, the authors propose to combine TD3 and CEM in order to improve sample efficiency. The authors evaluate the proposed method on a set of benchmarks classically used in deep RL and show that CEM-RL outperforms its competitors."
SP:78b2eb326695da0b0cc4ba39a9206d11644a5e32,This paper proposes a multi-variable LSTM recurrent neural network (IMV-LSTM) for multi-variate time series forecasting and knowledge extraction. The proposed method is based on a mixture attention mechanism and a summarization method to quantify the temporal and variable importance in data. Extensive experiments using real datasets demonstrate the prediction performance and interpretability of IMV-lSTM in comparison to a variety of baselines.
SP:1c26660569b579f060f7b4a31e321c6d2356b928,"This paper proposes feature smoothing, a simple data augmentation method for adversarial defense against adversarial attacks. Feature smoothing trains a neural network on virtual training data as an interpolation of features from a pair of samples, with the new label remaining the same as the dominant data point. The intuition is to generate virtual data points as close as adversarial examples, and to avoid the computational burden of generating data during training. The experiments on MNIST and CIFAR-10 datasets explore different combinations of known regularization and data augmentations methods, and show that feature-smoothing with logit squeezing performs best for both adversarial and clean accuracy."
SP:88d652f9e411dd3a2e9ad651d9011e579653c6aa,"This paper proposes a novel theoretical framework for deep neural networks with ReLU nonlinearity. The framework is built upon teacher-student setting, by projecting the student's forward/backward pass onto the teacher's computational graph. The authors do not impose unrealistic assumptions (e.g., Gaussian inputs, independence of activation, etc). The framework could help facilitate theoretical analysis of many practical issues, e.g. disentangled representations in deep networks."
SP:7842bbe0e2324cfd732db8745550733ccc3dfcdc,"This paper proposes a modular architecture of neural networks with a Behavioral Module (BM) and corresponding end-to-end training strategy. This approach allows efficient learning of behaviors and preferences representation. This property is particularly useful for user modeling (as for dialog agents) and recommendation tasks, as it allows learning personalized representations of different user states. The experiments also show network extendability through independent learning of new behavior patterns. Moreover, the authors demonstrate a strategy for an efficient transfer of newly learned BMs to unseen tasks."
SP:300c391ff644b6889cd9ae27cf0d162dfcdd4451,"This paper proposes a differentiable formulation for the neuromodulation of plasticity in neural networks. This formulation is based on differentiable Hebbian plasticity, which can be used to train neural networks with gradient descent. The authors show that this formulation is able to improve the performance of neural networks on both reinforcement learning and supervised learning tasks. In particular, they show that the differentiable plasticity can be applied to a neural network with millions of parameters."
SP:1ab5d94d31e99351433436c026799c8aa597bf73,"This paper proposes a novel quantization method for deep neural networks. The authors propose to re-train the full precision model, followed by directly optimizing the corresponding binary model. They also propose a new loss function to regularize the weights, resulting in reduced quantization error. Experiments on CIFAR and WikiText-2 show the effectiveness of the proposed method."
SP:0876b1d9a6d664808ca1ab15865679fbf638267e,"This paper proposes a method for open-ended style transfer onto open-ended content. The method is based on a VAE-VAE architecture with a style encoder and a content encoder. The authors propose to use an auxiliary loss, leakage filtering, to ensure that no style information remains in the content representation is used for reconstruction and vice versa. The proposed method is evaluated on few-shot learning tasks and achieves state-of-the-art performance."
SP:d37e15cde7765fca87595a242f0a4511b3346d46,"This paper proposes a new method to speed up deep reinforcement learning (deep RL) training for problems that have the property of state-action permissibility (SAP). Two types of states are defined under SAP: (1) states where the agent can decide whether the action at is permissible or not permissible in state st+1, and (2) states that even without performing an action at in st, the agent is able to decide whether at is permitted or not in st. The paper proposes to incorporate the proposed SAP property into two state-of-the-art deep RL algorithms to guide their state-actions exploration."
SP:20015d8b60e13300586b67c281858cbe28825c48,"This paper studies the behavior of weight-tied multilayer vanilla autoencoders under the assumption of random weights. Via an exact characterization in the limit of large dimensions, the analysis reveals interesting phase transition phenomena when the depth becomes large. This, in particular, provides quantitative answers and insights to three questions that were yet fully understood in the literature. Firstly, it provides a precise answer on how the random deep weight-Tied autoencoder model performs “approximate inference” as posed by Scellier et al. (2018), and its connection to reversibility considered by several theoretical studies. Secondly, it shows that deep autoencopers display a higher degree of sensitivity to perturbations in the parameters, distinct from the shallow counterparts. Thirdly, it obtained insights on pitfalls in training initialization practice, and demonstrated experimentally that it is possible to train a deep auto-encoder, even with the tanh activation and a depth as large as 200 layers, without resorting to layer-wise pre-training or batch normalization."
SP:91764f80dbe2401ade38b35a8253ba05f0f86386,"This paper proposes a new adversarial black-box attack method based on the discrete cosine transform (DCT) algorithm. The key idea is to randomly pick a low frequency component of the DCT and either add or subtract it to the target image. The proposed method can be used for both targeted and untargeted attacks, and it can be implemented in less than 20 lines of PyTorch code. The authors demonstrate that the proposed algorithm can produce adversarial ImageNet images with a median of 600 model queries (ResNet-50) and successfully attack Google Cloud Vision with 2500 median queries."
SP:fc20ae0fbf57a1ce489c04b85c7c2f4c93dc2450,"This paper proposes a method for option discovery in hierarchical reinforcement learning. The authors propose a new model called Successor options that leverages Successor representations to achieve the same goal of discovering “landmark” sub-goals which are points from which a densely connected set of states are easily accessible. They also design a novel pseudo-reward for learning the intra-option policies. Finally, they describe an incremental options model that iteratively builds options and explores in environments where exploration through primitive actions is inadequate to form the successor representations. They demonstrate the efficacy of their approach on a collection of grid worlds and on complex high dimensional environments."
SP:12a172c1e2892d016b37932acfc48dcb56874a89,"This paper studies the problem of domain division which aims to segment instances drawn from different probabilistic distributions. The authors propose a domain division algorithm to split the testing instances into known, unknown and uncertain domains, and then conduct recognition tasks in each domain. Two statistical tools, namely bootstrapping and KolmogorovSmirnov (K-S) Test, are introduced to uncover and fine-tune the decision boundary of each domain, and the uncertain domain is newly introduced in the framework to adopt those instances whose domain labels cannot be predicted confidently. Extensive experiments demonstrate the state-of-the-art performance on OSL and G-ZSL benchmarks."
SP:28bcf7c6a4673e9ec2b4ebed09839d85188e0b2a,"This paper proposes a neural network for classification and regression, without the need to learn layout structures in the output space. The structure is defined by polar prototypes, points on the hypersphere of the output spaces. For classification, each class is described by a single polar prototype and they are a priori distributed with maximal separation and equal shares. For regression, training can be performed as a polar interpolation between two prototypes, arriving at a regression with higher-dimensional outputs. Experiments show that polar prototype networks benefit from large margin separation and semantic class structure, while only requiring a minimal amount of output dimensions."
SP:d1034342785d133cf8372b8624897963cc2ee83a,"This paper proposes a method for learning a policy for reinforcement learning (RL) in an environment where the state of the environment is already optimized for what the agent wants to do. The authors argue that this is because the agent has access to a set of preferences for what to do and what not to do in the environment, and that these preferences are already satisfied in our environment. The paper proposes to use this implicit preference information from the state to fill in the blanks. The algorithm is based on Maximum Causal Entropy IRL (MCE) algorithm and is evaluated in a suite of proof-of-concept environments designed to show its properties. "
SP:417a4e0acee699b3e004ad30d0ecf533a9ed987e,"This paper proposes a method for learning the dependency structure between latent variables in deep latent variable models. The proposed method combines the complementary strengths of deep generative models and probabilistic graphical models. In particular, the authors express the latent variable space of a variational autoencoder (VAE) in terms of a Bayesian network with a learned, flexible dependency structure. The network parameters, variational parameters as well as the latent topology are optimized simultaneously with a single objective. Inference is formulated via a sampling procedure that produces expectations over latent variable structures and incorporates top-down and bottom-up reasoning over latent variables values. Experiments on MNIST, Omniglot, and CIFAR-10 show improvements over state-of-the-art structured VAEs."
SP:976dedab53e69610692a563382ada1dbb82c1e9d,This paper proposes a dynamical neural network (DNN) architecture for solving dictionary learning problems. The main idea is to use spiking neurons to construct the dynamical network. The authors show that the gradients for learning are provably computable by individual neurons in the DNN. The paper also provides a theoretical analysis of the dynamics of the network and its gradients. 
SP:f45117a6beaeb86a70b1380b4fac3cfba37fb892,"This paper proposes a novel network for lane detection. The proposed network consists of multiple encoder-decoders module in end-to-end ways and show the promising results for the lane detection task. In addition, the authors analyze different configurations of the encoder and decoder networks and propose to rethink the evaluation methods of lane detection for the limitation of the popular IoU. "
SP:68b0a10ca06df74612d0753cc3f3ddddde806035,"This paper proposes a new method for batch contextual bandit learning from logged bandit feedback. The proposed method is based on Maximum Likelihood Inverse Propensity Scoring (MLIPS), which is a variant of inverse propensity scoring (IPS) and Policy Optimizer for Exponential Models (POEM). The main idea is to estimate a maximum likelihood surrogate policy based on the logged action-context pairs, and then use this surrogate policy as the proposal. The authors prove that MLIPS is asymptotically unbiased, and moreover, has a smaller nonasymptotic mean squared error than IPS. Experiments on multi-label classification problems and a large-scale ad placement dataset demonstrate the empirical effectiveness of MLIPS."
SP:8e0ed65c5dded23b34798499b2436b24422fd729,"This paper proposes a new meta-learning method for few-shot classification. The proposed method is based on the idea of learning an individualized feature embedding specific to a given query image for better classifying, i.e., given a query image, a kernel generator is used to learn to construct feature embeddings for query images. The kernel generator acquires meta-knowledge of generating adequate convolutional kernels for different query images during training, which can generalize to unseen categories without fine-tuning. Experiments on Omniglot and miniImageNet show that the proposed method can achieve competitive performance."
SP:faa3f7ffdcfb6e3b8ec0421193dae3d9987b015c,"This paper proposes a population-based genetic algorithm (GA) for deep reinforcement learning (RL) that can evolve the weights of a DNN with a simple, gradient-free, population based genetic algorithm and it performs well on hard deep RL problems, including Atari and humanoid locomotion. The Deep GA successfully evolves networks with over four million free parameters, the largest neural networks ever evolved with a traditional evolutionary algorithm. The results (1) expand our sense of the scale at which GAs can operate, (2) suggest intriguingly that in some cases following the gradient is not the best choice for optimizing performance, and (3) make immediately available the multitude of neuroevolution techniques that improve performance."
SP:dfdbe3267a8160f24746884cdf5297993e424231,"This paper proposes a novel curiosity module for reinforcement learning. The novelty bonus is based on the comparison of the current observation with previous observations in memory. This is done based on how many environment steps it takes to reach the current observations from those in memory, which incorporates rich information about environment dynamics. The proposed method is evaluated on VizDoom, DMLab, and MuJoCo. "
SP:1e58a1c5344d1b5b7c8a40210a243700bd933d65,"This paper proposes a method for modeling transition models in complex uncertain domains using relational rules. For any action, a rule selects a set of relevant objects and computes a distribution over properties of just those objects in the resulting state given their properties in the previous state. An iterative greedy algorithm is used to construct a deictic references that determine which objects are relevant in any given state. Feed-forward neural networks are used to learn the transition distribution on the relevant objects’ properties. This strategy is demonstrated to be both more versatile and more sample efficient than learning a monolithic transition model in a simulated domain."
SP:8ce00a3fedbf54a7f2c1ff414511cbb7d59b4597,"This paper proposes a new instance-wise feature selection method, which is based on the actor-critic methodology. The method consists of 3 neural networks, a selector network, a predictor network, and a baseline network, which are used to train the selector network. The selector network is trained using the Actor-Critic methodology, and the predictor network is used to select the feature subsets of a different size for each instance. Experiments on synthetic and real data show that the proposed method outperforms the state-of-the-art methods."
SP:b91d6c33349df0bb6cb7e1c5e9433f0d4744b4da,"This paper proposes a method for semantic segmentation in the unlabeled target domain. The authors propose to learn discriminative feature representations of patches based on label histograms in the source domain, through the construction of a disentangled space. They then use an adversarial learning scheme to push the feature representations in target patches to the closer distributions in source ones. The proposed method is evaluated on several benchmark datasets with various settings, such as synthetic-to-real and cross-city scenarios."
SP:00922af13a21464cbc4cd7b34c196dd4f86c9247,"This paper proposes two new algorithms for online learning based on the observation that mini-batch of stochastic gradients in consecutive iterations do not change drastically and consequently may be predictable. Inspired by the similar setting in online learning literature called OPTIMISTIC ONLINE LEARNING, the authors propose two new optimistic algorithms for AMSGrad and Adam, respectively, by exploiting the predictability of gradients. The new algorithms combine the idea of momentum method, adaptive gradient method, and algorithms in OPTIMistic Online Learning to speed up the training of deep neural networks in practice."
SP:52228b48f2776d57dd422edb33b82e247f056b75,"This paper proposes a new benchmark for image classifier robustness, which is based on image corruption and perturbation. The paper is well-written and well-motivated, and the paper is easy to follow. The main contribution of this paper is the introduction of a new dataset called IMAGENET-P, which allows researchers to benchmark a classifier’s robustness to common perturbations. The authors also propose a bypassed adversarial defense method to improve the robustness of the classifier."
SP:20358ea0f769e6ea9222d8e35159d711ee1b20b2,"This paper shows that dropout training can be understood as performing MAP estimation for an entire family of conditional models whose objectives are lower bounded by the usual dropout objective. This discovery allows us to pick any model from this family after training, which leads to a substantial improvement on regularisation-heavy language modelling. The family includes models that compute a power mean over the sampled dropout masks, and their less stochastic subvariants with tighter and higher lower bounds. The deterministic subvariant’s bound is equal to its objective, and the highest amongst these models. It also exhibits the best model fit in the experiments."
SP:ac1b950ad29429ae045bb5e53279014a6a0b9d2b,"This paper proposes a new method to prune redundant filters of CNNs. The proposed method is based on cumulative saliency based soft pruning, which measures the global redundancy of the filter in the whole model by using the soft-pruning strategy. The authors also propose a reasonable normalization formula to prevent certain layers of filters in the network from being completely clipped due to excessive pruning rate. Experiments on MNIST and CIFAR-10 show that the proposed method achieves a much higher compression ratio compared with prior work."
SP:621e41d4199e333ec7f9d0936d4e34c918f39c11,"This paper proposes a cross-lingual document classification framework (CACO) between related language pairs. CACO uses a joint character representation for both the source language and the target language, which allows the embedder to generalize knowledge about source language words to target language words with similar forms. The embedder derives vector representations for input words from their written forms, and the classifier makes predictions based on the word vectors. The authors propose a multi-task objective that can further improve the model if additional crosslingual or monolingual resources are available."
SP:544e421f9c747640d949f433e3091763508b7237,"This paper proposes a novel method for weakly supervised temporal action localization. The proposed method is based on the marginalized average attentional network (MAAN), which learns a set of latent discriminative probabilities in an end-to-end fashion to suppress the dominant response of the most salient regions in a principled manner. Theoretically, the authors prove that the MAA module can reduce the difference in responses between the most relevant regions and the others. The authors also propose a fast algorithm to reduce the complexity of constructing MAA from O(2) to O(T). Extensive experiments on two large-scale video datasets show that the proposed method achieves a superior performance on weakly-supervised video localization."
SP:9f98c9bac99003741dd14e093b54d692c0b0e8d8,"This paper proposes a new representation for natural language processing (NLP) models based on the Holographic Reduced Representation (HRR) framework. HRR is a compositional representation of the word-level and chunk-level embeddings of a language model. The authors show that HRR can be used as a structured representation for NLP models, and that it is able to discover linguistic roles, which roughly resembles a classic division between syntax and semantics."
SP:5908b6acfed0e7c51e203c72eba907e6635e6c60,"This paper proposes a method for learning a POMDP model for partially observable Markov Decision Processes (POMDPs) where the agent has an active role in its perception by selecting which observations to receive. The authors argue that it is computationally intractable to integrate the perception decision with the planning decision due to the combinatorial nature of such selection process. To prevent such expansion of the action space, the authors propose a greedy strategy for observation selection that aims to minimize the uncertainty in state. They develop a novel point-based value iteration algorithm that incorporates the greedy strategy to achieve near-optimal uncertainty reduction for sampled belief points. This in turn enables the solver to efficiently approximate the reachable subspace of belief simplex by essentially separating computations related to perception from planning. The proposed solver is evaluated in a range of robotic scenarios where the robot simultaneously performs active perception and planning."
SP:0adec4abec17b3aab0c6eb69d11925dc20544950,"This paper proposes a curriculum loss for training deep neural networks. The main idea is to train top layers on “good” samples to reduce the distribution shifting, and encourage “bad” examples to learn from ‘good’ samples. The authors also propose an additional representation loss for low-weighted samples to encourage their training. The proposed curriculum loss is easy to combine with existing stochastic algorithms like SGD. Experimental results on CIFAR-10 and ImageNet demonstrate the effectiveness of the proposed method."
SP:8b555b9f24044bc68c204169d6a37e262361d706,"This paper presents a method for learning heuristics for combinatorial optimization problems. The authors propose a model based on attention layers with benefits over the Pointer Network and train this model using REINFORCE with a simple baseline based on a deterministic greedy rollout, which they find is more efficient than using a value function. With the same hyperparameters, they learn strong heuristic for two variants of the Vehicle Routing Problem (VRP), the Orienteering Problem (OP) and (a stochastic variant of) the Prize Collecting TSP (PCTSP), outperforming a wide range of baselines and getting results close to highly optimized algorithms."
SP:efb76bcf1dbd9a9cf6b5db74b5d4256a9f9e9e73,This paper proposes a method for quantizing different layers of neural networks with different bit-widths. The authors formulate the problem as a neural architecture search problem and propose a novel differentiable neural Architecture Search (DNAS) framework to efficiently explore its exponential search space with gradient-based optimization. Experiments on CIFAR-10 and ImageNet show that the proposed quantized models can achieve a 21.1x smaller model size or 103.9x lower computational cost compared to baseline quantized or full precision models.
SP:ea4173f8265bc50296de51c4ee7ecb6b8f78bec0,"This paper proposes a new architecture for neural networks based on posterior attention. The authors argue that the current attention architectures do not adequately model the dependence among the attention and output tokens across a predicted sequence. To this end, the authors propose to change the position where attention is marginalized is changed from the input to the output, and the attention propagated to the next decoding stage is a posterior attention distribution conditioned on the output. Empirical results on 5 translation and 2 morphological inflection tasks show that the proposed posterior attention models yield better BLEU score and alignment accuracy than existing attention models."
SP:987e2c14abc091d4d3ef9b48fb2046408eb1f59e,"This paper proposes a method for unpaired image-to-image translation. The authors propose to learn bi-directional translations between the source and the target domains by introducing a smoothness term over the sample graph to enforce consistent mappings during the translation process. The proposed method is evaluated on a variety of tasks including medical imaging, object transfiguration, and semantic labeling."
SP:885a69003bad0e79cb2872a4e5c772191ad7e34f,"This paper proposes a simple stochastic algorithm (h-detach) that is specific to LSTM optimization and targeted towards addressing the exploding and vanishing gradient problem (EVGP). Specifically, the authors show that when the weights of LSTMs are large, the gradient components through the linear path (cell state) in the computational graph get suppressed. Based on the hypothesis that these components carry information about long term dependencies (which they show empirically), their suppression can prevent LSTm from capturing them. The proposed algorithm prevents gradients flowing through this path from getting suppressed, thus allowing the LST mn to capture such dependencies better. The authors show significant improvements over vanilla L STM gradient based training in terms of convergence speed, robustness to seed and learning rate, and generalization."
SP:9aaff3777321347d1194884af5690b0b5185eff9,"This paper proposes SnapQuant, a method for training binary weight neural networks without layer-wise or filter-wise scaling factors. The method is based on Bayesian deep learning, where the objective is to approximate the posterior distribution of binary weights rather than reach a point estimation. The posterior distribution is parameterized as a policy network trained with a reinforcement learning scheme. During the training phase, the authors generate binary weights on the fly since what they actually maintain is the policy network, and all the binary weights are used in a burn-after-reading style. At the testing phase, they can sample binary weight instances for a given recognition architecture from the learnt policy network."
SP:29d1f6d0661a51e56c59bbb106da56700fc22d9a,"This paper proposes a Bayesian nonparametric framework for federated learning with neural networks. Each data server is assumed to train local neural network weights, which are modeled through the framework. An inference approach is then developed to synthesize a more expressive global network without additional supervision or data pooling. The experimental results demonstrate the efficacy of the proposed method on two popular image classification datasets."
SP:ab1f2bd216635d63450688866c729a501bd7e9d0,"This paper proposes a new algorithm for learning in differentiable games. The main idea is to interpolate between LOLA and a stable variant of LookAhead, which is a variant of LOLA. Theoretical analysis is provided to show that the proposed SOS algorithm converges locally to equilibria and avoids strict saddles. Experiments show that SOS outperforms LOLA on the Iterated Prisoner’s Dilemma."
SP:bdafb5fca09a775a8c92d2826d5dc977d28091c2,"This paper proposes an alarm system to set off alarms when the segmentation result is possibly unsatisfactory. The proposed method is based on the shape feature which is a strong prior information shared among different data, so it is capable to predict the qualities of segmentation results given different segmentation algorithms on different datasets. The VAE is able to detect all kinds of shapes that are out of the distribution of normal shapes in ground truth (GT). Finally, the representation in the one-dimensional feature space is learned by learning the representations in the low dimensional feature space. The results are evaluated on the medical segmentation task, and the system consistently provides reliable prediction."
SP:60738395d9efe2b3fe3a00c542ebb4261e54386c,"This paper proposes a simple network architecture for image denoising. The proposed method is based on a simple architecture with no convolutions and fewer weight parameters than the output dimensionality of the network. The authors show that the proposed network is on par with wavelet-based thresholding in terms of the quality of the denoised image. The network is simple in the sense that each layer has an identical structure that consists of only one upsampling unit, pixel-wise linear combination of channels, ReLU activation, and channelwise normalization. This simplicity makes the network amenable to theoretical analysis."
SP:1c9bad3bd4d670172f65aa0304e9837ecafc6b3d,"This paper presents an end-to-end neural network architecture for program synthesis from natural language (NL) specifications. The authors propose a pretrained word embedding and a bi-directional multi-layer LSTM for processing of word sequences. The decoder features a doubly-recurrent LSTMs, for which the authors propose novel signal propagation schemes and soft attention mechanism. The experimental results show that the proposed method performs on par with or better than the method proposed in the previous work."
SP:d2ec231bb6153a303e5110e671dea14c2721e636,"This paper studies the problem of adversarial robustness of deep neural networks against adversarial attacks on MNIST. The authors propose a novel class-conditional adversarial defense model that performs analysis by synthesis using learned class-conditioned data distributions. They derive bounds on the robustness and go to great length to empirically evaluate their model using maximally effective attacks by (a) applying decision-based, score based, gradient-based and transfer-based attacks for several different Lp norms, (b) by designing a new attack that exploits the structure of our defended model and (c) by devising a novel decision based attack that seeks to minimize the number of perturbed pixels (L0). The results suggest that our approach yields state-of-the-art robustness against L0, L2 and L∞ perturbations."
SP:91a24e7f4b952c37441feab4a7e8555014c856a4,"This paper proposes a reparameterization approach for the weight matrices of the discriminator in GANs, which allows us to directly manipulate the spectra of the weights matrices through various regularizers and constraints, without intensively computing singular value decompositions. Theoretically, the authors show that the spectrum control improves the generalization ability of GAN. Experiments on CIFAR-10, STL-10 and ImgaeNet datasets confirm that the proposed method is capable of generating images with competitive quality by utilizing spectral normalization and encouraging the slow singular value decay."
SP:8115fd9b681198d62100c36794926fb57dc0a4f5,"This paper proposes an accelerated value iteration method for reinforcement learning. The authors propose to accelerate the value iteration by using the Anderson acceleration technique, which is an approximation of the policy evaluation by interpolating on historical data. The paper also proposes a deep Q-learning algorithm based on the proposed method. The theoretical analysis of the proposed algorithm is provided, and experiments are conducted on both toy problems and Atari games."
SP:bd79b0c0af778a36008a0c0cf2fb6393fd2789d4,"This paper proposes a novel method to solve the catastrophic forgetting problem in the class incremental learning scenario. The proposed method combines the strength of deep learning and support vector machine (SVM) to identify the support data from the old data, which are fed to the deep learning model together with the new data for further training. Two powerful consolidation regularizers are applied to stabilize the learned representation and ensure the robustness of the learned model. The experimental results show that the proposed method significantly outperforms the state-of-the-art incremental learning methods."
SP:d228d213f79716774043cea253305fecece659ec,"This paper presents an empirical study of unit selectivity in AlexNet. The authors compare the performance of different measures of unit selection on the network, including localist, precision, CCMAS, class-conditional mean activity selectivity, and a new measure called top-class selectivity. They find that the precision and CCMAS measures provide a much higher level of selectivity than is warranted, with the most selective hidden units only responding strongly to a small minority of images from within a category. They also generate activation maximization (AM) images that maximally activated individual units and found that under (5%) of units in fc6 and conv5 produced interpretable images of objects, whereas fc8 produced over 50% interpretable image."
SP:b9deae0392e0160b400d76c549d382e235196f8c,"This paper proposes Graph Neural Networks (GNNs) for solving community detection problems in a supervised learning setting. In particular, the authors propose to augment GNNs with the non-backtracking operator defined on the line graph of edge adjacencies. They show that, in a data-driven manner and without access to the underlying generative models, they can match or even surpass the performance of the belief propagation algorithm on binary and multiclass stochastic block models, which is believed to reach the computational threshold in these cases. In addition, they show that under certain simplifications and assumptions, the loss value at any local minimum is close to that of the global minimum."
SP:a9ed31090e55f6152fc31c7512af5d634cc7225a,"This paper studies the problem of online dictionary learning, where the model is modeled as a linear combination of a few columns of a matrix known as a dictionary, and the sparse weights forming the linear combination are known as coefficients. Since the dictionary and coefficients, parameterizing the linear model are unknown, the corresponding optimization is inherently non-convex. This paper proposes a simple Neurally plausible alternating Optimization-based Online Dictionary Learning algorithm (NOODL) which recovers both dictionary and coefficient exactly at a geometric rate, when initialized appropriately. The proposed algorithm is scalable and amenable for large scale distributed implementations in neural architectures, by which they mean that it only involves linear and non-linear operations."
SP:85232b72a2643d6dc81cf952ccbb95192032b7c5,"This paper proposes a new loss function and training scheme for learning binary hash codes with any differentiable model and similarity function. The loss function uses log likelihood loss on top of an accurate approximation for the probability that two inputs fall within a Hamming distance target. The training scheme obtains a good estimate of the true gradient by better sampling inputs and evaluating loss terms between all pairs of inputs in each minibatch. To fully leverage the resulting hash codes, the authors use multi-indexing. The authors demonstrate that these techniques provide large improvements to a similarity search tasks."
SP:3bd4ccff7f48380d2db8dff2c4ca515894a7f1db,"This paper proposes Graph HyperNetwork (GHN) to automatically find the best task-specific neural network topology for neural architecture search (NAS) automatically. The authors propose to use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHN is fast – they can search nearly 10x faster than other random search methods on CIFAR-10 and ImageNet. GHNs can be further extended to the anytime prediction setting, where they have found networks with better speed-accuracy tradeoff than the state-of-the-art manual designs."
SP:65ccf43cd4e033d22239069057f5200d49f33724,This paper proposes a method to improve imitation learning by using additional information from non-expert demonstrations which are easier to obtain. The key idea of the proposed method is to perform multiclass classification to learn discriminator functions where non-experts demonstrations are regarded as being drawn from an extra class. Experiments on continuous control tasks demonstrate that the method learns better policies than the generative adversarial imitation learning baseline when the number of expert demonstrations is small.
SP:e8427949a98effbd37ce7604fa11f240e2342196,"This paper proposes a new class of neural networks, called Invertible Neural Networks (INNs), which aims to solve the inverse problem in the sense that the forward process from measurement space is well-defined, whereas the inverse process is ambiguous: multiple parameter sets can result in the same measurement. The authors argue that INNs are well-suited for this task because they focus on learning the forward processes, using additional latent output variables to capture the information otherwise lost. They prove theoretically and verify experimentally, on artificial data and real-world problems from medicine and astrophysics, that INN are a powerful analysis tool to find multi-modalities in parameter space, uncover parameter correlations, and identify unrecoverable parameters."
SP:75c9bb53bac29bdb390f9ba5707caee4ab1f5925,"This paper proposes a method for quantifying the uncertainty of deep neural networks (NNs) by using an adaptive, input-dependent distribution (specifying the probability of each component) represented by an NN and considering uncountably many mixture components. The proposed model can be seen as the continuous counterpart to mixture density networks and is therefore referred to as compound density networks. The authors empirically show that the proposed model results in better uncertainty estimates and is more robust to adversarial examples than previous approaches."
SP:e1e38289285c1b8fdb318e4f6d37a198a08787a2,"This paper proposes a new compression method for neural networks. The main idea is to relax weight determinism and use a full variational distribution over weights, which allows for more efficient coding schemes and consequently higher compression rates. In particular, following the classical bits-back argument, the authors encode the network weights using a random sample, requiring only a number of bits corresponding to the Kullback-Leibler divergence between the sampled Variational distribution and the encoding distribution. The proposed encoding scheme can be shown to be close to the optimal information-theoretical lower bound, with respect to the employed variational family. On the benchmarks LeNet-5/MNIST and VGG-16/CIFAR-10, the proposed method achieves the best test performance for a fixed memory budget."
SP:ad70d8cf3a4558aab0d3b7155594464a3debd912,"This paper proposes ProxylessNAS, an architecture search algorithm that directly learns the architectures for large-scale target tasks and target hardware platforms. The main contribution of this paper is to address the high memory consumption issue of differentiable NAS and reduce the computational cost (GPU hours and GPU memory) to the same level of regular training while still allowing a large candidate set. The paper also proposes to specialize neural architectures for hardware with direct hardware metrics (e.g. latency) and provide insights for efficient CNN architecture design. Experiments on CIFAR-10 and ImageNet demonstrate the effectiveness of directness and specialization."
SP:e5b70d43d301d1980fae02623ea711976b429c14,"This paper proposes to use second-order penalties for penalizing fairness in non-convex optimization problems. In particular, the authors argue that this is a more practical training procedure in large-data settings, as it avoids the instability and potential lack of convergence associated with two-player min-max games. The authors also derive a method for efficiently computing the gradients associated with the second order penalties in stochastic mini-batch settings. The proposed algorithm is evaluated on a number of standard benchmarks, and the proposed algorithm performs well."
SP:e4720b8e4efdb222c45eafd47fd8a7fbf15d881d,"This paper proposes a reweighted wake-sleep (RWS) algorithm for learning discrete latent variable models. RWS is based on the reweighting of the sleep-sleep algorithm (Bornschein & Bengio, 2015). The authors show that RWS outperforms the state-of-the-art methods in learning discrete models. The authors also show that the RWS algorithm can learn better models and inference networks with increasing number of particles, and that its benefits extend to continuous latent variables as well."
SP:7459ae5b1d886e68930c4c9e21df508bc8ab3c9a,"This paper proposes a method to train structured prediction energy networks (SPENs) for structured output prediction tasks, where the true output is unknown and the goal is to evaluate predictions using a scalar reward function, which may be easily assembled from human knowledge or non-differentiable pipelines. Instead of searching through the entire output space to find the best output with respect to this reward function is typically intractable. In this paper, the authors propose to use efficient truncated randomized search in the reward function to train SPENs, which provide efficient test-time inference using gradient-based search on a smooth, learned representation of the score landscape, and have previously yielded state-of-the-art results in structured prediction. In particular, this truncated Randomized Search (RNS) algorithm yields previously unknown local improvements, which provides effective supervision to SPEN."
SP:638c1bc09992029b78bd83f0127594dcccb96c06,"This paper proposes an active learning based framework for robust policy search. The proposed method is based on EPOpt, which is a method for learning robust policies that do not degrade in performance when subject to unseen environment model parameters. The authors propose a method to selectively choose model parameters for this purpose so as to collect only as much data as necessary to select such a subset. They also present a Multi-Task Learning perspective to the problem of Robust Policy Search, and draw connections from their proposed framework to existing work on multi-task learning. They apply this framework to an existing method, namely EPOpt and experimentally validate the gains in sample efficiency and the performance of their approach on standard continuous control tasks."
SP:491c239713a6489f0b1790ca26db54a1813c67ae,"This paper proposes a two-timescale network (TTN) architecture that enables linear methods to be used to learn values, with a nonlinear representation learned at a slower timescale. The authors prove convergence for TTNs, with particular care given to ensure convergence of the fast linear component under potentially dependent features provided by the learned representation. They empirically demonstrate the benefits of TTNs compared to other nonlinear value function approximation algorithms, both for policy evaluation and control."
SP:327d606cf3813b00a009a7785e08ef9e11f89493,"This paper proposes a model-based and model-free approach to planning and planning with semantic regularities in the context of man-made environments. The approach consists of a multi-target sub-policy that acts on visual inputs, and a Bayesian model over semantic structures. The agent plans with the semantic model to make high-level decisions, proposes the next sub-target for the sub-Policy to execute, and updates the model based on new observations. The proposed method is evaluated in visual navigation tasks using House3D, a 3D environment that contains diverse human-designed indoor scenes with real-world objects."
SP:d7c26f43bc68d160095b1f50447528843d79edbd,"This paper proposes a multi-task perception-related basic knowledge and driving knowledge stepwisely. Specifically, segmentation map and depth map (pixel level understanding of images) are considered as what & where and how far knowledge for tackling easier drivingrelated perception problems before generating final control commands for difficult driving task. The results of experiments demonstrated the effectiveness of multitask perception knowledge for better generalization and accident explanation ability."
SP:b6bd98cc70fab97e1245cbb63a42ef89ab7e7ed5,"This paper studies the trade-off between adversarial robustness and generalization in deep neural networks. The authors show that training robust models may not only be more resource-consuming, but also lead to a reduction of standard accuracy. They demonstrate that this tradeoff between the standard accuracy of a model and its robustness to adversarial perturbations provably exists even in a fairly simple and natural setting. Further, they argue that this phenomenon is a consequence of robust classifiers learning fundamentally different feature representations than standard classifiers."
SP:9c9275d75cd95b1b82e0cbb1421e3d3ade1ce33a,"This paper proposes a new method for gradient-based training of neural networks that uses only local learning rules and does not rely on neurons having a mechanism for back-propagating an error gradient. The authors propose Initialized Equilibrium Propagation, which trains a feedforward network to initialize the iterative inference procedure for Equilibrium propagation. This feed-forward network learns to approximate the state of the fixed-point using a local learning rule. The experiments show that this network appears to work as well or better than the original version of Equilibrium propagate while requiring fewer steps to converge. This shows how we might go about training deep networks without using backpropagation."
SP:ac9ea91eb465517de495477cf67bc94d5ed1b0cb,"This paper proposes a new zeroth-order stochastic optimization algorithm, ZO-signSGD, which enjoys the dual advantages of gradient-free operations and signSGD. The authors analyze the convergence rate of the proposed algorithm and propose several variants of the algorithm. In the application side, the authors explore the connection between the proposed method and black-box adversarial attacks in robust deep learning. The empirical evaluations on image classification datasets MNIST and CIFAR-10 demonstrate the superior performance of ZOSignSGD on the generation of adversarial examples from black- box neural networks."
SP:5f79b11777f6ef1d70c85418bfc2e4616dd7d960,"This paper proposes a method to reduce the computation efforts of convolutional neural networks. The authors propose to set a checkpoint in the multiply-accumulate (MAC) operations to determine whether a filter could terminate early based on the intermediate result. Furthermore, a fine-tuning process is conducted to recover the accuracy drop due to the applied checkpoints. The experimental results show that the proposed method can save approximately 50% MAC operations with less than 1% accuracy drop for CIFAR-10 example model and Network in Network on the Cifar-10 and CifAR-100 datasets."
SP:7801e9c854ad7d960c0d24fda15597af6994c23f,"This paper investigates the use of temporal dependency in audio data to improve the robustness of speech recognition systems against adversarial attacks. The authors propose to exploit the temporal dependency of audio data in order to increase the discriminative power of the adversarial attack. In particular, they propose to use the input transformation from image adversarial defense to improve robustness, and to use temporal dependency to improve adversarial robustness against audio adversarial examples. They show that temporal dependency can be exploited to gain discriminate power against audio attacks and is resistant to adaptive attacks. "
SP:51830b811a8e39b4f0a5b7609df719e026fac6a1,"This paper proposes a generative model that learns to generate images by means of compositional composition. The key idea is that the generator of a GAN should consider objects and their relations explicitly, and generate images that are compositional in nature. The paper proposes to learn the relation between the generated image and the original image, and to learn to disentangle information corresponding to different objects at a representational level. Experiments are conducted on several multi-object image datasets, and show that the proposed method is able to generate more accurate images than the state-of-the-art."
SP:fb59990b8da0e95d8202383478a456667de60449,"This paper proposes a method for learning disentangled representations from unlabelled images, where the only supervision comes from an auxiliary “reference set” that contains images where the factors of interest are constant. The authors propose a variational variational autoencoder model to exploit the weak supervisory signal provided by the reference set. During training, they use the variational inference framework where adversarial learning is used to minimize the objective function. Experiments are conducted on feature learning, conditional image generation, and attribute transfer tasks."
SP:dbc1983d9b9d72aa14f8e8515d793d2bbde26c9c,"This paper proposes a method for continual online learning from an incoming stream of data, using deep neural network models. The authors formulate an online learning procedure that uses stochastic gradient descent to update model parameters, and an expectation maximization algorithm with a Chinese restaurant process prior to develop and maintain a mixture of models to handle non-stationary task distributions. This allows for all models to be adapted as necessary, with new models instantiated for task changes and old models recalled when previously seen tasks are encountered again. Furthermore, the authors observe that meta-learning can be used to meta-train a model such that this direct online adaptation with SGD is effective, which is otherwise not the case for large function approximators. In this work, the proposed method is applied to model-based reinforcement learning, where adapting the predictive model is critical for control."
SP:5665e5f006f84927beb0440e145f476e02538077,"This paper studies the problem of training a distributed RL agent from experience replay. The authors propose to train an RNN-based DQN with a single network architecture and a fixed set of hyperparameters. The proposed method is evaluated on Atari-57 and DMLab-30 games, where the proposed method outperforms the state-of-the-art."
SP:47ace37f31a46d5ee85c283e62ddb71a12f2c5c4,"This paper proposes a hierarchical generative model for modeling multi-agent trajectories of basketball games. The authors propose a hierarchical framework that can learn sequential generative models that can capture long-term coordination using intermediate variables. The proposed model is inspired by recent work on leveraging programmatically produced weak labels, which extend to the spatiotemporal regime. In addition to synthetic settings, the authors show how to instantiate their framework to effectively model complex interactions between basketball players and generate realistic multi-Agent trajectories over long time periods."
SP:1a90cdf028068528b0559e7d44bf26dda20310bd,"This paper presents a method to integrate temporal information, from a learned dynamics model, with ambiguous visual information, with a learned vision model, in the context of interacting agents. The method is based on a graph-structured variational recurrent neural network (Graph-VRNN), which is trained end-to-end to infer the current state of the (partially observed) world, as well as to forecast future states. The proposed method outperforms various baselines on two sports datasets, one based on real basketball trajectories and one generated by a soccer game engine."
SP:8392f04b7265f665ba6d44d297bca245d44b4708,"This paper proposes a method for end-to-end training of a base neural network that integrates calls to existing blackbox functions. The base network is trained by approximating the black-box functionality with a differentiable neural network in a way that drives the base network to comply with the black box function interface during the optimization process. At inference time, the differentiable estimator is replaced with its external black box non-differentiable counterpart such that the network output matches the input arguments of the blackbox function. The integrated model generalizes better than a fully differentiable model, and learns more efficiently compared to RL-based methods."
SP:13fb86de763a0b34ac6fa34ea9dfbd1c476ce43e,This paper proposes a meta-learning method that combines the idea of hierarchical Bayesian models and model-agnostic meta learning (MAML) with gradient-based meta learning. The authors propose a stochastic expectation maximization procedure to jointly estimate parameter initializations for gradient descent as well as a latent assignment of tasks to initializations. This approach better captures the diversity of training tasks as opposed to consolidating inductive biases into a single set of hyperparameters. The experiments demonstrate better generalization performance on the standard miniImageNet benchmark for 1-shot classification.
SP:a410144dbe19713a06c63da87d9fb58b999a7492,"This paper proposes a meta-augmentation method for image classification, where the auxiliary task is hierarchical sub-class image classification. The meta-learner is a multi-task evaluator, which is trained to select the target labels for each auxiliary task. The proposed method is self-supervised and general. Experiments on three different CIFAR datasets show that MAXL outperforms baseline auxiliary learning methods, and is competitive even with a method which uses human-defined auxiliary tasks."
SP:76248e1c914c60ce69de244fe7ec62488d01e161,"This paper presents a neural network based representation for open set recognition. The proposed method is based on the idea that instances from the same class are close to each other while instances from different classes are further apart, resulting in statistically significant improvement when compared to other approaches on three datasets from two different domains. The paper is well-written and well-motivated."
SP:d4ee856bbf2dfb6390e5247086fec2e52dcb6858,"This paper studies the problem of finding low-precision networks that are close to the accuracy of the full precision baseline networks after one epoch of fine-tuning on ImageNet. The authors find that gradient noise due to quantization during training increases with reduced precision, and seek ways to overcome this noise. They propose to reduce solution distance by starting with pretrained fp32 baseline networks and fine-tuneing, and combat noise introduced by quantizing weights and activations during training, by using larger batches along with matched learning rate annealing. They also demonstrate that these techniques, coupled with proper activation function range calibration, offer a promising heuristic to discover low precision networks, if they exist, close to fP32 precision baseline network."
SP:6bfdc37b346e6ddfa049e0414647f4beda8ede3f,This paper proposes a method for predicting post-bounce trajectories of a ball bouncing off a surface. The method is based on a combination of a physics-based model (PIM) and a visual model (VIM) that learns to model the physical properties of a scene. The model is trained on a dataset of 5K RGB-D videos of bouncing trajectories from a foam ball bouncing on surfaces of varying shapes and materials in everyday scenes including homes and offices. The experiments show that the proposed method outperforms the state-of-the-art trajectory fitting with Newtonian physics.
SP:010bd055310c363d3cb0fbe0e11546de58220e15,"This paper studies the adversarial vulnerability of neural networks in the presence of adversarial perturbations. The authors show that the gradients of the training objective increase with the square root of the input size of the network. They prove that the `1-norm of these gradients grows as the square-root of the image size, and that the network becomes increasingly vulnerable with growing image size. The paper is well-written and well-motivated, and the experimental results are convincing."
SP:5fa3ae057e55be6b71cc94a7dbfe31e54e1c536f,"This paper proposes an imitation-based reinforcement learning method for interactive agent modeling. In particular, the probing agent learns to interact with the environment and with a target agent (i.e., a demonstrator) to maximize the change in the observed behaviors of that agent. Through probing, rich behaviors can be observed and are used for enhancing the agent modeling to learn a more accurate mind model of the target agent. The proposed method consists of two learning processes: i) imitation learning for an approximated agent model and ii) pure curiosity-driven reinforcement learning for a probing policy to discover new behaviors that otherwise can not be observed. The experimental results show that the agent model learned by the proposed method generalizes better in novel scenarios than the ones learned by passive observation, random probing, and other curiosity driven approaches do."
SP:3af184a5529d6ec2a0862efd1af80ef5b50d2952,"This paper proposes a modification to neural networks inspired by biological neuromodulators. Specifically, the authors introduce a new type of neural network architecture, called modulators, which allows the network to adjust its activation function based on the input patterns. The authors show that the modulators can be used to improve the performance of neural networks in the context of image classification and long-term memory."
SP:287a577834fd2820a939a1113b39146a22727491,"This paper presents a neural analysis and synthesis (NANSY) framework that can manipulate voice, pitch, and speed of an arbitrary speech signal. The authors propose a novel training strategy based on information perturbation. The idea is to perturb information in the original input signal (e.g., formant, pitch and frequency response), thereby letting synthesis networks selectively take essential attributes to reconstruct the input signal. Because NANSY does not need any bottleneck structures, it enjoys both high reconstruction quality and controllability. Furthermore, the authors do not require any labels associated with speech data such as text and speaker information, but rather uses a new set of analysis features, i.e., wav2vec feature and newly proposed pitch feature, Yingram, which allows for fully self-supervised training."
SP:90f35ad1ec0c38b0817f5678ee2a5c4f0e08fb38,"This paper studies the generalization properties of gradient-based bilevel programming (GBC) algorithms. The authors provide an expectation bound w.r.t. the validation set based on uniform stability. They also provide a lower bound for the classical cross-validation algorithm. In addition, they show that regularization terms in both the outer and inner levels of GBC can help alleviate the overfitting problem in gradient based algorithms. In experiments on feature learning and data reweighting for noisy labels, they corroborate their theoretical findings."
SP:42f52aec3a776d87daa5fd72b8e6325d12c88d63,"This paper proposes a novel knowledge distillation method for knowledge transfer between student and teacher models. The main idea is to train a student model on top of a pre-trained teacher model, and then distill the knowledge from the student model to the teacher model. The student model is trained jointly with the teacher models, and the student models are trained jointly to obtain student-friendly representations. Experiments show that the proposed method outperforms the state-of-the-art distillation methods in terms of accuracy and convergence speed."
SP:e15a1c21229233fd97dc1dfa0a4ef48b69dc9f95,"This paper studies the problem of generalization to out-of-distribution (OOD) data. The authors propose a new concept of expansion function, which characterizes to what extent the variance is amplified in the test domains over the training domains, and therefore give a quantitative meaning of invariant features. Based on these, the authors prove OOD generalization error bounds and show that the generalization performance depends on the expansion function. They also show that any OOD learning algorithm without a model selection module is incomplete. Extensive experiments on benchmark OOD datasets demonstrate that their model selection criterion has a significant advantage over baselines."
SP:37b04b9068d39bcf0a581eb8181d13cf1a8926bf,"This paper proposes a Variational Continual Bayesian Meta-Learning (VC-BML) algorithm for online meta-learning. The authors propose a Dynamic Gaussian Mixture Model for meta-parameters, with the number of component distributions determined by a Chinese Restaurant Process (CPR). The authors also propose a more robust posterior approximation method, structured variational inference for the sake of avoiding forgetting knowledge. Experiments on tasks from non-stationary distributions show that the proposed algorithm is superior in transferring knowledge among diverse tasks and alleviating catastrophic forgetting in an online setting."
SP:776d5b02b8d3a8bbcc1f52706f3887c384cb149e,"This paper proposes a probabilistic solution of boundary value problems (BVPs), which are ordinary differential equations subject to boundary conditions. The authors propose a Gauss–Markov prior and tailor it specifically to BVPs, which allows computing a posterior distribution over the solution in linear time, at a quality and cost comparable to that of well established, non-probabilistic methods. The model further delivers uncertainty quantification, mesh refinement, and hyperparameter adaptation. The experimental results demonstrate how these practical considerations positively impact the efficiency of the scheme."
SP:86aac0c6b75fdc12f84bba342934865616f866d4,"This paper studies the problem of learning a near optimal policy in episodic reinforcement learning in a reward-mixing Markov decision process (MDP). The reward function is drawn from one of multiple possible reward models at the beginning of every episode, but the identity of the chosen reward model is not revealed to the agent. The latent state space, for which the dynamics are Markovian, does not give the agent access to the state space. The authors provide a polynomial-time algorithm that finds an optimal policy after exploring $O(\sqrt{H})$ episodes, where $H$ is time-horizon and $S$ is the number of states and actions."
SP:1a3c70ae9cf2a806d603f4b9e7ca6e10b720a956,This paper proposes a method for conditional average treatment effect estimation for multi-causal interventions. The proposed method is based on augmenting the observational dataset with the estimated potential outcomes under single-cause interventions. It then performs covariate adjustment on the augmented dataset to obtain the estimator. The method is agnostic to the exact choice of algorithm in either step. The experimental results on synthetic and semi-synthetic experiments demonstrate the performance gain of the proposed method.
SP:247bc6675cce89d51558537daf63dadb0c4307f8,"This paper proposes a multi-wavelet-based neural operator learning scheme that compresses the associated operator’s kernel using fine-grained wavelets. By explicitly embedding the inverse multiwavelet filters, the proposed method learns the projection of the kernel onto fixed multi wavelet polynomial bases. This allows learning the complex dependencies at various scales and results in a resolution-independent scheme. The proposed method achieves state-of-the-art results on the Korteweg-de Vries (KdV) equation, Burgers’ equation, Darcy Flow, and Navier-Stokes equation."
SP:1153785e6a016cfee2644952a772aa08927299b6,"This paper proposes a novel method for training binary neural networks (BNNs) by approximating the gradient of sign function in the Fourier frequency domain using the combination of sine functions for training BNNs, namely frequency domain approximation (FDA). The proposed approach does not affect the low-frequency information of the original sign function which occupies most of the overall energy, and high-frequency coefficients will be ignored to avoid the huge computational overhead. In addition, the authors embed a noise adaptation module into the training phase to compensate the approximation error. The experiments on several benchmark datasets and neural architectures illustrate that the binary network learned using DA achieves the state-of-the-art accuracy."
SP:33b95ea8da4d30b8e8f9d3fe3acca023d4b8d831,"This paper proposes to use multi-area RNNs with neuroscience-inspired architecture constraints to derive key features of multi-Area computation. In particular, the authors show that incorporating multiple areas and Dale’s Law is critical for biasing the networks to learn biologically plausible solutions. The authors also leverage the full observability of the RNN to show that output-relevant information is preferentially propagated between areas. These results suggest that cortex uses modular computation to generate minimal sufficient representations of task information."
SP:db3ced65d67e3373fb3936ec50f41c8ef010bbbe,This paper proposes a method to search for multiple explanations for a single saliency map for image classification. The main idea is to use a beam search algorithm to systematically search for several explanations for each image. The authors propose structured attention graphs (SAGs) to represent sets of attention maps for an image by visualizing how different combinations of image regions impact the confidence of a classifier. An approach to computing a compact and representative SAG for visualization is proposed via diverse sampling. The paper conducts a user study comparing the use of SAGs to traditional saliency maps for answering counterfactual questions about image classifications.
SP:f2b385bfd9ada0e26aa8829214b424f58582d9f7,"This paper studies how the choice of training objective affects the transferability of the hidden representations of convolutional neural networks trained on ImageNet. The authors show that many objectives lead to statistically significant improvements in ImageNet accuracy over vanilla softmax cross-entropy, but the resulting fixed feature extractors transfer substantially worse to downstream tasks. The choice of loss has little effect when networks are fully fine-tuned on the new tasks. Using centered kernel alignment, the authors find that differences among loss functions are apparent only in the last few layers of the network."
SP:b66b5e24f68563e2e200eda660f0dbaff53efeff,This paper proposes a method to train a neural network that can infer the dynamics of neurons in a neural time series. The method is based on the idea of selective backpropagation through time (SBTT). The authors propose to train the model on a set of data points where the set of observed variables changes at each time step. The authors show that the learned model is able to infer activity for missing samples by combining observations with learned latent dynamics. They test SBTT applied to sequential autoencoders and demonstrate more efficient and higher fidelity characterization of neural population dynamics in electrophysiological and calcium imaging data.
SP:3513a83806e71006b86d60b779d8bd6bb87c3546,"This paper proposes a hierarchical approach to sequence-to-sequence learning with quasi-synchronous grammars, where each node in the target tree is transduced by a node in a source tree. The source and target trees are treated as latent and induced during training. The authors develop a neural parameterization of the grammar which enables parameter sharing over the combinatorial space of derivation rules without the need for manual feature engineering. They apply this latent neural grammar to various domains such as SCAN, style transfer, and small-scale machine translation."
SP:d06fc251f2a9287f7a2236a188349628d8f39d9a,This paper proposes a new algorithm to solve the Group Elastic Net problem in the context of function-on-scalar feature selection. The main idea is to use the sparsity structure of the Augmented Lagrangian to reduce the computational burden of the algorithm. The authors also extend the algorithm to the function on scalar regression framework and show that the proposed algorithm can achieve better performance than existing methods. 
SP:e0b53f76f3a6b756fedd09926f9cf034f89f4a5a,"This paper proposes a method to cluster repeatedly observed marked point processes to identify potential heterogeneity in the observed data. Specifically, the authors study a matrix whose entries are marked log-Gaussian Cox processes and cluster rows of such a matrix. An efficient semi-parametric Expectation-Solution (ES) algorithm combined with functional principal component analysis (FPCA) is proposed for model estimation. The effectiveness of the proposed framework is demonstrated through simulation studies and real data analyses."
SP:3aa213076f3e9f9838ac654517df2fe1fca33499,"This paper proposes an online meta-adaptive multi-task learning approach for adaptive nonlinear control. The main idea is to learn a shared representation of the dynamics of the system, which can then be used to adaptively control the system. The authors provide a convergence analysis for the proposed method, and show that it converges to a state-of-the-art convergence rate. The paper also provides a theoretical analysis of the convergence rate of the proposed algorithm. The experimental results show that the proposed approach outperforms existing methods in the inverted pendulum and 6-DoF tasks."
SP:cb274c93a169b199ea09120ca02105a3f16b31c5,"This paper proposes a new method for training neural networks with certifiable robustness guarantees. The method is based on interval bound propagation (IBP) and CROWN-IBP. The authors identify two important issues in existing methods, namely exploded bounds at initialization, and the imbalance in ReLU activation states and improve IBP training. To mitigate these issues and conduct faster certified training with shorter warmup, the authors derive a new weight initialization method and propose to fully add Batch Normalization (BN) to each layer in the model, since they find BN can reduce the imbalance of ReLU activations. The paper also design regularization to explicitly tighten certified bounds and balance ReLu activation states during wamrup. "
SP:18ffeb199a670fb2b1f4417b8653479001944dab,"This paper studies the problem of change point detection in the context of adversarial attacks. The authors propose a novel method that is robust against the Huber-contamination framework, which allows the contamination distributions to be different at each time point. The detection boundary is a function of the contamination proportion and is the first time shown in the literature. In addition, the authors derive the minimax-rate optimal localisation error rate, which quantifies the cost of accuracy in terms of contamination proportion. Extensive numerical experiments are conducted with comparisons to existing robust change point detectors methods."
SP:d03617b5fc446768809cf015c9234b0c9386a690,"This paper studies the power of learning via mini-batch SGD and batch gradient descent (GD) on the empirical loss of a differentiable model or neural network. In particular, the authors study the precision of the gradient calculations relative to the minibatch size b (for SGD) and sample size m (for GD) and show that when bρ is small enough, SGD can go beyond SQ learning and simulate any sample-based learning algorithm and thus its learning power is equivalent to that of PAC learning; this extends prior work that achieved this result for b = 1. Similarly, with polynomially many bits of precision (i.e. when ρ is exponentially small), GD can both simulate PAC learning regardless of the mini batch size. On the other hand, when b^{-1/\epsilon} is large enough, the learning power of SGD is equivalent of that of SQ learning."
SP:1de2864fe2f53e25596a9bd2c61e2048e79296f6,"This paper studies the problem of generating a discrete probability distribution over a set of N points that minimizes the Wasserstein distance to the model distribution. This problem is non-convex in the sense that the unknowns are the positions of the atoms. The authors show that a suitably adjusted version of Lloyd’s algorithm, in which Voronoi cells are replaced by Power cells, leads to configurations with small Wassersteins error. This is surprising because, again, of the non-Convex nature of the problem, as well as the existence of spurious critical points. They provide explicit estimates for the convergence of this Lloyd-type algorithm, starting from a cloud of points that are sufficiently far from each other."
SP:c3d364aeee55230a436c3ce4e8dc8310ee73959e,"This paper proposes a dynamic self-attention method for video recognition. The proposed method is based on the idea of dynamic convolutional kernels, where the kernel is generated by aggregating relations in space and time. The authors propose to generate the kernels based on spatio-temporal relations in video frames, which are aggregated into a relational kernel, which is then aggregated to produce the final feature representation. The method is evaluated on the standard motion-centric benchmarks for video action recognition, such as Something-Something-V1&V2, Diving48, and FineGym. "
SP:2c2530069d5cab485629090243da464d107feadd,"This paper studies the second-order mean field limit of multilayer neural networks. The authors derive a system of dynamical equations that captures the limiting fluctuation distribution around the infinite-width limit of the network. They show that the second order limit is related to the limit of large-width networks. They also show that gradient descent mean field training progressively biases towards a solution with minimal fluctuation, even after the network has been initialized at or has converged to a global optimum."
SP:a3d927854d9d7fd39b8d05a79666810d585d5062,"This paper proposes a method for learning reversible dynamical systems with unknown a priori model form. In particular, the authors propose a novel parameterization of dissipative brackets from metriplectic dynamical system appropriate for learning irreversible dynamics with unknown model form, which learns generalized Casimirs for energy and entropy guaranteed to be conserved and nondecreasing, respectively. Furthermore, for the case of added thermal noise, they guarantee exact preservation of a fluctuation-dissipation theorem, ensuring thermodynamic consistency. The authors provide benchmarks for dissipative systems demonstrating learned dynamics are more robust and generalize better than either ""black box"" or penalty-based approaches."
SP:32e8e83e06b1e9a4dad761334d5947c91bfd1853,"This paper proposes a sample selection-based algorithm for fair and robust training. The authors formulate a combinatorial optimization problem for the unbiased selection of samples in the presence of data corruption. They propose a greedy algorithm that is efficient and effective in practice. Experiments show that their algorithm obtains fairness and robustness that are better than or comparable to the state-of-the-art technique, both on synthetic and benchmark real datasets."
SP:991127729bf067fe27fdd7ed360aab39e4df5921,"This paper proposes periodic activation functions for Bayesian neural networks (BNNs). The authors show that the periodic activation function can be used as a regularizer to regularize the weights of BNNs. The authors also show that this regularizer can also be used for other functions such as triangular wave and periodic ReLU activation functions. In the experiments, the authors compare the performance of the proposed method with sinusoidal and Fourier activation functions and show that periodic activation is comparable to sinusoid activation for in-domain and out-of-domain detection. "
SP:d61a2aecfea4612c473b4e6fd41f3dc2fcbb04a1,"This paper proposes a method for automatic feedback for interactive code assignments in coding classes. The authors propose to use an autoregressive model to sample trajectories from the input MDP to a classifier to determine membership of the MDP. The proposed method is evaluated on a dataset of 711,274 anonymized student submissions to a single assignment with hand-coded bug labels. "
SP:daf99ad91613d6e11b13315ccbd1bbe25094ae4b,"This paper proposes a method for interpretability of deep reinforcement learning (DRL) models based on disentangled latent representations. The authors propose to train a latent representation for each object and a mimic tree that extracts the causal impact of the latent features on DRL action values. To jointly optimize both the fidelity and the simplicity of the mimic tree, the authors derive a novel Minimum Description Length (MDL) objective based on the Information Bottleneck (IB) principle. The paper also proposes a Monte Carlo Regression Tree Search (MCRTS) algorithm that explores different splits to find the IB-optimal mimic tree. Experiments show that the proposed method achieves strong approximation performance with significantly fewer nodes than baseline models."
SP:84560de78af979354fff83d1370d8675c1e9191f,"This paper proposes a Bayesian framework for modeling the structure of dynamic predictions over time. The authors model the trajectories of future binary outcomes by assuming predictions update according to a latent process of information flow, which is inferred from historical data. This approach preserves important properties of probability paths such as the martingale structure and appropriate amount of volatility and better quantifies future uncertainties around probability paths. They show that GLIM outperforms three popular baseline methods, producing better estimated posterior probability path distributions measured by three different metrics."
SP:0c4bfb44e0a353256692d5e5ae96f65c1a14363d,"This paper studies the problem of active pure exploration with fixed confidence in stochastic bandit environments. The goal of the learner is to answer a query about the environment with a given level of certainty while minimizing her sampling budget. For this problem, instance-specific lower bounds on the expected sample complexity reveal the optimal proportions of arm draws an Oracle algorithm would apply. The authors propose Frank-Wolfe-based Sampling (FWS), a simple algorithm whose sample complexity matches the lower bounds for a wide class of pure exploration problems. They apply FWS to various pure exploration tasks including best arm identification in unstructured, thresholded, linear, and Lipschitz bandits. They show that FWS is competitive compared to state-of-art algorithms."
SP:0947a0f08fba53d3c8af9b78dd64e6e10fc73e32,"This paper proposes a new method for Bayesian optimization of combinatorial spaces. The main idea is to use a structure-coupled kernel that explicitly integrates the structural information from decoded structures with the learned latent space representation for better surrogate modeling. The experiments on real-world benchmarks show that LADDER significantly improves over the BO over latent space method, and performs better or similar to state-of-the-art methods."
SP:37adabdc6615c5199a481553c8ccc06d57363614,"This paper studies the representation of state-action value functions in regret minimization in finite-horizon MDPs with linear structure. The authors derive a necessary condition on the representation, called universally spanning optimal features (UNISOFT), to achieve constant regret in any MDP with linear reward function. They then demonstrate that this condition is sufficient for these classes of problems by deriving a constant regret bound for two optimistic algorithms (LSVI-UCB and ELEANOR). Finally, they propose an algorithm for representation selection and prove that it achieves constant regret when one of the given representations or a suitable combination of them satisfies the UNISOFT condition."
SP:92566b664ab2f6ee9b73f29327aeef85d14ecf60,"This paper proposes a differentiable contact model for learning dynamics in physical systems. The proposed model is based on a Lagrangian and Hamiltonian neural network architecture, which allows simultaneous learning of frictionless/frictional and elastic/inelastic properties of the system. This model can also accommodate inequality constraints, such as limits on the joint angles. Experiments are conducted on a series of challenging 2D and 3D physical systems with different coefficients of restitution and friction. The learned dynamics can be used as a simulator for downstream gradient-based optimization tasks."
SP:82d59a3609dfd458f90f23d4e477c8b497e9dc18,"This paper investigates the Benevolent training hypothesis (BTH) which claims that the complexity of a deep neural network can be deduced by its training dynamics. The authors show that the Lipschitz constant close to the training data affects various aspects of the parameter trajectory, with more complex networks having a longer trajectory, bigger variance, and often veering further from their initialization. They also show that NNs whose 1st layer bias is trained more steadily (i.e., slowly and with little variation) have bounded complexity even in regions of the input space that are far from any training point. Finally, they show that steady training with Dropout implies a training and datadependent generalization bound that grows poly-logarithmically with the number of parameters."
SP:9b329c915fa8d4045c167c9df37a49ee314d190e,"This paper studies the problem of distribution-independent PAC learning of halfspaces in the Massart noise model with strongly polynomial sample complexity, i.e., independent of the bit complexity of the examples. In particular, the authors show that any distribution can be decomposed as a disjoint mixture of few distributions for which a Forster transform exists and can be computed efficiently. The main application of this result is the first polynomially-time algorithm for distribution-dependent PAC learning in the half-spaces learning of Massart Noise Model."
SP:e5229305af00067ae2dbabd903e585964aec8928,"This paper proposes a Bayesian optimisation-based attack method for adversarial attacks on graph neural networks (GNNs). The proposed method is based on Bayesian Optimization (BOO) and is a query-efficient and parsimonious attack method. The authors empirically validate the effectiveness and flexibility of the proposed method on a wide range of graph classification tasks involving varying graph properties, constraints and modes of attack. An open-source implementation is available at GitHub."
SP:4999e5664383066fdacd14be6242c7b83f85f3dd,"This paper studies the problem of online label shift adaptation in the online setting, where the test-time label distribution is continually changing and the model must dynamically adapt to it without observing the true label. The authors propose adaptation algorithms inspired by classical online learning techniques such as Follow The Leader (FTL) and Online Gradient Descent (OGD) and derive their regret bounds. They empirically verify their findings under both simulated and real world label distribution shifts and show that OGD is particularly effective and robust to a variety of label shift scenarios."
SP:806515ae07fb1c9d02773592005d53d4158ef102,"This paper considers the problem of detecting and localization of gradual changes in the distribution of a sequence of time-ordered observations. The authors propose a general method for detecting and localizing gradual changes that does not require a specific data generating model, a particular data type, or prior knowledge about which features of the distribution are subject to change. Despite relaxed assumptions, the proposed method possesses proven theoretical guarantees for both detection and localization."
SP:7a3c8a7b17ecab19361d36e1d3d73fa35b71214c,This paper proposes a neural network architecture for blind source separation (BSS) that is based on the neural architecture of a biological neural network (NN). The authors propose a novel objective function for ICA based on neural architecture and the synaptic learning rules. The authors show that the proposed algorithm is biologically plausible and can be used to solve BSS problems in the online setting. 
SP:22f8b517a3df65144412938f5891c463d7bae0ab,"This paper studies the dynamics of a two-neuron network on three tasks: delayed discrimination, interval discrimination, and time reproduction. The authors analyze the behavior of the network on these tasks and show that the network has a diverse set of solutions. They also show that one layer of variability can be found directly in the neural activity of the networks. An additional layer is uncovered by testing the trained networks’ ability to extrapolate, as a perturbation to a system often reveals hidden structure. Furthermore, extrapolation patterns to specific dynamical objects and effective algorithms found by the networks are shown."
SP:9b08a0f547ead3b59077a43b1052c6d46a0730f6,This paper proposes a new method for conditional density estimation of unobserved features and observed features. The proposed method is based on the idea of conditioning with energy (ACE) which can simultaneously estimate the distribution p(xu | xo) for all possible subsets of the unobserved feature xu and the observed feature xo. The authors propose to learn a one-dimensional conditionals for the conditional density estimator and reduce the problem to only learning one dimensional conditionals (from which more complex distributions can be recovered during inference). The authors show that ACE achieves state-of-the-art for arbitrary conditional likelihood estimation and data imputation.
SP:f2b14f5854e6aa6922795d1d2051b7402486cef6,"This paper proposes an adaptive weighted loss for single image super-resolution (SISR) to train deep networks focusing on challenging situations such as textured and edge pixels with high uncertainty. Specifically, they introduce variance estimation characterizing the uncertainty on a pixel-by-pixel basis into SISR solutions so the targeted pixels in a high-resolution image (mean) and their corresponding uncertainty (variance) can be learned simultaneously. The uncertainty estimation allows them to leverage conventional wisdom such as sparsity prior for regularizing SisR solutions. The experimental results on three popular SIsR networks show that the proposed uncertainty-driven loss has achieved better PSNR performance than traditional loss functions without any increased computation during testing."
SP:9997583f40fa648adf57bb4fc34228f357be0cf1,"This paper proposes a general PAC-Bayesian generalization bound for adversarial robustness, which is based on the PACBayesian framework. The main contribution of this paper is to derive a generalization of the worst-case risk of a hypothesis over all possible perturbations for majority votes (over the whole class of hypotheses), which is then used to derive an upper bound on the average risk of the perturbation for the majority of the hypotheses. The upper bound is proved to be tight and can be directly minimized during the learning phase to obtain a robust model on different attacks."
SP:90b72e8dc41584e38f25dff9fb2853f5b11dc8fa,"This paper proposes a probabilistic entity representation model (PERM) for logical reasoning over Knowledge Graphs (KG). The proposed model encodes entities as a multivariate Gaussian density with mean and covariance parameters to capture its semantic position and smooth decision boundary, respectively. The authors also define the closed logical operations of projection, intersection, and union that can be aggregated using an end-to-end objective function. The proposed PERM is evaluated on the logical query reasoning problem on various public benchmark KG datasets on standard evaluation metrics, and evaluated on a COVID-19 drug repurposing case study."
SP:b6184c9732dbb7eba7c20cae8869d975c428efe4,"This paper proposes a new method for gradient-based hyperparameter optimization for few-shot meta-learning. The proposed method is based on forward-mode differentiation with sharing (FDS), which is a simple and efficient algorithm that tackles memory scaling issues and gradient degradation issues by sharing hyperparameters that are contiguous in time. The authors provide theoretical guarantees about the noise reduction properties of their algorithm, and demonstrate its efficiency empirically by differentiating through 10 gradient steps of unrolled optimization. The experimental results on CIFAR-10 show that the proposed method significantly outperforms greedy gradientbased alternatives."
SP:9c3a326e5ee4e862923d3bf9415f32a077db8534,"This paper proposes a method for improving neural sequence models by adding logical reasoning to them. In particular, the authors propose to use a symbolic reasoning module that can either accept or reject the generations of a neural sequence model. The authors also propose to train a neural inference module to mediate between the neural system 1 and the logical system 2. The experiments show that the proposed method can improve the coherence and accuracy of neurally-based generations. "
SP:d77d046095e4c8336c0c76ac48cb046923230753,"This paper considers the problem of off-policy evaluation (OPE) in continuous treatment settings, where one aims to estimate the mean outcome under a new treatment decision rule using historical data generated by a different decision rule. The authors propose a novel estimation method for OPE using deep jump learning. The key ingredient of their method lies in adaptively discretizing the treatment space using deep discretization, by leveraging deep learning and multiscale change point detection. The method is further justified by theoretical results, simulations, and a real application to Warfarin Dosing."
SP:4d085e57286fdd36143108a002d16914222c239a,"This paper proposes a variational inference algorithm for continuous-time dynamical systems based on a Markov jump process modulating a subordinated diffusion process. The authors provide the exact evolution equations for the prior and posterior marginal densities, the direct solutions of which are however computationally intractable. Therefore, the authors develop a new continuous time inference algorithm, combining a Gaussian process approximation on the diffusion level with posterior inference for Markov jumping processes. By minimizing the path-wise Kullback-Leibler divergence, they obtain Bayesian latent state estimates for arbitrary points on the real axis and point estimates of unknown system parameters, utilizing variational expectation maximization."
SP:d1f396e691f9d331adfb7b694a99c50e8004331f,"This paper studies the impact of the spectrum of sensing matrices on the difficulty of recovering x from y in a nonlinear inverse problem. In particular, the authors study the performance of expectation propagation algorithm (EP) and show that the spikiness of spectrum of A is an important factor in EP's performance. The authors define certain quantities based on the function f that enables them to describe the impact on the EP recovery. Based on their framework, they show that for phase-retrieval problems, matrices with spikier spectrums are better for EP, while in 1-bit compressed sensing problems, less spiky (flatter) spectrums offer better recoveries."
SP:ee66604d4da9fd04826e90ccbb94f0499eba4c63,"This paper proposes a novel method to address the problem of domain shift in zero-shot learning, i.e., confusion between seen and unseen categories, by progressively improving cross-domain transferability and category discriminability of visual representations. The proposed method is named Dual Progressive Prototype Network (DPPN), which constructs two types of prototypes that record prototypical visual patterns for attributes and categories, respectively. With attribute prototypes, DPPN alternately searches attribute-related local regions and updates corresponding attribute prototypes to progressively explore accurate attribute-region correspondence. With category prototypes, the proposed method further projects category prototypes into multiple spaces to progressively repel visual representations from different categories. Experiments on four benchmarks demonstrate the effectiveness of the proposed approach."
SP:61eb6297568c3f6869fbb03eaf6a21260de5466c,"This paper presents an end-to-end deep learning approach for removing defocus blur from a single image, so as to have an all-in-focus image for consequent vision tasks. First, a pixel-wise Gaussian kernel mixture (GKM) model is proposed to represent spatially variant defocus kernels in an efficient linear parametric form, with higher accuracy than existing models. Then, a deep neural network is developed by unrolling a fixed-point iteration of the GKM-based deblurring. Extensive experiments show that the proposed method can outperform existing defocus debLurring methods, but also has its advantages in terms of model complexity and computational efficiency."
SP:18bf447c90935c373e5ec4cdfbbf8f2a273d2edb,"This paper proposes a cross guidance contrastive learning algorithm for self-supervised video representation learning (SSVRL). The proposed method is based on the idea of cross-guidance contrastive loss (CGC), which is a multi-instance InfoNCE loss that takes into account both the RGB and the motion vectors of the input video. The method is evaluated on a variety of downstream tasks and achieves state-of-the-art performance. "
SP:8c7b1d976d9758cd534c565ec31a23f97892e503,"This paper studies the problem of asymptotic overconfidence in Bayesian neural networks (BNNs) in the presence of infinite ReLU features. The authors show that the output variance of a BNN with finitely many features is quadratic in the distance from the data region. Meanwhile, Bayesian linear models with infinite-width features converge to a particular Gaussian process (GP) with a variance that grows cubically so that no overconfidence can occur. In this paper, the authors extend finite ReLU BNNs with infinite ReLu features via the GP and show the resulting model is asymPTotically maximally uncertain far away from the training data while the BNN’s predictive power is unaffected near the data."
SP:e77276f61626e896f6a985296f1d832129242cdf,This paper considers the problem of selecting a formula for identifying a causal quantity of interest among a set of available formulas. The main contribution of this paper is to formalize the bestarm-identification bandit framework where the standard goal of learning the arm with the lowest loss is replaced with the goal to learn the arm that will produce the best estimate. The authors introduce new tools for constructing finite-sample confidence bounds on estimates of the asymptotic variance that account for the estimation of potentially complex nuisance functions. They validate their method by providing upper bounds on the sample complexity and an empirical study on artificially generated data.
SP:471361588bfc6c6033631509d1e43e77fd9721ce,"This paper proposes ErrorCompensatedX, which uses the compression error from the previous two steps of the stochastic gradient descent (SGD) algorithm to improve the convergence rate of SGD. The authors show that adding the previous step’s compression error, as done in existing work, does not fully compensate for the bias in the previous steps. Instead, they propose to use the error compensation from the first two steps, and show that it can achieve the same asymptotic convergence rate with the training without compression. "
SP:3b7ff0dc668cac2191d95fcc4dc6e0335dec3206,"This paper proposes a method for generating multi-grained explanations for graph neural networks (GNNs). The authors propose a pre-training and fine-tuning approach to generate multi-class explanations for GNNs. The authors use contrastive contrastive learning to learn the class-wise and class-specific explanations for different classes, and then fine-tune the explanations in the local context. Experiments on both synthetic and real-world datasets show the superiority of the proposed method. "
SP:9b5a62d3a2b27bc60da28980e9fb0ecdff1215c0,This paper proposes a method to generate counterfactual explanations for Graph Neural Networks (GNNs) by explicitly modelling the common decision logic of GNNs on similar input graphs. The authors argue that their method is robust to noise because it is based on the decision boundaries of a GNN that govern the predictions of many similar input graph. They also argue that removing the set of edges identified by an explanation from the input graph changes the prediction significantly. The experimental results on several public datasets demonstrate the superior performance of their method.
SP:4edb870786c9cea2c6075359cb4e79b02a8e2f5f,"This paper proposes a method for voice-to-voice transfer based on self-supervised representation learning and adversarial feedback. In particular, the authors propose to decompose the content and style of the converted speech into two parts: (1) a content discriminator and (2) a style discriminator, which is trained with self- supervision. The proposed method is evaluated on a variety of datasets and compared with a few baselines. The authors show that the proposed method outperforms the baselines in terms of disentanglement and transfer performance."
SP:9fbb0c6beb3f8f88972f13dcf0e1fe7db03233c7,"This paper proposes a Siamese voxel-to-BEV tracker for 3D object tracking in sparse 3D point clouds. The proposed method consists of two components: (1) a shape-aware feature learning network, and (2) a target localization network. The first component is a template feature embedding to embed the template’s feature into the potential target and then generate a dense 3D shape to characterize the shape information of the target. The second component is an anchor-free network to localize the 2D and the z-axis center from the dense bird's eye view (BEV) feature map. Experiments on KITTI and nuScenes show that the proposed method significantly outperforms the state-of-the-art methods."
SP:8b788c78680a54c453a04f4551436763ee57585e,"This paper proposes a positional encoding method based on learnable Fourier features for multi-dimensional positional encoding. The proposed method is based on a multi-layer perceptron, which is modulated with a learnable feature mapping. The method is evaluated on a variety of image classification tasks, and it is shown to outperform the state-of-the-art methods."
SP:d2ac1b6381315bce4449f09bd519f33a2a42d714,"This paper proposes a new method for learning the causal MAG of a system from observational data in the presence of latent variables and selection bias. The key idea of the proposed method is to learn the structure efficiently and recursively, as this technique reduces both the number of required conditional independence (CI) tests and the size of the conditioning sets. The authors provide an upper bound on the required CI tests in the worst case, which is the tightest bound in the literature. The lower bound is also provided. The experimental results on synthetic and real-world data show that the proposed approach is competitive with the state of the art."
SP:49a4912ce457f5f5ec62c44fa10444af8075fabf,"This paper proposes a batch Thompson Sampling (BTS) algorithm for stochastic multi-arm bandit and linear contextual bandit with finitely many arms. The algorithm is based on Thompson sampling, which is a variant of Thompson sampling. The main idea is to dynamically decide the duration of each batch in order to balance the exploration-exploitation trade-off. The authors show that the proposed algorithm achieves the same (asymptotic) regret bound of a fully sequential one while carrying out only O(log T) batch queries. They also demonstrate experimentally that dynamic batch allocation dramatically outperforms natural baselines."
SP:653a519e3c799c25e0d0b4240322642040b121a3,"This paper studies the problem of domain adaptation (DA) and domain generalization (DG) in the multi-source and multi-domain settings. The authors propose a novel upper-bounds for the target generalization loss and define two kinds of domain-invariant representations. They further study the pros and cons as well as the trade-offs of enforcing learning each domain-specific representation. Finally, they conduct experiments to inspect the tradeoff of these representations for offering practical hints regarding how to use them in practice."
SP:2a7bee950cd07494d59dfee60ac2e86cc0e481b1,"This paper proposes an aligned structured sparsity learning (ASSL) method for lightweight image super-resolution (SR) networks. The authors propose a weight normalization layer and L2 regularization to the scale parameters for sparsity. To align the pruned filter locations across different layers, they propose a sparsity structure alignment penalty term, which minimizes the norm of soft mask gram matrix. The proposed method ASSLN is applied to train efficient image SR network with smaller model size and lower computation than state of the art methods."
SP:e9830bb9e7d3ddc3bd1c2994590fdb5d8f3668be,"This paper proposes a novel method for exploration in multi-agent reinforcement learning (MARL) called Episodic Multi-Agent Exploration (EMC). The main idea is to use the individual Q-values of individual agents as intrinsic rewards for coordinated exploration. The intrinsic reward is based on the observation that the dynamics of an agent’s individual utility function captures the novelty of states and the influence from other agents, and thus can induce coordinated exploration to new or promising states. Empirical results show that the proposed method outperforms the state-of-the-art MARL baselines on the StarCraft II micromanagement benchmark."
SP:c7e33d479575c88e22282ee6fd4f978bcd3c06ed,"This paper studies the problem of list-decodable linear regression, where an adversary can corrupt a majority of the examples. The goal is to output a small list of hypothesis vectors such that at least one of them is close to the target regression vector. The main result is a Statistical Query (SQ) lower bound of d for this problem. The SQ lower bound qualitatively matches the performance of previous algorithms, providing evidence that current upper bounds for this task are nearly best possible."
SP:7b258252a9063514348f5fa8d9c85afd85748747,This paper proposes a model for predicting the patient health status and disease progression over time based on pharmacological models. The model is based on the idea of integrating expert-designed ODEs with machine-learned Neural ODE models to fully describe the dynamics of the system and to link the expert and latent variables to observable quantities. The proposed model is evaluated on synthetic data as well as real-world intensive care data of COVID-19 patients.
SP:3ea9e86e5755ef84d28e3163c60531ace5d62e3a,"This paper presents a theoretical framework for analyzing a MAML-like algorithm, assuming all available tasks require approximately the same representation. The authors provide risk bounds on predictors found by finetuning via gradient descent, demonstrating that the method provably leverages the shared structure. In contrast, the authors establish settings where learning one representation for all tasks (i.e. using a “frozen representation” objective) fails."
SP:8ba5a2ac80f7c53f81ad008e96c033ecad14ac0d,"This paper presents Grammar-Based Grounded Lexicon Learning (G2L2), a lexicalist approach to learning a compositional and grounded meaning representation of language from grounded data, such as paired images and texts. At the core of the approach is a collection of lexicon entries, which map each word to a syntactic type and a neuro-symbolic semantic program. The learned meaning programs can be executed on grounded inputs. To facilitate learning in an exponentially growing compositional space, the authors introduce a joint parsing and expected execution algorithm, which does local marginalization over derivations to reduce the training time. Experiments are conducted on two domains: visual reasoning and language-driven navigation."
SP:16c458651815813efdcbe8ba1205bbddbe3e4e68,"This paper proposes a stochastic Newton algorithm for distributed distributed stochastically convex optimization, where each machine has access to a set of gradient and Hessian-vector products of the population objective. The authors show that their algorithm can reduce the number, and frequency, of required communication rounds compared to existing methods without hurting performance, by proving convergence guarantees for quasi-self-concordant objectives (e.g., logistic regression) and empirical evidence."
SP:d7e479d59f82d4c55372a68ca7b4516f2871f346,"This paper proposes a new measure called density-aware Chamfer distance (DCD) to measure the similarity between two point sets. It is based on Chamfer Distance (CD) and Earth Mover’s Distance (EMD) which are two widely used metrics for measuring point cloud similarity. The authors claim that DCD is more sensitive to the local density than CD and EMD because it can detect disparity of density distributions and is more computationally efficient than EMD. In addition, the authors propose a novel point discriminator module that estimates the priority for another guided downsampling step, and it achieves noticeable improvements under DCD together with competitive results for both CD and EMD."
SP:e4b302009520770814ff2c096020b779a9fc38fe,"This paper studies the problem of knowledge distillation, a popular technique for training a small student network to emulate a larger teacher model, such as an ensemble of networks. The authors show that distillation can improve student generalization, but it does not typically work as it is commonly understood: there often remains a surprisingly large discrepancy between the predictive distributions of the teacher and the student. They identify difficulties in optimization as a key reason for why the student is unable to match the teacher. They also show how the details of the dataset used for distillation play a role in how closely the student matches the teacher — and that more closely matching the teacher paradoxically does not always lead to better student generalisation."
SP:895c7e03f9e4dadb94be1f39d61bf0b5e1533f4f,"This paper studies the problem of partitioning a k-decision tree (k-tree) of a 2D matrix into k-1 block matrices, where each rectangle is assigned a real label. The authors show that a (k, \epsilon)-coreset C of the k-tree is a small summarization that approximates this loss to every such tree, up to a multiplicative factor of 1/\eps. They provide the first algorithm that outputs such a coreset for every such matrix D. The size |C| of the coreset is polynomial in k log(N)/ε, and its construction takes O(Nk) time. Experimental results on sklearn and lightGBM show that applying their coresets on real-world data-sets boosts the computation time of random forests and their parameter tuning by up to x10, while keeping similar accuracy."
SP:f3ece96b15ec06d703925df2061ed9694ec3bca5,"This paper studies the problem of Top-m identification for misspecified linear bandit models. The authors first derive a tractable lower bound on the sample complexity of any $\delta$-correct algorithm for the general Top-M identification problem. They then describe the first algorithm for this setting, which is both practical and adapts to the amount of misspecification. Finally, they evaluate their algorithm on both synthetic and real-world data, showing competitive performance with respect to existing baselines."
SP:e71c5e39b8d8d1640d6de2352ac51ddd52eea89d,"This paper proposes a self-supervised learning method for learning disentangled representations for graph neural networks (GNNs). The method is based on the idea of factorized representation learning, where each latent factor of the input graph is represented as a latent representation of a different aspect of the graph. The authors propose a novel factor-wise discrimination objective in a contrastive learning manner, which can force the factorized representations to independently reflect the expressive information from different latent factors. Extensive experiments on both synthetic and real-world datasets demonstrate the superiority of the proposed method."
SP:0a7edbbdabab11273689c40c517001eb46491113,This paper proposes a method to evaluate the robustness of a trained network to input uncertainties with a stochastic simulation inspired by the field of Statistical Reliability Engineering (SRE). The robustness assessment is cast as a statistical hypothesis test: the network is deemed as locally robust if the estimated probability of failure is lower than a critical level. The procedure is based on an Importance Splitting simulation generating samples of rare events. Theoretical guarantees are derived that are nonasymptotic w.r.t. sample size. Experiments tackling large scale networks outline the efficiency of the method making a low number of calls to the network function.
SP:c1db485ff1ff9573daa421e167225654babb55ac,"This paper proposes a polynomial neural network (PNN) architecture for conditional image generation. The main idea is to use polynomials for two-variable inputs, i.e., the noise variable and the conditional variable. The authors show that the proposed architecture can be applied to a wide range of conditional generation tasks, including super-resolution, inverse problems, image-to-image translation, and attribute-guided generation. "
SP:5a75bc7a3ea0ce971cfceebbc1c2434e3aa2584d,"This paper proposes a neural tangent kernel (NTK) based method for computing the Maximum Mean Discrepancy (MMD) statistic for neural networks. Theoretically, the authors show that NTK-MMD can be used to compute the MMD statistic and perform NTK based two-sample tests towards addressing the long-standing challenge of memory and computational complexity of MMD, which is essential for online implementation to assimilating new samples. Numerical experiments on synthetic and real-world datasets validate the theory and demonstrate the effectiveness of the proposed NTK."
SP:1df2ffbbe56b8018067820980b93af2a8b57f891,"This paper studies the problem of adversarial attack detection and defense against adversarial attacks. In particular, the authors propose a method to decompose the input image x into x-G(x) and x-D(x), where x is the input to a neural network D(x, G(x)). The authors propose to train a variational autoencoder (VAE) to extract the class-dependent information from x, which is a trade-off between reconstructing x and classifying x, where the former competes with the latter in decomposing x so that the latter retains only necessary information for classification in x-g(x). Experiments on both clean images and adversarial images show that the perturbations generated by adversarial perturbation mainly lie in the class dependent part of x. The authors then propose to conduct adversarial detection and attack models on x-divergence and g(x)-Divergence, which consistently outperform the results on the original x."
SP:2789874561620ba7894c4672f935056bb911e919,"This paper proposes a federated Thompson sampling (FTS) algorithm for Bayesian optimization (BO) in federated learning (FL) with differential privacy (DP) and distributed exploration (DE) to improve the utility of the algorithm. The proposed algorithm is based on the DP-FTS-DE framework, which is a general framework for adding DP to iterative algorithms. Theoretical guarantees for both privacy and utility are provided for the proposed algorithm. Experiments on real-world datasets show that the proposed method achieves competitive performance with a strong privacy guarantee."
SP:be7d6b81736a2c3f89abd8771b41b18802e88832,"This paper proposes a multi-label active learning (ML-AL) method that uses a Gaussian Process-Bayesian Bernoulli Mixture model (GP-BM) to estimate the overall contribution of a data sample to a correlated label space and choose the most informative samples for cost-effective annotation. In particular, the BM encodes label correlations using a BayesianBernoulli mixture of label clusters, where each mixture component corresponds to a global pattern of label correlations. The BM is further integrated with a predictive GP to connect data features as an effective inductive bias and achieve a feature-component-label mapping. A principled sampling function is designed accordingly to naturally capture both the feature uncertainty (through GP) and label covariance (through BM) for effective data sampling. The model also outputs a predictive distribution that provides both the label prediction and their correlations in the form of a label covariances matrix. Experiments on real-world datasets demonstrate the state-of-the-art AL performance."
SP:2b7270b0370c193300bcbbb5fb0a4101b3329d99,"This paper proposes to use a polar coordinate system to improve the spatial context of the point cloud in lidar perception models. The authors propose to use multi-scale padding from neighboring sectors: preceding sector from current scan and/or the following sector from the past scan. In addition, the authors introduce feature undistortion and range stratified convolutions to the core polar convolutional architecture. Experimental results on the nuScenes dataset show significant improvements over other streaming based methods."
SP:7ae2c5b7d9c8a6c8f4a353606aa419929c47f31b,"This paper proposes a method for learning structured latent variables. The authors extend the Gumbel-Max trick to define distributions over structured domains by leveraging the score function estimators for optimization. In particular, they highlight a family of recursive algorithms with a common feature we call stochastic invariant. The feature allows us to construct reliable gradient estimates and control variates without additional constraints on the model. In experiments, the authors consider various structured latent variable models and achieve results competitive with relaxation-based counterparts."
SP:415d363c66a6967c1daca9dc02001b85bf7f0752,"This paper proposes GainTuning, a method to adaptively fine-tune CNNs for image denoising. The authors propose to use a single multiplicative scaling parameter (the Gain) of each channel in the convolutional layers of the CNN. The proposed method is evaluated on standard image-denoising benchmarks, and it is shown to improve state-of-the-art CNNs on nearly every image in a held-out test set. The adaptive improvements are even more substantial for test images differing systematically from the training data, either in noise level or image type. In addition, the authors demonstrate the potential of adaptive GainT tuning in a scientific application to transmission-electronmicroscope images, using a CNN that is pre-trained on synthetic data."
SP:90afa1102683b456bc72a54abef466326827546a,This paper proposes a differentiable architecture for simultaneous semantic and instance segmentation (a.k.a. panoptic segmentation) consisting of a convolutional neural network and an asymmetric multi-way cut problem solver. The latter solves a combinatorial optimization problem that elegantly incorporates semantic and boundary predictions to produce a pan-optic labeling. The formulation allows to directly maximize a smooth surrogate of the pan-opinative quality metric by backpropagating the gradient through the optimization problem. Experimental evaluation shows improvement over the existing methods on Cityscapes and COCO datasets.
SP:1952e174d9ec7b83ad1d394ece7fe77ea1f6d78d,"This paper proposes Recursive Bayesian Networks (RBNs), which generalize and unify PCFGs and dynamic Bayesian networks (DBNs) by combining their strengths and containing both as special cases. The main challenge lies in performing joint inference over the exponential number of possible structures and the continuous variables. The authors provide two solutions: 1) for arbitrary RBNs, they generalise inside and outside probabilities from PCFG to the mixed discrete-continuous case, which allows for maximum posterior estimates of the continuous latent variables via gradient descent, while marginalising over network structures. 2) for Gaussian RBN, they additionally derive an analytic approximation of the marginal data likelihood (evidence) and marginal posterior distribution, allowing for robust parameter optimisation and Bayesian inference."
SP:5f29b169d3e4bbaeeec85e1aeebe2094fae4be6e,"This paper proposes a post-training method called constrained backpropagation (CBP) which is based on the pseudo-Lagrange multiplier method to obtain the optimal set of weights that satisfy a given set of constraints. The authors considered various types of constraints such as binary, ternary, one-bit shift, and two-bit-shift weight constraints, and showed that CBP can address diverse constraints with the minimal performance loss by employing appropriate constraint functions. The proposed algorithm outperforms the state-of-the-art methods on ImageNet, e.g., 66.6%, 74.4%, and 64.0% top-1 accuracy for binary weights, respectively."
SP:3ddf8e2e108fb261bb23aec8a27a25aba7523dc1,"This paper studies the problem of active learning for Gaussian process classification (GPC) in the context of query synthesis. The authors propose a novel algorithm for EER-based active learning with GPC. The main idea is to use the joint predictive distribution of label pairs as a one-dimensional integral to reduce the computation of the acquisition function, which avoids retraining the GPC for each query. They also derive the gradient chain rule to efficiently calculate the gradient of acquisition function. The proposed algorithm is evaluated on both synthetic and real-world datasets."
SP:fa1fac04cd4ccb1f3eaf80807db09f9683ce6b50,"This paper studies the effect of unbounded gradients on the regularization of autoencoder-based architectures, including VAE models, as applied to data lying on or near a low-dimensional manifold (e.g., natural images). The main finding is that, if the ultimate goal is to simultaneously avoid over-regularization (high reconstruction errors, sometimes referred to as posterior collapse) and under-regularisation (excessive latent dimensions are not pruned from the model), then an autoencoders-based energy function with infinite gradients around optimal representations is provably required. This result suggests that heuristic modifications to or constraints on the VAE energy function may at times be ill-advised, and large gradients should be accommodated to the extent possible."
SP:2611cfd6e0696a57d061687993cef1fe5c95999d,"This paper studies the bandit problem with graph feedback, which is modeled by a directed graph G = (V,E) where V is the collection of bandit arms, and once an arm is triggered, all its incident arms are observed. A fundamental question is how the structure of the graph affects the min-max regret. The authors propose the notions of the fractional weak domination number and the k-packing independence number capturing upper bound and lower bound for the regret respectively. They show that the two notions are inherently connected via aligning them with the linear program of the weakly dominating set and its dual — the fractionsal vertex packing set respectively. Based on this connection, they utilize the strong duality theorem to prove a general regret upper bound O ( (δ∗ log |V |) 1 3 T 2 3 ) and a lower bound O(\epsilon/\alpha) where $\alpha$ is the integrality gap of the dual linear program. Their bounds are tight up to a (log |V|) 1.3 factor on graphs with bounded integrality gaps for the vertex packing problem including trees and graphs with a bounded degree."
SP:e50dec57af337839cbde4b65fb7b431785fda44d,"This paper proposes a new neighbourhood Shapley value (N-Shapley value) based on neighbourhood reference distributions. The authors argue that the proposed neighborhood Shapley values are more interpretable than the standard Shapley Value (SV) which is based on the global Shapley Values (GV). The authors propose to use the Nadaraya-Watson estimator as a self-normalized importance sampling estimator, which can be expressed as an estimator of the importance of a neighbourhood. The proposed Neighbourhood Shapley values can be used to improve the interpretability of the SV. In particular, the authors show that the Neighbours Shapleyvalues are more explainable and robust to adversarial attacks. "
SP:35bdeb78f9fe74e754177fb54b48e7399dc8590d,"This paper proposes a novel method to generate cycle-consistent virtual trajectories to enhance the data efficiency for RL feature representation learning. The proposed method is based on a dynamics model that predicts future states in a latent space based on the current state and action and then predicts the previous states by a backward dynamics model, which forms a trajectory cycle. Based on this, the authors augment the actions to generate a large amount of virtual state-action trajectories. The authors validate the effectiveness of their designs on the Atari and DeepMind Control Suite benchmarks."
SP:ca09e472cbcf2ac8c8c9b192a87df2ed59218210,"This paper proposes a theoretical framework to study the relationship between network architecture and robustness to noisy labels. The authors propose to measure the predictive power of a network using the test performance of a linear model trained on the learned representations using a small set of clean labels. They hypothesize that a network is more robust if its architecture is more aligned with the target function than the noise. To support their hypothesis, they provide both theoretical and empirical evidence across various neural network architectures and different domains."
SP:903727fe028684623a8ccadec210e641ecffc685,"This paper proposes a method for learning a reward function that maximizes the future probability of successful outcome examples. The authors propose to learn a value function from transitions and successful outcomes, without learning an intermediate reward function. They show that their method satisfies a new data-driven Bellman equation, where examples take the place of the typical reward function term. Experiments show that the proposed method outperforms prior methods that learn explicit reward functions."
SP:39ccbd5909a1d7ed212fe92d8d6843c2c70dfe1f,"This paper studies differentially private stochastic optimization in convex and non-convex settings. In the convex case, the authors focus on the family of non-smooth generalized linear losses (GLLs). Their algorithm for the l2 setting achieves optimal excess population risk in near-linear time, while the best known differentially public algorithms for general convex losses run in super-linear times. For the l1-case with smooth losses and polyhedral constraint, they provide the first nearly dimension independent rate, Õ ( log d (nε)1/3 ) in linear time. For constrained l2-case, they obtain a linear-time algorithm with rate Ú ( 1 n1/4 + d 1/5 (n\epsilon)2/5 ) for l2 weakly convex optimization. "
SP:99a476f71e6901aefe281f11fb72ff78265a5b6e,"This paper studies the cooperative bandit problem in the context of decentralized reinforcement learning. The authors study the problem in three settings: (1) message-passing over stochastic time-varying networks, (2) instantaneous reward sharing over a network with random delays, and (3) adversarially corrupted rewards, including byzantine communication. They propose decentralized algorithms that achieve competitive performance, along with near-optimal guarantees on the incurred group regret as well as an improved delayed-update algorithm that outperforms the existing state-of-the-art on various network topologies. Finally, they present tight network-dependent minimax lower bounds on the group regret."
SP:d3e896a65470f2439bc7753b4f66e152306b2d6f,"This paper proposes a post-training quantization algorithm for vision transformers. The main idea is to find the optimal low-bit quantization intervals for weights and inputs, respectively. To preserve the functionality of the attention mechanism, the authors introduce a ranking loss into the conventional quantization objective that aims to keep the relative order of the self-attention results after quantization. Moreover, they thoroughly analyze the relationship between quantization loss of different layers and the feature diversity, and explore a mixed-precision quantization scheme by exploiting the nuclear norm of each attention map and output feature."
SP:aa6b1328585b5916267a3ff4f9119e7aa4ce2bb5,"This paper studies the convergence of double-Q-learning in the case of constant learning rate. The authors show that synchronous double Q-learning attains an accurate global optimum with a time complexity of $O(\sqrt{L}(L^2/\epsilon^2)$ and asynchronous algorithm achieves a complexity of $\Omega(L^{-1/\gamma)$ where $L$ is the cardinality of the state-action space, $\gamma$ is a discount factor, and $D$ is related to the sampling strategy for asynchronous double Q learning. The results improve the existing convergence rate by an order of magnitude. "
SP:04fd4d83717c4f7e1a4b5651a59200151f33411d,This paper proposes a method for semi-supervised out-of-distribution (OOD) detection. The proposed method is based on the idea of Structure-Keep Unzipping (STU) which learns a new representation space in which OOD samples could be separated well. An efficient optimization algorithm is derived to solve the objective. Experiments on various OOD detection benchmarks show that the proposed method outperforms other methods by a large margin.
SP:6bf8b94483b26033795b0eda9649518027f5e1c2,"This paper proposes a multi-task model for referring expression comprehension (REC) and segmentation (RES) tasks. The proposed model is based on a transformer architecture, where two modalities are fused in a visual-lingual encoder and decoder. In the decoder, the model learns to generate contextualized lingual queries which are then decoded and used to directly regress the bounding box and produce a segmentation mask for the corresponding referred regions. Experiments show that the proposed model outperforms state-of-the-art methods on both REC and RES tasks."
SP:29b552b36696c9bda72f3ab4f31605d98880fd6b,"This paper studies the problem of multiclass boosting, which is an algorithmic approach to combining weak and moderately inaccurate hypotheses to a strong and accurate one. The authors study the resources required for boosting, especially how they depend on the number of classes k, for both the booster and weak learner. They show that the boosting algorithm itself only requires O(log k) samples, as they show by analyzing a variant of AdaBoost for the setting. They also prove a trade-off between number of oracle calls and the resources needed of the weak learners."
SP:f63b050773871338c48b778c362172e4b72477a4,"This paper proposes a method for unsupervised image segmentation and object-centric scene generation based on embedding-based methods. The proposed method is based on a differentiable clustering of pixels using a stochastic stick-breaking process, which is similar to iterative refinement, but without the need of initialising a fixed number of clusters a priori. This is used to develop a new model, GENESIS-V2, which can infer a variable number of object representations without using RNNs or iterative methods. Experiments on synthetic and real-world datasets show that the proposed method outperforms the baselines."
SP:408deb9e5577ee7118b836fee77135df641fe545,"This paper proposes a new method for online prediction in the online setting where the data generating distribution is allowed to vary over time in an unknown fashion. The proposed method is based on the idea of adaptive conformal inference, which is an extension of the Conformal Inference (CIFAR-10) method. The main idea is to model the distribution shift as a learning problem in a single parameter whose optimal value is varying over time and must be continuously re-estimated. The method is tested on two real world datasets and finds that its predictions are robust to visible and significant distribution shifts."
SP:e6e5b1e2428abcf1a163ec1cce15cd299f9a544f,This paper proposes a pose-level inference method for multi-person pose estimation in crowded scenes. The proposed method is based on the Part-based Pose Generation (PPG) and Pose Refinement (PRe) modules. The Pose Fusion (PF) module is a fusion of the PPG and PRe modules. Experiments on several crowded scenes pose estimation benchmarks demonstrate the superiority of PINet. 
SP:e76f048c3dccffcb8bcc6a66f6165fc19d175610,This paper proposes a new algorithm for solving the Bellman operator for S-rectangular robust Markov decision processes with L-constrained rectangular ambiguity sets. The algorithm combines a novel homotopy continuation method with a bisection method to solve the ambiguity in quasi-linear time in the number of states and actions. The experimental results confirm the practical viability of the proposed algorithm and show that it outperforms a leading commercial optimization package.
SP:c4af66a64a5c2bd58ca2e29dbc4b27d5bf4b63b8,"This paper studies the problem of online knapsack problem with very weak predictions. The paper shows that even seemingly weak predictions can be utilized effectively to improve the performance of online algorithms. In particular, the paper systematically derive online algorithms that attain the best possible competitive ratio for any fixed prediction and extend the results to more general settings such as generalized one-way trading and two-stage onlineknapsack. "
SP:1d478d4fa3f5df0ded963ef164325667fd744dbb,"This paper proposes a new model-based episodic memory of trajectories for episodic control. The memory estimates trajectory values, guiding the agent towards good policies. A complementary learning model is built upon the memory, which is a dynamic hybrid control model. Experiments demonstrate that the proposed model allows significantly faster and better learning than other strong reinforcement learning agents across a variety of environments."
SP:551174c1266b5f4b6aaf5432a4c713386f90898c,"This paper proposes a new semi-supervised learning method based on data programming (DP) scheme to generate probabilistic labels for unlabeled data. The authors propose a multiple-choice learning (MCL) based approach to automatically generate LFs from scratch in SSL style. They design a label model to resolve the conflict and overlap among the noisy labels, and finally infer the label for unlabelled data. Extensive experiments on four standard SSL benchmarks show that DP-SSL can provide reliable labels and achieve better classification performance on test sets than existing SSL methods."
SP:d1d6a40a8bde62a21da4fc18a076e344c84ab0d0,"This paper proposes a multi-view pose transformer (MVPT) method for estimating multi-person 3D poses from multi view images. The proposed method is based on the idea of learning a query embedding for skeleton joints, which is then used to train a neural network to estimate the 3D joint locations. The method is evaluated on the Panoptic dataset and compared to several state-of-the-art methods. "
SP:2e147bd5321e25bb27d2531fd58c46460a1e5320,"This paper studies the problem of support recovery and approximate recovery of sparse vectors from a fixed family of unknown sparse vectors. In particular, the authors consider the case where each vector in the family has at most k non-zero elements, and the goal is to learn the supports of all vectors from the family using a sequence of noisy responses. The authors prove the existence of learning algorithms for the first problem which work without any assumptions on the unknown vectors. They also show that learning algorithms exist for the second problem and rigorously analyze their query complexity."
SP:e3388e479a825be429f3a878e2c4d8b05903ff10,"This paper studies the problem of bandit quickest changepoint detection, where only a small subset of sensors are used to detect abrupt changes in temporal behavior patterns. The authors derive an information-theoretic lower bound on the detection delay for a general class of finitely parameterized probability distributions, and propose a computationally efficient online sensing scheme that seamlessly balances the need for exploration of different sensing options with exploitation of querying informative actions. They derive expected delay bounds for the proposed scheme and show that these bounds match the information lower bounds at low false alarm rates, establishing optimality of the proposed method. They then perform a number of experiments on synthetic and real datasets demonstrating the effectiveness of their proposed algorithm."
SP:268260e9452ba2bc57e50a6b7b3328233137ac9b,"This paper proposes a new method for solving stochastic nested optimization problems. The main contribution of this paper is to unify several SGD-type updates for nested problems into a single SGD approach that they term ALternating Stochastic Gradient dEscenT (ALSET) method. The authors show that under certain regularity conditions, the proposed ALSET method can converge to the stationary point of the nested problem with a sample complexity of O(2/\epsilon^2). The authors also show that the proposed method can be applied to compositional, min-max, and reinforcement learning problems."
SP:82ad52361bc5b2c421f1dc6b76e1a5520570fc6c,"This paper proposes a Siamese Sampling and Reasoning (SiaSamRea) method for video question answering. The authors propose a siamese sampling mechanism to generate sparse and similar clips from the same video, and a novel reasoning strategy for integrating the interdependent knowledge between contextual clips into the network. The reasoning strategy consists of two modules: (1) siamesese knowledge generation to learn the inter-relationship among clips; (2) Siameses knowledge reasoning to produce the refined soft label by propagating the weights of inter-relation to the predicted candidates of all clips. Extensive experiments demonstrate that the proposed method achieves state-of-the-art performance on five VideoQA benchmarks."
SP:160022e2cd61159da92f92e85520b7062a337a8d,"This paper proposes a method to reduce the computational and memory complexity of a large class of structured models. The main idea is to view the central inference step as a matrix-vector product and use a low-rank constraint to trade off model expressivity and speed via the rank. Experiments on language modeling, polyphonic music modeling, unsupervised grammar induction, and video modeling show that the proposed method matches the accuracy of standard models while providing practical speedups."
SP:238592ad73927194cdf0c0cf9ae2e48ca86e182c,"This paper proposes Sample Average Uncertainty (SAU) as a new exploration method for deep contextual bandits. SAU is a frequentist approach that directly estimates the uncertainty of the outcomes based on the value predictions. The authors show theoretically that SAU asymptotically matches the uncertainty provided by Thompson Sampling, as well as its regret bounds. Empirically, the authors show that the proposed SAU-based exploration outperforms current state-of-the-art deep Bayesian bandit methods on several real-world datasets at modest computation cost."
SP:ffc5b18f7e18607b2934e5aa199e7542005d79f4,"This paper proposes a method for disentangled behavior embedding from videos. The method is based on disentangling the dynamic behavioral factors (pose) from time-invariant, non-behavioral nuisance factors (context) in a deep autoencoder, and exploit the temporal structures of pose dynamics. The authors further combine DBE with a stochastic temporal model to propose Variational Disentangled Behavior Embedding (VDBE), an end-to-end approach that learns meaningful discrete behavior representations and generates interpretable behavioral videos. Compared to competing approaches, DBE and VDBE enjoy superior performance on downstream tasks such as fine-grained behavioral motif generation and behavior decoding."
SP:bf78a450e4aad6b87fdeb8ec0d68adaaff7b595b,This paper proposes a deep 3D conditional generative model that can synthesize high-resolution 3D shapes using simple user guides such as coarse voxels. It marries the merits of implicit and explicit 3D representations by leveraging a novel hybrid 3D representation. The core of DMTET includes a deformable tetrahedral grid that encodes a discretized signed distance function and a differentiable marching tetrahedra layer that converts the implicit signed distance representation to the explicit surface mesh representation. This combination allows joint optimization of the surface geometry and topology as well as generation of the hierarchy of subdivisions using reconstruction and adversarial losses defined explicitly on the surface mesh.
SP:2bc0bd6aa2a12691b16145f0d23542c4c86e3a44,"This paper proposes sliced mutual information (SMI) as a surrogate measure of statistical dependence. SMI is defined as an average of MI terms between one-dimensional random projections. The authors show that SMI preserves many of the structural properties of classic MI, while gaining scalable computation and efficient estimation from samples. Furthermore, SMI can grow as a result of deterministic transformations. This enables leveraging SMI for feature extraction by optimizing it over processing functions of raw data to identify useful representations thereof."
SP:e220b348901b476c2afd95f97630fb5400582f40,"This paper proposes a computationally efficient two-step lookahead constrained Bayesian optimization acquisition function (2-OPT-C) for both sequential and batch settings. The authors argue that being non-myopic is even more important in constrained problems because fear of violating constraints pushes myopic methods away from sampling the boundary between feasible and infeasible regions, slowing the discovery of optimal solutions with tight constraints. To enable fast acquisition function optimization, the authors develop a novel likelihoodratio-based unbiased estimator of the gradient of the two step optimal acquisition function that does not use the reparameterization trick. In numerical experiments, the proposed method is shown to improve query efficiency by 2x or more over previous methods, and in some cases by 10x."
SP:51fbd861422647912f275b48861ea3c4812afdc8,"This paper proposes Multi-Dimensional Distributional DQN (MD3QN), which extends distributional RL to model the joint return distribution from multiple reward sources. The authors prove the convergence for the joint distributional Bellman operator and build an empirical algorithm by minimizing the Maximum Mean Discrepancy between joint return distributions and its Bellman target. In experiments, the authors show that the proposed method can accurately model the return distribution in environments with richly correlated reward functions and outperforms previous RL methods utilizing multi-dimensional reward functions in the control setting."
SP:1f85c93d6bbfd65bf497c92c9cd534d799753097,"This paper proposes a method for 3D surface reconstruction based on a flow-based method. The method is based on the idea of learning to deform a reference template towards a target object, which is then used to train a neural network to generate a 3D model of the target object. The model is trained on a set of diffeomorphic transformations of the reference template, which are then used as input to the neural network. Theoretical analysis is performed to show that the proposed method is able to generate more realistic 3D surfaces than the state-of-the-art methods."
SP:2f31d9cf4ad17ad08344439ca0aef7ec91944545,"This paper studies the problem of data deletion in the non-convex setting. In particular, the authors consider the case where data is deleted from a model (e.g., when the model is adaptive) and the deletion algorithm is adaptive. In this setting, the paper provides a general reduction from deletion guarantees for adaptive sequences to deletion guarantees against non-adaptive sequences, using differential privacy and its connection to max information. The paper also provides a practical attack against the SISA algorithm of Bourtoule et al. [2021] on CIFAR-10, MNIST, Fashion-MNIST."
SP:7150006590e268ab732c9be6c9048f67a377f956,"This paper studies the problem of risk-averse Bayes-adaptive reinforcement learning in MDPs. In particular, the authors consider the conditional value at risk (CVaR) of the total return in Bayesian Markov decision processes (MDPs). The authors show that a policy optimising CVaR in this setting is risk averse to both the epistemic uncertainty due to the prior distribution over MDP and the aleatoric uncertainty of the MDP. The authors reformulate the problem as a two-player stochastic game and propose an approximate algorithm based on Monte Carlo tree search and Bayesian optimisation. The experiments demonstrate that their approach significantly outperforms baseline approaches for this problem."
SP:a94f39406f73d7483ddd744ed2f03c78b8bc5d44,"This paper studies the behavior of shallow ReLU networks trained with the logistic loss via gradient descent on binary classification data where the underlying data distribution is general, and the (optimal) Bayes risk is not necessarily zero. In this setting, it is shown that gradient descent with early stopping achieves population risk arbitrarily close to optimal in terms of logistic and misclassification losses, but also in terms calibration, meaning the sigmoid mapping of its outputs approximates the true underlying conditional distribution arbitrarily finely. The necessary iteration, sample, and architectural complexities of this analysis all scale naturally with a certain complexity measure of the true conditional model. While it is not shown that early stopping is necessary, it was shown that any univariate classifier satisfying a local interpolation property is inconsistent."
SP:a9c786cbb61e1f10f3542161b13e43a1a68ab34d, social media. This paper proposes a method for coordinated group detection based on neural temporal point process. The proposed method is based on a Gibbs distribution of group assignment based on how consistent an assignment is to the account embedding space and prior knowledge. The authors also design a theoretically guaranteed variational inference approach to learn a mean-field approximation for the Gibbs distribution. The experimental results on a real-world dataset show the effectiveness of the proposed method compared to state-of-the-art model in both unsupervised and semi-supervised settings.
SP:b5c6e967a26a02861db2ecd620e9061db0c03e59,"This paper studies the problem of binary classification in the neural tangent kernel (NTK) regime, where the network depth plays the role of a fitting resource in solving the classification problem. In particular, the authors show that when the network is sufficiently deep, the NTK can be locally approximated by a translationally invariant operator on the manifolds and stably inverted over smooth functions, which guarantees convergence and generalization. This is the first generalization guarantee for deep networks with nonlinear data that depends only on intrinsic data properties."
SP:8f6bee3be43df6b6e80804974014caaafe08c49e,"This paper proposes a new auxiliary classifier for conditional generative adversarial networks (cGANs) based on the idea of projecting input vectors onto a unit hypersphere. The authors also propose a data-to-data cross-entropy loss (D2D-CE) to exploit relational information in the class-labeled dataset. The experimental results show that ReACGAN achieves state-of-the-art generation results on CIFAR10, Tiny-ImageNet, CUB200, and ImageNet datasets."
SP:080e80746a87228b156408ff649ab7a17f44e92d,"This paper proposes an extensive-form double oracle algorithm for two-player zero-sum games that is guaranteed to converge to an approximate Nash equilibrium linearly in the number of infostates. Unlike PSRO, which mixes best responses at the root of the game, XDO mixes best response at every infostate. The authors also introduce Neural XDO (NXDO), where the best response is learned through deep RL. In tabular experiments on Leduc poker, the authors show that XDO achieves an approximate equilibrium in a number of iterations an order of magnitude smaller than PSRO. The experimental results on Oshi-Zumo and Leduc Poker show that tabular XDO can achieve a lower exploitability than CFR with the same amount of computation. The experiments also show that the proposed XDO outperforms PSRO and NFSP on a sequential multidimensional continuous-action game."
SP:bda04facef4f34679fc4e17b8ea1aae74c3d649f,"This paper proposes a permutation-invariant variational autoencoder for graph-level unsupervised representation learning. The proposed method is based on the idea of variational auto-encoder (VAE), which learns to match the node order of input and output graph, without imposing a particular node order or performing expensive graph matching. The authors demonstrate the effectiveness of their proposed model for graph reconstruction, generation and interpolation, and evaluate the expressive power of extracted representations for downstream graph level classification and regression."
SP:e17ea6aeba78c9dfc25596d8b35a2a4f1f1f6763,"This paper proposes to decouple the depth and scope of Graph Neural Networks (GNNs) by first extracting a localized subgraph as the bounded-size scope, and then applying a GNN of arbitrary depth on top of the subgraph. Theoretically, the paper shows that this decoupling improves the expressive power from the perspectives of graph signal processing (GCN), function approximation (GraphSAGE), and topological learning (GIN). Empirically, on seven graphs (with up to 110M nodes) and six backbone GNN architectures, the proposed method achieves significant accuracy improvement with orders of magnitude reduction in computation and hardware cost."
SP:4890f251db559a0a572afc66e0c1f899b577d9ff,"This paper studies the problem of approximating any log-concave distribution using affine-coupling flows. The authors show that any logconcavity distribution can be approximated using well-conditioned affine coupling flows. In particular, the authors prove that the Jacobian of the latent-to-observable-variable transformation is triangular, which allows the likelihood to be computed in linear time. The paper also provides theoretical evidence for the benefits of Gaussian padding when training normalizing flows. "
SP:5ffa81488ed1092deb89bd5e150fa146325057ce,This paper proposes a method for online coupons allocation in the context of online e-commerce. The authors propose a budget constrained offline reinforcement learning and evaluation with λ-generalization (BCORLE(λ)) framework. The proposed method can help enterprises develop a coupons allocation policy which greatly improves users’ retention rate on the platform while ensuring the cost does not exceed the budget. The experiments on the simulation platform and real-world e-Commerce market validate the effectiveness of the proposed method.
SP:6b04cc7b4e45b9e65a1d34c15e3f75a2ef27d601,"This paper proposes a method for source-free domain adaptation (SFDA) where the source pretrained model is adapted to the target domain in the absence of source data. The method is based on the observation that target data, which might no longer align with the source domain classifier, still forms clear clusters. To capture this intrinsic structure, the authors define local affinity of the target data and encourage label consistency among data with high local affinity. The authors observe that higher affinity should be assigned to reciprocal neighbors, and propose a self regularization loss to decrease the negative impact of noisy neighbors. To aggregate information with more context, they consider expanded neighborhoods with small affinity values. The experimental results verify that the inherent structure of target features is an important source of information for domain adaptation."
SP:ac1bf04ff782e5892a0bc5fe5949848ca8e731c2,"This paper proposes a method for pooling features from a set of features into a fixed-dimensional representation. The proposed method is based on the idea of sampling from a probability distribution. The authors propose an end-to-end trainable Euclidean embedding for sliced-Wasserstein distance to learn from set-structured data effectively. They evaluate their proposed pooling method on a wide variety of set- structured data, including point cloud, graph, and image classification tasks, and demonstrate that their proposed method provides superior performance over existing set representation learning approaches."
SP:6cb2f0cbc076f8680cb00411790629f8e1478053,"This paper proposes a new family of RNNs that can be formulated using stochastic bilevel optimization (SBO). The main idea is to convert the SBO problem into an RNN where the feedforward and backpropagation solve the lower and upper-level optimization for learning hidden states and their hyperparameters, respectively. The authors prove that under mild conditions there is no vanishing or exploding gradient in training SBO-RNN. Empirically, the authors demonstrate the effectiveness of the proposed method with fewer parameters, less training data, and faster convergence."
SP:d3a4300e21ca215334f256f0467a428470548fe4,"This paper studies the online problem of minimizing power consumption in systems with multiple power-saving states. During idle periods of unknown lengths, an algorithm has to choose between different power saving states of different energy consumption and wake-up costs. The authors develop a learning-augmented online algorithm that makes decisions based on (potentially inaccurate) predicted lengths of the idle periods. The algorithm’s performance is near-optimal when predictions are accurate and degrades gracefully with increasing prediction error, with a worst-case guarantee almost identical to the optimal classical online algorithm for the problem."
SP:22aba6284123af0ecd6605ee4e89b351bd7e10a3,"This paper proposes a mathematical framework for quantifying the transferability in multi-source transfer learning problems, with both the task similarities and the sample complexity of learning models taken into account. In particular, the authors consider the setup where the models learned from different tasks are linearly combined for learning the target task, and use the optimal combining coefficients to measure transferability. The authors demonstrate the analytical expression of this transferability measure, characterized by the sample sizes, model complexity, and the similarities between source and target tasks, which provides fundamental insights of the knowledge transferring mechanism and the guidance for algorithm designs. Furthermore, they apply their analyses for practical learning tasks, and establish a quantifiable transferable measure by exploiting a parameterized model. In addition, they develop an alternating iterative algorithm to implement their theoretical results for training deep neural networks in multi source transfer learning tasks."
SP:0fb8dcf15e0d43547d566fdba7bc70b3bb600005,"This paper proposes a model for visual search that aims to explain why there is an asymmetry in visual search tasks. Specifically, the authors propose a model that takes a target and a search image as inputs and produces a sequence of eye movements until the target is found. The model integrates eccentricity-dependent visual recognition with target-dependent top-down cues. The authors propose that the polarity of search asymmetry arises from experience with the natural environment and test this hypothesis by training the model on augmented versions of ImageNet where the biases of natural images are either removed or reversed depending on the training protocol."
SP:f0cc968ea9da4884dcdaf6d0c75ea9f1511bdfc3,"This paper studies the problem of certifiable training for adversarial robustness. The authors propose a new method for certifiable robustness based on smoothing the loss landscape of linear relaxation-based methods. They show that the current state-of-the-art method, Interval Bound Propagation (IBP) training, uses much looser bounds but outperforms other models that use tighter bounds. In addition, they identify another key factor that influences the performance of certified training: smoothness of loss landscape. To test the claim, they design a new certified training method with the desired properties. "
SP:a158f8772a9dada059ffd1d6d7838ed40d8483da,"This paper studies the problem of online linear regression in the stochastic setting. The authors derive high probability regret bounds for online ridge regression and the forward algorithm. This enables them to compare online regression algorithms more accurately and eliminate assumptions of bounded observations and predictions. In particular, they advocate for the use of forward algorithm in lieu of ridge due to its enhanced bounds and robustness to the regularization parameter. Moreover, they explain how to integrate it in algorithms involving linear function approximation to remove a boundedness assumption without deteriorating theoretical bounds. They showcase this modification in linear bandit settings where it yields improved regret bounds."
SP:17ff9a2133aebf2d1b1787e8efc49d709389c0e7,"This paper proposes a fast extragradient method for nonconvex-nonconcave minimax problems. The main contribution of this paper is the development of a two-time-scale variant of the standard EG method with an anchoring technique, named FEG, which has a fast O(1/k) rate on the squared gradient norm for smooth structured non-convolutional problems. This paper further develops its backtracking line-search version, called FEG-A, for the case where the problem parameters are not available. The theoretical analysis of FEG is provided."
SP:4e38973033de24fc183c6112e1146f8eef0ddaea,"This paper studies the problem of uniformity testing for statistical data that consists of rankings over m items, where the alternative class is restricted to Mallows models. The authors show that uniform distribution can be distinguished from Mallows model with O(m 1/2) samples based on simple pairwise statistics, which allows us to test uniformity using only two samples, if m is large enough. In addition, the authors consider uniformity test with central and local differential privacy (DP) constraints. The central DP algorithm requires O(max{1/\sqrt{0, 1/p m}), where $p$ is the privacy budget parameter. The local DP algorithm is straightforward to apply to binary statistics that is extracted from the ranking data."
SP:99a835191a3ba8372e391b6d3316e9b68e543295,"This paper studies a general greedy score-based algorithm for learning directed acyclic graphs (DAGs). The main idea is to learn a score function for each vertices of a DAG, which can be expressed as a function of the number of vertices in the graph. The authors show that this score function can be interpreted as a special case of order-based algorithms for learning DAGs, and provide a theoretical analysis of the duality between Bregman divergences and exponential families. They also provide a computational complexity bound for the algorithm. Finally, they provide extensive experiments to show that the proposed algorithm indeed optimizes the score."
SP:b60989706296b963b6671c01f22384978a334be1,This paper proposes a neural architecture dilation algorithm to improve the adversarial robustness of the backbone CNNs. The proposed method is based on the fact that the standard and adversarial error bounds are well-known and can be derived from the theoretical analysis. Theoretical analysis is provided to show that the proposed method can achieve a trade-off between accuracy and robustness. Empirical results on real-world datasets and benchmark neural networks demonstrate the effectiveness of the proposed algorithm.
SP:77ed765e911a4e5f2bfba13cbd2403500a5d05e6,"This paper studies model-based reward-free reinforcement learning with linear function approximation for episodic Markov decision processes (MDPs). In this setting, in the exploration phase, the agent interacts with the environment and collects samples without the reward, and in the planning phase, in which the agent is given a specific reward function and uses samples collected from exploration phase to learn a good policy. The authors propose a new provably efficient algorithm called UCRL-RFE under the Linear Mixture MDP assumption, where the transition probability kernel of the MDP can be parameterized by a linear function over certain feature mappings defined on the triplet of state, action, and next state. They show that to obtain an $\epsilon$-optimal policy for arbitrary reward function, the algorithm needs to sample at most $O(\sqrt{H})$ episodes during exploration phase. The upper bound matches the lower bound in terms of the dependence on $H$ and $d$."
SP:28563ba0975f56ddb662cd46e85de78bb6024d36,This paper proposes a method for forecasting future events in a data stream of events with seasonal patterns that evolve over time. The proposed method is based on shifting seasonal matrix factorization (SSMF) that learns multiple seasonal patterns (called regimes) as well as switching between them. The method is evaluated on three real-world data streams and compared to state-of-the-art methods. The results show that the proposed method can accurately forecast future events.
SP:e4bb07033001be4d04695ef058f426d49fe440be,"This paper proposes a neural network architecture for solving the assignment problem. The core module, feature weaving layer, is stacked to model frequent communication between elements in a parameter-efficient way to solve the combinatorial problem of assignment. The experimental results showed its impressive performance among the learning-based baselines."
SP:8a559e21d45661eef427b310e5fe8488d5749137,"This paper studies the impact of various self-supervised learning proxy tasks on different architectures and threat models for 3D point clouds with adversarial training. Specifically, the authors study MLP-based (PointNet), convolution-based DGCNN, and transformer-based PCT architectures. The authors demonstrate that appropriate applications of self supervision can significantly enhance the robustness in 3D 3d point cloud recognition. The analysis reveals that local feature learning is desirable for adversarial robustness since it limits the adversarial propagation between the point-level input perturbations and the model’s final output. This insight also explains the success of D GCNN and the jigsaw proxy task in achieving stronger 3D adversarial attacks."
SP:657c5a1114c0d054b9e767d85990bbbb0492912d,This paper considers the problem of computing iterative projections of close-by points over submodular base polytopes. The authors propose a toolkit to speed up the computation of projections using both discrete and continuous perspectives. They also adapt the away-step Frank-Wolfe algorithm to use this information and enable early termination. The theoretical results show orders of magnitude reduction in runtime in preliminary computational experiments.
SP:8dae43d6b5cebb7ef6c39437d997b390c2380536,"This paper studies the problem of learning the natural parameters of a k-parameter minimal exponential family from i.i.d. samples in a computationally and statistically efficient manner. The authors propose a new estimator that is consistent as well as asymptotically normal under mild conditions. They provide finite sample guarantees to achieve an (`2) error of α in the parameter estimation with sample complexity O(poly(k/alpha)) and computational complexity O(\sqrt{k}/\alpha) and show that, at the population level, their method can be viewed as the maximum likelihood estimation of a re-parametrized distribution belonging to the same class of exponential family."
SP:4f9ddb697e86356fb293ef34a69ca3702c4e8164,"This paper proposes a differentiable renderer for inverse graphics that combines the advantages of rasterization and ray-tracing. The main idea is to use a differentiability-based renderer to predict intrinsic object properties from a single image. The proposed renderer is based on the DIB-R++ architecture, which is a combination of differentiable physics-based and path tracing based renderers. In particular, the authors propose to use two different ways of rendering the light: direct estimation and spherical basis functions. The authors evaluate the performance of the proposed method on synthetic and real-world data. "
SP:6ac1c8556e7131939cc582f513bc9921470e1b09,"This paper proposes a differentiable training method for localization based on sampling-argmax. The main idea is to minimize the expectation of the localization error, which can be approximated by the average error of all samples drawn from the output distribution. The authors propose a continuous formulation of the distribution and develop a sampling process to approximate the expectation. Experiments show that the proposed method can seamlessly replace the conventional soft-arg max operation on various localization tasks."
SP:478c05c90090f9d80b72ac352c488073b45a5d8b,"This paper proposes a directed graph data augmentation method called Laplacian perturbation to generate contrastive views for graph contrastive learning (GCL). The proposed method is based on the idea that the graph structure of directed graphs should not be changed too much, as it may mislead the message passing scheme. The paper also proposes a multi-task curriculum learning method to learn from multiple contrastive view. Experiments on various benchmarks show that the proposed method outperforms the state-of-the-art approaches."
SP:85b383d2f722f7bff438840e423f5cb4c67d5980,"This paper proposes a new benchmark for language grounding that unifies a collection of diverse grounded language learning environments under a common interface. It consists of grid-world environments that require generalization to new dynamics, entities, and partially observed worlds (RTFM, Messenger, NetHack), as well as symbolic counterparts of visual worlds that require interpreting rich natural language with respect to complex scenes (ALFWorld, Touchdown). In addition, the authors propose the first shared model architecture for RL on these environments, and evaluate recent advances such as egocentric local convolution, recurrent state-tracking, entity-centric attention, and pretrained LM using SILG."
SP:23c8db56f59f778fe812a5dd161f7a1f21c3cdba,"This paper proposes a sparse version of the Vision Transformer (V-Transformer) that is scalable and competitive with the largest dense networks. In particular, the authors propose an extension to the routing algorithm that can prioritize subsets of each input across the entire batch, leading to adaptive per-image compute. This allows V-MoE to trade-off performance and compute smoothly at test-time. The authors demonstrate the potential of V-V-transformer to scale vision models and train a 15B parameter model that attains 90.35% on ImageNet."
SP:c5235f41dfb8b5cc478f11c5d5e0ab0b8676871e,"This paper studies the problem of training narrow neural networks with fewer than n neurons. The authors prove that as long as the width m > 2n/d (where d is the input dimension), there exists at least one global minimizer with zero training loss. They also identify a nice local region with no local-min or saddle points and show that it is not clear whether gradient descent can stay in this nice region. In addition, they consider a constrained optimization formulation where the feasible region is the nice region, and prove that every KKT point is a nearly global minimiser. They show that projected gradient methods converge to KKT points under mild technical conditions."
SP:0be529f5254afd59dcfa6b34a359c7037e7a8323,"This paper proposes a continuous mean-covariance bandit (CMCB) model that explicitly takes into account option correlation. Specifically, in CMCB, there is a learner who sequentially chooses weight vectors on given options and observes random feedback according to the decisions. The agent’s objective is to achieve the best trade-off between reward and risk, measured with option covariance. To capture different reward observation scenarios in practice, the authors consider three feedback settings, i.e., full-information, semi-bandit, and full-Bandit feedback. They propose novel algorithms with optimal regrets (within logarithmic factors), and provide matching lower bounds to validate their optimalities. The experimental results also demonstrate the superiority of their algorithms."
SP:472a90bb175b0286765c5a47b040e1a58f594a05,"This paper proposes a non-commutative extension of Lee-Seung’s Multiplicative Update (MMU) algorithm for computing Positive Semidefinite (PSD) factorization of a data matrix X, which is a collection of r-dimensional PSD matrices satisfying the condition Xij = tr(AiBj) for all i\in [m, j\in n]. The authors show that the MMU algorithm ensures that updates remain PSD by congruence scaling with the matrix geometric mean of appropriate PSD matrix matrices, and it retains the simplicity of implementation that the multiplicative update algorithm for NMF enjoys. The authors also show that under their update scheme the squared loss objective is non-increasing and fixed points correspond to critical points. The analysis relies on Lieb's concavity theorem."
SP:83abd6d149d88cc6e96cbc4d488e4fe9dc2a4fcb,"This paper proposes a meta-learning framework for domain generalization (DG) based on meta-domain specific-domain invariant (mDSDI) that extends beyond the invariance view to further capture the usefulness of domain-specific information. The key insight is to disentangle features in the latent space while jointly learning both domain-invariant and domainspecific features in a unified framework. The domain specific representation is optimized through the meta learning framework to adapt from source domains, targeting a robust generalization on unseen domains. Empirical results show that mDSDI provides competitive results with state-of-the-art techniques in DG."
SP:4191474c75e2fedf514f0f3001a67a047eb74c30,"This paper presents a method for improving the quality of image synthesis using a combination of ablations and classifier guidance. The ablations are used for unconditional image synthesis, while the guidance is used for conditional image synthesis. The authors show that the ablations improve FID on ImageNet 128, 256, and 512 by a factor of 4. The guidance is a simple, compute-efficient method for trading off diversity for fidelity using gradients from a classifier. The paper also shows that the guidance can be combined with upsampling diffusion models to further improve the quality."
SP:fe3cab08596cde4c14ecf6fca8d0f95b02bab229,"This paper proposes a method to improve few-shot learning by leveraging out-of-distribution samples. The proposed method is based on the idea of Poodle, which is an extension of the Poodle algorithm. The key idea is to minimize the distance from prototypes to out- of-distributed samples while maximizing the distance between prototypes and out of distribution samples (i.e., support, query data). The method is simple to implement, agnostic to feature extractors, lightweight without any additional cost for pre-training, and applicable to both inductive and transductive settings. Extensive experiments on various standard benchmarks demonstrate that the proposed method consistently improves the performance of pretrained networks with different architectures."
SP:b1f65724926f136979829b7a6c870bc31f38f591,"This paper studies the problem of prioritized sampling in reinforcement learning. In particular, the authors propose two methods to compute the prioritization weight, namely ReMERN and ReMERT. Theoretical analysis is provided to show that data with higher hindsight TD error, better on-policiness and more accurate Q value should be assigned with higher weights during sampling. The authors also provide theoretical justifications for previous criteria, such as TD error and recentness, which are mostly heuristically designed. In addition, they propose two new algorithms to compute prioritization weights: ReMerner, which learns an error network, and reMERT, which exploits the temporal ordering of states."
SP:601ebf30b3c6aa35fcef49633aa8eb0acd0f2c66,This paper studies the problem of sequential prediction with expert advice in a nonstationary environment with long-term memory guarantees in the sense of Bousquet and Warmuth [4]. The authors give a linear-time algorithm that improves on the best known regret bounds [27]. This algorithm incorporates a relative entropy projection step. This projection is advantageous over previous weight-sharing approaches in that weight updates may come with implicit costs as in for example portfolio optimization.
SP:b2439973063e827b3cbe92306a2fdee3286b6b44,"This paper studies the problem of contextual linear bandits, which is motivated by routing applications in navigational engines and recommendation systems. In this problem, the learner is presented with a subset Xt ⊆ R of possible actions and can only learn the identity of the best action arg maxx. The authors propose algorithms for this problem which achieve regret O(d log T^T) and exp(O(dlog d)). To accomplish this, they design novel cutting-plane algorithms with low “regret” – the total distance between the true point w∗ and the hyperplanes the separation oracle returns. In addition, they also consider the variant where we are allowed to provide a list of several recommendations and give an algorithm with O(log d log d) regret and list size poly(d). Finally, they construct nearly tight algorithms for a weaker variant of this problem where the learners only learns an action that is better than the recommendation. Their results rely on new algorithmic techniques in convex geometry."
SP:abe83c7e0bcf4829742609d709637e2f84d8a4d9,"This paper introduces a small set of orthogonal combinators for composing machine learning operators into pipelines. It describes a translation scheme from pipelines and associated hyperparameter schemas to search spaces for AutoML optimizers. The paper presents Lale, an open-source sklearn-compatible AutoML library, and evaluates it with a user study."
SP:0d7f1cae577ed598048b64617e85ca6bd5c6d7fa,"This paper studies the problem of meta-learning in the context of sparse gradient descent (SGD). The authors propose to learn a weight initialization such that a small number of weight changes results in low generalization error. They show that patterned sparsity emerges from this process, with the pattern of sparsity varying on a problem-by-problem basis. This selective sparsity results in better generalization and less interference in a range of few-shot and continual learning problems. The authors also show that sparse learning also emerges in a more expressive model where learning rates are meta-learned."
SP:05037e1850003a725a466b64d3e32aa2aed458fb,"This paper proposes a new method for multi-view learning based on shared independent component analysis (ShICA) that models each view as a linear transform of shared independent components contaminated by additive Gaussian noise. The authors show that this model is identifiable if the components are either non-Gaussian or have enough diversity in noise variances. They then show that in some cases multi-set canonical correlation analysis can recover the correct unmixing matrices, but that even a small amount of sampling noise makes Multiset CCA fail. To solve this problem, the authors propose to use joint diagonalization after multiset correlation analysis, leading to a new approach called ShICA-J, which is based on second-order statistics. They further propose to leverage non-gaussianity of the components using a maximum-likelihood method, which can be both more accurate and more costly. Finally, they provide empirical evidence on fMRI and MEG datasets that ShICA yields more accurate estimation of components than alternatives."
SP:44dd1faa1813c433fd7581d05cae3df440bfb93e,"This paper studies the problem of how to train agents that collaborate well with human partners without using human data. The authors argue that the crux of the problem is to produce a diverse set of training partners. Drawing inspiration from successful multi-agent approaches in competitive domains, they find that a surprisingly simple approach is highly effective. They train our agent partner as the best response to a population of self-play agents and their past checkpoints taken throughout training, a method they call Fictitious Co-Play (FCP). Their experiments focus on a two-player collaborative cooking simulator that has recently been proposed as a challenge problem for coordination with humans. They find that FCP agents score significantly higher than SP, PP, and BCP when paired with novel agent and human partners. Furthermore, humans report a strong subjective preference to partnering with FCP agent over all baselines."
SP:21c84bd720b1e90ea0f88fbf8fd24dbcb49b547c,"This paper proposes a new multi-agent actor-critic method for cooperative multi-Agent reinforcement learning. The proposed method is based on the factored critic method of MADDPG, which combines per-agent utilities into the joint action-value function via a non-linear monotonic function, as in QMIX. The authors also employ a centralised policy gradient estimator that optimises over the entire joint action space, rather than optimising over each agent’s action space separately. The experimental results demonstrate the superior performance of the proposed method on MuJoCo and StarCraft II tasks."
SP:1c8351b8a6cdf1212840388e19a596729b3bfda4,This paper proposes a new neural network architecture for long-term memory. The key idea is to use a key-value mechanism to store and read out memories in a single step. The authors propose a combination of biologically plausible three-factor plasticity rules. The network is trained using meta-learning. The experimental results show that the proposed architecture is comparable to the classical Hopfield network in terms of performance on memory tasks.
SP:7ad6da2c63859d64970e9b35326e9ceab48add47,"This paper studies the problem of pairwise learning, where the loss function depends on a pair of instances. The authors propose stochastic and online gradient descent methods for solving the problem. The main contribution of this paper is to develop stability results, optimization, and generalization error bounds for both convex and nonconvex problems. The paper also introduces novel techniques to decouple the dependency of models and the previous instance in both the optimization and the generalization analysis."
SP:cb11dacc930d71a616ee2fbe4acfae030f9dca59,"This paper proposes REDO, a class-agnostic framework to reconstruct the Dynamic Objects from RGBD or calibrated videos. Compared to prior work, the problem setting is more realistic yet more challenging for three reasons: 1) due to occlusion or camera settings an object of interest may never be entirely visible, but the aim is to reconstruct its complete shape; 2) the authors aim to handle different object dynamics including rigid motion, non-rigid motion, and articulation; 3) they aim to reconstruct different categories of objects with one unified framework. To address these challenges, the authors develop two novel modules. First, they introduce a canonical 4D implicit function which is pixel-aligned with aggregated temporal visual cues. Second, they develop a 4D transformation module which captures object dynamics to support temporal propagation and aggregation. The experiments on synthetic RGBD video datasets SAIL-VOS 3D and DeformingThings4D++, and on real-world video data 3DPW, show that REDO outperforms state-of-the-art dynamic reconstruction methods."
SP:8ae97752e74b4395774575009031abcb6ba5cea7,"This paper provides a non-asymptotic analysis of linear stochastic approximation (LSA) algorithms with fixed stepsize. The analysis is based on new results regarding moments and high probability bounds for products of matrices which are shown to be tight. The authors derive high probability bound on the performance of LSA under weaker conditions on the sequence {(An,bn) : n 2 N⇤} than previous works. However, in contrast, the authors establish polynomial concentration bounds with order depending on the stepsize and the leading terms contain the covariance matrices."
SP:86c1e937755e35efafecc09dfe2606ffb1653a41,"This paper extends the options framework for temporal abstraction in reinforcement learning from discounted Markov decision processes (MDPs) to average-reward MDPs. The authors propose general convergent off-policy inter-option learning algorithms, intra-option algorithms for learning values and models, as well as sample-based planning variants of the learning algorithms. They also extend the notion of option-interrupting behavior from the discounted to the average reward formulation. They show the efficacy of the proposed algorithms with experiments on a continuing version of the Four-Room domain."
SP:7e4e1e20e7c253d02c6ae58457fb30029f130f0c,"This paper proposes an auxiliary self-supervised task for visual transformers (VTs) that is designed to encourage the VTs to learn spatial relations within an image and makes the VT training much more robust when training data is scarce. The proposed task is used jointly with the standard (supervised) training and it does not depend on specific architectural choices, thus it can be easily plugged in the existing VTs. The experimental results show that the proposed task can improve the final accuracy of the trained VTs and it can improve (sometimes dramatically) the final performance."
SP:0132ef17585e293b23e9dc45189c0989d829b52a,"This paper proposes a new method for label-free alignment of hierarchical datasets in hyperbolic spaces. The proposed method is based on Procrustes analysis, which consists of three components: translation, scaling, and rotation. The three components are based on the Riemannian geometry of the Lorentz model of the space. The authors analyze the proposed components, highlighting their useful properties for alignment. The efficacy of HPA, its theoretical properties, stability and computational efficiency are demonstrated in simulations. In addition, the authors demonstrate its performance on three batch correction tasks. "
SP:3580ac64f09e3021de5d4c92411bcc0f3c5d10f3,"This paper studies the trade-off between accuracy for a population of interest (“sum query”) vs. accuracy for its component sub-populations (‘point queries’) in differentially private query answering systems that are not required to produce microdata. The authors show that an uncertainty principle governs the tradeoff between the accuracy for the sum query and the accuracy of the other sub-population. They provide lower bounds for pure, approximate, and concentrated differential privacy. They propose mitigation strategies and create a collection of benchmark datasets that can be used for public study."
SP:c0e64dc8acfaed3e4d7745af12fd34003d0e5017,"This paper proposes a method to train a planner and a goal-conditioned RL agent to jointly learn from each other on a curriculum of tree-structured sub-tasks. The planning policy is trained to minimize the RL agent’s cost of completing the sequence in each layer from top to bottom layers of the tree, which gradually increases the sub-task complexity. The bottom-up traversal of the trees trains the planner from easier sub- tasks with denser rewards on bottom layers to harder ones on top layers and collects its cost to train the planner in the next episode. The method is evaluated on navigation and continuous control tasks."
SP:9911693a04a300b5a93634fb0267ef83e5489d77,"This paper proposes a Bayesian framework for generating black box explanations for black box models. The proposed framework is based on Bayesian versions of LIME and KernelSHAP, which output credible intervals for the feature importances, capturing the associated uncertainty. The authors carry out a detailed theoretical analysis that leverages the aforementioned uncertainty to estimate how many perturbations to sample, and how to sample for faster convergence. Experimental evaluation with multiple real world datasets and user studies demonstrate the efficacy of the proposed framework."
SP:5efb4b81bd37c70640e8768e9dfb5bba14a0cfb8,"This paper studies the problem of heavy tails in adversarial neural networks (ANNs). The authors argue that unordered heavy tails could be the key component which prevents ANNs from achieving superior classification performance since fatter tails tend to overlap in feature space. To address this issue, the authors propose to pre-define Multivariate Skew Laplace distributions and embed the feature distributions into the loss function. The authors further propose a novel method for tackling existing heavy tails with only a modification of classifier where ANN features are clustered with their tails wellformulated through proposed angle-based constraint on the distribution parameters to encourage high diversity of tails. Experiments conducted on several benchmarks and comparison with other distributions demonstrate the effectiveness of proposed approach for boosting the performance of ANNs."
SP:cbccb65457564992d534504c0d060da44cafce8c,"This paper studies the phenomenon of gradient starvation in deep neural networks. The authors provide a theoretical explanation for the phenomenon and propose a novel regularization method to decouple feature learning dynamics. The paper is well-written and well-motivated. However, there are a few issues that need to be addressed in the paper."
SP:8f6fe37cb0a332b66e10cc00261a44622841c8c6,"This paper presents a single-blind evaluation of teams of humans and AI agents in the cooperative card game Hanabi, with both rule-based and learning-based agents. In addition to the game score, the paper also quantify subjective measures of human’s perceived performance, teamwork, interpretability, trust, and overall preference of AI teammate. The authors find that humans have a clear preference toward a rule based AI teammate (SmartBot) over a state-of-the-art learning based AI agent (Other-Play) across nearly all subjective metrics, and generally view the learning based agent negatively. This result has implications for future AI design and reinforcement learning benchmarking, highlighting the need to incorporate subjective metrics of human-AI teaming."
SP:2a05e333fc1a14057515ef3addde9a40152373db,"This paper proposes a novel approach for visual question generation (VQG) based on double-hints. The key idea is that the salient visual regions of interest can be viewed as a constraint to improve the generation procedure for producing high-quality questions. To this end, the proposed method estimates the probability of being ground-truth questions, which in turn implicitly measures the quality of predicted visual hints. Experimental results on two benchmark datasets show that the proposed model outperforms the state-of-the-art approaches by a large margin on a variety of metrics."
SP:15756d6ef47b39ded404acea2135c93bd5ee1062,"This paper proposes Generalized Data Weighting (GDW) to simultaneously mitigate label noise and class imbalance by manipulating gradients at the class level. Specifically, GDW unrolls the loss gradient to class-level gradients by the chain rule and reweights the flow of each gradient separately. Extensive experiments in various settings verify the effectiveness of GDW."
SP:7a8f56a01bec51ebf70d9ff689005a62cccfe5c6,"This paper proposes a novel task of grounding language in spatio-temporal representations of behavioral traces of an embodied agent. The grounding is achieved by training a truth function that predicts if a description matches a given history of observations. The descriptions involve time-extended predicates in past and present tense as well as spatio temporal references to objects in the scene. To study the role of architectural biases in this task, the authors train several models including multimodal Transformer architectures, which implement different attention computations between words and objects across space and time. They test models on two classes of generalization: 1) generalization to randomly held-out sentences; 2) generalisation to grammar primitives. They observe that maintaining object identity in the attention computation of our Transformers is instrumental to achieving good performance on generalization overall, and that summarizing object traces in a single token has little influence on performance."
SP:3d4a9d439bc84c3b0e6600f6985a23bdf95cd67f,"This paper proposes Prototypical Cross-Attention Network (PCAN) for multiple object tracking and segmentation. PCAN first distills a space-time memory into a set of prototypes and then employs cross-attention to retrieve rich information from the past frames. To segment each object, PCAN adopts a prototypical appearance module to learn the contrastive foreground and background prototypes, which are propagated over time. Extensive experiments demonstrate that PCAN outperforms current video instance tracking and video segmentation competition winners on both Youtube-VIS and BDD100K datasets."
SP:1175ad16382b349ab1a39895150172d266abe571,"This paper studies the relationship between gradient flow and gradient descent in the context of deep learning. In particular, the authors show that gradient flow can be viewed as an approximate numerical solution to the initial value problem of gradient descent, and that the degree of approximation depends on the curvature around the gradient flow trajectory. The authors then show that over deep neural networks with homogeneous activations, gradient flow trajectories enjoy favorable curvature, suggesting they are well approximated by gradient descent. This finding allows them to translate an analysis of gradient flow over deep linear neural networks into a guarantee that gradient descent efficiently converges to global minimum almost surely under random initialization. Experiments suggest that over simple neural networks, gradient descent is indeed close to gradient flow."
SP:b8412e9ce82ce92125fe7cd3aff7bea8b906d16e,"This paper considers a stochastic multi-armed bandit problem with delayed impact of actions. In this setting, actions taken in the past impact the arm rewards in the subsequent future. The authors generalize the bandit setting to encode the dependency of this “bias” due to the action history during learning. The goal is to maximize the collected utilities over time while taking into account the dynamics created by the delayed impacts of historical actions. They propose an algorithm that achieves a regret of $O(KT^2/3)$ and show a matching regret lower bound of $KT^3/3$."
SP:9c1d678dff5f609197dc3cfb67b841827f4a439a,"This paper proposes an end-to-end solution for video instance segmentation (VIS) based on transformers. Specifically, the authors propose to utilize concise memory tokens as a means of conveying information as well as summarizing each frame scene. The features of each frame are enriched and correlated with other frames through exchange of information between the precisely encoded memory tokens. The authors validate their method on the latest benchmark sets and achieved state-of-the-art performance (AP 42.6 on YouTube-VIS 2019 val set using the offline inference) while having a considerably fast runtime (89.4 FPS)."
SP:6c922eaa358f6fb9771690b1240e4f6f08a35b69,This paper proposes a method for graph embedding based on residual2vec (R2vec) that can debias various structural biases in graphs by using random graphs. R2vec is a general method that can be applied to embeddings of graphs. The main contribution of this paper is to study the impact of random walks’ bias on graph representation learning and propose a method to debias the bias by sampling from a random graph. The experimental results show that the proposed method can improve link prediction and clustering performance and can explicitly model salient structural properties in graphs. 
SP:851eac96135b577a5014166edcb43db6a190cf4b,"This paper studies the problem of estimating the power sum functional of a function of a discrete distribution under local differential privacy. In particular, the paper considers the case where the initial data x1,..., xn are supposed i.i.d. and distributed according to an unknown discrete distribution p = (p1,..., pK). Only α-locally differentially private (LDP) samples are publicly available, where the term ‘local’ means that each zi is produced using one individual attribute xi. The paper considers privacy mechanisms that are sequentially interactive (i.e. they are allowed to use already published confidential data) or non-interactive. The authors describe the behavior of the quadratic risk for estimating the function of the discrete power sum of the power of K, n, and α as well as a two-step procedure which attains the parametric rate (nα2-1/2) for all $k \epsilon$ when $k=1$. The paper also provides lower bounds on the lower bound of the lower bounds for all estimators using the private samples."
SP:a0408b54f88a26479f33f36bb27e0a675f637ccd,"This paper studies the problem of online multiclass classification in the setting where the learner’s feedback is determined by an arbitrary directed graph. The paper proposes a new algorithm called GAPPLETRON that works with arbitrary feedback graphs. The authors prove surrogate regret bounds that hold, both in expectation and with high probability, for a large class of surrogate losses. They also prove a general lower bound of order max {BK,\sqrt{T}}. Experiments on synthetic data show that for various feedback graphs our algorithm is competitive against known baselines."
SP:490262589efce6fb10b913431ec6db8d4e5b2dec,"This paper studies the problem of explainable clustering in the context of decision trees. In particular, the authors consider the case of a decision tree where each node splits data points with a threshold cut in a single dimension (feature), and each of the k leaves corresponds to a cluster. The authors propose an algorithm that outputs an explainable cluster that is at most a factor of O(log k) compared to an optimal (not necessarily explainable) clustering for the k-medians objective. The algorithm is remarkably simple and runs in time O(dk log k), independent of the number of data points n. "
SP:6a9e47be710ddaf386bffc54d003d7dc2b67fdc3,"This paper proposes a multilingual pre-trained language model (PrLM) that supports both explicit universal dependency parsing and implicit language modeling. Syntax in terms of universal dependency parse serves as not only pre-training objective but also learned representation in the model, which brings unprecedented PrLM interpretability and convenience in downstream task use. The model outperforms two popular multilingual PrLM, multilingual-BERT and XLM-R, on cross-lingual natural language understanding (NLU) benchmarks and linguistic structure parsing datasets."
SP:94f4b65214a648cbc84f13beba45a825e2e9901a,"This paper proposes a dual-aspect collaborative transformer architecture for vehicle routing problems. The authors propose to learn embeddings for the node and positional features separately, instead of fusing them together as done in existing ones, so as to avoid potential noises and incompatible correlations. The positional features are embedded through a novel cyclic positional encoding (CPE) method to capture the circularity and symmetry of VRP solutions (i.e., cyclic sequences). The authors train DACT using Proximal Policy Optimization and design a curriculum learning strategy for better sample efficiency. They apply DACT to solve the traveling salesman problem (TSP) and capacitated vehicle routing problem (CVRP). Results show that DACT outperforms existing Transformer based improvement models, and exhibits much better generalization performance across different problem sizes on synthetic and benchmark instances."
SP:e5c8680d8da9e7548fcb9bb5c073848eb80e1dd0,"This paper presents a method for computing the exact Bayes error of generative models learned using normalizing flows. The method is based on the invertible transformation theorem, which states that the Bayesian error is invariant under the normalizing flow. The authors then show that they can compute the exact error of the learned flow models by computing it for Gaussian base distributions, which can be done efficiently using Holmes-Diaconis-Ross integration. Moreover, the authors show that by varying the temperature of the model, they can generate synthetic datasets that closely resemble standard benchmark datasets, but with almost any desired Bayes errors. Finally, they use their method to evaluate the intrinsic ""hardness"" of benchmark datasets."
SP:2896679f0472522bc3334178cd7574494cf12b7b,"This paper proposes a new method for initialization of neural networks. The method is based on a simple heuristic: the norm of each network layer is adjusted so that a single step of SGD or Adam with prescribed hyperparameters results in the smallest possible loss value. This adjustment is done by introducing a scalar multiplier variable in front of each parameter block, and then optimizing these variables using a simple numerical scheme. Gradinit accelerates the convergence and test performance of many convolutional architectures, both with or without skip connections, and even without normalization layers. It also improves the stability of the original Transformer architecture for machine translation."
SP:f69731403592fa5bdd4ca327708582d615aa131c,This paper proposes a method for estimating disease progression using longitudinal data. The authors propose to learn the metric from the data by learning the metric as the push-forward of the Euclidean metric by a diffeomorphism. The metric update is estimated iteratively as the composition of radial basis functions belonging to a reproducible kernel Hilbert space. The proposed method is evaluated on the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset and compared with 56 other methods in the TADPOLE challenge.
SP:438e906f52c4c0538956b51a2270b3ac498b27a8,"This paper proposes a routing-by-memory mechanism for existing CNN architectures. In each stage of the network, they introduce parallel Procedural Units (PUs) which consists of a memory head and a procedure. For an intermediate feature, they search its closest memory and forward it to the corresponding procedure in both training and testing. In this way, different procedures are tailored to different features and therefore tackle them better."
SP:d240173080cd3647dbaa5173a6422396f226775b,"This paper studies the equivariance of polynomials in physics. The authors show that it is possible to parameterize polynomial functions that are equivariant under symmetries of the Euclidean, Lorentz, and Poincaré groups. This is achieved by using scalar products and scalar contractions of the scalar, vector, and tensor inputs. The scalar-based method is simple, efficient, and scalable. The paper also provides numerical examples that show that scalar based methods are simple and efficient."
SP:72c0f47566904deb27d8157da30807ec1d6b5685,This paper proposes a new family of loss functions for bounding box regression. The main idea is to generalize existing IoU-based losses to a family of power IoU losses that have a power-IoU term and an additional power regularization term with a single power parameter α. The authors analyze properties such as order preservingness and loss/gradient reweighting. Experiments on multiple object detection benchmarks and models demonstrate that the proposed loss can surpass existing IoI-based loss functions by a noticeable performance margin.
SP:397125177d7007316d67194ec00d5dc57b44ac79,"This paper studies the problem of imitation learning in a Markov decision process (MDP) setting where the reward function is not given, but demonstrations from experts are available. The authors propose Distributionally Robust Imitation Learning (DROIL) which aims to learn a policy that is distributionally robust against noisy demonstrations based on an adversarial construction to avoid optimistic generalizations of the demonstrated data. DROIL can be seen as a framework that maximizes a generalized concept of entropy. They develop a novel approach to transform the objective function into a convex optimization problem over a polynomial number of variables for a class of loss functions that are additive over state and action spaces. They show the significant benefits of DROIL on synthetic data and a highway driving environment."
SP:58f220bbbed8d3e0633b408fca3b6838c4ad323d,"This paper proposes a general post-processing algorithm for individual fairness (IF) based on graph Laplacian regularization. In particular, the authors cast the individual fairness problem as a graph smoothing problem, which is a graph-regularized version of individual fairness. Theoretical analysis is provided to show the connection of the new objective function to a local relaxation of the original individual fairness objective. Empirically, the proposed algorithm is shown to correct individual biases in large-scale NLP models."
SP:ef791aa29decd839e7e583c9d1f71e8309ca87ef,"This paper proposes a new model for cross-domain Text-to-SQL task. The proposed model is based on Graph-Aware Dual Graph Aggregation Network (SADGA) and aims to generalize the question-schema linking method to the unseen database schemas. SADGA adopts the graph structure to provide a unified encoding model for both the natural language question and database schema, and further devise a structure-aware aggregation method to learn the mapping between question-graph and schema-graph. Experiments on the Spider benchmark show that the proposed model achieves 3rd place on the challenging task."
SP:a2fa25a4539a38af61a0993f65ecc14339f26c2e,"This paper studies the problem of learning end-to-end learnable discrete-continuous models with multiple discrete components. The authors analyze the behavior of more complex stochastic computations graphs with multiple sequential discrete components and show that it is challenging to optimize the parameters of these models, mainly due to small gradients and local minima. They then propose two new strategies to overcome these challenges. First, they show that increasing the scale parameter of the Gumbel noise perturbations during training improves the learning behavior. Second, they propose dropout residual connections specifically tailored to stochastically, discrete, continuous computation graphs."
SP:bb3ec363e90269db4a2ba99d8107cb56f86e68f0,"This paper studies the problem of Bayesian neural networks (BNNs) with high-fidelity approximate inference via full-batch Hamiltonian Monte Carlo (HMC) in the context of covariate shift. The authors show that BNNs with HMC with Bayesian model average can be problematic in cases where linear dependencies in the input features cause a lack of posterior contraction. They also show why the same issue does not affect many approximate inference procedures, or classical maximum a-posteriori (MAP) training. Finally, the authors propose novel priors that improve the robustness of BNN to many sources of covariances shift."
SP:f86ec7042e9b73ae071704a6d3ed17d7e3da1b75,"This paper studies the problem of few-shot meta-learning in the out-of-distribution (OOD) setting. The authors point out that most existing few shot classification benchmarks do not reflect OOD evaluation, as they use disjoint sets of train (base) and test (novel) classes for task generation. This discrepancy is problematic because meta-learners that perform better on existing OOD datasets may perform significantly worse in the ID setting. In addition, in the OOD setting, even though current FSL benchmarks seem befitting, the study highlights concerns in 1) reliably performing model selection and 2) consistently comparing the performance of different methods. To address these concerns, the authors provide suggestions on how to construct benchmarks to allow for ID evaluation as well as more reliable OOD evaluations."
SP:371f77148b4f00a929f7c118b1bb7c5a6238d264,"This paper studies the problem of rule induction in the context of language model-based rule generation. In particular, the authors argue that the current methods are “learning rules from rules”, which limits these methods to only produce “canned” rules whose patterns are constrained by the annotated rules, while discarding the rich expressive power of LMs for free text. The authors propose the open rule induction problem, which aims to induce open rules utilizing the knowledge in LMs. Besides, they propose the Orion (open rule induction) system to automatically mine open rules from LMs without supervision of annotated rule. They conducted extensive experiments to verify the quality and quantity of inducted open rules."
SP:8be2e0ea4a83fe32a4859f456007a829e5e9270a,This paper proposes Implicit Constraint Q-learning (ICQ) for offline multi-agent reinforcement learning. The main idea of ICQ is to decompose the joint-policy under the implicit constraint. The authors show that the extrapolation error is controlled within a reasonable range and insensitive to the number of agents. The experimental results demonstrate that ICQ achieves the state-of-the-art performance in StarCraft II.
SP:1939b24b68970c33ca16ce238deed257f76d009e,"This paper proposes a method for adversarial training of deep neural networks with non-uniform perturbations to improve the robustness of the model against adversarial attacks. The method is based on the observation that the features of a deep neural network often have semantically meaningful dependencies. The authors propose to train a neural network with non uniform norm-bounded adversarial perturbation, and then certify the model's robustness to adversarial attack. The proposed method is evaluated on malware classification, credit risk prediction, and spam detection datasets."
SP:417b30930b245667d777e5d90ee80dd41546760e,"This paper proposes an iterated Tikhonov regularization scheme for generalized self-concordant loss functions (GSC), which is an extension of the work of Marteau-Ferey et al. (2018) on spectral filtering. The main contribution of this paper is to extend the theoretical analysis of spectral filtering to the case of generalized self concordant losses. The authors show that the iterated regularization is equivalent to the proximal point method in optimization, and that it can be used to improve the convergence rate of the excess risk for GSC. "
SP:1caeee4f00b52fe356ff4e5dd004d0203e838370,"This paper proposes a new neural network layer called Deformable butterfly (DeBut) that generalizes the conventional butterfly matrices and can be adapted to various input-output dimensions. The proposed layer is a drop-in replacement of standard fully connected and convolutional layers and demonstrates its superiority in homogenizing a neural network and rendering it favorable properties such as light weight and low inference complexity, without compromising accuracy. The paper also opens up new rooms for analytical and practical research."
SP:d345ce1d7afc367ee1a9fb68d50ff1b2219f02cb,"This paper proposes MetA Reusable Knowledge (MARK) to address the problem of catastrophic forgetting in deep neural networks. The authors propose to use a common knowledge base (KB) for each task, which consists of a set of shared weights among tasks. The idea is that the KB can be used to selectively choose the relevant weights to solve each task. The paper also proposes a metalearning approach to incrementally enrich the KB with new knowledge and to foster weight reusability among tasks to avoid forgetting of old information."
SP:722c52467e384058f8fdffa254d0e8db47440a64,"This paper proposes a data-driven framework for scheduling heuristics in exact MIP solvers for mixed integer programming (MIP). In particular, the authors propose a method for learning a schedule of primal heuristic policies for a specific MIP problem. The proposed method is based on the idea of learning from data describing the performance of different primal heuristic policies. The authors also propose an efficient algorithm for computing such a schedule. Experiments show that the proposed method can reduce the average primal integral by up to 49% on two classes of challenging instances."
SP:5a21f0a49731dcb1d68deb06a75138e8e9d514d5,"This paper studies the problem of binary feedback in reinforcement learning, where the learner receives binary feedback only once at the end of an episode. The authors study the case where trajectory labels are generated by an unknown parametric model, and provide a statistically and computationally efficient algorithm that achieves sublinear regret. This is an extreme test case for theory, but it is also arguably more representative of real-world applications than the traditional requirement in RL practice that the learners receive feedback at every time step."
SP:e66bd9582058ba0f6091bb1042ce2ecfdaae1515,"This paper proposes a novel edge representation learning framework based on Dual Hypergraph Transformation (DHT), which transforms the edges of a graph into the nodes of a hypergraph. This dual hypergraph construction allows the authors to apply message-passing techniques for node representations to edges. After obtaining edge representations from the hypergraphs, the authors then cluster or drop edges to obtain holistic graph-level edge representations. The proposed method is evaluated on graph reconstruction and graph generation tasks, and graph classification tasks for which the edges are important for discrimination."
SP:e398873e29b05176e1d52dc6f86a59a4f405e6fd,"This paper studies the sufficiency of different mutual information maximization (MI) objectives for representation learning in the context of reinforcement learning (RL). The authors consider the case of two popular MI objectives: (1) Mutual Information Maximization (MIM) and (2) mutual information minimization. The authors show that these two objectives are not sufficient for RL from a theoretical perspective. The paper also provides theoretical analysis of why these objectives do not yield sufficient representations for RL. Finally, the authors conduct experiments on a simulated game environment to verify the theoretical results."
SP:50181f740910195d3a50dd7d7f8cbb1c476d730b,"This paper proposes a novel method for steerable convolution for 3D object semantic analysis. The proposed method is based on a feature-steering module that takes advantage of the SE(3)-equivariance of the convolutional layers. The method is evaluated on 3 tasks: instance-level 6D pose estimation, category-level pose and size estimation, and category level 6D tracking. The results show that the proposed method outperforms existing methods on almost all the metrics evaluated by the three tasks."
SP:d746bfb200577c980d92727bb0b1a3c23e7bfdc5,"This paper proposes a dynamic token sparsification framework to prune redundant tokens progressively and dynamically based on the input. Specifically, a lightweight prediction module is added to different layers to estimate the importance score of each token given the current features. To optimize the prediction module in an end-to-end manner, an attention masking strategy is proposed to differentiably prune a token by blocking its interactions with other tokens. By hierarchically pruning 66% of the input tokens, the method greatly reduces 31% to 37% FLOPs and improves the throughput by over 40% while the drop of accuracy is within 0.5%."
SP:d0b6cde42b1cba5e6e3c7c5131426fd84adbd3d7,"This paper studies the problem of inference on the conditional mean E [Y |X] in the continuous case, where the features X are continuously distributed. In particular, the authors consider the case where the support size of the distribution of X is smaller than the square of the sample size. In this case, they show that the confidence intervals of the confidence interval of E can have vanishing width, even as sample size tends to infinity. On the other hand, if X takes only a small number of possible values, then inference on E is trivial to achieve. "
SP:123952325765c040c3078fc7dca2b6d370e55590,"This paper proposes Representation Neutralization for Fairness (RNF), a method for reducing discrimination of DNN models by only debiasing the classification head, even with biased representations as inputs. The proposed method is based on a bias-amplified model to generate proxy annotations for sensitive attributes. The paper is well-written and well-motivated. The experimental results on several benchmark datasets demonstrate the effectiveness of the proposed RNF framework."
SP:210eb2c811f966bb1ac53932cacabbad9bb608fe,"This paper proposes a new convolutional layer that takes advantage of Bessel functions, well known in physics, to build Bessel-CNNs (B-CNN) that are invariant to all the continuous set of possible rotation angles by design. B-CNN is an extension of the Bessel convolution layer of the standard CNN, which is used to learn models that can be used in medical imaging applications. The paper is well-written and well-motivated. The experimental results are convincing."
SP:ee51ecbd476d5b65903c942a62be89ff5d91698b,"This paper proposes a new method for kernel ridge regression, which combines partitioning with random projections and iterative optimization to reduce space and time complexity while maintaining the same statistical accuracy. In particular, constructing suitable partitions directly in the feature space rather than in the input space, the authors promote orthogonality between the local estimators, thus ensuring that key quantities such as local effective dimension and bias remain under control. The authors characterize the statistical-computational tradeoff of their model, and demonstrate the effectiveness of their method by numerical experiments on large-scale datasets."
SP:1f096d6fabd5b1fde43d06c552d46d87cd35cb4a,"This paper proposes a method for learning discrete communication tokens for reinforcement learning agents. The authors propose to learn discrete tokens from a learned, continuous space, instead of using one-hot vectors, which is the standard for discrete communication in RL. The proposed method is based on word embedding techniques from natural language processing (NLP). The authors show that the learned discrete tokens can be used for communication in a variety of scenarios, and that the proposed method can outperform the standard one hot communication method in terms of zero-shot understanding. "
SP:8630ccc627534f9033bced04e2137a897ffef701,"This paper proposes CoAtNets (pronounced “coat” nets), a family of hybrid models built from two key insights: (1) depthwise convolution and self-attention can be naturally unified via simple relative attention; (2) vertically stacking convolution layers and attention layers in a principled way is surprisingly effective in improving generalization, capacity and efficiency. Experiments show that the proposed model achieves state-of-the-art performance under different resource constraints across various datasets."
SP:d3ecbeeffa5ab365743ba8653c6739f24742ee31,"This paper presents a new second-order oracle bound for the expected risk of a weighted majority vote. The bound is based on a novel parametric form of the Chebyshev-Cantelli inequality, which is amenable to efficient minimization. The authors also derive a new concentration of measure inequality which combines PAC-Bayesian bounding with Bennett’s inequality. The empirical evaluation demonstrates that the new bounds can improve on the work of Masegosa et al. [2020]."
SP:5bac542a6532d43cf100e085398b4a4783719814,"This paper proposes a method for weakly supervised audio-visual video parsing. The authors propose to leverage cross-video and cross-modality supervisory signals to facilitate the learning of a parsing model. The proposed method exploits both the common and diverse event semantics across videos to identify audio or visual events. In addition, the authors explore event co-occurrence across audio, visual, and audio- visual streams to localize segments of target events while excluding irrelevant ones. Experiments show that the proposed method performs favorably against existing methods on the weakly-supervised video parsing task."
SP:8fd6a03c1794afa524328d45f4232eacf6f86693,"This paper proposes a personalized federated learning algorithm called QuPeD, which compresses the model of each client based on the knowledge distillation (KD) loss. The authors propose to learn quantized models through a relaxed optimization problem, where quantization values are also optimized over. For personalization, the authors propose an alternating proximal gradient update for solving the compressed personalization problem, and analyze its convergence properties. The experimental results show that the proposed algorithm outperforms FedAvg and local training of clients."
SP:fca8b4f1e765cf1724a37f0ae9a7dac1cb79c8b1,"This paper proposes a generative model for constrained clustering based on probabilistic relations. Specifically, the authors propose to use a variational variational inference framework to learn the underlying distribution of data conditioned on prior clustering preferences, expressed as pairwise constraints. The proposed method is evaluated on two real-world datasets and compared with several state-of-the-art methods. The results show that DC-GMM outperforms the state of the art in terms of clustering performance."
SP:84379c0c881b7390ecc22fb398edfaf66d1af1ff,"This paper proposes a sketching-based approximation method for the Neural Tangent Kernel (NTK) and its convolutional counterpart (CNTK). The authors propose a near input-sparsity time approximation algorithm for NTK, by sketching the polynomial expansions of arc-cosine kernels. They also prove a spectral approximation guarantee for the NTK matrix, by combining random features (based on leverage score sampling) of the arc- cosine kernels with the sketching algorithm. The authors evaluate their methods on various large-scale regression and classification tasks and show that a linear regressor trained on our CNTK features matches the accuracy of exact NTK."
SP:fa2668083ff3bb592c29a4c6822ae96ff54d0dbe,"This paper proposes a multi-person 3D motion trajectory prediction model that combines a local-range encoder for individual motion prediction and a global-range decoder for social interactions. The proposed model is based on the Transformer architecture. The model is evaluated on long-term motion prediction, and it is shown to outperform state-of-the-art methods. The paper is well-written and well-motivated."
SP:0a0e07af37c8fe8580639b1df62d27b6f63f8dee,"This paper proposes a method for training a generative model to predict the unobserved portions of the world and then synthesizing a program based on samples from this model in a way that is robust to its uncertainty. The method is evaluated on a set of long-horizon planning tasks in a 2D Minecraft-inspired environment, where the agent must complete a complex sequence of subtasks to achieve its goal, and achieves a similar performance as using handcrafted programs to guide the agent."
SP:5bb42b178b0d27da271bfa60e633fdac718638c4,This paper studies the problem of causal imitation learning in the presence of a mismatch between the demonstrator and imitator. The authors propose a graphical criterion that is necessary and sufficient for determining the feasibility of such imitation learning. They provide an efficient algorithm for determining imitability and corroborate their theory with simulations.
SP:85bd81f0c5b6ccbc421ebbaf6f5c72164bc70b7f,"This paper presents a slot-wise, object-based transition model that decomposes a scene into objects, aligns them (with respect to a slotwise object memory) to maintain a consistent order across time, and predicts how those objects evolve over successive frames. The model is trained end-to-end without supervision using transition losses at the level of the object-structured representation rather than pixels. Thanks to the introduction of a novel alignment module, the model deals properly with two issues that are not handled satisfactorily by other transition models: object persistence and object identity. The combination of an objectlevel loss and correct object alignment over time enables the model to outperform a state-of-the-art baseline, and allows it to deal well with object occlusion and re-appearance in partially observable environments."
SP:f32eddbb5c33a8422c075579ff08aa9833338d44,"This paper studies the problem of adaptive risk minimization (ERM) in the context of bandit-collected data. In particular, the authors propose a weighted importance sampling weighted ERM algorithm for using adaptively collected data to minimize the average of a loss function over a hypothesis class and provide first-of-their-kind generalization guarantees and fast convergence rates. Their results are based on a new maximal inequality that carefully leverages the importance sampling structure to obtain rates with the good dependence on the exploration rate in the data. For regression, they provide fast rates that leverage the strong convexity of squared-error loss. For policy learning, the regret guarantees close an open gap in the existing literature whenever exploration decays to zero."
SP:f549a0c231b71bae0acbed6e3afb41890ee89cd9,"This paper proposes a novel reweighting strategy for kernel-reweighted regression. The authors propose to reparametrize the sample weights using a doubly non-negative matrix, which can be used to solve the adversarially reweighted estimate problem. The proposed method is evaluated on MNIST, CIFAR-10, and ImageNet, and the authors show that the proposed method outperforms the baseline."
SP:fe12e13602925b9400fd596a987755beb10aa3d1,"This paper proposes a novel estimator for categorical gradient estimators based on importance sampling and Rao-Blackwellization. The main idea is to reparameterize categorical variables as sequences of binary variables and use Rao-blackwellization to reduce the variance of the gradient estimator. The proposed estimator outperforms the state-of-the-art REINFORCE estimator, which is based on a leave-one-out-baseline estimator (Kool et al., 2019)."
SP:e16fdf963ec2f9c0d79fa404e47e7862a5d6e922,This paper proposes a new predictor-based neural architecture search method called WeakNAS. The main idea is to progressively refine the search path towards the high-performance sub-space through a set of weaker predictors. The paper argues that the probability of sampling better architectures is increasing as the number of predictors increases. The proposed method is evaluated on NAS-Bench-101 and NAS-bench-201 and achieves better results than the state-of-the-art predictor-only NAS methods.
SP:8f74abb04037ba2e59dcf8320dc555b149f68ed8,"This paper proposes a novel method for learning a global coordinate system for exploration in deep reinforcement learning. The method is based on the idea of entropic Desired Dynamics for Intrinsic ConTrol (EDDICT), which is an extension of Entropic DQN (DQN) that uses a fixed additive latent dynamics. The authors show that the proposed method is tractable and interpretable in terms of interpretable latent codes, and that it can be used in combination with other methods for exploration. Experiments show that EDDICT outperforms the state-of-the-art in Montezuma’s Revenge on a variety of tasks."
SP:c731a78c3e7f98ccd0253b51a0d42bf8deeb71f9,This paper proposes a method to generate molecules with pharmacochemically acceptable properties for drug design. The authors propose a fragment-based generative RL with Explorative Experience replay for Drug design (FREED) method that constrains the generated molecules to a realistic and qualified chemical space and effectively explores the space to find drugs by coupling the fragment generation method and a novel error-prioritized experience replay (PER). The authors also show that their model performs well on both de novo and scaffold-based schemes and achieves state-of-the-art performance on two of three targets.
SP:b938bca513e7de1231212064caf8877a78d8b612,"This paper studies the problem of learning directed acyclic graphical models from observational data in general settings without specific distributional assumptions. The authors propose an information-theoretic algorithm that uses a local Markov boundary search procedure in order to recursively construct ancestral sets in the underlying graphical model. They show that for certain graph ensembles, a simple forward greedy search algorithm (i.e. without a backward pruning phase) suffices to learn the Markov boundaries of each node. This substantially improves the sample complexity, which is at most polynomial in the number of nodes. This is then applied to the entire graph under a novel identifiability condition that generalizes existing conditions from the literature."
SP:af08109d4c45dc9401efb0e63c22167e9da28adb,"This paper studies the problem of learning with differential privacy (DP) in the setting where each user holds m samples and the privacy protection is enforced at the level of each user’s data. The authors show that, as long as each user receives sufficiently many samples, we can learn any privately learnable class via an ("", )DP algorithm using only O(log(1/\sqrt{1}) users. The main contribution of this paper is a generalization of global stability [BLM20] that allows the use of public randomness. The global stability can be boosted to be arbitrarily close to one, at a polynomial expense in the number of samples. "
SP:da4f21d107a7f442c4d3e3ec13bdb44b041e07cf,"This paper studies the effect of implicit representations of value functions on the convergence of SGD in the context of reinforcement learning. In particular, the authors consider the case of value iteration networks (VINs) and show that the implicit representation of the value function can lead to a faster convergence rate than the explicit representation. The authors also provide some theoretical analysis of the convergence rate for the linear case and the non-linear case. Finally, they provide empirical results in some simple domains that illustrate the theoretical findings."
SP:992aa07d4f815d1c81f967374590eece933833b1,"This paper proposes a method to refine Knowledge Graphs (KGs) by combining PSL-KGI and KG embeddings such as ComplEx and ConvE. The proposed method is based on the idea of co-training a KG-based model with a type-supervised embedding of the refined KG, which is called TypeE-X. The authors evaluate the proposed method on a variety of KG benchmarks and show that it can improve the quality of the KG and the new facts."
SP:676fc4a3041af22e8f20ccba7daa2a0b1f5d6af5,"This paper proposes a novel evaluation paradigm for knowledge base completion (KBC) methods. The authors argue that consideration of binary predictions is essential to reflect the actual KBC quality, and propose a new evaluation paradigm, designed to provide more transparent model selection criteria for a realistic scenario. They construct the data set FB14k-QAQ with an alternative evaluation data structure: instead of single facts, they use KB queries, i.e., facts where one entity is replaced with a variable, and construct corresponding sets of entities that are correct answers. This way, they can explicitly measure a model’s ability to handle queries that have more correct answers in the real world than in the KB, including the special case of queries without any valid answer. They evaluate a number of state-of-the-art KB embeddings models on the new benchmark. The differences in relative performance between ranking-based and classification-based evaluation that they observe in their experiments confirm their hypothesis that good performance on the ranking task does not necessarily translate to good performance in the actual completion task."
SP:83fe0a496a79bcf97ccba1c6d34b7d11e7d5c330,"This paper proposes a new model for dialog system models that uses a pre-trained language model to model each speaker separately and takes advantage of the large pretrained language model. The proposed model, Alternating Roles Dialog Model (ARDM), is trained on two task-oriented dialog datasets: CamRest676 and MultiWOZ. ARDM outperforms or is on par with state-of-the-art methods on both tasks. It can generalize to more challenging, non-collaborative tasks such as persuasion."
SP:b11c06b7c4ef1aa43c59f808a679425e302d158e,"This paper studies the problem of estimating the probability that the classification predicted by a deep neural network is correct (or in the Top 5) on the test set. It is well-known that the softmax values of the network are not estimates of the probabilities of class labels. However, there is a misconception that these values are not informative. The authors define the notion of implied loss and prove that if an uncertainty measure is an implied loss, then low uncertainty means high probability of correct (top k) classification on the tests set. The paper proposes a confidence measures for Top k which can be evaluated by binning values on the Test set."
SP:ab9666e15f2a0113d96cb4b47b1cbb30fa1f7982,"This paper studies the generalization properties of neural networks in the context of wide neural networks at large depths. The authors show that in the wide network limit, random networks before training are Gaussian processes governed by a kernel known as the Neural Network Gaussian Process (NNGP) kernel, and that at large depth the spectrum of the NNGP kernel simplifies considerably and becomes “weakly data-dependent”. In contrast, gradient descent training of wide networks is described by the Neural Tangent Kernel (NTK), which is related to the neural network Gaussian process kernel (NNGP) kernel. The spectrum of NTK is shown to be much the same way as that of NNGGP kernel in the large depth limit. By analyzing this spectrum, the authors arrive at a precise characterization of trainability and a necessary condition for generalization across a range of architectures including Fully Connected Networks (FCNs) and Convolutional Neural Networks (CNNs)."
SP:d3470c35aae48bf92439a55fdb98ccf07100e567,"This paper proposes a graph-based method to estimate the quality of protein models. The authors propose GRAPHQA, which is a graph based method that is able to model both sequential and 3D structure of proteins. The method is based on Graph-based representation learning, and the authors show that it can be used for both hand-engineered and representation-learning approaches. The experimental results show that the proposed method outperforms the state-of-the-art in terms of computational efficiency."
SP:5188280131b58a35d3deda126a0754aea8fa6e58,"This paper studies the critical locus of the loss function of a linear neural network, which is determined by the geometry of the functional space and by the parameterization of this space by the network’s weights. The functional space is either the set of all linear maps from input to output space, or a determinantal variety, i.e., a set of linear maps with bounded rank. The authors introduce a natural distinction between pure critical points and spurious critical points, which arise from the parameters of the network. The analysis clearly illustrates that the absence of “bad” local minima in the loss landscape of linear networks is due to two distinct phenomena that apply in different settings: it is true for arbitrary smooth convex losses in the case of architectures that can express linear maps (“filling architectures”) but it holds only for the quadratic loss when the functional spaces is a determinantsal variety. Without any assumption on the architecture, smooth conveX losses may lead to landscapes with many bad minima."
SP:ee71597ceab23eb4db1d6608f15f80ad51f7ff6d,"This paper proposes SEED (Sampling, Encoding, and Embedding Distributions) for inductive and unsupervised representation learning on graph structured objects. The proposed SEED framework samples a number of subgraphs whose reconstruction errors could be efficiently evaluated, encodes the subgraph samples into a collection of sub graph vectors, and uses the embedding of the sub graph vector distribution as the output vector representation for the input graph. Theoretical analysis is provided to demonstrate the close connection between SEED and graph isomorphism. Empirical results on several benchmark datasets demonstrate the effectiveness of SEED."
SP:d9406fdf0a180a5efc6f15ba8739524665f0f9d2,This paper proposes a new counterfactual regret minimization algorithm for zero-sum extensive games. The main idea is to use a lazy update strategy to avoid traversing the whole game tree in each round. The authors prove that the regret of Lazy-CFR is almost the same as that of the vanilla CFR and only needs to visit a small portion of the game tree. Empirical results show that the proposed algorithm is fast in practice.
SP:023aa3dca1cf7992b22993a7088e8a74c92bb47e,"This paper proposes a novel method for Unsupervised Domain Adaptation (UDA) based on explicit feature distribution modeling. Specifically, the authors propose to model the deep features from each domain as Gaussian mixture distributions. The authors also propose two new domain discrepancy losses with probabilistic interpretations. The first one minimizes the distance between the corresponding Gaussian component means of the source and target data. The second one is the pseudo negative log likelihood of generating the target features from source feature distribution. To learn both discriminative and domain invariant features, DMPN is trained by minimizing the classification loss on the labeled source data and the domain discrepancy loss together. Extensive experiments are conducted over two UDA tasks. The proposed method achieves state-of-the-art performance on VisDA 2017 dataset."
SP:40be996e8bb86e887077b762b87c7c34a786ac98,"This paper proposes InfoCNF, a conditional continuous normalizing flow (CNF) model that partitions the latent space into a class-specific supervised code and an unsupervised code that is shared among all classes for efficient use of labeled information. The partitioning strategy (slightly) increases the number of function evaluations (NFEs) and the authors also employ gating networks to learn the error tolerances of its ordinary differential equation (ODE) solvers for better speed and performance. Experiments on CIFAR-10 show that the proposed method improves the test accuracy over the baseline while yielding comparable likelihood scores and reducing the NFEs. The authors also apply the same partitioning method to time-series data to improve extrapolation performance."
SP:97764e3393216106ff2ac3f550845acf4636119f,"This paper studies the approximation of the value function for infinite-horizon discounted Markov Reward Processes (MRP) with nonlinear functions trained with the Temporal-Difference (TD) learning algorithm. The authors consider the problem under a certain scaling of the approximating function, leading to a regime called lazy training. In this regime the parameters of the model vary only slightly during the learning process, a feature that has recently been observed in the training of neural networks, where the scaling arises naturally, implicit in the initialization of their parameters. Both in the under and over-parametrized frameworks, the authors prove exponential convergence to local and global minimizers of the above algorithm in the lazy training regime. They then give examples of such convergence results in the case of models that diverge if trained with non-lazy TD learning."
SP:c518e4030f12b0f59ad1d7c0fc0ebd313c68ef95,"This paper proposes a reinforcement learning method for hypothesis verification. The main idea is to train an agent to generate observations that can be used to predict whether the hypothesis is true or false. The agent is trained to take actions that generate observations which can help predict the hypothesis. The authors propose to train the agent on a set of triplets (pre-condition, action sequence, post-condition) and then fine-tune the agent to verify more general hypotheses."
SP:6fa2f842b1bc993ed8024a3ce13dbd91529c61be,"This paper proposes a simple experiment to study whether neural networks can perform several steps of approximate reasoning in a fixed dimensional latent space. The set of rewrites (i.e. transformations) that can be successfully performed on a statement represents essential semantic features of the statement. The paper proposes to compress this information by embedding the formula in a vector space, such that the vector associated with a statement can be used to predict whether it can be rewritten by other theorems. The experiments show that graph neural networks are able to make non-trivial predictions about the rewrite-success of statements, even when they propagate predicted latent representations for several steps."
SP:a77ab500a5e7d4ea8430871d1e603941e92974fd,"This paper proposes a method for learning depth estimation from images with very sparse ground truth. The method is inspired by natural agents, who interact with the environment via visual and haptic feedback. To learn from such extremely sparse supervision, the authors introduce an appropriate inductive bias by designing a specialized global-local network architecture. Experiments on several datasets show that the proposed model can learn monocular dense depth estimation when trained with a single pixel per image. The global parameters extracted by the network are predictive of the metric agent motion."
SP:2afba5e24478da4e9d493887c7cf00e288cc0deb,"This paper extends the idea of word pieces in natural language models to machine learning tasks on opaque ids. This is achieved by applying hash functions to map each id to multiple hash tokens in a much smaller space, similarly to a Bloom filter. The authors show that by applying a multi-layer Transformer to these Bloom filter digests, they are able to obtain models with high accuracy. They outperform models of a similar size without hashing and, to a large degree, model of a much larger size trained using sampled softmax with the same computational budget."
SP:745dd86d7f7bba79a02d27922003b764b620f83e,"This paper proposes a method for learning 3D parts for objects in unseen categories. The proposed method is based on a learning-based agglomerative clustering framework, which learns a grouping policy to progressively group small part proposals into bigger ones in a bottom-up fashion. The method is evaluated on the PartNet dataset and compared against four shape segmentation baselines."
SP:868fc6df740b04963442d5abcfe2f4845585cfc8,"This paper proposes a method for generating new samples from out-of-sample data. The method is based on an autoencoder that decomposes the variation within the dataset into activations of different neurons and generate transformed data by defining an editing transformation on those neurons. By performing the transformation in a latent trained space, the authors encode fairly complex and non-linear transformations to the data with much simpler distribution shifts to the neuron’s activations. The technique has the advantage of being generally applicable to a wide variety of data domains, modalities, and applications. The authors demonstrate it on image transformations and then move to two main applications in biology: removal of batch artifacts representing unwanted noise and modeling the effect of drug treatments to predict synergy between drugs."
SP:6dee6932e64fe47bb44dd42fc242fa9d89b8d89c,"This paper proposes a meta-learning method for image segmentation. The method is based on the idea of first-order meta learning of initializations for deep neural networks that must produce dense, structured predictions given an arbitrary amount of training data for a new task. The authors propose a novel neural network architecture for parameter efficiency and fast learning which they call EfficientLab, a formalization of the generalization error of meta learning algorithms, which they leverage to decrease error on unseen tasks, and a small benchmark dataset, FP-k, for the empirical study of how meta learning systems perform in both few-shot and many-shot settings. They show that their network, with an empirically estimated optimal update procedure yields state-of-the-art results on the FSS-1000 dataset, while only requiring one forward pass through a single model at evaluation time."
SP:ec6f390f6d45fb79c33ae5d9c8a24cadb96fbd60,"This paper proposes a novel method for semi-supervised few-shot learning. The method is based on Prototypical Networks (PN) and a random walk loss. The authors show that the proposed method is able to learn representations that are compact and well-separated. They also show that their model is resistant to distractors, unlabeled data that does not belong to any of the training classes, and hence reflects robustness to labelled/unlabelled class distribution mismatch."
SP:d12e687bd2ee9fa60554312e644bb0a6487974f1,"This paper proposes a new self-supervised training objective for multi-sensor representation learning in remote sensing. The proposed objective is based on contrastive sensor fusion, which exploits coterminous data from multiple sources to learn useful representations of every possible combination of those sources. This method uses information common across multiple sensors and bands by training a single model to produce a representation that remains similar when any subset of its input channels is used. The authors train an encoder to produce semantically meaningful representations from any combination of channels from the input sensors. The encoder is trained on a dataset of 47 million unlabeled image triplets, which is used to train the encoder."
SP:4d8e054f07006b4f896721b5c24da805727d2c22,"This paper studies the problem of neural network pruning. The authors compare the performance of weight rewinding (WRT) and learning rate rewiring (LRT) on a variety of tasks, including fine-tuning, network compression, and network-agnostic pruning, and show that WRT and LRT outperform the standard fine-tune-based pruning methods. In particular, LRT is shown to outperform WRT in terms of accuracy and compression ratio. In addition, the authors show that LRT can be used to train the weights of a network to their values from earlier in training and retrain them from there."
SP:3bb1c79f9482e09828eda45fbb2e654f37219365,"This paper studies the relationship between output margin and generalization in deep neural networks. The authors propose to analyze a new notion of margin, which they call the “all-layer margin” and show that it has a clear and direct relationship with generalization for deep models. In particular, the authors show that by analyzing the all layer margin, they obtain tighter generalization bounds for neural nets which depend on Jacobian and hidden layer norms and remove the exponential dependency on depth. In addition, they provide a theoretically inspired training algorithm for increasing the alllayer margin."
SP:3d44f27468087280e85dfb1fc7291db05179fe6d,This paper proposes a method for knowledge-grounded dialogue generation. The authors propose a disentangled response decoder to isolate the parameters that depend on knowledge-based dialogues from the entire generation model. The proposed method is evaluated on two benchmark datasets and compared with the state-of-the-art. 
SP:9b555f7fe743f5effdbdc8701ed519ce3159c4b0,"This paper proposes a mirror-generative neural machine translation model (MGNMT) that simultaneously integrates the source to target translation model, the target to source translation model and two language models. The main idea is that both translation models and language models share the same latent semantic space, therefore both translation directions can learn from non-parallel data more effectively. Experiments show that the proposed MGNMT consistently outperforms existing approaches in a variety of language pairs and scenarios."
SP:d7a530a0ec4112095a58cef4cda9646f8ca6449d,"This paper studies the role of the entropy term in Soft Actor Critic (SAC) in Deep Reinforcement Learning (DRL) algorithms. The authors show that SAC's entropy term is limited to the action spaces of the Mujoco benchmark, and propose a simple non-uniform sampling method for selecting transitions from the replay buffer during training. The proposed method is shown to outperform SAC and other SAC-based algorithms on the MuJoco benchmark."
SP:545e8da553fcb47d84eaa044d8a4947d3cd3230e,"This paper studies the problem of adversarial attacks on industrial copyright detection systems. The authors propose to use a neural network-based system to detect the copyright of a piece of music, and then attack this system using simple gradient methods. They demonstrate the effectiveness of the proposed method on YouTube's Content ID system, AudioTag copyright detector, and YouTube's Music ID system. "
SP:b511822850da3bf1079a36ed6f5ad4db80fbc424,This paper proposes to decompose the final activation map of deep metric learning (DML) into two parts: (1) the overall activation map and (2) the point-to-point activation intensity between two images. The proposed decomposition is based on the idea that the point to point activation intensity can be used to show the relationship between different regions of the image. The authors show that the proposed method can be directly deployed to a large range of metric learning applications and provides valuable information for understanding the model. The experiments show its effectiveness on two potential applications: cross-view pattern discovery and interactive retrieval.
SP:67bf71219fe6bedec5f5525200e734638e4a6ca2,"This paper studies the problem of continual learning in an online lifelong learning scenario. The authors propose a new algorithm called Adaptive Online Planning (AOP) that combines model-based planning with model-free learning. The main idea is to use a planner to estimate the performance of the planner and the uncertainty of the model-focussed components of the policy, and then use the planner to decide when to use more extensive planning only when necessary, leading to reduced computation times. Experiments show that AOP is able to deal with novel situations, adapting behaviors and policies effectively in the face of unpredictable changes in the world."
SP:11159cb878a436a5d4fc6edb4132f2cc3c1b3f72,"This paper proposes to replace the traditional softmax attention mechanism by two alternative sparsity-promoting transformations: sparsemax and Total-variation Sparse Attention (TVMAX). With sparsemax, we obtain sparse attention weights, selecting relevant features. With TVMAX, we propose to fusing of the related adjacent spatial locations. By selecting relevant groups of features, the TVMAX transformation improves interpretability."
SP:fb0c3ce3db6ad674ddc615bdc6203cdcbe42c804,"This paper proposes a model for predicting the evolution of dynamic graphs. The model is based on a graph neural network and a recurrent architecture. The authors propose a generative model which predicts the topology of the graph at the next time step and constructs a graph instance that corresponds to that topology. They evaluate the proposed model on several artificial datasets following common network evolving dynamics, as well as on real-world datasets."
SP:ff722957a1765c0568426ed88dd910a6b74054ef,"This paper proposes a method for imputing missing features and estimating the distribution of target assignments given incomplete data. The proposed method is based on a generator network that generates imputations that a discriminator network is tasked to distinguish. Then, a predictor network is trained using the imputed samples from the generator network to capture the classification uncertainties and make predictions accordingly. The experimental results show the effectiveness of the proposed method in generating imputations as well as providing estimates for the class uncertainties in a classification task when faced with missing values."
SP:c051b0fe779d9e4131016970b7ba469b596f3009,"This paper proposes an off-policy estimation method for long-horizon optimization problems. The main idea is to use RKHSs to estimate the importance ratio of the stationary distribution of a known behavior policy. The paper is well-written and well-motivated. However, there are a few issues that need to be addressed. "
SP:065c900843011a71b70ed35357a2f71fe83872a7,"This paper proposes a method to compute the conditional likelihood of a Gaussian mixture model (GMM) using a generative adversarial network (GAN) framework. The authors propose to use the latent space z instead of x in the GMM model, which allows them to compute p(z|k,\theta) instead of p(x|x, \theta). The authors also propose an end-to-end GAN model that is trained with the GAN framework. Experiments are conducted on a synthetic dataset and an unsupervised dataset. "
SP:2da1608209058d214f8671062cc9eb0833ba4831,"This paper proposes a method to train large capacity neural networks with significantly improved accuracy and lower dynamic computational cost. The method is based on gating the deep-learning architecture on a fine-grained-level. Individual convolutional maps are turned on/off conditionally on features in the network. To achieve this, the authors introduce a new residual block architecture and introduce a generally applicable tool batch-shaping that matches the marginal aggregate posteriors of features in a neural network to a pre-specified prior distribution. The authors show that their method can slim down large architectures conditionally, such that the average computational cost on the data is on par with a smaller architecture, but with higher accuracy."
SP:f90e9f0eb53f92601bdfa3f7bf86f71d037aad30," is a probabilistic importance inference approach for pruning DNNs. Specifically, the authors test the significance of the relevance of a connection in a DNN to the DNN’s outputs using a nonparemetric scoring test and keep only those significant ones. Experimental results show that the proposed approach achieves better lossless compression rates than existing techniques."
SP:64cbbb6a2f6847ef71cd5a23ba3e4cc5c815a56e,"This paper presents a method for learning hierarchical reinforcement learning by iteratively compressing action trajectories to learn nested behavioral hierarchies of arbitrary depth, with actions of arbitrary length. The learned temporally extended actions provide new action primitives that can participate in deeper hierarchies as the agent learns. The authors demonstrate the relevance of this approach for tasks with non-trivial hierarchical structure and show that the approach can be used to accelerate learning in recursively more complex tasks through transfer."
SP:e1ccfb3a684aef8a0fb36194eb16af1667811e81,"This paper proposes a probabilistic autoencoder model for generating complex image sets. The model is based on the Hierarchical Bayes Autoencoders (HBAE) framework, where the decoder is modeled as an energy-based model (EBM) instead of the commonly adopted unimodal Gaussian distribution. The proposed model is trained using variational inference, similar to a VAE, to recover latent codes conditioned on inputs. During inference time, the HBAE consists of two sampling steps: first a latent code for the input is sampled, and then this code is passed to the conditional generator to output a stochastic reconstruction. In both single image and set cases, the proposed model generates plausible variations consistent with the input data, and generates realistic unconditional samples."
SP:1130a391afa30d1e0fddadedd2a3aaa70a4cb751,"This paper proposes a new normalization technique for off-policy temporal difference (TD) methods. The idea is to use a mixture of on-policy transitions and cross-policy transition, which is an extension of batch normalization. The authors show that the proposed cross-normalization improves the performance of TD3 and DDPG on a range of MuJoCo tasks."
SP:f9cafaa5131176290fa069e6d24046c079cd9eea,"This paper proposes an adversarial training strategy to learn discriminative features that are unbiased and invariant to the confounder(s). The proposed method is based on the adversarial loss function that encourages a vanished correlation between the bias and learned features. The authors apply their method to synthetic data, medical images, and a gender classification (Gender Shades Pilot Parliaments Benchmark) dataset and show that the learned features by their method not only result in superior prediction performance but also are uncorrelated with the bias or confounders variables."
SP:783049ff463edd1283c058c6106a3e1f9a033df4,This paper proposes a lightweight Transformer-based model for character-level language modeling. The proposed method is based on the idea of grouped embedding operators. The authors propose to use inter-group linear operators to prevent performance degradation from the group strategy. The experimental results on enwik8 and text8 show that the proposed method can achieve better performance than existing Transformer models.
SP:946c26d371297c88d0ac246257104099b4585edc,"This paper proposes Optimal Transport, a method for training generative models with hierarchical-latent-variable structures based on Variational Autoencoders (VAEs). The main idea is to train a generative model with deep-latency hierarchies based on a variational autoencoder (VAE) that is trained using Optimal transport. Theoretical analysis is provided to show that optimal transport is a non-likelihood-based framework that allows for easier training convergence between distributions. Experiments are conducted on MNIST, CIFAR-10, and Fashion MNIST. "
SP:309b47441d227ffa33f96f9f16f2addc607e5bb0,"This paper presents an autoregressive video generation model that uses a three-dimensional self-attention mechanism to generate high-quality continuations of videos. The model is based on the three-dimensionality of the input video, which is modeled as a 3D image. The authors evaluate the model on a variety of video datasets, and show that the proposed model can achieve state-of-the-art results. The paper also presents results on Kinetics, a large-scale action recognition dataset."
SP:ad8fcdbc47a50dd2bf58aba2bc6cfe199e84dd4d,"This paper proposes a latent feature generation framework for generalized zero-shot ICD coding, where they aim to improve the prediction on codes that have no labeled data without compromising the performance on seen codes. The framework generates semantically meaningful features by exploiting ICD code hierarchical structure and a novel cycle architecture that reconstructs the relevant keywords. Extensive experiments demonstrate the effectiveness of the proposed method on the public MIMIC-III dataset."
SP:3ce82ae297e5759ab957babe9927062e7a71b0ba,"This paper proposes a self-supervised representation learning method to improve sample efficiency in reinforcement learning (RL). The authors propose a forward prediction objective for simultaneously learning embeddings of states and action sequences, which capture the structure of the environment’s dynamics, enabling efficient policy learning. The authors demonstrate that their action embedding alone improves the sample efficiency and peak performance of model-free RL on control from low-dimensional states. The proposed method achieves efficient learning of high-quality policies on goal-conditioned continuous control from pixel observations in only 1-2 million environment steps."
SP:11ce1616e721340eea9e80dad7460c77355ac7d1,This paper proposes an automated relational meta-learning (ARML) framework that automatically extracts the cross-task relations and constructs the meta-knowledge graph. ARML is motivated by the way of knowledge organization in knowledge bases and proposes a method to automatically extract the cross task relations and construct the meta knowledge graph. The proposed method is evaluated on 2D toy regression and few-shot image classification and shows the superiority of ARML over state-of-the-art baselines.
SP:37c209cd1c628b5c2f2b282fbeaf4bbf437c7670,"This paper proposes a method for controlling attributes of the generated language (e.g. switching topic or sentiment) without modifying the model architecture or fine-tuning on attribute-specific data and entailing the significant cost of retraining. The authors propose a simple alternative: the Plug and Play Language Model (PPLM) which combines a pretrained LM with one or more simple attribute classifiers that guide text generation without any further training of the LM. The PPLM is flexible in that any combination of differentiable attribute models may be used to steer text generation, which will allow for diverse and creative applications beyond the examples given in this paper."
SP:12d0980bfea2de880905a0b87b40856969bb1c58,"This paper proposes a novel unsupervised learning method for learning representations with unlabeled data. The proposed method is based on denoising autoencoders, where the noisy input data is generated by corrupting clean data in the gradient domain. The authors propose to learn representations with a Laplacian pyramid representation of the input data. Experiments on several visual benchmarks demonstrate that better representations can be learned with the proposed approach, compared to its counterpart with single-scale corruption."
SP:12afc1b259e51a31cbeb72366d2b93fbee1aafaa,This paper proposes a method for verifying the under-sensitivity of neural networks in the context of natural language inference. The main idea is to use interval bound propagation (IBP) to verify whether a particular sample is free from the under sensitivity problem. The authors propose to use the decomposable attention mechanism to train the model. The proposed method is evaluated on the SNLI and MNLI datasets and compared with standard training methods.
SP:14257af9fe83522c6e5b5d6b0d68945b944e30fb,"This paper proposes a method for off-policy deep reinforcement learning (RL) that uses a data graph to represent transitions in a Markov Decision Process (MDP) for which exact Q-values can be computed efficiently as more data comes in – resulting in a QGRAPH. The authors show that the Q-value for each transition in the simplified MDP is a lower bound of the lower bound for the same transition in a continuous Q-learning problem. By using these lower bounds in TD learning, the proposed method is less prone to soft divergence and exhibits increased sample efficiency while being more robust to hyperparameters."
SP:c92c97e47d8b218dfd009bbf61f5b3547b395f91,"This paper studies the problem of unsupervised domain adaptation, i.e., generalization from a source domain to an unlabeled target domain. In particular, the authors study the effect of the embedding complexity on the generalization to the target domain, and provide a theoretical analysis of this effect. The authors then propose a multilayer neural network architecture that mitigates the sensitivity of the complexity of the encoder and decoder to the domain-invariant embedding. Experiments are conducted on MNIST, CIFAR-10, and Fashion MNIST."
SP:f3f3c6fbae757836551b3f1ee54a7d1e040132b8,"This paper studies generalization error bounds for learning general non-convex objectives. The authors develop a new framework, termed Bayes-Stability, which combines PAC-Bayesian theory and the notion of algorithmic stability. They obtain new data-dependent generalization bounds for stochastic gradient Langevin dynamics (SGLD) and several other noisy gradient methods (e.g., momentum, mini-batch and acceleration, Entropy-SGD). Their result recovers (and is typically tighter than) a recent result in Mou et al. (2018) and improves upon the results in Pensia et al (2018). They also study the setting where the total loss is the sum of a bounded loss and an additional `2 regularization term."
SP:a82fcd1d3196ddf078cfe8f4bc6f445d9d2bdc11,"This paper investigates the role of the hippocampus in continual learning in the context of continual learning of two different spatial navigation strategies. The authors analyze population-level activity of 612 hippocampal CA1 neurons of rodents learning to perform allocentric and egocentric spatial tasks. The results show that the components uncovered using dPCA from the firing activity reveal that hippocampal neurons encode relevant task variables such as decisions, navigational strategies and reward location. They compare this hippocampal features with standard reinforcement learning algorithms, highlighting similarities and differences. They demonstrate that a standard deep reinforcement learning model achieves similar average performance when compared to animal learning, but fails to mimic animals during task switching."
SP:51acf1f8108683dce543a1fb4a61fbd593f9b4cc,"This paper proposes a tree search based policy optimization method for continuous environments. The proposed method is based on bootstrapping tree search with a pre-trained policy, which allows to achieve high quality results with a low MCTS branching factor and few simulations. In the experiments, the proposed method significantly improves the policy on nearly all the environments and achieves a 2.5x improvement over the baseline algorithm."
SP:1ce3bc4d31712886f7dcada5b5ae67c3c376819a,"This paper studies the lottery ticket hypothesis, which claims that neural networks contain sparse subnetworks, which, if appropriately initialized (the winning tickets), are capable of matching the accuracy of the full network when trained in isolation. The paper investigates the properties of winning tickets, especially the importance of supervision in the generating process, and aims to answer the following open questions: can we find winning tickets with few data samples or few labels? can we even obtain “good” tickets without supervision? The paper finds that winning tickets found in these scenarios are, perhaps surprisingly, competitive with winning tickets generated on the full ImageNet dataset when evaluated on ImageNet classification task."
SP:dbcebe5b73486885d9f4478b258047c02f8481a2,"This paper studies the problem of adversarial attacks on neural reading comprehension models. The authors propose a noisy adversarial attack that searches among semantic variations of comprehension questions for which a model still erroneously produces the same answer as the original question – and with an even higher probability. They show that, despite comprising unanswerable questions, SQuAD2.0 and NewsQA models are vulnerable to this attack and commit a substantial fraction of errors on adversarially generated questions. This indicates that current models—even where they can correctly predict the answer —rely on spurious surface patterns and are not necessarily aware of all information provided in a given comprehension question. The paper further proposes data augmentation and adversarial training as defense strategies: both are able to substantially decrease a model’s vulnerability to undersensitivity attacks on held out evaluation data. Finally, the paper demonstrates that adversarically robust models generalise better in a biased data setting with a train/evaluation distribution mismatch; they are less prone to overly rely on predictive cues only present in the training set."
SP:5da870060778de460c1abe91562d6f3e707efef4,"This paper proposes a model-based approach to ensuring the safety of reinforcement learning agents. The proposed method is based on the idea that the agent can look into the future and be aware of the future consequences of its actions. To this end, the authors learn the transition dynamics of the environment and generate a directed graph called the imaginative module. This graph encapsulates all possible trajectories that can be followed by the agent, allowing the agent to efficiently traverse through the imagined environment without ever taking any action in reality. Experiments on two gridworld environments and a self-driving car simulator demonstrate that the proposed approach to safety visits unsafe states significantly less frequently than a baseline."
SP:c2796f28fb067138303df8d424d646f4ada31558,"This paper proposes a novel architecture for learning finite differences in graph neural networks inspired by physics equations. Specifically, the authors propose a graph neural network architecture that leverages data-driven end-to-end learning to discover underlying dynamical relations between the spatial and temporal differences in given sequential observations. The authors demonstrate the superiority of PA-DGN in the approximation of directional derivatives and the prediction of graph signals on the synthetic data and the real-world climate observations from weather stations."
SP:db8ed4f4fc3967f5dd4d208d5d029730eb99e840,"This paper studies the problem of training structured neural networks with nonsmooth regularization (e.g. `1-norm) and constraints. The authors propose a proximal-type stochastic gradient descent (ProxSGD) algorithm to solve this problem. They show that under proper learning rates, with probability 1, every limit point of the sequence generated by the proposed Prox SGD algorithm is a stationary point. Theoretical analysis and numerical experiments are provided to support the theoretical analysis and demonstrate the flexibility of the proposed algorithm."
SP:2ca1f4da9faee79768764cda5d09d949cc942acc,"This paper proposes a novel framework for lossy image compression that is end-to-end differentiable. The proposed method is based on a non-deterministic compression codec that maps the input image to a distribution in continuous space from which a sample can be encoded with expected code length being the relative entropy to the encoding distribution, i.e. it is bitsback efficient. The method is trained using standard gradient-based optimizers. Experiments on CLIC 2018 and Kodak show that the proposed method outperforms the state-of-the-art on low bitrates."
SP:788fd2b6956dd69bf7752d39ea21883947128c8a,"This paper proposes a method for super-resolution (SR) generation from compressed JPG images. The authors propose a novel SR structure with two specifically designed components, as well as a cycle loss. First, they propose a functional sub-model to recover information for C-JPG images, instead of the perspective of noise elimination in traditional SR approaches. Second, they further integrate cycle loss into SR solver to build a hybrid loss function for better SR generation. Experiments show that their approach achieves outstanding performance among state-of-the-art methods."
SP:18dd92f2f55020be4f5a089b3b251327e47886f4,This paper presents a neural network architecture that is able to estimate a full surface of pass probabilities from single-location labels derived from high frequency spatio-temporal data of professional soccer matches. The network is trained with a low-level feature hierarchy that produces predictions at different sampling levels that are merged together to preserve both coarse and fine detail. The proposed deep learning architecture can be easily adapted to solve many other related problems in sports analytics such as pass-selection likelihood.
SP:1ae31baf383fc520687b255d9cac14c3b040e253,"This paper proposes an inductive matrix completion model without using side information. It trains a graph neural network (GNN) based on 1-hop subgraphs around (user, item) pairs generated from the rating matrix and maps them to their corresponding ratings. It achieves highly competitive performance with state-of-the-art transductive baselines. In addition, IGMC is inductive – it can generalize to users/items unseen during the training (given that their interactions exist), and can even transfer to new tasks."
SP:c5cb1b50e17a69e88d5ae28848e265215162da1e,"This paper considers the unconstrained minimization of a smooth objective function in R, where only function evaluations are possible. The authors propose and analyze stochastic zeroth-order method with heavy ball momentum. They show new complexity results for non-convex, convex and strongly convex functions. They test their method on a collection of learning to continuous control tasks on several MuJoCo Todorov et al. (2012) environments with varying difficulty."
SP:a216cfc29937eb398ea98cb1aea3481c9aed8240,"This paper proposes Action Semantics Network (ASN), a neural network architecture for multi-agent reinforcement learning (MAS) systems. The main idea of the proposed network is to use the action semantics between agents to represent the influence of different actions on other agents. The network is trained using deep reinforcement learning. The proposed network can be easily combined with existing DRL algorithms to boost their performance. The experimental results on StarCraft II micromanagement and Neural MMO show that the proposed ASN significantly improves the performance of state-of-the-art DRL approaches compared with several network architectures."
SP:efaf3a440dc17e05177832083ffbc23760ed7c97,"This paper proposes to exploit the underlying structures of the state-action value function, i.e., Q function, for both planning and deep RL. Specifically, the authors investigate the lowrank structure, which widely exists for big data matrices, and verify empirically the existence of low-rank Q functions in the context of control and deep reinforcement learning tasks. By leveraging Matrix Estimation (ME) techniques, this paper proposes a general framework that exploits the underlying low rank structure in Q functions. This leads to a more efficient planning procedure for classical control, and a simple scheme that can be applied to value-based RL techniques to consistently achieve better performance on “low-rank” tasks."
SP:430336893b247b7bd45687d78b0d0511a7369e87,"This paper proposes a new algorithm for off-policy reinforcement learning in the context of batch reinforcement learning. The main idea is to use imitation learning to select high-performing actions for their corresponding states, and then use them to train a policy network using imitation learning. This is an interesting idea, and the paper is well-written and well-motivated. The experimental results on the Mujoco benchmark show that the proposed algorithm can achieve state-of-the-art performance."
SP:94078964876667e8a5d9ae7728d779d5b91a576e,This paper proposes a novel architecture for deep extreme multi-label learning. The proposed DeepXML algorithm splits training of head and tail labels by learning word embeddings on head labels and transferring them through a novel residual connection to data impoverished tail labels. The authors also extend the state-of-the-art negative sub-sampling techniques to increase the amount of negative training data available by extending the Slice algorithm for pretrained embedding to learn the proposed deepXML architecture.
SP:b1b1252d82fa1bea18309e0b0b894e0f28f48bc9,"This paper proposes an end-to-end trainable variational hashing-based collaborative filtering approach that uses the novel concept of self-masking: the user hash code acts as a mask on the items (using the Boolean AND operation), such that it learns to encode which bits are important to the user, rather than the user’s preference towards the underlying item property that the bits represent. This allows a binary user-level importance weighting of each item without the need to store additional weights for each user. The authors evaluate their approach against state-of-the-art baselines on 4 datasets."
SP:80898d0f2b2c8dc3388fa9164e529eae36aa1b21,"This paper presents a method for quantitatively measuring the mode collapse of GANs. Specifically, the authors propose a set of statistical tools that are broadly applicable to quantitatively measure mode collapse. The authors analyze possible causes of mode collapse and propose two simple yet effective “black-box” methods to calibrate the GAN learned distribution, without accessing either model parameters or the original training data. Experiments are conducted on several state-of-the-art GAN models and show that the proposed method is effective in detecting mode collapse on several models."
SP:e5b5dda2f024cfda10526e744aa035e0165af58a,"This paper studies the problem of training over-parametrized neural networks that are beyond the NTK regime and are still governed by the Taylor expansion of the network. The authors propose to randomize the neural networks, which allows them to escape their NTK and couple with quadratic models. They show that the optimization landscape of randomized two-layer networks is nice and amenable to escaping-saddle algorithms. They also prove concrete generalization and expressivity results on these randomized networks which lead to sample complexity bounds (of learning certain simple functions) that match NTK."
SP:cef7ea513eb3e42be4edf40e4ee1701a969bcbea,"This paper presents a method for evaluating the effectiveness of different graph convolutional filters for semi-supervised node classification. The authors propose a novel assessment tool, Graph Filter Discriminant Score (GFD), which is based on the fact that there is no single filter as a “silver bullet” that performs the best on all possible graphs. Based on these findings, the authors propose Adaptive Filter Graph Neural Network (AFGNN), a simple but powerful model that can adaptively learn data-specific filters. AFGNN leverages graph filter assessment as an extra loss term and learns to combine a set of base filters. Experiments on both synthetic and real-world benchmark datasets have demonstrated that the proposed model has the flexibility in learning an appropriate filter."
SP:3c5ec9dbcf914c8901e4e35f3c2a7df4707422ab,"This paper studies the problem of distributionally robust optimization (DRO) for overparameterized neural networks. The authors propose a new DRO method for group DRO, where the objective is to minimize the worst-case training loss over a set of pre-defined groups. In particular, the authors argue that existing DRO methods can perfectly fit the training data, and any model with vanishing average training loss also already has vanishing worst case training loss. Instead, the poor worst case performance arises from poor generalization on some groups. To address this issue, the paper proposes two regularization methods: (1) a stronger-than-typical `2 penalty or early stopping penalty, and (2) a stochastic optimization algorithm, with convergence guarantees, to efficiently train group DRo models. Experiments are conducted on a natural language inference task and two image tasks, and the authors show that the proposed method can achieve 10-40% improvement in the worst group accuracy."
SP:eb1ee2e0f7d8466a04b58508ecb3da7b667eecdf,"This paper proposes a new local explanation method for black-box classifiers. The proposed method is based on the idea of distribution controllers and integrates it with a neural network to directly guide the distribution of relevance scores. Then, the classification loss is introduced to optimize the proposed predictor. The experimental results demonstrate that the proposed method also outperforms other methods in terms of faithfulness."
SP:32ea7cbc47cbdb1f703f4e07c31ce90abe083424,"This paper proposes a method to train a network that can be used for image reconstruction and classification problems that involve detection of multiple object instances, without any supervision regarding their whereabouts. The network learns to extract the most significant K patches, and feeds these patches to a task-specific network – e.g., auto-encoder or classifier – to solve a domain specific problem. The method is able to learn to detect recurring structures in the training dataset by learning to reconstruct images. It can also learn to localize structures when only knowledge on the occurrence of the object is provided, and it outperforms the state-of-the-art."
SP:da1c5f6351d531482e90b86c3cceb52850c520de,"This paper proposes a neural program synthesis algorithm, AutoAssemblet, which learns to generate a chunk of assembly code that can be executed to match a state change inside the CPU and RAM. The algorithm is learned via self-learning reinforcement learning, where policy networks and value networks are learned to reduce the breadth and depth of the Monte Carlo Tree Search. The paper also proposes an effective multi-entropy policy sampling technique to alleviate online update correlations. Experiments are conducted on a variety of programming tasks and show significant higher success rates compared to several competing baselines."
SP:0d4687fc36c02e27d1b95d532a3947589f92b1da,This paper studies the impact of model architecture on the speed of training in the context of gradient descent optimization. The authors use the ideas from prior work that shows gradient descent can be modeled as a first-order ODE and use ODE’s coefficient matrix H to characterize the convergence rate. They introduce a simple analysis technique that enumerates H in terms of all possible “paths” in the network. They show that changes in model architecture parameters reflect as changes in the number of paths and the properties of each path. They also show that this analysis technique is useful in reasoning about more complex model architecture modifications.
SP:3e3bc8f617df742a395e7d315ec3810a42071294,"This paper studies the bias of initialization on strongly overparametrized neural networks (NNs) under gradient descent. The authors prove that fully-connected wide ReLU-NNs trained with squared loss are essentially a sum of two parts: the first is the minimum complexity solution of an interpolating kernel method, while the second contributes to the test error only and depends heavily on the initialization. This decomposition has two consequences: (a) the second part becomes negligible in the regime of small initialization variance, which allows to transfer generalization bounds from minimum complexity interpolating kernels methods to NNs; (b) in the opposite regime, test error of wide NNs increases significantly with the initialization variance."
SP:b15ea009a36a0a76728dfc103d668d6781a8a99a,This paper proposes a new pseudo-LiDAR method for stereo 3D object detection. The main contribution of this paper is to improve the depth estimation of the pseudo-Lidar method. The authors propose a depthpropagation algorithm to diffuse the few exact measurements across the entire depth map. The proposed method is evaluated on the KITTI object detection benchmark and achieves state-of-the-art results.
SP:983d84502264633f3385d426c1d4601a0744ea9a,"This paper proposes a novel adversarial example detection method that can withstand norm-constrained white-box attacks. Inspired by one-versus-the-rest classification, in a K class classification problem, they train K base detectors where the i-th detector is trained to discriminate natural data of class i from adversarial examples perturbed from other classes. They further devise a generative approach to detect/classify adversarial samples by interpreting each base detector as an unnormalized density model of the classconditional data. They provide comprehensive evaluation of the proposed methods and demonstrate their competitive performances and compelling properties."
SP:461e9308d050bc3dc7b35233452668bb31f5d491,"This paper proposes a novel intrinsic reward for model-free reinforcement learning that encourages the agent to take actions that lead to significant changes in its learned state representation. The proposed intrinsic reward is based on the idea that the agent should explore states that it can control. The authors evaluate their method on multiple procedurally-generated tasks in MiniGrid, as well as on tasks with high-dimensional observations used in prior work. The experiments demonstrate that this approach is more sample efficient than existing exploration methods, particularly for procedurally generated MiniGrid environments. "
SP:c002c20b5e8696588e029c0f65e88860418826c4,"This paper studies the embedding-based retrieval model for large-scale query-document retrieval problems. The authors propose a set of paragraph-level pre-training tasks for Transformer-based embedding models. They show that the key ingredient of learning a strong embedding based Transformer model is the set of pre-trained tasks. Inverse Cloze Task (ICT), Body First Selection (BFS), Wiki Link Prediction (WLP), and the combination of all three. The results show that with these tasks, the Transformer models can outperform BM-25 as well as embedding model without Transformers."
SP:4e161e08a624f87633dfb49dfd46bd1665e15189,"This paper proposes to replace graph convolution and pooling layers in graph neural networks with a single parametric bipartite convolution operation, which is a parameterized transformation between different input and output graphs. The proposed method is general enough to subsume conventional graph convolutions and graph pooling as its special cases and supports multi-graph aggregation leading to a class of flexible and adaptable network architectures, termed BiGraphNet. Experiments are conducted on graph skip connections, graph autoencoders, and graph aggregation networks."
SP:9b9b6ee9014e5538442ba76d6059ed01f59ec8fb,"This paper proposes a novel method for few-shot classification for metric-based methods. The main idea is to use feature-wise transformation layers for augmenting the image features using affine transforms to simulate various feature distributions under different domains in the training stage. The authors further apply a learning-to-learn approach to search for the hyper-parameters of the feature-based transformation layers. The proposed method is evaluated on 5 datasets: mini-ImageNet, CUB, Cars, Places, and Plantae. The experimental results show that the proposed method can generalize to unseen domains."
SP:df46627cb984a56bba36d510bfc52e00751e9107,"This paper proposes a convolutional neural network architecture for fluid simulation. The authors propose to use spatial convolutions as the main differentiable operation that relates particles to their neighbors. This is a simple extension of N-D convolutions to the continuous domain. The proposed network architecture can simulate different materials, generalizes to arbitrary collision geometries, and can be used for inverse problems. In addition, the authors demonstrate that their continuous convolutions outperform prior formulations in terms of accuracy and speed."
SP:3e17f333cf07183969c02bb66afdd3ccbf25bb19,"This paper proposes BatchEnsemble, an ensemble method for training neural networks. The method is based on the Hadamard product of a shared weight matrix among all ensemble members and a rank-one matrix per member. It is parallelizable across devices, where one device trains one member, and parallelizable within a device, where multiple ensemble members are updated simultaneously for a given mini-batch. The proposed method is evaluated on CIFAR-10, Cifar-100, WMT14 EN-DE/EN-FR translation, and out-of-distribution tasks. The speedup at test time is 3x and memory reduction is 3X at an ensemble of size 4. The authors also apply Batchensemble to lifelong learning, where on Split-CifAR-100 it yields comparable performance to progressive neural networks while having a much lower computational and memory costs."
SP:a123a425ef3eb6188833d5a42e851bc3fa59df65,This paper proposes a neural network-based method for solving PDEs. The network is trained to minimize deviations of the learned function from the strong PDE solution and satisfy the boundary conditions. The resulting solution is an explicit smooth differentiable function with a known analytical form. The proposed algorithm is a unified formulation of both forward and inverse problems where the optimized loss function consists of few elements: fidelity terms of L2 and L∞ norms that unlike previous methods promote a strong solution.
SP:973d0ad0faadcf7298300f2758de9154205e7113,"This paper proposes a method to improve the performance of logic-based SAT solvers by reducing the size of Binarized Neural Networks (BNNs). The authors argue that the main bottleneck of existing methods is their ability to reason about large BNNs efficiently. The authors propose changes to the BNN architecture and the training procedure to get a simpler network without sacrificing accuracy on the primary task. The experimental results demonstrate that their approach scales to larger deep neural networks compared to existing work for existential and probabilistic queries, leading to significant speed ups on all tested datasets."
SP:ca985e758f195bd04fb9f24b290a83974d6d308b,"This paper studies the expressive power of graph neural networks falling within the message-passing framework (GNNmp). First, GNNmp are shown to be Turing universal under sufficient conditions on their depth, width, node attributes, and layer expressiveness. Second, it is discovered that GNNMP can lose a significant portion of their power when their depth and width is restricted. The proposed impossibility statements stem from a new technique that enables the repurposing of seminal results from distributed computing and leads to lower bounds for an array of decision, optimization, and estimation problems involving graphs."
SP:a98ae70a91850bbe624c307ba61d3daeb2494b82,"This paper proposes a localised generative flow (LGF) method for density estimation. The authors argue that flow-based density models based on continuous bijections are limited in their ability to learn target distributions with complicated topologies, and propose LGFs to address this problem. The proposed LGFs are composed of stacked continuous mixtures of bijection, which enables each bijection to learn a local region of the target rather than its entirety. Unlike normalising flows, LGFs do not permit exact computation of log likelihoods, but the authors propose a simple variational scheme that performs well in practice. The experiments show that LGFs yield improved performance across a variety of density estimation tasks."
SP:3adc341dece170f428195e4dccadfb5f5daddf2d,"This paper studies the problem of vision-and-language navigation (VLN) in unseen environments. The authors propose two methods to address the issue of performance drop in unseen VLN testing: environment re-splitting and feature replacement. The first method is based on the observation that the low-level visual appearance of ResNet features directly affects the agent model and contributes to the environment bias in results. Based on this observation, the authors explore several kinds of semantic representations which contain less low level visual information, hence the agent learned with these features could be better generalized to unseen testing environments. Experiments show that the explored semantic features significantly decrease the performance gap between seen and unseen on multiple datasets."
SP:298e0043e99f586d314fbd9d16fdc6ae885e1ebb,This paper proposes to use human feedback to accelerate and optimize the training of a deep reinforcement learning algorithm. The authors propose to use an electroencephalogram (EEG) cap to monitor the human EEG signals and use them as an auxiliary reward function to a DRL algorithm with the intent of accelerating its learning of the game. The EEG signals are used to decode the implicit human feedback (specifically error-related event potentials) for state-action pairs in an Atari-type environment. The paper also proposes two different frameworks to combine recent advances in DRL into the error-potential based feedback system in a sample-efficient manner.
SP:a8395f8b877e1eebaef9ff2e8b4e488d55a74ef4,"This paper proposes a method for laconic classification, where the goal is to minimize the amount of information (aka. entropy) required in individual test images to maintain correct classification. Given a classifier and a test image, the authors compute an approximate minimal-entropy positive image for which the classifier provides a correct classification, becoming incorrect upon any further reduction. The notion of entropy offers a unifying metric that allows to combine and compare the effects of various types of reductions (e.g., crop, colour reduction, resolution reduction) on classification performance, in turn generalizing similar methods explored in previous works. The authors propose two complementary frameworks for computing the minimal entropy positive images of both human and machine classifiers, in experiments over the ILSVRC test-set, they find that machine classifier are more sensitive entropy-wise to reduced resolution (versus cropping or reduced colour for machines, as well as reduced resolution for humans), supporting recent results suggesting a texture bias in the I LSVRC-trained models used. They also find, in the evaluated setting, that humans classify the minimal-ENTropy positive images with higher precision than machines classify those of humans."
SP:81cec8f907d8fa0653b5bc08af1f59bfefd49619,"This paper studies adversarial defense methods for convolutional neural networks. In particular, the authors focus on perturbation methods that are based on the instability assumption. The authors identify a family of defense techniques based on deterministic lossy compression algorithms and randomized perturbations to the input that all lead to similar gains in robustness. They provide a comprehensive analysis of when and why these defenses work and potential mechanisms that could explain their effectiveness (or ineffectiveness) in different settings."
SP:a136b98e0ed478144ce9dd26e2b6d611543124e8,"This paper proposes a neural 3D mapping network that takes as input 2.5D (color and depth) video streams captured by a moving camera, and lift them to stable 3D feature maps of the scene, by disentangling the scene content from the motion of the camera. The model also projects its feature maps to novel viewpoints, to predict and match against target views. The authors propose contrastive prediction losses to replace the standard color regression loss, and show that this leads to better performance on complex photorealistic data. The proposed model learns visual representations useful for (1) semi-supervised learning of 3D object detectors, and (2) unsupervised learn for 3D moving object detectors."
SP:6fd61604a2eeb8a2cbbda6c40807cebef6d40f2f,"This paper studies the problem of unsupervised domain translation (UDT) from a theoretical point of view. The authors propose to cast UDT into an Optimal Transport (OT) framework by making the implicit bias explicit, which allows them to provide theoretical guarantees for existing methods, and to solve UDT problems where previous methods fail. They also propose a simple approach to solve the UDT problem, and illustrate its properties in two distinct settings. "
SP:8bb3ce11ad773685f6e41d90db3e7a5481e5ba47,"This paper proposes a novel regularization method, RotationOut, for neural networks. The idea is to treat the input layer as an entire vector and introduce regularization by randomly rotating the vector. The proposed method can also be used in convolutional layers and recurrent layers with small modifications. Extensive experiments in vision and language tasks are conducted to show the effectiveness of the proposed method."
SP:37620ae8dc5683eb2843792e0aa4cbe6cba366f7,"This paper proposes a method to create adversarial perturbations (UAPs) for a given CNN in a data-free manner. The authors propose a dilate loss that maximizes the Euclidean norm of the output before nonlinearity at any layer. By doing so, the perturbation constrains the ReLU activation function at every layer to act roughly linear for data points and thus eliminate the dependency on data for crafting UAPs. Extensive experiments demonstrate that the proposed method not only has theoretical support, but achieves higher fooling rate than the existing data free work."
SP:2fd7d5507a8727db743dc89379a6f021d31ed39a,"This paper proposes a transferable neural architecture search method based on meta-learning. The main idea is to learn a meta-architecture that is able to adapt to a new task quickly through a few gradient steps, which makes the transferred architecture suitable for the specific task. Extensive experiments show that T-NAS achieves state-of-the-art performance in few-shot learning and comparable performance in supervised learning but with 50x less searching cost."
SP:1314a79ba12474adb33ff31b3cb22bed25b94fb7,"This paper proposes a simple and effective stochastic neural network architecture for discriminative learning by directly modeling activation uncertainty and encouraging high activation variability. Compared to existing SNNs, the proposed SE-SNN is simpler to implement and faster to train, and produces state-of-the-art results on network compression by pruning, adversarial defense and learning with label noise."
SP:bd4935d4fcf33f60f22e0f2fd9f7dc8ddfab6d17,"This paper proposes a meta-learning algorithm for meta-reinforcement learning in the context of curiosity. The motivation is that curiosity is a mechanism found by evolution that encourages meaningful exploration early in an agent’s life in order to expose it to experiences that enable it to obtain high rewards over the course of its lifetime. The paper proposes to meta-learn algorithms that combine neural networks with other building blocks such as buffers, nearest-neighbor modules and custom loss functions. Experiments are conducted on grid navigation with image inputs, acrobot, lunar lander, ant and hopper."
SP:6dff0f3a84809ae0ba9f58f36303597f1ba6dcc5,"This paper proposes a method for generating code given its surrounding code without any restriction on the vocabulary or structure. The proposed method is based on a neural model that models a code snippet as a tree and uses conditional probabilities to estimate the probability of the program’s abstract syntax tree (AST) by decomposing it into a product of conditional probabilities over its nodes. Unlike previous structural techniques that have severely restricted the kinds of expressions that can be generated in this task, this approach can generate arbitrary expressions in any programming language. The model significantly outperforms both seq2seq and a variety of existing structured approaches in generating Java and C# code."
SP:7fc60d6fd1cfcc135c34f9664d172d3fd1c0ae0a,"This paper studies the problem of learning large-scale neural networks (NN) in non-convex optimization. The authors prove that the objective functions in learning NNs are convex in the canonical model space. They further elucidate that the gradients between the original NN model space and the canonical space are related by a pointwise linear transformation, which is represented by the so-called disparity matrix. Furthermore, they prove that gradient descent methods surely converge to a global minimum of zero loss provided that the disparity matrices maintain full rank."
SP:78a536138570fe9b5d88350e4b16d598a7db1fe0,"This paper proposes an interactive graph-based segmentation algorithm that uses a discrete Potts model and a class-aware integer linear programming (ILP) formulation that ensures global optimum. The proposed algorithm can take RGB, or utilize the feature maps from any DCNN, whether trained on the target dataset or not, as input. The authors present competitive semantic (and panoptic) segmentation results on the PASCAL VOC 2012 and Cityscapes dataset given initial scribbles. They also demonstrate that their interactive approach can reach 90.6% mIoU on VOC validation set with an overhead of just 3 correction scribbles, and can be used inside any weakly supervised learning framework on new datasets."
SP:2eb90879ddbc39b6b5c05152784d6044d1940513,"This paper proposes to use learned saliency models as a real-time adversarial defense against adversarial attacks. The proposed method is based on the idea that the salient features of an image can be used to detect adversarial perturbations. The authors propose a CNN that distinguishes between adversarial images and natural images using salient pixels as its input. The method is evaluated on MNIST, CIFAR-10, and ASSIRA, and can detect various adversarial attack types."
SP:fe5510d05ff091a5f133f2dbcd1b23d8d58d2c3e,"This paper studies the problem of adversarial robustness for machine learning models. Specifically, given a trained model, the authors consider the probability that its prediction at any point sampled from the (unknown) input distribution is susceptible to adversarial attacks. The authors prove that concentration inequalities can be employed to compute global robustness with estimation error upper-bounded by, for any > 0 selected a priori. They then provide statistically sound analysis of the robustness/accuracy trade-off for a variety of neural networks architectures and training methods on MNIST, Fashion-MNIST and CIFAR."
SP:8f5616a1480b68c04b496ed498d237d5a7e87794,"This paper studies the problem of robust reinforcement learning, where the goal is to find the optimal policy with some extent of robustness to environmental dynamics. The authors propose to use the Wasserstein distance to measure the disturbance to the reference transition kernel, and derive risk-aware optimal Bellman equation to reduce the infinite-dimensional optimization problem to a finite-dimensional risk aware problem. They also provide a sensitivity analysis for the perturbations, and design a novel robust learning algorithm called Wassersteins Robust Advantage Actor-Critic algorithm (WRAAC). The effectiveness of the proposed algorithm is verified in the Cart-Pole environment."
SP:d85963f5f0f6b20cf08f2a7c169ae33a45db7de2,"This paper proposes a method to approximate mixed strategy Nash equilibria in multi-player continuous games, which always exist and include the pure ones as a special case. The proposed method is based on the pushforward measure technique to represent a mixed strategy in continuous spaces. This allows the authors to generalize the Gradient-based Nikaido-Isoda (GNI) function to measure the distance between the players’ joint strategy profile and a Nash equilibrium. In numerical experiments, the proposed method consistently and significantly outperforms recent works on approximating Nash equilibrium for quadratic games, general blotto games, and GAMUT games."
SP:280d85cd8164a268f9d496ae5f17189c50f30dc1,"This paper proposes a neural execution tree (NExT) framework to augment training data for text classification using natural language explanations (NL explanations). The idea is to transform NL explanations into executable logical forms by semantic parsing, and then generalize different types of actions specified by the logical forms for labeling data instances. Experiments on two NLP tasks (relation extraction and sentiment analysis) demonstrate the superiority of NExT over baseline methods. The extension to multi-hop question answering achieves performance gain with light annotation effort."
SP:a9b5f7257dedd719cfe341fca275776734af1d98,"This paper proposes a method for verifying the robustness of recurrent neural networks (RNNs) trained with verified training. The method is based on the idea of verifying the consistency of the trained RNNs with a set of specifications. The authors extend the verification procedure from simple adversarial robustness to more complex specifications that capture temporal properties, such as requiring that a robot periodically visits a charging station or that a language model always produces sentences of bounded length. The main contribution of the paper is the extension of the verified training procedure to RNN architectures and specifications."
SP:3903680e07b676409e3cf6a1044b67291fe38630,"This paper proposes a regularization method for visual domain randomization, which aims to reduce the variance in the learned policies. The authors propose to regularize the state representations of the learned policy by minimizing the Lipschitz constant of the policy’s state representation with respect to the randomization parameters. The proposed regularization is motivated by the fact that the policy is only trained on one variation of the environment, and its learned state representations are regularized during training to minimize this constant. The experimental results show that the proposed method leads to more efficient and robust learning than standard domain randomisation while achieving equal generalization scores."
SP:c79046dc56b9ee9c926f87386046422ea134ae8d,"This paper studies the problem of imbalanced data pairs in deep metric learning (DML). The authors propose a simple and effective framework to sample pairs in a batch of data for updating the model. The key to this framework is to define a robust loss for all pairs over a mini-batch of data, which is formulated by distributionally robust optimization. The flexibility in constructing the uncertainty decision set of the dual variable allows the authors to recover state-of-the-art complicated losses and also to induce novel variants. Empirical studies on several benchmark data sets demonstrate that the proposed method outperforms the state of the art results."
SP:38420928e40ef80c0136ad607b9275f9ab1e0769,"This paper studies the problem of finding a local minimum in non-convex finite-sum minimization. The authors first prove that the trust region method with inexact gradient and Hessian estimation can achieve a convergence rate of order O(1/k) as long as those differential estimations are sufficiently accurate. Combining such result with a novel Hessian estimator, the authors propose a sample-efficient stochastic trust region (STR) algorithm which finds an approximate local minimum within $\sqrt{n/\sqrt{\frac{n}{\epsilon})$. The authors also develop Hessian-free STR algorithms which achieve the lowest runtime complexity. Experiments verify theoretical conclusions and the efficiency of the proposed algorithms."
SP:28a35b70b5e6915af28cacebc4ea50690c9534af,"This paper proposes a method for training deep neural networks without batch normalization or weight initialization. The proposed method is based on the idea of Farkas layers, which is a geometrically motivated method that ensures at least one neuron is active at a given layer. The method is evaluated on a variety of networks with ReLU activations, and it is shown that the proposed method outperforms the existing methods in terms of training capacity."
SP:1d325b148e3efe407241c1f1cbe8d17400499741,"This paper studies the problem of computing exact robustness certificates for deep classifiers with differentiable activation functions in two steps. First, they show that if the eigenvalues of the Hessian of the network (curvatures of the networks) are bounded, they can compute a robustness certificate in the l2 norm efficiently using convex optimization. Second, they derive a computationally efficient differentiable upper bound on the curvature of a deep network and use it as a regularization term during the training of a network to boost its certified accuracy against adversarial examples. The proposed method, called Curvature-based Robustness Certificate (CRC), is a combination of CROWN and CRT."
SP:33f6f5aa0d4655e5d75fe612e0eff05e579d45c5,"This paper proposes a method for compressed sensing recovery using untrained deep generative models. The method is based on the recently proposed Deep Image Prior (DIP), wherein the convolutional weights of the network are optimized to match the observed measurements. The authors show that this approach can be applied to solve any differentiable linear inverse problem, outperforming previous unlearned methods, and does not require pre-training over large datasets. They further introduce a novel learned regularization technique, which incorporates prior information on the network weights. This reduces reconstruction error, especially for noisy measurements."
SP:23c0f621e6041003b59bf0532130760694cf6a4a,"This paper proposes TAIC, a hierarchical reinforcement learning algorithm that learns temporal abstractions for long-term reinforcement learning problems. TAIC learns the temporal abstraction from past experience or expert demonstrations without task-specific knowledge. The authors propose to regularize the latent space by adding information-theoretic constraints to maximize the mutual information between the latent variables and the state changes. The learned abstraction allows the algorithm to learn new tasks on higher level more efficiently. The experimental results show that TAIC can improve the convergence rate and sample efficiency."
SP:4e54c9196ba1eb2b6a0b0eee41e4a6f3a9de72dd,"This paper proposes a novel layer-wise sampling strategy for graph convolutional networks (GCN). The proposed sampling strategy is based on the factors of the bi-directional diffusion between layers. The authors also apply the self-attention mechanism to learn suitable weights for the sampled nodes, which allows the model to incorporate both the first-order and higher-order proximities during a single layer propagation process without extra recursive propagation or skip connection. Extensive experiments on three large benchmark graphs demonstrate the effectiveness and efficiency of the proposed model."
SP:bb0af9c011ef982c34fcadb545f6b5771818e7fa,"This paper presents a state-space model for videos that explicitly reasons about objects and their positions, velocities, and interactions. The model is constructed by combining an image model and a dynamics model in compositional manner and improves on previous work by reusing the dynamics model for inference, accelerating and regularizing training. The authors also demonstrate the strength of the model as a simulator for sample efficient model-based control in a task with heavily interacting objects. The proposed model outperforms previous unsupervised models and approaches the performance of supervised baselines."
SP:e67b463bc0aec2345925d609fa521ea49df57fd9,This paper proposes a new autoencoding model based on variational autoencoders (VAE) and generative adversarial networks (GAN). The main idea of the paper is to replace the VAE loss with an implicit likelihood by an adversarially trained discriminator. The proposed model is evaluated on CIFAR-10 and TinyImagent datasets. The experimental results show that the proposed model achieves the state-of-the-art trade-off between generation and reconstruction quality.
SP:87056d0147ddcaf5d78f6888b05161fbdbb3346c,"This paper studies the problem of adversarial attacks on CNN classifiers. The authors show that adversarial examples can be used against the Bayes-Optimal classifier for certain class distributions, while for others the optimal classifier is robust to such attacks. They show that under certain conditions on the data distribution under which all points can be made arbitrarily close to the optimal decision boundary and show that this can happen even when the classes are easy to separate, when the ideal classifier has a smooth decision surface and when the data lies in low dimensions. They also introduce new datasets of realistic images of faces and digits where the Bayesian classifier can be calculated efficiently. The experimental results show that standard CNN training consistently finds a vulnerable classifier, while large-margin methods often find a robust classifier with the exact same training data."
SP:a7b3a35e6a79084bdfd1e4a963dfa081279cd8bb,"This paper studies the effect of pruning on the top-1 accuracy of a neural network. The authors study the impact of different pruning methods on different classes and images. They find that certain examples, which they term pruning identified exemplars (PIEs), and classes are systematically more impacted by the introduction of sparsity. Removing PIE images from the test-set greatly improves the performance for both sparse and non-sparse models."
SP:4b17edaa7ec6201891433320d85f9a415656b763,"This paper proposes a novel method for interactive fiction games, where the agent interacts with the world purely through natural language. The method is based on the idea that the knowledge graph can be used to reason about the game state and to constrain the natural language generation of natural language actions. The proposed method is evaluated on a variety of text-based games, and it is shown to outperform the state-of-the-art."
SP:b1784ecbb8f36eef9cae33d61ce60d80c2f9c38d,"This paper proposes a new method for maximum likelihood estimation (MLE) for language generation. The main idea is to use a data-dependent Gaussian prior (D2GPo) instead of the data-independent L2 regularization (L2-regularization) which is commonly used in smoothing the training of MLE. The proposed method is based on the Kullback-Leibler divergence term, which is derived by comparing the prior and the detailed training prediction. Experimental results show that the proposed method makes effective use of a more detailed prior in the data and has improved performance in typical language generation tasks."
SP:7c29cb5a32b14e1392408dc5daba4cd35848bea9,"This paper proposes to replace the widely used cross-entropy loss with focal loss to improve the calibration of deep neural networks. The authors argue that focal loss preserves the confidence of the model’s correct predictions, which is extremely desirable for downstream tasks. They provide a thorough analysis of the factors causing miscalibration, and use the insights to theoretically justify the empirically excellent performance of focal loss. They perform extensive experiments on a variety of computer vision (CIFAR-10/100) and NLP (SST, 20 Newsgroup) datasets, and show that their approach achieves state-of-the-art accuracy and calibration in almost all cases."
SP:cd6b8417ec8bcb773c78cff677bb0a76d6b3f6f3,"This paper proposes LiPopt, a polynomial optimization framework for computing increasingly tighter upper bounds on the Lipschitz constant of neural networks. The underlying optimization problems boil down to either linear (LP) or semidefinite (SDP) programming. The authors show how to use the sparse connectivity of a network, to significantly reduce the complexity of computation. This is specially useful for convolutional as well as pruned neural networks, and the experiments on networks with random weights and networks trained on MNIST show that the proposed approach yields superior estimates compared to baselines available in the literature."
SP:31c9dc0dd8806daddc9cb48c56ec819577fe46cd,"This paper proposes a self-supervised learning approach for video features that results in significantly improved performance on downstream tasks (such as video classification, captioning and segmentation). The method extends the BERT model for text sequences to the case of sequences of real-valued feature vectors, by replacing the softmax loss with noise contrastive estimation (NCE). The authors also show how to learn representations from sequences of visual features and sequences of words derived from ASR (automatic speech recognition), and show that such cross-modal training helps even more."
SP:0f24424d10f1201dd25e8c56354e10afc9b2b11c,"This paper proposes a method to reduce the amount of data that needs to be transferred between servers and clients during the inference phase of a neural network. The authors propose a simple yet effective framework that allows to select certain parts of the input data needed for the subsequent application of a given neural network and train both the selection masks and the neural network simultaneously such that a good model performance is achieved while, at the same time, only a minimal amount of the data is selected. The experiments indicate that it is often possible to significantly reduce the number of data needed to transfer without affecting the model performance much."
SP:aa4fcf5b2cae05c5c6a903c24e4992b56655dee2,"This paper proposes a method for detecting out-of-distribution (OOD) samples from novel class distributions. The method is based on the Outlier Exposure (OE) technique, and the authors propose a novel loss function for OOD detection. The authors also propose a Mahalanobis distance-based classifier for the detection of OOD samples. The proposed method is evaluated on image classification and text classification tasks."
SP:89bc528ef801182365ac279e8963803afccb391d," for RNA secondary structure prediction. This paper proposes an end-to-end deep learning model, called E2Efold, which can effectively take into account the inherent constraints in the problem. The key idea is to directly predict the RNA base-pairing matrix, and use an unrolled algorithm for constrained programming as the template for deep architectures to enforce constraints. The experiments on benchmark datasets demonstrate the superior performance of E2efold."
SP:b68560cce8c64ebe0ca5e6534b3732c775d36452,"This paper proposes a method to train a collective policy that can be transferred to the real-world environment. The idea is to train an ensemble of agents, each of which has its own biased representation of the environment, and each agent takes turns to play a series of episodes in which they interact with their own biased representations. The goal is to learn a policy that maximizes the performance of the ensemble. The authors propose to train the collective policy sequentially, sequentially visiting the internal simulations of the other agents, and train the policy on top of the learned ensemble policy. Experiments show that the proposed method outperforms the best individually trained policies."
SP:bd1dc08b4fd9a5cc78d26d7eb7f05dbb4a629ab1,"This paper proposes a dialog generation model that learns a semantic latent space, on which representations of semantically related sentences are close to each other. This latent space is learned by maximizing correlation between the features extracted from prompt and responses. An additional autoencoder is trained, for recovering the full sentence from the latent space. Experimental results show that the proposed model eliminates the generic response problem, while achieving comparable or better coherence compared to baselines."
SP:ef0d5fd333ed60feb3946d24002e9a90642aea66,This paper proposes Gaussian light and shadow (GLAS) to explain the spatial impact of deep models by the feature perturbation inspired by light and shadows in nature. GLAS provides a useful coarseto-fine control benefiting from scalability of Gaussian mask. The authors also devised the ability to identify multiple instances through recursive GLAS. The experimental results show that GLAS has state-of-the-art performance at high speed (about 0.5 sec per 224×224 image) via the ImageNet large scale visual recognition challenge.
SP:d17ca20cc527c28ab7358cb5b14954e5fb56409f," of removing pixel-wise and channel-wise correlations before the data is fed into each layer of a neural network. The paper proposes a method called network deconvolution to remove pixel and channel correlations in the first layer of the network. It is shown that the proposed method can be efficiently calculated at a fraction of the computational cost of a convolution layer. Experiments are conducted on CIFAR-10, Cifar-100, MNIST, Fashion-MNIST, Cityscapes, and ImageNet datasets to demonstrate the effectiveness of the method."
SP:e1b0de9a36bf8359df368b7a55a7f23e99d88db7,"This paper proposes a novel quantization method for GANs based on EM algorithms, named as QGAN. The authors propose a multi-precision algorithm to help find an appropriate quantization precision of GAN models given image qualities requirements. Experiments on CIFAR-10 and CelebA show that QGAN can quantize weights in GAN to even 1-bit or 2-bit representations with results of quality comparable to original models."
SP:58c4905f59f04a50b30d27c99521126a6455d38a,"This paper studies the last-iterate convergence of Hamiltonian gradient descent (HGD) algorithm for convex-concave min-max optimization problems. The main contribution of this paper is to prove that HGD converges to a linear solution in a variety of general settings, including a novel “sufficiently bilinear” condition. The authors also prove convergence rates for stochastic HGD and for some parameter settings of the Consensus Optimization algorithm of Mescheder et al. (2017)."
SP:d8556b52272321a1415ac2d85bb12e88b51ee73a,"This paper studies the stability of learning ResNet block hl = φ(hl−1 + tau · g(hl-1) where hl is a ReLU activation and tau is a scalar. The authors show that for standard initialization of ResNet, the stability is guaranteed for tau = 1/\sqrt{L}(L) where L is the number of residual blocks. Moreover, if ResNet is properly over-parameterized, gradient descent is guaranteed to find the global minima 1, which significantly enlarges the range of $\tau$ that admits global convergence in previous work. Empirically, deep ResNet can be easily trained even without normalization layer."
SP:cf70dc496825ece2f28fdf4f1a6f4316c69e0e48,"This paper proposes a method to train sparse neural networks with a fixed parameter count and a fixed computational cost throughout training, without sacrificing accuracy relative to existing dense-to-sparse training methods. The method updates the topology of the network during training by using parameter magnitudes and infrequent gradient calculations. The authors show that this approach requires fewer floating-point operations (FLOPs) to achieve a given level of accuracy compared to prior techniques. They demonstrate state-of-the-art sparse training results on several datasets."
SP:d2d2b892518d54d0e63e26a056f2298be3be2610,"This paper proposes a method to find meaningful directions in the latent space of any generative model along which we can move to control specific properties of the generated image like the position or scale of the object in the image. The method does not require human annotations and is particularly well suited for the search of directions encoding simple transformations such as translation, zoom or color variations. The experimental results demonstrate the effectiveness of the proposed method qualitatively and quantitatively."
SP:1c63389e972d4652fac831e9d11609cd3c3c371a,"This paper proposes a physics-as-inverse-graphics model for unsupervised physical parameter estimation of systems from video, where the differential equations governing the scene dynamics are known, but labeled states or objects are not available. This framework allows the model to perform long term extrapolative video prediction, as well as vision-based model-predictive control for a pendulum system. The proposed model significantly outperforms related methods in long-term future frame prediction of systems with interacting objects (such as ball-spring or 3-body gravitational systems), due to its ability to build dynamics into the model as an inductive bias. The controller’s interpretability provides unique capabilities in goal-driven control and physical reasoning for zero-data adaptation."
SP:c6b8b682bf3087a65cb2379700b8a0183853c2af,"This paper proposes a method for learning a classifier from noisy labels when a few clean labeled examples are given. The proposed method is based on Graph Convolutional Networks (GCN) which is used to predict class relevance of noisy examples. For each class, the GCN is treated as a binary classifier learning to discriminate clean from noisy examples using a weighted binary cross-entropy loss function, and then the “clean” probability is exploited as a relevance measure. Experimental results show that the proposed method outperforms the transductive approach (Douze et al., 2018) that is using the same additional data without labels."
SP:dd9c9a5dccbba5dd15b03ca6b314a9e153e95548,"This paper proposes a new objective for graph neural networks (GNNs) that maximizes the Mutual Information (MI) between edge features and message passing channels. The MI is reformulated as a differentiable objective via a variational approach. The paper theoretically shows that the newly introduced objective enables the model to preserve edge information, and empirically corroborates the enhanced performance of MI-maximized models across a broad range of learning tasks including regression on molecular graphs and relation prediction in knowledge graphs."
SP:f1cf63d728da51b4f83eb50ef69e3788b3a5ed74,"This paper proposes a method to certify the properties of generative models. The method is based on the idea of probabilistic abstract interpretation, which is a combination of deterministic and probabilistically abstract interpretation. The authors show that the proposed method is able to verify interpolations in the network’s latent space. The paper is well-written and well-motivated. The experimental results are convincing."
SP:2b0887dcf09249e8cee30d38163aeb9ef1e92b27,"This paper proposes GRESNET (Graph Residual Network) to address the problem of suspended animation in existing graph neural networks (GNNs) based on the spectral graph convolutional operator (GCN). In this paper, the authors further identify the suspended animation problem with the existing GNNs and propose a new graph residual network (GRESNET) framework to resolve the problem. The authors also provide a theoretical analysis about the causes of the problem with existing models. Experiments on real-world benchmark datasets demonstrate the effectiveness of the proposed method."
SP:dc436ade4d04072de35a90e5e4a1bfebfddb04e9,"This paper proposes a semi-supervised method for face reconstruction from unlabeled and labeled images. The proposed method is based on an adversarial loss that aims to disentangle the identity, expression, pose, lighting, and lighting representations. The paper also proposes a novel center loss to make sure that different facial images from the same person have the same identity shape and albedo. Experiments show that the proposed method outperforms the state-of-the-art methods on various facial reconstruction tasks."
SP:f7bc06697b09e2d59ec06b2cbcf3c0828ece32ae,"This paper proposes a method for imitation learning in the presence of other experts. In particular, the authors propose to replace the unknown transition kernel with a synthetic kernel that simulates the transition of state components for which the transition kernel is known (SR) and extract from demonstrations the state components which the kernel is unknown (su). The next state is then stitched from the two components: s = {sr, su}. The authors describe in detail the recipe for building an eMDP and analyze the errors caused by its synthetic kernel. They show that combining a policy gradient algorithm with their model achieves superior performance compared to simulation-free alternative."
SP:82cce92821e8168ab4a6fd67573b66c1d17673b8,"This paper proposes a self-supervised reinforcement learning approach for learning to control states of interest without any external reward function. The authors formulate the intrinsic objective as rewarding the skills that maximize the mutual information between the context states and the state of interest. They evaluate their approach for different simulated robotic manipulation tasks from OpenAI Gym and a navigation task in the Gazebo simulator. They show that their method is able to learn to manipulate the object, such as pushing and picking up, purely based on the intrinsic mutual information rewards. Furthermore, the pre-trained policy and mutual information discriminator can be used to accelerate learning to achieve high task rewards."
SP:5db63d39cfd8132bec832ab64b8fbd403b3b8df0,This paper proposes a trojan attack method for neural network (NN) trojaning attacks. The attack is programmable that the malicious misclassification target is not fixed and can be generated on demand even after the victim’s deployment. The authors show that the attack is not limited in a small domain; one trojaned model on a large-scale dataset can affect applications of different domains that reuses its general features. The trojan shows no biased behavior for different target classes which makes it more difficult to defend.
SP:35ea626ee4dd1a7a368a660eb852192924966b7f,"This paper proposes a new few-shot regression algorithm for drug discovery. The proposed method is based on deep kernel learning. The authors propose to learn a deep network in combination with a kernel function and a differentiable kernel algorithm. The choice of kernel is critical, and the proposed algorithm learns to find the appropriate kernel for each task during inference. Experiments are conducted on both toy and real-world drug discovery tasks."
SP:91ca4c3ee07617356250bae9f4ef9799b3b134ff,"This paper proposes a framework to characterize which reasoning tasks a network can learn well, by studying how well its computation structure aligns with the algorithmic structure of the relevant reasoning process. The authors define this algorithmic alignment and derive a sample complexity bound that decreases with better alignment. This framework offers an explanation for the empirical success of popular reasoning models, and suggests their limitations."
SP:a52aee8da5cf5acd2baf3c2a62cb679e13b18bd5,"This paper proposes a new metric for evaluating conditional generative adversarial networks (cGANs) based on the Fréchet Joint Distance (FJD), which is defined as the distance between joint distributions of images and conditioning distributions. The authors propose to use the FJD as a single metric for cGAN benchmarking and model selection. Experiments are conducted on a controllable synthetic dataset and compare the proposed FJD with existing metrics. "
SP:fa822e8472efae17c7dfde8258057898383ecbbb,"This paper proposes a method for learning to identify ‘decision states’, i.e. the parsimonious set of states where decisions meaningfully affect the future states an agent can reach in an environment. The authors use the VIC framework (Gregor et al., 2016), which maximizes an agent’s ‘empowerment’ and formulate a sandwich bound on the empowerment objective that allows identification of decision states. Unlike previous work, the decision states are discovered without extrinsic rewards – simply by interacting with the world."
SP:a19a51df7e28a5d3380be4fba13842efbfe3efec,"This paper proposes a method to classify irregularly sampled time series with unaligned measurements, focusing on high scalability and data efficiency. The method SEFT (Set Functions for Time Series) is based on recent advances in differentiable set function learning, extremely parallelizable, and scales well to very large datasets and online monitoring scenarios. The authors extensively compare their method to competitors on multiple healthcare time series datasets and show that it performs competitively while significantly reducing runtime."
SP:4ae89d64460b08749acc192004545c1fa8b7553b,"This paper proposes a new convolutional neural network architecture for audio processing based on the harmonic structure of audio signals. Specifically, the authors propose a convolution operation called ""Harmonic Convolution"" which is based on convolution kernels that are composed of sets of harmonic series instead of local neighborhoods. The authors show that the proposed method can be used to model audio priors and achieve high performance on unsupervised audio restoration tasks. They also show that it can achieve better generalization performance for supervised musical source separation tasks."
SP:c81a2b3fd1c56b9b18e4a358e3ff8b40aea5256a,"This paper proposes a method to reduce the total computation used by earlier pipeline stages and speed up training whenever computation upstream from accelerators dominates the training time. Data echoing reuses (or “echoes”) intermediate outputs from earlier pipeline stage in order to reclaim idle capacity. The authors investigate the behavior of different data echoing algorithms on various workloads, for various amounts of echoing, and for various batch sizes. They find that in all settings, at least one data echoing algorithm can match the baseline’s predictive performance using less upstream computation."
SP:b4cf56d3fa7d65cacde33f17cd04bd5bbc52dd71,"This paper proposes a method for learning controllable features that can be leveraged to improve the generalization ability of successor features. The proposed method is based on the Variational Intrinsic Successor FeatuRes (VISR) algorithm, which is a variant of the successor features framework. The main idea is to learn a feature space that is a linear function of the reward function, and then use this feature space to train a successor policy that can generalize beyond the finite set of behaviors that are explicitly learned in the first task. The authors evaluate the proposed method on the Atari suite, where the rewards are only exposed briefly after a long unsupervised phase. The experimental results show that VISR can achieve human-level performance on 12 games and beats all baselines."
SP:83500230586a9134f910ad067b7233dc563dc1ba,"This paper studies the generalization properties of deep neural networks (DNNs) from a functional point of view. In particular, the authors study the smoothness of the functional approximation of DNNs, which is a function of the depth of the network, the number of units, and the initialization of the networks. Theoretical results are provided for both shallow and deep networks, and experiments are conducted on MNIST, CIFAR-10, and ImageNet. The authors show that generalization results from smoothness and flat initializations of the DNN."
SP:7225825e353b711a7d023f706fafe5e17e4e2fb2,"This paper proposes a new method for image-to-image translation based on the attention mechanism in GANs. Specifically, the proposed method is based on an attention mechanism that estimates the probability that its input is real, and also does it create an attention map that highlights the critical features for such prediction. This attention map then assists the generator to produce more plausible and realistic images. Experiments are conducted on a number of image transfer tasks and show the superiority of the proposed approach."
SP:41c089ba65393174dae1dc136f79030a0a4fc532,"This paper studies the role of multiplicative interaction layers as a unifying framework to describe a range of classical and modern neural network architectural motifs, such as gating, attention layers, hypernetworks, and dynamic convolutions. The authors conjecture that multiplicative interactions offer a particularly powerful inductive bias when fusing multiple streams of information or when conditional computation is required. They argue that they should be considered in many situation where multiple compute or information paths need to be combined, in place of the simple and oft-used concatenation operation. Finally, they back up their claims and demonstrate the potential of multiplicator interactions by applying them in large-scale complex RL and sequence modelling tasks, where their use allows them to deliver state-of-the-art results."
SP:5144391584e6d3825e12684b7c053e4e282cff2b,"This paper proposes a new algorithm for active learning with deep neural network models. Specifically, the authors propose to sample groups of points that are disparate and high magnitude when represented in a hallucinated gradient space, which is a strategy designed to incorporate both predictive uncertainty and sample diversity into every selected batch. Crucially, BADGE trades off between uncertainty and diversity without requiring any hand-tuned hyperparameters. While other approaches sometimes succeed for particular batch sizes or architectures, the proposed algorithm consistently performs as well or better, making it a useful option for real world active learning problems."
SP:ce6023b1e6bf45b071a6f5457b2575425ae03366,This paper proposes a method for self-explaining deep neural networks (DNNs). The authors argue that existing deep architectures are hard to interpret because each hidden layer carries a mix of low level features and high level features. The authors propose a novel feature leveling architecture that isolates low-level features from high-level feature on a per-layer basis to better utilize the GLM layer in the proposed architecture for interpretation. Experimental results show that the modified models are able to achieve competitive results comparing to main-stream architectures on standard datasets while being more self explainable.
SP:b70ceead1bf6c7dc684c74501716e7012b891022,"This paper proposes an adversarial training method for extreme classification. The proposed method is based on the adversarial sampling mechanism that produces negative samples at a cost only logarithmic in C, thus still resulting in cheap gradient updates. The paper also provides a mathematical proof that this adversarial model minimizes the gradient variance while any bias due to non-uniform sampling can be removed. The experimental results on large scale data sets show a reduction of the training time by an order of magnitude relative to several competitive baselines."
SP:29b52fee83309268d9864f3b1fc3617948577d41,This paper proposes an exploration method that leverages a low-dimensional encoding of the environment learned with a combination of model-based and model-free objectives. The intrinsic rewards are based on a weighted distance of nearest neighbors in the low dimensional representational space to gauge novelty. The authors leverage these intrinsic rewards for sample-efficient exploration with planning routines in representational spaces. One key element of the approach is that the authors perform more gradient steps in-between every environment step in order to ensure the model accuracy.
SP:257c98dc1a9f3efcbf9544d9ee2ff524b000543d,"This paper studies the problem of out-of-distribution detection in the few-shot classification setting. The authors propose two new methods for this task and establish benchmark datasets based on four popular few shot classification datasets. Then, they propose two methods for out of distribution detection and investigate their performance. The proposed methods are evaluated on two benchmark datasets and show improved results with the proposed methods. "
SP:a3632b773143dfb3a8f104c6b658dfa1167d155b,"This paper proposes a generative model that unifies decoding in directed and undirected neural sequence models. Specifically, the generative process is modeled as an autoregressive process, and the authors propose to model the decoding process as a special case of the generation process. The authors also propose a method to adapt decoding algorithms originally developed for directed sequence models to unify decoding in undirectED models. The proposed method is evaluated on a cross-lingual masked translation task, where it is shown to outperform the state of the art on WMT’14 English-German translation."
SP:eca5e2be9831dfb79c4f5e633cbfadcfd2e00eb1,"This paper proposes a novel two-stage approach for the recognition of mathematical expressions (MEs) in real-world scenes. In the first stage, an object detection algorithm is used to detect the math symbols of the input image, and in the second stage, a seq2seq model is trained to generate LaTeX sequences with position information. The proposed method is evaluated on a variety of datasets and compared with the end-to-end method. The experimental results show that the proposed method outperforms the state-of-the-art."
SP:923fee8623da1569a7f54a57b4b326f29440b4c0,This paper proposes a vector quantization method to reduce the memory footprint of convolutional neural networks. The method is based on the idea that the quality of the reconstruction of the network output should be preserved rather than its weights. The authors propose to use a set of unlabelled data at quantization time and use bytealigned codebooks to store the compressed weights. They validate their approach by quantizing a high performing ResNet-50 model to a memory size of 5 MB while preserving a top-1 accuracy of 76.1% on ImageNet object classification and by compressing a Mask R-CNN with a 26x factor.
SP:74850ad70241948f93fed95ba1f0ac11360437c1,"This paper proposes a new Transformer-based model for the Mathematics Dataset, which is a set of 56 free-form math word-problems. The model is based on the Transformer architecture, but with the addition of a Tensor-Product Transformer (TP-Transformer) module that encodes the relations between each Transformer cell and the other cells from which values have been retrieved by attention. The proposed TP-Attention is a novel attention mechanism that explicitly encodes relations between Transformer cells and other cells. The paper is well-written and well-motivated. The experimental results show that the proposed model is able to achieve state-of-the-art performance on the mathematics dataset."
SP:d319df820c6630c409fab32097652a083e8f53ea,"This paper studies the problem of generalization in deep neural networks, where the training and test sets may not be sufficiently representative of the empirical sample set, which consists of real-world input samples. To address this problem, the authors reformulate a learning algorithm as a procedure for searching for a source code that maps input features to classes, and derive a necessary and sufficient condition for generalization using a universal cognitive similarity metric, namely information distance, based on Kolmogorov complexity. To achieve this end, they extend the input features by concatenating encodings of them, and then train the classifier on the extended features. They demonstrate through extensive systematic experiments that, as a result of learning a more general classification function, a model trained on encoded input features is significantly more robust to common corruptions, e.g., Gaussian and shot noise, as well as adversarial perturbations, than the models trained on uncoded input features."
SP:b8e86f5e89330d81ba4967a7ed2dbfb56375d8a0,"This paper proposes a new graph pooling operation based on compressive Haar transforms, called HaarPooling. The proposed method is based on following a chain of sequential clusterings of the input graph. The input of each pooling layer is transformed by the compressive haar basis of the corresponding clustering. By the sparsity of the Haar basis, the computation of Haarpooling is of linear complexity. Experiments are conducted on graph classification and graph-based regression tasks."
SP:17bea301d6718ef5f28864dd2445552b3cf65eeb,"This paper proposes a sample-based point-cloud decoder architecture that maps a shape representation to a point feature distribution, allowing an arbitrary number of sampled features to be transformed into individual output points. The proposed method is based on a fully-connected network that maps shape representations to a fixed number of output points, while the proposed method maps a feature distribution to a set of sampled points. Experiments show that the proposed methods outperform the state-of-the-art feedforward architectures."
SP:51d826ead5d1d9cb89d493ce4c39728651bbc57b,"This paper presents a benchmark of real-world noisy labels at 10 controlled noise levels. The authors conduct a large-scale study across a variety of noise levels and types, architectures, methods, and training settings. They show that: (1) Deep Neural Networks (DNNs) generalize much better on real world noise. (2) DNNs may not learn patterns first on real- world noisy data. (3) When networks are fine-tuned, ImageNet architectures generalize well on noisy data, yet it is more difficult for robust DNN methods to improve. (4) Robust learning methods that work well on synthetic noise may not work as well on real data."
SP:9873f78fb2821afdbb5551700e6ab6a0e8bcb9f0,"This paper proposes a method for combining human supervision with supervised learning for denoising rules. The proposed method is based on the idea that human supervision is natural for humans and synergistic for learning. The supervision is coupled with a soft-implicit loss that jointly denoises rules via latent coverage variables, and trains the model through a soft implication loss over the coverage and label variables. The denoised rules and trained model are used jointly for inference. Empirical evaluation on five different tasks shows that the proposed algorithm is more accurate than several existing methods."
SP:6f2c656dbb7629f652a4291d6971625184d8118b,This paper proposes a memory-based GNN (MemGNN) and graph memory network (GMN) for graph neural networks (GNNs) that can jointly learn node representations and coarsen the graph. The authors also introduce two new networks based on this layer: MemGNN and GMN. The experimental results show that the proposed models achieve state-of-the-art results in eight out of nine graph classification and regression benchmarks. The learned representations could correspond to chemical features in the molecule data.
SP:81bc52d734c86975d741b6482d65ca71a9d81620,"This paper analyzes the effect of initialization in deep linear networks on the convergence of deep neural networks. The authors prove that orthogonal initialization speeds up convergence relative to the standard Gaussian initialization with iid weights. They show that for deep networks, the width needed for efficient convergence to a global minimum is independent of the depth and scales linearly in the depth. Their results demonstrate how the benefits of a good initialization can persist throughout learning, suggesting an explanation for recent empirical successes found by initializing very deep non-linear networks according to the principle of dynamical isometry."
SP:9f5d95fc89c2f0d59d04838aa180f3db67997dfa,"This paper studies the problem of how to optimize the bit allocation of weights and activations for deep CNNs compression. The authors propose a Lagrangian-based method to solve the optimization problem of bit allocation in the case of 2-bit quantization. The main contribution of this paper is to study the additivity of output error caused by quantization and find that additivity property holds for deep neural networks which are continuously differentiable in the layers. Based on this observation, the authors formulate the optimal bit allocation problem of weights/activations in a joint framework and propose a very efficient method. The proposed method can compress deep CNN ResNet-50 down to 2 bits with only 0.7% accuracy loss."
SP:7191d7b217a12b1bf9c47d790896a8227c14cc3d,"This paper proposes a novel inference WGAN (iWGAN) model, which is a principled framework to fuse auto-encoders and WGANs. The iWGAN jointly learns an encoder network and a generative network using an iterative primal dual optimization process. The authors establish the generalization error bound of iWgan and provide a rigorous probabilistic interpretation of the model under the framework of maximum likelihood estimation. The empirical experiments show that the proposed model mitigates the symptom of mode collapse, speeds up the convergence, and is able to provide a measurement of quality check for each individual sample."
SP:cca6ae14fd0dd12352855e594acf7f3263bb1f24,"This paper proposes a new model for crowdsourced crowdsourced coreference. The proposed model is based on the mention pair model of anaphoric annotation (MPA). The authors propose to use a nonparametric partially pooled structure (based on a stick breaking process) to alleviate the effects of sparsity inherent in some crowdsourcing environments. The authors show that the proposed model performs better than its unpooled counterpart in conditions of data sparsity, and on par when enough observations are available."
SP:4295cae4a56a02eb21c486408c1bf37a7483cb49,"This paper proposes a method for sparse reward reinforcement learning that combines intrinsic and extrinsic rewards. The intrinsic reward is modeled as a linear combination of the intrinsic reward and the task reward, and the extrinsics are modeled as the successor feature control (SFC) reward, which takes into account statistics over complete trajectories and thus differs from previous methods that only use local information to evaluate intrinsic motivation. The authors evaluate their proposed intrinsic drive (SID) agent using three different environments with pure visual inputs: VizDoom, DeepMind Lab and DeepMind Control Suite. The results show a substantially improved exploration efficiency with SFC and the hierarchical usage of intrinsic drives."
SP:9fa22eb03a79bce0fc1c8e84ae8640e010701eca,", the paper proposes a method for weakly supervised video moment retrieval. The method is based on a multi-level co-attention mechanism to learn richer multimodal representations. The proposed method consists of a Frame-By-Word interaction module as well as a Word-Conditioned Visual Graph (WCVG). The paper also incorporates a novel application of positional encodings, commonly used in Transformers, to learn visual-semantic representations."
SP:27ac670353f34ee7a23bb7622f80c1dfbc0985e0,"This paper proposes a method for image-guided re-rendering of reconstructed objects for virtual and augmented reality applications. The main idea is to train an object-specific deep neural network to synthesize the view-dependent appearance of an object. As input data we are using an RGB video of the object. This video is used to reconstruct a proxy geometry of the objects via multi-view stereo. Based on this proxy, the appearance of a captured view can be warped into a new target view as in classical image-based rendering. This warping assumes diffuse surfaces, in case of view- dependent effects, such as specular highlights, it leads to artifacts. To this end, the paper proposes EffectsNet, a neural network that predicts view-independent effects. The paper demonstrates the effectiveness of the approach both qualitatively and quantitatively on synthetic as well as on real data."
SP:257d124367b1da9a595dc11a9df750d6bade298e,"This paper presents a sparse representation of model uncertainty for deep neural networks (DNNs) that relies on an inverse formulation of Multivariate Normal Distribution (MND): an information form. The paper shows that the model uncertainty can be estimated in this form using a scalable Laplace Approximation scheme, which involves a diagonal correction of the Kronecker-factored eigenbasis. As this makes the inversion of the information matrix intractable an operation that is required for a full Bayesian analysis, the paper further devise a novel low-rank approximation of this eigenBasis that exploits spectral sparsity of DNNs."
SP:2e03ceba4004b82f86f8349352a8ee4520e9c35d,"This paper proposes a load-balanced hashing method for Minwise hashing (MH) that aims to reduce the number of empty bins in Minwise Hashing (MH). In particular, the authors propose to balance the load of the bins (the number of elements in a bin) in the MinHash algorithm, which is based on one-permutation hashing (OPH). The authors claim that the proposed method AHash is more load balanced and accurate without hurting runtime efficiency compared with OPH and densification strategies. The experiments on real datasets validate the claim."
SP:d73827ab98b0ff6bd92abfefea43a5f88ea40de2,This paper proposes a method for extracting features from phase shift data by adding a graph structure to each data point and constructing a suitable machine learning architecture for graph data with cyclic permutation. The proposed method is based on graph neural networks (GNNs) which are trained to extract features from periodic signals. The authors show that the proposed method outperforms the state-of-the-art baselines in both synthetic and real-world experiments.
SP:0df5ad333eb4ff9cca7f2d117909e2ce533a65d8,"This paper proposes a method to train conditional text generation systems that are more faithful to the source text. The authors propose a confidence-based decoder that assigns a confidence score to each target position. This score is learned in training using a variational Bayes objective, and can be leveraged at inference time using a calibration technique to promote more faithful generation. Experiments on a structured data-to-text dataset – WikiBio (Lebret et al., 2016) show that their approach is more faithful than existing state-of-the-art approaches, according to automatic metrics and human evaluation."
SP:03307deac29173b2968fbd08f95fc77eb1f82410,"This paper proposes a new method for pruning neural networks based on magnitude-based pruning. The proposed method is based on the observation that magnitude pruning indeed minimizes the Frobenius distortion of a linear operator corresponding to a single layer. Based on this observation, the authors propose to extend the single layer optimization to a multi-layer optimization. The experimental results demonstrate that the proposed method consistently outperforms magnitude based pruning on various networks including VGG and ResNet, particularly in the high-sparsity regime."
SP:dc80fdc75bc14ae19fe4ba9b85c35ce00b12856f,"This paper proposes Moniqua, a method for decentralized stochastic gradient descent (SGD) that uses quantized communication. Theoretical analysis shows that the proposed method can communicate a provably bounded number of bits per iteration, while converging at the same asymptotic rate as the original algorithm does with full-precision communication. Empirical results on CIFAR-10 and VGG-16 show that the method is robust to very low bit-budgets, allowing less than 4-bits-per-parameter communication without affecting convergence."
SP:86c61a658d07ab86e2d84cef7e480bf7a06e4ddb,"This paper studies the problem of learning a model of future rewards for reinforcement learning. The authors propose a family of partial models that are provably causally correct, yet remain fast because they do not need to fully model future observations. In particular, they show that partial models can be causally incorrect: they are confounded by the observations they don’t model, and can therefore lead to incorrect planning. To address this, the authors introduce a general family of models that is provably correct, but still fast. "
SP:c70479b2096a52584b242de58272ca8d8565feea,"This paper proposes a new variational autoencoder (VAE) model that learns a succinct common representation of two correlated data variables for conditional and joint generation tasks. The proposed model is based on two information theoretic problems: distributed simulation and channel synthesis, in which Wyner’s common information arises as the fundamental limit of the succinctness of the common representation. Experimental results show that the proposed model outperforms existing VAE variants and the variational information bottleneck method."
