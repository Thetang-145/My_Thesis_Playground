paper_id,summary
SP:b19df5243359791fbaad005d6f13d7e9fdb0ff63,"This paper proposes to decompose joint action spaces into restricted role action spaces by clustering actions according to their effects on the environment and other agents. The proposed method ( RODE ) learns a role selector based on action effects and a role policy based on actions. The role selector searches in a smaller role space and at a lower temporal resolution, while the role policies learn in significantly reduced primitive action - observation spaces. The authors further integrate information about action effects into the role policy to boost learning efficiency and policy generalization. RODE outperforms the current state - of - the - art MARL algorithms on 9 out of the 14 scenarios that comprise the challenging StarCraft II micromanagement scenarios."
SP:7deb61890d97422a0fe141ca807f968c70ab239a,"This paper studies the behaviour of the stochastic subgradient descent ( SSGD ) method applied to over - parameterized nonsmooth optimization problems that satisfy an interpolation condition. By leveraging the composite structure of the empirical risk minimization problems, the authors prove that SSGD converges, respectively, with rates O(1 / ) and O(log(1/ ) for convex and strongly - convex objectives when interpolation holds. These rates coincide with established rates for the SGD method, which also satisfies an interpolated condition. The authors provide a partial explanation for the empirical observation that sometimes SGD and SSGD behave similarly for training smooth and nons mooth machine learning models."
SP:c7e0b3fedc0d0409d662dd612b529fdacad2b03e,"This paper presents a novel approach to non - linear training of transformer layers in machine translation and language modelling tasks. The authors propose to replace regular transformer layers with a series of reservoir layers that are randomly initialized and never updated. They also propose to skip the backward pass by approximating top - layer gradients using an approach they call backskipping, with a relatively small sacrifice in performance. Experiments are conducted on a variety of machine translation tasks, including machine translation, language modelling, and machine translation."
SP:ba9f1d4738ec67a440346f3ac6c4cf35f7232077,This paper proposes a new approach to steerable CNN based on filter transform and group representation theory. The authors show that the kernel constructed by filter transform can also be interpreted in the group representations theory. They also show that filter transformed kernels can be used to convolve input and output features in different group representation. They then propose a new method ( FILTRA ) to use filter transform to establish steerability between features in group representation in cyclic group CN and dihedral group DN. Experiments are performed on multiple datasets to verify the feasibility of the proposed approach.
SP:c1116fbb4d058eb6be195b5d13d19a55ba86b602,"This paper proposes an optimal neural synthesis approach where the goal is to find a program that satisfies user - provided constraints while maximizing the program ’s score with respect to a neural model. Specifically, they focus on multimodal synthesis tasks in which the user intent is expressed using combination of natural language ( NL ) and input - output examples. At the core of their method is a top - down recurrent neural model that places distributions over abstract syntax trees conditioned on the NL input. This model not only allows for efficient search over the space of syntactically valid programs, but it allows us to leverage automated program analysis techniques for pruning the search space based on infeasibility of partial programs with partial user's constraints. The experimental results show that their method substantially outperforms prior state - of - the - art techniques in terms of accuracy and explores fewer states during search."
SP:55e02d79146bbb42f1ab6d4fafa2db5ddbe599b0,"This paper proposes a protein convolutional neural network ( PGCN ) based on a structure - based molecular interaction graph generated using the Rosetta energy function that describes the topology and energetic features, to determine the substrate specificity of a protease enzyme. The proposed method is able to predict the specificity of protease enzymes with better accuracy than existing methods. The paper also proposes a novel method to design novel enzymes with tailored specificity against disease targets. The method is evaluated on a variety of datasets and compared with a number of baselines."
SP:7727eeb7b17ad94ddfa0cf24e64a9626d83a8876,This paper proposes a novel value estimator for double Q - learning based on the Bellman operation to reduce the underestimation bias in double - q - learning. The proposed method is based on an approximate dynamic programming approach to estimate the bound of the target value. The method is evaluated on a variety of Atari benchmark tasks and shows significant improvement over baseline algorithms.  
SP:1d630b69f95392a5ef3d7d580b523e077a3555a8,"This paper proposes a two - step training framework for deep generative models ( DGMs ) of high - dimensional natural images. First, a sampler is trained to generate images in low - frequency bands by training a decoder in the wavelet domain. Then, a wavelet - based down - resolution decoder network is trained in the decoder domain. The authors show that the proposed method is more efficient than pixel - based methods, leading to significantly better generative quality of the low - resolution sampler."
SP:b943a73b1ec34867371325748dc3a91ff4011947,"This paper presents a theoretical analysis of self - supervised learning ( SSL ) for fewshot learning ( FSL ), which aims at distilling transferable knowledge on existing classes with large - scale labeled data to cope with novel classes for which only a few labeled data are available. The authors show that a pre - trained embedding network with SSL can provide representation for downstream FSL tasks in theory. They further analyze the main difference between supervised training and self - supervised training on FSL and obtained the bound for the gap between self -supervised loss and supervised loss. They show that under the two assumptions, one can get a test performance close to supervised training."
SP:bd552f98e6a447cefa6b1a9bbdf40bc6539fb643,"This paper studies the convergence property of neural networks with global minima near the initialization under first order methods. In particular, the authors show that the input weights of student neurons eventually align with one of the teacher neurons in a two - layer teacher - student network. They show that this convergence property is distinct from convergence property for networks with finite width. The authors also show that under the most basic settings, all student neurons must align with the teacher neuron at any local minima. The proof is extendable to more general cases, where the proof can be reduced to analyzing the properties of a special class of functions that are called Angular Distance ( AD ) function. Finally, they demonstrate that these properties can be easily verified numerically."
SP:0f62846913ec10b44ed32845770da0565479dc75,"This paper proposes Deep Adaptive Semantic Logic ( DASL ), a novel framework for automating the generation of deep neural networks that incorporates user - provided formal knowledge to improve learning from data. The authors provide formal semantics that demonstrate that their knowledge representation captures all of first order logic and that finite sampling from infinite domains converges to correct truth values. The representation improves on prior neuro - symbolic work by avoiding vanishing gradients, allowing deeper logical structure, and enabling richer interactions between the knowledge and learning components. The paper also demonstrates that the addition of commonsense knowledge improves performance by 10.7% in conditions of data scarcity with limited training data."
SP:2f19259d65fab904c1b771244da3dcb2f8aa0c26,"This paper studies the convergence properties of iterative recurrent computations in neural networks ( ResNet ). The authors define three indices of convergence and show that ResNet can express iterative solutions, but they do not learn them when trained conventionally on computer vision tasks. They then introduce regularizations to encourage iterative convergent computation and test whether this provides a useful inductive bias for ResNets. They show that the gradient coupling and the Lipschitz constraint succeed at making the networks iterative and convergent. However, neither recurrence regularization nor spectral normalization improve classification accuracy."
SP:6c14506b8b2b06043409d912e6bf877651aaa665,"This paper proposes two new normalization methods, SelfNorm and CrossNorm, for out - of - distribution ( OOD ) generalization. SelfNorm uses attention to recalibrate statistics ( channel - wise mean and variance ), while CrossNorm exchanges the statistics between feature maps. Extensive experiments on different domains ( vision and language ), tasks ( classification and segmentation ), and settings (supervised and semi - supervised ) show their effectiveness."
SP:2774abdc11917321dd4994af0f0da1ff824bea03,This paper proposes a simple attention module for reinforcement learning ( RL ). The proposed attention module is based on a simple convolutional encoder. The authors show that the proposed module can extract interpretable task - relevant information such as agent locations and movements without the need for data augmentations or contrastive losses. Experiments on DeepMind Control Suite environments demonstrate the effectiveness of the attention module.
SP:31a7051d08d19c01e11f1fac2f3041ed2fa28f15,"This paper proposes an extension of GradNorm, a widely used gradient - based approach for training multitask networks, where different tasks share, and thus compete during learning, for the network parameters. GradNorm eases the fitting of all individual tasks by dynamically equalizing the contribution of each task to the overall gradient magnitude. However, it does not prevent the individual tasks’ gradients from conflicting, i.e., pointing towards opposite directions. In this work, the authors propose Rotograd, an extension to GradNorm that addresses this problem by dynamically homogenizing not only the gradient magnitudes but also their directions across tasks. For this purpose, they add a layer of task - specific rotation matrices that aligns all the task gradients with respect to all the shared parameters.   The authors provide theoretical guarantees on the algorithm stability and convergence and empirically show that results are comparably good to the usual way of applying GradNorm."
SP:ac9ebd027b92527d9a87b13ad11d002d99a2b0f6,"This paper proposes a new constraint for unsupervised image - to - image translation, called minimal geometry - distortion constraint ( MGC ). The proposed constraint is based on mutual information ( MI ) based dependency measure that models the nonlinear relationships of pixel values in the source and translated images. To estimate MI from data, the authors propose relative Squared - Loss Mutual Information ( rSMI ) which can be efficiently estimated in an analytic form. The authors show the effectiveness of their MGC constraint by providing quantitative comparisons with the state - of - the - art methods on several benchmark datasets."
SP:92a38d7d18f07f68b8f93c61180e2cc1dddd21de,"This paper studies the long - neglected yet important effects of point sampling patterns in point cloud GANs. The authors propose a sampling spectrum to depict the different sampling sensitivities of discriminators. They show that sampling - insensitive discriminators produce shape point clouds with point clustering artifacts while sampling - oversensitive discriminators ( e.g. PointNet++, DGCNN, PointConv, KPConv ) fail to guide valid shape generation. They propose a middle - point sampling - aware baseline discriminator, PointNet - Mix, which improves all existing point cloud generators by a large margin on sampling - related metrics. They also show that even the most naive fully - connected generator, coupled with PointNet-Mix, simply beats all the start - of - the - art point cloud generator."
SP:16c4be3eb162bc81cb3343c2fc115eb8e926a5b5,This paper investigates the robustness of Capsule Networks ( CapsNets ) against adversarial attacks. The authors propose a novel vote attack where they attack the output capsules of the Capsule Network with a vote attack. They show that the vote attack is effective and efficient and can bypass the class - conditional reconstruction based adversarial detection method. They also show that they can also bypass the detection - aware attack paradigm. They conduct extensive experiments to show the effectiveness of the proposed vote attack and the proposed method.
SP:dbd093dff7a38ba8882bb8119c34623ddaaf4cc6,"This paper proposes a new meta - reinforcement learning algorithm called IMPORT, which learns an informed policy that uses privileged information in the form of a task descriptor at train time to improve the learning of recurrent policies in online adaptation. The authors show that the policy regularization of IMPORT significantly speeds up learning compared to TI, Thompson sampling and task - inference approaches to meta - re - reward learning."
SP:bd89d254fbf31db61db237d08ab42981e27c52df,"This paper proposes Adaptive Policy in Sequential Recommendation Systems ( OapRS ), a method to learn an RL policy from offline data in the real - world sequential recommendation system ( SRS ). The method is based on the model learning technique, based on model learning to adapt to diverse simulators generated by the offline dataset. The authors show that the method can learn reasonable environments and makes robust recommendations in unseen environments. They conduct experiments in a synthetic environment and a real world recommendation system of a ride - hailing platform."
SP:1a166b28cf684e0d5759bd629f6a53370d2bf11c,"This paper proposes a goal - reaching RL algorithm that uses imitation learning to acquire goal reaching policies from scratch, without the need for expert demonstrations or a value function. The authors propose a simple algorithm in which an agent continually relabels and imitates the trajectories it generates to progressively learn goal -reaching behaviors from scratch. Each iteration, the agent collects new trajectories using the latest policy, and maximizes the likelihood of the actions along these trajectories under the goal that was actually reached, so as to improve the policy. In practice, GCSL is simpler, more stable, and less sensitive to hyperparameters than value - based methods, while still retaining the benefits of off - policy learning. The method is shown to outperform value based and policy gradient methods on several challenging robotic domains on several benchmark tasks."
SP:c306530164d677e670554eeba8203c66bb3d9f7a,"This paper proposes a new speech synthesis model FastSpeech, which is based on an autoregressive text - to - speech ( TTS ) model. The authors propose two modifications to the TTS model : ( 1 ) directly train the model with ground - truth target instead of the simplified output from teacher, and ( 2 ) introduce more variation information of speech ( pitch, pitch, energy and more accurate duration ) as conditional inputs in training and use predicted values in inference. Experimental results show that the proposed method achieves a 3x training speed - up over the original TTS - based model and even faster inference speed. The proposed method also achieves better voice quality than the original model."
SP:79e9fb20d383816f54738ce70d137131ebc10290,"This paper considers the problem of approximating an empirical probability density function pemp(x ) by another tempered distribution q(x) whose support is in a k - dimensional subspace. The problem is reduced to the minimization of the distance between q and pemp, D(q, pemp ) over a set of generalized functions. The authors introduce a nonnegative penalty function R(f ) that “forces the support of f to be k -dimensional. ” Then they propose a method for solving minuetization of I(f + λR(f) + R(F ), based on the idea of two - step iterative iterative computation, which is an adaptation to real data and to fake data sampled around a k-dimensional subspace found at a previous iteration. They demonstrate the method on 4 examples ( 3 UDR and 1 SDR ) using synthetic data and standard datasets."
SP:93e54522e6c2b805905d21fc968fc40866f2898b,"This paper proposes a novel contrastive learning method called Feature Contrastive Learning ( FCL ) that aims to improve robustness and sensitivity to rare or underrepresented patterns. The proposed method is based on two notions : contextual feature utility and contextual feature sensitivity. The main idea is to train the model to be more sensitive to the features that have higher contextual utility. Empirical results demonstrate that models trained with FCL achieve a better balance of robustness, sensitivity, and sensitivity."
SP:f03c50f15022c4f56ac2b3085354ffed38ad1145,"This paper proposes a novel adversarial imitation learning algorithm, Disentangling Generative Adversarial Imitation Learning ( DisentanGAIL ), which uses adversarial learning with a latent representation inside the discriminator network to incentivize learning only features that encode information about the completion levels of the task being demonstrated. This allows to obtain a shared feature space to perform imitation while disregarding the differences between the expert and the agent's domains. The authors show that their algorithm is able to efficiently imitate in a diverse range of control problems including balancing, balancing, manipulation and locomotive tasks while being robust to domain differences in terms of both environment appearance and agent embodiment."
SP:ef18f4188426bc01be309633b486884b0e7a81a4,"This paper provides a theoretical analysis of the performance of training a pruned neural network for the lottery ticket hypothesis ( LTH ), which states that learning on a properly pruned network ( the winning ticket ) improves test accuracy over the original unpruned network. The paper shows that the convex region near a desirable model with guaranteed generalization enlarges as the neural network model is pruned, indicating the structural importance of a winning ticket. The authors also show that the number of samples required for achieving zero generalization error is proportional to number of the non - pruned weights in the hidden layer. Theoretical results are further provided to justify the implications in pruning multi - layer neural networks."
SP:eed6cb2f8caed39f8295f4aeb6e044c2ac981c4d,"This paper proposes AutoLabel to automatically learn the labels for augmented data based on the distance between the clean distribution and augmented distribution. AutoLabel is built on label smoothing and is guided by the calibration - performance over a hold - out validation set. The authors show that AutoLabel can be easily applied to existing data augmentation methods, including AugMix, mixup, and adversarial training. Experiments on CIFAR-10, CifAR-100 and ImageNet show that the proposed method can improve models ’ accuracy and calibration performance, especially under distributional shift."
SP:0d5017e1a405bf86e3bac40e6e59886d4bf48450,This paper proposes a novel self - supervised representation learning method called Representation Learning via Invariant Causal Mechanisms ( RELIC ) that enforces invariant prediction of proxy targets across augmentations through an invariance regularizer which yields improved generalization guarantees. The authors show how data augmentations can be more effectively utilized through explicit invariance constraints on the proxy classifiers employed during pretraining. They show that learning on refinements is a sufficient condition for learning useful representations and provide an alternative theoretical explanation for the success of these methods.
SP:8f80a6f79f78c6421857f392c9a5e98061d7eb60,This paper proposes a visual transformer network ( VTNet ) to learn informative visual representations for navigation policy learning in object - goal navigation. The proposed VTNet embeds object and region features with their location cues as spatial - aware descriptors and then incorporates all the encoded descriptors through attention operations to achieve informative representation for navigation. Experiments in the artificial environment AI2 - Thor demonstrate that VTNet significantly outperforms state - of - the - art methods in unseen testing environments.
SP:3e7cbe3dff592ef371e48dd86be7719fc5343f17,This paper proposes a new secure federated learning framework based on the secure aggregation primitive. The main idea is to design the topology of the secret - sharing nodes ( G ) as sparse random graphs instead of the complete graph corresponding to the existing solution. The authors provide theoretical guarantees on the reliability / privacy guarantees of the proposed scheme and provide extensive real - world experiments to show that the proposed method maintains the same levels of reliability and data privacy.
SP:00fae41e0eca0a1575cd7b2dcfabf0dc5c9c8b8a,"This paper proposes a new auction design method based on a time - independent Lagrangian. The proposed method is inspired by the work of Duetting et al. ( 2019 ), which proposes to use an inner maximization loop to compute optimal misreports. In contrast, the proposed method uses an additional neural network to learn competitively improved auctions. The method is evaluated on a two - player game with stationary utility functions. The results show that the proposed approach outperforms the existing methods."
SP:a0e8061beb5e9a6c631419861559d22b8d645cb4,"This paper proposes a two - head fine - tuning approach to fine - tune both supervised and unsupervised pre - trained representations to downstream tasks. The authors propose two heads : a classifier head with an improved contrastive contrastive cross -entropy loss to better leverage the label information in an instancecontrast way, and a projector head with a newly - designed categorical contrastive learning loss to fully exploit the intrinsic structure of data in a category - consistent way. The experiments show that the proposed approach achieves state - of - the - art results on CUB in low - data regime."
SP:87e5b552c13d73bd85249062a152c6c140e594a9,This paper proposes a new measure for the robustness of classifiers called genuine adversarial accuracy. The authors argue that standard adversarial training does not measure robustness properly because it does not allow for generalization. They propose a new metric that measures adversarial robustness without trading off accuracy on clean data and accuracy on the adversarially perturbed samples. They prove that a single nearest neighbor ( 1 - N ) classifier is the most robust classifier according to genuine adversarian accuracy for given data and a norm - based distance metric when the class for each data point is unique.
SP:2fda410b9281c5e253d385bc4382ec168bc161f3,"This paper studies the problem of disparate impact on graph - structured data in machine learning applications and its societal impacts. The authors propose a new algorithm, FairAdj, to empirically learn a fair adjacency matrix with proper graph structural constraints for fair link prediction, and in the meanwhile preserve predictive accuracy as much as possible. The proposed algorithm is evaluated on six real - world social and citation networks to demonstrate the effectiveness of the proposed method. The results are consistent with the existing literature ( Zhao & Gordon, 2019 ; Fish et al. 2016 ; Calders et al, 2009 )."
SP:b614e9fbec58e9efa7722d2ec4a60fc93d210f92,This paper proposes a disentangled exploration autoencoder ( DEAE ) to improve the generative ability of autoencoders. The proposed method is based on disentanglement representation and regularization to guarantee the validity of exploration in latent space and achieve controllable synthesis. Experiments demonstrate that DEAE can improve the performance of downstream tasks by synthesizing attribute - controlled augmented samples and can help to eliminate dataset bias.
SP:c934adb14926a00ef9c73c9773cb0b3a2669921e,"This paper proposes a novel memory allocation scheme based on a hierarchical latent variable model, inspired by the Kanerva Machine, that learns to compress an episode of samples, referred to by the set of pointers, into a latent multi - dimensional memory. The K++ model infers a key distribution as a proxy to the pointers ( Marlow et al. 2008 ) and is able to embed similar samples to an overlapping latent representation space, thus enabling it to be more efficient on compressing input distributions. The authors demonstrate that this allocation scheme improves performance in memory conditional image generation, resulting in new state - of - the - art conditional likelihood on binarized MNIST."
SP:e63d7d8c581019e17585fb9c0eac33d6836e187d,"This paper studies the effect of attention mechanisms on the loss landscape of attention - based neural networks. The authors show that under certain assumptions, every local minimum of the attention model has low prediction error, and attention models require lower sample complexity than models without attention. Besides revealing why popular self - attention works, the theoretical results also provide guidelines for designing future attention models. Experiments on various datasets validate the theoretical findings."
SP:f739d199fdee26f09994e3f9487aec1eab0f2e89,"This paper proposes an inverse RL algorithm for active inference based rewards based on the expected free energy ( EFE ), which is a core quantity in active inference. The authors claim that EFE can be treated as a negative value function from an RL perspective and propose a novel algorithm for designing EFE based rewards, by learning a prior preference from expert demonstrations. The experiments show the applicability of the proposed algorithm to inverse RL problems."
SP:5592b79e49eba95c15103a3348f2bde57b60f2ab,"This paper proposes a data augmentation method to improve generalization in both adversarial and standard learning by using out - of - distribution ( OOD ) data that are devoid of the abovementioned issues. The proposed method is shown to improve the generalization theoretically using OOD data in each learning scenario and complement their theoretical analysis with experiments on CIFAR-10, CIFar-100, and a subset of ImageNet. The results indicate that undesirable features are shared even among image data that seem to have little correlation from a human point of view. Furthermore, the proposed method can further improve the existing state -of - the - art adversarial training."
SP:3cac7a2c310165ed0de46d8e5546c3bfbd639158,"This paper proposes Fast Linearized Adaptive Policy ( FLAP ), a new meta - RL method that is able to extrapolate well to out - of - distribution tasks without the need to reuse data from training, and adapt almost instantaneously with the need of only a few samples during testing. FLAP builds upon the idea of learning a shared linear representation of the policy so that when adapting to a new task, it suffices to predict a set of linear weights. A separate adapter network is trained simultaneously with the policy such that during adaptation, it can directly use the adapter network to predict these linear weights instead of updating a meta - policy via gradient descent. The application of the separate feed - forward network not only speeds up the adaptation run - time significantly, but also generalizes extremely well to very different tasks that prior MetaRL methods fail to generalize to."
SP:21a1bd4ada0723c96c0dbf7a142a2faf5defa4e3,"This paper proposes a federated kernel k - means algorithm to solve the optimization problem of kernel k- means under federated settings. The proposed algorithm is based on a distributed stochastic proximal gradient descent ( DSPGD ) algorithm and a communication efficient mech anism ( CEM ) to reduce the communication cost. The communication cost is linear to the dimension of the right singular vector times the number of users, which can be much smaller than the size of the data samples. The experimental results show that the federated kerne l k-means achieves the highest clustering quality with the communication costs reduced by more than 60% in most cases."
SP:be568dd3fea51ce33a6d1e4b07dda5aee6342395,"This paper proposes a method to reduce the training cost of CNNs by reducing the search space and hence the training budget by constraining search to models close to the accuracy - latency Pareto frontier. The authors propose CompOFA, a design space smaller by several orders of magnitude than the original Once - For - All ( FA ) design space. They show that this smaller design space is dense enough to support equally accurate models for a similar diversity of hardware and latency targets, while also reducing the complexity of the training and subsequent extraction algorithms. They demonstrate that even with simple heuristics, they can achieve a 2x reduction in training time and 216x speedup in model search /extraction time compared to FA."
SP:04b84d26cf282dbb753cbf27f14c334f65d3f8ec,"This paper proposes an adversarial meta - learning algorithm, ADML ( ADversarial Meta - Learner ), which leverages clean and adversarial samples to optimize the initialization of a learning model in an adversarially trained adversarial manner. It is shown that ADML outperforms several representative meta -learning algorithms in the cases involving adversarial data generated by different attack mechanisms, on two widely - used image datasets, MiniImageNet and CIFAR100, in terms of both accuracy and robustness."
SP:dfbaa6b53c4e8328d52666ad4641fc917bf0c0b3,"This paper proposes a new method for permutation decoding based on self - attention and node embedding. The method is based on a self - Attention - based decoder, which embeds all the permutations of a code in a word - independent manner, by extracting relevant features from the embeddings. The proposed method is evaluated on the Bose - Chaudhuri - Hocquenghem ( BCH ) code and shows significant improvements in the bit error rate compared to the baselines."
SP:c860a7b0952d708e7851c9bc4b63d246f64d1cba,This paper proposes a method for training BERT for an intermediate text classification task. The authors propose to perform an unsupervised clustering task prior to finetuning on the target task and train BERT on predicting the cluster labels. They show that this additional classification step can significantly reduce the demand for labeled examples mainly for topical classification tasks. They further analyze the results to gain insights as to when this approach would be most valuable.
SP:ea37f5882fd98dd4ce233077bb3069517d4ed4ea,"This paper studies the performance of generative models using a random shooting control agent ( RRL ) on the control problem. The authors show that the mixture density nets outperform all other models when the control agent is deterministic. They also show that heteroscedasticity at training time, perhaps acting as a regularizer, improves predictions at longer horizons. They show that deterministic models are on par, in fact they consistently outperform their probabilistic counterparts.   The authors propose a new metric to measure the performance on a static data set and an experimental protocol to evaluate the various models."
SP:4e25ba3714d78ba59a0d8efbb65e0ef5201702f8,"This paper proposes a generative adversarial network ( ADIS - GAN ) that can explicitly disentangle affine transformations in a self - supervised and rigorous manner. The objective is inspired by InfoGAN, where an additional affine regularizer acts as the inductive bias. Unlike the disentangled representations learned by existing approaches, the features learned by ADIS-GAN are axis - aligned and scalable, where transformations such as rotation, horizontal and vertical zoom, horizontal, vertical skew, and vertical translation can be explicitly selected and learned.    The authors propose to decompose the affine matrix into separate transformation matrices and inferring the transformation parameters by maximum likelihood estimation."
SP:121f8420cfb49c6d80b5ebb4051e85947182594a,"This paper proposes CLSA, a contrastive contrastive learning method that leverages strong augmentations in representation learning to improve the performance of unsupervised learning. The proposed method is based on a linear classifier with a single - layer classifier fine - tuned. The method is evaluated on ImageNet linear evaluation protocol, ImageNet-50 dataset, and ImageNet object detection dataset. The results show that the proposed method outperforms the previous self - supervised and supervised methods on both the transfer learning and object detection tasks."
SP:af54e542223097c315ecd677d0b968e9a0b2a1d4,"This paper proposes a new method for de - identifying magnetic resonance imaging ( MRI ) images. The proposed method is based on a 3D GAN architecture that takes a patient’s MRI scan as input and generates a 3 - D volume in which the brain is not modified but the face has been de - identified. The authors propose a new class of MRI de - identification techniques that remodel privacy - sensitive facial features as opposed to removing them. They propose a conditional, multi - scale, 3DGAN architecture to achieve this. Compared to the classical removal - based techniques, their deep learning framework preserves privacy more reliably without adversely affecting downstream medical analyses on the brain."
SP:0ac3964bd2320341488476d60f57b75d2a79f92c,"This paper proposes a graph pooling method based on a multiset encoding problem with auxiliary information about the graph structure. The proposed method is called GMT ( Graph Multiset Transformer ), which is a multi - head attention based global pooling layer that captures the interaction between nodes according to their structural dependencies. The paper shows that GMT satisfies both injectiveness and permutation invariance, such that it is at most as powerful as the Weisfeiler - Lehman graph isomorphism test. The experimental results show that GMT significantly outperforms state - of - the - art graph pooler methods on graph classification benchmarks with high memory and time efficiency."
SP:76848e7ac3e6709e92f6a6db60269cb5177495d1,"This paper proposes a new explanation for the problem of over - squashing in graph neural networks ( GNNs ). The paper argues that the problem is caused by a bottleneck when aggregating messages across a long path. This bottleneck causes the over - Squashing of exponentially growing information into fixed - size vectors. As a result, GNNS fail to propagate messages originating from distant nodes and perform poorly when the prediction task depends on long - range interaction. In this paper, the authors demonstrate that the bottleneck hinders popular GNN models such as GCNs and GINs that absorb incoming edges equally. They also show that prior work that extensively tuned GCN models suffer from over -squashing and that breaking the bottleneck improves their state - of - the - art results without any tuning."
SP:90d8fa381446923902e42b259392e5e975e6caa1,"This paper proposes a new method for cross - domain sentiment analysis based on a Gaussian mixture modal ( GMM ) distribution for source and target domains. The method is based on learning a prototypical distribution for the source domain in a cross - domains embedding space which is trained to be domain - agnostic. The authors estimate the parameters of the GMM distribution using a subset of source samples for which the classifier is confident about its predictions. As a result, larger margins between classes are introduced in the prototypical distributions which help reduce the domain gap. Theoretical proof is provided to demonstrate that the method minimizes an upperbound for the target domain expected error. Experimental results demonstrate that our algorithm outperforms state - of - the - art sentiment analysis algorithms."
SP:893fd7440b82f5da0d4c0944928810322eaee2f0,"This paper proposes an evaluation methodology to measure gender bias in NLI models by constructing a challenge task which involves pairing gender neutral premise against gender - specific hypothesis. The challenge task is designed to investigate state - of - the - art models on the presence of gender stereotypes using occupations using occupations. The authors show that three models (BERT, RoBERTa, BART ) trained on MNLI and SNLI data - sets are significantly prone to gender induced prediction errors. They also find that debiasing techniques such as augmenting the training dataset to ensure a gender - balanced dataset can help reduce such bias in certain cases."
SP:a32ab755bd249c393b70938036ce8e810c0c439f,"This paper studies variational intrinsic control ( VIC ), an unsupervised reinforcement learning method for finding the largest set of intrinsic options available to an agent. In the original work by Gregor et al. ( 2016 ), two VIC algorithms were proposed : one that represents the options explicitly, and the other that does it implicitly. The authors show that the intrinsic reward used in the latter is subject to bias in stochastic environments, causing convergence to suboptimal solutions. To correct this behavior and achieve the maximal empowerment, they propose two methods respectively based on the transitional probability model and Gaussian mixture model. They substantiate their claims through rigorous mathematical derivations and experimental analyses."
SP:b4df2c4627a6d46c5100133e38c4bea20b296dd8,"This paper studies the use of neural ensembling for image classification in the low - data regime by using an ensemble of relatively small deep neural networks. The authors propose a simple yet effective technique that outperforms current state - of - the - art approaches for learning from small datasets. They compare different ensemble configurations to their deeper and wider competitors given a total fixed computational budget and provide empirical evidence of their advantage. Furthermore, they investigate the effectiveness of different losses and show that their choice should be made considering different factors."
SP:4a0ee01f4897efa81659f37ef0468ee8195bbc4f,"This paper proposes Sparse Binary Neural Networks ( SBNN ), a novel model and training scheme that allows to introduce sparsity in BNNs by using positive 0 / 1 binary weights, instead of the - 1 / 1 weights used by state - of - the - art binary networks. The proposed method is able to achieve a high compression factor and reduces the number of operations and parameters at inference time. Experiments on linear and convolutional networks over MNIST and CIFAR-10 datasets show that SBNNs can achieve high compression rates and good generalization, while further reducing the operations."
SP:5be8539ad02595ad3c7a2d7afe8cbb3e9924467d,"This paper proposes a new calibration method for predicting uncertainty in out - of - distribution ( OOD ) data. The method uses outlier exposure to properly calibrate the model probabilities. The calibration error is the difference between predicted error rates and actual error rates, as measured by collecting data into bins based on pmax = maxi p softmax i bins. The baseline method for predictive uncertainty is simply use the softmax probabilities of the model, p(x ) = softmax(f(f)(f ), as a surrogate for class membership probabilities ( Hendrycks & Gimpel, 2017 )."
SP:ea503f67e38fce7dee9cc4996b55b8959911f030,"This paper studies the expressive power of graph neural networks and graph kernels from an empirical perspective. Specifically, they compare the graph representations and similarities produced by these algorithms against those generated by an intractable graph similarity function. They also investigate the impact of node attributes on the performance of the different models and kernels. Their results reveal interesting findings. For instance, theoretically more powerful models do not necessarily yield higher - quality representations, while graph kernels are shown to be very competitive with neural networks."
SP:0cf7b7d929f50e0b7f4fda5e1f68e5ade2f7c29b,"This paper proposes a new method for self - supervised image animation based on the motion of a driving video. The proposed method is based on an occlusion mask and a background mask to regularize the discriminator predictions. The main idea is to use the top - k percent occluded pixels of the foreground of the source image and the background mask for regularizing the discriminators predictions on the inpainting. The method is evaluated on three datasets : VoxCeleb, BAIR, and Tai - Chi -HD.   "
SP:60b535fc6cbc1a7a26ad53f706ebb17de346dc4f,"This paper proposes a method for learning disentangled representations of independent causal mechanisms ( ICM ) from observational data. The authors propose to learn a model that disentangles each mechanism and approximates the groundtruth mechanisms from the observational data using a single self - supervised generative model with an unconventional mixture prior, simplifying previous methods.   The authors demonstrate the identifiability of their model w.r.t the mechanisms in the self - supervised scenario. They compare their approach to disentangle representations on various downstream tasks, showing that their approach is more robust to intervention, covariant shift, and noise due to the disentanglement."
SP:44d4e24428d043a69b40013919cda0e8e7bff99c,"This paper proposes a novel self - labeling framework for predicting chemical compound graphs from 2D images. The authors propose a graph aligning approach that generates rich or detailed labels given normal labels W. They show that the rich labeling can be performed by graph alignment, and show that it enables data efficient domain adaption and reaches state - of - the - art performance on Maybridge compound data set. Finally, on the Maybridge data set the proposed self - labeling approach reached higher performance than the current state of the art."
SP:ad906dd9a176cffd283593321ff6b9ad19595528,"This paper proposes a monotonic neural network ( MNN ) based deep learning framework to solve the chiller plants energy optimization problem. The proposed method is based on domain knowledge in the structure and loss design of deep network to build a nonlinear model with lower redundancy function space. The energy consumption estimation of most chillers can be physically viewed as an input - output monotony problem. Thus, the proposed MNN can design a Neural Network with monotsonic constraints to mimic the physical behavior of the system. The authors verify the proposed method in a cooling system of a data center, experimental results show the superiority of their framework in energy optimization compared to the existing ones."
SP:6cb65ee5d2926858570601eeeade24fe86c7f32f,"This paper proposes a causal spatio - temporal fusion transformer ( CausalTrans ) method for multi - task forecasting. The authors propose to replace softmax in multi - head attention with Taylor expansion attention to reduce the number of nodes in a graph. They further design a spatial graph fusion mechanism to significantly reduce the parameters on the parameters'scale. They conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various components, and the time efficiency of their Causal Trans framework."
SP:223980a1954d626d90ff54d8dc61b5d85a6b349c,"This paper proposes an unsupervised framework called coupled mixture VAE ( cpl - mix VAE ), which utilizes multiple interacting autoencoding agents to learn mixture representations. The individual agents operate on augmented copies of training samples to learn the mixture representations, while being encouraged to reach consensus on the categorical assignments. The authors provide theoretical justification to motivate the use of a multi - agent framework, and formulate it as a variational inference problem. They benchmark their approach on MNIST and dSprites, achieving state - of - the - art categorical assignment while preserving interpretability of the continuous factors. They then demonstrate the utility of this approach in jointly identifying cell types and type - specific, activity - regulated genes for a single - cell gene expression dataset profiling over 100 cortical neuron types."
SP:c982610ad28662c3bd13132abe1f7307d1a61b68,"This paper provides a general characterization of the G - steerable kernel spaces of GCNNs for any compact group. The authors show that the G-steerable kernels satisfy an equivariance constraint on the kernel space of a GCNN, which is a generalization of the equivariant convolutional network ( GCNNs ). They show that this kernel space can be used to derive the endomorphism bases, Clebsch - Gordan coefficients, and harmonic basis functions on homogeneous spaces. They provide an analogy between the constraints underlying steerable kernels on the one hand and spherical tensor operators from quantum mechanics on the other hand. They prove that the steerable kernel space is fully understood and fully understood in terms of generalized reduced matrix elements, 2 ) generalized reduced matrices elements and 3 ) harmonic basis function."
SP:7b2ea39069277ad0f4f79476a77ef84587a804d9,"This paper studies the effect of selective classification on the accuracy of classification models in the presence of spurious correlations between groups. The authors show that selective classification can improve accuracy across groups, but it can also magnify existing accuracy disparities between groups within a population. They show that increasing abstentions can even decrease accuracy on some groups. To better understand this phenomenon, they study the margin distribution, which captures the model’s confidences over all predictions. They prove that whether selective classification monotonically improves or worsens accuracy is fully determined by the accuracy at full coverage ( i.e., without any abstention ) and whether the distribution satisfies a property they call left -log - log - concavity."
SP:f1d57ee27e901daf7e4e2b84139019e945818911,"This paper proposes a hierarchical nonnegative CANDECOMP/PARAFAC decomposition ( NCPD ) model and a training method, Neural NCPD, for performing hierarchical topic modeling on multi - modal tensor data. The proposed method utilizes a neural network architecture and backpropagation to mitigate error propagation through hierarchical NCPD. In the remainder of Section 1, the authors present related work on tensor decompositions and training methods. In Section 2, the main contributions are two main contributions, hierarchical NC PD model and neural NCPD training method. The authors also present their main contributions on real and synthetic data."
SP:b6ddc3a560aa7155e7e927bf5360bedc36586597,"This paper proposes a new adversarial robustness certificate for graph neural networks ( GNNs ). The authors propose to fuse multiple single - node certificates into a collective one, i.e., the number of predictions that are simultaneously guaranteed to remain stable under perturbation. The proposed method is based on Graph Neural Networks and leverage their locality property.   The authors show that the proposed method can be applied to node classification tasks like node classification, image segmentation, namedentity recognition, and named entity recognition. In particular, the authors propose the first collective robustness certificates for node classification."
SP:cc93dd2f68e415e2457166e78627865dc1b44697,"This paper proposes Quantile Regression GAN ( QRGAN ), a new method for training GANs. The proposed method is based on the loss function modification methodology of loss functions for improving the performance of GAN models. The main contribution of the paper is to propose a new loss function for training a GAN model. The loss function is a loss function that modifies the distribution between real and generated data distribution. The authors show that the proposed loss function can be used to train a model that is robust against mode collapse and cause mode collapse. They also show that QRGAN outperforms other GAN variants in terms of robustness to mode collapse problem and cause collapse."
SP:4ddb47ee77c374ae6c3e419412d92ca77260692e,"This paper proposes to evaluate relevance metrics for explaining the predictions made by complex machine learning models. The authors propose three relevance metrics : cosine similarity of gradients of the loss, identical class test, and identical class and identical subclass test. The relevance metrics are evaluated on identical class, identical subclass, and the identical class / identical subclass tests. The experiments show that the relevance metrics perform best on the similarity metrics, while some metrics perform poorly on the other two metrics and the authors analyze the reasons of their failure."
SP:6c2cbf2bc0f6dabe974e80ec1e82d2d12189906e,"This paper proposes to add a low - rank global attention ( LRGA ) module to Graph Neural Networks ( GNNs ) to improve their generalization power. The proposed LRGA module is a computation and memory efficient variant of the dot - product attention ( Vaswani et al. 2017 ). The authors show that augmenting the LRGA with the 2 - FWL algorithm provides algorithmic alignment to a powerful graph isomorphism test, namely the 2-Folklore Weisfeiler - Lehman ( 2 -FWL ) algorithm. They show that adding LRGA to existing GNN layers with LRGA produces state - of - the - art results in current GNN benchmarks."
SP:b4abdd28504b4c1de239eabd4e0e27d370efee71,"This paper proposes a method to improve the calibration performance of Convolutional Neural Networks ( CNNs ) based on the idea of objectness and label smoothing during training. In particular, the authors propose a smoothing factor that is adaptive based on relative object size within an image. The authors show that their method is able to produce an order of magnitude reduction in confidence when predicting on context only images when compared to baselines. They also show extensive results using ImageNet to demonstrate that CNNs trained using adaptive label smoothed are much less likely to be overconfident in their predictions."
SP:5254658923e594294b69d124a8d004166852822a,"This paper proposes a two - layer ReLU denoising network for convex optimization of neural networks. The main contribution of the paper is to propose a dual duality framework for the dual network optimization problem. In particular, the authors propose a convex duality network with a weight decay regularization regularization and a piecewise linear filtering method. The authors show that the proposed dual network is able to achieve the optimal training with convex solvers and can also be used for interpreting training and prediction. Experiments on MNIST and fastMRI datasets show the effectiveness of the proposed method."
SP:085cad6bc143c8713580bddfaa71f06496dac314,"This paper proposes an end - to - end speech synthesis method to synthesise speech from normalised text or phonemes in an end to end manner, resulting in models which operate directly on character or phoneme input sequences and produce raw speech audio outputs. The proposed method is feed - forward and thus efficient for both training and inference, using a differentiable alignment scheme based on token length prediction. It learns to produce high fidelity audio through a combination of adversarial feedback and prediction losses constraining the generated audio to roughly match the ground truth. The resulting model achieves a mean opinion score exceeding 4 on a 5 point scale, which is comparable to the state - of - the - art models relying on multi - stage training and additional supervision."
SP:01148cea55db606aa78d27e900818684a8bce9ab,This paper proposes a non - parametric method for node representation learning based on the Wasserstein metric. The authors propose to embed nodes into a low - dimensional discrete distribution of the attribute matrix of the node features. The nodes are then distributed in a neighborhood distribution based on their local neighborhoods. This allows them to reduce the distortion caused by missing attributes and obtain integrated representations expressing information of both topology structure and attributes. They then pull the nodes back to the original space and produce corresponding point representations to facilitate various downstream tasks. They also propose two algorithms based on it for node classification and matrix completion.
SP:aeeb5909f7123ef631f569b469af9715205c881f,"This paper proposes a new reinforcement learning method called AMIGO, which proposes to train a goal - conditioned student policy in the absence of reward in a reward - free environment. The teacher learns to propose increasingly challenging GOals that allow the student to learn general skills for acting in a new environment, independent of the task to be solved. The authors show that their method generates a natural curriculum of self - proposed goals which ultimately allows the agent to solve challenging tasks where other forms of intrinsic motivation and state - of - the - art RL methods fail."
SP:3d05bc7dca97681cb582298e318b9b973841eed3,"This paper considers the problem of information retrieval from a dataset of files stored on a single server under both a user distortion and a user privacy constraint. The proposed model can be seen as an extension of the well - known concept of private information retrieval by allowing for distortion in the retrieval process and relaxing the perfect privacy requirement. The authors study the tradeoff between download rate, distortion, and user privacy leakage, and show that the optimal rate - distortion - leakage tradeoff is convex and that in the limit of large file sizes this allows for a concise information - theoretical formulation in terms of mutual information."
SP:3f9e2db00fc3dcd7a40588adcb638503ec10dc09,"This paper proposes a decoupled greedy learning method for graph neural networks ( GNNs ) that decouples the input graph into smaller modules and associates each module with greedy auxiliary objectives. The proposed method allows GNN layers to be updated during the training process without waiting for feedback from successor layers, thus making parallel GNN training possible. The authors evaluate their proposed training strategy thoroughly on benchmark datasets, and demonstrate it has superior efficiency while not sacrificing much performance."
SP:5ecb1b288f7fc02aead4493f81640867bc349290,"This paper proposes a framework for efficiently answering complex queries on incomplete Knowledge Graphs, where the truth value of each atom is computed by a pre - trained neural link predictor. The authors propose two solutions to the optimisation problem, including gradient - based and combinatorial search. The proposed approach produces more accurate results than state - of - the - art methods — black - box neural models trained on millions of generated queries — without the need of training on a large and diverse set of complex queries. Using orders of magnitude less training data, the authors obtain relative improvements ranging from 8% up to 40% in Hits@3 across different knowledge graphs containing factual information."
SP:f04a522fd04c503754fdb8c52da68646d31271a4,"This paper proposes a method for verifying the robustness of feed - forward neural networks with piecewise - linear activation functions. The method is based on a geometric projection of the input space into a set of convex polyhedral regions in which the network ’s behavior is linear. The authors show how the regions around a point can be analyzed using simple geometric projections, thus admitting an efficient, highly - parallel GPU implementation that excels particularly for the `2 norm, where previous work has been less effective. Empirically, they find this approach to be far more precise than many approximate verification approaches, while at the same time performing multiple orders of magnitude faster than complete verifiers."
SP:5297651ff873f97c07b9c47ed3eff52251661844,"This paper proposes an approach for embedding objects in an affordance space, in which each dimension corresponds to an aspect of meaning shared by many actions, using text corpora. This embedding makes it possible to predict which verbs will be applicable to a given object, as captured in human judgments of affordance, better than a variety of alternative approaches. The dimensions learned are interpretable, and that they correspond to typical patterns of interaction with objects. Finally, the dimensions can be used to predict a state - of - the - art mental representation of objects, derived purely from human judgements."
SP:72b4f3b40c6c6fa2eb53e95ed9a10a4077ffa049,"This paper proposes a method for the emergence of individuality in multi - agent reinforcement learning ( MARL ). The method is based on a probabilistic classifier that predicts a probability distribution over agents given their observation and gives each agent an intrinsic reward of being correctly predicted by the classifier. The intrinsic reward encourages the agents to visit their own familiar observations, which makes the intrinsic reward signals stronger and in turn makes the agents more identifiable. Two regularizers are proposed to increase the discriminability of the classifiers. The authors evaluate EOI in three scenarios where agents are preferred to take different roles, i.e. Pac - Men, Windy Maze, and Firefighters, and demonstrate that EoI significantly outperforms existing methods."
SP:112509d6d3573a9d495d182fdfae6ec0327cddf5,This paper proposes a method to improve the robustness of randomized smoothed classifiers against adversarial attacks. The proposed method is based on the Smoothed WEighted Ensembling ( SWEEN ) method. The authors propose an ensemble - based method to train the classifier. They show that SWEen can achieve optimal robustness. They also propose an adaptive prediction algorithm to reduce the prediction and certification cost. They conduct extensive experiments to demonstrate the effectiveness of the proposed method.
SP:ea892e3d199ed6121279b20061a87f43afae8796,"This paper proposes a new memory policy network ( OMPN ) that learns to decompose tasks into sub - tasks based on the inductive bias. The authors propose to use a bottom - up recurrence and a top - down recurrence to implement horizontal update and vertical expansion respectively to implement a memory - update rule to maintain a hierarchy among memories such that the higher - level memory can store longer - term information. Experiments on Craft and Dial demonstrate that the model can achieve higher task decomposition performance under both unsupervised and weakly supervised settings, comparing with strong baselines."
SP:cc6aa977ce561a2493ae74bb694205cd67c8d890,"This paper proposes a Causal Semantic Generative model ( CSG ) based on causal reasoning for out - of - distribution ( OOD ) examples. The proposed method is based on the causal invariance principle, with a novel design in variational Bayes for both efficient learning and easy prediction. Theoretically, the authors prove that under certain conditions, CSG can identify the semantic factor by fitting training data, and this semantic -identification guarantees the boundedness of OOD generalization error."
SP:be3f34a59e5e61dcdbc7cb085f031ba4a5a5b758,"This paper studies the problem of designing robust online learning algorithms tolerant to adversarially corrupted rewards. In particular, the authors study the design of algorithms with small regret over a period of time steps, while the algorithm observes corrupted rewards, and they require its regret to be small with respect to the true uncorrupted reward distribution. They build upon recent advances in robust estimation for unsupervised learning problems to design robust online algorithms with near optimal regret in three different scenarios : stochastic multi - armed bandits, linear contextual bandits, and Markov Decision Processes ( MDPs ). They show that an extension of a UCB style exploration scheme achieves an optimal penalty of O( T ) by maintaining robust optimistic estimates of rewards at each state - action pair. They then extend this to the more general case where they modify the UCRL2 algorithm ( Auerhab et al. 2009 ) by maintain robust estimates of the estimated rewards and transition probabilities."
SP:6d62a80aaebb2988df3953d4d7164e5a2fa1aa6d,"This paper proposes a novel framework for neural machine translation ( NMT ) based on a rewriter and an evaluator. The rewriter produces a new translation to improve the past translation and the evaluators estimates the translation quality to decide whether to terminate the rewriting process. The authors propose a prioritized gradient descent ( PGD ) method that facilitates training the rewriter, and the evaluation and training the evaluation jointly. The proposed method is evaluated on two translation tasks, Chinese - English and English - German, and show that the proposed framework notably improves the performances of NMT models and significantly outperforms previous baselines."
SP:9761fca8848868dfc9cacdab2537f8276ca76e0f,"This paper proposes a novel two - stage adversarial refinement method for learning a multimodal predictive distribution for semantic segmentation. In the first stage, the authors train an adversarial network to sample from it an arbitrary number of coherent predictions. The second stage uses a categorical likelihood model to model the data. The model can be used independently or integrated into any black - box segmentation framework to facilitate learning of calibrated stochastic mappings. The authors demonstrate the utility and versatility of the approach by attaining state - of - the - art results on the LIDC dataset and a modified Cityscapes dataset."
SP:ce965758f1b795a56c02f45d6a8d06cb8bdf29cb,"This paper proposes a new method to deal with the error induced by contractive compressors in distributed computing systems. The proposed method is based on a construction that transforms any contractive compressor into an induced unbiased compressor. The authors show that the proposed method leads to vast improvements over existing methods able to work with unbiased compressors, including reduced memory requirements, better communication complexity, and fewer assumptions. They also perform several numerical experiments which validate their theoretical findings."
SP:4fd702490293e481c79614852ba27dd3ce9215a4,"This paper proposes a new research framework : hyperparameter transfer across adjustments ( HT - AA ). The authors provide four simple HT -AA baseline algorithms and eight benchmarks changing various aspects of ML algorithms, their hyper parameter search spaces, and the neural architectures used. The best baseline, on average and depending on the budgets for the old and new HPO, reaches a given performance 1.2 - 3.6x faster than a prominent HPO algorithm without transfer. As HPO is a step in ML development but requires extensive computational resources, this speedup would lead to faster development cycles, lower costs, and reduced environmental impacts."
SP:e8f99bae5853de525450fcb8facd23cf973fc161,"This paper proposes a method to train an image classifier to regress audio labels rather than traditional categorical probabilities. The authors argue that high dimensional, high entropy label representations are generally more useful because they provide a stronger error signal. They support this hypothesis with evidence from various label representations including matrices, spectrograms, shuffled spectrogram, Gaussian mixtures, and uniform random matrices of various dimensionalities. Their experiments show that high - dimensional labels achieve comparable accuracy to text ( categorical ) labels on the standard image classification task, but features learned through label representations exhibit more robustness under various adversarial attacks and better effectiveness with a limited amount of training data."
SP:4e8d924cba7367af0999b30d79250b4dc40413e1,"This paper proposes a method to improve the robustness and uncertainty performance of ensemble neural networks by using multiple forward passes for prediction. The authors show that the benefits of using multiple predictions can be achieved ‘for free ’ under a single model ’s forward pass. They show that, using a multi - input multi - output configuration ( MIMO ) configuration, one can utilize one model’s capacity to train multiple subnetworks that independently learn the task at hand. They observe a significant improvement in negative log - likelihood, accuracy, accuracy and calibration error on CIFAR10, ImageNet, and ImageNet and their out - of - distribution variants compared to previous methods."
SP:d2f1c23b67c6744101034dc5e1c70765a733b169,"This paper proposes Sparse representation matching ( SRM ), a method to transfer intermediate knowledge obtained from one Convolutional Neural Network ( CNN ) to another by utilizing sparse representation learning. SRM first extracts sparse representations of the hidden features of the teacher CNN, which are then used to generate both pixellevel and image - level labels for training intermediate feature maps of the student network. The authors formulate SRM as a neural processing block, which can be efficiently optimized using stochastic gradient descent and integrated into any CNN in a plugand - play manner. Extensive experiments demonstrate that SRM is robust to architectural differences between the teacher and student networks, and outperforms other KD techniques across several datasets."
SP:e8c0f43bd5debf6544f588cd3442dc3dd62d0eee,"This paper proposes a novel representation learning approach to generalize policies that generalize to unseen environments. The authors introduce a theoretically motivated policy similarity metric ( PSM ) for measuring behavioral similarity between states. They also present a contrastive representation learning procedure to embed any state similarity metric, which they instantiate with PSM to obtain policy similarity embeddings ( PSEs1 ). They demonstrate that PSEs improve generalization on diverse benchmarks, including LQR with spurious correlations, a jumping task from pixels, and Distracting DM Control ( DMC )."
SP:92f3b4942da9075440dda618f561a85f8fde5a5c,"This paper proposes a new approach to disentangle natural factors of variation in data ( e.g. object shape vs pose vs pose ) based on distributed equivariant operators for disentanglement. The authors show that this approach introduces discontinuities in the encoder for a broad family of transformations acting on images —encompassing simple affine transformations such as rotations and translations. They propose an alternative, more flexible approach, based on group representation theory, which relies on distributed operators, potentially acting on the entire latent space. They theoretically and empirically demonstrate the effectiveness of their approach."
SP:ef0f58c462bc5dd1c7b78f562c42a4e17f0f252b,"This paper proposes an expectationmaximization ( EM ) algorithm to estimate the maximum posteriori ( MAP ) estimate for neural spike trains. The EM algorithm is based on three auxiliary latent variables ( Pólya - Gamma variables, latent marked Poisson processes and sparsity variables ), which are augmented to make functional connection weights in a Gaussian form, which allows for a simple iterative algorithm with analytical updates. The authors demonstrate the accuracy and efficiency performance of the EM algorithm on synthetic and real data."
SP:1156d3deac022829bda930ffcb081947609d972b,"This paper studies the gradient descent ( GD ) algorithm for training two - layer neural network models for different parameter regimes. It shows that there are two distinctive phases in the GD dynamics in the under - parameterized regime : an early phase in which the dynamics follows closely that of the corresponding random feature model, followed by a late phase where the neurons are divided into two groups : a group of “ activated ” neurons that dominate the dynamics and a group that support the continued activation and deactivation process. In particular, when the target function can be accurately approximated by a relatively small number of neurons, this quenching - activation process biases GD to picking sparse solutions. This neural network - like behavior is continued into the mildly over - parameterized regime, in which it undergoes a transition to a random featurelike behavior where the inner -layer parameters are effectively frozen during the training process. The quenched process seems to provide a clear mechanism for “implicit regularization ”."
SP:9e81401a6f30c70d870a12cce0cf600557f92b80,"This paper proposes a method to solve a CMDP problem by decomposing the CMDPs into a pair of MDPs ; reconnaissance MDP and planning MDP. In R - MDP, they train threat function, the Q - function analogue of danger that can determine whether a given state - action pair is safe or not. In P - PDP, the authors train a reward - seeking policy while using a fixed threat function to determine the safeness of each action. They also present an efficient approximation method for the threat function that can greatly reduce the difficulty of solving R - RDP. They demonstrate the efficacy of their method over classical approaches in benchmark dataset and complex collision - free navigation tasks."
SP:f1d4ac7d5516dd0df742e224c8c09c721d0d0886,"This paper studies the performance of modern neural networks trained with square loss and cross - entropy loss. The paper argues that there is little compelling empirical or theoretical evidence indicating a clear - cut advantage to the cross - entropy loss over square loss. In particular, the paper shows that the square loss produces better results in the dominant majority of NLP and ASR experiments. Cross - entropy appears to have a slight edge on computer vision tasks. The authors argue that training using square loss needs to be a part of best practices of modern deep learning on equal footing with cross - Entropy loss."
SP:915f1f0fc4850507c28c1d609239b41775863ebe,"This paper proposes a self - supervised reinforcement learning method, called Self - Predictive Representations ( SPR ), which trains an agent to predict its own latent state representations multiple steps into the future using an encoder which is an exponential moving average of the agent ’s parameters and makes predictions using a learned transition model. On its own, this future prediction objective outperforms prior methods for sample - efficient deep RL from pixels. The authors further improve performance by adding data augmentation to the future prediction loss, which forces the agent’s representations to be consistent across multiple views of an observation."
SP:983f01c170909c8c67fd3be25f121bd61bdd8307,"This paper proposes an efficient method for generating single - node representations using local PageRank computations. The paper provides theoretical guarantees on the locality of the computation, as well as the proof of the global consistency of the generated embeddings. They show empirically that their method is able to produce high - quality representations on par with state - of - the - art methods, with efficiency several orders of magnitude better in clock time and memory consumption."
SP:d11037b8fe2b10aee672ba82f69410b40181f0f9,"This paper proposes a new method for graph coarsening, GOREN, based on the Laplace operator on the coarse graph and associated projection / lift operators. The authors propose a framework for measuring the quality of the method, and show that depending on the goal, the method needs to carefully choose the La place operator and the projection operator. The method is evaluated on both synthetic and real graphs and real neural networks. Experiments show that the method significantly improves the method under various metrics, reduction ratios, graph sizes, and graph types. It generalizes to graphs of larger size, is adaptive to different losses, and scales to much larger graphs than previous work."
SP:0d680213339f0e2aedb0be4aeed51423706b8bf6,"This paper proposes a geometric deep learning method for estimating the scattering field of 3D objects based on discrete - laplacian and implicit encoders. The method is based on a point cloud approximation of each object, and each point is encoded in a high - dimensional latent space. The proposed method can accurately estimate these acoustic properties for arbitrary topologies and takes less than 1ms per object on a NVIDIA GeForce RTX 2080 Ti GPU. The authors also prove that their learning method is permutation and rotation invariant and demonstrate high accuracy on objects that are quite different from the training data."
SP:afc33a782c43e3d4c5c4fbf047d0b1108bc30bae,"This paper proposes a method to reduce the variance of training risk across training domains. The authors propose a method called Risk Extrapolation ( REx ) as a form of robust optimization over a perturbation set of extrapolated domains ( MMREx ) and propose a penalty on training risk variance ( V - REx) as a simpler variant. They show that REx can recover the causal mechanisms of the targets, while also providing some robustness to changes in the input distribution ( “ covariate shift ” )."
SP:411d5bcf7698d534ad60f581d479ff74849ba4de,"This paper proposes a new neural operator for partial differential equations ( PDEs ) based on Fourier transform. The proposed method is based on the Fourier neural operator, which is a combination of linear operators and non - linear operators. The authors show that the proposed method outperforms the state - of - the - art PDE solvers in terms of accuracy. They also show that their method is able to model turbulent flows with zero - shot super - resolution compared to previous methods."
SP:41d268d0eac9b4c84baa156fb641aa6d3060b5a4,"This paper proposes a tensor formulation of neural networks that includes fully - connected, diagonal, and convolutional networks as special cases. The authors show that gradient flow on separable classification finds a stationary point of the `2/L max - margin problem in a “ transformed ” input space defined by the network. For underdetermined regression, the authors prove that the gradient flow finds a global minimum which minimizes a norm - like function that minimizes between weighted `1 and `2 norms in the transformed input space."
SP:e27907ef4a4e6e0f5841618fcaa7e7e0db443f91,"This paper proposes a new method for optimizing the width - multipliers of slimmable neural networks. The main idea is to jointly optimize the width multipliers for different layers and the shared weights of the network. The proposed method is based on stochastic gradient descent and PareCO. The method is evaluated on 15 network and dataset combinations and two types of cost objectives, i.e. FLOPs and memory footprint, to demonstrate the effectiveness of the proposed method compared to existing alternatives."
SP:cf59403abb6ca89ccee4f8e77e9a33d99e6a00f5,"This paper proposes FedMatch, a federated semi - supervised learning ( SSL ) method for federated learning with labeled and unlabeled data. The authors propose FedMatch as a new method to tackle the problems of federated SSL based on the location of the labeled data. They consider two scenarios of FSSL based on labels - at - client and labels at - server. They show that FedMatch significantly outperforms both local SSL and the naive combination of FL with SSL algorithms under the conventional labels -at - client scenario and the novel labels-at - server scenario, across multiple clients with both non - i.i.d and i.d data."
SP:9457b6d430a2cd864d526d7e90bf3e1ab13d6df4,"This paper proposes a new method for self - supervised learning on discrete event sequences generated by real - world users. The proposed method is based on contrastive learning, previously used for audio and computer vision domains, to the discrete event sequence domain in a self - supervised setting. Unlike most previous studies, the authors justify under mild conditions that the augmentation method underlying CoLES provides representative samples of discrete events sequences. The authors evaluated CoLES on several public datasets and showed that CoLES representations consistently outperform other methods on different downstream tasks."
SP:385942a5bcee7384bb722a1669b541f2fac0cd36,"This paper proposes a new method for unsupervised dependency parsing based on a new parsing framework named StructFormer. The proposed method is based on an existing dependency - constrained self - attention mechanism. The authors propose a transformer mechanism to transform the induced dependency relations into transformer, in a differentiable manner, through a novel dependency - constraint mechanism. Experimental results show that the proposed method can achieve strong results on un - supervised dependency parsing and masked language modeling at the same time."
SP:078966ff62775bba6031e47d374bda95f4a7dde3,"This paper proposes a method to learn a metric among visual objects and scene graph nodes by incorporating information from both object features and relational features. The proposed method learns a metric between visual objects, scene graphs, and object bounding boxes. The method is evaluated on Visual Genome ( VG ) and Visual Relation Detection ( VRD ) datasets. Experiments on scene graph parsing task verify the grounding found by the model can reinforce the performance of the existing method."
SP:4644dbf7466b6234d8abf69995fdfb357efcc119,"This paper proposes two variants of the RAE framework to learn the distribution of data by minimizing a reconstruction loss together with a relational regularization on the latent space. The first variant, named mixture spherical sliced fused Gromov Wasserstein ( SSFG ), replaces the vMF distribution by a mixture of von Mises - Fisher distributions to capture multiple important areas of directions that are far from each other. The second variant, PSSFG ( PSSF ) is a power spherical distribution to improve the sampling time in high dimension settings. The authors conduct extensive experiments to show that the new proposed autoencoders have favorable performance in learning latent manifold structure, image generation, and reconstruction generation."
SP:5ae2c0af82cac89a65f1cc38c43e2d05ea298901,"This paper proposes a method to speed up training for a particular kind of deep networks which contain repeated structures, such as the transformer module. In this paper, the authors first train such a deep network with the weights shared across all the repeated layers till some point, and then stop weight sharing and continue training until convergence. The untying point is automatically determined by monitoring gradient statistics. The adaptive untying criterion is obtained from a theoretic analysis over deep linear networks. Empirical results show that their method is able to reduce the training time of BERT by 50%."
SP:a51710551142316b67e2fccd969fea1ece35ba39,"This paper studies the interaction inside adversarial perturbations to explain and boost the adversarial transferability. The authors show a negative correlation between the transferability and the interaction between the interaction and the adversarially perturbated perturbation. The negative correlation can be regarded as a unified perspective to understand current transferability - boosting methods. To this end, the authors propose a new loss to penalize interactions during the attacking process, which significantly improves the adversariatic transferability by penalizing interactions during attacking process."
SP:f1565319075c1442c2cb52d96443facb492c06c2,"This paper presents a quantitative analysis of forgetting in deep learning models. The authors show that deep layers are disproportionately responsible for forgetting, with sequential training resulting in an erasure of earlier task representational subspaces. They also provide an analytic argument and empirical picture relating forgetting to task semantic similarity, where they find that maximal forgetting occurs for task sequences with intermediate similarity, and together these show that forgetting is most severe for tasks with intermediate similarities."
SP:30d7532cdcf420bff3be6b92eea3d93bce59e6bd,"This paper proposes an efficient training algorithm for BERT and XLNet based on the Early Bird Lottery Tickets ( EBOT ). The proposed method is based on self - attention and fully - connected sub - layers inside a transformer. The method is applied to both pre - training and fine - tuning of large - scale language models. Experiments on GLUE and SQuAD show that the proposed method achieves comparable performance to standard BERT, with 35∼45% less training time."
SP:c547f23ff6caaf5e9f35d258490b86ae0ac8ed03,"This paper studies the robustness of a family of f - divergence measures for learning with noisy labels. The authors derive a nice decoupling property for this family of measures when label noise presents, where the divergence is shown to be a linear combination of the variational difference defined on the clean distribution and a bias term introduced due to the noise.   The authors then propose two solutions to make these measures robust to label noise. The first one is based on the standard robustness measure, and the second one is a variant of robustness measures based on a classifier ’s predictions and the supervised labels."
SP:841888179dcdac901889c8d62cb5234311fe28f1,"This paper proposes an ensemble - based weighted Bellman backup method for off - policy deep reinforcement learning ( RL ). The proposed method, SUNRISE, re - weights target Q - values based on uncertainty estimates from a Q - ensemble. The authors show that the proposed method stabilizes and improves learning on both continuous and discrete control benchmarks. They also specifically investigate the signal - to - noise aspect by studying environments with noisy rewards, and find that weighted bellman backups significantly outperform standard Bellman backups."
SP:afc08f203562b841180811aef943bfb63a1659ea,"This paper proposes a method for estimating uncertainty in a few - shot classification framework based on meta - learning. The authors propose a method to measure the distributional mismatch between support and query sets via class - wise similarities, and propose a novel meta - training that lets the model predict with careful confidence. The method is algorithm - agnostic and readily expanded to include a range of meta -learning models. The experiments show that the training strategy helps the model avoid being indiscriminately confident, and thereby produce calibrated classification results without the loss of accuracy."
SP:12ae325ea3bce1e60195afac7d85895d2d20c29c,"This paper proposes a novel method for learning video - text - to - video representation learning that leverages a generative model to naturally push these related samples together. Specifically, each sample’s caption must be reconstructed as a weighted combination of other support samples’ visual representations. This simple idea ensures that representations are not overly - specialized to individual samples, are reusable across the dataset, and results in representations that explicitly encode semantics shared between samples, unlike noise contrastive learning. The authors show that the proposed method outperforms state - of - the - art baseline by a large margin on MSR - VTT, VATEX - Activity, and MS for video-to - text and text -to - video retrieval retrieval."
SP:8a71d8fad25a126aff01431cacf348c05de75667,"This paper proposes a method to train a pre - trained language model ( PLMs ) for Chinese natural language processing ( NLP ) tasks based on the vocabulary provided by Google Chinese Bert Devlin et al. ( 2018 ), which is based on Chinese characters. The authors propose a novel method, seg tok, to form the vocabulary of Chinese BERT, with the help of Chinese word segmentation ( CWS ) and subword tokenization. Then they propose three versions of multi - vocabulary pretraining ( MVP ) to improve the models expressiveness. Experiments show that the proposed method improves the performances of Chinese PLMs on sentence level tasks, it can also improve efficiency ; (b ) MVP improves PLMs ’ downstream performance, especially it can improve seg - tok ’s performances on sequence labeling tasks."
SP:b93ec7bc02b48068073ffe705f71d2643e663d51,"This paper proposes a method for distributed training of graph convolutional neural networks ( GCNs ). The authors propose a method called BDS - GCN, which adopts an unbiased boundary sampling strategy to enable efficient and scalable distributed GCN training while maintaining the full - graph accuracy. The proposed method is evaluated on a variety of datasets, including Reddit and ogbn - products. Experiments are conducted to validate the effectiveness of the proposed method."
SP:2d4ba873d11e969ebd1fc31f9b5ab450c964d154,"This paper proposes a graph neural network ( GNN ) based model for quantum chemistry simulations. The main idea is to use GNN to estimate the per - atom forces of atoms in a 3D molecular structure. The model is trained using GNN with expressive message passing architecture and non - linear activation functions. Experiments show that the model outperforms state - of - the - art GNN models in predicting quantum force fields, reducing the MAE force errors by 30%."
SP:8bdcf4fe6abf4739d4732b7ea8538513135dcccc,"This paper presents a neural network generalisation bound based on Rademacher complexity that uses the distance the weights have moved from their initial values. This bound is highly relevant for fine - tuning, because providing a network with a good initialisation based on transfer learning means that learning can modify the weights less, and hence achieve tighter generalisation. Inspired by this, the authors develop a simple yet effective fine - tuned algorithm that constrains the hypothesis class to a small sphere centred on the initial pre - trained weights, thus obtaining provably better generalisation performance than conventional transfer learning. Empirical evaluation shows that their algorithm works well, corroborating their theoretical results."
SP:3a3249e97ef2345ea2264de5ed8287e16687838e,"This paper proposes to study the phenomenon of decoupling the hyperparameters for mask discovery ( Hfind ) and mask evaluation ( Heval ) in the context of model pruning. In particular, the authors propose to decouple the Hfind and Heval hyperparameter for mask evaluation. The authors show that the decoupled Hfind values lead to models which have lower performance, but generate masks with substantially higher eventual performance compared to using the same hyperparametrized for both stages. They also show that this phenomenon holds across a number of models, datasets, configurations, and also for one - shot structured pruning, and demonstrate that different H find values yield different masks with materially different layerwise pruning ratios. Finally, they show that different LPRs are causally mediated by the differences in LPR, and show that when the LPR is fixed to “ good ” LPR ( i.e. that of a high performance mask ), the previously bad hyper parameters lead to better performance and better mask generation."
SP:2d6f5d72b21675f74ff4cde4d16bfb36abd5795f,"This paper proposes a metric called m - coherence to study the alignment of per - example gradients during training of neural networks. The metric is based on gradient coherence, which is the number of examples in the sample that benefit from a small step along the gradient of any one example on average. The authors show that compared to other commonly used metrics, m - Coherence is more interpretable, cheaper to compute ( O(m ) instead of O(O(m)) ) and mathematically cleaner and is closely connected to gradient diversity, a quantity previously used in some theoretical bounds. They show the evolution of alignment of each gradients in ResNet and EfficientNet models on ImageNet and several variants with label noise, particularly from the perspective of the recently proposed Coherent Gradients theory."
SP:e7c5de9a475d0ba71bc79580e8436024fb2c6f59,"This paper proposes a method for constructing statistics for implicit generative models where the evaluation of the likelihood function is intractable but sampling data from the model is possible. The idea is to frame the task of constructing sufficient statistics as learning mutual information maximizing representations of the data with the help of deep neural networks. The infomax learning procedure does not need to estimate any density or density ratio. The authors apply their approach to both traditional approximate Bayesian computation and recent neural likelihood methods, boosting their performance on a range of tasks. With the proposed statistics, they develop two new likelihood - free inference methods namely SMCABC+ and SNL+. Experiments on tasks with various types of data demonstrate their effectiveness."
SP:c5997bf2348e94949684f45fbd418661e85220c1,"This paper proposes a fully unsupervised image - to - image translation model ( TUNIT ) that simultaneously learns to separate image domains and translate input images into the estimated domains. The proposed model achieves comparable or even better performance than the set - level supervised model trained with full labels, generalizes well on various datasets, and is robust against the choice of hyperparameters (e.g. pseudo domains )."
SP:0cd97e64e638cabbeea0fdef3e9c5b33f4000f72,"This paper studies the implicit bias of gradient descent in the training of wide neural networks and the corresponding implicit bias in function space. For 1D regression, the authors show that the solution of training a width - n shallow ReLU network is within n−1/2 of the function which fits the training data and whose difference from initialization has smallest 2 - norm of the weighted second derivative with respect to the input. The curvature penalty function 1/ζ is expressed in terms of the probability distribution that is utilized to initialize the network parameters, and they compute it explicitly for various common initialization procedures. For instance, asymmetric initialization with a uniform distribution yields a constant curvatures penalty, and hence the solution function is the natural cubic spline interpolation of training data."
SP:8b885142facbb3b8db41ec9d83822cee81324694,This paper proposes a method to fix the unstable weight decay problem in adaptive gradient methods. The authors propose a method called Stable Weight Decay ( SWD ) to fix this problem. The proposed method is based on L2 regularization and decoupled weight decay. They show that SWD improves the performance of Adam with SWD and Adam with Decoupled Weight Decay.
SP:a3206dc71e32ba1830895bf442d3840f3331a532,This paper proposes a novel method to combine the strengths of both TM and NMT to improve the translation quality of neural machine translation ( NMT ). The proposed method uses the matched sentence pair of TM as the additional signal and apply one encoder enhanced by the pre - trained language model ( PLM ) to encode the TM information and source sentence together. The authors also extend the sentence level retrieval method to the n -gram retrieval method that extends the similarity score score score from TM to the NMT decoder. They validate their proposed methods on a mixed test set of multiple domains and show that the proposed methods can significantly improve translation quality and show strong adaptation for an unknown or new domain.
SP:72b43991a242872b2ceb1861e8ffbdf26c9f4818,"This paper proposes a method for deep convolutional networks based on gradient ascent. The authors show that the gradient ascent scheme leads to a deep neural network with one iteration per layer. The network is constructed layer - by - layer in a forward propagation fashion in the form of a “ white box ” network. They show that such a network can already learn a good discriminative deep representation without any back propagation training. Moreover, they show that all linear operators of the so - derived network naturally become multi - channel convolutions when they enforce classification to be rigorously shift - invariant."
SP:f8b02cf1b918b0956761829ec6ef9127596071ec,"This paper studies the implicit acceleration of gradient flow in two - layer linear models. The authors show that implicit acceleration emerges from a conservation law that constrains the dynamics to follow certain trajectories. More precisely, gradient flow preserves the difference of the Gramian matrices of the input and output weights and the amount of acceleration depends on both the magnitude of that difference and the spectrum of the data. In addition, and generalizing prior work, the authors prove their results without assuming small, balanced or spectral initialization for the weights, and establish interesting connections between the matrix factorization problem and Riccati type differential equations."
SP:e5f086c806be88d50e461a782b5b00124f4656fb,"This paper proposes CLIME, a framework for explainable machine learning ( ML ) models. The main idea is to train a surrogate interpretable model to be locally faithful on perturbed instances, which is then used to generate explanations for the perturbed model. The authors show that LIME ’s explanations can be unstable and are susceptible to adversarial attacks as a result of out - of - distribution ( OOD ) sampling. They propose a theoretically sound framework based on uniform sampling of user - defined subspaces to mitigate the problem of OOD sampling, but also allow experts to drill down and uncover bugs and biases hidden deep inside the model. For testing the quality of generated explanations, they develop an efficient estimation algorithm that is able to certifiably measure the true value of metrics such as fidelity up to any desired degree of accuracy."
SP:b1d5ef15772e192eb8c8a0e65b3c21ee7c794295,"This paper proposes a pre - trained language model called AMBERT ( Multi - GRained BERT ) based on fine - grained and coarse grained tokenization. The authors propose to use two encoders : one encoder for processing the sequence of words and one encoder for processing sequence of phrases, and finally a sequence of contextualized representations of the words and phrases. The proposed model is evaluated on benchmark datasets for Chinese and English, including CLUE, GLUE, SQuAD, RACE, CLUE and CLUE."
SP:fd1cfe80343d3789227d99d836a5674374a234f5,"This paper proposes a neural network architecture for semantic parsing. The main idea is to incorporate Long Short - Term Memory ( LSTM ) into the Self - Attention mechanism of the original Transformer to capture more local context of phrases. Experimental results show that the proposed model captures the detailed meaning better than Transformer, raises local context awareness and achieves strong competitive performance on Geo, MSParS datasets and new SOTA performance on Atis dataset."
SP:2056a65a7500d79465685af883083cd706277c1f,"This paper proposes a new adversarial training method for deep neural networks ( DNNs ) that is designed to defend against multiple perturbations. The authors show that the proposed method is able to improve the robustness of DNN models to multiple adversarial perturbation attacks. The proposed method, called CAT, is evaluated on several benchmark datasets and models and shows that it outperforms existing adversarial defense methods by large margins in defending against the compositions of pixel perturbed and spatial transformations."
SP:006e5b9ac9a8eb7223843731488bfefbd8eb09bd,"This paper proposes a new neural network architecture called the Emergent Symbol Binding Network ( ESBN ), a recurrent network augmented with an external memory that enables a form of variable - binding and indirection. The binding mechanism allows symbol - like representations to emerge through the learning process without the need to explicitly incorporate symbol - processing machinery, enabling the ESBN to learn rules in a manner that is abstracted away from the particular entities to which those rules apply. The authors evaluate the effectiveness of the proposed architecture on a suite of tasks involving relationships among images that are governed by abstract rules and show that it is capable of learning rules from a limited number of training examples and systematically generalizing these rules to novel entities. They conclude from these results that a capacity for variable binding is a necessary component for human - like abstraction and generalization and that ESBN is a promising candidate for how to incorporate such a capacity into neural network algorithms."
SP:4171ce45966ac499f51450a19fb233934c0847f0,"This paper proposes a translation between augmented natural languages ( TANL ) framework to solve many structured prediction language tasks including joint entity and relation extraction, nested named entity recognition, relation classification, semantic role labeling, event extraction, coreference resolution, and dialogue state tracking. Instead of tackling the problem by training task - specific discriminative classifiers, the authors frame it as a translation task between natural languages, from which the task - relevant information can be easily extracted. The approach can match or outperform task -specific models on all tasks, and in particular, achieves new state - of - the - art results on joint entity extraction ( CoNLL04, ADE, NYT, and ACE2005 datasets ) and relation classification ( FewRel and TACRED ). The authors also show that their framework can also significantly improve the performance in a low - resource regime, thanks to better use of label semantics."
SP:8f1b2fc6829e0bdfcc981020b0dcf3e63a947910,"This paper studies the problem of entity recognition ( NER ) models in the unlabeled entity problem, where the entities of a sentence may not be fully annotated. The authors propose a general approach, which can almost eliminate the misguidance brought by unlabelled entities. The key idea is to use negative sampling that, to a large extent, avoids training NER models with unlabelED entities. Experiments on synthetic datasets and real - world datasets show that the proposed method is robust to unlabeling entity problem and surpasses prior baselines."
SP:dd76ece8d92a8a230a8b43033d8cb2368c677a94,"This paper proposes a novel acoustic word embedding called Acoustic Neighbor Embeddings where speech or text of arbitrary length are mapped to a vector space of fixed, reduced dimensions by adapting stochastic neighbor embedding (SNE ) to sequential inputs. The Euclidean distance between coordinates in the embedding space reflects the phonetic confusability between their corresponding sequences. Two encoder neural networks are trained : an acoustic encoder that accepts speech signals in the form of frame - wise subword posterior probabilities obtained from an acoustic model and a text encoder. Compared to a triplet loss criterion, the proposed method is shown to have more effective gradients for neural network training. Experimentally, it also gives more accurate results with low - dimensional embeddings when the two encoder networks are used in tandem in a word ( name ) recognition task, and when the encoder network is used in an approximate phonetic matching task."
SP:9142189126b8612ac0acee6fe18a0cfcb70b6545,"This paper proposes a reinforcement learning algorithm for stationary mean - field games, where the goal is to learn a pair of mean field state and stationary policy that constitutes the Nash equilibrium. The authors propose a fictitious play algorithm which alternatively updates the mean state and the policy via gradient - centred and proximal policy optimization, respectively. The algorithm is in stark contrast with previous literature which solves each single - agent reinforcement learning problem induced by the iterative updates of both mean field states and policy to the optimum. Furthermore, the authors prove that the proposed play algorithm converges to Nash equilibrium at a sublinear rate. To the best of the knowledge, this seems the first provably convergent RL algorithm for mean field games."
SP:c498f8a199da1818fe64ed88b0825c5aad688aec,"This paper studies the problem of probabilistic inference on the joint distribution defined by a normalizing flow model. Given a pre - trained flow model p(x, x1, x2 ), the authors show that this task is computationally hard for a large class of flow models. Motivated by this hardness result, they propose to train a new generative model with the property that its composition with the given model approximates the target conditional distribution. By parametrizing this new distribution as another flow model, they can efficiently train it using variational inference and also handle conditioning under arbitrary differentiable transformations. Since the resulting approximate posterior remains a flow, it offers exact likelihood evaluation, inversion, and efficient sampling. The authors provide an extensive empirical evidence showcasing the flexibility of their method on a variety of inference tasks with inverse problems."
SP:1d0f27f61c9d32911b8bd15d6b82ef5eec644f0f,"This paper proposes a new evaluation criterion for cell membrane segmentation based on high - resolution images of the cell membrane. The paper first introduces an annotated Electron Microscopy ( EM ) dataset for the Cell membrane with multiple iterative annotations and uncompressed high resolution raw data. The authors show that the current popular segmentation evaluation criteria are inconsistent with human perception, and propose a new criterion called Perceptual Hausdorff Distance ( PHD ) to measure the quality of cell segmentation results and discussion of classic segmentation methods along with two iterative manual annotation results under existing evaluation criteria and PHD is given."
SP:8ca7aff87c82be69c9542550c814f52c9419ab0a,"This paper proposes a new modular architecture for continuous learning ( CL ) based on a data - driven prior over the space of possible architectures, which allows only local perturbations around the architecture of the previous task whose features best solve the current task (§4.2 ). The authors propose a new benchmark called Benchmark Benchmark 5, which is designed to evaluate the performance of the proposed method on a new set of benchmarks. The proposed method is shown to outperform state - of - the - art methods on standard benchmarks, and much better on new and more challenging benchmarks."
SP:cc819c61f408e88f247eb87946187ccec3dad32e,"This paper proposes a novel meta - learning approach that generates meta - tasks using generative models. The proposed method is based on a generative model that generates pairs of in - class and out - of - class samples from the latent space in a principled way, allowing to create synthetic classes forming the training and validation data of a meta - task. The authors show that the proposed approach, LASIUM, outperforms or is competitive with current unsupervised learning baselines on few - shot classification tasks on the most widely used benchmark datasets."
SP:b25771e5c214a352f74ba6196fbd88bca6c43c98,"This paper studies the injectivity of generative models in the context of inverse problems and compressed sensing with generative priors. The authors show that injectivity with Gaussian matrices, a commonly used tractable model, requires larger expansivity between 3.4 and 10.5. They also show that the stability of inverting an injective network via worst - case Lipschitz constants of the inverse can be approximated by injective ReLU networks. They then use arguments from differential topology to study injectivity in deep networks."
SP:a95a153d3fe9bcf535ebf8514f51d00df483f210,"This paper proposes a continuous conditional generative adversarial network ( CcGAN ) for image generation conditional on continuous, scalar conditions ( regression labels ). Existing conditional GANs ( cGANs ) are mainly designed for categorical conditions ( e.g., class labels ), and conditioning on regression labels is mathematically distinct and raises two fundamental problems : ( 1 ) Since there may be very few ( even zero ) real images for some regression labels, minimizing existing empirical versions of cGAN losses ( ak a empirical cGAN loss ) often fails in practice ; ( 2 ) Since regression labels are scalar and infinitely many, conventional label input methods (e.g., combining a hidden map of the generator/discriminator with a one - hot encoded label ) are not applicable. The proposed ccGAN solves the above problems, respectively, by ( S1 ) reformulating existing empirical losses to be appropriate for the continuous scenario, and ( S2 ) proposing a novel method to incorporate regression labels into the generator and the discriminator. A new benchmark dataset, RC-49, is also proposed for generative image modeling conditional on regression label."
SP:10dd09ab315870631d1451d200f2c87a023f8226,"This paper proposes a novel query strategy for active learning ( AL ) and semi - supervised learning ( SSL ) to reduce the sample complexity associated with deep learning ( DL ). The authors propose an algorithm called CRC to control the convergence rate of a classification network by actively querying instances to improve the rate of convergence upon inclusion to the labeled set. The proposed algorithm is inspired by recent developments in DNN theory, namely the neural tangent kernel ( NTK ) (Jacot et al. 2018 ). Experiments show that a deep neural network trained using a combination of CRC and a recently proposed SSL algorithm can quickly achieve high performance using far less labeled samples than SL."
SP:7f3947c3fa5b09674507d8f3e10d9280376ecb94,"This paper proposes a novel federated learning method for training neural network models, where the server orchestrates cooperation between a subset of randomly chosen devices in each round. The authors point out that the minima of the local - device level empirical loss are inconsistent with those of the global empirical loss, and propose a dynamic regularizer for each device at each round, so that in the limit the global and device solutions are aligned. They demonstrate both through empirical results on real and synthetic data as well as analytical results that their scheme leads to efficient training, in both convex and non - convex settings, while being fully agnostic to device and robust to large number of devices."
SP:a3fbb073b0e2371b20d5d9df6ab829673f90354f,"This paper proposes a method to accelerate contrastive learning algorithms with little or even no loss of accuracy. The main idea is to use intermediate contrastive losses as a surrogate of the final similarity between pairs of images. The intermediate losses are introduced by truncating the back - propagation and updating only a part of the parameters for each gradient descent update. The authors propose to use the intermediate losses to filter easy regions for each image, which further reduces the computational cost. The proposed method is evaluated on ImageNet linear classification, PASCAL VOC object detection and segmentation, and MOCO V2."
SP:5b5e705ea1ee1b857e17e64d560a39052804949d,"This paper studies the global convergence and global optimality of actor - critic reinforcement learning algorithms. The authors focus on the single - time update setting, where the actor and critic are updated simultaneously. The critic update is obtained by applying the Bellman evaluation operator only once while the actor is updated in the policy gradient direction computed using the critic.   The authors show that the actor sequence converges to a globally optimal policy at a sublinear O(K−1/2 ) rate, where K is the number of iterations. They also show that under the broader scope of policy optimization with nonlinear function approximation with linear function approximation, they prove that actorcritic with deep neural network with linear or deep neural networks with linear neural network finds the globally optimality policy at sublinear rate for the first time."
SP:26705a4dc305cce336f657c5937d1f5b4209548a,"This paper proposes a new representation of log files for log processing. The authors propose to represent log files at three levels of abstraction : field level, log level, and log sequence level. The representations are in vector format and serve as interfaces to downstream applications. They use a version of Transformer Networks (TNs ) to encode numerical and textual information that is suitable for log embeddings. They show how a number of log processing applications can be readily solved with their representation."
SP:165c51a16f17fb8726e968f8b34742b62011d60e,"This paper proposes a new wavelet decomposition method for deep convolutional neural networks ( CNNs ) that is motivated by the similarities between trained CNN kernels and oriented Gabor filters for addressing this problem. The core idea is to constrain the behavior of CNNs by splitting them into a succession of wavelet packet decompositions, which are modulated by freely - trained mixture weights with the AlexNet architecture for image classification as an example. The first variant relies on the separable wavelet network transform while the other two implement the 2D dual - tree real and complex wavelet packets transforms, taking advantage of their feature extraction properties such as directional selectivity and shift invariance. The experiments show that the proposed method achieves the accuracy rate of standard AlexNet, but with a significantly lower number of parameters and an interpretation of the network that is grounded in mathematical theory."
SP:d0a284da462584724ba6a3a48c9e986d391233f6,"This paper proposes a coach - player framework for dynamic team composition of heterogeneous agents. The authors propose an attention mechanism for both the players and the coach, incorporate a variational objective to regularize learning, and design an adaptive communication method to let the coach decide when to communicate with different players. They evaluate their methods on resource - collection tasks in multi - agent particle environments. Results show comparable or even better performance against methods where players have full observation but no coach."
SP:4eb662b527d556758aaa1a0b589495fcc337fad0,"This paper studies the effect of influence functions in neural network models trained on datasets such as Iris, MNIST, CIFAR-10 and ImageNet. The authors provide a comprehensive and large - scale empirical study of successes and failures of influence function estimates in neural networks trained on a variety of datasets. They show that the network architecture, its depth and width, as well as the extent of model parameterization and regularization techniques have strong effects in the accuracy of influence estimates. They find that influence estimates are fairly accurate for shallow networks, while for deeper networks the estimates are often erroneous. They also show that for certain network architectures and datasets, training with weight - decay regularization is important to get high - quality influence estimates, and the accuracy can vary significantly depending on the test points."
SP:5fea74a2031d097a99dacf613bedcb054b0c3831,"This paper studies the relationship between the pretraining task of next word prediction and text classification. The authors propose a formalization of the connection between the two tasks and show that language models that are -optimal in cross - entropy learn features that can linearly solve such classification tasks with linearly linearly error, thus demonstrating that doing well on language modeling can be beneficial for downstream tasks. Theorem 4.2 shows a stronger result for low - dimensional softmax models by leveraging a new tool, conditional mean features ( definition 4.1 ) to be effective in practice. The usefulness of the language model features themselves is demonstrated by arguing a weak linear relationship between them and conditional mean feature distributions."
SP:a67da438e9821010284416170c3699ae7ff96c99,"This paper proposes a new method to detect if data samples were used to train a neural network model. The method is based on the idea that some images are “universally easy ” easy, and others are difficult, and the reconstruction error alone is less effective at discriminating between difficult images used in training and easy images that were never seen before. To overcome this, the authors propose to use a novel difficulty score that can be computed for each image, and its computation does not require a training set. The proposed method is evaluated on an extensive number of benchmarks demonstrating its effectiveness compared to strong baseline methods."
SP:6fe23ebe09f2a4e42a21598f8e9c79edeca99863,"This paper proposes a differentiable architecture search method by formulating it into a distribution learning problem. The continuously relaxed architecture mixing weight as random variables, modeled by Dirichlet distribution, can be easily optimized with gradient - based optimizer in an end - to - end manner. This formulation improves the generalization ability and induces stochasticity that naturally encourages exploration in the search space. Furthermore, to alleviate the large memory consumption of differentiable NAS, they propose a simple yet effective progressive learning scheme that enables searching directly on large - scale tasks, eliminating the gap between search and evaluation phases. Extensive experiments demonstrate the effectiveness of their method."
SP:c590d0ed2487b42480b53fc077546a4a0bc27a78,"This paper proposes a new method for approximating functions over low - dimensional inputs. The authors propose a new class of function approximators called multiplicative filter networks ( MFNs ), which is based on a Fourier feature representation of the input. The proposed method is similar to ReLU networks or Fourier features in positional encodings, but the authors propose to use sinusoidal nonlinearities ( SIREN ) and multiply together ( Gabor wavelet functions ) to approximate functions over linear functions. The results show that the proposed method outperforms SIRN and Fourier Feature Networks on a wide range of tasks."
SP:f5be855300f63c185a006834302bd4b033b56258,"This paper proposes an intuitive teacher - student scheme to enable the gradient - based meta - learning algorithms to explore long horizons by the inner loop. The key idea is to employ a student network to adequately explore the search space of task - specific models ( e.g., by more than ten steps ) and a teacher then takes a “leap toward the regions probed by the student ”. The teacher not only aims at a high - quality model but also defines a lightweight computation graph for meta - gradients. The proposed method performs well when applied to four meta -learning algorithms over three tasks : few - shot learning, long -tailed classification, and meta - attack."
SP:0361e02d56b7d121cb5ede1cb582284cc18fc599,This paper proposes a new algorithm for offline reinforcement learning based on behavior regularization. The algorithm is based on an analytical upper bound on KL divergence as the behavior regularizor to reduce variance associated with sample based estimations. The authors also propose a gradient penalty penalty to penalize the gradient of the Q value w.r.t the out - of - distribution actions. Experiments show that the proposed algorithm outperforms existing model - free and model - based offline RL algorithms in various datasets.
SP:b2cfb380aa2a21f72f508b453cf5949257a5b4ec,This paper proposes an adjoint training method to compress and regularize CNN - based neural networks. The proposed method trains both the original and the smaller networks together. The parameters of the smaller network are shared across both the smaller and the larger network. The authors provide theoretical guarantees on the regularization behavior of the proposed method. They also provide an empirical evaluation of both the compression and regularization behaviour of the adjoint networks.
SP:dba40073f79143e5355d194aa16db9eee0267a5d,"This paper proposes an exploration algorithm that retains the simplicity of greedy while reducing dithering. The main limitation of greedy exploration is its lack of temporal persistence, which limits its ability to escape local optima. The authors propose a temporally extended form of - greedy that simply repeats the sampled action for a random duration. It turns out that, for many duration distributions, this suffices to improve exploration on a large set of domains. Interestingly, a class of distributions inspired by ecological models of animal foraging behaviour yields particularly strong performance."
SP:5efb581a368ace3bd085d48801a899559d6a43ef,"This paper studies the implicit regularization of gradient descent with infinitesimal initialization in matrix factorization. The authors provide theoretical and empirical evidence that for depth - 2 matrices factorization, gradient flow is mathematically equivalent to a simple heuristic rank minimization algorithm, Greedy Low - Rank Learning ( GLRL ) under some reasonable assumptions. They also extend the results to the case where depth is deeper, and they show that the benefit of being deeper is that this rank - minimization is more likely to take effect for initialization with practical scale."
SP:7f997cf7a63a7330fc12fd525516080c91a3cb9b,"This paper proposes a two - stage model patching framework for improving robustness of classifiers in machine learning. The first stage is to learn semantic transformations between class features within a class and then train a classifier with data augmentations that deliberately manipulate subgroup features within the class. The second stage consists of training the classifier to learn the intra - class, inter - subgroup augmentations, and balances subgroup performance using a theoretically -motivated subgroup consistency objective. The authors demonstrate the effectiveness of the proposed method on 3 datasets, with reductions in robust error of up to 33% relative to the best baseline."
SP:de6cea1e35a0555175e17546a93422e9a96a511e,"This paper proposes a new classifier, named Rulebased Representation Learner ( RRL ), that automatically learns interpretable nonfuzzy rules for data representation. To train the non - differentiable RRL effectively, the authors project it to a continuous space and propose a novel training method, called Gradient Grafting, that can directly optimize the discrete model using gradient descent. An improved design of logical activation functions is also devised to increase the scalability of RRL and enable it to be used in scenarios demanding high model interpretability and good model expressivity."
SP:e36388a9452e557dd51bf0170bf2f9da22271a49,"This paper proposes a regret minimization algorithm ( RGM ) and its extension for structured environments. RGM builds from invariant risk minimization ( IRM ) by recasting simultaneous optimality condition in terms of predictive regret, finding a representation that enables the predictor to compete against an oracle with hindsight access to held - out environments. The structured extension adaptively highlights variation due to complex environments via specialized domain perturbations. They evaluate their method on multiple applications : molecular property prediction, protein homology and stability prediction and show that RGM significantly outperforms previous state - of - the - art baselines."
SP:cad3ed2fba57faf17a3e8899dc5a744d5358aa68,"This paper proposes a novel architecture, cross - probe BERT ( CP BERT ), for cross - modal attention in text - vision BERT. The proposed method is based on a two - tower architecture, where the vision probes and the image probes are concatenated and fed into the vision tower and generate the attended vision probes, and the attended text probes are fed into a series of cross - attention layers to exploit the cross -modal attentions. The number of text probes is considerably smaller than the number of words in the query, which makes the cost of the proposed method significantly less than that of text -vision BERT, making it more efficient. Systematic experiments conducted on two public benchmarks demonstrate state - of - the - art effectiveness and efficiency of proposed method."
SP:51fd82de525fcb738fdeaeeae20fbb2cdf975f0c,"This paper proposes a new type of Actor, named forward - looking Actor ( FORK ), for Actor - Critic algorithms. The proposed FORK can be easily integrated into a model - free ActorCritic algorithm. The experiments on six Box2D and MuJoCo environments with continuous state and action spaces demonstrate significant performance improvement for FORK. A variation of FORK - TD3 -FORK can further solve BipedalWalkerHardcore in as few as four hours using a single GPU."
SP:6e730239e6e8b43c4988dd61dca30f15dc039ef7,"This paper proposes a new aggregation method for federated learning based on Bayesian model ensemble ( BME ) based on Gaussian and Dirichlet distributions. The authors show that the proposed method can be used to aggregate local models into a global model. The proposed method is evaluated on CIFAR-10/100, Tiny - ImageNet, MobileNetV2, and ConvNet under different client conditions ( i.e., i.i.d. and non - i.d. ones ). The method is shown to outperform FEDAVG."
SP:3ac5f437fc349a33810d0645664d1c448528af74,"This paper presents a novel approach to the double blind review of BERT. The authors propose a new method for understanding BERT, which is based on a combination of two existing methods. The main contribution of this paper is to propose a novel method to understand BERT in the form of a two - blind review. The paper is well - written and well - motivated. The proposed method is very well - organized and easy - to follow."
SP:efa2343ead47263a0d09e1c17f9aa044605b9650,"This paper provides a priori upper bound on the settling time of deep neural networks based on the Lyapunov - based analysis of the loss function to derive an upper bound of finite - time convergence of neural networks. The authors formulate the supervised learning framework as a control problem where weights of the network are control inputs and learning translates into a tracking problem. An analytical formula for finite time convergence is provided to derive the upper bound under the assumptions of boundedness of input. Finally, the authors prove that their loss function is robust against input perturbations against a single neuron and multi - layer perceptron network."
SP:7a0ded4b3b2d08d43765ff7b722da9b9863aabd6,"This paper proposes a method to learn a good representation of data by using a general incompressible - flow network ( GIN ) to recover the underlying latent variables that generate the data, and thus can provide a compact and disentangled representation. The authors argue that the method taken by GIN for informative latent variables selection is not theoretically supported and can be disproved by experiments. They propose to use the mutual information between each learned latent variables and the auxiliary variable to correctly identify informative latent variable. They show the advantage of their method on various downstream tasks including classification, outlier detection and adversarial attack on both synthetic and real data."
SP:0d9ba12bbf47b13a46c2225f9dc06878418daaea,"This paper proposes a new pooling method for image classification in convolutional neural networks based on the classical Lifting Scheme from signal processing. The proposed method consists of two parts : ( 1 ) LiftDownPool decomposes a feature map into various downsized sub - bands, each of which contains information with different frequencies, and ( 2 ) LiftUpPool is a corresponding up - pooling layer that generates a refined upsampling feature map using the detail sub -bands, which is useful for image - to - image translation. The authors show the proposed methods achieve better results on image classification and semantic segmentation using various backbones using various ConvNet backbones."
SP:147239edceb17bade6ea5d3dca44e3a59998aa47,"This paper proposes a fast, distance - preserving, binary embedding algorithm to transform a high - dimensional dataset T ⊆ R into binary sequences in the cube {±1}. When T consists of well - spread ( i.e. non - sparse ) vectors, the embedding method applies a stable noise - shaped quantization scheme to Ax where A is a sparse Gaussian random matrix. The authors show that Euclidean distances among the elements of T are approximated by the ` 1 norm on the images of T under a fast linear transformation. This again contrasts with standard methods, where the Hamming distance is used instead. The method is both fast and memory efficient, with time complexity O(m ) and space complexity of O(n log n )."
SP:f65e229bca3904095743e7a501b1083cc60f1e22,"This paper proposes a new method for learning plasticity rules for neural networks. The authors argue that the plasticity rule is a proxy for Gradient Descent ( GD ) and that it can be learned by applying GD on the rule parameters. In particular, the authors propose to use the Perceptron algorithm and the Multiplicative Weights ( or Winnow ) algorithm to learn plasticity weights for recurrent neural nets ( RNNs ). Experiments are conducted to show that the proposed method is able to recover the performance of the RNN with no hidden layer and applied to a binary classification task."
SP:f435530146fa975cb27cd375a857df9bcbd87682,"This paper proposes a new method for visual question generation ( VQG ) that aims to generate human - like questions from an image and potentially other side information ( e.g. answer type or the answer itself ). To address these limitations, the authors propose a novel learning paradigm to generate visual questions with answer - awareness and region - reference. To this end, they develop a simple methodology to self - learn the visual hints without introducing any additional human annotations. Furthermore, they propose a new double - hints guided Graph - to - Sequence learning framework that first models them as a dynamic graph and learns the implicit implicit topology end to end, and then utilize a graph to sequence model to generate the questions with double hints. Their experiments on VQA2 and COCO - QA datasets demonstrate that their proposed model on this new setting can significantly outperform existing state - of - the - art baselines by a large margin."
SP:53a26ce11647866d3f6ba8b84ca9f13106197a8d,"This paper proposes a new regularization method to mitigate the double descent phenomenon in linear regression models. The authors show that optimally - tuned regularization achieves monotonic test performance as long as the sample size or the model size does not grow too much. They also demonstrate empirically that the optimal regularization can mitigate double descent for more general models, including neural networks.  "
SP:c193ccc74b987beaf8d53a29a8529a0af5e87742,"This paper introduces a novel neural network for building image generators ( decoders ) and apply it to variational autoencoders ( VAEs ) based on spatial dependency networks ( SDNs ). The authors show that augmenting the decoder of a hierarchical VAE by spatial dependency layers considerably improves density estimation over baseline convolutional architectures and the state - of - the - art among the models within the same class. Furthermore, they demonstrate that SDN can be applied to large images by synthesizing samples of high quality and coherence. In a vanilla VAE setting, they find that a powerful SDN decoder also improves learning disentangled representations."
SP:db91512a90e75675af03c2f197751c8526d6f5e9,"This paper proposes a simplified version of BCQ ( Fujimoto et al., 2018a ) for offline reinforcement learning ( offline RL ). The main contribution of the paper is the introduction of a novel backup operator, Expected - Max Q - learning ( EMaQ ), which is more closely related to the original BCQ algorithm. The proposed method is shown to be competitive with Soft Actor Critic ( SAC ) and surpasses SAC in the deployment - efficient setting ( Matsushima et al, 2020a ) in the offline RL setting."
SP:e2b80adeaa9208e0667a64a3f24661f77b48e487,"This paper proposes a batch selection algorithm called FairBatch to improve model fairness in machine learning models. The algorithm is based on batch optimization, where the inner optimizer selects the batch size and the outer optimizer optimizes the size of the batch. The authors show that the proposed algorithm outperforms existing batch selection algorithms in terms of model fairness. They also show that it is compatible with batch selection techniques intended for different purposes such as faster convergence."
SP:72f26b850bb2258223c0fc71598e35ad07d690e6,"This paper studies the bounds on the Lipschitz constant of monDEQs, a recently proposed class of deep equilibrium models. The authors show that the bounds can be bounded as a simple function of the strong monotonicity parameter of the network. They derive simple - yet - tight bounds on both the input - output mapping and the weight -output mapping defined by these networks, and demonstrate that they are small relative to those for comparable standard DNN bounds. They also show that one can use these bounds to design monotone DEQ models, even with e.g. multiscale convolutional structure, that still have constraints on the bounds. The bounds are comparable with bounds on DNNs of around depth 5 and avoid the exponential dependence on depth of those bounds."
SP:bcfd4d7fd4590e3bc248a0a5422ce4b67db74a74,"This paper proposes a method for imitation learning and goal - conditioned reinforcement learning. In both settings, the goal is to learn to reach a specified state ( a goal ) or a set of states ( a demonstration ). In imitation learning, the value function is learned by sampling expert states that the agent is currently not likely to visit and using a goal - conditioned value - function to guide the agent towards those states. In goal conditioned reinforcement learning, it is shown that the approach can circumvent the problem of sparse rewards while addressing hindsight bias in stochastic domains. The authors show that the method can learn from extremely sparse amounts of expert data and achieves state - of - the - art results on a common benchmark."
SP:d57550b2f323b356d7e609acc35ee33039f376b4,"This paper proposes a variational Bayesian inference framework for multi - task learning. The proposed method is based on variational priors, where the priors are a mixture of the prior of each task on related tasks and the mixing weights are learned in a data - driven manner for each individual task. To further leverage the shared knowledge from related tasks, the authors introduce the Gumbel - softmax prior to each task, which is a mix of variational posteriors of other related tasks. The results demonstrate the effectiveness of the proposed VMTL by extensive evaluation on four challenging benchmarks."
SP:3ccdf8322f16c8a7bef82e32fad4c03969a510d1,"This paper proposes a new benchmark suite for evaluating the model quality of long - range Transformers. The proposed benchmark suite consists of a suite of tasks consisting of sequences ranging from 1K to 16K tokens, encompassing a wide range of data types and modalities such as text, natural, synthetic images, and mathematical expressions requiring similarity, structural similarity, and visual - spatial reasoning reasoning. The authors propose a unified framework for enabling easy side - by - side comparisons of efficient Transformer models and broadly speaking, long range sequence models in general. The framework is written in JAX/FLAX1."
SP:e12e410c3335b76133ceda4c865b244fbbab8580,"This paper proposes a multilingual code summarization model for source code representation learning. The proposed model is based on a combination of source code source code and source code structure tree ( AST ). The model uses only language - agnostic features, i.e., source code features that can be computed directly from the AST. The authors show that training the model on multiple programming languages improves results on all individual languages, where the strongest gains are on low - resource languages."
SP:f46e98d48f90071831f1c0069bf74a7993be6db8,"This paper proposes a reinforcement learning approach to audio - visual navigation with two key novel elements : 1 ) waypoints that are dynamically set and learned end - to - end within the navigation policy, and 2 ) an acoustic memory that provides a structured, spatially grounded record of what the agent has heard as it moves. Both new ideas capitalize on the synergy of audio and visual data for revealing the geometry of an unmapped space. The authors demonstrate their approach on two challenging datasets of real - world 3D scenes, Replica and Matterport3D scenes. It outperforms the state - of - the - art for AudioGoal navigation by a substantial margin (8 to 49 points in SPL on heard sounds ) and generalizes much better to the challenging cases of unheard sounds, noisy audio, and distractor sounds."
SP:23bfe317dcef00a91ea92389b3f39d9b93972454,"This paper investigates the effect of weight initializations on the performance of neural networks trained to predict the two - dimensional cellular automaton Conway’s Game of Life. The authors find that networks trained on this task rarely converge to a solution, and that networks require substantially more parameters to consistently converge. They also find that the parameters that gradient descent converges to the solution are sensitive to small perturbations, such as a single sign change. Finally, they observe a critical value d0 such that training minimal networks with examples in which cells are with probability d0 dramatically increases the chance of convergence."
SP:1b5ba618d3e28d48f9205c0780f8288a08fa5392,"This paper proposes a new objective function, BatchMeanTripleT loss, for semi - supervised learning ( SSL ) based on consistency regularization, that considers not only the perturbed inputs but also the similarity among the inputs having the same label. The proposed objective function has the advantage of computational efficiency while taking into account all input samples. It achieves state - of - the - art performance across many standard SSL benchmarks with a variety of labeled data amounts, including 95.13% accuracy on CIFAR-10 with 250 labels, 77.7 % accuracy on SVHN with 100 labels, and 97.77% accuracy with 1000 labels."
SP:f3abccf4a2566ffbc821aba209fab15058639ad4,"This paper proposes a new meta - learning algorithm for learning new tasks from a small number of examples, by meta - training across static data from a set of previous tasks. The authors propose a variable - shot algorithm that can adapt to variable amounts of data and ( b ) an online version of this algorithm that addresses the above problem setting of online incremental learning. They theoretically derive their algorithm and combine it with deep neural networks for effective online learning on challenging sequential problem settings. They find that their approach can outperform empirical risk minimization and a previous online meta -learning method ( Finn et al. 2019 ) on two online image classification problems consisting of sequences of classification tasks and one online regression problem. They also find that, in the offline setting, their approach performs comparably to previous state - of - the - art algorithms in few - shot learning, and provides considerable gains in the variable - shots setting."
SP:95cb420d92ec42e12a4bbb0e66224f1c498a7161,"This paper studies the representation invariance of Transformer representations from pretrained Transformer networks pretrained with self - supervision. The authors propose a series of probes designed to test the sensitivity of the representations to several kinds of structure in sentences. The probes are designed to compare the representations from perturbed sentences against the original sentences. They use three different perturbations : ( 1 ) random permutations of n -grams of varying width, ( 2 ) swapping two spans which do or do not form a syntactic phrase, and ( 3 ) swapping of two adjacent words which do not break apart a sentence, to test sensitivity to local phrase structure. They also connect their probe results to the Transformer architecture by relating the attention mechanism to syntactic distance between two words. Results from three probes collectively suggest that Transformers build sensitivity to larger parts of the sentence along their layers, and that hierarchical phrase structure plays a role in this process. In particular, sensitivity to Local phrase structure increases along deeper layers."
SP:cb27b27a6fefc192ad1c2bd083d13eb9e51a5c44,"This paper studies the few - shot image synthesis task for GANs with minimum computing cost. The authors propose a light - weight GAN structure that gains superior quality on 1024 × 1024 resolution. The model converges from scratch with just a few hours of training on a single RTX - 2080 GPU, and has a consistent performance, even with less than 100 training samples. Two technique designs constitute their work, a skip - layer channel - wise excitation module and a self - supervised discriminator trained as a feature - encoder. They show their model ’s superior performance compared to the state - of - the - art StyleGAN2, when data and computing budget are limited."
SP:c0dbeb5d94b2388595cf7ad9675c55df0bac7f8e,This paper proposes a novel dual dual solver for neural network bounding. The proposed method is based on a linear relaxation of the number of neurons and a linear separation oracle. The authors show that the proposed method can achieve better bounds than off - the - shelf dual solvers in only a fraction of their running time and recover the speed - inaccuracy trade - off of looser duals if the computational budget is small. They also show that their method shares the benefits of previous dual approaches for weaker relaxations.
SP:56e3837417dbcce0d65338dc3aac4e1a20eb0df8,"This paper proposes an intermediate self - supervised learning method for pre - trained language models ( PTLMs ) based on the concept - aware language model ( CALM ). The main idea is to train a PTLM on a small corpus of text - to - text data and then fine - tune the model on a larger corpus of data. The authors propose two objectives : generative and contrastive objectives for learning common sense from the text, and use them as intermediate self supervised learning tasks for incrementally pre - training the model before fine - tuning on downstream datasets. The proposed method is evaluated on four commonsense - related NLU datasets ( COMMONSENSEQA, PIQA, ANLI, and COMMONGEN ) and a commonsense related NLG dataset. The results show that the proposed method outperforms baseline methods by a consistent margin and even comparable with some larger PTL Ms, which suggests that CALM can serve as a general, “plug - and - play ” method for improving the commonsense reasoning ability of a P TLM."
SP:7ec69bdee021af506293c87a3b75bce1c40a03d7,"This paper proposes a new method for unsupervised physical object discovery. The method is based on the idea that physics, especially object interactions, facilitates disentangling of 3D geometry and position of objects from video. The proposed method uses both multi - scale pixel cues and physical motion cues to accurately segment observable and partially occluded objects of varying sizes, and infer properties of those objects. The model reliably segments objects on both synthetic and real scenes. The discovered object properties can also be used to reason about physical events."
SP:66997bc19a3ba6548fcf21f114e748bea95cad1c,"This paper proposes an adversarial training method to improve robustness of deep neural networks ( DNNs ) against adversarial attacks. The proposed method increases the margins of training samples by moving the decision boundaries of the DNN model far away from the training samples to increase robustness. The method is evaluated on six publicly available datasets ( including a COVID - 19 CT image dataset ) under strong 100 - PGD white - box adversarial attack, and the results show that the proposed method significantly improved classification accuracy on noisy data while keeping a relatively high accuracy on clean data."
SP:276ffd59fbf49e3ee02756da8920218102214917,"This paper proposes ProKT, a new model - agnostic method for knowledge distillation for deep neural networks. The proposed method is based on projecting the supervision signals of a teacher model into the student’s parameter space by decomposing the training objective into local intermediate targets with approximate mirror descent technique. Experiments on both image and text datasets show that the proposed ProKT consistently achieves the state - of - the - art performance comparing to all existing knowledge distillations methods."
SP:906dc21d6988953fcf57d63bbdd12973e5818d16,"This paper proposes a novel channel pruning method to solve the problem of compression and acceleration of Convolutional Neural Networks ( CNNs ). The proposed method uses a hyper - structure network to generate the architecture of the main network, which can be optimized by regular backpropagation. The authors also use a regularization term to specify the computational resource of the compact network. Extensive experiments on CIFAR-10 and ImageNet show that the proposed method can outperform both conventional channel pruned methods and AutoML based pruning methods on ResNet and MobileNet."
SP:890fd9454596c051b0e9535baf73b1dd1fae67ca,This paper proposes a method for learning a theorem proving method that can be applied to a large knowledge base of potential premises without learning from human proofs. The method is based on a simple tf - idf ( term frequency - inverse document frequency ) based lookup in a deep reinforcement learning scenario. The authors show that their method outperforms a human proof - based method trained with imitation and reinforcement learning. The main contribution of the paper is to show that the method can outperform a human - proof based method.
SP:88209417a8ad07e6103084e41709be900303ce5f,"This paper proposes an automated data augmentation approach called MODALS ( Modalityagnostic Automated Data Augmentation in the Latent Space ) to augment data for any modality in a generic way in the latent space. The authors propose to fine - tune four universal data transformation operations in latent space to adapt the transform to data of different modalities. They demonstrate the effectiveness of MODALS on multiple datasets for text, tabular, time - series and image modalities for text and tabular data."
SP:6d84670d321b0d584b097c630574bd748e85c9a2,"This paper studies the convergence of three - layer neural networks under stochastic gradient descent training in the mean field regime. The authors show a global convergence result for unregularized feedforward 3 - layer networks in the means field regime in the form of a universal approximation property, natural of neural networks, which is shown to hold at any finite training time ( not necessarily at convergence ) via an algebraic topology argument. The main contribution of the paper is a rigorous framework to establish a mean field limit of three layer networks. The paper proposes an idea of a neuronal embedding, which comprises of a fixed probability space that encapsulates neural networks of arbitrary sizes, and is then used to prove global convergence guarantee under suitable regularity and convergence mode assumptions."
SP:b90f893f927db9c439595fd119a565cf43c971f4,"This paper proposes to learn explanations of expert decisions by modeling their reward function in terms of preferences with respect to “ what if ” outcomes. To learn these costbenefit tradeoffs associated with the expert’s actions, they integrate counterfactual reasoning into batch inverse reinforcement learning. This offers a principled way of defining reward functions and explaining expert behavior, and also satisfies the constraints of real - world decision - making, where active experimentation is often impossible ( e.g. in healthcare ). They demonstrate the effectiveness of their batch - based approach in recovering accurate and interpretable descriptions of expert behavior in the batch setting."
SP:c92916780418bfa7f0796fd9766b6d28b9eea5ef,"This paper proposes a transformer - based continuous control method based on graph neural networks ( GNNs ) for continuous control. The authors show that the proposed method AMORPHEUS outperforms GNN - based methods that use the morphological information to define the message - passing scheme. The proposed method is shown to outperform existing methods in terms of sample efficiency and final performance, and it exhibits nontrivial behaviour such as cyclic attention patterns coordinated with gaits."
SP:2cf58f5cac20dccdc2034ef60e8e46b7988ebd7d,"This paper proposes a method for visual counting based on modulated convolutions that fuse the query and the image locally. The method is called MoVie, short for Modulated Convolutional Bottlenecks, which is based on a residual bottleneck. The authors show that the method is able to achieve state - of - the - art performance on counting - specific VQA tasks while being more efficient than prior - art on difficult benchmarks like COCO for common object counting and GQA. They also show that it can be used as a general mechanism for reasoning tasks beyond counting."
SP:c64e77507e562f236cb69361b22fb1a7951ffb22,"This paper proposes a model - targeted poisoning attack that can target a desired model based on online convex optimization. Unlike previous model - targeted poisoning attacks, this attack comes with provable convergence to any achievable target classifier. The distance from the induced classifier to the target classifiers is inversely proportional to the square root of the number of poisoning points. The authors provide a lower bound on the minimum number of poison points needed to reach the target model. The attack is also efficient in incremental poisoning scenario as it works in online fashion and can incrementally find poisoning points that are nearly optimal."
SP:a526023ec4cb839b83c574d31f59a9a67bc7af00,"This paper proposes a binarization approach for efficient deep learning on point clouds. The authors propose two methods : EMA - Maximizing Aggregation ( EMA ) to modulate the distribution before aggregation for the maximum information entropy, and Layer - wise Scale Recovery ( LSR ) to efficiently restore feature representation capacity. Extensive experiments show that BiPointNet outperforms existing binarized methods by convincing margins, at the level even comparable with the full precision counterpart."
SP:825b4d1db0c537a607655bb5b4bf221ec672c8af,"This paper proposes to augment the Transformer model by adding memory tokens to store non - local representations of a sequence by adding a memory bottleneck for the global information. The paper proposes two models : MemTransformer, MemCtrl and MemBottleneck, which have dedicated general purpose tokens that can be used by the model as a placeholders to store and process global or copy of local representations. Experiments are conducted on a variety of machine translation and language modelling tasks and show that the presence of memory correlates with the model performance."
SP:f0fa1b7684bc605f6edd4813c44be20988fe8b4c,"This paper presents Prototypical Contrastive Learning ( PCL ), an unsupervised representation learning method that bridges contrastive learning with clustering. PCL not only learns low - level features for the task of instance discrimination, but more importantly, it encodes semantic structures discovered by clustering into the learned embedding space. Specifically, the paper introduces prototypes as latent variables to help find the maximum - likelihood estimation of the network parameters in an Expectation - Maximization framework. The paper proposes ProtoNCE loss, a generalized version of the InfoNCE Loss for Contrastive learning, which encourages representations to be closer to their assigned prototypes.   The paper shows that PCL outperforms state - of - the - art instance - wise contrastivelearning methods on multiple benchmarks."
SP:5342a5e1d87fd17b1a2efed967dbbfeafa440ee7,This paper proposes an orthogonal multi - path ( OMP ) block to defend neural networks from adversarial attacks. The proposed OMP block consists of a block containing multiple paths to learn robust features and the parameters of these paths are required to be Orthogonal with each other. The authors propose a forward learning and backward correction method to make the neural networks learn features that are appropriate for all the paths and hence are expected to be robust. Experiments are conducted on white - box and black - box attacks to show the effectiveness of the proposed block.
SP:776df66274ed12449fde8dcef873a593980f397c,This paper proposes a self - supervised graph attention network ( SuperGAT ) for graph attention. The proposed method is based on two attention forms ( GO and DP ). The authors analyze the effectiveness of attention forms and self - supervision : homophily and average degree. They show that GO is better at label agreement and DP at link prediction than DP. They also propose recipes to design graph attention concerning the importance of the relationships between nodes. They conduct experiments on 17 real - world datasets and show that the proposed method outperforms other methods.
SP:80a05296d6b1e4c6e9e2df01938c73029ff8487d,"This paper proposes a new dialogue system for medical automatic diagnosis ( DSMAD ) that aims to learn an agent that mimics the behavior of a human doctor, i.e. inquiring symptoms and informing diseases. The authors propose a novel DSMAD agent, INS - DS ( Introspective Diagnosis System ) consisting of two separate yet cooperative modules : an inquiry module for proposing symptom - inquiry and an introspective module for deciding when to inform a disease. They also propose two evaluation metrics to validate the reliability and robustness of DSMAD methods. Extensive experimental results demonstrate that INS -DS achieves the new state - of - the - art under various experimental settings and possesses the advantages of reliability and strength compared to other methods."
SP:10ae09d90d465125433a9b4f15b1405ab017920d,"This paper proposes a batch - wise regularization method for the Fine - Grained Visual Classification ( FGVC ) problem. The proposed method is based on the Batch Confusion Norm ( BCN ) framework, which is a batch norm - based framework with sufficient model capacity to simultaneously deal with FGVC and long - tailed issues at the same time. The method is shown to improve the performance of the FGVC model by the BCN technique by incorporating extra attention mechanism. The experimental results show that the proposed method has good potential to function as a generic regularizer for solving a wide range of classification tasks."
SP:90f1e0fe1e9678d1e9a4dcb519d4e8fd61098ce0,"This paper proposes a new method for approximate reward inference in inverse reinforcement learning ( IRL ), called AVRIL, which aims to learn an approximate posterior distribution over the reward that scales to arbitrarily complicated state spaces with an imitator policy in a completely offline manner through a variational approach to the latent reward.   The proposed method is evaluated on real medical data and classic control simulations, and it is shown to outperform the state - of - the - art Bayesian reward inference methods in both real - world and simulated control environments."
SP:ccd251d95c0a2d8dc5ad2a148ec29955e105e71e,"This paper proposes a new method for learning belief distributions for partially observable environments. The proposed method is based on an approximate auto - regressive counterfactual belief that is learned as a supervised task. The method is applied to the Hanabi benchmark game Hanabi, where it is shown to be computationally efficient compared to other methods in terms of the computational cost of the exact belief distribution."
SP:db408e6bfe69a9b3984f3b27ca92b802aa37af42,"This paper proposes a novel method to control the bias - variance trade - off between MCTS and random shooting. The proposed method is named Shoot Tree Search ( STS ), which is an interpolation between two celebrated search mechanisms. The authors show that STS can get the best of both worlds consistently achieving higher scores compared to TD(n ) in the tree search context."
SP:5efc271ccc555fd9aa542548838170bd4c98e957,"This paper proposes a new method for learning inductive bias in neural architectures by training a transformer network on synthetic datasets. The authors propose a new pre - training methodology called “ LIME ” ( Learning Inductive bias for Mathematical rEasoning ), which is based on the idea that deduction, induction, and abduction form an irreducible set of reasoning primitives. They design three synthetic tasks that are intended to require the model to have these three abilities. They specifically design these synthetic tasks in a way that they are devoid of mathematical knowledge to ensure that only the fundamental reasoning biases can be learned from these tasks. They show that models trained with LIME significantly outperform vanilla transformers on three very different large mathematical reasoning benchmarks."
SP:bb8e0b554d3b3314fa343c902d9e60f1a141ea30,"This paper studies the inductive bias of gradient descent for weight normalized smooth homogeneous neural nets, when trained on exponential or cross - entropy loss. The analysis focuses on exponential weight normalization ( EWN ), which encourages weight updates along the radial direction. This paper shows that the gradient flow path with EWN is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. These results can be extended to hold for gradient descent via an appropriateadaptive learning rate. The convergence rate of the loss in this setting is given by 1 t(log t )2, and is independent of the depth of the network."
SP:c71f9d2a602516865a0b103028186e83b52e5f00,This paper proposes a novel training method to mitigate the mode collapse problem in generative adversarial networks ( GANs ). The authors propose a new training procedure that dynamically spawns additional discriminators to remember previous modes of generation. They show that their training scheme can be plugged-in to existing GAN frameworks to mitigate mode collapse and improve standard metrics for GAN evaluation and coverage of generated samples.
SP:52c48198c95826e042f9e5a512ef3265daaff882,"This paper proposes a method to regularize BERT by pruning its attention heads based on a proxy score for head importance. The method is based on reinforcement learning and leverages reinforcement learning to automatically prune attention heads from BERT. Instead of depending on heuristics or rule - based policies, AUBER learns a pruning policy that determines which attention heads should or should not be pruned for regularization. Experimental results show that the proposed method outperforms existing pruning methods by achieving up to 9.39% better accuracy."
SP:abcbbad146f1b0d5d579c215952c95e5499a378a,"This paper proposes a method to learn correspondence between two domains of robot dynamics, i.e., simulation and real - world robot dynamics. The authors propose a cycle - consistency constraint to align dynamic robot behavior across two domains using a cycle consistency constraint. They also propose an algorithm to learn the correspondence between the two domains. The method is evaluated on a variety of problem domains, both in simulation and on real robot. The results show that the proposed method is able to find correspondence and align two domains across different modalities."
SP:006434d56992836ab9420d7d4215bc70664de304,"This paper proposes two solutions to the Shapley explainability problem, one based on generative modelling and the other based on Shapley value - function learning. The generative model provides flexible access to data imputations, while the other directly learns the value function, providing performance and stability at the cost of flexibility. While “ off - manifold ” Shapley values can ( i ) give rise to incorrect explanations, (ii ) hide implicit model dependence on sensitive attributes, and (iii ) lead to unintelligible explanations in higher - dimensional data, on - man explainability overcomes these problems."
SP:7cda6bccf08887c7cef66d0ac3ccefdea8f5d7c8,"This paper proposes a new method for opponent modelling based on variational autoencoders ( VAEs ). VAEs are trained to reconstruct the local actions and observations of the opponent based on embeddings which depend only on the local observations. The proposed method is trained via deep reinforcement learning ( DRL ). The authors provide a comprehensive evaluation and ablation study in diverse multi - agent tasks, showing that the proposed method achieves comparable performance to an ideal baseline which has full access to opponent ’s information, and significantly higher returns than a baseline which does not use the embedding learned by the authors."
SP:c239bc531bcf7293032748af29a1b786e9d893dd,"This paper proposes Consistent Contrast ( CO2 ), a method for contrastive learning based on semi - supervised learning on unlabeled data. CO2 introduces a consistency regularization term into the current contrastive training framework, which takes the similarity of the query crop to each crop from other images as “unlabeled ”, the consistency term takes the corresponding similarity of a positive crop and a negative crop as a pseudo label, and encourages consistency between these two similarities. The authors show that CO2 improves Momentum Contrast ( MoCo ) by 2.9% on top - 1 accuracy on ImageNet linear protocol, 3.8% and 1.1% top - 5 accuracy on 1% and 10% labeled semi - labeled settings. It also transfers to image classification, object detection, and semantic segmentation on PASCAL VOC."
SP:d18bab21790713e2facb053c47298fc9079ab783,"This paper studies the convergence rates of two optimization algorithms for optimization in bilinear games over the probability simplex. The authors show that the convergence rate of OMWU is linear last - iterate convergence with a learning rate whose value is set to a universal constant, and that OGDA converges exponentially fast even without the unique equilibrium assumption.   The authors also provide experimental results to further support their theory and show that for matrix games, OGDA generally converges faster than OMWU."
SP:bbc7f77308b298c332a39747f693bc396f00a89f,"This paper proposes Federated User Verification ( FedUV ), a framework for private and secure training of UV models in federated setup. In FedUV, users jointly learn a set of vectors and maximize the correlation of their instance embeddings with a secret user - defined linear combination of those vectors. They show that choosing the linear combinations from the codewords of an error - correcting code allows users to collaboratively train the model without revealing their embedding vectors. The experimental results for user verification with voice, face, and handwriting data and show that FedUV is on par with existing approaches, while not sharing the embedding with other users or the server."
SP:40fa47cc0928e2925ef5ce6d808073f368ca2cd4,"This paper proposes a method to estimate the effective dimension of class manifolds ( CMs ) by computing their intersection with random subspaces of varying dimension. The authors provide a theory for the technique and verify that their theoretical predictions agree with measurements on real neural networks. Through extensive experiments, they leverage this method to show deep connections between the geometry of CMs, generalization, and robustness. In particular, they investigate how CM dimension depends on the dataset, architecture, random initialization, stage of training, class, ensemble size, and training stage."
SP:09bce202ac7a750c3700a8ef3cd92cfe8ed00c39,"This paper proposes a novel approach to the exploration - exploitation trade - off between exploration and exploitation in reinforcement learning ( RL ). The authors argue that the agent should explore more in an unfamiliar state, while less in a familiar state, so as to understand the environment more efficiently. To this purpose, they propose Curiosity - Aware entropy Temperature for SAC ( CAT - SAC ), which utilizes the curiosity mechanism in developing an instance - level entropy temperature for each state. The proposed method is evaluated on the MuJoCo benchmark against the state - of - the - art model - based / model - free methods."
SP:dce5eb20581a21c5de0a9fc07a8a79a1fbb28c71,"This paper proposes a meta - reinforcement learning algorithm that is both efficient and extrapolates well when faced with out - of - distribution tasks at test time. The proposed method is based on a simple insight that dynamics models can be adapted efficiently and consistently with off - policy data, more easily than policies and value functions without using meta - training. To continue improving the policy, the authors leverage all data collected from other tasks during meta training, by using the learned model to relabel the next state and reward on every previously seen transition, obtaining synthetic data to continue training the policy. This enables MIER to adapt to tasks outside of the meta training distribution, outperforming prior meta - reinforcement learning methods in this setting."
SP:34d78aa11f9d50baf75a9646a6f9128318c3389a,"This paper proposes a method to address the few - shot learning ( FSL ) problem with sampling and label noise. In particular, the authors propose Eigen - Reptile ( ER ) that updates the meta - parameters with the main direction of historical taskspecific parameters to alleviate gradient noise. The authors also propose Introspective Self - paced Learning ( ISPL ) that constructs a plurality of prior models to determine which sample should be abandoned. The experiments on different tasks demonstrate that the proposed methods outperform or achieve highly competitive performance compared with the state - of - the - art methods with or without noisy labels."
SP:a571bff9ffe4edafd7bc064c4d10609e6b981ce3,"This paper proposes a new adversarial training method to improve robustness to adversarial perturbations. The authors propose to use adversarial batch normalization ( AdvBN ) to train adversarial models that are robust to distributional shifts in the mean and variance of deep image features, rather than image pixels. They show that AdvBN improves the performance of ResNet - 50 on ImageNet - C, Stylized - ImageNet, and ImageNetInstagram over standard training practices. They also show that the AdvBN can improve generalization on semantic segmentation."
SP:6a9c46bd3cf854299f360bff136e1d79d3edb2e4,"This paper proposes Variance of Gradients ( VoG ) as a proxy metric for detecting outliers in the data distribution. The authors provide quantitative and qualitative support that VoG is a meaningful way to rank data by difficulty and to surface a tractable subset of the most challenging examples for human - in - the - loop auditing. Data points with high VoG scores are far more difficult for the model to learn and over - index on corrupted or memorized examples. VoG can be computed using checkpoints stored over the course of training and is model agnostic, which makes it an unsupervised auditing tool at test time."
SP:074bfacc75837bb19049be8a2890e10de073dd8e,"This paper proposes a method to improve the generation quality of samples from deep generative models. The method is based on the gradient flow of entropy - regularized f - divergences between the real and the generated data distributions. The gradient flow takes the form of a non - linear Fokker - Plank equation, which can be easily simulated by sampling from the equivalent McKean - Vlasov process. By refining inferior samples, the proposed method avoids wasteful sample rejection used by previous methods ( DRS & MH -GAN ). Experiments on synthetic image ( CIFAR10 & STL10 ) and text ( Billion Words ) datasets demonstrate that DGf low is effective in improving samples from generative model."
SP:74ecbc5a6d464bfa49337da9e0dd6a0fe714d4bb,"This paper presents a variable encoder - decoder ( VECO ) pre - training approach to unify the two mainstreams in both model architectures and pre -training tasks. The main idea is to split the standard Transformer block into several sub - modules trained with both innersequence and cross - sequence masked language modeling, and correspondingly reorganize certain sub - module for understanding and generation tasks during inference. The proposed method outperforms all existing cross - lingual models and state - of - the - art Transformer variants on WMT14 English - to - German and English -to - French translation datasets with gains of up to 1∼2 BLEU."
SP:3d177ad50727d1a2619b68ab8a897b79d8652beb,This paper proposes to use auditory event prediction as an intrinsic motivation for Reinforcement Learning ( RL ). The authors propose to train a neural network to predict the auditory events and use the prediction errors as intrinsic rewards to guide RL exploration. They first conduct an in - depth analysis of their module using a set of Atari games. They then apply their model to audio - visual exploration using the Habitat simulator and active learning using the ThreeDWorld ( TDW ) simulator. Experimental results demonstrate the advantages of using audio signals over vision - based models as intrinsic reward for guide RL explorations.
SP:014f6118ebe55ece6be23c3a10f12e4591e444b1,"This paper proposes an end - to - end framework to jointly learn a reliable representation and assign clusters to unlabelled data. To avoid over - fitting the learnt embedding to labelled data, the authors take inspiration from self - supervised representation learning by noise - contrastive estimation and extend it to jointly handle labelled and unlabeled data. In particular, they proposed using category discrimination on labelled data and cross - modal discrimination on multimodal data to augment instance discrimination used in conventional contrastive learning approaches. They further employ Winner - Take - All ( WTA ) hashing algorithm on the shared representation space to generate pairwise pseudo labels for unlabelling data to better predict cluster assignments. They thoroughly evaluate their framework on large - scale multi - scale video benchmarks and single -modal image benchmarks, outperforming existing methods by a significant margin."
SP:4df640f502e88ddba2d7e183625231d70b083e82,"This paper proposes a weakly supervised segmentation method for image segmentation. The authors propose 4 types of contrastive contrastive relationships between pixels and segments in the feature space, capturing low - level image similarity, semantic annotation, co -occurrence, and feature affinity. The proposed method is evaluated on Pascal VOC and DensePose and shows consistent gains over the state - of - the - art ( SOTA )."
SP:f7d6099adb40a0ce2f8a3563dbd5207cf1fdea0f,"This paper proposes a simple but effective distillation strategy for unsupervised learning. The key idea is that the relationship among similar samples counts and can be seamlessly transferred to the student to boost the performance. The proposed method, BINGO, achieves new state - of - the - art performance on small scale models, i.e., 65.5% and 68.9% top - 1 accuracies with linear evaluation on ImageNet, using ResNet-18 and ResNet - 34 as backbone, respectively, surpassing baselines by a significant margin."
SP:328866aad6544c81ded8980934df31dc4472435f,"This paper proposes an adversarial approach to Simulation - based inference ( SBI ) based on generative adversarial networks ( GANs ). Specifically, the authors reformulate the variational objective in the adversarial setting to learn implicit posterior distributions, which is amortised across observations, works in high - dimensional posterior spaces and supports implicit priors. The authors evaluate GATSBI on two SBI benchmark problems and on two high - dimension simulators. On a model for wave propagation on the surface of a shallow water body, they show that it can return well -calibrated posterior estimates even in high dimensions. They also show how it can be extended to perform sequential posterior estimation to focus on individual observations."
SP:2915e82097eae4eb8546dc500f32b3ec37e3766f,"This paper considers the identification and estimation of treatment effects ( TEs ) under limited overlap, when subjects with certain features belong to a single treatment group. The authors propose a new variational autoencoder ( VAE ) based on a generative prognostic model that recovers a prognostic score, and the model identifies individualized treatment effects. The model is then learned as a new type of VAE. The TE error bounds are derived that enable representations balanced for treatment groups conditioned on individualized features. The proposed method is compared with recent methods using (semi - synthetic ) datasets using ( semi - synthetic ) datasets."
SP:ca358c9f36aac6e58ed1b3949c349d210c49a48e,"This paper proposes a framework for autonomous reinforcement learning ( ARL ), where the agent not only learns through its own experience, but also contends with the lack of human supervision to reset between trials to provide the agent with multiple attempts to provide multiple attempts. The authors introduce a simulated benchmark EARL1 around this framework, containing a set of diverse and challenging simulated tasks and challenging challenging tasks. They show that standard RL methods and methods designed for reset - free learning struggle to solve the problems in the benchmark and often get stuck in parts of the state space, underscoring the need for algorithms that can learn with greater autonomy and suggesting a path towards the development of such methods."
SP:abe51d4a9817c08f0abde5da0bb8e6ca4e02e7cf,"This paper investigates the reasoning capability of Graph Neural Networks ( GNNs ) in the context of knowledge - aware reasoning in question answering ( QA ) systems. The authors analyze the reasoning capabilities of GNN - based modules for QA systems on two popular QA benchmark datasets, CommonsenseQA and OpenBookQA. They show that existing knowledge -aware GNN modules may only carry out some simple reasoning such as counting. They also show that even a very simple graph neural counter can outperform all the existing GNN-based modules on the two popular benchmark datasets which heavily rely on knowledge - Aware reasoning."
SP:3ea5a38e7fcd9111dcd299ad039b634e2781685f,"This paper proposes a three - stage compression method for Deep Neural Networks ( DNN ) inference. The main idea of the method is to compress the representation of a DNN model into a data structure that can be queried directly on the compressed representation without decompression. The proposed method first transforms the DNN models as their proposed formulations in either Blockwise or Blockwise - wise manner. Then, the proposed method transforms the data structure using Succinct Data Structures to retrieve relevant data for DNN inference. Experiments show that the proposed compression method achieves near - optimal compression, and achieves at least 8.7X/11.5X speedup on AlexNet/VGG-16 inference compared with Huffman Coding."
SP:94c395afc794a9cc163e362078769ff83f3d20d0,"This paper proposes a new training method for improving the performance of tiny neural networks. The authors argue that training tiny models is different from training large models : rather than augmenting the data, we should augment the model, since tiny models tend to suffer from under - fitting rather than over - fitting due to limited capacity. To alleviate this issue, NetAug augments the network ( reverse dropout ) instead of inserting noise into the dataset or the network. It puts the tiny model into larger models and encourages it to work as a sub - model of larger models to get extra supervision and functioning as an independent model."
SP:9c24549b980e415616f818acbf4cf680ef8edb52,"This paper proposes a generative adversarial network ( GAN ) for dynamic point cloud sequences without requiring point correspondence annotation. The proposed model, Temporal Point cloud Upsampling GAN ( TPU -GAN ), can implicitly learn the underlying temporal coherence from point cloud sequence, which in turn guides the generator to produce temporally coherent output. In addition, a learnable masking module is proposed to adapt upsampling ratio according to the point distribution. The quantitative and qualitative evaluation demonstrates the effectiveness of the method."
SP:67efe60ad37807505369b7852bc0abed29ffdda8,"This paper proposes a new pre - training method that fully pre - trains an encoder - only transformer and smoothly finetunes it for object detection via a task adapter. The proposed method is inspired by the success of textual prompts in NLP, which treat query positional embeddings as visual prompts to help the model attend to the target area (prompting ) and recognize the object. To this end, the authors propose the task adapter which leverages self -attention to model the contextual relation between object query embedding and object detection. Experiments on the challenging COCO dataset demonstrate that the proposed PT - DETR achieves competitive performance and achieves better robustness to common corruptions."
SP:a1f9897496303984fc7ad469222106b14b4a6233,"This paper proposes a new federated learning algorithm, FedPAGE, which uses the recent optimal PAGE method ( Li et al. 2021 ) to further reduce the communication complexity of federated averaging ( FedAveraging, also known as Local - SGD ). The authors show that FedPAge uses much fewer communication rounds than previous local methods for both federated convex and nonconvex optimization, and achieves new theoretical state - of - the - art results in terms of communication complexity for both convex convex - optimization and non - convex optimization."
SP:81e74765abc6524edd8fdf9a3ba107d7bddaa04b,"This paper proposes to study the decision boundary geometry of artificial neural networks ( ANNs ) that are robust to adversarial input perturbations. The authors define adversarial subspaces, which are spanned by orthogonal directions of minimal perturbation to decision boundary from any given input sample. The decision boundary lies close to input samples in a large subspace, where the distance to the boundary grows smoothly and sub -linearly as one increases the dimensionality of the subspace. They find that the boundary is more curved within the adversarial boundary than within a random subspace of equal dimensionality. They provide new insight into the consequences of adversarial training by quantifying the increase in boundary distance within adversarial subsets, and the decrease in boundary curvature away from adversarial examples."
SP:af5c25ecf38c5c3f3387720bdc80c2c54c5699fe,"This paper proposes a weakly - supervised contrastive learning approach for visual representations based on auxiliary information. The idea is to cluster data according to its auxiliary information and learn similar representations within the same cluster and dissimilar representations for data from different clusters. The proposed approach is compared to conventional self - supervised representation learning approaches. The authors show that the auxiliary - information - infused representations bring the performance closer to the supervised representations, which use direct downstream labels as supervision signals. They also show that their approach outperforms the cross - entropy method and performs better than the CMC method."
SP:0a92fcc52970201de4a66b1e76c93dbea9dfd3f1,"This paper proposes a method to learn algorithms automatically from data. The method is based on unrolling a path - following algorithm, with some components being more flexible and learnable. The authors show the improved recovery accuracy achievable by PLISA. They also analyze the empirical Rademacher complexity of PLISA to characterize its generalization ability to solve new problems."
SP:5064eda9ba27060af15e81b2b317b2e4558b0ac4,"This paper proposes a hybrid action representation algorithm to learn a compact and decodable latent representation space for the original hybrid action space. The proposed method is based on an embedding table and conditional Variational Auto - Encoder ( VAE ). The agent is trained to be semantically smooth through unsupervised environmental dynamics prediction. Then, the agent learns its policy with conventional DRL algorithms in the learned representation space and interacts with the environment by decoding the hybrid action embeddings to the original action space, and the algorithm is evaluated in a variety of environments with discrete - continuous action space and high - dimensional action spaces. The results demonstrate the superiority of HyAR when compared with previous algorithms in representative hybrid - action benchmarks."
SP:5128bf712f6b197de113c7a371b4bec36f978eca,"This paper proposes SGEM, Stochastic Gradient with Energy and Momentum to solve a large class of general non - convex stochastic optimization problems. SGEM incorporates both energy and momentum at the same time so as to inherit their dual advantages. The paper shows that SGEM features an unconditional energy stability property, and derive energy dependent convergence rates in the general nonconvex setting, as well as a regret bound in the online convex setting. A lower threshold for the energy variable is also provided. The experimental results show that the proposed SGEM converges faster than AEGD."
SP:11f49b0a975be87769be29e85d7e3924699cf2c9,"This paper proposes a masked language model with correction ( CMLMC ) for non - autoregressive machine translation ( NAR ) models. The proposed model is based on the Conditional Masked Language Model with Correction architecture. The authors propose two modifications to the CMLM architecture to improve the performance of the model. First, the authors propose a new decoder structure that exposes the positional encodings and incorporates causal attention layers to differentiate adjacent tokens. Second, they propose a novel correction loss that teaches the model how to correct translation mistakes made in early decoding iterations from fully masked sentence. The model achieves state - of - the - art performance when trained on raw data without distillation and approaches AR performance on multiple datasets."
SP:96f8ac3c6163e56d8ae1954a162bae01e6b58a0a,This paper proposes a spiking neural network architecture inspired by the WaveNet architecture. The proposed architecture is based on a simple neural dynamics model with fixed time - constant and a simple feed - forward architecture and hence is particularly well suited for a neuromorphic implementation. The experimental results show that the proposed network beats the state - of - the - art of other artificial neural networks such as CNNs and LSTMs on several datasets for keyword - spotting.
SP:7f20a2e4e95f857140b87b0730360b3ff2f371f4,"This paper proposes a new algorithm, Shifty, that provides high - confidence behavioral guarantees that hold under demographic shift. The proposed algorithm is based on a real - world dataset of university entrance exams and subsequent student success. The authors evaluate the effectiveness of the proposed algorithm on a variety of datasets. They show that Shifty outperforms existing methods in terms of fairness guarantees. They also show that their algorithm is an effective tool for training models that are fair when demographic shift occurs."
SP:94f097921bee5fdc10ec2e7c901b2ddb876d9d41,"This paper proposes a neural - based method for solving stochastic dual dynamic programming ( SDDP ) problems. The authors propose a neural model that learns to map problem instances to a piece - wise linear value function within low - dimension space, which is architected specifically to interact with a base SDDP solver, so that it can accelerate optimization performance on new instances. The proposed Neural Stochastic Dual Dynamic Programming ( NSDDP ) continually self - improves by solving successive problems. An empirical investigation demonstrates that the proposed method can significantly reduce problem solving cost without sacrificing solution quality over competitors such as supervised learning and reinforcement learning algorithms."
SP:3d9f5132f9ec3807dbca78462a459fd123a09b24,"This paper proposes a new protocol for next - token prediction for language models that were fine - tuned on a private corpus after pre - training on a public corpus. The proposed method is based on a relaxation of group differentially private prediction. The authors show that the proposed method limits the leakage of information that is unique to any individual user in the private corpus via a relaxed of group private prediction, which allows it to thwart existing data - extraction attacks while maintaining the utility of the language model. They also show that it can effectively prevent existing data extraction attacks against GPT-2."
SP:7f524d186ea939309c7eeb843c62b6a4b4cfbc8a,"This paper proposes an unsupervised method to detect OOD samples using a k -NN density estimate with respect to a classification model’s intermediate activations on indistribution samples. The authors leverage a recent insight about label smoothing, which they call the Label Smoothed Embedding Hypothesis, and show that one of the implications is that the k-NN density estimator performs better as an OOD detection method both theoretically and empirically when the model is trained with label smoothed. They show that their proposal outperforms many OOD baselines and they also provide new finite - sample high - probability statistical results for k - NN density estimation ’s ability to detect out - of - distribution examples."
SP:aafbd6ada14cc59a272fe4bf95fac71fa18e57ab,"This paper proposes a new representation learning method based on the denoising score matching framework. The authors propose to learn an infinite - dimensional latent code which achieves improvements of state - of - the - art models on semi - supervised image classification without sacrificing image quality. The proposed method is compared with GANs and VAEs, which learn representations by directly transforming latent codes to data samples. They show how adversarial training in diffusion - based models can improve sample quality and improve sampling speed."
SP:8cfc837d5c10d539bbd098df7134c42e4830ba25,"This paper proposes an algorithm for goal - conditioned reinforcement learning ( RL ) that learns to reach distant goals by planning at training time to automatically generate a curriculum of intermediate states. The algorithm, Classifier -Planning ( C - planning ), frames the learning of the goal - conditioned policies as expectation maximization. The E - step corresponds to planning a sequence of waypoints using graph planning, while the M - step aims to learn a goal -conditioned policy to reach those waypoints. Unlike prior methods that combine goal - Conditioned RL with graph search, ours performs planning only during training and not testing, significantly decreasing the compute costs of deploying the learned policy. The authors demonstrate that their method is more sample efficient that prior methods."
SP:ef3193842e06d4a6edb8a6a86ea5bc97ee5eaa4a,"This paper extends mixup to k - mixup, which is a popular regularization technique for training deep neural networks that can improve generalization and increase adversarial robustness. It perturbs input training data in the direction of other randomly - chosen instances in the training set. To better leverage the structure of the data, the authors propose to use displacement interpolation, i.e., interpolation under the Wasserstein metric, to perturbing k - batches of training points in the directions of other k - batch instances. The authors demonstrate theoretically and in simulations that k - Mixup preserves cluster and manifold structures, and extend theory studying the efficacy of standard mixup. The empirical results show that training with k - mixingup further improves generalization, robustness and generalization across several network architectures and benchmark datasets of differing modalities."
SP:0fe6a9848026e5f6436a380199e27a9ad26cffed,This paper proposes a nonlinear kernelized classification layer for deep networks to tackle the problem of nonlinearity for representation learning. The authors show that their classification layer optimizes over all possible radial kernel functions on the space of embeddings to learn an optimal nonlinear classifier. They then demonstrate the usefulness of this layer in learning more model - efficient classifiers in a number of computer vision and natural language processing tasks.
SP:01ee8ec81619784788eb0ce9785098e437d17a7c,"This paper investigates the sources of bias in Graph Neural Networks ( GNNs ), which may lead to biased results towards underrepresented groups in subsequent tasks. The authors theoretically analyze the source of bias that is propagated towards node representations in a GNN - based learning framework. Based on the analysis, they develop novel fairness - aware graph data augmentations that can reduce potential bias in learning node representations. Their approach is adaptive to both input graph and sensitive attributes, and to the best of our knowledge, is the first study that tackles fairness enhancement through adaptive graph data augmentation design. The proposed strategies incur low additional computation complexity compared to non - adaptive counterparts, and are compatible to operate in conjunction with various GNN-based learning frameworks, including other fairness enhancement methods. Extensive experiments on node classification and link prediction are carried out over real networks in the context of graph contrastive learning."
SP:7739dc9e37f7f1384f87d2e60281e5bb27fece99,"This paper proposes a Confounder Balanced IV Regression ( CB - IV ) algorithm to jointly remove the bias from the unmeasured confounders with IV regression and achieve better bias - variance trade - off in imbalanced treatment distributions. The proposed method consists of three main modules : ( 1 ) regressing the treatment with IVs and confounder distributions in the first stage, leading to confounding bias between the predicted treatment and outcome in the second stage, ( 2 ) learning a balanced representation of Confounders representation for treatment effect estimation, and ( 3 ) outcome regression. Extensive experiments on both synthetic and real - world datasets demonstrate the effectiveness of the proposed algorithm."
SP:fdb68c39fce254b73310a3101b2fe97ba47e69fe,"This paper studies the performance of model - agnostic meta - learning ( MAML ) in a linear regression setting consisting of a mixture of easy and hard tasks, where hardness is related to the rate that gradient descent converges on the task. They show that in order to achieve substantial gain over standard non - adaptive learning ( NAL ), there must be some discrepancy in hardness among the tasks, and the optimal solutions of the hard tasks must be closely packed with the center far from the center of the easy tasks optimal solutions. They also give numerical numerical results suggesting that these insights apply to two - layer neural networks. Finally, they provide few - shot image classification experiments that support their insights and emphasize the importance of training MAMl on hard tasks in practice."
SP:e8143c7880c16ee9ce7a544e0fd80f001b1b4f9f,"This paper proposes a method for learning sparse sparse source separation ( BSS ) algorithms. The method is based on an unrolling method that leverages the data - driven knowledge stemming from realistic simulations or ground - truth data by learning both PALM hyperparameters and variables. In contrast to most existing unrolled algorithms, which assume a fixed known dictionary during the training and testing phases, this article further emphasizes on the ability to deal with variable mixing matrices ( a.k.a. a kkk a dictionary ). The proposed Learned PALM ( LPALM ) algorithm thus enables to perform semi - blind source separation, which is key to increase the generalization of the learnt model in real - world applications. The algorithm outperforms other unrolled source separation methods in the semi -blind setting."
SP:7716315001949ab88c8a216302fe51bae872fc87,This paper studies the scaling properties of transformers on the task of language modeling. The authors propose a new attention module called implicit self - attention and construct a Legendre Memory Unit based model that exhibits an O(n ) and O( n lnn ) dependency for memory and computation respectively. They show that for the same amount of training their model improves the loss over transformers about as much as transformers improve over LSTMs. They also show that adding global self -attention complements our architecture and the augmented model improves performance even further.
SP:832f422b3554e89702e13c8c5690ee26f2289e3b,"This paper proposes a two - stage GAN based on the classical GAN objective with internal conditioning on a set of space keypoints. These keypoints have associated appearance embeddings that respectively control the position and style of the generated objects and their parts. The authors propose a new method for unsupervised keypoint detection that is trained end - to - end on the classic GAN. They demonstrate that LatentKeypointGAN provides an interpretable latent space that can be used to re -arrange the generated images by re - positioning and exchanging keypoint embed dings, such as generating portraits by combining the eyes and mouth from different images."
SP:9206ae6e31077569313838504ef6daa89ad3b59c,"This paper presents a non - perturbative analysis of signal propagation in fully - connected neural networks with layer normalization using the mean field formalism. The authors show that increasing the depth leads to gradient explosion or to another undesirable phenomenon called representation shrinkage. They show that the appearance of at least one of these problems is not restricted to a specific activation function or a choice of activation function, but rather is an inherent property of the fully connected architecture itself. They also show that many popular normalization techniques fail to mitigate these problems, and show that they can also be applied to residual networks."
SP:2177be818b5843c580c787f1b2d725154846feb6,"This paper proposes a line - search method to find optimal step sizes for stochastic gradient descent automatically. The authors propose a line search method that approximates the full - batch loss with a parabola estimated over several mini - batch losses. The proposed method is evaluated on several datasets, models, and gradient noise levels. The results show that the proposed method outperforms other line search approaches for Deep Learning across models, datasets, and batch sizes."
SP:62233782f9046c85617d9ccfe8427eae7d1c9da7,"This paper proposes an algorithm to improve the performance of Noise - Contrastive estimation ( NCE ) by replacing the log loss in NCE with an exponential loss. The authors show that the resulting condition number is polynomial in the dimension and the parameter distance between P ∗ and Q when they belong to an exponential family. The proposed algorithm is shown to be a simple and effective fix to the flatness of the loss landscape in many settings, as evidenced by experimental results on synthetic and MNIST datasets."
SP:ceba6c1421b2d03863007fdaf029b8b946519c1b,"This paper studies the convergence of distributed SGD and Byzantine resilience in distributed machine learning. The authors show that the convergence holds only if the model size, batch size, and dataset size are small enough. They also show that a smaller convergence ensures better convergence. The convergence is achieved by carefully re - tuning the learning algorithm. They show that an imprudent combination of standard approaches to DP and BR might be fruitless."
SP:bc783f0c829f90931535e63687d13172879631b3,"This paper considers the problem of code editing with few exemplars. The authors propose a novel deep learning approach to solve this code editing problem automatically. The proposed method combines edit representations extracted from support exemplars and compositionally generalizes them to the query code snippet editing via multi - extended similarities ensemble. They apply the similarities measurement in multiple extents from individual nodes to collective tree representations for query and support sample matching, and ensemble the matching results through a similarity - ranking error estimator. They evaluate the proposed method on C# and Python datasets, and show up to 8.6% absolute accuracy improvements compared to existing methods by 8 - 10% in terms of absolute accuracy."
SP:ca0c4bdb02f7d939fb6de38b6b446ced4b5984a0,"This paper proposes a new generative model for generating sequence data based on relational constraints between different subcomponents of an example ( e.g., lines of a poem or measures of music ). The authors propose a program synthesis algorithm that infers the relational constraints present in the training data, and then learn a generative models based on the resulting constraint data. In the experiments, the authors show that their approach significantly improves over state - of - the - art methods in terms of capturing high - level structure in the data."
SP:692ae0c583a1585eff1a7d9c0d3b51b7879611cc,"This paper proposes a scalable model for set - to - hypergraph prediction, where the goal is to infer the set of relations for a given set of entities. The authors propose to change the asymptotic memory scaling from exponential to linear, and introduce a training method that encourages iterative refinement of the predicted hypergraph, which allows us to skip iterations in the backward pass for improved efficiency and constant memory usage. The model handles different input set sizes and varying numbers of edges, while respecting the permutation symmetry of both. The paper provides an in - depth ablation on each of the technical contributions and compare their model against prior work on common set - To - Hypergraph benchmarks."
SP:e3481fb6d8d1aa45d6ed4a454e781f5a2c30c57e,"This paper proposes a post - processing method to mitigate bias of state - of - the - art models. The proposed method consists in learning a shallow neural network, called the Ethical Module, which transforms the deep embeddings of a pre - trained model to give more representation power to the discriminated subgroups. The training is supervised by the von Mises - Fisher loss, whose hyperparameters allow to control the space allocated to each subgroup in the latent space. Besides being very simple, the resulting methodology is more stable and faster than most current methods of bias mitigation."
SP:3fb5dcc8b8fb731e09c14b16480cada1c7ccfaa7,"This paper proposes a new method for class - incremental learning ( CIL ) that leverages placebo data from a free image stream to improve the KD effect for both logit distillation and feature distillation methods. The authors propose a reinforcement - learning - based algorithm that learns a policy to adaptively produce phase - specific functions to evaluate the quality of placebos. The proposed method is evaluated on three CIL benchmarks, e.g. ImageNet-1k, ImageNet - Subset, and ImageNetNet-Subset - ImageNet, and it outperforms existing KD methods on all three benchmarks."
SP:506e0a888c03a955b708464eed3670c04baf4912,"This paper proposes a path auxiliary algorithm that uses a composition of local moves to efficiently explore large neighborhoods. The authors also give a fast version of their algorithm that only queries the evaluation of energy function twice for each proposal via linearization of the energy function. Empirically, the authors show that their path auxiliary algorithms considerably outperform other generic samplers on various discrete models for sampling, inference, and learning. Their method can also be used to train deep EBMs for high dimensional discrete data."
SP:4b466277aa5561a80c48d5e72559de4ce95f228b,"This paper presents Variational Predictive Routing ( VPR ), a neural probabilistic inference system that organizes latent representations of video features in a temporal hierarchy based on their rates of change, thus modeling data as a hierarchical renewal process. The authors propose an event detection mechanism that relies solely on the system’s latent representations ( without the need of a separate model ) to dynamically adjust its internal state following changes in the observed features, promoting an optimal organisation of representations across the levels of the model ’s hierarchical latent hierarchy. They show that VPR is able to detect event boundaries individually, be cost - effective, adjust representations to the dataset’S temporal factors of variation and produce farsighted and diverse rollouts in the environment, all of which are key advantages for agent learning and planning."
SP:459ef2e6bd7638020955dbb4d8ae1098619f7b95,This paper proposes an end - to - end and single - stage pipeline method for image retrieval based on global and attention - based Local Features Retrieval ( UGALR ). The proposed method is based on the idea of unifying global feature matching and attention based local feature retrieval. The authors show that the proposed method achieves state - of - the - art performance on two datasets with less memory and faster extraction speed compared with other popular methods.
SP:487cc308a1e8ee078c54b2158bcae47e920e73f8,"This paper proposes RotoGrad, an algorithm that jointly homogenizes gradient magnitudes and directions across tasks, while ensuring training convergence. The authors show that the proposed algorithm outperforms competing methods in complex problems, including multi - label classification in CelebA and computer vision tasks in the NYUv2 dataset. They run extensive experiments to empirically demonstrate that the algorithm leads to stable (convergent ) learning, up to complex network architectures, and outperforms competitors in multi -label classification settings in CIFAR10 and CelebA."
SP:050cd8319d84a1bd8c2ccb930ba69b33c8fb6e60,"This paper proposes a model fusion framework for fusing heterogeneous neural networks, namely, unequal width and unequal depth neural networks. The proposed method, CLAFusion, consists of three parts : cross - layer alignment, layer balancing method, and layer - wise model fusion method. The experiments demonstrate that the fused network achieves a more favorable performance compared to the individual networks trained on heterogeneous data without the need for any retraining. In addition, the fused model serves as an efficient initialization when training residual networks."
SP:f764eae15cd083fdb4eb2af09ac64c2d878a454f,"This paper studies the effect of implicit regularization in deep reinforcement learning ( DRL ) on the generalization performance of deep neural networks trained via supervised learning. The authors propose an explicit regularizer, DR3, to counter the effects of this implicit regularizer in the offline RL setting. DR3 is a simple and effective regularizer that minimizes the feature similarity between state - action pairs appearing in a bootstrapping update. Empirically, using DR3 in conjunction with existing offline RL methods provides about 60% performance improvement on the harder D4RL tasks, and 160% and 25% stability gains for REM and CQL respectively, on offline RL tasks in 17 Atari 2600 games."
SP:6fd793b27123bf80504e2ad5957455b7ec311612,"This paper proposes HyperDQN, a novel exploration method for randomized least - square value iteration ( RLSVI ) based on a probabilistic hyper - model. The proposed method is based on the meta - model, which is a non - linear neural network that predicts Q - values. The authors show that the proposed method outperforms DQN with 200M frames in terms of the maximum human - normalized score on the Atari suite and SuperMarioBros."
SP:b428383660928374c953f659ea1e05852dbdcd6e,"This paper proposes to learn causal representation from observational data by regularizing the learning procedure with mutual information measures according to the hypothetical causal graph. The optimization involves a counterfactual loss, based on which the authors deduce a theoretical guarantee that the causality - inspired learning is with reduced sample complexity and better generalization ability. Extensive experiments show that the models trained on causal representations learned by the approach is robust under adversarial attacks and distribution shift."
SP:1258c05a80a17949b50e6dae13deea1d2235f456,"This paper proposes ProgFed, a progressive training framework for efficient and effective federated learning. It reduces computation and two - way communication costs while maintaining the strong performance of the final models. The authors theoretically prove that ProGFed converges at the same asymptotic rate as standard training on full models. Extensive results on a broad range of architectures, including CNNs ( VGG, ResNet, ConvNets ) and U -nets, and diverse tasks from simple classification to medical image segmentation show that our highly effective training approach saves up to 20% computation and up to 63% communication costs for converged models."
SP:8cdaa6e0dafd750ebdb5d7a4c1987a042400662f,"This paper studies the generalization of adversarial training in deep neural networks to adversarial examples using adversarial Rademacher complexity. The authors provide a method to overcome this issue and provide upper bounds of the adversarial complexity of deep neural nets. They also provide experiments to show that the adversarially trained weight norms are larger than the standard trained weight norm, thus providing an explanation for the bad generalization performance of adversarian training."
SP:925d6bb051e9b384669fb695085b678c11f7c11a,"This paper proposes a kernel - based differential entropy estimator ( KNIFE ) based estimator for differential entropy. The method is parameterized and differentiable, and can be used to estimate differential entropy for discrete and continuous variables. It can also be used as a mutual information estimator. Experiments on visual domain adaptation, textual fair classification, and textual fine - tuning demonstrate the effectiveness of the method."
SP:d2f3beac855f0d72c13552fecb2bdb9d42195df3,"This paper proposes a new soft - greedy operator based on a probability matching scheme called resmax, which takes actions proportionally to their suboptimality gap : the residual to the estimated maximal value. It is simple to use and ensures coverage of the state - space like softmax, but focuses exploration more on potentially promising actions. It does not concentrate probability as quickly as softmax and so better avoids overemphasizing sub -optimal actions that appear high - valued during learning. The authors prove that resmax is a non - expansion for any fixed exploration hyperparameter, unlike the softmax policy which requires a state - action specific temperature to obtain a non-expansion."
SP:792ae8808aa6902758146aef1548c975492b833c,"This paper proposes an adversarial invertible transformation method to control the model's learnability on a specific dataset with a special key. The proposed method is based on adversarial adversarial transformation, which is a mapping from image to image, to slightly modify data samples so that they become “unlearnable ” by machine learning models with negligible loss of visual features. Meanwhile, one can unlock the learnability of the dataset and train models normally using the corresponding corresponding key.   The proposed learnability lock leverages class - wise perturbation that applies a universal transformation function on data samples of the same label. This ensures that the learnable can be easily restored with a simple inverse transformation while remaining difficult to be detected or reverse - engineered. The authors empirically demonstrate the success and practicability of their method on visual classification tasks."
SP:9af10703605e620e563241e2602a50b629f3d37a,"This paper proposes a new method for handling missing features in graph neural networks ( GNNs ). The proposed method is based on the Dirichlet energy and leads to a diffusion - type differential equation on the graph. The discretization of this equation produces a simple, fast and scalable algorithm which is called Feature Propagation. The authors show that the proposed approach outperforms previous methods on seven common node - classification benchmarks and can withstand surprisingly high rates of missing features."
SP:cbaa3f1379fa99159899d79ccb479c0187403aca,This paper proposes an active learning method for training a model with limited labeled data by selecting a core subset of an unlabeled data pool to label. The authors propose a Generalized Benders Decomposition algorithm to select a core set that minimizes the discrete Wasserstein distance from the unlabelled data pool. They show that this problem can be tractably solved with a generalized benders position algorithm. The method uses high - quality latent features that can be obtained by unsupervised learning on the unlabelED pool. Numerical results on several data sets show that their optimization approach is competitive with baselines and particularly outperforms them in the low budget regime where less than one percent of the data set is labeled.
SP:4c72923f78ca6590dc11e10d1a2403076a583718,This paper proposes a method to solve the de novo genome assembly problem by applying geometric deep learning to the central part of the genome assembly. The method is based on a graph convolutional network trained on a dataset generated from human genomic data to reconstruct the genome by finding a path through the assembly graph from which a genomic sequence needs to be reconstructed. They show that their model can compute scores from the lengths of the overlaps between the sequences and the graph topology which can be used to estimate the correct path. They also show that the method reconstructs the correct paths through the graph in the correct fraction of time required for the state - of - the - art de - novo assemblers. This favourable result paves the way for the development of powerful graph machine learning algorithms that can solve this problem much quicker and possibly more accurately.
SP:24de906e4289c9073b6c55c747b0913b8df5e053,"This paper proposes a meta - learning method to improve continual learning by incorporating experience replay ( ER ) into meta - training. The paper proposes to store the samples ’ representations, instead of the samples themselves, into the replay buffer. This ensures the batch nature of ER does not conflict with the online - aware nature of OML. Experimental results on a number of real - world benchmark data sets demonstrate that the proposed method outperforms the state - of - the - art. Moreover, the learned representations have better clustering structures and are more discriminative."
SP:3c78454f053f74930979a8054cd7c8a34b6fe63d,"This paper proposes Explicit Credit Assignment Joint Q - learning ( ECAQ ), a method for multi - agent cooperation based on centralized training with decentralized execution ( CTDE ). The authors propose an explicit credit assignment problem where each agent gives its suggestion about how to weight individual Q - values to maximize the joint Q - value, besides guaranteeing the Bellman optimality. Theoretically, the authors give a gradient ascent solution for this problem. Empirically, they instantiate the core idea with deep neural networks and propose explicit Credit Assignment joint Q-learning (ECAQ ) to facilitate multi -agent cooperation in complex scenarios. The results demonstrate that the proposed method achieves interpretable credit assignment and superior performance compared to several advanced baselines."
SP:0d2b225ac697679d10df25f371b2a718d4949b42,"This paper studies the robustness of adversarial learning - based defenses for adversarial robustness. The authors propose an attack framework called Greedy Model Space Attack ( GMSA ) that can be used as a new baseline for evaluating transductive - learning based defenses. They show that even weak instantiations of GMSA can break various defenses, such as DENT, URejectron, and AutoAttack. On the positive side, they report a somewhat surprising empirical result of “ adversarially adversarial training ” : Adversarially retraining the model using fresh randomness at the test time gives a significant increase in robustness against attacks we consider."
SP:e7024cae196fc5eb6a62d289a95d76b532b6a36c,"This paper proposes a method for batch normalization of neural networks based on batch renormalization. The method is based on the idea that the gradients of the model parameters are commonly averaged over the minibatch in SGD. The authors show that the gradient of the gradient can be approximated by adding a small factor increase in the training step computation and a fully per - example training procedure, which removes the extra computation at the cost of a small drop in the final model accuracy. They also show that their method is able to improve the accuracy for very small minibatches.   The authors propose a method to perform per - average gradient computation by adding an aggregation step to the gradient computation."
SP:4aa42984fcb0fd66936d668477b2719ef5c427d4,"This paper proposes a low - rank adaptation ( LoRA ) method to reduce the number of parameters required for fine - tuning a pre - trained language model. The authors propose to use a low rank representation to encode a rank decomposition matrix that is both compute - and memory - efficient. The proposed method is evaluated on a variety of tasks, including GPT-3 175B, GPT - 2, DeBERTa, and GPT 3. The results show that the proposed method outperforms the baseline method, Adam, in terms of accuracy and training time."
SP:b77a00beb0802f47810b03d3c4aa24d92781414f,"This paper proposes a regular - constrained CRF ( RegCCRF ) based on regular language L that can be used as a drop - in replacement for standard CRFs. The authors show that the proposed method is able to enforce constraints at decoding time, and that it better approximates the true data distribution. They also show that their method is distinct from approaches that enforce constraints only during decoding time. They evaluate their model empirically as an output layer of a neural network and attain state - of - the - art performance for semantic role labeling."
SP:74c186a96c12adff178264aa84ace8d04dc7d725,"This paper proposes two neural models for camera - based physiological measurement called EfficientPhys that remove the need for face detection, segmentation, normalization, color space transformation or any other preprocessing steps. Using an input of raw video frames, their models achieve state - of - the - art accuracy on three public datasets. They show that this is the case whether using a transformer or convolutional backbone. They further evaluate the latency of the proposed networks and show that their most light weight network also achieves a 33% improvement in efficiency in performance."
SP:3003bab6e3f7e2e21cd6cf27ee7d483d877d9fb3,"This paper proposes Hardware - Aware Latency Pruning ( HALP ), a method for structural pruning that aims to optimize the accuracy while constraining the latency under a predefined budget. The proposed method leverages a latency table to track latency reduction potential and global saliency score to gauge accuracy drop. The paper shows that HALP outperforms prior work in pruning efficacy and accuracy - efficiency trade - offs on both classification and detection tasks, over varying networks, on ImageNet and VOC datasets."
SP:c44d676c09c8e5a70d73b21b507b41a422fec809,"This paper proposes GraphEBM, a molecular graph generation method via energy - based models ( EBMs ) that can perform permutation invariant and multi - objective molecule generation. The authors propose to learn the energy function by contrastive divergence and generate samples by Langevin dynamics. In addition, to generate molecules with a specific desirable property, they propose a simple yet effective learning strategy, which pushes down energies with flexible degrees according to the properties of corresponding molecules. They empirically demonstrate that their approach is effective via random, single - objective, and multiobjective molecules generation."
SP:70e60fa5deef3e3ba77d05d0c3e0e7fbf396aa1d,"This paper proposes a neural - based approach to program synthesis, CROSSBEAM, which uses a neural model to learn a hands - on search policy for bottom - up synthesis, instead of relying on a combinatorial search algorithm. The neural model learns how to combine previously - explored programs into new programs, taking into account the search history and partial program executions. The proposed method is evaluated on two very different domains, string manipulation and logic programming. The authors show that CROSS BEAM learns to search efficiently, exploring much smaller portions of the program space compared to the state - of - the - art methods, and achieves nearly 100% success rate on tasks."
SP:daa044ffefe80bae16b014f60061d941ed8c2ba6,This paper proposes to replace the squared Bellman error with a functional regularizer based on regularization based on target networks. The regularization standard is explicit and enables to use up - to - date parameters as well as control the regularization. This leads to a faster yet more stable training method. The proposed method is evaluated on a range of Atari environments and shows that it outperforms target - network based methods in terms of both sample efficiency and performance.
SP:dd174014d056a7d2bc86ee99119841eafa62ed52,"This paper proposes a new perspective on designing powerful Graph Neural Networks ( GNNs ). The authors propose a new hierarchy of local isomorphism on neighborhood subgraphs and a novel neural model, called GraphSNN, which is more expressive than the Weisfeiler Lehman test in distinguishing graph structures. They empirically verify the strength of their model on different graph learning tasks. It is shown that their model consistently improves the state - of - the - art methods on the benchmark tasks without sacrificing computational simplicity and efficiency."
SP:beb9ba0261e176bfc50e9bf5bed2b6169d388285,"This paper proposes a new uncertainty quantification method for prediction intervals ( PIs ) based on linear combinations of neural networks ( NNs ). The proposed method is based on a linear combination of three NNs, each of which is independently trained using the standard mean squared error loss. The coefficients of the linear combinations are computed using root - finding algorithms to ensure tight PIs for a given confidence level for a series of confidence levels without retraining NNs and it avoids the crossing issue. The authors show that the proposed method outperforms several state - of - the - art approaches with respect to predictive uncertainty quality, robustness, and OOD samples identification."
SP:4b44a834e2212bacb4c2d9408a81f1efc76a670b,"This paper proposes a fully online meta - learning method for learning to adapt to changing tasks and input distributions. The authors propose a new algorithm called Fully Online Meta - Learning ( FOML ), which does not require any ground truth knowledge about the task boundaries and stays fully online without resetting back to pretrained weights. The algorithm is evaluated on Rainbow - MNIST and CIFAR100 datasets on a simple sequential image classification task from prior work and a more complex benchmark that is based on the Cifar100 dataset, with a sequence of 1200 tasks."
SP:fbae35cb171b3a3eb7c5d4bc83881ed7c4a70aae,This paper proposes a differentiable scaffolding tree ( DST ) that utilizes a learned knowledge network to convert discrete chemical structures to locally differentiable ones. DST enables a gradient - based optimization on a chemical graph structure by back - propagating the derivatives from the target properties through a graph neural network ( GNN ). The experiments show that DST is both effective and sample efficient. The authors also provide an explanation that helps domain experts understand the model output.
SP:61b59899cf6ae442d9f8f5226e79708a4280cfb2,"This paper proposes a method for predicting the response of patients to a target lab test result based on the drug - lab interactions and diagnosis - lab interaction graphs. The authors propose a knowledge - augmented approach to predict patients ’ response to the target lab result. The proposed method is based on a graph representation of drug interactions, diagnosis interactions, and lab interactions as graphs. It is shown that the proposed method can reduce the prediction errors by a large margin compared to one - size - fits - all."
SP:8623cebb515c4a736427449b46ad2cdf8b806b77,This paper proposes CrossMatch to improve the performance of domain generalization methods on identifying unknown classes by leveraging a multi - binary classifier. CrossMatch generates auxiliary samples out of source label space by using an adversarial data augmentation strategy. The authors also adopt a consistency regularization on generated auxiliary samples between multibinary classifiers and the model trained by SDG methods. Experimental results on benchmark datasets prove the effectiveness of CrossMatch on enhancing the performance in the OS - SDG setting.
SP:126f8ffb855aa22eda4d681a499953879ed3679e,"This paper proposes two trust - region methods for policy optimization in reinforcement learning based on Wasserstein and Sinkhorn trust regions. The main contribution of the paper is to propose a new policy optimization method based on the Lagrangian duality. The authors show that WPO guarantees a monotonic performance improvement, and SPO provably converges to WPO as the entropic regularizer diminishes. Experiments across tabular domains and robotic locomotion tasks further demonstrate the performance improvement of both approaches."
SP:999eacf6500c87205584a3256d7ca45b3016fb1c,"This paper proposes a forgetting - and - re - learning framework to improve the performance of neural networks in image classification and language emergence. The forgetting step removes undesirable information from the model, and the relearning step reinforces features that are consistently useful under different conditions. The authors propose to use the forgetting step to improve upon existing algorithms by designing more targeted forgetting operations. They provide a coherent view on the dynamics of iterative training in neural networks and show that many existing algorithms have successfully demonstrated improved performance."
SP:2789859517b6624730b14a7e010444a72d3dd3ed,"This paper studies the performance of batch RL agents trained in an offline - online setting, where the agent has access to a batch of data to train on but is also allowed to learn during the evaluation phase in an online manner. This is an extension to batch RL, allowing the agent to adapt to new situations without having to precommit to a policy. The authors show that batch RL can outperform agents trained only offline or online, sometimes by a large margin, highlighting the potential of this new setting. They find that larger datasets and a good policy can be critical to good results."
SP:76625a25e770415599a34122110d61cb3b7e614c,"This paper proposes a method for domain generalization ( DG ) via learning to reduce domain shift with an episodic training procedure. In particular, it learns to optimize Y - discrepancy between the unseen target domain and source domains only using source - domain samples. Theoretically, it gives a PAC - style generalization bound for discrepancyoptimal meta - learning and further make comparisons with other DG bounds including ERM and domain - Invariant learning. The theoretical analyses show that there is a tradeoff between classification performance and computational complexity for discrepancy - optimal meta learning. Empirically, the authors conduct experiments on DomainBed ( Gulrajani & Lopez - Paz, 2020 ) and evaluate on two DG benchmarks. Results show that their method is highly effective and achieves state - of - the - art performances."
SP:6421a9759c766641fd8c128a249f1a9c5699d19c,"This paper proposes a new method to solve PSPACE - hard planning problems by combining best - first search and Monte Carlo tree search with Deep Neural Networks ( DNN ) heuristic prediction. The authors show that DNN - based methods can solve hard planning instances beyond specialized solvers. To better understand why these approaches work, the authors studied the interplay of the policy and value networks in DNN-based best -first search on the Sokoban domain and show the surprising effectiveness of the DNN based best search. The experiments show the critical role of policy network as a powerful heuristic guiding the search, which can lead to left heavy tails with polynomial scaling by avoiding exploring exponentially sized sub - trees."
SP:84c415bc0f120d1997289f91661ff74e7297d3bd,"This paper presents an approach of meta - imitation learning by watching video demonstrations from humans to train the meta - policy with adaptive loss based on the quality of the translated data. The approach relies only on human videos and does not require robot demonstration, which facilitates data collection and is more in line with human imitation behavior. Experiments show that the method achieves the comparable performance to the baseline on fast learning a set of vision - based tasks through watching a single video demonstration."
SP:fedf5c75e83d6ab41ef9d5daa9054ffe4e424ec2,"This paper considers the problem of training deep neural networks trained with gradient - based optimizers ( SGD ). The authors argue that SGD can lead to poor generalization performance due to the large batch size of SGD. They also argue that large batch sizes are useful for speeding up the training process by leveraging parallel GPUs and leveraging hyper - parametrized learning rate and batch normalization.   The authors propose to train a neural network with batch sizes of 8k to 8k without loss in generalization. They argue that this can be achieved by fine - tuning parameters like learning rate, batch normalisation, and batch size. They show that small batch sizes yield better generalization results."
SP:819df8d847a99f13ed5efdcabae8b464c12b464b,"This paper proposes a partial G - CNN method for learning equivariant neural networks. The main idea is to learn a family of networks able to learn partial and full equivariances from data at every layer end - to - end end - end. The authors show that partial equivariance allows their networks to improve upon conventional G -CNNs for tasks for which full equivariances are harmful. However, whenever beneficial, their models learn to stay fully equivariant and match the performance of G-CNNs."
SP:0c0ca9df96f1fa2eb8b83a47d0d5964590fef290,"This paper proposes an amortized Langevin dynamics ( ALD ) method to replace the MCMC iterations with updates of an inference model that maps observations into latent variables. ALD can be extended to sampling from an unconditional distribution such as an energy - based model, enabling more flexible generative modeling by applying it to the prior distribution of the latent variable. Based on ALD, the authors propose a new deep latent variable model named the Langevin autoencoder - like posterior inference and sampling from the latent space EBM. The authors show that ALD converges significantly faster than traditional MCMC methods."
SP:5631097031c7e599bdeae64366ffa6e4558837c6,This paper proposes a new neural network model for hypergraph reasoning based on sparsity regularization. The proposed model is based on neural networks and finite - domain quantification operations to infer new facts based on the input facts. The model is trained via sub - graph sampling and label calibration and achieves state - of - the - art performance on several real - world knowledge graph reasoning benchmarks.
SP:9657121b01c51f78c00d06b47d3e8d678dd85d54,"This paper proposes a new family of differentiable top - k cross - entropy classification losses based on the assumption that k is a positive integer such as 1 or 5. The authors propose to draw k from a probability distribution for training based on differentiable sorting and ranking. They find that relaxing k does not only produce better top - 5 accuracies, but also makes models more robust, which leads to top - 1 accuracy improvements. When finetuning publicly available ImageNet models, they achieve a new state - of - the - art on ImageNet for publicly available models with an 88.37% top -1 and a 98.68% top-5 accuracy accuracy."
SP:cb3188f435c54a365890e20e4d582c250d919833,"This paper proposes a method for solving large - scale optimal transport ( OT ) problems at an unprecedented combination of speed and accuracy. The method is built on the celebrated Douglas - Rachford splitting technique, which tackles the original OT problem directly instead of solving an approximate regularized problem, as many state - of - the - art techniques do. This allows to provide sparse transport plans and avoid numerical issues of methods that use entropic regularization. The algorithm has the same cost per iteration as the popular Sinkhorn method, and each iteration can be executed efficiently, in parallel, in parallel. The proposed method enjoys an iteration complexity O(1/ ) compared to the best - known O( 1/ ) of the Sinkshorn method. In addition, the authors establish a linear convergence rate for their formulation of the OT problem, which maintains a primal - stopping criterion at no extra cost."
SP:9a087cc734a3e7f3ab848bef5e2eff37fe40f303,"This paper proposes a framework for disentangling performance gaps in federated learning from unseen client data gaps. The authors propose a semantic synthesis strategy that enables realistic simulation without naturally - partitioned data. They observe and explain differences in behavior across natural and synthetic federated datasets, indicating that dataset synthesis strategy can be important for realistic simulations of generalization. They use their results to inform a series of recommendations for future works studying generalization in FL across six tasks."
SP:da0e8c89f343abfe500eb4c1968e418c2fb52ef6,"This paper proposes to study the performance of prompt - based language models ( PLMs ) in the zero - shot setting. The authors propose to use three BERT models from the most popular BERT family to launch the empirical study on 20 different datasets. They are surprised to find that a simple Multi - Null Prompting ( without manually created prompts ) strategy can yield very promising results on a few widely - used datasets, e.g. IMDB dataset, and 86.22%(±2.71 ) accuracy on the Amazon dataset. However, they also observe some limitations of PLMs under the zero shot setting, particularly for the language understanding tasks."
SP:9817dccb1a121058b23a2ef825ed339cf8b53674,This paper proposes a sharpener module to improve the alignment of attention mechanism in attention mechanism. The sharpener is a module that aims to align relevant parts of the encoded image with the target output. The paper proposes to use an image region - based sharpener to align the target with the image region of the input image. The proposed method is evaluated on synthetic handwritten and real - world scene text recognition datasets. Experiments show that the proposed method outperforms the mainstream ones such as soft and hard attention.
SP:3913ed3b3cf6494368e3be6cacb637ff85f80ee6,This paper proposes a novel approach to learning to solve combinatorial optimization problems for the vehicle routing problem. The authors propose a supervised deep learning framework that constructs a complete tour plan from scratch while respecting an apriori fixed number of available vehicles. The proposed approach is evaluated against several state - of - the - art deep learning and OR solvers through a thorough and unified experimental evaluation protocol that ensures comparability amongst different ML - based approaches. They show that their approach delivers competitive results in comparison to approaches that work only for unbounded fleet sizes and outperforms these methods when considering fixed vehicle costs.
SP:594a813c0d0baa66738b9c8331370f861ad3c416,This paper proposes a novel link prediction method for graph learning based on counterfactual inference. The authors propose to train a link prediction model based on causal inference to predict the existence of a link between a pair of nodes in a graph. The proposed method is based on GNN - based link prediction. The method is evaluated on several benchmark datasets and compared to a number of baselines.
SP:48a7e50451b887f55be17b2662aa11ce18791cc1,"This paper proposes a two - stage unsupervised feature selection method based on knowledge contrastive disTillation ( SOFT ) model that incorporates the second - order covariance matrix with the first - order data matrix for feature selection. In the first stage, we learn a sparse attention matrix that can represent second order relations between features, and in the second stage we build a relational graph based on the learned attention matrix and perform graph segmentation. Experimental results on 12 public datasets show that SOFT outperforms classical and recent state - of - the - art methods, which demonstrates the effectiveness of our proposed method."
SP:14bcae11aeede63f28d1b80c05ed18a01d3e3f3c,"This paper proposes a new multimodal multi - modal VAE model that avoids explicit combinations by repurposing semisupervised VAEs to combine information between modalities implicitly through mutual supervision. This formulation naturally allows learning from partiallyobserved data where some modalities can be entirely missing, something that most existing approaches either cannot handle, or do so to a limited extent. The paper shows that MEME outperforms baselines on standard metrics across both partial and complete observation schemes on the MNIST - SVHN ( image - image ) and the less common but notably more complex CUB (image - text ) datasets."
SP:e834a52cadebe5f125ce491273b4ad1146beae3f,"This paper proposes Deep Explore Options, a method to combine intrinsic rewards and extrinsic rewards in reinforcement learning. The authors propose a transition selection algorithm called J - PER, a new transition algorithm based on the interest of multiple agents. They show that the proposed method can learn from multiple intrinsic rewards, ignore harmful intrinsic rewards. They also show that it can learn to balance exploration and exploration but also isolate exploitative or exploratory behaviors."
SP:41578dd1a4bdb043b3d68afa5f9cebb3e14f3907,"This paper proposes a new method for learning Hamiltonian dynamical systems from data. The method is based on a stiffness - aware neural network ( SANN ) that splits the training data into stiff and nonstiff portions based on the stiffness aware index. The authors show that SANN is more stable and can better preserve energy when compared with the state - of - the - art methods, leading to significant improvement in accuracy. They validate the SANN method with complex Hamiltonian dynamics including a three - body problem and billiard model."
SP:bfb0a059eeb6f40a18fbd20c0eec5037a64ca09e,"This paper studies the ability of large pre - trained language models to perform complex multistep computations. The authors train Transformers to perform multi - step computations by asking them to emit intermediate computation steps into a “ scratchpad ”. They show that these same models are able to perform these complex computations even in the few - shot regime when asked to perform the operation “ step by step ”, showing the results of intermediate computations, and show that training Transformers to emit full program traces line by line annotated with local variables dramatically improves their ability to predict the result of executing a given computer program on a given input."
SP:e6c1a8b4bba287455dc9cf145b6bd1f04e2148a9,"This paper proposes a novel adversarial attack method for adversarial adversarial perturbations against deep networks. The proposed method is based on deep image generators and a novel optimization objective. The authors show that the adversarial attacks are able to generate targeted feature - level attacks at the ImageNet scale that are simultaneously interpretable, universal to any source image, and physically - realizable. These attacks can also reveal spurious, semantically -describable feature / class associations that can be exploited by novel combinations of natural objects. They use them to guide the design of “ copy / paste ” adversaries in which one natural image is pasted into another to induce an unrelated misclassification. Based on these findings, the authors emphasize the importance of cautious deployment for vision networks and their fortification against these types of feature level adversarial Attacks."
SP:873618263dc4246a39c44d0abfecfb5f688817e3,"This paper proposes a new method for solving stochastic annealing ( SA ) problems. The proposed method is based on a reinforcement learning approach, where the proposed proposal distribution is used as a policy, which can be optimised for higher solution quality given a fixed computational budget. The authors show that the proposed method outperforms baselines with hand - selected parameters on a number of problems, including Rosenbrock ’s function, the Knapsack problem, the Bin Packing problem, and the Travelling Salesperson problem."
SP:cae31f7436920eb3946e3f5bca0ac88a73d7c3ec,"This paper proposes a novel measure of the non - stationarity of a policy sequence in cooperative multi - agent reinforcement learning ( MARL ). The authors introduce a novel notion, the $ \delta$-stationarity measurement, to explicitly measure the    non - Stationarity of the policy sequence, which can be further proved to be bounded by the KL - divergence of consecutive joint policies. A straightforward but highly non - trivial way is to control the joint policies’ divergence, which is difficult to estimate accurately by imposing the trust - region constraint on the joint policy. Although it has lower computational complexity to decompose the joint joint policy and impose trust -region constraints on the factorized policies, simple policy factorization like mean - field approximation will lead to more considerable policy divergence. The proposed algorithm could bring noticeable and stable performance improvement in multiple cooperative tasks of different complexity than baselines."
SP:989b58167a15ae4fafbe27ff534d327991b6c4d7,This paper proposes a self - supervised representation learning framework for audio - visual speech representation learning. The proposed method is based on a multi - stream audio / visual hidden unit representation learning model. The model is trained on audio - only speech recognition data and self - trained on video - visual representation learning data. The authors show that the proposed method outperforms the state - of - the - art HuBERT model on the lip - reading benchmark LRS3 with only 30 hours of labeled data.
SP:7c9eb8aa4a4dcb5965157d860e812d81654e3aa7,"This paper proposes a novel algorithm, ECORD, for reinforcement learning ( RL ) based on graph neural networks ( GNNs ). The main idea of ECORD is to restrict the GNN to a single pre - processing step, before entering a fast - acting exploratory phase directed by a recurrent unit. ECORD achieves a new SOTA for RL algorithms on the Maximum Cut problem, whilst also providing orders of magnitude improvement in speed and scalability. The authors show that ECORD reduces the optimality gap by up to 73 % on 500 vertices graphs with a decreased wall -clock time."
SP:f741d980c9c560a21298e947f1605dcbab7ceeac,"This paper proposes a new method for training VAEs with discrete latents. The proposed method is based on a variational optimization approach, where the latent variables are represented by truncated posteriors. The authors show that it is possible to train discrete VAEs without the use of sampling approximation, reparameterization trick and amortization. They also show that the proposed method can be used to train VAEs in a zero - shot learning setting."
SP:deb189d37bd51b92762ce259a106d9a9e9d81ea4,"This paper proposes an unsupervised method based on counterfactual measures of blame to identify effects on the environment controlled by the agent. The controlled effect network ( CEN ) is evaluated in a wide range of environments showing that it can accurately identify controlled effects. The authors evaluate CEN as an intrinsic motivator by integrating it in the state - of - the - art exploration method, achieving substantially better performance than action - prediction models."
SP:ea18d57904e25fd09ed0f6c9972029d78779a8a6,"This paper proposes structure - regularized pruning ( SRP ), which imposes regularization on the pruned structure to make sure the locations of pruned filters are aligned across different layers. SRP is applied to train efficient image SR networks, resulting in a lightweight network ( named SRPN - L ) and a very deep one ( SRPN ). The authors conduct extensive comparisons with both lightweight and larger image SR network networks. They achieve superior performance gains over recent methods quantitatively and visually."
SP:0dee45001ae9600f485614dfe6874a516ac01db5,"This paper proposes a framework for few - shot learning called ConFeSS ( Contrastive Learning and Feature Selection System ) that tackles large domain shift between base and novel categories. The first step of the framework trains a feature extracting backbone with the contrastive loss on the base category data. The second step trains a masking module to select relevant features that are more suited to target domain classification. Finally, a classifier is fine - tuned along with the backbone backbone such that the backbone produces features similar to the relevant ones. The method is evaluated on the new CDFSL benchmark ( Guo et al. 2020 )."
SP:92aa611d71a8da597358330d84fddbb90de2cf4f,"This paper studies the effect of gradient descent on the generalisation of neural networks trained by Bayesian inference and finite - width gradient descent trained by gradient descent. The authors show that gradient descent can improve generalisation by selecting networks with a large margin. They use a new theoretical tool to estimate the average test error of the neural network - Gaussian process ( NNGGP ) posterior. This error is found to be already better than chance, corroborating the findings of Valle - Pérez et al. ( 2019 ) and underscoring the importance of architecture. They also show that test performance can be substantially improved by selecting a function with much larger margin than the typical NNGP posterior."
SP:a0e3cf719a95bbc5aad2f663ba5a3169c316ee9b,"This paper proposes a method to improve the performance of cross - lingual transfer methods. The authors propose a method called X - Mixup, which adaptively calibrates the representation discrepancy and gives compromised representations for target languages. Experiments on the XTREME benchmark show X -Mixup achieves 1.8% performance gains on multiple text understanding tasks, compared with strong baselines, and reduces the cross -lingual representation discrepancy significantly."
SP:19f8cd8f0c274b6141ba097d2ebb6d18af0986fd,"This paper studies Byzantine robust distributed distributed learning, where a central server wants to train a machine learning model over data distributed across multiple workers. However, a fraction of these workers may deviate from the prescribed algorithm and send arbitrary messages to the server. The authors propose a simple bucketing scheme that adapts existing robust algorithms to heterogeneous datasets at a negligible computational cost. They also theoretically and experimentally validate their approach, showing that combining bucketing with existing robust algorithm is effective against challenging attacks."
SP:4d63513b9a1b9b9fc44a69b3d5679a8f48eb95e7,This paper studies the relationship between disentanglement and multi - task learning based on hard parameter sharing. The authors propose a set of standard metrics to measure the degree to which disentangled representations are obtained by neural networks trained on automatically generated supervised tasks. They show that disentangling appears naturally during the process of multi - tasks neural network training. They verify their hypotheses by training multiple models in single - and multi task settings and investigating the level of disentangle achieved in their latent representations. They find that in a hard - parameter sharing scenario multi -task learning indeed seems to encourage disentangles.
SP:9851adb72e2918780f661f83f7da06eb866787be,"This paper proposes two types of robustness certification criteria : robustness of per - state actions and lower bound of cumulative rewards. The authors propose a local smoothing algorithm that uses a policy derived from Q - functions smoothed with Gaussian noise over each encountered state to guarantee the robustness. They also propose a global smoothing method for certifying the robusts of a finite - horizon cumulative reward under adversarial state perturbations.   The authors evaluate their methods on three Atari games, including adversarial training and several forms of regularization, on three representative Atari games. They show that RegPGD, RegCVX, and RadialRL achieve high certified robustness among these algorithms, and their certifications are often tight."
SP:78da3c97182ec1baf6a131740bf7c91a9afb2fd2,"This paper proposes a new approach to conformal prediction in which it aims to output a precise set of promising prediction candidates that is guaranteed to contain a limited number of incorrect answers. This is particularly relevant to large - scale settings where the cost (monetary or otherwise ) of false positives is substantial, such as in - silico screening for drug discovery, where any positively identified molecular compound is then manufactured and tested. The authors propose to trade coverage for precision by enforcing that the presence of incorrect candidates in the predicted conformal sets is bounded according to a user - specified tolerance. They then optimizes for a generalized notion of set coverage ( i.e., the true positive rate ) that allows for any number of true answers for a given query ( including zero ). They demonstrate the effectiveness of this approach across a number of classification tasks in natural language processing, computer vision, and computational chemistry."
SP:b126d2f3c397633745c8833e22ace93a2470e963,"This paper studies the behavior of ReLU networks with random initialization. The authors show that the expected length distortion does not grow with depth, and indeed shrinks slightly, for ReLU network with standard random initialization, and generalize this result by proving upper bounds both for higher moments of the length distortion and for the distortion of higher - dimensional volumes. The theoretical results are corroborated by their experiments."
SP:b3b6d0512edfca461ea295ee8665f7f226c45d57,"This paper proposes SAFER, a behavioral prior learning algorithm that accelerates policy learning on complex control tasks, under safety constraints. Through principled contrastive training on safe and unsafe data, SAFER learns to extract a safety variable from offline data that encodes safety requirements, as well as the safe primitive skills over abstract actions in different scenarios. The authors demonstrate its effectiveness on several complex safety - critical robotic grasping tasks inspired by the game Operation,1 in which SAFER outperforms baseline methods in learning successful policies and enforcing safety."
SP:a5dadb3ecc3caed3b9d9a68eda0d48a53c2d1ce2,"This paper proposes a multi - branch restoration model based on the Human Visual System ( HVS ) for image restoration tasks. The proposed model is based on a neural network architecture and is trained on three types of restoration tasks : image dehazing, deraindrop, and deblurring. Experiments show that the proposed model can achieve competitive performance on all three restoration tasks compared to baselines."
SP:263b386beee44b0b45b6f6dc3cf80d020500be62,"This paper proposes a new federated learning method, IT - PFL - HN, that learns a personalized model to novel unlabeled clients at inference time. The proposed method is based on a hypernetwork module and an encoder module. The authors evaluate the proposed method on 4 benchmark datasets, CIFAR10, Cifar100, iNaturalist, and Landmarks, showing that it performs better or equally as well as baselines."
SP:960d0a63a82593f6e72275b65f0501f0469d1924,This paper presents a new method to visualize representations learned with self - supervised models. The method is based on a conditional diffusion based generative model ( RCDM ). The authors show that SSL representations trained with RCDM are more robust to adversarial attacks than those trained with supervised representations. They also demonstrate that SSL - trained representations retain more detailed information on the content of the background and object style while supervised representations appear oblivious to these.
SP:398899e6c86b4a2a17dfa5c2f4478811f4331c1d,"This paper presents a new algorithm for frequency estimation of frequency moments ( FPMs ) based on a well - known streaming algorithm called Fp sketch. The algorithm is differentially private as is when p ( 0, 1 ) is a polylogarithmic space. The authors show that the algorithm is exponentially better than existing DP baselines and only worse than the optimal non - private baseline by a logarithmic factor. The evaluation shows that the FPM sketch can achieve reasonable accuracy with differential privacy guarantee."
SP:3253b13851b5a3b5e3c8c6e24891db05903a4e57,"This paper proposes a novel reward - based reward optimization method for learning novel policies that are both locally optimal and sufficiently different from existing policies. The authors propose RSPO ( Reward - Switching Policy Optimization ), a method to learn novel policies by iteratively finding novel policies in complex RL environments. The proposed method is based on a trajectory - based novelty measurement to encourage the learning policy to consistently converge towards a previously undiscovered local optimum. Experiments show that the proposed method can discover a wide spectrum of strategies in a variety of domains, ranging from single - agent particle - world tasks and MuJoCo continuous control to multi - agent stag - hunt games and StarCraftII challenges."
SP:e3ab3aa87ab023bd9949b99a17d4b6e26c1473c0,"This paper proposes a new method for fast diffusion model sampler search based on gradient descent and reparametrization trick and gradient rematerialization. The method is based on the Generalized Gaussian Diffusion Model ( GGDM ), a family of flexible non - Markovian samplers for diffusion models. The main contribution of the paper is the introduction of DDSS ( Differentiable Diffusion Sampler Search ), which optimizes fast sampler for any pre - trained diffusion model by differentiating through sample quality scores via gradient descent. The authors show that the proposed method achieves strong results on unconditional image generation across various datasets ( e.g., FID scores on LSUN )."
SP:7a7506f2b5500a573c0cfb8b0822e5ea725c886a,"This paper proposes a method to improve the accuracy of large language models ( LLMs ) based on continuous language prompts. The authors propose a lightweight model called P - Adapters, which takes the embedding embedding and first attention layer of LLMs as input and output continuous prompts that are used to query the LLM. They also propose a Mixture of Experts ( MoE ) model that learns a set of continuous prompts ( “experts ” ) and select one to query. They show that the MoE model is able to outperform BERT and RoBERTa models in extracting factual information from BERT while eliminating the need for additional annotations."
SP:35cdf71f027cc5168b55cc34c64bfb2f3087d6f5,"This paper proposes Continuous Classification of Time Series ( CCTS ), a method to classify time series at every time. The main idea is to use multiple distributions simultaneously to achieve the high - accuracy classification. The authors propose a novel Adaptive model training policy ( ACCTS ) to train the model to adapt to the distribution evolution and the model change. ACCTS only replays the important samples adaptive to the contribution of data to the model. Experiments on four real - world datasets show that the method can classify more accurately than all baselines."
SP:d9b74b749aa465496763d3a3a9bf3a53e800587e,"This paper proposes to extend language models with the ability to memorize the internal representations of past inputs by using a kNN lookup into the memory. The authors show that an approximate kNN look - into - memory improves language modeling across various benchmarks and tasks, including generic webtext ( C4 ), math papers ( arXiv ), books ( PG-19 ) and code ( GitHub ), as well as formal theorems ( Isabelle ). They show that the performance steadily improves when we increase the size of memory up to 131k tokens. They also find that the model is capable of making use of newly defined functions during test time. Finally, they show that their models are actually using external memory in the way that we had hoped, by looking up the definitions of lemmas in a theorem proving corpus."
SP:7a1bbf86c3fdb8738aa826ca330493e857d050ba,"This paper proposes a sampling scheme based on the Metropolis–Hastings Monte Carlo algorithm to generate samples from masked language modeling ( MLM ) objective effectively discriminate probable and improbable sequences. In this paper, samples are proposed from the same masked conditionals used for training the masked language models, and they are accepted or rejected based on their energy values according to the target distribution. They validate the effectiveness of the proposed parametrizations by exploring the quality of samples drawn from these energy - based models for both open - ended unconditional generation and a conditional generation task of machine translation."
SP:011626ba4fafee13d4a30e3f13c1df5b7071a7f1,"This paper proposes an augmentation policy learning method for data augmentation in the context of NLP. The authors propose a novel reward function for updating the augmentation policies to construct more diverse and challenging samples for providing informative training signals, while avoiding the risk of losing the semantics of original samples. They also introduce a sample re - weighting scheme to focus on difficult augmented samples after the original ones are learned confidently for more effective learning from the augmented ones. The proposed method outperforms the recent state - of - the - art augmentation schemes on various text classification tasks and GLUE benchmark by successfully discovering the effective augmentations for each task."
SP:69d41a862ea189f72d4e8af2854e27b95a91fa41,"This paper proposes a new meta - RL algorithm called FOCAL, which combines intra - task attention mechanism and inter - task contrastive learning objectives to improve the robustness of task representation learning against sparse reward and distribution shift in offline RL. The proposed algorithm is based on a model - free framework with end - to - end and model - model free framework compared to prior algorithms across multiple meta -RL benchmarks. Theoretical analysis and experiments are presented to demonstrate the superior performance of the proposed algorithm compared to existing algorithms in the literature."
SP:ed86c60850d5c8302dcf1c2167db303e778fe681,"This paper proposes an inference - time improvement framework for parametric sequential generative modeling methods called belief fine - tuning ( BFT ). BFT leverages approximate dynamic programming in the form of fine -tuning to determine the model parameters at each time step. It can improve the accuracy of the belief model at test time because it specializes the capacity of the model to the space of local observations. Furthermore, because this specialization occurs after the action or policy has already been decided, BFT does not require a belief model to process it as input. This is the first instance of successful approximate belief state - based search in a multi - agent setting in which computing an exact belief state is intractable."
SP:6150725599c10f0e26f0d7cb1fc04b5b227a4456,"This paper proposes a new method for sparse training of neural networks. The proposed method is based on a simple fixed sparsity pattern based on flat block butterfly and low - rank matrices to sparsify most of the network layers ( e.g., MLP - Mixer, ViT, MLPMixer, Vision Transformer, and GPT - 2 medium ). The paper proposes two variants of the butterfly matrices : block - aware and flat - aware. The authors show that the proposed method outperforms other sparse training baselines on a wide range of domains and tasks."
SP:136e31054a55abca840f6478491972023c2296cb,"This paper proposes a conditional diffusion probabilistic model ( ST - DDPM ) based on score - based generative models. The proposed method is inspired by the class clustering phenomenon and the forward process of the Markov chain. The authors propose to model the class center in the forward and reverse process, and make an elegant modification to the original formulation, which enables controllable generation and gets interpretability. To verify the effectiveness of the formulated framework, the authors conduct extensive experiments on the task of conditional image generation, free - form image inpainting, and CIFAR-10 with an inception score of 9.58 and FID score of 3.05."
SP:fc2196f1f4ecd864398fed6640ff3f8b19870763,"This paper proposes a method for domain generalization ( DG ) based on a LASSO - based method. The proposed method is based on the idea of learning latent subspaces and learning individual hypotheses on those sub - spaces. The authors argue that existing DG approaches often rely on the assumption of the existence of fixed domain - invariant features and common hypotheses learned from a set of training domains. They argue that this assumption could be overly strict and sub - optimal and that the source domains share little information or the target domains leverages information from selective source domains in a compositional way instead of relying on a unique invariant hypothesis across all source domains. Instead of constructing a single hypothesis shared among domains, the authors propose a LassO method that explores diverse latent sub - Spaces and learns individual hypotheses. They empirically evaluate their method on several well known DG benchmarks, where it achieves state - of - the - art results. They also empirically demonstrate that their proposed method can achieve favorable results when evaluating their model on domains generalization benchmarks in comparison with state of the art methods."
SP:6e8e5bdeb77e3cafe1975da8411fb65118955d14,"This paper proposes a method to compress a probability distribution more effectively than independent sampling by targeting a reproducing kernel Hilbert space ( RKHS ) and leveraging a less smooth squareroot kernel. The authors show that KT applied directly to the target kernel yields tighter, dimension - free guarantees for any kernel, any distribution, and any fixed function in the RkHS. They show that for analytic kernels like Gaussian, inverse multiquadric, and sinc, target KT admits maximum mean discrepancy ( MMD ) guarantees comparable to or better than those of square - root KT without making explicit use of a square root kernel. They prove that KT with a fractional power kernel yields better - than -Monte - Carlo MMD guarantees for non - smooth kernels, like Laplacian MMD. They also establish that KT applies to a sum of the target and power kernels ( a procedure we call KT+ ) simultaneously inherits the improved MMD guarantee of power KT and the tighter individual function guarantees of target KT."
SP:645c3f1864aa843d4899fc2406f694b5aab8460d,"This paper presents an open - source benchmark suite for the NP - hard MAXIMUM INDEPENDENT SET problem, in both weighted and unweighted variants. The benchmark suite offers a unified interface to various state - of - the - art traditional and machine learning - based solvers. The authors conduct an in - depth analysis of the popular guided tree search algorithm by Li et al. [ NeurIPS 2018 ], testing various configurations on small and large synthetic and real - world graphs. They show that the graph convolution network used in the tree search does not learn a meaningful representation of the solution structure, and can in fact be replaced by random values. The tree search relies on algorithmic techniques like graph kernelization to find good solutions. Thus, the results from the original publication are not reproducible. The paper extends the analysis to compare the tree - search implementations to other solvers, showing that the classical algorithmic solvers often are faster, while providing solutions of similar quality."
SP:155ecd17d264a084b014abdfd0362146d8fb07e0,"This paper proposes Wavelet Compressed Convolutional Neural Networks ( WCC ), a novel approach for activation maps compression for 1 × 1 convolutions ( the workhorse of modern CNNs ). WCC achieves compression ratios and computational savings that are equivalent to low bit quantization rates at a relatively minimal loss of accuracy. To this end, they use a hardware - friendly Haar - wavelet transform, known for its effectiveness in image compression, and define the convolution on the compressed activation map. They show that using WCC dramatically improves the results over aggressive quantization for the same compression rates while retaining the baseline network architecture."
SP:004865e6affad32403b7965493a53c8a7ffdda0a,This paper proposes a new no - regret learning algorithm for extensive - form correlated equilibrium ( EFCE ) in multiplayer general - sum imperfect - information extensive -form games. The authors show that their algorithm can converge to an O(T 3/4)-approximate E FCE when all agents play T repetitions of the game according to the accelerated dynamics. This significantly improves over the best prior rate of O(O(T 1/2 ). The proposed algorithm can also be computed efficiently through a variant of the Ellipsoid algorithm.
SP:ee545ff83df4d7ff256ac61fbe0eb0765f52f1d5,"This paper proposes Action Quantization from Demonstrations ( AQuaDem ) to learn a discretization of continuous action spaces by leveraging priors of demonstrations. The proposed method reduces the exploration problem, since the actions faced by the agent not only are in a finite number but also are plausible in light of the demonstrator’s behavior. By discretizing the action space we can apply any discrete action deep RL algorithm to the continuous control problem. The authors evaluate the proposed method on three different setups : Reinforcement Learning with demonstrations, RL with play data, and Imitation Learning. For all three setups, we only consider human data, which is more challenging than synthetic synthetic data."
SP:4b39279b98d6aa311bb49dd1384925f9d6f66c2d,"This paper proposes a novel adversarial style augmentation ( AdvStyle ) approach, which can dynamically generate hard stylized images during training and thus can effectively prevent the model from overfitting on the source domain. Specifically, AdvStyle regards the style feature as a learnable parameter and updates it by adversarial training. AdvStyle can also be applied to single DG in image classification and can produce state - of - the - art accuracy on two datasets."
SP:4a2e6d70b383e4941e0bc44e7e82972b22e26792,"This paper proposes a neuromorphic gesture recognition system for mid - air gesture recognition. The proposed method is based on a dynamic vision sensor ( DVS ) that encodes event - based gesture data into a latent space representation to compute the similarity of mid air gesture data. The authors propose a hybrid VAE - Guided Variational Autoencoder ( VAE ) to encode the sparse, noisy inputs into an interpretable latent space representations, visualized through T - SNE plots. They also implement the encoder component of the model on neuromorphic hardware and discuss the potential for their algorithm to enable real - time, self - supervised learning of natural mid air gestures."
SP:2e66468a6b94177e54b0052b97713ee63902c278,"This paper proposes a Sparse Hierarchical Table Ensemble ( S -HTE ) architecture for deep learning for tabular data. S - HTE is based on a sparse hierarchical table ensemble ( SHTE ) architecture, where the weights are sparse at the beginning of the training process and gradually sparse using an annealing mechanism, leading to an efficient final predictor. Unlike previous work with ferns, S-HTE learns useful internal representations, and it earns from increasing depth. Using a standard classification and regression benchmark, the authors show its accuracy is comparable to alternatives, while having an order of magnitude lower computational complexity."
SP:b238db9252d83a13438bb747d70e635bb9945958,"This paper proposes a method for learning value functions from state - only experience in discrete Markov decision processes ( MDPs ). The authors propose a method called Latent Action Q - learning ( LAQ ) that learns value functions using Q - Learning on discrete latent actions obtained through a latent - variable future prediction model. They show that LAQ can recover value functions that have high correlation with value functions learned using ground truth actions. They also show that it can outperform imitation learning methods, even when these methods have access to privileged ground - truth action information. Their experiments in 5 environments ranging from 2D grid world to 3D visual navigation in realistic environments demonstrate the benefits of LAQ over simpler alternatives."
SP:108ebe9045a9e2b8b5aba8352733782462db8a81,"This paper proposes SWARM Parallelism1, a model - parallel training algorithm designed for swarms of poorly connected, heterogeneous unreliable devices. The authors propose to train a large Transformer language model with 1.1B shared parameters on a swarm of preemptible T4 GPUs with less than 400Mb/s network throughput on a preemptible low - power T4 network. They demonstrate that it is possible to train the model with high training throughput on the preemptible network on a large network with low training throughput. They also propose several compression - aware architecture modifications."
SP:91d2f094d5481651b554f58aecc2a6207057a47c,"This paper proposes an online transition correction ( OTC ) method to bridge offline training and online tuning in decentralized multi - agent reinforcement learning ( MARL ). The authors propose two types of distance measures, i.e. distance between transitions, and value based distance, to measure the similarity between transitions. They propose adaptive rank - based prioritization to sample sample transitions according to the transition similarity. Experimental results show that OTC outperforms baselines in a variety of tasks, and ablation studies demonstrate the effectiveness of the distance measures."
SP:d0e650d568214481b07a0452ec606ccbf6d05410,"This paper proposes an unbiased quantization method to reduce the computational footprint of Deep Neural Networks ( DNNs ) training by quantizing both the forward and backward phase of the training process to 4 - bit. The authors propose a logarithmic quantization ( LQ ) method to quantize the forward phase to 4-bit and a variance reduction method to avoid multiplications during two - thirds of training process, thus reducing by 5x the area used by the multiplier. The proposed method achieves state - of - the - art results in 4 -bit training and achieves a degradation of 1.18 %."
SP:f2862d1f987164ed6c3c375cd8962e57c369373b,"This paper proposes a self - attention feature - selection mechanism for meta - learning based on polythetic classifications based on shared patterns of features that need neither be universal nor constant among members of a class, and greatly outnumber monothetic classifications over a set of features. The authors show that threshold meta - learners such as Prototypical Networks require an embedding dimension that is exponential in the number of task - relevant features to emulate these functions. In contrast, attentional classifiers, such as Matching Networks, are poly thetic by default and are able to solve these problems with a linear embedding dimensions. However, the authors find that in the presence of task-irrelevant features, inherent to meta -learning problems, Attentional models are susceptible to misclassification. To address this challenge, they propose a selfattention feature -selection mechanism that adaptively dilutes non - discriminative features. They demonstrate the effectiveness of their approach in Meta - learning Boolean functions, and synthetic learning tasks."
SP:e1e513fef25d29e17cdadd1b36d932a8ad8897cd,"This paper proposes to study the emergence of language between agents in a continuous communication channel trained through reinforcement learning. The authors propose an environment and training methodology to carry out an initial exploration of these questions. They use a simple messaging environment where a "" speaker "" agent needs to convey a concept to a "" listener "" agent. The speaker is equipped with a vocoder that maps symbols to a continuous waveform, and the vocoder is trained using deep Q - learning. They show that basic compositionality emerges in the learned language representations. They also show that noise is essential in the communication channel when conveying unseen concept combinations. And they show that they can ground the emergent communication by introducing a caregiver predisposed to “hearing ” or “speaking ” English. Finally, they describe how their platform serves as a starting point for future work."
SP:0e6ff65ba4a3df35947d1b6f4d438612088d90a0,"This paper proposes a novel backdoor attack against pre - trained natural language processing ( NLP ) models. The authors propose BadPre, a novel task - agnostic backdoor attack to the language foundation models. They design a twostage algorithm to backdoor downstream language models more efficiently. They also design a simple and effective trigger insertion strategy to evade a state - of - the - art backdoor detection method. They perform extensive experiments over 10 different types of downstream tasks and demonstrate that BadPre can achieve performance drop for up to 100%. The backdoored downstream models can still preserve their original functionality completely."
SP:58d3ecb4a1906251e79ad883aa97cc2502642658,"This paper proposes a reward - free, unsupervised skill discovery algorithm ( DISk ) that can effectively learn skills in a decoupled manner. DISk learns skills one after another in an incremental fashion. The authors show that DISk can learn a diverse set of controllable skills on continuous control tasks that outperform current state - of - the - art methods on skill quality, as well as in sample and computational efficiency."
SP:2c6595408f5ec95537eaf555e5fe3d992b58c222,"This paper proposes a new convolution method called log - polar space convolution ( LPSC ), where the convolution kernel is elliptical and adaptively divides its local receptive field into different regions according to the relative directions and logarithmic distances. The proposed method can be implemented with conventional convolution via log - polar space pooling and can be applied in any network architecture to replace conventional convolutions. Experiments on different tasks and datasets demonstrate the effectiveness of the proposed method."
SP:7791f96b1eef277a9133975507a750d9e7c6b8ff,This paper proposes a new information bottleneck based on the PAC - Bayes generalization guarantee for neural networks ( NNs ). The paper proposes an algorithm for the efficient approximation of the intractable IIW and a Bayesian inference algorithm based on stochastic gradient Langevin dynamics ( SGLD ) for sampling from the optimal weight posterior specified by PIB. The authors demonstrate that their new information measure covers the wide ground of NN ’s behavior and can adapt any existing NN to a PAC - IB augmented NN.
SP:a733847ade77ffbf38760fc79da17893dea8d53f,This paper investigates the effectiveness of data poisoning attacks on training data. The authors show that the perturbations of advanced attacks are almost linear separable when assigned with the target labels of the corresponding samples. They further confirm that linear separability is indeed the workhorse for recent attacks and show that synthetic perturbation are as powerful as the deliberately crafted attacks. The paper also suggests that the shortcut learning problem is more serious than previously believed as deep models heavily relies on shortcuts even if they are of an imperceptible scale.
SP:7b50be406138ad01db3ee112899f622637896fe9,This paper proposes a new algorithm POELA to optimize the importance weighted return in offline policy evaluation. The main contribution of the paper is to provide a theoretical justification of the proposed algorithm through a better per - state - neighborhood normalization condition and show the limitation of previous attempts to this approach through an illustrative example. The proposed algorithm is further tested in a healthcare - inspired simulator and a logged dataset collected from real hospitals. The experiments show the proposed method with less overfitting and better test performance compared with state - of - the - art reinforcement learning algorithms.
SP:c976752a55b9ff47dc63c95a9fd7b51a81e8a42e,"This paper presents CoLLIE, a model for continual learning of how language is grounded in vision. The model learns a transformation function that adjusts the language embeddings when needed to accommodate new language use. Unlike traditional few - shot learning, the model does not just learn new classes and labels, but can also generalize to similar language use and generalize from only a few examples, with little interference with the model's original zero - shot performance.   The model is trained on a pre - trained multimodal embedding model, where language and images are projected in the same semantic space ( in this case CLIP by OpenAI )."
SP:d3371b322acfc321ee79a2e1b438d82644872fa4,"This paper proposes a novel object captioning ( NOC ) model for describing objects or visual concepts which are unseen ( i.e., novel ) in the training of NOC models. The authors propose VLAF2, a novel method for learning NOC captioning models for describing novel objects and visual concepts. The proposed method is based on a combination of BERT and CLIP. The method is evaluated on a number of benchmark NOC datasets and compared against state - of - the - art models on several metrics including fluency, fidelity, and fluency."
SP:9f3b6486662d80350d77a4b060d4a5b8b22a6130,"This paper studies the effect of neural collapse on transfer learning in the few - shot setting. The authors show that the features learned by overparameterized classification networks show an interesting clustering property, called neural collapse, that generalizes to new samples from the training classes, and – more importantly – to new classes as well, allowing foundation models to provide feature maps that work well in transfer learning and, specifically, in the new - class setting. They provide an explanation for this behavior based on the recently observed phenomenon. They demonstrate both theoretically and empirically that neural collapse generalizes new samples and new classes."
SP:624c95d9ce1ee4b66274e858e2da22bef6b052c7,"This paper proposes a deep point cloud reconstruction network consisting of two stages : 1 ) a 3D sparse stacked - hourglass network as for the initial densification and denoising, 2 ) a refinement via transformers converting the discrete voxels into 3D points. In particular, a newly proposed module called amplified positional encoding is designed to differently amplify the magnitude of positional encoding vectors based on the points ’ distances for adaptive refinements. Extensive experiments demonstrate that the proposed network achieves state - of - the - art performance among the recent studies in the ScanNet, ICLUIM, and ShapeNetPart datasets."
SP:34a81ca65131576d4c14332a4e9eb3a4c344cab7,"This paper proposes PipeGCN, a method for training graph convolutional neural networks ( GCNs ) with distributed training across multiple accelerators. The main idea is to reduce the communication overhead of communicating node features and feature gradients among partitions for every GCN layer in each training iteration, limiting the achievable training efficiency and model scalability. To this end, the authors propose a simple - yet - effective scheme that is based on pipelining inter - partition communication with intra - partition computation. The authors also propose a smoothing method to further improve the convergence rate of the method. Extensive experiments show that the proposed method can largely boost training throughput (up to 2.2× ) while achieving the same accuracy as the vanilla full - graph training methods."
SP:8302d49558ee0f16392d623d4e604e92db10d041,"This paper proposes an adaptation method for test - time robustification, i.e., using the test input to improve model robustness. The proposed method is called marginal entropy minimization with ensembled augmentations ( MEME ). The authors propose a simple approach that can be used in any test setting where the model is probabilistic and adaptable : when presented with a test example, perform different data augmentations on the data point, and then adapt ( all of ) the model parameters by minimizing the entropy of the model ’s average, or marginal, output across the augmentations. In the experiments, the authors evaluate two baseline ResNet models, two robust ResNet - 50 models, and a robust vision transformer model, and demonstrate that this approach achieves accuracy gains of 1 - 8% over standard model evaluation and also generally outperforms prior augmentation and adaptation strategies."
SP:a985de5e940ff3a4160b378201b8c02f68d1914a,"This paper proposes a new algorithm for model - based reinforcement learning ( RL ) based on Mismatched No More ( MnM ). The main contribution of this work is an algorithm that maximizes a lower bound on expected reward on expected return. The algorithm is based on a GAN classifier that distinguishes between real and fake transitions, and the policy is updated to avoid states where the model predictions are unrealistic. The authors demonstrate that their algorithm is competitive with prior state - of - the - art methods on benchmark tasks and outperforms prior methods based on maximum likelihood estimation."
SP:a469fbcdc20b11dff4085b6fbc384e77f33cd37d,"This paper proposes a new method for behavioral cloning from observation history ( BC - OH ) based on human decision making. The authors propose a simple model combination approach inspired by human decision - making : first compute a coarse action based on the instantaneous observation, and then refine it into a final action using historical information. They show that this method outperforms all baselines on CARLA autonomous driving from images and various MuJoCo continuous control tasks."
SP:95c4533b5d1a865c4cc6a54615e7ad6357bdaad1,"This paper proposes a model - based meta - learning method called DyAd which can generalize across heterogeneous domains by partitioning them into different tasks. DyAd has two parts : an encoder which infers the time - invariant hidden features of the task with weak supervision, and a forecaster which learns the shared dynamics of the entire domain. The encoder adapts and controls the forecaster during inference using adaptive instance normalization and adaptive padding. Theoretically, they prove that the generalization error of such procedure is related to the task relatedness in the source domain, as well as the domain differences between source and target domains. They also demonstrate that their model outperforms state - of - the - art approaches on both both turbulent flow and real - world data forecasting tasks."
SP:ec70553cb0c27e5349c1b8cce6bcaa96a83bf050,"This paper proposes a weakly supervised monocular 3D object detection method for object detection in 3D scene understanding. The proposed method is based on two - D box detection on the image and a network to predict the corresponding RoI LiDAR points as the weak supervision. The method is evaluated on the KITTI benchmark, where it outperforms existing fully supervised methods which use massive 3D box labels."
SP:34217c6a8ca43b8eeb9ddc83d6f1f0af05918984,"This paper proposes a new model inductive bias that learns a subword tokenization end - to - end as part of the model. To this end, they introduce a soft gradient - based sub word tokenization module ( GBST ) that automatically learns latent subword representations from characters in a data - driven fashion. Concretely, GBST enumerates candidate subword blocks and learns to score them in a position - wise fashion using a block scoring network. They additionally introduce CHARFORMER, a deep Transformer model that integrates GBST and operates on the byte level. The experiments on English GLUE, multilingual, and noisy text datasets show that the proposed model outperforms a series of competitive byte - level baselines while generally performing on par and sometimes outperforming subword - based models."
SP:d26d25f2ef23a89a2c139d0dd87c4c86fddcff5e,"This paper proposes an adversarial approach to detecting backdoor attacks on deep neural networks ( DNNs ). The authors propose a method called adversarial extreme value analysis ( AEVA ) to detect backdoors in black - box neural networks. AEVA is based on an extreme - value analysis of the adversarial map, computed from the monte - carlo gradient estimation. They show that this adversarial objective leads to a solution with highly skewed distribution. They evaluate AEVA on three widely - adopted tasks with different backdoor trigger implementations and complex black - label attack variants and show that it is effective in detecting backdoors under multiple popular tasks and backdoor attacks."
SP:c6dbca0ed0799b7fec21777606f6f809eb2d8c48,"This paper proposes a new uncertainty measure for in - distribution and out - of - distribution ( OOD ) uncertainty estimation based on the Kullback - leibler divergence criterion ( KLoS ). The proposed measure is based on a class - wise Dirichlet distribution. The authors propose a neural network to learn a refined criterion directly aligned with the evidential training objective for training samples and to improve uncertainty estimation. They also propose to learn an auxiliary model to learn the values of a refined objective for OOD training samples. Experiments show that the proposed measure outperforms existing uncertainty measures when training with OOD samples, while existing measures are brittle to the choice of OOD dataset."
SP:8b4f3916dca4e627931558e14836749bd4a6792f,"This paper proposes a semi - supervised method for learning convolutional networks ( CNNs ) from unlabeled natural image data. The method is based on a linear classifier algorithm that first constructs a representation based on an unlabelled set of examples, and then learns a linear network classifier over the produced representation. The authors show that the algorithm provably learns CNNs, under some natural distributional assumptions. Specifically, the authors assume that the distribution of patches in the input images has low - dimensional structure ( e.g., when the patches are sampled from a low -dimensional manifold ). They show that under this assumption, the dependence of the algorithm on the dimension of the patch distribution is essentially optimal, i.e., any learning algorithm must depend on this number in the same way that our algorithm does."
SP:7f2f354d5cc1030bd97bd716aea8fe1d3af86b25,"This paper proposes a new clustering algorithm for face clustering based on Graph Convolutional Networks ( GCNs ). The proposed algorithm, Ada - NETS, aims to cluster faces by constructing clean graphs for GCNs. In Ada -NETS, each face is transformed to a new structure space, obtaining robust features by considering face features of the neighbour images. Then, an adaptive neighbour discovery strategy is proposed to determine a proper number of edges connecting to each face image. It significantly reduces the noise edges while maintaining the good ones to build a graph with clean yet rich edges. Experiments on multiple public clustering datasets show that Ada - NetS significantly outperforms current state - of - the - art methods, proving its superiority and generalization."
SP:a3bc8e26f55e78f07de081ca85865afd52b6ae4a,"This paper proposes a method for learning robust models that are able to perform well on a collection of possible data distributions ( the “uncertainty set ” ) without demographics. Under this more realistic setting, distributionally robust optimization ( DRO ) provides a promising way to learn robust models. However, the convex condition of DRO may not hold for overparameterized neural networks and applying KL DRO fails to generalize under distribution shifts in real scenarios. Instead, the authors propose a simple yet efficient approach, Unit DRO minimizes the loss over a reweighted dataset where important samples ( i.e. samples on which models perform poorly ) will be upweighted and others will be downweighted. Empirical results show that unit DRO achieves superior performance on large - scale DG ReID and cross - domain ReID benchmarks compared to standard baselines. The proposed method achieves improved performance on DG and CD benchmarks even compared to these methods that rely on demographics."
SP:62c1f734b7f6c6e7d5114da6f37c9e3cdda73a23,"This paper proposes a method to improve the performance of graph neural networks ( GNNs ) by adding noise to the input graph and correcting the node - level loss. The authors introduce a noise correction loss for node latents and a noise regulariser for the noise - correcting loss. They show that their method improves the performance on three 3D molecular property prediction tasks : OC20 IS2RE direct task by 43% over previous work, 12% on OC20 Is2RS direct, and top results on 3 out of 12 of the QM9 tasks. They also demonstrate the effectiveness of Noisy Nodes with non - spatial architectures on Open Graph Benchmark ( OGBN - Arxiv ) datasets."
SP:24a1b44f37f8eedbab2047fb84600a322d289f3b,"This paper presents a new approach to the set2vec problem, which is the task of extracting a vector representation from an input set comprised of a variable number of feature vectors from a mixture distribution. The authors propose a feed - forward network ( MAP - EM ) based on the maximum - a - posterior ( MAP ) estimate of the mixture distribution which is approximately attained by a few ExpectationMaximization ( EM ) steps, allowing efficient auto - diff backpropagation for any given downstream task. The proposed mixture set data fitting framework allows unsupervised set representation learning naturally via marginal likelihood maximization aka the empirical Bayes Bayes. The paper shows improved results over state - of - the - arts on various set embedding tasks in bioinformatics and NLP."
SP:b4f7b660b84fe7702fbcc8a96c192abc3a64f045,"This paper proposes a method for unsupervised feature selection in contrastive analysis ( CA ), where the goal is to select a small number of informative features for use in unknown downstream tasks. The authors propose a method called CFS ( Contrastive Feature Selection ) to perform feature selection for the CA setting. The proposed method is evaluated on four real - world biomedical datasets, and they find that it consistently outperforms previous state - of - the - art methods designed for standard un - supervised feature selection scenarios. They validate their approach through extensive experiments."
SP:bc4f69f23aba2034cbf14cb31bdc7a991806bbf6,"This paper studies the relationship between optimal early stopping time and model dimension as well as sample size of the dataset for linear regression models. The authors show that when the model dimension exceeds the number of features arising from data, early stopping can help mitigate double descent. They also show that early stopping helps mitigate double - descent in multiple settings.    The authors provide theoretical results on the effect of early stopping on the training process of deep neural network and generalization of the model."
SP:ede87b50cd9c4a6533f17e3e5ddfaaeaaac71dcf,This paper proposes a new policy gradient algorithm with entropy regularization for policy gradient algorithms with Shannon entropy. The authors show that the proposed method converges faster than the Newton - type quadratic convergence rate of existing algorithms. They provide a simple proof that all these algorithms enjoy the Newton-type quadrastic convergence near the optimal policy. They also show that some of the algorithms with linear convergence rate can suffer from slow convergence.
SP:3535504f7599b1f39239f7cd8e09acd40fa8fdf0,"This paper proposes a new method for training RL agents for text - based games ( TBGs ) based on case - based reasoning to train agents and generalize out of the training distribution. The method can be applied in conjunction with any existing on - policy neural agent in the literature for TBGs. The experiments show that the proposed approach consistently improves existing methods, obtains good out - of - distribution generalization, and achieves new state -of - the - art results on widely used environments on the TextWorld Commonsense dataset."
SP:9a5dd0148a15dc5b4d2bc6762dfe8a8991f8866c,"This paper proposes a two - stage method to distill multiple word senses from a pre - trained contextual language model ( BERT ) by using attention over the senses of a word in a context and transferring this sense information to fit multi - sense embeddings in a skip - gram - like framework. The authors demonstrate an effective approach to training the sense disambiguation mechanism in BERT by using a distribution over word senses extracted from the output layer embedding of BERT. Experiments on the contextual word similarity and sense induction tasks show that this method is superior to state - of - the - art multi - senses embedding on multiple benchmark data sets, and experiments with an embedding - based topic model ( ETM ) demonstrates the benefits of using this multi -sense embedding in a downstream application."
SP:e4cdba0fc7cd7f440d4436219f3959d8d5e2ad28,"This paper proposes to transfer image - pretrained models from a neural net model to a 3D point - cloud model by inflating convolutional filters and finetuning the inflated imagepretrained models ( FIP ). The authors show that FIP is able to achieve competitive performance on 3d point cloud classification with a wide range of point cloud models that adopt task - specific architectures and use a variety of tricks. They also show that the method improves data efficiency, reaching up to 10.0 points top - 1 accuracy gain on few - shot classification and speeds up training."
SP:dc99c307931ae9c5d4a1b998dc94cfc6ac78d11f,"This paper proposes a method for training an autoregressive generative model that takes advantage of a well - designed energy - based learning objective. The method is capable of alleviating the exposure bias problem and increase temporal coherence by imposing a constraint which fits joint distributions at each time step. Besides, unlike former energy based models, the model estimates energy scores based on the underlying Autoregressive network itself, which does not require any extra network. Finally, thanks to importance sampling, the proposed method can train the entire model efficiently without an MCMC process."
SP:51e748c55bd4134047098559577fa3f37aa7433a,"This paper proposes a new distributional robustness method for adversarial training of deep neural networks ( DNNs ). The proposed method is based on the Wasserstein method ( SOTA - AT ), which aims to improve the robustness of a DNN - based classifier by adding adversarial examples during training. The authors propose a new method, PGD - AT, which is a generalization of the SOTA AT method. They also propose a novel family of algorithms that generalize the AT methods in the standard robustness setting, which have better generalization capacity. Empirically, they conduct extensive experiments on benchmark datasets, which show that the proposed AT methods achieve better performance than standard AT methods."
SP:f192046ea8ad61bfc8e05a0ddb90a8bd15b4640b,"This paper presents a novel representation learning framework for multivariate time series. The authors propose a novel framework, Bilinear Temporal - Spectral Fusion ( BTSF ), to incorporate spectral information and temporal - spectral relations in feature representation. The proposed method is evaluated on three tasks : classification, forecasting and anomaly detection, which is the first to evaluate on all three tasks."
SP:ef54840009afb095c67bbbc29a7824c20a375ee8,"This paper proposes an algorithm for automatically adjusting the learning rate during gradient descent during line - search. The method is motivated by an analysis that exploits the structure of neural networks and formulate first and second - order gradients with respect to learning rate as functions of consecutive weight gradients, leading to a cost - effective implementation. Extensive experimental evaluation is conducted, validating the effectiveness of the proposed method for a plethora of different settings. The proposed method has proven to be robust to both the initial learning rate and the batch size."
SP:263c787361cd6d4443ce516d389c694d0fe44b28,"This paper proposes a continual meta - policy search ( CoMPS ) method to address the meta - reinforcement learning problem in sequential multi - task learning. In this setting, the agent ’s goal is to achieve high reward over any sequence of tasks quickly by meta - training in an incremental fashion, over each task in a sequence, without revisiting prior tasks during training. The authors introduce a new method, continual Meta - Policy Search, that removes this limitation by meta-training in a incremental fashion. The experiments show that as the agent experiences more tasks, learning time on new tasks decreases, indicating that meta - learning performance increases asymptotically with the number of tasks. To our knowledge, this work is the first to formulate and address the continual meta-reinforcement learning problem, which is a realistic formulation of meta - RL for real - world settings."
SP:2bd729b7aa045bf74e31229c9e76e57af36e804b,"This paper proposes a human - in - the - loop attack method for poisoned classifiers, where a third party aims to gain control of the poisoned classifier without access to the original trigger and the training data. The authors propose a test - time, human in the loop method to generate multiple effective alternative triggers by first generating adversarial examples for a smoothed version of the classifier and then using human inspection to construct effective triggers. They demonstrate the effectiveness of their attack through extensive experiments on high - resolution datasets : ImageNet and TrojAI. They also compare their approach to previous work on modeling trigger distributions and find that their method are more scalable and efficient."
SP:e58ab0e3cff6b18013145a1a99cfa9da0a3d872f,"This paper proposes a novel method for distilling unconditional GANs, especially for the popular StyleGAN2 architecture. The main insight is that the main challenge of unconditional distillation lies in the output discrepancy issue, where the teacher and student model yield different outputs given the same input latent code. Standard knowledge distillation losses typically fail under this heterogeneous distillation scenario. The style module plays a vital role in determining semantic information of generated images. Based on this finding, the authors propose a novel initialization strategy for the student model, which can ensure the output consistency to the maximum. To further enhance the semantic consistency, they present a latent - direction - based distillation loss that preserves the semantic relations in latent space. Extensive experiments demonstrate the effectiveness of their approach in distilling StyleGAN 2, outperforming existing GAN distillation methods."
SP:2c2231743fa33b95828c6615263954ce1c05f95d,"This paper proposes a method for approximating offline algorithms in online settings by encoding the behavior of online algorithms in graphs. The authors train a multi - task learning model to simultaneously detect behavioral structures which have already occurred and predict those that may come next. They demonstrate the methodology on both synthetic data and historical stock market data, where the contrast between explanation and prediction is particularly stark. Taken together, this work represents the first general and end - to - end differentiable approach for generating online approximations of offline algorithms."
SP:ee3a21d2fb8a073099aa200129a53c31f3b6561d,"This paper proposes a method for sparse Gaussian Processes ( GPs ) based on neural networks and variational inference to reduce the cost of GPs per iteration to O(M ) per iteration. The authors propose a neural network architecture that computes the inducing points for each potential data point to be used for prediction. The inducing points are simply given by a mapping from the inputs provided by the neural network to the outputted inducing points. They show on several experiments that the proposed method is able to perform similar or better than standard sparse GPs and competitive methods. However, the training and prediction times of their method are much better."
SP:f20c99b441545047a16ae524cc2e317b2c3787a2,"This paper proposes a protocol for secure ( byzantinetolerant ) decentralized training that emphasizes communication efficiency in distributed deep learning. The proposed protocol is based on ResNet - 18 for CIFAR - 10 classification and pretraining ALBERT - large in a setup where almost half of all peers are malicious. The authors provide theoretical bounds for its resistance against Byzantine and Sybil attacks and show that it has a marginal communication overhead overhead overhead. To demonstrate its practical effectiveness, the authors conduct large - scale experiments on image classification and modeling in presence of Byzantine attackers."
SP:93894f20ab2593e5237b6972fef9fe63e96af89a,"This paper proposes a new method for learning physics - informed models for learning Lagrangian models of turbulence. Specifically, the authors propose to learn a hierarchy of parameterized and “ physics - explainable ” SPH - informed fluid simulators using both physics based parameters and Neural Networks as universal function approximators. The authors propose a mixed mode approach, mixing forward and reverse mode automatic differentiation with forward and adjoint based sensitivity analyses to efficiently perform gradient based optimization. They show that their learning method is capable of solving inverse problems over the physically interpretable parameter space, as well as over the space of Neural Network parameters. They also show that it can generalize to longer times and larger Reynolds numbers."
SP:d11b81f9ab414fcf430a03cd70c2d3246b678474,"This paper proposes an approach to regularize a single deterministic neural network to obtain improved accuracy and reliable uncertainty estimates. The authors propose a data - dependent regularization regularizer corresponding to the predictive distribution in the regions of the embedding space between the class clusters. This is achieved by synthetically generating between - cluster samples via the convex combination of two images from different classes and maximizing the entropy on these samples. This regularization guides the maximum likelihood estimation to prefer a solution that maps out - of - distribution samples to high entropy regions ( creating an entropy barrier ) and is more robust to the superficial input perturbations. Experiments on real - world datasets ( CIFAR-10 and CifAR-100 ) using ResNet and Wide - ResNet architectures demonstrate that the proposed method provides much improved classification accuracy, better accuracy, and better probabilities in estimating uncertainty estimates when exposed to situations involving domain - shift and out of distribution samples."
SP:365490b872464f00634dc7a50d024fceaf0a61ee,"This paper proposes a self - supervised auto - encoder - based method for image animation. The proposed method is based on the idea of linear navigation in the latent space of a deep generative model. Specifically, the authors propose to learn a set of orthogonal motion directions, and use their linear combination, in order to represent any displacement in the Latent Image Animator ( LIA ). Extensive quantitative and qualitative analysis suggests that the proposed method outperforms state - of - the - art methods on VoxCeleb, Taichi, and TED - talk datasets w.r.t. generated quality."
SP:86f9f89f84e117c86478b9afaf087f65524f5472,"This paper proposes a new meta - learning method called task interpolation ( MLTI ), which augments the task distribution by adding additional tasks to the meta - training task set. The proposed method is based on gradient - based and metric - based methods. The authors show that MLTI corresponds to a data - adaptedive meta - regularization and further improves the generalization ability. Empirically, in eight real - world datasets from various domains, MLTI consistently outperforms six prior metalearning regularization methods and is compatible with six representative meta -learning algorithms."
SP:73d577e9c4f4af5e11a9e5bdb583ee0f50a315f5,"This paper proposes a new fair representation learning method called Fair Normalizing Flows ( FNF ), which aims to reduce the distance between the latent representations of different groups by training an encoder as a normalizing flow trained to minimize the statistical distance between different groups. The main advantage of FNF is that its exact likelihood computation allows us to obtain guarantees on the maximum unfairness of any potentially adversarial downstream predictor. Experiments are conducted on a variety of real - world datasets to demonstrate the effectiveness of the proposed method."
SP:404d5643327f60f0f06f820033a56081f9e01900,"This paper proposes a novel graph neural network model COUNT - GNN for subgraph isomorphism counting. The proposed model is based on edge - centric message passing scheme, where messages on edges are propagated and aggregated based on the edge adjacency. The authors also propose a query - conditioned graph modulation to adapt structure matching to different queries from the graph perspective. Extensive experiments on several benchmark datasets demonstrate that the proposed model outperforms state - of - the - art baselines."
SP:5a94f18156ab2949c86de45fcf0de2e16977eebb,"This paper proposes a framework for federated learning where local participants can have their own personalized labels, which might not be compatible with others ( even for the same class ), and can be also possibly from a variety of multiple domains. In this sense, the authors propose a loosely constrained federated Learning framework called Agnostic Personalized Federated Learning ( APFL ), where any clients, regardless of what they have learned with their personalized labels can collaboratively learn while benefiting each other. The method measures task - level similarity based on locally learned knowledge and matches the relevant ones for personalized knowledge reflection. The authors extensively validate their method in both label - and domain - heterogeneous scenarios and show that their method outperforms the current state - of - the - art baselines on both single and multi - domain datasets."
SP:97f30bea31eccef6c770fbce1e14fd6d2493a178,"This paper proposes an object dynamics distillation network ( ODDN ) that distills explicit object dynamic representations ( e.g. velocity, velocity ) from raw video input. The authors also build a relation module that calculates object - pair interactions and applies it to the corresponding dynamic representations of objects. They verify their approach on tasks of video events reasoning and video prediction, which are two important evaluations for video understanding. The results show that visual representations of O DDN perform better in answering reasoning questions around physical events in a video compared to representaions of the previous scene representation methods."
SP:ba8e50d1fa9cb824fa3f76c0c691997cd151d760,"This paper proposes a new class of graph neural networks ( GNNs ) that allow positional features of nodes given by positional encoding ( PE ) techniques such as Laplacian Eigenmap, Deepwalk, etc.. The authors propose a class of GNN layers termed PEG with rigorous mathematical analysis to update the original node features and positional features simultaneously. Extensive link prediction experiments over 8 real - world networks demonstrate the advantages of PEG in generalization and scalability."
SP:cf448479f68c3194c1a9e11729bf70d7cc2ae8fd,"This paper proposes LaMer, a novel text style transfer framework based on large - scale language models. LaMer first mines the roughly parallel expressions in the non - parallel datasets with scene graphs, and then employs MLE training, followed by imitation learning refinement to leverage the intrinsic parallelism within the data. On two benchmark tasks (sentiment & formality transfer ) and a newly proposed challenging task ( political stance transfer ), LaMer achieves qualitative advances in transfer accuracy, content preservation, and fluency."
SP:8f7b2d1020d9e527118b8fb816760c13b0d0bfcb,"This paper proposes a method to answer hyper - relational queries in Graph Neural Networks ( GNNs ) based on a neural network model. The method is based on the idea of query answering ( QA ), which is an extension of the one - hop link prediction problem to hyper - rational queries. The authors propose to express queries in terms of a subset of first - order logic ( FOL ) and propose to answer conjunctive queries in latent space. Experiments are conducted to show that the proposed method is able to answer such queries on a variety of query patterns."
SP:5f8b58424a1a8eeb72217e75189d6f773a298a7a,"This paper proposes a new method for hyperparameter optimization for deep neural networks. The authors propose a method called DYHPO that learns to dynamically decide which configuration to try next, and for what budget. They propose a new surrogate for Gaussian Processes that embeds the learning curve dynamics and a new acquisition function that incorporates multi - budget information. They demonstrate the superiority of their method over state - of - the - art methods in large - scale experiments on a variety of datasets."
SP:99d3d94e3af5d2dc7b92c00ac1345d1d2dd0d15b,"This paper proposes a new method for quantizing neural networks to improve the performance of learned image compression. The authors propose to make the model inference integer - arithmetic - only, which is much simpler than existing training and fine - tuning based approaches yet still keeps the superior rate - distortion performance. They further improve the discretization of the entropy parameters and extend the deterministic inference to fit Gaussian mixture models. They show that the current state - of - the - art image compression models can infer in a cross - platform consistent manner, which makes further development and practice of learning image compression more promising."
SP:85d0df515e9e555f3ea1c21d607304dfaeae69c0,"This paper proposes an unsupervised noise reconstruction and removal network for denoising scanning electron microscopy images. The architecture, inspired by gated recurrent units, reconstructs and removes the noise by synthesizing the sequential data. The authors provide detailed performance analysis using numerical as well as empirical metrics."
SP:e6275b0b103fa90dcebcdd3d3c14c830c3402972,"This paper studies the label trick in graph neural networks ( GNNs ). The authors propose to use a randomly - selected portion of the training labels as GNN inputs, concatenated with the original node features for making predictions on the remaining labels. This so - called label trick accommodates the parallel use of features and labels, and is foundational to many of the top - ranking submissions on the Open Graph Benchmark ( OGB ) leaderboard. They show that under certain simplifying assumptions, the stochastic label trick can be reduced to an interpretable, deterministic training objective composed of two factors. The first is a data - fitting term that naturally resolves potential label leakage issues, while the second serves as a regularization factor conditioned on graph structure that adapts to graph size and connectivity."
SP:b6cbc3661f9c440687c3dd01ee35a118c87db377,"This paper proposes to model machine theory of mind ( ToM ) in a more flexible and symmetric scenario where all agents can speak, listen, see other agents, and move freely through a grid world. They show that SymmToM can be solved neither by using well - known multi - agent deep reinforcement learning ( RL ) models, nor by tailoring those models to our task. They also show that even maintaining the simple rules of the environment, modifying its parameters results in much more difficult challenges, even for models where we artificially introduce perfect information."
SP:f8ce83805eee46c6c196e8477bf10d8d7f7e0f46,This paper proposes a novel zero - shot object detection method for object detection in the manufacturing setting. The authors propose a novel neural network structure based on YOLOv5 and a novel attribute labelling method for objects in YCB Video dataset. The output bounding boxes can be further combined with other gZSL algorithm to achieve full zero - shots object detection and recognition. A novel splitting method for YCB video dataset that splits the dataset by seen and unseen objects can be used for both gZSD and GZSL research that related to daily objects.
SP:aa1dcd9217270010f16a00004facede942efea17,"This paper proposes a method to train an autoregressive latent video prediction model capable of predicting high - fidelity future frames with minimal modification to existing models, and produce high - resolution ( 256x256 ) videos. The method is based on a high - fidelity image generator ( VQ - GAN ) with a causal transformer model, and introduce additional techniques of top - k sampling and data augmentation to further improve video prediction quality. The proposed method achieves competitive performance to state - of - the - art approaches on standard video prediction benchmarks with fewer parameters, and enables high resolution video prediction on complex and large - scale datasets."
SP:7f57896afd63bc869d2db6ddf7abbeaa71daae11,"This paper proposes to use ViT - based generative adversarial networks ( GANs ) for image generation. The main idea is to use the ViT architecture to train a GAN based discriminator for image recognition. The authors show that existing GAN regularization methods interact poorly with self - attention, causing instability during training. To resolve this issue, they introduce several novel regularization techniques for training GAN with ViTs. For ViT generators, they examine architectural choices for latent and pixel mapping layers to faciliate convergence. Empirically, their approach, named ViTGAN, achieves comparable performance to the leading CNN based GAN models on three datasets : CIFAR-10, CelebA, and LSUN bedroom."
SP:bbae3afcaea0a2e54904cb8daaed7df4fe37da6e,"This paper proposes a two - stage training process to improve the ELBO performance of variational autoencoders in image generative modeling. The authors argue that the entropy in natural image distributions is attributable to visually imperceptible information, which dominates the training objective, giving models an easy way to achieve competitive likelihoods without successful modeling of the visually perceptible bits. Based on this hypothesis, they decompose the task of generative model explicitly into two steps : first prioritize the modeling of visually perceptibles information to achieve good sample quality, and then subsequently model the imperceptibles information and the bulk of the likelihood signal. They propose a secondary high - rate model on top of the low - rate models to overcome this issue."
SP:bfed56018134ec66cde9a7e958df964d4cca3164,"This paper proposes a method to estimate the optimal variance of a Diffusion Probabilistic Model ( DPM ) based on the Monte Carlo method and a pretrained score - based model. The authors show that both the optimal reverse variance and the optimal KL divergence of a DPM have analytic forms w.r.t its score function. They then propose a training - free inference framework that estimates the analytic forms of the variance and KL divergence using Monte Carlo methods and a score based model, and derive both lower and upper bounds of optimal variance and optimal divergence. They show that their method improves the log - likelihood of various DPMs, produces high - quality samples, and enjoys a 20× to 80× speed up compared to the full timesteps."
SP:3f935ba5784c3e86db72421426bc479061af1a4b,"This paper investigates the use of vision transformers ( ViTs ) in medical image classification and segmentation tasks. The authors consider whether it is feasible to switch to transformer - based models for medical image diagnosis as well, or if we should keep working with CNNs – can we trivially replace CNNs with transformers? They consider this question in a series of experiments on several standard medical image benchmark datasets and tasks. Their findings show that, while CNNs perform better if trained from scratch, off - the - shelf visiontransformers can perform on par with CNNS when pretrained on ImageNet, both in a supervised and self - supervised setting. They also suggest that ViTs can be used in medical images analysis, while at the same time potentially gaining from other properties of ViTs such as built - in explainability."
SP:a64e0535f268901e38fd51e027c612ebcdbae1a4,"This paper studies the pretraining neural language models ( NLMs ) for natural language understanding tasks. The authors show that the pretrained NLMs can model much stronger dependencies between text segments that appeared in the same training example, than it can between different training examples. This intuitive result has a twofold role. First, it formalizes the motivation behind a broad line of recent successful NLMs training heuristics, proposed for pretraining and fine - tuning stages, which do not necessarily appear related at first glance. Second, their result clearly indicates further improvements to be made in NLM pretraining for the benefit of Natural Language Understanding tasks."
SP:59066956fa2e423d5f2d2ea4f91c4ddf6afd4683,"This paper proposes a new method for learning to optimize ( L2O ) based on symbolic regression. The main idea is to use symbolic regression to learn a symbolic representation for the black - box optimization rule. The method is trained on ResNet-50 ( 23.5 million parameters ) and achieves state - of - the - art ( SOTA ) performance when applied to training larger ( ResNet -152, 58.2 million parameters) or very different deep models ( MobileNet v2 ( Sandler et al. 2018 ) on various datasets."
SP:54dfeb363beee9959aecc9e0853ff06e43bd94e4,"This paper proposes a method to certify the robustness of deep neural networks ( DNNs ) against adversarial attacks in reinforcement learning ( RL ). The proposed method is based on smoothing - based adversarial robustness certificates, where the adversarial perturbation at a particular time can be a stochastic function of current and previous observations and states as well as previous actions. The authors propose policy smoothing where the agent adds a noise to its observation at each time - step before passing it through the policy function to guarantee that the final total reward obtained by smoothing remains above a certain threshold, even though the actions at intermediate time - steps may change under the attack. They show that their certificates are tight by constructing a worst - case scenario that achieves the bounds derived in their analysis. The experiments on various environments like Cartpole, Pong, Freeway and Mountain Car show that the method can yield meaningful robustness guarantees in practice."
SP:e0f9add5fde18eaab0eeb2b10b14928acc8ec5b8,"This paper proposes a method for predicting the target domain accuracy using only labeled source data and unlabeled target data. The proposed method is based on a threshold on the model ’s confidence and predicts the accuracy as the fraction of unlabelled examples for which model confidence exceeds that threshold. The method outperforms previous methods across several model architectures, types of distribution shifts ( e.g. due to synthetic corruptions, dataset reproduction, or novel subpopulations ) and datasets ( WILDS, ImageNet, BREEDS, CIFAR, and MNIST ). The authors also explore the theoretical foundations of the problem, proving that, in general, identifying the accuracy is just as hard as identifying the optimal predictor and thus, the efficacy of any method rests upon ( perhaps unstated ) assumptions."
SP:e748bf6ee653087cae825df32a8546f9ccebfcf1,"This paper proposes a partial Wasserstein - 1 discrepancy ( PWAN ) method for partial distribution matching ( PDM ) problem, where the goal is to recover a transformation that matches one set to the other. The authors show that the proposed method is robust against outliers and the unknown non - rigid deformations. They show that PWAN can be efficiently optimized to handle large scale PDM problem by utilizing the partial PWAN method.    The authors also propose a neural network to learn the transformation adversarially with the network, which also incorporates an efficient coherence regularizer for non -rigid transformations to avoid unrealistic deformations, and show that it is robust and scalable."
SP:f94f77696d100b2638fa2a6d82c8df47db3b6a36,This paper proposes a novel method for transfer learning for hyperparameter optimization ( HPO ). The authors propose a novel Deep Kernel Gaussian Process surrogate with Landmark Meta - features ( DKLM ) that can be jointly meta - trained on a set of source tasks and then transferred efficiently on a new ( unseen ) target task. They design DKLM to capture the similarity between hyperparameters configurations with an end - to - end meta - feature network that embeds the set of evaluated configurations and their respective performance. They demonstrate the empirical superiority of their method against a series of state - of - the - art baselines on a very - large - scale experimental protocol ( 3.4 million HPO evaluations ) against a large number of baselines.
SP:e3c57f3589e8ab674644d900c14b3473cd71a23f,"This paper proposes a novel method for fingerprinting generative models that enables a responsible disclosure of state - of - the - art GAN models with distinct fingerprints. The proposed method is based on an efficient and scalable ad - hoc generation of a large population of models that can be trained while more than 1038 fingerprinted generator instances can be obtained with little overhead during deployment. The authors also justify several key properties of their fingerprinting mechanism, including effectiveness, fidelity, large capacity, scalability, secrecy, robustness, and immunizability."
SP:73bffd1a0856b80d29f7a2b2b68be57882531f07,This paper proposes a method to explain the similarity between two input pairs using a black - box similarity learner. The method is based on a feature - based explanation and a new form of explanation based on analogies. The main idea is to find pairs of examples that share the same level of similarity as the input pair and provide insight into (latent ) factors underlying the model ’s prediction. The proposed method outperforms baselines in both quantitative evaluation and human user study and provides reasons that users find sensible.
SP:6a3c4ae05d582f8896840483b08c735ced2976bc,"This paper studies the certified robustness of ensemble ML models. The authors show that ensemble models are more robust than a single model empirically, but the standard ensemble models only achieve marginal improvement compared to single model. To address this issue, the authors propose the lightweight Diversity Regularized Training ( DRT ) to train certifiably robust ensemble models under the model - smoothness assumption. The DRT enhanced ensembles can consistently achieve higher certification robustness than existing single and ensemble models, demonstrating the state - of - the - art certified L2 - robustness on MNIST, CIFAR-10 and ImageNet datasets."
SP:3002b29c27709780238876d8c3f81bbd6a0f8112,"This paper studies the expressive power of Graph Neural Networks ( GNNs ) in the context of graph neural networks ( GRNs ). The authors propose a new GNN model based on local neighborhoods that allows different tradeoffs of computational cost and expressive power. In particular, they prove that this model can count subgraphs of size k, and thereby overcomes a known limitation of low - order GNN - based models. They also show how recursively pooling can exploit sparsity to reduce the computational complexity compared to the existing higher - order GRNs. More generally, they provide a matching information - theoretic lower bound for counting sub - graphs with graph representations that pool over representations of derived ( sub -graphs )."
SP:5d0cbd84336caf5f31e1f98e11f6733230e4d792,"This paper studies knowledge - enhanced language models ( KMs ), which incorporate external knowledge into pretrained language models. The authors propose a simple probe model called Graph Convolution Simulator ( GCS ) to interpret the KI process and expose what kind of knowledge is integrated into these models. They find that only a small amount of factual knowledge is captured in these models during integration. While K - Adapter is better at integrating simple relational knowledge, complex relational knowledge is better in ERNIE. They further find that while K - adapter struggles to integrate time - related knowledge, it successfully integrates knowledge of unpopular entities and relations."
SP:7e73948421e98307fceb69a316d8a4e7c4926cda,"This paper studies the effect of the adaptation learning rate in meta - learning with mixed linear regression. The authors propose a principled way to estimate optimal adaptation learning rates that minimize the population risk of MAML. They show that compared with empirical risk minimization ( ERM ), the optimal learning rate is closer to the task optima, consistent with previous practical findings. They also extend their result about the choice of α to more practical regime, including deep learning."
SP:effbc85d89b1197d9c2abcaf5ff13864135dd6e1,"This paper proposes a method for source - free domain adaptation ( SFDA ) that aims to adapt a model trained on labelled data in a source domain to unlabelled data in the target domain without access to the source - domain data during adaptation. The authors propose Bottom - Up Feature Restoration ( BUFR ), a bottom - up training scheme for FR which boosts performance by preserving learnt structure in the later layers of a network. They demonstrate that BUFR outperforms existing SFDA methods on real and synthetic data in terms of accuracy, calibration, and data efficiency, while being less reliant on the performance of the source model."
SP:7d63034ec7e6a4f178681ff2a49feb485cd47116,"This paper proposes FedRBN, an adversarial robustness propagation method for distributed federated learning ( FL ). The proposed method is based on batch normalization ( BN ) statistics. The authors propose to train two separate BNs for each data type, which are adaptively chosen at the inference stage. The method is communication efficient as it only incurs an one - time additional communication after training. Experiments are conducted to demonstrate the feasibility and effectiveness of the proposed method."
SP:42c7a79e58b6a9f776fa6ae928bd89c194f9303f,"This paper proposes a novel transformer - like architecture that learns a mapping from the equilibrium actions to the network structure of the game without explicit knowledge of the utility function. The proposed method is tested on three different types of network games using both synthetic and real - world data, and demonstrate its effectiveness in network structure inference and superior performance over existing methods."
SP:1c7b9157cf8c06ca771da78895fc3af969b0fb85,"This paper proposes GraphANGEL, a relation prediction framework that predicts relations between each node pair by checking whether the subgraphs containing the pair are similar to other subgraphes containing the relation. Each graph pattern explicitly represents a specific logical rule, which contributes to an inductive bias that facilitates generalization to unseen relation types and leads to more explainable predictive models. The proposed method outperforms existing models in terms of heterogeneous graph based recommendation as well as knowledge graph completion. Extensive experimental comparisons on both transductive and inductive settings exhibit the superiority of the method."
SP:26ed25a7b42da2cf11b76a727102d8aa36d76657,"This paper proposes to combine contrastive learning ( CL ) with latent augmentation ( LA ) to build a few - shot system that learns useful representations without manual labels, while LA transfers semantic variations of the base dataset in an unsupervised way. They show that CL learned models generalize better than the supervised counterparts for histology images by a large margin. They analyze and provide empirical explanations for this observation, which could contribute to understanding how model generalizes to novel samples in the context of representation learning and histology image analysis."
SP:badbe687258cd5c282ca167b1f6fbfc6b5400dbf,"This paper proposes a continuous - time recurrent model ( mmRNN ) for learning long - term dependencies of irregularly - sampled time series. The authors show that the ODE - RNNs suffers from the vanishing and vanishing gradient problem, making them unable to learn long -term dependencies efficiently. They provide a solution by equipping arbitrary continuous time networks with a memory compartment separated from its timecontinuous state. This way, they encode a continuous time dynamical flow within the RNN, allowing it to respond to inputs arriving at arbitrary time - lags while ensuring a constant error propagation through the memory path. They call these models mixed - memory - rNNs ( MMMRNNs ) and show that they outperform RNN - based counterparts on non - uniformly sampled data."
SP:4efd22f9122fa5856a9f4302eb6875fa0c414912,This paper proposes a binarized version of the BERT model for natural language processing ( NLP ) tasks. The authors propose a method called BiBERT ( Bi - Attention Structure for maximizing representation information statistically and a DirectionMatching Distillation ( DMD ) scheme ) to optimize the full binarization of BERT accurately. The proposed method outperforms the baseline and existing state - of - the - art quantized BERTs with ultra - low bit activations by convincing margins on the NLP benchmark.
SP:619bd742e92bea6241852f5a9d2b7bacf13b393a,"This paper proposes a new method to solve keypoint detection and instance association by using Transformer. The authors argue that the naive attention patterns are still not subjectively controlled, so there is no guarantee that the keypoints will always attend to the instances to which they belong. To address this issue, the authors propose a novel approach of supervising self - attention for multi - person key point detection. By using instance masks to supervise self - Attention to be instance - aware, they can assign the detected keypoints to their instances based on the pairwise attention scores, without using pre - defined offset vector fields or embedding like CNN - based bottom - up models. An additional benefit of the method is that the instance segmentation results of any number of people can be directly obtained from the supervised attention matrix, thereby simplifying the pixel assignment pipeline."
SP:14750819593136fc9ef4efd032ab6f94dc5f6a02,"This paper proposes a new reinforcement learning method for considering mean - variance ( MV ) trade - offs in reinforcement learning ( RL ). The main idea is to train an agent to maximize the expected quadratic function, in which the maximizer corresponds to the Pareto efficient policy. To achieve this purpose, the authors propose two algorithms : ( 1 ) a gradient estimator for the gradient of the variance term, and ( 2 ) an agent - based policy maximizer. The authors show the effectiveness of the proposed methods in the experiments."
SP:f675b564b3a9c8626ce7944d752fa3e0d868428e,"This paper proposes a method for adapting a generative mixture density network ( MDN ) for end - to - end learning of a communication system using an autoencoder. The authors propose a fast and sample - efficient method that adapts the generative MDN model without modifying the encoder and decoder neural networks, and adapting only the MDN channel model. The method utilizes feature transformations at the decoder to compensate for changes in the channel distribution. Experimental evaluation on simulated datasets and real mmWave wireless channels demonstrate that the proposed method can adapt the model using very limited number of samples, and improve or maintain the error rate of the autoencoders under changing channel conditions."
SP:77dc92137ea490d3e1b4b8ee1630dbe2ee0bddfa,"This paper proposes a new model for the abductive natural language inference task ( αNLI ) where two observations are given, and the most plausible hypothesis is asked to pick out from the candidates. The authors argue that it is unnecessary to distinguish the reasoning abilities among correct hypotheses and similarly, all wrong hypotheses contribute the same when explaining the reasons of the observations. Therefore, they propose to group instead of ranking the hypotheses and design a structural loss called “ joint softmax focal loss ” in this paper. Based on the observation that the hypotheses are generally semantically related, they have designed a novel interactive language model aiming at exploiting the rich interaction among competing hypotheses. The IMSL method has achieved state - of - the - art results in ACC and AUC on both the validation set and test set. The best language model DeBERTa is not tested due to the constraint by our limited resources ( 4 - piece RXT 2080Ti )."
SP:17cd72df5fc19398f582d27516fd742b073f79e3,"This paper proposes an adversarially robust OOD detection method that combines a certifiable OOD detector with a standard classifier from first principles into an OOD aware classifier. The proposed method achieves the best of two worlds : certifiably robust detection, even for OOD samples close to the in - distribution, without loss in either prediction accuracy or detection performance for non - manipulated OOD data. Moreover, due to the particular construction of the classifier, the proposed method provably avoids the asymptotic overconfidence problem of standard neural networks."
SP:9c3756f13932236aff3e8104f4fa193dcc8fde2f,"This paper proposes Image Classification Eraser ( ICE ) to erase classification information for any encountered images from arbitrary dataset. The authors define a new Generalized Transferable Attack ( GTA ) problem where they assume the attacker has a set of surrogate models trained on different datasets ( with different label sets and image sizes ) and none of them is equal to the dataset used by the victim model. They then propose a novel method called Image classification eraser to erase information from arbitrary datasets. They show that existing transfer attack methods can be modified to tackle the GTA problem, but with significantly worse performance compared with ICE. Extensive experiments on Cifar-10 ( Krizhevsky et al. 2009 ), CIFar-100, and TieredImageNet ( Ren et al, 2018a ) demonstrate that the proposed ICE outperforms the modified transfer attacks methods on the GTA."
SP:2e0447c741a3f09be1095633d870200355211260,"This paper proposes a pre - training method for discriminative pre - trained language models ( PrLMs ) that aims to prevent false negative predictions from being used in the training process. The proposed method is based on the ELECTRA architecture ( Clark et al. 2019 ) and fine - tuned it on widely - used down - streaming benchmark tasks, including GLUE and SQuAD. The authors propose two methods : 1 ) soft regularization by minimizing the semantic distances between the prediction and the original one to smooth the rough cross - entropy and 2 ) hard correction to shield the gradient propagation of the false negative samples to avoid training with true negative predictions. Experimental results show that their approach boosts the baseline performance by a large margin, which verifies the effectiveness of their proposed methods."
SP:281bc59d639aa76d84921b3ec4ce1ee8f1ba5b51,"This paper proposes a novel open - world semi - supervised learning ( SSL ) setting that formalizes the notion that novel classes may appear in unlabeled test data. The authors propose ORCA, an end - to - end approach that assigns instances to previously seen classes or novel classes or forms novel classes by grouping similar instances without assuming any prior knowledge. The key idea in ORCA is to utilize uncertainty adaptive adaptive margin to circumvent the bias towards seen classes caused by learning seen classes faster than the novel classes. In this way, ORCA gradually increases the discriminability of the model during the training and reduces the gap between intra - class variance of seen with novel classes, and novel classes with seen classes. Extensive experiments on image classification datasets and a single - cell dataset demonstrate that ORCA consistently outperforms alternative baselines."
SP:6c572c4c21b01a0cf3fd9ef97fbb348ef4e405ae,"This paper proposes SLIM - QN, a light stochastic quasi - Newton optimizer for training large - scale deep neural networks ( DNNs ). The proposed method addresses two key barriers in existing second - order methods : 1 ) the high computational cost of obtaining the Hessian matrix and its inverse in every iteration ( e.g. KFAC ) and 2 ) convergence instability due to stochastically training ( L - BFGS ). To tackle the first challenge, SLIM-QN uses the BFGS update rule that directly approximates Hessian inverse using past parameters and gradients. To achieve stable convergence, the proposed method introduces momentum in Hessian updates together with an adaptive damping mechanism. The authors provide rigorous theoretical results on the convergence of SLIM -- QN and show that SLIM has much less compute and memory overhead compared to SGD."
SP:4bffce00ebb02d2e676eec897647ac14c3344deb,"This paper proposes a method for graph neural network ( GNN ) pruning based on Locality Sensitive Pruning ( LSP ) based on locality sensitive hashing ( LSH ). LSP pruned graphs are qualified with structure dynamics that alleviate the ability to distinguish between different graphs and mitigate the computation burden. Extensive experiments on synthetic and real - world datasets demonstrate the superiority of LSP, which removes a significant amount of edges from large graphs without compromising the performance."
SP:c5e024f4e2079586298519ca868630efd7579eca,"This paper proposes a data augmentation method for contrastive self - supervised learning ( SSL ) based on adversarial augmentation. The authors propose to decompose a sample x to be its variational auto - encoder reconstruction ( VAE ) reconstruction G(x ) plus the residual R(x) = x − G(X ), where the residual retains most identitydistinctive information due to an information - theoretic interpretation of the VAE objective.   The authors show that the proposed method can modify training data to be hard positives/negatives without distorting the key information about their original identities. The proposed method, IDAA, only needs a pretrained VAE model and does not require any labeled data. On multiple benchmarks on multiple benchmarks, when applied to different SSL methods, this simple yet principal data augmentation approach consistently brings improvements on both the efficiency and the performance on downstream tasks."
SP:0991bc5f213bd8ab7572e2fed309e1b57a35835b,"This paper proposes a new method for detecting distribution shifts in machine learning models. The authors propose a simple sequential method to detect distribution shifts that can be used to both detect harmful shifts while ignoring benign ones, and to allow continuous monitoring of model performance without increasing the false alarm rate. The proposed method is tested on both simulated and real data. It is shown that the proposed method outperforms existing methods on a variety of datasets."
SP:1c7b954273e3a9cda333385b15a3e8ed3bf8178a,"This paper proposes to combine neural implicit representations for appearance modeling with neural ordinary differential equations ( ODEs ) in order to obtain interpretable physical models directly from visual observations. The proposed model combines several unique advantages : ( i ) Contrary to existing approaches that require large training datasets, we are able to identify physical parameters from only a single video. ( ii ) The use of neural implicit representation enables the processing of high - resolution videos and the synthesis of photo - realistic imagery. ( iii ) The embedded neural ODE has a known parametric form that allows for the identification of interpretable parameters, and long - term prediction in state space. Furthermore, the photo -realistic rendering of novel scenes with modified physical parameters becomes possible."
SP:51efd1451343f4994d857daa5490e299b812bc2d,"This paper proposes a context - dependent Reinforcement Learning algorithm for Markovian Markov Decision Processes ( MDPs ). The authors propose to use a Hierarchical Dirichlet Process ( HDP ) prior for model learning, which is arguably best - suited for MDP modeling. They then derive a context distillation procedure, which identifies and removes spurious contexts in an unsupervised fashion. They argue that the combination of these two components allows to infer the number of contexts from data thus dealing with the context cardinality assumption, and then find the representation of the optimal policy enabling efficient policy learning using off - the - shelf RL algorithms. They show that their algorithm appears to provide an optimization profile with fewer local maxima and minima than the maximum likelihood approach, which they attribute to the Bayesian nature of their algorithm."
SP:ea167b126212b2092bc1190d7f8376bf7c54a888,"This paper proposes a novel framework to train knowledge based multilingual language models ( KMLMs ) based on knowledge - based knowledge graph data. The method is based on the Wikidata knowledge graphs, which are used to generate synthetic sentences and reasoning - based training data using the knowledge graphs. The authors then design pretraining tasks to facilitate knowledge learning, which allows the language models to not only memorize the factual knowledge but also learn useful logical patterns. The proposed method is evaluated on a wide range of knowledge - intensive cross - lingual NLP tasks including named entity recognition, factual knowledge retrieval, relation classification, and logic reasoning."
SP:6c11cf29c90f923346372ba6f11452c36e69ad6d,This paper proposes an unsupervised reinforcement learning approach to learn to act altruistically towards other agents by giving them more choice and thereby allowing them to better achieve their goals. The authors propose to train an agent that learns to increase the choices another agent has by preferring to maximize the number of states that the other agent can reach in its future. They evaluate their approach on three different multi - agent environments where another agent’s success depends on the altruistic agent ’s behaviour. They show that their approach can perform comparably to agents explicitly trained to work cooperatively in some cases even outperforming them.
SP:5dbc54201ba184266c5054f0d2944bd197bc307a,"This paper studies the phenomenon of double descent in finite - width neural networks. The main contribution of the paper is an analysis of the effect of the loss functions used to train neural networks on the double descent phenomenon. The authors propose a method to derive the population loss and the lower bound of the Hessian with respect to the interpolation threshold. The lower bound is derived based on the maximum - likelihood - type estimator, which is a parametric estimator based on maximum - likelihood - type neural networks, and the upper bound is based on a Hessian based estimator.   The authors show that Hessian - based estimators exhibit a double descent behaviour at the optimum, and more importantly, exhibit double descent behavior at the $ \epsilon$-threshold."
SP:b485114712055f39a7afb951dbc3db482ff523fd,"This paper proposes an edge - based sampling method, named Critical DropEdge, to overcome the exponential decay of trainability of deep GCNs. The proposed method is a graph - adaptive and connectivity - aware method is easy to implement in both finite - width and infinite - width GNNs. The experiments show using the proposed method can outperform counterparts in the large depth."
SP:25a92b3583afdc6892e59f1e769125d52c8011af,"This paper proposes a novel deep learning architecture that incorporates the second derivative input frames and target signals and evaluate it against clinical - grade contact sensor measurements. The authors show that adding second - order dynamics into the loss function improves the quality of the estimated higher - order signals in terms of waveform morphology and second - derivative inputs additionally improves performance when estimating second order dynamics. In addition, the authors propose a method to train a neural network model that is able to estimate higher order dynamics in a loss function.  "
SP:0a88d2fcbdfab3e196bf6b9c75adb1006ab87536,"This paper proposes a novel communication architecture called symbolic mapping as a basic component of the communication system of agent learning. The authors propose to use symbolic mapping in simple referential games to help agents learn a compositional and symmetric language in complex settings like dialog games. They show that symbolic mapping helps agents learn to use new symbols when the environment becomes more complex. They also explore vocabulary expansion, and show that with the help of symbolic mapping, agents can easily learn to using new symbols in complex environments."
SP:89575be04cb33b41d7a0a7b62f9496c2838a1317,"This paper proposes a hierarchical modular approach to learn agents that navigate and manipulate objects in a divide - and - conquer manner for the diverse nature of the entailing tasks. Specifically, the policy operates at three levels of hierarchy : ( 1 ) a sequence of subgoals to be executed based on language instructions by high - level policy composition controller ( PCC ) ; ( 2 ) a master policy by alternating between navigation policy and various independent interaction policies ; ( 3 ) manipulation actions with the corresponding object masks using the appropriate interaction policy. The proposed agent achieves state - of - the - art performance on the ALFRED benchmark."
SP:e2c8efe00db7baba2368f4f6a37815809b9e235e,"This paper proposes Nuisance - randomized distillation ( NURD ) to build predictive models that perform well regardless of the nuisance - label relationship. The authors define a family of distributions where the nuisance and the label are independent, and then introduce a distribution where the label and the nuisance are independent. They show that the representations in this set always perform better than those in this family, while representations outside of this set may not. They also prove that the representation from this set that is most informative of the label under this distribution is the one that is optimal on every member of the family simultaneously. They evaluate the proposed method on class - conditional Gaussians, labeling colored MNIST images ( Arjovsky et al. 2019 ), detecting waterbirds, and classifying chest X - rays."
SP:c75998b76f4e0510fc719d25959a10fc07db1c40,"This paper proposes OTTER ( Optimal TransporT distillation for Efficient zero - shot Recognition ), which uses online entropic optimal transport to find a soft image - text match as labels for contrastive learning. The authors evaluate the image encoder ’s zero shot recognition of common visual concepts on Google Open Images ( GOI ) ( 19,958 categories ) and multi - labeled ImageNet 10K ( 10032 categories ) from Tencent ML -Images ( Wu et al. 2019a ). OTTER outperforms ( 35 ) or ties ( 2 ) all baselines in 37 of the baselines on 7 different datasets."
SP:e83cd70377542b5d187998e2e4a7ac070f453ed6,"This paper presents Pix2Seq, a simple and generic framework for object detection. Unlike existing approaches that explicitly integrate prior knowledge about the task, this paper simply cast object detection as a language modeling task conditioned on the observed pixel inputs. Object descriptions ( e.g. bounding boxes and class labels ) are expressed as sequences of discrete tokens, and a neural net is trained to perceive the image and generate the desired sequence. The approach is based mainly on the intuition that if a neural network knows about where and what the objects are, we just need to teach it how to read them out. Beyond the use of task - specific data augmentations, the approach achieves competitive results on the challenging COCO dataset, compared to highly specialized and well optimized detection algorithms."
SP:abc9315f61929cc1c54dfef8ff83d7eac56ec2f2,"This paper proposes a method to distill the symbolic policy into a more interpretable version of the CNN policy. The proposed method is based on a teacher - student approach that distills the policy into an interpretable symbolic policy that is composed from geometric and numerical symbols and operators. The symbolic policy can be treated as discrete and abstracted representations of the policy network, but are found to be interpretable, robust and transferable.   The proposed symbolic distillation approach is experimentally demonstrated to maintain the performance and “denoise ” of the proposed symbolic policy on six specific environments, while achieving comparable or higher scores than the CNN based RL agents."
SP:04e7e181aeb1244ae1c4837ad416aef93ea3ea32,"This paper proposes a new model for image - to - image translation based on the StyleGAN2 framework. The proposed model is based on a Vector - Quantized Spatial Normalization ( VQSN ) module for the generator for better pose - identity disentanglement, and a joint - training scheme with self - supervision methods for the GANInversion encoder and the generator. The authors show that the proposed model outperforms existing baselines in terms of visual quality and translation accuracy, and outperforms other baselines on unseen out - of - domain images, including zero - shot image transfer and semantic - transfer."
SP:e51a7f45493064972585109f203a867e9828eb15,"This paper proposes a multi - layer perceptron ( MLP ) architecture to extract information from speech signals. The model splits feature channels into non - overlapped chunks and processes each chunk individually. These chunks are then merged together and further processed to consolidate the output. By setting different numbers of chunks and focusing on different contextual window sizes, speech - MLP learns multiscale local temporal dependency. The proposed model is evaluated on two benchmark datasets : keyword spotting and speech enhancement. In all experiments, the proposed MLP outperforms the transformer - based solutions, achieving better performance with fewer parameters lower GFLOPS."
SP:d708d3886f4abd4552d8ccb2096df7361c803b13,This paper proposes a new lower bound on the generalization error that can be achieved by any transfer learning algorithm for binary classification problems. The lower bound depends on a natural notion of distance that can easily be easily computed on real world data sets and requires minimal assumptions that enables it application to a broad range of problems.   The authors provide a precise answer to this question for Binary classification problems by deriving a novel lower bound. They also consider a more general setting where there are more than one source domains for knowledge transfer to the target task and develop new bounds on generalization errors in this setting. The authors compare their lower bounds with upper bounds achieved by transfer learning base - lines that utilize weighted empirical risk minimization on the combination of source(s ) and target data sets.
SP:f7511ba9ccad03233b34b1bf41bbac7361d20a57,"This paper proposes a probabilistic shape completion method extended to the continuous geometry of large - scale 3D scenes. The problem of shape completion is inherently ill - posed, and high - quality result requires scalable solutions that consider multiple possible outcomes. The authors employ the Generative Cellular Automata that learns the multi - modal distribution and transform the formulation to process large -scale continuous geometry. The local shape is incrementally generated as a sparse voxel embedding, which contains the latent code for each occupied cell. The training objective for the sparse embedding maximizes the variational lower bound of the complete shape distribution and therefore their progressive generation constitutes a valid generative model. Experiments show that their model successfully generates diverse plausible scenes faithful to the input, especially when the input suffers from a significant amount of missing data."
SP:d22d8f074adbe8fb0f25fb8f8d96201b3159bf6b,This paper proposes a new method for off - policy reinforcement learning based on state - independent temporal priors. The proposed method is based on a probabilistic mixture of policy and temporal prior. The authors show that the proposed method outperforms baselines in long - horizon continuous control tasks under sparse reward settings. They also provide empirical evidence that their method improves upon strong baselines.
SP:25e06c022ae8b3cbbb8db413d7b534a1a5c92391,"This paper proposes a Graph - Network - based Scheduler ( GNS ) for learning rate scheduling in deep neural networks. The proposed method uses a directed graph for the underlying neural network of the target problem and trains an agent to control the learning rate accordingly via reinforcement learning. The method can capture the intermediate layer information while being able to generalize to problems of varying scales. Besides, an efficient reward collection procedure is leveraged to speed up training. The authors evaluate their framework on benchmarking datasets, Fashion - MNIST and CIFAR-10 for image classification and GLUE for language understanding."
SP:d73cb0471c1770607ad3e4621cfc5f170683dd8e,"This paper proposes a method for deep object - centric learning from a point cloud, which is crucial for high - level relational reasoning and scalable machine intelligence. In particular, the authors introduce a framework, SPAIR3D, to factorize a 3D point cloud into a spatial mixture model where each component corresponds to one object. They derive the Chamfer Mixture Loss, which fits naturally into a variational training pipeline, and adopt an object - specification scheme that describes each object’s location relative to its local voxel grid cell. The authors evaluate their method on the task of unsupervised scene decomposition and show that it has strong scalability and is capable of detecting and segmenting an unknown number of objects."
SP:3c57e921c1bf23e482551ceb71702931a7f07439,This paper investigates the ability of large language models ( LLMs ) to act in interactive environments by grounding high - level tasks to a set of actionable steps ( i.e. “ open the fridge ” ). The authors propose a procedure that conditions on existing demonstrations and semantically translates the plans to admissible actions. They show that the resulting method substantially improves executability over the LLMs baseline.
SP:e0159d1c9df2e657892a3a0c77549df4698d9a1a,This paper proposes a method to generate samples from the uniform distribution deriving intrinsically from the Riemannian manifold learned by a VAE. The method is based on the Variational Autoencoder framework. The authors show that VAEs naturally unveil a Riemanian structure of the learned latent space. They show that using these geometrical considerations can significantly improve the generation from the vanilla VAE which can now compete with more advanced VAE models on four benchmark datasets. They also stress the proposed method’s robustness in the low data regime which is known as very challenging for deep generative models.
SP:b4b8e1727f8617894f10f20365cb68de79f0e650,"This paper proposes a novel transformer architecture that replaces redundant heads in transformers with a mixture of keys at each head. The key idea is to use a Gaussian mixture model and allow each attention head to focus on different parts of the input sequence efficiently. Compared to its conventional transformer counterpart, Transformer - MGK accelerates training and inference, has fewer parameters, and requires less FLOPs to compute while achieving comparable or better accuracy across tasks. The authors demonstrate the advantage of this architecture in a range of practical applications including language modeling and tasks that involve very long sequences."
SP:82731dcce233e748f63382e09b6224a513fe9689,"This paper proposes a new two - dimensional continuous environment for spatial navigation. The authors propose a direct - inverse model of environment dynamics to fuse image and action related signals, allowing reconstruction of the action relating the two successive images, as well as prediction of the new image from its current value and the action. They propose a minimalistic recurrent architecture, called Resetting Path Integrator ( RPI ), that can easily and reliably be trained to keep track of its position relative to its starting point during a sequence of movements. RPI updates its internal state using the ( possibly noisy ) self - motion signal, and occasionally resets it when the image signal is present. The internal state of this minimal model exhibits strong correlation with position in the environment."
SP:1a27c397d1e73def5e724c5c6f25548975ba50fa,"This paper proposes to study the effect of feature learning in neural networks on learning problems motivated by practical data, where the labels are determined by a set of class relevant patterns and the inputs are generated from these along with some background patterns. The authors prove that neural networks trained by gradient descent can succeed on these problems. The success relies on the emergence and improvement of effective features, which are learned among exponentially many candidates efficiently by exploiting the data ( in particular, the structure of the input distribution ). In contrast, no linear models on data - independent features of polynomial sizes can learn to as good errors. Furthermore, if the specific input structure is removed, then no polynomials algorithm in the Statistical Query model can learn even weakly. These results provide theoretical evidence showing that feature learning depends strongly on the input structure and leads to the superior performance."
SP:8ada73ed7eade9ebdeef376485e849c42575bc5f,"This paper studies the robustness of machine learning models to adversarial examples generated by test - time adversaries. The authors provide a methodology to analyze the robusts of fixed feature extractors, which in turn provides bounds on the robustnesses of any classifier trained on top of it. The tightness of these bounds relies on the effectiveness of the method used to find collisions between pairs of perturbed examples at deeper layers. For linear feature extractor, the authors provide closed - form expressions for collision finding while for arbitrary feature extractingor, they propose a bespoke algorithm based on the iterative solution of a convex program that provably finds collisions. They also identify the layers of robustly trained models that contribute the most to a lack of robustness, as well as compare the same layer across different training methods to provide a quantitative comparison of their relative robustness."
SP:874b5fa51924cbcceed490d98a0ea80f74586b32,"This paper proposes a new offline reinforcement learning method called Value - based Episodic Memory ( VEM ), which learns the V - function instead of the Q - function to naturally keep the learning procedure within the offline dataset. To enable effective generalization while maintaining proper conservatism in offline learning, they propose Expectile V - learning ( EVL ) which smoothly interpolates between the optimal value learning and behavior cloning. They introduce implicit planning along offline trajectories to enhance learned V - values and accelerate convergence. They provide theoretical analysis for the convergence properties of their proposed VEM method, and empirical results in the D4RL benchmark show that their method achieves superior performance in most tasks."
SP:34f08d92681504490c2f739b0d08f79f9764b2f5,"This paper proposes a novel adversarial training framework that learns to reweight the loss associated with individual training samples based on a notion of class - conditioned margin, with the goal of improving robust generalization. Inspired by MAML - based approaches, the authors formulate weighted adversarial learning as a bilevel optimization problem where the upper - level task corresponds to learning a robust classifier, and the lower - level learning is to learn a parametric function that maps from a sample’s multi - class margin to an importance weight. Extensive experiments demonstrate that their approach improves both clean and robust accuracy compared to related techniques and state - of - the - art baselines."
SP:3ad36be6b6900aabe43da043461cf178ce977082,"This paper proposes a method for equivariant graph neural networks ( SEGNNs ) that incorporate geometric and physical information in both the message and update functions. The authors define steerable node attributes, a new class of activation functions for general use with steerable feature fields, and introduce steerable MLPs for generalizing the existing model. The proposed method is evaluated on several tasks in computational physics and chemistry and provides extensive ablation studies. The results show that the more geometric quantities are injected the better the performance of the model."
SP:8928aa83f7ebd4e310f4fe1d01ff0eb0c96e4d2b,"This paper proposes a new differentiable physics model for differentiable materials based on gradient - based learning. The authors propose a differentiable fabrics model for composite materials such as cloths, where they dive into the granularity of yarns and model individual yarn physics and yarn - to - yarn interactions. They show that their model is more explicable, has higher data efficiency, generates more accurate predictions and fast in control learning. They also compare their model with the most similar work and traditional Bayesian optimization on inverse problems."
SP:2c8358c095b10981d3015b9f6c75765419a9480d,"This paper proposes a method for transfer learning in reinforcement learning that allows agents to learn a set of tasks from an unknown distribution and then decide what skills to add to its library and how to combine its current skills to solve new tasks. The authors provide theoretical bounds on the performance of the transferred policy on a new task and the number of tasks that need to be learned throughout an agent’s lifetime to generalise over a distribution. They show that the proposed method is able to achieve good performance on new tasks before training even starts. They also demonstrate that as a side effect of their transfer learning approach, an agent can produce an interpretable Boolean expression of its understanding of the current task."
SP:c85d71d05164d019cc32bf423e4c4fe20c169f41,"This paper proposes a distributed solution for MTSC based on a wavelet scattering transformation of the time series and distributed feature selection. The main contribution of the paper is to propose LightWaveS, a distributed method for training and inference of a multivariate time series classification model. The authors show that the proposed method is able to achieve speedup from 9x to 65x compared to ROCKET during inference on an edge device, on datasets with comparable accuracy and scalability."
SP:db43614ca016280a79448f44a97c81c8ff5ba981,This paper proposes a new pretraining method for adversarial learning based on auxiliary masked language models ( MLMs ). The main idea is to train multiple MLMs of different sizes to provide training signals at various levels of difficulty to train the discriminator to learn better with challenging replaced tokens. The authors propose to use a mixture of weights over the auxiliary MLMs’ outputs to maximize discriminator loss by backpropagating the gradient from the discriminators via Gumbel - Softmax. The proposed method is evaluated on GLUE and SQuAD benchmarks for BERT base - sized models.
SP:db3825633ab5d0671340390b23ab655838cc38b2,"This paper proposes an adaptive fine - tuning method for relational knowledge extraction from pre - trained language models. The authors propose to use a small training dataset of existing facts from a knowledge graph to train a language model on the standard fill - mask task. The training of the language model is performed on a small dataset of facts from the knowledge graph, and the model is trained on a restricted set of relations. Experiments are conducted to show that the model can learn to extract relational knowledge from the training of semantically related relationships."
SP:ae25d32714b2b9f7e02cc20f4a36252e20e78e4f,"This paper proposes to learn knowledge base embeddings in different geometric spaces and apply manifold alignment to align the shared entities. The aligned embedding is evaluated on the out - of - taxonomy entity typing task, where they aim to predict the types of the entities from the knowledge graph. Experimental results on two datasets based on YAGO3 demonstrate that their approach has significantly good performances, especially in low dimensions and small training rates."
SP:9ab3bc525ee4a9c96518c43e4c43082655a7674f,"This paper proposes a one - shot learning framework for link prediction in temporal knowledge graphs. The proposed method employs a self - attention mechanism to effectively encode temporal interactions between entities, and a network to compute a similarity score between a given query and a ( 1 - shot ) example. The authors conduct experiments on two real - world datasets and demonstrate the superiority of the proposed model over state - of - the - art baselines."
SP:91f92a40e12afd0702f07ae7f4175ecce57b7007,"This paper proposes a method for learning to solve tasks of increasing complexity by building on top of previously acquired knowledge. The authors propose to represent a solver for each task as a neural module that calls existing modules ( solvers for simpler tasks ) in a functional program - like manner. The lower modules are a black box to the calling module, and communicate only via a query and an output. The module for a new task learns to query existing modules and composes their outputs in order to produce its own output. They test their model in learning a set of visual reasoning tasks, and demonstrate improved performances in all tasks by learning progressively. By evaluating the reasoning process using human judges, they show that their model is more interpretable than an existing model."
SP:de33b02e7f2faec5bcae9a5516721aa1ef190572,"This paper proposes a new neural network architecture named Selective Convolutional Unit ( SCU ), a widely - applicable architectural unit that improves parameter efficiency of various modern CNNs with bottlenecks. SCU gradually learns the channel - selectivity on - the - fly via the alternative usage of ( a ) pruning unimportant channels, and ( b ) rewiring the pruned parameters to important channels. The paper shows that SCU can achieve both model compression and accuracy improvement compared to baselines."
SP:2d80fa4bc440061be2234b5070503d3fa056baed," classifier learns a scoring function that preserves the order induced by the class posterior under mild assumptions, which can be used as a classifier by setting an appropriate threshold. The proposed method outperforms previous methods for PU learning on various real - world datasets. The experimental results show that the proposed method is appropriate for real world applications compared to existing approaches for PUlearning."
SP:5f312626b0613d2e07c59214c5f00db208a98717,"This paper proposes an adaptive weighting method for learning neural networks based on cosine similarity between gradients of tasks. The main idea is to use the similarity between the gradients as a weight to detect when an auxiliary loss is helpful to the main loss. The authors show that their approach is guaranteed to converge to critical points of the main task and demonstrate the practical usefulness of the proposed algorithm in a few domains : multi - task supervised learning on subsets of ImageNet, reinforcement learning on gridworld, and reinforcementlearning on Atari games."
SP:e270ae3eeb7ab4fa91ba37d4d68ce10f2fa0a3b5,"This paper proposes a geometric framework to analyze the high - dimensional geometry of adversarial examples. In particular, for low - dimensional data manifolds embedded in high -dimensional space there are many directions off the manifold in which to construct adversarial example. Adversarial examples are a natural consequence of learning a decision boundary that classifies the low -dimensional data manifold well, but classifies points near the manifold incorrectly. Using this geometric framework, the authors prove ( 1 ) a tradeoff between robustness under different norms, ( 2 ) that adversarial training in balls around the data is sample inefficient, and ( 3 ) sufficient sampling conditions under which nearest neighbor classifiers and ball - based training are robust are robust. The authors provide experimental evidence on synthetic datasets and MNIST that support their theoretical results."
SP:e07d948a79d478ecd23a0a4406d4ddd3ac5e3be3,"This paper proposes a new representation learning framework based on discrete dimensionality reduction and deep generative modeling to learn discrete representations of time series data. The authors propose a gradient - based version of the traditional self - organizing map algorithm that is more performant than the original. They also propose a Markov model in the representation space in the temporal transition structure, which improves clustering performance even further and provides additional explanatory insights as well as a natural representation of uncertainty."
SP:5915ee71ea58dbdbafa31c1ad291d1e5940a0cf4,"This paper investigates the properties of multidimensional probability distributions in the context of latent space prior distributions of implicit generative models. The authors show that the distribution mismatch can be eliminated completely by the proper choice of the latent probability distribution or using non - linear interpolations. They prove that there is a trade off between the interpolation being linear, and the latent distribution having even the most basic properties required for stable training, such as finite mean. They also provide a general method of creating non -linear interpolations that is easily applicable to a large family of commonly used latent distributions."
SP:19b63ca635712f1509ca6e0141303c192f2709e0,"This paper proposes a method to learn deep neural networks in hyperbolic space by imposing a hyperboloid model on the embeddings used to compute the attention mechanisms for different neural networks architectures. The authors propose to use the hyperboloids to encode the embedding space more efficiently without increasing the number of parameters of the model. The method shows improvements in generalization on neural machine translation on WMT’14 ( English to German ), learning on graphs ( both on synthetic and real - world graph tasks ) and visual question answering ( CLEVR ) tasks while keeping the neural representations compact."
SP:f6049e9f80a63c9306c1cebcb6b229aa6da44ddc,"This paper presents an empirical security analysis of DNN fingerprinting attacks that exploit cache side - channel attacks. The authors define the threat model for these attacks as a co - located process on the host machine where the victim ’s deep learning ( DL ) system is running and passively monitors the accesses of the target functions in the shared framework. They introduce DeepRecon, an attack that reconstructs the architecture of the victim network using the internal information extracted via Flush+Reload, a cache side channel technique. They demonstrate how an attacker can reconstruct the architectures of two common networks, VGG16 ( Simonyan & Zisserman, 2014 ) and ResNet50 ( He et al. 2016 ) as proof of concept. They also demonstrate an example of model fingerprinting in a transfer learning attack. Finally, they propose countermeasures to obfuscate an attacker from extracting the correct attributes and sequences using observation attacks like deepRecon and show that these defenses significantly increase the errors in the extracted attributes."
SP:6a3dd89db6c24a1f98e8866ef0a4c1c2c1ec6635,"This paper proposes a hierarchical network model, called Hierarchical Prediction Network ( HPNet ), to understand how spatiotemporal memories might be learned and encoded in a representational hierarchy for predicting future video frames. The model is inspired by the feedforward, feedback and lateral recurrent circuits in the mammalian hierarchical visual system. The network learns by comparing the incoming signals with its prediction, updating its internal model of the world by minimizing the prediction errors at each level of the hierarchy in the style of predictive self - supervised learning. This allows it to learn relationships among movement patterns, yielding state - of - the - art performance in long range video sequence predictions in benchmark datasets. The paper shows that hierarchical interaction in the network introduces sensitivity to memories of global movement patterns even in the population representation of the units in the earliest level."
SP:fb74e57f35666742caf651e6da33b5defcf259a8,"This paper proposes a method to compute continuous embeddings for kmers from raw RNA - Seq data, in a reference - free fashion. The authors show that their model captures information of both DNA sequence similarity as well as DNA sequence abundance in the embedding latent space. They confirm the quality of these vectors by comparing them to known gene sub - structures and report that the latent space recovers exon information from raw RNSeq data from acute myeloid leukemia patients. Furthermore they show that this latent space allows the detection of genomic abnormalities such as translocations and patient - specific mutations, making this representation space both useful for visualization and analysis."
SP:03aca6ff6a7f0ad2d5ccbcb15ed9536e305a9880,"This paper proposes an architecture compression method for model compression. The proposed method is based on a 1 - D CNN encoder / decoder, which is trained to learn a mapping from discrete architecture space to a continuous embedding and back. This embedding is jointly trained to regress accuracy and parameter count in order to incorporate information about the architecture’s effectiveness on the dataset. The authors demonstrate the effectiveness of their approach on several visual recognition tasks such as CIFAR-10/100, FMNIST and SVHN and achieve a greater than 5 - 20x compression on architectures. They also compare this approach to conventional compression methods such as pruning, distillation and reinforcement learning and show that their architectures are smaller and faster than the baseline methods."
SP:0511b5d10a90e3fe814e2d35208b4a987894ea62,"This paper proposes a framework for planning online and learning offline, where an agent with an internal model needs to continually act and learn in the world. The authors propose to combine local trajectory optimization, global value function learning, and exploration. They show that trajectory optimization can be used to perform temporally coordinated exploration in conjunction with estimating uncertainty in value function approximation. This exploration is critical for fast and stable learning of the value function. They also study how approximate value functions can help reduce the planning horizon and allow for better policies beyond local solutions."
SP:771494fda4702cd8c7efbf225b19028f91b449b9,This paper proposes a zero - shot dual NMT system for low - resource language translation. The proposed method is based on reinforcement learning and monolingual training. The authors show that the proposed method outperforms standard NMT systems on the UN corpus. They also show that it outperforms LSTM - based and Transformers - based unsupervised NMTs.
SP:1558dc03f99670f9ddccdca9c223a2baf962d438,"This paper proposes a generative adversarial network ( IRGAN ) based on the framework for Information - Retrieval ( IR ). IRGAN models the conditional probability distribution p(d|q ) over the documents ( d ) given the query ( q ). The authors argue that optimizing their minimax loss function will result in a generator which can learn the distribution, but their setup and baseline term steer the model away from an exact adversarial formulation, and this work attempts to point out certain inaccuracies in their formulation. They propose a co - training like setup where two models are trained in a Co - Training rather than an adversarial fashion."
SP:6a13dda852ab075a3c0fb691476d6dc57919c729,"This paper proposes a new method for estimating sparse representations in variational auto - encoders ( VAEs ) based on sparse coding. The authors propose to explicitly model sparsity in the latent space of a VAE with a Spike and Slab prior distribution. They derive the evidence lower bound using a discrete mixture recognition function thereby making approximate posterior inference as computational efficient as in the standard VAE case. With the new approach, they are able to infer truly sparse representations with generally intractable non - linear probabilistic models. They show that these sparse representations are advantageous over standard VAEs representations on two benchmark classification tasks ( MNIST and Fashion - MNIST ) by demonstrating improved classification accuracy and significantly increased robustness to the number of latent dimensions."
SP:06a22143186fa2948fbe324ccae96a62ff12064e,"This paper proposes a novel feature matching - based approach to train generative models. The proposed method, Generative Feature Matching Networks ( GFMN ), leverages pretrained neural networks such as autoencoders and ConvNet classifiers to perform feature extraction. The experimental results demonstrate that, due to the expressiveness of the features from pretrained ImageNet classifier, even by just matching first order statistics, the approach can achieve state - of - the - art results for challenging benchmarks such as CIFAR10 and STL10."
SP:2d7cf2f07a27d6c8e304a1b47c25387ad2e4432d,"This paper presents a theoretical analysis of the expressive power of graph neural networks ( GNNs ) for graph representation learning. The main contribution of the paper is to analyze the discriminative power of popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, and show that they cannot learn to distinguish certain simple graph structures. The paper then develops a simple architecture that is provably the most expressive among the class of GNNS and is as powerful as the WeisfeilerLehman graph isomorphism test. The authors validate their theoretical findings on a number of graph classification benchmarks, and demonstrate that their model achieves state - of - the - art performance."
SP:51126f2dd37ce57d2614c9044ede1e43627f0829,"This paper proposes a framework for interpretable continual learning ( ICL ) based on the variational continual learning framework to take advantage of its flexibility and efficacy in overcoming catastrophic forgetting. ICL uses saliency maps to provide explanations of performed tasks and propose a new metric to assess their quality. Experiments show that ICL achieves state - of - the - art results in terms of overall continual learning performance as measured by average classification accuracy, and also by its explanations, which are assessed qualitatively and quantitatively using the proposed metric."
SP:27a565b3e5442b93d208652784051e640b0c1bfe,"This paper proposes a new evaluation framework for adversarial attacks on neural sequence - to - sequence ( seq2seq ) models taking meaning preservation into account and demonstrate that existing methods may not preserve meaning in general. Based on these findings, they propose new constraints for attacks on word - based MT systems and show, via human and automatic evaluation, that they produce more semantically similar adversarial inputs. Furthermore, they show that performing adversarial training with meaning - preserving attacks is beneficial to the model in terms of adversarial robustness without the test performance without hurting performance."
SP:54ddd8132bf9e4259d2c2d72b348d2bb5f9e227c,"This paper proposes a new reinforcement learning algorithm that combines the policies using original rewards and inverse ( negative ) rewards to improve the performance of reinforcement learning algorithms. The proposed algorithm is based on deep Q - learning, double Q - Learning, and on - policy actor - critic. Experiments on OpenAI gym show that the hybrid policy achieves better performance than the original policies and is more stable."
SP:89a732b57934d08b937c93560f391b7758e54f8a,"This paper proposes a method to learn a hierarchical object representation and a dynamics model for object parts from unlabeled videos. The model learns to recognize the object parts via a layered image representation, predict hierarchy via a structural descriptor that composes low - level concepts into a hierarchical structure, and model the system dynamics by predicting the future. Experiments on multiple real and synthetic datasets demonstrate that the model works well on all three tasks : segmenting object parts, building their hierarchical structure and capturing their motion distributions."
SP:bb2a655d67bed9da43f0b8ec7d888b89c217d12e,"This paper proposes Deep Determinantal Generative Classifier ( DDGC ), a generative classifier based on the discriminative deep model. The main idea of DDGC is to estimate the parameters of the classifier using the minimum covariance determinant estimator. The authors show that DDGC outperforms the softmax classifier on CIFAR-10 dataset with 60% noisy labels from 53.34% to 74.72%. The authors also show that it is robust against adversarial perturbations due to its large margin property."
SP:0fa525cc708470b757a60117cb608bb2feaa2c50,"This paper proposes a model - free method for subgoal discovery using incremental unsupervised learning over a small memory of the most recent experiences of the agent. The authors propose a unified algorithm that incorporates the learning of useful internal representations of states, automatic sub goal discovery, intrinsic motivation learning of skills, and learning of subgoal selection by a “ meta - controller ”, all within the model free hierarchical reinforcement learning framework. They demonstrate the efficiency of their method on two RL problems with sparse delayed feedback : a variant of the rooms environment and the ATARI 2600 game called Montezuma’s Revenge."
SP:e5861538bc8bb9165cb33299bbf12dd875abf976,"This paper proposes a neural framework to solve the Circuit Satisfiability Problem ( SAT ), which is a combinatorial optimization problem. The authors propose a rich embedding architecture that encodes the problem structure and an end - to - end differentiable training procedure that mimics Reinforcement Learning and trains the model directly toward solving the SAT. The experimental results show the superior out - of - sample generalization performance of the framework compared to the recently developed NeuroSAT method. The paper also shows the superior performance of their framework especially in terms of generalizing to new problem domains."
SP:ff3e5d44619df3825632b0b1a943add081364861,This paper proposes a new deep RL algorithm based on the cross - entropy method ( CEM - RL ) and TD3 ( TD3 - DDPG ). The proposed method is based on a combination of two existing deep RL algorithms : DDP - RL and TD - RL. The authors show that the proposed method achieves better sample efficiency than DDP-RL and TD-RL alone.
SP:78b2eb326695da0b0cc4ba39a9206d11644a5e32,This paper proposes an interpretable multi - variable recurrent neural network ( LSTM ) based on a hidden state matrix and update process to learn variableswise hidden states. The authors propose a mixture attention mechanism and associated summarization methods to quantify the temporal and variable importance in data. Extensive experiments using real datasets demonstrate the prediction performance and interpretability of IMV-LSTM in comparison to a variety of baselines. It also exhibits the prospect as an end - to - end framework for both forecasting and knowledge extraction over multivariate data.
SP:1c26660569b579f060f7b4a31e321c6d2356b928,"This paper proposes a data augmentation method called feature smoothing for adversarial defense against adversarial attacks. The proposed method trains a neural network on virtual training data as an interpolation of features from a pair of samples, with the new label remaining the same as the dominant data point. The paper also proposes an unified framework to understand the connections and differences among different different efficient methods by analyzing the biases and variances of decision boundary. The experiments on MNIST and CIFAR10 datasets explore different combinations of known regularization and data augmentation methods and show that feature - smoothing with logit squeezing performs best for both adversarial and clean accuracy."
SP:88d652f9e411dd3a2e9ad651d9011e579653c6aa,"This paper proposes a theoretical framework for deep convolutional neural networks with ReLU nonlinearity. The framework bridges data distribution with gradient descent rules, favors disentangled representations and is compatible with common regularization techniques such as Batch Norm, after a novel discovery of its projection nature.   The framework is built upon teacher - student setting, by projecting the student’s forward / backward pass onto the teacher ’s computational graph. The authors do not impose unrealistic assumptions ( e.g. Gaussian inputs, independence of activation, etc ). Their framework could help facilitate theoretical analysis of many practical issues."
SP:7842bbe0e2324cfd732db8745550733ccc3dfcdc,"This paper proposes a modular architecture of neural networks with a Behavioral Module ( BM ) and corresponding end - to - end training strategy. The proposed method allows efficient learning of behaviors and preferences representation. This property is particularly useful for user modeling ( as for dialog agents and recommendation tasks, as allows learning personalized representations of different user states ). The experiments show that the proposed method. allows separation of main task’s objectives and behaviors between different BMs. Experiments also show network extendability through independent learning of new behavior patterns. The experimental results show the effectiveness of the approach on video games domain."
SP:300c391ff644b6889cd9ae27cf0d162dfcdd4451,This paper proposes a differentiable formulation for neuromodulation of plasticity that can be used to train neural networks with gradient descent. The authors propose a framework backpropamine in reference to its ability to emulate the effects of natural neurodulators ( like dopamine ) in artificial neural networks trained by backpropagation. The experimental results show that the proposed framework outperforms both non - plastic and non - modulated plastic networks on simple reinforcement learning tasks and on a language modeling task.
SP:1ab5d94d31e99351433436c026799c8aa597bf73,"This paper proposes a novel quantization method for deep neural network training. The method is based on re - training the full precision model, followed by directly optimizing the corresponding binary model. The quantization training process takes no longer than the original training process. The authors propose a new loss function to regularize the weights, resulting in reduced quantization error. Combining both help them achieve full precision accuracy on CIFAR dataset using binary quantization and WikiText-2 using 2 - bit quantization."
SP:0876b1d9a6d664808ca1ab15865679fbf638267e,"This paper proposes an open - ended method for style transfer onto open - ended content. The method is based on the VAE reconstruction loss and a style encoder. The authors propose an auxiliary loss, leakage filtering, to ensure that no style information remaining in the content representation is used for reconstruction and vice versa. They propose to synthesize novel images by decoding the style representation obtained from one image from another image. They obtain state - of - the - art performance on few - shot learning tasks using this method."
SP:d37e15cde7765fca87595a242f0a4511b3346d46,"This paper proposes a new method to drastically speed up deep reinforcement learning ( deep RL ) training for problems that have the property of state - action permissibility ( SAP ). Two types of SAP are defined under SAP. The first type says that after an action at is performed in a state st and the agent reaches the new state st+1, the agent can decide whether the action at at is permissible or not permissible in state st. The second type of SAP says that even without performing the action in the state st, an agent can already decide whether at is permitted or not in st. To this end, the authors propose a novel approach to using the SAP property, i.e. building a binary predictive model to predict whether an action in state is permissible ahead of time. Experimental results show that the proposed approach can result in a huge speedup in RL training."
SP:20015d8b60e13300586b67c281858cbe28825c48,"This paper studies the behavior of weight - tied multilayer vanilla autoencoders under the assumption of random weights. Via an exact characterization in the limit of large dimensions, the analysis reveals interesting phase transition phenomena when the depth becomes large. The paper provides quantitative answers and insights to three questions that were yet fully understood in the literature. Firstly, it provides a precise answer on how the random deep weight - tied autoencoder model performs “approximate inference ” as posed by Scellier et al. ( 2018 ) and its connection to reversibility considered by several theoretical studies. Secondly, it shows that deep autoen coders display a higher degree of sensitivity to perturbations in the parameters, distinct from the shallow counterparts. Thirdly, it obtained insights on pitfalls in training initialization practice, and demonstrate experimentally that it is possible to train a deep auto - coder model even with the tanh activation and a depth as large as 200 layers."
SP:91764f80dbe2401ade38b35a8253ba05f0f86386,"This paper proposes a simple black - box attack algorithm for adversarial image search. The proposed algorithm is based on an iterative search strategy based on the discrete cosine transform ( DCT ) algorithm. The authors propose to randomly pick a low frequency component of the DCT and either add or subtract it to the target image. The algorithm can be implemented in PyTorch in less than 20 lines of code. The method can be used for both targeted and untargeted attacks, resulting in previously unprecedented query efficiency in both settings."
SP:fc20ae0fbf57a1ce489c04b85c7c2f4c93dc2450,"This paper proposes a new method for learning intra - option policies, called Successor options, that leverages the successor representations to achieve the same. The authors propose a novel pseudo - reward for learning the intra - options policies that extends to function approximators. They also propose an incremental approach that alternates between exploration and option construction to navigate the state space in tasks with a fixed horizon setup where primitive actions fail to explore fully. They demonstrate the efficacy of their approach on a collection of grid worlds and on complex high dimensional environments like Deepmind - Lab."
SP:12a172c1e2892d016b37932acfc48dcb56874a89,"This paper studies the problem of domain division which aims to segment instances drawn from different probabilistic distributions. This problem exists in many previous recognition tasks, such as Open Set Learning ( OSL ) and Generalized Zero - Shot Learning ( G - ZSL ) where the testing instances come from either seen or unseen / unseen / novel classes. The authors propose a domain division algorithm to split the instances into known, unknown and uncertain domains, and then conduct recognition tasks in each domain. Two statistical tools, namely, bootstrapping and Kolmogorov - Smirnov test, are introduced to uncover and fine - tune the decision boundary of each domain, and the uncertain domain is newly introduced in the framework to adopt those instances whose domain labels cannot be predicted confidently. Extensive experiments demonstrate that the proposed algorithm achieves the state - of - the - art performance on OSL and G -ZSL benchmarks."
SP:28bcf7c6a4673e9ec2b4ebed09839d85188e0b2a,"This paper proposes a neural network for classification and regression, without the need to learn layout structures in the output space. Standard solutions such as softmax cross - entropy and mean squared error are effective but parametric, meaning that known inductive structures such as maximum margin separation and simplicity ( Occam’s Razor ) need to be learned for the task at hand. Instead, the authors propose polar prototype networks, a class of networks that explicitly states the structure, i.e., the layout, of the output. The structure is defined by polar prototypes, points on the hypersphere of the input space. For classification, each class is described by a single polar prototype and they are a priori distributed with maximal separation and equal shares. For regression, they show that training can be performed as a polar interpolation between two prototypes, arriving at a regression with higher -dimensional outputs."
SP:d1034342785d133cf8372b8624897963cc2ee83a,"This paper proposes a reward learning algorithm for reinforcement learning ( RL ) agents that learns implicit preferences about what to do and what not to do in a proof - of - concept environment. The authors show that the initial state of the world at initialization serves as a source of information about human preferences, which can be used to infer both side effects that should be avoided as well as preferences for how the environment should be organized.   The authors propose an RLSP algorithm that infers reward from initial state based on a Maximum Causal Entropy ( MCE ) model of human behavior. The algorithm is evaluated on a suite of proof -of - concept environments designed to show the properties of RLSP."
SP:417a4e0acee699b3e004ad30d0ecf533a9ed987e,"This paper proposes a method for learning dependency structures between latent variables in deep latent variable models. The method combines the complementary strengths of deep generative models and probabilistic graphical models. In particular, it expresses the latent variable space of a variational autoencoder ( VAE ) in terms of a Bayesian network with a learned dependency structure. The network parameters, variational parameters as well as the latent topology are optimized simultaneously with a single objective. Inference is formulated via a sampling procedure that produces expectations over latent variable structures and incorporates top - down and bottom - up reasoning over latent variables values. The authors validate their framework in extensive experiments on MNIST, Omniglot, and CIFAR-10."
SP:976dedab53e69610692a563382ada1dbb82c1e9d,"This paper proposes a dynamical neural network for solving a dictionary learning problem. The proposed method is based on top - down feedback, contrastive learning, and spiking neurons. The authors show that the proposed method can be constructed from individual neurons and the true gradients for learning are provably computable by individual neurons. They also show that their method is computable in terms of the gradient information of the dictionary learning objective function which the network minimizes, as well as gradient information for the network to maintain weight dependency."
SP:f45117a6beaeb86a70b1380b4fac3cfba37fb892,This paper proposes an encoder - decoder network for lane detection based on CNNs. The proposed network is based on multiple encoder decoders module in end - to - end ways and show the promising results for the lane detection task. The paper also proposes different configurations of the encoder and decoder module. The results show that the proposed network outperforms other encoder / decoder networks in lane detection.
SP:68b0a10ca06df74612d0753cc3f3ddddde806035,"This paper proposes a new method for batch contextual bandit learning from logged bandit feedback. The proposed method is called Maximum Likelihood Inverse Propensity Scoring ( MLIPS ), which estimates a maximum likelihood surrogate policy based on the logged action - context pairs, and then use this surrogate policy as the proposal distribution to obtain the inverse propensity weights in the off - policy estimator. The authors show that MLIPS is asymptotically unbiased, and moreover, has a smaller nonasymptotic mean squared error than IPS. They evaluate the MLIPS estimator on several multi - label classification problems and a large - scale ad placement dataset to demonstrate its empirical effectiveness on mean - squared error reduction for policy and optimization."
SP:8e0ed65c5dded23b34798499b2436b24422fd729,"This paper proposes to learn an individualized feature embedding specific to a given query image for better classifying, i.e. given a query image, a kernel generator is trained to generate convolutional kernels for different query images during training, which can generalize to unseen categories without fine - tuning. The proposed method achieves competitive results on two standard few - shot classification data sets, including Omniglot Lake et al ( 2011 ) and miniImageNet Vinyals et al. ( 2016 )."
SP:faa3f7ffdcfb6e3b8ec0421193dae3d9987b015c,"This paper proposes an evolutionary algorithm for deep neural networks ( DNNs ) that can evolve the weights of a DNN with a simple, gradient - free, population - based genetic algorithm ( GA ) and it performs well on hard deep RL problems, including Atari and humanoid locomotion. The Deep GA successfully evolves networks with over four million free parameters, the largest neural networks ever evolved with a traditional evolutionary algorithm, and the Deep GA is faster than ES, A3C, and DQN ( it can train Atari in ∼4 hours on one workstation or ∼1 hour distributed on 720 cores )."
SP:dfdbe3267a8160f24746884cdf5297993e424231,"This paper proposes a new curiosity method for reinforcement learning that uses episodic memory to form the novelty bonus. To determine the bonus, the current observation is compared with the observations in memory, which incorporates rich information about environment dynamics. This allows us to overcome the known “couch - potato ” issue of prior work — when the agent finds a way to instantly gratify itself by exploiting exploiting actions which lead to hardly predictable consequences. The authors compare their method on a range of tasks from visually rich 3D environments VizDoom, DMLab and MuJoCo, and show that their method outperforms the state - of - the - art curiosity method ICM."
SP:1e58a1c5344d1b5b7c8a40210a243700bd933d65,"This paper presents a method for describing transition models in complex uncertain domains using relational rules. For any action, a rule selects a set of relevant objects and computes a distribution over properties of just those objects in the resulting state given their properties in the previous state. An iterative greedy algorithm is used to construct deictic references that determine which objects are relevant in any given state. Feed - forward neural networks are used to learn the transition distribution on the relevant objects ’ properties. This strategy is demonstrated to be both more versatile and more sample efficient than learning a monolithic transition model in a simulated domain in which a robot pushes stacks of objects on a cluttered table."
SP:8ce00a3fedbf54a7f2c1ff414511cbb7d59b4597,"This paper proposes a novel instance - wise feature selection method, called INVASE, which consists of 3 neural networks : a selector network, a predictor network, and a baseline network which are used to train the selector network using the actor - critic methodology. Using this methodology, INVASE is capable of flexibly discovering feature subsets of a different size for each instance, which is a key limitation of existing state - of - the - art methods. The proposed method is evaluated on synthetic and real - word data, and shows significant improvements over the state of the art in terms of true positive rates, false discovery rates, and show better predictive performance."
SP:b91d6c33349df0bb6cb7e1c5e9433f0d4744b4da,This paper proposes a domain adaptation framework for structured output prediction by utilizing global and patch - level adversarial learning modules to learn discriminative representations guided by the label histogram of patches via clustering and show that these representations help the patch-level alignment process. The authors show that the proposed adaptation method performs favorably against various baselines and state - of - the - art methods on semantic segmentation.
SP:00922af13a21464cbc4cd7b34c196dd4f86c9247,"This paper proposes two optimistic algorithms for AMSGrad and Adam. The algorithms are based on the observation that mini - batch of stochastic gradients in consecutive iterations do not change drastically and consequently may be predictable. The new algorithms combine the idea of momentum method, adaptive gradient method, and algorithms in OPTIMISTIC ONLINE LEARNING which leads to speed up in training deep neural nets in practice. Experiments show that the algorithms are faster than the baselines."
SP:52228b48f2776d57dd422edb33b82e247f056b75,"This paper proposes two benchmarks for image classifier robustness. The first benchmark, IMAGENET - C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety - critical applications. The second benchmark is a new dataset called IMAGenet - P which enables researchers to benchmark a classifier’s robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbation not worst - case adversarial perturbedations. The authors find that there are negligible changes in relative corruption robustnesses from AlexNet classifiers to ResNet classifier. Afterward, the authors discover ways to enhance corruption and adversarial robustness robustness, and even find that a bypassed adversarial defense provides substantial   robustness gains. Together their benchmarks may aid future work toward networks that robustly generalize generalize image classifiers."
SP:20358ea0f769e6ea9222d8e35159d711ee1b20b2,"This paper proposes a new dropout training method for language modelling based on a family of conditional models whose objectives are lower bounded by the usual dropout objective. The main contribution of the paper is to show that the deterministic dropout method can be used to perform MAP estimation concurrently for an entire family of models whose objective is lower bounded than the standard stochastic dropout. This allows the authors to pick any model from this family after training, which leads to a substantial improvement on regularisation - heavy language modelling. The family includes models that compute a power mean over the sampled dropout masks with tighter and higher lower bounds than the fully stochastically drop out objective. It also exhibits the best model fit in the experiments."
SP:ac1b950ad29429ae045bb5e53279014a6a0b9d2b,"This paper proposes a cumulative saliency based soft filter pruning ( GSFP ) scheme to prune redundant filters of Convolutional Neural Networks ( CNNs ). Specifically, the GSFP adopts a robust pruning method, which measures the global redundancy of the filter in the whole model by using the soft pruning strategy. In addition, in the model recovery process after pruning, the authors use the soft filter strategy to improve the accuracy of pruning. For a pre - trained CNN model, the saliency of filter varies with different input data. Therefore, accumulating the salient of filter over the entire data set can provide more accurate guidance for pruning for CNNs. On the other hand, pruning from a global perspective is more accurate than local pruning in the paper."
SP:621e41d4199e333ec7f9d0936d4e34c918f39c11,"This paper proposes a cross - lingual document classification framework ( CACO ) between related language pairs ( CLDC and CLWE - based models ) for text classification. The authors use a character - based embedder and a word - based classifier to jointly train the embedder. The embedder derives vector representations for input words from their written forms, and the classifier makes predictions based on the word vectors.   The authors also propose a multi - task objective that can further improve the model if additional cross -lingual or monolingual resources are available."
SP:544e421f9c747640d949f433e3091763508b7237,This paper proposes a new method for weakly - supervised temporal action localization based on a marginalized average attentional network ( MAAN ) module. MAAN learns a set of latent discriminative probabilities in an end - to - end fashion and samples multiple subsets from the video snippet features based on these probabilities and takes the expectation over all the averaged subset features. Theoretical analysis of the properties of MAA and an explanation of the reasons MAAN alleviates the issue raised by the domination of the most salient regions. The authors also propose a fast iterative algorithm to reduce the complexity of constructing MAA from O(2 ) to O(T ). Extensive experiments on two large - scale video datasets show that MAAN achieves a superior performance on weakly supervised temporal localization.
SP:9f98c9bac99003741dd14e093b54d692c0b0e8d8,"This paper proposes a novel language model based on the Holographic Reduced Representation ( HRR ) framework. The proposed model is based on VSA and HRR. The authors propose to use HRR as a structured compositional representation for word - level and chunk - level representations. They show that by using HRR, their models are able to discover crude linguistic roles, which roughly resembles a classic division between syntax and semantics."
SP:5908b6acfed0e7c51e203c72eba907e6635e6c60,This paper proposes a new method for learning a POMDP model for decision - making with uncertainty about the environment and under stochastic outcome. The authors propose a greedy strategy for observation selection that aims to minimize the uncertainty in state - action space. They develop a novel point - based value iteration algorithm that incorporates the greedy strategy to achieve near - optimal uncertainty reduction for sampled belief points. This in turn enables the solver to efficiently approximate the reachable sub - space of belief simplex by essentially separating computations related to perception from planning from planning.
SP:0adec4abec17b3aab0c6eb69d11925dc20544950,"This paper proposes a curriculum loss for training deep neural networks. The proposed curriculum loss consists of two parts : a ) an adaptive weight that mitigates large early punishment and b ) an additional representation loss for low weighted samples. The adaptive weight assigns small values to hard examples, reducing the influence of noisy gradients. On the other hand, the less - weighted hard sample receives the proposed representation loss. This is done by letting them learn a better representation from its superior neighbours but not participate in learning of top layers. Experiments are conducted on MNIST, Cifar10 and CIFar100 to show the effectiveness of the proposed loss."
SP:8b555b9f24044bc68c204169d6a37e262361d706,"This paper proposes a new method to learn heuristics for combinatorial optimization problems. The authors propose a model based on attention layers with benefits over the Pointer Network and show how to train this model using REINFORCE with a simple baseline based on a deterministic greedy rollout, which they find is more efficient than using a value function. They significantly improve over recent learned heuristic for the Travelling Salesman Problem ( TSP ), getting close to optimal results for problems up to 100 nodes. With the same hyperparameters, they learn strong heuristic for two variants of the Vehicle Routing Problem ( VRP ), the Orienteering Problem (OP ) and ( stochastic variant of ) the Collecting TSP ( PCTSP )."
SP:efb76bcf1dbd9a9cf6b5db74b5d4256a9f9e9e73,This paper proposes a novel neural architecture search method for quantizing different layers of neural networks with different bit - widths. The method is based on gradient - based optimization. The authors show that the proposed method outperforms the state - of - the - art compression of ResNet on CIFAR-10 and ImageNet. They also show that their method can outperform baseline quantized models with 21x smaller model size or 103.9x lower computational cost.
SP:ea4173f8265bc50296de51c4ee7ecb6b8f78bec0,"This paper proposes a new attention architecture called Posterior Attention Models ( PAM ), which is based on a joint distribution of the attention and output variables. The authors propose two major changes : first, the position where attention is marginalized is changed from the input to the output, and the attention propagated to the next decoding stage is a posterior attention distribution conditioned on the output. Empirically on five translation and two morphological inflection tasks the proposed posterior attention models yield better BLEU score and alignment accuracy than existing attention models."
SP:987e2c14abc091d4d3ef9b48fb2046408eb1f59e,"This paper proposes a method to learn bi - directional translations between the source and the target domains by introducing a smoothness term over the sample graph to attain harmonic functions to enforce consistent mappings during the translation. The method is called HarmonicGAN. The authors show that this method outperforms state - of - the - art methods in a number of applications including medical imaging, object transfiguration, semantic labeling, and semantic labeling. They show that the method turns CycleGAN from a failure to a success, halving the mean - squared error and generating images that radiologists prefer."
SP:885a69003bad0e79cb2872a4e5c772191ad7e34f,"This paper proposes a stochastic algorithm to address the exploding and vanishing gradient problem ( EVGP ) in neural network optimization. The authors show that when the LSTM weights are large, the gradient components through the linear path ( cell state ) in the computational graph get suppressed. Based on the hypothesis that these components carry information about long term dependencies ( which the authors show empirically ), their suppression can prevent LSTMs from capturing them. The proposed algorithm, H - Detach, is based on a simple algorithm ( h -detach ) that is specific to LSTm optimization and targeted towards addressing this problem. The paper shows significant improvements over vanilla L STM gradient based training in terms of convergence speed, robustness to seed and learning rate, and generalization using our modification of LST M gradient on various benchmark datasets."
SP:9aaff3777321347d1194884af5690b0b5185eff9,"This paper proposes a method for training real binary weight networks ( without layer - wise or filter - wise scaling factors ) from scratch under the Bayesian deep learning perspective, where the final objective is to approximate the posterior distribution of binary weights rather than reach a point estimation. The proposed method, named SnapQuant, has two intriguing features : ( 1 ) The posterior distribution is parameterized as a policy network trained with a reinforcement learning scheme, and all the binary weights are used in a burn - after - reading style. At the testing phase, the authors can sample binary weight instances for a given recognition architecture from the learnt policy network. Experiments conducted on the widely used image classification datasets including ImageNet show that SnapQuant has better performance in comparison to related probabilistic methods."
SP:29d1f6d0661a51e56c59bbb106da56700fc22d9a,"This paper proposes a Bayesian nonparametric framework for federated learning with neural networks. Each data server is assumed to train local neural network weights, which are modeled through the framework. An inference approach is then developed to synthesize a more expressive global network without additional supervision or data pooling. The authors demonstrate the efficacy of their approach on federate learning problems simulated from two popular image classification datasets."
SP:ab1f2bd216635d63450688866c729a501bd7e9d0,"This paper proposes a new method for learning with Opponent - learning awareness ( LOLA ) and a stable variant named LookAhead ( SOS ). The authors show that SOS outperforms LOLA in a number of different games, including IPD and IPD - IPD. They provide theoretical guarantees that SOS can outperform LOLA. They also provide experimental results showing that SOS is able to outperform both LOLA and LA in the IPD game."
SP:bdafb5fca09a775a8c92d2826d5dc977d28091c2,"This paper proposes an alarm system to set off alarms when the segmentation result is possibly unsatisfactory for a medical segmentation algorithm. The alarm system consists of two parts : ( 1 ) a classifier to predict the quality of segmentation results from a low dimensional feature space, and ( 2 ) a model to learn classifiers and regressors in the feature space. The classifier is trained using only the ground truth masks, therefore the bad results with bad shapes become the rare events for VAE and the VAE is able to detect all kinds of shapes that are out of the distribution of normal shapes in ground truth ( GT ). The model learns the representation in the one - dimension feature space and predicts the qualities of the results from VAE on different datasets."
SP:60738395d9efe2b3fe3a00c542ebb4261e54386c,"This paper proposes an untrained simple image model, called the deep decoder, which is a deep neural network that can generate natural images from very few weight parameters than the output dimensionality. The proposed model is simple in the sense that each layer has an identical structure that consists of only one upsampling unit, pixel - wise linear combination of channels, ReLU activation, and channelwise normalization. This simplicity makes the network amenable to theoretical analysis and it sheds light on aspects of neural networks that enable them to form effective signal representations. The paper shows the performance of the proposed model on inverse problems such as denoising, inpainting, and reconstruction from few and noisy measurements."
SP:1c9bad3bd4d670172f65aa0304e9837ecafc6b3d,"This paper proposes an end - to - end neural network architecture for program synthesis from natural language ( NL ) programming. The proposed architecture relies exclusively on neural components, and is trained on abstract syntax trees, combined with a pretrained word embedding and a bi - directional multi - layer LSTM for processing of word sequences. The decoder features a doubly - recurrent L STM, for which the authors propose novel signal propagation schemes and soft attention mechanism. When applied to a large dataset of problems proposed in a previous study, SAPS performs on par with or better than the method proposed there, producing correct programs in over 92% of cases."
SP:d2ec231bb6153a303e5110e671dea14c2721e636,"This paper presents an adversarial defense against adversarial perturbations to the MNIST dataset. The authors show that even the most successful L∞ defense by Madry et al. has lower L0 robustness than undefended networks and is still highly susceptible to L2 perturbation, ( 2 ) classifies unrecognizable images with high certainty, ( 3 ) performs not much better than simple input binarization, and ( 4 ) features adversarial attacks that make little sense to humans. They present a novel robust classification model that performs analysis by synthesis using learned learned class - conditional data distributions and a novel decision - based attack that seeks to minimize the number of perturbed pixels ( L0 ). They show that most adversarial examples are strongly perturbed towards the perceptual boundary between the original and the adversarial class."
SP:91a24e7f4b952c37441feab4a7e8555014c856a4,"This paper proposes a new framework for training generative adversarial networks ( GANs ) by controlling the spectra of weight matrices in the discriminator. The authors propose a new reparameterization approach for the weight matrix of the discriminators in GAN, which allows them to directly manipulate the specta of the weight matrix through various regularizers and constraints, without intensively computing singular value decompositions. The experiments on CIFAR-10, STL - 10, and ImgaeNet datasets confirm that compared to other methods, the proposed method is capable of generating images with competitive quality by utilizing spectral normalization and encouraging the slow singular value decay."
SP:8115fd9b681198d62100c36794926fb57dc0a4f5,"This paper proposes an accelerated value iteration method for reinforcement learning. The authors introduce Anderson acceleration technique into the value iteration, developing a value iteration algorithm that they call Anderson Accelerated Value Iteration ( A2VI ). They further apply their method to the Deep Q - learning algorithm, resulting in the Deep Anderson accelerated Q - Learning ( DA2Q ) algorithm. The proposed method can be viewed as an approximation of the policy evaluation by interpolating on historical data, which is more efficient than the modified policy iteration. They give theoretical analysis of their algorithm and conduct experiments on both toy problems and Atari games. Both the theoretical and empirical results show the effectiveness of the algorithm."
SP:bd79b0c0af778a36008a0c0cf2fb6393fd2789d4,"This paper proposes a method to solve the catastrophic forgetting problem in the class incremental learning scenario. The proposed method combines the strength of deep learning and support vector machine ( SVM ), where SVM is used to identify the support data from the old data, which are fed to the deep learning model together with the new data for further training. Two powerful consolidation regularizers are applied to stabilize the learned representation and ensure the robustness of the learned model. The authors validate their method with comprehensive experiments on various tasks, which show that SupportNet drastically outperforms the state - of - the - art incremental learning methods."
SP:d228d213f79716774043cea253305fecece659ec,"This paper proposes a new measure of unit selectivity in neural networks, called top - class selectivity, to measure the selectivity of neural network representations learned by neural networks ( NNs ). The proposed measure is based on a combination of three existing measures : localist selectivity Bowers et al. ( 2014 ), precision ( Zhou et al, 2015 ), class - conditional mean activity selectivity CCMAS ( Morcos et al ( 2018 ) ), and a new measures called top class. The authors compare these measures on AlexNet, and show that the precision and CCMAS measures provide a much higher level of selectivity than is warranted, with the most selective hidden units only responding strongly to a small minority of images from within a category. They also generated activation maximization ( AM ) images that maximally activated individual units and found that under ( 5%) of units in fc6 and conv5 produced interpretable images of objects, whereas fc8 produced over 50% interpretable objects. These findings highlight the problem with current selectivity measures and show new measures are required in order to provide a better assessment of learned representations in NNs."
SP:b9deae0392e0160b400d76c549d382e235196f8c,"This paper presents a novel family of Graph Neural Networks ( GNNs ) for solving community detection problems in a supervised learning setting in a data - driven manner and without access to the underlying generative models. The authors show that the GNN can match or even surpass the performance of the belief propagation algorithm on binary and multiclass stochastic block models, which is believed to reach the computational threshold in these cases. They also provide an upper bound on the energy gap controlling the energy difference between local and global minima ( or minimum ). The energy gap will shrink as the size of the input graphs increases, which would mean that the optimization landscape is benign."
SP:a9ed31090e55f6152fc31c7512af5d634cc7225a,"This paper proposes a new algorithm for online dictionary learning based on a linear combination of a few columns of a matrix known as a dictionary, where the sparse weights forming the linear combination are known as coefficients. Since the dictionary and coefficients, parameterizing the linear model are unknown, the corresponding optimization is inherently non - convex. This was a major challenge until recently, when provable algorithms for dictionary learning were proposed. Yet, these provide guarantees only on the recovery of the dictionary, without explicit recovery guarantees on the coefficients. This potentially limits the utility of existing provable dictionary learning methods in applications where coefficient recovery is of interest. To this end, the authors develop NOODL : a simple Neurally plausible alternating Optimization - based Online Dictionary Learning algorithm, which recovers both dictionary and coefficient exactly at a geometric rate, when initialized appropriately."
SP:85232b72a2643d6dc81cf952ccbb95192032b7c5,"This paper proposes a new training scheme for learning binary hash codes with any differentiable model and similarity function. The authors propose to use log likelihood loss on top of an accurate approximation for the probability that two inputs fall within a Hamming distance target. Their novel training scheme obtains a good estimate of the true gradient by better sampling inputs and evaluating loss terms between all pairs of inputs in each minibatch. To fully leverage the resulting hashes, these techniques provide large improvements to a similarity search tasks. They report the best results to date on competitive information retrieval tasks for ImageNet and SIFT 1M, improving MAP from 73% to 85% and reducing query cost by a factor of 2-8."
SP:3bd4ccff7f48380d2db8dff2c4ca515894a7f1db,"This paper proposes Graph HyperNetwork ( GHN ) to amortize the search cost of Neural architecture search ( NAS ). GHN generates the weights by running inference on a graph neural network to predict the topology of an architecture and therefore can predict network performance more accurately than regular hypernetworks and premature early stopping. To perform NAS, they randomly sample architectures and use the validation accuracy of networks with GHN generated weights as the surrogate search signal. GHNs are fast – they can search nearly 10 times faster than other random search methods on CIFAR-10 and ImageNet."
SP:65ccf43cd4e033d22239069057f5200d49f33724,This paper proposes a method to improve generative adversarial imitation learning by using additional information from non - expert demonstrations which are easier to obtain. The key idea of the method is to perform multiclass classification to learn discriminator functions where non -expert demonstrations are regarded as being drawn from an extra class. Experiments in continuous control tasks demonstrate that the method learns better policies than the GAIL baseline when the number of expert demonstrations is small.
SP:e8427949a98effbd37ce7604fa11f240e2342196,"This paper proposes an inverse neural network ( INN ) approach to learning the posterior parameters of the forward process from a set of measurements. Unlike classical neural networks, which attempt to solve the ambiguous inverse problem directly, INNs focus on learning the inverse process using additional latent output variables to capture the information otherwise lost. The authors argue that INNs are a powerful analysis tool to find multi - modalities in parameter space, uncover parameter correlations, and identify unrecoverable parameters. While forward training is sufficient in the asymptotic limit, unsupervised backward training improves results on finite training sets."
SP:75c9bb53bac29bdb390f9ba5707caee4ab1f5925,"This paper proposes an ensemble method for estimating uncertainty estimates of deep neural networks ( NNs ) based on a mixture model with uniform mixing weights. The authors propose to replace the fixed mixing weights by an adaptive, input - dependent distribution ( an NN ) and by considering uncountably many mixture components. The resulting model can be seen as the continuous counterpart to mixture density networks and is therefore referred to as compound density networks. The proposed method is shown to be more robust to adversarial examples than previous approaches and is more robust than Bayesian NNs."
SP:e1e38289285c1b8fdb318e4f6d37a198a08787a2,"This paper proposes a new compression method for neural network compression based on the Kullback - Leibler divergence between the sampled variational distribution and the encoding distribution. The proposed method is based on a variational encoding scheme, where the weights are encoded using a random sample. The authors show that the proposed method achieves the best compression rate for fixed memory budget and achieves the highest compression rates for fixed test performance. They also show that their method can be shown to be close to optimal information - theoretical lower bound, with respect to the employed variational family."
SP:ad70d8cf3a4558aab0d3b7155594464a3debd912,"This paper proposes ProxylessNAS, a new method for neural architecture search ( NAS ) that can directly learn the architectures for large - scale target tasks and target hardware platforms. The main contribution of the paper is to address the high memory consumption issue of differentiable NAS and reduce the computational cost ( GPU hours and GPU memory ) to the same level of regular training while still allowing a large candidate set. The paper also proposes to specialize neural architectures for hardware with direct hardware metrics ( e.g. latency ) and provide insights for efficient CNN architecture design. Experiments on CIFAR-10 and ImageNet demonstrate the effectiveness of directness and specialization. On Cifar-10, the model achieves 2.08% test error with only 5.7M parameters, better than the previous state - of - the - art architecture AmoebaNet-B, while using 6x fewer parameters. On ImageNet, our model achieves 3.1% better top - 1 accuracy than MobileNetV2, while being 1.2x faster with measured GPU latency."
SP:e5b70d43d301d1980fae02623ea711976b429c14,"This paper proposes an algorithm for penalizing two - player min - max games with second - order penalties in the Lagrangian dual with additive linear penalties. The authors argue that the use of second order penalties allows training the penalized objective with a fixed value of the penalty coefficient, thus avoiding the instability and potential lack of convergence associated with two - players min - min games. In addition, the authors derive a method for efficiently computing the gradients associated with the second order penalty in stochastic mini - batch settings. The resulting algorithm performs well in learning an appropriately fair classifier on a number of benchmarks."
SP:e4720b8e4efdb222c45eafd47fd8a7fbf15d881d,"This paper studies the problem of learning discrete latent variables in deep generative models. The authors propose a new method, RWS, to learn discrete latent variable models with high - variance gradient estimators. They show that RWS outperforms existing state - of - the - art methods in learning discrete - variable models in terms of both the utility of the control - variable schemes and the necessity of evaluating (potentially exponentially ) many branch paths in the model. They also show that the RWS algorithm learns better models and inference networks with increasing particle budgets."
SP:7459ae5b1d886e68930c4c9e21df508bc8ab3c9a,"This paper proposes to train structured prediction energy networks ( SPENs ) with a reward function based on gradient - based search on a smooth, learned representation of the score landscape. The reward function is based on a scalar reward function, which may be easily assembled from human knowledge or non - differentiable pipelines, but searching through the entire output space to find the best output is typically intractable. In this paper, the authors propose to use efficient truncated randomized search in this reward function to train the reward function in SPENS, which provide efficient test - time inference using gradient based search. The authors show that the proposed method yields state - of - the - art results in structured prediction tasks."
SP:638c1bc09992029b78bd83f0127594dcccb96c06,"This paper proposes an active learning based framework, EffAcTS, to selectively choose model parameters for this purpose so as to collect only as much data as necessary to select such a subset of trajectories. The authors apply this framework to an existing method, namely EPOpt, and experimentally validate the gains in sample efficiency and the performance of their approach on standard continuous control tasks. They also present a Multi - Task Learning perspective to the problem of Robust Policy Search, and draw connections from their proposed framework to existing work on Multi -Task Learning."
SP:491c239713a6489f0b1790ca26db54a1813c67ae,"This paper proposes a two - time - scale network ( TTN ) architecture that enables linear methods to be used to learn values, with a nonlinear representation learned at a slower timescale. The approach facilitates the use of algorithms developed for the linear setting, such as data - efficient least - squares methods, eligibility traces, and the recently developed linear policy evaluation algorithms, to provide non - linear value estimates. The authors show that TTNs converge, despite the fact that a linear algorithm is used with a changing representation, and that they can exploit several benefits of linear value approximations algorithms. They demonstrate the benefits of TTNs compared to other nonlinear value function approximation algorithms, both for policy evaluation and control."
SP:327d606cf3813b00a009a7785e08ef9e11f89493,"This paper proposes LEArning and Planning with Semantics ( LEAPS ), a model - free approach to planning and planning with semantic regularities. The authors propose a multi - target sub - policy that acts on visual inputs, and a Bayesian model over semantic structures. The agent plans with the semantic model to make high - level decisions in an unseen environment, proposes the next sub - target for the sub -policy to execute, and updates the semantic models based on new observations. The proposed method is tested on House3D, a 3D environment that contains diverse human - designed indoor scenes with real - world objects. The experimental results show that the proposed method outperforms baselines over baselines."
SP:d7c26f43bc68d160095b1f50447528843d79edbd,"This paper proposes a new driving model that consists of two modules : perception module for see and think and driving module for behave, and trained it with multi - task perception - related basic knowledge and driving knowledge stepwisely. The perception module is used for learning easier driving - related perception knowledge, which is able of pixel level understanding of input including what & where and how far knowledge. The driving module is trained with segmentation map and depth map for tackling easier drivingrelated perception problems before generating final control commands for difficult driving task. The results of experiments demonstrated the effectiveness of multitask perception knowledge for better generalization and accident explanation ability."
SP:b6bd98cc70fab97e1245cbb63a42ef89ab7e7ed5,"This paper studies the trade - off between adversarial robustness and standard generalization in adversarial training. The authors show that training robust models may not only be more resource - consuming, but also lead to a reduction of standard accuracy. They argue that this phenomenon is a consequence of robust classifiers learning fundamentally different feature representations than standard classifiers. These differences, in particular, seem to result in unexpected benefits : the features learned by robust models tend to align better with salient data characteristics and human perception."
SP:9c9275d75cd95b1b82e0cbb1421e3d3ade1ce33a,This paper proposes a method for gradient - based training of deep neural networks without backpropagation. The proposed method is based on a feedforward network that learns to approximate the state of the fixed - point using a local learning rule and an initializing network for inference. Experiments show that the proposed method outperforms the original Equilibrium Propagation method in terms of accuracy.
SP:ac9ea91eb465517de495477cf67bc94d5ed1b0cb,"This paper proposes a new stochastic optimization algorithm, ZO - signSGD, which combines gradient - free operations and sign SGD. The authors show that the convergence rate of the new algorithm is O(d/T ) under some mild conditions, where d is the number of optimization variables, and T is number of iterations. They also show the effect of different types of gradient estimators on the convergence of ZO-signSGD. They propose several variants of the algorithm, and explore the connection between ZO and black - box adversarial attacks in robust deep learning."
SP:5f79b11777f6ef1d70c85418bfc2e4616dd7d960," - based deep learning method is proposed to reduce the computation efforts of convolutional neural networks. The authors propose to set a checkpoint in the MAC process to determine whether a filter could terminate early based on the intermediate result. Furthermore, a fine - tuning process is conducted to recover the accuracy drop due to the applied checkpoints. The experimental results show that the proposed method can save approximately 50% MAC operations with less than 1% accuracy for CIFAR-10 and CifAR-100 datasets. The proposed method is more effective than the state - of - the - art method."
SP:7801e9c854ad7d960c0d24fda15597af6994c23f,This paper proposes a new adversarial defense method for adversarial attacks on automatic speech recognition ( ASR ) systems. The authors propose to use temporal dependency in audio data to gain discriminative power against adversarial examples. They show that input transformation developed from image - based defense provides limited robustness improvement and is subtle to advanced attacks. They also show that temporal dependency can be exploited to gain discriminating power against audio adversarial example and is resistant to adaptive attacks considered in their experiments. Their results show promising means of improving the robustness of ASR systems but also offer novel insights in exploiting domain - specific data properties to mitigate negative effects of adversarial attack.
SP:51830b811a8e39b4f0a5b7609df719e026fac6a1,"This paper proposes a generative model to generate images by means of composition of objects and their relations explicitly. The authors propose to structure the generator of a GAN to consider objects, their relations, and their composition explicitly. They evaluate their approach on several multi - object image datasets, and find that the generator learns to identify and disentangle information corresponding to different objects at a representational level. A human study reveals that the resulting GAN model is better at generating images that are more faithful to the reference distribution."
SP:fb59990b8da0e95d8202383478a456667de60449,"This paper proposes a novel deep generative model for learning disentangled representations from unlabelled images, where the only supervision comes from an auxiliary “ reference set ” that contains images where the factors of interest are constant. In order to address this problem, the authors propose reference - based variational autoencoders, which is a novel model designed to exploit the weak supervisory signal provided by the reference set. During training, they use the variational inference framework where adversarial learning is used to minimize the objective function. They show how the proposed framework is able to naturally address different tasks such as feature learning, conditional image generation, and attribute transfer."
SP:dbc1983d9b9d72aa14f8e8515d793d2bbde26c9c,"This paper proposes a method for continual online learning from an incoming stream of data, using deep neural network models, using stochastic gradient descent to update model parameters, and an expectation maximization algorithm with a Chinese restaurant process prior to develop and maintain a mixture of models to handle non - stationary task distributions. This allows for all models to be adapted as necessary, with new models instantiated for task changes and old models recalled when previously seen tasks are encountered again. Furthermore, the authors observe that this direct online adaptation with SGD is effective, which is otherwise not the case for large function approximators. In this work, they apply their meta - learning for online learning ( MOLe ) approach to model - based reinforcement learning, where adapting the predictive model is critical for control. They demonstrate that MOLe outperforms a state - of - the - art prior method, as well as continuous gradient updates for adaptation and online learning without meta - training."
SP:5665e5f006f84927beb0440e145f476e02538077,"This paper investigates the training of distributed RL agents with experience replay. The authors propose to train a distributed RL agent using a single network architecture and a fixed set of hyperparameters. They demonstrate the effect of experience replay on parameter lag, leading to representational drift and recurrent state staleness in the training setting. They also provide an empirical study into the effects of several approaches to RNN training with replay, and propose an agent that integrates these findings to achieve significant advances in the state of the art on Atari - 57 and matches the state - of - the - art on DMLab - 30."
SP:47ace37f31a46d5ee85c283e62ddb71a12f2c5c4,"This paper studies the problem of training sequential generative models for capturing coordinated multi - agent trajectory behavior, such as offensive basketball gameplay. The authors present a hierarchical framework that can effectively learn such sequential models. Their approach is inspired by recent work on leveraging programmatically produced weak labels, which extend to the spatiotemporal regime. They show how to instantiate their framework to effectively model complex interactions between basketball players and generate realistic multi -agent trajectories of basketball gameplay over long time periods. They validate their approach using both quantitative and qualitative evaluations, including a user study comparison conducted with professional sports analysts."
SP:1a90cdf028068528b0559e7d44bf26dda20310bd,"This paper proposes a method to learn a graph - structured variational recurrent neural network ( Graph - VRNN ) to infer the current state of the ( partially observed ) world, as well as to forecast future states. The method learns to integrate information from a learned dynamics model, with ambiguous visual information, with a learned vision model, in the context of interacting agents. The authors show that their method outperforms various baselines on two sports datasets, one based on real basketball trajectories, and one generated by a soccer game engine. The main contribution is a unified way to do state estimation and future forecasting at the level of objects and relations directly from pixels using Graph -VRNN."
SP:8392f04b7265f665ba6d44d297bca245d44b4708,"This paper proposes a method for end - to - end training of a base neural network that integrates calls to existing black - box functions with a differentiable neural network in a way that drives the base network to comply with the black box function interface during the training process. The proposed method is motivated by the fact that existing black box functions can be used to decompose a task to a series of functions, of which for some people may prefer to use a neural network to learn the functionality, while for others the preferred method would be to use existing blackbox functions. The authors propose a method to train a base network by approximating the blackbox functionality with a Differentiable Neural Network ( DNN ). They show that by leveraging the existing precise blackbox function during inference, the integrated model generalizes better than a fully differentiable model, and learns more efficiently compared to RL - based methods."
SP:13fb86de763a0b34ac6fa34ea9dfbd1c476ce43e,This paper proposes a method for learning meta - learning based on hierarchical Bayesian models over the parameters of an arbitrary function approximator such as a neural network. The authors propose a stochastic expectation maximization procedure to jointly estimate parameter initializations for gradient descent as well as a latent assignment of tasks to initializations. This approach better captures the diversity of training tasks as opposed to consolidating inductive biases into a single set of hyperparameters. The experiments demonstrate better generalization performance on the standard mini - image benchmark for 1 - shot classification.
SP:a410144dbe19713a06c63da87d9fb58b999a7492,"This paper proposes Meta Auxiliary Learning ( MAXL ) for image classification, where the task is hierarchical sub - class image classification. The proposed method is based on meta - learning to generate target labels to train a multi - task evaluator, such that these labels improve the generalisation performance on the principal task. Experiments on three different CIFAR datasets show that MAXL outperforms baseline auxiliary learning methods, and is competitive even with a method which uses human - defined sub-class hierarchies."
SP:76248e1c914c60ce69de244fe7ec62488d01e161,"This paper proposes a neural network based representation for addressing the open set recognition problem. In this representation instances from the same class are close to each other while instances from different classes are further apart, resulting in statistically significant improvement when compared to other approaches on three datasets from two different domains. The authors propose a loss function that enables them to use the same distance function both when training and when computing an outlier score."
SP:d4ee856bbf2dfb6390e5247086fec2e52dcb6858,"This paper presents a new method for training low - precision deep convolutional neural networks. The authors show that the accuracy of low precision networks can match or exceed full - precision baseline networks after one epoch of finetuning. In particular, the authors demonstrate ResNet - 18, ResNet-34, Res net - 50, Resnet -152, Inception - v3, densenet161, and VGG - 16bn networks on the ImageNet classification benchmark that, at 8 - bit precision exceed the accuracy   of the full precision networks. They also show that, for 4 - bit models, the accuracy matches the accuracy, at the same time as full precision. They find that gradient noise due to quantization during training during training increases with reduced precision and seek ways to overcome this noise."
SP:6bfdc37b346e6ddfa049e0414647f4beda8ede3f,"This paper proposes a new method for predicting post - bounce trajectories based on the physics of bouncing trajectories. The method is based on two modules : a physics inference module ( PIM ) and a visual inference module ( VIM ), which learns to infer physical parameters for locations in a scene given a single still image, while PIM learns to model model physical interactions for the prediction task given physical parameters and observed pre - collision 3D trajectories, respectively. The authors present a new dataset of 5K RGB - D videos of real - world bounces and probe surfaces of varying shapes and materials in everyday scenes including homes and offices. They show that the proposed method outperforms other baselines in predicting trajectories and inferring physical properties of a scene."
SP:010bd055310c363d3cb0fbe0e11546de58220e15,"This paper shows that adversarial vulnerability increases with the gradients of the training objective when viewed as a function of the inputs. For most current network architectures, the authors show that the `1 - norm of these gradients grows as the square root of the input size. These nets therefore become increasingly vulnerable with growing image size. The authors provide theoretical and empirical arguments supporting the existence of a monotonic relationship between the gradient norm of training objective ( of a differentiable classifier ) and its adversarialulnerability. They show that CNNs and most feed - forward networks, by design, exhibit increasingly large gradients with dimension d with input dimension d."
SP:5fa3ae057e55be6b71cc94a7dbfe31e54e1c536f,"This paper proposes an interactive agent modeling scheme that encourages an agent to learn to probe. The probing agent learns to interact with the environment and with a target agent ( i.e., a demonstrator ) to maximize the change in the observed behaviors of that agent. Through probing, rich behaviors can be observed and are used for enhancing the agent modeling to learn a more accurate mind model of the target agent. The framework consists of two learning processes : i ) imitation learning for an approximated agent model and ii ) pure curiosity - driven reinforcement learning to learn an efficient probing policy to discover new behaviors that otherwise can not be observed. The experimental results suggest that the agent model learned by our approach generalizes better in novel scenarios than the ones learned by passive observation, random probing, and other curiositydriven approaches."
SP:3af184a5529d6ec2a0862efd1af80ef5b50d2952,"This paper proposes a modification to artificial neural networks ( ANNs ) based on biological neuromodulators. The authors propose a new type of ANN node, called modulators, to enable other traditional ANN nodes to adjust their activation sensitivities in run - time based on their input patterns. In this manner, they enable the slope of the activation function to be context dependent. This modification produces statistically significant improvements in comparison with traditional ANNs in the context of Convolutional Neural Networks and Long Short - Term Memory networks."
SP:287a577834fd2820a939a1113b39146a22727491,"This paper proposes a neural analysis and synthesis ( NANSY ) framework that can manipulate voice, pitch, and speed of an arbitrary speech signal. The idea is to perturb information in the original input signal ( e.g., formant, pitch, and frequency response ), thereby letting synthesis networks selectively take essential attributes to reconstruct the input signal. Because NANSy does not need any bottleneck structures, it enjoys both high reconstruction quality and controllability. Furthermore, it does not require any labels associated with speech data such as text and speaker information, but rather uses a new set of analysis features, i.e., pitch feature, Yingram, which allows for fully self -supervised training. The experiments show that NansY can achieve significant improvement in performance in several applications."
SP:90f35ad1ec0c38b0817f5678ee2a5c4f0e08fb38,"This paper presents an expectation bound for the validation set of the gradient - based bilevel programming framework based on uniform stability. The expectation bound is based on the assumption that uniform stability is a function of the stability of the validation. The authors show that the expectation bound can be used to explain some of the overfitting behaviour of the validated validation set in practice. They also show that gradient based algorithms can be better than cross - validation algorithms under certain conditions. In experiments on feature learning and data reweighting for noisy labels, they corroborate their theoretical findings."
SP:42f52aec3a776d87daa5fd72b8e6325d12c88d63,"This paper proposes a novel knowledge distillation approach to facilitate the transfer of dark knowledge from a teacher to a student. The main idea is to learn the teacher models that are friendly to students and, consequently, more appropriate for knowledge transfer. In other words, at the time of optimizing a teacher model, the proposed algorithm learns the student branches jointly to obtain student - friendly representations. Since the main goal of the approach lies in training teacher models and the subsequent knowledge distilling procedure is straightforward, most of the existing knowledge distillations methods can adopt this technique to improve the performance of diverse student models in terms of accuracy and convergence speed. The experimental results with in - depth analyses are presented in Section 4, and the conclusion in Section 5 is that there is no prior knowledge about student models."
SP:e15a1c21229233fd97dc1dfa0a4ef48b69dc9f95,"This paper studies generalization to out - of - distribution ( OOD ) data, which is one of the central problems in modern machine learning. The authors introduce a new concept of expansion function, which characterizes to what extent the variance is amplified in the test domains over the training domains, and therefore give a quantitative meaning of invariant features. Based on these, they prove that OOD generalization error bounds can be generalized to arbitrary out of distribution data. They also propose a model selection method based on the expansion function and model selection module. Extensive experiments on benchmark OOD datasets demonstrate that their model selection criterion has a significant advantage over baselines."
SP:37b04b9068d39bcf0a581eb8181d13cf1a8926bf,"This paper proposes a Variational Continual Bayesian Meta - learning ( VC - BML ) algorithm that addresses the issues of negative knowledge transfer and catastrophic forgetting for streaming low - resource tasks. The proposed algorithm maintains a Dynamic Gaussian Mixture Model for meta - parameters, with the number of component distributions determined by a Chinese Restaurant Process. Dynamic mixtures at the meta - parameter level increase the capability to adapt to diverse and dissimilar tasks due to a larger parameter space. To infer the posteriors of model parameters, compared to the previously used point estimation method, the authors develop a more robust posterior approximation method – structured variational inference for the sake of avoiding forgetting knowledge. Experiments on tasks from non - stationary distributions show that VC -BML is superior in transferring knowledge among diverse tasks and alleviating catastrophic forgetting in online setting."
SP:776d5b02b8d3a8bbcc1f52706f3887c384cb149e,"This paper proposes a fast algorithm for the probabilistic solution of boundary value problems ( BVPs ), which are ordinary differential equations subject to boundary conditions. In contrast to previous work, the authors introduce a Gauss - Markov prior and tailor it specifically to BVPS, which allows computing a posterior distribution over the solution in linear time, at a quality and cost comparable to that of well - established, non - probabilistic methods. The model delivers uncertainty quantification, mesh refinement, and hyperparameter adaptation. The main practical considerations positively impact the efficiency of the scheme. Altogether, this results in a practically usable BVP solver that is natively compatible with other parts of the statistical modelling tool - chain."
SP:86aac0c6b75fdc12f84bba342934865616f866d4,"This paper considers the problem of learning a near optimal policy for two reward - mixing Markov decision processes ( RM - MDPs ) where the reward function is drawn from one of multiple possible reward models at the beginning of every episode, but the identity of the chosen reward model is not revealed to the agent. Unlike existing approaches that rely on strong assumptions on the dynamics, the authors make no assumptions and study the problem in full generality. They provide the first polynomial - time algorithm that finds an -optimal policy after exploring 2 episodes, where H is the number of states and actions and S is time - horizon. This is the first efficient algorithm that does not require any assumptions in partially observed environments where the observation space is smaller than the latent state space. With no further assumptions, the problem requires several new ideas beyond existing algorithmic and analysis techniques for efficient exploration."
SP:1a3c70ae9cf2a806d603f4b9e7ca6e10b720a956,This paper proposes a method to estimate the effect of a single - cause intervention on a multi - cause treatment effect. The proposed method is called Single - Cause Perturbation ( SCP ) and it is based on a two - step procedure : 1 ) augmenting the observational data with the estimated potential outcomes under single cause interventions and 2 ) performing covariate adjustment on the augmented dataset to obtain the estimator that is agnostic to the exact choice of algorithm in either step. The authors demonstrate the performance gain of SCP on extensive synthetic and semi - synthetic experiments.
SP:247bc6675cce89d51558537daf63dadb0c4307f8,"This paper proposes a multiwavelet - based neural operator learning scheme that compresses the associated operator ’s kernel using fine - grained wavelets. The proposed method is trained at multiple scales derived from repeated computation of multi - wavelet transform. This allows learning the complex dependencies at various scales and results in a resolution - independent scheme. Compared with the existing neural operator approaches, the proposed model shows significantly higher accuracy and achieves higher accuracy in a range of datasets. For the time - varying equations, it exhibits a ( 0.0018 ) relative L2 error for Burgers’ ( KdV ) equation, Burgers ’ equation, Korteweg - De Vries equation, and Darcy Flow equation."
SP:1153785e6a016cfee2644952a772aa08927299b6,"This paper proposes a novel method for training binary neural networks ( BNNs ) by approximating the gradient of the sign function in the Fourier frequency domain using the combination of sine functions. The proposed approach does not affect the low - frequency information of the original sign function which occupies most of the overall energy, and high - frequency coefficients will be ignored to avoid the huge computational overhead. In addition, they embed a noise adaptation module into the training phase to compensate the approximation error. The experiments on several benchmark datasets and neural architectures illustrate that the binary network learned using the proposed method achieves the state - of - the - art accuracy."
SP:33b95ea8da4d30b8e8f9d3fe3acca023d4b8d831,This paper proposes to study the distributed computation dynamics of multi - area neural networks ( RNNs ). The authors propose to use multiple - area RNN with neuroscience - inspired architecture constraints to derive key features of distributed computation. They show that incorporating multiple areas and Dale’s Law is critical for biasing the networks to learn biologically plausible solutions. They also show that output - relevant information is preferentially propagated between areas. The results suggest that cortex uses modular computation to generate minimal sufficient representations of task information.
SP:db3ced65d67e3373fb3936ec50f41c8ef010bbbe,"This paper proposes a method to search for multiple explanations for each image of interest using a beam search algorithm. The proposed method is based on the idea of structured attention graphs ( SAGs ), which represent sets of attention maps for an image by visualizing how different combinations of image regions impact the confidence of a classifier. The authors argue that a single saliency map provides an incomplete understanding since there are often many other maps that can explain a classification equally well. They show that there are indeed multiple relatively localized explanations for many images, and show that showing multiple explanations to users can be overwhelming and does not reveal their common and distinct structures. They conduct a user study to demonstrate the effectiveness of SAGS in helping users gain a deeper understanding of CNNs."
SP:f2b385bfd9ada0e26aa8829214b424f58582d9f7,"This paper studies how the choice of training objective affects the transferability of the hidden representations of convolutional neural networks trained on ImageNet. The paper shows that many objectives lead to statistically significant improvements in ImageNet accuracy over vanilla softmax cross - entropy, but the resulting fixed feature extractors transfer substantially worse to downstream tasks. The choice of loss has little effect when networks are fully fine - tuned on the new tasks. Using centered kernel alignment to measure similarity between hidden representations, the paper finds that differences among loss functions are apparent only in the last few layers of the network. Different objectives and hyperparameter combinations lead to dramatically different levels of class separation."
SP:b66b5e24f68563e2e200eda660f0dbaff53efeff,"This paper proposes a novel neural network training strategy, selective backpropagation through time ( SBTT ), which enables learning of deep generative models of latent dynamics from data in which the set of observed variables changes at each time step. The resulting models are able to infer activity for missing samples by combining observations with learned latent dynamics. The authors demonstrate that SBTT enables accurate inference of neural population dynamics with lower interface bandwidths, providing an avenue to significant power savings for implanted neuroelectronic interfaces."
SP:3513a83806e71006b86d60b779d8bd6bb87c3546,"This paper proposes a hierarchical approach to sequence - to - sequence learning with quasi - synchronous grammars, where each node in target tree is transduced by a node in the source tree, and both the source and target trees are treated as latent and induced during training. The authors develop a neural parameterization of the grammar which enables parameter sharing over the combinatorial space of derivation rules without the need for manual feature engineering. They apply this latent neural grammar to various domains, including SCAN style transfer and small - scale English - French machine translation, and find that it performs respectably compared to standard baselines compared to baseline approaches."
SP:d06fc251f2a9287f7a2236a188349628d8f39d9a,"This paper proposes a new algorithm to solve Group Elastic Net in ultrahigh dimensional settings, which exploits the sparsity structure of the Augmented Lagrangian to greatly reduce computational burden. The authors extend their algorithm to the function - on - scalar regression framework, where a functional response is modeled against a very large number of potential scalar predictors. They use simulations to demonstrate the CPU time gains afforded by their approach compared to its best existing competitors, and present an application to data from a Genome Wide Association Study on childhood obesity."
SP:e0b53f76f3a6b756fedd09926f9cf034f89f4a5a,"This paper proposes a method to cluster repeatedly observed marked point processes to identify potential heterogeneity in the observed data. The proposed method is based on a multi - level marked point process model, which is a mixture of log - Gaussian Cox processes and cluster rows of such a matrix. The authors propose an efficient semi - parametric Expectation - Solution ( ES ) algorithm combined with functional principal component analysis ( FPCA ) of point processes is proposed for model estimation. The effectiveness of the proposed framework is demonstrated through simulation studies and real data analyses."
SP:3aa213076f3e9f9838ac654517df2fe1fca33499,"This paper proposes an online meta - adaptive control approach for adaptive nonlinear control, which is motivated by robot control, where a robotic system encounters a sequence of new environmental conditions that it must quickly adapt to. A key emphasis is to integrate online representation learning with established methods from control theory in order to arrive at a unified framework that yields both control - theoretical and learning - theoretic guarantees. The authors provide instantiations of their approach under varying conditions, leading to the first non -asymptotic end - to - end convergence guarantee for multi - task non - linear control. They also show how to integrate OMAC with deep representation learning to improve empirical performance."
SP:cb274c93a169b199ea09120ca02105a3f16b31c5,This paper proposes a method for training neural networks with certifiable robustness guarantees. The method is based on interval bound propagation ( IBP ) and CROWN - IBP. The authors propose a new weight initialization method for IBP training and propose to add Batch Normalization to each layer in the model. They also design regularization to explicitly tighten certified bounds and balance ReLU activation states during wamrup training. They achieve a verified error of 65.03% on CIFAR-10 in 160 epochs and 82.36% on TinyImageNet in 80 epochs.
SP:18ffeb199a670fb2b1f4417b8653479001944dab,"This paper proposes an adversarial change point detection method ( ARC ) that is robust against adversarial attacks. The proposed method is based on the Huber - contamination framework, which allows the contamination distributions to be different at each time point. The authors propose a variant of ARC, namely automatic ARC ( aARC ), which adapts to the contamination proportion. They show that the proposed method can provide optimal estimation without the presence of change points. They also show that their robust univariate mean estimator ( RUME ) provides optimal estimation."
SP:d03617b5fc446768809cf015c9234b0c9386a690,"This paper studies the power of learning via mini - batch stochastic gradient descent ( SGD ) and batch Gradient Descent ( GD ) on the empirical loss of a differentiable model or neural network. They show that SGD and GD can always simulate learning with statistical queries ( SQ ), but their ability to go beyond that depends on the precision ρ of the gradient calculations relative to the minibatch size b and sample size m ( for GD ). With fine enough precision, namely when bρ is small enough, SGD can go beyond SQ learning and simulate any sample - based learning algorithm and thus its learning power is equivalent to that of PAC learning. This extends prior work that achieved this result for b = 1. Similarly, with fine enough accuracy relative to sample size, GD can also simulate any model - based algorithm based on m samples. In particular, with polynomially many bits of precision ( i.e. when ρ is exponentially small ), the mini -batch size b plays an important role, and simulating arbitrary sample based methods is provably not possible using fbGD or with bSGD."
SP:1de2864fe2f53e25596a9bd2c61e2048e79296f6,"This paper studies the convergence of the Lloyd - type algorithm in deterministic and probabilistic settings. The authors show that in most cases, a suitably adjusted version of Lloyd’s algorithm — in which Voronoi cells are replaced by Power cells — leads to configurations with small Wasserstein error. This is surprising because, again, of the non - convex nature of the problem, as well as the existence of spurious critical points. They provide explicit estimates for the convergence, starting from a cloud of points that are sufficiently far from each other. Their estimates are tight when the algorithm is initialized from an point cloud that is evenly distributed in the ambient space. These bounds naturally lead to a modified Poliak - Łojasiewicz - type inequality for the distance cost, depending on the distances between Dirac masses in the discrete distribution."
SP:c3d364aeee55230a436c3ce4e8dc8310ee73959e,"This paper proposes a new self - attention feature transform ( RSA ) that leverages rich structures of spatio - temporal relations in videos by dynamically generating relational kernels and aggregating relational contexts. The authors show that the proposed RSA network substantially outperforms the state - of - the - art on the standard motion - centered benchmarks for video recognition, such as Something - Something-V1&V2, Diving48, and FineGym."
SP:2c2530069d5cab485629090243da464d107feadd,"This paper studies the fluctuation around the infinite - width limit of multilayer neural networks. The authors derive a new dynamical equation based on the neuronal embedding framework recently introduced by Nguyen and Pham [ 17 ], called the second - order mean field limit, that captures the limiting fluctuation distribution. They demonstrate through the framework the complex interaction among neurons in this second order limit, the stochastic dependency with cross - layer dependency and the nonlinear time evolution inherent in the limit, and show a stability property of gradient descent mean field training in the large - width regime."
SP:a3d927854d9d7fd39b8d05a79666810d585d5062,"This paper proposes a novel method for learning a dissipative model for learning irreversible dynamics with unknown a priori model form. The proposed method learns generalized Casimirs for energy and entropy guaranteed to be conserved and nondecreasing, respectively, and for the case of added thermal noise, it guarantees exact preservation of a fluctuation - dissipation theorem, ensuring thermodynamic consistency. The authors provide benchmarks for dissipative systems demonstrating learned dynamics are more robust and generalize better than either "" black - box "" or penalty - based approaches. Finally, this work is an important first step toward handling more complicated dissipative chaotic systems ubiquitous to science and engineering problems."
SP:32e8e83e06b1e9a4dad761334d5947c91bfd1853,"This paper proposes a sample selection - based algorithm for fair and robust training. The authors formulate a combinatorial optimization problem for the unbiased selection of samples in the presence of data corruption. Observing that solving this optimization problem is strongly NP - hard, they propose a greedy algorithm that is efficient and effective in practice. Experiments show that their algorithm obtains fairness and robustness that are better than or comparable to the state - of - the - art technique."
SP:991127729bf067fe27fdd7ed360aab39e4df5921,"This paper proposes to use periodic activation functions in Bayesian neural networks ( BNNs ) to build models that ‘ know what they do not know ’ by introducing inductive biases in the function space. The authors show that the prior on the network weights and translation - invariant, stationary Gaussian process priors establish a connection between the prior and the weights of the hidden layer of the BNN. They show that this link goes beyond sinusoidal ( Fourier ) activations by also covering triangular wave and periodic ReLU activation functions. They also show that periodic activation function obtain comparable performance for in - domain data and capture sensitivity to perturbed inputs in deep neural networks for out - of - domain detection."
SP:d61a2aecfea4612c473b4e6fd41f3dc2fcbb04a1,"This paper proposes a method to provide feedback to interactive programs as a task of classifying Markov Decision Processes ( MDPs ). Each student’s program fully specifies an MDP where the agent needs to operate and decide, under reasonable generalization, if the dynamics and reward model of the input MDP should be categorized as correct or broken. The authors demonstrate that by designing a cooperative objective between an agent and an autoregressive model, they can use the agent to sample differential trajectories from the MDP that allows a classifier to determine membership. The method enables an automatic feedback system for interactive code assignments."
SP:daf99ad91613d6e11b13315ccbd1bbe25094ae4b,"This paper proposes a method for deep reinforcement learning ( DRL ) that leverages the influence of high - level latent features on the action values of a DRL model. The authors propose a new method for training a mimic tree based on an identifiable latent representation to capture the independent factors of variation for the objects, and a MCRTS algorithm to search for the optimal mimic tree. They show that their mimic tree achieves strong approximation with significantly fewer nodes than baseline models."
SP:84560de78af979354fff83d1370d8675c1e9191f,This paper proposes a Bayesian framework to model the structure of dynamic predictions over time. The authors propose a Gaussian latent information martingale ( GLIM ) based on Bayesian Bayes Bayes method. The proposed method is based on the Gaussian Bayes distribution of the probability of rain on a given day. The method is shown to outperform other Bayesian methods on three different metrics.   
SP:0c4bfb44e0a353256692d5e5ae96f65c1a14363d,"This paper studies the problem of active pure exploration with fixed confidence in generic stochastic bandit environments. The goal of the learner is to answer a query about the environment with a given level of certainty while minimizing her sampling budget. For this problem, instance - specific lower bounds on the expected sample complexity reveal the optimal proportions of arm draws an Oracle algorithm would apply. These proportions solve an optimization problem whose tractability strongly depends on the structural properties of the environment, but may be instrumental in the design of efficient learning algorithms. The authors devise Frank - Wolfe - based Sampling ( FWS ), a simple algorithm whose sample complexity matches the lower bounds for a wide class of pure exploration problems. The algorithm is computationally efficient as it relies on a single iteration of Frank -Wolfe algorithm applied to the lower - bound optimization problem. They apply FWS to various exploration tasks, including best arm identification in unstructured bandits and Lipschitz bandits. Despite its simplicity, FWS is competitive compared to state - of - art algorithms."
SP:0947a0f08fba53d3c8af9b78dd64e6e10fc73e32,"This paper proposes a new method for optimizing combinatorial spaces ( e.g. sequences, trees, and graphs ) by learning a latent representation of structures using deep generative models ( DGMs ). The proposed method, LADDER, is based on a novel structure - coupled kernel that explicitly integrates the structural information from dec dec dec structures with the learned latent space representation for better surrogate modeling. Experiments on real - world benchmarks show that the proposed method significantly improves over the BO over latent space method, and performs better or similar to state - of - the - art methods."
SP:37adabdc6615c5199a481553c8ccc06d57363614,"This paper studies the regret minimization problem in finite - horizon Markov Decision Processes ( MDPs ) with linear structure. The authors derive a necessary condition on the representation, called universally spanning optimal features ( UNISOFT ), to achieve constant regret in any MDP with linear reward function. They then demonstrate that this condition is also sufficient for these classes of problems by deriving a constant regret bound for two optimistic algorithms ( LSVI - UCB and ELEANOR ). Finally, they propose an algorithm for representation selection and prove that it achieves constant regret when one of the given representations, or a suitable combination of them, satisfies the UN ISOFT condition."
SP:92566b664ab2f6ee9b73f29327aeef85d14ecf60,"This paper proposes a differentiable contact model for learning dynamics from data. The proposed contact model is based on a contact model that captures contact mechanics : frictionless / frictional, as well as elastic /inelastic. This model can also accommodate inequality constraints, such as limits on the joint angles. The contact model extends the scope of Lagrangian and Hamiltonian neural networks by allowing simultaneous learning of contact and system properties. The authors demonstrate this framework on a series of challenging 2D and 3D physical systems with different coefficients of restitution and friction and friction. The framework can be used as a Differentiable physics simulator for downstream gradient - based optimization tasks."
SP:82d59a3609dfd458f90f23d4e477c8b497e9dc18,This paper studies the effect of stochastic training on the Lipschitz constant of a deep neural network ( NN ) on the complexity of the training dynamics of the NN. The authors show that the training trajectory of NNs with a 1st layer bias is trained more steadily ( i.e. slowly and with little variation ) have bounded complexity even in regions of the input space that are far from any training point. They also show that steady training with Dropout implies a training and datadependent generalization bound that grows polylogarithmically with the number of parameters.
SP:9b329c915fa8d4045c167c9df37a49ee314d190e,"This paper presents an algorithm for distribution - independent PAC learning of halfspaces in the Massart noise model with strongly polynomial sample complexity, independent of the bit complexity of the examples. The authors show that any distribution can be efficiently decomposed as a disjoint mixture of few distributions for which a Forster transform exists and can be computed efficiently. The algorithm of [ DGT19 ] requires n = poly(d, b, 1/ ) labeled examples, runs in time poly(n, b ) and achieves misclassification error $ O(n, b )$. The dependence on b in the runtime is likely to be inherent ( learning halfspaced without noise amounts to solving a general linear program (LP ) ) and removing the b dependence from the runtime would yield a strongly Polynomial algorithm for general LP. The main result of this paper provides an affirmative answer to this question."
SP:e5229305af00067ae2dbabd903e585964aec8928,"This paper proposes a Bayesian optimisation - based attack method for adversarial attacks on graph neural networks ( GNNs ). The proposed method is based on Bayesian Bayesian Optimisation ( BO ) based attack, which is both query - efficient and parsimonious with respect to the perturbation applied. The method is evaluated on a wide range of graph classification tasks involving varying graph properties, constraints and modes of attack. It is shown that the proposed method can be easily adapted to perform various modes of attacks such as deleting or rewiring edges and node injection. The authors also investigate the topological properties of the successful adversarial examples found by their method."
SP:4999e5664383066fdacd14be6242c7b83f85f3dd,This paper studies the problem of online label shift adaptation in the online learning setting. The authors propose two adaptation algorithms inspired by classical online learning techniques such as Follow The Leader ( FTL ) and Online Gradient Descent ( OGD ) and derive their regret bounds. They empirically verify their findings under both simulated and real world label distribution shifts and show that OGD is particularly effective and robust to a variety of challenging label shift scenarios.
SP:806515ae07fb1c9d02773592005d53d4158ef102,"This paper proposes a method for detecting and localizing gradual changes in the distribution of a sequence of time - ordered observations. The proposed method requires no prior domain knowledge, and it offers theoretical guarantees on both detection ( false positive rate, power ) and localization ( Consistency ). Despite relaxed assumptions, the proposed method possesses proven theoretical guarantees for detection and localization."
SP:7a3c8a7b17ecab19361d36e1d3d73fa35b71214c,"This paper proposes an online algorithm to solve the blind source separation ( BSS ) problem in signal processing. The algorithm is based on the ICA neural network ( NN ), which is an online neural network that computes the sources on the fly without storing any significant fraction of the data in memory. The authors propose a novel objective function for ICA to be updated using local learning rules, extending more conventional Hebbian learning rules by a time - varying modulating factor which is a function of the total output activity of the output neurons. In the brain, this could be accomplished by neuromodulators, extracellular calcium, local field potential, or nitric oxide."
SP:22f8b517a3df65144412938f5891c463d7bae0ab,"This paper proposes to characterize the space of solutions associated with various tasks. The authors first study a simple two - neuron network on a task that leads to multiple solutions. They trace the nature of the final solution back to the network ’s initial connectivity and identify discrete dynamical regimes that underlie this diversity. They then examine three neuroscience - inspired tasks : Delayed discrimination, Interval discrimination, and Time Reproduction. They show that different networks with identical hyperparameters find qualitatively different solutions for each task. They find one layer of variability within the neural activity in response to stimuli from the training set. They also show that the diversity revealed with these challenging inputs corresponds to different computations performed by the network."
SP:9b08a0f547ead3b59077a43b1052c6d46a0730f6,"This paper proposes a new method for arbitrary conditional density estimation based on energy - based learning. The method is called Arbitrary Conditioning with Energy ( ACE ), which aims to estimate the distribution p(xu | xo ) for all possible subsets of unobserved features xu and observed features xo. ACE is designed to avoid unnecessary bias and complexity, and specify densities with a highly expressive energy function and reduce the problem to only learning one - dimensional conditionals ( from which more complex distributions can be recovered during inference ). Empirical results show that ACE achieves state - of - the - art results on standard benchmarks and data imputation."
SP:f2b14f5854e6aa6922795d1d2051b7402486cef6,"This paper proposes a new adaptive weighted loss function for SISR to train deep networks focusing on challenging situations such as textured and edge pixels with high uncertainty. Specifically, the authors introduce variance estimation characterizing the uncertainty on a pixel - by - pixel basis into SisR solutions so the targeted pixels in a high - resolution image (mean ) and their corresponding uncertainty (variance ) can be learned simultaneously. Experiments show that the proposed uncertainty - driven loss has achieved better PSNR performance than traditional MSE or L1 loss for a wide range of network architectures."
SP:9997583f40fa648adf57bb4fc34228f357be0cf1,"This paper proposes a generalization of PAC - Bayesian generalization bounds for adversarial robustness, that estimate, at test time, how much a model will be invariant to imperceptible perturbations in the input. Instead of deriving a worst - case analysis of the risk of a hypothesis over all the possible perturbation, the authors leverage the PACBayesian framework to bound the averaged risk on the perturbings for majority votes ( over the whole class of hypotheses ). Their theoretically founded analysis has the advantage to provide general bounds that are valid for any kind of attacks ( i.e., the adversarial attacks ) that are tight thanks to the PAC - bayesian framework, and that can be directly minimized during the learning phase to obtain a robust model on different attacks at the test time."
SP:90b72e8dc41584e38f25dff9fb2853f5b11dc8fa,"This paper proposes a Probabilistic Entity Representation Model ( PERM ) to encode entities as a Multivariate Gaussian density with mean and covariance parameters to capture its semantic position and smooth decision boundary, respectively. PERM also defines the closed logical operations of projection, intersection, and union that can be aggregated using an end - to - end objective function. On the logical query reasoning problem, they demonstrate that the proposed PERM significantly outperforms the state - of - the - art methods on various public benchmark KG datasets on standard evaluation metrics. They also evaluate PERM’s competence on a COVID - 19 drugrepurposing case study and show that their proposed work is able to recommend drugs with substantially better F1 than current methods."
SP:b6184c9732dbb7eba7c20cae8869d975c428efe4,"This paper proposes a forward - mode differentiation with sharing ( FDS ) algorithm for gradient - based hyperparameter optimization ( HPO ). FDS is a simple and efficient algorithm which tackles memory scaling and gradient degradation issues by sharing hyperparameters that are contiguous in time. The authors provide theoretical guarantees about the noise reduction properties of their algorithm, and demonstrate its efficiency empirically by differentiating through 10 gradient steps of unrolled optimization. They show that their method can significantly outperform various HPO algorithms."
SP:9c3a326e5ee4e862923d3bf9415f32a077db8534,"This paper proposes a dual - system model to improve the consistency and robustness of neural sequence models by adding a symbolic reasoning module to a neural sequence model. The proposed method is based on a neural system model ( GPT - 3 ), which is trained using a few - shot learning approach. The authors show that the proposed method improves the consistency of text generation as measured by human judges. They also show that their method can be combined with goalprediction models and execution models to achieve improved performance in low - data regimes."
SP:d77d046095e4c8336c0c76ac48cb046923230753,"This paper proposes a novel method for estimating the mean outcome of off - policy evaluation ( OPE ) in continuous treatment settings. The main contribution of the paper is a deep jump learning ( DJL ) method that adaptively discretizes the treatment space using deep discretization, by leveraging deep learning and multiscale change point detection. The method is further justified by theoretical results, simulations, and a real application to Warfarin Dosing. Empirically, the proposed method outperforms existing state - of - the - art OPE methods in both simulations and real data application."
SP:4d085e57286fdd36143108a002d16914222c239a,"This paper proposes a variational inference framework for continuous - time hybrid systems. The proposed method is based on a Markov jump process modulating a subordinated diffusion process. The authors provide the exact evolution equations for the prior and posterior marginal densities, the direct solutions of which are however computationally intractable. Therefore, the authors develop a new continuous time inference algorithm, combining a Gaussian process approximation on the diffusion level with posterior inference for Markov Jump Process. By minimizing the path - wise Kullback - Leibler divergence, they obtain Bayesian latent state estimates for arbitrary points on the real axis and (ii ) point estimates of unknown system parameters, utilizing variational expectation maximization."
SP:d1f396e691f9d331adfb7b694a99c50e8004331f,"This paper studies the impact of the spikiness of the spectrum of sensing matrices on the difficulty of recovering from the expectation propagation algorithm ( GLM - EP ). The authors define a notion for the spikyness of spectrum of A and show the importance of this measure in the performance of the EP. They show that in phase - retrieval problems, matrices with spikier spectrums are better for EP, while in 1 - bit compressed sensing problems, less spiky ( flatter ) spectrums offer better recoveries."
SP:ee66604d4da9fd04826e90ccbb94f0499eba4c63,"This paper proposes Dual Progressive Prototype Network ( DPPN ), a novel method to improve cross - domain transferability and category discriminability of visual representations in GZSL. The main contribution of the paper is to propose a novel dual prototype network ( DPN ) that constructs progressive prototypes for both attributes and categories. The proposed method is based on two types of prototypes : attribute prototypes that record prototypical visual patterns for attributes and category attributes, respectively, and category prototypes for category attributes. Experiments on four benchmarks demonstrate that the proposed method achieves state - of - the - art performance in the domain shift problem and achieves new state of the art performance."
SP:61eb6297568c3f6869fbb03eaf6a21260de5466c,"This paper presents an end - to - end deep learning approach for removing defocus blur from a single image, so as to have an all - in - focus image for consequent vision tasks. First, a pixel - wise Gaussian kernel mixture ( GKM ) model is proposed for representing spatially variant blur kernels in an efficient linear parametric form, with higher accuracy than existing models. Then a deep neural network is developed by unrolling a fixed - point iteration of the GKKM - based deblurring. The GKMKNet is built on a lightweight scale - recurrent architecture, with a scale - Recurrent attention module for estimating the mixing coefficients in GKMM. The paper also presents extensive experiments to show the effectiveness of the proposed method."
SP:18bf447c90935c373e5ec4cdfbbf8f2a273d2edb,"This paper proposes a new method for self - supervised video representation learning ( SSVRL ) based on a cross guidance contrastive learning algorithm based on multi - instance NCE loss, where motion vectors can take supervision signals from RGB frames and vice versa. The authors propose a novel Motion Vector based Cross Guidance Contrastive learning approach ( MVCGC ) that can learn representations from compressed videos on - the - fly. The proposed method is evaluated on two downstream tasks ( action recognition and action retrieval ) across different benchmarks. The results show that the proposed method achieves state - of the - art performance while being more efficient than its counterparts."
SP:8c7b1d976d9758cd534c565ec31a23f97892e503,"This paper proposes a method to mitigate overconfidence in ReLU Bayesian neural networks ( BNNs ) that can still underestimate uncertainty and thus be asymptotically overconfident. The output variance of a BNN with finitely many features is quadratic in the distance from the data region. Meanwhile, Bayesian linear models with ReLU features converge, in the infinite - width limit, to a particular Gaussian process ( GP ) with a variance that grows cubically. The authors show that the resulting model approximates a full GP posterior, thanks to its structure, can be applied post - trained to any pre - trained ReLU BNN at a low cost."
SP:e77276f61626e896f6a985296f1d832129242cdf,"This paper considers the problem of selecting a causal quantity of interest among a set of available formulas. The authors propose a sequential strategy in which the investigator decides which subset of variables to observe with the goal of identifying the best formula with the fewest observations. They cast this strategy into the best - arm - identification bandit framework [ 20 ], by considering each formula as one arm and by replacing the typical goal of learning the arm with the best mean. This enables them to introduce methods for implementing the strategy by leveraging algorithms from the bandit literature. To enable them to meaningfully compare long - run behavior of different estimators, they focus on √ n - consistent estimators and use the asymptotic variance, which is the leading constant in the error rate, as the performance evaluation metric. They adapt well - known bandit algorithms to this goal by introducing finite - sample confidence intervals on the asymetrical variance. They validate their method by providing upper bounds on the sample complexity and an empirical study on artificially generated data. They show significant sample complexity reduction with respect to a naïve uniform sampling method."
SP:471361588bfc6c6033631509d1e43e77fd9721ce,"This paper proposes a new algorithm ErrorCompensatedX, which uses the compression error from the previous two steps of the stochastic gradient descent algorithm to improve the convergence rate of the original algorithm without compression. The authors show that the proposed algorithm can achieve the same asymptotic convergence rate with the training without compression and without compression without compression, as well as with compression. They also provide a unified theoretical framework for this class of variance reduced algorithms, with or without error compensation."
SP:3b7ff0dc668cac2191d95fcc4dc6e0335dec3206,"This paper proposes a method for explaining graph neural networks ( GNNs ) based on multi - granularity explainability ( AUC ). The main idea is to use a pre - training phase to generate explanations for the class - wise contrastivity among different classes, and then a fine - tuning phase to adapt the explanations in the local context. The method is evaluated on both synthetic and real - world datasets. The results show the superiority of the method in terms of AUC on explaining graph classification over the leading baselines."
SP:9b5a62d3a2b27bc60da28980e9fb0ecdff1215c0,"This paper proposes a novel method to generate robust counterfactual explanations on GNNs by explicitly modelling the common decision logic of Graph Neural Networks ( GNN ) on similar input graphs. The main contribution of the paper is to propose an explanation method that is robust to noise and aligns well with human intuition. The proposed method is evaluated on several datasets and compared to several state - of - the - art methods on fidelity, robustness, accuracy, accuracy and efficiency."
SP:4edb870786c9cea2c6075359cb4e79b02a8e2f5f,This paper proposes a new method for voice - style transfer based on self - supervised representation learning and adversarial feedback. The proposed method is based on a novel information bottleneck that can decompose the content and style with only a small loss of content information. The discriminator is decomposed into content discriminator and style discriminator with self - supervision. The experimental results show the superiority of the proposed method in disentanglement and transfer performance compared to other baselines.
SP:9fbb0c6beb3f8f88972f13dcf0e1fe7db03233c7,This paper proposes a voxel - to - BEV tracking method for 3D object tracking in sparse 3D point clouds. The method consists of a Siamese shape - aware feature learning network and a Voxel to BEV target localization network. The proposed method is evaluated on KITTI and nuScenes datasets and shows that it significantly outperforms the current state - of - the - art methods by a large margin.
SP:8b788c78680a54c453a04f4551436763ee57585e,"This paper proposes a novel positional encoding method based on learnable Fourier features for multi - dimensional positional encoding. The proposed method is based on a multi - layer perceptron based on Fourier feature mapping ( MLP ). The main contributions of the paper are as follows : 1. The authors propose a positional encoding function that learns a function to map multi -dimensional positions into a vector space. 2. The method is parameter - efficient, in the sense that the number of parameters do not grow with sequence length. 3. To allow complex positional relationships, the representation is also composable by encoding each subset of dimensions, in a multidimensional space, using a shared learnable feature mapping. 4. Experiments on several public benchmark tasks show that the proposed method outperforms existing methods by both improving the accuracy and allowing faster convergence."
SP:d2ac1b6381315bce4449f09bd519f33a2a42d714,"This paper considers the problem of learning the causal MAG of a system from observational data in the presence of latent variables and selection bias. Constraint - based methods are one of the main approaches for solving this problem, but the existing methods are either computationally impractical when dealing with large graphs or lacking completeness guarantees. The authors propose a novel computationally efficient recursive constraint - based method that is sound and complete. The key idea of their approach is that at each iteration a specific type of variable is identified and removed and this allows us to learn the structure efficiently and recursively, as this technique reduces both the number of required conditional independence ( CI ) tests and the size of the conditioning sets. The former substantially reduces the computational complexity, while the latter results in more reliable CI tests. To the best of our knowledge, this is the tightest bound in the literature."
SP:49a4912ce457f5f5ec62c44fa10444af8075fabf,"This paper proposes a batch Thompson Sampling framework for two canonical online decision making problems : stochastic multi - arm bandit and linear contextual bandit with finitely many arms. To achieve this exponential reduction, i.e. reducing the number of interactions from T to O(log T ), the batch policy dynamically determines the duration of each batch in order to balance the exploration - Exploitation trade - off. The authors also demonstrate experimentally that dynamic batch allocation dramatically outperforms natural baselines such as static batch allocations."
SP:653a519e3c799c25e0d0b4240322642040b121a3,"This paper presents a theoretical analysis of the trade - off of learning domain - invariant representations in domain adaptation ( DA ) and domain generalization ( DG ) settings. The main contribution of the paper is a novel upper - bounds for the target general loss for the two kinds of domain - Invariant representations. Theoretical bounds are developed in a general setting of multi - class classification with a sufficiently general loss, which can be viewed as a non - trivial generalization of existing works in DA [ 30, 3, 53, 31, 54, 54 ], each of which considers binary classification with specific loss functions. Theorems 1 and 3 interweaving both input and latent spaces are novel and benefit theoretical analyses in deep learning. The paper also conducts experiments to inspect the trade off of these representations for offering practical hints regarding how to use them in practice and explore other interesting properties of their theory."
SP:2a7bee950cd07494d59dfee60ac2e86cc0e481b1,"This paper proposes an aligned structured sparsity learning ( ASSLN ) method to improve the performance of lightweight image super - resolution ( SR ) networks with moderate model size. The proposed method is based on a weight normalization layer and applies L2 regularization to the scale parameters for sparsity. To align the pruned filter locations across different layers, the authors propose a sparsity structure alignment penalty term, which minimizes the norm of soft mask gram matrix. The authors conduct extensive comparisons with lightweight SR networks and compare their method with SOTA lightweight image SR methods."
SP:e9830bb9e7d3ddc3bd1c2994590fdb5d8f3668be,"This paper proposes a novel method for multi - agent reinforcement learning with Curiosity - driven exploration, called Episodic Multi - Agent reinforcement learning ( EMC ). EMC leverages an insight of popular factorized MARL algorithms that the individual utility functions used for local execution are the embeddings of local actionobservation histories, and can capture the interaction between agents due to reward backpropagation during centralized training. The authors propose to use prediction errors of individual Q - values as intrinsic rewards for coordinated exploration and utilize episodic memory to exploit explored informative experience to boost policy training. They evaluate EMC in didactic examples, and a broad set of StarCraft II micromanagement benchmark tasks."
SP:c7e33d479575c88e22282ee6fd4f978bcd3c06ed,"This paper studies the problem of list - decodable linear regression, where an adversary can corrupt a majority of the examples. The main result is a Statistical Query ( SQ ) lower bound of d for this problem, which is based on a linear regression model with Gaussian covariates and a noise distribution. The goal is to output a small list of hypothesis vectors such that at least one of them is close to the target regression vector, and the remaining ( 1 - α)-fraction of the points are drawn from an arbitrary noise distribution, and a small number of the hypothesis vectors are considered. The authors show that their lower bound matches the performance of previously developed algorithms, providing evidence that current upper bounds for this task are nearly best possible."
SP:7b258252a9063514348f5fa8d9c85afd85748747,"This paper proposes a novel hybrid modeling framework, the Latent Hybridisation Model ( LHM ), that integrates a system of expert - designed ODEs with machine - learned Neural ODES with a larger latent variable ML model. In the larger model, they use observational data to learn both the evolution of the unobservable latent variables and the relationship between measurements and all the latent variables. The machine learning component provides links between the expert variables and clinical measurements, the underlying pharmacological model improves sample efficiency, and expert variables provide additional insights to the clinicians. A variety of experiments ( using synthetic and real data ) demonstrate the effectiveness of the hybrid approach."
SP:3ea9e86e5755ef84d28e3163c60531ace5d62e3a,"This paper presents a theoretical framework for analyzing a MAML - based representation learning algorithm. The authors provide risk bounds on predictors found by finetuning via gradient descent, demonstrating that the method provably leverages the shared structure. In contrast, the authors establish settings where learning one representation for all tasks ( i.e. using a “frozen representation ” objective ) fails to outperform directly learning the target task with no other information, in the worst case."
SP:8ba5a2ac80f7c53f81ad008e96c033ecad14ac0d,"This paper proposes G2L2, a lexicalist approach toward learning a compositional and grounded meaning representation of language from grounded data, such as paired images and texts. At the core of the paper is a collection of lexicon entries, which map each word to a tuple of a syntactic type and a neuro - symbolic semantic program. To facilitate learning in an exponentially growing compositional compositional space, the paper introduces a joint parsing and expected execution algorithm, which does local marginalization over derivations to reduce the training time. The paper evaluates the proposed method on two domains : visual reasoning and language - driven navigation. Results show that the model can generalize from small amounts of data to novel compositions of words."
SP:16c458651815813efdcbe8ba1205bbddbe3e4e68,"This paper proposes a stochastic Newton algorithm for homogeneous distributed stochastically convex optimization, where each machine can calculate the same population objective. The authors show that their method can reduce the number, and frequency, of required communication rounds compared to existing methods without hurting performance, by proving convergence guarantees for quasi - self - concordant objectives ( e.g. logistic regression ). The main guarantees of the method are provided in Section 1. In Section 2, the authors show how, for some regimes in terms of M, K, and R, our method may improve upon the rates of previous first - order methods, including FEDAC ( Yuan and Ma, 2020 )."
SP:d7e479d59f82d4c55372a68ca7b4516f2871f346,"This paper proposes a new similarity measure named Density - aware Chamfer Distance ( DCD ) to measure the similarity between two point sets. DCD is derived from CD and benefits from several desirable properties : 1 ) it can detect disparity of density distributions and is thus a more intensive measure of similarity compared to CD ; 2 ) it is stricter with detailed structures and significantly more computationally efficient than EMD ; 3 ) the bounded value range encourages a more stable and reasonable evaluation over the whole test set. Experimental results validate that the proposed metric, DCD, successfully overcomes the aforementioned issues of CD and EMD. It is proved to be more faithful to visual quality in Sec 5 and a user study in the supplementary material."
SP:e4b302009520770814ff2c096020b779a9fc38fe,"This paper studies the relationship between knowledge distillation and student generalization in the context of neural information processing systems ( NeurIPS ). The authors show that knowledge distillations are not always effective in generalizing the teacher model to the student model. They show that there is a large discrepancy between the predictive distributions of the teacher and the student, even in cases when the student has the capacity to perfectly match the teacher. They also show how the details of the dataset used for distillation play a role in how closely the student matches the teacher, and that more closely matching the teacher paradoxically does not always lead to better student generalizability."
SP:895c7e03f9e4dadb94be1f39d61bf0b5e1533f4f,"This paper proposes a new algorithm for decision tree optimization based on decision trees. The algorithm is motivated by the following challenges : ( 1 ) Sub - optimality of decision trees is NP - hard to compute the optimal k - tree, or its approximation, when the number k is not fixed, and ( 2 ) finding a decision tree that provides a good accuracy usually requires many runs, since each of them returns only a local minimum that might be arbitrarily far from the global optimum. ( 3 ) Scalability is a problem that is hard to scale to realistically - sized problems unless simplified to trees of a specific form as stated in [ 31 ]. ( 4 ) Streaming, parallel, and dynamic updates do not support continuous learning or updating of the modeled tree when an input sample is either added or removed from the dataset, e.g. when the dataset does not fit into memory or arrives on - the - fly. ( 5 ) Computation time is difficult due to this lack of optimality."
SP:f3ece96b15ec06d703925df2061ed9694ec3bca5,"This paper studies the problem of identifying arms with the largest means under a fixed error rate ( fixed confidence Top - m identification ) for misspecified linear bandit models. The problem is motivated by practical applications, especially in medicine and recommendation systems, where data inevitably deviates from linearity. In this work, the authors derive a tractable lower bound on the sample complexity of any correct algorithm for the general Top - M identification problem. They then describe the first algorithm for this setting, which is both practical and adapts to the amount of misspecification and adaptivity. They derive an upper bound to its sample complexity which confirms this adaptivity and that matches the lower bound when δ = 0. Finally, they show their algorithm on both synthetic and real - world data, showing competitive performance with existing baselines."
SP:e71c5e39b8d8d1640d6de2352ac51ddd52eea89d,"This paper proposes a novel method for learning disentangled graph representations with self - supervised learning for graph neural networks ( GNNs ). The authors propose a novel factor - wise discrimination objective in a contrastive learning manner, which can force the factorized representations to independently reflect the expressive information from different latent factors. Extensive experiments on both synthetic and real - world datasets demonstrate the superiority of their method against several state - of - the - art baselines."
SP:0a7edbbdabab11273689c40c517001eb46491113,This paper proposes a robustness assessment method to assess the robustness of a network trained to input uncertainties with a stochastic simulation inspired by the field of Statistical Reliability Engineering. The method is based on an Importance Splitting simulation generating samples of rare events. The authors derive theoretical guarantees that are nonasymptotic w.r.t. sample size. Experiments show the efficiency of the method making a low number of calls to the network function. The paper presents a scalable and efficient procedure assessing robustness under a large panel of statistical models.
SP:c1db485ff1ff9573daa421e167225654babb55ac,"This paper proposes a new polynomial neural network ( PNN ) framework, called CoPE, for conditional generation tasks. CoPE consists of two variables : the noise variable and the conditional variable. The authors show how CoPE can be trivially augmented to accept an arbitrary number of input variables. Experiments are conducted on five tasks ( class - conditional generation, super - resolution generation, inverse problems, translation, image - to - image translation, attributeguided generation ) involving eight datasets. The results show that CoPE is able to achieve good performance on all tasks."
SP:5a75bc7a3ea0ce971cfceebbc1c2434e3aa2584d,"This paper proposes a novel neural network MMD statistic based on neural tangent kernel ( NTK ) and MMD. The authors propose a two - sample NTK - MMD method to compute the MMD statistics and perform NTK based 2 - sample tests to address the long - standing challenge of memory and computational complexity of MMD, which is essential for online implementation to assimilate new samples. Theoretically, such a connection allows the authors to understand the NTK test statistic properties, such as the Type - I error and testing power for performing the two - samples test, by adapting existing theories for kernel MMD and NTK. Numerical experiments on synthetic and real - world datasets validate the theory and demonstrate the effectiveness of the proposed method."
SP:1df2ffbbe56b8018067820980b93af2a8b57f891,"This paper proposes a class - disentanglement method to train a variational autoencoder G(x ) to extract the class - dependent information from an image x by a trade - off between reconstructing x by G(X ) and classifying x by D(x − G( x ), where the former competes with the latter in decomposing x so that the latter retains only necessary information for classification in x. The method is applied to both clean images and adversarial images and the authors show that the perturbations generated by adversarial attacks mainly lie in clean images. In experiments, this simple approach substantially improves the detection and defense against different types of adversarial attack. The authors also provide novel interpretations to classification and attack models."
SP:2789874561620ba7894c4672f935056bb911e919,"This paper proposes a federated Thompson sampling ( FTS ) algorithm for Bayesian Optimization ( BO ) in federated learning ( FL ) setting. The proposed algorithm is differentially private ( DP - FTS - DE ) algorithm with a rigorous guarantee on the user - level privacy in the FBO setting, which guarantees that an adversary cannot infer whether an agent has participated in the algorithm, hence assuring every agent that its participation will not reveal its sensitive information. The authors provide theoretical guarantees for both the privacy and utility trade - off between privacy - utility trade-off in real - world applications. They empirically demonstrate that DP -FTS -DE delivers an effective performance with a strong privacy guarantee and induces a favorable trade -off between privacy, utility and utility."
SP:be7d6b81736a2c3f89abd8771b41b18802e88832,"This paper proposes a new active learning method for multi - label active learning ( ML - AL ) based on Gaussian process - Bayesian Bernoulli Mixture model ( GP - BM ) to quantify a data sample ’s overall contribution to a correlated label space and choose the most informative samples for cost - effective annotation. The BM encodes label correlations using a Bayesian mixture of label clusters, where each mixture component corresponds to a global pattern of label correlations. The model also outputs a predictive distribution that provides both the label prediction and their correlations in the form of a label covariance matrix. Extensive experiments on both synthetic and real - world multi - labeled data and competitive models demonstrate that the proposed GP - B2M achieves the state - of - the - art active learning performance."
SP:2b7270b0370c193300bcbbb5fb0a4101b3329d99,This paper proposes a new method to reduce the latency of lidar perception models by using a polar coordinate system. The proposed method is based on a polar convolutional architecture. The authors propose to increase the spatial context by using multi - scale padding from neighboring sectors. They also introduce feature undistortion and range stratified convolutions. Experimental results on the nuScenes dataset show significant improvements over other streaming based methods.
SP:7ae2c5b7d9c8a6c8f4a353606aa419929c47f31b,"This paper proposes a framework for learning structured latent variables. The authors extend the Gumbel - Max trick to define distributions over structured domains by leveraging the score function estimators for optimization. In particular, they highlight a family of recursive algorithms with a common feature called stochastic invariant. The feature allows them to construct reliable gradient estimates and control variates without additional constraints on the model. In the experiments, they consider various structured latent variable models and achieve results competitive with relaxation - based counterparts."
SP:415d363c66a6967c1daca9dc02001b85bf7f0752,"This paper proposes GainTuning, a method for adapting CNNs trained on large datasets to a single test image. The method is based on a multiplicative scaling parameter ( Gain ) of each channel in the convolutional layers of the CNNs. The authors show that the proposed method improves the performance of CNNs on standard image - denoising benchmarks, boosting their performance on nearly every image in a held - out test set. They also show that it can improve the performance when the test images differ systematically from the training data, either in noise level or image type."
SP:90afa1102683b456bc72a54abef466326827546a,This paper proposes a new architecture for simultaneous semantic and instance segmentation ( a.k.a. panoptic segmentation ) consisting of a convolutional neural network and an asymmetric multi - way cut problem solver. The latter solves a combinatorial optimization problem that elegantly incorporates semantic and boundary predictions to produce a pan - optic labeling. The formulation allows to directly maximize a smooth surrogate of the quality metric by backpropagating the gradient through the optimization problem. Experimental evaluation on Cityscapes and COCO datasets shows that the proposed architecture outperforms other baselines.
SP:1952e174d9ec7b83ad1d394ece7fe77ea1f6d78d,"This paper proposes Recursive Bayesian Networks ( RBNs ), which generalizes and unifies PCFGs and DBNs, combining their strengths and containing both as special cases. The main challenge lies in performing joint inference over the exponential number of possible structures and the variables. The authors provide two solutions : ( 1 ) generalise and unify the PCFG to the mixed discrete - continuous case, which allows for maximum posterior estimates of the continuous latent variables via gradient descent, while marginalising over network structures. ( 2 ) derive an analytic approximation of the marginal data likelihood ( evidence ) and marginal posterior distribution, allowing for robust parameter optimisation and Bayesian inference."
SP:5f29b169d3e4bbaeeec85e1aeebe2094fae4be6e,"This paper proposes a constrained backpropagation ( CBP ) algorithm based on the pseudo - range multiplier method to obtain the optimal set of weights that satisfy a given set of constraints. The proposed CBP algorithm is the utilization of a Lagrangian function ( loss function plus constraint function ) as its objective function. The authors evaluate the performance of CBP applied to AlexNet, ResNet-18, ResNet -50, and GoogLeNet ( pre - trained using backpropageation with full - precision weights ) with four different constraints ( binary, ternary, one - bit shift, and two -bit shift weight constraints ) on ImageNet as proof of concept examples. The results highlight the classification accuracy outperforming the previous state - of - the - art results by employing appropriate constraint functions."
SP:3ddf8e2e108fb261bb23aec8a27a25aba7523dc1,"This paper proposes a novel active learning algorithm for Gaussian process classification ( GPC ) based on estimating the estimated error reduction ( EER ). The proposed algorithm is based on a joint distribution of queries as a one - dimensional integral, which avoids retraining the GPC for each query when calculating the EER / MOCU - based acquisition function. The authors also derive the gradient chain rule to efficiently calculate the gradient of the acquisition function, which leads to the first query synthesis active - learning algorithm implementing EER - based strategies with GPC. The experiments demonstrate the computational efficiency of the proposed algorithms on both synthetic and real - world datasets."
SP:fa1fac04cd4ccb1f3eaf80807db09f9683ce6b50,"This paper studies the effect of unbounded gradients on the regularization of autoencoder - based architectures, including VAE models, as applied to data lying on or near a low - dimensional manifold ( e.g., natural images ). The authors show that if the ultimate goal is to simultaneously avoid over - regularization ( high reconstruction errors, sometimes referred to as posterior collapse ) and underregularization (excessive dimensions are not pruned from the model ), then an autoencoder - based energy function with infinite gradients around optimal representations is provably required per a certain technical sense which the authors carefully detail."
SP:2611cfd6e0696a57d061687993cef1fe5c95999d,"This paper studies the regret upper bound for the bandit problem with graph feedback. The authors propose two notions of the fractional weak domination number and the k - packing number capturing upper bound and lower bound for regret respectively. They show that the two notions are inherently connected via aligning them with the linear program of the weakly dominating set and its dual. They also show that for graphs with bounded integrality gap, the bound is tight up to a ( log | V | ) 1 3 factor for the vertex packing problem and a lower bound of $ O(\sqrt{V})$ for the regret bound."
SP:e50dec57af337839cbde4b65fb7b431785fda44d,"This paper proposes to use neighbourhood reference distributions to improve the local interpretability of Shapley values. The authors propose to use the Nadaraya - Watson estimator, a well - studied kernel regressor, as a self - normalised importance sampling estimator. The results show that the Neighbourhood Shapley Values identify meaningful sparse feature relevance attributions that provide insight into local model behaviour. They also increase on - manifold explainability and robustness to the construction of adversarial classifiers."
SP:35bdeb78f9fe74e754177fb54b48e7399dc8590d,"This paper proposes PlayVirtual, which augments cycle - consistent virtual trajectories to enhance the data efficiency for RL feature representation learning. PlayVirtual predicts future states in a latent space based on the current state and action by a dynamics model and then predicts the previous states by a backward dynamics model, which forms a trajectory cycle. The authors demonstrate the effectiveness of their PlayVirtual on discrete control benchmark Atari [ 2 ] and continuous control benchmark DMControl Suite [ 43 ], where it achieves the state - of - the - art performance on both benchmarks."
SP:ca09e472cbcf2ac8c8c9b192a87df2ed59218210,"This paper studies the robustness of neural networks to noisy labels. The authors propose a formal framework to study the relationship between network robustness and the alignments between the network architecture and the target function. In particular, the authors consider a linear model trained on a small set of clean labels trained on the learned representations of a linear network trained on clean labels. They show that a network is more robust to noise labels if its architecture is more aligned with the model's target function than the noise. They provide both theoretical and empirical evidence across various neural network architectures and different domains. They also find that when the network is well - aligned with target function, its predictive power in representations could improve upon state - of - the - art ( SOTA ) noisy - label - training methods in terms of test accuracy and even outperform sophisticated methods that use clean labels, such as SOTA noisy - labeling methods."
SP:903727fe028684623a8ccadec210e641ecffc685,"This paper proposes a novel method for learning reward functions for reinforcement learning ( RL ) algorithms. The main idea is to learn to predict whether the task will be solved in the future via classification, without using separate reward learning and policy search procedures. The authors show that their method satisfies a new data - driven Bellman equation, where examples take the place of the typical reward function term, where rewards are replaced by data (examples of success ). Experiments show that the proposed method outperforms prior methods that learn explicit reward functions."
SP:39ccbd5909a1d7ed212fe92d8d6843c2c70dfe1f,"This paper studies differentially private stochastic optimization in convex and non - convex settings. For the convex case, the authors focus on the family of non - smooth generalized linear losses ( GLLs ). Their algorithm for the l2 setting achieves optimal excess population risk in near - linear time, while the best known differentially public algorithms for general convex losses run in super -linear time. For constrained l2 - case with smooth losses, they obtain a linear - time algorithm with rate Õ ( 1 n1/3 + d 1/5 ( nε )2/5 ). Finally, for l2-case with polyhedral constraint, they provide the first method for non - smoothing weakly convex stochastically optimization. The authors extend all their results above for the non -convex l2 set to the lp setting, with only polylogarithmic ( in the dimension ) overhead in the rates."
SP:99a476f71e6901aefe281f11fb72ff78265a5b6e,"This paper studies cooperative bandit learning under three typical real - world communication scenarios, namely, message - passing over stochastic time - varying networks, instantaneous reward sharing over a network with random delays, and message - passing with adversarially corrupted rewards, including byzantine communication. For each of these environments, the authors propose decentralized algorithms that achieve competitive performance, along with near - optimal guarantees on the incurred group regret as well as an improved delayed - update algorithm that outperforms the existing state - of - the - art on various network topologies. The proposed algorithms are straightforward to implement and obtain competitive empirical performance."
SP:d3e896a65470f2439bc7753b4f66e152306b2d6f,"This paper proposes a post - training quantization algorithm for vision transformers to reduce the memory storage and computational costs. The quantization task can be regarded as finding the optimal low - bit quantization intervals for weights and inputs, respectively. To preserve the functionality of the attention mechanism, the authors introduce a ranking loss into the conventional quantization objective that aims to keep the relative order of the self - attention results after quantization. The authors also analyze the relationship between quantization loss of different layers and the feature diversity, and explore a mixedprecision quantization scheme by exploiting the nuclear norm of each attention map and output feature. The effectiveness of the proposed method is verified on several benchmark models and datasets."
SP:aa6b1328585b5916267a3ff4f9119e7aa4ce2bb5,"This paper studies the convergence rate of synchronous and asynchronous double - Q - learning algorithms. The synchronous algorithm achieves a global optimum with a time complexity of $ \mathbb{R}$-1.7 $, while the asynchronous algorithm achieves $ 1.1 $-1 $, and the authors show that synchronous algorithms converge faster than the asynchronous algorithms.   The authors propose two new analytical tools to improve the existing convergence rate by the order of magnitude in terms of its dependence on all major parameters. The authors also propose a novel analysis technique to improve convergence rate."
SP:04fd4d83717c4f7e1a4b5651a59200151f33411d,This paper proposes a new method for semi - supervised OOD detection based on Structure - Keep - Unzipping ( STEP ). The proposed method is based on the idea of structure - keep - unzipping. The idea is to learn a new representation space in which OOD samples could be separated well. The authors show that STEP outperforms other methods by a large margin and achieves remarkable detection performance on several benchmarks.
SP:6bf8b94483b26033795b0eda9649518027f5e1c2,"This paper proposes a transformer - based framework for visual grounding tasks, where two modalities are fused in a visual - lingual encoder. In the decoder, the model learns to generate contextualized lingual queries which are then decoded and used to directly regress the bounding box and produce a segmentation mask for the corresponding referred regions. With this simple but highly contextualized model, they outperform state - of - the - art methods by a large margin on both REC and RES tasks. They also show that a simple pre - training schedule ( an external dataset ) further improves the performance."
SP:29b552b36696c9bda72f3ab4f31605d98880fd6b,"This paper studies the problem of boosting a class of weak hypotheses to a strong and accurate one. The weak learner is an agnostic PAC learner for that class with respect to the standard classification loss. The goal of the overall boosting algorithm is to learn a combination of weak hypothesis by repeatedly calling the weak learners. The authors study the resources required for boosting, especially how they depend on the number of classes k, for both the booster and the weaklearner. They prove that the weak Learner ’s accuracy parameter must be smaller than an inverse polynomial in k, showing that the returned weak hypotheses must be nearly the best in their class when k is large. They also prove a trade - off between number of oracle calls and the resources needed of the weakLearner."
SP:f63b050773871338c48b778c362172e4b72477a4,"This paper proposes a novel method for unsupervised object segmentation and object - centric scene generation based on an embedding - based approach that uses a stochastic stick - breaking process to cluster object representations in a differentiable fashion. The proposed method is evaluated on several synthetic and real - world datasets and compared to several recent baselines. The results show that the proposed method outperforms baselines in terms of image segmentation, scene generation, and object centricity."
SP:408deb9e5577ee7118b836fee77135df641fe545,This paper proposes an adaptive conformal inference ( ACI ) method for forming prediction sets in an online setting where the data generating distribution is allowed to vary over time in an unknown fashion. ACI models the distribution shift as a learning problem in a single parameter whose optimal value is varying over time and must be continuously re -estimated. The authors show that over long time intervals ACI achieves the desired coverage frequency over long - time intervals irrespective of the true data generating process. They also show that ACI will additionally obtain approximate marginal coverage at most time steps.
SP:e6e5b1e2428abcf1a163ec1cce15cd299f9a544f,"This paper proposes a direct pose - level inference strategy that is free of bounding box detection and keypoint grouping. Instead of inferring individual keypoints, the proposed PINet directly infers the complete pose cues for a person from his/her visible body parts. PINet first applies the Part - based Pose Generation ( PPG ) to infer multiple coarse poses for each person. Those coarse poses are refined by the Pose Refinement module through incorporating pose priors, and finally are fused in the Pose Fusion module. Experiments on several crowded scenes pose estimation benchmarks demonstrate the superiority of PINet."
SP:e76f048c3dccffcb8bcc6a66f6165fc19d175610,This paper proposes a method for computing the Bellman operator for S - rectangular robust Markov decision processes with L-constrained rectangular ambiguity sets. The method combines a novel homotopy continuation method with a bisection method to solve S - Rectangular ambiguity in quasi - linear time in the number of states and actions. The algorithm improves on the cubic time required by leading general linear programming methods. The experimental results confirm the practical viability of the method and show that it outperforms a leading commercial optimization package.
SP:c4af66a64a5c2bd58ca2e29dbc4b27d5bf4b63b8,This paper studies the online knapsack with frequency predictions problem with weak predictions. The authors derive online algorithms that attain the best possible competitive ratio for any fixed prediction. They also extend the results to more general settings such as generalized one - way trading and two - stage online KNAPSACK and show that even seemingly weak predictions can be utilized effectively to provably improve the performance of online algorithms.
SP:1d478d4fa3f5df0ded963ef164325667fd744dbb,This paper proposes a new model - based episodic control method for reinforcement learning based on episodic memory of trajectories. The proposed method is based on a combination of episodic and habitual learning models. The authors propose to combine the episodic - based and habitual - based learning models via a dynamic hybrid control. Experiments show that the proposed method outperforms existing methods in a variety of environments including stochastic and non - Markovian settings.
SP:551174c1266b5f4b6aaf5432a4c713386f90898c,"This paper proposes a new semi - supervised learning ( SSL ) method DP - SSL for unlabeled data. The proposed method is based on an innovative data programming scheme to generate probabilistic labels for unlabelled data. In particular, the authors propose a multiple - choice learning ( MCL ) based approach to automatically generate LFs from scratch in SSL style. The authors also design a label model to resolve the conflict and overlap among the noisy labels produced by the LFs. Extensive experiments on four standard SSL benchmarks show that DP -SSL achieves better classification performance on test sets than existing SSL methods, especially when only a small number of labeled samples are available."
SP:d1d6a40a8bde62a21da4fc18a076e344c84ab0d0,This paper proposes a multi - view pose transformer ( MVPT ) model for estimating multi - person 3D poses from multi - views images. The proposed model is based on a hierarchical query embedding scheme to represent the joint information from the input images to directly regress the actual 3D joint locations. The authors also propose a novel projective attention module along with a RayConv operation to integrate the view - dependent camera geometry into the feature representations. They show that their model outperforms state - of - the - art methods on several benchmarks while being much more efficient.
SP:2e147bd5321e25bb27d2531fd58c46460a1e5320,"This paper proposes two learning problems : 1 ) A family of sparse vectors is fixed, where each vector has at most k non - zero elements, and 2 ) A query vector is designed such that all sparse vectors from the family can be approximately reconstructed based on the error - free responses. In the first problem, a sequence of noisy responses is used to learn the supports of all vectors from a family of unknown sparse vectors. The second problem is designed to design queries such that the support of the family is approximately reconstructed. The authors propose two learning algorithms for both problems. The first one is based on tensor decomposition techniques and constructions of union - free families, and it is shown how to efficiently learn with high probability the supports for all unknown vectors without any assumptions. For the second one, the authors show how to improve the query complexity for the robust support recovery problem."
SP:e3388e479a825be429f3a878e2c4d8b05903ff10,"This paper proposes a computationally efficient online sensing scheme for the bandit quickest changepoint detection problem. The proposed method is based on an information - theoretic lower bound on the detection delay for a general class of finitely parameterized probability distributions. The authors derive expected delay bounds for the proposed scheme and show that these bounds match the lower bounds at low false alarm rates, establishing optimality of the proposed method. They then perform a number of experiments on synthetic datasets on synthetic and real datasets demonstrating the effectiveness of their proposed method and show gains due to adaptive sensing."
SP:268260e9452ba2bc57e50a6b7b3328233137ac9b,"This paper proposes a new method for solving stochastic nested optimization problems. The main idea is to combine several SGD - type updates for nested problems into a single SGD approach that is called ALternating Stochastic gradient dEscenT ( ALSET ) method. By leveraging the hidden smoothness of the problem, this paper presents a tighter analysis of ALSET for solving this class of nested problems. Under certain regularity conditions, applying the proposed method either improves or matches the best - known sample complexity in the respective cases."
SP:82ad52361bc5b2c421f1dc6b76e1a5520570fc6c,"This paper proposes Siamese Sampling and Reasoning ( SiaSamRea ) approach, which consists of a siamese sampling mechanism to generate sparse and similar clips from the same video, and a novel reasoning strategy for integrating the interdependent knowledge between contextual clips into the network inference. The proposed method is evaluated on a variety of video question answering ( VideoQA ) tasks, and it achieves state - of - the - art performance."
SP:160022e2cd61159da92f92e85520b7062a337a8d,"This paper proposes an approach to reduce the computational and memory complexity of a large class of structured models, i.e. distributions over combinatorial spaces, which are commonly used to learn latent probabilistic representations from observed data. The authors propose to use a matrix - vector product and a low - rank constraint in the central inference step of HMMs and PCFGs. They show that by viewing the inference step as a matrix product and using a low rank constraint, they can trade off model expressivity and speed via the rank constraint. Experiments with neural parameterized structured models for language modeling, polyphonic music modeling, unsupervised grammar induction, and video modeling show that their approach matches the accuracy of standard models at large state spaces."
SP:238592ad73927194cdf0c0cf9ae2e48ca86e182c,"This paper introduces Sample Average Uncertainty ( SAU ), a simple and efficient uncertainty measure for Bayesian exploration strategies like Thompson Sampling and deep contextual bandits. The authors show that the uncertainty measure estimates the uncertainty of the outcomes of the action - value function based on the value predictions. They also show that SAU can be seamlessly applied as a drop - in replacement for epsilongreedy exploration. They empirically study the deployment of SAU - UCB and SAU-Sampling in the deep bandit setting and use them as exploration strategy for deep neural network value function models and show that they consistently outranks the deep Bayesian bandit algorithms that they analyzed on the benchmarks that they proposed."
SP:ffc5b18f7e18607b2934e5aa199e7542005d79f4,"This paper proposes a method to learn behavioral embeddings from multiple videos of animals performing a repeated motor task. The authors propose a stochastic temporal model to learn continuous and discrete latent representations for simultaneous embedding and segmentation within the same model. They also propose Variational Disentangled Behavior Embedding ( VDBE ), an end - to - end approach that learns meaningful discrete behavior representations and generates interpretable behavioral videos. The proposed method outperforms existing methods on downstream tasks such as fine - grained behavioral motif generation and behavior decoding."
SP:bf78a450e4aad6b87fdeb8ec0d68adaaff7b595b,"This paper proposes a deep 3D conditional generative model to synthesize high - resolution 3D shapes using simple user guides such as coarse voxels. The core of DMTET includes a deformable tetrahedral grid that encodes a discretized signed distance function and a differentiable marching tetrahedra layer that converts the implicit signed distance representation to the explicit surface mesh representation. Compared to the current implicit approaches, which are trained to regress the signed distance values, this paper directly optimizes for the reconstructed surface, which enables the synthesize finer geometric details with fewer artifacts. Unlike deep 3d generative models that directly generate explicit representations such as meshes, this model can synthesize shapes with arbitrary topology and can be trained on a dataset of complex 3D animal shapes."
SP:2bc0bd6aa2a12691b16145f0d23542c4c86e3a44,"This paper proposes sliced mutual information ( SMI ) as a surrogate measure of dependence between one - dimensional random projections. SMI is defined as an average of MI terms between one-dimensional random projections between one and two dimensions. The authors show that SMI preserves many of the structural properties of classic MI, while gaining scalable computation and efficient estimation from samples. Furthermore, SMI can grow as a result of deterministic transformations. This enables leveraging SMI for feature extraction by optimizing it over processing functions of raw data to identify useful representations thereof."
SP:e220b348901b476c2afd95f97630fb5400582f40,"This paper proposes a two - step lookahead constrained Bayesian optimization acquisition function ( 2 - OPT - C ) for non - myopic acquisition functions in the unconstrained setting. The authors argue that existing methods that use the reparameterization trick for more efficient derivative - based optimization of the two - stage acquisition function do not extend to constrained settings. They propose a novel likelihoodratio - based unbiased estimator of the gradient of the 2 - step optimal acquisition function that uses a change of measure of the same type used within importance sampling to estimate the gradient. They show that their method is computationally efficient by 2x or more over previous methods, and in some cases by 10x more than previous methods."
SP:51fbd861422647912f275b48861ea3c4812afdc8,"This paper proposes Multi - Dimensional Distributional Distributional DQN ( MD3QN ), which extends distributional RL to model the joint return distribution from multiple reward sources in reinforcement learning ( RL ). The main contribution of the paper is to propose a method for joint distribution modeling in RL that can capture both the randomness in returns for each source of reward, as well as the rich reward correlation between randomness of different sources of reward. The authors show that the proposed method outperforms previous RL algorithms utilizing multiple sources of rewards, and accurately models the joint returns from all sources."
SP:1f85c93d6bbfd65bf497c92c9cd534d799753097,"This paper proposes a new deep learning method, CorticalFlow, that learns to deform a reference template towards a targeted object using a flow Ordinary Differential Equation ( ODE ) framework. The proposed method is based on a small GPU memory footprint, allowing the generation of surfaces with several hundred thousand vertices. To reduce topological errors introduced by its discrete resolution, the authors derive numeric conditions which improve the manifoldness of the predicted triangle mesh. To demonstrate the utility of the proposed method, they demonstrate its performance for the challenging task of brain cortical surface reconstruction, which is an essential step for the analysis of brain morphometry in neurodegenerative diseases and psychological disorders."
SP:2f31d9cf4ad17ad08344439ca0aef7ec91944545,"This paper proposes a new algorithm for unlearning models that is able to handle adaptive deletion sequences. The algorithm is based on differential privacy and its connection to max information. The authors show that the proposed algorithm can handle arbitrary model classes and training methodologies without requiring pretraining on non - user data. The proposed algorithm is evaluated on CIFAR-10, MNIST, Fashion -MNIST, and Fashion - MNIST. It is shown that the algorithm is robust to adaptive deletions."
SP:7150006590e268ab732c9be6c9048f67a377f956,This paper proposes an algorithm to optimise the conditional value at risk ( CVaR ) of the total return in Bayes - adaptiveive Markov decision processes ( MDPs ). The authors propose an algorithm based on Monte Carlo tree search and Bayesian optimisation based on Bayesian optimization. They show that the proposed algorithm is risk - averse to both the epistemic uncertainty due to the prior distribution of the MDP and the aleatoric uncertainty of the stochasticity of the decision process. They also show that their algorithm significantly outperforms baseline methods on two domains.
SP:a94f39406f73d7483ddd744ed2f03c78b8bc5d44,"This paper studies the behavior of shallow ReLU networks trained with the logistic loss via gradient descent on binary classification data where the underlying data distribution is general, and the (optimal ) Bayes risk is not necessarily zero. In this setting, it is shown that gradient descent with early stopping achieves population risk arbitrarily close to optimal in terms of not just logistic and misclassification losses, but also in term of calibration, meaning the sigmoid mapping of its outputs approximates the true underlying conditional distribution arbitrarily finely. The necessary iteration, sample, and architectural complexities of this analysis all scale naturally with a certain complexity measure of the true conditional model. While it is not shown that early stopping is necessary, it was shown that any univariate classifier satisfying a local interpolation property is inconsistent."
SP:a9c786cbb61e1f10f3542161b13e43a1a68ab34d,"This paper proposes a coordination detection framework incorporating neural temporal point process with prior knowledge such as temporal logic or pre - defined filtering functions. The proposed method jointly learns a Gibbs distribution of group assignment based on how consistent an assignment is to ( 1 ) the account embedding space and ( 2 ) the prior knowledge. To address the challenge that the Gibbs distribution is hard to be efficiently computed and sampled from, the authors design a theoretically guaranteed variational inference approach to learn a mean - field approximation for it. Experimental results on a real - world dataset show the effectiveness of the proposed method compared to state - of - the - art model in both unsupervised and semi - supervised settings. The detection result suggests presence of suspicious coordinated efforts on spreading misinformation about COVID-19 vaccines."
SP:b5c6e967a26a02861db2ecd620e9061db0c03e59,"This paper studies a binary classification problem with low - dimensional non - linear structure. The authors prove that when the network depth is large relative to certain geometric properties that set the difficulty of the problem and the network width and number of samples are polynomial in the depth, randomly - initialized gradient descent quickly learns to correctly classify all points on the two curves with high probability. To their knowledge, this is the first generalization guarantee for deep networks with nonlinear data that depends only on intrinsic data properties. Their analysis proceeds by a reduction to dynamics in the neural tangent kernel ( NTK ) regime, where the network is wide enough to guarantee that gradient descent can make large changes in the network output while making relatively small changes to the network weights."
SP:8f6bee3be43df6b6e80804974014caaafe08c49e,"This paper proposes a method to train a classifier - based GAN with softmax cross - entropy loss ( ACGAN ). The method is based on the idea that gradient exploding in the classifier can cause an undesirable collapse in early training. To address this problem, the authors propose to use a data - to - data cross entropy loss to exploit the class - labeled dataset. The proposed method is called D2D - CE. The authors conduct image generation experiments on CIFAR10, TinyImageNet, CUB200, and ImageNet datasets and show that ReACGAN achieves state - of - the - art generation results on the four datasets."
SP:080e80746a87228b156408ff649ab7a17f44e92d,"This paper proposes an extensive - form double - oracle algorithm for two - player zero - sum games that is guaranteed to converge to an approximate Nash equilibrium linearly in the number of infostates. Unlike PSRO, which mixes best responses at the root of the game, the authors propose Neural XDO ( NXDO ), where the best response is learned through deep RL. Experiments on a modified Leduc poker game and Oshi - Zumo show that XDO achieves approximate Nash equilibria in a number of iterations an order of magnitude smaller than PSRO."
SP:bda04facef4f34679fc4e17b8ea1aae74c3d649f,"This paper proposes an autoencoder architecture for graph - level unsupervised representation learning. The authors propose a permutation - invariant variational autoencoder architecture that is by design invariant to the order of nodes in a graph. The paper proposes to train an encoder and decoder model with an additional permutation matrix to align the input graph node order with the node order of the reconstructed graph. They demonstrate the effectiveness of their proposed model for graph reconstruction, generation and interpolation and the expressive power of extracted representations for downstream graph classification and regression."
SP:e17ea6aeba78c9dfc25596d8b35a2a4f1f1f6763,"This paper proposes to decouple the depth and scope of Graph Neural Networks ( GNNs ) to generate representation of a target entity ( i.e., a node or an edge ). The authors first extract a localized subgraph as the bounded - size scope, and then apply a GNN of arbitrary depth on top of the subgraph. A properly extracted subgraph consists of a small number of critical neighbors, while excluding irrelevant ones. Empirically, on seven graphs ( with up to 110M nodes ) and six backbone GNN architectures, the design achieves significant accuracy improvement with orders of magnitude reduction in computation and hardware cost."
SP:4890f251db559a0a572afc66e0c1f899b577d9ff,"This paper presents a theoretical analysis of affine - coupling flows, a common type of normalizing flows for latent - variable generative models with a tractable likelihood. The authors show that the Jacobian of the latent - to - observable - variable transformation is triangular, allowing the likelihood to be computed in linear time.   The authors also provide theoretical evidence for the benefits of Gaussian padding when training affine coupling flows. They show that a padded version of the input distribution with iid Gaussians can be approximated using well - conditioned affine-coupling flows. The paper also provides theoretical evidence that underdamped Langevin dynamics ( a stochastic differential equation often used to sample from Gibbs measures ) and Hénon maps ( a structured dynamical system that appears in the study of symplectic diffeomorphisms ) can be used to approximate a padded distribution."
SP:5ffa81488ed1092deb89bd5e150fa146325057ce,"This paper proposes a method to solve the problem of coupons allocation policy learning in the e - commerce market. The proposed method is based on a budget constrained offline reinforcement learning ( BCORLE(λ ) framework ) framework, an offline policy learning method, an off - policy evaluation method, and a random ensemble mixture evaluator ( REME ) algorithm are proposed for policy learning and policy evaluation, respectively. The experiments on the simulation platform and real - world e -commerce market validate the effectiveness of the proposed methods."
SP:6b04cc7b4e45b9e65a1d34c15e3f75a2ef27d601,"This paper proposes a method for source - free domain adaptation ( SFDA ) where the source pretrained model is adapted to the target domain in the absence of source data. The method is based on the observation that target data, which might no longer align with the source domain classifier, still forms clear clusters. The authors define local affinity by defining local affinity of the target data and encourage label consistency among data with high local affinity. They observe that higher affinity should be assigned to reciprocal neighbors, and propose a self - regularization loss to decrease the negative impact of noisy neighbors. In the experimental results, the authors verify that the inherent structure of target features is an important source of information for domain adaptation."
SP:ac1bf04ff782e5892a0bc5fe5949848ca8e731c2,"This paper proposes an end - to - end embedding method for learning representations from set - structured data. The proposed method is based on the Sliced - Wasserstein distance ( SW ) distance, which is a measure of the distance between samples in a set of samples from a probability distribution. In particular, the proposed method uses a permutation - equivariant pooling mechanism to learn the embedding between sets. The method is evaluated on a variety of data modalities, including point cloud classification, graph classification, image recognition, and image recognition. The results show that the method outperforms other pooling methods."
SP:6cb2f0cbc076f8680cb00411790629f8e1478053,"This paper proposes a new family of recurrent neural networks ( RNNs ) based on stochastic gradient descent ( SGD ). The proposed RNN - SBO - RNN uses SGD to solve the lower and upper - level optimization for learning hidden states and their hyperparameters, respectively. The authors prove that under mild conditions there is no vanishing or exploding gradient in training SBO-RNN. Empirically, the authors demonstrate superior performance on several benchmark datasets with fewer parameters, less training data, and much faster convergence."
SP:d3a4300e21ca215334f256f0467a428470548fe4,"This paper proposes an online algorithm for minimizing power consumption in systems with multiple power - saving states. During idle periods of unknown lengths, an algorithm has to choose between power saving states of different energy consumption and wake - up costs. The algorithm makes decisions based on (potentially inaccurate ) predicted lengths of the idle periods, and the algorithm ’s performance is near - optimal when predictions are accurate and degrades gracefully with increasing prediction error, with a worst - case guarantee almost identical to the optimal classical online algorithm. A key ingredient in the approach is a new algorithm for the online ski rental problem in the learning augmented setting with tight dependence on the prediction error. This is a work of theoretical nature and they are not aware of potential negative societal impact."
SP:22aba6284123af0ecd6605ee4e89b351bd7e10a3,"This paper proposes a framework for quantifying the transferability in multi - source transfer learning problems, with both the task similarities and the sample complexity of learning models taken into account. In particular, the authors consider the setup where the models learned from different tasks are linearly combined for learning the target task, and use the optimal combining coefficients to measure the transferable transferability. Then they demonstrate the analytical expression of this transferability measure, characterized by the sample sizes, model complexity, and the similarities between source and target tasks, which provides fundamental insights of the knowledge transferring mechanism and the guidance for algorithm designs. In addition, they develop an alternating alternating iterative algorithm to implement their theoretical results for training neural networks in multi-source transfer learning tasks."
SP:0fb8dcf15e0d43547d566fdba7bc70b3bb600005,This paper proposes a neural network model for visual search based on a combination of eye - dependent visual recognition and top - down cues. The model is trained on an ImageNet dataset and trained on a modified version of ImageNet with an augmented version of the ImageNet. The proposed model is evaluated on six paradigmatic search tasks that show visual search asymmetry in humans. It is shown that the model is able to find the target image and the search image more easily than a human search model. The authors also show that the polarity of the asymmetry arises from the statistical properties of the developmental diet fed to the model.
SP:f0cc968ea9da4884dcdaf6d0c75ea9f1511bdfc3,"This paper studies the problem of training robust models against adversarial examples. The authors propose a new training method with tighter bounds on the worst - case loss over the allowed perturbation and a smoothness of the loss landscape. They show that the current state - of - the - arts method often has a landscape with favorable optimization properties. The proposed method achieves a decent performance under a wide range of perturbations, while others with only one of the two factors can perform well only for a specific range of adversarial perturbants."
SP:a158f8772a9dada059ffd1d6d7838ed40d8483da,"This paper considers the problem of online linear regression in the stochastic setting. The authors derive high probability regret bounds for online ridge regression and the forward algorithm. This enables them to compare online regression algorithms more accurately and eliminate assumptions of bounded observations and predictions. They advocate for the use of forward algorithm in lieu of ridge due to its enhanced bounds and robustness to the regularization parameter. Moreover, they explain how to integrate it in algorithms involving linear function approximation to remove a boundedness assumption without deteriorating theoretical bounds."
SP:17ff9a2133aebf2d1b1787e8efc49d709389c0e7,"This paper proposes a two - time - scale variant of the extragradient ( EG ) method with an anchoring technique, named extra anchored gradient ( EAG ), for smooth structured nonconvex - convex nonconcave problems. The proposed method has a fast O(1/k ) rate on the squared gradient norm, where k denotes the number of iterations. The authors also propose a stochastic version of FEG - A, named S - FEG, for the case where the problem parameters are not available. The corresponding saddle - gradient operator satisfies the negative comonotonicity condition."
SP:4e38973033de24fc183c6112e1146f8eef0ddaea,"This paper studies uniformity testing for ranking data that consists of rankings over m items, where the alternative class is restricted to Mallows models. The authors show that uniform distribution can be distinguished from Mallows model with O(m 1/2 ) samples based on simple pairwise statistics, which allows them to test uniformity using only two samples, if m is large enough. They also consider uniformity test with central and local differential privacy ( DP ) constraints. They present a central DP algorithm that requires O(max{1/1/0, 1 / p m}, where $ O$ is the privacy budget parameter. They show that their algorithm is straightforward to apply to the local DP scenario, since it works with binary statistics that is extracted from the ranking data."
SP:99a835191a3ba8372e391b6d3316e9b68e543295,This paper proposes a score - based algorithm for learning directed acyclic graphs ( DAGs ) with sparse structure. The algorithm is based on a greedy score based algorithm that requires a polynomial number of score evaluations. The authors show that this algorithm can be seen as a special case of order - based greedy algorithms. They also show that recent polynomially - time algorithms for learning DAG models are also special cases of this algorithm. They provide extensive experiments suggesting that the proposed algorithm indeed optimizes the score in a variety of settings.
SP:b60989706296b963b6671c01f22384978a334be1,"This paper proposes a neural architecture dilation for adversarial robustness ( NADAR ) algorithm to improve the robustness of the backbone CNNs that have a satisfactory accuracy over the natural data. The authors propose a dilation architecture to pursue a maximal robustness gain while preserving a minimal accuracy drop. They also apply a FLOPs - aware approach to optimize the architecture, which can prevent the architecture from increasing the computation cost of the network too much. Experimental results on real - world datasets and benchmark neural networks demonstrate the effectiveness of the proposed algorithm."
SP:77ed765e911a4e5f2bfba13cbd2403500a5d05e6,"This paper studies reward - free reinforcement learning with linear function approximation for episodic Markov decision processes ( MDPs ). In this setting, the agent works in two phases : exploration phase and planning phase. The authors propose a new provably efficient algorithm UCRL - RFE under the Linear Mixture MDP assumption, where the transition probability kernel of the MDP can be parameterized by a linear function over certain feature mappings defined on the triplet of state, action, and next state. They show that to obtain an ε - optimal policy for arbitrary reward function, UCRL-RFE needs to sample at most Ú(Hd(H + d )ε−2 ) episodes during the exploration phase during the planning phase, which is the length of the dimension of the feature mapping. They also propose a variant of UCRLRL -RFE using Bernstein - type bonus to achieve an $ H$-optimal policy. The upper bound matches the lower bound in terms of the dependence on ε and dependence on d if H < d."
SP:28563ba0975f56ddb662cd46e85de78bb6024d36,"This paper proposes a method for forecasting future events based on a data stream of events with seasonal patterns that evolve over time. The authors propose a method called SSMF that can adaptively learn multiple seasonal patterns ( called regimes ) as well as switching between them. The proposed method has the following properties : ( a ) it accurately forecasts future events by detecting regime shifts in seasonal patterns as the data stream evolves ; ( b ) it works in an online setting, i.e. processes each observation in constant time and memory ; ( c ) it effectively realizes regime shifts without human intervention by using a lossless data compression scheme ; ( d ) it outperforms state - of - the - art baseline methods by accurately forecasting upcoming events on three real - world data streams."
SP:e4bb07033001be4d04695ef058f426d49fe440be,"This paper proposes a novel neural network architecture for solving assignment problems. The authors propose a novel network architecture, WeaveNet, to solve the assignment problem. The core module, feature weaving layer, is stacked to model frequent communication between elements in a parameter - efficient way for solving the combinatorial problem of assignment. The experimental results showed its impressive 14 performance among the learning - based baselines compared to the state - of - the - art algorithmic method, depending on the size of problem instances."
SP:8a559e21d45661eef427b310e5fe8488d5749137,"This paper studies the impact of self - supervised learning proxy tasks on the robustness of 3D point cloud recognition models against adversarial attacks with adversarial training. Specifically, the authors study MLP - based ( PointNet, DGCNN, and transformer - based ) 3D architectures and threat models for 3D threat models. They demonstrate that appropriate applications of self supervised learning can significantly enhance robustness in 3D recognition. They further leverage ensemble models to boost the adversarial robustness by a substantial margin."
SP:657c5a1114c0d054b9e767d85990bbbb0492912d,"This paper proposes a method for computing iterative projections of close - by points over widely - prevalent submodular base polytopes B(f ). The main contribution of the paper is to adapt away - step Frank - Wolfe to consider combinatorial structure from previous projections, and accordingly obtain improvements over the basic AFW algorithm. The authors show that the proposed method is able to reduce the runtime of computing certain Bregman projections by a factor of $ O(n/ log(n )$ by an order of magnitude compared to AFW."
SP:8dae43d6b5cebb7ef6c39437d997b390c2380536,This paper considers the problem of learning the natural parameters of a k - parameter minimal exponential family from i.i.d. samples in a computationally efficient manner. The authors propose a method that is consistent as well as asymptotically normal under mild conditions. They provide finite sample guarantees to achieve an ( `2 ) error of α in the parameter estimation with sample complexity O(poly(k/α ) ) and computational complexity $ \mathbb{R}(k / \alpha)$. They show that their method can be viewed as the maximum likelihood estimation of a re - parameterized distribution belonging to the same class of exponential family.
SP:4f9ddb697e86356fb293ef34a69ca3702c4e8164,"This paper proposes a differentiable renderer ( DIBR++ ) based on a combination of rasterization and ray - tracing. The renderer is able to predict the intrinsic object properties from a single image by combining the strengths of their respective strengths -- speed and realism. The proposed renderer incorporates environmental lighting and spatially - varying material models to efficiently approximate light transport, either through direct estimation or via spherical basis functions. Experiments are conducted on both synthetic and real images and demonstrate superior performance on reconstructing realistic materials BRDFs and lighting configurations over prior Rasterization - based methods."
SP:6ac1c8556e7131939cc582f513bc9921470e1b09,"This paper proposes sampling - max, a differentiable training method that imposes implicit constraints to the shape of the probability map by minimizing the expectation of the localization error. The expectation can be approximated by calculating the average error of all samples drawn from the output distribution. Experiments are conducted to demonstrate the effectiveness and flexibility of the proposed method."
SP:478c05c90090f9d80b72ac352c488073b45a5d8b,"This paper proposes a directed graph data augmentation method called Laplacian perturbation ( DiGCL ) for graph contrastive learning ( GCL ). The authors argue that GCL does not take full advantage of the contrastive information provided by data augmentation, resulting in incomplete structure information for models learning. They propose to learn from multiple easy - to - difficult contrastive views generated by LaPLACian perturbing. They show that their method outperforms the state - of - the - art GCL models on various benchmarks."
SP:85b383d2f722f7bff438840e423f5cb4c67d5980,"This paper proposes a multi - environment Symbolic Interactive Language Grounding benchmark ( SILG ) that unifies a collection of diverse grounded language learning environments under a common interface. SILG consists of grid - world environments that require generalization to new dynamics, entities, and partially observed worlds ( RTFM, Messenger, NetHack ), as well as symbolic counterparts of symbolic worlds that require interpreting natural language with respect to complex scenes ( ALFWorld, Touchdown ). In addition, the authors propose the first shared model architecture for RL on these environments, and evaluate recent advances such as egocentric local convolution, recurrent state - tracking, entity - centered attention, and pretrained LM using SILG."
SP:23c8db56f59f778fe812a5dd161f7a1f21c3cdba,"This paper presents a sparse version of the Vision Mixture of Experts network ( MoE ) that is scalable and competitive with the largest dense networks. The authors propose an extension to the routing algorithm that can prioritize subsets of each input across the entire batch, leading to adaptive per - image compute. They train models with up to 24 MoE layers, 32 experts per layer, and almost 15B parameters. They show that these models can be stably trained, seamlessly used for transfer, and successfully fine -tuned with as few as 1 000 datapoints. Moreover, their largest model achieves 90% test accuracy on ImageNet when fine - tuned."
SP:c5235f41dfb8b5cc478f11c5d5e0ab0b8676871e,"This paper proposes a novel method for training narrow neural networks. The authors consider a constrained optimization formulation where the activation is smooth when the size of the neurons is small. They show that as long as the width m > 2n/d ( where d is the input dimension ), the expressivity is strong, i.e. there exists at least one global minimizer with zero training loss. They identify a nice local region with no local - min or saddle points, and prove that every KKT point is a nearly global minimizing point. They also show that the proposed method significantly outperforms SGD in training narrow networks."
SP:0be529f5254afd59dcfa6b34a359c7037e7a8323,"This paper proposes a continuous continuous - covariance bandit ( CMCB ) model to explicitly take into account option correlation in risk - aware multi - armed bandit models. The proposed method is based on a continuous learning model, where a learner is given a set of options and an agent is trained to choose the best trade - off between reward and risk, measured with option covariance. To capture different reward observation scenarios in practice, the authors consider three feedback settings, i.e., full - information, semi - bandit, and full bandit feedback. They propose novel algorithms with optimal regrets ( within logarithmic factors ) and provide matching lower bounds to validate their optimalities. The experimental results demonstrate the superiority of their algorithms."
SP:472a90bb175b0286765c5a47b040e1a58f594a05,This paper proposes a method for computing positive semidefinite ( PSD ) factorizations of data matrices. The method is an extension of Lee - Seung ’s Multiplicative Update ( MMU ) algorithm for computing PSD factorizations. The authors show that the squared loss objective is non - increasing and fixed points correspond to critical points. The analysis relies on Lieb’s Concavity Theorem and shows that the MMU algorithm can be also used as a primitive to calculate blockdiagonal PSD and tensor PSD factors. Experiments are conducted on real and synthetic data.
SP:83abd6d149d88cc6e96cbc4d488e4fe9dc2a4fcb,"This paper proposes a meta - learning framework for domain generalization ( DG ) based on domain - specific - domain - invariance ( DSDI ). The idea is to learn a domain specific representation of the latent space while jointly learning both domain - invariant and domainspecific features in a unified framework. The proposed framework is evaluated on several DG benchmark datasets, including Colored - MNIST, VLCS, PACS, Office - Home, Terra Incognita, DomainNet, and a newly created background - colored MNIST."
SP:4191474c75e2fedf514f0f3001a67a047eb74c30,"This paper proposes a method to improve the performance of generative models on image synthesis tasks. The authors propose to use a classifier guidance method to guide the diffusion model during sampling. The proposed method is shown to achieve better image sample quality than state - of - the - art models on unconditional image synthesis and conditional image synthesis.   The authors show that the proposed method improves the FID on ImageNet and ImageNet 256 with as few as 25 forward passes per sample, while maintaining better coverage of the distribution."
SP:fe3cab08596cde4c14ecf6fca8d0f95b02bab229,"This paper proposes to leverage out - of - distribution samples, i.e. unlabeled samples coming from outside target classes, for improving few - shot learning. The proposed method is simple to implement, agnostic to feature extractors, lightweight without any additional cost for pre - training, and applicable to both inductive and transductive settings. Extensive experiments on various standard benchmarks demonstrate that the proposed method consistently improves the performance of pretrained networks with different architectures."
SP:b1f65724926f136979829b7a6c870bc31f38f591,"This paper proposes two new methods to compute the prioritization weight for Bellman update in reinforcement learning, ReMERN and ReMERT. The main contribution of the paper is a theoretical analysis of the regret minimization objective, and an optimal prioritization strategy that can directly maximize the return of the policy. The theory suggests that data with higher hindsight TD error, better on - policiness and more accurate Q value should be assigned with higher weights during sampling, thus most previous criteria only consider this strategy partially. The authors also provide theoretical justifications for previous criteria, but also propose two new ways to compute prioritization weights. The experiments show that the proposed methods outperform standard off - policy RL methods in various benchmarks."
SP:601ebf30b3c6aa35fcef49633aa8eb0acd0f2c66,"This paper proposes a linear - time algorithm for sequential prediction with expert advice in a nonstationary environment with long - term memory guarantees in the sense of Bousquet and Warmuth [ 4 ]. This algorithm incorporates a relative entropy projection step which is advantageous over previous weight - sharing approaches in that weight updates may come with implicit costs as in for example portfolio optimization. The authors give an algorithm to compute this projection step in linear time, which may be of independent interest. The paper is organized as follows. First introduce the model and discuss related work, giving a detailed overview of the previous results on which they improve. In Section 3 they give their main results, a regret bound which holds for two algorithms, and a new method to compute relative entropy projections with non - uniform lower box constraints inlinear time."
SP:b2439973063e827b3cbe92306a2fdee3286b6b44,"This paper considers the problem of contextual linear bandits, which is motivated by routing applications in navigational engines and recommendation systems to learn a hidden d - dimensional value w.r.t. a subset Xt ⊆ R of possible actions. The authors propose two algorithms for this problem which achieve regret O(d log T ) and exp(O(D log d ) regret and list size poly(d ) regret. They also propose an algorithm for a weaker variant of this problem where the learner only learns the identity of an action that is better than the recommendation. The algorithms are based on new algorithmic techniques in convex geometry ( including a variant of Steiner’s formula for the centroid of a convex set ) which may be of independent interest."
SP:abe83c7e0bcf4829742609d709637e2f84d8a4d9,"This paper introduces a small set of orthogonal combinators for composing machinelearning operators into pipelines. It describes a translation scheme from pipelines and associated hyperparameter schemas to search spaces for AutoML optimizers. The paper presents Lale, an open - source sklearn - compatible AutoML library and evaluates it with a user study."
SP:0d7f1cae577ed598048b64617e85ca6bd5c6d7fa,"This paper proposes a meta - learning method for learning neural network weights that generalize well from small datasets. The authors show that this method can be improved by letting the learning algorithm decide which weights to change, i.e., by learning where to learn. They show that patterned sparsity emerges from this process, with the pattern of sparsity varying on a problem - by - problem basis. This selective sparsity results in better generalization and less interference in a range of few - shot and continual learning problems. They also show that sparse learning also emerges in a more expressive model where learning rates are meta - learneded. Their results shed light on an ongoing debate on whether meta - Learning can discover adaptable features and suggest that learning by sparse gradient descent is a powerful inductive bias for meta -learning systems."
SP:05037e1850003a725a466b64d3e32aa2aed458fb,"This paper proposes a new method for multi - view learning based on shared independent component analysis ( ShICA ). The authors show that this model is identifiable if the components are either non - Gaussian or have enough diversity in noise variances. They then show that in some cases multi - set canonical correlation analysis can recover the correct unmixing matrices, but that even a small amount of sampling noise makes Multiset CCA fail. To solve this problem, they propose to use joint diagonalization after multiset cCA, leading to a new approach called ShICA - J. They show via simulations that ShICA-J leads to improved results while being very fast to fit. They further propose a maximum likelihood estimator of ShICA, which is based on a Gaussian mixture model."
SP:44dd1faa1813c433fd7581d05cae3df440bfb93e,"This paper proposes a novel method of training agents to collaborate well with human partners without using human data. The authors propose a method called Fictitious Co - Play ( FCP ), which is based on a two - player collaborative cooking simulator that has recently been proposed as a challenge problem for coordination with humans. They show that FCP agents score significantly higher than SP, PP, and BCP when paired with novel agent and human partners. They also show that humans also report a strong subjective preference to partnering with F CP agents over all baselines."
SP:21c84bd720b1e90ea0f88fbf8fd24dbcb49b547c,"This paper proposes FACMAC, a new method for cooperative multi - agent reinforcement learning in both discrete and continuous action spaces. Unlike MADDPG, which uses deep deterministic policy gradients to learn policies, FACMAC learns a centralised but factored critic, which combines per - agent utilities into the joint action - value function via a non - linear monotonic function, as in QMIX. The authors evaluate FACMAC on variants of the multi -agent particle environments, a novel multi - agents MuJoCo benchmark, and a challenging set of StarCraft II micromanagement tasks. Empirical results demonstrate FACMAC’s superior performance over MAD DPG and other baselines."
SP:1c8351b8a6cdf1212840388e19a596729b3bfda4,This paper proposes a biologically plausible model of long - term memory based on Hebbian plasticity. The authors propose to use a combination of biologically plausible three - factor plasticity rules to store and read out memories in a key - value mechanism. They show that the same rules are recovered when network parameters are meta - learned. They also show that meta - learning of the plasticity recovers rules similar to the simplified model. They further show that their network performs on par with classical Hopfield networks on autoassociative memory tasks and can be naturally extended to continual recall.
SP:7ad6da2c63859d64970e9b35326e9ceab48add47,"This paper proposes a simple stochastic and online gradient descent methods for pairwise learning. The proposed methods are based on SGD algorithms. The main idea is to pair the current instance with a buffering set of instances with a sufficiently large size and therefore suffers from a scalability issue. A notable difference from the existing studies is that they only pair the present instance with the previous one in building a gradient direction, which is efficient in both the storage and computational complexity. They develop novel stability results, optimization, and generalization error bounds for both convex and nonconvex problems as well as both smooth and nonsmooth problems. They also extend their algorithms and stability analysis to develop differentially private SGD algorithm for pair wise learning which significantly improves the existing results."
SP:cb11dacc930d71a616ee2fbe4acfae030f9dca59,"This paper proposes REDO, a class - agnostic framework to reconstruct the Dynamic Objects from RGBD or calibrated videos. The authors introduce a canonical 4D implicit function which is pixel - aligned with aggregated temporal visual cues and a 4D transformation module which captures object dynamics to support temporal propagation and aggregation. They study the efficacy of REDO in extensive experiments on two synthetic RGBD video datasets SAIL - VOS 3D and DeformingThings4D++ and on real - world video data 3DPW. They find that REDO generalizes well and consistently outperforms prior 4D reconstruction methods by a great margin."
SP:8ae97752e74b4395774575009031abcb6ba5cea7,"This paper provides a non -asymptotic analysis of linear stochastic approximation ( LSA ) algorithms with fixed stepsize. This family of methods arises in many machine learning tasks and is used to obtain approximate solutions of a linear system. The analysis is based on new results regarding moments and high probability bounds for products of matrices which are shown to be tight. In particular, the authors derive high probability bound on the performance of LSA under weaker conditions on the sequence {(An,bn ) : n 2 N⇤} than previous works. However, in contrast, in the paper, the polynomial concentration bounds with order depending on the stepsize are established. The authors show that their conclusions cannot be improved without additional assumptions on the sequences of random matrices."
SP:86c1e937755e35efafecc09dfe2606ffb1653a41,"This paper extends the options framework for temporal abstraction in reinforcement learning from discounted Markov decision processes ( MDPs ) to average - reward MDPS. The authors propose a general convergent off - policy inter - option learning algorithms, intra - option algorithms for learning values and models, as well as sample based planning variants of reinforcement learning algorithms. They also extend the notion of option - interrupting behavior from the discounted to the average -reward formulation. They show the efficacy of the proposed algorithms with experiments on a continuing version of the Four - Room domain."
SP:7e4e1e20e7c253d02c6ae58457fb30029f130f0c,"This paper proposes a self - supervised training method for visual transformers ( VTs ), which is an architectural paradigm alternative to convolutional networks ( CNNs ). The authors show that the performance of different VTs trained on ImageNet and ImageNet - based datasets can be significantly different from those trained on smaller datasets. They also propose an auxiliary self - supervision task which can extract additional information from images with only a negligible computational overhead. They show that this task is beneficial to speed - up training and improve the generalization ability of different VTs."
SP:0132ef17585e293b23e9dc45189c0989d829b52a,"This paper proposes a new method for label - free alignment of hierarchical data. The method is based on the Lorentz model of hyperbolic space. The proposed method consists of three components : translation, scaling, and rotation. The authors provide theoretical analysis and justification of the alignment method based on new derivations of Riemannian geometry operations in the Lorenz model. The efficacy of HPA, its theoretical properties, stability and computational efficiency are demonstrated in simulations."
SP:3580ac64f09e3021de5d4c92411bcc0f3c5d10f3,"This paper studies the trade - off between accuracy for a population of interest ( “ sum query ” ) vs. accuracy for its component sub - populations ( ‘ point queries ’ ). Compared to differentially private query answering systems that are not required to produce microdata, accuracy can degrade by a logarithmic factor. This uncertainty principle affects some, but not all, possible datasets. To this end, the authors propose a benchmark suite of real and synthetic datasets that can be used by the wider community for further study of this problem. They also propose some algorithms, inspired by their lower and upper bound proofs, for mitigating the effects of this uncertainty principle."
SP:c0e64dc8acfaed3e4d7745af12fd34003d0e5017,"This paper proposes a method to train a planner and an RL agent on a curriculum of tree - structured sub - tasks. The planner decomposes a long - horizon task to a tree of sub - tasks in a top - down manner, whose layers construct coarse - to - fine sub - task sequences as plans to complete the original task. The planning policy is trained to minimize the planning policy ’s cost of completing the sequence in each layer from top to bottom to bottom, which gradually increases the sub -tasks and thus an easy curriculum for the planner. Next, a bottom - up traversal of the tree trains the planner from easier sub-tasks with denser rewards on bottom layers to harder ones on top layers and collects its cost on each sub -task in the next episode. CO - PILOT repeats this mutual training for multiple episodes before switching to a new task, so the RL agent and planner are fully optimized to facilitate each other's training."
SP:9911693a04a300b5a93634fb0267ef83e5489d77,"This paper proposes a novel Bayesian framework for generating local explanations for black box explanations. The proposed framework is based on Bayesian versions of LIME and KernelSHAP, which output credible intervals for the feature importances, capturing the associated uncertainty. The resulting explanations not only enable us to make concrete inferences about the quality of the explanations, but are also highly consistent and stable. Experimental results on a variety of datasets including COMPAS, German CreditNet, and MNIST demonstrate that the explanations output by the proposed framework are not only highly reliable, but also very consistent, stable, and reliable."
SP:5efb4b81bd37c70640e8768e9dfb5bba14a0cfb8,"This paper proposes a method for improving the performance of Adder neural networks ( ANNs ) by pre - defining the feature distributions in order to model the heavy -tailedness in ANNs. The authors propose to use a mixture of Multivariate Skew Laplace Distributions ( MSE ) and Skew - Laplace distributions ( SLE ) for the distribution parameters for the classifier head. They also propose an angle - based constraint on the feature distribution parameters based on their locations, covariance and skewness, which drives the distribution tails to different angle regions for disentanglement. The proposed method improves classification accuracy by 0.7% on both CIFAR-20 and ImageNet with ResNet-18 compared to vanilla ANN with only a modification to the ANN classifier heads."
SP:cbccb65457564992d534504c0d060da44cafce8c,"This paper studies the phenomenon of gradient starvation in over - parameterized neural networks. Gradient starvation arises when cross - entropy loss is minimized by capturing only a subset of features relevant for the task, despite the presence of other predictive features that fail to be discovered. This work provides a theoretical explanation for the emergence of such feature imbalances in neural networks, and proposes a novel regularization method aimed at decoupling feature learning dynamics, improving accuracy and robustness in cases hindered by gradient starvation."
SP:8f6fe37cb0a332b66e10cc00261a44622841c8c6,"This paper studies human - AI teaming in the cooperative card game Hanabi with both rule - based and learning - based agents. The authors evaluate the performance of the human - human team in Hanabi using both the game score and subjective measures of human performance, teamwork, interpretability, trust, and overall preference of AI teammate. They find that humans have a clear preference toward a rule - - based AI teammate ( SmartBot ) over a state - of - the - art learning - - AI teammate, across nearly all subjective metrics, and generally view the learning - learning -based agent negatively, despite no statistical difference in game score. This result has implications for future AI design and reinforcement learning benchmarking."
SP:2a05e333fc1a14057515ef3addde9a40152373db,"This paper proposes a novel method for visual question generation ( VQG ), which aims to generate human - like neural questions from an image and potentially other side information ( e.g., answer type or the answer itself ). The proposed method consists of a visual hints predictor with a cross - modal reasoning module to determine the salient visual regions associated to the corresponding question, and a question generation module with predicted visual hints and textual answer hints. Experimental results on two benchmark datasets show that the proposed method outperforms the state - of - the - art approaches by a large margin on a variety of metrics, including both automatic machine metrics and human evaluation."
SP:15756d6ef47b39ded404acea2135c93bd5ee1062,"This paper proposes Generalized Data Weighting ( GDW ) to mitigate label noise and class imbalance by manipulating gradients at the class level. GDW unrolls the loss gradient to class - level gradients by the chain rule and reweights the flow of each gradient separately. In this way, GDW achieves remarkable performance improvement on both class imbalance and label noise. Extensive experiments in various settings verify the effectiveness of GDW."
SP:7a8f56a01bec51ebf70d9ff689005a62cccfe5c6,"This paper proposes a novel spatio - temporal language grounding task for embodied agents. The goal is to learn the meaning of behavioral descriptions of behavioral traces of an embodied agent by training a truth function that predicts if a description matches a given history of observations. The descriptions involve time - extended predicates in past and present tense as well as spatio-temporal references to objects in the scene. To study the role of architectural biases in this task, the authors train several models including multimodal Transformer architectures and the latter implement different attention computations between words and objects across space and time. They show that maintaining object identity in the attention computation is instrumental to achieving good performance on generalization overall, and that summarizing object traces in a single token has little influence on performance."
SP:3d4a9d439bc84c3b0e6600f6985a23bdf95cd67f,"This paper proposes a method for multiple object tracking and segmentation based on cross - attention network ( PCAN ). PCAN first distills a space - time memory into a set of prototypes and then employs cross - Attention to retrieve rich information from the past frames. To segment each object, PCAN adopts a prototypical appearance module to learn contrastive foreground and background prototypes, which are then propagated over time. Extensive experiments demonstrate that PCAN outperforms current video instance tracking approaches on both Youtube - VIS and BDD100K datasets."
SP:1175ad16382b349ab1a39895150172d266abe571,"This paper studies the theory of gradient flow in the context of deep neural network optimization. The authors show that gradient flow trajectories in deep neural networks with homogeneous activations have favorable curvature, suggesting they are well approximated by gradient descent. This finding allows them to translate an analysis of gradient descent over deep linear neural networks into a guarantee that gradient descent efficiently converges to global minimum almost surely under random initialization. They also show that over simple neural networks, gradient descent with conventional step size is indeed close to gradient flow."
SP:b8412e9ce82ce92125fe7cd3aff7bea8b906d16e,"This paper considers a stochastic multi - armed bandit ( MAB ) problem with delayed impact of actions. In the MAB setting, actions taken in the past impact the arm rewards in the subsequent future. The authors propose an algorithm that achieves a regret of regret ( KT 2/3 ) and show a matching regret lower bound of ⌚KT 2 / 3 ), where K is the number of arms and T is the learning horizon. Their results complement the bandit literature by adding techniques to deal with actions with long - term impacts and have implications in designing fair algorithms. The goal is to maximize the collected utilities over time while taking into account the dynamics created by the delayed impacts."
SP:9c1d678dff5f609197dc3cfb67b841827f4a439a,This paper proposes an end - to - end solution for video instance segmentation ( VIS ) based on transformers. The authors propose to utilize concise memory tokens as a means of conveying information as well as summarizing each frame scene. The features of each frame are enriched and correlated with other frames through exchange of information between the precisely encoded memory tokens. They validate their method on the latest benchmark sets and achieved state - of - the - art performance ( AP 42.6 on YouTube - VIS 2019 ).
SP:6c922eaa358f6fb9771690b1240e4f6f08a35b69,"This paper investigates the impact of the random walks ’ bias on graph embedding and proposes residual2vec, a general graph embeddings method that can debias various structural biases in graphs by using random graphs. The authors show that word2vec by itself has an implicit bias arising from the optimization algorithm -- skip - gram negative sampling ( SGNS ), which happens to negate the bias due to the friendship paradox. To leverage this debiasing feature further, the authors propose a more general framework, residual 2vec, that can also compensate for other systematic biases in random walks. They show that residual1vec performs better than conventional embedding methods in link prediction and community detection tasks."
SP:851eac96135b577a5014166edcb43db6a190cf4b,"This paper studies the problem of estimating non - linear functionals of discrete distributions in the context of local differential privacy. The initial data are supposed i.d. and distributed according to an unknown discrete distribution p = ( p1,..., pK ). Only α - Locally Differentially Private ( LDP ) samples z1,..., zn are publicly available, where the term ‘ local ’ means that each individual attribute xi is produced using one individual attribute. The privacy mechanisms ( PM ) that are sequentially interactive ( i.e. they are allowed to use already published confidential data ) or non -interactive ( non - interactive ) are introduced. The paper describes the behavior of the quadratic risk for estimating the power sum functional Fγ = ∑K k=1 pk, k, k < 0 as a function of K, n, and α. In the non - active case, two plug - in type estimators of Fγ, for all γ > 0, that are similar to the MLE analyzed by Jiao et al. in the multinomial model. However, due to the privacy constraint the rates we attain are slower and similar to those obtained in the Gaussian model."
SP:a0408b54f88a26479f33f36bb27e0a675f637ccd,"This paper studies the problem of online multiclass classification in a setting where the learner’s feedback is determined by an arbitrary directed graph. While including bandit feedback as a special case, feedback graphs allow a much richer set of applications, including filtering and label efficient classification. The authors introduce GAPPLETRON, the first online multiclasses algorithm that works with arbitrary feedback graphs. For this new algorithm, the authors prove surrogate regret bounds that hold, both in expectation and with high probability, for a large class of surrogate losses. The bounds are of order B, where B is the diameter of the prediction space, K is the number of classes, T is the time horizon, and ρ is the domination number."
SP:490262589efce6fb10b913431ec6db8d4e5b2dec,"This paper studies the problem of explainable clustering in the setting first formalized by Dasgupta, Frost, Moshkovitz, and Rashtchian ( ICL 2020 ). A k - clustering is said to be explainable if it is given by a decision tree where each internal node splits data points with a threshold cut in a single dimension ( feature ) and each of the k leaves corresponds to a cluster. The authors give an algorithm that outputs an explainable cluster that loses at most a factor of O(log k ) compared to an optimal ( not necessarily explainable ) clustering for the k - medians objective and a factor O(k log k ) for k - means objective. They also give a lower bound showing that an Ω( log k) loss is unavoidable. The algorithm is remarkably simple and the algorithm is oblivious to the data points and runs in time O(dk log k, independent of the number of data points )."
SP:6a9e47be710ddaf386bffc54d003d7dc2b67fdc3,"This paper proposes a multilingual pre - trained language model ( PrLM ) that supports both explicit universal dependency parsing and implicit language modeling. Syntax in terms of universal dependency parse serves as not only pre - training objective but also learned representation in the model, which brings unprecedented PrLM interpretability and convenience in downstream task use. The model outperforms two popular multilingual PrLM, multilingual -BERT and XLM - R baselines in all the above tasks."
SP:94f4b65214a648cbc84f13beba45a825e2e9901a,"This paper presents a novel Dual - Aspect Collaborative Transformer ( DACT ) to learn embeddings for the node and positional features separately, instead of fusing them together as done in existing ones, so as to avoid potential noises and incompatible correlations. The positional features are embedded through a novel cyclic positional encoding ( CPE ) method to allow Transformer to effectively capture the circularity and symmetry of VRP solutions. The relative PE method seems to help, however, it is found to be even worse than the absolute PE method for VRPs in Wu et al. [ 11 ], partly due to the disharmony issue caused by learning the unified representation."
SP:e5c8680d8da9e7548fcb9bb5c073848eb80e1dd0,"This paper proposes a method to compute the Bayes error of generative models learned using normalizing flows for Gaussian base distributions. The method is based on a fundamental result that the Bayesian error is invariant under invertible transformation. The authors show that this is the case for both Gaussian and Gaussian - Gaussian distributions. They then show that by varying the temperature of the learned flow models, they can generate synthetic datasets that closely resemble standard benchmark datasets, but with almost any desired Bayeserror error."
SP:2896679f0472522bc3334178cd7574494cf12b7b,"This paper proposes Grad Init, an automated method for initializing neural networks. The method is based on a simple heuristic ; the norm of each network layer is adjusted so that a single step of SGD or Adam with prescribed hyperparameters results in the smallest possible loss value. This adjustment is done by introducing a scalar multiplier variable in front of each parameter block, and then optimizing these variables using a simple numerical scheme. Grad Init accelerates the convergence and test performance of many convolutional architectures, both with or without skip connections and even without normalization layers. It also improves the stability of the original Transformer architecture for machine translation, enabling training it without learning rate warmup using either Adam or SGD under a wide range of learning rates and momentum coefficients."
SP:f69731403592fa5bdd4ca327708582d615aa131c,"This paper proposes a method for estimating the progression of a patient's disease progression using longitudinal data. The proposed method is based on linear mixed - effect models. The authors propose to embed the data in a Riemannian manifold and learn patient - specific trajectories distributed around a central geodesic. A few interpretable parameters characterize the subject trajectories at the cost of a prior choice of the metric, which determines the shape of the trajectories. They extend this approach by learning the metric from the data allowing more flexibility while keeping the interpretability. Specifically, they learn the metric as the push - forward of the Euclidean metric by a diffeomorphism, which is estimated iteratively as the composition of radial basis functions belonging to a reproducible kernel Hilbert space. The metric update allows us to improve the forecasting of imaging and clinical biomarkers in the Alzheimer's Disease Neuroimaging Initiative ( ADNI ) database. They validate the presented method on synthetic data in 3.1 and 3.2 by comparing it with previous models on the task of predicting patient ’s biomarker progression."
SP:438e906f52c4c0538956b51a2270b3ac498b27a8,"This paper proposes a routing - by - memory mechanism for existing CNN architectures. In each stage of the network, they introduce parallel Procedural Units ( PUs ). A PU consists of a memory head and a procedure. The memory head maintains a summary of a type of features. For an intermediate feature, they search its closest memory and forward it to the corresponding procedure in both training and testing. They apply their mechanism to VGGNet, ResNet, and EfficientNet and achieve significant improvements in the accuracies on Tiny ImageNet, Imagenet, and CIFAR-100 benchmarks."
SP:d240173080cd3647dbaa5173a6422396f226775b,"This paper presents a method for parameterizing polynomial functions that are equivariant to translation, rotation, reflection, boost (relativity ), and permutations in classical physics. The authors show that it is simple to parameterize universally approximating polynomials approximated under these symmetries, or under the Euclidean, Lorentz, and Poincaré groups, at any dimensionality d. The key observation is that nonlinear O(d)-equivariant functions can be universally expressed in terms of a lightweight collection of scalars and scalar products of scalar, vector, tensor, and tensor inputs. They show that the scalar - based method is simple, efficient, and scalable. They also note that the symmetryetries considered in this work are all global symmetrie, as they act on all points in the same way."
SP:72c0f47566904deb27d8157da30807ec1d6b5685,This paper proposes a new loss function for bounding box regression based on the Intersection over Union ( IoU ) loss and its variants. The loss function is based on a power IoU term and an additional power regularization term with a single power parameter. The paper introduces a new family of losses called the α - IoU losses and analyzes its properties such as order preservingness and loss / gradient reweighting. Experiments on multiple object detection benchmarks and models demonstrate that the new loss can outperform existing IoU - based losses by a noticeable performance margin.
SP:397125177d7007316d67194ec00d5dc57b44ac79,"This paper studies the distributionally robust imitation learning problem of learning a policy in a Markov Decision Process ( MDP ) setting where the reward function is not given, but demonstrations from experts are available. This paper studies Distributionally Robust Imitation Learning ( DROIL ) and establishes a close connection between DROIL and Maximum Entropy Inverse Reinforcement Learning ( MaxEntRL ). They show that DROIL can be seen as a framework that maximizes a generalized concept of entropy. They develop a novel approach to transform the objective function into a convex optimization problem over a polynomial number of variables for a class of loss functions that are additive over state and action. They extend the formulation to stationary policies, which enables them to experimentally show the benefits of learning robust policies in a highway driving simulation."
SP:58f220bbbed8d3e0633b408fca3b6838c4ad323d,"This paper proposes a post - processing algorithm for individual fairness ( IF ) in ML systems. The authors propose a graph smoothing method Laplacian regularization that preserves the desired “treat similar individuals similarly ” interpretation. They show that the new objective function leads to a local relaxation of the original individual fairness. Empirically, their post -processing algorithms correct individual biases in large - scale NLP models such as BERT, while preserving accuracy."
SP:ef791aa29decd839e7e583c9d1f71e8309ca87ef,"This paper proposes a unified model for cross - domain Text - to - SQL task. The authors propose a structure - aware Dual Graph Aggregation Network ( SADGA ) method to learn the mapping between the question - graph and the database schema. The proposed method is based on the graph structure to provide a unified encoding model for both the natural language question and database schema, and a question - schema linking method for learning mapping between words in the question and tables/columns in the database schemas. Experiments show that the proposed method outperforms baseline methods and achieves 3rd place on the challenging Text - To - SQL benchmark Spider 2."
SP:a2fa25a4539a38af61a0993f65ecc14339f26c2e,"This paper studies the training of stochastic computation graphs with multiple discrete components. The authors show that it is challenging to optimize the parameters of these models, mainly due to small gradients and local minima. They then propose two new strategies to overcome these challenges. First, increasing the scale parameter of the Gumbel noise perturbations during training improves the learning behavior. Second, they propose dropout residual connections for discrete - continuous computation graphs. They show that the proposed methods are required for training. They also show that they generalize better than their continuous counterparts on several benchmark datasets."
SP:bb3ec363e90269db4a2ba99d8107cb56f86e68f0,"This paper shows that Bayesian neural networks ( BNNs ) with high - fidelity approximate inference via full - batch Hamiltonian Monte Carlo achieve poor generalization under covariate shift, even underperforming classical estimation. The authors explain this surprising result, showing how a Bayesian model average can in fact be problematic under covariance shift, particularly in cases where linear dependencies in the input features cause a lack of posterior contraction. They additionally show why the same issue does not affect many approximate inference procedures, or classical maximum a - posteriori ( MAP ) training. Finally, they propose novel priors that improve the robustness of BNNS to many sources of covariate shifts."
SP:f86ec7042e9b73ae071704a6d3ed17d7e3da1b75,"This paper presents an analysis of meta - learning evaluation in two settings : in - distribution ( ID ) and out - of - distribution evaluation ( OOD ). In the ID setting, the authors identify that most existing few - shot classification benchmarks instead reflect OOD evaluation, as they use disjoint sets of train ( base ) and test ( novel ) classes for task generation. This discrepancy is problematic because meta -learning methods that perform better on existing OOD datasets may perform significantly worse in ID setting. In addition, in the OOD setting, even though current FSL benchmarks seem befitting, their study highlights concerns in 1 ) reliably performing model selection for a given meta - Learning method, and 2 ) consistently comparing the performance of different methods. To address these concerns, they provide suggestions on how to construct FSL benchmark to allow for ID evaluation as well as more reliable OLD evaluation."
SP:371f77148b4f00a929f7c118b1bb7c5a6238d264,"This paper proposes an open rule induction method for rule induction based on language model ( LM ) based rule generation. The authors argue that the current rule induction methods are “ learning rules from rules ”, which limits these methods to only produce “canned ” rules whose patterns are constrained by the annotated rules, while discarding the rich expressive power of LMs for free text. In this paper, the authors propose the Orion ( Open Rule Induction ) system to automatically induct open rules from LMs without supervision. They conducted extensive experiments to verify the quality and quantity of the inducted open rules. They found that the automatically inducted rules even outperformed the manually annotated rule inductions."
SP:8be2e0ea4a83fe32a4859f456007a829e5e9270a,This paper proposes a novel offline RL algorithm named Implicit Constraint Q - learning ( ICQ ) to reduce the extrapolation error in multi - agent RL algorithms. The proposed method is based on an implicit constraint on the state - action pairs given in the dataset for value estimation. The authors extend ICQ to multi - agents tasks by decomposing the joint - policy under the implicit constraint. Experimental results show that ICQ achieves state - of - the - art performance in the challenging multi -agent offline tasks ( StarCraft II ).
SP:1939b24b68970c33ca16ce238deed257f76d009e,"This paper proposes a method to generate non - uniform perturbations that takes into account the characteristics of the empirical data distribution, both on correlations between the features and the importance of the features themselves. The authors show that their method outperforms uniform norm - ball constraints in these types of applications. They also show that the method is more robust to real - world attacks."
SP:417b30930b245667d777e5d90ee80dd41546760e,"This paper extends the theory of Tikhonov regularization to generalized self - concordant loss functions ( GSC ). The main contribution of the paper is to provide an upper bound on the excess risk of the GSC function. The upper bound is based on an iterated version of the iterated regularization scheme. The authors show that the upper bound can be achieved for GSC functions by using the iterate regularization method, which is intrinsically related to the proximal point method in optimization, and overcomes the limitation of the classical Tikh onov regularisation scheme."
SP:1caeee4f00b52fe356ff4e5dd004d0203e838370,"This paper proposes a new linear transform named Deformable Butterfly ( DeBut ) that generalizes the conventional butterfly matrices and can be adapted to various input - output dimensions. The proposed DeBut is a drop - in replacement of standard fully connected and convolutional layers, and demonstrates its superiority in homogenizing a neural network and rendering it favorable properties such as light weight and low inference complexity, without compromising accuracy. The natural complexity - accuracy tradeoff arising from the myriad deformations of a DeBut layer also opens up new rooms for analytical and practical research."
SP:d345ce1d7afc367ee1a9fb68d50ff1b2219f02cb,"This paper proposes a new method called MetA Reusable Knowledge ( MARK ) to address the problem of catastrophic forgetting ( CF ) in artificial neural networks. The authors propose to use shared weights among tasks as a common knowledge base ( KB ) that is not only used to learn new tasks, but also enriched with new knowledge as the model learns new tasks. The proposed method is evaluated on the 20 - split - mini - imageNet dataset and achieves almost zero forgetfulness using 55% of the number of parameters."
SP:722c52467e384058f8fdffa254d0e8db47440a64,"This paper proposes a data - driven framework for scheduling heuristics in an exact MIP solver. Specifically, the authors propose a problem - specific schedule of heuristic parameters that is based on the performance of the primal heuristic in a specific MIP setting. The proposed method is evaluated on two classes of MIP settings. The authors show that the proposed method can reduce the average primal integral by up to 49% on two sets of challenging MIP instances."
SP:5a21f0a49731dcb1d68deb06a75138e8e9d514d5,"This paper proposes an algorithm for reinforcement learning ( RL ) in which the learner receives binary feedback only once at the end of an episode. This is an extreme test case for theory, but it is also more representative of real - world applications than the traditional requirement in RL practice that the learners receive feedback at every time step. To show that learning is possible in this more challenging setting, the authors provide a statistically and computationally efficient algorithm that achieves sublinear regret."
SP:e66bd9582058ba0f6091bb1042ce2ecfdaae1515,"This paper proposes a novel edge representation learning framework based on Dual Hypergraph Transformation ( DHT ), which transforms the edges of a graph into the nodes of a hypergraph. This dual hypergraph construction allows to apply message - passing techniques for node representations to edges. The authors validate their method with edge learning method with hypergraphs on diverse graph datasets for graph representation and generation performance, on which their method largely outperforms existing graph representation learning methods. Moreover, their method also largely outperform state - of - the - art graph pooling methods on graph classification tasks."
SP:e398873e29b05176e1d52dc6f86a59a4f405e6fd,"This paper studies the problem of learning representations of data in reinforcement learning ( RL ). In RL, representations are learned by discarding irrelevant and redundant information, while retaining the information necessary for control. The authors propose a new representation learning objective for RL based on the maximization of mutual information ( MI ) maximization. The paper provides a theoretical analysis of the sufficiency of a state representation for learning and representing the optimal policy, and study several popular MI based objectives through this lens. They find that two of these objectives can yield insufficient representations given mild and common assumptions on the structure of the MDP. The experimental results corroborate their theoretical results with empirical experiments on a simulated game environment with visual observations."
SP:50181f740910195d3a50dd7d7f8cbb1c476d730b,"This paper proposes Sparse Steerable Convolution ( SS - Conv ) to address the shortcoming of steerable convolution with sparse tensors, while strictly preserving the property of SE(3)-equivariant deep feature learning. The authors propose a general pipeline for precise estimation of object poses, wherein a key design is a Feature - Steering module that takes the full advantage of SE - Equivariance and is able to conduct an efficient pose refinement. They conduct thorough experiments on three tasks of 3D object semantic analysis, including instance -level 6D pose estimation, category - level 6D estimation and size estimation, and category-level 6 - D pose tracking. Their proposed pipeline based on SS - Conv outperforms existing methods on almost all the metrics evaluated by the three tasks. Ablation studies also show the superiority of our SS -Conv over alternative convolutions in terms of both accuracy and efficiency."
SP:d746bfb200577c980d92727bb0b1a3c23e7bfdc5,"This paper proposes a dynamic token sparsification framework to prune redundant tokens progressively and dynamically based on the input. Specifically, it devise a lightweight prediction module to estimate the importance score of each token given the current features. To optimize the prediction module in an end - to - end manner, it proposes an attention masking strategy to differentiably prune a token by blocking its interactions with other tokens. The experimental results demonstrate the competitive trade - off between speed and accuracy. By hierarchically pruning 66% of the input tokens, our method greatly reduces 31% of GFLOPs and improves the throughput by over 40%."
SP:d0b6cde42b1cba5e6e3c7c5131426fd84adbd3d7,"This paper studies the problem of inference guarantees for regression functions in data analysis problems where the distributional assumptions are not available. The authors consider the case where the features X are continuously distributed, where the confidence interval for E [Y | X ] must have non - vanishing width, even as sample size tends to infinity. They show that there are several distinct regimes in settings in between the finite setting and the continuous setting, where vanishing confidence intervals are achievable if and only if the effective support size of the distribution of X is smaller than the square of the sample size. In the other extreme, if X takes only a small number of possible values, then inference on E is trivial to achieve."
SP:123952325765c040c3078fc7dca2b6d370e55590,"This paper proposes Representation Neutralization Neutralization for Fairness ( RNF ) to reduce the discrimination of DNN models by only debiasing the classification head, even with biased representations as inputs. To this end, the authors propose a new mitigation technique, namely RNF, that achieves fairness by debiased only the task - specific classification head of the DNN model. The authors leverage samples with the same ground - truth label but different sensitive attributes, and use their neutralized representations to train the classification heads of the model. Experimental results on several benchmark datasets demonstrate the effectiveness of RNF framework on several benchmarks, and show that RNF can be complementary to existing methods that learn debIased encoders and can be further improved within its framework."
SP:210eb2c811f966bb1ac53932cacabbad9bb608fe,"This paper proposes a new convolutional neural network ( CNN ) architecture that is invariant to translations and rotations. The proposed architecture is based on Bessel - CNNs ( B - CNN ), which is an extension of the Bessel Neural Networks ( BNN ) architecture. The main contribution of the paper is to propose a new BNN architecture that can be used to train CNNs with respect to rotational invariance. The authors propose to use BNNs to learn CNNs that are invariant in the continuous set of possible rotation angles by design.  "
SP:ee51ecbd476d5b65903c942a62be89ff5d91698b,"This paper proposes a new method for kernel ridge regression based on partitioning with random projections and iterative optimization to reduce space and time complexity while maintaining the same statistical accuracy. In particular, constructing suitable partitions directly in the feature space rather than in the input space, thus promoting orthogonality between the local estimators, thus ensuring that key quantities such as local effective dimension and bias remain under control. The authors demonstrate the effectiveness of their method by numerical experiments on large - scale datasets and show the statistical tradeoff of their model."
SP:1f096d6fabd5b1fde43d06c552d46d87cd35cb4a,"This paper proposes a novel communication method for reinforcement learning agents that learns to communicate via discrete tokens derived from a learned, continuous space. The authors propose a novel architecture and implementation for learning such learning such communication such that agents can effectively respond to novel human communication and that humans can understand it. They show in a decision theoretic framework that their technique optimizes communication over a wide range of scenarios, whereas one - hot tokens are only optimal under restrictive assumptions. In self - play experiments, the authors validate that their trained agents learn to cluster tokens in semantically - meaningful ways, allowing them communicate in noisy environments where other techniques fail. They demonstrate both that agents using their method can effectively communicate and that human agents can interpret unlabeled emergent communication tokens."
SP:8630ccc627534f9033bced04e2137a897ffef701,"This paper presents CoAtNets, a family of hybrid models built from two key insights : ( 1 ) depthwise Convolution and self - attention can be naturally unified via simple relative attention, and ( 2 ) vertically stacking convolution layers and attention layers in a principled way is surprisingly effective in improving generalization, capacity and efficiency. Experiments show that CoAtNet achieves state - of - the - art performance under different resource constraints across various datasets."
SP:d3ecbeeffa5ab365743ba8653c6739f24742ee31,"This paper proposes a new second order oracle bound for the expected risk of a weighted majority vote. The bound is based on a novel parametric form of the ChebyshevCantelli inequality, which is amenable to efficient minimization. The authors also derive a new concentration of measure inequality called PAC - Bayes - Bennett inequality. The paper provides an empirical evaluation demonstrating that the new bounds can improve on the work of Masegosa et al. [ 2020 ]."
SP:5bac542a6532d43cf100e085398b4a4783719814,"This paper proposes a method for weakly - supervised audio - visual video parsing based on cross - video and cross - modality supervisory signals. The proposed method exploits both the common and diverse event semantics across videos to identify audio or visual events. In addition, our method explores event co -occurrence across audio, visual, and audio-visual streams. We leverage the explored cross -modality co - existence co - occurrence to localize segments of target events while excluding irrelevant ones. The discovered supervisory signal across different videos and modalities can greatly facilitate the training with only video - level annotations."
SP:8fd6a03c1794afa524328d45f4232eacf6f86693,"This paper proposes a new algorithm for federated learning ( FL ) based on knowledge distillation ( KD ) to learn compressed models with different quantization parameters and model dimensions/structures. The authors propose an algorithm for learning quantized models through a relaxed optimization problem, where quantization values are also optimized over. They also formulate a compressed personalization framework by introducing knowledge distillillation loss for local client objectives collaborating through a global model. They validate that QuPeD outperforms competing personalized FL methods, FedAvg, and local training of clients in various heterogeneous settings, and provide extensive numerical results."
SP:fca8b4f1e765cf1724a37f0ae9a7dac1cb79c8b1,"This paper proposes a novel framework for constrained clustering based on stochastic gradient variational inference ( DC - GMM ). The proposed model is based on the VAE framework, where the clustering distribution is conditioned on prior clustering preferences, expressed as pairwise constraints. The authors provide extensive experiments to demonstrate the effectiveness of the proposed model on a wide range of data sets and demonstrate the usefulness of the approach on two challenging real - world applications."
SP:84379c0c881b7390ecc22fb398edfaf66d1af1ff,"This paper proposes a near - input - sparsity time approximation algorithm for NTK, by sketching the polynomial expansions of arc - cosine kernels for the convolutional counterpart of NTK ( CNTK ), which can transform any image using a linear runtime in the number of pixels. The authors prove a spectral approximation guarantee for the NTK matrix, by combining random features ( based on leverage score sampling ) of the arc - cosmicine kernels with a sketching algorithm. They benchmark their methods on various large - scale regression and classification and classification tasks and show that a linear regressor trained on our NTK features matches the accuracy of exact NTK on CIFAR-10 dataset while achieving 150× speedup."
SP:fa2668083ff3bb592c29a4c6822ae96ff54d0dbe,"This paper proposes a multi - person 3D motion trajectory prediction method based on the multi - range Transformers model. The model consists of a local - range encoder for individual motion and a global - range decoder for social interactions. The proposed method is evaluated on CMU - Mocap [ 1 ] and Panoptic [ 24 ] datasets. The method outperforms state - of - the - art methods on long - term motion prediction, but also generates diverse social interactions by automatically dividing the persons into different interaction groups. The authors show that their method achieves a significant improvement over state-of-the - art approaches for long -term predictions."
SP:0a0e07af37c8fe8580639b1df62d27b6f63f8dee,"This paper proposes a new model predictive program synthesis ( MPPS ), which trains a generative model to predict the unobserved portions of the world, and then synthesizes a program based on samples from this model in a way that is robust to its uncertainty. In experiments, MPPS outperforms non - program - guided approaches on a set of challenging benchmarks including a 2D Minecraft - inspired environment where the agent must complete a complex sequence of subtasks to achieve its goal, and achieves a similar performance as using handcrafted programs to guide the agent."
SP:5bb42b178b0d27da271bfa60e633fdac718638c4,"This paper investigates the problem of causal imitation learning in sequential settings, where the imitator must make multiple decisions per episode. The authors provide a graphical criterion for determining whether imitability is feasible based on a causal graph encoding the domain’s causal structure. They propose an efficient algorithm to determine imitability and to find the policy for each action that leads to proper imitation. They prove that the proposed criterion is complete ( i.e. both necessary and sufficient ). Finally, they verify that their approach compares favorably with existing methods in contexts where a demonstrator has access to latent variables through simulations."
SP:85bd81f0c5b6ccbc421ebbaf6f5c72164bc70b7f,"This paper proposes an object - based transition model that decomposes a scene into objects, aligns them ( with respect to a slot - wise object memory ) to maintain a consistent order across time, and predicts how those objects evolve over successive frames. The model is trained end - to - end without supervision using transition losses at the level of the object - structured representation rather than pixels. The authors show that the combination of an objectlevel loss and correct object alignment over time enables the model to outperform a state - of - the - art baseline, and allows it to deal well with object occlusion and re -appearance in partially observable environments."
SP:f32eddbb5c33a8422c075579ff08aa9833338d44,"This paper studies the importance sampling weighted ERM algorithm for using adaptively collected data to minimize the average of a loss function over a hypothesis class and provide first - of - their - kind generalization guarantees and fast convergence rates for regression and policy learning. The authors provide regret guarantees that close an open gap in the existing literature whenever exploration decays to zero, as is the case for bandit -collected data. They then apply this result to obtain generic slow rates for ISWERM for both Donsker - like and non - Donskers - like entropy conditions, as well as fast rates when the variance bound applies ( Section 3 ) and for policy learning ( Section 5 ). They also provide variance bounds from convexity and margin assumptions."
SP:f549a0c231b71bae0acbed6e3afb41890ee89cd9," regression is a popular method to train a weighted regression model for machine learning tasks. The authors propose a novel and coherent scheme for kernel - reweighted regression by reparametrizing the sample weights using a doubly non - negative matrix. When the weighting matrix is confined in an uncertainty set using either the log - determinant divergence or the Bures - Wasserstein distance, the authors show that the adversarially re - weighted estimate can be solved efficiently using first - order methods. Numerical experiments show that their reweighting strategy delivers promising results on numerous datasets."
SP:fe12e13602925b9400fd596a987755beb10aa3d1,"This paper proposes a gradient estimator based on importance sampling and statistical couplings for training models with discrete latent variables. The authors extend the work of Dong et al. ( 2020 ) and Yin et al. ( 2019 ) to the categorical setting and propose a novel derivation of their estimator. The proposed estimator is based on the importance sampling method, which is simpler and more direct while providing a natural extension to categorical case. They also consider estimators based on reparameterizing the problem with a sequence of binary variables and Rao - Blackwellization. They show that their proposed categorical gradient estimators provide state - of - the - art performance, whereas even with additional additional Rao -Blackwellization, previous estimators ( Yin et al., 2019 ) underperform."
SP:e16fdf963ec2f9c0d79fa404e47e7862a5d6e922,"This paper proposes a new method for finding the best architecture in the Neuromorphic Architecture Search ( NAS ) search space. The paper proposes to use a proxy accuracy predictor to find the best architectures in the search space instead of fitting the whole architecture space using one strong predictor, and then progressively fitting a search path towards the high - performance sub - space through a set of weaker predictors. The proposed method, WeakNAS, is evaluated on NAS Bench-101, NAS Bench -201, and ImageNet MobileNet Search Space. Compared to state - of - the - art ( SOTA ) predictor - based NAS methods, the proposed WeakNAS outperforms all with notable margins."
SP:8f74abb04037ba2e59dcf8320dc555b149f68ed8,"This paper proposes a new method for learning latent codes that can be used in a global coordinate system. The proposed method is based on a fixed additive latent dynamics ( EDDICT ), which assumes fixed additive dynamics, which results in tractable learning and an interpretable latent space. The authors show that the proposed method can reach more states in the long term while still optimizing a local objective. They show that their method is able to achieve better state coverage and increased unsupervised performance on hard exploration games such as Montezuma."
SP:c731a78c3e7f98ccd0253b51a0d42bf8deeb71f9,"This paper proposes a novel reinforcement learning - based generative RL framework to generate molecules with pharmacochemically acceptable molecules with large docking scores. The proposed method is based on a fragment - based generation method and a novel error - based replay experience ( PER ). The authors show that the proposed method produces molecules of higher quality compared to existing methods while achieving state - of - the - art performance on two of three targets in terms of the docking scores of the generated molecules. They further show with ablation studies that their method, predictive error - PER (FREED ) significantly improves the model performance."
SP:b938bca513e7de1231212064caf8877a78d8b612,"This paper studies the problem of learning directed acyclic graphical models from observational data in general settings without specific distributional assumptions. The authors propose a local Markov boundary search procedure to recursively construct ancestral sets in the underlying graphical model. They show that for certain graph ensembles, a simple forward greedy search algorithm ( i.e. without a backward pruning phase ) suffices to learn the Markov boundaries of each node. This substantially improves the sample complexity, which is at most polynomial in the number of nodes. This is then applied to learning the entire graph under a novel identifiability condition that generalizes existing conditions from the literature."
SP:af08109d4c45dc9401efb0e63c22167e9da28adb,"This paper considers the setting where each user has a single sample and the privacy protection is enforced at the level of each user’s data. The authors show that, as long as each user receives sufficiently many samples, they can learn any privately learnable class via an (, )DP algorithm using only O(log(1/1/ )/ ) users. They show that this can be done even in the local model, where d is the probabilistic representation dimension. They also show a nearly - matching lower bound on the number of users required."
SP:da4f21d107a7f442c4d3e3ec13bdb44b041e07cf,This paper presents a theoretical analysis of gradient descent with implicit parameterization. The authors show that gradient descent can converge to global optima for linear parametrization with implicit representation. They also show that the implicit representation can converge faster to a global optimum than the explicit representation. The paper also provides some empirical results to support their theoretical results.    The paper is well written and well - motivated. The main contribution of the paper is to provide a theoretical account of the performance of the end - to - end model - based methods.
SP:992aa07d4f815d1c81f967374590eece933833b1,This paper proposes a new KG refinement framework called IterefinE that combines two techniques : PSL - KGI and Markov Logic Network ( MLN ). The authors show that the proposed method is able to reject noisy facts from KG and at the same time infer higher quality new facts. The proposed method also shows that the embeddings that we produce are able to accept noisy facts and infer new facts while still being able to improve the quality of predictions.
SP:676fc4a3041af22e8f20ccba7daa2a0b1f5d6af5,"This paper proposes a new evaluation framework for knowledge base completion ( KB ) methods. The authors propose a new data set FB14k - QAQ with an alternative evaluation data structure : instead of single facts, they use KB queries, i.e., facts where one entity is replaced with a variable, and construct corresponding sets of entities that are correct answers. They argue that consideration of binary predictions is essential to reflect the actual KBC quality, and propose a novel evaluation paradigm, designed to provide more transparent model selection criteria for a realistic scenario. They evaluate a number of state - of - the - art KB embeddings models on their new benchmark. The results in relative performance between ranking - based and classification - based evaluation that they observe in their experiments confirm their hypothesis that good performance on the ranking task does not necessarily translate to good performances on the actual completion task. Their results motivate future work on KB embedding models with better prediction separability."
SP:83fe0a496a79bcf97ccba1c6d34b7d11e7d5c330,"This paper proposes an alternative language model ( ARDM ) for task - oriented dialog tasks. The proposed method is based on a pre - trained language model. The model is trained with two different language models : one for each speaker, and the other for each other. The authors show that ARDM outperforms state - of - the - art methods on two popular task - orientated dialog datasets : CamRest676 and MultiWOZ. They also show that the model can generate human - like responses to persuade people to donate to a charity."
SP:b11c06b7c4ef1aa43c59f808a679425e302d158e,"This paper proposes a method to estimate the confidence that the classification predicted by a deep neural network is correct ( or in the Top 5 ) on the test set. The authors define the notion of implied loss and prove that if an uncertainty measure is an implied loss, then low uncertainty means high probability of correct classification. They demonstrate empirically that these values can be used to measure confidence that classification is correct. The method is simple to use on existing networks. The proposed confidence measures for Top k which can be evaluated by binning values on test set are quite accurate for methods which are already quite accurate."
SP:ab9666e15f2a0113d96cb4b47b1cbb30fa1f7982,"This paper studies the generalization of neural networks as a function of their architecture and hyperparameters. The main contribution of the paper is to show that in the wide network limit, random networks before training are Gaussian processes governed by a kernel known as the Neural Network Gaussian Process ( NNGGP ) kernel, and that at large depths the spectrum of the NNGP kernel simplifies considerably and becomes “ weakly data - dependent ”. The paper also shows that gradient descent training of wide neural networks is described by a neural kernel called the Neural Tangent Kernel ( NTK ) that is related to the NTGP kernel. In the large depth limit limit, the authors show that NTK simplifies in much the same way as that of the neural network kernel."
SP:d3470c35aae48bf92439a55fdb98ccf07100e567,"This paper presents Graph Convolutional Networks ( GRAPHQA ), a graph - based method to estimate the quality of protein models. The method is based on graph convolutional networks ( GNNs ), which are graph networks that are used to learn representations of protein structures. The authors show that the proposed method outperforms the state - of - the - art for both hand - engineered and representation - learning approaches, as well as carefully evaluating the individual contributions of GRAPH QA components."
SP:5188280131b58a35d3deda126a0754aea8fa6e58,"This paper studies the loss landscape of linear neural networks with different loss functions and different parameterizations. In particular, the authors consider the case where the functional space is either the set of all linear maps from input to output space or a determinantal variety, i.e., a set of linear maps with bounded rank. The authors show that for this type of network, smooth convex losses may lead to landscapes with many bad local minima for arbitrary smooth loss functions. They also show that the absence of “ bad local minimima ” is due to two distinct phenomena that apply in different settings : it is true for the case of arbitrary smooth losses in different architectures that can express express expressive linear maps ( filling architectures ) but it holds only for the quadratic loss ( non - filling architecture )."
SP:ee71597ceab23eb4db1d6608f15f80ad51f7ff6d,"This paper proposes a framework SEED ( Sampling, Encoding, and Embedding Distributions ) for inductive and unsupervised representation learning on graph structured objects. The proposed SEED framework samples a number of subgraphs whose reconstruction errors could be efficiently evaluated, encodes the subgraph samples into a collection of subGraph vectors, and employs the embedding of the subGraph vector distribution as the output vector representation for the input graph. The authors demonstrate the close connection between SEED and graph isomorphism, and show that the proposed framework is able to achieve up to 10% improvement compared with competitive baseline methods, when a reasonable number of small subgraph are sampled."
SP:d9406fdf0a180a5efc6f15ba8739524665f0f9d2,"This paper proposes a new counterfactual regret minimization algorithm called Lazy - CFR, which adopts a lazy update strategy to avoid traversing the whole game tree in each round. The regret of the proposed algorithm is almost the same as the regret of vanilla CFR and only needs to visit a small portion of the game tree. Empirical results consistently show that Lazy-CFR is fast in practice."
SP:023aa3dca1cf7992b22993a7088e8a74c92bb47e,"This paper proposes a method to learn transferable features by minimizing the feature distribution discrepancy between the source and target domains. In particular, the authors propose Distribution Matching Prototypical Network ( DMPN ) to model the deep features from each domain as Gaussian mixture distributions. The authors propose two new domain discrepancy losses with probabilistic interpretations. The first one minimizes the distances between the corresponding Gaussian component means of the source data and target data. The second one minimises the pseudo negative log likelihood of generating the target features from source feature distribution. Extensive experiments on Digits Image transfer tasks and synthetic - to - real image transfer task demonstrate their approach can provide superior results than state - of - the - art approaches."
SP:40be996e8bb86e887077b762b87c7c34a786ac98,"This paper proposes a method to partition the latent space into a class - specific supervised code and an unsupervised code that is shared among all classes for efficient use of labeled information. The proposed method, called InfoCNF, also employs gating networks to learn the error tolerances of its ordinary differential equation ( ODE ) solvers for better speed and performance. The authors show empirically that the proposed method improves the test accuracy over the baseline while yielding comparable likelihood scores and reducing the NFEs on CIFAR10 on time - series data."
SP:97764e3393216106ff2ac3f550845acf4636119f,"This paper considers the approximation of the value function for infinite - horizon discounted Markov Reward Processes ( MRP ) with nonlinear functions trained with the Temporal - Difference ( TD ) learning algorithm. The authors consider this problem under a certain scaling of the approximating function, leading to a regime called lazy training. In this regime the parameters of the model vary only slightly during the learning process, a feature that has recently been observed in the training of neural networks. Both in the under and over - parametrized frameworks, the authors prove exponential convergence to local, respectively global minimizers of the above algorithm in the lazy training regime. They then give examples of such convergence results in the case of models that diverge if trained with non - lazy TD learning."
SP:c518e4030f12b0f59ad1d7c0fc0ebd313c68ef95,"This paper proposes a reinforcement learning method for hypothesis verification in reinforcement learning. The main idea is to train an agent that can take actions to generate observations which can help predict whether the hypothesis is true or false. The authors show that agents trained end - to - end with the reward fail to learn to solve this problem, and propose to train the agent as a triplet - based agent. The triplets can be formulated as triplets ( pre - condition, action sequence, post - condition ), and the agents can be fine - tuned to verify more general hypotheses."
SP:6fa2f842b1bc993ed8024a3ce13dbd91529c61be,"This paper proposes to study the feasibility of reasoning in a fixed dimensional latent space. The authors propose to train a neural network to map mathematical formulas into a latent space of fixed dimension. The network is trained by predicting – based on the latent representation being trained – whether a given rewrite is going to succeed ( i.e. returns with a new formula ). For successful rewrites, the authors also predict a latent representation of the resulting formula. They evaluate the effectiveness of this reasoning by performing sequences of rewrite steps both in formula space and in latent space, and compare the quality of embeddings of the generated formulas to their predicted latent representations. The experiments show that graph neural networks can make non - trivial predictions about the rewrite - success of statements, even when they propagate several latent representations for several steps."
SP:a77ab500a5e7d4ea8430871d1e603941e92974fd,"This paper proposes a new method for learning depth estimation from images with sparse ground truth measurements. The method is based on a global - local network architecture, which is designed to learn monocular dense depth estimation when trained with a single pixel per image. The authors show that the proposed method outperforms existing methods in the sparse data regime. The proposed method is evaluated on a variety of datasets."
SP:2afba5e24478da4e9d493887c7cf00e288cc0deb,"This paper proposes to use word pieces in natural language models to machine learning tasks on opaque ids. This is achieved by applying hash functions to map each id to multiple hash tokens in a much smaller space, similarly to a Bloom filter. They show that by applying a multi - layer transformer to these Bloom filter digests, they are able to obtain models with high accuracy. They outperform models of a similar size without hashing and, to a large degree, models of much larger size trained using sampled softmax with the same computational budget. The key observation is that it is important to use a multi-layer Transformer for Bloom filter Digests to remove ambiguity in the hashed input. They believe this provides an alternative method to solving problems with large vocabulary size."
SP:745dd86d7f7bba79a02d27922003b764b620f83e,"This paper proposes a learning based agglomerative clustering framework that learns a grouping policy to progressively group small part proposals into bigger ones in a bottom - up fashion. The idea is to restrict the local context for extracting part - level features, which encourages the generalizability to unseen categories. On the largescale fine - grained 3D part dataset, PartNet, the authors demonstrate that their method can transfer knowledge of parts learned from 3 training categories to 21 unseen testing categories without seeing any annotated samples."
SP:868fc6df740b04963442d5abcfe2f4845585cfc8,"This paper proposes a neuron editing method to learn how to encode an edit for a particular transformation in a latent space in a neural network. The method is based on an autoencoder to decompose the variation within the dataset into activations of different neurons and generate transformed data by defining an editing transformation on those neurons. By performing the transformation in the latent space, it is possible to perform fairly complex and non - linear transformations to the data with much simpler distribution shifts to the neuron’s activations. The proposed method has the advantage of being generally applicable to a wide variety of data domains, modalities, and applications. The authors first demonstrate it on image transformations and then move to two main applications in biology : removal of batch artifacts representing unwanted noise and modeling the effect of drug treatments to predict synergy between drugs."
SP:6dee6932e64fe47bb44dd42fc242fa9d89b8d89c,"This paper proposes a meta - learning algorithm for image segmentation based on first - order initializations of neural networks. The authors propose a novel neural network architecture built for parameter efficiency and fast learning which they call EfficientLab, a formalization of the generalization error of Meta - Learning ( MAML ) algorithms. They also propose a small benchmark dataset, FP - k, for the empirical study of how meta -learning systems perform in both few - shot and many - shot settings. They show that meta - learned initializations for ImageNet initializations outperform random and ImageNet - trained initialization for up to 400 densely labeled examples.   They also show that a fixed update routine does hinder generalization performance."
SP:ec6f390f6d45fb79c33ae5d9c8a24cadb96fbd60,"This paper proposes a new method for semi - supervised few - shot learning ( SS - FSL ) based on Prototypical Networks ( PN ) to learn representations that are compact and well - separated from unlabelled data. The proposed method is based on a random walk semi - supervised loss. The authors show that the proposed method outperforms PN trained on 100% of the labels in the 1 - shot mini - imagenet case with 50.89% to 49.4% accuracy. They also show that their model is resistant to distractors, unlabeled data that does not belong to any of the training classes, and hence reflects robustness to labelled/unlabelled class distribution mismatch."
SP:d12e687bd2ee9fa60554312e644bb0a6487974f1,"This paper proposes a new self - supervised training objective, Contrastive Sensor Fusion, which exploits coterminous data from multiple sources to learn useful representations of every possible combination of those sources. This method uses information common across multiple sensors and bands by training a single model to produce a representation that remains similar when any subset of its input channels is used. Using a dataset of 47 million unlabeled image triplets, the authors train an encoder to produce semantically meaningful representations from any combination of channels from the input sensors. These representations outperform fully supervised ImageNet weights on a remote sensing classification task and improve as more sensors are fused. The experiments show that the unsupervised encoder learns to produce representations of many different combinations of sensors that separate images into semantically - meaningful classes and perform well on real problems in the semi - supervised setting."
SP:4d8e054f07006b4f896721b5c24da805727d2c22,"This paper presents a new method for fine - tuning neural network pruning algorithms that trains the unpruned weights from their final trained values using a small fixed learning rate. The method is based on weight rewinding ( as proposed by Frankle et al. ( 2019 ) ), which rewinds un pruned weights to their values from earlier in training and retrains them from there using the original training schedule using the same learning rate schedule as weight re - winding. The proposed method outperforms fine - tuning in terms of accuracy and compression ratios of several more network - specific state - of - the - art techniques."
SP:3bb1c79f9482e09828eda45fbb2e654f37219365,"This paper studies the relationship between output margin and generalization in deep neural nets. The authors propose to analyze the all - layer margin, which they call the margin of margin, and show that it has a clear and direct relationship with generalization for deep models. They propose to train a training algorithm that encourages a larger all -layer margin and demonstrate that it improves empirical performance over strong baselines. They also show that their training algorithm improves both clean and adversarially robust test performance over the baselines in practice."
SP:3d44f27468087280e85dfb1fc7291db05179fe6d,This paper proposes a knowledge - grounded dialogue generation model based on a disentangled response decoder. The authors propose to use ungrounded dialogues and unstructured documents as training examples to train the decoder model. The decoder is designed to learn the parameters that depend on knowledge - grounded dialogues from the entire generation model. Experiments show that the proposed model can achieve state - of - the - art performance with only 1 - 8 training examples.
SP:9b555f7fe743f5effdbdc8701ed519ce3159c4b0,"This paper proposes a new neural machine translation model ( NMT ) architecture that integrates the source to target translation model, the target to source translation model and two language models. The authors propose a single unified architecture that simultaneously integrates both translation models and language models and share the same latent semantic space, therefore both translation directions can learn from non - parallel data more effectively. They show that the proposed MGNMT consistently outperforms existing approaches in a variety of language pairs and scenarios, including resource - rich and low - resource situations."
SP:d7a530a0ec4112095a58cef4cda9646f8ca6449d,"This paper studies the performance of maximum entropy RL algorithms on the Mujoco benchmark. The authors show that the entropy term in Soft Actor Critic ( SAC ) principally addresses the bounded nature of the action spaces, and propose a simple non - uniform sampling method for selecting transitions from the replay buffer during training. They also propose a streamlined algorithm which does not employ entropy maximization but nevertheless matches the sampling efficiency and robustness performance of SAC for the MuJoco benchmarks. The paper also shows that the streamlined algorithm with the simple Non - Uniform sampling scheme outperforms SAC and achieves state - of - the - art performance on challenging continuous control tasks."
SP:545e8da553fcb47d84eaa044d8a4947d3cd3230e,This paper studies the vulnerability of industrial copyright detection systems to adversarial attacks. The authors propose an adversarial music identification method based on a neural net - based music identification system. They demonstrate the effectiveness of the proposed method on the AudioTag copyright detector and YouTube’s Content ID system.   The authors also propose a gradient - based method to attack the system using simple gradient methods.
SP:b511822850da3bf1079a36ed6f5ad4db80fbc424,This paper proposes to decompose the final activation map of a metric learning model by decomposing it into a point - to - point activation map between two images. The idea is to show the relationship between different regions of the activation map. The authors show that the proposed framework can be directly deployed to a large range of metric learning applications and provides valuable information for understanding the model. The experiments show its effectiveness on two potential applications i.e. cross - view pattern discovery and interactive retrieval.
SP:67bf71219fe6bedec5f5525200e734638e4a6ca2,"This paper proposes a new algorithm, AOP, that combines model - based planning and model - free learning to improve the performance of a policy planning algorithm in the online lifelong learning setting. The authors show that AOP is able to achieve better performance in this setting when compared to other planning algorithms. They also show that the proposed algorithm AOP can adapt to novel situations, adapting behaviors and policies effectively in the face of unpredictable changes in the world."
SP:11159cb878a436a5d4fc6edb4132f2cc3c1b3f72,"This paper proposes to replace the softmax attention mechanism by two alternative sparsity - promoting transformations : sparsemax and Total - Variation Sparse Attention ( TVMAX ). With sparsemax, sparse attention weights are obtained by selecting relevant features, while with TVMAX, the attention is generated by a transformation that selects relevant groups of features. The authors present results in the Microsoft COCO and Flickr30k datasets, obtaining gains in comparison to softmax. They also carry out a human evaluation experiment."
SP:fb0c3ce3db6ad674ddc615bdc6203cdcbe42c804,"This paper proposes a graph neural network model to predict the evolution of dynamic graphs. The proposed model is based on a neural network architecture and a recurrent architecture to capture the temporal evolution patterns of dynamic graph topology. The model predicts the topology of the graph at the next time step and constructs a graph instance that corresponds to that topology in the graph generation problem. The authors evaluate the proposed model on several artificial datasets following common network evolving dynamics, as well as on real - world datasets to demonstrate the effectiveness of proposed model."
SP:ff722957a1765c0568426ed88dd910a6b74054ef,"This paper proposes a method for imputing missing features and estimating the distribution of target assignments given incomplete data. The proposed method is based on a simple and effective generator network to generate imputations that a discriminator network is tasked to distinguish. Following this, a predictor network is trained using the imputed samples from the generator network, to capture the classification uncertainties and make predictions accordingly. Experimental results show the effectiveness of the proposed method in generating imputations as well as providing estimates for the class uncertainties in a classification task when faced with missing values."
SP:c051b0fe779d9e4131016970b7ba469b596f3009,"This paper proposes a new estimator for off - policy estimation for long - horizon problems. In particular, the authors propose a novel approach that eliminates such limitations as the stationary distribution of a known behavior policy. They formulate the problem as solving for the fixed point of a certain operator. The estimator computes importance ratios of stationary distributions, without knowledge of how the off policy data are collected. They analyze its asymptotic consistency and finite - sample generalization generalization on the effectiveness of the estimator."
SP:065c900843011a71b70ed35357a2f71fe83872a7,"This paper proposes a method to compute the responsibility distribution of a Gaussian Mixture Model ( GMM ) dataset, which is a probabilistic framework which allows us to define a dataset containing K different modes. In a traditional GMM paradigm, it is straightforward to compute in closed - form, the conditional likelihood p(x|k, θ ) as well as the responsibility probability p(k|x, \� ) which describes the distribution index corresponds to the data. To this paper, the authors propose a modified GMM framework to compute these probabilities at the data’s latent space z instead of x. The authors also propose an additional classification network which is trained with the GAN in an “ end - to - end ” fashion. These techniques allow the authors to discover interesting properties of an unsupervised dataset, including dataset segments and generating new “ outdistribution ” data by smooth linear interpolation across any combinations of the modes."
SP:2da1608209058d214f8671062cc9eb0833ba4831,"This paper proposes a method to train large capacity neural networks with significantly improved accuracy and lower dynamic computational cost. The authors introduce a new residual block architecture that gates convolutional channels in a fine - grained manner. They also introduce a generally applicable tool batch - shaping that matches the marginal aggregate posteriors of features in a neural network to a pre - specified prior distribution. They use this novel technique to force gates to be more conditional on the data. They present results on CIFAR-10 and ImageNet datasets for image classification, and Cityscapes for semantic segmentation."
SP:f90e9f0eb53f92601bdfa3f7bf86f71d037aad30,"This paper proposes a probabilistic importance inference approach for pruning deep neural networks ( DNNs ). Specifically, the authors test the significance of a connection in a DNN to the DNN’s outputs using a nonparemetric scoring test and keep only those significant ones. Experimental results show that the proposed approach achieves better lossless compression rates than existing techniques."
SP:64cbbb6a2f6847ef71cd5a23ba3e4cc5c815a56e,"This paper proposes a method to learn nested behavioral hierarchies of arbitrary depth, with actions of arbitrary length, by iteratively compressing action trajectories. The learned temporally extended actions provide new action primitives that can participate in deeper hierarchies as the agent learns. The authors demonstrate the relevance of this approach for tasks with non - trivial hierarchical structure and show that the approach can be used to accelerate learning in recursively more complex tasks through transfer learning."
SP:e1ccfb3a684aef8a0fb36194eb16af1667811e81,"This paper proposes a new generative model, the Hierarchical Bayes Autoencoder ( HBAE ), which is based on an energy - based model ( EBM ). The model is trained using variational inference, similar to a VAE, to recover latent codes conditioned on inputs. The decoder is trained with adversarial approximation where a conditional generator is trained to match the EBM distribution. The proposed model is also able to model sets by inferring a latent code for a set of examples, and sampling set members through the multimodal decoder."
SP:1130a391afa30d1e0fddadedd2a3aaa70a4cb751,"This paper proposes a new normalization method called cross - normalization based on a mixture of on - policy and off - policy transitions, which can be regarded as an extension of batch normalization that re - centers data for two different distributions. The authors show that the proposed method improves over the state of the art across a range of MuJoCo benchmark tasks. They also show that well - designed normalization improves optimization stability and removes the necessity of target networks."
SP:f9cafaa5131176290fa069e6d24046c079cd9eea,"This paper proposes a novel adversarial training strategy to learn discriminative features unbiased and invariant to the confounder(s ). The proposed method is based on adversarial loss function that incorporates synthetic data, medical images, and a gender classification ( Gender Shades Pilot Parliaments Benchmark ) dataset. The authors show that the learned features by their method not only result in superior prediction performance but also are uncorrelated with the bias or confounders variables."
SP:783049ff463edd1283c058c6106a3e1f9a033df4,"This paper proposes a lightweight Transformer - based model for character - level language modeling based on Transformer. The authors propose a lightweight model, called GroupTransformer, that factorizes the calculation paths by grouped embedding operators, and employs inter - group linear operators to prevent performance degradation from the group strategy. The proposed model is evaluated on two benchmark datasets, enwik8 and text8, and found that Group - Transformer outperformed all LSTM - based models with under 35M parameters."
SP:946c26d371297c88d0ac246257104099b4585edc,"This paper proposes a novel approach to training generative models with deep - latent hierarchies based on Optimal Transport, without the need for highly bespoke models and inference networks. The authors show that their method STACKEDWAE enables the generative model to fully leverage its deep -latent hierarchy, and that in - so - doing, it is more effective than the original Wasserstein Autoencoder with Maximum Mean Discrepancy."
SP:309b47441d227ffa33f96f9f16f2addc607e5bb0,"This paper proposes a new video generation model based on a three - dimensional self - attention mechanism. The proposed model is based on an autoregressive neural network architecture. The authors show that the proposed model outperforms state - of - the - art video generation models on multiple metrics on popular benchmark datasets, for which they produce continuations of high fidelity and realism. They also present results on Kinetics, a large scale action recognition dataset comprised of YouTube videos."
SP:ad8fcdbc47a50dd2bf58aba2bc6cfe199e84dd4d,"This paper proposes an adversarial generative model for the generalized zero - shot learning on multi - label text classification on the International Classification of Diseases ( ICD ) codes. The authors propose a latent feature generation framework for generalized zero shot ICD coding, where they aim to improve the prediction on codes that have no labeled data without compromising the performance on seen codes. Their framework generates semantically meaningful features for zero shot codes by exploiting ICD code hierarchical structure and a novel cycle architecture that reconstructs the relevant keywords. Extensive experiments demonstrate the effectiveness of their approach on the public MIMIC - III dataset, improving the F1 score from nearly 0 to 20.91% for the zero -shot codes and increase the AUC score by 3% ( absolute improvement ) from previous state of the art."
SP:3ce82ae297e5759ab957babe9927062e7a71b0ba,"This paper proposes a forward prediction objective for simultaneously learning embeddings of states and action sequences to improve sample efficiency in reinforcement learning ( RL ). The authors propose to combine state and action embedding to improve the sample efficiency and peak performance of model - free RL on control from low - dimensional states.   The authors demonstrate that their approach improves sample efficiency compared to state - of - the - art RL methods on control tasks, with larger gains on more complex environments. They demonstrate good performance on a simple family of goal - conditioned 2D control tasks within a few million environment steps without adjusting any TD3 hyperparameters."
SP:11ce1616e721340eea9e80dad7460c77355ac7d1,"This paper proposes an automated meta - learning framework that automatically extracts the cross - task relations and constructs the meta - knowledge graph. When a new task arrives, it can quickly find the most relevant structure and tailor the learned structure knowledge to the meta-learner. The proposed framework not only addresses the challenge of task heterogeneity by a learned meta-knowledge graph, but also increases the model model model and improves interpretability. The authors conduct extensive experiments on 2D toy regression and few - shot image classification and the results demonstrate the superiority of ARML over state - of - the - art meta learning algorithms."
SP:37c209cd1c628b5c2f2b282fbeaf4bbf437c7670,This paper proposes a new method for controlling the generation of text generation in large transformer - based language models ( LM ). The authors propose to combine a pretrained LM with one or more simple attribute classifiers that guide text generation without any further training of the LM. They show that the PPLM approach can be used to detoxify instances where generation of toxic content is likely by following the negative gradient of a model trained to detect toxicity ( Section 4.4.4 ). They also show how PPLMs can also be used for structurally constrained story writing.
SP:12d0980bfea2de880905a0b87b40856969bb1c58," is an unsupervised learning framework that can be easily generalized to other domains. The authors propose to learn data representations with a novel type of denoising autoencoder, where the noisy input data is generated by corrupting clean data in the gradient domain. This can be naturally generalized to span multiple scales with a Laplacian pyramid representation of the input data. In this way, the agent learns more robust representations that exploits the underlying data structures across multiple scales. Experiments on several visual benchmarks demonstrate that better representations can be learned with the proposed approach compared to its counterpart with single - scale corruption. Furthermore, the learned representations perform well when transferring to other vision tasks."
SP:12afc1b259e51a31cbeb72366d2b93fbee1aafaa,This paper proposes a method to verify the robustness of natural language networks ( NLNs ) to under - sensitivity in natural language inference. The method is based on the decomposable attention mechanism. The authors propose to use the efficient yet effective interval bound propagation ( IBP ) approach to verify robustness. The proposed method is evaluated on the SNLI and MNLI datasets and compared with standard training methods.  
SP:14257af9fe83522c6e5b5d6b0d68945b944e30fb,"This paper proposes a Markov Decision Process ( MDP ) for deep reinforcement learning ( TD ). The authors show that the Q - value for each transition in the simplified MDP is a lower bound of the Q-value for the same transitions in the original continuous Q - learning problem. By using these lower bounds in TD learning, their method is less prone to soft divergence and exhibits increased sample efficiency while being more robust to soft divergences."
SP:c92c97e47d8b218dfd009bbf61f5b3547b395f91,"This paper studies the effect of the embedding complexity on generalization to the target domain in unsupervised domain adaptation ( UDA ). In particular, the authors show that the complexity affects an upper bound on the target risk. The authors provide a theoretical framework for multilayer neural networks and propose a strategy that mitigates sensitivity to the complexity. The proposed strategy achieves performance on par with or better than the best layer - dependent complexity tradeoff tradeoff."
SP:f3f3c6fbae757836551b3f1ee54a7d1e040132b8,"This paper studies generalization error bounds for stochastic gradient Langevin dynamics ( SGLD ) and several other noisy gradient methods ( e.g., with momentum, mini - batch and acceleration, Entropy - SGD ). The authors develop a new framework, termed Bayes - stability, for proving algorithm - dependent generalisation error bounds. The new framework combines ideas from both PAC - Bayesian theory and the notion of algorithmic stability. They obtain new data -dependent generalization bounds for learning general non - convex objectives. They also study the setting where the total loss is the sum of a bounded loss and an additional ` 2 regularization term. Their results show that their bounds can distinguish randomly labelled data from normal data, which provides an explanation to the intriguing phenomena observed in Zhang et al. ( 2017 )."
SP:a82fcd1d3196ddf078cfe8f4bc6f445d9d2bdc11,"This paper proposes to investigate the role of the hippocampus in continual learning of spatial navigation strategies in the context of continual learning. The authors propose to analyse the population level activity of hippocampal CA1 neurons of rodents learning to perform allocentric and egocentric spatial tasks. The components uncovered using dPCA from the firing activity reveal that hippocampal neurons encode relevant task variables such as decisions, navigational strategies and reward location. They compare this hippocampal features with standard reinforcement learning algorithms, highlighting similarities and differences. They demonstrate that a standard deep reinforcement learning model achieves similar average performance when compared to animal learning, but fails to mimic animals during task switching. Overall, their results gives insights into how the hippocampus solves reinforced spatial continual learning and puts forward a framework to explicitly compare biological and machine learning during spatial continuallearning."
SP:51acf1f8108683dce543a1fb4a61fbd593f9b4cc,This paper proposes a tree search based policy optimization method for continuous environments. The proposed method is based on the MCTS tree search algorithm. The authors propose a new loss function based on trajectories ’ mean and standard deviations. The paper also proposes a new policy update and data collection approach to train the policy and generate trajectories. Experimental results show that the proposed method significantly improves the performance of the baseline policy optimization algorithm.
SP:1ce3bc4d31712886f7dcada5b5ae67c3c376819a,"This paper proposes a new method for finding winning tickets for neural networks trained on ImageNet. The authors show that winning tickets generated on the full ImageNet dataset are competitive with winning tickets on the ImageNet classification task. They also show that using large datasets is important to study lottery tickets, since deep networks trained with CIFAR-10 are natually sparse, making conclusions potentially misleading."
SP:dbcebe5b73486885d9f4478b258047c02f8481a2,This paper studies the problem of adversarial adversarial training of neural reading comprehension models. The authors propose a noisy adversarial attack which searches among semantic variations of comprehension questions for which a model still erroneously produces the same answer as the original question – and with an even higher probability – and show that SQuAD2.0 and NewsQA models are vulnerable to this attack and commit a substantial fraction of errors on adversarially generated questions. They show that robust models generalise better in a biased data setting with a train / evaluation distribution mismatch ; they are less prone to overly rely on predictive cues only present in the training set and outperform a conventional model in the biased setting.
SP:5da870060778de460c1abe91562d6f3e707efef4,"This paper proposes a model - based approach to safety that allows the agent to look into the future and be aware of the future consequences of its actions. It learns the transition dynamics of the environment and generate a directed graph called the imaginative module. This graph encapsulates all possible trajectories that can be followed by the agent, allowing agent to efficiently traverse through the imagined environment without ever taking any action in reality in reality. A baseline state, which can either represent a safe or an unsafe state ( based on whichever is easier to define ) is taken as a human input. The imaginative module is used to predict whether the current actions of the agent can cause it to end up in dangerous states in the future. The authors run experiments to confirm that their proposed method improves safety throughout learning and at convergence."
SP:c2796f28fb067138303df8d424d646f4ada31558,This paper proposes a novel method to learn finite differences inspired by physics equations. The method leverages data - driven end - to - end learning to discover underlying dynamical relations between the spatial and temporal differences in given sequential observations. The authors demonstrate the superiority of PA - DGN in the approximation of directional derivatives and the prediction of graph signals on the synthetic data and the real - world climate observations from land - based weather stations.
SP:db8ed4f4fc3967f5dd4d208d5d029730eb99e840,"This paper considers the problem of training structured neural networks with nonsmooth regularization ( e.g. `1 - norm ) and constraints. The authors propose a convergent proximal - type stochastic gradient descent ( ProxSGD ) algorithm. They show that under properly selected learning rates, with probability 1, every limit of the sequence generated by the proposed Prox SGD algorithm is a stationary point. Finally, they show by extensive numerical tests how ProxPGD can be used to train either sparse or binary neural networks."
SP:2ca1f4da9faee79768764cda5d09d949cc942acc,"This paper proposes an end - to - end differentiable compression framework for lossy image compression based on a non - deterministic compression codec. The proposed method is trained using a Probabilistic Ladder Network ( PLN ), which maps the input image to a distribution in continuous space from which a sample can be encoded with expected code length being the relative entropy to the encoding distribution, i.e. it is bitsback efficient. The rate - distortion curve of the method is competitive with the state - of - the - art on the Kodak dataset ( Eastman Kodak Company ) on low bitrates."
SP:788fd2b6956dd69bf7752d39ea21883947128c8a,"This paper proposes a new super - resolution ( SR ) model for compressed JPG images. The proposed SR model is based on two components : ( 1 ) an integrated SR model training pipeline with two - level data, i.e., CJPG LR and LR images, as well as a new integrated loss function, and ( 2 ) a cycle loss for SR generation. The experimental results demonstrate that the proposed model outperforms state - of - the - art SR models."
SP:18dd92f2f55020be4f5a089b3b251327e47886f4,"This paper proposes a convolutional neural network architecture that is able to estimate a full surface of pass probabilities from single - location labels derived from high frequency spatio - temporal data of professional soccer matches. The network is designed to perform remarkably well from low - level inputs by learning a feature hierarchy that produces predictions at different sampling levels that are merged together to preserve both coarse and fine detail. The approach presents an extreme case of weakly supervised learning where there is just a single pixel correspondence between ground - truth outcomes and the predicted probability map. By providing not just an accurate evaluation of observed events but also a visual interpretation of the results of other potential actions, the approach opens the door for spatiotemporal decision - making analysis."
SP:1ae31baf383fc520687b255d9cac14c3b040e253,"This paper proposes an inductive matrix completion method based on Graph - based Matrix Completion ( GC - MC ). The main idea is to train a graph neural network ( GNN ) based on low - dimensional latent embeddings of rows ( users ) and columns ( items ) into the product of low - dimension matrices ( users and items ). In this paper, the authors propose IGMC, a graph - based matrix completion model based on GNN. The authors show that IGMC can be trained without using side information ( such as user ’s age or movie’s genre, or high - quality content is not always available, and can be hard to extract ). IGMC achieves competitive performance with state - of - the - art transductive baselines on five benchmark datasets."
SP:c5cb1b50e17a69e88d5ae28848e265215162da1e,"This paper proposes a stochastic zeroth - order method with heavy ball momentum ( SMTP ), a momentum version of STP ( Bergou et al. ( 2019 ) ). The authors show new complexity results for non - convex, convex and strongly convex functions and show that SMTP significantly outperforms STP and all other methods that they considered in their numerical experiments.   The authors provide convergence analysis of this method for non-convex and convex convex objectives."
SP:a216cfc29937eb398ea98cb1aea3481c9aed8240,This paper proposes a novel network architecture named Action Semantics Network ( ASN ) that explicitly represents such action semantics between agents in multiagent systems ( MASs ). ASN characterizes different actions ’ influence on other agents using neural networks based on the action semantics. The proposed ASN can be easily combined with existing deep reinforcement learning ( DRL ) algorithms to boost their performance. Experimental results on StarCraft II micromanagement and Neural MMO show ASN significantly improves the performance of state - of - the - art DRL approaches compared with several network architectures.
SP:efaf3a440dc17e05177832083ffbc23760ed7c97,"This paper proposes to exploit the low - rank structure of the state - action value function, i.e., Q function, for both planning and deep reinforcement learning ( RL ). In particular, the authors propose a framework to exploit low rank structure in Q functions by leveraging Matrix Estimation ( ME ) techniques. This leads to a more efficient planning procedure for classical control, and additionally, a simple scheme that can be applied to value - based RL techniques to consistently achieve better performance on “ low -rank ” tasks. Extensive experiments on Atari games and Atari games confirm the efficacy of the proposed approach."
SP:430336893b247b7bd45687d78b0d0511a7369e87,"This paper proposes a new algorithm, Best - Action Imitation Learning ( BAIL ), which does not involve maximizing Q functions over the action space. Instead, BAIL first selects from the batch the actions it believes to be high - performing actions for their corresponding states, and then uses those state - action pairs to train a policy network using imitation learning. Although BAIL is simple, it achieves state - of - the - art performance on the Mujoco benchmark, and outperforms Batch Constrained deep Q - learning ( BCQ )."
SP:94078964876667e8a5d9ae7728d779d5b91a576e,This paper proposes a novel architecture for deep extreme multi - label learning for short text documents. The proposed DeepXML algorithm splits training of head and tail labels by learning word embeddings on head labels and transferring them through a novel residual connection to data impoverished tail labels. The authors propose to increase the amount of negative training data available by extending state - of - the - art negative sub - sampling techniques and re - ranking the set of predicted labels to eliminate the hardest negatives for the original classifier. They also propose an efficient training algorithm that allows the algorithm to be an order of magnitude more scalable than leading deep extreme classifiers.
SP:b1b1252d82fa1bea18309e0b0b894e0f28f48bc9,"This paper proposes a variational hashing - based collaborative filtering approach that learns binary vector representations ( hash codes ) of users and items, such that recommendations can be computed very efficiently using the Hamming distance, which is simply the sum of differing bits between two hash codes. To this end, the authors propose an end - to - end trainable variational method that uses the novel concept of self - masking : the user hash code acts as a mask on the items ( using the Boolean AND operation ) such that it learns to encode which bits are important to the user, rather than the user ’s preference towards the underlying item property that the bits represent. This allows a binary user - level importance - based representation to be computed without the need to store additional weights for each user. The authors evaluate their approach against state - of - the - art baselines on 4 datasets, and obtain significant gains of up to 12% in NDCG."
SP:80898d0f2b2c8dc3388fa9164e529eae36aa1b21,"This paper proposes a method to measure the mode collapse of GANs. The authors propose two methods to calibrate the GAN learned distribution without access to model parameters or the original training data. The first method is based on Gaussian mixture models and importance sampling. The second method uses latent space reshaping to adjust the generated distribution of any GAN with minimized re - training efforts. The method is shown to alleviate mode collapse without re - touching training data, nor even needing any access to the model parameters."
SP:e5b5dda2f024cfda10526e744aa035e0165af58a,"This paper proposes to train neural networks that are beyond the NTK regime yet still governed by the Taylor expansion of the network. The idea of randomizing the neural networks allows them to escape their NTK and couple with quadratic models. They show that the optimization landscape of randomized two - layer networks are nice and amenable to escaping - saddle algorithms. They prove concrete generalization and expressivity results on these randomized networks, which lead to sample complexity bounds that match NTK without distributional assumptions and are advantageous when mild isotropic assumptions are present."
SP:cef7ea513eb3e42be4edf40e4ee1701a969bcbea,"This paper proposes a Graph Filter Discriminant Score ( GFD Score ) for evaluating the effectiveness of graph convolutional filters for a given graph in terms of node classification. The authors propose a novel assessment tool, called Graph filter distriminant score ( GFD Score ), to evaluate whether there exists an optimal filter that performs the best on all graph data, which graph properties should be considered for finding the best graph filter, and how to design appropriate filters that adapt to a given Graph Neural Network ( GNN ). They find out that there is no single filter as a “ silver bullet ” that performs best on the best of all possible graphs, and graphs with different properties are in favor of different graph convolutionsal filters. Based on these findings, they develop Adaptive Filter Graph neural network ( AFGNN ), a simple but powerful model that can adaptively learn data - specific filters. Experiments on both synthetic and real - world benchmark datasets have demonstrated that the proposed model has the flexibility in learning an appropriate filter and consistently provides state - of - the - art performance."
SP:3c5ec9dbcf914c8901e4e35f3c2a7df4707422ab,"This paper proposes a new distributionally robust optimization ( DRO ) algorithm for overparameterized neural networks. The main idea is to learn models that minimize the worst - case training loss over a set of pre - defined groups. The authors propose a stochastic optimizer for group DRO models that is stable and scales to large models and datasets and empirically show that it behaves well in their non - convex models. The experiments show that the proposed algorithm achieves substantially higher worst - group accuracies, with increased regularization, with a stronger - than - typical `2 penalty or early stopping."
SP:eb1ee2e0f7d8466a04b58508ecb3da7b667eecdf,"This paper proposes a new method for explaining the behavior of black - box classifiers based on the distribution of relevance scores of features according to their contributions. The proposed method is based on a distribution controller, a neural network, and a classification loss. The classification loss is used to train the distribution controller and the classification loss to optimize the proposed predictor. The authors show that the proposed method outperforms other local explanation methods in terms of faithfulness and explainability."
SP:32ea7cbc47cbdb1f703f4e07c31ce90abe083424,"This paper proposes a deep neural network that can be trained to tackle image reconstruction and classification problems that involve detection of multiple object instances, without any supervision regarding their whereabouts. The network learns to extract the most significant K patches, and feeds these patches to a task - specific network – e.g. auto - encoder or classifier – to solve a domain specific problem. The challenge in training such a network is the non - differentiable top - K selection process, which is the training optimization problem. To address this issue, the paper proposes to train the network by treating the result of top - k selection as a slack variable, resulting in a simple, yet effective, multi - stage training. The method is able to learn to detect recurring structures in the training dataset by learning to reconstruct images and localize structures when only knowledge on the occurrence of the object is provided."
SP:da1c5f6351d531482e90b86c3cceb52850c520de,This paper proposes a neural program synthesis algorithm called AutoAssemblet to generate assembly code for 32 - bit x86 processors and RAM. The algorithm is based on self - learning reinforcement learning to reduce the breadth and depth of the Monte Carlo Tree Search. The authors also propose an effective multi - entropy policy sampling technique to alleviate online update correlations. The proposed method outperforms several baselines on basic programming tasks.
SP:0d4687fc36c02e27d1b95d532a3947589f92b1da,"This paper studies the impact of model architecture on the speed of training in gradient descent optimization in the context of neural network architecture design space. The authors use the ideas from prior work that shows gradient descent can be modeled as a first - order ODE and use ODE’s coefficient matrix H to characterize the convergence rate. They introduce a simple analysis technique that enumerates H in terms of all possible “paths ” in the network. They show that changes in model architecture parameters reflect as changes in the number of paths and the properties of each path, which jointly control the speed and speed of convergence."
SP:3e3bc8f617df742a395e7d315ec3810a42071294,"This paper studies the relationship between overparametrized neural networks ( NNs ) and kernel methods ( interpolating kernel methods ). The authors show that the initialization of wide ReLU - NNs trained with squared loss are essentially a sum of two parts : The first is the minimum complexity solution of an interpolating kernels method, while the second contributes to the test error only and depends heavily on the initialization. This decomposition has two consequences : ( a ) the second part becomes negligible in the regime of small initialization variance, which allows us to transfer generalization bounds from minimum complexity interpolating Kernel methods to NNs, and ( b ) in the opposite regime, the test test error of wide NNs increases significantly with the initialization variance."
SP:b15ea009a36a0a76728dfc103d668d6781a8a99a,This paper proposes a new method for 3D object detection based on pseudo - LiDAR based on stereo depth estimation. The authors propose a depthpropagation algorithm to improve the accuracy of the depth estimation of faraway objects. The proposed method is evaluated on the KITTI object detection benchmark and shows that the proposed method outperforms the previous state - of - the - art detection accuracy for faraway object detection by 40%.
SP:983d84502264633f3385d426c1d4601a0744ea9a,"This paper proposes a principled adversarial example detection method that can withstand norm - constrained white - box attacks. The authors train K base detectors where the i - th detector is trained to discriminate natural data of class i from adversarial examples perturbed from other classes. At inference time, they first get the predicted label ( say k ) of the input, and then use the k - third detector to identify whether the input is a natural sample (of class k ) or an adversarial sample ( of class k or other classes ). They further devise a generative approach to detecting / classifying adversarial cases by interpreting each base detector as an unnormalized density model of the classconditional data. They provide comprehensive evaluation of the above adversarial case detection / classification methods, and demonstrate their competitive performances and compelling properties."
SP:461e9308d050bc3dc7b35233452668bb31f5d491,"This paper proposes a novel intrinsic reward for RL that encourages agents to take actions that lead to significant changes in the learned state representation of the environment state. The proposed reward is based on the idea of reward - based exploration, where the agent is encouraged to visit a state more than once. The authors evaluate their method on multiple challenging procedurally - generated tasks in MiniGrid, as well as on tasks with high - dimensional observations used in prior work. Their experiments demonstrate that this approach is more sample efficient than existing exploration methods, particularly for procedurally generated MiniGrid environments. Furthermore, they analyze the learned behavior of the agent and the intrinsic reward received by the agent."
SP:c002c20b5e8696588e029c0f65e88860418826c4,"This paper presents a comprehensive study on the large - scale query - document retrieval problem for embedding - based retrieval models. The authors propose a two - tower retrieval model ( BFS ) and Wiki Link Prediction ( WLP ) based on the Transformer model. The retrieval phase first reduces the solution space, returns a subset of candidate documents, and re - ranks the documents. The scoring phase then re - rates the documents and the retrieval algorithm is evaluated on a set of pre - training tasks. The results show that the proposed retrieval model outperforms the widely - used BM - 25 and TF - IDF baselines in terms of accuracy and recall."
SP:4e161e08a624f87633dfb49dfd46bd1665e15189,"This paper proposes a new graph neural network architecture based on graph convolutional networks ( GNNs ), where the input and output graphs must have the same structure. The authors introduce the bipartite Graph Convolutional Network ( BGN ), which is a parameterized transformation between the input graph and the output graph. They show that the proposed architecture is able to build efficient architectures such as graph skip connections, and graph autoencoders. They demonstrate that the general BiGraphNet formalism ( i.e., the general GNN architecture ) provides flexibility to building efficient architectures and that it can be used to replace graph pooling and pooling in hierarchical architectures."
SP:9b9b6ee9014e5538442ba76d6059ed01f59ec8fb,"This paper proposes a feature - wise transformation layer for few - shot classification under domain shifts for metric - based methods. The idea is to augment the image features using affine transforms to simulate various feature distributions under different domains in the training stage. To capture variations of the feature distributions, the authors propose a learning - to - learn approach to search for the hyper -parameters of the transform layers. The authors conduct extensive experiments and ablation studies under the domain generalization setting using five datasets : mini -ImageNet, CUB, Cars, Places, and Plantae. They show that the proposed feature -wise transformation layers can effectively improve the generalization ability of metric based models to unseen domains. They also demonstrate further performance improvement with a learning to learn scheme for learning the feature - Wise transformation layers."
SP:df46627cb984a56bba36d510bfc52e00751e9107,"This paper proposes a continuous convolutional network architecture for fluid simulation. The authors propose to extend N - D convolutions to the continuous domain and propose a new convolution network architecture to process moving particles in space and time. They show that their network architecture can simulate different materials, generalizes to arbitrary collision geometries, and can be used for inverse problems. They demonstrate that their continuous convolutions outperform prior formulations in terms of accuracy and speeda learned – and hence differentiable – fluid simulator."
SP:3e17f333cf07183969c02bb66afdd3ccbf25bb19,"This paper proposes BatchEnsemble, an ensemble method for learning neural networks. The idea is to use a rank - one matrix for each member of the ensemble and a shared weight matrix for the weights of the rest of the members. The proposed method is evaluated on CIFAR-10/100 classification with ResNet32 ( He et al., 2016 ) and WMT14 EN-DE/EN-FR machine translation with Transformer ( Vaswani et al, 2017 ). The authors show that the proposed method achieves comparable performance to progressive neural networks while having a much lower computational and memory costs than typical ensembles."
SP:a123a425ef3eb6188833d5a42e851bc3fa59df65,"This paper proposes a neural network - based partial differential equations solver for forward and inverse problems. The solver is grid free, mesh free and shape free, and the solution is approximated by a neural networks. The network is trained to minimize deviations of the learned function from the strong PDE solution and satisfy the boundary conditions. The resulting solution in turn is an explicit smooth differentiable function with a known analytical form. Unlike other numerical methods such as finite differences and finite elements, the derivatives of the desired function can be analytically calculated to any order. This framework therefore, enables the solution of high order non - linear PDEs. The proposed algorithm is a unified formulation of both forward and inverse problems where the optimized loss function consists of few elements : L2 terms of L2 and L∞ norms that unlike previous methods promote a strong solution Robust boundary conditions constraints and additional regularizers are included as well."
SP:973d0ad0faadcf7298300f2758de9154205e7113,"This paper studies the problem of reasoning about large neural networks ( BNNs ) with logic - based reasoning tools like SAT solvers. The authors propose a modified training procedure that makes the resulting network easier for SAT - friendly reasoners, to reason about the network. The proposed training procedure is based on a modified BNN architecture and the training procedure to get a simpler network without sacrificing accuracy on the primary task. The experimental results demonstrate that their approach scales to larger deep neural networks compared to existing work for existential and probabilistic queries, leading to significant speed ups."
SP:ca985e758f195bd04fb9f24b290a83974d6d308b,"This paper studies the expressive power of graph neural networks falling within the message - passing framework ( GNNmp ). Two results are presented : First, GNNMP are shown to be Turing universal under sufficient conditions on their depth, width, node attributes, and layer expressiveness. Second, it is discovered that GNN MP can lose a significant portion of their power when their depth and width is restricted. The proposed impossibility statements stem from a new technique that enables the repurposing of seminal results from distributed computing and leads to lower bounds for an array of decision, optimization, and estimation problems involving graphs."
SP:a98ae70a91850bbe624c307ba61d3daeb2494b82,"This paper proposes a localised generative flow ( LGF ) method to learn target distributions with complicated topologies. Unlike normalising flows, LGFs do not permit exact computation of log likelihoods, but propose a simple variational scheme that performs well in practice. They show empirically that LGFs yield improved performance across a variety of density estimation tasks, and that all densities are with respect to the Lebesgue measure."
SP:3adc341dece170f428195e4dccadfb5f5daddf2d,"This paper proposes a novel method to improve the performance of vision - language navigation ( VLN ) models when tested on unseen environments. The authors propose three kinds of semantic features : ( 1 ) ground truth semantic views ( Ren et al., 2017 ), ( 2 ) semantic views and ( 3 ) learned semantic view features. They show that these semantic features significantly reduce the environment bias in multiple datasets and achieve strong results in testing unseen environments and achieve competitive unseen results to previous state - of - the - art models."
SP:298e0043e99f586d314fbd9d16fdc6ae885e1ebb,"This paper proposes to use human feedback to accelerate and optimize the training of a Deep Reinforcement Learning ( DRL ) algorithm. The human feedback is provided by placing electrodes on the human scalp and monitoring what are known as event - related electric potentials ( ErrP ). The implicit feedback is then used to augment the agent's learning in the RL tasks. The authors develop a system to obtain and accurately decode the implicit human feedback ( specifically error - related event potentials ). They demonstrate the generalizability of ErrP over various Atari - like environments (discrete grid - based navigation games, studied in this work ), enabling the estimation of implicit human Feedback in new and unseen environments."
SP:a8395f8b877e1eebaef9ff2e8b4e488d55a74ef4,"This paper proposes a novel method to compare the performance of diverse image classifiers. The goal is to minimise the amount of information required in individual test images to maintain correct classification. Given a classifier and a test image, the authors compute an approximate minimal - entropy positive image for which the classifier provides a correct classification, becoming incorrect upon any further reduction. The notion of entropy offers a unifying metric that allows to combine and compare the effects of various types of reductions ( e.g. crop, colour reduction, resolution reduction ) on classification performance, in turn generalising similar methods explored in previous works. The authors propose two complementary frameworks for computing the minimal -entropy positive images of both human and machine classifiers, in experiments over the ILSVRC test - set. They find that machine classifier are more sensitive to reduced resolution - wise entropy - wise reduced resolution. They also find that humans classify images of machine models with higher precision than machines classify those of humans. They conclude with open challenges regarding classification of images using DNNs."
SP:81cec8f907d8fa0653b5bc08af1f59bfefd49619,This paper studies the robustness of adversarial adversarial examples in neural networks. The authors propose a family of defense techniques that are based on the instability assumption. The defenses include deterministic lossy compression algorithms and randomized perturbations to the input that all lead to similar gains in robustness.   The authors present a comprehensive experimental analysis of when and why perturbation defenses work and potential mechanisms that could explain their effectiveness ( or ineffectiveness ).
SP:a136b98e0ed478144ce9dd26e2b6d611543124e8,"This paper proposes a neural 3D mapping network to learn 3D visual recognition. The network takes as input 2.5D ( color and depth ) video streams captured by a moving camera, and lift them to stable 3D feature maps of the scene, by disentangling the scene content from the motion of the camera. The model also projects its feature maps to novel viewpoints, to predict and match and match against target views, and to replace the standard color regression loss, and show that this leads to better performance on complex photorealistic data. The authors show that the proposed model learns visual representations useful for semi - supervised learning of 3D object detectors, and unsupervised learning for 3D moving object detectors."
SP:6fd61604a2eeb8a2cbbda6c40807cebef6d40f2f,"This paper studies the problem of unsupervised domain translation ( UDT ), which consists in finding meaningful correspondences between two domains, without access to explicit pairings between them. The authors define UDT in a rigorous, non - ambiguous manner, explore the implicit biases present in the approach and demonstrate the limits of the approaches. They show that these methods are biased towards low energy transformations, leading them to cast UDT into an Optimal Transport ( OT ) framework by making this implicit bias explicit. This not only allows them to provide theoretical guarantees for existing methods, but also to solve UDT problems where previous methods fail. Finally, making the link between the dynamic formulation of OT and CycleGAN, they propose a simple approach to solve the UDT, and illustrate its properties in two settings."
SP:8bb3ce11ad773685f6e41d90db3e7a5481e5ba47,"This paper proposes a new regularization method, RotationOut, for neural networks. Different from Dropout that handles each neuron / channel independently, R rotationOut regards its input layer as an entire vector and introduces regularization by randomly rotating the vector. The proposed method can also be used in convolutional layers and recurrent layers with small modifications. The authors further use a noise analysis method to interpret the difference between Rotation out and Dropout in co - adaptation reduction. Extensive experiments in vision and language tasks are conducted to show the effectiveness of the proposed method."
SP:37620ae8dc5683eb2843792e0aa4cbe6cba366f7,"This paper proposes a method to create adversarial adversarial perturbations ( UAPs ) in a data - free manner where the original training data is unavailable for crafting adversaries. The proposed dilate loss basically maximizes the Euclidean norm of the output before nonlinearity at any layer. By doing so, the perturbation constrains the ReLU activation function at every layer to act roughly linear for data points. Extensive experiments demonstrate that the proposed method not only has theoretical support, but achieves higher fooling rate than the existing data free work."
SP:2fd7d5507a8727db743dc89379a6f021d31ed39a,"This paper proposes a transferable neural architecture search ( NAS ) method based on meta - learning to learn a new neural architecture for a new task. The proposed method, T - NAS, learns a meta - architecture that is able to adapt to the new task quickly through a few gradient steps. Extensive experiments show that T -NAS achieves state - of - the - art performance in few - shot learning and comparable performance in supervised learning but with 50x less searching cost, which demonstrates the effectiveness of the method."
SP:1314a79ba12474adb33ff31b3cb22bed25b94fb7,"This paper proposes a stochastic neural network ( SNN ) architecture for discriminative learning by directly modeling activation uncertainty and encouraging high activation variability. Compared to existing SNNs, their SE - SNN is simpler to implement and faster to train, and produces state - of - the - art results on network compression by pruning, adversarial defense and learning with label noise."
SP:bd4935d4fcf33f60f22e0f2fd9f7dc8ddfab6d17,"This paper proposes a meta - learning algorithm for generating curious behavior in the context of reinforcement learning. The motivation is that curiosity is a mechanism found by evolution that encourages meaningful exploration early in an agent’s life in order to expose it to experiences that enable it to obtain high rewards over the course of its lifetime. However, current meta - RL methods based on transferring neural network weights have only generalized between very similar tasks. To broaden the generalization, the authors propose to meta - learn algorithms that use pieces of code similar to those designed by humans in ML papers. They demonstrate the effectiveness of the approach empirically, finding two novel novel curiosity algorithms that perform on par or better than human - designed published curiosity algorithms in domains as disparate as grid navigation with image inputs, acrobot, lunar lander, ant and hopper."
SP:6dff0f3a84809ae0ba9f58f36303597f1ba6dcc5,"This paper proposes a new method for generating code for Any - Code - to - Code Generation ( AnyC2C ). The proposed method leverages the strict syntax of programming languages to model a code snippet as a tree - based language modeling ( SLM ). It estimates the probability of the program ’s abstract syntax tree ( AST ) by decomposing it into a product of conditional probabilities over its nodes. The authors present a neural model that computes these conditional probabilities by considering all AST paths leading to a target node. Unlike previous structural techniques that have severely restricted the kinds of expressions that can be generated in this task, the proposed method can generate arbitrary expressions in any programming language."
SP:7fc60d6fd1cfcc135c34f9664d172d3fd1c0ae0a,"This paper presents a theoretical analysis of gradient descent methods for learning large - scale neural networks ( NNs ). The authors show that the objective functions in learning NNs are convex in the canonical model space. They show that gradients between the original NN model space and the canonical space are related by a pointwise linear transformation, which is represented by the so - called disparity matrix. They also show that gradient descent algorithms converge to a global minimum of zero loss provided that the disparity matrices maintain full rank. If this full - rank condition holds, the learning of NNs behaves in the same way as normal convex optimization."
SP:78a536138570fe9b5d88350e4b16d598a7db1fe0,"This paper proposes an interactive graph - based segmentation algorithm that enforce connectivity between pixels of the same label to be connected. The authors introduce an instanceaware heuristic of a discrete Potts model, and a class - aware Integer Linear Programming ( ILP ) formulation that ensures global optimum. Both algorithms can take RGB, or utilize the feature maps from any DCNN, whether trained on the target dataset or not, as input. They present competitive semantic ( and panoptic ) segmentation results on the PASCAL VOC 2012 and Cityscapes dataset given initial scribbles. They also demonstrate that their interactive approach can reach 90.6% mIoU on VOC validation set with an overhead of just 3 correction scribbles on new datasets."
SP:2eb90879ddbc39b6b5c05152784d6044d1940513,This paper proposes a novel adversarial defense based on the learned saliency model to detect adversarial images generated by adversarial perturbations. The authors propose a CNN that distinguishes between adversarial and natural images using salient pixels as its input and propose a novel defense : a CNN - based defense that uses the saliency map alone and can detect various adversarial attacks alone. The proposed defense generalizes well (detecting stronger attacks when trained on weaker attacks ) and is more robust than the salient - pixel based defense against white - box attacks. The defense is tested on adversarial examples generated by C&W and DeepFool4 attacks.
SP:fe5510d05ff091a5f133f2dbcd1b23d8d58d2c3e,"This paper considers the problem of estimating the robustness of a machine learning model to adversarial attacks. The authors propose a method for computing the probability that its prediction at any point sampled from the ( unknown ) input distribution is susceptible to an adversarial attack.   The method is based on the concentration inequalities, which can be used to compute global robustness with estimation error upper - bounded by, for any > 0 selected a priori. The paper then provides a statistically sound analysis of robustness / accuracy trade - off for a variety of neural networks architectures and training methods on MNIST, Fashion - MNIST and CIFAR. They empirically observe that robustness and accuracy tend to be negatively correlated for networks trained via stochastic gradient descent and with iterative pruning techniques, while a positive trend is observed in the literature."
SP:8f5616a1480b68c04b496ed498d237d5a7e87794,"This paper proposes a robust reinforcement learning algorithm based on Wasserstein distance to measure the disturbance to the transition kernel. The authors propose a robust advantage actor - critic algorithm ( WRAAC ) based on the moderated robust Bellman equation. They show the existence of optimal robust policies, provide a sensitivity analysis for the perturbations, and then design a novel robust learning algorithm. The effectiveness of proposed algorithm is verified in the Cart - Pole environment."
SP:d85963f5f0f6b20cf08f2a7c169ae33a45db7de2,"This paper proposes a method to approximate mixed strategy Nash equilibria in multi - player continuous games, which always exist and include the pure ones as a special case. The paper proposes to use the pushforward measure technique to represent a mixed strategy in continuous spaces, which allows them to generalize the Gradient - based Nikaido - Isoda ( GNI ) function to measure the distance between the players ’ joint strategy profile and a Nash equilibrium. In numerical experiments, the paper shows effective convergence property in all the randomly generated quadratic games, general blotto games, GAMUT games and Delta - GAN (in appendix )."
SP:280d85cd8164a268f9d496ae5f17189c50f30dc1,"This paper proposes a novel Neural Execution Tree ( NExT ) framework to augment training data for text classification using natural language explanations ( NL explanations ) for augmenting model learning with NL explanations. The authors argue that NL explanations are unstructured and inherently compositional, which asks for a modularized model to represent their semantics, and NL explanations often have large numbers of linguistic variants, resulting in low recall and limited generalization ability. To address these issues, the authors propose a novel neural execution tree framework to utilize NL explanations, which is able to model the compositionality of NL explanations and improve the generalizability ability. Experiments on two NLP tasks (relation extraction and sentiment analysis ) demonstrate its superiority over baseline methods. Experimental results demonstrate the superiority over various baselines. The paper also proposes an extension to multi - hop question answering task, where it achieves performance improvement with only 21 explanations and 5 rules."
SP:a9b5f7257dedd719cfe341fca275776734af1d98,"This paper proposes a method for verifying the robustness of machine learning models to adversarial perturbations of the input features. The authors extend the verified training method to recurrent neural network architectures and complex specifications that go beyond simple adversarial robustness, particularly specifications that capture temporal properties like requiring that a robot periodically visits a charging station or that a language model always produces sentences of bounded length. Experiments show that while models trained using standard training often violate desired specifications, this method produces models that both perform well ( in terms of test error or reward ) and can be shown to be provably consistent with specifications."
SP:3903680e07b676409e3cf6a1044b67291fe38630,"This paper proposes a regularization method for visual domain randomization in reinforcement learning. The authors propose to regularize the learned state representations of an agent trained on one variation of the environment, and its learned representations are regularized during training to minimize the variance in the learned policies. The proposed method is evaluated on a toy grid - world problem, and compared to standard randomization and other regularization techniques in complex visual environments. Results show that the proposed method leads to more efficient and robust learning, while achieving equal generalization scores."
SP:c79046dc56b9ee9c926f87386046422ea134ae8d,"This paper proposes a new method for deep metric learning ( DML ) based on a simple pairwise binary classification problem that classifies a pair of examples as similar or dissimilar. It identifies the most critical issue in this problem — imbalanced data pairs — and proposes a simple and effective framework to sample pairs in a batch of data for updating the model. The key to this framework is to define a robust loss for all pairs over a mini -batch of data, which is formulated by distributionally robust optimization. The flexibility in constructing the uncertainty decision set of the dual variable allows us to recover state - of - the - art complicated losses and induce novel novel variants."
SP:38420928e40ef80c0136ad607b9275f9ab1e0769,"This paper proposes a stochastic trust region ( STR ) algorithm for finding a local minimum in non - convex finite - sum minimization. The authors first prove that the trust region method with inexact gradient and Hessian estimation can achieve a convergence rate of order O(1/k ) as long as those differential estimations are sufficiently accurate. Combining such result with a novel Hessian estimator, the authors propose a sample - efficient STR algorithm which finds an approximate local minimum within stochastically Hessian Hessian oracle queries. This improves the state - of - the - art result by a factor of O(n ). Finally, they also develop Hessian - free STR algorithms which achieve the lowest runtime complexity."
SP:28a35b70b5e6915af28cacebc4ea50690c9534af,"This paper proposes a method for training deep neural networks without batch normalization or weight initialization. The method is based on linear programming. The authors introduce Farkas layers, a method that ensures at least one neuron is active at a given layer of the network. They show that the method improves training capacity in the absence of batch regularization or methods of initialization across a broad range of network sizes on benchmark datasets."
SP:1d325b148e3efe407241c1f1cbe8d17400499741,"This paper proposes to compute robustness certificates for deep classifiers with differentiable activation functions in two steps. First, they show that if the eigenvalues of the Hessian of the network are bounded, they can compute a robustness certificate in the l2 norm efficiently using convex optimization. Second, they derive a computationally efficient differentiable upper bound on the curvature of a deep network. They also use curvature bound as a regularization term during the training of the classifier to boost its certified certified robustness against adversarial examples. They show that their method outperforms CROWN’s certificate ( Zhang et al. 2018b ) significantly while taking less time to compute."
SP:33f6f5aa0d4655e5d75fe612e0eff05e579d45c5,"This paper proposes a method for compressed sensing recovery using untrained deep generative models. The method is based on the recently proposed Deep Image Prior ( DIP ), wherein the convolutional weights of the network are optimized to match the observed measurements. The authors show that this approach can be applied to solve any differentiable linear inverse problem, outperforming previous unlearned methods. Unlike various learned approaches based on generative model, the method does not require pre - training over large datasets, and introduces a novel learned regularization technique, which incorporates prior information on the network weights."
SP:23c0f621e6041003b59bf0532130760694cf6a4a,"This paper proposes TAIC, a temporal abstraction method for reinforcement learning ( RL ). TAIC learns the temporal abstraction from past experience or expert demonstrations without task - specific knowledge. The authors formulate the problem as learning latent representations of action sequences and present a novel approach of regularizing the latent space by adding information - theoretic constraints. They show that TAIC can learn an effective abstraction of the long action sequences. The learned abstraction allows us to learn new tasks on higher level more efficiently."
SP:4e54c9196ba1eb2b6a0b0eee41e4a6f3a9de72dd,"This paper proposes a novel layer - wise sampling strategy for GCN - based graph representation learning based on the factors of the bi - directional diffusion between layers. The authors propose a self - attention mechanism to learn suitable weights for the sampled nodes, which allows the model to be able to incorporate both the first - order and higher - order proximities during a single layer propagation process without extra recursive propagation or skip connection. Extensive experiments on three large benchmark graphs demonstrate the effectiveness and efficiency of the proposed model."
SP:bb0af9c011ef982c34fcadb545f6b5771818e7fa,"This paper proposes a new state - space model for video - based video prediction based on an image - based model and a dynamics model. The model is based on a combination of an image model and dynamics model for inference and training. The authors show that the model is able to predict videos with convincing physical behavior over thousands of timesteps, outperforms previous unsupervised models, and even approaches the performance of supervised baselines."
SP:e67b463bc0aec2345925d609fa521ea49df57fd9,"This paper proposes an autoencoding model based on the best properties of variational autoencoders ( VAE ) and generative adversarial networks ( GAN ). It is known that GAN can produce very realistic samples while VAE does not suffer from mode collapsing problem. To tackle this problem, the authors propose a novel approach to train the VAE model with an implicit likelihood by an adversarially trained discriminator. It consists of two parts : one part is the standard adversarial training, and the second one is the very objective of the VaE model. The model optimizes the divergence between the model distribution and the true data distribution. The authors show that it takes the best property of VAE and GAN objectives. In an extensive set of experiments on CIFAR-10 and TinyImagenet datasets, the model achieves the state - of - the - art trade - off between generation and reconstruction quality."
SP:87056d0147ddcaf5d78f6888b05161fbdbb3346c,"This paper studies adversarial attacks on CNN classifiers that can make an imperceptible change to an input image and alter the classification result. The authors show that similar attacks can be used against the Bayes - Optimal classifier for certain class distributions, while for others the optimal classifier is robust to such attacks. They present analytical results showing conditions on the data distribution under which all points can be made arbitrarily close to the optimal decision boundary and show that this can happen even when the classes are easy to separate, when the ideal classifier has a smooth decision surface and when the data lies in low dimensions. They introduce new datasets of realistic images of faces and digits where the Bayesian classifier can be calculated efficiently efficiently. They show that for some of these datasets optimal classifiers is robust and for others it is vulnerable to adversarial examples. In addition, they show that standard CNN training consistently finds a vulnerable classifier even when optimal classifer is robust while large - margin methods often find a robust classifier with the exact same training data."
SP:a7b3a35e6a79084bdfd1e4a963dfa081279cd8bb,"This paper proposes a method to remove the majority of weights in a neural network with surprisingly little degradation to top1 test set accuracy by pruning identified exemplars ( PIEs ). The authors propose to remove PIE images from the test - set to improve top - 1 accuracy for both sparse and non - sparse models. They show that the pruned examples tend to be mislabelled, of lower image quality, entail abstract representations, atypical examples or require fine - grained classification. They also show that certain examples, and classes are systematically more impacted by the introduction of sparsity."
SP:4b17edaa7ec6201891433320d85f9a415656b763,This paper proposes a novel knowledge graph - based action generation method for reinforcement learning in interactive fiction games ( IF games ). The proposed method builds a dynamic knowledge graph while exploring and generates actions using a template based action space. The authors claim that the dual uses of the knowledge graph to reason about game state and to constrain natural language generation are the keys to scalable exploration of combinatorially large natural language actions. They then conduct an empirical study evaluating their agent across a diverse set of IF games followed by an ablation analysis studying the effectiveness of various components of the algorithm as well as its overall generalizability.
SP:b1784ecbb8f36eef9cae33d61ce60d80c2f9c38d,"This paper proposes a method to improve the training of maximum likelihood estimation ( MLE ) by adding an extra Gaussian prior objective to augment the current MLE training with an extra Kullback–Leibler divergence loss term. The extra loss is computed by comparing two probability distributions, the first of which is from the detailed model training prediction and the second is from a ground - truth token - wise distribution. The proposed data - dependent Gaussian prior objective ( D2GPo ) is then injected into the final loss through a KL divergence term. Experimental results show that the proposed method makes effective use of a more detailed prior in the data and has improved performance in typical language generation tasks, including supervised and unsupervised machine translation."
SP:7c29cb5a32b14e1392408dc5daba4cd35848bea9,"This paper proposes to replace the widely used cross - entropy loss with focal loss to calibrate the accuracy of deep neural networks ( DNNs ). The authors show that the proposed method is able to learn models that are already very well calibrated, while preserving the confidence of the model's correct predictions, which is extremely desirable for downstream tasks. They provide a thorough analysis of the factors causing miscalibration, and use the insights they glean from this to theoretically justify the theoretically justified performance of focal loss. They perform extensive experiments on a variety of computer vision and NLP datasets, and with a wide variety of different network architectures, and show that their approach achieves state - of - the - art accuracy and calibration in almost all cases."
SP:cd6b8417ec8bcb773c78cff677bb0a76d6b3f6f3,"This paper proposes LiPoptopt, a polynomial optimization framework for computing increasingly tighter upper bounds on the Lipschitz constant of neural networks. The underlying optimization problems boil down to either linear ( LP ) or semidefinite ( SDP ) programming. The paper proposes to use the sparse connectivity of a network to significantly reduce the complexity of computation. This is specially useful for convolutional as well as pruned neural networks, and the authors conduct experiments on networks with random weights and networks trained on MNIST. They show that in the particular case of the `∞-Lipschitzer constant, their approach yields superior estimates, compared to baselines available in the literature."
SP:31c9dc0dd8806daddc9cb48c56ec819577fe46cd,"This paper proposes a self - supervised learning approach for video features that results in significantly improved performance on downstream tasks ( such as video classification, captioning and segmentation ) compared to existing methods. The method extends the BERT model for text sequences to the case of sequences of real - valued feature vectors, by replacing the softmax loss with noise contrastive estimation ( NCE ). The paper also shows how to learn representations from sequences of visual features and sequences of words derived from ASR ( automatic speech recognition )."
SP:0f24424d10f1201dd25e8c56354e10afc9b2b11c,"This paper proposes a framework that automatically learns to select the relevant parts of the input data needed for the subsequent application of a given neural network and its task. Both the associated selection masks as well as the neural network are trained simultaneously such that a good model performance is achieved while, at the same time, only a minimal amount of data is selected. During the inference phase, only the parts selected by the masks have to be transferred between the server and the client. The authors show that it is often possible to significantly reduce the amount of information needed during inference phase without affecting the model performance much."
SP:aa4fcf5b2cae05c5c6a903c24e4992b56655dee2,This paper proposes a novel loss function for out - of - distribution ( OOD ) detection based on the Outlier Exposure ( OE ) technique. The authors propose a loss function that achieves state - of the - art results in OOD detection with OE both on image and text classification tasks. The combination of the two methods outperforms the original Mahalanobis distance - based classifier method in all of the experiments and to the best of our knowledge.
SP:89bc528ef801182365ac279e8963803afccb391d,"This paper proposes an end - to - end deep learning model, called E2Efold, for RNA secondary structure prediction which can effectively take into account the inherent constraints in the problem. The key idea is to directly predict the RNA base - pairing matrix, and use an unrolled algorithm for constrained programming as the template for deep architectures to enforce constraints. The experiments on benchmark datasets show superior performance compared to previous SOTA ( especially for pseudoknotted structures )."
SP:b68560cce8c64ebe0ca5e6534b3732c775d36452,"This paper proposes to train a collective policy based on an agent's simulation of a real - world environment. The idea is to train an agent to play a series of simulated episodes of the environment, where each agent is given a set of actions to take. The agents are trained to take turns to play the episodes and interact with their own biased representations. The policy is trained on top of the agents ’ simulations and is then applied to the real world. The authors show that the collective policy is able to outperform the best individually trained policies in the experiment.   "
SP:bd1dc08b4fd9a5cc78d26d7eb7f05dbb4a629ab1,This paper proposes a dialog generation model for open - domain dialog generation that learns a semantic latent space of semantically related sentences. The latent space is learned by maximizing correlation between the features extracted from prompt and responses and learning the pair relationship between the prompts and responses as a regression task on the latent space. An additional autoencoder is trained for recovering the full sentence from the latent spaces. Experimental results show that the proposed model eliminates the generic response problem while achieving comparable or better coherence compared to baselines on two dialog datasets.
SP:ef0d5fd333ed60feb3946d24002e9a90642aea66,This paper proposes a new black - box method for fine - grained classification based on Gaussian light and shadow ( GLAS ). GLAS estimates the spatial impact of deep models by the feature perturbation inspired by Gaussian lighting and shadow in nature. It provides a useful coarseto - fine control benefiting from scalability of Gaussian mask. The authors also devised the ability to identify multiple instances through recursive GLAS. They prove the effectiveness of GLAS for fine-grained classification using the fine - Grained classification dataset using the ImageNet Large Scale Visual Recognition dataset.
SP:d17ca20cc527c28ab7358cb5b14954e5fb56409f,"This paper proposes a method to reduce the computational cost of convolutional neural networks ( CNNs ) by removing pixel - wise and channel - wise correlations before the data is fed into each layer of the network. The authors show that the deconvolution filters in the first layer of CNNs resemble the center - round structure found in biological neurons in the visual regions of the brain. The method is applied to 10 modern neural network models by replacing batch normalization within each neural network model with the method proposed in this paper. Experiments are conducted on CIFAR-10, MNIST, Fashion -MNIST, Cityscapes, and ImageNet datasets to demonstrate the effectiveness of the method."
SP:e1b0de9a36bf8359df368b7a55a7f23e99d88db7,This paper proposes a novel quantization method for GANs based on a multi - precision quantization algorithm named QGAN. The proposed method is based on existing CNN quantization methods to quantize GAN models to extreme low bits. Experiments on CIFAR-10 and CelebA show that QGAN can quantize weights to even 1 - bit or 2 - bit representations with results of quality comparable to original models. The authors also propose a multi-precision algorithm to help find an appropriate quantization precision of GAN.
SP:58c4905f59f04a50b30d27c99521126a6455d38a,"This paper proposes a new last - iterate convergence rate for gradient descent algorithms in convex - concave settings. The main contribution of the paper is to show that the Hamiltonian Gradient Descent ( HGD ) algorithm achieves linear convergence in a variety of more general settings than the bilinear and strongly convex settings. In particular, the paper introduces a novel condition on the second - order derivatives of the objective g and shows that this condition is sufficient for HGD to achieve linear convergence. The paper also shows that a stochastic version of HGD will have a last -iterate rate of O(1 / k ) in the “sufficiently bilinearly ” setting, while vanilla HGD has issues training GANs in practice. The authors also prove that a related algorithm known as Consensus Optimization ( CO ) can effectively train Generative Adversarial Networks ( GAN )."
SP:d8556b52272321a1415ac2d85bb12e88b51ee73a,"This paper studies the stability of learning ResNet. Specifically, they consider the ResNet block hl = φ(hl−1 + τ · g(hl - 1 ) + \tilde{\sqrt{L}(hl-1 ) }, where $ hl$ is the number of residual blocks and $ L$ is a scalar. They show that for standard ResNet training, stability is guaranteed for $ 1/\tilde {L}$-1/\mathbb{R}(L)$. They also show that if ResNet is properly over - parameterized, it is guaranteed to find the global convergence of gradient descent that admits global convergence in previous work. They also demonstrate that the over - parameterization requirement of ResNet only weakly depends on the depth, which corroborates the advantage of Resnet over vanilla feedforward network."
SP:cf70dc496825ece2f28fdf4f1a6f4316c69e0e48,"This paper proposes a method to train sparse neural networks with a fixed parameter count and a fixed computational cost throughout training, without sacrificing accuracy relative to existing dense - to - sparse training methods. The method updates the topology of the network during training by using parameter magnitudes and infrequent gradient calculations. The authors show that this approach requires fewer floating - point operations ( FLOPs ) to achieve a given accuracy compared to prior techniques."
SP:d2d2b892518d54d0e63e26a056f2298be3be2610,"This paper proposes a new method to control the latent space of generative models by finding meaningful directions in the latent spaces of any generative model along which to control precisely specific properties of the generated image like the position or scale of the object in the image. The method does not require human annotations and is particularly well suited for the search of directions encoding simple transformations, such as translation, zoom or color variations. The authors demonstrate the effectiveness of their method qualitatively and quantitatively, both for GANs and variational auto - auto - encoders."
SP:1c63389e972d4652fac831e9d11609cd3c3c371a,"This paper proposes a physics - as - inverse - graphics - based method for unsupervised physical parameter estimation of systems from video, where the differential equations governing the scene dynamics are known, but labeled states or objects are not available. Existing physical scene understanding methods require either object state supervision, or do not integrate with differentiable physics to learn interpretable system parameters and states. This framework allows to perform long term extrapolative video prediction, as well as vision - based model - predictive control. The paper shows that the proposed method significantly outperforms related un - supervised methods in long - term future frame prediction of systems with interacting objects ( such as ball - spring or 3 - body gravitational systems ) due to its ability to build dynamics into the model as an inductive bias."
SP:c6b8b682bf3087a65cb2379700b8a0183853c2af,"This paper proposes a method for learning a classifier from noisy labels when a few clean labeled examples are given. The proposed method is based on Graph Convolutional Networks ( GCN ), which are used to predict class relevance of noisy examples. The GCN is treated as a binary classifier learning to discriminate clean from noisy examples using a weighted binary cross - entropy loss function, and then the GCN - inferred “ clean ” probability is exploited as a relevance measure. The authors evaluate their method on an extended version of a few - shot learning problem, where the few clean examples of novel classes are supplemented with additional noisy data. They show that their method outperforms the method by Douze et al. ( 2018 ) using the same large - scale collection of data."
SP:dd9c9a5dccbba5dd15b03ca6b314a9e153e95548,"This paper proposes a new model for graph neural networks ( GNNs ) that maximizes the Mutual Information ( MI ) between edge features and message passing channels. The MI is reformulated as a differentiable objective via a variational approach via a new objective approach. The authors show that the newly introduced objective enables the model to preserve edge information, and empirically corroborate the enhanced performance of MI - maximized models across a broad range of learning tasks including regression on molecular graphs and relation prediction in knowledge graphs."
SP:f1cf63d728da51b4f83eb50ef69e3788b3a5ed74,"This paper presents a new verifier, APPROXLINE, that can certify non - trivial properties of generative networks. The verifier performs both deterministic and probabilistic abstract interpretation and captures infinite sets of outputs of the generative network. The main contribution of the paper is the introduction of a deterministic verification method for generative models. The authors show that the verifier can verify interesting interpolations in the network’s latent space. They also show that it can verify the classifier “ is bald ” is robust to different amounts of “moustache ”."
SP:2b0887dcf09249e8cee30d38163aeb9ef1e92b27,"This paper studies the suspended animation problem with existing graph neural networks ( GNNs ) based on spectral graph convolutional operator ( GCN ). In this paper, the authors propose a new graph residual learning framework GRESNET ( Graph Residual Network ) framework to address the problem of suspended animation. The proposed method is based on graph residual networks ( GRESnet ), which is a graph residual network ( GRNN ) framework. The authors provide an analysis about the causes of the problem in this paper as well as several other factors that will impact the problem as well. Experiments are conducted to show the effectiveness of the proposed method."
SP:dc436ade4d04072de35a90e5e4a1bfebfddb04e9,This paper proposes a non - linear 3D morphable model ( CNN ) based on convolutional neural networks ( CNNs ) to reconstruct the face shape and texture from a single image. CNNs are trained on a dataset that is generated from a linear 3 - D morphable models ( 3DMM ) learned from limited scan data. This paper proposes to train CNNs with adversarial loss in a semi - supervised manner to exploit the value of large amounts of unlabeled face images from unconstrained photo collections. A novel center loss is introduced to make sure that different facial images from the same person have the same identity shape and albedo.
SP:f7bc06697b09e2d59ec06b2cbcf3c0828ece32ae,"This paper proposes a model - based imitation learning method called Expert Induced Markov Decision Process ( eMDP ) to solve imitation problems using Reinforcement Learning ( RL ) when only partial knowledge about the transition kernel is available. The idea is to replace the unknown transition kernel with a synthetic kernel that simulates the transition of state components for which the kernel is known. The next state is then stitched from the two components : s = {sr, su }. The paper describes in detail the recipe for building an eM DP model and analyze the errors caused by its synthetic kernel. The experiments include imitation tasks in multiplayer games, where the agent has to imitate one expert in the presence of other experts for whom we cannot provide a transition model. The authors show that combining a policy gradient algorithm with their model achieves superior performance compared to the simulation - free alternative MDP model."
SP:82cce92821e8168ab4a6fd67573b66c1d17673b8,"This paper proposes a new self - supervised reinforcement learning method for learning to control states of interest without any external reward function. The authors propose Mutual Information - based State - Control ( MISC ), which is based on the mutual information between the context states and the states of the interest. They evaluate their approach for different simulated robotic manipulation tasks from OpenAI Gym and a navigation task in the Gazebo simulator and demonstrate that MISC enables the agent to learn skills, such as reaching, pushing, picking up, and sliding the object without rewards. They show that the pre - trained policy can be quickly adapted to the specific tasks with external sparse reward signal. The pretrained mutual information discriminator also improves the learning process of the agent."
SP:5db63d39cfd8132bec832ab64b8fbd403b3b8df0,"This paper proposes a trojan attack method for large models, which outperforms existing studies in capability, generality, and stealthiness. The attack is programmable that the malicious misclassification target is not fixed and can be generated on demand even after the victim’s deployment. The trojaned model on a large - scale dataset can affect applications of different domains that reuses its general features."
SP:35ea626ee4dd1a7a368a660eb852192924966b7f,This paper proposes a new few - shot regression ( FSR ) algorithm for drug discovery. The proposed algorithm is based on a deep network in combination with a kernel function and a differentiable kernel algorithm. The choice of kernel is critical and the algorithm learns to find the appropriate kernel for each task during inference. The algorithm is evaluated on both toy and real - world tasks and outperforms state - of - the - art algorithms.
SP:91ca4c3ee07617356250bae9f4ef9799b3b134ff,"This paper proposes a framework to characterize which reasoning tasks a network can learn well, by studying how well its computation structure aligns with the algorithmic structure of the relevant reasoning process. The authors define this algorithmic alignment and derive a sample complexity bound that decreases with better alignment. This framework offers an explanation for the empirical success of popular reasoning models, and suggests their limitations. Experimental results confirm the theory."
SP:a52aee8da5cf5acd2baf3c2a62cb679e13b18bd5,"This paper proposes a new metric called Fréchet Joint Distance ( FJD ), which is defined as the distance between joint distributions of images and conditioning distributions. The authors show that FJD can be used as a promising metric for cGAN benchmarking and model selection for hyper - parameter selection and hyper - parameter selection. Experiments are conducted on a controllable synthetic dataset, which consistently highlight the benefits of FJD when compared to existing metrics."
SP:fa822e8472efae17c7dfde8258057898383ecbbb,"This paper proposes a novel method to identify decision states in a task - agnostic manner ( DS - VIC ). The authors propose to use the VIC framework ( Gregor et al. 2016 ), which maximizes an agent's ‘empowerment ’, i.e. the ability to reliably reach a diverse set of states – and formulate a sandwich bound on the empowerment objective that allows identification of decision states. Unlike previous work ( Goyal et al. 2019, 2019 ), the decision states are discovered without extrinsic rewards – simply by interacting with the world, and are often interpretable, and lead to better exploration on downstream goal - driven tasks in partially observable environments. They show that their method is transferable and leads to improved sample - efficiency on goal -driven tasks in novel environments."
SP:a19a51df7e28a5d3380be4fba13842efbfe3efec,"This paper proposes a novel framework for classifying irregularly sampled time series with unaligned measurements, focusing on high scalability and data efficiency. The method SEFT ( Set Functions for Time Series ) is based on recent advances in differentiable set function learning, extremely parallelizable, and scales well to very large datasets and online monitoring scenarios. They extensively compare their method to competitors on multiple healthcare time series datasets and show that it performs competitively whilst significantly reducing runtime."
SP:4ae89d64460b08749acc192004545c1fa8b7553b,This paper proposes a method to train deep neural networks to model audio signals by using harmonic kernels instead of local neighborhoods as convolutional kernels. The method is called Harmonic Convolution. The authors show that the proposed method improves the performance of CNNs on unsupervised audio restoration tasks. They also show that it improves the generalization performance for supervised musical source separation tasks.
SP:c81a2b3fd1c56b9b18e4a358e3ff8b40aea5256a,"This paper proposes a data echoing method to speed up training of neural networks. The authors propose to use data echoing to reduce the total computation used by earlier stages of the training pipeline and speed up the training time. They propose to reuse intermediate outputs from earlier pipeline stages in order to reclaim idle capacity. They investigate the behavior of different data echoing algorithms on various workloads, for various amounts of echoing, and for various batch sizes. They find that in all settings, at least one data echoing algorithm can match the baseline performance using less upstream computation using less computation. They also show that in some settings, the performance of the algorithm is comparable to the baseline."
SP:b4cf56d3fa7d65cacde33f17cd04bd5bbc52dd71,"This paper proposes a novel algorithm to learn a reward function for a Markov Decision Process ( MDP ) that can generalize beyond the finite set of behaviors being explicitly learned, as may be needed in subsequent tasks. The main contribution of this paper is to address this generalization and slow inference problem by making use of another recent advance in RL, successor features ( Barreto et al. 2017 ). Successor features ( SF ) enable fast transfer learning between tasks that differ only in their reward function, which is assumed to be linear in some features. The authors show that the proposed algorithm, Variational Intrinsic Successor FeatuRes ( VISR ), improves performance in the RL with unsupervised pre - training scenario, and augment the popular 57 - game Atari suite with such an unsuper supervised phase. The proposed algorithm achieves human - level performance on 12 games and outperforms all baselines."
SP:83500230586a9134f910ad067b7233dc563dc1ba,"This paper studies the generalization properties of deep neural networks. The authors show that generalization results from smoothness of the functional approximation, combined with a flat initial approximation. The smoothness increases with number of units, explaining why massively overparameterized networks continue to generalize well. In particular, the global, rather than local, impact of breakpoints and delta - slopes helps regularize the approximating function in the large gaps between training data, resulting in their smoothness. Due to these nonlocal effects, more over parameterization leads to smoother approximations (all else equal ) and thus typically better generalization."
SP:7225825e353b711a7d023f706fafe5e17e4e2fb2,"This paper proposes an image - to - image translation method called GuideGAN based on an attention mechanism based on the attention mechanism of the discriminator. The idea is to train a discriminator with attention mechanism to estimate the probability that its input is real, but also does it create an attention map that highlights the critical features for such prediction. This attention map then assists the generator to produce more plausible and realistic images. The proposed method is evaluated on a number of image transfer tasks. The results show that the proposed method outperforms the baselines."
SP:41c089ba65393174dae1dc136f79030a0a4fc532,"This paper proposes a framework to describe a range of classical and modern neural network architectural motifs, such as gating, attention layers, hypernetworks, and dynamic convolutions amongst others. The authors conjecture that multiplicative interactions offer a particularly powerful inductive bias when fusing multiple streams of information or when conditional computation is required. They argue that they should be considered in many situation where multiple compute or information paths need to be combined, in place of the simple and oft - used concatenation operation. Finally, they back up their claims and demonstrate the potential of multiplicative interaction by applying them in large - scale complex RL and sequence modelling tasks, where their use allows us to deliver state - of - the - art results."
SP:5144391584e6d3825e12684b7c053e4e282cff2b,"This paper proposes a new algorithm for batch active learning with deep neural network models ( DNNs ). The proposed algorithm is called Batch Active Learning by Diverse Gradient Embeddings ( BADGE ), which samples groups of points that are disparate and high magnitude when represented in a hallucinated gradient space. The algorithm is designed to incorporate both predictive uncertainty and sample diversity into every selected batch. While other approaches sometimes succeed for particular batch sizes or architectures, BADGE consistently performs as well or better than other approaches for real world active learning problems."
SP:ce6023b1e6bf45b071a6f5457b2575425ae03366,"This paper proposes a self - explanation model for deep neural networks ( DNNs ). The authors propose a novel feature leveling architecture that isolates low level features from high level features on a per - layer basis to better utilize the GLM layer in the proposed architecture for interpretation. They show that their proposed architecture is able to achieve competitive performance on various real - world datasets while improving interpretability. In section 6, they show that the model is also able to automatically prune redundant hidden layers, thus reducing the complexity."
SP:b70ceead1bf6c7dc684c74501716e7012b891022,"This paper proposes an adversarial sampling method for training a classifier over a large number of classes, known as ‘ extreme classification ’. The authors propose a simple training method for drastically enhancing the gradient signal by drawing negative samples from adversarial model that mimics the data distribution.   The authors provide a mathematical proof that this adversarial method minimizes the gradient variance while any bias due to non - non - un - uniform sampling can be removed. They show a reduction of the training time by an order of magnitude relative to several competitive baselines."
SP:29b52fee83309268d9864f3b1fc3617948577d41,"This paper proposes a low - dimensional encoding of the environment learned with a combination of model based and model - free objectives. The approach uses intrinsic rewards that are based on a weighted distance of nearest neighbors in the low dimensional representational space to gauge novelty. The authors then leverage these intrinsic rewards for sample - efficient exploration with planning routines in representational spaces. One key element of the approach is that the authors perform more gradient steps in - between every environment step in order to ensure the model accuracy is high ( and hence ensure an accurate model accuracy ). They test their approach on a number of maze tasks, as well as a control problem and show that their exploration approach is more sample -efficient compared to strong baselines."
SP:257c98dc1a9f3efcbf9544d9ee2ff524b000543d,"This paper proposes two new methods for out - of - distribution detection in the few - shot classification setting. The authors propose two new benchmark datasets for out of distribution detection and establish benchmark datasets, based on four popular few -shot classification datasets. The proposed methods are evaluated on two benchmark datasets and compared to two baselines. The results show that the proposed methods perform better than the baselines on out of distributed detection.  "
SP:a3632b773143dfb3a8f104c6b658dfa1167d155b,"This paper proposes a generalized model of sequence generation that unifies decoding in directed and undirected models. The proposed framework models the process of generation rather than a resulting sequence, and under this framework, the authors derive various neural sequence models as special cases, such as autoregressive, semi - autore progressive, and refinement - based non -autoregressive models. This unification enables the authors to adapt decoding algorithms originally developed for directed sequence models to undirectED models. They also demonstrate that the proposed approach enables constant - time translation with similar performance to linear time translation from the same model. The experiments show that generation from the proposed model is competitive with the state of the art on WMT’14 English - German translation."
SP:eca5e2be9831dfb79c4f5e633cbfadcfd2e00eb1,"This paper proposes a two - stage method for the recognition of mathematical expressions ( MEs ) in real - world scenes. In the first stage, the method locates and recognizes the math symbols of input image by object detection algorithm, and in the second stage, it translates math symbols with position information into LaTeX sequences by seq2seq model equipped with attention mechanism. In particular, the detection of mathematical symbols and the structural analysis of mathematical formulas are carried out separately in two steps, which effectively improves the recognition accuracy and enhances the generalization ability. The experiment shows that the two stage method significantly outperforms the end - to - end method."
SP:923fee8623da1569a7f54a57b4b326f29440b4c0,This paper proposes a vector quantization method that aims at preserving the quality of the reconstruction of the network outputs rather than its weights. The method only requires a set of unlabelled data at quantization time and allows for efficient inference on CPU by using bytealigned codebooks to store the compressed weights. They validate their approach by quantizing a high performing ResNet-50 model to a memory size of 5 MB ( 20× compression factor ) while preserving a top - 1 accuracy of 76.1% on ImageNet object classification and by compressing a Mask R - CNN with a 26× factor. They show that applying their approach to the semi - supervised ResNet - 50 of Yalniz et al. 2019 leads to a 5 MB memory footprint and a 76 1% top -1 accuracy on image classification.
SP:74850ad70241948f93fed95ba1f0ac11360437c1,"This paper proposes a novel attention mechanism, called TP - Attention, which encodes the relations between each Transformer cell and the other cells from which values have been retrieved by attention. The paper proposes to use TensorProduct Transformer ( TP - Transformer ) in order to better support the explicit representation of relation structure within the Transformer. The TP - Attention goes beyond linear combination of retrieved values, strengthening representation - building and resolving ambiguities introduced by multiple layers of standard attention. It is shown theoretically how the proposed TP -Attention avoids such ambiguity from the binding problem."
SP:d319df820c6630c409fab32097652a083e8f53ea,"This paper proposes a method to generalize deep neural networks based on the Kolmogorov complexity metric based on information distance, which is a universal cognitive similarity metric. The authors derive a necessary and sufficient condition for generalization using this metric and formulate an optimization problem to learn a more general classification function. To achieve this end, they extend the input features to a classifier with systematically generated encodings of the original features. Experiments show that a model trained on encoded input features is significantly more robust to common corruptions, e.g. Gaussian and shot noise, as well as adversarial perturbations, than the models trained on uncoded input features."
SP:b8e86f5e89330d81ba4967a7ed2dbfb56375d8a0,This paper proposes a new graph pooling method based on Haar transforms for deep graph neural networks ( GNNs ). The proposed method is called HaarPooling and is based on a chain of sequential clusterings of the input graph. The input of each pooling layer is transformed by the compressive Haar basis of the corresponding clustering. The method is evaluated on a variety of graph classification and graph - based regression tasks. The experimental results show that the proposed method outperforms existing methods on the benchmark graph classification tasks.
SP:17bea301d6718ef5f28864dd2445552b3cf65eeb,"This paper proposes a new point cloud decoder architecture that matches the semantics of variable - sized point clouds with a sample - based decoder network that maps a shape representation to a point feature distribution, allowing an arbitrary number of sampled features to be transformed into individual output points. The proposed method is based on the PointNet encoder network, which maps shape representations to a distribution of point features. The authors show that the proposed method improves the performance of the decoder networks compared to feedforward decoders. They also propose a new noise learning algorithm to learn the shape representation of the point clouds."
SP:51d826ead5d1d9cb89d493ce4c39728651bbc57b,"This paper studies the effect of real - world noise on deep neural networks ( DNNs ) on their performance on noisy labels. The authors conduct a large - scale study across a variety of noise levels and types, architectures, methods, and training settings. They show that DNN generalize much better on real world noise than on synthetic noise. They also show that when networks are fine - tuned, ImageNet architectures generalize well on noisy data. Finally, they show that Robust learning methods that work well on synthetic noisy data may not work as well on real-world noise."
SP:9873f78fb2821afdbb5551700e6ab6a0e8bcb9f0,"This paper proposes a rule - inspired supervision method to collect human supervision to combine the efficiency of rules with the quality of instance labels. The supervision is coupled such that it is both natural for humans and synergistic for learning. The training algorithm jointly denoises rules via latent coverage variables, and trains the model through a soft implication loss over the coverage and label variables. The denoised rules and trained model are used jointly for inference. Empirical evaluation on five different tasks shows that the proposed method is more accurate than several existing methods of learning from a mix of clean and noisy supervision."
SP:6f2c656dbb7629f652a4291d6971625184d8118b,This paper proposes a new memory layer for graph neural networks ( GNNs ) based on memory - based GNN ( MemGNN ) and graph memory network ( GMN ) that can learn hierarchical graph representations. Experiments show that the proposed models achieve state - of - the - art results in eight out of nine graph classification and regression benchmarks. The learned representations could correspond to chemical features in the molecule data.
SP:81bc52d734c86975d741b6482d65ca71a9d81620,"This paper presents a theoretical analysis of the effect of initialization in deep linear networks on the convergence of neural networks. The authors show that the width needed for efficient convergence to a global minimum with orthogonal initializations is independent of the depth and Gaussian initializations scales linearly in the depth. They also show that Gaussian initialization leads to exponentially long convergence time if the width is too small compared with the depth in the network. Finally, they conduct experiments to support their theoretical results and show that a good initialization can persist throughout learning."
SP:9f5d95fc89c2f0d59d04838aa180f3db67997dfa,"This paper proposes a method to compress deep neural networks down to 2 bits without losing accuracy. The authors propose a method based on Lagrangian formulation to optimize the bit allocation of weights and activations for deep CNNs compression. They first explore the additivity of output error caused by quantization and find that additivity property holds for deep neural network which are continuously differentiable in the layers. Based on this observation, they formulate the optimal bit allocation problem and propose a very efficient method to solve the optimization problem. Their method obtains excellent results on deep CNN ResNet-50 down to two bits with only 0.7% accuracy loss. To the best of the knowledge, this is the first paper that reports 2 - bit results on Deep CNNs without hurting the accuracy."
SP:7191d7b217a12b1bf9c47d790896a8227c14cc3d,"This paper proposes a novel inference framework for generative adversarial networks ( GANs ) based on the Wasserstein distance. The authors propose to fuse the variational auto - encoder network ( VAEs ) and GAN ( WGANs ) to learn a generative model using an iterative primal dual optimization process ( iWGAN ).   The authors provide a generalization error bound for the iwGANs and a probabilistic interpretation of their model under the framework of maximum likelihood estimation. The empirical experiments show that their model greatly mitigates the mode collapse, speeds up the convergence, and is able to provide a measurement of quality check for each individual sample."
SP:cca6ae14fd0dd12352855e594acf7f3263bb1f24,"This paper proposes to extend the MPA model of anaphoric annotation ( MPA ) to alleviate the effects of sparsity inherent in some crowdsourcing environments. Specifically, the authors propose to use a nonparametric partially pooled structure ( based on a stick breaking process ) based on the ability of the annotators hierarchical community profiles. The individual estimates can thus be improved using information about the community when the data is scarce. The proposed model is thus more resilient to different crowdsourcing setups, and, further provides insights into the community of workers. The model is also flexible enough to be used in standard annotation tasks for classification where it registers on par performance with the state of the art."
SP:4295cae4a56a02eb21c486408c1bf37a7483cb49,"This paper proposes a method for sparse reward reinforcement learning ( DRL ) that combines intrinsic motivation and extrinsic reward. The authors propose a new type of intrinsic reward called successor feature control ( SFC ), which is general and not task - specific. They also propose a hierarchical exploration framework ( SID ) to accelerate exploration and stabilize learning. They evaluate their proposed intrinsic reward SFC agent using three different environments with pure visual inputs : VizDoom, DeepMind Lab and DeepMind Control Suite. The results show a substantially improved exploration efficiency with SFC and hierarchical usage of the intrinsic drives."
SP:9fa22eb03a79bce0fc1c8e84ae8640e010701eca,"This paper proposes a method for weakly supervised video moment retrieval based on a multi - level co - attention mechanism to learn richer multimodal representations. The proposed method is comprised of a Frame - By - Word interaction module as well as a novel Word - Conditioned Visual Graph ( WCVG ). The authors also incorporate a novel application of positional encodings, commonly used in Transformers, to learn visual - semantic representations that contain contextual information of their relative positions in the temporal sequence through iterative message - passing. The experiments on the DiDeMo and CharadesSTA datasets demonstrate the effectiveness of the combined wMAN model."
SP:27ac670353f34ee7a23bb7622f80c1dfbc0985e0,"This paper proposes a novel neural image - guided rendering method that combines the benefits of image - based rendering and GAN - based image synthesis. The goal of the method is to generate photo - realistic re - renderings of reconstructed objects for virtual and augmented reality applications ( e.g., virtual showrooms, virtual tours & sightseeing, the digital inspection of historical artifacts ). A core component of the approach is the handling of view - dependent effects in the source and the target views using EffectsNet that can be learned in a self - supervised fashion. The composition of the reprojected views to a final output image without the need of hand - crafted blending schemes is enabled using a network called CompositionNet. The authors demonstrate the effectiveness of their approach both qualitatively and quantitatively on synthetic and real data."
SP:257d124367b1da9a595dc11a9df750d6bade298e,"This paper presents a sparse representation of model uncertainty for deep neural networks ( DNNs ) that relies on an inverse formulation of Multivariate Normal Distribution ( MND ), an information form. The paper shows that the model uncertainty can be estimated in this form using a scalable Laplace Approximation scheme, which involves a diagonal correction of the Kronecker - factored eigenbasis. As this makes the inversion of the information matrix intractable an operation that is required for a full Bayesian analysis, the paper further devise a novel low - rank approximation that exploits spectral sparsity of deep neural network. The methods to realize this sparsification are provided that develops into a memory - wise tractable sampling computations. Both of the theoretical analysis and empirical evaluations over various benchmarks show the superiority of their approach over existing methods."
SP:2e03ceba4004b82f86f8349352a8ee4520e9c35d,This paper proposes a method to compute set similarities and compact high - dimensional data for efficient learning and searching. The authors propose a method called Amortization Hashing ( AHash ) which can generate as few empty bins as possible without hurting runtime efficiency compared with OPH and densification strategies. The proposed method is evaluated on a variety of datasets.
SP:d73827ab98b0ff6bd92abfefea43a5f88ea40de2,"This paper proposes a method for extracting features from phase shift data by adding a graph structure to each data point and constructing a suitable machine learning architecture for graph data with cyclic permutation to a graph neural network. This method assures that the results account for the order in which all of the points are collected, which is difficult for classical methods, like multi - layer perceptron, to identify or quantify these alterations because they depend on the order of the input vectors’ components. It is not necessary to consider the vertex order in the graph originally, but it is necessary to give the order for computability. The authors identify the graphs whose vertex orders are different due to phase shifts. The conventional graph neural networks regard them different. Therefore, they propose a method that intentionally focuses on shift invariance by acting   cyclically permutation by acting cyclically to a Graph Neural Network. The use of this method offers predictions with sufficient accuracies for idealized data and experimental data obtained from a test setup."
SP:0df5ad333eb4ff9cca7f2d117909e2ce533a65d8,"This paper proposes a confidence - oriented decoder that assigns a confidence score to each target position in Neural conditional text generation systems. The confidence score is learned in training using a variational Bayes objective, and can be leveraged at inference time using a calibration technique to promote more faithful generation. Experiments on a structured data - to - text dataset – WikiBio ( Lebret et al., 2016 ) show that the proposed method is more faithful to the source than existing state - of - the - art approaches, according to both automatic metrics and human evaluation."
SP:03307deac29173b2968fbd08f95fc77eb1f82410,"This paper proposes to extend the magnitude - based pruning method from a single layer optimization to a multi - layer optimization. The proposed method, called lookahead pruning, is motivated by the observation that the magnitude-based pruning minimizes the Frobenius distortion of a linear operator corresponding to a single - layer operator. The authors show that the proposed method outperforms magnitude - basing pruning on various networks, including VGG and ResNet, particularly in the high - sparsity regime."
SP:dc80fdc75bc14ae19fe4ba9b85c35ce00b12856f,"This paper proposes a decentralized SGD algorithm called Moniqua that uses quantized communication to communicate with SGD. The authors prove in theory that the proposed algorithm can communicate a provably bounded number of bits per iteration, while converging at the same asymptotic rate as the original algorithm does with full - precision communication. They also show that the algorithm is robust to very low bit - budgets, allowing less than 4 - bits - per - bit."
SP:86c61a658d07ab86e2d84cef7e480bf7a06e4ddb,"This paper proposes a family of partial models that are provably correct, yet remain fast because they do not need to fully model future observations. They show that partial models can be causally incorrect : they are confounded by the observations they don’t model, and can therefore lead to incorrect planning. To address this, the authors propose a general family of viable solutions and empirically investigate their effects on models learned in illustrative environments ( simple MDPs and 3D environments )."
SP:c70479b2096a52584b242de58272ca8d8565feea,This paper proposes a variational autoencoder ( VAE ) model that learns a succinct common representation of two correlated data variables for conditional and joint generation tasks. The proposed Wyner VAE model is based on two information theoretic problems — distributed simulation and channel synthesis — in which Wyner ’s common information arises as the fundamental limit of the succinctness of the common representation. The paper proposes an encoder - encoder method for learning the model based on the optimization problem. Experimental results show that the proposed model achieves better generative performance and outperforms existing VAE variants.
